these findings extend our previously revealed mechanism for the integration of letters and speech sounds and demonstrate that fmr-a is sensitive to multisensory congruency effects that may not be revealed in bold amplitude per se.
the results revealed an occipital-temporal network that adapted independently of the audiovisual relation.
we predicted that if multisensory neuronal populations exist in stc and encode audiovisual content relatedness, adaptation should be affected by the manipulated audiovisual relation.
these results suggest that the revealed clusters contain multisensory neuronal populations that encode content relatedness by selectively responding to congruent audiovisual inputs, since unisensory neuronal populations are assumed to be insensitive to the audiovisual relation.
however, a still unanswered question is how superior temporal cortex encodes content-based associations, especially in light of inconsistent results from studies comparing brain activation to semantically matching  versus nonmatching  multisensory inputs.
many functional magnetic resonance imaging  studies propose the  superior temporal cortex  as the key structure for integrating meaningful multisensory information.
we presented repetitions of audiovisual stimuli  and manipulated the associative relation between the auditory and visual inputs .
interestingly, several smaller clusters distributed over superior temporal cortex within that network, adapted stronger to congruent than to incongruent audiovisual repetitions, indicating sensitivity to content congruency.
