we analyze data from a mixture experiment where genomic dna samples from pairs of individuals of known genotypes are pooled to create allelic imbalances at varying levels for the majority of snps on the array.
we observe that goldengate has less sensitivity at detecting subtle allelic imbalances  compared to extreme imbalances, and note the benefit of applying local background correction to the data.
throughout this paper, we find that a linear model analysis of the data from each snp is a flexible modelling strategy that allows for testing of allelic imbalances in each sample when replicate hybridizations are available.
our analysis shows that local background correction carried out by illumina's software, together with quantile normalization of the red and green channels within each array, provides optimal performance in terms of false positive rates.
analysis of data from a dye-swap control experiment allowed us to quantify dye-bias, which can be reduced considerably by careful normalization.
high-throughput measurement of allele-specific expression  is a relatively new and exciting application area for array-based technologies.
the need to filter the data before carrying out further downstream analysis to remove non-responding probes, which show either weak, or non-specific signal for each allele, was also demonstrated.
in addition, we strongly encourage intensity-based filtering to remove snps which only measure non-specific signal.
