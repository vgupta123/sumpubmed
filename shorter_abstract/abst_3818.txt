l <dig> mkl yields better performance on most of the benchmark data sets.
this paper extends the statistical framework of genomic data fusion based on mkl.
to tackle the computational burden of mkl, this paper proposes several novel lssvm based mkl algorithms.
systematic comparison on real data sets shows that lssvm mkl has comparable performance as the conventional svm mkl algorithms.
this paper introduces the notion of optimizing different norms in the dual problem of support vector machines with multiple kernels.
understanding the dual l <dig> problem grants a unified view on mkl and enables us to extend the l <dig> method to a wide range of machine learning problems.
the experiments are carried out on six real biomedical data sets and two large scale uci data sets.
we provide a theoretical analysis of the relationship between the l <dig> optimization of kernels in the dual problem with the l <dig> coefficient regularization in the primal problem.
in real biomedical applications, l <dig> mkl may have more advantages over sparse integration method for thoroughly combining complementary information in heterogeneous data sources.
moreover, large scale numerical experiments indicate that when cast as semi-infinite programming, lssvm mkl can be solved more efficiently than svm mkl.
in particular, l <dig> mkl is a novel method that leads to non-sparse optimal kernel coefficients, which is different from the sparse kernel coefficients optimized by the existing l∞ mkl method.
allowing non-sparse weights on the data sources is an attractive option in settings where we believe most data sources to be relevant to the problem at hand and want to avoid a "winner-takes-all" effect seen in l∞ mkl, which can be detrimental to the performance in prospective studies.
we implement l <dig> mkl for ranking and classification problems and compare its performance with the sparse l∞ and the averaging l <dig> mkl methods.
in particular, we propose a novel l <dig> mkl least squares support vector machine  algorithm, which is shown to be an efficient and promising classifier for large scale data sets processing.
the selection of norms yields different extensions of multiple kernel learning  such as l∞, l <dig>  and l <dig> mkl.
