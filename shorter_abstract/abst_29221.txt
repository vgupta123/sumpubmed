frequently applied linear correlation measures, which are often used on an ad-hoc basis without further justification, are thereby extended.
this concept is subsequently illustrated on two large-scale gene expression datasets and the results are compared to those obtained using other similarity measures.
since mutual information is defined in terms of discrete variables, its application to continuous data requires the use of binning procedures, which can lead to significant numerical errors for datasets of small or moderate size.
the information theoretic concept of mutual information provides a general framework to evaluate dependencies between variables.
in this work, we propose a method for the numerical estimation of mutual information from continuous data.
the utilisation of mutual information as similarity measure enables the detection of non-linear correlations in gene expression datasets.
in the context of the clustering of genes with similar patterns of expression it has been suggested as a general quantity of similarity to extend commonly used linear measures.
