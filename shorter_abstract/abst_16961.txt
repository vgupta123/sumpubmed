using correlation statistics proved to be more effective than using p-values for correctly ranking candidate interactions.
furthermore, the reconstruction of the regulatory network of the transcription factor ikaros in human peripheral blood mononuclear cells  is presented as a case-study.
the results from the pbmc case-study indicate that the findings of the present study generalize to different types of network reconstruction algorithms.
furthermore, both approaches outperformed  the na√Øve solution of merging data together ignoring possible biases, and  the results that are expected when only one dataset out of the available ones is analyzed in isolation.
ignoring the systematic variations that differentiate heterogeneous studies can produce results that are statistically indistinguishable from random guessing.
integrating multiple datasets is generally believed to provide increased statistical power and to lead to a better characterization of the system under study.
this comparative evaluation is performed on both synthetic and real data, the latter consisting of two manually curated microarray compendia comprising several e. coli and yeast studies, respectively.
the meta-analysis and data-merging methods included in our experimentations provided comparable performances on both synthetic and real data.
meta-analysis and data merging methods have proved equally effective in addressing this issue, and thus researchers may safely select the approach that best suit their specific application.
however, the presence of systematic variation across different studies makes network reverse-engineering tasks particularly challenging.
we contrast two approaches that have been frequently used in the literature for addressing systematic biases: meta-analysis methods, which first calculate opportune statistics on single datasets and successively summarize them, and data-merging methods, which directly analyze the pooled data after removing eventual biases.
