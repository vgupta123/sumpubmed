the mixture variance model provides a realistic and flexible estimate for the variance of gene expression data under limited replicates.
we believe that in using the latent class variances, estimated from a larger number of genes in each derived latent group, the p-values obtained are more robust than either using a constant gene or gene-specific variance estimate.
the result is that genes in the same latent class share the similar variance, estimated from a larger number of replicates than purely those per gene, i.e.
the total of all replicates of all genes in the same latent class.
an example dataset, consisting of  <dig> genes with four replicates per condition, resulted in four latent classes based on their similarity of the variance.
we propose a bayesian mixture model, which classifies genes according to similarity in their variance.
an alternative strategy is to assume independent gene-specific variances; although again this is problematic as variance estimates based on few replications are highly unstable.
thus, estimates of gene variances are inaccurate.
in many laboratory-based high throughput microarray experiments, there are very few replicates of gene expression levels.
more meaningful and reliable comparisons of gene expression might be achieved, for different conditions or different tissue samples, where the test statistics are based on accurate estimates of gene variability; a crucial step in the identification of differentially expressed genes.
