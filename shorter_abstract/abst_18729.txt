previous attempts to use computerized structure comparison methods show only partial agreement with curated databases, but have failed to provide detailed statistical and structural analysis of the causes of these divergences.
some of the observed divergences can probably be addressed with better structure comparison methods and better automatic, intelligent classification procedures.
specifically, variations of the "common core" of some folds are severe enough to defeat attempts to automatically detect structural similarity and/or to lead to false detection of similarity between domains in distinct folds.
at a low  false positive rate,  <dig> to 38% of domain pairs in the same scop folds do not appear similar.
current classification of protein folds are based, ultimately, on visual inspection of similarities.
we construct a map of similarities/dissimilarities among manually defined protein folds, using a score cutoff value determined by means of the receiver operating characteristics curve.
finally, the common core within a structure may be too small relative to the entire structure, to be recognized as the basis of similarity to another.
structures in different folds may contain similar substructures, which produce false positives.
our results suggest either that some of these folds are defined using criteria other than purely structural consideration or that the similarity measures used do not recognize some relevant aspects of structural similarity in certain cases.
others may be intrinsic to the problem, suggesting a continuous rather than discrete protein fold space.
it identifies folds which appear to overlap or to be "confused" with each other by two distinct similarity measures.
it also identifies folds which appear inhomogeneous in that they contain apparently dissimilar domains, as measured by both similarity measures.
