we explored two use scenarios: one in which chunkers are trained on an ssc in a new domain for which a gsc is not available, and one in which chunkers are trained on an available, although small gsc but supplemented with an ssc.
we conclude that an ssc can be a viable alternative for or a supplement to a gsc when training chunkers in a biomedical domain.
to train chunkers in recognizing noun phrases and verb phrases in biomedical text, an annotated corpus is required.
for the first scenario, we showed that the systems trained for noun-phrase recognition on the ssc in one domain performed  <dig> - <dig>  percentage points better in terms of f-score than the systems trained on the gsc in another domain, and only  <dig> - <dig>  percentage points less than when they were trained on a gsc in the same domain as the ssc.
whether the approach is applicable to other systems in a natural-language processing pipeline has to be further investigated.
a combined system only shows improvement if the ssc is used to supplement a gsc.
the combined system even performed better than any of the individual chunkers trained on a gsc of  <dig> abstracts.
gscs therefore tend to be small and to focus on specific subdomains, which limits their usefulness.
