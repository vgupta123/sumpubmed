in an application to discover biomarkers for breast cancer patients based on gene expression data, stability selection yielded sparser models and the resulting discriminatory power was higher than with lasso penalized cox regression models.
the performance of the approach, which works best for small numbers of informative predictors, is demonstrated in a large scale simulation study: c-index boosting in combination with stability selection is able to identify a small subset of informative predictors from a much larger set of non-informative ones while controlling the per-family error rate.
the combination of stability selection and c-index boosting can be used to select small numbers of informative biomarkers and to derive new prediction rules that are optimal with respect to their discriminatory power.
those are, however, not necessarily optimal with respect to the resulting discriminatory power and are based on restrictive assumptions.
when constructing new biomarker or gene signature scores for time-to-event outcomes, the underlying aims are to develop a discrimination model that helps to predict whether patients have a poor or good prognosis and to identify the most influential variables for this task.
the gradient boosting algorithm is combined with the stability selection approach to enhance and control its variable selection properties.
stability selection controls the per-family error rate which makes the new approach also appealing from an inferential point of view, as it provides an alternative to classical hypothesis tests for single predictor effects.
time-to-event databoostingstability selectionconcordance indexvariable selectionhigh-dimensional datadeutsche forschungsgemeinschaftschm 2966/1-2schmid matthias interdisciplinary center for clinical researchj49mayr andreas issue-copyright-statementÂ© the author 2016
due to this objective function, the resulting prediction models are optimal with respect to their ability to discriminate between patients with longer and shorter survival times.
the resulting algorithm fits prediction models based on the rankings of the survival times and automatically selects only the most stable predictors.
due to the shrinkage and variable selection properties of statistical boosting algorithms, the latter tests are typically unfeasible for prediction models fitted by boosting.
we present a combined approach to automatically select and fit sparse discrimination models for potentially high-dimensional survival data based on boosting a smooth version of the concordance index .
