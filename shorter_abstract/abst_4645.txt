in contrast, a generalized linear model  is very interpretable especially when forward feature selection is used to construct the model.
this random generalized linear model  predictor provides variable importance measures that can be used to define a “thinned” ensemble predictor  that retains excellent predictive accuracy.
rglm is a state of the art predictor that shares the advantages of a random forest  with those of a forward selected generalized linear model .
however, forward feature selection tends to overfit the data and leads to low predictive accuracy.
a novel bootstrap aggregated  glm predictor that incorporates several elements of randomness and instability  often outperforms a host of alternative prediction methods including random forests and penalized regression models .
comprehensive evaluations involving hundreds of genomic data sets, the uci machine learning benchmark data, and simulations are used to give glm based ensemble predictors a new and careful look.
ensemble predictors such as the random forest are known to have superior accuracy but their black-box predictions are difficult to interpret.
therefore, it remains an important research goal to combine the advantages of ensemble predictors  with the advantages of forward regression modeling .
to address this goal several articles have explored glm based ensemble predictors.
since limited evaluations suggested that these ensemble predictors were less accurate than alternative predictors, they have found little attention in the literature.
