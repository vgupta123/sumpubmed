due to the dynamic selection property of feature selection, it is hard to define significant features for the classifier, which predicts classes of future samples.
the main input to this class predictors are high dimensional data with many variables and few observations.
in this paper, we propose a new data-driven bandwidth selection criterion for kpca, which is related to least squares cross-validation for kernel density estimation.
then, we compare its performances  and computational time) with other well known techniques such as whole data set + ls-svm, pca + ls-svm, t-test + ls-svm, prediction analysis of microarrays  and least absolute shrinkage and selection operator .
both feature selection and feature transformation perform well on classification tasks.
we propose, evaluate, and compare several mathematical/statistical techniques, which apply feature transformation/selection for subsequent classification, and consider its application in medical diagnostics.
moreover, the proposed strategy enjoys a distinctive advantage with its relatively lesser time complexity.
disease class predictors can be designed for known disease cases and provide diagnostic confirmation or clarify abnormal cases.
dimensionality reduction of these features set significantly speeds up the prediction task.
studies show that a well tuned kernel pca  is an efficient preprocessing step for dimensionality reduction, but the available bandwidth selection method for kpca was computationally expensive.
