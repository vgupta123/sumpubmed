vision-based surveillance and monitoring is a potential alternative for early detection of respiratory disease outbreaks in urban areas complementing molecular diagnostics and hospital and doctor visit-based alert systems.
we also developed a suitable novel algorithm by introducing two types of action matching kernels, where both types aim to integrate two aspects of local features, namely the space-time layout and the bag-of-words representations.
in particular, we show that the pyramid match kernel and spatial pyramid matching are both special cases of our proposed kernels.
visible actions representing typical flu-like symptoms include sneeze and cough that are associated with changing patterns of hand to head distances, among others.
in this paper, we make a first attempt at the challenging problem of recognizing flu-like symptoms from videos.
our sneeze and cough video dataset and newly developed action recognition algorithm is the first of its kind and aims to kick-start the field of action recognition of flu-like symptoms from videos.
the technical difficulties lie in the high complexity and large variation of those actions as well as numerous similar background actions such as scratching head, cell phone use, eating, drinking and so on.
since there was no related dataset available, we created a new public health dataset for action recognition that includes two major flu-like symptom related actions  and a number of background actions.
empirically, we observe that our approach achieves competitive performance compared to the state-of-the-arts, while recognition on the new public health dataset is shown to be a non-trivial task even with simple single person unobstructed view.
it will be challenging but necessary in future developments to consider more complex real-life scenario of detecting these actions simultaneously from multiple persons in possibly crowded environments.
