it achieves this objective on two fronts: first, by reducing development time of parallel programs by avoiding reimplementation of existing methods and second, by reducing processing time by speeding up computations on current desktop computers.
such methods can be quickly reused and adapted to each particular experiment.
we have designed and implemented an r add-on package, r/parallel, that extends r by adding user-friendly parallel computing capabilities.
because r does not support parallel computations, several tools have been developed to enable such technologies.
however, in experiments where large amounts of data are generated, for example using high-throughput screening devices, the processing time required to analyze data is often quite long.
a solution to reduce the processing time is the use of parallel computing technologies.
with no need to change the implemented algorithms, the processing time can be approximately reduced n-fold, n being the number of available processor cores.
with r/parallel any bioinformatician can now easily automate the parallel execution of loops and benefit from the multicore processor power of today's desktop computers.
future work is focused on extending the envelope of r/parallel by interconnecting and aggregating the power of several computers, both existing office computers and computing clusters.
r is the preferred tool for statistical analysis of many bioinformaticians due in part to the increasing number of freely available analytical methods.
r/parallel saves bioinformaticians time in their daily tasks of analyzing experimental data.
