parameter performance demonstrated wide variability on both low and high p/n data.
our findings demonstrate that parameterization is highly correlated with prediction accuracy and variable importance measures .
therefore, there is significant benefit to be gained by model tuning rfs away from their default parameter settings.
its popularity has been increasing, but relatively few studies address the parameter selection process: a critical step in model fitting.
we examined the effects of parameter selection on classification performance using the rf machine learning algorithm on two biological datasets with distinct p/n ratios: sequencing summary statistics  and microarray-derived data .
the random forest  algorithm for supervised machine learning is an ensemble learning method widely used in science and many other fields.
due to numerous assertions regarding the performance reliability of the default parameters, many rf models are fit using these values.
further, we demonstrate that different parameters are critical in tuning different datasets, and that parameter-optimization significantly enhances upon the default parameters.
