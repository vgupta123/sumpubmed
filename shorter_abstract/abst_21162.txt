we investigate three different approaches: early, intermediate and late integration, which respectively combine features, kernels over feature subsets, and decisions.
the percentage of false positives can be decreased to less than  <dig>  by rejecting  <dig> per cent using late integration.
we find that in both early and late integration, combining inputs or decisions is useful in increasing accuracy.
computational prediction of protein stability change due to single-site amino acid substitutions is of interest in protein design and analysis.
by implementing different machine learning integration approaches, we combine information from different features or representations.
the server for stability prediction for three integration approaches and the data sets are available at .
newly added features, namely, local compositional packing and the mobility extent of the mutated residues, improve accuracy significantly with intermediate integration.
intermediate integration allows assessing the contributions of individual features by looking at the assigned weights.
we consider the following four ways to improve the performance of the currently available predictors:  we include additional sequence- and structure-based features, namely, the amino acid substitution likelihoods, the equilibrium fluctuations of the alpha- and beta-carbon atoms, and the packing density.
overall accuracy of regression is not better than that of classification but it has less false positives, especially when combined with the reject option.
the highest accuracy is  <dig>  on cross-validation and  <dig>  on testing using only sequence information.
for s <dig> data set, our highest accuracy using both sequence and structure information is  <dig>  on cross-validation and  <dig>  on testing using early integration.
we compare classification vs. regression methods to predict the sign vs. the output of stability change.
for s <dig> data set, we also train regression methods to estimate not only the sign but also the amount of stability change and apply risk-based classification to reject when the learner has low confidence and the loss of misclassification is high.
we allow a reject option for doubtful cases where the risk of misclassification is high.
