we identify and complete a novel tokenizer design pattern and suggest a systematic approach to tokenizer creation.
tokenization is an important component of language processing yet there is no widely accepted tokenization method for english texts, including biomedical texts.
in doing so, pos tag sequences and training data have a significant impact on proper text tokenization.
the idiosyncratic nature of each biomedical tokenizerâ€™s output complicates adoption and reuse.
our machine learning approach differs from the previous split-join classification approaches.
furthermore, biomedical tokenizers generally lack guidance on how to apply an existing tokenizer to a new domain .
other than rule based techniques, tokenization in the biomedical domain has been regarded as a classification task.
we implement a tokenizer based on our design pattern that combines regular expressions and machine learning.
our evaluation of our design pattern and guidelines supports our claim that the design pattern and guidelines are a viable approach to tokenizer construction .
medpost and our adapted viterbi tokenizer performed best with a  <dig> % and  <dig> % accuracy respectively.
we evaluate our approach against three other tokenizers on the task of tokenizing biomedical text.
biomedical classifier-based tokenizers either split or join textual objects through classification to form tokens.
12- <dig> december  <dig> machine learning for biomedical literature analysis and text retrieval in the international conference for machine learning and applications  <dig> washington, dc, usa
our evaluation also demonstrates that ambiguous tokenizations can be disambiguated through pos tagging.
