such a query is challenging because the amount of information attached to a single abstract is little, whereas classification-based retrieval algorithms are optimally trained with large sets of relevant documents.
as a solution to this problem, we propose a query expansion method that extends the information related to a manuscript using its cited references.
this query expansion method performed significantly better than pseudo relevance feedback in  <dig> out of  <dig> topics.
cited references from particular sections might not be appropriate for all topics.
best performance was often obtained when using all cited references, though using the references from introduction and discussion sections led to similarly good results.
data on cited references and text sections in  <dig>  full-text biomedical articles was extracted from the open access subset of the pubmed centralÂ® database .
classification performance was sensitive to the topic and also to the text sections from which the references were selected.
our method could be a better alternative to pseudo relevance feedback though it is limited by full text availability.
