in our simulations, both sparse and non-sparse methods are able to reconstruct networks with cluster structures.
on six real data sets, we also clearly distinguish the results obtained using the non-sparse methods and those obtained using the sparse methods where specification of the regularization parameter automatically means model selection.
in this article, we investigate a general framework for combining regularized regression methods with the estimation of graphical gaussian models.
in our simulation studies, the investigated non-sparse regression methods, i.e.
for networks with higher densities, the difference in performance of the methods decreases.
a key issue when the number of variables greatly exceeds the number of samples is the estimation of the matrix of partial correlations.
in addition, all proposed algorithms are implemented in the r package "parcor", available from the r repository cran.
furthermore, for data that violate the assumption of uncorrelated observations , the lasso and the adaptive lasso yield very complex structures, indicating that they might not be suited under these conditions.
ridge regression and partial least squares, exhibit rather conservative behavior when combined with  false discovery rate multiple testing in order to decide whether or not an edge is present in the network.
in five out of six data sets, partial least squares selects very dense networks.
since the  inverse of the sample covariance matrix leads to poor estimates in this scenario, standard methods are inappropriate and adequate regularization techniques are needed.
for sparse networks, we confirm the lasso's well known tendency towards selecting too many edges, whereas the two-stage adaptive lasso is an interesting alternative that provides sparser solutions.
graphical gaussian models are popular tools for the estimation of  gene association networks from microarray data.
these methods are extensively compared both qualitatively and quantitatively within a simulation study and through an application to six diverse real data sets.
this framework includes various existing methods as well as two new approaches based on ridge regression and adaptive lasso, respectively.
popular approaches include biased estimates of the covariance matrix and high-dimensional regression schemes, such as the lasso and partial least squares.
the shrinkage approach is more stable than the regression based approaches when using subsampling.
