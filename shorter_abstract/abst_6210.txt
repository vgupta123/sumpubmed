our mixed model is suitable for ranking purposes whereas our hierarchical model is better for filtering.
only extracting likely positive data, however, will bias the classification model unless sufficient negative data is also added.
unfortunately, negative data is very hard to obtain because there are no resources that compile such information.
therefore, our second aim is to select such negative data from unlabeled pubmed data.
thirdly, we explore how to exploit these likely positive and negative data.
our first goal in this paper is to find a method of selecting likely positive data from such supplementary databases.
although many ppi databases with large numbers of labeled articles are available, incorporating these databases into the base training data may actually reduce classification performance since the supplementary databases may not annotate exactly the same ppi types as the base training data.
experimentally verified protein-protein interactions  cannot be easily retrieved by researchers unless they are stored in ppi databases.
our final model achieves an f-measure and auc  <dig> % and  <dig> % higher than those of the top-ranking system in the ias challenge.
our results show that adding likely-labeled data generally increases auc by 3~6%, indicating better ranking ability.
in addition, our results indicate that supervised weighting schemes outperform unsupervised ones.
our experiment results show tfbrf to be the most effective among several other top weighting schemes.
our newly-proposed weighting scheme, tfbrf, which considers documents that do not contain the target word, avoids some of the biases found in traditional weighting schemes.
