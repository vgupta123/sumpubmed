BACKGROUND
estimating divergence times in phylogenies using a molecular clock depends on accurate modeling of nucleotide substitution rates in dna sequences. rate heterogeneity among lineages is likely to affect estimates, especially in lineages with long stems and short crowns  and no internal calibration. we evaluate the performance of the random local clocks model  and the more routinely employed uncorrelated lognormal relaxed clock model  in situations in which a significant rate shift occurs on the stem branch of a broom clade. we compare the results of simulations to empirical results from analyses of a real rate-heterogeneous taxon – australian grass trees  – whose substitution rate is slower than in its sister groups, as determined by relative rate tests.


RESULTS
in the simulated datasets, the rlc model performed much better than ucln: rlc correctly estimated the age of the crown node of slow-rate broom clades, whereas ucln estimates were consistently too young. similarly, in the xanthorrhoea dataset, ucln returned significantly younger crown ages than rlc . in both real and simulated datasets, bayes factor tests strongly favored the rlc model over the ucln model.


CONCLUSIONS
the choice of an unsuitable molecular clock model can strongly bias divergence time estimates. in particular, for data predicted to have more rate variation among than within clades, dating with rlc is much more likely to be accurate than with ucln. the choice of clocks should be informed by the biology of the study group  or assessed with relative rate tests and post-hoc model comparisons.

electronic supplementary material
the online version of this article  contains supplementary material, which is available to authorized users.

keywords
divergence timessubstitution rate heterogeneityuncorrelated lognormal clockrandom local clocksrelative rateslife historyxanthorrhoeaissue-copyright-statement© the author 2014

