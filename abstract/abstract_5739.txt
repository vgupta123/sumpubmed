BACKGROUND
the post-genomic era is characterised by a torrent of biological information flooding the public databases. as a direct consequence, similarity searches starting with a single query sequence frequently lead to the identification of hundreds, or even thousands of potential homologues. the huge volume of data renders the subsequent structural, functional and evolutionary analyses very difficult. it is therefore essential to develop new strategies for efficient sampling of this large sequence space, in order to reduce the number of sequences to be processed. at the same time, it is important to retain the most pertinent sequences for structural and functional studies.


RESULTS
an exhaustive analysis on a large scale test set  was performed to compare the efficiency of four different sampling methods aimed at selecting the most pertinent sequences. these four methods sample the proteins detected by blastp searches and can be divided into two categories: two customisable methods where the user defines either the maximal number or the percentage of sequences to be selected; two automatic methods in which the number of sequences selected is determined by the program. we focused our analysis on the potential information content of the sampled sets of sequences using multiple alignment of complete sequences as the main validation tool. the study considered two criteria: the total number of sequences in blastp and their associated e-values. the subsequent analyses investigated the influence of the sampling methods on the e-value distributions, the sequence coverage, the final multiple alignment quality and the active site characterisation at various residue conservation thresholds as a function of these criteria.


CONCLUSIONS
the comparative analysis of the four sampling methods allows us to propose a suitable sampling strategy that significantly reduces the number of homologous sequences required for alignment, while at the same time maintaining the relevant information concerning the active site residues.

