BACKGROUND
dna microarrays are potentially powerful technology for improving diagnostic classification, treatment selection, and prognostic assessment. the use of this technology to predict cancer outcome has a history of almost a decade. disease class predictors can be designed for known disease cases and provide diagnostic confirmation or clarify abnormal cases. the main input to this class predictors are high dimensional data with many variables and few observations. dimensionality reduction of these features set significantly speeds up the prediction task. feature selection and feature transformation methods are well known preprocessing steps in the field of bioinformatics. several prediction tools are available based on these techniques.


RESULTS
studies show that a well tuned kernel pca  is an efficient preprocessing step for dimensionality reduction, but the available bandwidth selection method for kpca was computationally expensive. in this paper, we propose a new data-driven bandwidth selection criterion for kpca, which is related to least squares cross-validation for kernel density estimation. we propose a new prediction model with a well tuned kpca and least squares support vector machine . we estimate the accuracy of the newly proposed model based on  <dig> case studies. then, we compare its performances  and computational time) with other well known techniques such as whole data set + ls-svm, pca + ls-svm, t-test + ls-svm, prediction analysis of microarrays  and least absolute shrinkage and selection operator . finally, we assess the performance of the proposed strategy with an existing kpca parameter tuning algorithm by means of two additional case studies.


CONCLUSIONS
we propose, evaluate, and compare several mathematical/statistical techniques, which apply feature transformation/selection for subsequent classification, and consider its application in medical diagnostics. both feature selection and feature transformation perform well on classification tasks. due to the dynamic selection property of feature selection, it is hard to define significant features for the classifier, which predicts classes of future samples. moreover, the proposed strategy enjoys a distinctive advantage with its relatively lesser time complexity.

