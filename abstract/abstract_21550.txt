BACKGROUND
different classes of haplotype block algorithms exist and the ideal dataset to assess their performance would be to comprehensively re-sequence a large genomic region in a large population. such data sets are expensive to collect. alternatively, we performed coalescent simulations to generate haplotypes with a high marker density and compared block partitioning results from diversity based, ld based, and information theoretic algorithms under different values of snp density and allele frequency.


RESULTS
we simulated  <dig> haplotypes using the standard coalescent for three world populations – european, african american, and east asian – and applied three classes of block partitioning algorithms – diversity based, ld based, and information theoretic. we assessed algorithm differences in number, size, and coverage of blocks inferred under different conditions of snp density, allele frequency, and sample size.

each algorithm inferred blocks differing in number, size, and coverage under different density and allele frequency conditions. different partitions had few if any matching block boundaries. however they still overlapped and a high percentage of total chromosomal region was common to all methods. this percentage was generally higher with a higher density of snps and when rarer markers were included.


CONCLUSIONS
a gold standard definition of a haplotype block is difficult to achieve, but collecting haplotypes covered with a high density of snps, partitioning them with a variety of block algorithms, and identifying regions common to all methods may be the best way to identify genomic regions that harbor snp variants that cause disease.

