BACKGROUND
ontologies and catalogs of gene functions, such as the gene ontology  and mips-fun, assume that functional classes are organized hierarchically, that is, general functions include more specific ones. this has recently motivated the development of several machine learning algorithms for gene function prediction that leverages on this hierarchical organization where instances may belong to multiple classes. in addition, it is possible to exploit relationships among examples, since it is plausible that related genes tend to share functional annotations. although these relationships have been identified and extensively studied in the area of protein-protein interaction  networks, they have not received much attention in hierarchical and multi-class gene function prediction. relations between genes introduce autocorrelation in functional annotations and violate the assumption that instances are independently and identically distributed , which underlines most machine learning algorithms. although the explicit consideration of these relations brings additional complexity to the learning process, we expect substantial benefits in predictive accuracy of learned classifiers.


RESULTS
this article demonstrates the benefits  of considering autocorrelation in multi-class gene function prediction. we develop a tree-based algorithm for considering network autocorrelation in the setting of hierarchical multi-label classification . we empirically evaluate the proposed algorithm, called nhmc , on  <dig> yeast datasets using each of the mips-fun and go annotation schemes and exploiting  <dig> different ppi networks. the results clearly show that taking autocorrelation into account improves the predictive performance of the learned models for predicting gene function.


CONCLUSIONS
our newly developed method for hmc takes into account network information in the learning phase: when used for gene function prediction in the context of ppi networks, the explicit consideration of network autocorrelation increases the predictive performance of the learned models. overall, we found that this holds for different gene features/ descriptions, functional annotation schemes, and ppi networks: best results are achieved when the ppi network is dense and contains a large proportion of function-relevant interactions.

