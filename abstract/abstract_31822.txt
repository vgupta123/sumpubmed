BACKGROUND
gene regulatory networks  inference is an important bioinformatics problem in which the gene interactions need to be deduced from gene expression data, such as microarray data. feature selection methods can be applied to this problem. a feature selection technique is composed by two parts: a search algorithm and a criterion function. among the search algorithms already proposed, there is the exhaustive search where the best feature subset is returned, although its computational complexity is unfeasible in almost all situations. the objective of this work is the development of a low cost parallel solution based on gpu architectures for exhaustive search with a viable cost-benefit. we use cuda™, a general purpose parallel programming platform that allows the usage of nvidia® gpus to solve complex problems in an efficient way.


RESULTS
we developed a parallel algorithm for grn inference based on multiple gpu cards and obtained encouraging speedups , when assuming that each target gene has two multivariate predictors. also, experiments using single and multiple gpus were performed, indicating that the speedup grows almost linearly with the number of gpus.


CONCLUSIONS
in this work, we present a proof of principle, showing that it is possible to parallelize the exhaustive search algorithm in gpus with encouraging results. although our focus in this paper is on the grn inference problem, the exhaustive search technique based on gpu developed here can be applied  to other combinatorial problems.

23- <dig> february  <dig> second ieee international conference on computational advances in bio and medical sciences  las vegas, nv, usa

