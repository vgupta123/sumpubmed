BACKGROUND
semantic relations increasingly underpin biomedical text mining and knowledge discovery applications. the success of such practical applications crucially depends on the quality of extracted relations, which can be assessed against a gold standard reference. most such references in biomedical text mining focus on narrow subdomains and adopt different semantic representations, rendering them difficult to use for benchmarking independently developed relation extraction systems. in this article, we present a multi-phase gold standard annotation study, in which we annotated  <dig> sentences randomly selected from medline abstracts on a wide range of biomedical topics with  <dig> semantic predications. the umls metathesaurus served as the main source for conceptual information and the umls semantic network for relational information. we measured interannotator agreement and analyzed the annotations closely to identify some of the challenges in annotating biomedical text with relations based on an ontology or a terminology.


RESULTS
we obtain fair to moderate interannotator agreement in the practice phase . with improved guidelines and additional semantic equivalence criteria, the agreement increases by 12%  in the main annotation phase. in addition, we find that agreement increases to  <dig>  when the agreement calculation is limited to those predications that are based only on the explicitly provided umls concepts and relations.


CONCLUSIONS
while interannotator agreement in the practice phase confirms that conceptual annotation is a challenging task, the increasing agreement in the main annotation phase points out that an acceptable level of agreement can be achieved in multiple iterations, by setting stricter guidelines and establishing semantic equivalence criteria. mapping text to ontological concepts emerges as the main challenge in conceptual annotation. annotating predications involving biomolecular entities and processes is particularly challenging. while the resulting gold standard is mainly intended to serve as a test collection for our semantic interpreter, we believe that the lessons learned are applicable generally.

