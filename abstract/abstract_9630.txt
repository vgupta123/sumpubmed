BACKGROUND
selecting an appropriate classifier for a particular biological application poses a difficult problem for researchers and practitioners alike. in particular, choosing a classifier depends heavily on the features selected. for high-throughput biomedical datasets, feature selection is often a preprocessing step that gives an unfair advantage to the classifiers built with the same modeling assumptions. in this paper, we seek classifiers that are suitable to a particular problem independent of feature selection. we propose a novel measure, called "win percentage", for assessing the suitability of machine classifiers to a particular problem. we define win percentage as the probability a classifier will perform better than its peers on a finite random sample of feature sets, giving each classifier equal opportunity to find suitable features.


RESULTS
first, we illustrate the difficulty in evaluating classifiers after feature selection. we show that several classifiers can each perform statistically significantly better than their peers given the right feature set among the top  <dig> % of all feature sets. we illustrate the utility of win percentage using synthetic data, and evaluate six classifiers in analyzing eight microarray datasets representing three diseases: breast cancer, multiple myeloma, and neuroblastoma. after initially using all gaussian gene-pairs, we show that precise estimates of win percentage  can be achieved using a smaller random sample of all feature pairs. we show that for these data no single classifier can be considered the best without knowing the feature set. instead, win percentage captures the non-zero probability that each classifier will outperform its peers based on an empirical estimate of performance.


CONCLUSIONS
fundamentally, we illustrate that the selection of the most suitable classifier  not only depends on the dataset and application but also on the thoroughness of feature selection. in particular, win percentage provides a single measurement that could assist users in eliminating or selecting classifiers for their particular application.

1- <dig> august  <dig> acm conference on bioinformatics, computational biology and biomedicine  <dig>  chicago, il, usa

