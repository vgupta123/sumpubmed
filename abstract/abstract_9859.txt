BACKGROUND
efficient dissection of large proteins into their structural domains is critical for high throughput proteome analysis. so far, no study has focused on mathematically modeling a protein dissection protocol in terms of a production system. here, we report a mathematical model for empirically optimizing the cost of large-scale domain production in proteomics research.


RESULTS
the model computes the expected number of successfully producing soluble domains, using a conditional probability between domain and boundary identification. typical values for the model's parameters were estimated using the experimental results for identifying soluble domains from the  <dig>  kazusa huge protein sequences. among the  <dig> fragments corresponding to the  <dig> domains that were expressed correctly,  <dig>  corresponding to  <dig> domains, were soluble. our model indicates that, under the conditions used in our pilot experiment, the probability of correctly predicting the existence of a domain was 81%  and that of predicting its boundary was 63% . under these conditions, the most cost/effort-effective production of soluble domains was to prepare one to seven fragments per predicted domain.


CONCLUSIONS
our mathematical modeling of protein dissection protocols indicates that the optimum number of fragments tested per domain is actually much smaller than expected a priori. the application range of our model is not limited to protein dissection, and it can be utilized for designing various large-scale mutational analyses or screening libraries.

