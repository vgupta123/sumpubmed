BACKGROUND
the decomposition of complex metabolic networks into elementary flux modes  provides a useful framework for exploring reaction interactions systematically. generating a complete set of efms for large-scale models, however, is near impossible. even for moderately-sized models , existing approaches based on the double description method must iterate through a large number of combinatorial candidates, thus imposing an immense processor and memory demand.


RESULTS
based on an alternative elementarity test, we developed a depth-first search algorithm using linear programming  to enumerate efms in an exhaustive fashion. constraints can be introduced to directly generate a subset of efms satisfying the set of constraints. the depth-first search algorithm has a constant memory overhead. using flux constraints, a large lp problem can be massively divided and parallelized into independent sub-jobs for deployment into computing clusters. since the sub-jobs do not overlap, the approach scales to utilize all available computing nodes with minimal coordination overhead or memory limitations.


CONCLUSIONS
the speed of the algorithm was comparable to efmtool, a mainstream double description method, when enumerating all efms; the attrition power gained from performing flux feasibility tests offsets the increased computational demand of running an lp solver. unlike the double description method, the algorithm enables accelerated enumeration of all efms satisfying a set of constraints.

elementary modeextreme pathwaylinear programmingrankparallelmemory

