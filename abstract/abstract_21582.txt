BACKGROUND
pam, a nearest shrunken centroid method , is a popular classification method for high-dimensional data. alp and ahp are nsc algorithms that were proposed to improve upon pam. the nsc methods base their classification rules on shrunken centroids; in practice the amount of shrinkage is estimated minimizing the overall cross-validated  error rate.


RESULTS
we show that when data are class-imbalanced the three nsc classifiers are biased towards the majority class. the bias is larger when the number of variables or class-imbalance is larger and/or the differences between classes are smaller. to diminish the class-imbalance problem of the nsc classifiers we propose to estimate the amount of shrinkage by maximizing the cv geometric mean of the class-specific predictive accuracies .


CONCLUSIONS
the results obtained on simulated and real high-dimensional class-imbalanced data show that our approach outperforms the currently used strategy based on the minimization of the overall error rate when nsc classifiers are biased towards the majority class. the number of variables included in the nsc classifiers when using our approach is much smaller than with the original approach. this result is supported by experiments on simulated and real high-dimensional class-imbalanced data.

