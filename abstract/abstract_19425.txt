BACKGROUND
complementary dna  microarrays are a well established technology for studying gene expression. a microarray image is obtained by laser scanning a hybridized cdna microarray, which consists of thousands of spots representing chains of cdna sequences, arranged in a two-dimensional array. the separation of the spots into distinct cells is widely known as microarray image gridding.

methods
in this paper we propose m3g, a novel method for automatic gridding of cdna microarray images based on the maximization of the margin between the rows and the columns of the spots. initially the microarray image rotation is estimated and then a pre-processing algorithm is applied for a rough spot detection. in order to diminish the effect of artefacts, only a subset of the detected spots is selected by matching the distribution of the spot sizes to the normal distribution. then, a set of grid lines is placed on the image in order to separate each pair of consecutive rows and columns of the selected spots. the optimal positioning of the lines is determined by maximizing the margin between these rows and columns by using a maximum margin linear classifier, effectively facilitating the localization of the spots.


RESULTS
the experimental evaluation was based on a reference set of microarray images containing more than two million spots in total. the results show that m3g outperforms state of the art methods, demonstrating robustness in the presence of noise and artefacts. more than 98% of the spots reside completely inside their respective grid cells, whereas the mean distance between the spot center and the grid cell center is  <dig>  pixels.


CONCLUSIONS
the proposed method performs highly accurate gridding in the presence of noise and artefacts, while taking into account the input image rotation. thus, it provides the potential of achieving perfect gridding for the vast majority of the spots.

