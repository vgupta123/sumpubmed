BACKGROUND
a popular query from scientists reading a biomedical abstract is to search for topic-related documents in bibliographic databases. such a query is challenging because the amount of information attached to a single abstract is little, whereas classification-based retrieval algorithms are optimally trained with large sets of relevant documents. as a solution to this problem, we propose a query expansion method that extends the information related to a manuscript using its cited references.


RESULTS
data on cited references and text sections in  <dig>  full-text biomedical articles was extracted from the open access subset of the pubmed central® database . of the five standard sections of a scientific article, the introduction and discussion sections contained most of the citations . a large proportion of articles  and their cited references  were indexed in the pubmed® database.

using the medlineranker abstract classification tool, cited references allowed accurate retrieval of the citing document in a test set of  <dig>  documents and also of documents related to six biomedical topics defined by particular mesh® terms from the entire pmc-oa .

classification performance was sensitive to the topic and also to the text sections from which the references were selected. classifiers trained on the baseline  were outperformed in almost all the cases. best performance was often obtained when using all cited references, though using the references from introduction and discussion sections led to similarly good results. this query expansion method performed significantly better than pseudo relevance feedback in  <dig> out of  <dig> topics.


CONCLUSIONS
the retrieval of documents related to a single document can be significantly improved by using the references cited by this document . using references from introduction and discussion performs almost as well as using all references, which might be useful for methods that require reduced datasets due to computational limitations. cited references from particular sections might not be appropriate for all topics. our method could be a better alternative to pseudo relevance feedback though it is limited by full text availability.

information retrievaltext categorizationcitationsfull-text documentsbiomedical literaturequery expansiondocument classification

