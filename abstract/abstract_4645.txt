BACKGROUND
ensemble predictors such as the random forest are known to have superior accuracy but their black-box predictions are difficult to interpret. in contrast, a generalized linear model  is very interpretable especially when forward feature selection is used to construct the model. however, forward feature selection tends to overfit the data and leads to low predictive accuracy. therefore, it remains an important research goal to combine the advantages of ensemble predictors  with the advantages of forward regression modeling . to address this goal several articles have explored glm based ensemble predictors. since limited evaluations suggested that these ensemble predictors were less accurate than alternative predictors, they have found little attention in the literature.


RESULTS
comprehensive evaluations involving hundreds of genomic data sets, the uci machine learning benchmark data, and simulations are used to give glm based ensemble predictors a new and careful look. a novel bootstrap aggregated  glm predictor that incorporates several elements of randomness and instability  often outperforms a host of alternative prediction methods including random forests and penalized regression models . this random generalized linear model  predictor provides variable importance measures that can be used to define a “thinned” ensemble predictor  that retains excellent predictive accuracy.


CONCLUSIONS
rglm is a state of the art predictor that shares the advantages of a random forest  with those of a forward selected generalized linear model . these methods are implemented in the freely available r software package randomglm.

