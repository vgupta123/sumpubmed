BACKGROUND
we introduce the linguistic annotation of a corpus of  <dig> full-text biomedical publications, known as the colorado richly annotated full text  corpus. we further assess the performance of existing tools for performing sentence splitting, tokenization, syntactic parsing, and named entity recognition on this corpus.


RESULTS
many biomedical natural language processing systems demonstrated large differences between their previously published results and their performance on the craft corpus when tested with the publicly available models or rule sets. trainable systems differed widely with respect to their ability to build high-performing models based on this data.


CONCLUSIONS
the finding that some systems were able to train high-performing models based on this corpus is additional evidence, beyond high inter-annotator agreement, that the quality of the craft corpus is high. the overall poor performance of various systems indicates that considerable work needs to be done to enable natural language processing systems to work well when the input is full-text journal articles. the craft corpus provides a valuable resource to the biomedical natural language processing community for evaluation and training of new models for biomedical full text publications.

