BACKGROUND
mathematical modeling is often used to formalize hypotheses on how a biochemical network operates by discriminating between competing models. bayesian model selection offers a way to determine the amount of evidence that data provides to support one model over the other while favoring simple models. in practice, the amount of experimental data is often insufficient to make a clear distinction between competing models. often one would like to perform a new experiment which would discriminate between competing hypotheses.


RESULTS
we developed a novel method to perform optimal experiment design to predict which experiments would most effectively allow model selection. a bayesian approach is applied to infer model parameter distributions. these distributions are sampled and used to simulate from multivariate predictive densities. the method is based on a k-nearest neighbor estimate of the jensen shannon divergence between the multivariate predictive densities of competing models.


CONCLUSIONS
we show that the method successfully uses predictive differences to enable model selection by applying it to several test cases. because the design criterion is based on predictive distributions, which can be computed for a wide range of model quantities, the approach is very flexible. the method reveals specific combinations of experiments which improve discriminability even in cases where data is scarce. the proposed approach can be used in conjunction with existing bayesian methodologies where  posteriors have been determined, making use of relations that exist within the inferred posteriors.

model selectioninferencebayes factoruncertainty

