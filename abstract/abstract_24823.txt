BACKGROUND
interest is growing in the application of syntactic parsers to natural language processing problems in biology, but assessing their performance is difficult because differences in linguistic convention can falsely appear to be errors. we present a method for evaluating their accuracy using an intermediate representation based on dependency graphs, in which the semantic relationships important in most information extraction tasks are closer to the surface. we also demonstrate how this method can be easily tailored to various application-driven criteria.


RESULTS
using the genia corpus as a gold standard, we tested four open-source parsers which have been used in bioinformatics projects. we first present overall performance measures, and test the two leading tools, the charniak-lease and bikel parsers, on subtasks tailored to reflect the requirements of a system for extracting gene expression relationships. these two tools clearly outperform the other parsers in the evaluation, and achieve accuracy levels comparable to or exceeding native dependency parsers on similar tasks in previous biological evaluations.


CONCLUSIONS
evaluating using dependency graphs allows parsers to be tested easily on criteria chosen according to the semantics of particular biological applications, drawing attention to important mistakes and soaking up many insignificant differences that would otherwise be reported as errors. generating high-accuracy dependency graphs from the output of phrase-structure parsers also provides access to the more detailed syntax trees that are used in several natural-language processing techniques.

