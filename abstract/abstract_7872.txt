BACKGROUND
machine-learning tools have gained considerable attention during the last few years for analyzing biological networks for protein function prediction. kernel methods are suitable for learning from graph-based data such as biological networks, as they only require the abstraction of the similarities between objects into the kernel matrix. one key issue in kernel methods is the selection of a good kernel function. diffusion kernels, the discretization of the familiar gaussian kernel of euclidean space, are commonly used for graph-based data.


RESULTS
in this paper, we address the issue of learning an optimal diffusion kernel, in the form of a convex combination of a set of pre-specified kernels constructed from biological networks, for protein function prediction. most prior work on this kernel learning task focus on variants of the loss function based on support vector machines . their extensions to other loss functions such as the one based on kullback-leibler  divergence, which is more suitable for mining biological networks, lead to expensive optimization problems. by exploiting the special structure of the diffusion kernel, we show that this kl divergence based kernel learning problem can be formulated as a simple optimization problem, which can then be solved efficiently. it is further extended to the multi-task case where we predict multiple functions of a protein simultaneously. we evaluate the efficiency and effectiveness of the proposed algorithms using two benchmark data sets.


CONCLUSIONS
results show that the performance of linearly combined diffusion kernel is better than every single candidate diffusion kernel. when the number of tasks is large, the algorithms based on multiple tasks are favored due to their competitive recognition performance and small computational costs.

