BACKGROUND
modern omics research involves the application of high-throughput technologies that generate vast volumes of data. these data need to be pre-processed, analyzed and integrated with existing knowledge through the use of diverse sets of software tools, models and databases. the analyses are often interdependent and chained together to form complex workflows or pipelines. given the volume of the data used and the multitude of computational resources available, specialized pipeline software is required to make high-throughput analysis of large-scale omics datasets feasible.


RESULTS
we have developed a generic pipeline system called cyrille <dig>  the system is modular in design and consists of three functionally distinct parts: 1) a web based, graphical user interface  that enables a pipeline operator to manage the system; 2) the scheduler, which forms the functional core of the system and which tracks what data enters the system and determines what jobs must be scheduled for execution, and; 3) the executor, which searches for scheduled jobs and executes these on a compute cluster.


CONCLUSIONS
the cyrille <dig> system is an extensible, modular system, implementing the stated requirements. cyrille <dig> enables easy creation and execution of high throughput, flexible bioinformatics pipelines.

