BACKGROUND
population inference is an important problem in genetics used to remove population stratification in genome-wide association studies and to detect migration patterns or shared ancestry. an individualâ€™s genotype can be modeled as a probabilistic function of ancestral population memberships, q, and the allele frequencies in those populations, p. the parameters, p and q, of this binomial likelihood model can be inferred using slow sampling methods such as markov chain monte carlo methods or faster gradient based approaches such as sequential quadratic programming. this paper proposes a least-squares simplification of the binomial likelihood model motivated by a euclidean interpretation of the genotype feature space. this results in a faster algorithm that easily incorporates the degree of admixture within the sample of individuals and improves estimates without requiring trial-and-error tuning.


RESULTS
we show that the expected value of the least-squares solution across all possible genotype datasets is equal to the true solution when part of the problem has been solved, and that the variance of the solution approaches zero as its size increases. the least-squares algorithm performs nearly as well as admixture for these theoretical scenarios. we compare least-squares, admixture, and frappe for a variety of problem sizes and difficulties. for particularly hard problems with a large number of populations, small number of samples, or greater degree of admixture, least-squares performs better than the other methods. on simulated mixtures of real population allele frequencies from the hapmap project, admixture estimates sparsely mixed individuals better than least-squares. the least-squares approach, however, performs within  <dig> % of the admixture error. on individual genotypes from the hapmap project, admixture and least-squares perform qualitatively similarly and within  <dig> % of each other. significantly, the least-squares approach nearly always converges  <dig> - to 6-times faster.


CONCLUSIONS
the computational advantage of the least-squares approach along with its good estimation performance warrants further research, especially for very large datasets. as problem sizes increase, the difference in estimation performance between all algorithms decreases. in addition, when prior information is known, the least-squares approach easily incorporates the expected degree of admixture to improve the estimate.

