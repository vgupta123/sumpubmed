BACKGROUND
there are currently a number of competing techniques for low-level processing of oligonucleotide array data. the choice of technique has a profound effect on subsequent statistical analyses, but there is no method to assess whether a particular technique is appropriate for a specific data set, without reference to external data.


RESULTS
we analyzed coregulation between genes in order to detect insufficient normalization between arrays, where coregulation is measured in terms of statistical correlation. in a large collection of genes, a random pair of genes should have on average zero correlation, hence allowing a correlation test. for all data sets that we evaluated, and the three most commonly used low-level processing procedures including mas <dig>  rma and mbei, the housekeeping-gene normalization failed the test. for a real clinical data set, rma and mbei showed significant correlation for absent genes. we also found that a second round of normalization on the probe set level improved normalization significantly throughout.


CONCLUSIONS
previous evaluation of low-level processing in the literature has been limited to artificial spike-in and mixture data sets. in the absence of a known gold-standard, the correlation criterion allows us to assess the appropriateness of low-level processing of a specific data set and the success of normalization for subsets of genes.

