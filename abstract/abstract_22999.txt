BACKGROUND
the rapid growth of the amount of publicly available reports on biomedical experimental results has recently caused a boost of text mining approaches for protein interaction extraction. most approaches rely implicitly or explicitly on linguistic, i.e., lexical and syntactic, data extracted from text. however, only few attempts have been made to evaluate the contribution of the different feature types. in this work, we contribute to this evaluation by studying the relative importance of deep syntactic features, i.e., grammatical relations, shallow syntactic features  and lexical features. for this purpose, we use a recently proposed approach that uses support vector machines with structured kernels.


RESULTS
our results reveal that the contribution of the different feature types varies for the different data sets on which the experiments were conducted. the smaller the training corpus compared to the test data, the more important the role of grammatical relations becomes. moreover, deep syntactic information based classifiers prove to be more robust on heterogeneous texts where no or only limited common vocabulary is shared.


CONCLUSIONS
our findings suggest that grammatical relations play an important role in the interaction extraction task. moreover, the net advantage of adding lexical and shallow syntactic features is small related to the number of added features. this implies that efficient classifiers can be built by using only a small fraction of the features that are typically being used in recent approaches.

