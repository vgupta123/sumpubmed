BACKGROUND
ordinary differential equation  models are widely used to describe chemical and biological processes. to enhance the predictive power of these models, their unknown parameters are estimated from experimental data. these experimental data are mostly collected in perturbation experiments, in which the processes are pushed out of steady state by applying a stimulus. the information that the initial condition is a steady state of the unperturbed process provides valuable information, as it restricts the dynamics of the process and thereby the parameters. however, implementing steady-state constraints in the optimization often results in convergence problems.


RESULTS
in this manuscript, we propose two new methods for solving optimization problems with steady-state constraints. the first method exploits ideas from optimization algorithms on manifolds and introduces a retraction operator, essentially reducing the dimension of the optimization problem. the second method is based on the continuous analogue of the optimization problem. this continuous analogue is an ode whose equilibrium points are the optima of the constrained optimization problem. this equivalence enables the use of adaptive numerical methods for solving optimization problems with steady-state constraints. both methods are tailored to the problem structure and exploit the local geometry of the steady-state manifold and its stability properties. a parameterization of the steady-state manifold is not required.

the efficiency and reliability of the proposed methods is evaluated using one toy example and two applications. the first application example uses published data while the second uses a novel dataset for raf/mek/erk signaling. the proposed methods demonstrated better convergence properties than state-of-the-art methods employed in systems and computational biology. furthermore, the average computation time per converged start is significantly lower. in addition to the theoretical results, the analysis of the dataset for raf/mek/erk signaling provides novel biological insights regarding the existence of feedback regulation.


CONCLUSIONS
many optimization problems considered in systems and computational biology are subject to steady-state constraints. while most optimization methods have convergence problems if these steady-state constraints are highly nonlinear, the methods presented recover the convergence properties of optimizers which can exploit an analytical expression for the parameter-dependent steady state. this renders them an excellent alternative to methods which are currently employed in systems and computational biology.

electronic supplementary material
the online version of this article  contains supplementary material, which is available to authorized users.

keywords
parameter optimizationdifferential equationsteady stateperturbation experimentsbundesministerium für bildung und forschung 01zx1310btheis fabian j. helmholtz zentrum münchenpostdoctoral fellowship programhasenauer jan issue-copyright-statement© the author 2016

