BACKGROUND
designing appropriate machine learning methods for identifying genes that have a significant discriminating power for disease outcomes has become more and more important for our understanding of diseases at genomic level. although many machine learning methods have been developed and applied to the area of microarray gene expression data analysis, the majority of them are based on linear models, which however are not necessarily appropriate for the underlying connection between the target disease and its associated explanatory genes. linear model based methods usually also bring in false positive significant features more easily. furthermore, linear model based algorithms often involve calculating the inverse of a matrix that is possibly singular when the number of potentially important genes is relatively large. this leads to problems of numerical instability. to overcome these limitations, a few non-linear methods have recently been introduced to the area. many of the existing non-linear methods have a couple of critical problems, the model selection problem and the model parameter tuning problem, that remain unsolved or even untouched. in general, a unified framework that allows model parameters of both linear and non-linear models to be easily tuned is always preferred in real-world applications. kernel-induced learning methods form a class of approaches that show promising potentials to achieve this goal.


RESULTS
a hierarchical statistical model named kernel-imbedded gaussian process  is developed under a unified bayesian framework for binary disease classification problems using microarray gene expression data. in particular, based on a probit regression setting, an adaptive algorithm with a cascading structure is designed to find the appropriate kernel, to discover the potentially significant genes, and to make the optimal class prediction accordingly. a gibbs sampler is built as the core of the algorithm to make bayesian inferences. simulation studies showed that, even without any knowledge of the underlying generative model, the kigp performed very close to the theoretical bayesian bound not only in the case with a linear bayesian classifier but also in the case with a very non-linear bayesian classifier. this sheds light on its broader usability to microarray data analysis problems, especially to those that linear methods work awkwardly. the kigp was also applied to four published microarray datasets, and the results showed that the kigp performed better than or at least as well as any of the referred state-of-the-art methods did in all of these cases.


CONCLUSIONS
mathematically built on the kernel-induced feature space concept under a bayesian framework, the kigp method presented in this paper provides a unified machine learning approach to explore both the linear and the possibly non-linear underlying relationship between the target features of a given binary disease classification problem and the related explanatory gene expression data. more importantly, it incorporates the model parameter tuning into the framework. the model selection problem is addressed in the form of selecting a proper kernel type. the kigp method also gives bayesian probabilistic predictions for disease classification. these properties and features are beneficial to most real-world applications. the algorithm is naturally robust in numerical computation. the simulation studies and the published data studies demonstrated that the proposed kigp performs satisfactorily and consistently.

