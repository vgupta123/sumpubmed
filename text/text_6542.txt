BACKGROUND
coding sequences have been shown to harbor numerous regulatory sites in their nucleotide sequences for functions such as rna localization  <cit> , translation efficacy  <cit> , mrna splicing  <cit> , mrna stability  <cit> , and accessibility to the translation machinery  <cit> . the existence of such regulatory sites suggests that searching for cis-regulatory elements only in promoter regions or utrs overlooks a great deal of important biology. this regulatory importance within coding regions is perhaps not surprising, as coding sequences are comparable in length to both utrs and promoter regions. although there is substantial variation in the length of utrs and coding sequences, on average human coding sequences are ~  <dig> bp long, while 3' utrs are ~  <dig> bp and 5' utrs are ~ 100- <dig> bp. in 56% of transcripts the coding region is longer than the 5' and 3' utrs combined .

high-throughput studies of both rna and dna have also shown evidence of functional sites in coding regions, indicating the need for computational methods to identify such sites. some of the rna studies include those showing binding of proteins or micrornas to mrna coding regions  <cit> . at the dna level, transcription factor binding site mapping has shown that coding regions contain extensive binding sites in bacteria  <cit> , dnase hypersensitivity measurements have shown that the transcription factors are likely to bind into the first several hundred bases of human coding regions  <cit> , and transcription factor chromatin immunoprecipitation studies have shown similar behavior in drosophila coding regions  <cit> . it has also been shown that the sequence motifs overlapping the stop codon may influence protein yield  <cit> .

identifying functional motifs in coding sequences computationally has been challenging due to the lack of appropriate algorithms to separate nucleotide-level signals from those caused by the amino acid sequences. here we use the term motif to refer to a short possibly degenerate sequence element that may or may not be functional. sequence conservation approaches that calibrate for the amino acids are one promising technique for identifying functional motifs, as it was shown that conservation can detect exonic splicing, microrna binding, and dna replication-associated motifs  <cit> . however, the function of a motif identified by sequence conservation is often non-obvious. this is in contrast to motif identification by overrepresentation, for which functions can be assigned based on the manner in which the sequence set was identified. for example, sequences captured in rna immunoprecipitation or chromatin immunoprecipitation are likely to contain overrepresented motifs relevant to the specific proteins binding to the rna or dna. development of a motif overrepresentation algorithm for coding regions would therefore be of considerable value.

a few groups  <cit>  have attempted to separate the amino acid and nucleotide-level pressures on motif copy number, using codon usage biases as a starting point. however all of these methods have been based on sampling sequences whose codons have been shuffled while preserving the amino acid sequence. such an approach is limited by the number of shuffled sequences that can be sampled in a feasible amount of time. proteins are on average more than  <dig> codons long  <cit>  and almost all codons are at least 2-fold degenerate, yielding exponentially many possible codon sequences per protein. prior studies have sampled only an infinitesimal portion of the sequence space, e.g. down et al compared real sequences to a single shuffle  <cit> , itzkovitz et al compared to  <dig> shuffles  <cit> , and robins et al compared to  <dig> shuffles  <cit> . to compensate for the limited sampling depth, parametric approximations were used for the motif count null distribution based on the behavior of the sampled sequences  <cit> . however, the adequacy of such parametric approximations is unclear, as they depend on many factors, including the number of samples, the length of the original sequence, the encoded amino acid sequence, the shape of the distribution implied by the parametric approximation, and the true prevalence of the motif to be tested. the validity of the parametric approximation as well as the required depth of sampling are in general unknown for a given dataset and motif.

methods based on comparisons to empirical motif counts in control exonic  sequences have also been developed  <cit> , though such approaches require additional functional knowledge of the control sequences and, like the shuffling approaches, are limited by size of the control set.

algorithms that simply ignore the amino-acid sequence have been applied to coding sequences as well. for example jambhekar et al  <cit>  used meme, which is designed for noncoding sequences  <cit> , to search for rna localization zipcodes. however they concluded that meme, even when combined with rna folding simulations, was unreliable for this purpose  <cit> .

in this work we present a novel enumerative method, codingmotif, to detect functional noncoding motifs in coding sequences, solving the problems associated with sampling approaches. the algorithm exactly calculates the distribution of a motif's occurrence frequency over all coding sequences that code for the amino acid sequence, given a null model of codon usage. this approach allows for exact evaluation of the overrepresentation or underrepresentation p-value for a motif in any length of sequence n. this removes the need for sampling or for parametric approximations, providing a key advance over prior approaches. our algorithm is able to efficiently calculate the distribution in o2) time through a novel dynamic programming algorithm. we describe how to speed up the calculation by taking advantage of motif sparseness as well. importantly, the program also takes into account dinucleotide biases, which are built into the model through a codon-to-codon markov process. we show that codingmotif assesses motifs more accurately than sampling approaches in both eukaryotic and prokaryotic datasets.

RESULTS
independent codon model
as a first approach to the problem, we developed a motif overrepresentation algorithm based on an independent codon model , in which our null assumption was that codons do not influence the codons at adjacent positions . to determine the effectiveness of this assumption, we first analyzed k-mer strings k ) for overrepresentation in the coding sequences of mouse chromosome  <dig> . prior studies have focused on analyzing overrepresentation for k-mers as well  <cit> .

k-mer scores exhibited a strong bimodal behavior under the icm null, with the vast majority of p-values close to either  <dig> or  <dig>  the distribution of p-values for these k-mers is shown in figure  <dig>  and labeled as "original sequence." for example, 32% of 6-mers have p-value <  <dig> , and 19% of 6-mers have p-value >  <dig> . the large number of motifs with strong copy number biases suggests that the icm model may not be an adequate null model for detecting motifs under selection. to clarify the reason for the bimodal behavior, we shuffled the codons while keeping the amino acid sequences fixed, yielding a "codon shuffled" sequence. when the overrepresentation algorithm was run on this shuffled sequence, the bimodality of the scores was substantially decreased . this suggests that there are systematic dinucleotide biases at the boundaries of neighboring codons that significantly impact the p-values calculated for the original sequence. such biases may include selective pressures on motifs, which is what we seek to identify; however the large number of motifs with scores altered by the codon shuffling suggests that there are neutral effects as well.

we hypothesized that the icm null model may be inadequate for detecting motifs under selection because it ignores neutral dinucleotide mutation biases. to clarify the effect of dinucleotide biases, we shuffled the original coding sequences while maintaining dicodon frequencies  using the method of  <cit> . when the overrepresentation program was applied to this dicodon-shuffled sequence, the distribution of motif p-values was very close to that for the original sequence . thus dinucleotide biases at codon boundaries are responsible for much of the behavior of motif p-values for the original sequence. this finding is consistent with previous works showing that the cpg effect has a strong influence on motif occurrence in coding regions  <cit> , as well as earlier studies that have analyzed dicodon correlations in coding regions  <cit> . therefore when detecting motifs whose copy numbers are increased due to selective pressures, it is important to include dinucleotide effects in the null model; otherwise many of the motifs inferred to be under selection would be false positives.

dinucleotide-corrected codon model
to handle this problem, we developed a method to calculate the motif frequency distribution that would be generated by a null model that includes dinucleotide biases. the algorithm uses as its null a markov model that closely preserves the expected codon usage and dinucleotide frequencies in the reference sequence. we refer to this as the dinucleotide-corrected codon model . full details of the dcm are given in the methods.

if each amino acid had only one possible first nucleotide for the underlying codon, then the expected dinucleotide and codon usage in the dcm null model would be exactly equal to those of the reference sequence . however, the true genetic code deviates slightly from this behavior . to determine how well the dcm preserves dinucleotide and codon usage, we generated a sequence using the dcm markov model and compared to the properties of the reference sequence. figure  <dig> shows the dinucleotide usage of the original sequence and that generated by both the dcm markov model and the icm model. the original sequence used was the set of all mouse coding sequences . the dcm and icm sequences were generated through python scripts using the python built-in random number generator. the correlation of the original and icm dinucleotide frequencies is high , but the correlation with the dcm value is noticeably superior . the strongest discrepancy is for cg nucleotides, which are well-known to be hypermutable compared to other dinucleotides. the cg frequency in the icm is  <dig>  times that in the original data, while the dcm cg frequency is only  <dig>  times that in the original data. none of the dcm dinucleotide frequencies differs from its respective original sequence dinucleotide frequency by more than  <dig> % of the original sequence value, even though such differences are affected by both systematic biases and finite-size fluctuations.

preservation of dinucleotide usage inherently implies preservation of codon usage, as shown by the following argument. define f ˜ to be the expected codon usage generated by the markov process. then we have:

  f ˜= ∑bpf ˜, 

where f ˜ is the average occurrence of the base b 3' of amino acid a in the sequences generated by the markov process. consistent with this, we found that the codon usage was extremely well preserved between the markov process and the original sequence. there was no codon whose frequency under the dcm differed by more than  <dig> % of its value in the original sequence. because of its accurate accounting for both codon usage and dinucleotide effects, the dcm model was used for all further motif overrepresentation calculations. since the dcm analysis above indicates that dinucleotide corrections are important we consider the dcm algorithm to be the standard method, and henceforth refer to it by the name codingmotif.

would it be better to use a higher order markov model for the null? 5th order cyclic markov models are used commonly in gene-finding algorithms, which would suggest they might be appropriate for a null model in motif finding. however, these models were chosen to be 5th order because hexamers were shown to be good for discriminating protein-coding and non-coding regions  <cit> . this is a criterion unrelated to the present work so such a null model provides no particular advantage for discovering functional motifs. higher order models also have the drawback of subsuming more of the true signal for motifs into the null, in conflict with the fact that many short motifs are known to be functional. for example, hundreds of 6-mers have been experimentally shown to have a significant effect on exonic splicing activity  <cit> , and microrna binding sites are only 6- <dig> bp long  <cit> .

the aa/dinucleotide null has the advantages of being straightforwardly interpretable and of being the lowest order model that accounts for both a a effects and dinucleotide mutation biases. our emphasis on dinucleotide effects is reasonable because, in many genomes, by far the strongest neutral cause of base-base correlations is the cpg effect, which is known to act on  <dig> bases at a time  <cit> . even in genomes without the cpg effect, there are few 3rd or higher order processes known to be explicitly due to mutation, aside from the special cases of tandem repeats arising from replication slippage or the insertion of transposable elements. consequently, higher order effects are most reasonably treated as results rather than as part of the null.

time scaling
the codingmotif algorithm takes as input a motif μ and a set of independent sequences s = {s <dig>  s <dig> ...,sl}, corresponding to the coding regions to be analyzed with total sequence length n. the algorithm determines and outputs the distribution of the number of occurrences of a motif in sequences that are compatible with the given set of coding regions. the algorithm consists of two parts: first the distribution of each si is determined, and second these distributions are combined into a single distribution. each of these parts is analyzed in turn.

determination of the distribution for each si is governed by the induction relation  <dig>  equation  <dig> calculates a new distribution dμ by adding contributions from at most  <dig> previously calculated distributions . this calculation is performed for all possible values of αk-Δ+ <dig> ... αk+ <dig>  yielding at most 6Δ calculations during each stage of the induction. the number of basic operations each induction step requires depends directly on the size of the distribution, which is stored as an array. the size of the distribution is determined by the maximum number of motif occurrences, which is very conservatively bounded by the length of the subsequence, i.e. length. since len induction steps are required, an upper bound for the steps required to calculate the distribution of si is 6Δ length <dig>  we need to do this calculation for all l independent sequences, so the total time is also proportional to l.

in practice even within a single coding sequence si we frequently observe sections where no copies of a given motif can possibly occur, due to the structure of the genetic code. these break each sequence si into much smaller subsequences for which we can calculate the distribution independently, while we can ignore the sections where a motif is forbidden. to see why these subsequences are short, consider a 6-mer motif and its potential occurrence within a stretch of  <dig> codons. at most, each of these codons has 6-fold degeneracy, so there can be at most  <dig> =  <dig> possible dna sequences consistent with the given amino acids. if the 6-mer occurs within the three codons, it may overlap in position 1- <dig>  2- <dig>  3- <dig>  or 4- <dig>  at most  <dig> ·  <dig> =  <dig> motifs may occur within this three codon stretch, while there are  <dig> =  <dig> possible 6-mer motifs. so at least 79% of 6-mers are forbidden within any three codon stretch. consequently, regions where a motif is not forbidden will have an approximately geometrically decreasing length distribution. this leads to a much larger number of effective independent regions each with short lengths. we use these effective si for the distribution function calculations, and this significantly improves the runtime of the algorithm . the actual independent regions are a function of the motif, genetic code, and amino acid sequences, and in general there will be o of them with lengths o. while it is theoretically possible that some amino acid sequences would necessitate independent regions with longer lengths, such amino acid sequences are exponentially unlikely as long as the amino acid sequences can be approximated as being generated by a finite-length markov process.

the step of combining the distributions for all independent regions into the overall distribution is rate-limiting. denote the maximum possible number of motif occurrences in the complete sequence as n ~ o. then there can be at most n independent regions, and thus at most n distributions to be combined. suppose n = 2k for some k . then we can recursively combine the distributions pairwise until only one remains.

the distributions will be combined from smallest to largest size. consider the worst case scenario in which there are 2k distributions of size  <dig>  in the first stage we combine these into distributions of size  <dig>  this involves 2k- <dig> pairs of distributions. in the next stage we combine 2k- <dig> pairs of distributions of size  <dig> into distributions of size  <dig>  continuing hierarchically, at each stage we combine 2k-l pairs of distributions of size 2l- <dig> for l =  <dig>   <dig> ..., k . at a given stage each convolution takes time o) using the fft procedure. the total calculation time is then given by

 o= ∑l=1k2k-1o)=2k- <dig> ∑l=1k=2k-1k2=n2logn2=o2). 

so the time requirement for the program is o2) = o2), much shorter than the exponential number of possible coding sequences.

tests of codingmotif
bacterial motifs
there are two relevant tests for codingmotif, the first being its ability to more accurately detect over- and under- represented motifs relative to prior methods, and the second being its ability to identify biologically meaningful motifs. for the first type of test, we analyzed the coding sequences of the bacterium e. coli. we compared our results to those of robins et al  <cit> , who used a shuffling-based approach to identify motifs of unusual copy number. their method involves performing 20- <dig> shuffles of synonymous codons within each gene to determine the expected copy number of each motif, though their null model does not account for dinucleotide effects. they then identify unusual motifs by comparing the real counts to the shuffled average using the kullback-leibler distance, with a z-score threshold based on the standard deviation of counts across shuffled sequences.

because we used an identical dataset to robins et al, we were able to directly compare whether our exact approach gives results better than a finite sampling/z-score approach. robins et al reported a set of  <dig> over- or under- represented motifs. among their underrepresented motifs, we found  <dig> with very weak underrepresentation according to our exact method . moreover,  <dig> other motifs they call as underrepresented are in fact overrepresented in the data . among the  <dig> motifs they report to have unusually high occurrence frequencies, all  <dig> exhibited very low p-values according to codingmotif as well, with most exhibiting extremely low p-values . however, our exact method detected a total of  <dig> motifs of lengths between  <dig> and  <dig> that have p < 10- <dig>  these findings indicate that, even with a dataset as large as the coding regions in a bacterial genome, a sampling/z-score approach can have significant error rates, which in this dataset are mostly false negatives. the differences between our exact method and that of robins et al are somewhat influenced by the lack of dinucleotide effects in the robins et al null model. when we used an icm null, which is more similar to the robins et al null, we found that codingmotif classifies the motifs ccc, cagat, and ctcc similarly as robins et al. however, under an icm null, codingmotif still finds the motif ctgctgg to be overrepresented , indicating that the misclassification by the robins et al method is caused by weakness in the sampling/parameterization approach. moreover, under the icm null we find a total of  <dig> motifs of lengths 3- <dig> with overrepresentation p-values < 10- <dig>  demonstrating that the high false negative rate of robins et al is due to the sampling/parameterization approach rather than the lack of dinucleotide effects in the null.

mammalian splicing motifs
as a test of the ability of codingmotif to identify biologically relevant motifs, we analyzed the behavior of splicing motifs on the coding sequences in human chromosome  <dig>  our expectation was that motifs with known activity in coding regions, such as exonic splicing enhancers, would show overrepresentation. figure  <dig> shows the log p-values from codingmotif versus experimentally measured exonic splicing enhancer activity, for sequences assayed previously by  <cit>  . the splicing activities refer to rates of splicing rescue when a particular hexamer was inserted into exon <dig> of a psxn reporter construct. we found that motifs with superior p-values indeed have greater splicing activities. for example, the motifs with the top  <dig> p-values all have splicing activities of at least 40%. overall, we observe a correlation with r <dig> =  <dig>   between - log and splicing activity. however, some motifs with strong overrepresentation do not show strong splicing activity. this illustrates the importance of dataset size, as it is likely that this large dataset may have a number of other functional motifs that are overrepresented but have functions unrelated to splicing.

human transcription factor motifs
this issue of dataset size is important for applicability of the method, as a common application for motif detection algorithms is to search for functional motifs in targeted experimental datasets such as determined by chromatin or rna immunoprecipitation. because this type of dataset is typically smaller than the genome-scale sets described in the above examples, it can provide a more stringent and practical test of the effectiveness of a motif evaluation program. neither itzkovitz et al  <cit>  or robins et al  <cit>  analyzed such targeted functional sets, instead focusing on whole genome data. we analyzed chip-seq data for the human transcription factors gabp and nrsf in the human jurkat cell line, using data from  <cit> . for each of these transcription factors, the canonical binding motif is known, as described in  <cit> . we extracted the sequences around chip-seq peaks overlapping coding regions for each of these transcription factors, and then applied codingmotif to determine if the known motif could be recovered. since data were from the human genome, we used the full set of coding sequences in the human genome to calculate the null model.

results for gabp are shown in figure 4a, with the previously known canonical motif shown in weblogo form  <cit> . the signal for the canonical gabp motif is essentially 7bp long with little degeneracy . we determined the top  <dig> 6-mer motifs from codingmotif as ranked by their overrepresentation p-values, each of which was 1e- <dig> or better. we found that these  <dig> motifs were the  <dig> possible perfect 6-mer matches to the canonical motif: cggaag, ccggaa, and their reverse complements cttccg and ttccgg. to determine whether a parametric approximation of the count distribution would perform equally well, we also calculated z-scores for each 6-mer based on their observed counts and their average counts over all possible coding sequences, which we determined directly from the distribution function calculated by codingmotif. note that the mean calculated according to this method is is the ideal of what would be found with an infinite amount of sampling. we found that the top  <dig> motifs produced by a z-score approach returned only 3/ <dig> of the canonical gabp hexamers. we also sorted motifs according to their count ratio , the statistic used by itzkovitz et al  <cit>  to identify motifs. we found that count ratio yielded only 1/ <dig> of the canonical hexamers among the top  <dig>  thus codingmotif gives superior results to this idealized parametric method. methods which parameterize the count distribution from a finite sample set can do no better than this parametric ideal.

we performed a similar test for the transcription factor nrsf also using data from  <cit> , and the results are shown in figure 4b. nrsf has a bipartite motif, essentially made up of an 8-mer  and a 6-mer . the top  <dig> motifs returned by codingmotif  all matched to 6-mers in these canonical sequences. two matched to the 8-mer portion  and two matched to the 6-mer . however, the z-score measure performed considerably worse. none of the top  <dig> motifs ranked by z-score matched to the canonical 8-mer or 6-mer. similarly, none of the top  <dig> motifs ranked by the count ratio matched to these canonical motifs. these results demonstrate that codingmotif is superior to parametrically-based methods for protein immunoprecipitation-sized datasets.

we have reported results for 6-mers rather than longer k-mers because we observed that for k >  <dig>  a large fraction of k-mers did not appear in the data and many k-mers also had expected copy numbers much less than  <dig>  these properties led to large numbers of outliers in the motif z-score and count ratio statistics. codingmotif p-values did not suffer from this problem. for example the top gabp 7-mer was the canonical 7-mer ccggaag, but the 7-mers with the highest z-scores and count ratios were all low copy number motifs not matching the canonical 7-mer. although z-scores in principle correct for small copy number effects, these corrections fail when there are strong non-gaussian deviations in the count distribution. codingmotif is by construction immune to this problem, and this is likely one of the reasons for its superior results.

we also analyzed whether sampling without resorting to parametric approximations could yield accurate motif predictions. for the gabp dataset, we obtained  <dig> randomized dicodon shuffles of the data using the method of  <cit> . we then calculated the fraction of shuffles showing at least as many copies of the motif as found in the original sequence . the  <dig> canonical 6-mers had better than average p-values according to this approach , but in fact  <dig> of the possible  <dig> hexamers had p-values of  <dig>  or better. thus the only motif which could be distinguished in this approach was ccggaa, and with a confidence only proportional to the number of shuffles. the many k-mers with low p-values are likely due to a large fraction of the bases in the sequence being under selective pressure in this dataset, a behavior which would distort the null model associated with codon-shuffling. similar results were found for the nrsf data. of the  <dig> motifs found by codingmotif, the one with the best p-value in this shuffling approach was ctgtcc . however again a very large number of the 6-mers  showed p-values of  <dig>  or better. these findings demonstrate the superiority of an externally defined null model as implemented in codingmotif over one based on shuffling, even in the absence of parameterization.

evaluation on synthetic data
finally, we tested codingmotif on synthetic data to estimate what types of counts may be necessary for it to successfully identify motifs. we generated  <dig> random sequences each  <dig> codons long  according to the dcm markov model using human coding sequences to train the null and assuming that the 3'-most codon was a stop codon. we then picked from 1- <dig> of these sequences and inserted a copy of the motif into each by replacing randomly chosen positions. if replacement would create a premature stop codon, another location was chosen. we performed this test for each of the  <dig> 6-mers  <dig> times for each number of inserted motifs ranging from  <dig> to  <dig>  the average and standard deviation of log p were calculated across 6-mers and trials. codingmotif calculations took  <dig> minutes on a  <dig>  ghz dual core poweredge system without making use of multithreading.

for 6-mers, a p-value better than 4- <dig> =  <dig>  is an appropriate significance threshold taking into account multiple testing. as can be seen in figure  <dig>  this level of significance is achieved, on average, when 6- <dig> of the sequences have a copy of the motif, though there is strong variability from motif-to-motif as indicated by the plotted standard deviations. for larger datasets, a relatively lower motif density would be expected to be sufficient for detection of significant overrepresentation.

for comparison, we also calculated the average z-score for each motif across these runs, where the z-score was calculated from the exactly enumerated distribution returned by codingmotif. we observed that the z-score based p-values were systematically too weak  at  <dig> or fewer inserted motif copies, though as for codingmotif there was strong variation from motif-to-motif . while codingmotif tends to exhibit greater sensitivity at these lower copy numbers, this systematic effect is probably less important than the fact that codingmotif p-values are more accurate for individual motifs. for greater than  <dig> inserted copies, z-score based p-values are systematically lower than those of codingmotif. however, both codingmotif and the z-score method have very significant p-values  at this range of copy numbers, so this systematic difference is again probably less important than the differences for individual motifs.

human synonymous constraint elements
recently, lin et al developed a method to detect elements in coding regions likely to be under constraint based on their synonymous conservation across  <dig> mammalian genomes   <cit> . we analyzed whether these regions contained overrepresented motifs. lin et al reported that these regions had relatively weak compositional biases relative to other coding regions, e.g. with only a ~ 3% difference in gc content between sce regions and control regions, and significant but small enrichment for known functional motifs such as exonic splicing enhancers and mirna seeds . however, we found a number of motifs with extremely strong enrichment p-values in sces compared to the human genome coding sequence background, including  <dig> motifs with p-value 1e- <dig> or better and each having more than  <dig> times the number of copies expected by chance. notably, these include several motifs with multiple cpg dinucleotides. the strong enrichment of specific motifs in these datasets indicates the importance of further motif studies in human coding regions. note that this dataset  was considerably larger than the synthetic datasets but calculating overrepresentation for all  <dig> 6-mers was feasible on a standard laptop computer .

software usage and caveats
a software implementation of codingmotif is available at bioinformatics.bc.edu/chuanglab/codingmotif.tar. we have extended the algorithms described above to allow codingmotif to calculate p-values for degenerate motifs  defined by a set of k-mers. these can be evaluated together, such that an occurrence of any of the k-mers constitutes a match to the degenerate motif. this requires only a minor modification to the counting procedure in the calculation of the distribution function. note that this k-mer set approach is more general than using iupac symbols to handle degeneracy, since iupac symbols cannot handle base correlations within a motif. the k-mer set functionality can also be used to handle motifs that could appear on either the forward or reverse strand, e.g. by placing reverse complements such as  together in a set. in addition, we have written a wrapper allowing codingmotif to evaluate multiple motifs, each of which may be defined by a set of k-mers, in succession. codingmotif has been written to handle arbitrary-sized motifs, so motifs of any length can be used as input. for a given run, codingmotif can return the motif count in the input, its p-value, the count distribution in the null, the mean number of counts in the null, and the z-score for the motif. underrepresentation p-values can be straightforwardly calculated as  <dig> minus the overrepresentation p-value. we have demonstrated that p-values for all  <dig> 6-mers can be calculated for dataset sizes on the scale of several hundred kb in a few hours on a single workstation. calculations for larger datasets can be trivially parallelized using multiple processors by distributing motif runs across cpus. the code is open source in c++.

codingmotif takes fasta files as input. note that input sequences which are not made up of full codons are conceptually inconsistent with the amino acid-conditioned null model, as hanging bases can match with many possible amino acids. the ends of sequences beginning/ending out of the canonical codon frame should be repaired to full codons before input to codingmotif, e.g. by truncation of hanging ends. full documentation for codingmotif can be found in the downloadable tar file.

it is worth discussing what types of motifs codingmotif will work best for. the results on nrsf and gabp are based on overrepresentation of exact 6-mers, which are appropriate because binding sites for these two transcription factors both have a relatively strong signal for exact 6-mer sequences as evidenced in their sequence logos . for motifs of greater degeneracy or motifs of different length, the results of codingmotif would be improved by also testing non 6-mers or degenerate motifs using the software features described above. however, allowing for degeneracy and different lengths also leads to stronger p-value requirements to correct for multiple-testing. these issues may be important for some transcription factors, since transcription factor binding sites may be as long as  <dig> binding sites  <cit>  with varying levels of degeneracy at internal positions. these issues will be less important for motifs likely to have little degeneracy, such as microrna binding motifs. in general, we expect codingmotif to have the greatest advantage over sampling/parametrically-based approaches if the expected and observed number of copies of the motif are both relatively small. this is because codingmotif is generally more sensitive than z-score approaches when there are low numbers of extra motif copies , and also because non-gaussian deviations distort z-score approaches when the expected number of copies is small.

similar issues also affect the power of codingmotif for building a target classifier. for example, a simple type of classification would be whether a sequence does or does not have a copy of a motif determined to be overrepresented by codingmotif. for the gabp data, we observe that 65% of the sequences have a copy of at least one of the top  <dig> codingmotif hexamers from figure  <dig> . 59% of the sequences have a copy of at least one of the top  <dig> hexamers by z-score. there are  <dig> copies of the top  <dig> codingmotif k-mers in the gabp sequences, while  <dig>  are expected under the dcm null, corresponding to a precision of 90%. for the top z-score hexamers, there are  <dig> copies while  <dig>  are expected, also yielding a precision of 90%. however, we observe a stronger difference in the power of codingmotif and z-scores for nrsf. 66% of the nrsf sequences contain at least one copy of the top  <dig> codingmotif hexamers, while only 21% of the sequences contain a copy of a top  <dig> z-score hexamer. this low recall for nrsf z-scores is slightly compensated by an increase in precision . similar behavior is observed if we train motifs on half the sequences and evaluate on the other half. using this approach and classifying based on the top  <dig> motifs, we find that gabp has recall and precision of 63% and 91% respectively for codingmotif, and 57% and 90% for z-scores. for nrsf, we observe recall and precision of 49% and 77% for codingmotif, but only 4% and 25% for z-scores. this strong difference between z-scores and codingmotif for nrsf but not gabp is due to the larger number of possible hexamers that can induce nrsf binding. this causes the prevalence of each such hexamer to be lower, increasing the importance of exact evaluation. although we have used a naive classification approach to illustrate this idea, this principle should also affect more sophisticated target classification approaches. in standard approaches to building a classifier, the scores for individual motifs are used in the process of clustering and merging motifs to form a position-specific weight matrix, e.g. as described in  <cit> .

CONCLUSIONS
codingmotif provides an exact non-parametric method for calculating overrepresentation p-values of motifs in coding regions, a previously unsolved problem. we have shown that codingmotif is able to accurately detect functional motifs in a variety of prokaryotic and eukaryotic datasets, and in short times accessible on single workstations. prior works have been based on sampling, an approach limited by the infeasibility of sampling more than a tiny fraction of the sequence space, and by their use of parametric approximations for the motif count distribution. we have demonstrated that codingmotif performs better than such methods using representative experimental data, including human transcription factor chip-seq data overlapping coding regions.

codingmotif provides a theoretically and empirically improved approach over prior methods to identify unusually overrepresented motifs in coding regions. we expect it to be useful for the study of a wide variety of functional genomic problems, notably dna-protein binding, rna-protein binding, and microrna-rna binding.

