BACKGROUND
in the course of evolution, new genomes occasionally arise by duplication or triplication of an existing genome, so that there are two or three identical copies of each maternal and each paternal chromosome. after a  transient period of polyploidy marked by unusual patterns of meiosis where more than just one maternal and paternal chromosome are aligned and recombine, processes of sequence divergence and chromosome rearrangement lead to more familiar diploid patterns. at the same time a process of fractionation eliminates some or most of the duplicate genes, some from each chromosomal copy, but in the simplest model, never all members of a duplicate pair or triple - for reasons of viability. fractionation processes have been surveyed across evolutionarily diverse types of eukaryote organisms  <cit> .

since one copy of a duplicate pair of genes must be retained, we can identify not only the chromosomal regions that have been retained – by simple observation of the genome – but also each region that is now invisible – by reference to the duplicate chromosome that has necessarily retained a copy of this region. thus, the data on which inferences about the deletion process can be made consist of alternating segments of deleted and undeleted genome of varying lengths.

among the important questions about the nature of the deletion process, we can ask whether deletion proceeds one gene at a time or by larger chromosomal fragments. in this paper, we model the process as the deletion of segments from the real line, with a biologically realistic treatment afforded to overlapping deletions. previous work focused on the difficult question of how many overlapping deletion events are responsible for each contiguous deleted region , but was not able to account analytically for the dynamics of the process.

in the present paper we attack and solve the inference problem of the size, form and spacing of deletion events, allowing for a number of sweeps over the genome as a way of accounting for overlapping deletions. we carry this out in a continuous analog of the original discrete gene-order context, and address the “one-sided” version of the problem, where all deletions occur on one of the duplicate chromosomes.

there has been a certain amount of work on the quantification of the fractionation process, starting in  <dig> with  <cit> , which claimed deletions involved one gene at a time, and  <cit> , which treated the number of genes deleted in a single event as a random variable with mean greater than  <dig>  other work of this kind includes  <cit>  and  <cit> . however, the modelling of fractionation where the whole genome evolves as a stochastic process began with  <cit> . the previously unstudied phenomenon taken into account in that work was the overlap of deletion events, something that assumes much importance soon after the fractionation process commences. overlap must be handled differently if all deletions occur from one copy of the genome or in either copy. to isolate the most important aspect of overlap,  <cit>  gave analytical results for the case where deletions all occurred on one copy . then  <cit>  extended this to the more realistic case where deletion could occur at different rates, or the same rate, from either copy of the genome . this analysis was more difficult and could not be taken as far as with the one-sided model.

for the one-sided model, a closed form solution of how many deletion events contribute to a deleted region after a single event  was obtained in  <cit> .

methods
the proposed model
we model the fractionation process in terms of a number of successive sweeps of a point process with parameter ν on the positive reals, i.e., ν∈r
+, representing one copy of the genome. at the origin, we say that all points of this genome are “visible”. a deletion event, rendering a segment of exponentially  distributed length “invisible”, occurs at each point determined by the point process. the second copy of the genome remains undisturbed throughout and retains a 1-to- <dig>  length preserving, correspondence with the fractionating copy, without regard to any disruption caused by invisibility. in applications, the acceptance of the one-gene-at-a time theory of deletion depends on whether μ is below or above a certain absolute value, but the present work is part of the mathematical preliminaries to the practical questions. the eventual goal of this work is to determine the relative size of the “spacing” parameter ν and the deletion length parameter μ. the model innovation here is to introduce the parameter ν in the place of a rate parameter in previous work, which was awkward to work with.

during the first sweep, illustrated at the top of fig.  <dig> at time  t= <dig>  the first deletion point
x
 <dig> is determined by sampling from the exponential distribution 
  <dig> ρ=1νe−xν,x≥ <dig>  
fig.  <dig> processes pertinent to first sweep and t-th sweep. solid horizontal bars represent the visible regions of the genome. grey curves represent invisible regions. dashed markers represent deletion points, solid markers represent end of deletion segments. ν and μ are the means of the deletion point spacing and deletion segment length variables, while λ
 is the mean space  between visible deletion points after the t−1-st sweep




with mean ν. then a deletion length a
 <dig> is chosen from another exponential distribution 
  <dig> γ=1μe−aμ,a≥ <dig>  


with mean μ. normally, ν≫μ, but this is not necessary to the analysis. the segment [x
 <dig> x
1+a
1) is “deleted", or is designated as invisible. the next deletion point x
 <dig> is chosen by sampling x2′ from the first exponential distribution , so that x
2=x2′+x
1+a
 <dig>  then the length a
 <dig> of the second deleted segment is determined by sampling from γ again. the process continues in this way to find x
 <dig> a
 <dig> … concatenating only those segments that are still visible, we see that x
 <dig> x
 <dig> … are points determined by a point process with parameter ν. associated with each of these points x is an “event counter" c. initially, each c= <dig>  we define a function π
t,i= <dig> … measuring the proportion of event counters registering i events at time t≥ <dig>  thus π
1= <dig> and π
1= <dig>  for all j> <dig> 

at times t= <dig> ,…, the second, third, … sweeps begin, all independent of the first sweep and each other, and each applied to the concatenated visible segments only. we sample x <dig> and a <dig> in the same way as x
 <dig> and a
 <dig> according to ρ and γ, respectively, to determine a deletion interval [x <dig> x1+a1).

if the interval [x <dig> x1+a1) contains no previously defined deletion point, a new event counter at c) is set at  <dig>  if [x <dig> x1+a1) already contains j> <dig> deletion points z
 <dig> …,z
j, the event counter at c) is set at 1+∑i=1jc. the j deletion points z
 <dig> …,z
j become invisible, along with the rest of the segment [x <dig> x1+a1) that contains them.

we find the next deletion point by sampling x2′ from ρ, and setting x2=x1+a1+x2′. we continue the t sweep, adding visible deletion points and making others invisible. some deletion points from the earlier sweep will remain unchanged, i.e. are still visible. the xi by themselves define a point process with parameter ν on the concatenated visible segments. but the xi and the additional deletion points remaining from the earlier sweep define a process with mean λ
t, a parameter that decreases with t, as the undeleted segments are interrupted by more and more deletions. this parameter is important as it is directly inferable from the observed genome at time t.

more important, it is clear, that at each sweep, more and more of the genome becomes invisible. since each concatenation of visible segments still extends to the positive reals, we cannot observe directly how much the genome has been reduced in absolute terms. but thanks to the length-preserving isomorphism between the second copy of the genome and the fractionating one, for any large finite interval we can observe the proportion of the genome that is left by time t and we can predict that it is approximately t.

we will calculate λ, the number of deletion points in [x
i,x
i+1), the distribution p,j= <dig> ... of the number j of pre-existing deletion points in intervals deleted during each sweep, and discuss how to calculate π
 <dig> j≥ <dig>  the proportion of event counters with c=j.

RESULTS
the length of undeleted segments λ
after the first sweep, x
i is the only deletion point in [xi,ai) and the only deletion point in the visible [xi,xi+1), so that λ
1=ν. during the second sweep, the number of these first-sweep deletion points that the visible [xi,xi+1) contains is poisson distributed with mean νν+μ, while the remaining first-sweep deletion points that the invisible [xi,ai) contains are poisson distributed with mean μν+μ. −xixi+1+ai−2xi and ai−xixi+1+ai−2xi, respectively.) in addition the visible segment contains one new deletion point, created during the second sweep itself. we can then predict λ
 <dig> to be roughly 
  <dig> λ^2=ν1+νν+μ. 


suppose λ
t− <dig> is the parameter of the point process that generates the deletion points visible after sweep t− <dig>  then, in the sweep at time t, the number of deletion points that the invisible [xi,ai) will contain is poisson distributed with mean μλt− <dig>  the number of deletion points in the visible [x
i,x
i+1), not including x
i, is poisson distributed with mean νλt− <dig>  in addition, the visible segment contains one new deletion point, created during the t-th sweep itself. λ
t can thus be predicted to be approximately 
  <dig> λ^t=ν1+νλ^t− <dig>  


since λ^1=ν, 
  <dig> λ^t=νt. 


the treatment of overlapping deletions
the discussions in this section and the next do not depend on t, so let Λ be the exponential distribution with mean λ. from  <cit> , the probability p
 <dig> that a deletion event contains no extant deletion points is 
  <dig> p0=∫l=0∞lΛλ∫x=0l1l∫y=0l−xγdydxdl. 


carrying out the integrations, we find 
  <dig> p0=λμ+λ. 


the probability p
 <dig> that a deletion event overlaps exactly one existing run of deletions is: 
  <dig> p1=1λ∫l=0∞∫z=0∞ΛΛ∫x=0l∫y=l−xl−x+zγdydxdzdl 



  <dig> =λμ+λ·μμ+λ. 


it can be proved by induction that the probability a deletion event overlaps exactly q existing runs of deletions is: 
  <dig> pq=λμ+λμμ+λq. 


thus we have the surprisingly uncomplicated result that the number q of pre-existing runs of single-copy regions overlapped by a new deletion event is geometrically distributed on q= <dig> ,… with parameter μ/.

the distribution of event counts π
the event count c at a visible deletion point x tells us how many deletion events have occurred to make up the invisible segment adjacent to x. in contrast to the undeleted segments, where we know that no events occurred, observing that a segment has been deleted does not tell us c. some work has focused on the distribution π of the probabilities that a deletion point x has c=i, and we are able to calculate how π changes with each sweep. then we can update π
t by a linear combination of the distribution of changes due to the deletion and the existing π
t− <dig>  let Δ represent the change in π
i at any sweep t. this can be calculated from eq.  and the net effect that a deletion overlapping q existing runs has on the various π. without giving details here, 
  <dig> Δ=p0−p1π−2p2π−3p3π−4p4π−… 



  <dig> Δ=p1π−p1π−2p2π−3p3π−4p4π−... 



  <dig> Δ=p1π+p2π2−p1π−2p2π−3p3π−4p4π−... 



  <dig> Δ=p1π+2p2ππ+p3π3−p1π−2p2π−3p3π−4p4π−… 



  <dig> Δ=p1π+p22ππ+π2+3p3π2π+p4π4−p1π−2p2π−3p3π 



  <dig> −4p4π−5p5π−…… 


unfortunately, even knowing the dynamics of c does not help us with the inference problem, since the number of events associated with an invisible segment, is not directly associated with the total length of the segment. it is known that the overlapping gamma variables making up each segment are related in a complex way, and cannot simply be treated as the sum of gammas drawn a single population.

this leads us to the approach in the next two sections, where simulations strongly suggest the functional form of the distribution of invisible segment lengths, including shape and rate parameters that can be observed, leading to inference of the simulation parameters based on the observations.

simulation
our simulation experiments were based on initial visible segments of length  <dig> , which is very long in comparison to the deletion lengths with μ≤ <dig>  in other words, we do not risk artificial effects, like a disappearing genome, after a few sweeps, t≤ <dig>  moreover, after each sweep, if the total undeleted length =l, we add, to the end of the remaining visible portion, segments where the lengths of the visible portions total  <dig> −l, copied from a replicate trial. the program, written in java, was repeated  <dig> times for each configuration of the parameters μ,ν and t. each set of  <dig> trials averaged a total of less than  <dig> min on a lenovo y <dig> laptop.

after each sweep, we calculated the distribution of segment lengths for both the invisible and visible parts of the model genome.

parameter estimation
the results of the simulations strongly suggest that the lengths of the invisible segments are gamma distributed, as illustrated in the cullen-frey graphs at the top of fig.  <dig>  as the parameters ν,μ and t change, the moments of the simulated distributions also change, but remain those of a gamma distribution. similarly, the distribution of the lengths of the visible segments is always exponential, as at the bottom of fig.  <dig>  with rate 
  <dig> λ−1=tν. 
fig.  <dig> cullen-frey diagrams for length distributions of invisible  and visible  segments




as a first step towards the ability to infer μ and ν from the length distributions of invisible and visible segments, we would like to predict α and β, the shape and rate parameters of the gamma distribution, from t,μ and ν. table  <dig> suggests, for a fixed value of t and a fixed value μν, that shape is constant as μ changes, and that the rate is inversely proportion to μ.

μ
ν



similar results hold for each combination of t and μν, with different shape constants and rate proportions. figure  <dig> shows how the shape constant varies with t for four values of μν.
fig.  <dig> linear relation between 1/α and t− <dig> for fixed μν





the four coefficients of the linear relationships inferred from fig.  <dig> are plotted in fig.  <dig>  fitting this curve with a quadratic yields 
  <dig> α−1−1=. 
fig.  <dig> relation between slope of 1/α as a function of t, and μν





as for the rate parameter of the gamma, fig.  <dig> shows that it is the logarithm of the rate that behaves linearly over time for a fixed value of μν.
fig.  <dig> relation between 1/rate  as a function of t for fixed μν





the four coefficients of the linear relationships inferred from fig.  <dig> are plotted in fig.  <dig>  fitting this curve with a quadratic yields 
  <dig> β−1=μexp− <dig> μν2+ <dig> μν− <dig>  
fig.  <dig> relation between slope of ln1/β as a function of t, and μν





the observable quantities in our model are the distribution of visible segment lengths, predicted to be exponential with mean λ, and the shape and rate parameters α and β of the predicted gamma distribution of invisible segment lengths. these three observable quantities are related to the unknown model parameters μ,ν, and t through eqs. ,  and . with the given value of these parameters, we can estimate the values of μ,ν, and t.

lacking a closed form solution for μ,ν, and t in terms of λ,α and β, we use the following procedure. since t must be an integer, we can find values of ν
t and μ
t for each t= <dig> ,… with eqs.  and . then we can solve eq.  to find β
t.

we then compare all the β
t, for t= <dig> ,… with the β observed in the simulation, and set 
  <dig> t^=argminβ−βtβ 


as an example, in one set of simulations where μ= <dig> ν= <dig> and t= <dig>  the experimental value of parameters are λ
−1= <dig> ,s
h
a
p
e= <dig>  and β= <dig> . when t≤ <dig>  there is no solution for μ. for t> <dig>  table  <dig> shows the results of this procedure, where 100δ is  <dig> × the normalized difference between β and β
t in eq. .μ= <dig> ν= <dig> t= <dig> λ
−1= <dig> ,α= <dig> ,β= <dig> 

par ∖time t

μ

ν

β
t
100δ
 <dig> 
bold entry indicates the t most consistent with the observed data on α,β and λ





the minimum value of 100δ occurs when t= <dig>  expressing the fact that the inferred values of μ and ν, together with t= <dig>  are the parameter values most consistent with the observed values of α,β and λ. other typical examples spanning a range of parameter values are given in tables  <dig>   <dig> and  <dig> μ =  <dig> ν =  <dig> t =  <dig> λ
−1= <dig> ,α= <dig> ,β= <dig> 

par ∖time t

μ

ν

β
t
100δ
 <dig> 
bold entry indicates the t most consistent with the observed data on α,β and λ


μ= <dig> ν= <dig> t= <dig> λ
−1= <dig> ,α= <dig> ,β= <dig> 

par ∖time t

μ

ν

β
t
100δ
 <dig> 
bold entry indicates the t most consistent with the observed data on α,β and λ


μ= <dig> ν= <dig> t= <dig> λ
−1= <dig> ,α= <dig> ,β= <dig> 

par ∖time t

μ

ν

β
t
100δ
 <dig> 
bold entry indicates the t most consistent with the observed data on α,β and λ





it can be seen, at least in these diverse examples, that the inference procedure generally identifies the correct value of t, and good estimates of μ and ν.

discussion
the introduction of sweeps consisting of alternating jumps and deletions, with time-invariant parameters ν and μ, provide us with an improved possibility of solving the fractionation model completely. we do announce such a solution, though it has much room for improvement. though the exponential distribution of visible segment lengths should be easy to establish analytically, it is also possible that the gamma distribution of invisible segment lengths could be proved, including the α and β parameters as a function of the number of sweeps. depending on the functional form of such a solution, the inference of t,μ and ν might be amenable through closed form formulae rather than the quadratic modeling. nevertheless, we have succeeded for the first time in inferring the parameters of a fractionation model, albeit a “one-sided” model and a continuous analog of more realistic discrete fractionation models.

CONCLUSIONS
aside from theoretical improvements, the first priority for this work should be the return to a discrete gene-order model of fractionation with the insights gained in the current report. this should be extended to, or at least tested on simulations of, two-sided fractionation models with subgenome dominance .

