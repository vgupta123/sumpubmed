BACKGROUND
global plants, a collaborative between jstor and some  <dig> herbaria, is now the world’s largest database of digitized plant specimens . it currently contains images of  <dig> , <dig> million herbarium sheets . each of the images is accompanied by metadata including the latin  species name and data transcribed from the label, such as name of collector , collection date and location , and the acronym of the herbarium that owns the specimen. many of the images in jstor plants are of so-called type specimens, which have received priority in digitization projects because they are essential to biological nomenclature. as set out in the code of nomenclature for algae, fungi, and plants  <cit> , type specimens fix the application of names, and by definition, a type specimen is, and always remains, correctly identified, no matter the changing taxonomic views and insights from new data. the plants shown in these images are not always perfectly preserved; for example, their leaves often overlap each other or are damaged.

herbaria that are digitizing their type specimens are allocating considerable recourses to the maintenance of computer hardware and rental of storage space for growing numbers of images. it is therefore important to consider, and test, the future utility of the millions of high-resolution type specimens. an obvious desideratum in this context is the application of machine learning to quickly classify images into thousands of categories of interest to different user, such as “rosaceae”, “crataegus”, or “fagus sylvatica.” so far, computer vision has not been applied to jstor plant specimen images. instead, use of digitized plant images still relies exclusively on human pattern recognition and on the  memories of taxonomists who know under which latin name to search for an image. between june  <dig> and april  <dig>   <dig>  unique visitors viewed  <dig>   of the  <dig>  million jstor plant images. during a slightly larger period of  <dig>  years , there were  <dig>  unique visitors . at this time, of course, only people who know the latin name of a plant  can find images of specific species in jstor.

machine learning applied to images of museum specimens offers the opportunity to identify  specimens speedily, which would facilitate subsequent fine-scale analysis by taxonomic experts, for example, whether a specimens is an outlier in its traits or geographic range and may represent a new species. . the application of machine learning and computer vision to museum specimens differs from applications of computer vision to living specimens where the primary goal is not find a latin name for an unnamed specimen, but instead to cluster specimens for other purposes. so far, computer vision approaches in biology have been applied to cluster  wings of drosophila species  <cit> , wings of common british moths  <cit> , bee wings  <cit> , and color spots of cichlid fish  <cit> . in plants, computer vision has been applied to images of  <dig> fresh leaves belonging to  <dig> different plant species  <cit> , images of fresh leaves of a few tree species  <cit> , and images of fresh leaves of three legume species  <cit> . one study has applied machine learning to images of dead leaves, using   <dig> leaf clearings from  <dig> genera of flowering plants to categorize leaf vein patterns  <cit> . leaf clearings are leaves that have been chemically treated and preserved to show the veins. the images used in all these studies show non-overlapping leaves. specimens in herbarium image databases, by contrast, have many overlapping leaves, presenting a challenge for the application of computer vision.

here, we test whether a standard computer vision algorithm can be trained on images of typical herbarium specimens to learn to identify the  <dig> tree species  most commonly encountered in germany  and surrounding countries of central europe. algorithms that examine morphometric characters usually require large training databases of images per category . for example, wilf et al.  <cit>  used at least  <dig> images per category . to generate a training database, we used only  <dig> images per species to simulate the empirical fact that most species are represented in image databases by just a few images. the photographed specimens were collected between  <dig> and  <dig> and were typical of herbarium material in often having overlapping leaves. our approach to deal with the problem of overlapping leaves consisted of first segmenting single, non-overlapping leaves for each species in a preprocessing step. a normalization routine was then used to counteract distortions and ensure comparability of the images. next, features of three categories were extracted from the normalized images and fed into a support vector machine to achieve the final classification. no prior study has adopted this combination of tools for leaf identification, using herbarium material.

methods
imaging setup for herbarium specimens
to obtain the training images, we used the munich herbarium’s herbscan unit, which consist of a flatbed scanner , modified for inverted use. specimens were photographed at a resolution of 5144  ×  3599 pixels and  <dig> dpi. for each species, specimens were selected to cover a range of typical herbarium material, including broken over folded leaves, leaves damaged by herbivores, and overlapping leaves. the most common german trees include several species that have similar leaves, for example, acer plantanoides, acer pseudoplantanus, populus tremula, populus nigra, quercus cerris, quercus robus, quercus petraea, ulmus glabra, and ulmus minor. a selection of our 260+ images is available as online supporting material. we initially tried using images from jstor but finding  <dig> per species proved extremely time-consuming and not possible for all  <dig> species.

preprocessing
to extract leaf characteristics from herbarium specimens, the first step is to locate and segment single leafs. the automatic segmentation routines had to distinguish leaves, fruits, flowers and stems, and to cope with overlapping and damaged leaves. we achieved this using the lazy snapping routine  <cit> , which requires that the user exemplarily mark a few points on the leaf and on the background. lazy snapping is based on graph cuts and provides visual feedback to the user so that segmentation results can be corrected if necessary. although fully automatic segmentation routines have been proposed  <cit> , the semi-automatic approach allowed for efficient and flexible processing and was able to deal with overlapping and damaged leaves.

normalization
to counteract shape distortions, the main vein connecting a leaf’s base and apex was aligned to a straight line as illustrated in fig.  <dig>  to enhance line structures, we applied the line operator described by zwiggelaar et al.  <cit> , providing line orientation o  and strength s  measures for each position . basically, the method matches a line template where the line is passing through the center pixel. lines of arbitrary orientation are detected by rotating the pattern. the best match determines the strength and orientation, using gaussian smoothing and subsampling. in our setup, we employed  <dig> orientations and three subsampling steps using line templates with a length of  <dig>  the main vein was considered as a path from the leaf base to the leaf tip that maximized the line strength and minimized the angle ∆α between the orientation angle and the straight line connecting petiole and leaf tip. a geodesic time algorithm finds a path connecting the leaf base and tip and minimizing εab = −s + ∆α,  where the leaf tip is given by the outermost 2% of the segmented area when following the straight line from the petiole passing the centroid of the leaf segmentation . this minimization takes into account that the main vein is only slightly curved and points towards the tip of the leaf. the resulting path can be approximated by a third order polynomial . for a consistent alignment, the leaves were rotated so that g was a vertical axis and the leaf tip pointed upwards. finally, for each row of the image, a horizontal alignment was made so that the identified main vein formed a straight vertical line.fig.  <dig> normalization of leaf distortions: the main vein is detected  and mapped to a straight line  providing a consistent data set for classification purposes


fig.  <dig> the orientation  and strength  of the vein network given by the line operator. the path minimizing εab from the petiole  to the leaf tip finally corresponds to the main vein




feature extraction
three sets of descriptive features  were defined and served as input to a support vector machine characterizing the leaf shape and leaf veins. fourier descriptors can easily be modified to be invariant under translation, rotation, and scaling. the first feature set, fs <dig>  consisted of fourier descriptors characterizing the outline of the binary leaf segmentation. the second set, fs <dig>  consisted of the descriptive leaf shape parameters compactness, convexity, solidity, rectangularity, circularity, perimeter-area ratio, slimness, position of maximum thickness, and dispersion  <cit> . the third set, fs <dig>  quantified the structure of the vein network. because a pixel-wise identification of the vein network could not be performed in a robust manner, we focused on features representing the orientation of the vein structure by using weighted orientation histograms.

figure  <dig> illustrates examples for leaf species  and their corresponding weighted histograms  characterizing their leaf vein network. in weighted histograms, each pixel is weighted by its line strength, and the cumulative weight of each of the  <dig> orientation bins is presented. the histograms were evaluated for the upper and lower half of each leaf and averaged for the left and the right side. different vein networks are indicated by the peak locations in the histograms as well as the spread and shifts between upper and lower peaks. for example, although the vein networks of alnus incana and fagus sylvatica are optically similar, their histograms emphasize different vein angle signatures. alnus incana  shows a shift of the orientation angle between lower and upper parts of the leaf, whereas fagus sylvatica  has parallel venation. the histograms therefore can serve as fingerprints of the venation networks and constitute the vein network-related feature set.fig.  <dig> examples for leaf species  and their corresponding weighted histograms  characterizing their leaf vein network




classifier setup
a support vector machine  was trained in order to assign unknown feature vectors to one of the species classes. the svm was configured with a linear kernel providing the best performances. due to the low number of mages per species, a leave-one-out validation strategy was pursued. multiclass classification was realized through the one-against-one strategy  <cit> .

validation
two test sets were used for validation. test set i consisted of all  <dig> species , a few of them in the same genus. in contrast, test set ii included only one species per genus, leaving  <dig> species.

RESULTS
the number of fourier descriptors was set to  <dig>  which was found to perform best in both test sets. with regard to the individual feature sets , the best overall performance was otained when all three were combined. with this approach, we achieved  <dig> % of accuracy in test set i, and  <dig> % in test set ii . the normalization step, which straightened the midvein, considerably increased the classification accuracy as seen in in fig.  <dig>  where the yellow bar shows the results without the normalization step and the blue bar with this step. this was particularly true for the fourier descriptors and the combination of the three feature sets. figure  <dig> shows the confusion matrix of test set i  when the three feature sets were combined. figure  <dig> shows examples of frequent misclassifications.fig.  <dig> classification accuracy obtained with data sets i and ii and the feature sets fs <dig>  fs <dig>  fs <dig> and combinations thereof. the best classification results are observed for a combination of all three feature sets combined with the proposed normalization step


fig.  <dig> confusion matrix showing the true class  and the class assigned by the system , at the 10-image minimum per category. the color-coding is explained to the right and refers to the percentage correctly identified


fig.  <dig> true species assignments in the first row; assignment achieved by the system in the second. morphologic similarities  and damaged leaves caused misclassifications




discussion
taxonomists are increasingly relying on digitized images, either to achieve specimen identification via visual matching of features or to extract morphological features that can be coded and used for phylogenetic, morphometric, or other purposes  <cit> . because of the great number of databased images now available and the comparatively few taxonomic experts, there is a great need for computer vision to be applied to specimen images of which millions are being made available online at substantial costs . deep learning approaches  <cit>  for computer vision in principle could allow automated plant specimen identification --meaning the suggestion of a latin name for the respective image-- as long as the software could be trained on suitable subsets of the millions of latin-named plant images already available online. extracting such subset is not an easy task, however, and the first insight from this project was that we had to make new images  to obtain  <dig> images for each of the tree species. it is an empirical fact that most of the estimated  <dig>  species of higher plants are known from few collections and are so far represented by few images in public databases. therefore the use of  <dig> images for training purposed sets a realistic bar.

our success rate of  <dig> to 85% with the two test sets is comparable to that in the few other projects that have applied computer vision to name plants by clustering of similar leaf types, although not necessarily on finding formal  species names. for example, the leafsnap application developed by kumar et al.  <cit> , which identifies common north american tree species in the washington  area, had success rates of  <dig> %, but requires snapshots of fresh, non-overlapping leaves. a classification of different grapevine varieties  had success rates of up to 80%  <cit> . scans of herbarium specimens of four fern species, using  <dig> scans per species, gave classification accuracies of at least 96%  <cit> . we found not data on identification success rates for image sharing and retrieval applications, such as pl@ntnet, where users can upload photos of plants and identify them for others . for comparison to all these photo-based tools, a study in which  <dig> common british trees  were identified by barcoding had species discrimination success rates of  <dig> to 86%  <cit> .

CONCLUSIONS
this study represents the first application of computer vision to images of old herbarium specimens, similar to the  <dig>  million specimen images in jstor. there is a need to efficiently use images of herbarium material  that are stored in public databases by making them more useful for non-specialists who need names for their plants. the results demonstrate that computer vision can be used to classify specimens even when they have many overlapping leaves and even when few training images are available. rapid identification even just to the genus level could help non-botanists who need a quick list of the tree species in a particular street or park.

additional file

additional file 1: table s <dig>  the  <dig> tree species most common in germany used on this study. 




