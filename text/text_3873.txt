BACKGROUND
microarray data analysis is widely used for the identification of ‘informative’ genes. however, due to the ‘curse’ of dimensionality, where the number of gene probes represented on microarrays far exceeds the available number of cases  as well as the inherent noise in microarray data, feature selection  approaches strive to achieve this goal. typically, informative genes are selected according to a two-sample statistical test combined with multiple testing procedures to guard against type  <dig> errors  <cit> . this methodology generates gene lists, which then can be either ranked or filtered according to certain statistical criteria, e.g. p-value, q-value etc. the selected subset of genes is assumed to construct better classifiers, both in terms of accuracy and efficiency. in particular, we expect improved classification performance and generalization by avoiding over-fitting. furthermore, the classifiers will be more efficient in time and space because of the fewer features, and biologists’ insights will be augmented  <cit> .

a wide variety of fs algorithms has been proposed  <cit>  and depending on how they combine the feature selection search with the construction of the classification model they can be classified into  <dig> categories: filter, wrapper, and embedded  <cit> . a filter based algorithm either selects features through univariate rankings  <cit>  or incorporates feature dependencies  like correlation based feature selection   <cit> . on the other hand, wrapper algorithms like genetic algorithms  <cit> , attempt to select multiple features simultaneously based on their performance on a training set  <cit> . finally, embedded algorithms, like random forest  <cit> , select the best subset of genes incorporating the classifiers’ bias  <cit> .

complementary to this categorization, hybrid approaches have drawn researchers’ interest. specifically the benefits of usually two different techniques are combined towards the identification of an improved gene subset selection, for example, a univariate filter with a wrapper or an embedded method  <cit> . apart from fs methods, there are also data reduction techniques such as principal component analysis and partial least squares, which search for linear combinations of all genes to provide us with a small subset of ‘metagenes’  <cit> .

an fs algorithm should perform efficiently and independently of the sample size and yield its subset within a reasonable period, to enable numerous experiments. moreover, the subset’s length should be small, for instance, less than  <dig> genes, and the selected genes should present biological relevance to the inspected disease so as to facilitate further analysis. despite the plethora of available fs methods, none of them has managed to successfully deal with all the aforementioned issues playing the role of a milestone. for instance, some methods are effective with small cohorts while others with large ones  <cit> . aside from this, there are methods that are developed and tested for specific diseases, leaving their suitability for broader use unexplored  <cit> . furthermore, some fs algorithms are so sophisticated that they either need specialized and expensive hardware to operate or an impractically long run time  <cit> .

we propose a data-driven and classifier-independent hybrid fs method , which combines multiple hypothesis testing  <cit>  and affinity propagation  clustering algorithm  <cit>  in conjunction with the krzanowski & lai  <cit>  cluster quality index, to select a small subset of informative genes. our hypothesis is that among the statistically significant genes there should be clusters of genes that share similar biological functions related to the investigated disease. thus, instead of keeping a number of the top ranked genes, it would be more appropriate to define and keep a number of gene cluster exemplars. we tested map-kl on real data from small and large cohorts, as well as on simulated data, and compared its performance against  <dig> other fs approaches. according to the results, map-kl achieves competitive classification results, particularly in the neuromuscular disease data, as well as in breast and colon cancers data, with subsets of less than  <dig> genes in most of the cases.

methods
rationale for selecting the proposed approach
jaeger et al.  <cit>  claimed that ranking algorithms produce lists of genes, where the top ranked genes are highly correlated with each other, mainly because they belong to the same pathway. additionally, hall in his thesis  <cit>  investigated the hypothesis that “a good feature subset is one that contains features highly correlated with the class, yet uncorrelated with each other”.

so far several approaches have been proposed  <cit>  based on these beliefs with promising classification results  <cit> . however, certain methodological differences or limitations prompt the development of our approach. the order of the analysis steps , the number of informative genes, and the data manipulation are issues that need specific focus in such an analysis. our method uses ranking prior to clustering, similarly to hykgene  <cit>  and mrmr  <cit>  and contrary to jaeger and hanczar  <cit> , because we wanted to filter the statistically redundant genes to facilitate the clustering analysis. regarding the number of genes, we employ a clustering index to determine the ‘actual’ number of representative genes. this differs from mrmr method, which iterates in its ranked gene list before concluding to a subset, and from jaeger and hanczar, where the resultant subset is driven by the initial number of potential clusters, which is set arbitrarily. in relation to hykgene, we determine the number of clusters and thus the ‘representative genes’ irrespectively of the classifier employed. finally, apart from the necessary transformation and normalization on the raw intensity values we do not perform any further preprocessing manipulation, like discretization as mrmr does to improve the classification results.

the general framework and implementation of our methodology
the proposed methodology combines ranking-filtering and cluster analysis to select a small set of non-redundant but still highly discriminative genes. in relation to the filtering step, we first employ the maxt function  from the ‘multtest’ package to rank the genes of the training set and then we reserve the top n genes  for further exploitation. we based our decision on keeping only the top  <dig> genes on the findings of a previous study  <cit> , where we observed a weak impact on the classification performance when differentiating the subset’s length.

in turn, prior to clustering analysis with ap we have to define the number of clusters, which in essence will be the number of representative genes that finally will compose our subset. we apply the index of krzanowski and lai as included in the ‘clustersim’ package  <cit>  to determine the number of clusters solely on the disease samples of the training test set. krzanowski and lai is defined by

  diffk=k−12/pwk−1−k2/pwk' 

when choosing the number of clusters  to maximize the quantity klk=diffkdiffk+ <dig>  the wk denotes the within-cluster sum of squared errors.

the final step of our methodology involves the cluster analysis. for this task, we engage the ap clustering method, which detects n  clusters among the top n genes, according to the pre-defined number, and provides us with a list of the most representative genes of each cluster, the so called exemplars. these n exemplars are expected to form a classifier that shall discriminate between the normal and disease classes in a test set. finally, we formulate the test set by keeping only those n genes, and proceed with the classification.

the map-kl is developed under the r environment  <cit> , in which we first incorporated the ‘multtest’, ‘clustersim’, and ‘apcluster’  <cit>  packages, and then created a function  to implement our methodology. the general flowchart of our methodology appears in figure  <dig> 

.

affinity propagation clustering method
affinity propagation identifies a set of centers  from actual data points. contrary to k-centers technique, which begins with an initial set of randomly selected exemplars and iteratively refines this set to decrease the sum of squared errors, ap considers each data point as a node in a network, and recursively transmits real-valued messages along edges of the network until a good set of exemplars and corresponding clusters emerges. at any point in time, the magnitude of each message reflects the current affinity that one data point has for choosing another data point as its exemplar.

messages exchanged between data points can be of two kinds: ‘responsibility’ r, and ‘availability’ a. ‘responsibility’ reflects the accumulated evidence for how well-suited point k is to serve as the exemplar for point i, taking into account other potential exemplars for point i. on the other hand, ‘availability’ reflects the accumulated evidence for how appropriate it would be for point i to choose point k as its exemplar, taking into account the support from other points that point k should be an exemplar. initially, the availabilities are set to zero. ap can be applied to problems where the similarities are neither symmetric nor satisfy the triangle inequality  <cit> .

classification and evaluation
regarding the classification phase we employed svm  <cit>  with linear kernel, knn  <cit> , and rf  <cit>  classifiers under the weka  <cit>  environment, to evaluate the performance of all fs methods employed. we first conducted a 5-fold cross-validation  on the training sets to assess the potential classification strength of the models’ and then estimated its prediction power on the separate test sets.

to evaluate the classification results, we employed various standard performance measures, which provide different insights. accuracy  is one of the most popular performance measures in machine learning classification, though it does not take into account the nature of the incorrect predictions, which can be crucial in clinical medicine and totally misleading about the actual classification performance of a given classifier. therefore we engaged the area under the receiver operating characteristics  curve or in short auc, which has been introduced as a better measure for evaluating the predictive ability of machine learners than accuracy  <cit> . the roc curve is a two-dimensional plot between the tpr  against the fpr  of the predictions. the closer the curve is to the y-axis  and the further away it is from the x-axis , the more accurate the predictions are  <cit> .

additionally, we employed true negative rate  or specificity, which represents the ratio of correctly classified negatives to the actual number of negatives and controls type i errors, as well as true positive rate  or sensitivity, which is defined to be the ratio of positives correctly classified to the actual number of positives and controls type ii errors. both, specificity and sensitivity are mutually independent  <cit> . the combination of those three measures provides us with an adequate overview of the classification’s performance.

datasets illustration
microarray data
in this study, we utilized real and synthetic data to assess map-kl’s performance. neuromuscular and cancer diseases data comprise the real microarray data and are available in comma-delimited format in the supplementary section. neuromuscular diseases are rare among the general population, thus the available tissue samples and whole transcriptome data are very limited. this characteristic is crucial since we intended to develop a fs method that produces robust models even in studies with limited number of samples. we therefore included data from bakay et al.  <cit>  related to ‘amyotrophic lateral sclerosis’ , ‘duchenne muscular dystrophy’ , ‘juvenile dermatomyositis’ , ‘limb-girdle muscular dystrophy type 2a’ , and ‘limb-girdle muscular dystrophy type 2b’ , as well as ‘nemaline myopathy’  data from sanoudou and beggs  <cit>  and sanoudou et al.  <cit> . the gene expression data for the first five diseases originate from affymetrix hg_u133a gene chips and share a set of  <dig> normal samples, whereas the nm data originate from affymetrix hg_u95a gene chips and have been compared to  <dig> normal samples. we divided the data approximately in half, and kept the first half to build a balanced train sets and the second half to validate the classification models . concerning the pre-processing approach, all neuromuscular data underwent log <dig> transformation and quantile normalization across samples.


regarding the cancers datasets, we utilized microarray data from breast cancer, colon cancer, leukemia, and prostate cancer, all of which are considered benchmark datasets and have been widely used in gene expression-classification studies. van’t veer  <cit>  explored breast cancer patients’ clinical outcome following modified radical mastectomy or breast-conserving treatment combined with radiotherapy. patients with good and poor 5-year prognosis following initial diagnosis were included. the breast cancer data was already normalized so we omitted the preprocessing step. the colon datasets  <cit>  consisted of  <dig> samples of colon epithelial tissue taken from colon-cancer patients. sample were obtained both from tumor tissue as well as adjacent, unaffected parts of the colon of the same patients, and measured using high density oligonucleotide arrays. for the analysis of the colon microarray data we followed the same pre-processing approach as we did for the neuromuscular data i.e. we performed log <dig> transformation and quantile normalization across samples.

datasets from acute lymphoblastic leukemia  and acute myeloid leukemia   <cit> , two distinct acute leukemias, were used for cancer subtype classification. the train set consisted of  <dig> all samples and  <dig> aml samples. finally, prostate cancer  <cit>  training data consisted of  <dig> prostate tumour tissue and  <dig> normal prostate tissue datasets, while the testing data consisted of  <dig> tumour and  <dig> normal datasets  <cit> . in relation to the preprocessing of the leukemia and the prostate data, we first set the golub’s floor and ceiling values , though without filtering the genes, and then applied log <dig> transformation and quantile normalization across samples. for all cancers datasets we kept the train and test sets as provided, see table  <dig> 

simulated data
apart from the real microarray data, we investigated map-kl’s performance on two synthetic datasets. we intentionally utilized two different simulation setups to examine two different hypotheses. in the first hypothesis, we wanted to verify that map-kl provides us with a small subset of representative features, at least one gene per cluster, adequate for accurate classification. therefore, we considered a binary classification problem simulating a normal-disease case with six different scenarios  in relation to the number of differentially expressed genes  that are included in the disease class samples.

in particular, we started with  <dig> degs belonging to five clusters of  <dig> ‘genes’ and reached to  <dig> degs spreading in  <dig> clusters of  <dig> ‘genes’ per cluster, trying to imitate pathways. the normal and the disease classes have  <dig>  samples of  <dig>  ‘genes’ per sample, where the first  <dig> samples from each class compose the train set and the rest form the test set. the non-differentially expressed genes are independently drawn from normal distribution with mean =  <dig> and variance =  <dig> .

in the second hypothesis, we employed a subset of the publicly available ‘golden spike’  <cit>  affymetrix case–control experiment, incorporated in the ‘st’ package  <cit>  under the name ‘choedata’. in this scenario, it was intriguing to explore the number of the known degs included in map-kl’s subset and whether they are capable of providing us with accurate models. the ‘choedata’ describes a binary classification problem with three replicates per class and  <dig>  degs scattered randomly among  <dig>  genes.

feature selection methods
we employed  <dig> feature selection/elimination approaches on the same real microarray datasets and compared its performance with that from map-kl. we set the subset’s length to  <dig> top ranked genes for all methods, except for maxt where we additionally engaged the top  <dig> gene list and evaluate their prediction strength. we decided to include methods that belong to different feature selection categories. in particular, we selected seven univariate filter methods , one multivariate filter algorithm , three dimension reduction approaches , one embedded method , one hybrid method  and one monte-carlo like  technique.

between group analysis  is a multiple discriminant approach that can be used with any combinations of numbers of genes and samples. bga uses a conventional ordination technique such as correspondence analysis  or principal component analysis  to carry out ordination of groups of samples. for n groups we find n −  <dig> eigenvectors or axes that arrange the groups so as to maximise the between group variances. the individual samples are then plotted along them. each eigenvector can be used as a discriminator to separate one of the groups from the rest. new samples are then placed on the same axes and can be classified on an axis-by-axis basis or by proximity to the group centroids. it is especially effective when combined with coa because it allows us to examine the correspondences between the grouped samples and those genes which most facilitate the discrimination of these groupings  <cit> .

the hybrid system for marker gene selection  is a hybrid approach that combines sequentially gene ranking and clustering analysis. firstly, a set of top-ranked informative genes is selected with the aid of filtering algorithms , and secondly a hierarchical clustering is applied on these genes to generate a dendrogram. finally, a sweep-line algorithm is used to analyze the dendrogram and marker genes are selected by collapsing dense clusters. the best number of clusters is determined systematically by applying the leave-one-out cross-validation  on the training data, trying all different options for extracting clusters from the dendrogram  <cit> .

principal component analysis  is a classic and one of the oldest dimension reduction approaches. it searches for linear combinations of the original measurements called principal components  that can effectively represent effects of the original measurements. pcs are orthogonal to each other and may have dimensionality much lower than that of the original measurements. because of its computational simplicity and satisfactory statistical properties, pca has been extensively used in bioinformatics studies, particularly gene expression studies, to reduce the dimensionality of high-throughput measurements and shown to have satisfactory performance  <cit> . we implement it through the bga package.

the optimal discovery procedure  is a high dimensional approach that uses all of the relevant information across tests when assessing the significance of each one. it allows us to test multiple hypotheses simultaneously in such a way that the total number of expected true positive results is maximized for each fixed number of expected false positive results. this procedure can be viewed as a multiple-test extension of the neyman–pearson  procedure for testing a single hypothesis. this method is available through the edge software program  <cit> .

maxt: it is a function that computes permutation adjusted p-values for step-down maxt multiple testing procedures as described in westfall & young  <cit> , which provides strong control of the family-wise type i error rate   <cit> . it determines the family-wise error rate adjusted p-values using the wilcoxon rank sum statistic. to do this the class labels are permuted, and the wilcoxon statistic for each gene is calculated. the maximum wilcoxon statistic is recorded for  <dig>  random permutations and the p for each gene is estimated as the proportion of the maximum permutation-based t-statistics that are greater than the observed value  <cit> . this is the ranking approach that we have engaged in map-kl.

genepattern is a software package, which provides a comprehensive environment that can support  a broad community of users at all levels of computational experience and sophistication,  access to a repository of analytic and visualization tools and easy creation of complex analytic methods from them and  the rapid development and dissemination of new methods  <cit> . the comparative marker selection suite is freely available as a genepattern module that allow users to apply and compare different methods of computing significance for each marker gene, a viewer to assess the results, and a tool to create derivative datasets and marker lists based on user-defined significance criteria. during our experiment we utilized two test statistics, the t-test and signal-to-noise ratio. from a plethora of estimates related with the significance of each gene we used the “rank” estimate which is based on the value of the test statistic  <cit> .

t-test: this is the standardized mean difference between the two classes. it is the difference between the mean expression of class  <dig> and class  <dig> divided by the variability of expression, which is the square root of the sum of the standard deviation for each class divided by the number of samples in each class.

snr: the signal-to-noise ratio is computed by dividing the difference of class means by the sum of their standard deviations.

partial least squares  is a highly efficient statistical regression technique that is well suited for the analysis of high-dimensional genomic data. the underlying idea of pls is to find uncorrelated linear transformations of the original predictor variables which have high covariance with the response variables. these linear transformations can then be used as predictors in classical linear regression models to predict the response variables. since the p original variables are summarized into a small number of relevant new components, linear regression can be performed even if the number of original variables p is much larger than the number of available observations  <cit> .

random forests  are a combination of tree-structured predictors where each of the trees grows using a random process. given a training set with n samples and m features, the n instances are sampled at random , so as to generate a random vector Θ for each tree. for the kth tree, there is a random vector Θk which is independent of the previous random vectors, Θ <dig>  … , Θk− <dig>  but with the same distribution for all trees in the forest. hence, every tree is grown using the training set and its random vector, resulting in a classifier, which votes for the most popular class.

when rf draws the training set for the current tree by sampling with replacement, about one-third of the cases are left out of the sample, and called out-of-bag data . this oob data is used to get estimates of variable importance. to measure the importance of variable xj, values of xj are permuted in the oob sample, and the class membership of the oob samples are predicted again from the tree. the number of correctly classified samples after permutation is subtracted from the original count of correctly classified samples and divided by the number of oob samples for that tree, thus giving the decrease in classification accuracy as a proportion of samples. this permutation procedure is repeated for each tree in the forest, and the mean decrease in accuracy  is defined as the average of these values over all trees in the forest . in this experiment, a random forest classifier with  <dig>  trees is applied  <cit> .

significance analysis of microarrays  identifies genes with significant changes in gene expression by conducting a set of gene-specific t-tests and then assigning a score to each gene relative to the standard deviation of those tests. genes are characterized as significant if their score is greater than an adjustable threshold . sam employs permutations of the repeated measurements in order to estimate the false discovery rate  i.e. the percentage of genes identified by chance. through the threshold adjustment, we may conclude to smaller or larger sets of genes  <cit> .

the empirical bayes moderated t-statistic  ranks genes by testing whether all pairwise contrasts between different outcome-classes are zero. it is applied to extract information across genes thus making the final analyses more stable even for experiments with limited number of arrays. moderated t-statistics lead to p-values with increased degrees of freedom for the individual variances hence, reflecting the greater reliability associated with the smoothed standard errors  <cit> . linear models for microarray data  is a package, which incorporates this statistic  <cit> .

correlation-adjusted t’-scores  is the product of the square root of the inverse correlation matrix with a vector of t scores and represents the individual contribution of each single feature  to separate two groups after removing the effect of all other features. this method takes account of correlations among genes before adjusting the t-statistics. in the absence of correlation the cat score reduces to the standard t-score. the cat score offers a simple approach to feature selection, both of individual genes and sets of genes  <cit> .

apart from these standard methods, we wanted to explore whether the use of a feature selection method over the top  <dig> list will benefit the prediction or not. therefore, we decided to select randomly gene probes from the ranked list and then assess its classification performance. in order to control the randomness and finally conclude to a stable outcome we created randomly  <dig> subsets of  <dig> gene probes, run the classification process and finally summarized the results. thus, the random  scores refer to these mean values per disease.

RESULTS
overview
following the development of map-kl we designed and executed an elaborate set of analytical experiments with 5-cv on the training set and hold-out validation on a separate set to assess its performance across whole genome expression datasets from both small and large patient cohorts. in relation to small cohorts, we employed data from  <dig> neuromuscular diseases, while for large cohorts we utilized data from  <dig> different types of cancer. on those microarray datasets, we also applied  <dig> other feature selection/elimination approaches and compared the classification results .


hykgene
 <dig> 
maxt
 <dig> 
snr
 <dig> 
rnd
 <dig> 
pca
 <dig> 
bga-coa
 <dig> 
maxt
 <dig> 
rnd
 <dig> 
t-test
 <dig> 
odp
 <dig> 
map-kl
 <dig> 
sam
 <dig> 
ebayes
 <dig> 
cat
 <dig> 
pca
 <dig> 
t-test
 <dig> 
hykgene
 <dig> 
maxt 
 <dig> 
cat
 <dig> 
map-kl
 <dig> 
pca
 <dig> 
bga-coa
 <dig> 
pls-cv
 <dig> 
maxt
 <dig> 
odp
 <dig> 
rf-mda
 <dig> 
ebayes
-
we further assessed the map-kl’s performance towards other feature selection and/or classification studies, conducted on the same cancer datasets. finally, we engaged two different simulation setups with known structures and investigated map-kl’s behaviour.

neuromuscular diseases data
the use of small cohorts in biomedical research is common in some types of studies such as those of rare diseases. these small cohorts make feature selection algorithms prone to overfitting and thus less reliable  <cit>  compared to larger cohorts. it was therefore intriguing to explore the robustness and generalization of map-kl on train sets with length ranging from  <dig> to  <dig> samples and test sets with  <dig> to  <dig> samples respectively .

the majority of the methods in als and dmd validation achieved the highest classification score  except for the hykgene in als and the pca in dmd with auc scores of  <dig>  and  <dig>  respectively. similarly, in 5-cv test, only the bga-coa and the pca with auc scores of  <dig>  and  <dig>  respectively, deviated from the rule. in jdm although all of the methods achieved the highest auc score  during hold-out validation, the respective tnr score was  <dig>  for the bga-coa, ebayes, odp, snr and cat methods. in 5-cv the pca was the only method that failed to distinguish correctly all samples .

in relation to the lgmd2a, ten methods, including the maxt , achieved the highest auc value, though only bga-coa, map-kl and maxt  achieved the highest tnr and tpr, too. the tnr score for pls-cv was  <dig> , for rf-mda, odp and snr was  <dig> , while for hykgene was  <dig>  and for ebayes  <dig> . it is worth noticing that the tnr score of the maxt with the  <dig> genes subset, was considerably lower to that of maxt . during the 5-cv evaluation, the classification results are almost ideal, since only pca had an auc score less than  <dig> .

contrary to the previous datasets, in lgmd2b validation, only three of the methods  and pls-cv) achieved the highest auc  but their tnr score was  <dig> ,  <dig>  and  <dig>  respectively. although many methods distinguish all disease samples correctly i.e. tpr =  <dig> , all of them failed to discern all normal samples i.e. tnr <  <dig> . approximately half of the methods had a tnr below  <dig>   and no method had tnr greater than  <dig> . on the other hand, the 5-cv classification results were very promising since all methods but pca achieved the highest score i.e.  <dig>  in all three metrics.

likewise in nm validation, all of the methods faced considerable difficulties in distinguishing disease and normal samples. only the snr, the t-test and the hykgene methods managed to reach an auc score close to  <dig> . the tpr results for nm as opposed to those for lgmd2b were discouraging, since only four methods  classify all the disease samples correctly, and the tpr score for the rest of the methods range from  <dig>  to  <dig> , with the exception of t-test and hykgene . in contrast, in 5-cv ten methods achieved auc score of  <dig> , though only map-kl, maxt, maxt , rf-mda, and snr achieved the optimum score in tnr and tpr metrics. the pls-cv and bga-coa had the same tnr score  but different tpr  and auc . the pca method achieved the lowest auc score  with tnr and tpr scores equal to  <dig>  and  <dig> . finally, the ebayes method failed to produce a list of significant genes.

cancer data
as far as the large patient cohorts is concerned, we utilized microarray data from four different types of cancer , with train sets length ranging from  <dig> to  <dig> samples and test sets from  <dig> to  <dig> .

in breast cancer ho validation, map-kl attained the optimum score  in tnr metric and the best auc score . two methods, pls-cv and rf-mda, achieved competitive tnr and auc scores of  <dig>  and  <dig>  respectively. however, all methods faced difficulties to distinguish the non-responsive samples, and except the maxt  with a tpr score of  <dig> , followed by the rnd technique  and the rf-mda, the hykgene and the sam methods . during the 5-cv validation, pls-cv, rf-mda, hykgene and cat had an auc score of  <dig> , which was also the highest score attained. the rest of the methods achieved auc scores between  <dig>  and  <dig> , but only sam had a balance performance between tnr and tpr metrics. it is worth noticing that the tpr results for all methods were below the tnr results. the ebayes method failed to fulfil the analysis task.

in relation to colon cancer, map-kl presented similar classification behaviour to breast cancer, with an auc score of  <dig>  and a more balanced behaviour between tnr and tpr . only the bga-coa method achieved a competitive auc score of  <dig> . the auc score for the rest of the methods lay between  <dig>  and  <dig> . contrary to breast cancer, the tpr scores were higher than the tnr scores and range from  <dig>  to  <dig>  for all methods. regarding the tnr metric, all methods but rnd  and pca  and cat  achieved the same score of  <dig> . the classification results in 5-cv are very promising with auc values from  <dig>  to  <dig>  for all of the methods except pca, which attained an auc score of  <dig> .

concerning the leukemia datasets,  <dig> of the methods  and maxt) performed similarly in both validation tests. their auc were close to  <dig>  in both cases, and the tnr results were better than the tpr scores. the map-kl, although achieving high classification scores in 5-cv, failed to predict correctly all aml samples , and as a results its overall performance was  <dig>  during the hold-out validation. the pca, snr and t-test methods failed to predict any of the  <dig> aml samples, although they identified all or almost all of the all samples. the odp algorithm failed to analyse the colon dataset.

finally, in prostate cancer, no method succeeded in discriminating the samples in both types of validation, alike to nm in neuromuscular diseases section. even more importantly, during the hold-out validation, many of the methods , maxt, pca, snr and t-test) failed to identify even a single sample from the normal class. only the hykgene excelled in this metric with a tnr score equal to  <dig> . however, because of the normal: disease ratio , the auc values of ebayes  and sam  are a little deceptive. on the other hand, pls-cv and map-kl appear to have an opposite behaviour in relation to tnr and tpr metrics, but the normal: disease ratio tips the scales in favour of pls-cv . two algorithms, odp and cat, could not deal with the prostate data.

analysis of previous experiments
at a different level of assessment, we compared the map-kl’s classification results of the specific cancer datasets, against those published in previous classification studies of the same data. for the purposes of this comparison, we have cited the author’s name, the classification type, the number of the features used, and finally the achieved accuracy . since we utilized three different classifiers to build and test map-kl’s models, in this comparison we present all three results achieved.

in relation to the van ’t veer et al.  <cit>  breast cancer datasets, we present the classification results from  <dig> different approaches stemming from  <dig> studies, see table  <dig>  regarding the cv test, hassan et.al  <cit>  and hu et al.  <cit>  achieved acc above  <dig> %, higher than van ’t veer et al. and with less features. however, they utilized all of the samples contrary to van ’t veer et al. our method achieved moderate results  as absolute numbers for the  <dig> samples but with only  <dig> features and 5-cv contrary to loo-cv that engaged by the others. in the hold-out test, although the acc of map-kl is the lowest score, we did manage to identify correctly all responsive samples. however, we should consider why we discern only half of the non-responsive samples .


fourteen methods employed the alon et al.  <cit>  colon cancer datasets to assess their classification performance, see table  <dig>  during the cv assessment we achieved acc =  <dig> % with rf and knn classifiers higher than the one achieved by tan and gilbert  <cit>  . regarding the hold-out validation, li et al.  <cit> , nguyen and rocke  <cit>  and furey et al.  <cit>  achieved acc of  <dig> %,  <dig> % and  <dig> % respectively. we reached to  <dig> % and  <dig> % acc with  <dig> genes contrary to nguyen and rocke with  <dig> genes.


the all/aml discrimination in the leukemia datasets, table  <dig>  as first presented by golub et al.  <cit> , is the one most often analyzed among the datasets considered. more than  <dig> studies and  <dig> methods have based their evaluation on this set of data. comparing map-kl to golub classification results, we notice that in cv we identify one more sample, whereas in hold-out we misclassify two samples from golub, though we did that with only  <dig> genes. there are many methods that distinguish correctly all samples in cv although only hewett and kijsanayothin  <cit>  achieved an acc of  <dig> % with only two genes, but using all of the  <dig> samples. regarding the hold-out validation, several methods achieved high classification scores with acc above  <dig> %, though only mukherjee et al.  <cit>  reached the 100%, with only  <dig> genes. liu et al.  <cit>  predict correctly all samples in both validation assessments, but we are unaware of the subset’s length. finally, singh et al.  <cit>  first employed the specific prostate cancer datasets and we have included the results from three studies, table  <dig>  map-kl with the aid of svm-linear classifier, misclassified one sample in hold-out validation just like liu et al.  <cit> . however, in cv we misclassified approximately eight samples more than liu et al., but with only  <dig> genes.


biological relevance of discriminatory gene lists
the power of the proposed fs approach is evident not only from its performance in the statistical metrics, but also from the biological relevance of the selected genes either to a broad range of different molecular pathways and biological processes or more importantly to the respective pathological phenotypes. representative examples include the genes col3a <dig>  sparc and pttg1ip, which are related to extracellular matrix formation and fibroblast growth, biological processes consistent with the increased fibrosis that is observed in skeletal muscles affected by dmd  <cit> . in als the selected genes fhl <dig> and aldoa have been directly implicated in muscle function and pathology  <cit>  while the multiple genes implicated in the translational process support previous reports on an als mouse model  <cit> . in nm and lgmd2b, the structure associated myh <dig>  myh <dig> and pfn <dig> genes were depicted, in agreement with the reports of cytoskeletal disorganization in the affected muscle fibers of these patients  <cit> . as opposed to the other skeletal muscle diseases included in this study, jdm is an inflammatory myopathy of presumed autoimmune dysfunction. consistently with the disease pathology, multiple short-listed genes  are related to interferon or to chemokine and cytokine production, all key molecules of the immune system  <cit> .

these findings jointly, demonstrate that despite their small size, the discriminatory ‘lists of selected genes’  depicted by the proposed fs approach contain biologically relevant genes, representative of the respective disease related molecular pathways.

simulation studies
i. the clusters setup
we applied the map-kl on training sets of  <dig> samples with  <dig>  ‘genes’ and diverse number of degs. moreover, for each training set we differentiated the number of the top ranked genes kept for clustering . the purpose of this case study was twofold. on the one hand, we wanted to investigate how many degs are included in our final subset along with their cluster origin. furthermore, we explored the influence on the degs’ selection when varying the number of top ranked genes. we also employed three other fs methods, , keeping either the top  <dig> ranked ‘genes’  or the top  <dig> ranked ‘genes’  trying to keep their length comparable with the subset’s length of map-kl.


as far as the identification of degs belonging to different clusters is concerned, the map-kl managed to compose subsets with at least one representative ‘gene’ from each cluster. besides, as shown in table  <dig>  in almost all cases the maximum subsets’ length does not exceed the actual number of clusters in the training set. in relation to the other fs methods, only the rf-mda method composed subsets of ‘genes’ with satisfactory representation of the actual clusters and comparable to map-kl. the ebayes and maxt methods demonstrated poor enrichment.

with respect to the effect of the number of top ranked ‘genes’ kept for clustering, it is evident that the closer to the real number of degs, the better the identification and selection of representative genes. specifically, in cases where the number of degs is considerably lower than the number of n top ranked genes  the identified clusters are less than the actual. similarly, when the number of degs far exceeds the number of n top ranked genes the identified clusters are fewer, for instance  <dig> degs with  <dig> top ranked genes parameter. nonetheless, during the real gene expression data experiment, we employed a moderate value for the parameter n =  <dig> top ranked genes.

as a final point, we formed the respective train-test sets for all methods and evaluated their performance with the aid of three classifiers . all methods performed accurately  for all three classifiers, see additional file  <dig> 

ii. the ‘choedata’ setup
in this setup, we were interested in exploring, the length of the map-kl’s subset in relation to the known degs included in it. therefore, we applied on the ‘choedata’ the map-kl, engaging a non-parametric and a parametric statistical methods table  <dig>  we observed that the parametric welch-t test, led us to a subset of  <dig> genes with  <dig> degs included, whereas the non-parametric wilcoxon’s test, concluded to a subset of  <dig> genes with only  <dig> degs.


we then formed classification models with the assistance of three classifiers  and assessed their performance. despite this remarkable difference in the number of degs included in the two subsets, the classification results were accurate in both cases. nonetheless, including more degs in a classifier is of benefit to the biological analysis if not to the classification process itself.

CONCLUSIONS
the proposed hybrid fs method , demonstrates how effective the combination of a multiple hypothesis testing approach with a clustering algorithm can be to select small yet informative subsets of genes in binary classification problems. across a variety of diseases and number of samples, map-kl presents competitive classification results , compared to other fs methods and specifically to the hykgene method, which follows a similar philosophy, first ranking and then clustering. however, we discern an unbalanced behaviour between the tnr and tpr metrics. in particular, the map-kl outperforms the other fs methods regarding the control of the type i error but underperforms with regard to the type ii error. this issue is under ongoing investigation so as to further improve the efficiency of our method.


apart from the classification performance, its data-driven and classifier independent features characterize map-kl. indeed, the engagement of a cluster quality index diminishes any fuzziness and provides the clustering algorithm with a representative number of potential clusters, as clearly presented in the first simulation data setup. hence, the data determine the size of the subset and the clustering algorithm decides on which informative genes are to be included. since no classifier takes part during the subset construction, our subsets perform efficiently across several classification algorithms, for instance svm-linear, knn and rf. a further advantage of the employment of map-kl is that the clustering correlation on the gene expression values may reflect biological relevance of the selected genes with the respective disease, thus providing a reasonable basis for discovering prognostic biomarkers  <cit> .

finally, we would like to highlight some points of interest in relation to ranked gene lists, which retrospectively confirm our initial motivation towards the map-kl’s implementation. in particular, a subset of  <dig> or more top ranked genes, may lead to accurate classification as demonstrated by the results of maxt , which achieved outstanding classification results with auc =  <dig>  in neuromuscular diseases and auc =  <dig>  in cancers, but such a lengthy subset may contain a number of irrelevant genes that will act as “noise” when performing further biological analysis. on the other hand, keeping a subset of top n genes, where n =  <dig> ,…n, needs several rounds of “trial and error” attempts before concluding to the best n value. otherwise setting the n parameter arbitrarily does not guarantee robust and efficient classification results, as shown in the case of the  <dig> genes subset of the maxt. additionally, forming subsets by selecting genes randomly from an already ranked list may lead to satisfactory classification results. the rnd technique achieved comparable classification results to maxt either with  <dig> or  <dig> genes subset. however, the subsets are not reproducible and no biological evidence can be inferred for them. taking into account all the aforementioned issues, we claim that the novelty and strength of map-kl is the efficient sampling of the ranked gene list, selecting those genes that are necessary for improved classification, rather than keeping just a predefined number of top n ranked genes.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
as, ds and gs conceived this project. as carried out all the experiments and the analysis as principal investigator. ds carried out the biological relevance analysis and wrote the relevant section. as wrote the rest of the paper. gs supervised this project. all authors read and approved the final manuscript.

supplementary material
additional file 1
this function implements in r-code, the map-kl’s functionality.

click here for file

 additional file 2
in this file, we present the 5-cv classification results for all real microarray data, when using three different classifiers .

click here for file

 additional file 3
in this file, we present the hold-out validation results for all real microarray data, when using three different classifiers .

click here for file

 additional file 4
in this file, we have cited the subsets of genes according to the map-kl method.

click here for file

 additional file 5
contains the microarray data used in this experiment. for each disease, we provide the ‘class_labels.csv’, ‘train.csv’ and ‘test.csv’ files, which represent the analogy of samples as described in table  <dig>  the intensity values are unprocessed.

click here for file

 additional file 6
in this file, we have cited the clustering setup parameters, the degs position per simulation dataset, as well as the degs identified per method.

click here for file

 additional file 7
in this file, we present the classification results of  in the first simulation setup, where the clustering identification was under investigation. we employed three classifiers .

click here for file

 additional file 8
in this file, we present the classification results in the ‘choedata’ when using two different map-kl’s subsets, stemming from two different ranking approaches. we used the svm-linear, knn, and rf classifiers to assess their performance.

click here for file

 additional file 9
this file contains the relevant scripts and functions for generating the simulated data. the ‘clustersim’ r-package is required.

click here for file

 acknowledgements
despina sanoudou is supported by the european community’s seventh framework programme fp7/2007– <dig> under grant agreement no. health-f2-2009- <dig>  eutrigtreat.
