BACKGROUND
with the availability of genome-wide mrna expression data from dna microarray experiments, transcriptional regulatory network inference  from large compendia of these microarrays has become a fundamental task in computational systems biology. in this approach, transcription factor -gene interactions are predicted based on observed trends in mrna expression across many experimental conditions. unsupervised pairwise methods for trni, including relevance networks  <cit> , partial correlation methods  <cit> , graphical gaussian models   <cit> , and context likelihood of relatedness   <cit> , are attractive as they do not require prior knowledge of the network and have been successfully applied at the genome-wide scale, performing well relative to other unsupervised methods  <cit> .

while many of these approaches have relied on user-defined or truth set-based thresholds for determining the network, the correlation- and partial correlation-based methods can in principle calibrate established tests to a desired level of prediction accuracy via control of the false discovery rate  alone. however, such tests nominally assume independent and identically distributed  microarray experiments. work in differential gene expression analysis has demonstrated the necessity in such testing procedures of accounting for the correlation and consequent dependency inherent in microarray data, e.g.,  <cit> . potential sources of dependence between microarray experiments include biases in microarray preparation and lab-specific environmental factors , and are particularly pertinent in compendia comprised of data from multiple labs. moreover, recent work shows that the very gene-gene correlations in question in trni can even induce an effective dependency among seemingly homogeneous and independent sets of experiments . thus, we expect such effective dependency  between microarray experiments, given that our approach to trni is based on the expectation of meaningful gene-gene correlations across the dataset. such  dependency invalidates the assumption of i.i.d. experiments upon which the statistical tests are based, thereby complicating the calibration of these tests.

to the best of our knowledge, the phenomenon of dependency in microarray compendia and its implications for trni has been noted and addressed only indirectly in the literature to date. in particular, it is known that the actual null hypothesis model in trni methods based on statistical testing typically will not conform to the nominal null model , and that dependency is a possible culprit  <cit> . furthermore, methods have been proposed to adaptively infer the form of that model from the data using, for example, principles of empirical null modeling . however, such methods do not facilitate quantification and exploration of the nature of this dependency in and of itself.

here in this paper, we sought to explicitly quantify and characterize dependency, in the context of an escherichia coli microarray compendium, containing both mrna expression data and substantial information on experimental conditions. then, utilizing the large set of known tf-gene interactions in e. coli from regulondb  <cit>  to evaluate performance, we explored the implications of such dependency in trni using the correlation relevance networks method  <cit> . in doing so, we propose a new method of trni, which is simple but effective. on a broader scale, our contributions are aimed at lending a more quantitative structure to the discussion of optimal construction of mrna expression compendia for trni.

throughout this paper, as above, we refer to both "effective dependency" and "dependency". in seminal work  <cit> , efron has shown both empirically and theoretically that it is possible for microarrays to be statistically independent and yet, due to the very gene-gene correlations that are of interest in trni, these same arrays are effectively dependent, in the sense that empirical correlations among experiments can be inflated. efron's focus in  <cit>  was on the implications of this effective dependency on statistical tests for independence of a set of microarray experiments from a single project/lab in the context of differential expression analysis. he introduces an expression for the effective number of genes  that plays a key role in that work. in contrast, we focus here on the implications of dependency  on the task of trni, based on a compendium of microarray experiments, and introduce the natural complementary notion of the effective number of experiments .

realistically, both types of dependency  need to be dealt with in analyzing microarray compendia. the effective dependency is a given considering our expectation of gene-gene correlations, whether the experiments in the compendia are dependent or not  <cit> . but in fact, in addition, it is natural to expect that there also be actual dependence among experiments, whether due, say, to biases introduced by sample collection and/or microarray preparation, or to environmental variables that can vary between different laboratories or even projects within laboratories. separation of effects of true dependency from those of effective dependency is complicated  and is not our goal here. rather, we aim only to accurately quantify the aggregate effects and, where necessary, adjust for them appropriately in trni analysis.

for the work detailed below, we utilized the affymetrix e. coli compendium available on m3d, with mrna expression data and corresponding experimental condition metadata for n =  <dig> experiments and p =  <dig> "genes"  . this compendium is comprised of many sets of related experiments. here, we define a "project" as a set of microarray experiments conducted under the same principle investigator towards investigation of related questions. in the majority of cases, a publication defined a project, but in some instances microarrays from multiple publications were combined to form one project.

applying a test proposed in  <cit> , the null hypothesis of i.i.d. experiments in the e. coli compendium was rejected, with visually evident structure based on project membership. upon regrouping the data, we observed that experimental condition factors were a significant driving force behind the observed structure. we found that the vast majority of significantly correlated pairs of experiments were between experiments in the same project.

we explored the implications of this dependency between experiments in trni. this exploration was enabled by a summarization of the dependency in the form of an estimate of the effective number of experiments, neff. a greedy search for microarray experiments that maximized neff revealed that a larger neff was achieved with a subset of the compendium, with the peak neff attained using less than one third of the experiments. this surprising result suggested that subsets of the data might effectively contain more information than the full compendium. we used correlation as our measure of gene-gene interaction for trni , and were able to evaluate performance in trni using the large set of known regulatory interactions in e. coli from regulondb  <cit> . consistent with the observed peak in neff , we found that subsets of the compendium also performed better than the full compendium in trni. again, detailed examination of the data suggested that experimental conditions were a driving force behind the observed changes in neff and trni performance.

we then used neff to adjust p-values in tests for statistically significant edges and demonstrated that fdr levels using these values were within range of empirical fdr levels , while this was not the case when the actual number of experiments was used. accurate computation of fdr levels for trni enables reliable predictions even when a truth set like regulondb is not available. we found that our trni method produced networks similar to those derived from regulondb-based thresholds. using recent experimental findings, we confirmed the inferred topology of known tf lrp, and examined that of a predicted hub in our network, putative tf yrba.

RESULTS
structure and dependence in a compendium of microarrays
we first performed permutation tests following methods in  <cit>  to determine whether experiments in the e. coli affymetrix microarray compendium were i.i.d. if the microarray experiments were indeed i.i.d., we would expect the components of the first eigenvector of the experiment correlation matrix, v <dig>  to be random with respect to the experiment order. we plotted v <dig> against the experiment index with experiments grouped by project . structure across these values was visually evident: in many cases, they were grouped by project. results from permutation tests using a block statistic , with blocks defined on projects, strongly suggested the existence of structure within the data set, with p-value =  <dig> for  <dig> permutations.

in order to look at factors beyond project membership that may be contributing to the observed structure, we utilized the experimental condition data in m3d. we define an experimental condition factor as any detail about each microarray experiment that is part of the curated metadata on m3d; this includes any experiment variable that was reported for a microarray experiment in its associated publication, e.g., growth phase, strain, temperature, ph, culture type, etc. assigning each experiment the v <dig> value corresponding to its index in the original order , we re-sorted the experiments according to a given experimental condition factor. for example, experiments in which glucose was present in the media were grouped together, and all those without glucose formed a separate group. results for five experimental condition factors are shown in figure  <dig>  indeed, we observed structure in each of these five cases across experiments from different projects, and two-sample t-tests in each case were rejected with p-values <1e- <dig>  note that in these tests, the antibiotic and ccdb toxin experiments  were grouped together, as ccdb is known to have a similar mechanism of action. similarly, experiments with cells in late-log, stationary, or biofilm growth phase  were grouped and compared to all other experiments . multi-way anova analysis  of the effect of these five experimental condition factors on their corresponding v <dig> values revealed that three of the condition factors  vs. late stage growth phase) were likely influencing these values, while the structure observed for the other two condition factors  could likely be explained by the other factors. these results strongly indicate that the observed structure is biologically driven by experimental condition factors. from this perspective, with observation of structure due to individual condition factors, it is not surprising that we observe structure consistently at the project level , as the effects of these condition factors are undoubtedly confounded with project membership.

correlated experiments
given the structure observed in the data set above, it was reasonable to ask which experiments in the compendium were significantly correlated. we assessed this following  <cit>  using experiment-experiment correlation. this is not straightforward in the presence of dependency, and accordingly, the author in  <cit>  used an estimate of the effective number of genes peff  in testing for significantly correlated experiments. we found that peff =  <dig>  for this compendium, a drastic reduction compared to the number of genes p =  <dig>  following  <cit> , we used peff as the sample size to calculate p-values in testing for correlation between experiments using fisher transformed correlation coefficients . using the benjamini and hochberg fdr procedure   <cit>  , we applied an fdr threshold q =  <dig>  to these p-values and identified  <dig> pairs of significantly correlated experiments , constituting 2% of all possible pairs. consistent with the trend observed in figure  <dig>  it is clear that a majority of these were pairs of experiments from the same project . we note that using the number of genes p =  <dig> as the sample size in these tests resulted in 91% of all pairs significantly correlated at q =  <dig>  , a rather dubious value.

it is not surprising that the majority of correlated experiment pairs were from the same project. many factors could contribute to such correlation, including similarity of experiments within the same project , biases introduced by sample collection and/or microarray preparation, and environmental variables that can vary between different laboratories . we quantified the correlated-ness of projects as the fraction of correlated pairs  in each project. considering only projects with more than three experiments, we observed that five of the six projects with the largest fcp  were predominantly comprised of genetic perturbation experiments, demonstrating that this type of perturbation yields generally less diverse expression profiles.

there were also several cases in which experiments from different projects were correlated. a full list and description of significant between-project correlations is included in additional file  <dig>  supplementary table s <dig>  in some instances, these correlations would be expected due to similarity of experimental conditions, as was the case for the pairs in the green boxes . however, pairs in the white boxes were not necessarily expected. in box , we see several correlations between experiments in projects  <dig> and  <dig>  indicating that the high cell density  late log conditions in project  <dig> have similar expression profiles to several biofilm conditions in project  <dig>  in box , treatment with the antibiotic spectinomycin in project  <dig> correlated with serine hydroxamate treatment in a rela knockout in project  <dig>  this indicates that serine hydroxamate treatment  in cells unable to undergo canonical stringent response  induces a similar transcriptional response to treatment with spectinomycin, an antibiotic known to act on the ribosome and inhibit protein synthesis. finally, we observed that many experiments in which cells were sampled in the late-log, stationary, and biofilm growth phases tended to correlate with one another irrespective of other factors, including whether cells were grown in rich or minimal media, suggesting that these low-to-no growth state cells share similar expression patterns that don't vary significantly with perturbation. this is consistent with the clear separation of values corresponding to these later stages of growth  observed in figure  <dig>  bottom panel.

figures  <dig>   <dig>  and  <dig> provide stark visual evidence of the dependency among experiments within the compendium. this type of analysis can be used to guide experiment design by identifying conditions that correlate across different projects , and also highlighting projects with minimally correlated experiments . furthermore, unexpected correlations between well-studied and less well-studied experimental conditions can be used to gain insight into mechanisms of the resulting cellular response.

effective sample size and choice of experiments
we expected that the dependency between experiments would lead to an effective reduction in the number of experiments, just as  <cit>  found that dependency between genes led to an effective reduction in the number of genes. here, we were more naturally interested in the effective number of experiments, both as a potential measure of relative "usefulness" of experiments in the compendium, and also as it is relevant in testing for significant correlation between genes . accordingly, we defined an expression for the effective number of experiments, neff , analogous to that of peff in  <cit> . we found that neff was equal to peff , as can be predicted by theorem  <dig> in  <cit>  , indicating that this quantity is essentially representative of a certain notion of reduced dimensionality for the entire data matrix.

given the varying degrees of correlation between experiments observed above, we expected some experiments to be more informative than others. while it is challenging to address the broad issue of choice of experiments in its full generality, we propose here to use neff as a metric of relative usefulness of experiments. we conducted a greedy search for combinations of experiments yielding maximum neff . experiments in the compendium were added one at a time until all experiments were included, at each step adding that experiment which maximized neff . interestingly, we saw a peak of neff =  <dig>  using  <dig> experiments, and a decrease in neff as the remaining experiments were added  . as might be expected given the project-based structure observed in figures  <dig> and  <dig>  the subset of  <dig> experiments at the peak of this curve included experiments from nearly all projects in the compendium .

the peak in the neff curve indicates that adding experiments can decrease neff . while at first glance this result may seem counter-intuitive, it is simple to construct a small-scale example to illustrate this phenomenon. consider the case where our samples take the form of three scalar values x <dig>  x <dig>  and x <dig>  let corrij be the correlation between samples i and j. if corr <dig> =  <dig> , and corr <dig> = corr <dig> =  <dig> , we find that neff =  <dig>  when only samples  <dig> and  <dig> are included, but neff =  <dig>  when all three samples are included. thus, adding a third experiment with a strong enough correlation to both of the first two experiments effectively reduces the sample size. this is a toy illustration of the well-recognized role that latent variables can have in correlation-based analyses, wherein a subset of more fundamental variables can actually drive what appears to be more complex behavior among an ostensibly larger number of variables ; sample  <dig> in this example clearly "drives" much of what is in samples  <dig> and  <dig>  the same phenomenon is occurring in the microarray compendium, but at a much larger  scale.

we also evaluated neff for subsets in which projects were omitted from the data set, one at a time; i.e for each project, we removed only that project from the full compendium, computed neff , and looked at the change in neff of the subset relative to neff when all data were included. similarly, we quantified the correlated-ness of each project as the fraction of correlated pairs  in that project . in figure  <dig>  we looked at fcp vs. change in neff for all projects and found that projects with highly correlated experiments  generally contributed less to or even decreased overall effective sample size. omission of high fcp projects  <dig>   <dig>  and  <dig> actually increased effective sample size; notably, all three of these projects were predominantly comprised of genetic perturbation experiments, indicating that this type of perturbation is prone to contributing redundant information to the data set.

implications for transcriptional regulatory network inference 
we applied the concepts presented above 1) to evaluate contributions of subsets of experiments to trni accuracy and 2) for edge selection in trni. we used the set of known regulatory interactions in regulondb  <cit>  to evaluate performance in trni. we focused on trni using correlation as our measure of interaction between two genes for two principal reasons. first, statistical testing of correlations is straightforward and well-established, in the standard case of i.i.d. measurements, with formulas for calibration of tests involving the sample size n in a straightforward fashion. this latter aspect in turn allows us to propose a rather simple and straightforward adjustment of the tests as applied for edge selection in trni, substituting the estimated neff for n in the standard formula to account for dependencies in the data set. while analogous standard statistical tests exist for partial correlation, this method requires specification of the set of regressors; this can be nontrivial, with performance in trni substantially affected by the choice.  second, we found that correlation performed similarly to partial correlation algorithms  <cit>  and the mutual information-based context likelihood of relatedness  algorithm  <cit>  for this affymetrix e. coli compendium . we observed that correlation performed as well or better than the other methods at higher precision , which is arguably of most interest given the goal of identifying highly probable edges. we emphasize that we do not adopt a correlation-based method because it is better, but rather because it i) performs similarly to arguably more sophisticated unsupervised pairwise inference methods , and ii) at the same time, is more amenable to our study of n and neff .

performance of subsets of the compendium in trni
motivated by the observed peak in neff using a subset of the compendium, we looked at the performance of subsets of the compendium in trni. subsets were selected  randomly,  based on the neff greedy search, or  via clustering as in  <cit>  . performance was measured as auc <dig>  the area under that part of the regulondb-based precision vs. sensitivity curve  above 10% precision.  the results for subsets including  <dig> to  <dig> experiments are shown in figure  <dig> 

we found that subsets selected to maximize neff uniformly outperformed randomly selected subsets and, for sufficiently many experiments , outperformed the full compendium. we also observed that subsets selected to maximize neff generally included experiments from more projects than random subsets at a given subset size . performance using subsets selected via clustering was found to be the best, uniformly outperforming both random and neff selected subsets for most sample sizes , and outperforming the compendium with substantially fewer experiments  than neff selected subsets. this improvement is to be expected, as clustering is making more sophisticated use of the information in the data than neff , with the former considering the distance  between all experiments simultaneously, and the latter considering only one experiment at a time and always searching for the experiment most distant from the subset already selected. regardless, we believe these findings support the merit of neff as a quantity relevant to the relative performance of subsets of experiments in trni. the improved performance using cluster-based subset selection is intriguing and may merit further study, but is beyond the scope of this work. however, we also note that when this comparison was conducted using alternative e. coli compendia, the outcome was more nuanced, with the neff -based and cluster-based subset selection methods each outperforming the other over certain separate ranges of subset size .

we also evaluated per-project change in neff  and trni performance; i.e for each project, we removed only that project from the full compendium, computed neff and auc <dig> in trni, and looked at the changes of these measures relative to their values when all data were included. we found that changes in neff roughly trended with changes in auc <dig> , indicating that projects positively contributing to overall neff were also some of the most informative projects in overall performance in trni. notably, project  <dig> contributed the most positively to trni accuracy; this is the largest project in the compendium, and includes time-series experiments with antibiotic and toxin treatments, all conducted in rich media. we found that two of the three projects that decreased overall neff also decreased trni accuracy , while project  <dig> contributed positively to trni performance. this could be attributed to the fact that project  <dig> is relatively large , or possibly because the specific perturbations in this project  are pertinent to regions of the transcriptional regulatory network that are 1) well-sampled in this compendium  and/or 2) better represented in regulondb.

we repeated the same analysis on a per-experiment basis, where experiments were omitted one at a time from the data set and neff and auc <dig> were computed. we observed a moderate trend between per-experiment change in auc <dig> with change in neff . this trend was stronger among experiments with positive change in neff, i.e. less informative experiments. the weaker trend with auc <dig> for experiments that were informative to neff could reflect the fact that auc <dig> is a measure of performance in a specific task , and it is possible that certain experiments are informative generally but not necessarily informative in the specific task of trni . we also observed that all but one of the  <dig> experiments in project  <dig> fell in the upper right quadrant of this plot, in contrast to the overall positive per-project contribution to auc <dig> observed for this project in figure 8a, demonstrating that, while all of these experiments might be similar to one another , removing the entire project from the data set is detrimental.

in order to investigate whether specific experimental condition factors were more or less informative in these measures, we replotted figure 8b coloring points based on their state in each of the five condition factor attributes considered in figure  <dig> . we then tested whether there was a relationship between the distribution of points and each binary condition factor  by binning points into four bins based on overall auc <dig> and neff values  and performing a chi-square test for independence . plots for the two condition factors with the smallest p-values in this test are presented here: growth phase stage  and media type  . it is evident that experiments with early stage growth phase labels  were generally more informative than those in the later stage growth phases  . additionally, in figure 8d we see that experiments conducted in minimal media were generally informative, though rich media experiments were not necessarily less informative .

edge selection for correlation-based trni using fdr
in e.coli, it is possible to evaluate trni performance and guide desired edge selection thresholds using regulondb, as we have done in our analysis above. however, in general, this is not the case; for most other species, it is necessary to select edges purely based on the data, without aid from a truth set. edge selection in this context is increasingly important as transcription profiling  experiments from species with no known regulatory interactions accumulate in initiatives such as the human microbiome project  <cit>  and the ten thousand microbial genomes project http://sz.genomics.org.cn/en/. controlling the fdr in multiple hypothesis testing can be used to guide this process for trni  <cit> . fdr estimates rely on correct computation of p-values, which, in the case of the fisher transformed correlation coefficients we use, depend on sample size n . thus, the effective reduction in sample size from n to neff has critical implications in testing for correlations between genes in trni.

we computed gene-gene correlation z-values using the full data set and calculated corresponding p-values using two choices of sample size: i) the nominal number of experiments n =  <dig>  and ii) the effective number of experiments neff =  <dig> , the latter of which adjusts for dependency among experiments .  for each set of p-values, we determined thresholds for desired fdr levels using bh-fdr , and at these same thresholds, computed an "empirical fdr" using regulondb. , but we've chosen to use "fdr" to simplify our discussion.) ideally, these two fdr values would be equal at each threshold, indicating that the nominal fdr levels accurately reflected the empirical fdr from the known truth set.  the results are shown in figure  <dig>  there it can be seen clearly that using the nominal number of experiments n to compute p-values led to drastically inaccurate thresholds, according to regulondb, while using neff yielded results within acceptable range of the ideal case . results in figure  <dig> were corroborated by histograms of the p-values for each case: p-values calculated using n were far from the expected uniform distribution, with a substantial majority of p-values near zero, while those using neff were much closer to uniform .

furthermore, and somewhat surprisingly, we observed that using values for n even slightly higher  or lower  than neff yielded noticeably worse results , providing further evidence that these effective sample size estimates are meaningful quantities. note, in particular, that a naive choice of sample size, such as the number of projects , while vastly less than the nominal sample size, would still do little better than the nominal sample size. overall, these findings support the use of bh-fdr for network edge selection when the effective sample size of the data set is taken into account. additionally, the successful application of neff in this setting substantiates the use of the equivalent peff for identification of correlated experiments in figure  <dig>  where there was no truth set available for comparison.

thus, in the combination of the correlation relevance networks approach and edge selection via fdr , we propose a simple and general method for trni . the association measure of our method  performed comparably to other methods tested herein, and our method has the distinct advantage of providing meaningful estimates of the precision of predictions.

the most significant impact of using the corrected p-values for fdr-based edge selection in trni is a drastic reduction in the size of the inferred network. for example, using bh-fdr without our correction and setting fdr ≤ 20%  leads to an overwhelming  <dig>  interactions for which the null hypothesis is rejected , while, in stark contrast, using our correction at this same precision yields a network of  <dig> edges. using regulondb-based empirical estimates of the true fdr, these networks correspond to 98% and 33% fdr, respectively, demonstrating that our correction yields a vast improvement. in additional file  <dig>  supplementary table s <dig>  we summarized comparisons between networks defined by controlling fdr using either n or neff or empirically estimating fdr using regulondb, with nominal or empirical fdr ≤ 20%, 40%, or 60%. additionally, we looked at the inferred connectivity for the well studied tf lrp to illustrate the validity of our approach at the gene level, using additional experimental data from  <cit>  to evaluate inferred edges . finally, we highlight a putative tf, yrba, that is predicted to be a large hub by our approach, and present evidence that it is involved in regulation of translation .

on a final note, we point out that fdr analysis above utilized bh-fdr to determine p-value thresholds. however, bh-fdr is just one of many approaches for controlling/estimating fdr . using the fdr evaluation framework afforded by regulondb for e. coli trni, we compared the performance of several fdr estimation methods available in the r package fdrtool <cit>  . we found that the performance offered by our simple approach, based on neff, is comparable to the best performance observed by other tools, and noticeably better than some. see the additional file  <dig> for details.

application of analysis to an additional data set
to gain further insight into concepts explored throughout this work, we compare and contrast our findings above to those obtained by applying the same analyses to an e. coli data set from zare et al.  <cit> . these data are complementary in certain useful ways to those in the m3d compendium, in that they are small , from a single lab , and range across an intentionally diverse set of experimental conditions . this choice of data, and our findings, allow us to provide additional insight into how neff may relate to the underlying biology in a data set.

the results of our analysis are presented in additional file  <dig>  section  <dig>  we observed that nearly all experiments in the compendium contributed positively to neff , and peak neff was very close to overall neff. this indicates that when a compendium is designed in a more controlled manner with a goal of surveying a broad and diverse range of conditions, there is accordingly less redundancy  across the data set, in contrast to the m3d compendium analyzed herein. congruous with this finding, we did not observe that subsets of the data consistently outperformed the full data set in the trni task. notably, however, bh-fdr control of neff -adjusted p-values for edges in correlation-based trni was not well-matched to empirical fdr estimates; we believe this is largely attributable to an overall lesser degree of informativeness of this compendium for correlation-based trni , and we discuss this further in the additional file  <dig>  finally, we conducted a comparison of our neff-maximizing selection of experiments to a measure of median gene set activity per experiment , which we argue can be expected intuitively to bear a reasonably strong correlation to each other, and found that this is indeed the case.

discussion and 
CONCLUSIONS
having more microarrays in trni is not necessarily better. how many you have, and which you have, matters. while these statements arguably have been part of the common wisdom in this area for some time, our work here attempts to formalize and quantify relevant aspects of the basic issue of which and how many microarrays to use in trni. we have demonstrated the presence of dependency among experiments within a compendium of e. coli microarrays, and found that this dependency can be well-characterized by a corresponding effective sample size, neff . we found that subsets of the compendium actually yielded larger neff than the full data set, and correspondingly, these subsets performed better in trni. finally, we proposed a straightforward method for trni that uses neff in an explicit fashion, which performed comparably to competing methods and produced meaningful estimates of the precision of predictions. we emphasize that the merit of neff derives from the totality of its role in this work, rather than from any single application. the fact that it can be seen to be usefully interwoven through various applications and quantitative summaries and analyses speaks strongly to its relevance.

a major result of the dependency in our compendium is a consequent sizable reduction of n to neff, which suggests significant redundancy across the data set. similar redundancy was observed in  <cit> , using cluster analysis methods. there are many possible causes of this redundancy, including: the structure of the compendium, comprised of individual projects that often vary only one or a few experimental variables while controlling all others; the robust nature of the underlying biological network, making it difficult to perturb the system; a modular trend in transcriptional responses, resulting in similar expression changes over a range of conditions; or limitations of the microarray technology. additionally, this result may indicate that the in vitro conditions that almost exclusively comprise this compendium only perturb a fraction of the transcipritonal regulatory network, promoting investigation of vastly different conditions, including in vivo and multi-organism cultures, as suggested in  <cit> . apart from promoting exploration of entirely new experimental space, the analysis herein provides insight into potential strategies for experimental design, highlighting conditions that vary minimally across the compendium  and sets of conditions  yielding diverse expression responses .

nonetheless, we note that while results presented in figures  <dig> and  <dig> are highly suggestive of a link between experiment-experiment correlations and experimental condition factors, additional work would need to be done to establish this more rigorously. for example, one could conduct a design-based study to test for and quantify the effects of experiment-experiment interactions. our work here is meant to lay the motivation for and suggest the need for additional work of this nature.

the trni approach proposed here follows a framework with some similarities to the ggm method proposed in  <cit> , which also employed fdr estimation for network selection , but used partial correlation instead of correlation. in our analysis, we found that this ggm method did not perform as well in trni on our data, and that corresponding fdr estimates deviated significantly from regulondb-based fdr estimates .

as a peripheral benefit, our work demonstrated the utility of the regulondb-based testing framework used in  <cit>  for evaluation of different methods of fdr estimation designed for high-dimensional data. nevertheless, while regulondb provides a useful framework for evaluation of trni performance and fdr estimation using experimental data, this is still not an ideal test setting. regulondb is incomplete; the test set used for the affymetrix e. coli compendium included interactions involving  <dig> genes, less than half of the 4000+ genes predicted in e. coli. this truth set also potentially includes incorrect interactions, as it is manually curated and derived from experiment-based conclusions. thus, these drawbacks should be considered when drawing conclusions from such evaluations, cautioning distinctions between methods that perform similarly. nonetheless, we believe that this testing framework is valuable, particularly given that generation of truly representative simulated data sets is challenging due to the multi-level nature of the underlying biological network. additionally, the accuracy of regulondb-based precision estimates in trni was supported by experimental validation carried out in  <cit> .

the trni approach highlighted here provides a simple but general method for predicting highly probable transcriptional regulatory interactions from large collections of microarray data. this generalized approach can be readily applied to less well-studied organisms for which large microarray compendia are available, such as p. aeruginosa  database  <cit> ), and s. oneidensis . additionally, as rna-seq and other improved methodologies become more widespread and begin to replace dna microarray experiments, observations from microarray compendia can serve as useful tools, including guidance in experimental design as noted above. also, it is highly likely that issues of dependency within novel-platform data sets will persist given the nature of the underlying biological network, so that considerations of such issues here will be applicable in this new context.

the work in this paper, taken as a whole, is aimed at the broader goal of providing a more quantitative framework for the discussion of the construction of microarray compendia for trni. we see the ultimate goal in this context to be the development of a complete, unified methodology for the design and use of compendia for trni - from choice of the experiments run, to assembly of the compendia, to the actual network inference.

