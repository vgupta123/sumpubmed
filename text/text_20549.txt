BACKGROUND
the ongoing gwas era has led to  <dig>  association findings for  <dig> complex traits by 6/ <dig>  <cit> . typically small effect sizes, however, leave a large fraction of disease susceptibility unexplained, a phenomenon that has become famous as “the case of the missing heritability”  <cit> . several potential explanations for the phenomenon were given, including over-estimation of the heritability, rare variants with larger effects, common variants with even smaller effects than observed so far, incomplete coverage of current gwas marker panels, but also epigenetic effects  <cit>  or interactions between genetic variants  <cit> . in order to address incomplete coverage and common variants with small effects, a most required method is an efficient combination of genome-wide association studies  of the same objective. meta-analysis  is capable of improving the power of gwas and to examine the heterogeneity between studies  <cit> . available tools  <cit>  for meta-analysis combine study data marker by marker. markers which are not part of all included studies are underestimated in their contribution to the phenotype under investigation. hence, such markers may be lost in further consideration, regardless of their actual disease association, simply due to misrepresented study power. therefore, imputation is used to unify the available marker panels of gwas and to avoid loss of snps that are present in one study but not in another. conjunction of imputation and subsequent meta-analysis has become a standard technique for combination of gwas data. several imputation methods have been developed during the last years, including mach  <cit> , impute  <cit> , bimbam  <cit> , beagle  <cit> , or eminim  <cit>  which are widely used. however, imputation is a time-consuming step with high computational performance requirements, which can be conducted in acceptable time only on high performance computer clusters. furthermore, the imputation accuracy varies greatly from snp to snp, which is difficult to take into account for meta-analysis, and, may result in a loss of power  <cit> . hence, great care has to be taken by each research group contributing to a meta-analysis effort. here, we present a ma-approach that directly operates on gwas association results and that can be run within about  <dig> hour with our yamas  software. in particular, it is possible to carry out a first analysis without the need to impute. the idea of our algorithm is that for snps that are present in one study but not in another, substitute proxy snps are defined using reference data from the hapmap  <cit>  or  <dig>  genomes projects  <cit> . in this way, all snps that are present in at least one of the experimental marker panels can be analyzed. we evaluate the performance of the proxy algorithm with data sets that were simulated using realistic linkage disequilibrium patterns obtained from the  <dig>  genomes project. moreover, we successfully applied our approach to type ii diabetes  gwas data derived from the database of genotypes and phenotypes .  <cit> .

RESULTS
simulation study
we conducted a power study based on  <dig>  genomes  <cit>  data , in order to obtain realistic linkage disequilibrium  patterns. we used the chromosome  <dig> data of the  <dig> individuals of european descent  as a “master” data set m. in general, we simulated series of new data sets mi by random re-assignment of cases-control status, so that each mi consisted of  <dig> cases and  <dig> controls. for each data set, we conducted a single-marker analysis on mi and identified the smallest p-value minpmi obtained for any of the snps in mi. in case minpmi was smaller than 1×10− <dig>  we kept the simulated data set for further analysis. we stopped the simulation process when  <dig> data sets with minpmi<1×10− <dig> had been obtained. in order to compare the relative performance of the proxy algorithm and imputing we investigated to what degree minpmi could be retrieved in a meta-analysis. for this purpose, mi was split into two “studies” ai and bi, each involving only  <dig> individuals. in addition, for ai snp information was kept only for snps from the illumina® human660wquad v <dig> panel, and for bi, snp information was kept only for affymetrix®  <dig>  chip content. meta-analysis of ai and bi was then performed either using only the snps available in both panels , or using the proxy algorithm , or based on ai and bi imputed with the impute  <cit>  software using the  <dig>  genomes data . the comparison of the three ma strategies was then based on their potential to recapture the association signal in the complete master sample. to meet this purpose, the p-values minpma−intersectioni,100kb, minpma−proxyi,100kb and minpma−imputei,100kb were defined by the smallest p-values obtained within the  <dig> kb window around the top signal minpmi of the master file. the window size was chosen since ld typically extends about  <dig> kb  <cit> . therefore, we investigated the regions  <dig> kb upstream and downstream of the top signal. nominal “power” was then evaluated based on the minp values: we counted the fraction of data sets for which minp was smaller than α ∈{ <dig> , <dig> ,..,1×10−6}. for comparison, we will show also the power values that would be obtained when both studies a and b had been genotyped for all snps of the  <dig>  genomes panel . that reflects the upper limit of what the meta-analysis approaches could have reached. adjustment for the number of snps within the  <dig> kb window was not performed. in particular, minpma−proxy and minpma−impute were treated equally, even though more snps were considered with imputation-based ma. thus, ma-imputed was favored in a way by our power definition. however, in practice a significance level of 5×10− <dig> is the consensus to establish genome-wide significance, irrespective of the number of snps actually tested. therefore, it seems to be appropriate not to adjust for the varying amount of snps tested when comparing different ma strategies.

we tried to mimic different scenarios of potential reference panels, an “ideal”, an “incomplete” and a “mismatched” one. first, the “ideal” reference panel represents a perfect and complete match of the haplotype distribution between the study and the reference data. the “ideal” reference panel consisted of exactly the same haplotypes as the master file. in practice, the reference data will contain only a fraction of the haplotypes that are actually present in the study population, simple because of the limited size of the reference samples. therefore, our “incomplete” reference consisted only of a third of the haplotypes present in the master file, in order to mimic a real data analysis situation. third, the “mismatched” reference consisted only of the haplotypes of african descent  and was included to investigate the robustness against poorly fitting reference panels.

running time
running time was evaluated on a cluster with  <dig> cpus . in table  <dig>  running time estimates  from analysis with yamas are listed. analysis of the type ii diabetes data  took  <dig> minutes and  <dig> seconds with the point-wise approach, and  <dig> minutes and  <dig> seconds with the proxy-algorithm, using a single cpu. in order to investigate running time in correlation with the number of studies, we increased the meta-analysis to  <dig>  studies by using each of the original dbgap studies twice . running time of the point-wise algorithm is about proportional in the number of investigated studies: increasing the number of studies by a factor of  <dig> leads to an increase in running time from 2m5s to 6m56s, which corresponds to factor of  <dig> . the running time of the proxy-algorithm grows only moderately with an increasing number of studies. for  <dig> studies, the running time is only about  <dig> minutes longer than with  <dig> studies. this is because most of the running time is needed for reading, indexing and storing the proxy reference file, which has to be done only once. we conclude that the proxy-algorithm can be run even with a large number of studies within less than two hours. in addition, several algorithms and data processing routines are parallelized, based upon the openmp project  <cit> , such that the yamas running time can be further improved if required by the user.

anumber of studies examined by meta-analysis.

bnaive approach, real time in minutes  and seconds .

cproxy algorithm, real time in minutes  and seconds .

we wish to contrast the running time of the proxy-algorithm of 92m5s  to that of imputation. imputation was carried out in chunks using imputev <dig>  <cit> . we used  <dig> cpus such that we were able to analyze each in one go. the average running time of a chunk was  <dig> hours. since  <dig> studies had to be analyzed,  <dig> cpus run  <dig> hours, each. in addition, association analysis ran  <dig> hours on average per chromosome, using plink  <cit> , i.e.,  <dig> cpus were needed for  <dig> hours, in addition. in total, but ignoring extra running time for merging of chunks, imputation and association testing took  <dig> ·  <dig> ·  <dig> +  <dig> ·  <dig> ·  <dig> =  <dig>  cpu-hours which is  <dig>  more than what is needed with the proxy-approach. when one assumes that ample cpus are available to impute all chunks of one study in parallel, the running time the user actually has to wait is  <dig> ·  <dig> +  <dig> ·  <dig> =  <dig> hours, ignoring overhead that is need to check and format the data for association testing. thus, even when a cluster with hundreds of cpus is available, running time improves by a factor of almost one hundred with the proxy-algorithm .

results from simulation study
in table  <dig> results from simulations under the null hypothesis are shown. none of the investigated methods exceeds the nominal level, of either α =  <dig>  or α=  <dig> , irrespective of the reference file that is chosen. in particular, there is no evidence for inflated type i error with the new proxy algorithm. this was also true when the r2-limit for a snp and its proxy was relaxed from  <dig>  to  <dig>  . we conclude that the proxy approach is a valid method. of notice, all methods are too conservative when a random effects model is used. this is in concordance with a recent publication  <cit>  in which is was shown that the random effects model tests an inappropriately strict null hypothesis.

aenumeration using either the naive approach, proxy algorithm or imputation strategy.

breference data set used for proxy algorithm and imputation.

ccalculation of the allelic effects by the fixed effect or random effect model.

dempirical levels for nominal α of  <dig>  .

eempirical levels for nominal α of  <dig> .

the results from our power study are depicted in figures  <dig>   <dig> and  <dig>  the x-axis displays various α-levels on a logarithmic scale, moving from higher to lower levels. the y-axis displays power levels.

when an ideal reference panel is used , ma with imputing strongly outperforms naïve ma restricted to the joint marker panel . thus, imputing is highly recommendable. nevertheless, the power level with ma-impute is considerably lower than power that can be achieved with a hypothetical sample that genotyped for all  <dig>  genomes snps . thus, our simulation study also confirms the claim that imputing cannot replace complete genotyping or sequencing  <cit> . ma-proxy clearly outperforms ma-intersection, but is, as expected, less powerful than ma-impute. this is partly due to, first, the smaller marker panel that ma-proxy can analyze, and, second, that in case of incomplete ld the proxy marker will not necessarily reflect the true effect size.

in the presumably most realistic scenario , we still see an impressive power gain with ma-impute when compared to ma-intersection. the performance of ma-proxy now comes much closer to that of ma-impute than with unrealistic “ideal” reference panel. we conclude that the proxy algorithm can yield valuable ad hoc results at an early analysis stage.

thirdly, considering the mismatched reference panel , it is noteworthy, that ma-impute and ma-proxy still markedly outperform naïve ma. obviously, even distant ethnical groups still share common ld patterns that can be useful in extending snp information. of note, there is no longer a measurable difference between the performance of ma-proxy and ma-impute. in summary, the difference between ma-impute and ma-proxy becomes smaller with reduced fit of the reference panel with the data. this is plausible: the imputing approach is the more sophisticated one, taking into account higher-order ld, whereas the proxy algorithm uses only pairwise ld information. thus, the relative performance of the imputing approach will be the better the more closer its assumption “concordance of the study and reference haplotype set” is fulfilled. in contrast, the proxy algorithm uses a rougher metric, and, therefore, is more robust to peculiar mismatches in haplotype structure. as a consequence, the proxy algorithm can be recommended as an alternative main approach when a close-fitting reference panel is not available.

analysis of type ii diabetes dbgap data
we examined the performance of the proxy approach on the basis of six type ii diabetes gwas studies that were available from dbgap  <cit> , cf. table  <dig>  the six gwas studies belong to three different projects.

aproject health research - vanderbilt university, northwestern nugene project: type  <dig> diabetes, national human genome research institute .

bproject health research - northwestern university, northwestern nugene project: type  <dig> diabetes, national human genome research institute .

cnurses health study.

dhealth professionals follow-up study.

there are two projects of the northwestern nugene project type  <dig> diabetes from the national human genome research institute , each of which contributed  <dig> studies to our analysis. the “project health research - vanderbilt university” project provided two studies from different platforms. data generated with the illumina® human660w-quad v <dig> chip comprised  <dig> individuals and  <dig>  markers. another fraction of patients were examined with the illumina® human1m-duo v <dig> array, for which  <dig> individuals and  <dig>  snps remained after quality control . the same arrays were used for the second project, the “northwestern nugene project”. here,  <dig>  individuals with  <dig>  from the human660w-quad v <dig> array were available after qc, and,  <dig> individuals with  <dig>  markers were available for human1m-duo v <dig>  finally the third project “geneva diabetes study”, comprised two further studies, the nurses health study  and the health professionals follow-up study . after provided quality control ,  <dig>  individuals and  <dig>  snps were available for nhs, and  <dig>  individuals and  <dig>  snps were available for hpfs. both studies were performed on the affymetrix® human snp array  <dig> . in total, data from three different platforms with different marker content were used in six gwas studies.

the dbgap data was analyzed with naïve ma , i.e., conventional ma restricted to the joint marker panel, with the proxy algorithm , and based on data imputed with imputev <dig>  <cit> , using  <dig>  genomes reference data. we relied on the qc data available from dbgap, since our focus was on the relative performance of the various ma approaches rather than on the detection of novel associations.

only  <dig>  snps were available in all six studies and  <dig>  snps were available in at least four studies. the proxy approach enabled the analysis of  <dig> , <dig> snps and snp/snp–proxy combinations, whereof  <dig> , <dig> were available in all six studies and  <dig> , <dig> were available in at least four studies. more than 85% of the proxies had an r <dig> greater than  <dig>  with the substituted snp.

our philosophy was to compare the performance of the methods on type ii diabetes genes that the community considers to be “undoubtedly” confirmed. to this purpose, we used the catalog of published gwas results provided by the american national human genome research institute  <cit> . the catalog lists  <dig> type ii diabetes gwas genes/ld regions  with at least one snp that meets the genome-wide significance criterion of 5×10− <dig>  for each of these gene regions, we investigated the  <dig> kb up- and downstream region of the snp reported to be most significant and computed minpma−impute and minpma−proxy for the six studies available for us. of note, a considerable part of the  <dig> genes was identified by meta-analysis efforts and shows only moderate odds ratios  <cit> . as a consequence, it cannot be expected that all the genes show measurable association effects within the smaller data sets we analyzed. in other words, not all the genes will be informative for the evaluation of the performance of the two meta-analysis approaches. therefore, we restricted our comparison to gene regions that reached a significance level of  <dig>  with at least one method.

in table  <dig>   <dig> such gene regions are shown, together with the minimum p-values for all approaches. for  <dig> of the gene regions, ma-proxy yields a more significant result than ma-intersection. for tcf7l <dig> for instance, minp improves from  <dig> ×10− <dig> to  <dig> ×10− <dig>  a change by a factor of  <dig>  in total, there are  <dig> gene regions with a p-value improvement of at least a factor of  <dig>  including fto, irs <dig>  jazf <dig>  kcnj <dig>  and kcnq <dig>  for kcnq <dig>  we observe p =  <dig>  with ma-intersection and p =  <dig>  with ma-proxy,

an increase in significance by a factor of  <dig> . for another  <dig> genes we observe an improvement with the proxy algorithm by a factor ranging from  <dig>   to  <dig>  . there are also  <dig> gene regions for which no difference between ma-intersection and ma-proxy can be observed. in these cases, the most significant snp is available in all  <dig> studies and, therefore, ma-intersection and ma-proxy coincide. finally, for tspan8/lgr <dig>  significance slightly decreases from  <dig>  to  <dig> . in summary, ma-proxy outperforms ma-intersection in the majority of cases and we observe an average  improvement of the level of significance of  <dig>  , demonstrating the usefulness of proxy-snps.

aeach gene region is listed only once, even if listed several times in the gwas catalogue.

bmost significant snp according to gwas catalog  <cit> .

cp-value according to gwas catalog.

dmost significant snp with naïve ma on intersection of marker panels of  <dig> dbgap gwas described before.

ep-value refering to snp from previous column.

fmost significant snp with proxy ma on  <dig> dbgap gwas.

gp-value refering to snp from previous column.

hp-value of the correslonding snp calculated by imputation/snptest.

iimprovement with proxy algorithm: quotient of columns “p-pointwise” and “p-proxy”.

jimprovement with imputation: quotient of columns “p-proxy” and “p-impute”.

imputation-based ma outperforms ma-proxy in  <dig> out of  <dig> cases and we observe an average  improvement of the level of significance of  <dig>  . in two cases, imputing outperforms the proxy-algorithm by a factor of more than  <dig>  slc30a <dig>  and hmga <dig> , and in another case by a factor of  <dig>   which demonstrates the usefulness of long-range ld for association analysis. for  <dig> genes, the loss of significance with the proxy-algorithm is moderate with a factor of less than  <dig>  of which for  <dig> genes we observe a factor of less than  <dig>  for three genes, fto, kcnq <dig> and rbsm1/itgb <dig>  the proxy-algorithm even performs slightly better than ma-impute. in summary, one can say that the proxy algorithm yields good approximations of the actual level of significance in the majority of cases and that it is a potentially useful screening algorithm.

aenumeration according to table  <dig> 

beffect allele: the allele beta is given for.

cother allele.

deffect estimate according to logistic regression.

estandard error.

fp-value.

gbetween snp and proxy-snp according to reference data .

CONCLUSIONS
via real data analysis we were able to show that the proxy algorithm is not only fast and quickly employed, but also powerful. it clearly outperformed naïve snp-by-snp meta-analysis on real genotype data, when applied to a set of established type  <dig> diabetes regions. moreover, our simulation study indicates that the proxy algorithm is very robust in terms of power with respect to a ethnically poorly matched reference panel. thus, it is worth considering it as an alternative ma approach for studies on ethnical groups that are not directly represented in the  <dig>  genomes, for instance studies carried out in population isolates.

it is a known phenomenon that the catalogue of confirmed gwas findings  <cit>  is strikingly sparse for the x chromosome. at the moment, it is unclear if this phenomenon reflects the “true genetics” of human diseases or whether it is a detection bias. one might indeed speculate that the x chromosome is often ignored in ma efforts since it requires additional efforts to be imputed  <cit> . in this context, yamas may be particular helpful since no special analysis steps are necessary for the x chromosome.

another notable feature of yamas is that it can be combined with imputed data. in practice, it may happen that studies are imputed with different reference panels. moreover, particular snps might pass imputing-qc in some studies but not in others. in these situations, the analysis panel can be completed with the proxy-algorithm. in this context we wish to emphasize that our goal is not to compete with imputing as the standard approach for meta-analysis. indeed, our own simulation study demonstrates a power advantage of imputation-based ma in a standard setting. our aim is rather to speed up and give impetus to meta-analysis efforts. even though the required analysis time for genome-wide imputing is meanwhile limited to a few weeks for experienced and well-equipped groups, joint projects are frequently long-lasting. everyone who has worked in a meta-analysis project has either experienced or can imagine that it can easily take one year until all participating groups have provided their imputing results, either because some of the participating groups are less experienced in imputing analysis than others or either because they are involved in projects which they assign higher priority to. in particular, the priorities the participants have will sometimes be heterogeneous, causing delay for those who have the primary interest in the joint effort. therefore, we believe that a method that facilitates ma and yields ad hoc, but still interpretable and meaningful results, is highly warranted. the proxy algorithm we have introduced fulfills these criteria: it directly operates on gwas analysis results and can be run in a few hours even when the meta-analysis comprises many groups, and has descent power since it can analyze all snps that were genotyped in at least one of the participating studies.

