BACKGROUND
dna motifs are short sequences in the genome that play important functional roles in gene regulation. due to their short length, it is difficult to identify these regions using features intrinsic in their composition. assuming that the motifs are conserved in closely related species due to the importance of their function, it is possible to discover them by comparing the respective dna sequences to identify the sub-sequences that are very similar to each other.

there are two common combinatorial formulations that identify the motifs: the first is the consensus motif problem which made its first appearance in  <dig>  <cit> , while the second is the planted -motif problem that was presented in  <dig>  <cit> . it is worth noting that the latter formulation is a special case of the former. the exact definitions are as follows:

given a set of t sequences si where  <dig> ≤ i ≤ t defined over an alphabet ∑. the consensus motif problem is to find an l-length motif sequence m such that in each sequence si,  <dig> ≤ i ≤ t, there is at least one subsequence pi differing with at most d mismatches from m; i.e., dh ≤ d, where dh is the hamming distance between pi and m.

the planted  motif problem is a special case of the consensus problem in which we restrict that pi occurs only once in si.

due to its combinatorial nature, the consensus motif problem and its variant defined above is extremely challenging. over a benchmark data of  <dig> sequences, each of length  <dig> characters, large instances of , ,  and  have been addressed and many algorithms have been developed to solve them one after another. these algorithms can be classified into two major categories: approximation algorithms  <cit>  and exact algorithms  <cit> . approximation algorithms are based on probabilistic local search techniques, such as gibbs sampling, expectation maximization, etc. although these algorithms may solve the challenging instances in practice, there is no guarantee that the motif can be found even when l is short.

exact algorithms are based on exhaustive search techniques. the brute force algorithm proceeds by testing all possible motifs of length l using pattern matching, leading to o  time complexity. this algorithm, however, is not suitable for discovering long motifs in practice, and many algorithms have been developed to provide faster solutions. examples of these algorithms are census  <cit> , pms <dig>  <cit> , pmsp  <cit> , pmsprune  <cit> , pms <dig>  <cit> , smile  <cit> , riso  <cit> , risotto  <cit> , and voting  <cit> . in the following we briefly review the most efficient ones and the ones related to our work.

the algorithms smile  <cit> , riso  <cit> , and risotto  <cit>  are based on the use of suffix tree. the time complexity of these algorithms is the same and it is o), where v=∑di=0cil3i is the size of the d-mismatch neighbourhood of motifs of length l and n=∑ti=1ni, ni is the length of sequence i from input sequences. risotto improved the time complexity of smile and riso in the average case and solved some challenging instances such as  and .

pmsp  <cit>  is based on exploring the neighbourhood of the l-mer of the first sequence and checking whether the elements of such neighbourhoods are  motifs. the time complexity is o). it is able to solve some challenging instances such as  and . pmsprune  <cit>  is an improved version of the pmsp algorithm, based on the branch and bound strategy. although it has the same worst-case time complexity as pmsp algorithm, it is more efficient in practice and it could tackle the  and  instances for the first time. pms <dig>  <cit>  is based on computing the common d-neighbourhood of three l-mers using integer programming formulation. it combines this novel idea with the algorithms pms <dig> and pmsprune. pms <dig> can tackle the large challenging instances ,  and . the only drawback of pms <dig>  it requires larger amount of internal memory to finish computation.

our contribution
in a previous work  <cit> , we have introduced an idea composed of two stages to speed up the exact algorithms: in the first stage, we generate a set of candidate motifs by applying one of the exact algorithms based on the neighbourhood method  using q ≤ t sequences. in the second stage, for each candidate motif we check if it is a valid motif or not using pattern matching on the reminder  sequences. this dramatically reduces the search space and leads to significant speed up. the bottleneck in this approach, however, was the determination of the q value that yields the fastest running time. that is, the user has to guess the value of q, which might lead to non-optimal running time and even no speed up compared to the traditional methods. also, the authors in  <cit>  have used the same idea on pms <dig>  risotto, and pmsprune algorithms.

in this paper, we present a theoretical method which can be used to determine the appropriate value of q. then we apply this strategy on pmsprune algorithm and solve some big challenging instances such as . furthermore, we propose a parallel version of our algorithm to present a practical solution to the challenging instances of the motif problem. our parallel version further speeds up the solution of the  instance.

definitions and related work
in this section, we introduce some notations and definitions that will help us to describe our algorithm and related work in a concise manner.

definition  <dig> adapted from  <cit> : for any string x, with |x| = l, let bd = {y: |y| = l, dh ≤ d}, where dh denotes the hamming distance and bd denotes the set of neighbourhoods of x. we also write v to refer to |bd|.

definition  <dig> adapted from  <cit> : let s denote a string of length n and let x denote another string of length l, l <n. we define the minimum distance between s and x as d ¯h=minx′⊲lsdh, where x ⊲l s denotes that x is a substring of s with length l.

definition  <dig> adapted from  <cit> : given an l-length string x and a set of strings s = {s <dig>  ..., st} with |si| = n for i =  <dig>  ..., t and l <n, we define the distance between s and x as d ¯h=maxi=1t{d ¯h}=maxi=1t{minr⊲lsi{dh}}

definition  <dig> adapted from  <cit> :a string x is an  motif for a set of sequences s = {s <dig>  ..., st}, if:

1) d ¯h≤d.

2) ∃y⊲ls1:x∈bd∧d ¯h≤d.

proposition  <dig> adapted from  <cit> : let u and v be two random strings of length l over an alphabet of  <dig> characters with equal probability of occurrence. the probability pd that dh ≤ d is pd= ∑i=0dli3/4i1/4l-i, and the probability that d ¯h≥dis n-l+1)t. the expected number of l-length motifs that occur at least once in each of the t sequences with up to d substitutions is e = 4ln-l+1)t.

pmsprune algorithm
because the first stage of our method will depend on the pmsprune algorithm. we will review the basic steps of it in the notions presented above.

the main strategy of pmsprune is to generate bd, for every l-mer y in s <dig>  using a branch and bound technique. an element x∈bd is a motif only if d¯hx,s≤d. the step of verifying that d¯hx,s≤d is achieved by scanning all substrings of s. for fixed values of t, n, and l, the expected time complexity of pmsprune is equal to

  tpmsprune=otn-l+12l+p2d ∑i=12d-d′+1li3i 

where p2d is the probability that the hamming distance between two strings is at most 2d, and it is defined in proposition  <dig>  for fixed values of t, n, and l, value d' was estimated such that the probability of d ¯h≥d′ is close to  <dig>  ≥d′ is given in proposition  <dig> and it is 1-1-pd′n-l+1t).

implementation
our proposed strategy
our new strategy, referred to as hybrid exact pattern motif search , is composed of three steps: first, we determine the value q, corresponding to the size of a subset of input sequences, as explained below. second, we apply an exact exhaustive algorithm £  on the set of q sequences to find the set of d-neighbourhood bd . we call this set the candidate motif set. finally, we apply a pattern search algorithm over the remaining sequences to verify each motif. note that our algorithm is generic in the sense that it takes the program £ also as input in addition to the input sequences and user parameters. a pseudo code for this strategy using the exact algorithm £ is as follows:

algorithm 2: hep 

begin

1) determine the number of sequences q using the method given below.

2) implement the exact algorithm £ on q input sequences. let c be the set of candidate motifs found in the q sequences.

3) for each pattern v in c, check if v is a valid motif or not in the reminder  input sequences using pattern matching algorithm.

end.

theorem 1: algorithm  <dig> correctly finds all  motifs in a given t input sequences.

proof: step  <dig> of the algorithm is exhaustive and finds the whole set of d-neighborhood for the q sequences. therefore, and by definition of the  motif problem, any  motif belongs to this set, even if q =  <dig>  in step  <dig>  each candidate motif is verified by comparison to each substring in the remaining sequences. this step is conducted by an approximate pattern matching algorithm for each l-length substring in the candidate motif set and each l-length substring in the remaining sequences such that the hamming distance between these two substrings is ≤ d. this guarantees that no motif is missing.

theorem 2: the running time of the hep is equal to

  thep=t£+le 

where t£ is the running time of step  <dig> involving the use of an exact algorithm £ on the q input sequences and l  e is the running time of step  <dig> such that e is the number of elements in the set c, which is estimated to be 4ln - l + 1)q. note that the complexity of step  <dig> takes constant time, as we will explain below. note that the running time of the brute force algorithm is acquired if q =  <dig> in equation  <dig>  the running time of the exact algorithm £ is acquired if q = t in equation  <dig> 

determination of the best q
the range of the number of sequences q, enhancing the performance of the exact motif finding problem is calculated by solving the following inequality for the parameter q:

  thep≤t£ 

definition 5: we define mns as the minimum number of sequences q that yields better running time; i.e., the first value of q that verifies the inequality. we also define ons as the optimal number of sequences q that yields the best running time; i.e., the value of q such that thep is minimum over  <dig> ≤ q ≤ t.

implementing hep based on pmsprune
we decided to use pmsprune for implementing the first step in our method, because of its superiority compared to other algorithms as discussed in  <cit> . however, we stress that our approach is generic and can be used with any better algorithm that appears in future. in the following, we will refer to our method based on pmsprune as hep_pmsprune. if q = mns we will denote it with hep_pmsprune, and if q = ons we will denote it with hep_pmsprune.

determining mns for pmsprune
replacing t£ by the time of pmsprune on q sequences, equations  and  can be rewritten as follows:

 tpmsprune=q2 + <dig> 

 thep_pmsprune=q2+l e 

replacing thep with thep_pmsprune and t£ with tpmsprune in the inequality results in the following variation:

 le <  <dig> 

substituting the value of e with the value given in proposition  <dig> in the left hand side yields

  4l n-l+1)q<l 

dividing both sides by 4l and taking the logarithm,

   q>log-log logn-l+1) 

the inequality  provides the range of the values of q that makes the running time of hep using pmsprune less than the running time of the original pmsprune over the all set of sequences. the minimum value of q in the range of the inequality is called mns and it is equal to:

 log-log logn-l+1)+ <dig> 

determining ons for pmsprune
for fixed values of t, n, l and d, ons can be calculated for pmsprune by selecting the value of q that minimizes the total number of operations thep_pmsprune for  <dig> ≤ q ≤ t. the following algorithm computes the value of ons for each instance .

algorithm 3: find ons

begin

1) q = ons = 1

2) e=4l il-i))n-l+1)q

3) tmin=q2+le

4) for q = mns to t do

 e=4l il-i))n-l+1)q 

 t=q2+le 

if t <tmin then

tmin = t

ons = q

5) return ons

end

the above algorithm computes q in o time. in practice, the time for computing q takes negligible time with respect to the rest of motif finding steps; it took maximum one second for all experiments included in this paper with simulated and real datasets. to save some time, our implementation includes a look-up table containing pre-computed values of q for different values of l, n, and d, where l <  <dig>  d <  <dig>  and selected values of n with n =  <dig>  n =  <dig>   <dig>  ..., n =  <dig>  for other values of l, n, and d, we compute the best q using the above algorithm.

parallel version of hep_pmsprune
we propose a parallel version for hep_pmsprune called phep_pmsprune. the two main steps of hep_pmsprune can be parallelized as follows:

we parallelize the pmsprune algorithm by assigning a set of l-mers from s <dig> to each processor for establishing the set of neighboring motifs. the resulting sets are stored in candidate motif lists ci, i ∈ { <dig>   <dig>  ..., p}, where p is the number of processors. after each processor finishes computation, the ci lists are merged together in a larger set c, such that each motif is represented once in this list; i.e., all repetitions are removed. creating the c list is done in linear time with respect to the number of candidate motifs and it is achieved as follows:

we incrementally construct the partial list cj that contains the lj lists,  <dig> ≤ j ≤ p, by appending the list lj at the end of the list cj- <dig> such that all elements in lj existing in cj- <dig> are discarded. this continues until j = p; i.e., cp is c. discarding a repeated element is done efficiently as follows: for small values of l, we create a look-up table with size Σl, where Σ is the alphabet size. each possible l-length string can be mapped to a number in the range between zero and Σl in o time. the ith entry in this table contains one if a string in cj- <dig> is mapped to i. otherwise, it contains zero. the strings in cj are queried against this look-up table to discard repetitions and set entries they are mapped to with value one. for longer values of l, we use the aho-corasick automaton to index all l-length motifs in cj- <dig>  and check if a strings in cj exists in the automaton or not and add the new strings of cj to the automaton. for these string matching algorithms, we refer the reader to  <cit> .

in the second step, we validate each candidate motif independently in parallel over the available processors. the running time of this algorithm is o, where ts is the sequential running time and |c| is the size of set c.

the first step in the parallel algorithm does not lead to loss of any motifs. this is because the set c includes the d-neighborhood set of the q-sequences. the reason is that we run pmsprune in parallel against the strings , where x is a substring of s <dig>  that is, each substring is not processed. the second step in the parallel algorithm is also correct, because the elements in c are independent of each other and checking the validity of each candidate motif can be safely run in parallel. our experimental results confirm the correctness of our parallelization procedure.

RESULTS
experiments on simulated datasets
we used the simulated data sets that are used in many articles  <cit>  with t =  <dig> sequences and n =  <dig> characters, where the alphabet size is  <dig>  each  input instance dataset is generated as follows: we generate random strings with length  each, where the characters appear randomly with equal probability. then we generate randomly an l-length string m and plant a copy of it in each sequence at random position after mutating it with at most d random mutations. we tested the algorithms for varying n, l, and d values and for the following challenging instances: , , , , , and .

experiments overview
our experiments address three major issues: the first is the performance of our method compared to the use of pmsprune only. the second, we show that our method for selecting q, already achieves the best running time. the third is the performance of the parallel version and its scalability. the algorithms are implemented on a  <dig> quad-core processors  machine. the programs are coded in c language. in the parallel version, we use openmp directives for parallelizing the code.

performance of hep on pmsprune
tables  <dig> and  <dig> show the performance of the algorithms hep_pmsprune and hep_pmsprune with respect to pmsprune algorithm respectively. the last column in tables  <dig> and  <dig> displays the improvement in pmsprune which equals to  tpmsprune-thep_pmsprunetpmsprune and  tpmsprune-thep_pmsprunetpmsprune respectively. we used the notations 's', 'm', 'h', and 'dy' in computing the time for seconds, minutes, hours, and days, respectively. the results confirm that, the algorithms hep_pmsprune and hep_pmsprune significantly reduced the running time compared to the standard pmsprune algorithm in all challenging instances.

evaluating the choice of q
in this section, we experimentally evaluate our algorithm for determining the best q that minimizes the running time of the hep_pmsprune algorithm. to achieve this, we will follow the following steps:

 <dig>  we run hep_pmsprune, mns ≤ q ≤ t for the problem instances , , , , , and  and determine the value of q that minimizes the running time; we will refer to this value with onsexp.

 <dig>  compare the onsexp against our ons computed theoretically.

we also conducted another experiment, where the problem instances were generated with different n and l and d. table  <dig> shows the results for many of these instances, where the number of sequences t =  <dig>  we can observe that our algorithm finds the optimal q in all these instances. we also observe improvement of the running time with respect to the pmsprune algorithm in most of the cases. the cases with no improvement in the running time are attributed to the fact that the expected number of motifs is very low and the original algorithm runs already fast in these cases.

the first column includes the sequence length n, the second includes the hamming distance d, and the third includes the motif length l. the entries l+, means greater than l leads to no improvement. 'ons' stands for the theoretically computed q, while "ons_exp" stands for the experimentally found one. we report range of ons_exp that yielded best time. there also range of ons for l+. "t_ons" and "t_onsexp" stand for the times  with ons and ons_exp, respectively. "t_pms" stands for the time with the original pmsprune algorithm only.

note that it was not feasible to list the results for all possible values n, l, and d in table  <dig>  but in other instances with different values of n, l, and d, we found that ons and its time were consistent with onsexp and its time published in this table.

performance of phep_pmsprunealgorithm
in table  <dig>  we show the results of applying the parallel version of our algorithm phep_pmsprune using different number of processors and for different problem instances. the running time of the difficult instance  has been decreased from  <dig>  days to about  <dig>  hours using  <dig> processors. figure  <dig> shows the scalability results for the algorithm where speedup=theppmsprunetheppmsprune. from table  <dig> and figure  <dig> we note that phep_pmsprune reduce the time of hep_pmsprune and the speedup achieved scales well with the increasing number of processors.

experiments on real datasets
we used two collections of real datasets used in previous research papers  <cit> . the first collection is a dataset including a number of the upstream regions of yeast genes  <cit>  affected by certain transcription factors. the transcription factors are from the scpd  <cit>  database and the paper  <cit> . the upstream dna sequences were extracted using the saccharomyces genome database  <cit> . the second collection includes the dataset of blanchette  <cit>  which includes the upstream dna regions of many genes from different species. this dataset is available at http://bio.cs.washington.edu/supplements/footprinter and a copy of it is available with our software tool for testing.

tables  <dig> and  <dig> show the motifs found by our method compared to the published ones for both collections. in each table, we give a reference to the published motif. our program could detect all published motifs. it is also interesting to note that our program could detect extra novel motifs in the case of the interleukin- <dig> problem instance in table  <dig>  these motifs look interesting, because they are  <dig> bp long with hamming distance zero; an observation that calls for further biological investigation.

hse_hstf
pdr
pdr <dig>  hxt <dig>  hxt <dig>  pdr <dig> 

tccgcgga
mcb
cdc <dig>  cln <dig> 
ecb
mcm <dig>  cdc6
the first column includes the transcriptional factors  and the length of upstream sequences. the second column includes the regulated genes. the first three factors and their related genes are available at the scpd  <cit> . the ecb is the early-cell-cycle-box promoter region described in  <cit>  and we extracted its related genes from the yeast genome database  <cit> . the third column includes the motif detected by our tool and the respective parameters . the fourth column includes the published motifs and their references. the final column includes the running time in seconds needed to run our program in the parameter range from  until , i.e., there are  <dig> invocation of our program. the percentages in brackets refer to percentage improvements in rum time compared to pmsprune method.

insulin family
5' promoter
metallothionein
5'utr+promoter
interleukin- <dig> 5'utr+promoter
atggaggttccatgtcagat,
ctatggaggttccatgtcag,
gaggttccatgtcagataaa,
ggaggttccatgtcagataa,
tatggaggttccatgtcaga,
tggaggttccatgtcagata,
growth-hormone
5'utr+promoter
c-fos
5' utr+promoter
c-myc
5'+promoter
histone h1
5'utr+promoter
the first column includes the gene family and the length of upstream sequences. the second column includes the number of sequences. the third column includes the motif detected by our tool and the respective parameters . the fourth column includes the published motifs and their references; "gb" stands for genebank annotation. the final column includes the running time in seconds needed to run our program in the parameter range from  until , i.e., there are  <dig> invocation of our program. the percentages in brackets refer percentage improvements in rum time compared to pmsprune method.

tables  <dig> and  <dig> also include the running times  of running our method for the listed problem instances and the improvement in time compared to the pmsprune method. the running time for one problem instance is the time needed to run our program in the  parameters range from  until , i.e., there are  <dig> invocations of our program. the results show that our program is superior to the pmsprune for large instances.

CONCLUSIONS
in this paper, we introduced an efficient method that can enhance the performance of exact algorithms for the motif finding problem. our method depends on dividing the sequence space into two sets. over the first set, we generate a set of candidate motifs. then, we use the remaining set of sequences to verify if each candidate motif is a real one. the experimental results show that our method is superior to the best methods available so far and could tackle large problems like . finally, we introduced a scalable and efficient parallel version for the proposed method. our tool is available for free for academic research at http://www.nubios.nileu.edu.eg/tools/hymotif.

availability and requirements
project name: hymotif.

project home page: http://www.nubios.nileu.edu.eg/tools/hymotif

operating system: linux.

programming language: c.

other requirements: c/c++ libraries.

license: gpl.

any restrictions to use by non-academics: no restrictions.

competing interests
the authors declare that they have no competing interests.

authors' contributions
all authors contributed to theoretical and practical developments which form the basis of hep method. all authors wrote and approved the manuscript.

