BACKGROUND
knowledge discovery and data mining in the biological literature have been attracting more and more interest  <cit> . automated text mining can facilitate the efforts of both biological database curators  <cit> , and of biologists who consult the literature to acquire novel information both within and outside of their immediate expertise. text mining applications come in various styles. some rely on statistical methods to detect unusually strong co-occurrences between genes or gene products . other applications aim to extract precise information from the text, for instance protein mutations  <cit>  or interactions  <cit> . a new promising type of application, pioneered by textpresso  <cit> , consists of portals that help end-users locate information more effectively.

most text mining applications require the ability to identify and classify words, or multi-word terms, that authors use in an article to refer to biological entities . this task is called named entity recognition and has been well studied in computer science for problems such as recognizing names of places, people and organizations in news articles  <cit> . efforts to automate the named entity recognition task in the news domain have been very successful, with accuracies of automated methods that compete with accuracies of human efforts . however, adapting these methods to the biomedical literature has been challenging  <cit> , and recently published methods on text from abstracts report accuracies around 75% for protein names  <cit> .

several strategies have been tried to recognize biological entity names in articles. some methods rely on protein and gene databases to assemble dictionaries of protein names. a key disadvantage of these methods is that they critically depend on the database used as source of names, and will not recognize new protein names before the name is entered in the database. another problem is that databases may not contain each name variant used to refer to a protein, so that partial or fuzzy matching of the names in the database to the text in the article is needed  <cit> . fuzzy matching is difficult to control for and may introduce spurious matches. another class of methods attempt to recognize protein names using the morphology of the term: whether a term contains mixed case, or includes a prefix or suffix next to a protein name  <cit> . the main advantage of these methods is that they can detect protein names that authors have just created, if they follow the morphological clues that the method recognizes. the main disadvantage is that authors do not use morphology consistently, and that certain terms of the language that have been used to refer to proteins  cannot be recognized based on morphology  <cit> .

most of these methods were developed for abstracts, because abstracts are readily available for millions of articles . however, it is clear that information content in text from full length articles is much greater than in abstracts, even if the information density  is higher in abstracts  <cit> . specifically, as noted by horn et al., information about protein mutations is much more likely to be found in full length articles than in abstracts  <cit> . this is most likely to be true of other types of information as well, such as experimental techniques and protocols, cell types, species names, and interactions. since full texts are becoming more accessible , developing methods to extract information from full text is becoming more practical.

compared to abstracts, however, full length articles are a complex source of text. they usually require pre-processing to convert the document from the html or pdf format to plain text streams. the result of the conversion will contain all the sections of the article and separating sections is a hard problem in itself because formatting styles and conventions vary across journals, and change periodically even for a given journal. in addition, journal presentation styles are interleaved with the text of the article and require specialized processing so that the tokenization of the document matches the way the document looks when rendered in a web browser. for instance, removing all html tags when converting an html document to text is inappropriate, as this may create tokens that do not exist in the article . although some measures can be taken to limit these problems, in practice, conversion procedures are difficult to fine tune for each style and journal, and converted full length articles are noisy sources of text. therefore, methods designed to extract named entities from full text must be robust to types and amounts of noise which are not found in abstracts.

in this article, we present a method that extracts biological named entities directly from full length articles. this method is used to process a corpus of  <dig>  full text articles and assemble a catalog of protein name references indexed by an article pubmed identifier  with high precision. based on this catalog, we construct a dictionary of  <dig>  protein names. we also present a method that uses this dictionary to identify the set of protein names a full text article refers to. we evaluated the performance of this method with a set of full text articles that was not used for the construction of the catalog. the method evaluated on a test set of  <dig> articles achieves an average precision of 75%. most other published methods have been trained and tested on abstracts only . while these methods were not developed for full text, they are representative of the state of the art for protein name extraction. we thus chose to compare the results obtained with our approach to the results obtained with nlprot and yagi, when used on the same text material. we found that the performance of our method compares favorably to the 42% average precision that nlprot achieves on the same test set, at similar levels of recalls. tested on another set, our approach has better average precision than yagi, but fails to detect long protein name variants that are often detected by yagi. these results demonstrate the usefulness of direct name extraction from full text articles.

we have implemented the approaches described here in the textractor framework .

RESULTS
high frequency terms in biological journal articles are enriched in biological entity names
many biological research journal articles focus on one or a few genes or gene product. typical examples are articles that describe the cloning of a particular gene. other articles that describe the discovery of a new interaction will often focus on the two gene products involved in the interaction. thus, the high frequency terms in these articles often refer to a gene/protein, the cell line in which the gene/protein is being studied, or the biological process in which the gene/protein is involved. setting a threshold on the frequency of terms in an article allow us to define the set of terms that are most frequent in the article. in this study, we used a threshold of  <dig>  and thus we considered "most frequent" a term that occurred at least  <dig> times in a given article .

learning and classifying with the neighboring features
three support vector machine  models were constructed to predict if a term occurs in a context that indicates  a protein versus a cell,  a protein versus a process  a protein versus an interaction .

since each of the most frequent terms occurs at least  <dig> times in a given article, we can make at least  <dig> predictions for one term in one article. we expect that some occurrences of a term will occur in contexts that do not clearly indicate if the term is a protein or not. for instance, in a sentence such as "the exact  its molecular mass in insect cells...", the context included in the window offers little clue to decide if the term refers to a protein or not . in such cases, the svm score is expected to be small. in comparison, occurrences like "...is restricted to skeletal muscle and does not affect .", are very informative since the features "expression" and "isoform" are present together in the local context .

we used a simple heuristic expression to combine the classification results of these three models  and created a protein name catalog for all the articles in the jbc <dig> dataset.

quality of the protein name catalog
for the jbc <dig> dataset, we predicted a catalog of  <dig>  protein names and ranked them by their combined scores . the sc distribution was evenly divided into  <dig> buckets. one continuous score range was then randomly selected in each of the  <dig> buckets, so that each range includes  <dig> protein names. we evaluated the quality of this catalog by manually verifying this random sample of  <dig> names in the corresponding articles. figure  <dig> summarizes this evaluation and provides precision measures. from jbc <dig>  we estimate that, on average only  <dig> or  <dig> protein names will be extracted from a given article. since this number of names extracted is very low compared to the complete set of names that an average article contains, we have not evaluated the coverage of the prediction. however, because protein names are reused in different articles, if the method misses a name in one article, this name may still find its way into the protein name dictionary through another article . a more interesting evaluation is thus how well would this catalog do in a specific application, such as extracting unique protein names in a full text article. this is the evaluation that we present in the rest of this article.

quality of the protein dictionary
to address this question, we created a protein dictionary from a more comprehensive protein catalog, which is based on  <dig>  full text articles  . we used names in the dictionary to lookup protein names in a set of  <dig> full length articles from nature cell biology . the tool used to lookup protein names is provided in additional file  <dig> we used the relative recall measure to compare our dictionary-based method to nlprot on ncb <dig> . table  <dig> summarizes these precision and relative recall measurements. these data indicate that the lookup approach that we implemented in textractor outperforms nlprot on full text articles in precision  at the same level of relative recall .

during the evaluation on ncb <dig>  we noticed that nlprot made systematic errors on tokens that appeared in the text of these articles because of journal style formats " which was part of the npg javascript header that our pre-processing protocol failed to remove). these terms were mistaken for gene/protein names. to rule out any possible effect due to the selection of the articles in ncb <dig> , we performed a second evaluation on  <dig> randomly selected articles from pubmedcentral . data in table  <dig> confirm that textractor outperforms nlprot on full text .

inspection of the validation data suggests that yagi is very good at identifying protein names variants that are longer  than the ones that textractor typically detects . this point also illustrates a difficulty of comparing protein name extraction methods, since the total set of correct names may include redundancy.

in our evaluation, we have chosen to count as correct names those that refer to proteins by themselves, even if such names are shorter versions of longer names. these shorter versions are not partial names, however, because their occurrence in the text is sufficient to recognize a reference to a specific protein.

since yagi and nlprot use similar sources of information, including protein names derived from biological databases, but differ in their machine learning approach, these results also suggest that conditional random fields , were able to better capture the distribution of protein names in full text, when learning on abstracts, than the learning approach used by nlprot. to corroborate this conjecture, many errors made by yagi seem to appear in the reference section of articles, which has a different structure than the rest of a full text article. since both yagi and nlprot use a database derived dictionary, it would be interesting to see if the precision of these approaches on full text can be increased when using a dictionary built directly from full text.

limited overlap with swissprot derived names
we matched terms in the dictionary to description lines in swissprot , as described for matching terms in the dictionary to full text articles. we found that only  <dig> % of the terms in our dictionary are included in swissprot descriptions. examples of terms present in the dictionary that do not match swissprot description lines include: "collagen xi", "collagen alpha <dig> i", "trhrs", "trim <dig> gerp". this result indicates that our method is strong at identifying protein name variants that are not found in swissprot descriptions. swissprot is a main source of protein names used for building protein name recognition methods  <cit> . therefore, combining our dictionary with names derived from swissprot may lead to improved performance for a variety of name recognition methods.

implementation and performance
we implemented the methods described in this manuscript in the textractor framework . briefly, this framework provides support to parse full length articles into sentences; create inverted indices where sentences are indexed by words; store sentences, articles and other information in a database; calculate features from sentences, articles or part of the above; and import results of predictions made with the features into the database for integration with other types of information. the textractor framework uses jdo  <cit>  for data persistence, mg4j  <cit>  for inverted-index support, and svmlight  <cit>  for machine learning. the framework is implemented in java  <dig> +. the distribution includes a version of the lookup tool that functions independently of a database and uses mg4j for fast term lookups.  this tool is distributed as additional file  <dig>  with a dictionary containing about  <dig>  names, processing a set of  <dig> articles  took about  <dig> seconds on a red hat linux dual xeon  <dig> ghz processor server, while it took nlprot  <dig> minutes, and yagi  <dig> seconds. similarly, yagi processed a set of  <dig> articles in  <dig> seconds, while textractor needed  <dig> seconds .

we distribute the implementation of our method and other relevant information, e.g., the list of regular expressions used to extract the terms for svm training, under the gnu general public license to maximize their use in the biomedical community .

discussion
information in full text
compared to full text, abstracts have the advantages of convenient access and uniformity of format. based on recent studies, however, the information content in abstracts is less than half the information content in full text  <cit> . in addition, most experimentalists would consider full text a more informative source of information than abstracts. indeed, an abstract usually focuses on the general idea of a biological issue per se, but the details, such as how the issue was studied in that article, are very unlikely to be fully described in an abstract. for an experimentalist, the question is more often "how" than "what" and is always about details. thus, automatic text mining applications that target experimentalists should ideally also be able to extract relevant information from full text articles.

this study addresses an initial step in this direction â€“ to collect and classify several categories of biological entity names from full text that are essential for a detailed understanding of an issue, including how it was studied, from a biological article. these categories include the terms that refer to protein/gene, cell type, biological process, and interactions. specifically, we compared the recognition of the protein/gene names with other systems and emphasized the strength of our approach in identifying term variants.

term variants and disambiguation
our method draws on several concepts introduced in  <cit> , but differs in the following ways.  we use only features derived from the context of the term. this makes our method insensitive to the morphology of the term and allow us to collect terms as diverse as "d2-dopamine receptor", "dopamine d <dig> receptor", "d <dig> dopamine receptor", "d2r", "d2dr", "drd2", "d2s receptor", "d2l receptor" and their plural forms for the same protein in the catalog.  we applied term disambiguation to terms extracted from full text without the help of a dictionary of protein names. in contrast,  <cit>  used genbank as the source of its dictionary and extracted terms by fuzzy-matching the text of the article.  we combine information from the multiple sentences in which a term occurs to make a prediction if the term is a protein or not in a given article. since we disambiguate only terms that appear more than  <dig> times in an article, information from at least  <dig> sentences is considered for each term in an article.  the precision measures that we report benchmark the ability of our method to precisely identify that a term is a protein in a given article. performance measures given in  <cit>  measure the performance of a related, but distinct task: assigning a term to one of three classes  when it is already known that the term belongs to one of these classes.

extraction of long protein names
we have described that our method may fail to detect long protein names . such names appear with a lower frequency in articles and are often abbreviated in full text. approaches to extract acronym definitions from full-text may complement our approach and help extract long protein names .

specific evaluation protocol for full-text
protein name marking is a task where a program tries to mark the occurrences of all the protein names in a text. in full text, some protein names are repeated very often. if we followed the name marking benchmark standards, we would count correct extractions several times for such repeated terms. while this is not a problem for abstracts, we noticed that this practice would artificially inflate the precision measures on full text.

instead of benchmarking the performance of gene/protein name tagging in the text, we thus benchmark the performance of extracting the names of gene/proteins mentioned in a given article. we evaluate this by counting errors and success at the level of unique terms. since this protocol is different from the ones used in other published studies, performance measures that we report cannot be compared to other published measures. another factor that renders such comparison meaningless is the difference in the input material. we show in tables  <dig> and  <dig> that the performance of a given method varies widely from article to article. our validation protocol, however, compares the performance of several methods on the same input material, using the same evaluation measures and therefore supports objective comparisons between the methods benchmarked.

relative recall helps compare several methods
obtaining accurate measures of coverage is challenging because coverage requires counting the number of correct protein names in an article. several factors make obtaining these counts more difficult for full text than for abstracts.  full texts refer to a large number of protein names in all the sections of the paper .  it is difficult for human annotators to identify all spelling variants of protein names that automated methods may identify. to alleviate the impact of these factors on the evaluation, we presented annotators with names identified by each prediction method. in practice, this procedure guarantees that annotators consider each name variant predicted by one of the methods and determine if the name refers to a protein. the protocol thus helps avoid omissions that can occur when annotators are not familiar with the subject of the article, and directly provides the annotation counts  required to calculate the relative recall measure .

building the catalog
our method creates a catalog of protein and gene name references directly from full length noisy article materials. tanabe and wilbur recently described a method to assemble a gene/protein lexicon from the text of abstracts  <cit> . while there is certainly an overlap between protein names used in abstract and in full text, it is not clear what the extent of the overlap is. thus, our method and the one presented by tanabe and wilbur should be complementary. finally, our study of the quality of the protein catalog in a common application , demonstrates the utility of direct name extraction from full text articles.

CONCLUSIONS
our results show that a pure dictionary-based lookup method can outperform nlprot  <cit>  on full text articles, when using a dictionary built directly from the same type of source material . we have presented a method that can build such a focused dictionary from a large corpus  of articles. the method is computationally efficient. we freely distribute the dictionary that we have built to carry out our evaluations and a program that can extract names of proteins from full length articles.

our method is robust to various sources of noise found in full length articles and achieves a state of the art level of precision on this material. a key element that contributes to the robustness of our method seems to be that we never extract a name from an article as a protein name based only on the morphology of the term, but instead require that the term is predicted several times as a protein name in other articles. this robustness may be the result of considering an array of evidence, found in the sentences from several articles, to determine if a term is likely to refer to a gene or gene product, and reusing this knowledge again and again. in its current state, an outstanding limitation of our approach is its inability to deal with certain types of term ambiguity . this is an area for improvement that will require further research.

