BACKGROUND
major histocompatibility complexes  bind short peptides derived from antigens and present them on the cell surface for inspection by t-cells. the binding mechanism appears to be the most selective step in the recognition of t-cell epitopes. the molecular mechanisms underlying this selectivity are still debated  <cit> , but a crucial factor is the complementarity between amino acids in the antigen peptide and the mhc binding pocket  <cit> . successfully modelling the behaviour exhibited by mhcs can be used to pre-select candidate peptides, which, in turn, can limit the practical work involved and facilitate the search for new vaccines.

mhc alleles are grouped according to their structure. for class i mhc alleles, the binding groove is closed at both ends, making it possible to predict exactly which residues are positioned in the binding groove. for class ii mhc molecules, the binding groove is open at both ends and peptides which bind class ii alleles are generally longer than those which bind class i mhcs, typically  <dig> to  <dig> residues. moreover, the grooves of mhc class ii alleles will only accommodate  <dig> to  <dig> residues of the target peptide  <cit> . thus class ii peptides have the potential to bind to the mhc groove in one of several registers .

interaction, within the groove, between mhc and peptide side chains is generally considered the principal determinant of binding affinity  <cit> . however, for mhc class ii type alleles, a recent study speculates that binding may not be completely deterministic, and that the same peptide can have multiple possible binding cores  <cit> . moreover, several studies have shown that the binding core is, indeed, not the only factor; residues outside the binding groove  can also interact with the mhc molecule and influence binding  <cit> . hence, this creates additional complexity in determining which residues are involved in the interaction, and suggests that a suitable method must include a full-length representation of the peptide.

numerous methods have been applied to the problem of predicting mhc binding. prediction of mhc class i binding has been very successful, reporting prediction accuracies of up to 95% . attempts at predicting class ii mhc binding show significantly lower accuracies, although many efforts using both traditional and novel approaches have been applied, some demonstrating inspirational progress.

in recent years, efficient pattern recognition methods have been applied to the class ii problem, such as artificial neural networks  <cit>  and support vector machines  <cit> . however, these methods are based on inductive learning and require fixed-size representations to perform attribute-by-attribute comparisons of input variables. a typical approach for such methods is to first estimate  a binding core, and subsequently predict the binding affinity of an unknown peptide based on the estimated core . this 2-step process is convenient from a mathematical modelling perspective, because it restricts the prediction task to a fixed-length formulation  and thus avoids the problem of handling variable length peptides. the subsequent conversion of the 9-mer amino acid representation into a numerical representation is achieved by using either a binary positional system with  <dig> inputs per amino acid  <cit> , or by using amino acid properties  <cit> . the results are fixed-length, high-dimensional, input vectors used for training the model .

approaches for solving the dynamic nature of the prediction problem, and which can handle the variability in peptide lengths, have shown promising prediction qualities. methods include an iterative "meta-search" algorithm  <cit> , an iterative partial least squares method  <cit> , hidden markov models  <cit> , an ant colony search  <cit> , and a gibbs sampling algorithm  <cit> . some of these novel approaches have produced remarkable results, significantly outperforming conventional approaches.

the method presented here aims to combine the advantages of the two approaches: it utilises an efficient fixed-length discriminative method, but is still able to handle variable length peptides. this is achieved by applying a customised kernel.

kernel methods have become popular thanks to support vector machines , originally introduced by vapnik  <cit> . they have been applied to multiple bioinformatical problems, and have shown excellent performance using real-world data sets . in its basic form, a single svm is a binary classifier which learns a decision boundary between two classes  in some input space . to find a decision boundary between two classes, an svm attempts to maximise the margin between the classes, and choose a linear separation in a feature space. a function called the kernel function k  is used to project the data from input space to feature space, and if this projection is non-linear it allows for non-linear decision boundaries. the effectiveness of svms is due to two factors: a) the principle of maximising margins  and b) using the kernel trick to extend linear methods so that they can address non-linear problems. details of the svm formulation have been described thoroughly in many books and publications .

an advantage of kernel methods, which render them particularly suited for problems in computational biology, is the ability to customise the kernel. the kernel can be seen as a distance measure between two samples, e.g. in the case of a linear kernel the euclidean distance between two samples. a custom kernel can be used to define explicitly a distance measure between two samples, and thus knowledge-based kernels can be designed to process variable length data and convert samples into fixed-length representations needed for direct comparisons. for sequences of proteins, it can be used to define similarity measures between pairs of sequences . methods utilising such direct kernel functions have lead to significant improvements in performance on classical bioinformatical problems, such as remote homology detection  <cit>  and protein classification  <cit> .

in this paper, we present a kernel method based on the direct kernel function of  <cit> , which we have adapted to the problem of predicting mhc binding. the local alignment kernel is a kernel quantifying the similarity between a pair of protein sequences by taking into account all possible optimal alignment scores between all possible sub-sequences.

RESULTS
using several sets of data , a method for the prediction of class ii epitopes was developed and subsequently optimised. initially, the effect on accuracy of varying the two parameters of the model was explored; these include a regulatory parameter β and a substitution matrix s , which are both described in detail below. tests were then run to compare the performance of this kernel approach with existing prediction methods.

overview of the benchmark data sets. mhcbench sets 1– <dig> contain data from the hla-drb1* <dig> allele. mhcpep consists of data from numerous alleles, with  <dig> mhc class ii and a single mhc class i allele selected.

optimising the β-parameter
the kernel is based on similarity scores between pairs of peptides. for each pair, a similarity score is composed of multiple sub-scores based on alignments between pairs of sub-sequences. the model parameter β regulates the relative influence that each sub-score will have on the cumulative score. in turn, it enables adjustment of the importance of sub-optimal alignments.

experiments were undertaken to evaluate the effect on performance of varying the β-parameter using a simple test set. the mhcbench set 4b was chosen for this purpose; it contains experimentally verified binders and non-binders of hla-drb1* <dig>  it consists of only natural peptides and an equal number of binders and non-binders , which makes it well-suited for model testing.

the blosum <dig> substitution matrix was used for s . this matrix is generally considered to be a good matrix for modelling evolutionary problems  <cit> . 10-fold cv was used to evaluate performance, and a rough search for a good β-parameter was undertaken. the effect on performance of varying β can be seen in figure  <dig>  which shows that the skm is capable of distinguishing well between binders and non-binders. the best accuracy is  <dig> % at β =  <dig> . the best performance in terms of aroc is  <dig>  at β =  <dig> . generally, the best results for most measures are found for β-values between  <dig>  and  <dig> . higher β values of  <dig>  to  <dig>  were also evaluated, but as β becomes larger performance degrades for all measures.

bootstrapping using case resampling  <cit>  was performed to analyse the variance in results.  <dig> repetitions were undertaken, with data set sizes of  <dig>  at a β-value of  <dig> , which produced the best accuracy in the tests referred to above, the average bootstrapping accuracy was  <dig> % with a standard deviation of  <dig> %. this degree of variance was found throughout our experiments.

interestingly, a low β indicates that the best solution is found when sub-optimal alignments have a large influence, as seen by the mathematical formulation below; when lowering the β-value, the relative contributions from scores of various alignments are evened out. this tendency was observed throughout the remaining experiments, with most "optimal" β-values being below  <dig> . interestingly, the same observation regarding the positive influence of sub-optimal alignments was also reported in nielsen et al  <cit>  using a very different method.

selecting the substitution matrix
a substitution matrix was used in the calculation of the smith-waterman score to evaluate similarities between amino acids . the blosum <dig> matrix initially used is regarded as a good descriptor for evolutionary problems  <cit> . however, using an alternative substitution matrix could prove more effective.

the aaindex database  <cit>  contains a large collection of substitution matrices produced during the last three decades. the matrices are based on numerous different measures, such as physicochemical properties and structural differences. an extensive search among the substitution matrices was conducted. each substitution matrix was used instead of the blosum <dig> matrix as above. due to the scale of the experiment, only a crude search using  <dig> values of β was evaluated per substitution matrix. from the  <dig> matrices, the ten best performing substitution matrices with regard to aroc scores were retested with a refined search for the best value of β. the  <dig> best performing substitution matrices from this experiment are shown in table  <dig> 

evaluating performance for using different scoring matrices using 10-fold cv. the test measurements are same as in previous experiment. best values are shown in bold.

as can be seen from the table, the three matrices have very similar aroc values. the best performance was produced by a recently developed substitution matrix sm_threader_norm, which is based on molecular mechanics force fields.  <cit>  suggest that force fields can provide more reliable mutation matrices because of the incorporation of natural weighting of different physical contributions. interestingly, the blosum <dig> matrix is among the best three matrices out of  <dig>  this suggests that the evolutionary rationale behind blosum <dig> is also appropriate for mhc peptide similarity or that the chemical similarities underlying protein evolution also underlie peptide selectivity by the mhc. such conjecture is supported in part by the fact that the sm_threader_norm is also placed in the same family of substitution matrices when assessing the magnitude of distances between matrices  <cit> . in the following experiments, the sm_threader_norm is used.

performance on hla-drb1* <dig> and hla-drb1*0301
two mhc class ii alleles from the mhcbn database  <cit>  were evaluated. the mhcbn database contains  <dig> binders and  <dig> non-binders for hla-drb1* <dig> and for hla-drb1* <dig> contains  <dig> binders and  <dig> non-binders. duplicates and peptides with 75% or more alanines were removed. 5-fold cross-validation was undertaken , and a crude optimisation of the β-parameter was performed as described in the methods section. results are shown in table  <dig>  the table reports comparison results from two other methods, a linear programming model "lp_top2"  <cit>  and tepitope, a quantitative matrix method  <cit> .

results of 5-fold cross-validation with best results shown in bold. results from lp_top <dig> and tepitope are taken from  <cit> . measurements are same as previously reported, except for aover-roc, which is the area over the roc curve. aroc =  <dig>  is perfect classification, so aover-roc, 1- aroc, can be seen as an error measure.

the results in table  <dig> show that the skm method performs significantly better than lp_top <dig> and tepitope. the relative improvements in aroc scores are 8% and 41%, and the improvements in aover-roc are 37% to 60%. other methods have also been evaluated on the data sets. in  <cit> , results on two methods using hidden markov models combined with successive state splitting are reported. the best 10-fold cv results were  <dig>   and  <dig>  , which are close to but still lower than the  <dig>  aroc of skm using 5-fold cv; using 10-fold cv the skm performance increases to  <dig>  aroc.

performance on allele hla-drb1*0401
mhcbench  <cit>  contains  <dig> data sets of binders and non-binders for hla-drb1* <dig>  again, the skm was evaluated using 10-fold cross validation, and a crude search for optimal values of β was performed for each set. aroc performance from all  <dig> sets are reported in table  <dig>  which also includes results of perun, a method based on tepitope  <cit> , neural networks  <cit> , gibbs sampler, a method based on metropolis sampling  <cit> , and lp_top <dig>  a linear programming method  <cit> .

comparing performance of skm with results reported for the gibbs sampling method  <cit> , "lp_top2"  <cit> , and perun  <cit> . best results shown in bold.

1: best reported results, where cysteines are treated as alanines  <cit> .

2: best reported results of  <cit> .

results of the lp_top <dig> and gibbs sampler are from evaluation on the mhcbench sets. however, as is described in  <cit> , training was performed on a training set consisting of selected samples from mhcpep  <cit>  and syfpeithi  <cit> . however, mhcbench mainly consists of samples from mhcpep, and a large overlap exist between training and test sets .

the results on table  <dig> show that the skm is significantly better on  <dig> out of  <dig> benchmark sets . on sets 5a and 5b, another method, lp_top <dig>  scored the best results . the relative lower accuracies of the skm method on these two data sets may be due to the small training set sizes ; in training, the skm method selected nearly all training samples as support vectors, indicating there may not be sufficient samples to properly describe the model space.

alleles from mhcpep
all mhc class ii alleles from the mhcpep database were evaluated. this database contains only binders, with binding strengths graded from low to high. an extensive number of alleles were tested, making it hard to obtain known non-binders for the sets. one approach is to use binders from other alleles as non-binders for the allele of interest. however, more than 10% of peptides were found to bind two or more alleles, which would generate a large amount of noise and uncertainty in predictions if used as non-binders. instead, the non-binders were generated randomly in order to have the same length-distribution as the set of binders. yewdell et al estimated that only one in  <dig> to  <dig> peptides will bind to an average allele  <cit> , which makes this approach a reasonable approximation. moreover, generating an equal amount of binders and non-binders creates a balanced data set well suited for computational experiments.

for each allele, the data set was extracted from mhcpep and evaluated using 10-fold cv. as in previous experiments, a crude search for the best value of β was conducted. the results can be seen in table  <dig>  the skm is able to model multiple mhc class ii alleles well, with an average aroc of well over  <dig>  in all cases except for hla-dr <dig>  which is a data set containing only  <dig> binders. overall, the average performance  is competitive  compared with literature results.

evaluating performance on multiple alleles using 10-fold cv. average scores shown underneath, weighted by number of samples.

1all binders belonging to a group of alleles.

in  <cit> , internal test sets of * <dig> and * <dig> extracted from mhcpep were predicted with  <dig>  aroc and  <dig>  aroc, respectively. in comparison, the corresponding results for the skm are  <dig>  and  <dig> . in  <cit> , an iterative stepwise discriminant analysis was run on  <dig> hla-dr <dig> high and moderate binders from mhcpep and  <dig> non-binders. classification accuracy using jack-knife cross-validation was  <dig> %. here, the overall classification accuracy is slightly better at  <dig> %.

in  <cit> , a fuzzy neural network, combined with  <dig> amino acid property descriptors, was used to separate high, moderate and low binders from non-binders of hla-drb1* <dig>  of the  <dig> binders and  <dig> non-binders collected for the allele, the highest performance was on strong  binders vs. non-binders with an accuracy of  <dig>  aroc. however, for moderate and low affinity binders, their results were  <dig>  and  <dig> , respectively. for the skm, the average aroc value for all binders vs. non-binders is  <dig> .

in  <cit> , an ensemble classifier based on support vector machines with a representation using qsar descriptors achieved  <dig>  aroc on a data set consisting of 9-mers of hla-dr <dig>  as in this study, non-binders were generated randomly. the performance of the skm  on hla-dr <dig> is significantly higher.

discussion
the proposed kernel method is shown to provide excellent discrimination between binders and non-binders for multiple alleles. it is able to model the dynamic mhc class ii problem, and produce results that compare favourably with previously published results. the reason for the good performance may be due to several factors, and it is important to identify which of these are the most significant. the main focus of modelling was to consider the full length of peptides, as studies have shown that peptides outside the binding core can influence binding affinity  <cit> . avoiding estimation of binding cores eliminates the potential for using faulty alignments, which can lead to increased model noise and, in turn, lower accuracy.

the use of similarity scores is a significant conceptual change in peptide evaluation, quantifying the overall similarity between peptides and interrelations between residues. this concept contrasts to the fixed-length representation  which enforces a direct pocket-to-pocket comparison of residues. most static pattern recognition methods consider each input property to be a separate and independent entity, which is clearly not the case for a peptide string. instead, higher order interactions within the peptide may also make a significant contribution to the modulation of affinity. hattotuwagama et al. showed that the motif-dependence of class ii peptides is even weaker than that of class i epitopes  <cit> . modelling such subtle effects, also seen in x-ray structures, are beyond the scope of much existing prediction technology. this change in concept could be a significant reason for the improved performance. incorporating sub-optimal alignments into similarity scores have certainly contributed to an observed improvement, where low values of β produced the best performance.

kernel methods, such as support vector machines, have previously been shown to work well on biological problems, particularly when custom engineered kernels are used  <cit> . the svm itself and the training principle of structural risk minimisation may have contributed to enhanced performance. however, simply applying svms to the mhc problem using aligned and truncated peptides , in combination with a binary representation of amino acids similar to  <cit> , did not produce promising results in initial experiments; custom kernels must be used to take full advantage of the kernel machines' excellent capacity for generalisation. another advantage of using kernel methods is the ability to choose a kernel method independent of the choice of kernel itself. thus, a kernel can readily be combined with a range of different kernel methods. this is useful when certain properties of the predictor are desired; e.g. some kernel methods can handle large-scale data sets while others allow for probabilistic interpretation of outputs.

naturally, the proposed method is not without it's disadvantages. firstly, the method is purely data-driven, in the sense that it relies solely on information derived from peptide data sets and thus does not consider mhc allele-specific structural information about the binding groove. while this may be seen as an advantage, since it keeps assumptions to a minimum, potentially important information is not considered, such as a specific pockets' preference for certain amino acids. secondly, the method does not attempt to estimate alignments, which may be of interest, and finally, computational complexity and run-time speed could also be an issue for large scale testing. calculating the kernel is time-consuming even with an efficient implementation; it cannot currently handle more than a few thousand samples before run-time becomes prohibitive.

many potential improvements are possible that could either improve classification accuracy or provide more informative results. more advanced kernels could be developed: by increasing the importance of similarity scores of certain sized windows  and subsequently weighting each residue in the window according to known binding motifs . this would have the advantage of incorporating allele-specific information into the method. other improvements include modifying the kernel method to improve training or classification speeds, and developing new substitution matrices specific to the mhc domain similar to that undertaken for trans-membrane proteins  <cit> . finally, the binary classification could be extended to a multi-class problem , or directly predicting binding affinity by kernel regression, as lui et al  <cit>  has done for class i.

CONCLUSIONS
the combination of a complex similarity score and an efficient kernel method are shown here to be a powerful tool for predicting mhc class ii peptide binding affinity. the principle of using kernels to define similarities between sequences explicitly is a simple, yet flexible and powerful, way of modelling sequence data, and can readily be extended to address a variety of immunological and other biological problems.

