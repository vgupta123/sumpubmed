BACKGROUND
a key step in the process of gene regulation is the binding of transcription factors to specific cis-regulatory regions of the genome, usually located in the proximal promoter upstream of target genes or in distal enhancer regions  <cit> . each transcription factor recognizes and binds to a more or less distinct nucleotide pattern – a motif – thereby regulating the expression of the nearby gene. determining the location and specificity of each transcription factor binding site in the genome is thus an important prerequisite for reconstructing the gene regulatory network of an organism.

since establishing these binding sites experimentally is a rather laborious process, much effort has been made to develop methods that can automatically discover such binding sites and motifs directly from genomic sequence data. more than a hundred methods have already been proposed  <cit> , and new methods are published nearly every month. there is a large diversity in the algorithms and models used, and the field has not yet reached agreement on the optimal approach. most methods search for short, statistically overrepresented patterns in a set of sequences believed to be enriched in binding sites for particular transcription factors, such as promoter sequences from coregulated genes or orthologous genes in distantly related species.

in higher organism, however, transcription factors seldom function in isolation, but act in concert with nearby bound factors in a combinatorial manner to induce specific regulatory behaviours. a set of binding motifs associated with a cooperating set of transcription factors is called a composite motif or cis-regulatory module. in recent years, the field of computational motif discovery has therefore shifted from the detection of single motifs towards the discovery of entire regulatory modules.

the diversity of approaches to module discovery is even greater than for single motif discovery, and methods vary widely in what they expect as input and what they provide as output. for instance, methods like co-bind  <cit> , logos  <cit>  and cismodule  <cit>  expect only a set of coregulated or orthologous promoter sequences as input and are able to infer both the location and the structure of modules with few prior assumptions regarding their nature. these programs infer an internal model that includes a representation of each individual transcription factor binding motif as well as constraints on the distances between them. on the other hand, programs such as lra  <cit>  and hexdiff  <cit>  demand as input a collection of already known module sites to serve as training data. the known positive sites are used along with negative sequence examples to build a model representation which can then be compared to new sequences in order to identify novel module instances. searching for new matches to a previously defined model might be considered a special case of module discovery and is often referred to as module scanning. programs that specialize in searching for modules this way without inferring the models themselves include moduleinspector  <cit>  and modulescanner  <cit> . the general problem of module discovery, however, usually involves inferring both a model representation of the modules and to find their locations in the sequences.

most module discovery methods require users to supply a set of candidate single motif models in the form of iupac consensus strings or position weight matrices   <cit> . these are used to discover putative transcription factor binding sites in the sequences, and the programs then search for significant combinations of such binding sites to report as modules.

what constitutes a significant combination varies between methods. mscan  <cit> , for instance, searches for regions within sequences that have unusually high densities of binding sites, more so than would be expected from chance alone. the types of the binding motifs are irrelevant, however, and each potential module instance is analyzed independently from the rest. other tools, like modulesearcher  <cit> , composite module analyst  <cit>  and creme  <cit> , search for specific combinations of motifs that co-occur multiple times in regulatory regions of related genes.

with an increasing number of programs available, both for single and composite motif discovery, there is a growing need among end users for reliable and unbiased information regarding the comparative merits of different approaches. a few independent investigations have been undertaken to assess the performance of selected single motif discovery methods, for instance by sze et al.  <cit>  and hu et al.  <cit> . the most comprehensive benchmark study to date was carried out by tompa et al. and included thirteen of the most popular single motif discovery methods  <cit> . the authors of this study also provided a web service to enable new methods to be assessed and compared to the original methods using the same datasets.

however, in spite of the increased interest in regulatory modules, we are not aware of any similar independent benchmarking efforts that have been undertaken with respect to composite motif discovery.

RESULTS
we have developed a framework for assessing and comparing the performance of methods for the discovery of composite motifs. sequence sets containing real, experimentally verified modules are made available for download through our web service, and users can test programs of their own choice on these datasets and submit the results back to the web service to get the predictions evaluated. results are presented both as tabulated values and in graphical format, and performances of different methods can be compared. since most module discovery tools require users to input candidate motifs, each sequence dataset is supplemented by a set of pwms capable of detecting the binding sites involved in the modules. to test how programs respond to varying levels of noise in the pwm sets, we created extended pwm sets for one of our datasets where the genuine matrices were mixed with various decoy matrices.

scoring predictions
we adopted a simple and general definition of a module: a module is a cis-regulatory element consisting of a collection of single binding sites for transcription factors. a module is thus characterized by only two aspects in our framework: its location in a sequence and its composition, that is, the set of transcription factor binding motifs involved. a module's location is further defined as the smallest contiguous sequence segment encompassing all the single binding sites in the module, including also the intervening bases. for our purpose, the composition of a module is represented by a set of pwm identifiers. different modules that share the same composition are said to belong to the same module class. module class definitions may also be limited by structural constraints. these are rules governing, among others, the strand bias, order and distances between the transcription factor binding sites of modules of the same class. since it requires a substantial effort to determine these constraints experimentally, this kind of information is available for a very limited number of classes. few methods also report such module constraints explicitly. consequently, we have chosen not to consider this aspect of modules further in our framework, at least for the time being.

module discovery programs are requested to predict both the location of modules and to identify the motifs involved by naming the proper pwms. however, not all programs are able to perform both these tasks. the mcast program  <cit> , for instance, only reports the location of predicted modules, even though it uses a set of pwms to detect single binding sites internally. on the other hand, programs that discover single motifs de novo without relying on pre-constructed matrices have, of course, no way of correctly naming the motifs involved. methods like that of perco et al.  <cit>  and gcmd  <cit>  identify modules by looking for groups of pwms whose binding sites consistently appear together in multiple sequences, but disregard any further information about the precise position of these sites. hence, such programs only report the composition of modules but not their location. by assessing the location and composition aspects of modules separately, our framework can equally well be used with programs that predict only one or the other.

to measure prediction accuracy of methods with respect to module location, we have used the nucleotide-level correlation coefficient . this statistic has been widely used before, among others, for coding region identification and gene structure prediction  <cit> . it was also adopted by tompa et al. to evaluate binding site predictions in their single motif discovery benchmark study. the value of ncc lies in the range - <dig> to + <dig>  a score of + <dig> indicates that a prediction is coincident with the correct answer; whereas a score of - <dig> means that the prediction is exactly the inverse of the correct answer. random predictions will generally result in ncc-values close to zero.

 ncc=tp⋅tn−fn⋅fp 

here, tp is the number of nucleotides in a sequence that are correctly predicted by a program as belonging to a module, while tn is the number of nucleotides correctly identified as background. fn is the number of true module nucleotides incorrectly classified as background, and fp is the number of background nucleotides incorrectly classified as belonging to a module.

a similar statistic, the motif-level correlation coefficient , was used to evaluate prediction accuracy with respect to module composition. the definition of mcc follows that of ncc, except that instead of counting the number of nucleotides, we count the number of single motifs  correctly or incorrectly classified as being part of a module or not. hence, for mcc, tp is the number of pwms correctly identified as constituents of the module, while fp is the number of pwms incorrectly predicted as being part of a module. note that the correlation statistics, as defined here, are only applicable when both the datasets and the predictions made by a program contain a combination of module and non-module instances, if not, the divisor will be zero and the value of the statistic will be undefined. consequently, the mcc-score is only informative when the set of pwms supplied to a module discovery program contains false positives, i.e. additional matrices besides those that are actually involved in the modules. final scores for each dataset are obtained by summing up tp, fp, tn and fn over all sequences before calculating the correlation scores. if no module predictions are made on a set of sequences, the resulting scores for ncc and mcc are assigned a value of zero rather than being left undefined. in addition to cc scores, several other statistics mentioned in  <cit>  such as sensitivity, specificity, positive predictive value, performance coefficient  and average site performance are calculated for both nucleotide- and motif-level.

datasets
we compiled three datasets from sequences containing experimentally verified regulatory modules. the first and the last two datasets have different characteristics and were chosen to complement each other to test methods under different conditions.

our main dataset was based on annotated composite motifs from the transcompel database  <cit> . the modules selected for this dataset are small, each consisting of exactly two single binding sites for different transcription factors , but we specifically chose modules that had multiple similar instances in several sequences. sequences containing modules from the same class were grouped together producing ten sequence sets named after their constituent single motifs as shown in table  <dig>  each of the sequences in a set contained at least one copy of the module with the same two motifs, but the order, orientation and distance between the tfbs could vary between sequences. separate pwm collections, with matrices for the two single motifs involved, were constructed for each of the sequence sets. all in all there were eleven distinct single tf binding motifs in our full transcompel dataset, and pwms representing these motifs were collected from the companion transfac database  <cit> . since transfac often contains several different pwms for each motif, we grouped all the matrices corresponding to a particular motif into an equivalence set, essentially treating these pwms as if they were one and the same with respect to prediction and scoring. in addition to the transfac matrix sets, we also constructed eleven custom matrices that were specifically tailored to the particular motifs and binding sites present in the sequences . assessment of module discovery programs on the transcompel dataset was conducted using both the transfac sets and the customized pwm sets independently. the motivation for using two different pwm sets was to test the stability of methods and examine how the specific representations used for single motifs might influence the ability of methods to find the correct modules.

a brief overview of the ten transcompel sequence sets and the liver and muscle datasets used in the assessment. further information can be found in additional file  <dig> 

the two last datasets were based on combinations of tfbs found in the regulatory regions of genes specifically expressed in liver  <cit>  and muscle  <cit>  cells. the modules here are usually larger compared to the transcompel modules, containing up to nine binding sites for four different motifs in the liver regulatory regions and up to eight sites for five motifs in the muscle regions. pwms for these motifs were taken from the respective publications. the composition of the modules in these two datasets is variable; modules can contain multiple binding sites for the same motifs and not all motifs are present in every module.

while most programs require candidate pwms to be entered, this can pose a problem for users who might not always know in advance the kind of modules that should be present in a sequence or which transcription factors that might bind. it could be the case, for instance, that a researcher has only a set of promoters from a coregulated set of genes and is interested in identifying the hitherto unknown module that controls the common expression of these genes. a popular strategy then is to employ an excessive set of pwms which, hopefully, also includes the appropriate matrices. an extreme, but not unlikely, scenario would be to use all the matrices available from a published compilation like transfac  or jaspar  <cit>  . although this approach will inevitably lead to lots of false positive pwm matches that might thwart the module discovery process, good module discovery tools should nonetheless be able to report the true module instances without simultaneously predicting too many spurious occurrences.

to simulate these conditions and test methods' response to noisy pwm sets, each pwm set under the transcompel dataset was issued in multiple versions with progressively more decoy matrices added to the set of true annotated motifs. decoy matrices were randomly sampled from the complete transfac compilation after removing the matrices corresponding to the true motifs for a sequence set. decoy sets are available at 50%, 75%, 90%, 95% and 99% levels, where the percentage number relates the amount of decoy matrices in the set. thus, a custom pwm set at the 90% level includes  <dig> genuine matrices and  <dig> decoy matrices. the number of decoy matrices in the transfac pwm sets varies with each module class but is always higher than for the custom sets at the same percentage level. information on the exact number of pwms in each set is available in additional file  <dig>  the 99% sets include as decoys all of the matrices from transfac which do not correspond to the correct motifs. they are called "99%" for consistency, although the actual percentage of decoys ranges between 95% and 99% depending on the module class. to avert artefacts stemming from possibly biased selections of decoys, all decoy sets  consist of ten independently sampled decoy collections, and the final correlation statistics for a decoy level are calculated by averaging prediction scores made from using each collection in turn. this also means that variation due to any stochastic nature of algorithms will be averaged over ten independent runs.

benchmark of module discovery methods
using our assessment framework, we benchmarked eight published methods for module discovery: cismodule  <cit> , cister  <cit> , cluster-buster  <cit> , composite module analyst   <cit> , mcast  <cit> , modulesearcher  <cit> , mscan  <cit>  and stubb  <cit> . see table  <dig> for brief descriptions of each of these methods. cismodule, cma and modulesearcher process all the sequences in a dataset simultaneously and look for instances of similar modules across multiple sequences. the other methods examine the sequences individually, although stubb considers multiple instances of similar modules within the same sequence. except for mcast, which does not report module composition, all the programs report both the location and composition of modules. cismodule, however, predicts modules de novo without relying on supplied pwm sets and so does not name the single motifs involved the way we require. hence, motif-level scores were not calculated for mcast and cismodule. cluster-buster and mcast report the full module segments, while the rest of the methods list the positions of the pwm hits in the modules. in these cases we extracted the start position of the first reported binding site and the end position of the last binding site and used these as the boundaries of a module prediction.

the table contains short descriptions of the eight methods included in the assessment. all methods except for cismodule rely on supplied pwms and consider matches on both strands, usually with equal probability . not all methods are able to consider overlapping single binding sites, which do occur in a few modules.

we generally relied on default parameter settings for all programs. however, since choosing the proper parameter values can sometimes prove crucial for a method's performance, we decided to provide the programs with a few general clues where applicable; specifically, that the size of modules should not exceed  <dig> bp  and that the modules should consist of exactly two single binding sites for different tfs in the transcompel dataset but possibly up to ten binding sites for four and five different tfs on the liver and muscle sets respectively. furthermore, binding sites could potentially overlap and the composition of the modules in liver and muscle sets should be allowed to vary between sequences.

figures 1a and 1b show the resulting nucleotide-level correlation scores on each sequence set in the transcompel dataset when methods were supplied with transfac matrices and custom matrices respectively. the scores vary widely between individual sequence sets but are generally fairly well correlated between methods, so that most methods tend to get high  scores on the same sets. the notable exception is cismodule which performs poorly on all sequence sets. the correlation suggests that some sequence sets are inherently more easy  to tackle than others. scores for cebp-nfκb and irf-nfκb are the highest overall. the reasons why these sets are generally easy to predict might be that their modules are quite long and the matrices representing the single binding motifs have high information content . conversely, the short size of the modules and the low information content of pwms for ap1-nfat would make this a hard sequence set. we also calculated combined scores for the whole transcompel dataset which are shown in the inset legends of figure  <dig> and graphically in figure  <dig>  these combined scores were obtained by summing up tp, tn, fp, fn over all sequence sets when calculating the score measures. the highest combined ncc scores achieved were  <dig>  with the transfac matrices  and  <dig>  with custom matrices . the average performances across all methods were also about the same with the two pwm sets. some methods performed quite differently depending on the pwms, however. for instance, mcast scored much better using custom matrices than with transfac matrices, while mscan and cluster-buster did a better with job with transfac. the rank order of methods is thus somewhat altered between the two cases. still, some tendencies remain: cma, cluster-buster, mcast, modulesearcher and mscan occupy the top five positions in both cases, followed by cister and stubb and then finally cismodule which consistently scored lowest.

we conducted a simple correlation analysis to examine which properties of the transcompel sequence sets and pwms correlated best with the highest and average ncc scores obtained by the methods on these sets. "ic-content " is the information content  of the pwm with the lowest ic of the two involved in each sequence set. the information content of a pwm is inversely related to the amount of variability in the binding patterns from which the pwm is constructed  <cit> . pwms with higher information content are more specific and match only sites with a high degree of similarity to the consensus motif. "ic-content " is the sum of ic-contents for the two motifs . the three highest values are highlighted in each column. the properties that seem to correlate best with methods' performances are the minimum and average size of modules  and the total ic-content, which would imply that module discovery is harder for datasets containing short and degenerate modules.

figures  <dig> and  <dig> show score tendencies as increasingly more decoys are added to the pwm sets. the nucleotide-level performances of cma and modulesearcher are only slightly affected by the larger amounts of decoys, whereas the scores for the other methods steadily decline. at the motif-level we clearly see a division into two groups with cma and modulesearcher performing significantly better than the rest. additional graphs detailing the effects of added noise with respect to each individual sequence set and the variations due to different decoy selections can be found at our web site.

results for the liver and muscle datasets are shown in figures  <dig> and  <dig>  for these datasets we supplied only four liver- and five muscle-pwms respectively, and no decoy matrices were used. since the modules in these datasets do not necessarily include binding sites for all of these motifs however, we could calculate motif-level scores by treating the pwms for the missing motifs as false instances. all methods, except cismodule, did a better job on locating the modules in the liver dataset than in the transcompel dataset. cluster-buster scored highest, but stubb showed the largest improvement in ncc score. the motif-level scores, on the other hand, were not very high, which can most likely be attributed to overprediction of motifs in the case of cma and underprediction for mscan. results on the muscle dataset display the same main tendencies as the other two datasets, but for the first time, cismodule obtains an ncc score above zero and actually bypasses one the other methods.

discussion
objective benchmarking efforts are important for providing unbiased reviews of published methods and for establishing the methodological frontier with respect to bioinformatics techniques. in this study we wanted to explore benchmarking in the context of module discovery and to investigate related design issues such as dataset construction and performance evaluation.

benchmarking of tools for composite motif discovery is harder than benchmarking of single motif discovery tools, since the former methods are more diverse with respect to input requirements and the type of predictions they make. we have aimed at creating a simple and general framework that can be used with a wide range of methods. nevertheless, we do not provide every kind of information that programs might ask for, and not all module discovery tools can be fairly assessed with our system.

to construct the benchmark datasets we relied on real genomic sequences containing experimentally verified modules, rather than creating synthetic datasets with fabricated and planted modules. the motivation for only using real data was to avoid introducing artificial bias related to the composition and constraints of modules. good benchmark datasets should be diverse enough to discriminate the behaviour of different methods, when possible, and provide them with a wide range of realistic challenges. for module discovery these challenges could include discovering modules with few or many single motifs, tightly clustered or widely spaced motifs and modules with highly conserved or degenerate binding sites. ideally, benchmark datasets should also be novel to the methods tested. currently the amount of experimental data available is too limited to achieve all of these goals. the particular dataset we have constructed based on transcompel data is novel in terms of performance testing. the modules in transcompel are short, however, and to include larger modules we were forced to rely on a few well-known datasets from liver and muscle regulatory regions that have been used extensively in the past for testing and possibly for designing and developing module discovery methods. some methods might therefore be intrinsically biased to perform well on these sets. it is conspicuous, for instance, that cismodule – which was tested with muscle data in its original publication – scored comparably well to the other methods on our muscle set, yet close to zero on both the transcompel and liver datasets.

we chose the correlation coefficient as our main statistic for evaluating and comparing module discovery methods because it captures aspects of two of the most commonly used performance measures – sensitivity and specificity – into a single score value. however, since different statistics often favour different methods, it is prudent to consider several measures to get a better comprehension of each method's qualities. the sensitivity measure , for instance, tells us to what extent a method's predictions include the true module instances. at the nucleotide level, mcast seems overall to be the most sensitive method among those tested here, while cma shows high sensitivity on the transcompel dataset. yet, to achieve these high sensitivity scores the methods at the same time make a lot of false positive predictions, as can be seen from the lower positive predictive values . mscan and modulesearcher, on the other hand, generally have the highest nucleotide-level ppv scores, which tells us that the positive predictions made by these two programs are more trustworthy than predictions made by the other programs.

pwms from the transfac database were used to represent both the true motifs and the decoys for the transcompel dataset. a potential problem when using transfac is that many of the matrices are quite similar to each other  <cit> . this is partly due to some tfs being represented by several pwms, but also because different tfs might bind to similar-looking motifs. as a result, module discovery programs can be unduly penalized for selecting an incorrect pwm at the motif level, even though the predicted pwm is very similar to the target. we have tried to remedy this situation by grouping together pwms that correspond to the same tfs and consider these as the same motif with respect to scoring. however, there might still be other matrices in the decoy sets that can match with the annotated binding sites.

since we are using real genomic sequences, some of the predicted modules that we label as false positives can in fact represent unannotated true positives, and so the actual performance of methods might very well be better than indicated, especially at high noise levels.

it should be noted that while the annotated length of a tf motif may vary from binding site to binding site, the length of a standard pwm is fixed, and pwms do not always match the locations of their corresponding binding sites precisely. perfect ncc scores can therefore be difficult or even impossible to obtain. the ncc score also drops fast if a method predicts a larger module region than what is annotated, even though the target module is correctly covered by the predicted region. this can severely penalize methods that tend to predict large module regions, especially on the transcompel dataset where most modules are rather short.

some programs can utilize additional information to strengthen confidence in predictions and improve their performance. for instance, stubb is a sensitive method and the predictions it makes usually include the correct modules, especially when using large pwm sets; yet, its cc-scores are generally low because it simultaneously predicts a lot of false positives. stubb can employ a phylogenetic footprinting  <cit>  strategy to filter out many of these false predictions, but it requires that orthologous sequences from related species are supplied along with the regular sequences. however, in order to make the tests as comparable as possible, we have not made such additional information available to the programs in our benchmark test, unless the type of information can be expected to be readily obtained for any dataset.

caution should thus always be taken when interpreting score values, since the reported scores might not accurately reflect the optimal capabilities of the methods. also, we have run the programs using mostly their default parameter settings. we are fully aware that adjusting the parameters can greatly affect the performance of a program, however, selecting the most appropriate parameter values be can be tricky and running methods with default settings is probably closer to typical usage.

it is inherently difficult to conduct an assessment that is fair to all methods. even the most minute design choice can influence the outcome if it unintentionally favours some methods over others. for instance, limiting the size of input sequences will be beneficial for most module discovery tools since it improves the signal-to-noise ratio. on the other hand, using too short sequences can disadvantage methods that require substantial amounts of data in order to derive elaborate background models. the best solution, then, is to try to balance the scales by subjecting methods to several different situations with datasets exhibiting a range of characteristics. this will make it harder still to declare a winner, since it will inevitably lead to even greater variation in the results. then again, the purpose of benchmarks tests need not be to identify a single program that can be recommended for all needs, but rather to determine how different methods behave under different conditions, thus enabling us to select the most appropriate tool to use in specific situations.

the results from our assessment of eight published module discovery tools show that the top scoring method does vary a lot between datasets. on the transcompel dataset, for instance, all methods save stubb and cismodule score better than the others on at least one sequence set. but there is also a tendency for some methods to perform consistently better or worse across several datasets. cismodule performed poorly on most sequence sets, cister and stubb usually scored somewhere in the middle, while cma, modulesearcher, mscan and cluster-buster were often found among the top scoring methods on each set. cma and modulesearcher were clearly best at identifying the correct motif types involved in the modules, and they were also the only methods capable of coping with large and noisy pwm sets. the other pwm-reliant methods appear to be more suited for detecting modules with some prior expected composition than for discovering completely new and uncharacterized modules.

there was some variation when using custom pwms as opposed to transfac pwm sets. the average performance over all methods on the whole transcompel dataset was about the same in both cases, but there were a lot of local differences between sequence sets. the most extreme example can be seen on the ebox-ets sequence set where mscan scores highest of all with transfac matrices, yet completely fails to find any true modules with custom matrices. the average deviation in scores when using either pwm set was about  <dig>  and the effect could go both ways. mcast was the only method which almost consistently scored better with one set, namely custom matrices.

CONCLUSIONS
while improvements can still be made to our systems, we have taken a first step towards developing a comprehensive testing workbench for composite motif discovery tools. the assessment system is based on two established datasets for module discovery plus a novel dataset we constructed from transcompel module annotations. the performance of methods on our novel set is comparable to the previous two, demonstrating its utility as a benchmark set. together these datasets challenge methods to discover modules with different characteristics and varying levels of difficulty.

not surprisingly, trying to discover composite motifs de novo proves to be much more challenging than relying on pwms as an aid to detect potential single binding sites. with large and noisy pwm sets, however, it becomes crucial to consider multiple instances of conserved motif combinations in order to identify true modules. in general, our study shows that there are still advances to be made in computational module discovery.

