BACKGROUND
concurrent acquisition of electroencephalogram  and functional magnetic resonance imaging  allows combining the strength of both methods and completing the fragmentary information provided by either one of them  <cit> . since the first publication of the simultaneous recording of eeg and bold contrasted mri in  <dig>  <cit>  great efforts have been made to turn this powerful tool into a standardized technique. thus combined acquisition of eeg and fmri has turned into an essential tool not only to answer basic neuroscientific research questions, e.g. related to tonic alertness  <cit> , resting-state connectiviy  <cit>  or changes of sleep patterns  <cit> , but also in clinical applications, in particular to localize the sources of ictal and interictal epileptic neural activity and networks  <cit> .

these advantages of extended insights into brain activity come with drawbacks like mutual interference between the acquisition equipment. while artifacts in mri images and fmri data induced by the eeg equipment are minimal or even do not exist  <cit> , scanner-induced artifacts in eeg recordings are quite substantial and their elimination is challenging. basically, these artifacts can be divided into two groups:  artifacts related to the cardiac pulse, which causes movements of the electrodes within the static magnetic field  of the mr-scanner  <cit>  and  artifacts produced by the fast switching of the magnetic field gradients  <cit> . however, although well understood, gradient artifacts exceed the amplitude of the recorded eeg signals by several orders of magnitudes. additionally, the raw artifact amplitude strongly depends on the change rate of the magnetic gradient field , the eeg electrode wire paths , the eeg channel and the position of the head in the scanner  <cit> . the removal of this artifact is therefore a non-trivial task even when using optimized registration setups  <cit> .

several algorithms for the correction of these artifacts  have been proposed, ranging from average artifact subtraction  <cit>  to multi-step methods including various pre- and post-processing steps  <cit> . yet, these algorithms commonly address only certain specific problem. for example, the problem of unsynchronized clocks of the eeg recording system and the mr scanner was tackled by both, the interpolation–template–alignment–subtraction  algorithm  <cit>  which aligns every eeg epoch to maximize its cross-correlation with a reference epoch following an up-sampling of the data or by the retrospective synchronization algorithm  <cit> . slow drifts or subtle subject movements are commonly tackled using block-wise generation of templates  <cit> , weighted templates  <cit>  or using only every second slice to reduce possible correlations between them  <cit> . still problematic are abrupt changes of the artifact signal, i.e. subject movements of  <dig> mm have been shown to already impair the results. in order to rectify this problem a realignment parameter informed algorithm  <cit>  can be used which introduces the use of fmri realignment parameters calculated from the image data.

most of these described correction algorithms are freely available to the scientific community, while others are either not available or my even be proprietary. available implementations are tailored to correct specific aspects of mr-related artifacts, implementing the individual correction steps in a fixed order and thus do not allow for a flexible configuration or combination of different correction approaches. however, a more flexible approach is of tremendous importance, since, depending on the eeg dataset not every corrective step is necessarily required and may even have adverse effects on the results. on the other hand, additional steps or innovative combinations of present steps can contribute to an improvement of the results. for example, the template subtraction can be performed twice with different methods for the template generation.

here we present a new toolbox called facet  aiming to combine different correction steps in a flexible and extensible way using a single framework. dedicated tools for the analysis of the eeg input data as well as methods to correct faulty trigger recordings are implemented as well. the toolbox is complemented by a dedicated framework for the evaluation of artifact correction algorithms using selected performance indicators.

throughout the remainder of this manuscript we first describe the implementation of the toolbox followed by an in depth description of the currently implemented set of utilities, i.e. the most popular correction algorithms. to provide the user with insights into setup and execution of implemented algorithms, the setup demonstrating the functionality of the toolbox will be explained using short application examples throughout the manuscript. finally, the functionality of facet will be demonstrated on a dataset supplied with the fmrib plugin by niazy et al.  <cit>  using the popular algorithm by allen  <cit>  and niazy  <cit> . all scripts to demonstrate the functionality of facet are provided with the facet package as well as in the appendix .

implementation
facet – the artifact correction and evaluation toolbox – consists of an analysis, a correction and an evaluation framework and relies on the eeglab data structure  <cit> . eeglaba is a widely used and extensible open-source eeg processing toolkit program for matlab. as a starting point the fastr algorithm  <cit>  and the farm algorithm  <cit>  were used. while fastr is available as a pluginb for eeglab, the source of farm is not provided by the authors.

the analysis framework provides information on the eeg data at hand, useful for the further setup of the correction procedure. within the correction framework, a selection of various algorithms for correcting imaging induced artifacts are provided: e.g. average artifact subtraction   <cit> , pca based  <cit>  or realignment-parameter informed  <cit>  and adaptive template approaches  <cit> . these approaches can be combined with different pre- and post-processing steps e.g. high- and low-pass filters, volume onset detection  <cit> , sub-sample alignment  <cit> , principle component analysis  <cit>  and adaptive noise canceling  <cit> . the evaluation framework of this toolbox allows to assess the quality of the chosen correction approach using a wealth of parameters to compare different settings. additionally facet offers functions to automatically generate late x code with tables and diagrams  for direct inclusion in the user’s documentation.

facet is implemented in the object-oriented programming paradigm. all classes are put together in the matlab package facet . the whole package will be available at https://github.com/hansiglaser/facet under the terms of the gnu general public license  to provide powerful collaboration, review, and code management. the archive includes documentation, examples, and all scripts used for the evaluation examples in this manuscript.

software design
throughout the development of the facet toolbox, no advantageous points were identified to split the data and/or functionality into multiple classes. therefore, a single class “facet” was created to hold all parameters and data. its methods operate on this data to perform e.g., the artifact correction. besides the data encapsulation, no other object oriented concepts like inheritance and polymorphism are used. figure  <dig> shows the unified modeling language  class diagram for the correction framework. public member fields for parameters and the eeg data are placed in the class. these have to be set by the user after instantiation of the class.

keeping the eeg data inside the object as a member variable also improves memory management. in contrast, the fastr plugin  <cit>  uses functions and hands over the eeg data as function parameter and return value. in this case, matlab creates a copy of the data every time. in the object-oriented approach, all methods work on the object member variables, therefore no copy is performed. this leads to reduced memory requirements  and faster execution.

several public methods are provided to analyze the data and remove the artifact. first of all, the constructor facet() creates a new instance of the class. other methods  are used to identify  trigger events and to print an analysis of the eeg data. finally, the core algorithm is performed by executing its associated methods. the internal working is split into multiple private and protected methods. additionally, events are issued at important points of execution to notify any interested programs. this allows data modification and printing of progress reports during the algorithm execution. the central class facet silently performs the algorithm and does not print anything to the screen. the above mentioned events are used by the class facet_text, which is derived from facet. it registers listeners to every event and prints a short message for every notification.

listing 1cleaning example to demonstrate the concept of the correction framework.  

contrary to the graphical dialog user interface used in  <cit> , facet is fully configured with a configuration file . the user sets options and parameters for the algorithm before it is executed. this ensures reproducible results and allows the user to add comments for explanations and rationales for decisions. using the object-oriented paradigm and employing matlab itself as a scripting language enables the setup of the algorithm in exactly this way. the configuration values are assigned to public properties of the facet object. here the full power of matlab is available to determine the value, either as a direct value, or calculated with user-defined formulas and even functions.

the correction framework
this section describes the correction framework. the generalized scheme for artifact reduction algorithms consists of several steps that can be summarized as pre-processing, template generation, and post-processing . the pre-processing steps are introduced to avoid inaccuracies and thus residual artifacts in the following template subtraction step. the template generation step usually calculates the average of surrounding artifact epochs utilizing the fact that the artifact signal shape is a periodic function for the acquisition of every fmri slice and/or volume. depending on the exact algorithm, different epochs are selected for averaging. during post-processing, residual artifacts are commonly removed by applying principal component analysis or adaptive noise canceling and low-pass filtering.

application example 1: correction of eeg data
before we describe the different methods and possibilities implemented in facet a short application example will be provided to familiarize the reader with the general concept and with the individual steps needed. overall, the toolbox provides several examples which will be used in excerpts throughout this work to demonstrate the features of the toolbox. the here shown example cleanex <dig> m  uses the fmrib dataset and is given in extracts in lst.  <dig>  the full example with all definitions and extensive comments on most available functions can be found as a supplementary file .

for easier execution of the example, it is wrapped in a matlab function which accepts the raw eeg data in an eeglab dataset structure as an input parameter  and returns the cleaned data . this function is executed with the matlab command line  

where the variable eeg_fmrib holds the fmrib data set.

as first step, a facet_text object is instantiated  by executing the class constructor. the next step is to assign the raw eeg data to the public property eeg . note that this property is internally implemented with a setter method. this automatically checks for the proper data format and extracts the number of channels and other values. then, the function findtriggers  is used to find triggers with the label ’slice’ in the eeglab dataset and possibly correct their offset . in lines  <dig> and  <dig> two assignments of configuration values are shown. in the first case a direct value is assigned while the second case shows a formula using another configuration value. actually, any matlab construct can be used.

the first method called is analyzedata() in line  <dig>  it is part of the analysis framework and prints information about the eeg data to the screen . then, before the actual artifact correction algorithm is started, the data and the setup is checked for notable or problematic conditions using checkdata() in line  <dig>  execution of the actual artifact removal algorithm is invoked in lines 28– <dig>  prepare() derives some further internal variables from the setup configuration values. then a filter  is applied to the eeg data using prefilter(). this is part of the pre-processing step shown in figure  <dig> 

the main part of the correction algorithm is encapsulated in removeartifacts(). it internally iterates over all eeg channels for which further pre-processing steps, template generation, template subtraction and post-processing are performed. the method finish() simply stops the run-time counter and executes a final event notification. finally, the cleaned eeg in the property eeg is returned to the caller .

setup and preparation of data
within facet, several methods  are implemented to analyze and prepare the eeg, to check the setup, and to assign and correct mr related trigger information. all these steps aim to improve the following template subtraction step.

analysis of eeg
although users employing artifact correction algorithms are usually informed about the parameters of eeg and fmri acquisition, methods are provided to analyse the eeg data to find problems, but also to find more detailed information.

to this end analyzedata() is used which characterizes the eeg dataset and displays information about it . first all information stored within the eeglab dataset structure is printed, e.g. the number of samples, sampling rate, the number of channels including labels and a list of all event names that occur within the data together with their latency and frequency. next, this function estimates the begin and end of the fmri acquisition during the eeg recording – its duration as well as the duration of unimpaired eeg data before and after the fmri acquisition are shown. if mr-acquisition related triggers are found, i.e. when the method findtriggers  was executed, a histogram of the distances between successive triggers is shown and used to warn if triggers are missing. it also checks if the number of triggers is enough for the duration of the fmri acquisition. here facet automatically differentiates between volume acquisition and slice acquisition. the latter is assumed if the mean temporal distance between the triggers is below  <dig>  s. for slice triggers, an analysis for volume gaps using a dedicated function to determine the gaps and to possibly interpolate, in a way similar to the farm algorithm  <cit> , can be performed and an estimate of total volume and slice count is printed. if volume triggers are assumed, slice periods are estimated by finding maxima in the auto-correlation function of one volume interval. this acquired information can later be used to convert the volume triggers to slice triggers.

listing  <dig> exemplary output of analyzedata() for the fmrib dataset.  

define and correct mr-trigger
as a first step to prepare the execution of the artifact correction algorithm, the time instances of fmri volume or slice acquisition have to be determined. in most cases the eeglab dataset will contain a list of trigger events, each characterized by a name and a latency value. findtriggers() allows to filter these events specified by a given name and stores a list of all latency values in a member variable. the latency values will then be used by the template generation and subtraction steps. to correct for missing triggers, two methods are provided. first, users can scan the list of triggers for distances which are too large and can then insert missing volume or slice triggers automatically using findmissingtriggers() . in the case of slice triggers, this method furthermore takes care to handle volume gaps correctly, i.e. larger intervals between the last slice trigger of one volume and the first trigger of the next volume are automatically detected and acknowledged.

listing  <dig> example usage of findmissingtriggers().  

since findmissingtriggers() can only handle missing triggers between other triggers, but not e.g. before the first one to code for dummy-scans, additional methods are included in facet allowing to manually add these missing events using addtriggers() .

listing  <dig> example usage of addtriggers().  

finally, as noted before, volume triggers can be converted to slice triggers. this routine ) can be used in all cases where the eeg data was recorded with triggers for the onset of every fmri volume but without information on the slice onset. it creates a list of triggers from the number of slices per volume, the duration of every slice acquisition and the relative position of the slice acquisition within the volume acquisition.

testing and finalizing of the setup
finally, before the actual artifact correction algorithm is started, the data and the setup is checked for notable or problematic conditions. this is performed by the method checkdata(). the current implementation checks that eeg data is provided and that triggers were setup. future extensions are planned to check filter properties for sensible values and certain interdependencies of the settings.

listing  <dig> exemplary specification of the steps, which should be performed for artifact removal .  

prefiltering the data
many eeg recordings collected during fmri acquisition contain slow fluctuations of the baseline . these are highly irregular and cause an unpredictable offset between the short slice epochs as well as a  linear trend of their baseline. these slow fluctuations have to be tackled with a high-pass filter with a very low cut-off frequency. low-pass filter on the other side are sometimes used to remove the fmri gradient artifacts . the result often still shows large artifact amplitudes, because the base frequency of both the volume and slice acquisition are well below  <dig> hz. low-pass filtering of the data also strongly attenuates the harmonics of the volume and slice periods. this leads to a temporal jitter of the low frequency components of the artifact signal which in turn results in large residual artifacts after template subtraction. therefore, low-pass pre-filtering alone is generally not recommended for artifact removal.

in the current application of facet three different implementations of filters are offered. the selected filter and its specifications are applied to the data using prefilter()  in the additional files section for detail on available setting). these filters are: fir  filter, an ideal filter in the frequency domain, and a gaussian filter, again in the frequency domain.

to realize a high attenuation in the narrow frequency band from  <dig> hz to the cut-off frequency using fir filters, a very high number of filter coefficients, here  <dig>  are used. this results in high demand of processing power. additionally, the steep characteristic results in large overshoot of the transfer function, which contributes in turn to signal distortion effects.

while fir filters work in the time domain, the frequency domain can be used to implement an ideal filter. this filter allows arbitrary modification of the amplitude of the frequency domain values of the signal. in the case of an ideal high-pass filter, all amplitude values below the cut-off frequency are set to  <dig> . this approach gives the best attenuation, but results in severe ringing and oscillations after the inverse fourier transform  of the signal to time domain  <cit> . however, using an fft and ifft for these operations, leads to a dramatic reduction of the runtime of the filter compared to high-order fir filters.

the maximum edge steepness of the frequency response without any overshoot is provided by gaussian filters  <cit> . although matlab already provides a function to design a gaussian fir filter  a gaussian filter was reimplemented using a frequency domain filter because of its higher processing speed.

due to the differences in the mean value  of the three sections of the eeg signal , the filter is applied separately. altogether, these filters can be either used as low-pass, as high-pass or as a combination of both. additionally, methods to generate custom filters specified via a-priory chosen weights as well as the possibility to define individual cut-off frequencies per eeg channel are provided within facet.

setup of the correction algorithm
most algorithms, in particular fmri artifact slice template removal   <cit>  and fmri artifact reduction for motion   <cit> , both used as a basis for this work, implement the individual correction steps in a fixed order. as already mentioned before, not every step is necessarily required, or additional steps or innovative combinations of present steps may need to be added. therefore, the artifact correction algorithm was split into multiple blocks with a common interface for the input and output data. this allows these blocks to be flexibly combined and setup in an arbitrary order. each block is implemented as a method of the facet class. it operates on object member variables, which represent the eeg data  as well as the  artifact data. using the usually large amount of data as a common  variable avoids the need to copy the whole dataset within each and every function, as would be required in a pure procedural design paradigm.

to configure which blocks are executed, a member variable rasequence is set to an array of strings . each string specifies a corresponding block of the algorithm. these blocks are executed in exactly the given order. additionally, user-defined functions can be included , which are executed as well. similar to the setup and analysis of the data, first an application example will be presented followed by a description of the different steps.

correction algorithm example
listing  <dig> shows an example as implemented by cleanex <dig> m. in figure  <dig> the corresponding data flow graph is given. the top blue diamond symbols denote the function ‘cut’, which extracts the period of actual fmri acquisition from the total eeg data for artifact estimation. this subarea of data is first up-sampled and further processed, including the template subtraction and pca, before its sampling rate is reduced again. the bottom blue diamonds denote ‘paste’, which merges the data back to the full eeg data. this is finally filtered with a low-pass filter and corrected using adaptive noise cancellation . note that the  artifact signal  is initially zero, i.e. no artifact at all. the data is reconstructed step by step during the artifact removal.

sub-sample alignment
in most cases the fmri scanner and the eeg recording use separate clocks and do not utilize synchronization. this means that, in general, every period of the mr gradient artifact is sampled by the eeg recording system with a varying temporal offset. this varying temporal offset is illustrated in figure  <dig>  calculating an average of successive periods  leads to substantial error and thus residual artifact. to cope with this problem, two methods are provided. first, methods to increases the sampling rate by interpolating the data by a given factor  and aligning the triggers within this finer temporal quantization .

this reduces the residual amplitudes, but at steep slopes even a short uncertainty leads to large vertical differences . while this method  helps to reduce the error, it also increases memory and processing demands.

therefore, a second and recommended approach is to time-shift the data with a sub-sample resolution  <cit>  utilizing the time shifting property of the fourier transform . as a first step the eeg signal is converted to frequency domain using the fft. then a linear phase is added, depending on the desired sub-sample time-shift, before it is transformed back to the time domain using the inverse fft. since the necessary temporal shift is unknown, facet implements an iterative optimization algorithm. this optimization minimizes the least square error of the current epoch to a  reference epoch using the bisection method.

volume gap correction
the fmri acquisition is performed volume by volume, therefore it shows a main period of the volume acquisition. for every volume a number of slices are acquired which pose a sub-period. two cases for the relationship of slice and volume timing are possible: the time of a volume acquisition is an exact integer multiple of the time of the slice acquisition. in this case the acquisition of the last slice the fmri scanner immediately continues with the acquisition of the first slice of the following volume. the second, more general, case exists if the acquisition of all slices lasts shorter than the repetition time of the volume acquisition. this results in a  delay between the acquisition of the last slice until the next volume starts with the acquisition of its first slice. detection of these volume acquisition gaps is important since during this gap, an additional gradient artifact may be recorded and in addition, this artifact may extend to the following slice periods. this means that such slice periods have to be corrected with an additional method.

the algorithm implemented in facet, called via removevolumeart, is similar to that used in farm  <cit> : assume an fmri acquisition with n
v
 volumes of n
s
 slices each, i.e. a total of n
v
·n
s
=n
e
 slices. for every slice the time of its onset is given by t
e
 . due to the double periods, the epoch index can be expressed by the volume index v= <dig> …,n
v
and slice index s= <dig> …,n
s
 as e=·n
s
++1c. this enables the trigger events to be written as t
e
=t
v,s
. with this notation, the volume gap exists between the last slice s=n
s
 of each volume v at tv,ns and the first slice s= <dig> of the following volume v+ <dig> at t
v+ <dig> .

in a first step, the positions of the n
v
− <dig> volume gaps is determined by investigating the distances between the slice trigger events t
e
, utilizing the fact that

 tv+ <dig> −tv,ns>tv,s+1−tv,s∀v= <dig> …,nv−1ands= <dig> …,ns− <dig>  

as a second step, the volume artifact, which extends to the slice periods right next to the volume gap at tv,ns and t
v+ <dig> , is calculated. for this purpose the five slice epochs tv,ns− <dig> to tv,ns before the volume gap and the five slice epochs t
v+ <dig>  to t
v+ <dig>  after the volume gap are averaged and subtracted from the adjacent slice periods at tv,ns and t
v+ <dig> , respectively.

these volume artifact templates are weighted with a logistic function 

 wx=11+eα 

to emphasize the artifact near the volume gap and de-emphasize it farther away. the parameters α and x <dig> are chosen to give a 50% weight at 80% of the slice interval, 10% at 69% of the interval and 1% at 57% of the interval. the weighted templates are then subtracted from the adjacent slice epochs.

in a final step, the gap is filled with a linear function from the end of the last slice tv,ns to the beginning of the first slice of the next volume t
v+ <dig> .

artifact template matrix
the template generation step builds the core around every correction algorithm and usually calculates the average of surrounding artifact epochs. depending on the exact algorithm, different epochs are selected for averaging. the selection of epochs and calculation of the average value is usually implemented using a loop which iterates over the epochs from the start to the end index value. a generalized approach, as implemented in facet, uses a square matrix with the size equal to the number of epochs where the row and column indices correspond to the epochs  <cit> .

using a matrix to describe the averaging process poses the advantage that averaging can be performed with a single matrix multiplication. let the raw eeg data of one channel be stored in the row vector d
i
 with i= <dig> …,n, where n is the total number of samples of the eeg recording. this vector is wrapped to the data matrix d=, where each row e= <dig> …,n
e
 is one of the n
e
 epochs and j= <dig> …,n
l
 is the sample index within each epoch of length n
l
 .

the averaging matrix a= is a n
e
×n
e
 square matrix, where the columns f of every row e specify which epochs f are averaged . the multiplication of the averaging matrix a with the data matrix d results in the noise  matrix n= with the same dimensions as d.

the final step is to wrap back the noise matrix n to a row vector like d
i
. note that if the fmri acquisition poses volume gaps , the estimated noise during these intervals is unknown. two approaches are implemented by the artifact correction algorithm and setup with a configuration parameter. one method sets the noise values in the volume gaps to  <dig> . the other method fills the gap with a linear function from the end of the last slice to the beginning of the first slice of the next volume, i.e., interpolated values are used. in contrast to the volume artifact correction detailed before, this interpolation is performed on the estimated noise data during template generation instead of the eeg input data during pre-processing.

implemented artifact matrices
the beforehand described general averaging matrix provides a simple mean to calculate the templates in the template generation step . the matrix clearly shows which epochs are used for the templates. it is even possible to include weights, e.g. to enhance epochs near the current one while attenuating epochs further away. therefore, any linear combination of the epochs is possible. thus it represents a general and yet complete interface to specify an arbitrary template algorithm.

numerous methods for the generation of this matrix to reflect specific averaging algorithms were implemented and added to the facet package. these methods can be divided in adaptively calculated matrices and fixed defined calculation schemes. while the first group directly depends on the eeg data provided and therefore is defined within the rasequence, the second group does not depend on the data but solely on the number of slices and possible external data, like movement parameters.

currently, two adaptively calculated averaging matrix methods are provided: facet.avgartwghtfarm uses the best matching slice periods within a given window as used for the farm algorithm  <cit>  and facet.avgartwghtallen provides the functionality as implemented by aas  <cit> . in facet.avgartwghtallen the template generation and subtraction is performed block-wise, i.e. templates are calculated from n consecutive epochs. according to  <cit> n is set to  <dig> epochs for periodic fmri sequences with volume gaps and to  <dig> slices for sequences without delays between volumes. to further reduce the impact of atypical epoch signals, following the first five epochs the remaining epochs are added iteratively given their cross-correlation to the current template exceeded  <dig> . compared to this block-wise averaging, the template generation using facet.avgartwghtfarm is improved by using a larger sliding window of  <dig> slices, but choosing a set of  <dig> artifacts with the highest correlation to the current artifact. within facet each of these parameters are predefined, but can be easily changed according to current needs. besides these, a collection of data-independent methods is provided with the facet package, implementing the behavior of fastr  <cit> , the realignment parameter informed algorithm  <cit>  and others. note that these are not integrated in the rasequence setting, since they can be executed before the algorithm itself . for example, to reproduce fastr’s behavior for volume and section triggers facet.avgartwghtvolumetrigger is used and for every second slice trigger facet.avgartwghtslicetrigger is used. for the calculation of a realignment parameter informed matrix similar to  <cit> , e.g. facet.avgartwghtmoosmann can be used, assuming the file ’example <dig> txt’ contains the realignment parameters from spm. finally, a simple method to average the artifact template based on corresponding slices across the measured volumes can be assessed using with facet.avgartwghtcorrespondingslice with the object mrslice holding the acquisition sequence.

listing  <dig> calculation of the averaging matrix for corresponding slices using an interleaved epi-sequence.   

for all these adaptive and fixed methods the size of the averaging window can be defined using the avgwindow property .

post-processing of cleaned data
the afterwards described post-processing steps aim to further improve the eeg signal after removal of the gradient artifacts. these steps comprise of principal component analysis to remove the strongest components related to the fmri artifact as introduced by  <cit> , low-pass filtering the corrected signal to remove residual high-frequency components and final adaptive noise cancellation as used by  <cit> . since these methods work only on the data related to the fmri acquisition, they are therefore included into the rasequence .

principal component analysis
a temporal principal component analysis  is used to find the functions which best describe the residual artifact signal, separately in each channel. the input data for the pca is composed of only a random subset of all signal segments to avoid finding only artifacts which happen at regular multiples of the segments. from the principal components, the c strongest components  are used to build the estimated residual artifact. the number c is either configured by the user with the variable obsnumpcs, or it is determined automatically during the algorithm performance by setting obsnumpcs = ’auto’, based on the explained variance. the estimated residual artifact is finally scaled for best match with the signal and then subtracted.

low-pass filter
as mentioned by  <cit> , a low-pass filter as the only algorithm to reduce the artifacts does not suffice. on the other hand, it greatly improves the result as a post-processing step . therefore the toolbox provides a low-pass filter with a configurable cut-off frequency using the filtfilt function implemented in matlab.

as the filter is a post-processing step, it is only applied to the processed data, i.e., to the period with artifacts from fmri acquisition, and not to the unimpaired eeg data before and after the fmri acquisition. however, in certain situations one also wants to filter the data outside of the fmri acquisition . the behavior to use the full output of the algorithm, even outside of the fmri acquisition area can be triggered by setting the variable donttouchnonartifact to “false” .

adaptive noise cancellation
as introduced by  <cit> , adaptive noise cancellation   <cit>  was also employed by  <cit> . the according source code of their fmrib plugin  is reused with only slight changes in facet. the estimated artifact signal resulting from the previous steps is used as reference signal for the anc. this implements an adaptive filter which is iteratively adjusted to remove the components which are correlated to the reference signal. the order of the anc filter as well as its step size are determined automatically during the algorithm execution depending on properties of the eeg signal and the artifact.

the evaluation framework
as an integral part of facet, the evaluation framework allows the assessment of the quality of the results as soon as the eeg data with gradient artifacts is improved by the artifact correction algorithm. for this purpose, it provides an extensive set of performance indicators as utilized by different authors.

the goal was to perform multiple evaluation algorithms on the output data from the artifact removal algorithms. these evaluation results can be saved and then presented to the user in several formats. one format is to print the numbers with some descriptive text to the screen. additionally, late x source code can be used to produce tables and diagrams for high-quality publications.

for the evaluation framework, the same modern design paradigm of object oriented programming as for the correction algorithm is used, i.e. the software design provides a separation of  the execution of performance indicator algorithms, from  the storage of their results, and  the presentation of these results. this is achieved by the object-oriented design as shown in figure  <dig>  the functionality is divided and realized by the classes. eval is the main class which holds all evaluation algorithms. it is instantiated with the original and the corrected eeg data . the evaluation is performed by the method eval(). the results are stored in the member variable result, which is an instance of the evalresult class. evalresult is a storage object for the evaluation results. evalresultcontainer wraps the evalresult object and adds meta information , later used by the evalprint descendants. evalprint is an abstract base class, which is used to print the evaluation results in an arbitrary format. actual printing routines are implemented in descendant classes . evalprinttext is a descendant class of evalprint which implements the print() method to display a human-readable table. evalprintlatex also descends from evalprint and implements the creation of output to be used in late x documents. it generates code using the tikz and pgfplots packages with multiple commands, which are used by the user inside of table and figure environments.

performance indicators
to assess the quality of results after the application of a correction algorithm, multiple criteria found in previous publications were employed. these indicators can be grouped according to their underlying physical or numerical property into amplitude criteria like median signal amplitude, rms and snr criteria and criteria within the frequency domain.

median imaging artifact
this indicator calculates the median signal amplitude range across all channels the amplitude of the artifact is used by  <cit>  as an indicator of the quality of the aas algorithm. to calculate this measure ten intervals with a length of 10% to 20% more than the slice period time are taken from the eeg data of every channel. these intervals are equally spaced to cover the whole duration of the fmri acquisition. the range  of each interval is calculated and averaged across the ten samples. this results in a mean imaging artifact range  of every channel within the recording. finally the minimum, maximum and median of these ranges are calculated, where the latter is called “median imaging artifact”.

although  <cit>  solely use the median imaging artifact to show the reduction of the residual artifact, we also calculate the median range of the eeg data without fmri acquisition for comparison. therefore the very same algorithm is performed on the  eeg data before and after fmri acquisition.

rms ratios
the root-mean-square value  is the quadratic mean of a signal and is defined for a continuous time signal x and discrete time signal x
i
 by

 xrms=1t∫0tx2dt=1n∑i=1nxi <dig>  

respectively. within facet two rms measures are implemented, the “rms corrected to unimpaired.” and the “rms uncorrected to corrected”. the “corrected to unimpaired” performance indicator used by  <cit>  is the ratio of the rms of the  corrected eeg signal to the rms of the signal without fmri acquisition. this performance indicator represents the fraction of the corrected signal to the pure signal. if the ratio is greater than  <dig>  residual artifacts are still present while values below  <dig> show that the correction algorithm removed parts of the wanted signal. “rms uncorrected to corrected” proposed by  <cit>  use the ratio of the rms of the uncorrected eeg signal to the rms of the corrected signal. the bigger this ratio the better, i.e., the more artifact was removed. however, non of these measures show whether the algorithm has removed too much of the signal. the evaluation tool calculates both ratios individually for every channel and returns descriptive statistics on them.

snr of corrected
the signal to noise ratio  commonly relates the undistorted signal power s to the noise power n. in many cases these values are not directly available for practical calculations. examples are the eeg signal from an fmri acquisition or the result from the artifact correction algorithm.

in these cases only the power of the distorted signal d is known. assuming additive noise, the distorted signal can be written as sum of the undistorted signal and the noise signal x
d
=x
s
+x
n
. utilizing the statistical independence, the power of the undistorted signal and the noise signal are also additive: d=s+n.

most eeg datasets with fmri acquisition also contain periods without fmri acquisition. these can be used as a sample of the undistorted signal to calculate s. with this information, the noise power is given by n=d−s and the snr is 

 snr=sd−s. 

this equation is applied for every channel of the corrected eeg dataset with d as the corrected signal and s the signal outside of the fmri acquisition periods.

due to the subtraction term d−s the result can be negative. this happens when the correction algorithm has removed more signal power than the artifact signal power. physically a negative noise power n=d−s does not make sense, therefore only positive snr values are considered in the descriptive statistics.

median residual activity
this performance indicator is a measure for the deviance of the corrected signal in different eeg frequency bands  <cit> . to compare the activity in four eeg frequency bands , ten equally spaced periods of  <dig> sec.  are averaged and then transformed to frequency domain with an fft for every channel. then the mean activity in every frequency band of the corrected signal  is compared to the mean activity during no fmri acquisition  by calculating the absolute value of the relative difference in percent 

 percentage difference=100%×acorr−aniani. 

to summarize the percentage difference values, the median  for all channels is determined and given separately for each frequency band.

power density at slice frequency
this final frequency specific performance indicator lists the power density reduction achieved by the artifact correction at the slice frequency and its harmonics. for the given original and the corrected datasets an fft is performed for every channel. the magnitudes at the frequency bins of the volume and the slice frequencies and four harmonics are divided  and squared. these values are converted to decibel  and the mean over all channels is calculated.

the automatic generation of late x source code by evalprintlatex for clarity only includes a subset of the evaluation results. for the “median imaging artifact” the median amplitude range of the corrected data is shown. the “rms corrected to unimpaired”, the “rms uncorrected to corrected” as well as the “snr of corrected” are represented by the respective mean values across all channels. the mean snr value is supplemented by the number of included values with a positive noise power. for the “power density at slice frequency” the averaged value in db of the slice frequency and its harmonics across all channels are given.

usage examples
for a quick evaluation of the results, the evaluation framework is usable with a one line matlab command. the example in lst.  <dig> compares the corrected dataset cleaned <dig> to the raw dataset eeg_fmrib, but limits the comparison to channels  <dig> to  <dig> . additionally, the number of slices per volume is given as  <dig>  the command-line creates an eval object and executes its eval() method. then it creates an evalprinttext object and print()s the evaluation result to the screen. the evaluation result is stored to the variable eval <dig> 

listing  <dig> exemplary one-line matlab command to evaluate the result of the correction algorithm and to print the result.  

for a more complex case, it is advisable to store the eval, evalresult and evalprint* objects to variables and access their member variables for fine tuning.

an example is given in lst.  <dig>  in the first part, datasets are evaluated, each corrected once using averaged artifact subtraction  and once using fmri artifact slice template removal . in the second part, an evalprintlatex object is created. the evaluation results are added and short labels are provided. a prefix for the generated late x commands is given, before the result is written to a file. this can be used in a late x document, which flexibly places the generated tables and diagrams. this feature was extensively used to prepare all evaluation figures found within the next section.

listing  <dig> example of the usage of the evaluation framework to generate the late x tables and diagrams for the aas and fastr algorithm found in this paper.  

RESULTS
having described the possibilities and implemented methods of facet the following section will demonstrate the functionality of facet using the dataset supplied with the fmrib plugin by niazy et al.  <cit> d. this dataset was recorded using a systemplus eeg system and an sd <dig> mri amplifier by micromed s.r.l., tv, italy and consists of eeg data acquired from  <dig> channels:  <dig> eeg-channels complemented by two bipolar channels for electromyography  and electrocardiography . concurrent with the eeg data  <dig> epi volumes  were acquired using a  <dig> t varian inova scanner. the subject’s task was to open and close his eyes every  <dig> seconds. listing  <dig> shows further details on the eeg dataset as found with the analyzedata() method.

we will begin with a short characterization of the two algorithms used by allen  <cit>  and niazy  <cit> . then we will demonstrate the functionality of the correction framework to clean the given dataset using these two algorithms. finally, the obtained results will be evaluated using the evaluation framework of facet. all scripts used to demonstrate the functionality of facet are provided with the facet package as well as in the appendix .

description of the correction algorithms
the averaged artifact subtraction  algorithm utilizes the periodic shape of the artifact signal to calculate an artifact template. to circumvent high residual artifacts due to signal drifts or subject movements the template generation and subtraction is performed block-wise. to further reduce the impact of atypical epoch signals, following the first five epochs, remaining epochs are added iteratively provided that their cross-correlation to the current template exceeds  <dig> . residual artifacts are then eliminated using adaptive noise cancellation . the problem of missing synchronization of eeg and mr is tackled here by up-sampling using a sinc-interpolation before template calculation.

the fmri artifact slice template removal  algorithm was introduced by  <cit> . similar to aas, it uses triggers from the mr scanner which indicate the slice timing. however, in this case, the triggers have the same temporal resolution as the eeg sampling, as opposed to those used by aas  <cit> , which have a higher temporal resolution. to tackle the problem of unsynchronized acquisition, the eeg data is up-sampled, similar to aas, then mr-trigger indices are adjusted within the refined time resolution. the artifact template is calculated as a local moving average of a configurable number of slice segments. to remove residual artifacts a set of basis functions using the principal component analysis  method is calculated and components describing most of the variance , are scaled and added to the artifact template signal from the previous stage. similar to allen  <cit>  adaptive noise canceling  is used with the reference being the estimated error signal.

setup of the evaluation
the fmrib dataset was used as input data for three different algorithms. their results were then evaluated using the evaluation framework of facet. both aforementioned correction algorithms, averaged artifact subtraction  and fmri artifact slice template removal  were implemented with the facet correction framework using the same parameters as proposed in  <cit>  and  <cit> . the complete listing for aas  and fastr  together with the evaluation script  can be found in the additional files section . fastr as implemented with facet is termed fastr-f to differentiate it from the the original fastr implementation  which was also used for comparison.

for the aas algorithm, the setup parameters are: 

● length of averaging window:  <dig> consecutive slices

● interpolation factor: 10

● cross-correlation to the current template:  <dig> 

● low-pass filter cutoff:  <dig> hz

the fastr algorithm was implemented using: 

● high-pass filter cutoff:  <dig> hz

● length of averaging window:  <dig> slices,  <dig> slices before and after the current one. only every second slice is used so that the eeg signal is uncorrelated between slices.

● interpolation factor: 10

● low-pass filter cutoff:  <dig> hz

divergent to the original publications, we did not use a sinc-interpolation before template calculation but the interp function as provided by matlab for the aas algorithm. furthermore, a  <dig> hz low-pass filter was applied after artifact removal to better allow for comparability of the different algorithms. for fastr-f the sequence of the artifact removal was slightly changed. while the calculation of the optimal basis set is similar to the original fastr-plugin, the resulting obs was not added to the averaging matrix but subtracted in a separate step. additionally, we used a gaussian filter in the frequency domain as implemented in facet. for both algorithms, c.f.  <cit> , the noise signal was used as reference for the adaptive noise cancellation step and not the low-passed version of a binary vector reflecting the slice timing as done by  <cit> .

results of the evaluation
while the signals do not evince obvious differences between the used correction algorithms, individual evaluation summarized in table  <dig> and presented in figures  <dig>   <dig>  and  <dig> clearly favor the fastr over the aas algorithm. most performance indicators in the time-domain  show an advantage of fastr over aas; e.g. the median image artifact shows a decrease from  <dig> μv for aas to  <dig>  μv and  <dig>  μv for fastr-n and fastr-f, the ratio of the rms of the uncorrected eeg signal to the rms of the corrected signal shows an increase from  <dig>   to  <dig>   and  <dig>  for fastr-f as implemented in facet.

on the other hand, the frequency domain performance indicators show a partial deterioration of the median residual activity in the alpha frequency bands  for the aas and the fastr-f algorithms. while this band does not contain slice frequency harmonics , these are present in the 4– <dig> hz and 12– <dig> hz bands, which both show almost equal performance parameters between the three correction algorithms. the power density reduction at slice frequency harmonics again shows equal and comparable results across all three algorithms.

direct comparison of the two implementations of the fastr algorithms, once using the fmrib plugin  and once using facet , shows equal and comparable evaluation results with respect to the gradient artifacts. only the signal to noise ratio  relating the undistorted signal power to the noise power is doubled, c.f. figure  <dig>  in the facet implementation. the reason for this discrepancy might be manifold, but is most likely due the slightly different implementation of the sequence of the artifact removal. within the original fastr implementation, results from the obs are added to the averaging matrix. this might result in some unwanted cancellations or elevation of the final noise signal, possibly leading to the increased snr within fastr-f. another possibility for the observed differences might be the different settings for relative cut-off frequency parameters for the interpolation filter which is set to  <dig>  in the fmrib plugin and to  <dig>  in facet  and the gaussian high-pass applied to the whole dataset and not only for artifact filtering. this last change to the original algorithms is also the cause for the missing overall slow negative drift of the signal in figure  <dig>  bottom window.

finally, although not a quality criterion for artifact correction but a quality criterion for the implementation within facet, we evaluated the processing time needed to run the different algorithms. while fastr using the fmrib plugin executed for 2: <dig> minutes, implementing this algorithm in facet almost halved the processing time to 1: <dig> minutes. the aas algorithm, having the least processing steps, took  <dig>  seconds to complete.

discussion
multi-modal imaging is an aspiring methodology in neuroscience. it enables research as well as clinical applications to observe brain activity with distinct approaches and allows to correlate results of both. the application of concurrent eeg, emg and fmri poses problems due to mutual interference. while the artifacts in fmri data due to eeg electrodes and equipment is negligible, the fmri gradient artifacts in the eeg data caused by electromagnetic induction exceed the original eeg signal by several orders of magnitude.

within every channel, the artifact signal shape is a periodic function for the acquisition of every fmri slice and/or volume. many algorithms utilize this fact to calculate an artifact template  and subtract this from the original data . this template subtraction paradigm still leaves residual artifact signals which are larger than the biological signals. these residual artifacts originate from missing synchronisation between the fmri acquisition and the eeg sampling, slow drifts of the artifact shape, or sudden movements of the subjects among others. consequently, the calculation of the template is optimised and several pre-processing and post-processing steps are added by many authors.

several mostly multi-step correction algorithms were published tackling either one or several of the beforehand mentioned issues to improve the correction. however, these algorithms often apply the individual steps in fixed order leaving no space for the flexibility to either leave out or add new steps. furthermore, not all correction algorithms are freely available to the scientific community but are either proprietary or simply not available.

in this paper we presented facet – a “flexible artifact correction and evaluation toolbox” for the correction of gradient artifacts in concurrently recorded eeg/fmri data. facet is implemented in matlab and relies on the eeglab data structure  <cit> . the whole toolbox consists of an analysis, a correction and an evaluation framework. the analysis framework provides information on the eeg data at hand. within the correction framework a selection of various algorithms for correcting imaging induced artifacts are provided. additionally, various pre- and post-processing steps are implemented like volume onset detection, sub-sample alignment or obs and anc. all steps are implemented in a modular fashion to allow flexible combinations of different approaches. the evaluation framework of facet allows the assessment of the quality of the chosen correction approach and a comparison between different settings. in total, the “facet” toolbox provides facilities for all three: data analysis, artifact correction as well as evaluation and documentation of the results.

this toolbox was used to correct and evaluate a publicly available dataset using two popular and widely used gradient correction algorithms: the averaged artifact subtraction  and the fmri artifact slice template removal  algorithm. in addition the fmrib dataset was corrected using the fastr implementation provided with the eeglab plugin fmrib and then evaluated using facet. as expected fastr outperformed the aas algorithm across all performance measures fastr, irrespective which implementation was used. a direct comparison of the two fastr implementations showed an improvement in the processing time by a factor of almost two while all evaluation measures related to the gradient artifact showed equal performance.

in summary, the presented artifact correction and evaluation toolbox provides an extensible and flexible tool for the scientific community. it employs well known data structures using eeglab and a simple, yet powerful, method to setup the algorithm in almost any sequence which also ease the integration of improvements. facet is provided at https://github.com/hansiglaser/facet under the terms of the gnu general public license  to provide powerful collaboration, review, and code management of possible future extensions.

future work
extensibility of the toolbox was one of the design goals of facet and is achieved with the object oriented design paradigm. therefore, several improvements of facet are planned. among these is the correction of ballistocardiographic  artifacts which is currently missing. further improvements concern enhanced usability of the toolbox, in particular we plan to extent the checkdata() method to check all sensible settings for validity and interdependencies.

since the eeg signals and fmri gradient artifacts as well as the bcg are mutually statistically independent, an independent component analysis  can be added to further improve the gradient template estimation before subtraction. a very promising approach in this direction was recently shown in  <cit> .

other interesting enhancements are the usage of the wavelet transform for the artifact correction  <cit> . contrary to wavelet shrinkage, which is used to remove the small signal components, here the large signal components should be removed. this could be for example achieved by an inverted thresholding function.

finally, during the execution of the algorithm, an identical sequence is performed on the data of every eeg channel. this allows for easy parallelization using multi-core cpus or computing clusters. newer versions of matlab also allow the transfer of large computational tasks to graphics processing units , which are highly optimized engines for parallel processing.

CONCLUSIONS
in summary, the “facet” toolbox provides facilities for all three modalities: data analysis, artifact correction as well as evaluation and documentation of the results. due to its flexible and modular structure any combination of the implemented processing steps can be selected individually in any sequence to create new processing pipelines. the results then can be evaluated and compared to existing approaches within the same toolbox. thus, facet not only provides a valuable tool for the removal of imaging artefacts from concurrently recorded eeg and emg data but also offers an easily extendable framework for development and evaluation of new approaches.

availability and requirements
● project name: facet 

● availability: public github: https://github.com/hansiglaser/facet

● operating system: platform independent 

● programming language: matlab 

● requirements: facet relies on the eeglab data structure  <cit>  available at http://sccn.ucsd.edu/eeglab/. to run the example scripts, one also needs to install the fastr algorithm  <cit>  available as an eeglab plugin available at http://www.fmrib.ox.ac.uk/eeglab/fmribplugin.

● licence: this program is free software; you can redistribute it and/or modify it under the terms of the gnu general public license as published by the free software foundation; either version  <dig> of the license, or  any later version the terms of the gnu general public license  to provide powerful collaboration, review, and code management of possible future extensions.

endnotes
aeeglab available at http://sccn.ucsd.edu/eeglab/

b fastr plugin available at http://www.fmrib.ox.ac.uk/eeglab/fmribplugin

c − <dig> for v and s as well as + <dig> for the whole formula are necessary because the indices start at 1

d this dataset is freely available at http://www.fmrib.ox.ac.uk/eeglab/fmribplugin/

competing interests
the authors declare that they have no competing interests.

authors’ contributions
jg programmed the toolbox and wrote the section on the implementation of the toolbox. rb and hb co-wrote the manuscript and evaluated the toolbox. ff co-designed the toolbox and implemented the usage examples and wrote large parts of the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
complete listing of cleanex <dig> m. this file contains a complete listing of the example script cleanex <dig> m including a detailed documentation of the various settings.

click here for file

 additional file 2
evaluation scripts as compressed zip-file. this zip-file contains the complete listings of cleanaas.m, cleanfastr.m implementing different correction approaches and evaluatefacet.m used to generate the evaluation results and figures presented within this manuscript.

click here for file

 acknowledgements
the authors wish to thank dara Ó hógáin and two anonymous reviewers for their helpful comments on the manuscript. florian ph.s fischmeister was supported by a research cluster grant of the medical university and university of vienna .
