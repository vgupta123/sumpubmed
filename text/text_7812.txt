BACKGROUND
as the amount of textual information generated by scientific research expands, there is an increasing need for effective literature mining that can help scientists gather relevant knowledge encoded in text documents. the challenge is to develop methods of automated information extraction to support building logical databases and discover new knowledge from online journal collections. a large amount of information for biological research is available in the form of free text such as medline abstracts. abstracts are collected and maintained in the medline database which currently contains references to over  <dig> million articles dating back to the mid 1960's in domains of molecular biology, biomedicine and medicine, and currently growing by almost half a million articles per year.

medline articles of interest can be searched for through the pubmed server  <cit>  with queries using a boolean combination of free text or controlled vocabulary keywords. the usefulness of free text keyword searching will depend on the word content in the title and/or abstract of references of interest. some interfaces map free text terms to a corresponding medical subject heading   <cit> . subject heading  searching can also be a powerful strategy for finding information. subheadings can help to focus the scope of the search space. this strategy is appropriate for researchers interested in a narrow concept to retrieve a small slice of references for visual inspection. however, there are certain computational analyses of the literature or database developments that would require the ranking of the complete medline database of references as to their relation to a topic of interest. for example, given any two articles it would be useful to decide which one relates more to a topic.

many machine learning methods have been applied to the problem of document classification  <cit> . typically such algorithms learn from a set of text that has already been classified  how to classify another set of documents . naïve bayes, k-nearest neighbors, decision trees, neural networks, and support vector machines are a few of the most common machine learning algorithms  <cit> . a key difference between these methods is the way that the documents are represented by the features selected   <cit> . this results in differences not only in performance but also in the time that is needed to train the method of choice on the test set. those differences become very significant when the training and the test sets become on the order of thousands. as a result, only naïve bayesian learning has been applied to the ranking of medline abstracts  and only using training sets of one hundred examples  <cit> . just to give an example, a recent survey of these machine learning algorithms on comparatively small sets of text documents required more than five years of cpu time  <cit> . applying these methods to classifying thirteen million vectors which are each the width of the number of words used in all the articles in medline  would certainly be an impossible computational task.

an alternative is given by text indexing based on word frequencies  <cit> . the titles and abstracts of medline references contain words that are indicative of specific topics which can be detected by examining how a given word is used more often in references dealing with the topic than in unrelated references. we have previously used this to find keywords in medline abstracts describing protein families  <cit>  or genetic disease  <cit> , by using the ratio of word usage in a group of pre-selected abstracts with respect to word usage in medline.

here we propose to use this approach not just to extract keywords but also to evaluate the entire medline database with respect to a topic of interest, in a reasonable amount of time such that it can be used in an article search query. the idea is that the learning procedure does not rely on discriminating whole medline abstracts, but on the words inside, which is much less computationally expensive. this is translated into a dictionary of scored words that can be used later to score any abstract according to the words it contains.

because the approach is relatively inexpensive, we can evaluate different scoring schemes. we will discuss those and comment on how the performance of the approach is affected by the part of speech  used for the analysis.

RESULTS
the training set
the starting point of our algorithm is a set of articles associated  with a topic of interest. the system is trained with this set and therefore we define it as the training set. to ease evaluation of the method, we chose a subject for which the fraction of articles in the database would be neither too small nor too large of a subset of medline. in this work we used the topic stem cells and we took advantage of the annotation of medline entries with terms of the mesh keyword hierarchy to select the training set. for this we obtained by license the complete medline database .

the mesh vocabulary contains  <dig>  descriptors, and  <dig>  headings called supplementary concept records. an average of  <dig> mesh indexing terms are applied to each medline citation by nlm indexers, who after reading the full text of the article will choose the most specific mesh heading that describe the concepts discussed. the mesh indexing terms are organized into concept hierarchies  that represent is-a and part-whole relationships  <cit> . indexers can also assign subheadings to further describe a particular aspect of a mesh concept. in addition to assigning mesh terms that describe the topic of the article, the indexer provides terms that reflect the age group of the population studied, the nature of the studies , and the material represented . thus mesh headings serve as a telegraphic surrogate of the concepts contained in a journal article.

we selected all medline entries annotated with either the mesh term stem cells or any of its  <dig> children terms in the mesh keyword hierarchy . the resulting set contained  <dig>  articles with abstracts in medline . entries without abstracts were discarded because our training is based upon the words present in both the abstract and title of the reference. this training set of stem cell references represents ~ <dig> % of medline.

keyword scoring
the property to be analysed is the frequency of certain words in abstracts. based on our previous experience in the classification of abstracts, we registered the presence of words in the abstract , ignoring the cardinality of words within a single abstract as done in  <cit> , such that a word appearing many times within one abstract would not carry additional weight over a word appearing only once  <cit> . additionally, we restricted the analysis to words which commonly convey meaning, that is, nouns, verbs, and adjectives, and not adverbs or conjunctions which would be more appropriate for style studies than for information extraction purposes  <cit> .

accordingly, we registered the frequencies of  <dig>  unique nouns,  <dig>  adjectives, and  <dig>  verbs in all medline entries with abstracts  that appeared in at least  <dig> abstracts. frequencies of  <dig>  unique nouns,  <dig>  adjectives, and  <dig>  verbs were counted in the training set of stem cell references. to reduce noise we further filtered the list by considering only words that occurred in more than  <dig> of the  <dig>  entries in the training set . words were always distinguished by their part of speech. for example, of the combined set of  <dig>  nouns and adjectives,  <dig> occurred in the literature both as a noun and as an adjective. each noun was treated as a separate keyword from its adjective counterpart.

each word  occurring in  <dig> or more of the entries in the training set was scored by the ratio of frequency of occurrence in the training set divided by its frequency of occurrence in all of medline . the top  <dig> scoring nouns, adjectives, and verbs are listed in table  <dig>  table  <dig>  and table  <dig>  respectively. . the set of nouns was much larger than the sets of adjectives or verbs. the top keyword scores were also higher for nouns than for adjectives and verbs.

reference scoring
we studied two variables when scoring medline references on the basis of their word scores: one was the part of speech used, and the other was the number of words used for the score. to make this analysis feasible in terms of computing time, we constructed a set of medline references with the training set and an additional equal number of references with abstracts chosen at random from the rest of medline, which we will call the random set, ideally not related to stem cells. the self-consistency of a given scoring scheme was measured by the fraction of references from the training set that ranked in the top half when the whole set of  <dig>  references was scored. the scores for training and random sets are given as supplementary material .

we first analyzed the effect of scoring medline references using the average of all keywords in the abstract and title and compared the results to the average of only the top  <dig>  and the top  <dig> words with the highest scores, which gave worse results and a small improvement, respectively . for the rest of experiments we used the average of all words.

we then studied the influence of the part of speech used to score the references. figure  <dig> shows the fraction of articles from the training set that was retrieved when selecting a variable range of top-scoring articles. nouns were better keywords than were adjectives, or verbs. using both nouns and adjectives as keywords slightly improved retrieval for the top-ranking articles, but weakened prediction of middle and low-ranking stem cell articles. accordingly, we adopted as a scoring scheme the average over all nouns with scores.

we computed the scores for all medline references with abstracts. as expected, the medline score distribution agreed with the score distribution of the random set and was well below the score distribution of the training set . however, the considerable overlap between the background and the training set was indicative that neither all references in the training set were dealing with stem cells in a strict sense nor all references in the random set were unrelated to stem cells.

close inspection of the top ranking references from the random set revealed that they were also likely to be of interest to anybody wanting to read about stem cells . for these reasons, we measured performance of the method by observing recall and precision in a set evaluated by a human expert and not used to train the algorithm, a typical way to evaluate literature mining algorithms  <cit> .

recall and precision of the algorithm
we collected a test set of  <dig>  medline entries randomly chosen from articles published during january  <dig>  and therefore not included in our training set. their score distribution was in agreement with the medline background . according to a human evaluator with expertise in the field of stem-cell biology  there were  <dig> articles relevant to the topic of stem cells in the set, all with scores clearly above the background.

the first false positive, pmid:  <dig> ranked at position  <dig>  mentions the highly scoring keyword 'fibroblast'  but in the context of an inherited disease . similarly, other articles with high scores that were not considered to be relevant to stem cells by the human expert were usually talking of cells, genes, and proteins relevant to stem cells, but in a context not directly related to stem cell biology, such as cancer or metabolic disease. the worst scoring positive, pmid:  <dig> ranked at position  <dig>  was a review dealing with the use of neural stem cells for therapy of neurodegenerative diseases. the score was very low because its abstract does not contain any mention to relevant facts about stem cells.

this type of analysis is subjective because it reflects the prejudices of a particular human expert; however, it is indicative of the general agreement between human selection and automated ranking. the complete list of scored abstracts and the results of the human evaluation are available in additional file  <dig> 

discussion
we have introduced a simple strategy to judge the relevance of a text according to a topic of interest based on a training set of text. the method relies on different frequencies of discriminating words between the training set and other non-relevant articles. this algorithm is appropriate for information extraction of molecular biology data from the medline database of scientific references.

our analysis of more than six million medline entries with abstracts indicated that there were  <dig>  unique keywords  appearing in at least  <dig> abstracts. for comparison, the oed, the largest english-language dictionary, contains  <dig>  entries with about  <dig>  word forms  <cit> . oed omits many slang words, proper names, scientific and technical terms, and jargon . most estimates of the total vocabulary of english are well over three million words, but only ~ <dig>  words are still commonly used. an educated person has a vocabulary of ~ <dig>  words and uses ~ <dig>  per week through conversation.

to test the system, we constructed a set of references related to the topic of stem cells taking those annotated with the corresponding keywords of the mesh hierarchy . this set contained  <dig>  medline references. there were  <dig>  unique keywords  extracted from the training set of  <dig>  stem cell references.

we then focused on words that were used more often in the training set of stem cell references than elsewhere. regarding those words, it was not surprising that a high proportion of the keywords extracted were proper names and scientific jargon. in order to be sure of choosing relevant words  we took only those used in more than  <dig> references in the training set: only  <dig>   of the nouns,  <dig>   of the adjectives, and  <dig>  of the verbs.

the words were scored by their different usage in stem cell references compared to medline, and all medline references with abstracts were ranked by the average of scores of their keywords . the best keywords  were mostly related to sources of stem cells and therefore were identifying relevant references. the worst keywords  were totally off-topic and abstracts with many of these generic words would often rank poorly with respect to their relevance to stem cells.

the self-consistency analysis of the algorithm with a set combining the training set with an equally large set of randomly selected references was used to compare the performance of the algorithm for different parts of speech and simple scoring mechanisms. nouns were found to be superior to verbs and adjectives and the average score of all nouns in the abstract and title was found to be most appropriate. we observed truly stem cell related articles in the random set of articles that were not annotated with stem cells mesh terms, and also articles in the abstract set which were not relevant to the subject.

in order to further evaluate the capabilities of the method, we compared the results obtained with those returned by a human expert from a set of  <dig>  articles not used for training. a precision of 65% was found for a recall level of 65% in the retrieval of the  <dig> articles deemed by the human to be relevant.

it would be interesting to see how the algorithm presented here performs when searching for different concepts such as stem cells. evaluation of the self-consistency of the algorithm is relatively simple, so any user can have a good idea of whether there is enough information in the training set to allow distinction from the rest of the database and see how the part of the speech chosen affects performance. however, the least we can do here is to note that the part of speech that gave better performance were nouns. we propose two predictions. firstly, the optimal part of speech could be related to the part of speech of the topic under consideration; in this case nouns are the best keywords because the topic is an object, stem cells; if the topic was a verb, such as interact or phosphorylate, we expect that a small number of verbs will work better. our second prediction is that our algorithm will often work better using names as keywords, as it will be easier to discriminate topics composed of nouns or nouns and adjectives than bare adjectives or verbs. this is for the reason that nouns are used to name a person, place, thing, act, or concept, whereas adjectives indicate qualities of the nouns, and verbs tell of doing or being something. therefore, context is often needed to determine the meaning of adjectives and verbs whereas nouns are relatively context-insensitive, especially in science. most keywords used in molecular biology  <cit> , are nouns which are sometimes complemented with an adjective, such as mitochondrial membrane.

ideally biomedical texts should have a lower degree of linguistic variation than other genres  <cit> . however the naming conventions in biology and biomedicine are highly non-standardized even when it comes to the fundamental concepts. in theory, terms should be mono-referential , but in practice we have to deal with ambiguities  and variants . one approach to solve the ambiguities of the natural text used in abstracts has been the indexing of the literature in the medline database by keywords drawn from the mesh controlled terminology that was originally developed to categorize the citations contained in index medicus. the annotation of medline with mesh terms at the national library of medicine helps users to link their search terms to abstracts containing different terms with the same meaning  <cit> .

annotation of articles with mesh headings are optionally flagged with subheadings and importance markers . however some applications might require a fuzzy association to subjects, for example, one reference can be more strongly relevant to stem cells than another. this could be important for example when setting up priorities between references. another reference could be possibly relevant to stem cells with a low likelihood. this could matter if a researcher wanted to find out any possible relation of a gene to stem cells, even if it is a remote association. the approach presented in this work allows the ranking of any medline reference with respect to its relevance to a topic.

a different problem with mesh terms particular to the subject of stem cells is that many references were annotated with stem cells mesh terms because of the usage of stem cells as a technique. for example pmid:  <dig> is annotated with the mesh term stem cells because mouse embryonic stem cells were used to raise chimeric mice using a method previously described, yet the major finding of the publication really has nothing to do with stem cells. such an article would likely not be interesting to a researcher working on the biology of stem cells. as discussed previously  <cit> , such information will be contained in the methods section of the corresponding article and would often be omitted from the abstract. thus our algorithm defeats this problem by using a different focus to avoid the imprecision caused by trusting mesh annotations alone.

regarding the computational time needed by our method, the extraction of specific parts of speech from medline requires several hours on a reasonably fast machine, but this only has to be done once. newer entries added to the medline database can be parsed monthly or more frequently if desired. the main bottleneck is the production of a ranked list of medline references, which is not a problem if one is interested in only one concept such as stem cells. the real limitation arises if one considers using this strategy to the mining of ranked reference lists relating to many concepts. for each concept query, a set of training references must be collected, keyword scoring tables constructed, and all abstracts in medline must be scored. providing a real-time interface for arbitrary concept queries is possible but would require some combination of the large storage requirements of pre-processed tables and cluster  computing. a more realistic approach would be a local implementation of our approach according to the interests and requirements of individual researchers.

in our implementation, the training set was collected using a selection of medline references annotated with a subset of terms from the mesh hierarchy that we considered to be relevant to the subject of stem cells. however, there are many other ways of selecting sets of medline references relevant to topics, such as links from databases like omim  <cit> , hssp  <cit> , or by manual selection. the garbage in garbage out principle applies here as in many other applications where the quality of the training set matters, so if the selection is too messy the algorithm might not pick any relevant discriminating keywords.

to make our analysis as impartial and simple as possible, only mesh terms in the sub tree of stem cell were considered, but there are other terms elsewhere in the mesh hierarchy  that would also be good indicators that a given article is talking about stem cells. it would be feasible to determine the nearest neighbours of an arbitrary mesh term, and by setting a threshold similarity factor one could include all the mesh terms within a certain semantic distance of one another in a clustering manner. surely this would improve the performance of the relevance prediction algorithm. however, considering that we are in a stage of testing and illustrating the method, we employed a simple approach of using a mesh term and its children in the mesh hierarchy.

the cosine distance between vectors of word usage can be used to measure distance between medline abstracts  <cit> . however, this measure takes into account all the parts of speech, as well as the number of times each word is used in a body of text. the purpose of the cosine measure is to offer an objective distance between entries independent of the user's interest in a particular topic. therefore our scoring is more appropriate, which is not a distance but rather an absolute value used to derive a ranking upon learning from a training set, a typical strategy in information retrieval  <cit> . eventually, the cosine distance might be refined to use only certain parts of speech . we can assume this would give better results when searching medline neighbours of a given entry in medline, provided that the user is interested in topics similar to those contained in biological keyword systems.

CONCLUSIONS
this report describes an approach to compute a ranked list of publications according to relevance to a topic of interest, given a training set of medline references. it is evident that the analysis of the word usage in the abstracts of publications associated with a given concept can be used for literature mining. the strong dependency of the quality of the results with the part of speech used must be taken into consideration. even if the procedure applied in this work may seem to be too simplistic given the existence of sophisticated methods such as naïve bayesian classifiers, support vector machines, and neural networks, one should not forget that we are dealing with test sets of millions of abstracts, and training sets of tens of thousands, and that the variation of each single item to be classified is very large because they are composed of some hundred words. in situations like this, sophistication leads very quickly to impossibility of computation and pragmatic approaches are needed. we have produced a method that works and the conclusions obtained regarding the part of speech used may be useful for others working in information extraction from natural language.

