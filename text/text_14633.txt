BACKGROUND
the sequencing of the human genome has made it possible to conduct genome-wide studies on genetic variations in human populations. most of these variation data are in the form of single nucleotide polymorphisms , single dna bases that have two common variants in a population, of which several million have now been identified  <cit> . phylogenetic inference is central to identifying shared ancestry among populations and is also useful as a means of increasing the statistical power of association studies used to detect disease-related variations  <cit> . furthermore, phylogenies can provide specific guidance as to the selection of marker snps for such studies, for example by allowing one to avoid variant sites that have appeared multiple times in an evolutionary tree and that are therefore likely to confound association tests. phylogenetics on short evolutionary time scales, such as within a single species, is generally performed using a maximum parsimony objective  <cit> , i.e., finding trees that explain the observed data with the minimum possible number of mutations. on such data, it is usually assumed that one must find a steiner tree in which observed sequences may be present anywhere in the tree and additional steiner nodes may be introduced. this is in contrast to the species trees used to describe longer time scales, where observed sequences are generally found only at the leaves of the tree. although inferring maximum parsimony steiner trees on binary snp data  is an np-hard problem  <cit> , there are excellent methods now available for solving it in practice, including fast heuristics suitable for difficult instances  <cit> , fixed parameter tractable methods for provably efficient optimal solutions in some cases  <cit> , and integer linear programming methods for provably optimal solutions of many harder cases  <cit> .

unfortunately, the haplotype input data these methods assume, also known as "phased" data, are not easily available for autosomal genetic regions. large-scale genetic studies usually instead must gather unphased, or genotype, data, in which haplotype contributions from two homologous chromosomes are conflated with one another.

to illustrate the problem, it will be helpful to arbitrarily denote the minor allele at each snp site by  <dig> and the major allele by  <dig>  in a genotype data set, we only observe the number of minor alleles present at each snp site, which we will denote by  <dig> for homozygous major,  <dig> for heterozygous and  <dig> for homozygous minor. for example, see figure  <dig>  hence, if we examine m sites, then a genotype sequence is a string of the form { <dig>   <dig>  2}m while a haplotype sequence is a string of the form { <dig>  1}m. a pair of haplotype sequences is consistent with  a genotype sequence when they have the same allele counts at all sites. in the { <dig>   <dig>  2} notation above, a pair of haplotypes is consistent with a genotype when the sum of the two haplotype vectors produces the genotype vector.

while mitochondrial and y chromosome data can serve for tracking population histories on broad scales  <cit> , autosomal phylogenies are still independently valuable for practical applications in association study design, marker selection, and the identification of specific variant sites that are unusually mutable, repeatedly altered by gene conversion, or under selective pressure to recurrently mutate. phylogeny inference cannot generally be performed directly on genotype data and in practice one must therefore analyze autosomal data by first computationally phasing the data to predict the haplotypes  <cit> . many methods are now available for this phasing problem, such as phase  <cit> , fastphase  <cit> , hap  <cit>  and pph  <cit> . this phasing step, however, can produce erroneous assignments and the maximum parsimony phylogeny on the computationally phased genotypes need not be the same as, or even close to, the maximally parsimonious tree consistent with the original unphased genotypes. phasing programs are typically designed to minimize the "switch error," in which the contributions from two homologous chromosomes are swapped between two consecutive markers . yet a single switch error in a phasing assignment can introduce a large number of errors  in the resulting phylogeny assignment, as shown in figures  <dig> and  <dig>  even high-quality phasing methods can thus produce poor-quality phylogenies.

a limited amount of prior work has examined the prospect of inferring maximum parsimony phylogenies directly from genotype data. notice that in such problems, we wish to determine a pair of haplotypes for each input genotype sequence such that the maximum parsimony phylogeny size on the set of haplotypes is minimized. gusfield showed that the problem can be efficiently solved when the genotype data are consistent with a perfect phylogeny  <cit> , an evolutionary tree in which each variant site mutates only once. several subsequent algorithms were developed for the same problem that were either simpler or faster asymptotically  <cit> . while the perfect phylogeny assumption is restrictive, this variant does have practical importance as a technique for fast phasing . the perfect phylogeny assumption will not be true in general, however. in particular, it will not allow analysis of data containing recurrently mutating sites, the detection of which is an important reason for studying phylogenetics of autosomal dna. halperin et al.  <cit>  generalized gusfield's perfect phylogeny method heuristically to allow limited solution of phylogenies deviating slightly from the assumption of perfection. these are called near-perfect phylogenies  <cit>  and specifically q-near-perfect  when q additional mutations are needed beyond those required to produce a perfect phylogeny. song et al. <cit>  and sridhar et al. <cit>  developed rigorous methods for efficiently finding maximum parsimony near-perfect phylogenies, but these methods proved practical only for small q . in practice, the problem of finding maximum parsimony phylogenies from genotype data has remained intractable for all but the simplest data sets.

we note that the parsimony based approach described above is different from finding haplotypes corresponding to the given genotypes based on 'pure parsimony,' an objective that minimizes the number of distinct haplotypes needed to explain the observed genotypes as opposed to minimizing the number of mutations. the pure parsimony problem is np-complete as well and there are integer program based approaches that solve problem instances of reasonable size  <cit> . pure parsimony and maximum parsimony phylogenetic trees share some properties that we can exploit in our method. the solution to the pure parsimony problem provides a lower bound on the size of the maximum parsimony phylogeny, as no phylogeny can have fewer mutations than one less than the minimum number of haplotypes needed to explain the genotypes. furthermore, the solution of the pure parsimony problem also provides a good starting set of haplotypes from which we can obtain an upper-bound for the size of the maximum parsimony phylogeny.

in this paper, we provide the first general, practical methods for maximum parsimony phylogeny inference from genotypes and use these methods to assess the inaccuracies introduced by phasing genotypes prior to phylogeny inference. our algorithm relies on solving integer linear programs and allows for efficient solution of moderate-sized problem instances but large imperfection. as an immediate application, our method can be used to infer the minimum number of recurrent mutations required to explain the given set of genotypes. we apply the resulting methods to a selection of real and simulated data, where we compare the true imperfection, imperfection from haplotypes computationally inferred from genotypes and imperfection directly obtained from genotypes. this analysis shows that the phasing step often increases inferred phylogeny size, overestimating the true maximum parsimony. motivated by our observations, we introduce a new phylogenetic error statistic that is better suited for assessing phase accuracy for phylogenetic applications than the standard switch error statistic  <cit> .

RESULTS
we now present the results of a series of empirical tests to assess the utility of the method on real and simulated genetic data. with both kinds of data, we begin with known haplotypes and then artificially pair them to produce genotypes. for each problem instance, we reconstruct maximum parsimony  phylogenies in three ways: directly from the genotypes using the algorithm presented in this paper, from the original  haplotypes and from haplotypes computationally inferred from the genotypes using fastphase  <cit>  and haplotyper  <cit> , two leading methods for haplotype inference. we use the notation tmin, ttrue, and tphase to denote the mp phylogeny from the genotypes, true haplotypes and inferred haplotypes  respectively. we further denote the parsimony score  of a phylogeny t by length. for phylogeny t that is either tphase or tmin, we define a phylogenetic error based on length as follows.

definition 1
the phylogenetic error of phylogeny t  is |length - length|. phylogeny t is said to have a positive error if length > length and negative error if length < length.

note that it is impossible for tmin to have positive phylogenetic error. this is because our algorithm optimizes over all possible haplotypes consistent with the given set of genotypes and selects the one that minimizes the size of the phylogenetic tree. in contrast, tphase can suffer from both types of errors and it is impossible to know if the size of the true phylogeny is larger or smaller than tphase. the following definition of an imperfection of a phylogeny has been widely used.

definition 2
the imperfection of a phylogeny t constructed for an input set of sequences  with m varying sites is length - m.

simply stated, the imperfection is the minimum number of recurrent mutations required to explain the sequences using the phylogeny. notice that if there are m varying sites in an input set of genotypes then every possible set of haplotypes that explain it must have m varying sites as well. the experiments presented in the following section allow us to understand the gap between the size of the phylogeny from genotypes, the true size and the artificially inflated sizes due to incorrect phase inference.

simulated data
due to difficulty of obtaining phase-known autosomal data, we begin by examining simulated data. we used coalescent simulations to generate recombination-free haplotypes and genotypes for varying mutation rates and used these for a series of tests on how the accuracy of our method and the two comparative haplotype-based approaches varied with different parameter values. each test measured the total number of errors of each method in  <dig> independently generated data sets. we first varied the mutation rate parameter θ to test its influence on the accuracy of all the methods. the results are provided in figure  <dig>  we find that the relative performance of the three methods is fairly consistent. the greatest number of errors is generally made by fastphase and the least by direct phylogeny inference from the genotypes, with haplotyper in between. as one would expect, the number of errors of all three methods increases with increasing mutation rate. the curves are not monotonic, but additional simulation runs identical to those described here  show no conservation of specific peaks and troughs of the graphs, indicating that they reflect only random noise due to a high variance in phylogenetic errors across trials. table  <dig> separates the results of the two indirect methods, fastphase and haplotyper, into positive and negative errors. both methods show mixtures of generally similar numbers of positive and negative phylogenetic errors with no apparent consistent trends towards favoring one or the other error type as one particular parameter varies. note that by definition, our new method cannot produce positive errors and all errors it produces therefore reflect underestimates of phylogeny size.

the table separates the phylogenetic errors from the experiments of figure  <dig> into positive and negative errors for indirect phylogeny inference using fastphase and haplotyper.

we next tested variation in accuracy with the number of haplotype sequences sampled for fixed mutation rate with θ =  <dig> . the results are shown in figure  <dig>  our direct methods show a slightly more pronounced advantage for 10-snp windows than 5-snp windows. this could simply be due to higher variance in the results of the 5-snp windows. table  <dig> shows the breakdown of the indirect methods into positive and negative errors, with both indirect methods again showing a mixture of comparable numbers of positive and negative errors across the parameter range, haplotyper again shows generally better accuracy than fastphase by this measure. one might expect that with increase in the number of haplotypes, the number of mutations required to explain the data would increase as well. therefore, the number of errors should increase with the number of haplotypes. this, however, does not seem to be the case in practice, an observation that can be explained by the fact that greater numbers of haplotypes provides more information and thus yield improved accuracy in phase inference. therefore, the number of phylogenetic errors roughly stay the same with the increase in the number of haplotypes for all the methods.

the table separates the phylogenetic errors from the experiments of figure  <dig> into positive and negative errors for indirect phylogeny inference using fastphase and haplotyper.

mitochondrial dna
the next step in our analysis used mitochondrial dna , which is naturally haploid. although one would not normally need to phase mitochondrial dna, we use it in our validation because it provides a source of large numbers of known haplotypes and because it provides a good model of recombination-free dna. the lack of recombination in the mitochondrial dna means that if the most parsimonious phylogeny on the genotypes is q-imperfect, then that region must have undergone a minimum of q recurrent mutations. the mitochondrial genome contains known regions of high mutation rate that allow us to validate the ability of phylogenetic imperfection to identify true sites of recurrent mutation, a key application of our method. for the purpose of these tests, we generated artificial diploids by randomly combining  <dig> mitochondrial complete sequences  from a data set of fraumene et al. <cit>  to produce thirty diploids. we then computationally inferred haplotypes from the all of the genotypes using fastphase. haplotyper was omitted from these tests because the data set was larger than it could process. we then constructed phylogenies for all sliding windows of  <dig> bases across the data set by each of three methods: maximum parsimony using true haplotypes, inferred haplotypes and directly from the genotypes. our method required  <dig> seconds on a desktop linux pc to reconstruct the phylogenies for all the sliding windows, clearly demonstrating its practical efficiency.

phase-known autosomal dna
only a very limited amount of true phase-known autosomal data is available. we chose to examine a set taken from the lipoprotein lipase  gene  <cit> , which is the only true phase-known data publicly available that has a sufficiently large population sample and number of snps to provide a challenging test for the methods considered here. the dataset consists of  <dig> haplotypes  belonging to three different ethnicities and  <dig> snps. the true genotypes corresponding to the haplotypes were not published for this data sets and so we duplicated the first haplotype to obtain  <dig> distinct sequences and then randomly paired them to produce  <dig> artificial genotypes from the true haplotypes. as in the previous case, we ran fastphase and haplotyper on all of the snps put together to obtain inferred haplotypes. unlike mtdna, the autosomal chromosomes undergo recombinations and so we used the hap webserver  <cit>  to break the  <dig> snps into blocks. we obtained  <dig> blocks which we assume to be recombination-free. we then estimated the size of the phylogenies within each of the blocks separately from the true haplotypes, inferred haplotypes and genotypes directly. note that we would expect this to be a particularly difficult dataset for our algorithm because haplotyper and fastphase made inferences from all the snps at once, whereas our method was run on each block independently.

the results are shown in figure  <dig>  where the x-coordinate of each point is the central snp of the block and the y-coordinate is the imperfection in that block. most of the blocks are imperfect. on this dataset, in contrast to the prior ones, the direct and indirect approaches showed almost equal total accuracy, with haplotyper being slightly worse. this difference may reflect a failure to eliminate all recombination from the data set or might be because any advantage of direct inference is too modest to stand out on such a small data set. even on a dataset that would be expected to be unusually easy for a phasing program, though, our method does no worse than the indirect approach. this dataset also suggests that the two approaches could be used in a complementary fashion, as the methods often bracket the true answer from opposite directions.

resource usage
we have, finally, examined the performance of our method in run time and space usage using additional simulation tests. we examined a range of data set sizes from  <dig> to  <dig> genotypes for fixed mutation rate θ =  <dig>  for 5-snp and 10-snp windows using averages for  <dig> repetitions per parameter value. run times were measured for our method and for fastphase and haplotyper. figures  <dig> and  <dig> shows run times for the method for 5- and 10-snp windows, respectively. our method is consistently faster than fastphase and slower than haplotyper for 5-snp windows. like haplotyper and unlike fastphase, our method appears insensitive to the number of input sequences. our method shows a substantial slowdown in moving from 5-snp to 10-snp windows. while the method is faster than fastphase for 5-snp windows it is on average a few times slower with 10-snp windows. this slowdown is to be expected since our method constructs a program of potentially exponential size in window size, haplotyper is consistently the fastest of the methods for both window sizes.

we further assessed space usage of our method based on the maximum linear program relaxation size examined over the course of a given problem instance, averaging this value over the  <dig> trials. here size is expressed as the product of the number variables and constraints. figures  <dig> and  <dig> show the results for 5- and 10-snp windows. the results show a high degree of noise, with a single outlier point requiring roughly 100-fold more space than the others. nonetheless, program size appears generally to increase with number of input sequences. space usage also increases substantially with window size, which we would again expect given that worst-case program size is exponential in window size.

CONCLUSIONS
we have developed the first practical, general methods for finding maximum parsimony haplotypes from unphased genotype data and have used them to assess the costs introduced by computational phasing prior to phylogenetic inference. our methods used a collection of heuristics based on the theory of steiner trees, a variant of a flow-based ilp, and a branch-and-bound approach to solve problem instances with high imperfection that were not solvable by any prior method. while the method presented here is specific to the problem of inferring purely mutational phylogenies, similar approaches may prove productive for inference of ancestry by more general models of molecular evolution, such as ancestral recombination graphs . empirical tests on simulated and semi-simulated data show that direct phylogeny inference from genotypes leads to fewer errors than does the standard practice of building phylogenies from phased data. methods for this problem have several practical applications. most important is to estimate the minimum number of recurrent mutations required to explain a set of observed genotypes. a large such value may indicate frequent recurrent mutation or gene conversion or a selective pressure to recurrently alter a given allele. researchers trying to establish such effects need to ensure that the size of the phylogeny is not an artifact of phase inference. the method should similarly be useful for improving estimates of local mutation rates. other applications include improving the power of association tests by eliminating spurious effects from recurrent mutation, and providing alternative methods for detecting recombination-free autosomal regions and performing phase inference from genotype data.

