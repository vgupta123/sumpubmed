BACKGROUND
as the genome projects continue to generate sequence data, it is increasingly common to find protein superfamilies with thousands of members in the protein database. given sufficient numbers of sequences, sensitive iterative search and alignment procedures, such as psi-blast  <cit>  and sam  <cit> , often reveal that protein families previously thought to be distinct are, in fact, distantly related. protein structural analysis likewise reveals subtle evolutionary relationships between protein families sharing very little sequence similarity. since our ability to make protein structure and function predictions depends in large part on alignment accuracy, it is thus important to develop alignment methods able to handle these increasingly large and diverse sets of distantly related sequences.

certain protein families within these large superfamilies are often very highly conserved across distantly related organisms. such proteins include, for example, certain metabolic enzymes, dna replication and repair factors, certain structural proteins, such as actin, the motor protein dynein, and regulatory and signalling factors, such as protein kinases and ras-like gtpases. while many of these proteins seem relatively well characterized, we still cannot account for the strong selective constraints preserving their observed high degree of sequence conservation across major taxonomic groups. presumably these patterns of conservation contain implicit information regarding still unknown functional mechanisms. to access this information, we recently developed a statistically based approach, called contrast hierarchical alignment and interaction network  analysis  <cit> , that identifies, categorizes, and statistically characterizes co-conserved patterns in multiple alignments. the power of this approach strongly depends on the quality of the alignment, which thus motivated the development of the theoretical concepts and strategies described here.

aligning distantly related sequences presents unique algorithmic and statistical challenges because such proteins often only share a minimal structural core with sizable insertions occurring between, and even within, core elements. classical dynamic programming-based multiple alignment procedures typically have considerable difficulty spanning across these insert regions because the log-odds scores associated with weakly conserved core elements are often too low to offset the substantial gap penalties that such insert regions incur. this problem is further exacerbated when core elements contain short insertions or deletions within them.

to address this problems, we previously devised motif  based multiple alignment procedures  <cit>  that can easily jump over non-homologous insert regions. this approach seems easier to justify than attempting to align regions for which there is no statistical evidence of relatedness. a block based alignment strategy thus seeks to detect islands of subtle sequence similarity within otherwise dissimilar sequences. fortunately, even when the conserved motifs are very subtle, such a procedure can take advantage of large numbers of available sequences to detect weak, yet statistically significant similarities.

altschul at the national center for biotechnology information  likewise sought to address this problem through generalized affine gap costs  <cit> , but the utility of this approach is unclear, as the ncbi currently does not support any public programs based upon it. the programs muscle  <cit>  and mafft  <cit>  also are designed to avoid alignment of non-homologous regions and in other respects are generally superior to more widely used multiple alignment programs, such as clustalw  <cit>  and t-coffee  <cit> . because muscle and mafft can handle large data sets, we explored the use of these programs for chain analysis . somewhat surprisingly, these failed to achieve the degree of accuracy needed to detect subtle, co-conserved patterns, such as those recently identified and structurally confirmed within p loop gtpases  <cit> . we found that, although these programs align regions globally conserved in the sequences well, for several large test sets they fail to accurately align regions conserved only within more closely related subsets. this is, of course, a major drawback to their general application for chain analysis. by contrast, psi-blast  <cit> , which seems less likely to produce high quality global alignments given its simple alignment procedure nevertheless in many cases does a better job of aligning database sequences relative to the query. thus psi-blast  has turned out to be more generally useful than these other methods for chain analysis, which like psi-blast is query centric. note, however, that a systematic comparison of various methods within the context of chain analysis has not yet been done.

more relevant to our purpose here, another drawback to the use of muscle, mafft, and similar programs for chain analysis is that these will align randomly generated sequences – a characteristic incompatible with the statistical basis of chain analysis. muscle and mafft perform well on small sets of relatively diverse representative sequences, such as the balibase benchmark sets  <cit> , because they incorporate heuristics that unfortunately also can compromise statistical rigor and, as a result, confuse random noise with biologically valid homology. statistically the best alignment for random sequences is the 'null alignment', that is the procedure should leave such sequences unaligned – a property of psi-blast that played a key role in choosing it for chain analysis.

to maintain statistical rigor in our formulations here, we will 'let the data speak' by modelling only those characteristics of the sequences that can be justified by the input data. such an approach cannot be applied, however, to small benchmark alignment sets, because these lack sufficient sequences – less than the number of amino acids whose parameters are being estimated. thus, while a rigorous statistical approach has severe limitations when applied to small datasets, it works very well when applied to large, diverse sets of distantly related sequences, as demonstrated, for example, by some of our earlier analyses  <cit> .

two other theoretical issues, which are important to the multiple alignment problem, are devising an objective measure of alignment quality and an efficient strategy for finding the best alignments based on this measure. our previous methods  <cit>  addressed these issues using a bayesian statistical approach for modelling an arbitrary number of multiply aligned ungapped blocks, each of arbitrary length, in conjunction with a gibbs sampling procedure for exploring the 'space' of all such alignments. gibbs sampling is a markov chain monte carlo  method that iteratively realigns the sequences with probability proportional to how much the model is thereby improved. theoretically, beginning from an arbitrary starting alignment, this process will ultimately sample alignments according to the posterior distribution defined by our bayesian model. exploring the alignment space in this way is more efficient than taking a greedy approach  because an element of chance allows the sampler to maneuver around locally optimal traps.

within this mcmc sampler we implemented specific operations on the alignments, including those allowing for realignment of a sequence against the alignment model, shortening or lengthening of blocks, and creation of recombinant alignments. such operations function like catalysts to help the sampler avoid or more quickly escape from local optima. here we expand on the number of these operations and modify our bayesian model to allow for short insertions or deletions within blocks. in theory, such an approach could be used to sample representative multiple alignments from the posterior distribution, which is relevant to chain analysis because this could be used to adjust position-specific amino acid frequencies for alignment uncertainty. doing so for the model and operations described here, however, is non-trivial and thus is a topic for a future publication built upon this one. our primary objective here is merely to obtain the optimal alignment. thus we also introduce various annealing-like strategies for luring the sampler toward optimum alignments. these include simulated annealing, which is applied within sampling routines, and other intervention strategies. our primary motivation for developing and implementing these concepts and strategies is to improve chain analysis, as is illustrated here for g-protein α subunits, which belong to the p loop gtpase class  <cit> , prolyl endopeptidases, which belong to the α,β-hydrolase fold class  <cit> , and transitional endoplasmic reticulum  atpases  <cit> , which belongs to the aaa family  <cit>  within the aaa+ class  <cit> .

problem definition
the fundamental problem addressed here is to identify the essential features – the common structural core – characteristic of a large set of distantly related proteins. given an input sequence set, we build a bayesian statistical model with adjustable parameters to reflect the relationships among the proteins. we also design a stochastic search algorithm, with an mcmc sampler as its backbone, to explore possible alignments and corresponding model parameters in order to find alignment models that best 'explain' the input data. the model parameters specify, for example, the number and lengths of the motifs, their locations within each sequence, the residue frequencies observed at each position in each motif, and other properties . we may thus envision our sampler as searching through a discrete space where each point, corresponding to a particular alignment, has a probability associated with it. the probability function appears fairly smooth inasmuch as nearby points  have roughly comparable probabilities. as the sampler traverses from one point to another, it favors moves toward the better alignments, that is, toward that part of the alignment space with greater posterior probability. since it is computationally prohibitive for the sampler to consider many transitions at one time, a key design issue is the selection of allowed transitions between points.

RESULTS
the block-motif model
we first define the alignment model in precise mathematical terms, which provides a scoring scheme that allows us to judge which alignment is better than another. here, for the sake of conciseness and readability, we will keep the discussion on a conceptual level whenever possible. interested readers can consult our earlier publications for further details  <cit> .

as illustrated in fig.  <dig>  this previously described block-based motif model assumes that the aligned core of each protein sequence consists of m co-linear ungapped motifs, of width w <dig> ... , wm, respectively. each motif is modelled by a position specific frequency matrix Θi, whereas residues outside the motif blocks follow a common frequency distribution. independent prior dirichelet distributions are employed for these frequency parameters.

since both m and the wi's are unknown, we assume that they are uniformly distributed in a certain range a priori . we also employ a "fragmentation model," which allows non-informative aligned columns to be ignored by the motif model. although we use no explicit gap penalties between motifs, our prior imposes a large penalty on alignments with large m. let s denote the sequence data and let a denote the motif alignments . then the posterior alignment distribution is:

p ∝ p ∫ ppdΘ.

based on this distribution, our algorithm  attempts to maximize p, the so-called "maximum a posteriori " score.

hidden markov models for gapped motifs
a major drawback of the previous block-based alignment approach is that it disallows insertions or deletions within motif blocks. here we describe hidden markov model   <cit>  structures for insertions and deletions, which will be used by our current algorithm via the operation gapalign . the general architecture for these hmms is given in fig.  <dig>  and detailed descriptions, including the definition for our scoring function g, are given in methods.

for an intuitive notion of how within-motif penalties influence the total map score, consider a gap-opening penalty of say  <dig> bits  and an extension penalty of  <dig>  bits. then, for example, the overall map would need to improve by  <dig> bits in order to justify a 'surgical operation' on a sequence involving an insertion of three dummy residue  or a deletion of three residues . the statistical problem is thus that of finding the right penalty so that the sampler only adds insertions or deletions when the data provides sufficient justification. in a bayesian context, this justification is based on the posterior inference of the overall number of insertions and deletions from what it finds in the aligned sequences.

markov chain monte carlo methods
the bayesian analysis described in methods provides us the posterior distribution of the alignment up to a normalizing constant. although this distribution defines the answer to our problem, namely inferring the optimal alignment, it is difficult to make sense out of it because of the huge size of the alignment space. fortunately, recent progress in using mcmc methods for statistical analysis has made it possible to study this function.

mcmc methods, of which the gibbs sampler is a special case, refer to a set of techniques developed by physicists since the 1950s to simulate variables from a given probability distribution up to a normalizing constant. the central idea of these techniques is to evolve a markov chain, each step of which perturbs the current state  slightly, with the equilibrium distribution of the chain being the target distribution. a mcmc scheme is usually constructed in two steps:  propose a new state according to a certain reversible transition rule, and  accept or reject the proposal according to the probability ratio between the proposed and the current states  <cit> .

the broad utility and general applicability of these techniques are exemplified and popularized by recent developments in statistics: if one can sample from g one obtains a set of "typical" alignments according to the posterior distribution, which provides information regarding the most likely alignment supported by the data and its variability. in practice, however, one may wish to find the optimum of this function and explore only around this optimum considering the difficulty of summarizing a set of distinct alignments in a meaningful way. mcmc is also an important ingredient of an optimization technique termed "simulated annealing"  <cit> , of which we will develop a variation. a good mcmc scheme should have the following property:  its transition rules should collectively allow the sampler to access every point in the space;  these transitions should also allow for global changes, such as, for example, recombination between two alignments; and  the acceptance rate of these proposals should be reasonable . the sections below will focus on designing such transitions for multiple alignment.

an algebraic system for touring the alignment space
the elementary mathematical operations of addition and subtraction define a means of transitioning between points in the discrete space of natural numbers. "global" operations, such as multiplication and integer division, allow transitions between more distant points in this space. likewise, we define both elementary and global operations on multiple alignments as a means of transitioning between points in alignment space. in this case a set of unaligned sequences  serves the same role as the natural number zero. formal mathematical descriptions of the alignment and of certain simple operations are provided in our earlier papers  <cit> . since the new operations described here involve various combinations of these simple operations, it is straightforward to derive these new operations from the previously published descriptions.

there are two issues to consider in the design of multiple alignment operations. first, the reversibility of mcmc algorithms requires that every operation have an "inverse" so that the sampler can readily transit in either direction. second, to help find the optimal alignment according to our bayesian model, which is our main objective, annealing techniques and less restrictive acceptance rules should be considered for certain complex operations. by doing so the target alignment distribution has to be distorted to some degree, though the global optimum of the distribution remains the same.

all alignments described here are collinear multiple alignments , which are defined to contain zero or more motif blocks arranged collinearly in each sequence. partial or complete deletion of any motif from a particular sequence is modelled by aligning that motif against null residues , which the sampler may insert anywhere in the sequence. sequences may also contain more than one repeat of the entire protein domain, each of which is modelled by the full set of motifs.  for clarity, we describe operations deterministically, though it should be kept in mind that our sampler applies these stochastically.

elementary operations
the hideinsert operation  is applied to 'surgically' remove a region of the sequence that appears to correspond to a typically short insertion within a conserved motif. this operation thus changes the real sequence into an idealized sequence that, presumably, more closely resembles the canonical characteristics of the protein class. as a result, the sampler needs to maintain both a real and an idealized version of each protein's sequence and to store the operational derivation used to obtain the ideal sequence from the real. algorithmically it is convenient to deal with insert regions in this way because otherwise the sampler would need to look up the locations of insertions and deletion within each sequence when applying other operations. the filldeletion operation  likewise converts a sequence that contains a deletion of either part of or all of a motif into an idealized sequence in which the deletion has been filled in with null or 'dummy'  residues. note that hideinsert and filldeletion merely define data structure interconversions that allow basic operations, which were initially defined for ungapped motifs, to be efficiently applied to gapped motifs.

the align operation assigns motif positions within a sequence and thereby adds that sequence to the alignment, unalign removes the sequence from the alignment. note that these operations disallow gaps within motif blocks.

the addcolumn and deletecolumn operations add and remove aligned columns, respectively. note that these operations may add or remove columns internal to a motif as well as at the edges. moreover, addcolumn may also insert a column an arbitrary number of residues beyond the current edge of a motif. this is important for motif 'fragmentation'  <cit> , a procedure that allows certain nonconserved positions inside of a motif to be ignored by the alignment statistical model.

compound operations
elementary operations can be combined in a coordinated manner in various ways to produce compound operations that better facilitate escape from local traps. for example, gapalign  combines the row operation align with the sequence operations hideinsert and filldeletion in order to add a sequence to an alignment with insertions and deletions. the gapalign operation is performed using dynamic programming to obtain a gapped alignment of a sequence against a statistical model of the current alignment. the trace back procedure determines how to apply the hideinsert and filldeletion operations to the true sequence and how the align operation is then applied to the resultant idealized sequence.

we define several compound operations on a motif block: addblock, shiftright, and trimright . another compound operation, movecolumn, which transfers a column from one position to another within a block, is its own inverse. conceptually, addblock and deleteblock simply iteratively apply the addcolumn and deletecolumn operations, respectively. because our motif alignments are collinear, the position of an added block within each idealized sequence must be specified in a manner consistent with this collinear arrangement and, in order to add a new block in this way, the sampler may need to insert null residues at certain positions within some of the idealized sequences. this is an example of operational flexibility. similar operational flexibility is required for the shiftright and shiftleft operations, which remove one or more columns from one end and append it to the other end of a motif. trimright and trimleft allow poorly conserved residues to be trimmed from a motif block based on their relative entropy. these operations thus provide a means to manually edit motif-based alignments as discussed below.

three compound operations involving two motif blocks are: transfercolumn, splitblock and fuseblocks. transfercolumn deletes a column from one block and adds it to another block. splitblock splits a single block into two leaving two contiguous motif blocks in each of the idealized sequences. during future realignment operations the sampler typically induces these abutted blocks to drift apart. splitblock's inverse operation, fuseblocks, merges two blocks into one, which typically requires forced realignment of motif positions in each sequence in order to join the blocks together. all such forced realignments are followed by additional optimization via sampling prior to deciding whether to reject or accept this new configuration. we thus typically have to violate the mcmc's acceptance-rejection rule to enable such a move, which distorts the target distribution. the awkwardness of this procedure may be advantageous, however, inasmuch as it forces the sampler out of local traps in alignment space. fig.  <dig> illustrates the effect of applying compound operations during gibbs sampling.

recombinational operations
as an aid to locating the optimum alignment, we define recombination operations that combine the best features of two distinct, fairly well refined alignments. these operations require that the sampler first generate a population of fairly well refined alignments starting from distinct, randomly selected points in alignment space. all of these input alignments must, of course, contain the same set of sequences.

the recombine operation must be applied to two alignments that are fairly similar because the sampler needs to locate at least one crossover point between them. a crossover point is a set of positions, one position in each aligned sequence, such that the same set of blocks in the first alignment lie to the left of each of those points, while the same set of blocks in the second alignment lie to the right of each point. because this requirement often proves difficult to satisfy for every sequence, we define the recombine operation flexibly by allowing a certain number of sequences to violate this rule. in this case, violating sequences are removed prior to recombination and sampled back in afterwards .

the intersect operation takes as input two distinct alignments and produces a new alignment containing only those aligned columns common to corresponding motifs in both input alignments. more precisely, we first find the common blocks shared by the two alignments, where a common block is defined as two aligned motif blocks  that overlap within corresponding sequences. to allow for some flexibility, these are defined as blocks for which at least some minimum fraction  of the sequences are consistently aligned in both input alignments.  then, for each pair of common blocks, we find the sub-block shared by both blocks. next, we create a new alignment containing only these intersecting sub-blocks. finally, sequences that were inconsistently aligned between the two starting alignments are sampled back into the resulting alignment. the intersect operation allows the sampler to be reinitialized starting with a consensus alignment that aligns only those regions with high likelihood scores and eliminates those regions about which the sampler is less certain. subsequent sampling will then extend these sub-blocks, add new blocks, and explore more extensively the alignment space.

parameter settings for operations
there are no absolute rules on how to choose parameter settings for these algebraic operations, such as, for example, the maximum increase in motif length allowed during the movecolumn operation or the number of disordered blocks to tolerate for the recombine operation. we find, in fact, that it often matters little which settings are used and the slight degree to which it does matter depends on the particular protein class being analyzed. as a result, any biologically reasonable parameter settings work well. for example, since weakly conserved motifs are never a hundred residues long, motif blocks typically should be limited to no more than, say, fifty residues in length. nevertheless our algorithm tolerates unreasonable parameter settings, because then it either simply rejects the corresponding alignment space transitions  and/or learns to avoid applying useless operations through its memory module, as described below.

high level sampling strategies
having specified various operations on the alignment space, we now need to specify when and how often to apply them, as well as how to escape from local traps and thus to most rapidly converge on an optimum or nearly optimum alignment.

providing the sampler with a memory
since some of the alignment operations are computationally expensive, it would be helpful to avoid applying them over and over again when this proves to be unfruitful. for example, if the sampler has already converged on the correct number of motifs, applying the addblock operation may be a waste of time. on the other hand, we don't want to eliminate any operation entirely, as at some point it may be useful. to do this we define both short-term and long-term sampling memories. the short-term memory allows a rapid response to sudden changes while the long-term memory adds stability so that the sampler does not over respond to short term trends. details are given in methods.

simulated annealing with a thermostat
let the target alignment distribution be denoted generically as π . as the sampler converges on near optimum alignments, typically it has difficulty 'dropping' into the global optimum of π  because the chance of selecting the highest probability alignment is still very small due to the sheer number of near optimum alignments. this is true for the same reason that the most likely outcome of obtaining exactly  <dig>  heads and  <dig>  tails in  <dig>  flips of a fair coin is extremely unlikely.

a standard way around this problem is to take power of π  to some exponent, renormalizing it and using the "powered-up" distribution, denoted as πt ∝ π1/t  with the "temperature" parameter varying from a very large value to near-zero, for sampling. this procedure is a key component of simulated annealing  <cit> , which has the same effect on sampling as lowering the temperature has on annealing of single stranded dna into double stranded dna in solution. by 'cooling' the system , we raise the probability of high-density points and lower the probability of low-density points, so as to allow the best alignment to win out over alignments that are nearly as good. if the temperature is lower too abruptly, however, the sampler may get trapped in a sub-optimum alignment, so that the annealing strategy needs to be devised carefully.

we have built a 'thermostat' into the sampler that keeps track of variations in the  probability densities of the sampled alignments. if the variance of log π  in a given number k of consecutive iterations at a given temperature is below a certain threshold , the sampler may be stuck in a  optimum, and the thermostat raises the temperature a bit. on the other hand, if the log π  are varying wildly and, in particular, if they are greatly diverging from the best  alignment found thus far, then the sampler may be wandering away from near optimum alignments and the thermostat lowers the temperature. this approach thus attempts to keep the sampler just above its 'glass transition temperature'  <cit> , designated tg. details are given in methods.

since there are no absolute criteria for determining whether the sampler has actually found the optimum alignment, it is necessary to devise heuristics for terminating the computation. we retain the same criterion used in earlier gibbs samplers, such that if the alignment fails to improve after a specified number of sampling cycles, then the program stops and returns the best alignment found. since picking the right number of cycles depends heavily on the number and nature of the input sequences , the user can modify this parameter. as an alternative strategy, two or more programs may also be run in parallel until they both converge on the same alignment.

progressive refinement strategy
when painting a picture, it is helpful to first draw a rough sketch so that details will end up in the right place relative to each other. similarly the sampler uses the following progressive refinement strategy to avoid being too "shortsighted."

there are five stages to this strategy. in the first stage, the sampler applies the align operation, which aligns the sequences against contiguous ungapped blocks; it also applies compound ungapped motif operations. the initial numbers of block motifs and columns in each block are sampled from binomial distributions with means between roughly 5~ <dig> blocks and 10~ <dig> columns each, respectively. in the second stage, which is introduced after the sampler begins to converge on a local optimum under the ungapped block-motif model, elementary and compound column operations are introduced, which allow these ungapped blocks to 'fragment', thereby permitting nonconserved columns to be ignored by the alignment model . recombination operations are also applied during and after this stage. in the third stage, the gapalign operation based on a simple gapped sampling procedure  <cit>  with very conservative gap penalties is introduced, which allows the sampler to add short gaps within motif blocks and to delete part or all of a block. in the fourth stage, the number of blocks is fixed  and recombination and simulated annealing procedures are used to help guide the sampler into a  global optimum. these first four stages are implemented in the program gismo . a fifth stage, which is implemented in the program garma , recombines a set of alignments independently found by gismo and optimizes the recombinants using a gapalign procedure based on the hmm model described above.  gapalign sampling is performed by viterbi alignment of the sequence against the hmm where the hmm emission and transition probably parameters are sampled from the posterior distribution. afterwards the resultant alignment is either rejected or accepted based on our new scoring function g.

manual application of alignment operations
despite attempts to codify and fully automate optimization of a multiple sequence alignment, the algorithm may still create an alignment model that lacks certain properties observed to be biologically important for a particular class of proteins. take the situation, for example, where a motif, which occurs as a single block in most of the proteins, is split in two by a sizable insertion in other proteins and where the sampler, due to the a priori parameter settings chosen before the analysis, fails to split this motif into two blocks. in this case, a biologically more meaningful alignment may be achieved by manually intervening to split this ungapped region . to accommodate such tweaking, we thus allow manual application of various operations. we find that splitting and trimming of aligned blocks are particularly helpful in this regard. such manually modified alignments then may be reintroduced into a population of similar alignments for recombination and selection via our genetic algorithm  <cit>  followed by further optimization.

implementation and examples
the theoretical concepts and strategies just described were implemented in the programs gismo , garma  and gambit . garma recombines the output alignments provided by gismo and then applies simulated annealing strategies on the recombinants. gambit performs on a single alignment the same optimization procedures that garma performs on recombinants. manual application of alignment operations may be performed using another program, tweakaln. these programs along with sample alignments are available from the authors. multiple alignment of thousands of sequences in this way may take substantial time , but this is not critical because, once performed for a particular protein class, such an alignment can be updated readily by seeding the sampler with a previously optimized alignment. here we apply these programs to several large protein classes within the context of chain analysis, which is our primary reason for generating such alignments.

application to chain analysis
chain analysis both decomposes into distinct categories and quantifies the sequence constraints associated with conserved patterns in a multiple alignment. this yields evolutionary clues regarding the underlying structural mechanisms presumably preserving these patterns. aspects of these mechanisms can be inferred by comparing category-specific selective constraints with known structures of members of the protein class being investigated, as illustrated in three recent publications  <cit> .

'contrast hierarchical alignments', such as are shown in figs  <dig> , <dig>  are the primary output from chain analysis. in constructing such an alignment, three sets of related sequences are multiply aligned:  a 'displayed set',  a 'foreground set', which is a superset of the displayed set, and  a 'background set'. the displayed set corresponds to the aligned sequences of interest within the foreground set . the foreground set corresponds to the sequences whose selective constraints are being measured. these are not shown explicitly, but rather are merely represented by conserved patterns and residue frequencies shown below the displayed alignment . the original chain analysis procedure uses a modified version of the psi-blast algorithm to align these sequences. here these psi-blast alignments are compared with motif-based foreground alignments created using gismo, garma, gambit, and tweakaln.

chain analysis measures selective constraints in terms of the difficulty of randomly drawing the amino acids observed at a particular position in the foreground alignment from the distribution at that position in the background alignment. in the examples here, unless specified otherwise, the overall frequency of amino acids generally observed in proteins serves as an implicit background set at each position. foreground positions with compositions closely resembling the background presumably are subject to little or no selective constraints, while positions with compositions strikingly different from  the background are subject to strong constraints. in figs  <dig> , <dig> these constraints are displayed in the histograms above the alignments.

gα and p loop gtpases
we first examine in this way g protein α subunits. g proteins  <cit>  are heterotrimers, consisting of an α, a β and a γ subunit, that mediate transduction of extracellular signals to the cellular interior. as do many members of the p loop gtpase class, the gα subunit functions as a binary switch that is turned on by binding gtp in response to the signal and thereby relays this information to downstream components of the pathway. this switch is turned off by hydrolysis of gtp to gdp, an event mediated by gtpase activating proteins .

gα subunits are unique among such gtpase switches inasmuch as their gap domain is contained within the gα polypeptide chain itself rather than existing as a distinct protein. this unique arrangement presents particular difficulties for chain analysis because, during subsequent iterations, the psi-blast algorithm tends to slightly overextend the alignment beyond gα's region of homology to other p loop gtpases and into the c-terminal region of the gap domain. as a result, the foreground patterns for the walker a motif are mistakenly aligned against the c-terminal end of the gap domain . by contrast, the gibbs sampler avoids this misalignment problem because it can readily jump over the internal gap domain . this thus illustrates how our motif-based approach avoids a serious problem encountered by psi-blast.

α,β-hydrolase fold enzymes
similar misalignment problems may be encountered between motif regions even when the aligned proteins lack large inserts. this is seen, for example, when aligning α,β-hydrolase fold proteins  <cit> , which correspond to a large class of enzymes possessing a catalytic triad  at their active sites. these three residues are involved in an electron transfer mechanism and thus are generally very highly conserved, despite the often very weak pairwise similarity between many members of this class. chain analyses of prolyl oligopeptidases reveals that our motif-based alignment assigns very strong selective constraints to all three of these catalytic residues, the aspartate and histidine of which are shown in fig. 5a. this is as expected, because conservation of one member of the catalytic triad is highly correlated with conservation of the other two, as the α,β-hydrolase electron transfer mechanism requires all three residues. in contrast, the psi-blast alignment assigns a strong selective constraint to the catalytic serine  but much weaker constraints to these other two catalytic residues . this is because the psi-blast algorithm finds it much easier to correctly align the catalytic serine but, due to weak sequence similarity, often either misaligns or fails to extend the alignment into the c-terminal region of this domain. . thus our motif-based approach again provides a better measure of the selective constraints acting on these residues.

p <dig> an aaa+ atpase
improved identification of a short insertion within a motif by our approach is illustrated through chain analysis of p <dig>  a transitional endoplasmic reticulum aaa+ atpase . aaa+ atpases are a large and diverse class of chaperone and chaperone-like proteins  <cit> . they are characterized by the presence of one or more aaa+ modules, each of which consists of an α,β-fold domain, which it shares with other p loop ntpases, followed by a helical bundle domain. p <dig> contains two aaa+ modules, designated d <dig> and d2; our analysis was performed on the d <dig> module, whose structure is known  <cit> . these aaa+ modules often associate to form homohexameric complexes such that a prominently conserved arginine  and a conserved acidic residue  in one module are positioned near a walker b conserved acidic residue  and a bound atp-mg2+ in an adjacent aaa+ module.

when our motif-based approach was applied  to aaa+ atpases , it introduced within the box vii motif of the p <dig> d <dig> module a two-residue insertion  immediately before a prominently conserved arginine . by contrast, the psi-blast alignment tends to misalign this region and, consequently, obscures both the two-residue insertion and the prominence of the conserved arginine . the phenylalanine within this insert forms a ch-π interaction with an alanine  within the adjacent aaa+ module's three-helix bundle domain. notably, an arginine often occurs at this alanine position in related aaa+ modules and is believed to sense bound atp in the adjacent aaa+ module.  psi-blast again does a poorer job aligning this sensor ii arginine against a <dig> of p <dig> compared with our motif-based method. the improved motif-based alignment thus better reveals how the p <dig> aaa+ d <dig> module presumably utilizes an alternative configuration for sensing and responding to bound nucleotide relative to typical aaa+ modules . in particular, two highly conserved p <dig> family-specific features – namely the phe-gly insertion, which is highly conserved in eukaryotes though replaced by a pro-gly in eubacteria and archaea, along with a third well conserved arginine directly preceding this insert  – are likely to perform an important role associated with p97's unique cellular function.

CONCLUSIONS
with a view to improving alignments for chain analysis, we have enhanced our earlier motif-based methods by developing  a hmm for insertions and deletions within motifs,  an expanded algebraic system of operations on multiple alignments and  various annealing and sampling strategies that facilitate rapid convergence on optimum or near optimum alignments. furthermore, our approach, due to its rigorous statistical basis, fills a gap left by current multiple alignment methods inasmuch as it aligns only those characteristics of the input sequences that may be justified statistically. thus it is useful for statistical analysis of conserved patterns in multiple alignments. our statistical model likewise provides objective criteria for evaluating curated alignments, thereby guiding manual application of various operations. in the future, our mcmc sampling methods could be used to estimate alignment uncertainties, which will be useful for estimating background amino acid frequencies for chain analysis. these approaches also serve as a starting point for further enhancements that integrate mcmc sampling, hmm and psi-blast methods, which, based on our earlier analyses  <cit> , seem likely to improve both alignment accuracy and search sensitivity.

when this motif-based approach was applied to chain analysis of families belonging to large and diverse protein classes, we found numerous examples, three of which are described here, where this does a better job of revealing subtle, biologically important sequence features than does psi-blast. this is in large part due to the ability of our statistical model and sampling strategies to find weakly conserved islands of homology within a sea of essentially nonconserved regions. while this motif based approach will not become the default method for chain analysis – especially considering that psi-blast alignments also may be optimized using these approaches – it, nevertheless, often more accurately aligns very distantly related sequences and thus can provide a better measure of selective constraints in this situation.

