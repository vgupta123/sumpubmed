BACKGROUND
bacillus and clostridium species can adapt to rapidly changing environments and starvation by developing spores. an endospore is a dormant non-reproductive structure produced by these gram-positive bacteria and is a survival mechanism adapted to spending a long period of time in hostile conditions. the sporulation process in bacillus species causes singular molecular and cellular changes in the cell which are not seen in the vegetative state  <cit> . one of these changes is the biosynthesis of calcium dipicolinate, which is found in sporulated cells but not in the vegetative ones.

members of the genus bacillus are widely distributed in the environment and because their spores are so resistant their control is of considerable importance in the food manufacture  <cit> . some of these bacteria are pathogenic including b. cereus and b. subtilis which cause food poisoning. the most notorious member of this genus is b. anthracis, which is the causal agent of anthrax, and the rapid identification of spores and bacterial identification are paramount because of its importance as a potential biological warfare agent  <cit>  and in bioterrorism  <cit> . thus there is a need to have a generic characterisation method that allows rapid identification of spores and typing of bacteria.

many automated analytical techniques such as raman spectroscopy  <cit> , liquid and gas chromatography  <cit>  and curie-point pyrolysis mass spectrometry   <cit>  have been used to identify bacterial spores. all of these methods rely on chemometric analyses of the data and the question arises as to how robust these mathematical models are. however, the vast majority of modelling approaches are considered "black boxes" as they do not readily allow the specific association between input analytical data and output classification to be revealed.

these types of data analysis involve a large number of features to be analysed, such as several mass spectra. this high number of features makes interpretation of the data extremely difficult therefore, we start our data analysis by reducing data dimensionality. this data reduction step selects a small subset of key relevant masses to be further analysed and discards the less important ones. this feature selection procedure uses bayesian network learning methods coupled with genetic algorithms to identify bacterial spores and classify bacillus species.

a bayesian network  is basically a graphical model of a probability distribution over a set of variables of a given problem domain  <cit> . this graphical model provides a compact and intuitive representation of the relationships among variables of a given problem domain. nodes on the graph represent variables from the problem  and an arrow linking two nodes indicates a statistical correlation between them. this statistical correlation falls broadly into one of the two categories:  "positive correlation" indicates that the values of both variables increase or decrease together, and  "negative correlation" indicates that as one variable increases, the other decreases, or vice versa. the network structure of a bn encodes probabilistic dependencies among domain variables and a joint probability distribution quantities the strength of these dependencies  <cit> . the resulting graphical model or network has two main uses.  visualization of probabilistic relationships: the graphical model provides direct and accurate information about the underlying interactions among variables of interest, m/z intensities in our case, and  inference: the bayesian network is intrinsically an inference model and can be used to predict outputs or to classify new samples.

we use statistical and data mining algorithms to identify bacillus spores automatically from their curie-point pyrolysis mass spectrometry data. this process extends the data mining analysis to a two step hierarchical-based classification that further identifies the bacilli into one of their respective species. first, the data dimensionality is reduced by a feature selection process using genetic algorithms  and bns in parallel. subsequently, once that the relevant variables are identified, a classification model using only bn is built based on the reduced data set, and this process undergoes full validation. next a statistical analysis of the interactions among variables and classes and variables and variables is performed using the built bayesian network model. as this combined process identifies probabilistic biomarkers in the data set it is possible to develop predictive, testable models that allow inference of biological properties of the bacilli. the computer code for the ga-bn algorithm developed on this work was written in r programming language  <cit>  ver.  <dig> . <dig> and is freely available, together with the bacillus data set, on request to the corresponding author.

methods
the bacillus data set
the work uses the bacillus py-ms data set reported in  <cit>  and described as an additional file . unlike most data sets which concentrate on a single or only a handful of bacillus species, this data set investigates  <dig> different strains of aerobic endospore-forming bacteria encompassing seven different species: bacillus amyloliquefaciens, bacillus cereus, bacillus licheniformis, bacillus megaterium, bacillus subtilis , bacillus sphaericus, and brevibacillus laterosporus. these bacteria were grown axenically on nutrient agar as detailed in  <cit>  and vegetative biomass and spores were analyzed in triplicates by curie-point py-ms. the data set contains  <dig> bacillus samples;  <dig> are vegetative and  <dig> are sporulated. for a more detailed explanation of this data set see  <cit> . a phylogenetic tree of the type strains of the bacillus species studied in this paper can be found in  <cit> .

data analysis
the overall work flow for the data analysis is shown in figure  <dig> and involved a two stage process. the input data sets for the data analysis contained the full py-ms spectra,  <dig> m/z intensities. the data were normalised as a percentage of the total ion count to remove the influence of sample size per se.

stage  <dig> employed a genetic algorithm for feature selection with classification of  either spores versus vegetative biomass or  speciation to one of the seven different species. the classifier used is the bayesian network that best fits the best solution  found by a genetic algorithm. in this supervised learning procedure, the measurement of the fitness of a ga solution in this study follows a wrapper approach. the wrapper approach searches for an optimal feature subset tailored to a particular algorithm, such as a bayesian network. for more information on wrapper and other feature selection approaches see  <cit> .

stage  <dig> involved the fitting of a new bayesian network model to the best ga solution found on the previous stage. the built bn model is then used to determine probabilistic relationships between the m/z intensities selected by the ga and the classification . this two step process and model validation are detailed below.

genetic algorithms 
a ga is an optimization procedure that evolves a population of candidate solutions to solve an objective function  <cit> . a ga repeatedly applies operators based on natural selection and genetic recombination to the candidate solutions. in a standard ga the initial solutions are randomly generated using a uniform distribution. the candidate solutions are called chromosomes. the chromosomes are usually represented by fixed-length strings over a finite alphabet. the term fitness is used to describe the quality of a candidate solution. the fitness is a measurement of how well the chromosome solves the objective function. the fitness associated with a chromosome is used to select probabilistically which chromosomes from the population will recombine and possibly generate new solutions. a genetic operator called crossover is applied to create two new chromosomes  from a pair of selected chromosomes called parents. the crossover consists of swapping random subsets of the genetic material from both parents. because of the selective pressure applied on the population through a number of generations, the overall trend is towards higher-fitness chromosomes. mutations are used to help preserve diversity in the population by introducing random changes into the chromosomes. both crossover and mutation are usually applied with user-defined probabilities, and in general, the probability of crossover is much larger than the probability of mutation. for more details on genetic algorithms see  <cit> . the design of our genetic algorithm is as follows. we employed a binary chromosome with  <dig> bits, one for each m/z variable. a gene value of  <dig> indicates that the corresponding m/z variable is selected and a value of  <dig> indicates that it is not selected. a population size of  <dig> candidate solutions was used, with a crossover and mutation probabilities of  <dig>  and  <dig> , respectively. during the test phase of the ga these parameters generated the best results; but we make no claim that they are optimal parameter values. setting the parameters of a ga is not a trivial task and ga parameter optimization is a topic for future investigation. the objective function that we employed was to maximize classification accuracy. the fitness of a candidate solution was assessed as the classification accuracy, on a validation set, achieved by the bn model built for the candidate solution being assessed. as each candidate solution represents a different subset of features , the bn model built for a particular solution is a classification model based solely on the features present on that solution, e.i., the features that correspond to the genes whose value is equal to  <dig> inside the chromosome, figure  <dig>  the stopping criteria used were:  maximum of  <dig> generations are performed on a single ga run,  a solution whose classification model  produces 100% of predictive accuracy is found, or  when all the  <dig> solutions in the population converge to a single solution.

bayesian networks 
a bn is a graphical map of the probabilistic relationships among variables of a given problem domain  <cit> . the graphical representation of a bn is a directed acyclic graph. a directed acyclic graph g is an ordered pair g =  where v is a set whose elements are called vertices or nodes and e is a set whose elements are called directed edges, arcs, or arrows. the graph g contains no directed cycles; for any vertex υ ∈ v , there is no directed path that starts and ends on υ. an example of a bayesian network is as follows. this is a modified version of the so-called "asia" problem found in  <cit> . suppose that a doctor is treating a patient who has been suffering from shortness of breath, called dyspnoea. the doctor knows that diseases such as tuberculosis, bronchitis and lung cancer are possible causes of this. the doctor also knows that other relevant information includes whether the patient is a smoker, which increases the chances of lung cancer and bronchitis, and what sort of air pollution the patient has been exposed to. a positive x-ray would indicate either tuberculosis or lung cancer. the set of variables for this problem and their possible values are shown in an additional file  together with a bayesian network representing this problem. the network structure, also known as network topology, shows how variables correlate to each other. more formally, let x = {x <dig>  x <dig> ..., xn} be a multivariate random variable whose components xi are also random variables. a corresponding lower-case letter xi denotes an assignment of state or value to the random variable. xi parents  represents the set of nodes that have a directed edge pointing to xi.

consider a bn containing n nodes, x <dig> to xn, taken in that order. a particular value of x = {x <dig>  x <dig> ..., xn} in the joint probability distribution is represented by p = p, or more compactly, p. the chain rule of probability theory allows the factorization of joint probabilities, therefore:

  p=pp...p   =∏ip. 

as the structure of a bn implies that the value of a particular node is conditional only on the values of its parent nodes, equation  <dig> is reduced to:

  p=∏ip). 

learning the structure of a bn is an np-hard problem  <cit> . many algorithms developed to this end use a scoring metric and a search procedure. the scoring metric evaluates the "goodness-of-fit" of a structure to the data. the search procedure generates alternative structures and selects the best one based on the scoring metric. a greedy search algorithm is used to generate alternative structures for the bn. greedy search algorithms make a locally optimal choice at each stage. starting with an empty network, the greedy search algorithm adds to the current network the edge that most increases the score of the new resulting network. the search stops when no other edge addition improves the score of the network. additional file  <dig> shows the pseudocode of a generic greedy search algorithm for learning bayesian network structures. in this paper, we use an unconventional scoring metric to evaluate the goodness-of-fit"  of a network structure to the data. the scoring metric adopted is specific to our classification task and is computed as follows. the entire data set is divided into mutually exclusive training and test sets, see "model validation" for more details. the training set is further divided into two mutually exclusive parts - training and validation sets. the first part  is used to compute the probabilities for the bayesian network. the second part is used as the validation set. during the search for the best possible network structure only the validation set is used to compute predictive accuracy and the measurement  of the predictive accuracy achieved is used as the scoring metric for the bayesian network model proposed. the higher the predictive accuracy value, the better the bn model fits the data. once the best ga solution is found, at the end of the ga run, the validation set and the training set are merged and this merged data  is used to compute the probabilities for a new bn fitting to this data. using this newly built bn model the predicted accuracy, for that combination of folds, is then computed on the previously untouched test set. the results reported in this paper are the average predictive accuracy over  <dig> entirely distinct test folds.

to summarize, the bayesian network is used both in parallel to the ga and sequentially after each complete ga run is performed as shown in figure  <dig>  first, the parallel ga-bn usage. for each new ga solution the following procedure is repeated. solution sk is generated. a bayesian network model bk is built based only on the features  that are selected in sk and using the training set to compute probabilities. the model bk is then used to predict the samples on the validation set and the predictive accuracy produced by bk becomes the fitness value of solution sk, i.e., fitness value of sk = predictive accuracy resulting from model bk. at the end of the ga run, the solution with the highest fitness value sbest is retained. second, the sequential bn usage after the complete ga-bn run. a new bayesian network bbest is built based on sbest but this time using the combined data, training set + validation set, for computation of probabilities. the predictive accuracy of bbest is then evaluated on a third, previously untouched fold, the test set. this result is then added to the computation of the average accuracy over the 10-fold cross-validation. the process is repeated for each of the  <dig> folds.

feature selection
many data mining applications involve the task of building a model. the goal of such a model is to classify data records according to a set of common features. feature selection, also known as variable or attribute selection, is the technique of selecting a subset of relevant variables for building robust and accurate learning models. in the present work, feature selection using ga is used to reduce data dimensionality before a classification model is built. the reduction of the number of variables speeds up model building and improves model stability and interpretability. in addition, we independently applied a partial least squares-discriminant analysis  <cit>   algorithm for feature selection. pls-da is a particular case of partial least squares regression where the dependent variable, or response, is a binary or a dummy variable. we use the pls-da implementation form the r package "classification and regression training"  ver.  <dig>  written by max kuhn  <cit> . the importance of every variable for the prediction model is measured by their variable importance for projection  coefficient. variables with large vip, larger than  <dig>  are the most relevant ones for the model and contribute more for class discrimination.

model validation
for an accurate measurement of model generalization, ideally, model validation would involve the prediction of classes on a completely new and independently generated data set addressing the same questions under investigation. in practice, however, those two complete and independently generated sets of data are rarely available and the researcher has to balance the trade-off between model overfitting and generalization using the unique set of data available. to deal with this problem our model validation uses a standard data mining procedure called cross-validation  <cit> . first, the complete data set is divided into  <dig> equally sized folds. the folds are randomly generated but under the following criteria:  the proportion of classes in every single fold has to be similar to the proportion of classes found in the original data set containing all records  replicates are kept together and not split into different folds. each of the  <dig> folds is used once as a test set. out of the  <dig> remaining folds,  <dig> folds are used as training set and  <dig> fold is reserved to be a validation set. the bayesian network uses the training set  to compute the probabilities required to classify new examples. once those probabilities are computed, the bn classifies the examples in the validation set. when the run of the ga algorithm is completed, the training set  and the validation set  are merged into a full, bigger training set. this full merged training set is used to re-compute the probabilities for a new bn fitted to the best solution  returned by the ga. the new bayesian network is then used to classify examples in the test set , which was never accessed before during the run of the genetic algorithm. the reasons for having separate validation and test sets are that in a classification model the goal is to measure predictive accuracy  on a test set unseen during training. hence, the test set cannot be used by the ga, and is reserved just to compute the predictive accuracy associated with the bayesian network built with the best set of variables selected at the end of the ga run.

RESULTS
discriminating between different physiological states
first, a ga was used for the variable selection phase as detailed above. thirty independent runs of the genetic algorithm were performed. each individual run included a 10-fold cross-validation, therefore  <dig> randomly generated folds were analyzed overall. all variables that appeared in 70% or more of the final ga solutions were selected, and this included  <dig>  out of the  <dig> variables: m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig>  m/z  <dig> and m/z  <dig>  we chose a cutoff percentage of 70% for two main reasons:  to simplify the interpretation of the bayesian network model by limiting the number of variables used to build the model, and  to concentrate the analysis only on the most relevant features from the data. after this variable selection two classification models were built using bayesian networks. the first bn model is built using all  <dig> variables available; the second bn model is built using only the  <dig> ga-selected variables. table  <dig> shows the confusion matrices for both classification models and the statistics related to those matrices. tp and fp are the numbers of true positives and false positives respectively.

actual 
veg
the results in table  <dig> show an identical predictive accuracy for the classifications with either all  <dig> variables or the reduced data . in practice the classification model using only  <dig> variables should be favoured because it is less computationally expensive to run, more parsimonious  <cit> , and also simpler to interpret. whilst the variable selection and classification model shows the most relevant variables for the identification of bacillus spores, it does not give any information about how these variables correlate to the classes or indeed to each other. therefore, we use principal component analysis  to detect groups of m/z intensities that strongly correlate to each other and observe their relationships to the physiological state of the bacilli. figure  <dig> shows the biplot for the average pc scores value of the  <dig> classes and overlaid on this plot are the m/z intensities from the pc loadings matrix.

the pc scores plot in figure  <dig> shows a clear separation between the vegetative  and sporulated  bacilli in the first pc which accounts for 46% of the total explained variance. the m/z intensities that appear to the right of the vertical dotted line that divides the graph have a strong correlation with the sporulated physiological state and the intensities to the left of that line are strongly correlated to the vegetative state. the proximity of v1¯ and v6¯ on the graph indicates that in their vegetative state b. amyloliquefaciens and b. subtilis are very closely related and this reflects the known taxonomy of these two species  <cit> ; these are also closely related to the taxonomically similar b. licheniformis . this is also seen in the spores of these bacteria. this suggests that despite choosing m/z that can discriminate between spores and vegetative cells some information on the different species is still present. this is also true for b. cereus  and b. megaterium  that also co-cluster and are taxonomically similar  <cit> . to examine the interactions among the m/z intensities further we have developed a powerful probabilistic model based on bayesian networks. contrary to intuition, the direction of the arrows in a bayesian network does not necessarily imply a cause-effect relationship between the variables; that is to say a bayesian network is not a "causal network". thus to eliminate possible confusion we have intentionally omitted the arrow heads from our bn graphs. figure  <dig> shows the bn describing the association of the  <dig> selected m/z intensities, and as detailed above this was fully validated using 10-fold cross-validation. solid lines indicate a positive correlation between nodes, dashed lines indicate negative correlation and the thickness of the line indicates the strength of the correlation. therefore the thicker the line is the stronger the correlation. the number beside the line shows the partial correlation coefficient for that correlation. a partial correlation estimates the correlation between two nodes when the effect of all other nodes in the model is held constant, and this process avoids finding variables  that are not directly correlated to each other  <cit> .

the network figure  <dig> shows the correlation among the m/z intensities. the strongest correlation on the network is a positive correlation between m/z  <dig> and m/z  <dig>  m/z  <dig> is a pyridine ketonium ion known to arise from dpa  <cit>  and beverly et al., havey et al. and opitz have suggested that m/z  <dig> results from the electron ionization fragmentation pathway via loss of co from m/z  <dig>  <cit> . as these m/z are highly correlated in the bn and appear closer to the sporulated classes on figure  <dig>  the results indicate that for sporulated bacilli the m/z  <dig> and m/z  <dig> intensities are noticeably higher than for the vegetative case.

in order to generate a rule for differentiating spores from vegetative cells we also applied a classification and regression trees algorithm  implemented according to the methods described in  <cit>  and written in r programming language  <cit> . the classification tree procedure creates a tree-based classification model which classifies cases into groups. the procedure provides validation tools for exploratory and confirmatory classification analysis. the cart algorithm produced a classification tree containing only four biomarkers, m/z  <dig>  m/z  <dig>  m/z  <dig> and m/z  <dig>  as sufficient to discriminate accurately between the physiological states of the bacilli. we then proceeded to use discriminant analysis to produce a classification equation using those four m/z intensities. to compute such equation we used the discriminant analysis option in the software "statistical package for the social sciences" spss inc.  <cit>  ver.  <dig>  the equation coefficients are canonical discriminant coefficients. the resulting formula is shown in equation  <dig> 

  f={vegetative,if h ≤  <dig> spore,otherwise. 

where h =  <dig>  m/z  <dig> +  <dig>  m/z  <dig> -  <dig>  m/z  <dig> -  <dig>  m/z  <dig> -  <dig> , and mz = . this equation successfully classifies 100% of the cases from the bacillus data set correctly. thus we have understood some of the relationships between the variables, confirmed that dpa and its product ions in electron impact mass spectrometry  are excellent biomarkers for spores and have a very parsimonious model where only  <dig> of the original  <dig> ions are used to describe the solution adequately.

discriminating between species
for this analysis the species are considered as classes . in order to ascertain whether there was any difference in classifications based on physiology, we performed these experiments using three different partitions of the mass spectral data. the first partition uses all the  <dig> bacilli collectively, vegetative + sporulated. the second partition uses only vegetative cells and the third one uses only sporulated cells. experiments on the second and third partitions expect that one has already differentiated between the two physiology states  and would work like a hierarchical classification were the physiological state of the cases is known and only the species have to be predicted.

the variable selection ga-classifier was applied to each of the three partitions of the data and produced the subsets of variables shown in the venn diagram figure  <dig> 

the diagram, figure  <dig>  shows that for the data set containing the  <dig> bacilli, labelled both,  <dig> m/z intensities have been selected as relevant to discriminate between the different bacillus species, whereas for the data set containing only vegetative cells and the data set containing only sporulated cells,  <dig> and  <dig> variables were selected respectively it is also clear that some ions  were used by all classifiers irrespective of data partitioning.

species as classes: all bacilli
these experiments were aimed at classifying all the  <dig> py-ms spectra from the bacilli into one of the seven possible species. table  <dig> shows the confusion matrix for this classification when all  <dig> m/z ions were employed as well as the statistics related to these classifications. this table also details the results after ga variable selection down to the  <dig> ions highlighted in figure  <dig>  it is clear from the summary statistics  that prediction was improved when only these  <dig> ga selected ions were used again highlighting the power of the feature selection performed by the ga-bayesian network algorithm .


sub

lic

lat

cer

amy


3

1

0

0

1


24

1

0

0

3


0

21

0

0

0


1

0

23

1

0


0

0

1

14

0


14

7

0

0

26


0

0

0

15

0


3

1

1

3

0


32

0

0

0

3


0

22

0

0

1


0

1

23

0

0


0

0

0

25

0


7

6

0

0

26


0

0

0

2

0

confusion matrices and summary statistics, w. avg. = weighted average.

the bayesian network model built on the  <dig> ga selected variables is shown in figure  <dig>  interpretation of these relationships is difficult given the molecular nature of the ions in py-ms .

despite this limitation of the data, rather than the bn, we see two separate sub-networks for species classifying when both spores and vegetative cells are included in the bn analysis. these relationships are not directly related to the differences between spores and vegetative cells, nor are these probabilistic relationships among variables wholly mirrored in pc scores ), and we see a mixture of selected ions from the different areas of pca. for example, whilst m/z  <dig>   <dig>   <dig> are highly positively correlated in both the bn and pca the bn extends this network via a negative correlation to m/z  <dig> and m/z  <dig> which are located diagonally opposite in the pc loadings plot, but not m/z  <dig> which is not used in the bn at all. in addition, despite m/z  <dig> and  <dig> close relationship in pca these are found to be separated in the bn. thus this suggests that additional information could be generated from the bn when compared to pc loadings plots, and this will be an area of future work using ions of known origin.

species as classes: vegetative cells only
these experiments classified  <dig> mass spectra from the vegetative bacilli into one of the  <dig> possible species studied. table  <dig> shows the confusion matrix for this classification as well as the statistics related to this classification for both the full py-ms spectrum and for the  <dig> ions selected using ga, and in this case the data reduction has not led to a significant improvement in classification.


sub

lic

lat

cer

amy


0

0

0

0

0


19

3

0

0

4


1

12

0

0

0


0

0

12

0

0


0

0

0

15

0


1

0

0

0

11


0

0

0

0

0


0

0

0

0

0


19

3

0

0

4


0

12

0

0

0


0

0

12

0

0


0

0

0

15

0


2

0

0

0

11


0

0

0

0

0

confusion matrices and summary statistics, w. avg. = weighted average.

the bayesian network model built on the  <dig> ga selected variables is shown in figure  <dig> 

species as classes: spores only
these experiments classified the py-ms data from  <dig> sporulated bacilli into one of the  <dig> possible species studied. table  <dig> shows the confusion matrix for these classifications as well as the statistics related to this classification for both the full py-ms spectra and the  <dig> ga selected ions. in contrast to the model made from the vegetative cells, the reduced ions for the spores shows an improvement in the predictive ability for this model, which is encouraging considering that previous studies have suggested that the phenotype of bacillus species on sporulation, as measured using py-ms, becomes more similar and hence one would expect the predictions for spores to be worse than for vegetative cells  <cit> .


sub

lic

lat

cer

amy


0

0

0

1

0


21

0

0

0

1


0

14

0

0

0


0

0

11

0

0


0

0

1

14

0


0

1

0

0

14


0

0

0

0

0


0

0

1

0

0


21

0

0

0

0


0

14

0

0

0


0

0

11

0

0


0

0

0

15

0


0

1

0

0

15


0

0

0

0

0

confusion matrices and summary statistics, w. avg. = weighted average.

ga-bayesian network vs. pls-da
to assess the power of the proposed ga-bn method as a feature selection technique we compare it to pls-da. using exactly the same partitions of the data set assessed by the ga-bn algorithm, we applied pls-da to identify the most relevant features in each of those partitions. we then computed the new classification results based on those features selected by pls-da. table  <dig> reports the following classification results:  the weighted true positive rate,  the total number of variables selected, and  the percentage of variables selected by pls-da that have also been selected by ga-bn, described as "overlap". the true positive rates from table  <dig> show that variables selected by ga-bn separate the classes more accurately than the variables selected by pls-da, in all cases. in particular, the results suggest that as the number of classes increases, from  <dig> for physiological state to  <dig> to the other cases, the classification accuracy obtained by pls-da decreases noticeably. for the physiological state data partition there is a good agreement,  <dig> %, between the features selected by ga-bn and pls-da. we expected pls-da to perform well on this partition of the data set because the pca plot, figure  <dig>  suggests that this is a linearly separable system. by contrast, for the species vegetative only partition of the data set there is only a 1% agreement, and, although pls-da selected  <dig> variables more than ga-bn did, the pls-da model prediction accuracy was  <dig> % lower.

overlap represents the percentage of variables selected by pls-da that have also been selected by ga-bn.

CONCLUSIONS
in this study py-ms data from a diverse group of bacillus species were analysed using a novel approach of combining variable selection from ga with the probabilistic relationship inference from bn. this chemometrics-fusion approach was first used for the successful classification of spores versus vegetative biomass and subsequently the same data were used to identify the bacillus species that was under analysis. the results of the physiological classification confirm that m/z  <dig> which is a pyridine ketonium ion known to arise from dpa  <cit>  plays a significant part in discriminating the spores from vegetative bacilli. moreover, m/z  <dig> was also selected which is known to be a fragment ion that results from pyridine ketonium  <cit> . a very parsimonious rule was constructed that only used four ions and had a 100% classification rate on the validation data. taken together this shows that the ga-bn was able to discover novel biomarkers for spores and that these were validated by the know physiological differences that occur during sporulation  <cit> . variable selection is an important aspect of any multivariate data analysis as it seeks to simplify a data set by reducing its dimensionality and identifying relevant underlying variables without sacrificing predictive accuracy. as a result for species classification the ga-bn significantly reduced the redundancy in the information provided by the variables actually used for prediction from  <dig> m/z to between 22- <dig> depending on the subset of the data analysed. as no single classifier works best on all given classification problems , the present work designed a specific classification model for each partition of the data set analyzed. the results show that using significantly less m/z intensities, the classifiers obtained, on average, a better performance than the classifiers using all  <dig> m/z intensities available.

taking the true positive  rate as an example for analysing both spores and vegetative cells together the prediction from using  <dig> m/z to just  <dig> increased from  <dig>  to  <dig> . when only vegetative cells were analysed the tp rate was  <dig>  for all  <dig> m/z and  <dig>  for when the  <dig> ga selected variables were employed. by contrast, the tp rate increased from  <dig>  to an impressive  <dig>  when spores were analysed by py-ms using either all  <dig> m/z or  <dig> selected ions respectively. this result indicates that not only are individual classifiers better than combining both spores and vegetative biomass, but that bacillus speciation is better when spores are analysed. this is in contrast to what is expected from classical physiology studies and indicates that a lot more than just the production of dpa and specific proteins is occurring. this has implication for rapid analysis as one may be able to speciate the bacilli directly without the need for cultivation. notwithstanding our results show that a hierarchical-like, or informed, classification of the bacilli into classes has shown a higher predictive accuracy than the classification without previous knowledge of physiological state.

the ga-bn algorithm has also outperformed a traditional classification method used in chemometrics, namely pls-da, in all cases tested. although ga-bn did not always select the smallest subset of features, the classification accuracy indicated that it always selected the most relevant ones when compared to pls-da.

bayesian networks explore two main characteristics of the target data set: associations among variables and the strength of these associations. the graphical model output from the ga-bn explicitly informs one about probabilistic associations. a conditional probability table stores the strength of the correlations given the associations displayed on the graphical model. expert knowledge and statistical information can easily be introduced in bns, as demonstrated in this study. bns model the probability distribution of the problem domain and, therefore, can compute the predictive distribution on the outcomes of possible outputs.

in conclusion, we have developed a novel genetic algorithm-bayesian network and demonstrated its implementation on a well described data set comprising pyrolysis mass spectra from a wide variety of different bacillus species analysed both as vegetative cells and spores. the physiological assessment of these data reconfirmed that dipicolinic acid is a valuable biomarker for spore identification; whilst our hierarchical-informed classification structure showed excellent identification of the different species in the sporulated state, a finding that to our knowledge has not been shown before for py-ms data.

authors' contributions
ec designed and implemented the code for the ga-bn algorithm, performed the statistical analysis of the data and drafted the manuscript. rg designed and performed the py-ms analysis of the bacillus data set, collected the data and collaborated with the interpretation of the results from the statistical data analysis and manuscript preparation. both authors read and approved the final manuscript.

supplementary material
additional file 1
the distribution of samples on the bacillus data set. this table shows the distribution of samples of the bacillus py-ms data set reported in this article.

click here for file

 additional file 2
bayesian network representing the lung cancer problem. this figure shows a bayesian network representing the lung cancer problem: l = low, h = high, t = true, f = false, pos = positive and neg = negative.

click here for file

 additional file 3
pseudocode for a generic greedy search algorithm. shows the pseudocode of a generic greedy search algorithm for learning bayesian network structures.

click here for file

 acknowledgements
ec and rg would like to thank the "systems biology of microorganisms"  project and in particular bbsrc for financial support.
