BACKGROUND
over the last  <dig> years improvements in sequencing technologies have seen the launching of the single molecule, real-time  dna sequencing system from pacific bioscience; and benchtop sequencers from  <dig>  life technologies , and illumina. these technologies have completely changed the way the scientific community have designed and conceived experiments in microbial ecology to describe community complexity. with the rapid reduction in the cost of sequencing and improvements in read length and throughput, the field has been completely revolutionized and experimental designs, that before could not even have been attempted due to the high cost involved, have been made achievable. two approaches have been widely used in practice to describe microbial community structure, 16s rrna gene profiling and shotgun metagenomic sequencing.

ribosomal rna genes are highly conserved and evolutionarily stable but differ in their hypervariable region, these features have made them the ideal tool for phylogenetic studies. several papers have described the natural variation using in silico analyses  <cit>  and genome sequencing have boosted our knowledge of the biological world improving ribosomal gene databases which support phylogenetic studies. these improvements have made the 16s rrna gene the ideal marker for the characterization of microbial community diversity  <cit> . the 16s rrna gene compromises  <dig> hypervariable regions, which differ in length, position and taxonomic discrimination  <cit> . universal primers have been designed and evaluated to amplify the hypervariable regions  <cit>  and primer bias toward particular taxonomic groups has been reported  <cit> . the variable regions have different discriminatory power depending on the groups of microbes and amongst the short target regions , the hypervariable region  <dig>  was generally the most informative  <cit> .

in the last  <dig> years the most commonly used next generation sequencing platform for amplicon sequencing has been the  <dig> series of platforms   <cit>  and many groups have developed bioinformatics pipelines and denoising algorithms  that make the  <dig> a robust approach to investigate microbial diversity. however, roche have recently announced the withdrawal of the  <dig> sequencing platforms by  <dig> and this has highlighted the need for an alternative for taxonomic studies. the various sequencing platforms available have different strengths and weaknesses in read-length, accuracy, time-to-result, and throughput. longer reads are easier to assign to a taxonomic group because they contain more information but some recent studies have suggested that it is possible to achieve comparable results using shorter target regions  <cit>  and overlapping reads have been employed  <cit>  to increase the taxonomic discrimination on illumina platforms.

also, depending on the community being studied and the nature of the hypotheses posed, different target regions and multiplexing strategies can be employed. therefore, it is likely that different groups will opt for different study designs. hence, it is crucial to develop technical solutions and bioinformatics pipelines that can be applied across multiple study designs.

microbial profiling studies the abundance and the type of organisms within an environmental community. as with most molecular methods, a profiling experiment requires a series of distinct steps, which can potentially introduce errors and may even lead to biases and incorrect findings .

even though natural microbial communities are composed of a mix of microbes with unknown structure, synthetic microbial communities can be assembled to generate distinct systems with reduced complexity . previous studies have reported the use of a synthetic community as a control material to: investigate biases; interrogate different software packages; and find the impact of sample preparation, 16s rrna primer choice, amplicon preparation, direct sampling and library preparation . in this study we used two synthetic communities assembled in vitro by mixing genomic dna from  <dig> bacterial and  <dig> archaeal species at equal abundance  or uneven abundance .
acidobacterium capsulatum atcc 51196
akkermansia muciniphila atcc baa-835
bacteroides thetaiotamicron vpi-5482
bacteroides vulgatus atcc 8482
bordetella bronchiseptica rb50
burkholderia xenovorans lb400
caldicellulosiruptor saccharolyticus dsm 8903
chlorobaculum tepidum tls
chlorobium limicola dsm 245
chlorobium phaeobacteroides dsm 266
chlorobium phaeovibrioides dsm 265
chloroflexus aurantiacus j-10-fl
clostridium thermocellum atcc 27405
deinococcus radiodurans r1
desulfovibriodesulfuricans atcc 27774
desulfovibrio piger atcc 29098
dictyoglomus turgidum dsm 6724
enterococcus faecalis v583
fusobacterium nucleatum atcc 25586
gemmatimonas aurantiaca t-27t
herpetosiphon aurantiacus atcc 23779
hydrogenobaculum sp. y04aas1
leptothrix cholodnii sp-6
nitrosomonas europaea atcc 19718
nostoc sp. pcc 7120
pelodictyon phaeoclathratiforme bu-1
persephonella marina ex-h1
porphyromonas gingivalis atcc 33277
rhodopirellula baltica sh 1
rhodospirillum rubrum atcc 11170
ruegeria pomeroyi dss-3
salinispora arenicola cns-205
salinispora tropica cnb-440
shewanella baltica os185
shewanella baltica os223
sulfitobacter sp. ee-36
sulfitobacter sp. nas- <dig> 
sulfurihydrogenibium sp. yo3aop1
sulfurihydrogenibium yellowstonense ss-5
thermoanaerobacter pseudethanolicus atcc 33223
thermotoga neapolitana dsm 4359
thermotoga petrophila rku-1
thermotoga sp. rq2
thermus thermophilus hb8
treponema denticola atcc 35405
treponema vincentii i
zymomonas mobilis mobilis zm4
archaeoglobus fulgidus dsm 4304
ignicoccus hospitalis kin4/i
methanocaldococcus jannaschii dsm 2661
methanococcus maripaludis c5
methanococcus maripaludis s2
nanoarchaeum equitans kin4-m
pyrobaculum aerophilum im2
pyrobaculum calidifontis jcm 11548
pyrococcus horikoshii ot3
sulfolobus tokodaii 7


different amplicon library preparation methodologies have been proposed to unlock the power of next-gen technologies for targeted sequencing . the fusion primer design  uses pcr to attach a barcode  <cit>  but is expensive due to the requirement of purchasing long primers that are platform specific for every combination of primer and barcode to pair each sample in a study .

the adaptor ligase  approach ligates a barcoded adapter to the end of an amplicon. the ad approach uses a platform specific library preparation kit instead of specially designed fusion primers, and is functional for experiments where amplicons already exists or at least where template-specific primers already exist  <cit> . the universal tailed-tag amplicon design  uses a slightly more elaborate two-step library amplification process but it is more economical, avoiding the cost of a large number of barcoded primers  <cit> . this approach reduces the number of primers needed by attaching, in a first round of pcr, the linker/universal primer to each end and requires only as many primer pairs as the number of variable regions in the experiment. a second round of pcr is carried out, with universal primers hybridizing to the linker while the indexing sequence can be added to one or both ends to barcode the samples. as the second set of primers can be reused in other experiments  this method can be much cheaper than other approaches. illumina and most recently pacbio have developed a protocol based on the  <dig> step pcr design and a similar approach has been supported by fluidigm corporation  <cit> .

we compared the fusion primer  and tailed tag  methodologies  for building amplicon libraries using the illumina miseq platform. a single or a dual indexing strategy was also evaluated. moreover, we generated amplicon libraries across the  <dig> hypervariable regions of the 16s rrna gene  for  <dig> synthetic communities and compared the data generated with a shotgun metagenomic library. amplicon libraries were sequenced on  <dig> gs flx/flx+, illumina miseq , life technologies ion torrent  and pacific bioscience rs ii  platforms, to determine the impact of different experimental conditions on the community structure.
fig.  <dig> experimental design.  design of single and dual-index sequencing strategy and schematic describing the  <dig> amplicon designs: fusion primer design  is a one step pcr which uses a single 12-nt error-correcting golay index sequence  allowing a high multiplexing capability. tag tailed design  is a 2-step pcr which uses a universal primer for the first step and a dual index barcoded primer set in the second step. standard illumina nextera 8-nt index sequences were used . the pac bio ligate adapters design : two harpin adapters  were ligated to a barcoded template  to allow multiplexing.  platform specific amplicon libraries: illumina paired-end sequencing  generates  <dig> sequencing reads  per each cluster and can have single  or dual indexes . ion torrent and  <dig>  have a single read for each bead with a single index . pacific bioscience generate a single circular read for each molecule  and can have one  or two indexes. the starting point and direction of sequencing reads are indicated by a solid blue line and arrows, respectively. in the case of fusion primer design custom sequencing primer were used

fig.  <dig> schematic representation of the combination of primers covering the 16s rrna hypervariable regions and the sequencing platform used in this study



our results demonstrate that almost all aspects of experimental design will bias the results to some extent. we demonstrate that not only specific target region affected the community profiling but also pcr cycle numbers, sequencing platform, and library preparation method will give different results in terms of error rates and biases. despite this, by comparing data from um and em communities we show that the data on all sequencing platforms is quantitative even if it does not accurately describe the community composition. we also highlight the relative merits of the different experimental designs for describing species within a community and otu estimation.

methods
even and uneven microbial mock communities
high-molecular weight dna was extracted using a mechanical and organic cell lysis method as described in  <cit> , dissolved in te buffer  and measured using a qubitⓇ dsdna br assay. after quantification and calculation of the concentration of genomic copies for each dna preparation, two mixtures of genomic dnas were assembled, henceforth referred to as even  and uneven  synthetic communities. we considered organisms that were either sequenced previously or had a high quality draft genome in ncbi repository and covered a wide variety of strains that can be found in marine and terrestrial environments. unlike natural environmental communities where composition and abundance is unknown, the two synthetic communities were assembled to have known amount of purified gdna from archaea and bacteria domains. both communities comprised ten members of euryarcheota, crenarcheota and nanoarcheota for archaea and  <dig> bacterial strains from  <dig> phyla. the same organisms were used previously  <cit>  although they have been assembled in a different manner in this paper. our emphasis is on exploring the impact of the distributions of abundance distributions on recovery diversities. therefore, we assembled an em community to aim for an equal number of molecules per strain and an um community where the strains within the same phylum were distributed according to a log-normal distribution with proportions shown in table  <dig>  in the um, proportion between bacterial and archaeal strains was 9: <dig> 

amplicon library designs
the conditions studied varied across a gradient of template concentrations at a high cycle number and a low cycle number. we performed  <dig> independent amplifications using hifi hot start polymerase  or q <dig> polymerase  to test for polymerase derived bias . kapa and neb have developed pcr amplification kits specifically for ngs workflows and these are widely used as they have high yields with little amplification bias. the  <dig> kits were selected for their ability to amplify difficult templates  and increase yield, speed and sensitivity.


universal tailed tag design 
1− <dig> ng of em or um community dna was used in the first amplification step using the following conditions:  <dig>  μm forward tailed target specific primer;  <dig>  μm reverse tailed target specific primer; and 1x hifi or q <dig> polymerase ready mix. the pcr for each variable region was carried out in triplicate in a  <dig> μl reaction in a thermal cycler  with the following parameters: initial denaturation at  <dig> °c for  <dig> mins, followed by  <dig>   <dig>  and  <dig> cycles of  <dig> °c for  <dig> s,  <dig> °c for  <dig> s, and  <dig> °c for  <dig> s with a final extension at  <dig> °c for  <dig> min. the amplicon libraries were cleaned to remove excess nucleotides, salts and enzymes using  <dig> μl of the agencourt ampure xp system  and eluted in  <dig> μl of te buffer. the  <dig> μl of the first step reaction was submitted to a second amplification step using the following conditions:  <dig>  μm forward barcoded primer for the dual index strategy or a forward not barcoded primer for the single index strategy;  <dig>  μm primer barcoded reverse primer; 1x hifi  or q <dig>  polymerase ready mix. the pcr for each variable region was carried out in triplicate in a  <dig> μl reaction in the above-mentioned thermal cycler with the following parameters: initial denaturation at  <dig> °c for  <dig> min, followed by  <dig> cycles of  <dig> °c for  <dig> s,  <dig> °c for  <dig> s, and  <dig> °c for  <dig> s with a final extension at  <dig> °c for  <dig> min.

fusion primer design
1− <dig> ng of the em or um community was subjected to an amplification step using  <dig>  μm primer forward fusion specific;  <dig>  μm primer reverse fusion specific; 1x hifi or q <dig> polymerase ready mix. the pcr for each variable region was carried out in triplicate in a  <dig> μl reaction in the thermal cycler with the following parameters: initial denaturation at  <dig> °c for  <dig> min, followed by  <dig> cycles of  <dig> °c for  <dig> s,  <dig> °c for  <dig> s, and  <dig> °c for  <dig> s with a final extension at  <dig> °c for  <dig> min.

adapter ligation design
 <dig> ng of the em community dna was submitted to the following amplification reaction:  <dig>  μm forward variable region specific primer;  <dig>  μm reverse variable region specific primer; and 1x hifi polymerase ready mix. the pcr for each variable region was carried out in triplicate in a  <dig> μl reaction in the thermal cycler with the following parameters: initial denaturation at  <dig> °c for  <dig> min, followed by  <dig> cycles of  <dig> °c for  <dig> s,  <dig> °c for  <dig> s, and  <dig> °c for  <dig> s with a final extension at  <dig> °c for  <dig> min. the amplicon libraries were cleaned to remove excess nucleotides, salts and enzymes using  <dig> μl of the agencourt ampure xp system.  <dig> μl of each pcr product was run on a bioanalyzer hs dna chip to ensure the final product was the correct size and quantified using a qubitⓇ dsdna hs assay. a pool of the three independent pcr products  were subjected to end-repair using the pacific biosciences dna template prep kit  <dig> .  following manufacturer recommendations. briefly, the end repair reaction was incubated at  <dig> °c for  <dig> min. following the purification with  <dig> x of ampure pb beads and elution in  <dig> μl of elution buffer, the end repaired mixtures were blunt ligated with the adapters supplied in the template prep kit. the ligation was incubated at  <dig> °c for  <dig> min and then stored at  <dig> °c overnight. exonuclease digestion to remove the failed ligation products was performed by incubating at  <dig> °c for  <dig> h, followed by purification with 1x ampure beads.

amplicon quantitation and pooling
 <dig> μl of each amplicon library was run on a bioanalyzer hs dna chip to assess the amplicon size and quantified using a qubitⓇ dsdna hs assay. each amplicon library was size selected according to the expected amplicon size  using a pre-cast  <dig>  % agarose with ethidium bromide gel cassette on the pippin prep system . the library concentration for illumina and  <dig> amplicon libraries was assessed using a sybr green qpcr assay with primers specific to each platform .

multiplexing strategy
three multiplexing approaches were used to tag each pcr product: single index, dual index, and barcoded adapter. the single index and dual index strategies were used to build libraries for illumina’s ms technology. in the single index strategy approach, the primers contain the illumina adapter sequence, a unique 12nt error-correcting golay index sequence  comprising a 10nt pad to prevent hairpin formation, and a 2nt linker that is not complementary to the 16s rrna gene and a gene specific sequence. sequencing proceeded by using the combined pad-linker-primer as sequencing primers at the 3′ and 5′ ends  as described in caporaso et al.  <cit> . in the dual index strategy, the forward and reverse locus specific primers are modified to include a 35nt illumina adapter sequence at the 5′ ends that act as primer binding sites in the second step pcr . in the second step pcr, universal tag primer set  which contains a 39nt sequence  comprising a unique 8nt index sequence , and a 21nt complementary to the sequence introduced in the first step pcr, to tag the the library produced in the first step. the single index strategy was used to build libraries suitable for it and  <dig> sequencing. in the single index strategy approach the primers contain the it/ <dig> adapter sequence, a 4nt key sequence, a unique 10nt index sequence  and a gene specific sequence. the ligate adapter strategy was used to build libraries to submit to pb sequencing. forward and reverse locus specific primers were used to amplify the variable region but the primers were modified to include a 5nt pad sequence and a unique 16nt index sequence  at the 5′ ends. after amplification, pb specific adapters were ligated to both ends.
agagtttgatymtggctcag
the variable region primer sequence is displayed in bold. the position of the multiplex identifier  is shown as  and the respective sequences are shown in tables  <dig>   <dig>   <dig>  and  <dig>  degenerated bases in the sequence are represented as follows: m: c or a; b: not a; y: c or t; r: a or g; w: a or t; h: not g; k: g or t; v: not t

an  <dig> bp reverse index  and forward index  used in the universaltailed tag design  to barcode the reads in both directions

a forward  <dig> bp mid was used in the fusion approach  to tag the reads in forward direction



metagenomic dna library
the metagenomic library was constructed using the em community gdna and the illumina nextera xt kit. a standard tagmentation reaction was set up using 1ng as input according to the nextera protocol. after neutralization, barcoded primers were added to the reaction and submitted to  <dig> cycles of amplification. after this, a pcr cleanup was performed following the nextera protocol using a  <dig> : <dig> ratio of ampure xpⓇ  to pcr reaction. reactions were eluted in  <dig> μl of te buffer.

ms sequencing
due to the low library diversity, a phix control spike-in of 10− <dig> % was used for libraries run with rta v <dig> . <dig>  which is bundled with mcs v <dig> . when the older version of the software was used, a phix control spike-in was added at  <dig> %. each amplicon library was mixed with illumina-generated phix control libraries and denatured with naoh and subsequently the ssdna library fragments were diluted to a final concentration of  <dig> pm.  <dig> μl of ssdna library was loaded into a miseq reagent cartridge and a 500–cycle pe kit v <dig> was used. paired-end sequencing run was performed according to the manufacturer’s instruction . for the runs where fusion primer design and golay barcodes were employed, we used custom read  <dig>  read  <dig> and index read  according to  <cit> . raw fastq files generated by the real time analysis software on the ms were used in the subsequent analyses.

it sequencing
it sequencing was performed on the ion torrent personal genome machine  according to the manufacturer’s protocols.  <dig> pm of size-selected libraries were amplified by pcr that was carried out using the ion onetouchtm  <dig> template kit v <dig> dl  according to the manufacturer’s instructions. sequencing of the amplicon libraries was carried out on a  <dig> or  <dig> chip using the ion torrent pgm system and the ion sequencing  <dig> kit  according to the supplier’s instructions. after sequencing, the individual sequence reads were filtered by the it software to remove low quality and polyclonal sequences using default setting. all it quality-approved, trimmed and filtered data were exported as standard flowgram format  files and used in subsequent analyses.

sequencing
the libraries were clonally amplified via emulsion pcr adding  <dig>  molecule/bead per cup of emulsion, following manufacturer’s recommendations employing the gs flx titanium lv empcr kit . following amplification, empcr reactions were collected, and emulsions broken according to the manufacturer’s protocols. beads containing sufficient copies of clonally amplified library fragments were selected via the enrichment procedure and counted with a z <dig> coulter counter  prior to sequencing. following emulsion pcr enrichment, beads produced using the titanium library were deposited into 4-region gasket format wells of a titanium series picotiterplate device and  <dig> sequencing was performed using the gs flx titanium sequencing kit xlr <dig> on the gs or using gs flx titanium sequencing kit xl+ on the gs flx+ sequencer according to the manufacturer’s recommendations . image analysis, signal processing and base calling were performed using the supplied software system. sff files output from base calling were employed in downstream analyses using onboard software v <dig>  for gs flx and v <dig>  for gs flx+.

pb smrt sequencing
the pacific biosciences calculator was used to determine the amount of primers and polymerase needed for the binding reactions, based on an insert size of  <dig> bp. the primers and pacific biosciences proprietary p <dig> sa dna polymerase v <dig> was bound to the library and the magbead kit was used to bind the library complex with magbeads before sequencing to reduce adapter dimers. the magbeads smrt bell-polymerase complexes were loaded into a  <dig> well plate. the plate, along with a dna sequencing kit  <dig> , was loaded onto the instrument. each smrt cell was loaded with a single binding complex and  <dig> min movies were collected. the run was demultiplexed using the read of insert pipeline on the onboard software provided in the smrt portal  applying as filtering  <dig>   <dig>   <dig>   <dig> passes and minimum predicted accuracy of  <dig> 

bioinformatics
the results in this paper were generated using amplimock , a pipeline we developed for quantifying error rates and biases when a mock community with known reference sequences has been sequenced. the pipeline requires the original  and reverse-complimented  reference sequences for each 16s rrna operon present and a mapping file  which maps multiple 16s rrna operons onto the known species.

creation of the reference 16s rrna database
for the compilation of the 16s rrna reference database an e. coli 16s rrna sequence  was aligned against the full genome reference database using blastn  <cit> . if less than four blast hits were returned for any organism, the ncbi database was directly searched for additional sequences. for each individual organism duplicates and sequences that completely overlapped were removed. all reference sequences were subsequently verified by aligning them against the full genome reference database. sequences that failed to align were removed, resulting in a total of  <dig> rrna sequences. for the identification of single nucleotide polymorphisms  in the 16s rrna reference sequences, a large metagenomic sequencing data set  in combination with a full length 16s sequencing data set  was utilised. two sequencing data sets were used in order to avoid the incorporation of false positive snps. quality-trimmed reads with a minimum read length of  <dig> bp were aligned against the preliminary 16s rrna reference database with bwa  <cit> . the alignment was subsequently converted to pileup format using samtools  <cit>  and snps were identified with varscan  <cit>  . only snps that were identified for both sequencing datasets were incorporated into the database through the addition of a new sequence containing the snp. the process was repeated with the updated 16s reference database until no more snps were recognised for the metagenomic read data set. in total  <dig> snps were identified resulting in  <dig> 16s rrna reference sequences .

read trimming and filtering
the first step in the pipeline is filtering and quality trimming. for the it,  <dig> and ms platforms, reads were filtered and quality trimmed with sickle  which applies a sliding window approach and trims regions when the average base quality drops below  <dig>  <cit> . we also applied a  <dig> bp length threshold discarding reads that fall below this length after trimming. for the pacbio reads circular consensus sequencing  error correction was applied with different minimum thresholds .

generating non-chimeric overlapping reads
for the ms platform where paired-end reads were generated, we used pandaseq  with a minimum overlap of  <dig> bp to assemble them. pandaseq was used as it has been previously shown to perform better than other software for paired-end assembly  <cit> , reducing substitution rates for the ms platform by 77− <dig> % with an average of  <dig>  %. additionally, for the datasets where the raw data still had primers intact, we supplied primers to pandaseq after assembling the reads to remove them from the resulting sequences. the overlapped reads were then dereplicated using uclust , de novo clustered, annotated with cluster sizes, sorted while maintaining a record of redundancy and finally filtered for chimeras using uchime. both initial overlapping reads, and final non-chimeric reads were then matched against the reference database  to generate frequencies for each species in the reference database, error rates for matched reads and percentage of reads matching. for the it,  <dig> and pb platforms where paired-end reads are not available, the overlapping step was skipped, and the sequences are searched against the reference database after initial qc checks using sickle.

otu generation
we use the uparse  pipeline  for otu generation. for the ms datasets, input to uparse are the overlapped reads generated from pandaseq with amplimock, whereas for the rest of the platforms we use the single-end fasta files. the general approach is as follows: we pooled the reads from different samples together and added barcodes to keep an account of the samples these reads originate from. we then dereplicated the reads, sorted them by decreasing abundance and discarded singletons. in the next step, the reads are clustered based on  <dig> % similarity discarding reads that are shorter than 32bp. even though the cluster_otu command in usearch removes reads that match chimeric models built from more abundant reads, a few chimeras may be missed, especially if they have parents that are absent from the reads or are present with very low abundance. therefore, in the next step, we use a reference-based chimera filtering step using the gold database  that is derived from the chimeraslayer reference database in the microbiome utilities provided by the broad institute . finally, the original barcoded reads were matched against the clean otus with  <dig> % similarity to generate otu tables for different samples. all these steps are mentioned in uparse.pdf located at https://bitbucket.org/umerijaz/amplimock/src. we have adopted two different approaches for generating otu tables for each sample. in the first approach, we perform multiple sequence alignment of the database sequences using muscle  and then excise the amplicon region based on the forward and reverse primers used for each sample with clustalw . we then follow the general approach as mentioned before to generate a two column abundance table giving counts of otus that are present in the sample as well as the database. in the second approach, we generate the otus without collating the database sequences.

generating pipeline statistics
amplimock generates quantitative results for each sample that can further be analysed in a statistical software package such as r. the total numbers of forward, reverse, and overlapped reads; and average phred quality scores of forward and reverse reads are outputted. these reads are then matched against the the reference 16s rrna database extracted from the known genomes. from this the mean identity of forward , reverse , and overlapped reads, compared to their closest database match are calculated. the number of chimeric reads found in the above chimera checking steps and non-chimeric reads after chimera removal are also given. finally, diversity indexes such as shannon and simpson index based on the proportion of different matched species in the database are calculated. additionally, to determine error transition probabilities, we used the alignments against the best matching reference sequences generated by usearch to count all nucleotide transitions between the query and reference sequences.

RESULTS
error rates and percentage of reads matching across platforms
error rates were calculated by matching reads against the reference 16s rrna sequences using usearch as described above. only reads with greater than  <dig> % nucleotide similarity to the best matching reference were used in the error calculations  <cit> . results were calculated for all the em community datasets with greater than  <dig>  reads for the  <dig>  it and ms platforms but for pb, we used all data sets regardless of read number. this comprised  <dig>  <dig> data sets,  <dig> flx and  <dig> flx+,  <dig> it,  <dig> ms , and  <dig> pb replicates . to facilitate a fair comparison across all platforms, only forward reads were used for the ms platform, as although it allows paired-end sequencing, generating a forward and reverse read, this is not possible on the other platforms. in addition, the proportion of reads matching to the references was calculated. overall, tests of significance were performed using a kruskal-wallis non-parametric anova and individual t-tests performed to compare pairs of treatments. error rates differed across platforms  with an overall significance of p= <dig> . the pb consensus sequences were generated using a multi-pass sequencing. the read-of-insert , i.e. unfiltered consensus reads with no minimum coverage, had the highest error rate of  <dig>  % but this was not significantly higher than the it -  <dig>  % . both the pb roi and it error rates were significantly higher than the ms  and  <dig>  but pb could be reduced to an equivalent error rate of  <dig>  % when a minimum threshold of  <dig> passes  was used.
fig.  <dig> 
a error rates across four different platforms. platform had a significant impact on error rate  as did number of ccs cycles for pb . b percentage of reads not matching across the four different platforms. platform had a significant impact on percentage matching  as did number of ccs cycles for pb 



in calculating these error rates we only used reads with at most  <dig> % error; reads that are noisier than this will fail to match and hence not contribute to the error calculation. it is important therefore to also examine the percentage of reads that fail to match. this varied dramatically with platform  as can be seen in fig. 3b. the non-matching rate was similar for ms and  <dig>  but much higher for pb roi  and higher still for it . once again, increased numbers of circularisation cycles reduced the pb percentage not matching to the range observed for ms and  <dig> albeit at the cost of reduced read number .

nature of errors across the different platforms
the nature of the observed errors differed across the different platforms too. in additional file 3: figure s <dig>  we give heatmaps for each platform reflecting the proportion of the different possible transitions from the true ‘target’ based on the observed erroneous ‘query’ base. we include both base substitutions and insertions, a gap in the target sequence, or deletions, a gap in the query. the most common error for ms are substitutions and these are quite base-dependent with the transitions  being the most frequently observed, whereas for the other platforms insertions and deletions were more prevalent.

illumina: impact of library preparation method and overlapping reads on error rate
we explored two alternative methods for building the illumina ms libraries, the first involved a  <dig> step pcr with golay barcodes on the reverse read  and the second a  <dig> step pcr with standard illumina barcodes on both reads  - see fig. 1a, b. in fig. 4a and b we show the impact of overlapping the forward and reverse reads on the ms v <dig> error rates. it is apparent that the di method results in a significant reduction in the error rate compared to the fg. there is also a large variation in error rate for the forward di reads and the reverse fg. this variation is highly run-dependent  but does not seem to depend on the cluster density of the particular run.
fig.  <dig> 
a impact of overlapping reads on ms error rates for the di library preparation method. overlapping reads significantly reduced error rates for the di library preparation method . b impact of overlapping reads on ms error rates for the fg library preparation method. overlapping reads did not significantly reduce error rate for the fg library preparation method . it is also worth mentioning here that not all the reads overlapped, for example, for the ms platform, and with the given settings in pandaseq , the statistics for the percentage of reads that were assembled successfully are:  <dig>  % ;  <dig>  % ;  <dig>  % ; and  <dig>  % 



impact of pcr conditions on error rate and chimera frequency
we also evaluated the impact of pcr conditions on the error rate. we explored the impact of starting template concentration, taq polymerase enzyme and number of pcr cycles. each sample was generated from the em community using  <dig> independent pcr reactions targeting the v <dig> region of the 16s rrna gene on ms using 2× <dig> bp paired-end reads. the only consistent effect observed on error rate was a marginally significant increase associated with more pcr cycles .
fig.  <dig> 
a impact of no. of pcr cycles on the forward ms error rate. increasing number of cycles did increase forward error rate with marginal significance for the fg library preparation method with q <dig> taq . b impact of pcr starting amount on percentage of chimeric reads. decreased starting amount reduced percentage of chimeras for the fg library preparation method with hifi taq but not significantly . c impact of no. of pcr cycles on the percentage of chimeric reads. increasing cycle number increased the percentage of chimeric reads for the fg library preparation method with q <dig> taq 



there is another form of artefact associated with pcr, in addition to simple base errors, and that is pcr chimeras. pcr chimeras are sequences comprised of two or more true sequences. they form due to incompletely extended sequences acting as primers to template in the following rounds of pcr. our analysis revealed that the amount of starting material, and the number of cycles play an important role in controlling pcr errors. using  <dig> ng of template reduced the proportion of chimeric reads compared to  <dig> ng but only with marginal significance  . in contrast the cycle number did have a significant impact .

ability of different platforms and regions to reconstruct the em community
the observed species frequencies for the em community varied with the choice of platform and sequenced region . the individual species frequencies were highly unbalanced despite this community being designed to have equal molecule numbers for each genome. the causes of these biases could include primer mismatch, 16s rrna copy number and amplification bias associated with the target length. the observed community associated with each primer platform combination is summarised in a two-dimensional non-metric multidimensional scaling visualisation in fig. 6b. we also include a metagenome sample as a benchmark since this should be relatively unbiased given the fewer pcr amplification steps in the library construction. from this we see that the  <dig> flx+ v4-v <dig> sample is closest to the metagenome. other flx+, flx and pb samples also perform well probably reflecting their greater read length. the best ms region appears to be the v <dig>  to quantify the effectiveness of the different platforms and regions with a single number we calculated shannon’s entropy across species, i.e. h=∑s=1s−fsln where xs is the observed relative frequency of species s. this value will be maximised for an even distribution when xs=1/s and therefore the higher the entropy, the closer the sample appears to the true underlying even community. the results are shown in additional file 5: figure s4a. this appears to confirm the nmds plot in that one of the best performing combinations is  <dig> flx+ v4-v <dig> although now the best of the ms v <dig> samples appears comparable, although there is a great deal of variation.
fig.  <dig> 
a heatmap for em communities  reconstructed from different platforms using a range of experimental designs for amplicons. the design parameters are shown on top  nmds plot based on bray-curtis distance comparing the samples showns in 



barcode switching
there is another form of error and that is barcode switching between labelled samples. to test for switching we prepared libraries from individual genomes rather than the mock communities. then the frequency of observed reads deriving from species other than the focal one indicates the probability of barcode switching. we did this for both illumina library preparation strategies. in both cases the overall switching rates were low with a mean switching probability of  <dig>  % for di and  <dig>  % for fg with no significant difference between them . the two library preparation strategies did differ in that for the di most switching was to the other single species libraries on the run whereas for the fg a wider range of species from throughout the mock community was observed . in neither case was the mock community included on that run hence this may suggest that the fg library preparation method is more susceptible to carry-over from previous runs.

reconstruction of em and um communities
we have demonstrated above that all platforms and regions suffer from substantial bias. the observed relative frequencies do not reflect the true species frequencies in the community. however, it is still possible that when we compare two samples, the observed differences between samples reflect the true differences. hence, method is biased but still quantitative. to test this, we considered pairs of samples consisting of one from the em and one from the um community. pairs were taken from the same run and this was performed for the ms  and pb  platforms. for each species s the true ratio of frequencies in the pair is known this is simply the ratio of the volumes used to generate the mixtures. we denote this fs/gs where f and g are the relative frequencies in the um and em communities respectively. this is given on the x-axes of the plots in fig.  <dig> and is compared to the ratio of the observed frequencies in the two samples for the same species, ys/xs. in fig.  <dig> we give two examples one for the ms and one for the pb. in both cases there is a highly significant correlation between the two ratios and a slope that is nearly one for a regression forced through the origin. this implies that 16s rrna sequencing is strongly quantitative despite being biased. in general the ms  runs seem to be more quantitative than pb  with p =  <dig>  using a t-test. we can then ask which species are responsible for this difference and which are more accurately quantified on one platform relative to another, by comparing the absolute errors, i.e. how different was the observed ratio from the true ratio? the results are given in table  <dig>  in all cases where there was a difference in accuracy, then the ms was the better platform. the exception was shewanella baltica os <dig> which has a closely related strain in the data set shewanella baltica os <dig>  this suggests that the one advantage of pb may be better strain resolution when the entire 16s rrna is sequenced.
fig.  <dig> quantitative results for two em-um pairs  for ms and pb are shown. the fitted line through the points is represented by a blue line with r-squared shown on top. the red line is the ground-truth with the slope difference from the blue line also shown on top


caldicellulosiruptor

saccharolyticus

nitrosomonas

europaea

pelodictyon

phaeoclathratiforme

salinispora

tropica

shewanella

baltica os223


taxonomic classification of reads to rdp database
up until now we have calculated all statistics through comparison of the reads to the known 16s rrna sequences of the species that we sequenced. this was useful to explore bias in community proportions but in reality we will not know a priori which organisms are present. therefore, to provide a more realistic perspective of how diversity estimates and community predictions will be distorted we also performed de novo taxonomic classification against the rdp database using their standalone classifier  <cit>  with the default –minwords option of  <dig>  for the ms platform, assembled paired-end reads  were considered, whereas for other platforms, single-end reads were used. the results for observed genera number are shown in additional file 8: figure s <dig> where we have separated genera, by whether they were in the reference database and should be observed in the reads which we denote ‘good’, and also ‘noisy’ which are those genera which should not have been present. the short read platforms all outperformed pb in terms of their ability to recover the known genera, probably due to a combination of higher read number and less biased primers. given this though they performed similarly although marginally more genera were recovered by ms than  <dig> . however,  <dig> had fewer noisy genera than ms  and fewer still than it . the pb long reads also generated significantly fewer noisy otus than all the next generation technologies with a mean of  <dig> .

otu construction
we next constructed otus from the reads from each platform using uparse with default parameters. we did not employ any of the denoising methods available for  <dig>  in order to provide an equivalent cross-platform comparison. we did discard singletons as recommended in uparse but not for the pb sequencing where the sample sizes were so small that the singletons contained a large proportion of the true diversity. in additional file 9: figure s <dig> we give the observed total otu frequencies and of those ‘good’ otus that were also in the database and the ‘noisy’ otus that were not meant to be there. the full-length pb platform does succeed in identifying more good otus than the short read platforms, although not significantly more, but at the cost of far more ‘noisy’ artefact sequences. of the short read platforms  <dig> and ms appear almost equivalent. significantly more good otus were obtained for ms than it  and significantly fewer noisy otus .

discussion
for any experiment it is vital to be able to understand the accuracy of the measurements and the potential sources of error. here we have undertaken an exhaustive study that uses a multitude of primer combinations, library preparation protocols, and sequencing platforms. we quantified intrinsic errors and analyzed the relative accuracy of these approaches for absolute and relative estimation of species abundance and otu estimation.

our finding demonstrates the ms platform, using overlap read error correction, has the most accurate sequence reads. despite this, the extra read length of the  <dig> platform and pb does allow good estimation of the composition of our mock community when comparing the data to the known reference dataset used in the study. however, given the much higher throughput and economics of the illumina technology it would seem the pragmatic choice of platform for most studies.

as expected the number of pcr cycles during amplicon generation has a direct impact on the accuracy of the resulting data, we also demonstrate that the initial concentration of template will also affect the proportion of chimeras formed if the pcr cycle number is kept constant. this is most likely because when more template is present at the start of the reaction the amplicon abundance will increase more rapidly which enables more miss-priming during the pcr  <cit> . this demonstrates that normalizing the input dna quantity across all samples is vital to ensure that all data generated is comparable.

it has been demonstrated by others that amplicon libraries can be prone to barcode switching  <cit>  whereby the barcodes from one amplicon can be assigned to another in the same flowcell on the ms platform. our evaluation of this phenomenon using single species samples has highlighted the fact that some barcodes appear to be more prone to this occurrence than others. also the fg barcoding protocol appears to be more prone to switching. although the frequency of switching we observed was very low  this could be a major source of error for certain studies where species may be at a high abundance in some samples and absent in other, such as clinical samples being analysed for pathogens.

analysis of all experimental conditions used  demonstrates that amplicon choice has the most pronounced effect on the measurement of the relative abundance of the different species. this is evident in the pb data, which uses the v <dig> and v <dig> primers. this primer combination does not detect any of the archaeal species . also the v <dig> and v <dig> primers perform badly in detecting archaea. where different platforms are used with the same primers their performance in detecting species is similar. the whole genome shotgun approach gives the most accurate estimation of species abundance in this analysis.

the performance of the different platforms in describing the mock communities can be quantitatively measured by calculating the entropy of the data generated. our analysis shows that the platforms have a similar performance although the platforms with fewer reads  perform slightly less well. it should also be pointed out that different library methodologies have been used in a previous study to increase base calling accuracy  <cit>  using a mix of primers that have frameshifting nucleotides to increase cluster identification on the illumina platform. we have also used a mix of primers with random nucleotides for the di design , but ever since the software rta v <dig> . <dig> release, no significant differences were found. the barcode design  does affect the entropy of the data. in our hands, the di with v <dig> primers performed best, giving the highest entropy and therefore lower bias.

it should also be emphasised that although the v <dig> region appears to be performing the best out of the universal primers tested here it did not capture all the species present, failing to pick up the chlorobium species, for example. in general, our results confirm those of  <cit>  demonstrating that no single universal primer can capture all the microbial diversity. therefore primers should be carefully chosen for individual studies based on prior knowledge of the taxa likely to be present or combinations of primers must be used.

although the relative abundances of species within samples are not well described by 16s sequencing, the ability to estimate the relative abundance of the same species between samples is very good. as demonstrated in fig.  <dig>  both the pb and ms data correlate well with the different abundances of bacteria in the em and um communities. this is despite the small number of reads that are generated by the pb platform.

when classifying at the genera level using the rdp classifier all platforms underestimated the total number of genera, the pb performing the least well. this was again due to the failure of the v1-v <dig> primers in amplifying the archaea, as none of these species were present in our dataset.

the findings discussed above were generated by comparing benchmarking datasets against a database of 16s sequences in synthetic communities. however most 16s sequencing studies will use otu reconstruction to identify species, as in most cases the community structure will not be known. we calculated otus from our datasets at the  <dig> % level. at this granularity our community should have  <dig> different otus, however the pb massively overestimated the number of otus despite the low number of reads generated. the ms and it performed well with the v <dig> amplicon while the  <dig> underestimated the number of otus. nevertheless, when the pb data was compared to a database of known otus  it performed better than the other platforms predicting more of the “good otus”. so although the ms and it predict roughly the correct number of otus many of these are “noisy otus”. in the case of the it, around  <dig> % of the predicted otus are incorrect.

rarefaction analysis demonstrates that the short read platforms  additional file 12: figure s <dig> have reached asymptote in most experimental designs. therefore we would not predict the number of otus to increase much with more sequencing. however it is striking how different the otu estimation is between different experimental designs and replicates. however in the case of the pb, the rarefaction curves appear linear, other than the ccs <dig> reads. this demonstrates that the ccs sequencing can improve the data substantially but the result of this will be a reduction in the total number of reads.

CONCLUSIONS
we have used synthetic microbial communities for this and our previous study  <cit>  and while our communities are relatively complex compared to many other published studies they are not going to be representative of most environmental samples, which are likely to have much more species diversity across a wider range of abundances. here, we demonstrate that consistency in input dna quantity, pcr cycles and barcoding strategy is required to get reproducible and comparable results. the best design of the experiment will depend on the questions asked of the data and what prior knowledge exists. for example, we have shown that if the species present in a sample are known then pacbio is better than other platforms for identification and therefore it can be used for confirmation studies, conversely if otu estimation is done blind then the short read platforms perform best. there has recently been a heightened awareness about the over-interpretation of microbiome studies  <cit> . we hope that this analysis will better inform future experimental designs and interpretation but also highlight areas where out technology can be improved to better represent microbial diversity.

availability of supporting data
the datasets are available on the european nucleotide archive under the study accession number: erp <dig> .

additional files
additional file  <dig> 
figure s <dig>  amplimock pipeline. 



additional file  <dig> 
figure s <dig>  read quality distribution for pacbio. 



additional file  <dig> 
figure s <dig>  error transition probabilities for all platforms. 



additional file  <dig> 
figure s <dig>  impact of platform and region on entropy. 



additional file  <dig> 
figure s <dig>  impact of library preparation method on barcode switching probability. 



additional file  <dig> 
figure s <dig>  heatmap of observed species in the single-species libraries. 



additional file  <dig> 
figure s <dig>  taxonomic profiling of different platforms. 



additional file  <dig> 
figure s <dig>  otu comparison for all platforms. 



additional file  <dig> 
figure s <dig>  impact of pcr cycles on otus. 



additional file  <dig> 
figure s <dig>  heatmap of arc heal species in the em community. 



additional file  <dig> 
figure s <dig>  regression of abundances against primer mismatches and 16s rrna gene true copy numbers. 



additional file  <dig> 
table s <dig>  rarefaction curves for all platforms. 



competing interests

the authors have no competing interest.

authors’ contributions

nh and cq designed the study. rd, jk carried out the molecular biology and sequencing experiments, msh and mp assembled the microbial communities. uzi wrote the software and scripts; ms, uzi, cq carried out the statistical analysis; nh, uzi, cq, msc, rg, ad assisted in the data interpretation. nh, rd, uzi, cq wrote the paper. all authors read and approved the final manuscript.

this study was funded by technology strategy board  research grant “development of instrumental and bioinformatic pipelines to accelerate commercial applications of metagenomics approaches”. u. z. ijaz is funded by nerc irf ne/l011956/ <dig>  c. quince is funded by an mrc fellowship mr/m50161x/ <dig> as part of the cloud infrastructure for microbial genomics  consortium - mr/l015080/ <dig>  m. shakya and m. podar are supported by oak ridge national laboratory . ornl is managed by ut-battelle, llc, for the u.s. department of energy. dna sequence was generated by the university of liverpool centre for genomic research, uk.
