BACKGROUND
over the last few years, next generation sequencing  has become a widely adopted technology in many aspects of discovery and translational research, because of its ability to acquire sequence information and quantification at the same time  <cit> . among many applications using ngs, genomic dna variant analysis and rna expression analysis are the most popular ones. the scope of these analyses can be either as wide as the whole genome and transcriptome, or as focused as specific regions and gene panels.

targeted sequencing is particularly advantageous at achieving very high coverage of the region of interest  while keeping the cost of sequencing and complexity of data interpretation manageable. having very high sequencing coverage is especially important for discovering cancer mutations present at low fractions. for example, an average sequencing depth of > <dig>  reads is typically required for detecting single nucleotide variants  present at 5 % fraction with good confidence  <cit> . much higher sequencing depth is needed to detect snvs at less than 5 % fraction. in rna analysis, a targeted approach can provide more evidence of low expression transcripts, because in transcriptome sequencing most sequence reads are consumed by mid- and high-abundance transcripts, thus often leaving inadequate coverage of low abundance transcripts  <cit> .

there are multiple ways to enrich a target region before ngs. the most commonly used approaches are 1) hybridization capture from sequencing libraries using target specific probes  <cit>  and 2) pcr amplification directly from sample dna using target specific primers  <cit> . although requiring more effort in up front primer design and chemistry optimization, many people still employ pcr amplicon based enrichment because, in general, the pcr process is easier to handle, requires less overall time, is more specific in terms of target sequence enrichment and can easily accommodate much lower dna input. with the advent of high multiplex pcr, now hundreds to thousands of amplicons can be simultaneously amplified in one reaction, making the coverage of very large regions convenient  <cit> .

existing target enrichment, library preparation, and sequencing steps all utilize dna polymerase and amplification processes, which introduce substantial bias  and artifacts . pcr amplification bias significantly affects quantification accuracy, because final sequence read counts may not accurately represent the relative abundance of original dna and rna fragments. polymerase artifacts generated during the pcr cycles will most likely result in many “false” sequence variants present at low fractions in final sequence reads. these low level “false” variants cause difficulty in identifying real somatic mutations present at very low fraction  in the sample. the root cause of these problems is the inability to distinguish the initial sampling of different original molecules from the resampling of the same molecule by primers during the pcr process. such problems are exacerbated when more pcr cycles are needed to deal with low input dna or poor quality dna. pcr amplicon based target enrichment is more prone to these problems than the hybridization capture based enrichment for the following reasons. random shearing or tagmentation process before hybridization capture creates random and diversified fragment ends, which can be used as a unique identifier for each starting dna molecule  <cit> . such unique identifiers offer a limited ability to keep track of different starting molecules and to remove pcr duplicates and associated amplification artifacts. pcr amplicon based enrichment loses such ability because all starting molecules are enriched with the same sequence ends for a given target specific amplicon.

to mitigate the problems of pcr duplication and biased amplification in ngs analysis, researchers have reported the inclusion of known number of synthetic internal standard molecules to improve the accuracy of ngs quantification  <cit> . other approaches involve the use of exogenous molecular barcodes   <cit> . this is not to be confused with sample barcodes commonly used in current ngs workflows. the concept of molecular barcoding is that each original dna or rna molecule is attached to a unique sequence barcode. sequence reads having different barcodes represent different original molecules, while sequence reads having the same barcode are results of pcr duplication from one original molecule. although molecular barcoding cannot prevent pcr duplication from happening, it provides a nice solution to track duplicates and treat them differently for downstream analysis. by employing molecular barcodes, polymerase artifacts generated during pcr can be distinguished from sequence variants present in original molecules. this barcoding has the potential to increase the detection accuracy for mutations at 1 % fraction or lower by removing low level false positives  <cit> . the target quantification can also be better achieved by counting the number of unique molecular barcodes in the reads rather than counting the number of total reads, as total read counts are more likely skewed for targets by non-uniform amplification  <cit> .

several variations of molecular barcodes have been successfully applied in ngs applications. molecular barcodes have been incorporated into the ligation adapters during the library construction step for genome sequencing  <cit>  and transcriptome sequencing  <cit> . in another study, barcodes were incorporated into molecular inversion probes for targeted somatic mutation detection  <cit> . barcodes can also be incorporated into target specific pcr primers  in pcr amplicon sequencing  <cit> , thereby eliminating significant shortcomings in amplicon sequencing as mentioned earlier. in this aspect, so far all reported cases have been related to the amplification of one or a few amplicons by primers containing molecular barcodes, such as the analysis of a viral gene in an hiv resistance study  <cit> , the analysis of 16srrna gene in a human gut microbiota study  <cit> , and the analysis of ig heavy chain in immune repertoire profiling  <cit> . as a result, those analyses have all been restricted to only very small regions. thus, it will be beneficial if molecular barcodes can also be applied in high multiplex pcr amplicon sequencing. in order to accomplish this, some technical hurdles need to be overcome, e.g. how to avoid barcode resampling and how to suppress primer dimers in high multiplex pcr conditions.

we have developed and optimized a high multiplex pcr amplicon sequencing process, which can accommodate hundreds of target specific primers containing molecular barcodes in a single reaction. in addition, the new protocol eliminates the need for ligation-based library construction, by adding sequencing adapters during multiplex pcr amplification. using this protocol, we have constructed amplicon panels of several sizes to demonstrate: 1) the performance in detecting snvs at 1 % fraction using admixtures of reference materials from the coriell institute 2) the performance in quantifying low abundance rna transcripts using ercc spike-in controls; and 3) the ability to enrich large regions and detect unknown somatic mutations in ffpe samples. our data confirmed the superior performance of counting molecular barcodes over counting sequence reads in high multiplex amplicon sequencing. we show that the new protocol combines the simplicity of pcr amplicon sequencing with the accuracy of molecular barcodes, can provide deep coverage for a very large region, and will be a useful addition to existing target enrichment solutions.

RESULTS
overview of the high multiplex amplicon barcoding protocol and assay design
to design primers for our high multiplex amplicon barcoding protocol, we adopted the “primer id” design strategy  <cit>  by inserting a molecular barcode region  between the 5′ universal sequence and 3′ target specific sequence in one of the two primers for each amplicon. all primers containing the molecular barcode for different amplicons are pooled together  and all other non-barcoded primers are mixed in a different pool . because of our goal in high multiplex pcr, each target specific primer sequence is selected to minimize potential cross hybridization with other primers. specifically, a target primer sequence will be rejected when more than ten bases at its 3′ end will form perfect complementary match with another target primer.

the workflow is as the following . 1) the bc primers are annealed to and extended on target dna. at this step, each dna molecule containing our target locus will be copied and the resulting copy will have a unique molecular barcode. 2) the unused bc primers are removed through size selection purification. 3) a limited pcr amplification is conducted using the non-bc primers and a universal primer corresponding to the universal sequence in the bc primer. 4) the unused primers are removed from the amplicons. 5) a universal pcr is used to further amplify the material to desired quantity for amplicon sequencing. at this step, platform specific adapter sequences are also introduced to form complete sequencing libraries.fig.  <dig> overview of the high multiplex amplicon barcoding pcr



the keys to success in high multiplex amplicon barcoding pcr are minimizing primer dimer formation and controlling resource competition from amplicons of different amplification efficiencies. in general, long primers with universal sequences are more prone to primer dimer amplification in universal pcr. many different primer dimers may form during the preparation of many barcoded amplicons. although each dimer may be generated at a low level, they can be amplified together during the subsequent universal amplification to a level that severely hinders the amplification of target amplicons. to avoid this, we physically separated primers with different universal sequences into two pools, to reduce the likelihood of forming primer dimers containing both universal sequences, which would otherwise be amplified during universal pcr. furthermore, we removed unused bc primers before non-bc primers are added. in our experience, even a minute amount of leftover bc primers can risk dimer formation with non-bc primers, as well as causing a “barcode resampling” problem, i.e. the same dna input template being associated with multiple molecular barcodes, which defeats the benefits of molecular barcoding. after evaluating several approaches, we found that two-round size selection purification is the most efficient way to remove primer dimer background . secondly, because target specific primer extensions were used in limited cycles and our amplification was mostly driven by a pair of universal primers, we minimized the difference in amplification efficiency and competition among many different amplicons.

detecting snvs at very low allelic frequencies
distinguishing true snvs in the sample from sequencing or pcr artifacts is usually very challenging because both are often present at very low fractions in the reads. to demonstrate the benefit of molecular barcodes in supressing sequencing artifacts, we first applied our method to detecting snvs at very low fractions. following an earlier approach  <cit>  we created a sample containing a set of “known” snvs at 1–2 % fractions, by mixing dnas of two well-characterized individuals  from the  <dig>  genomes project. a high-confidence variant set has been developed for na <dig> by the nist-led “genome in a bottle” consortium  <cit> . variant data are also available for na <dig> from the  <dig>  genomes project.

a total of  <dig> primers were designed according to our primer design algorithm as described in the methods section. this dna amplicon panel i covered a  <dig>  bp region in the human genome, including  <dig> high confidence snvs that were not homozygous reference in na <dig> and were homozygous reference in na <dig>  out of these  <dig>   <dig> were heterozygous in na <dig> and  <dig> were homozygous non-reference in na <dig>  with this amplicon panel, we performed target enrichment using 10–80 ng genomic dna mixtures, following our high multiplex amplicon barcoding protocol. after illumina miseq pair-end sequencing,  <dig>  to  <dig>  million reads were generated from each sample with a mean coverage depth of at least  <dig> x .table  <dig> summary of the sequencing runs for in vitro dna mixtures



reads from the same amplicon with the same molecular barcode were processed into one consensus read. all consensus reads were aligned to the reference genome and snvs were identified. for  <dig>   <dig>   <dig> and 80 ng genomic dna inputs, the mean coverage depths calculated using consensus reads were 98x, 187x, 336x and 530x respectively . the number of consensus reads for a chromosomal locus is a reflection of the number of original dna molecules being enriched for that locus. the higher number of coverage depth based on consensus reads reflected the more genomic dna copies in the input samples. for snv detection,  <dig> out of  <dig>  high confidence snvs were detected  in the10ng sample, with no false positives. the sensitivity increased as sample input increased, and reached  <dig>  % with  <dig> false positives when we used 80 ng genomic dna .fig.  <dig> comparison of sensitivity and false-positive rates for different input dna amounts.  the x-axis represents different input quantity of the dna admixture. the left y-axis represents detection sensitivity for snvs at 1–2 % fraction. the right y-axis represents false positive rates  performance using the original protocol.  the sensitivity of snv detection was significantly higher after adding 3 cycles of limited amplification.  the roc curve from 80 ng 3-cycle data with or without using the information of molecular barcodes



these initial results suggested that the greater the fraction of initial dna molecules being converted to full amplicons by primer pairs, the greater the detection sensitivity that could be achieved. to improve sensitivity, we sought to improve the efficiency in forming full amplicons. one simple solution was to run multiple cycles of non-bc primer annealing/extension, trying to convert as many barcoded dna fragments as possible into full amplicons. after we changed step  <dig> in the protocol from 1 cycle to 3 cycles for 10 ng and 80 ng dna inputs, our mean coverage depths for consensus reads increased from 98x to 208x and from 530x to 839x respectively . as we expected, the sensitivity increased to  <dig>  % with four false positives, and to  <dig>  % with three false positives, respectively .

to compare the performance to that without using molecular barcodes, the raw reads and consensus reads from 80 ng 3-cycle sample were further analysed. variants were identified using different tlod settings in mutect . roc curves demonstrated that with low or medium sensitivity settings , raw reads and consensus reads had similar performance in terms of false positives. with high sensitivity settings , using molecular barcodes significantly reduced false positives. these data showed that polymerase and sequencing errors could be major contributor to false positives in variant calling, and using molecular barcodes could efficiently remove those errors and improve data quality. in addition, we believe our current consensus read model and variant calling were not fully optimized and the fpr using molecular barcodes can be further reduced by incorporating more sophisticated statistical methods.

measuring low abundance rna transcripts
next we evaluated the use of high multiplex amplicon barcoding in targeted quantification of rna transcripts. to set up this experiment, we used ercc rna spike-in control mix as our sample, because each mix contains a defined number of copies for each rna transcript  <cit> . the concentrations of  <dig> polyadenylated transcripts in the mix span  <dig> fold concentration range. knowing the sequencing capacity of miseq, we excluded  <dig> transcripts with the highest concentrations from our analysis, and designed  <dig> amplicons for the remaining  <dig> transcripts . for some of the longer transcripts, two amplicons were designed, one close to 5′end and the other close to 3′end. following the high multiplex amplicon barcoding pcr and miseq sequencing, we estimated the abundance of rna transcripts represented by each amplicon by sequence reads and by counting unique molecular barcodes. we then compared these estimates to the expected amounts in the ercc rna mix. we also examined the variability in the first barcode assignment step and in the universal pcr amplification step.

the measured transcript abundance by each amplicon correlated well with the expected levels  overall. two things are noteworthy. first, the correlations of the “measured” vs. the “expected”, calculated by reads and barcodes, were largely similar for higher abundant transcripts. however, for lower abundant transcripts, the correlation for measurements by barcodes was much better than those by reads, as evidenced by more scattering of read data in the lower left corner. this suggests that the value of using molecular barcodes is more evident for quantifying targets of low abundance. secondly, the overall correlation using barcodes was still not perfect for our set of amplicons. we postulate that these biases are likely introduced during reverse transcription and initial barcode assignment steps. it is known that reverse transcription efficiency along a rna transcript can be affected by rna secondary structures and rna integrity. since barcode assignment is accomplished by target specific primers, different primers will also possess different annealing efficiencies. because these biases are dependent on sequence context, fold change analysis between two samples for the same target may be less affected. in addition, using multiple amplicons sparsely tiling each transcript and using their average value will likely reduce these biases greatly.fig.  <dig> ercc rna quantification using amplicon barcoding.  correlation between “measured” vs. “expected” numbers for each ercc rna transcripts represented by each amplicon. the x-axis represents log <dig> values of known copies in the ercc rna spike-in mix. the y-axis represents log <dig> values of average barcode or read counts for each amplicon . both barcode count and read count from different sequencing runs were first normalized to a mean value of  <dig>  for each run before being averaged.  cv computed on the basis of barcode counts vs. raw read counts. three independent target enrichment experiments were performed. solid black line represents diagonal and two red dash lines represent 2-fold intervals.  cv vs mean plot for both barcode counts and read counts. x-axis represents the mean value for each amplicon on the basis of either barcodes or reads. corresponding cv is plotted on y-axis. the theoretical poisson cv is plotted as the black dash line



in addition, we observed that most measurements using barcodes have much smaller technical noise, assessed by the coefficient of variation , than those using raw sequence reads . the technical noise was reduced by about  <dig> -fold on average, and for some amplicons, by as high as 10-fold. most of the technical noise we observed using raw reads were likely the result of universal pcr amplification . for low abundance transcripts, sampling error could significantly contribute to observed variation. to confirm this, theoretical poisson distribution cv-vs-mean was plotted . cvs for barcodes were very close to the poisson cv, suggesting that using molecular barcodes enabled us to lower the counting variation close to the theoretical limits set by poisson sampling error. on the other hand, raw read counts were also influenced by technical noise during multiple pcr cycles and often overestimated the number of original molecules being sequenced, so variations higher than sampling error were observed. overall our data showed that pcr amplification can be highly stochastic and non-uniform, and counting molecular barcodes instead of reads can efficiently remove pcr amplification variation.

application of high multiplex amplicon barcoding protocol to ffpe samples
to demonstrate the scalability of our high multiplex amplicon barcoding protocol and its application in real biological samples, we designed an additional  <dig>  primers and combined them with those from dna amplicon panel i to form a larger panel. this dna amplicon panel ii was designed to cover all the coding regions of  <dig> important cancer genes, such as tp <dig>  atm, egfr, apc, braf, etc. we performed target enrichment experiments using this panel on dna extracted from commercial ffpe samples. the ffpe samples we used were of vastly different qualities, as measured by generead dna quantimize qc assays . based on our estimates of the pcr amplifiable fractions in the ffpe dna, we have to adjust the number of universal pcr cycles used in our protocol for poor quality dnas in order to yield enough material for miseq sequencing. the sequencing results showed overall very high percentage of reads on target  and very good uniformity  for all ffpe samples for which we were able to generate enough libraries . the presence of molecular barcodes for each amplicon allowed us to look at the actual number of original dna molecules represented in the raw reads. as expected, the number of original molecules enriched directly correlated with the quality of the ffpe dna. for example, the total reads for sample t <dig> were derived from only  <dig> copies of original dna on average. this number suggests that it would be very difficult to detect most mutations present below 5–10 % fraction in this ffpe sample under the conditions we used. such information on the limit of detection per sequencing run would not be available without the use of molecular barcodes. our data also suggested that deeper sequencing would not help improving the sensitivity in this case. in the end, about  <dig> to  <dig> snvs in our target region were identified from each ffpe sample by using our variant calling pipeline on consensus reads. particularly, from the two match-paired lung samples we tested, four snvs, at fractions ranging from  <dig>  to  <dig>  %, were uniquely identified in the primary tumor. however, we have not yet confirmed the validity of those variants by alternative methods.table  <dig> summary of the sequencing runs for ffpe samples



discussion
high multiplex amplicon pcr is a simple approach to enrich a target region of interest for ngs. it is highly specific and works well for dna from ffpe sections. however, the multiplex pcr approach has the major drawbacks of no ability to de-duplicate sequence reads and competition among primers with different efficiencies. by incorporating molecular barcodes into the multiplex pcr process and relying on universal amplification, we have avoided these problems and improved the overall performance.

the sensitivity of our method has more room for improvement. the current sensitivity for detecting low fraction variants is limited by low sample input. as the dna titration experiments suggested, the variant calling sensitivity is positively correlated with the amount of the input dna. there are approximately  <dig>  copies of haploid genomes in 10 ng human genomic dna. the improved 3-cycle method only captured  <dig> copies on average, which is about 6 % of the input. for variants at 1 % fraction, on average two copies of the variants were present in the final sequencing data. this may explain why the sensitivity was very low  for 10 ng genomic dna. increasing the efficiency to form full amplicons during initial steps is essential for detecting dna variants at low fractions when the input is limited. for rna quantification, this is also important for detecting low abundant transcripts.

there are many steps in the workflow that could result in sample loss and thus offer room for further improvement. those steps include bc primer extension, bc primer removal, and non-bc primer amplification. according to our estimates, the current conditions for bc primer assignment only captured on average 40 % of input dna. this step is limited to just one cycle, as “barcode resampling” must be strictly avoided. using higher concentrations of bc primers could be a way to improve capture efficiency; however it is not always possible, especially with hundreds or thousands of different primers in the reaction. we also know that significant sample loss can happen during the bc primer removal step. the ideal method should be highly efficient for removing unused bc primers and dimers, yet be able to recover as many elongated products as possible to minimize sample loss. initially we tried to use an enzymatic approach such as exonuclease i digestion to degrade leftover bc primers. our study showed that exo i digestion was not efficient enough, leading to significant amount of primer dimers in the final product . size selection purification in general is more efficient in removing primers but with higher sample loss. by our estimates, probably 50–80 % target dna was lost during the size selection protocol we used. improving the size selection process  should improve the overall target enrichment efficiency.

the sequence of the molecular barcodes can also affect variant calling performance. we were using random 10mer barcodes in the dna study. the benefit of completely random barcodes is that they are economical to synthesize. however, since they are completely random, we have only limited ability to distinguish an original barcode from a “mutant” barcode due to pcr or sequencing errors. those “mutant” barcodes will decrease our ability to remove amplification artifacts in the reads. one way to mitigate this is through barcode clustering, based on the assumption that any “mutant” barcode should come from an ancestor barcode with significantly higher number of reads. the possible number of different barcodes used in our current system is orders of magnitude higher than the number of dna molecules. in this case, the probability of barcode collision  is extremely low. if the edit distance between two observed barcodes is below a certain threshold, it is possible to assume that one of them is a mutated version of the other, and the two barcodes can be merged into a single barcode cluster. then the barcode cluster is used for building consensus reads and counting molecules. in practice, depending on the application, we can apply different strategies and thresholds for clustering the random barcodes. overly aggressive clustering can minimize the false-positives, but may also lead to underestimation of the dna copies and lower sensitivity. on the other hand, if the clustering is not aggressive enough, it can lead to too many false-positive variant calls. balanced clustering for random molecular barcodes deserves further optimization depending on the application. an alternative way to mitigate barcode errors is to use a mixture of error-correcting barcodes  <cit> . however, it is practically cost prohibitive to do so for many different primers in high multiplex amplicon pcr.

it is worth noting that in our variant calling example, the false positive rate increased when consensus read depth increased from  <dig> to 80 ng. we believe this was caused by both higher consensus read depth  and reduced read coverage of each consensus read . with higher consensus read depth, more loci gained higher coverage and became callable for mutect, so both tp and fp increases from  <dig> to 80 ng. when the read coverage of each consensus read decreases, it’s also possible to get more false positives due to lower quality of consensus reads. when we down sampled the reads in 10 ng  data to 25 % while keeping the consensus read depth about the same, we found that false positives increased from  <dig> to  <dig>  it is possible that our consensus read modeling can be further optimized so that the lower read coverage of each consensus read has lower impact on false variant calling.

when dealing with low copy number events, i.e. detecting low fraction variants or low abundant rna transcripts, sampling variation in multiple processes could become a major source of errors affecting data quality. this has been observed and discussed previously in various types of data   <cit> . in our targeted sequencing application, the use of molecular barcodes  enables researchers to identify and count only original molecules rather than assuming that each individual sequence read represents a separate original molecule. this practice makes it possible to observe and calculate sampling statistics. figure 3c, for example, suggests that consensus read counts followed theoretical poisson distribution while raw read counts were affected by other factors such as pcr amplification bias. this underlines the fact that sampling statistics can be used to greatly improve confidence in both variant calling and rna transcript counting applications. taking variant calling as an example and assuming that variant caller needs to see at least  <dig> variant molecules to make a call, based on negative binomial distribution, around  <dig> molecules need to be sampled in order to achieve 90 % probability to call variants at 1 % allele fraction. such sampling statistics can be used to determine the theoretical limit of sensitivity at a given allele fraction and to be able to rule out the existence of an alternative allele with some specified level of confidence. if molecule sampling efficiency is also known, one can calculate the dna input requirement in order to achieve a given sensitivity at certain allele fractions.

our protocol is easily scalable to thousands of primers in a single tube and worked well for dna from ffpe samples. the ability to detect mutations at low fractions is largely affected by the quality of ffpe samples. with the presence of molecular barcode in each read, we now have the ability to estimate the lower limit of variant fractions which can be detected in each ffpe sample. this information could be quite useful in interpreting the significance of negative findings in ffpe samples, as discussed above.

CONCLUSIONS
in summary, we have developed an ngs target enrichment process that integrates molecular barcodes into high multiplex pcr amplicon sequencing. we demonstrated the benefits of molecular barcoding in reducing low level sequencing artifacts, which would otherwise plague the detection of snvs at very low fractions. our process was highly reproducible and scalable, and was successfully applied to analyzing a large region of dna from ffpe sections.

