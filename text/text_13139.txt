BACKGROUND
gene fusions are well-recognized molecular events and serve as genetic markers and drug targets for several hematological disorders
 <cit> . the discovery of recurrent ets-family translocations in prostate cancer
 <cit> , a raf kinase gene fusion in ets-negative prostate cancer
 <cit> , and an alk kinase fusion in lung cancer
 <cit>  further advocates the significance of gene fusion events in the development of epithelial cancers
 <cit> . the discovery of gene fusion candidates was infrequent and challenging because of various technological limitations inherent in traditional techniques, such as spectral karyotyping, comparative genomic hybridization , representational oligonucleotide microarray analysis , fluorescent in situ hybridization , and sanger-based sequencing
 <cit> . however, the rapid evolution of non-sanger-based massively parallel sequencing technologies has empowered an unprecedented sequencing speed, enabled an unbiased systematic characterization of large-scale genome-wide analysis, and surprised researchers with numerous gene fusion candidates at an unmatched resolution
 <cit> . as this development in sequencing technology is still relatively new, no standard approach has been established for reporting or documenting a number of the key features associated with gene fusion discovery leading to a repetitive process of manual curation and interpretation of critical information that can entail scrutinizing the entire manuscript along with the supplementary information. to enable researchers to remain current with the information flow and make the data more accessible, various non-standard community efforts have been established through other structural variation databases
 <cit> . these were primarily developed as independent entities without much scope for data exchange and integrity. moreover, the non-standard mode of reporting the rapidly increasing gene fusion discoveries has challenged their manual processes of curation and data entry when updating the database. finally, a number of existing databases are not suited for documenting gene fusion features and lack many of the key attributes that are required for next-generation sequencing  analyses. in the near future, as we anticipate a downpour of gene fusion candidates from various high throughput analyses, representing the data in an unstructured, autonomous format poses a significant risk of misplacing such valuable information. similar to other standardization efforts and procedures such as the minimum information about a microarray experiment  that standardizes and shares microarray data
 <cit> , the proteomic standard initiative-molecular interaction  that was established to regulate protein-protein interaction representation
 <cit> , and the systems biology markup language  that represents biochemical reaction networks
 <cit> , there is an urgent need to create a standard for recording and reporting gene fusion discoveries. here, we propose a prototype standardization initiative we call the gene fusion markup language  to propose a standard format for representing and documenting gene fusions. in turn, this improved documentation will enable rapid access and maximize the usage of gene fusion findings to other researchers in the community. hence, these proposed guidelines would serve as a starting point for stricter standards that will evolve over time in the field as the standards undergo regular and thorough vetting by the community
 <cit> .

current literature issues
researchers have tried to practice and adopt the best possible methods to present their gene fusion data to the community. however, no standard list of features or data structures has been discussed or adopted to represent this special category of observations in an inter-operable and query-able fashion. in most cases, authors tend to describe the gene fusion and its features based on a fusion detection algorithm used for a particular set of studies and to represent the information based on their own experience. the depth of information generated from an ngs analyses pipeline, mostly filtered out in the published literature, leads to significant information loss between the observed and reported findings . here, we summarize some of the key concerns.  <dig>  representation format: in published reports data is simplified and filtered to include only the disease-specific or study-related gene fusions are described in an informal format . other non-recurrent or biologically unrelated gene fusions for the given study are merely listed in the results or the discussion of the article as a running text or are at times represented pictorially as a circos plot, histogram, or table . besides explaining the significance of the observations, there is no additional effort to represent the complete analyses outcome in a consistent and sharable manner.  <dig>  splice coordinates: apart from the fusion genes considered significant for the respective study, most of the other gene fusion candidates are simply listed in a table along with the number of supporting reads. unfortunately, the features that help predict their significance are not described. in order to assess the true biological significance of candidate fusion transcripts, the splice coordinates  are essential for the interpretation of the reading frame and domain signature of the fusion product. for example, the significance of fusion candidates involving kinase family members or transcription factors can be easily misinterpreted if there is no functional domain retained in the open reading frame of the fusion transcript.  <dig>  read evidence: to the best of our knowledge, there is no published study that reports actual reads mapped to any candidate gene fusion. currently, the only way to access the gene fusion-specific reads is to download the large raw sequence files from public sequence repositories  and perform the non-trivial task of repeating the complete analyses that can entail everything from mapping the raw reads to a fusion discovery pipeline. as there are many fusion candidates predicted in each study with potential false-positives, it is vital to retain sequence evidence from the analysis phase so that the observations can be independently verified.  <dig>  terminology: a controlled vocabulary in presenting the characteristic features of gene fusion events and their evidence is another potential problem that needs to be addressed in this discipline. almost half a dozen published fusion detection algorithms have been independently developed. these algorithms are associated with a number of discrepancies in naming the attributes and values describing gene fusion events and the supporting sequence evidence
 <cit> . 

existing database issues
there are some common evolving standards towards representation of generic structural variations
 <cit> , but there is no specialized data exchange standard available to submit published gene fusion discoveries with required ngs features to any public repositories or databases. in order to avoid repetitive manual curation and enhance data accessibility, there have been independent efforts to curate and document these gene fusion discoveries in public databases. the database of genomic variants
 <cit> , the mitelman database of chromosome aberrations and gene fusions in cancer
 <cit> , the atlas of genetics and cytogenetics in oncology and hematology
 <cit> , and the catalogue of somatic mutation in cancer
 <cit>  are a few of the most popular and closely related databases of this kind. here, we summarize some of the key concerns with the existing resources.  <dig>  ngs incompatible: ngs features that are specific to gene fusions are ignored and not captured, with the current gene fusion entries forcefully accommodated under generic structural variations. in other words, most of the existing databases are not yet adapted for ngs analyses. for example, information pertaining to the sequencing platform, mapping, the fusion detection algorithm, and the read evidence are omitted, leading to yet another level of information loss when the information from the published literature is captured in databases .  <dig>  non-interoperable: most of the existing online databases function independently with different scopes of operations and report curated data in custom formats not compatible with one another. in turn, this interrupts the data exchange and integrity .  <dig>  unsynchronized update: existing databases provides some function to the community. however, considering the volume of information generated out of recent ngs analyses and the current status of non-standard data representation in the literature, the manual mode of operation involved in curating and documenting such massive amount of data may significantly hamper the up-to-date status of the database.  <dig>  incomplete entries: manual curators primarily focus on validated gene fusions therefore many other non-validated candidates listed in the supplementary materials are overlooked and are represented in only a few of the current databases. moreover, the majority of gene fusion candidates predicted from ngs studies are listed in the supplementary materials because of the limited space allowed by many journals.

requirement for specialized standard data exchange format for gene fusions
various standardization procedures have been adopted by the community periodically, each designed to handle various data types generated by different technologies that is appropriate for the level of information required for the exchange. for example, bioxsd is a common generic data exchange format that bridges the gap between specialized standardization formats
 <cit> ; specialized data formats such as mage-ml are useful in describing the minimum information specific to microarray experiment
 <cit> ; psi-mi is more applicable for handling information specific to protein-protein interactions
 <cit> ; and molecular methods  database provides the research community with an up-to-date source of methods and protocols used in molecular biology and medicine
 <cit> . similarly, several sequencing-based standardization formats have been developed by open-access and international working bodies such as genomic standards consortium  and european nucleotide archive  that describe genomic, meta-genomic, and environmental sequences
 <cit> . previously developed sequencing-based standardization methods primarily focused on basic data such as sample information, experimental setup, machine configuration, sequence traces, reads, quality scores, assembly, mapping and annotation. however, standardization procedures describing secondary/tertiary analyses and their outcomes are limited, especially in the context of rapidly evolving technological advances in next generation sequencing. the currently available minimum information about a high-throughput nucleotide sequencing experiment , extends the miame specifications to capture the quantitative data  from hts technology, while dbvar and gvf are specialized data formats to exchange genomic structural variations
 <cit> . similarly, we envision a customized standardization procedure to accommodate the features of gene fusion data arising from the transcriptomic analyses that incorporates valuable attributes such as description of fusion detection algorithms, 5’ and 3’ fusion transcript annotations, fusion read evidence, open reading frames, splice junction features, experimental validation status, functional domain architecture, etc. currently not provided in a common data exchange format. many of the common attributes of gene fusion schema could potentially be derived from other xml schemas , such as “study”, “sample”, and “experiment” but the descriptions of such elements are also often varied across existing standardizations and are primarily based on the platform\ technology  that are specifically suited for the generation of information of primary interest. for example, the element “experiment” is fine-tuned to fit sequencing platform details in sra to exchange sequence data, in psi-mi it is structured to handle protocols which generate protein-protein interactions, and in mage-ml it is designed to capture information from array based technologies. therefore in the proposed gfml prototype, in order to ensure a wide scope for curation of gene fusion features across diverse platforms including ngs, fish, acgh, qpcr, etc., the common elements have not been derived from any of the available individual standards. however, to take advantage of the existing schema, tools to facilitate cross-talk and data sharing between various schemas will be enabled.

methods
we initiated an investigation to understand the commonality and characteristics of the published features and format in ngs studies specifically involving gene fusion algorithms and related findings
 <cit> . we identified nine major elements and related attributes describing the characteristics of gene fusion events and the sequence evidence. we also investigated the existing structural variations databases
 <cit>  to understand the documented features, working model, and current status of each database. to design and develop a compatible and robust data model, we also adopted some of the relevant features of existing standardization protocols and markup languages
 <cit> . based on our interpretation of existing sources, we standardized the identified elements and features and further developed a prototype . the graphical version of the gfml prototype was made using altova xmlspy version 2011rel3sp <dig> . the complete process flow is represented in figure
1b.

RESULTS
in addition to specifying all required data elements and features, the model recommends a database-independent structure and standardizes the data attributes and its values. the ultimate goal of this model is to provide a standard framework that enables different types of complex, biologically meaningful queries in order to maximize the data usage of the system . “record_set” is the root element of the gfml that contains one or more records . each “record” is a self-contained unit that allows gene fusion entries from one to multiple sources. nine major elements have been characterized and identified from various transcriptome studies describing gene fusion. a brief introduction for each element is summarized as follows :  the “source_list” element allows one or more source objects, describes the source of the study and normally refers to the publication or data provider details;  the “sample_list” allows one or more sample objects and describes the properties of the biological specimens associated with the study;  the “experiment_list” element allows one or more experiments and describes the experimental parameters associated with the study;  the “sequence_platform_list” element allows one or more sequence platform objects and describes the required sequencing parameters such as the platform name, description and application type;  the “validation_platform_list” elements allow one or more validation platform objects and describe the validation methods;  the “mapping_algorithm_list” allows one or more mapping algorithm objects and describes the mapping algorithm and its parameters;  the “fusion_detection_algorithm_list” allows one or more fusion detection algorithm objects and describes the fusion algorithm and its parameters;  the “sequence_repository_list” elements allow one or more sequence repository objects and describe the sequence repository details where the raw sequences have been deposited and made accessible; and  the “gene_fusion_list” element allows one or more gene fusion objects that describe the key attributes pertaining to gene fusion analyses including chromosomal location, gene annotation, read evidence, orf status, the splice junction, potential mechanism, and validation status and is linked to other elements in the model, including the experiment, sample, mapping, and the fusion detection algorithm. for accommodating the available legacy data, the initial version of the prototype has been made highly flexible. only  <dig> out of  <dig> elements , represented as a thick line in figure
 <dig>  are considered mandatory, whereas all others are represented as optional elements. as a proof of concept, we further illustrated the usefulness of this model with a prostate cancer-specific gene fusion candidate tmprss2-erg, re-discovered by next generation sequence analyses
 <cit>  . the instance further validated using the defined xml schema definition . 

controlled vocabularies
a central requirement for efficient data exchange is a common data exchange format, however the presence of this format is not a guarantee of data compatibility. ensuring the standardized use of the data attributes and its values through documentation and controlled vocabularies is also essential. akin to other standardization protocols, controlled vocabularies related to gene fusion attributes and attribute values are subjected to initial standardization in order to enhance the dynamic queries. to avoid redundancy the common elements such as sample details, experimental design, and protocol description that have already been discussed and standardized by other efforts were avoided
 <cit>  and emphasis is placed only on the new data elements specific to next generation sequencing and gene fusion analyses. we believe there are much room to improve upon these vocabularies as the system progresses and becomes widely adopted by the community.

discussion and 
CONCLUSIONS
each successful surveying information system that developed and supported by a community has adopted, during its evolution, certain standard procedures that were warranted for data integrity and interoperability. although a vast amount of microarray data and protein-protein interaction data were generated and reported in the public domain in a non-standard manner, over time the impaired status of data access and integrated analyses were exposed. in response to these issues, communities designed and developed appropriate standardization procedures such as miame / mage-ml
 <cit>  and psi
 <cit> . a number of gene fusion candidates from ngs studies have been recently reported without conforming to any standardized procedures for describing and documenting the associated data. because of this lack of standardization, there is an enormous risk of inaccessibility of such valuable information that can consequently impede data integrity and downstream analyses. although the ngs studies are new and still evolving, the rapid generation of information underscores the immediate requirement for a standardization procedure to represent and document the data in a common format for publication in a journal and deposition in a database in an exchangeable fashion. we believe that our proposed prototype standardization tool, gene fusion markup language  helps in resolving existing inconsistencies in gene fusion data representation and will facilitate the development of interoperable data model that can be dynamically queried and interpreted across different systems.

future plans
the model presented here offers the first necessary steps towards standardization of gene fusion features to share and exchange in a common standard format among the research community. the concept of incorporating the secondary and tertiary features derived from high throughput data can be extended to ngs-based de novo sequencing, gene expression, epigenetics, copy number variation, comparative genomics, metagenomics and pathogens. collaboration with other standardization consortia will be pursued to further develop and extend the existing standards. as part of the community standard initiative, we intend to engage the research community in discussions and look forward to active participation by others to catalyze future development.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
sk-s, as and amc designed the study and prepared the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
gfml_schema.xsd – describes the xml schema definition  of gene fusion markup language, can be viewed in internal explorer or in any xml editor.

click here for file

 additional file 2
 gfml_common.xsd – describes the common reusable elements of gene fusion markup language, can be viewed in internal explorer or in any xml editor.

click here for file

 additional file 3
 gfml_prototype_instance.xml – demonstrate the gene fusion markup language prototype with illustration, can be viewed in internal explorer or in any xml editor.

click here for file

 additional file 4
 gfml_prototype.xml – xml document describes the prototype of the gene fusion markup language. it would be good to view in internal explorer or in any xml editor.

click here for file

 acknowledgements
we thank nallasivam palanisamy, chandan kumar-sinha, dan r. robinson and saravana m. dhanasekaran for helpful discussions. supported in part by the nih r01ca <dig>  the dod era of hope scholar award  and the national functional genomics center  to a.m.c. a.m.c. is supported by the prostate cancer foundation and the doris duke foundation. a.m.c. is an american cancer society clinical research professor and an a. alfred taubman scholar.
