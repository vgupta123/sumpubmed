BACKGROUND
introduction
recombination is an important mechanism for shaping genetic polymorphism. estimating the effects of recombination on polymorphism plays important roles in population genetics  <cit> . one direct measure of the amount of recombination is the minimum number of recombination events in the history of a sample. however, not all recombination events occurred on the genealogy of a sample can be detected  <cit> . we can only estimate the minimum number of recombination events, rmin, which can be interpreted as, at least how many recombination events occurred in the history of a sample. estimating rmin is by no means an easy task, so that most of the previous work focused on the lower bound of rmin, which is also a valid lower bound of the true number of recombination events occurred.

the seminal work of hudson and kaplan  <cit>  introduced a lower bound on such minimum number, rm, which is based on the four-gamete tests under the infinite site model. for each pair of polymorphic sites, if there are four distinctive haplotypes , the data is said to be inconsistent and at least one recombination must occur in that interval. assuming all overlapping four-gamete intervals are caused by the same recombination event, rm is obtained by counting the total number of non-overlapping four-gamete intervals. of course, there is a large chance this assumption does not hold. so rm can be quite conservative. hein and his colleagues  <cit>  used dynamic programming to estimate rmin, which guarantees that the true minimum number can be found. nevertheless, the computational intensiveness prevents its application to a moderate number of sequences. recently, myers and griffiths  <cit>  introduced a new method based on combining recombination bounds of local regions  to estimate a global composite bound of the sample. this method shows a large improvement over rm while it is applicable to moderate to large data sets. further improvements of local bounds have also been suggested by song et al.  <cit> , lyngsø et al.  <cit> , song et al.  <cit>  and bafna and bansal  <cit> , which will be discussed in more detail in the next subsection.

this paper proposes two new improved lower bounds under the infinite site model and their extension to allow for recurrent mutations. the performances of these lower bounds are compared to those of other lower and upper bounds via simulation. two real data sets are analyzed to demonstrate the application of these new bounds. approximation algorithms for the bounds are also discussed in this paper.

previous work on local bound
myers and griffiths  <cit>  introduced two new local bounds under the infinite site model and one method to combine them into a global bound. the basic idea is that, since the algorithms available perform better on a sample of sequences with small number of polymorphic loci than on that with large number of loci, we can cut the sequences into small segments, estimate the lower bound of each segment and then combine them into a global bound for the whole sequences. it is easy to understand that a better local bound would improve the estimation of rmin when combined. in this subsection we summary the previous work on local bounds, and in next section we propose our new algorithms on improving and extending the estimation of local bounds.

to discuss the problem of local bound formally, let us assume a matrix m with n rows and m columns. each row represents a sequence or haplotype and each column represents a polymorphic site. we further assume that there are only two allele types, say  <dig> and  <dig>  at each polymorphic site, which is the most common case for snps. given a set of sequences, an allele type is called mutation if that type has only one copy in the set; a polymorphic site is called informative if each allele type of this site has more than one copy in the set. a local bound is a lower bound of the number of recombination events occurred in the unknown history of the sequences in m.

the local bound rh by myers and griffiths  <cit>  is called a haplotype bound. it is based on the observation of the haplotype number change on an ancestral recombination graph   <cit> . the original algorithm myers and griffiths  <cit>  provided is a heuristic search algorithm. song et al.  <cit>  described an algorithm based on an integer linear programming to compute the optimal rh- bafna and bansal  <cit>  suggested another local bound estimator, rg, which is an approximation of rh calculated with a greedy search algorithm. the local bound rs by myers and griffiths  <cit>  is estimated through tracing the history of the sample, which is similar to that of coalescent simulation. however, the specific topology and length of the branch are ignored. myers and griffiths  <cit>  showed in their paper rs ≥ rh ≥ rm when their global bounds were compared.

bafna and bansal  <cit>  proposed a faster algorithm for computing rs , which views the history of the sequences prospective in time other than retrospective in time as the original algorithm. given a history, there is a particular order of sequences associated with the history  for an example). assume the order is r <dig> r <dig> r <dig>  …, where rj represents a sequence with rank j, then all ri with i < j are potential ancestor sequences of rj. let set m = {r <dig>  r <dig>  … , rj} and m−j = {r <dig>  r <dig>  … , rj−1}. regarding the informative sites of m only , if rj is identical to any sequences in m−j , rj can be derived from m−j via only mutations; otherwise at least one recombination event is needed. the algorithm adds sequences one by one following a particular order. whenever a new sequence added is not redundant, the algorithm counts one recombination. after all possible orders of sequences are examined, the smallest count of an order is regarded as rs. of course, when a non-redundant sequence added, counting only one recombination event is quite conservative. lyngsø et al.  <cit>  suggested a branch and bound search of the exact position of crossovers on the ancestral sequence to produce a true arg. song et al.  <cit>  further extended the method to allow for gene conversion events. alternatively, bafna and bansal  <cit>  introduced an algorithm for computing the minimum number of recombination events, ij, needed to obtain a recombinant j given a set, m−j, of its possible ancestors. the the crucial part of the algorithm is computing the recurrence

 i={∞if j≠h0if j=h and c=1iminif j=h and c> <dig> 

where

 imin=min⁡{i,min⁡h′≠h{1+i}}, 

h  represents the allele type of sequence h at site c and j ≠ h is true only when the two allele types are not missing and different to each other. i  can be interpreted the minimum number of recombinations needed to explain the first c informative sites of sequence j with h  as the parent of j . then

 ij=min⁡h{i},h∈m−j, 

where s is the number of informative sites of sequences in set m = m-j ∪ j.

i can be larger than one if more than one recombination is needed to produce sequence j. in such situations, some recombination products are not presented in the sample and are called recombination intermediates  <cit> . figure  <dig> presents a genealogy of the sequences with their top-down vertical positions corresponding to a particular  order of the sequences, where  <dig> and  <dig> represent the two alleles on each site. the sequences in the boxes with solid lines are presented in the sample while those in the boxes with dashed lines are recombination intermediates. figure  <dig> is an example showing the computation of ij  with j =  <dig> and m−j = { <dig>   <dig>   <dig>   <dig>  11001} as in figure  <dig>  where arrows show how the final value two is obtained.

in bafna and bansal's  <cit>  prospective algorithm for rs , each time when a recombinant is added, one is added to the count of recombination events. at first glance, we can just replace one by ij . however, since the recombinant intermediates are unknown, it is possible some of them are parents of other sequences in the sample. so that the same recombination events may be counted more than once when adding these daughter sequences, which violates the definition of lower bound. although this quantity is no longer a lower bound, it is still informative. song et al.  <cit>  named it ru, as the upper bound of rmin, which can be interpreted as at least how many recombination events are enough to obtain the sample. to avoid counting any recombination intermediate more than once, bafna and bansal  <cit>  introduced the concepts of direct witness and indirect witness of a recombination event. a sequence is a direct witness if it is the direct product of a recombination, i.e. recombinant. a sequence is an indirect witness if it is derived from a recombinant via mutations. for example, in figure  <dig>  <dig> is an indirect witness and  <dig> is a direct witness. based on that they proposed the algorithm of ri which adds the minimum number of recombination intermediates of only one direct witness to the total count of recombination events, which avoids multiple counting of recombination intermediates and make ri a valid lower bound  <cit> . the original algorithms for ru and ri approximate the quantities over all possible orders of sequences  <cit> . algorithms a. <dig> and a. <dig> in appendices a show the corresponding ru and ri for a particular order of sequences, which is useful when only a small set of orders need to be examined. here is an example to compute ru and ri. in figure  <dig> the unobserved recombinant intermediate  <dig> produces both  <dig> and  <dig> in the sample. suppose the order of the sequences is  <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> according to their vertical positions in the figure. with this particular order, we obtain ru =  <dig>  because other than the two recombinations counted for  <dig> and one for  <dig>  two more recombination events are needed to explain  <dig> ), which can also be regarded as an additional count of the recombinant intermediate  <dig>  for the particular order of sequences in figure  <dig>  ri =  <dig> 

RESULTS
improved lower bounds under the infinite site model
in bafna and bansal  <cit> 's original algorithm for ri, the counting of the number direct witnesses and the counting of total number of recombination are independent to each other and may not correspond to the same order of the sequences. however, a particular order of sequence is associated to an arg, which is very informative itself. here we propose a modified lower bound called ro to overcome this disadvantage. the “o” in ro stands for order, which counts the number direct witnesses and the total number of recombinations depending on the same order of sequences. the detailed steps are presented in figure  <dig> .

it is easy to understand that all the difficulties of counting the minimum number of recombination events are due to the fact that all recombination intermediates are unknown. ideally, if in the process of computing rs or ri, when adding a recombinant j to m−j, we also add its recombinant intermediates leading to j, the true rmin can be obtained. it seems straightforward to recover the recombinant intermediates simply by tracing the “path” leading to the final ij , just as the arrows displayed in figure  <dig>  however, this strategy could be very inefficient because typically there will be multiple paths to the same ij  so that many possible recombination intermediates. although some of the intermediates may be redundant, the possible number of distinctive intermediates may still be large. in the case of figure  <dig>  four different paths lead to the same final value of two, each with two break points. there are a total of three distinctive intermediates, 1011*, *** <dig> and ** <dig>  where * represents a site that is not the ancestor of the corresponding site of sequence j, so that its allele type is not of interest. to find the final lower bound, one needs to store all possible combinations of recombinant intermediates as augmented sequences in a set, say m′, at each step of adding a recombinant. each m′ will be used as the possible parent sequences when adding the next recombinant. the number of m′ can grow exponentially at each step of adding a recombinant, so does the computational time. alternatively, we can make a compromise by adding some, but not all, recombinant intermediates.

one immediate candidate is the hypothetical parent sequence of an indirect witness. if only one new mutation is introduced to m from an indirect witness j, a hypothetical parent sequence of j is formed by replacing the mutant allele on the mutation site with the “wild-type” allele presented in all sequences in m−j. for example, in figure  <dig> the hypothetical parent sequence of  <dig> is  <dig>  if more than one new mutation is presented in j, a hypothetical parent sequence of j is formed by replacing all the mutant alleles with a missing data '?', which can be either the mutant allele or the “wild-type” allele. based on this, here we propose another improvement over ri, which is called ra. the “a” in ra stands for augmentation, which augments the hypothetical parent sequences of indirect witnesses into the sample during the process. the detailed steps are presented in figure  <dig>  the algorithm  and a proof  for ra with a particular order of sequences are given in appendices a and b, respectively. as to the example in figure  <dig>  algorithm a. <dig> recovers the recombination intermediate  <dig> and ra =  <dig>  which equals to the true number of recombination events presented.

extension to allow for recurrent mutations
the lower bounds developed under the infinite site model assume all polymorphic inconsistencies are caused by recombination. however, recurrent mutations, commonly observed on mutation hot-spots, also can cause inconsistency. there is a difference though. the former is more likely to affect a long range of sites because a segment of dna was involved in recombination. on the other hand, recurrent mutation occurs one site at a time, so that it is unlikely to observe inconsistent sites clustering together in a long range. this difference has been used to detect recombination and find breakpoints  <cit> . however, the difference is by no means clear-cut, especially when snp data other than sequence data is used, some information of the spacial inconsistent pattern is lost. as a result, it is difficult to distinguish recombination from recurrent mutations. nevertheless, it is informative to give a conservative estimation of the upper and lower bounds of rmin with the consideration of recurrent mutations.

this can be done by extending i , which can be regarded as the minimum cost if h  is the parent of j . in its recurrence, if j  ≠ h, i  = ∞. this is due to the fact that if j  ≠ h  and h  is the parent of j , then i  must be produced by a recurrent mutation on that site, which is not allowed under the infinite site model. so that, the computation of i  is a dynamic programming process which assigns a cost of ∞ to a recurrent mutation and  <dig> to a recombination, and minimizes the cost of all informative sites of sequence j. this minimum cost is also the minimum number of recombination events, since only recombination is allowed and each costs  <dig> 

to allow for recurrent mutations, we can simply assign a cost other than ∞ to it. assume the costs of recombination and recurrent mutation are cr and cm, respectively, then replace i  with i′  as

 i′={0if  j=h and c=1cmif  j≠h and c=1i′minif  j=h and c>1i′min+cmif  j≠h and c> <dig> 

where

 i′min=min⁡{i′,min⁡h′≠h{cr+i′}}. 

again we minimize the total costs of all sites of sequence j. then ij records the number of recombinations  that gives the minimum i′  of all h ∈ m−j. song et al.  <cit>  used a similar approach to incorporate gene conversion event into their search algorithm for the lower and upper bounds of rmin.

this simple extension can be easily applied to ri, ro, ra and ru since they all use the quantity ij . with this extension, they will be presented as rfi , rfo , rfa  and rfu . we can allow different number of continuous recurrent mutations with different combinations of cr and cm. for example, the procedure with cm =  <dig> and cr =  <dig> will prefer one recurrent mutation than a double recombination crossover  at a single inconsistent site, but will prefer a double crossover than two or more recurrent mutations at continuous sites. so that cm =  <dig> and cr =  <dig> can be used as a conservative lower bound of rmin with the assumption that a small number of mutation hot-spots are present and distributed evenly on the sequence. if per bp recombination rate  and mutation rate  are known, the procedure with cm = lg μ and cr = lgr will find the maximum likelihood estimation of the number of recombination events. we need to be careful about the interpretation of these extended bounds. they are just conservative estimations of the corresponding lower or upper bounds under the infinite site model.

another usage of this extension is to show what combination of recurrent mutations and recombinations can produce the same observed inconsistency. the lower and upper bounds under the infinite site model are of one extreme, which show the minimum number of recombination events required to produce the pattern if there is no recurrent mutations. the maximum parsimony tree method used in the phylogenetic study is of another extreme, which shows the minimum number of recurrent mutations needed to produce the pattern if there is no recombination. because a byproduct of rfo  and rfu  is the fully determined number of recurrent mutations associated with a particular order, which can be used to show different combinations of recurrent mutations and recombinations that can produce the same polymorphic pattern. we will show this usage in examples.

performance comparison
to compare the performances of these lower bounds, we conducted coalescent simulations to generate samples and then obtained estimations from the bounds. to simulate a sample, we assumed the values of two crucial population parameters, population mutation rate θ = 4n μ and population recombination rate ρ = 4nr, where n is the effective population size and μ and r are mutation rate and recombination rate per gene per generation, respectively. with different combinations of θ  and ρ ,  <dig>  independent samples were simulated with sample size n =  <dig>  the ms program  <cit>  was used to conduct the simulation.

to study the performances of the local bounds under the finite site model, we used the ms program to simulate gene genealogies and then used the seq-gen program  <cit>  to simulate dna sequences with 2501bp in length given these gene genealogies. for each simulation a kimura 2-parameter model  <cit>  was used with a large transition to transversion ratio, which made each site only had two alleles so that the bounds developed under the infinite site model can also be computed. for each combination of θ and ρ,  <dig>  samples were simulated.

examples
recombination analysis of the adh gene locus
kreitman  <cit>  sequenced  <dig> drosophila melanogaster alcohol dehydrogenase  genes from five natural populations and found  <dig> snps excluding insertion/deletions. this data set has become a benchmark for recombination analysis. song and hein  <cit>  concluded that the exact number of rmin equals seven. we applied the upper and lower bounds to this data set with or without extension to allow for recurrent mutations.

the results  showed that under the infinite site model, the composite bounds of ri, ro, ra and ru all equal seven. to be more conservative and consider the effects of recurrent mutations, we manipulated the costs of recurrent mutations and recombinations such as those shown in table  <dig>  which allow for one, two, three and four continuous recurrent mutations. the results of rfo  and rfu  suggested that the same data could also be explained by three or four recombinations with two recurrent mutations, or one recombination with eight recurrent mutations, or  <dig> recurrent mutations exclusively.

cm = ∞ and cr =  <dig> corresponds to the infinite site model. nm stands for the number of continuous recurrent mutations allowed. the numbers outside the brackets are local bounds. the numbers in square brackets are composite bounds. the numbers in round brackets are numbers of recurrent mutations associated with the corresponding number of recombinations.

recombination analysis of the human lpl locus
nickerson et al.  <cit>  sequenced a  <dig>  kb genomic dna from the human lipoprotein lipase  gene with a total of  <dig> chromosomes from three populations . the amount of recombination detectable in this data was previously analyzed by clark et al.  <cit>  and then by templeton et al.  <cit> . however, the conclusions drawn from these two studies were quite different. templeton et al.  <cit>  used a parsimony-based method to infer the minimum number of recombinations and found  <dig> recombination events clustering approximately at the center region of the sequence. they suggested this could be due to an elevated rate of recombination at that region. but clark et al.  <cit>  applied rm to the data and found no strong clustering of recombinations, which can be explained by false positives caused by recurrent mutations  <cit>  or lack of power  <cit> . with the development of new methods for lower bounds, this data has been analyzed by different authors in recent years. some  <cit>  supported the clustering of recombinations while others  <cit>  did not.

we applied ra and rfa  to the data with all insertion/deletions removed. in detail, first we calculated the local bounds of ra and rfa  for all continuous subsets of polymorphic loci that can distinguish less than or equal to  <dig> distinctive haplotypes in the data. then approximate composite bounds  of ra and rfa  were calculated. for each pair of loci if their distance is larger than 500bp but less than 5kb, the estimated number of recombination events was divided by the distance and recorded as an estimation of the ra or rfa  per bp, which is shown in figure  <dig> as a histogram at the center of that region. similar procedures have shown to be successful in discovering the true positions of recombination hot-spots  <cit> .

to test the significance of possible recombination hot-spots, we used simulation to determine the significance level of the maximum of ra or rfa  per bp. we assumed that ra or rfa  per bp follows a poisson distribution with a mean estimated from the ra or rfa  of the whole gene. then we simulated ra or rfa  for each pair of continuous loci and calculated the average ra or rfa  per bp for each pair of loci that with a distance between 500bp and 5kb. this procedure was replicated  <dig>  times and the empirical distribution of the maximum of ra or rfa  per bp was obtained. figure  <dig>  shows that ra per bp increased at the center of the sequences in the north karelia and rochester populations , but this trend was less obvious  in the jackson population or the combined population. we used rfa  instead of ra to make a conservative measure of the amount of recombinations. the pattern remained but the high peaks of rfa  in north karelia population and rochester population were no longer statistically significant ). this result suggested that those possible false positives produced by recurrent mutations may indeed cause the clustering pattern, other than disperse it.

discussion
although the dynamic programming algorithm used in rs, ri, ro, ra and ru is a significant improvement over the original algorithm proposed by myers and griffiths  <cit> , it can be quite slow when the number of haplotypes is large. alternatively, we can use a heuristic search algorithm to approximate the local bound. random-restart hill-climbing is a widely used heuristic search algorithm in artificial intelligence  <cit> . the basic idea of hill-climbing is as follows. we begin with a random order of the sequences, then we compute a local bound r  with this fixed order such as algorithm a. <dig> or a. <dig>  record it as rold. then we randomly replace the positions of two sequences  to form a new order and compute r with the new order again. repeat k times and we take the minimum of these k new estimations of r as rnew. if rnew ≥ rold, stop. otherwise, replace rold with rnew and begin another round of k flips from the new order that produced rnew. repeat this procedure until rnew ≥ rold. then this rold is an approximation of r with dynamic programming. then we restart the hill-climbing with another random order and repeat m times. the minimum of all estimations is taken as a result. note that the heuristic approximation of ru is still a valid upper bound, but that of any lower bound may not be a valid lower bound.

other than using the heuristic search algorithm described above to approximate local bound, we can also approximate the composite bound, e.g. only the local bounds on all continuous regions with m or less sites are computed and used to estimate the composite bound. with the limit of sites, the number of haplotypes for the local bounds is also limited so that it prevents the need for large computational complexity. alternatively, one can directly set a limit on the number of haplotypes used to compute the local bounds. the rational behind this procedure is that the information of the local recombination event between two sites sl and sl+ <dig> is mostly contained in sites that are closely linked to them. the sites far away from sl and sl+ <dig> contain little information so that adding those sites has little contribution to the composite bound.

CONCLUSIONS
in summary, the contributions of this research are several algorithms for estimating the lower bound of the minimum number of recombination events in the history of a sample. these new lower bounds are shown to be better than existing ones under the infinite site model. furthermore, they are extended to allow for recurrent mutations, which are robust to high mutation rates and mutation hot-spots. these extended bounds can be used as a conservative measure of the amount of recombination or can be used to show different combinations of recombination and recurrent mutations that can produce the same polymorphic pattern in the sample.

list of abbreviations used
arg: ancestral recombination graph

adh: alcohol dehydrogenase

lpl: lipoprotein lipase

competing interests
the authors declare that they have no competing interests.

authors contributions
xl participated in the design of the study, carried out the algorithm development and testing, and drafted the manuscript. yf conceived of the study, participated in its design and helped to draft the manuscript.

all authors read and approved the final manuscript.

appendices a: algorithms
algorithm a. <dig> an algorithm for computing ru with fixed order

compute_rm with fixed order

input: set m of all sequences

return: ru

local variable:

n: number of sequences in m

m: a subset of m

m−j: a subset of m by removing sequence j

for i =  <dig> to 3

subset m =first i sequences of m

ru  = 0

for i =  <dig> to n

subset m =first i sequences of m

if sequence i is redundant

ru  = ru

else

ru  = ii  + ru 

return ru 

algorithm a. <dig> an algorithm for computing ri or ro with fixed order

compute_ri or ro with fixed order

input: set m of all sequences

return: ri

local variable:

n: number of sequences in m

m: a subset of m

m−j: a subset of m by removing sequence j

for i =  <dig> to 3

subset m =first i sequences of m

rd= <dig>  ri=0

for i =  <dig> to n

subset m =first i sequences of m

if sequence i is redundant

rd  = rd 

ri  = ri 

else

rd  = a  + rd 

ri  = max{l + ri , rd  + ii }

return ri 

algorithm a. <dig> an algorithm for computing ra with fixed order

compute_ra with fixed order

input: set m of all sequences

return: ra

local variable:

n: number of sequences in m

m: a subset of m

m′: an augmented sequence set of m

m_j: a subset of m by removing sequence j

pj: hypothetical parent sequence of sequence j

for i =  <dig> to 3

subset m =first i sequences of m

m′ =ø, rd =  <dig>  ra = 0

for i =  <dig> to n

subset m =first i sequences of m

if sequence i is redundant in m ∪ m′

m′ = m′−i, rd  = rd , ra  = ra 

else

 ra  = max⁡ {1 + ra , rd + ii }rd = 1 + rd  

if sequence i is an indirect witness

m′ = m′ ∪ pi

return ra 

appendix b: proof of ra as a lower bound
here we present a simple proof for algorithm a. <dig> as a valid lower bound. bafna and bansal  <cit>  has proved that ri is a valid lower bound of rmin given a particular order of the sequences. this conclusion is true not only when all recombination intermediates are unknown, but also in the case if some “true” recombination intermediates are recovered in the order. if an indirect witness j introduces exactly one mutation into sequence set m, then forming a pj  by replacing the mutant allele with the “wild-type” allele of that site will recover the last recombination intermediate  that leads to j via one mutation. for example, in figure  <dig>  the lri of indirect witness  <dig> is  <dig>  if an indirect witness j introduces n  mutations into sequence set m, there are multiple possible lris of j but only one of them is the “true” lri. however, if we form a pj by replacing the alleles on the mutant sites of the true lri with missing data, ij must be less than or equal to ij, since in calculating i a missing data is never regarded as different to any alleles. similarly, ik must be less than or equal to ik, where k is a possible offspring of j and sk is a set of other possible parent sequences of k. so that, by augmenting the pj and then follow the procedure of ri we can get an estimation less than or equal to that with augmenting true lris. then the procedure  must produce a valid lower bound.

