BACKGROUND
subcellular localization is a key functional characteristic of proteins. each protein has some elementary functions. to co-operate for such physiological function, proteins must be localized to the correct intra- or extracellular compartments in a soluble form or attached to a membrane  <cit> . although the subcellular location of a protein can be determined by conducting various locational determination experiments, it is time consuming and costly to acquire the knowledge solely based on experimental measures. the number of protein sequence entry is increasing rapidly; it is highly desirable to develop a theoretical method for fast and accurately predicting protein subcellular location. a number of automated systems have been developed to predict the subcellular localization of proteins. most of these methods for prediction of subcellular localization of proteins are based on signal peptides  <cit> , the location by sequence homology, and the correlation between the total amino acid compositions of proteins using artificial neural network   <cit> . prediction schemes rely upon the identification of a key sorting signal , the presence of which suggests a fairly unambiguous subcellular localization. von heijne  <cit>  and colleagues have developed subcellular localization predictors designed to identify either signal peptides or chloroplast transit peptides. according to claros et al., 1997; nakai and kanehisa,  <dig>  <cit> , biological implication is the merit of such predictors because newly synthesized proteins are governed by an intrinsic signal sequence to their destination, whether they are to be translocated through a membrane into a particular organelle, or to become integrated into the membrane  <cit> . the utility of such localization prediction is dependent upon the availability of accurate n-terminal sequence, which can be somewhat problematic if the method predicts the start codons correctly, but can lead to leader sequences being missing or partially included, thereby confusing the algorithms depending on them  <cit> . subcellular localization can often be assigned by searching for homologous sequences. several localization predictors consider compartmentalizing proteins on the basis of amino acid sequence composition – correlating a typical amino acid composition with localization to a particular subcellular compartment or organelle  <cit> . unfortunately, his studies of the predictive power of amino acid compositional data for subcellular localization were restricted to small sets of only a few hundred proteins. studies showed that classifying into  <dig> different groups according to their subcellular locations improves the prediction accuracy. on the basis of this classification a covariant discriminant algorithm was proposed  <cit>  to predict subcellular location of a query protein. this method is also based on amino-acid composition and the results obtained through self-consistency, jacknife and independent dataset tests indicate the improved accuracy rate.

in this paper, an attempt has been made to improve the prediction accuracy of subcellular localization of proteins using support vector machine . two feature vectors e.g. amino acid compositions and amino acid pairs  composition is considered for the prediction.

RESULTS
svm kernel selection
it is not known beforehand which kernel function, value for parameters γ, c, and d is the best for classification problems, and consequently some kind of parameter search must be done to identify the good pair of c, γ for rbf and c, d for polynomial and linear kernels to achieve high training accuracy. when training the svm, we need to select the proper kernel function and the best values for the kernel parameters for the optimal results. in this study, we begin by searching the proper kernel function. different values of the γ parameter are used to test the performance of rbf kernel ranging from the default value  to  <dig> . while testing the value for γ parameter, regularization parameter c was kept constant to  <dig>  total accuracy  was computed after 10-fold cross validation. results of total accuracies for  <dig> sequences with different types of kernel functions and their parameters are summarized in tables  <dig>   <dig> & <dig>  further selection search was done for the value of c with  <dig>   <dig>  and  <dig>  it was found that total accuracy was best when c =  <dig> and γ =  <dig>  . we also examined the value of exponential parameter d for the polynomial and linear kernel ranging from d =  <dig> to  <dig>  we found that the total accuracy decreases with the increase in value of parameter d . finally, to avoid the over-fitting and capturing a better decision boundary, γ =  <dig>  , c =  <dig>  and d =  <dig>  is used. polynomial kernel turns to linear when the value of d =  <dig>  search results confirm that the rbf kernel performs better than polynomial and linear kernels.

the entire search method was also done for the dataset with  <dig> protein sequences. it was found that the total accuracy is worse with the rbf kernel. it appeared that the value of γ over-fits the svm classifier but polynomial and linear kernel worked well .

amino acid composition svms
the svm was provided with  <dig> dimensional feature vector based on amino acid compositions. rbf, polynomial and linear kernel functions are used with the most optimal value of the parameters. the best results are achieved using rbf kernel. the value of gamma factor and regulatory parameter “c” was optimized to “ <dig> ” and “100” respectively. the results obtained after five fold cross-validation gives the overall total accuracy of  <dig> %.

hybrid svm
the svm was provided with  <dig> dimensional ) feature vectors based on both the amino acid compositions and the amino acid pair compositions. in the hybrid approach best results are obtained with rbf kernel. we have also used the polynomial kernel and linear kernel but the results are poorer in comparison to rbf kernel. the value of the gamma  and regulatory parameter c optimized to “ <dig> ” and “100” respectively. the overall total accuracy increased to  <dig> %. figure  <dig> shows that rbf kernel for svm classifier performs better than polynomial and linear kernels. amino acid pair composition has been shown to contain sufficient information to distinguish proteins of different subcellular locations .

feature dimensions
considering just the amino acid composition gives some information about the subcellular locations but not sufficient enough to rely on it. adding more protein features might give better prediction accuracy. adding physicochemical properties like polarity and charge as the additional protein feature would be able to correctly classify the proteins with average or low sequence length. to measure the role of more features for prediction, we introduced amino acid pair composition. as expected, table  <dig> shows that more features give improved accuracy. accuracy reached to  <dig> % from  <dig> %. it is also noticed that the variation between the overall tpf, tnf and ta is much less .

impact of number of subcellular locations
in order to observe the role of the number of subcellular locations on the prediction rate, two datasets were constructed. the new datasets were derived simply by removing the small subsets from the  <dig> locations. one dataset contains  <dig> protein sequences from nine different subcellular locations. these locations are chloroplast, cytoskeleton, endoplasmic reticulum, extracellular, golgi, lysosome, mitochondrion, nucleus and peroxisome. the other dataset contains  <dig> protein sequences from five different subcellular locations. locations to which majority of proteins are targeted are considered. the locations are chloroplast, cytoskeleton, extracellular, lysosome and nucleus. total accuracy was measured after 10-fold cross validation with rbf kernel. as it was expected, the accuracy increased significantly. figure  <dig> shows that the overall total accuracy of five locations  is higher than the overall total accuracy of nine  and  <dig> locations .

impact of data distribution
in order to check the role of the data distribution on the prediction rate, we used the dataset of  <dig> locations by chou and elrod  <cit> . total of  <dig> protein sequences were used in this dataset with very uneven distribution of sequences among the  <dig> locations . we found that rbf kernel overfits this dataset but polynomial and linear kernels classify well. we noted that there is large variation in tpf and tnf. on the other hand, this variation is less when the balanced dataset is used . results show that few of the classes  have high prediction accuracy for amino acid composition as compared to amino acid pair composition and hybrid composition. it is observed that even though the number of sequences is very low in cytoskeleton class, the average sequence length is high as compared to the other classes. moreover there is a vast discrepancy related to sequence length in this class of sequences. some of the sequences are very short in length while others have length few times longer than these smaller sequences. in plasma membrane class the total number of sequences is very high. these sequences are almost similar in length. this length is higher as compared to average length of most of the other classes. this results in very high total amino acid count for this class as compared to others. for both these classes, the amino acid pair composition and hybrid compositions have almost similar prediction accuracies. it can thus be inferred from these examples that the sequence length and number of sequences present in a class contribute to the amino acid composition accuracy to a greater extent. future work is needed to assess the amino acid composition accuracy with the balanced data as compared to length and total number of sequences in each class. overall result shows that the predictive accuracy increases as the number of sequences in each class increases. increase in total amino acid composition for a class also leads to overall increase in accuracy for all types of compositions. the ratio of positive and negative samples in the training data might be a contributing factor for this. for the classes with less number of sequences, negative samples are very high as compared to positive samples. this results in reduced accuracies. figure  <dig> shows the overall tnf, tpf, and ta with polynomial kernel. so it is important that the positive and negative samples must be balanced in training data in order to achieve high accuracy. along with this, the total amino acid composition for all the classes used and hence all the samples also needs to be balanced for achieving good predictive accuracies.

comparison with other methods
the prediction performance of our svm approach was compared with other methods. this comparison is summarized in the table  <dig>  the dataset for neural network method  <cit>  was based on eukaryotic and prokaryotic sequences. the sequences were divided into  <dig> and  <dig> classes and the results were obtained with 6-fold cross validation. as seen in the table  <dig>  the prediction accuracy of our svm based approach for  <dig> classes is about  <dig> % higher than reinhardt & hubbard's  <cit>  approach and 6% higher than subloc's  <cit> . our approach performs better than another method proposed by garg et al.,  <dig>  <cit> .

CONCLUSIONS
based on the three different test results, svm with more than one feature vector seems to be superior in accuracy for distinguish proteins of different subcellular locations. it was observed that adding more protein features improves the prediction performance. various kernel functions with all possible values of parameters are used to train the svm. in case of amino acid compositions, selection of value for gamma parameter ‘ γ ’, regularization parameters ‘d’ and ‘c’ is vital as they control the complexity of the learning process of the machine. it also influences the speed of training process. selection of kernel function parameter is also important to define the maximum margin hyperplane. roc curve analysis for three kernel functions indicates the area under the curve is greater for rbf kernel  as compared to polynomial kernel  and linear kernel  .

