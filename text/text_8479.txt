BACKGROUND
bioinformatics data analysis often deals with additive mixtures of signals from unknown interfering sources. in the majority of cases, only class labels are known for each sample, which hampers the estimation of the original source signals. an example of such a situation is the search for metabolic features in blood within different patient groups. in blood, several signal sources add up as each single organ may submit hormones contributing its state into this complex mixture. for instance, adipocytes secrete the hormone leptin to indicate their state. this signal is then recognized in the hypothalamus to regulate the appetite. at the same time, insulin is secreted by pancreatic beta cells for the regulation of the blood sugar. both peptide hormones are present within the blood while their regulation results in different outcomes. however, both signals are also hidden within a huge and noisy background of further signals also present in the blood stream. consequently, a large number of samples must be taken to clearly identify an unknown signal. infrared  spectroscopy is a rapid method for detecting signals in biological samples. it relies on quantities of  <dig> μl size that can be easily obtained and it is fast: measuring a complete sample where each single molecule is detected requires a total time of  <dig> s on a bruker tensor  <dig> 

the principles of ir spectroscopy, see for instance  <cit> , are illustrated in figure  <dig>  ir spectroscopy can be used for the quantification of known compounds or for structural elucidation of unknown molecules. an ir source emits light towards a sample solution of chemical compounds. ir radiation is absorbed by chemical compounds as motion energy when the absorbed energy fulfills the resonance condition of a tone or related overtones. in this way, ir spectroscopy detects oscillations of bonds. as an additional condition, ir spectroscopy requires that oscillations lead to a periodical change of the molecular dipole moment. consequently, compounds having no dipole are ir inactive. however, in the case of an ir active compound functional groups can be identified by their characteristic absorption bands, and thus give hints for structural elucidation. alternatively, compounds can be identified through their characteristic fingerprint region within their ir spectra. this unique characteristic absorption fingerprint completely depends on the molecular constitution, because each path through a compound that is associated with a change in dipole moment absorbs at a characteristic wave length. all such paths of various lengths yield the characteristic absorption spectrum and uniquely identify the compound. thus, the prediction of the ir spectrum of a compound is a hard task. finally, we want to note that the ir detector records a mixture signal of all compounds present in the sample. consequently, each single molecule present in the  <dig> μl sample contributes to the signal, whether it is known or not. then, the vibration spectrum represents a complex " fingerprint" of the biochemical condition of the sample wherein single compounds are not recognized any more.

however, all diseased changes are included in detail integrately such that the sample can be analyzed objectively and without knowing disease markers with the ir-spectroscopy. in this way, ir spectroscopy has a great potential as a method for early diagnosis and therapy control  <cit> . analyzing ir spectra is however a complex signal processing problem.

nonetheless, there exist algorithms that are able to separate additive signals into estimated subcomponents. examples for these methods are non-negative matrix factorization   <cit>  or independent component analysis   <cit> . both compute a generative additive signal model that is fitted to data samples to estimate the basic subsignals each data sample is composed of. however, ir spectra do not completely fulfill sparseness or smoothness constraints used by ica or nmf completely, see  <cit> . moreover, these methods are not designed for training on data with classification labels nor do they yield predictive models. in this work, we solve the class assignment problem and design a factorization method using a generative additive model that can be trained on data samples having class labels. for each class label, a factor signal is computed that, when exceeding a learned threshold, predicts the specific label. therefore, our method can be trained on cheap ir spectra using class information and extract meaningful components from these signals, which leads to further insight into data and a predictive model.

methods
this section develops the new predictive matrix factorization algorithm named brierscoremf for ir spectra. first, we motivate and define the problem. then, we introduce factorization and classification loss functions and their matrix formulations. finally, we derive the brierscoremf algorithm.

 <dig>  problem formulation
in daily practice, bioinformatics often deals with signals from interfering sources. each source could have considerable impact on the final interpretation of the signal. for instance, consider endocrine signaling. the endocrine system is composed of glands secreting a hormone into the blood stream. within certain ranges, these signals represent the normal body state. however, increased signals may indicate a disease state, e.g. oncogenesis  <cit> . thus, measuring all endocrine signals yields a superposition of healthy and disease signal combinations that have to be separated to diagnose the physical state. moreover, disease signals may be combinations of coregulated signals not originating from a single signal source. in practice, measured signals are only grouped by disease classes raising the question for the characteristic shape of the disease signals.

thus, we are dealing with two simultaneous problems: a signal decomposition problem and a classification problem that is based on the signal decomposition. a practical approach would try to learn the signals from given data samples.

matrix factorization methods are convenient algorithms for the signal decomposition task  <cit> . these methods solve the problem of finding the decomposition x = as for any matrix x. in general, this problem is ill-posed. however, using constraints restricts the number of feasible solutions, which can be found by local optimization algorithms. commonly used restrictions comprise constraints for the statistical independence of signals  <cit>  as well as non-negativity or sparsity of coefficients in a  <cit> . up to now no factorization method is known using class labels, therefore our approach includes constraints for classification that are needed to learn from ir spectra obtained in clinical studies.

we begin with developing our predictive factorization algorithm. given n pairs  of data samples comprising signals x→i∈ℝd and k classes yi ∈ c = {c i, . . .,c k}, we define the following matrices

  design matrix x=t∀i 

  class matrix y=∀i whereyij={+ <dig>  if xi has class cj− <dig>  else. 

the dimensions are x ∈ ℝn × d and y ∈ ℝn × k. thus, each row in x defines a measured signal and relates to a row in y containing binary class information.

searching for a factorization into signals s→j∈ℝd and coefficients aij ∈ ℝ, we want that

  x→i=∑j=0kaijs→j∀i⇔x=as .

where a ∈ ℝn × k and s ∈ ℝk × d. equation  means that each signal is a linear combination of k different source signals and defines the general factorization problem in matrix formulation with respect to a and s. in practice, noise hampers the inference of the s→j and, consequently, this condition is not fulfilled exactly by any solution. however, we will see that in our special case the problem only reduces to finding a suitable s. for classification, we propose a linear approach using a threshold. therefore, we want that

  yij=signum ∀i,j 

where b→∈ℝk is a column threshold vector of the factorization. if the signal fraction exceeds a certain threshold, this will indicate the class membership within our prediction model.

 <dig>  factorization loss functions
in general, factorization algorithms focus on the signal side of the problem. these methods optimize special distance functions between probability distributions, referred to as divergences, to estimate a and s. it can be shown that optimizing a and s in parallel is a non-convex optimization problem. commonly used divergences include the frobenius norm as well as the kullback-leibler divergence. other exemplary divergences are the itakura-saito divergence and the families of α- and β-divergences  <cit> .

however, in this work we will rely on the frobenius norm between x and as for divergence. thus, we define the reconstruction error part of our loss function as

  ℱ=‖x−as‖f 

where

 ‖z‖f≡∑i,jzi,j2⇔‖z‖f2=trztz 

for some matrix z. here, tr denotes the trace of a matrix.

we have chosen the frobenius norm as divergence for the reconstruction error, because it easily allows to compute the matrix differentials of an expression. this will simplify the search for possible solutions in section  <dig> .

 <dig>  classification loss functions
classification algorithms focus on the inference of a predictive model for a target variable from training data. therefore, they optimize classification loss functions that penalize false predictions to find the most probable parametrization of a model. convenient loss functions comprise the brier score  <cit> , the svm loss  <cit> , the logistic loss  <cit> , as well as the misclassification loss function.

we chose the brier-score  <cit>  as it also can be expressed in terms of matrix computations. let y ∈ {- <dig>  +1} be the class label and let e denote the expectation operator. then the brier-score is defined as

  e 

where f is a parametrized model function.

now, consider equation  and define the matrix v to contain the signum arguments

 v≡n×k=a−1n×1b→t 

where b→∈ℝk× <dig> is the vector of column thresholds. then, the brier-score can be written as a matrix function from ℝn×k↦ℝ as

 ℬ=κtrt 

where κ=1nk,y is the class matrix, 1n×k an n×k matrix of ones, and ◦ denotes the hadamard product.

 <dig>  the predictive factorization algorithm
current factorization methods are not predictive and can only be used for signal inference. in the case of nmf methods  <cit> , this arises from the gradient descent methods used for optimization. often, an alternating gradient descent is performed, where one matrix is kept fixed while the other is optimized. the drawback for a predictive approach based on a is that for a given nmf signal matrix s the corresponding a is not uniquely defined.

for any predictive approach, training a model requires that a is treated as a function of s and x. this, to our best knowledge, is not the case in current factorization approaches.

here, we solve this problem by using the moore-penrose pseudoinverse  of s during training to compute a. the mp is uniquely defined for any matrix s. let s+ denote the mp of s being defined by the following properties

  ss+s=s,s+ss+=s+,t=ss+,t=s+s 

using these rules, it is easy to show that

  x=as⇔xs+=a 

using  and assuming the existence of the quadratic matrix - <dig>  now, a is clearly defined as a function of x and s and we have solved the problem of the uniqueness.

used in the following sections, we derive the differential for s+. therefore, we adopt the notation from  <cit>  to compute ds+ as

      ds=d=+ss+⇔ss=ds−−  ⇔ds+=−1s+s+−1−−1s+s+−1−−1s+s+−1  ⇔ds+=−s+s+. 

together with the two loss functions and the mp differential, all ingredients are available for the brierscoremf algorithm. first, we join both loss functions into a combined minimization problem

 min s,bℒ=ℱ2+←=trt+κtr−1)t−1) 

and substitute a = xs+. thus, the complete loss function is easily expressed using matrix terms, where we have omitted the sizes of the 1-matrices for simplicity. furthermore, we have used that is suffices to optimize a monotonic transformation of f .

to find a minimizer of the l, we compute the differential

 dℒ=dtrt+κdtr−1)t−1) 

for the first summand, we compute

  dtrt=2trtd=−2trtxd=−2trtxs+s+)=−2trtxs+s+s+)=2trtxs+s+s−2trtxs+ 

using trat  = tr c , the second summand derives to

  dtr−1)t−1)=2tr−1)td−1)=2tr−1)t)  −2tr−1)tt)=−2tr−1)∘y)txs+s+  −2tr−1)∘y)t1t 

now, consider the term

  −1)∘y)t=∘y−1∘y)t=t, 

because y ◦ y =  <dig> and  <dig> ◦ y = y. setting the differential to zero and using the computation rules for the trace, especially trabc = trcab, we derive

 dℒ=2trtxs+s+s−2trtxs+−2κtrtxs+s+−2κtrt1t=tr−2κtrt1t= <dig>  

as both tr terms relate to distinct differentials, we first obtain that

 0=xs+−1b→t−y⇔xs+=y+1b→t≡w 

for the coefficients of db→.


assuming xs+ ≠  <dig> and substitution of w back into 0=dℒ yields

    0=2s+st−2t−2κs+t=2−2κ0⇒x=ws⇔s=w+x=+x 

to this end, we have found a solution for the predictive matrix factorization problem using the brier score as classification loss and the frobenius norm as factorization loss. moreover, the solution is fully determined by a single k ×  <dig> vector b→ that allows the computation of the factorized signal matrix s as well as the computation of the predictive coefficient matrix

 a=x*s+=x*+x)+ 

for unknown data x*.

now, the final problem of finding the vector b→ remains. in the present approach, we found that optimizing the following target function yields best performance

 o≡1r∏i 

where si and ti denote the cross-validated sensitivities and specificities, and r denotes the cross-validated reconstruction error. using numerically computed gradients for b→ in combination with a bfgs local search method  <cit>  to optimize o
 completes the brierscoremf.

we conclude this section with an interpretation of equation . first, we note that the brierscoremf has very few parameters, namely b→∈ℝk, which minimizes the probability of over-fitting , but also hampers the algorithm in obtaining high prediction performance. next, the computation of s involves both, the design matrix x used for training and the class matrix y . thus, using the known classes and a linear offset b→ the training data is projected by the mp of + to a transformed matrix s.

consequently, the training information y and x are compressed together with the learned variables b→ in s. in this way, our new factorization method is similar to nearest neighbor classifiers, which also store the training data itself while learning a threshold value for classification.

all software used in this article is freely available from the author.

RESULTS
this section empirically compares the performance of the brierscoremf with linear support vector machines   <cit> . therefore, we sample synthetic signal functions together with class and coefficient matrices for training both machine learning models. this setting was specifically designed with regard to the application case of ir spectroscopy. finally, we train both algorithms on a real world ir data set comprising various diseases for classification.

we would like to note in advance that this comparison is not totally fair. svm are pure classification algorithms that are statistically highly robust and achieve very high performance. in contrast, the brierscoremf is a factorization method designed for both, signal decomposition and prediction. therefore, the problem solved by our algorithm is more constrained than the svm.

in addition, our method has less degrees of freedom. to infer a brierscoremf model only k, being the number of classes, variables are optimized. contrarily, even a linear svm has m, being the number of input dimensions, variables to specify a predictive model. in our case, m =  <dig> and k =  <dig>  thus rendering brierscoremf the less flexible model. in addition, our method is a native multi-class algorithm where one model suffices to explain all classes. in contrast, the employed multi-class linear svm are trained in one-versus-one mode resulting in  <dig> ·  <dig> =  <dig> models used for prediction. in terms of occam's razor, our model is the more simple method with an generative model suitable for prediction.

thus, we compare both algorithms for baseline reasons and not to demonstrate the superiority of the brierscoremf. a comparison to actual factorization methods is planned as future work, because the question for fair performance measures for this task turns out to be far more delicate.

 <dig>  experiments on synthetic data sets
ir spectra of chemical compounds and mixtures are smooth functions of the wavelength. in general, the measurement ranges from 400cm - <dig> to 4000cm - <dig> for fourier-transform infrared spectroscopy. however, we have chosen to sample base signals from sobolev spaces  <cit>  defined on the range  <dig> <cit>  as smoothness is more important than the signal domain.

sobolev spaces are function spaces defining smooth functions. in a sobolev space, smoothing a function means shrinking higher order coefficients towards zero. therefore, sampling signals from this family of functions yields appropriate spectra that are smooth. we chose the fourier basis ϕi

 φ1= <dig>  φ2j=12cos, φ2j+1=12sin, j= <dig> , … 

from which signals

 f=∑j=1∞θjφj. 

where sampled by their coefficients θj.

in this experiment, each synthetic data set is defined by four parameters: a seed for the random number generator to make the experiment reproducible, the number n of samples generated for the data set, the number k of classes contained in the data set, and the number m of feature dimensions. we used 5-fold cross-validation  to estimate the prediction performance in terms of sensitivity si and specificity ti as well as the reconstruction error r

 si≡tpitpi+fni, ti≡tnitni+fpi, r≡∥x−xs+s∥f 

where tpi denotes the true positives, tni the true negatives, fpi the false positives, and fni the false negatives of class ci. note that the brierscoremf employs an inner cross-validation loop for performance estimation, therefore the outer cross-validation measures the true generalization error of our model.

the generation of a data set was performed as follows: first, the seed of the random number generator was set. then, the b→ vector was sampled from a uniform distribution. after that an n-array y of classes was obtained by sampling classes with replacement from c <dig>  . . ., ck. this was followed by sampling the order o of the sobolev space by drawing an integer out of the range  <cit> . based on this, a matrix t containing o signal coefficients for each of the k signals was drawn from a uniform distribution. finishing the sampling round, we finally drew the coefficient matrix a from a uniform distribution.

first, the matrix s containing the m measurements at equally spaced coordinates between  <dig> <cit>  was computed from the coefficient matrix t . then, the class matrix y was constructed from the class array y by setting appropriate entries on + <dig> and every other entry to - <dig>  finally, we processed the coefficient matrix to relate to y as follows: each entry of a was scaled to the range  for positive ones. after that all entries relating to negative y -entries were scaled such that ∑jaij=1∀i. given a and s we finally computed x = as, completing the synthetic data set.

in this way, we obtained  <dig> synthetic data sets using  <dig> seeds for each combination of n ∈ { <dig>   <dig>  150}, k ∈ { <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>  25} and m ∈ { <dig> }. on each data set, first the brierscoremf and subsequently the linear multi-class svm from the r package e <dig> was trained  <cit> . thus, a direct performance comparison based on 5-fold cv was obtained. the prediction results are shown in figures  <dig> and  <dig> 

first, we found that there exist no significant differences in the performance behavior with respect to the input dimensions m for both algorithms. inspection of the class parameter reveals that the linear svm is superior to the brierscoremf for problems with less than five classes. nonetheless, in these categories the brierscoremf achieves sensitivities and specificities around  <dig>  with a standard deviation of less than  <dig> . for problems with the number of classes between  <dig> and  <dig> the brierscoremf achieves superior sensitivities and specificities to the linear svm. however, if the number of training samples is large , the linear svm obtains competitive specificities again. in summary, we find that the prediction performance of the brierscoremf decreases slower than the performance of the svm with increasing class size. finally, we note that in contrast to the svm the standard deviations of the brierscoremf for sensitivity do not exceed  <dig>  and for specificity  <dig> . in conclusion, we have characterized and compared the prediction performance of the brierscoremf on synthetic data with a state of the art machine learning method. as explained, the brierscoremf solves a more complex system by generating an interpretable signal factorization, which balances the performance loss.

in the next section, we present results of the brierscoremf obtained by training on real ir spectra.

 <dig>  experiments on a clinical data set
next, we applied the brierscoremf to real world data. therefore, we have reused the ir spectra of blood serum measured for the study in  <cit> . therein, serum samples were collected at the university hospital heidelberg, the university hospital mannheim, and the st. vencentius krankenhaus in karlsruhe, while the healthy control was obtained from the blood donating center in mannheim. in total,  <dig> different diseases were collected and analyzed. however, reference  <cit>  combines the classes mci and alzheimer, colitis ulcerosa and morbus crohn, heart insufficiency and heart infarction, as well as colorectal carcinoma and rectal carcinoma and, therefore, reports  <dig> diseases. in this work, we predict the more detailed classifications. for each ir spectrum,  <dig> μl of serum was diluted to  <dig> μl of distilled water, placed and dried on a  <dig> well si-sample carrier plate. then, the plate was measured on a bruker tensor  <dig> fourier transform ir spectrometer . in total, each sample was measured at least at three different days having randomized positions on the  <dig> well plate to avoid environmental effects. in this work, subsequent data processing consisted of the removal of all triplicates having a pairwise pearson correlation of less than  <dig> . all remaining triplicates were averaged before savitzky-golay smoothing . finally, we employed 5-fold cv to estimate the prediction performance of both svm and brierscoremf. the results of this evaluation are shown in figures  <dig>   <dig>  and  <dig> 

we found that the linear svm was often superior to the brierscoremf. it was highly specific  while being less sensitive  than our method in some cases. as explained above, this outcome was expected as the linear svm has more degrees of freedom  compared to brierscoremf . in addition, training one-versus-one classifiers provides additional robustness with respect to noise as the classification problem is separated into smaller pieces. whereas our algorithm is a native multi-class algorithm that is additionally constrained to yield an interpretable factorization.

however, our method achieved an estimated reconstruction error of  <dig>  × 10- <dig> per matrix entry for this data set. the sensitivity ranges from  <dig>  to  <dig> , while specificity ranges from  <dig>  to  <dig> . in addition, it infers interpretable and predictive signals that may lead to further insight into characteristic disease signals, figure  <dig> 

to demonstrate the ability of the brierscoremf to discover interesting signal features in ir spectra, we now focus on four exemplary signal peaks in figure  <dig>  named , ,  and . figure  <dig> shows only the discussed signals. the peak at  belongs to the colorectal carcinoma signal. it is within 1100-1150cm- <dig> and, therefore, may belong to the region were normally the dna/rna ribose co stretching vibrations appear  <cit> . in colorectal carcinoma, this potentially indicates an increase of dna/rna damage by post-transcriptionally modified nucleic acids induced by cancer progression  <cit> . the peak at  is at 2700-2950cm- <dig> and, thus, is in the region of the ch-group of phospholipids. signals comprising peaks at  include bronchial carcinoma, colorectal carcinoma, pancreas carcinoma, pancreatitis, as well as the prostate carcinoma. here, the phospholipid groups may relate to inflammatory signals in the blood responding to cancer  <cit> . the signal peaks marked with  relate to amid groups, while  indicates an ester of phospholipids. the disease specific signal showing these peaks  and  belong to heart attack . it is known that lipids form plugs that are a major cause for heart attacks, which could correlate the signals at   <cit> . additionally, we measured the pearson correlation between the heart attack and the heart insufficiency signal resulting in ρ =  <dig> , which equals the maximum positive correlation within the inferred signals. consequently, our algorithm was able to detect several interesting disease specific signals for further research.

the additional files provide supplementary results for training without the water peaks ) as well as the detailed prediction performance of the brierscoremf method on the clinical dataset .

CONCLUSIONS
in this work, we have presented the brierscoremf algorithm for factorization of additive signals. the ultimate goal was to employ ir spectra obtained from blood samples to classify patients based on disease specific signals. we have established a performance baseline for our method on both, synthetic and real world data. yielding interpretable base signals, our factorization obtains comparable prediction performance on synthetic data sets comprising more than  <dig> classes. on real world data, we measure sensitivities as well as specificities of up to  <dig> .

our factorization method combines both tasks of prediction and signal inference. therefore, we are confident that our work constitutes the basis for further development of similar factorization algorithms. future research should focus on improving the prediction performance of brierscoremf, as well as on a correct comparison with actual factorization methods. also, the integration of non-negativity constraints into our algorithm is of practical interest.

authors' contributions
ch developed the algorithm and designed the experiment. pl also contributed to the experimental design. ed and jb collected and measured the clinical ir spectra. bk and az supervised the project. all authors read and drafted the manuscript.

supplementary material
additional file 1
comparison of the brierscoremf performance excluding water absorbtion peaks. here, we compare the brierscoremf performance on the clinical dataset when training with and without the water absorption peaks located at  and . we find that omitting these regions does not significantly alter the prediction performance. this file can be opened with microsoft word  <dig>  open office writer  <dig> . <dig>  or similar word processor programs.

click here for file

 additional file 2
detailed bierscoremf performance. here, we provide the bierscoremf performance on the clinical dataset in terms of true positives, true negatives, false positives, false negatives, as well as sensitivity, specificity, and matthews correlation coefficient. this file can be opened with microsoft excel  <dig>  open office calc  <dig> . <dig>  or similar spreadsheet applications.

click here for file

 acknowledgements
we would like to thank dipl.-math. oliver lendle  for mathematical proofreading of this manuscript.
