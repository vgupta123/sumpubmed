BACKGROUND
gene expression profiles, produced by the microarray experiments, provide a way to investigate the expression levels of thousands of genes under various experimental conditions. it has been used in a broad range of areas in biology, such as regulatory pathway inferring, functional gene finding, etc.  <cit> . the downstream processing methods, such as clustering  <cit> , supervised learning algorithms  <cit> , etc., have been applied to the analysis of the available data.

consisting of hundreds or even thousands of gene-specific dna sequences, gene expression microarrays produce massive gene expression data sets in the form of large matrices, which, however, contain the missing values. these missing values can be caused by various factors, such as insufficient resolution, image corruption, or simply due to dust or scratches on the slide. moreover, systematically data missing might also present in the robotic method for the generation of gene expression profiles.

repetition of identical experiments  <cit>  has been adopted to validate downstream microarray analysis algorithms dealing with the missing value issue. however, this method is costly and time consuming. the naïve ways that have been commonly used include omitting the expression profile vector with missing values, and padding them with zeros, or row averages  <cit> . these methods are widely used by biologists, but the disadvantages of them are obvious: omitting the profile vector results in losing useful information; padding them with zeros and row averages do not provide proper missing value estimation. rather sophisticated approaches have been proposed by troyanskaya et al.  <cit> . the approaches are based on k-nearest neighbor algorithm  and singular value decomposition algorithm . the knn impute method aims at finding k genes mostly similar to genes containing missing values, where the similarity is estimated by euclidean distance measure, and the missing values are imputed with values of weighted average from these neighboring genes. the svd impute method obtains a set of mutually orthogonal expression patterns  from the gene expression matrix, and impute the missing values by regressing the gene against the k eigengenes and linearly combining the eigengenes. in most cases, the knn imputing performs better and more robust than does the svd, which is also good on time series data corrupted by low level noise. these initial attempts of imputing the missing-values by means of mathematical fashion have shown the promising progress in terms of superior performance of estimation accuracy on the test datasets.

recently, oba et al. has developed an optimization method based on bayesian principal component analysis   <cit> , which outperforms the knn and the svd impute methods. one of the features, which allow the method provides better performances, is the capability of auto-selection of the parameters used in estimation. the method also claims better estimation performance when the number of the samples is large. bayesian variable selection algorithm, developed by zhou et al.  <cit> , also aims at the auto-selection of the number of the nearest neighboring genes used in estimation. in this algorithm, both linear and nonlinear regressions are used for the estimation rule, and the procedures for the fast implementation have been developed for the essential steps of the algorithm. kim et al.  <cit>  has proposed a method based on local least squares , which exploited the local similarity structures in the data as well as the least squares optimization process. some of these methods, however, did not take most use of missing values in one row of certain expression profile , so that other missing values are just excluded, or padded with zeros or row average in the estimation.

in this paper, we propose a new approach based on the support vector regression  to estimate the missing values and use orthogonal input coding scheme to address the issue of multiple missing values in one row of certain expression profile. to evaluate the proposed method, six microarray datasets have been tested with various parameter settings. the superior performance, comparing with knn, bpca, and lls impute methods, indicates the promising estimation ability of the method.

in this paper, we use d ∈ rm*n to denote the whole gene expression data matrix, where m is the number of genes, and n is the number of different experimental conditions, i.e., entry di, j in the expression matrix denotes the expression level of the i-th gene in the j-th experimental condition.

RESULTS
data sets
in this paper, the performance of each method is evaluated by using six data sets. the first two data sets, initially made available by spellman et al  <cit> , focus on identification of the cell-cycle regulated genes in yeast saccharomyces cerevisiae, and are all time series data sets. one of the data set is from the study of α-factor block experiments, and it contains  <dig> sampling points of each gene. this data set is referred as data a hereafter. and another data set, referred to as data e, is an elutriation dataset with  <dig> sampling points. the third data set, data g, is from gasch's experiments  <cit>  focusing on the response to the environment changes of genes in yeast, and is a data set containing  <dig> expression ratios for each gene. after removing all the columns with more than 8% missing entries, we select all gene rows without the missing values. among the resulting  <dig> gene rows, we randomly select  <dig> columns to construct a non-time series subset of the whole data set by rearranging the columns at random. the fourth data set, data i, is original cdna microarray data relevant to human colorectal cancer   <cit> . this data set contains  <dig> primary crcs that include  <dig> non-metastatic primary crcs,  <dig> metastatic primary crcs to the liver, and  <dig> normal colonic epithelia that have been histopathologically confirmed to be free of cancer  <cit> . in this paper, the total number of the genes used from this subset is  <dig>  the fifth data set, data p, is a gene expression data set relevant to the molecular pharmacology of cancer, which contains gene expression profiles in  <dig> human cancer cell lines in a drug discovery screen  <cit> . this data set contains  <dig> genes with  <dig> sampling points for each gene. after removing all the columns with more than 30% missing entries, and selecting all gene rows without missing entries, we finally get the data set with  <dig> genes, which contain  <dig> sampling points for each gene. the last data set, data c, is also from reference  <cit> , the same data set used in kim's paper, focusing on the cell-cycle-regulated genes. this data set was classified into five classes by spellman, from the same  <dig> experiments as in data e. data c is used to test how much an imputing method is able to take advantage of strongly correlated genes in estimating the missing values.

the data sets we used in our study are processed with several steps. firstly, they are log-transformed after they are taken from the image. secondly, the rows and the columns which contain much missing values are excluded. thirdly, before using orthogonal input coding scheme and svr impute method, each of the columns are scaled to between  <dig> and  <dig>  which means the data sets are normalized. mean-normalizing the data will further help in regression performance using euclidian distance. finally, the data sets with all these pre-procession are used to construct the "complete matrix".

measurements for performance
we constructed the "complete matrices" by removing all the rows containing raw missing values, and randomly created the artificial missing values, from 1% to 20%, of the entries in a matrix. the performance is measured by the normalized root mean squared error , defined as

nrmse=meanvariance     
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgobgtcqwgsbgucqwgnbqtcqwgtbwucqwgfbqrcqgh9aqpdagcaaqaamaalaaabagaemyba0maemyzaumaemyyaemaemoba4maei4waslaeiikagiaemyeak3aasbaasqaaiabdeganjabdwha1jabdwgaljabdohazjabdohazbqabagccqghsislcqwg5bqedawgaawcbagaemyyaemaemoba4maem4camnaem4dacnaemyzaumaemocaihabeaakiabcmcapmaacaaaleqabagaegomaidaaogaeiyxa0fabaacbigae8ndaynae8xyaemae8ncainaemyaakmaemyyaemaemoba4maem4yammaemyzaumaei4waslaemyeak3aasbaasqaaiabdggahjabd6gaujabdohazjabdeha3jabdwgaljabdkhaybqabagccqggdbqxaaaaleqaaogaaczcaiaaxmaadaqadaqaaiabigdaxagaayjkaiaawmcaaaaa@6d1c@

where the mean and the variance are calculated from the complete matrix, and yguess are the estimated vectors for the missing values in the matrix while yanwer are the true value vectors for the artificial missing values. the nrmse varies according to the estimation performance. when predicted values are accurate, the nrmse reaches its minimum value  <dig>  and when the prediction is very poor or the noise involved is too large, the nrmse becomes much larger.

input coding scheme selection
performance comparison with other methods
the performance of the svr impute method, assessed over five different data sets, has been compared with three imputing approaches, i.e., knn, bpca and lls impute method. the k-value in the knn impute method was preset as  <dig>  according to proposed scope of between  <dig> and  <dig>  the parameter sets for the bpca impute method were taken directly from published resource. the lls impute method is a non-parameter method, and the referenced programs were used. performance of each method on different data sets is shown in figure  <dig>   <dig>   <dig>   <dig>   <dig>   <dig> 

data a and data e, which are the noisy time-series data sets, were pre-processed by removing all genes containing the missing values. they produce complete matrix with  <dig> genes. from figure  <dig> and  <dig> we can see that the svr impute method notably outperforms the other three methods on these two data sets. and we obtain similar results on data a. the svr also performs stably across the data missing percentages.

as claimed by troyanskaya  <cit> , data g is the most challenging prediction data set, where a clear expression pattern is often absent. the complete matrix contains  <dig> genes after pre-pressing. figure  <dig> shows that among all four methods, in most cases, the svr method gets minimal nrmse. when percentage of missing values in the data sets is below 20%, the svr achieves the best result. and when percentage of missing values reaches 20%, the nrmse of the svr is a little larger than those of the bpca and the lls impute methods, and still much smaller than that of the knn impute method. this shows the svr method is comparable with, if not better than, the previous methods on non time series data set.

data i is a data set relevant to human cancer, which involves much more complex regulation mechanisms. therefore, this type of gene expression profile data set is much difficult for the missing value estimation. figure  <dig> shows the performance of four methods on data i. on this data set, the svr method gets similar results as it does on data g. when the percentage of missing values is below 10%, the svr method gets good result. while the percentage of missing values exceeds 10%, the nrmse of svr is a little larger. on this data set, our method shows comparable estimating ability with the previous methods.

relevant to many kinds of human cancers, including colorectal, renal, ovarian, breast, prostate, lung and central nervous system origin, as well as leukaemias and melanomas, data p becomes the most difficult data set for missing value estimation. figure  <dig> shows the performance of each method on this data set. on this data set, the svr impute method gets similar result as other previous methods. all the methods get similar estimate performance with the nrmse between  <dig>  and  <dig> . on this data set, the svr impute method performs robustly as the percentage of the missing values increase.

data c is designed to test how much an imputing method is able to take advantage of strongly correlated genes in estimating the missing values according to the research work by kim et al.  <cit>  we can see from figure  <dig> that the svr method gets similar result as other previous methods. this indicates the svr method can take better use of strongly correlated genes than do other three methods in estimating the missing values.

performance of svr method on dataset with higher noise levels
for the real data set that always contains noise caused by various reasons, a good estimation method must be robust against certain levels of noise. to test the robustness of the svr method, we prepare five noisy datasets by adding random noise of various levels, with normal distribution, on data c, as has been proposed by kim  <cit> . to generate the six datasets, we first build six noise matrices with normal distribution of zero-mean  and various standard deviations , and then add them to data c with 5% entries missing. from figure  <dig> we can see that the performance of the svr method is not very sensitive to the noise level, especially when σ is less than  <dig> . therefore, the svr method is more robust against noise.

discussion
performance compared with previous methods
three pervious methods are used to compare the performance of the svr impute method in our research. one of the advantages of the svr method is that it makes most use of the information from the original data sets. the orthogonal input coding scheme raises the estimation performance notably, which contributes to the best performance of the svr method among these four methods. in the case of the knn and the lls method, the redundant missing values in the samples or genes with many missing values are just neglected, while the bpca method simply regards them equally with the non-missing values. another advantage comes from the svr method itself. the svr method is a method based on the structural risk minimization principle in statistical learning theory, which guarantees the global optimal solution of the dual quadratic programming problem. the knn method linearly combines the similar genes by weighting the average values of them. the coefficients used in combination are calculated by using euclidean distance, which is not an optimal measurement for gene similarity. this makes the knn method perform worst among all the methods. the bpca method uses the principal component regression, which makes the results highly depend on the numbers of the principal axes. if genes have dominant local similarity structures, the result of this method may not be the global optimal. the lls method is a method based on local similar structure. it shares the similar linear combination of k nearest genes as the knn impute, and surpasses the knn impute by optimizing the coefficients of the non-missing part of the similar genes using the least square solution. the lls method is based on local similarity structure of the data set, which draws back its performance when the local similarity is not very clear. in most cases, lls method performs worse than bpca impute method and svr impute method.

besides yeast gene expression profiles, our method also works well on the data sets those are much more difficult for regression, because of the complex regulation mechanisms involved . what's more, the length of the expression profiles in data i is  <dig>  which is much larger than the data sets relevant to yeast. this might make it more complex for regression. figure  <dig> and figure  <dig> show that the svr method achieves comparative results to the previous methods. when the percentage of missing values becomes too large, the svr impute method performs little worse than do the bpca and the lls impute method. this is partly due to the grid search strategy for the parameter sets. to maintain proper parameter sets, the user should specify the range of the parameters been searched, so the parameter sets might not be the optimum. the parameter selection is also a problem that has to be solved in the support vector regression. even if the parameter set might not be the optimum, the result is still comparative with other impute methods. thus the svr impute method performs well in present research.

input coding scheme selection
the main difference between the orthogonal input coding scheme and the other two is that the former utilizes the most information in the whole matrix, while the latter does not. all the values in two non-orthogonal input schemes are regarded equally in the input vector, which is not true. the flag bits in orthogonal coding, on the other hand, mark its strength by taking the missing value information into account, which is able to represent the difference between the missing and non-missing values.

let x <dig> =  denotes the gene expression profile, where x <dig> and x <dig> are missing. when imputing x <dig>  the orthogonal input coding schemes gets the input vector of vectororthogonal =  , and the zero-imputing input coding scheme gets the input vector of vectorzero = . when calculation the kernel function k = exp used in final regression function , we get:

korthogonal = exp)*exp)*exp     

in the orthogonal input coding scheme and

kzero = exp)*exp2))*exp     

in the zero-imputing input coding scheme, where xi = , xi' =  denote the center point of the svr in the orthogonal input coding scheme and the zero-imputing input coding scheme during calculation, respectively. the difference of the two input coding scheme in the kernel function is not only the difference of the center point, but also a coefficient of exp. so they perform differently in regression performance. it is also indicated that why the value of flag bit is set to be  <dig>  but not other values. the flag bit in the orthogonal input coding scheme is used as the coefficient of the parameter γ in the kernel function and the final regression function. since the parameter γ can be tuned by the user, the flag bit can be safely set to be  <dig> without any influence on the final regression result.

CONCLUSIONS
in this paper, we introduce the support vector regression  impute as a novel method for estimation of the missing values in gene expression profile. testing results reveal that the svr impute has outstanding prediction ability in the estimation of the missing values problem and robust against the noise. moreover, our approach makes most use of the missing value information in the whole gene expression matrix by using orthogonal input coding scheme. a comprehensive comparison of nrmse on five data sets shows that the svr impute performs comparative with, if not better than, the other missing value estimation methods in this area ever since, and it appears to be a proper solution to the missing value estimation in gene expression profile.

