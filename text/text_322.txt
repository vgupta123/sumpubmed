BACKGROUND
high throughput sequencing on samples pooled from different individuals is an efficient strategy to infer genetic variation in a population. in principle, single nucleotide polymorphisms  and indels can be effectively detected and their frequency can be estimated with a variance not much higher than for individual sequencing
 <cit> . however, interpretation of data from sequencing of pooled samples is quite different from that of individual samples and leads to additional issues. the most important difference is that in individual diploid samples, the frequency of alleles in each individual is known to be f =  <dig>  for all snps, while in pools the frequency is a generic multiple of 1/n, where n is the number of different homologous chromosomes in the sample. for large samples, the frequency could be any number between  <dig> and  <dig>  for this reason snp calling methods for individual sequencing can detect only segregating sites with intermediate frequency and cannot be immediately extended to pooled samples without losing rare alleles. rare alleles, though, are particularly important in population genetics because they represent most of the variability in natural populations. in fact, under the standard neutral model, singletons  and rare alleles  are the most frequent variants because p ∝ 1/f. moreover, the relative fraction of rare variants increases with read depth and sample size.

the detection of rare variants is also strongly affected by sequencing errors. while the impact of errors in individual sequencing can be reduced by setting a restriction on the minimum number of reads per allele, this would have a strong and undesired effect in pools because alleles at low frequency in the population often also appear at low frequency among the reads.

furthermore, the process used to generate the reads from pooled samples has a critical effect, that is allele frequencies among the reads can be different from actual frequencies among individuals in the sample. if we assume that reads are randomly extracted from the sampled individuals, read counts will follow a binomial distribution with mean equal to the allele frequency in the sample times the read depth. this means that an allele appearing only once in the reads from a pool does not necessarily correspond to a singleton in the set of individuals making up the pool, and vice versa, there can be more than one read – or none – from a true singleton. finally, since the frequency of each allele is unknown, snp calling would depend on the prior for the frequency spectrum p that is  specified. while maximum entropy  would favor a flat prior, the standard population genetics result for neutral sites and low mutation rate is p = θ/f  <cit>  where θ is the genetic variability. different choices could result in different calls in particular for low frequency snps. the need for a prior p points to bayesian methods to reconstruct the frequency spectrum. in this note we present a method for bayesian estimation of posterior frequency distribution for snps in pooled samples. this method addresses the issues described above, and it can be naturally used to call snps from the posterior probability that alleles are actually segregating for each site.

the model
our model presents two interesting, novel aspects when it comes to pooled snp calling: it takes into account sequencing errors, and allows the user to specify different priors. we explain below both these features, but first we introduce the basic formulae here. in what follows we will use c to indicate the read depth, f  for the true alternative allele frequency, and na for the number of symbols alternative to the reference allele in the pileup. moreover n is the number of different chromosomes in the pool and θ is the nucleotide diversity. note that n obviously needs not coincide with the number of individuals in the pool: for example when considering autosomes in diploid populations, the number of chromosomes is twice the number of individuals. there could be also experimental setups where n is not known a priori, however in these situations n is typically large and therefore its exact value is not relevant for the model in this section. in general, if n is not precisely known, a rough estimate of it should suffice for our purposes. the quantity we want to compute is p that is, the posterior distribution of allele frequency. from there, many quantities of interest  can be obtained. now, via bayes one has 

  p∝pp 

p can be written as follows: 

  p=∑k=0ncnapnaqc−nankfkn−k 

where, in the simplifying assumption that there are no sequencing errors,
p=kn and
q=1−kn . equation  accounts for the fact that the observed number of alleles na depends on the probability of including in the pool k alleles with frequency f  in the population and on the probability of those alleles getting sequenced once they are in the pool .

warding off sequencing errors
a conspicuous feature of high throughput sequencing is the presence of a non-negligible error rate, hence we must allow for a difference between the nucleotide we observe as a result of the measurement and what is really present on the genome. to this purpose we introduce the notation Ã which means that we observe “a” as an output of the sequencing machine, whereas a means that the symbol is actually present on the genome in the same position. here we have effectively only two symbols to account for, those which coincide with the reference genome  and those which belong to alternative alleles . to each letter generated by the sequencing machine there is associated a quality score , i.e. a character with ascii code  <dig> to  <dig>  this represents the probability that a particular base has been wrongly sequenced, and can be translated to numbers using the phred scale as
ε=10−c− <dig> where c is the ascii code. for each class of symbols we consider in our model  we compute the geometric mean of the respective error probabilities as they appear in the pileup, and we call it εr . hence we translate the sequencing errors into probabilities as follows: 

  p=1−εa,p=εap=1−εr,p=εr 

notice that once we set
p=p= <dig> the quantities
p  obey the following relations, dictated once again by bayes’ theorem: 

  p=p+p)p=p+p)p=p+p)p=p+p) 

from which we can infer
p=1−ρ and
p= α where
ρ=εr1−εa−εr and
α=εa1−εa−εr. now, this allows us to rewrite p so that it allows for sequencing errors : we call this new probability
p~. we have 

  p~=pp+pq 

we are aware of the fact that phred scores are useful only up to a point, and other kinds of errors can happen while sequencing which are not described by εa,εr. but many of these errors can be filtered out at an earlier stage. pcr duplicates are typically eliminated just after mapping; variants which are observed on one strand only  can be excluded from the pileup; the precision of the mapping can also be refined before using snape. we focus here on the problem of how to deal with the pooling because the error filtering is tackled by other packages which can easily be used together with snape.

different priors
having written p taking into account sequencing errors, we now focus on the choice of prior for the allele frequencies, p. first, we discuss the distribution of the frequencies of segregating alleles i.e. those which satisfy the condition  <dig> < f <  <dig>  if we assume complete ignorance about allele frequencies, a flat prior p =  <dig> is a possible choice. however, it is well known that frequency spectra from real populations exhibit an excess of rare alleles, due to the fact that new mutations are born at low frequency and only a few reach intermediate frequencies before going to fixation or extinction. to account for this effect, we use some results from population genetics. the site frequency spectrum under the standard neutral model  is equal to θ/f <cit> , where θ is the nucleotide variability in the population.

we will call this the informative prior with unfolded spectrum . an informative prior can also be written in the folded case i.e. when the identity of the ancestral allele is not known : in this case, it will have to be invariant with respect to the transformation f →  <dig> − f. see table
 <dig> for the possible  <dig> combinations considered in our algorithm. the prior distribution of extreme frequencies  is different since these frequencies correspond to fixed alleles in the population, i.e. to absorbing states of the dynamics of mutations and substitutions. the prior probability of f =  <dig> is naturally given by the genetic differentiation d between the outgroup sequence and the population studied, while the probability for f =  <dig> can be obtained by requiring the sum of all probabilities to be  <dig>  note that the continuum prior 1/f is improper since its integral diverges logarithmically; however we discretize the allele frequencies in the population as multiples of a minimum nonzero frequency 1/nd, so the discretized priors and posteriors that we use are well defined. p is computed for f  taking values in  <dig> . <dig> …, <dig> , <dig> 

we discretize the interval  <cit>  with nd =  <dig> breakpoints. the numbers  <dig>   <dig> and  <dig> appearing in the formulæ in the table are normalization factors . βis a normalization constant for the divergent function 1/f,
β=∑i=1nd1i=ln+γ where γ =  <dig> … is the euler-mascheroni constant.

methods
power and fdr
in order to test the performance of our method, we developed a pipeline. a  <dig> mb sequence obtained by randomly sampling nucleotides for each position was used both as the ancestral sequence of the population simulated by ms <cit>  and as the reference genome on the alignment step . the program ms was used to generate  snp data along a  <dig> mb long dna stretch for a single population with varying number of individuals  assuming nucleotide diversity  <dig>  and scaled recombination rate  <dig>  per site. for each resulting haplotype, the program art <cit>  was used to generate simulated next generation sequencing  reads with the built-in profile for illumina paired-end technology of  <dig> bp-long reads. to simulate the pooling process, reads were randomly selected from each sequence using either an equal proportion from each individual, or a skewed sampling scheme with some individuals over/under-sampled in the resulting pool. in the latter case, 50% of the individuals were sampled 50% more times whereas 50% of individuals were sampled 50% fewer times. an average depth of 20x was simulated for the whole pool in all cases, and reads were aligned with bwa
 <cit> . we used the ancestral sequence as reference for the alignment, allowing for a maximum of  <dig> mismatches in each read, and removing resulting reads with mapping quality below  <dig>  we also considered a more conservative mapping, up to  <dig> mismatches, but influence of this choice was small: we only observed a slight decrease in both power and false discovery rate . finally, snps were called with different methods restricting minimum and maximum depths to do the calling between 5x and 40x. we compared varscan <cit> , popoolation <cit> , samtools pileup <cit> , samtools mpileup <cit> , and snape with flat and informative priors. in varscan, behaviour depended largely on the significance level used : at low p-values power was very low, whereas at p-value  <dig>  fdr was very high. here we chose a p-value of  <dig>  as a compromise. in samtools pileup we retained snps with quality > <dig>  and samtools mpileup was run with default options. snape was run with flat and informative priors with options divergence  <dig> , prior nucleotide diversity  <dig>  and folded spectrum. we retained snps with posterior probability of segregation >  <dig>  . power was computed as the proportion of true snps in the population  located within regions of appropriate depth that were correctly recovered. false discovery rate  was obtained as the proportion of snp calls that were incorrect. a total of  <dig> replicates per case were simulated, and average power and fdr were plotted. besides, we also plotted power and fdr as functions of actual depth per site, and of minor allele frequency .

frequency spectrum
given that the snp calling process produces a bias against alleles found at low frequencies, we wished to study its effect on the site frequency spectrum . this is important because most real snps will be singletons or low frequency sites. we performed  <dig> coalescent simulations using the same settings as above with  <dig> chromosomes. for each simulation we subsampled, with replacement,  <dig> chromosomes in order to mimic the 20x read depth used in the simulations described above, and plotted the resulting folded sfs excluding non-polymorphic sites. to compare the performance of snape and samtools in recovering the sfs, we estimated the sfs obtained by snape and samtools for the same set of simulations. for each software, the sfs was calculated using the snps identified by each software that were covered by exactly  <dig> reads, and taking as estimate for the frequency of each snp the raw frequency of reads carrying the alternative allele. we restricted the estimate at depth 20x simply for estimates of sfs to be comparable. note that the interpretation of sfs is much more complicated if a mixture of depths is analyzed, e.g., for depth 4x the folded frequency can only be  <dig>  and  <dig> , whereas the range is smoother at higher depths. while the approach of using raw read frequency as the estimate of allele frequency is not optimal, it allows us to compare easily samtools and snape. note that, in contrast to snape, samtools does not output the posterior distribution of allele frequency f when using pooled samples.

RESULTS
power and fdr
average power and fdr are shown in figure
 <dig> 

popoolation exhibits the highest power overall, however this comes at the cost of a very high fdr, a behaviour which is not unexpected as this software was not conceived as a snp caller . other than popoolation, snape exhibited the largest power, whereas the samtools mpileup function turned out to perform much better than the deprecated pileup function. adding the prior information on the site frequency spectrum improved power by ≈ 15% in snape while not affecting fdr. this increase in power was observed across the range of parameters considered.

note that power decreases with n, the number of chromosomes in the pool. this occurs because the number of snps increases as well with n , and the increase is proportional to ewen’s constant
∑i=1n−11i. after taking into account this fact, the number of snps called is actually the same for a given depth, irrespective of the number of individuals in the pool.

two main factors affect the accuracy of snp calling in pools: depth and minimum allele frequency, although their effect varied according to the algorithm used .

popoolation’s fdr increased dramatically with depth because, as mentioned, it is not conceived as a snp caller and does not correct properly for sequencing errors. for the rest of the algorithms, fdr did not depend on depth. in contrast, power increased with depth, although it reached a plateau after 30x approximately except in popoolation and varscan.

for what regards the influence of allele frequencies, it is precisely at low frequency that snape performs better than other snp callers . note that power of different methods tend to converge at intermediate frequencies, simply because an intermediate allele frequency is equivalent to that in a diploid heterozygous individual, and snp callers usually assume diploid individuals. for instance, for n =  <dig> . <dig> and  <dig>  of snps for maf >  <dig>  are correctly called with snape and mpileup, respectively. for snps with maf <  <dig> , those numbers become  <dig>  and  <dig>  respectively.

two effects are worth mentioning : the reduction in power consequent to pooling, and what happens if samples are represented unevenly in the pool. for what regards the first, simple theoretical analyses show that the site frequency spectrum is highly distorted for moderate or low depths , even if snp calling were perfect. pérez-enciso and ferretti
 <cit>  also show that, even at very high depths, some chromosomes will not be sampled when the number of individuals in the pool is large, causing the loss of singletons and of low frequency alleles.

when it comes to the second concern, it has to be noted that it is difficult to develop methods that account for uneven sampling in pools without knowing the actual distribution of individual contributions. besides, there is no direct way to detect it from the data without extra assumptions about the demographic / evolutionary pattern of the data . nevertheless, the really important question is: how strong is the impact of uneven sampling on the method? snp calling should not be strongly affected because unequal sampling of chromosomes often results in a shift towards intermediate frequencies. consider, e.g., the extreme case of a pool containing only contributions from 2- <dig> chromosomes: while rare alleles remain rare, frequent snps will be detected even at higher power than in a balanced pool. on the other hand, the mean allele frequency is the same as for balanced pools, although the variance in the estimation of population allele frequencies will increase. this increase in variance cannot be captured by any available method. figure
 <dig>  shows the simulation results of an unbalanced pool . the figure confirms previous arguments whereby average power and fdr remain approximately constant, whereas variance increases slightly, as can be seen from the wider distribution of power values than that of balanced pooling.

frequency spectrum
the frequency spectra of snps called with informative snape and mpileup approaches are shown in figure
 <dig> 

the true spectrum is the black line. as expected from previous figures, which show a reduced power at low frequency alleles, singletons and low frequency alleles are clearly under represented with both methods. yet, snape obtains a less biased spectrum than other methods because a higher percentage of rare allele snps is called. the bias towards high maf sites decreased if we lowered the posterior probability threshold for a snp to be called , p =  <dig>  instead of p =  <dig> , but at the price of increasing fdr . all in all, missing low maf snps is inherent to all methods but the approach proposed here performs better than standard tools. also, snape computes the complete posterior probability of the allele frequency f , which is of interest to develop new statistics that consider the whole uncertainty on f , rather than point estimates.

implementation
we developed a software called snape-pooled that reads a file in pileup  format as input and a number of command line options specifying the total number of chromosomes being sequenced, θ , d , the prior type  and whether the reference allele can be taken as ancestral one or not . the output file contains p, together with other useful indicators .

CONCLUSIONS
using standard tools for calling snps in pools is not appropriate because many true variants will be confounded with sequencing errors and therefore will not be called. here, we present a bayesian method that overcomes this difficulty while retaining a low fdr. it also provides the posterior probability that a snp is segregating and the full binned posterior distribution of f  for every snp. this should allow us to develop more reliable tests based on site frequency spectrum compared to those that merely employ point estimates.

availability
the software  is available at
http://code.google.com/p/snape-pooled/.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
er, lf, mp developed the mathematical method. er wrote the software. bn wrote the simulation pipeline. ae and bn tested the software and ran the comparison against other packages. sh took part in discussions and testing. all authors read and approved the final manuscript.

