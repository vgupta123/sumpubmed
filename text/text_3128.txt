BACKGROUND
based on the concept of simultaneously studying the expression of a large number of genes, a dna microarray is a chip on which numerous probes are placed for hybridization with a tissue sample. the dna microarray has recently emerged as a powerful tool in molecular biology research, offering high throughput analysis of gene expression on a genomic scale. however, biological complexity encoded by a deluge of microarray data is being translated into all sorts of computational, statistical or mathematical problems.

driven by the growing genomic technology, molecular medicine has become a rapidly advancing field. an important research topic is to identify disease-related gene expression patterns based on microarray analysis. in one approach, genes are selected for constructing a clinically useful classifier for disease diagnosis. the genes thus selected often shed light on the fundamental molecular mechanisms of the disease  <cit> . as addressed in several research works  <cit> , the problem of gene selection considered in this context is a difficult one because there are thousands of genes at hand but only a very limited number of samples are available. mathematically, this problem is characterized by high data dimensionality. to develop a classifier, dimensionality reduction by gene selection is essential. genes selected for constructing a classifier are believed to be important. typically, only a small fraction of genes differentially expressed in the diseased tissue will be selected.

there exist two related but different objectives for gene selection. as mentioned above, one objective is to construct a classifier or predictor for classifying, diagnosing, or predicting the type of cancer tissue according to the expression pattern of selected genes in the tissue  <cit> . the other objective is to determine whether the changes in gene expression across two conditions are significant   <cit> . the present work is developed in the first context.

here, we report new theoretical developments and research results as an extension of our earlier work  <cit> , presenting a new probabilistic analysis of gene selection from microarray data, which distinguishes our work from other related work.

RESULTS
probability analysis of selected genes
under very high data dimensionality, questions can be raised of whether genes could have been selected by chance and whether selected genes are sufficiently significant beyond any doubt due to inherent uncertainty or data particularity. quite often, not identical sets of genes are selected from different subsets of the data. at the fundamental level, it would be important to distinguish between the case of diverse patterns and the case of false patterns. to address the problem, we take the approach that takes into account both statistical significance and performance issues. the bootstrapping technique lends itself well as far as the first issue is concerned.

suppose we randomly draw samples from a given domain and conduct a gene selection experiment. assume that we select one gene out of a total of p genes. the probability of the event that a particular gene is selected in a single trial is 1/p. according to the information theory, the smaller the probability is, the more informative the event is. given a large p, it seems that the event is significant, and this would be true only if we have a particular gene in mind before gene selection; otherwise, the probability should be adjusted for the presence of p genes, and then it becomes clear that any gene selected in a single trial is non-informative. now suppose we conduct multiple trials and ask the question of whether any gene repeatedly selected across trials is significant. here we devise an analysis for the question.

theorem
in r multiple independent trials conducted for gene selection, select one gene out of a total of p genes in each trial. given the level of significance α, a gene is considered significant if it is selected r times in r trials and



proof
the probability of the event that the same gene is selected r times in r trials is r. since there are p genes, the adjusted probability  is pr. therefore,



equivalently,



thus,



note that the value of  is negative. the result follows. €

corollary 1
the minimum threshold value of r for reaching the given level of significance is



where ⌈⌉ is the ceiling operator. this is because r must be an integer greater than or equal to the real threshold.

for example, consider the leukemia data  <cit> . there are  <dig> genes. assume α =  <dig> . from eq. , rθ =  <dig> 

consider a more general case: what is the probability of the event that a gene is selected r times in m trials? the adjusted probability becomes



where  is the combinatorial function that returns the number of possibilities for choosing r from m objects. assume a large p so that. then, we have



the level of significance  and ) is set to  <dig>  by convention in the present work.

reliability analysis of gene selection
the innovative feature of our method is to conduct reliability analysis for arriving at the gene expression signature. the analysis assesses the repeatability of genes selected and determines the repeatability for gene selection using m-fold cross-validation.

in the 10-fold cross-validation approach, the data set is divided into  <dig> disjoint subsets of about equal size. genes are selected on the basis of nine of these subsets, and then the remaining subset is used to estimate the predictive error of the trained classifier using only the selected genes. this process is repeated  <dig> times, each time leaving one set out for testing and the others for training. the cross-validation error rate is given by the average of the  <dig> estimates of the error rate thus obtained.

in each cross-validation cycle, we conduct svm-rfe gene ranking and selection operations, as described in the methods section. we select a minimal set of genes by collecting from the top rank one by one and picking the set associated with minimum error in each cross-validation cycle. there is no guarantee that the same subset of genes will be selected in each of the  <dig> cycles in 10-fold cross-validation. however, vital genes tend to be selected more consistently than others across cycles. the significance of a gene is correlated with the repeatability of selection according to the probabilistic analysis given earlier. we associate each selected gene with a repeatability value indicating how many times it is selected in the cross-validation experiment. the biological or clinical interpretation of "repeatability" would depend on the objective and design of the microarray experiment. we may consider the validity of a selected gene by its reliability in the sense that the more often a gene is selected, the less likely chance is a factor.

to select the final set of genes, we need to determine the repeatability threshold. a gene is in the final set if its repeatability reaches  the threshold. to this end, second 10-fold cross-validation is performed. then we choose the repeatability threshold that is associated with the minimal cross-validation error under the given level of significance . recall that a gene with a higher repeatability is associated with a small p value, as shown earlier.

to extend the method from two-class to multi-class classification, we adopt the one-against-all others strategy under which genes are selected for each class one at a time and then combined. for each class, all the other classes are grouped as a single class. in this way, a multi-class gene selection problem is converted into a series of two-class problems. the program was written in matlab  <cit> . an svm matlab toolbox as well as mathlab is required for the program use.

case analyses
in cancer research, our current goal is to develop a molecular classifier based on tissue gene expression patterns for diagnosis and subtype classification. with this in mind, we evaluate our method using well-known benchmark microarray data sets including those concerning small round blue cell tumors, colon cancer, leukemia as well as perturbed data sets.

the small round blue cell tumors  data set includes  <dig> training samples and  <dig> test samples derived from both tumor biopsy and cell lines  <cit> . in consistency with other reports in the literature, we used the test set of  <dig> samples after  <dig> non-srbct samples were removed. the data set consists of four types of tumor in childhood, including ewing's sarcoma , rhabdomyosarcoma , neuroblastoma , and burkitt lymphoma . after initial screening, the data set in the public domain contains  <dig> genes.

the colon cancer data set contains  <dig> tissue samples, each with  <dig> gene expression values  <cit> . the tissue samples include  <dig> normal and  <dig> colon cancer cases. in this study, we used all the  <dig> samples in the original data.

the leukemia data consist of  <dig> tissue samples, each with  <dig> genes expression values  <cit> . the samples include  <dig> all  and  <dig> aml . the original data have been divided into a training set of  <dig> samples and a test set of  <dig> samples.

the reference method with which we compared our method applied a technique referred to as svm-rfe  <cit>  to select genes from the training data without reliability assessment. the reference method  <cit>  is a multi-class extension of the svm-rfe method used for two-class classification. the svm-rfe method  has not been applied to the srbct data before. we implemented the computer algorithm of the reference method for comparison with ours. the same experimental conditions were applied to both methods.

small round blue cell tumor classification
on the srbct data, our method selected  <dig> genes  from the microarray gene expression data of the  <dig> training samples. the svm classifier trained on the  <dig> training samples using the  <dig> selected genes was tested on the  <dig> different test samples. both the training and test predictive accuracies were 100%. that is, the trained svm classifier can accurately predict the tumor class using the  <dig> gene expression data for both seen and unseen samples. since the classifier may tend to fit the training data, the generalization performance of the classifier is indicated by the test accuracy.

the reference method selected  <dig> genes with 100% training accuracy but with only 90% test accuracy. it seemed that the reference method did not select enough genes even though the selected genes could correctly classify all the training samples – an example of over-generalization, whereas our bootstrap-like strategy adequately dealt with this problem by taking into account of both reliability and diversity in gene selection.

we examined the consensus of genes selected by our method and by two other best-known methods: the method of khan et al.  <cit>  based on artificial neural networks and the method of tibshirani et al.  <cit>  based on shrunken centroids, and we found that there was high consensus between our and their results. out of the  <dig> genes selected by our method,  <dig> genes were also selected by khan's method and  <dig> genes by tibshirani's method . while agreement among results produced by different methods may imply similarities in the inductive biases, these two other methods use fundamentally different representational biases. thus, such agreement should not be taken for granted and would instead serve as substantial evidence indicative of the validity and significance of our method.

whether the selected genes served as meaningful markers for cancer classification was further confirmed by cluster analysis and visualization. to this end, we applied a hierarchical clustering program developed by eisen  <cit>  to the gene expression data of the selected genes. by visual inspection of the gene expression map, four clearly separated clusters  were identified. upon verification, each cluster corresponded exactly to a distinct tumor group with 100% accuracy. thus, a diagnostic chip can be designed based on the selected genes. this result also provides additional evidence to support our method.

colon cancer diagnosis
in performance analysis, we conducted multiple experiments with random data partitions. in each experiment, the data were randomly and equally split into training and test sets. the training set was used for gene selection and classifier training, and the test set for determining the predictive performance of the classifier based on the genes selected by the given algorithm. our method outperformed the reference method by a small margin. this result reflects the underlying fact that there are multiple possible ways of selecting genes for constructing a classifier with comparable performance using different methods.

our program selected  <dig> genes from the colon cancer data . the selected genes allow the separation of cancer from normal samples in the gene expression map . some genes were selected because their activities resulted in the difference in the tissue composition between normal and cancer tissue. other genes were selected because they played a role in cancer formation or cell proliferation. it was not surprise that some genes implicated in other types of cancer such as breast and prostate cancers were identified in the context of colon cancer because these tissue types shared similarity.

our method is supported by the meaningful biological interpretation of selected genes, as discussed below. new biological hypotheses can be formulated to further investigate the relationship of a particular gene with colon cancer. for example, what is the role of profilin  <dig> protein in colon cancer? some discovered genes could potentially serve as novel targets for drugs, vaccines, or gene therapy.

leukemia classification
on the leukemia data, our method selected four genes  from the microarray gene expression data of  <dig> training samples. the svm classifier trained on the  <dig> training samples using the selected genes was tested on the  <dig> different test samples. the training and test accuracies were 100% and  <dig> %, respectively. in addition, the aml and all samples formed separate clusters in the gene expression map of the selected genes.

the reference method also selected four genes and achieved the same level of test accuracy as our method. the original algorithm of svm-rfe  <cit>  selected  <dig> or  <dig> genes on this data set. the method based on shrunken centroids  <cit>  selected  <dig> genes on this data set. a recent study indicated that the unbiased error estimate of the classifier using a small number of selected genes was virtually non-zero on the leukemia data set  <cit> . taken together, the evidence showed that our method produced optimum results in terms of both predictive performance and the number of selected genes.

perturbed data
in practical circumstances, noise may arise during sample collection and handling, slide preparation, hybridization, or image analysis, as reflected by variations in microarray results generated from different laboratories. to address this issue, we also conducted performance evaluation of our gene selection method based on perturbed data.  <dig> data sets were produced by randomly perturbing 5%  of the training cases, reversing their class labels and leaving the test cases intact, in the domains of colon cancer diagnosis and leukemia classification . the average test predictive accuracies with our method in the two domains were  <dig> % and  <dig> %, respectively, compared with  <dig> % and  <dig> % with the reference method. the result suggests the potential advantage with our method in smoothing out data variations due to various sources in practice.

discussion
both cross-validation and bootstrapping are standard statistical methods for arriving at an unbiased estimate of the true error rate associated with a classifying or predicting system. bootstrapping has also been used for assessing the reliability or stability of phylogenetic trees  <cit>  or cluster analysis  <cit> . bootstrapping is a method for random re-sampling with replacement for a number of times and estimates the error rate by the average error rate over the number of iterations. cross-validation is a method of assessing the reliability of error; however, its application to learning the pattern in the data is novel. as discussed later, stability emerges as an important issue in gene selection. here we propose to use bootstrapping or cross-validation for analyzing the issue. our experience showed that cross-validation was more efficient than bootstrapping. for instance, genes selected based on a single 10-fold cross-validation were more accurate in prediction than those selected using bootstrapping with  <dig> re-sampling iterations. since the svm-based gene selection algorithm is time-consuming, we consider only cross-validation for assessment of error and stability in this study.

in the original svm-rfe algorithm  <cit> , error estimation and gene selection are not independent processes because both are based on the same training set. however, it is important to correct for the selection bias by performing a cross-validation or applying a bootstrap external to the selection process  <cit> . our implementation of svm-rfe is based on this idea.

genes selected for cancer diagnosis or classification can be validated by their biological significance since these genes are expected to show differential expression between normal and cancer tissue or among subtypes of cancer, and as such, they are implicated in cancer-related mechanisms or pathways. genes with unknown roles may be discovered through gene selection and later verified by biological studies.

from the srbct data set, genes selected by our method for a particular type of cancer/tumor against other types are generally consistent with its tissue of origin. for example, genes selected for neuroblastoma  are characteristic for nerve cells, such as neuronal n-cadherin, and meningioma 1; genes selected for rhabdomyosarcoma  are characteristic for muscle cells, such as alpha sarcoglycan, and slow skeletal troponin t1; genes selected for burkitt lymphoma  are characteristic for lymphocytes or blood cells, such as major histocompatibility complex . some genes discovered by means of microarray analysis have been reported in the biological literature, e.g., over-expression of mic <dig> in ewing's sarcoma   <cit> . some genes are over-expressed in a certain type of tumor but lack specificity. for instance, fgfr <dig>  was noted to be highly expressed only in rms and not in normal muscle, but it is also expressed in some other cancers and normal tissues  <cit> . a gene that is under-expressed in a particular type of tumor compared with other types can also be selected as a diagnostic marker. for instance, cold shock domain protein a selected for nb was under-expressed in this tumor, consistent with the fact that this gene is expressed in b cells and skeletal muscle but not in the brain  <cit> .

with our method, four muscle-related genes  were selected from the colon cancer data, reflecting the fact that normal colon tissue had higher muscle content, whereas colon cancer tissue had lower muscle content   <cit> . the selection of 60s ribosomal protein l30e agreed with an observation that ribosomal protein genes had lower expression in normal than in cancer colon tissue  <cit> . the selected interferon inducible protein 1-8d genes were found to be expressed in adenocarcinoma cell lines  <cit> . there was a potential connection of another selected gene, human chitotriosidase, to cancer  <cit> . the implications of cancer among other selected genes are explained as follows. s- <dig> protein can stimulate cellular proliferation and may function as a tumor growth factor  <cit> . profilin  <dig> protein can suppress tumorigenicity in breast cancer cells. a study showed consistently lower profilin  <dig> levels in tumor cells  <cit> . the reduced expression of p <dig> protein was linked to the possibility of colon carcinoma  <cit> . the a <dig> protein can inhibit a specific apoptotic pathway  <cit> . recall that apoptosis is a major mechanism for tumor suppression. the guanine nucleotide-binding protein is involved in signal transduction and its abnormality may contribute to cancer development  <cit> . a thyroid receptor interactor could be a target gene of a certain oncogene. the alpha trans-inducing protein  may be linked to oncogenic activity.

in the related work  <cit> ,  <dig> genes were selected from the colon cancer data: h <dig>  m <dig>  t <dig>  h <dig>  r <dig>  t <dig>  and h <dig>  for all of them, a possible link to cancer was found in the biological literature. these  <dig> genes, however, do not include any muscle-specific gene, despite that muscle content offered a discriminating index for colon cancer  <cit> .

in a typical microarray data analysis problem, the data dimensionality is high and the sample size is relatively small. under this condition, the problem of finding a classification model is under-constrained, and the model found tends to fit the training data so closely that it fails to generalize to unseen data. to address the issue of data overfitting, the svm has the capability of controlling the model complexity to the point where a satisfactory solution can be produced. on the other hand, the ability of causal discovery based on the svm-rfe approach or an alternative approach is discounted by the finding that most genes selected are selected only once from one data split to another in m-fold cross-validation  <cit> . this means that the svm is not free of the data-overfitting problem at least in the context of gene selection from microarray data, and it raises the question about stability or reliability of gene selection, as we address here.

the research finding that the svm may assign zero weights to strongly relevant variables and non-weights to weakly relevant  features  <cit>  implies the disadvantage with this approach for discovery of causal variables associated with the target variable concerned. this however can be understood since the svm-rfe is aimed to identify the best features for maximum margin of separation between different classes of samples, regardless of causal implications. in reality, causal variables are not necessarily most discriminant, as the target variable is not always categorized according to its causal factors. the issue of causality becomes even more complicated because of confounding variables leading to so-called spurious causation. the method presented here is developed in the context of cancer subtype classification and evaluated in terms of predictive performance rather than the capability of causal inference. however, some methods are both predictive and causal  <cit> .

we emphasize the importance of holding back some data to improve generalization and diversity of the learning outcome. in application of m-fold cross-validation to n samples, m can assume a value ranging from  <dig> to n. a small m is not sufficient to assess the repeatability of selected genes while a large m  is associated with high degree of redundancy on data for training and low diversity of genes selected. this argument suggests that there exists an optimum m value. so we conducted experiments to compare predictive accuracies for three cases: m =  <dig>   <dig>  and  <dig>  among the three cases, 10-fold cross-validation achieved the best results. it is thus consistent with our intuitive analysis. however, there is no proof that 10-fold cross-validation is always the best choice. in practice, the optimum m value should be determined by the value associated with the best cross-validation accuracy.

this study highlights the importance of reliability assessment of genes selected from a large-scale microarray data. we show how to derive the p value of each selected gene in multiple gene selection trials based on different data partitions. the importance of a gene is indicated by its associated p value. the distinctive feature of our method is that gene selection is determined by both ranking and reliability analyses. reliability analysis is conducted using m-fold cross-validation. some gene selection methods  <cit>  use cross-validation to determine the number of selected genes by minimum cross-validation error but not by optimum repeatability as in our method. thus, reliability analysis comprising repeatability measurement and optimum repeatability determination defines the novelty of our method, which has enabled a more accurate and cost-effective cancer classifier to be constructed, compared with other methods. notice, however, the argument about reliability or stability must rest on the assumption of sound performance, as will be clear from the apparent stability with some trivial approaches to gene selection such as the one based on lexicographic ordering of gene names. in fact, the theory behind the analytical scheme we developed is a general one and can therefore be extended to other performance-based gene selection methods.

CONCLUSIONS
the dna microarray technology has become a standard tool for gathering genome-wide gene expression information. molecular classification based on gene expression information has emerged as an important approach to cancer diagnosis. a cost-effective approach is to select a small set of genes for classifier design. moreover, it may be ineffective to use whole microarray data for classification purposes because the data dimensionality  is often several orders of magnitude greater than the available sample size.

experience shows that different sets of genes can be selected from different combinations of microarray data instances with the same gene selection algorithm. at the same time, it is noticed that a biologically significant gene tends to be selected repeatedly across different combinations of data instances. we have developed a method for analyzing this situation. in the domain of small round blue cell tumor subtype classification, we have demonstrated that the method we developed selected only  <dig> genes that provided 100% accuracy on both training and test data sets. in comparison, the approach based on artificial neural networks  <cit>  selected  <dig> genes, and the shrunken centroid method  <cit>  selected  <dig> genes. thus, our method suggests a mechanism for effectively reducing the tendency of fitting local data particularities in the process of gene selection for classifier design based on microarray data.

