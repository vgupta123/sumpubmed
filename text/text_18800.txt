BACKGROUND
noncoding rnas , which are transcribed but not translated into proteins, play diverse and important biological functions in all living organisms  <cit> . many types of ncrnas perform their functions through both their sequences and secondary structures, which are defined by the interacting base pairs. of the characterized secondary structures of ncrnas, watson-crick  and wobble base p airs  are most commonly seen. as knowing the secondary structure provides important information to undefirstafinding the tertiary structures and thus the functions of ncrnas, deriving the secondary structures of ncrnas remains an important research topic in rna informatics.

pseudoknot is an important structural motif in secondary structures of many types of ncrnas. formally, a pseudoknot occurs when an rna has two base pairs, i - j and i' - j', such that i <i' <j <j'. psuedoknots are known to play important functions in telomerase rna, tmrna, rrna, some riboswitch, some protein-biding rna, viral ribosomal frameshifting signals, etc  <cit> . there are  <dig>  sequences in  <dig> ncrna seed families of rfam  <dig>   <cit>  containing pseudoknots. with advances in sequencing technologies and structure prediction, more pseudoknot structures are expected to be disclosed.

many computational methods have been used to determine the native structure of ncrnas. a native structure is a structure that forms conformationally folding in native state before forming the tertiary structure. the gap between the free energy of the native state and other non-native structures is often small  <cit> . thus, misfolded conformations can form with high probabilities  <cit> . for a review of available tools, please see  <cit> .

although there is promising progress, finding the native secondary structure is still difficult. in particular, identifying the pseudoknot, an important structural motif in many types of ncrnas, poses a great challenge for existing methods. predicting the minimum free energy secondary structure that includes pseudoknots has been proven to be np-hard  <cit> . one recent attempt is to first predict the abstract shapes , which retain adjacency and nesting of structural features but disregard the length details of helix and loop regions  <cit> . the predicted shape will then be used to guide structure prediction. the idea of abstract shapes has long been used to characterize different types of structures. for example, most trnas have the clover-leaf structure; most pre-mirnas have the stem-loop structure; many types of pseudoknots have an h-type structure.

while the size of the folding space of an rna sequence increases exponentially with the sequence length  <cit> , many possible folding only differ in the details of the loop and helix regions and hence have the same abstract shape. previous analysis shows that the space of the abstract shapes is significantly smaller than the complete folding space  <cit> . knowing the abstract shape can significantly reduce the search space for structure prediction tools and improves the accuracy of structure prediction  <cit> . the utilities of abstract shapes have been demonstrated in a number of recent publications. the giegerich group used abstract shapes in comparative structure prediction in pseudoknot-free sequences  <cit> . people use shapes to aid mirna pre-cursor prediction in large-scale studies  <cit> . furthermore, shapes are used to index fast-expafinding ncrna families in rfam  <cit>  and lead to efficient known ncrna search  <cit> .

previous work focused on shape derivation and usage for pseudoknot-free ncrnas. there is a lack of studies of the usage of shapes in pseudoknot structure prediction. in this work, we predict the consensus shape of a group of homologous ncrnas that may contain pseudoknots. in addition, we develop a program that uses the consensus shape for consensus pseudoknot structure prediction. a majority of existing pseudoknot structure prediction tools often have topology restrictions such as h-type, recursive h-type  <cit> , kissing hairpin, or complexity levels of pseudoknot using genus numbers  <cit> . therefore, using the predicted abstract shapes of input sequences can help remove the topology restriction and leads to more general and practical pseudoknot structure prediction tools. compared with existing tools, our tool has the following properties:

• while most existing shape prediction tools use a single sequence as input, we conduct comparative shape prediction on homologous ncrnas that might contain pseudoknots. experiments show that comparative structure or shape prediction, which derives the consensus structure or shape from a group of homologous sequences, can achieve better accuracy than using a single sequence  <cit> .

• we can predict the abstract shapes of both pseudoknot-free and pseudoknot-containing sequences.

• current tools use the shape probability  <cit>  or the sum of energies of structures to rank shapes. we use multiple features by combining well-studied feature ranking methods and the support vector machine  method.

• we demonstrate the usage of the shape by applying it to pseudoknot structure prediction. the whole software package can be directly used to derive the consensus secondary structure of homologous ncrnas. the consensus shape prediction tool named knotshape and the corresponding consensus pseudoknot prediction tool named knotstructure are publicly available at our website.

we tested our software on hundreds of rna sequence sets. the experimental results show that we can achieve 18% higher accuracy than the state-of-the-art consensus shape prediction tools on pseudoknot free sequences. for pseudoknot-containing sequences, we achieve approximate 29% higher sensitivity and 10% higher positive predictive value in structure prediction than similar tools.

related work
computational structure prediction can be divided into de novo structure prediction and comparative structure prediction, which derive structures from a single sequence and multiple homologous ncrnas respectively. as our method is to derive the consensus shape and structure of homologous ncrnas, we briefly introduce related work in comparative ncrna structure derivation. there are three general approaches for structure derivation from multiple sequences: simultaneously align and fold, align-then-fold, and fold-then-align. it is computationally expensive to simultaneously align and fold pseudoknot structures. the performance of the align-then-fold pseudoknot prediction heavily depends on the quality of the alignment. usually multiple sequence alignment  tools such as clustalw  <cit>  are used to generate the alignment as the input to the folding tool. however, common structures can be missed due to misalignment between sequences lacking significant similarity  <cit> . in this work, we design a pseudoknot prediction tool using the fold-then-align strategy that does not require an alignment as input. tools based on fold-then-align use a de novo folding tool to construct a small but representative sample of the folding space, which consists of the predicted optimal and sub-optimal structures. structures from the folding space are chosen to maximize the structural and sequence similarity.

a number of software packages exist to predict the abstract shape for a single sequence. the sum of energies or the accumulated boltzmann probabilities of all structures within a shape have been used as main features for shape prediction. the latter is often referred to as the shape probability. usually the shapes with small sum of energies or high shape probabilities are more likely to be the correct shapes. it is claimed in rapidshapes  <cit>  that using shape probabilities has superior performance over free energy-based approach because of its independence on sequence length and base composition. however, exact computation of the shape probability incurs exponential computational cost to the sequence length  <cit> . thus, various heuristics or restrictions  <cit>  have been adopted for fast shape probability computation.

rnacast  <cit>  derives the consensus shape from homologous pseudoknot-free sequences based on the fold-then-align strategy. structures are grouped based on their shapes and shapes are ranked by sum of free energies of structures within the shape in ascending order. the first-ranked shape is presented as the consensus shape. the consensus structure is derived from the lowest free energy structures of each sequence within the shape.

methods
rna structures and their representations
rna structures and pseudoknots
rna molecules fold into complex three dimensional structures by nitrogenous bases that are connected via hydrogen bonds. the secondary structure of an ncrna is defined by the interacting base pairs. some rna molecules fold into pseudoknot structures by paring bases in loop regions with bases outside the stem loop .

in this work, two types of ncrna secondary structure representations are used. the first type is the arc-based representation, where nucleotides and hydrogen bonds are represented by vertices and arcs, respectively . for pseudoknot-free secondary structures, all arcs are either nested or in parallel. crossover arcs indicate pseudoknots. the second type is based on dot-bracket notation, where '.' represents unpaired bases and matching parenthesis '' indicate base-pairing nucleotides. following the annotation of rfam  <cit> , we use an extended dot-bracket notation to represent pseudoknot structures. the base-pairing nucleotides forming pseudoknots are represented by upper-lower case character pairs, such as a..a or b..b, as shown in figure 1c.

abstract shapes
abstract shapes were formally introduced by giegerich et al.  <cit> . the folding space of a given rna sequence is partitioned into different classes of structures, by means of abstracting from structural details. these classes are called abstract shapes, or shapes for short.

an rna secondary structure can be mapped to an abstract shape with different levels of abstraction  <cit> . in the abstract shape, details about the lengths of the loop and stacking regions are removed . stacking regions are represented by pairs of brackets and unpaired regions are represented by underscores.

pseudoknots are represented by pairs of upper-lower case characters. figure  <dig> presents examples of the abstract shapes of level  <dig>   <dig>  and  <dig> of a pseudoknot-free structure and a pseudoknot. level  <dig> represents the strongest abstraction and ignores all bulges, internal loops, and single-stranded regions. level  <dig> adds the helix interruptions caused by bulges or internal loops. level  <dig> only abstracts from loop and stack lengths while retains all single-stranded regions.

shape prediction
in this section we describe knotshape, a comparative shape prediction tool for homologous ncrna sequences that allows pseudoknots. the task of shape prediction is to select the best representative shape for given homologous sequences. in order to identify the best shape, various features such as shape probability  <cit> , sum of energies of all structures in this shape  <cit> , and the rank sum score  <cit>  are evaluated to rank shapes. it has not been systematically assessed whether combinations of multiple features can lead to better shape prediction. in this work, we incorporate support vector machine   <cit>  and feature selection techniques to determine important features for shape identification. in addition, we adopted a machine learning-based scoring function to evaluate the qualities of shapes.

the method contains two important components. the first one is the consensus shape prediction  and the second one is structure prediction using predicted shape as input . we will first describe knotshape, focusing on the feature construction and selection strategy. then we will describe how to derive the consensus structure given the consensus shape.

notation
• the n homologous ncrnas constitute the input sequence space. xi represents the ith sequence.

• each sequence can be folded into different secondary structures. let si represent the set of folded structures of the ith sequence xi. the set of structures predicted from all n input sequences is the union of si: s = s <dig> ∪ s <dig> ∪ . . . ∪ sn.

• sji is the jth structure in the folding space of xi. its free energy is denoted by Δg. for a sequence xi, the minimum free energy mfe is the lowest free energy among the energies of all predicted structures of xi, i.e. mfe=min1≤j≤|si|Δg.

• all structures in s can be classified into a set of abstract shapes. for a shape p, we record its associated sequences and structures. p.lx denotes the set of associated sequences, each of which can fold into a structure with shape p. p.ls denotes all structures with shape p.

• p ^ is the predicted shape of the given homologous sequences x <dig>  x <dig>  .., xn.

in order to explore the large folding space of multiple homologous sequences, we use a de novo folding tool to output the optimal and sub-optimal structures within a given energy cutoff. this heuristic does not allow us to explore the complete folding space. given the observation that the correct structure is usually close to the optimal structure, this heuristic works well in practice  <cit> .

feature construction and selection
intuitively, the correct shape tends to possess the following properties. the correct shape should have high shape probability, meaning that a large number of structures can be classified into this shape. when we have multiple homologous sequences as input, the correct shape should be well-represented by all or a majority of the input sequences. also, the ranking of the structure with the correct shape in the folding space of each sequence should be high. in addition, some structures with the correct shape have low thermodynamic energies. for the energy-related properties, various measurements can be introduced. for example, instead of using the sum of the energies of all structures within a shape, one can use the smallest energy. furthermore, more complicated properties such as the sequence similarity for all sequences associated with a shape p and the structural similarity of structures associated with a shape p might contribute to the shape prediction too. these similarities can be quantified using different methods such as k-mers profiles, multiple sequence alignment scores, variation of base pairs and so on.

it is not trivial to decide whether a single property is enough to choose the correct shape. if not, which combination of these properties can lead to the best shape prediction performance? in order to systematically choose a set of features  for shape prediction, we use f-score  <cit>  to measure the discrimination between a feature and its label. given the feature vector xk, k =  <dig>  .., m, the f-score of the ith feature is defined as:

 f≡-x¯i)2+-x¯i)21n+- <dig> ∑i=1n+-x¯i)2+1n-- <dig> ∑i=1n--x¯i) <dig> 

where n+ and n- are the numbers of positive and negative instances respectively. x¯i, x¯i, and x¯i are the average values of the ith feature of the whole, positive labeled, and negative labeled data. xk,i+ and xk,i- are the values of ith feature of the kth positive and negative instances respectively.

f-score reflects the discrimination of the features. the higher the f-score, the more discriminative the feature is. f-score is known to have a disadvantage in that it does not carry out the mutual information between features as it considers each feature separately. however, f-score is simple and quite effective in practice.

feature selection searches for the optimal subset of features  <cit> . there exist different methods for feature selection. in this work, we adopt sequential forward search   <cit>  because of its simplicity and effectiveness. starting with an empty set, we iteratively select one feature at a time and add it to the current feature set. features are selected in a descending order of the discriminative power determined by the f-score. the feature added is the one that gives the highest accuracy.

based on the properties that might be relevant to consensus shape prediction, we construct  <dig> features  and compute the f-score for each of them. the accuracy is evaluated using a linear svm method. the standard grid search approach is used to find an optimal svm parameter. the performance of a feature set is evaluated using 5-fold cross validation. prediction accuracy is the average value of all cross validation sets. the feature set that achieves the highest accuracy includes the following four features.

• f1: the contribution of sequences. we capture the contribution of sequences using the number of sequences mapped to the shape. this feature reveals how the shape is shared among the homologous sequences. f <dig> = |p.lx|.

• f2: the contribution of structures. this feature represents the abundance of structures mapped to the shape. f <dig> = |p.ls|.

• f3: the average free energy. energy model is commonly used to determine the stability of predicted structures. the basic idea behind this feature is that a stable shape is expected to be derived from a group of stable structures. f3=∑s∈p.lsΔg|p.ls|.

• f4: the average of minimal free energy. this feature is different from f <dig> in that it considers only the minimal free energy among all predicted structures of each sequence. f4=∑x∈p.lxmfe|p.lx|.

shape ranking using a simple scoring function
once the features are determined, they are used together with a trained linear svm for shape labeling. multiple shapes might be labeled as "true". in order to rank these candidate shapes for the final shape selection, we evaluate each candidate shape using a score named sc, which is proportional to the signed distance between the candidate shape to the classification hyperplane  <cit> . specifically, sc = w · x + b, where · denotes the dot product, w is the weight vector, and x is the instance vector. w is trained on the optimization function in the linear svm. the larger |wj| is, the more important the jth feature is. this is restricted to w in a linear svm model.

time complexity of shape prediction
for n input sequences, there are s predicted structures. these structure can be grouped into p' shapes. as we use the de novo folding tools to output near-optimal structures within a given energy range , we found that n: s: p' ≈ 1: 10: 1: <dig>  mapping structures to shapes takes o, where l is the sequence length. as sorting shapes according to their features takes p'log and p' ≤ 2n and s ≤ 11n, the procedure of shape prediction has time complexity o.

consensus structure prediction given a shape
once we determine the shape, we will predict the structure in the shape class for the given homologous ncrnas. structures corresponding to the same shape can differ significantly in the details of the loop and stacking regions. a strategy is needed to choose the correct structure inside the shape class for each input sequence. the simplest strategy is to output the mfe structure for the chosen shape, which has been used in previous work  <cit> . however, the mfe structure in a shape may not be the native structure. in particular, the accuracy of the mfe prediction for ncrnas containing pseudoknots is low.

in this section we describe knotstructure, a comparative structure prediction method for homologous sequences given the shape. the rationale behind comparative structure prediction is that the secondary structures and sequences are conserved during evolution. thus, finding the structures to maximize both the sequence and the secondary structure similarity among homologous ncrnas provides the basis for comparative structure prediction. various methods for evaluating structural and sequence similarity exist. the major challenge is to efficiently select |p ^.lx| representative structures to achieve the highest structural and sequence similarity.

as we already derived the consensus shape p ^ using knotshape, only structures with shape p ^ will be allowed. in addition, for each sequence xi∈p ^.lx, only one structure with shape p ^ can be selected. the total number of combinations of structures for measuring the similarity is thus ∏i=1to|p ^.lx||p ^.ls∩si|, where p ^.ls∩si contains structures with shape p ^ for a sequence xi. although efficient heuristics exist to measure the similarity among multiple structures and sequences, the sheer amount of combinations poses a great computational challenge.

procedure  <dig> representative structures selection

input: p ^, p ^.lx, p ^.ls

output: the representative structures

   <dig>  initialization

  for every two structures six and sjydo

    //only evaluate similarity of structures from different sequences

    if x ≠ y then

      evaluate the similarity of six and sjy

    else

      six and sjy has similarity -∞

    end if

  end for

   <dig>  select the set of representative structures using hierarchical clustering

  //each structure is a cluster by itself

  repeat

    combine a pair of clusters with the highest similarity

    for any structure six added to the cluster, remove all other structures sjx for j ≠ i

    re-evaluate the similarity between clusters

  until the cluster has size |p ^.lx|

in order to efficiently select representative structures, we use a similar method to unweighted pair group method with arithmetic mean , an agglomerative hierarchical clustering technique  <cit> . each object  starts in its own cluster. the closest pair of clusters is selected and merged into a single cluster as one moves up the hierarchy. the distance between clusters is measured using arithmetic mean defined in upgma. compared to the standard clustering procedure, we have constraints on the objects that can be selected into the same cluster. given the shape, only structures that have shape p ^ and come from different ncrnas can be combined in the same cluster. the detailed clustering process is described in procedure  <dig> 

during clustering, the structural and sequence similarity is evaluated using grammar string-based approach  <cit> . grammar strings encode both secondary structure and sequence information for an ncrna sequence. grammar string alignment score can accurately quantify the structural and sequence similarity of two ncrnas. in addition, grammar string can encode pseudoknot structures  <cit> . for a sequence xi and one structure sji in the folding space of xi, xi and sji are encoded in a grammar string gsji. we measure the similarity between any two grammar strings using the normalized grammar string-based alignment score over the alignment length. the similarity between groups of grammar strings is measured by arithmetic mean in upgma.

the progressive msa is performed on the set of representative structures using the clustering path as a guide tree. we then derive the consensus secondary structure from the alignment. the consensus structure can be mapped to each aligned sequence to accomplish the predicted structure of an individual sequence.

running time of structure prediction
converting a sequence and an associated secondary structure into a gs  takes o, where l is the length of the sequence. let the number of structures in p ^.ls be m. it takes o to encode all structures with shape p ^. in the first step of hierarchical clustering, we measure the similarity between gss of different ncrnas by conducting all-against-all comparison. conducting pairwise gs alignment takes o, where l is the length of the gs sequence and l ≤ l. by using the default energy cutoff  for sub-optimal structure generation, we observed that m ≤ 11n. thus, the all-against-all similarity measure has time complexity o. the guide tree generated using the clustering procedure contains at most n representative structures. thus, the total running time for clustering is o, which is the leading time complexity term for the consensus structure prediction algorithm.

experimental 
RESULTS
data sets
the training data set is the k <dig> from bralibase  <cit> . it contains  <dig> sequence sets, each of which has  <dig> homologous ncrnas. there are two test data sets. the first one is the k <dig> from bralibase. k <dig> contains  <dig> sequence sets, each of which has  <dig> homologous ncrnas. as existing shape prediction tools are not designed for handling pseudoknots, we use the pseudoknot-free sequence sets in k <dig> to compare the performance of shape prediction. after removing the sets containing pseudoknots, we have  <dig> sequence sets left. to test the performance of pseudoknot prediction, we constructed the second test set r <dig> from psuedoknot families of rfam  <cit> . in rfam  <dig> , there are  <dig> families containing pseudoknots.  <dig> of them have published structures. of the  <dig> families, only families with at least  <dig> seed sequences are used for testing our tools. for each chosen family, sets of  <dig> sequences are chosen randomly to construct the test sets. finally r <dig> contains  <dig> test sets. the average pairwise sequence identities range from 60-93%. for all sequence sets, the reference shapes were derived from rfam  <cit> .

svm training
for both the training and testing data sets, we need to apply de novo folding tools to the sequences. we choose a folding tool using the following criteria. first, this tool is able to output both the optimal and sub-optimal structures. second, this tool has high accuracy and can be efficiently applied to a large number of ncrnas. finally, if the target sequences contain pseudoknots, this tool should be able to output pseudoknot structures. as a result, we chose tt2ne  <cit> . different from many other pseudoknot prediction tools that have constraints on the type of the pseudoknot, tt2ne is more exible about the types of the target sequences. however, when it was applied to k <dig>  tt2ne failed to output structures for some sequences due to the length limit  and also existence of iupac characters in some sequences. thus, for the training data set k <dig>  we applied quikfold  <cit>  because k <dig> rarely contains pseudoknots. although it is ideal to use the same folding tool to the training and testing data set to achieve optimal classification performance, the complexity of the training and test data sets together with the performance of de novo folding tools lead to the current combination. in the discussion section we will briefly discuss how de novo folding tools affect the performance.

we employed the svm model implemented by libsvm tool  <cit>  for classification. for each sequence in k <dig>  we applied quikfold with the energy range 5% to obtain both optimal and sub-optimal structures of each sequence. the predicted structures were grouped based on their corresponding shapes. associated features were extracted and enclosed with each shape. we normalized feature values to fit the different properties of test sets to the same scale.

to label shapes, we used the shapes extracted from the consensus structures in rfam  <cit>  as the reference. shapes are labeled according to their correctness. we label a shape as  <dig> if it is as same as the reference shape. otherwise, it is labeled as - <dig> 

shape prediction comparison
we compared knotshape with rnacast  <cit> , which is part of rnashapes package  <cit> . rnacast takes the sequences as the input and predicts the consensus shape shared by all sequences. as it is not designed for pseudoknot structures, we only applied rnacast to  <dig> test sets of k <dig>  which are pseudoknot-free. tt2ne is applied to the test set using the default parameters. for each sequence, the optimal structure and  <dig> sub-optimal structures are kept as the sample of the folding space for each sequence. we compared our predicted shapes and the first-ranked shapes output by rnacast with the reference shapes derived from rfam  <cit> . the comparison is presented in table  <dig>  note that rnacast cannot output the shapes containing pseudoknots and thus is left blank for r <dig> in table  <dig>  the accuracy of knotshape is 18% higher than rnashapes.

structure prediction comparison
we applied the predicted shapes to pseudoknot structure prediction and compared the structure prediction performance with ipknot  <cit> , hxmatch  <cit> , and turboknot  <cit> , which are chosen because of their popularity, availability, and easy usage on large number of sequences. sequence alignments were generated using clustalw and entered as the input to ipknot and hxmatch. for ipknot, we chose the appropriate levels of prediction according to the test sets. we ran hxmatch with the default parameters. we used the parameters suggested in  <cit>  to run turboknot. sensitivity and the positive predicted value  are used to evaluate the performance:

 sensitivity=tptp+fn,ppv=tptp+fp 

tp is the number of correctly predicted base pairs. fn is the number of base pairs that are in the reference structure but not in the predicted structure. fp is the number of base pairs that are in the predicted structure but not in the reference structure. figure  <dig> is the boxplot of the sensitivity and ppv over all  <dig> test sets. knotstructure has the best overall performance on the whole data set. the median values of sensitivity and ppv are  <dig> % and  <dig> % for knotstructure. hxmatch has the next highest sensitivity and ppv . the abstract shapes of these families are shown in table  <dig>  three families contain simple h-type pseudoknots while the other three families contain more complicated pseudoknots. in order to show the effect of shape prediction in structure prediction, we predicted the structures of r <dig> using  <dig> randomly selected shapes. the average sensitivity and ppv of predicted structures with the predicted shapes are higher than those using random shapes as shown in table  <dig>  table  <dig> shows the average sensitivity and ppv over all sequences of each family compared to other tools. the average running time of knotstructure on each family compared to other tools is shown in table  <dig> 

bold number and underlined number indicate the highest and the second highest sensitivity or ppv for each family. ⊕ average sequence length. * the number of test sets.

discussion and 
CONCLUSIONS
based on the fold-then-align strategy, choice of folding tools can play an important role in the performance of the shape and structure prediction. for the test set, we tested two folding tools: hotknots  <cit>  and tt2ne. we used them in three different ways: hotknots, tt2ne, and both of them. we ran hotknots and tt2ne with default parameters. the experimental results show that using tt2ne alone achieves the best performance in consensus structure prediction. it is likely that other folding tools exist to yield better performance than tt2ne. however, as the performance of those tools also depends on the input data and the parameters, a systematic study is needed to choose the best tool.

for tt2ne, we currently only use  <dig> sub-optimal structures. increasing this number moderately does not affect the performance significantly. it indicates that the correct structures have high rankings in the folding space. however, there are a few sequence sets for which the correct structures are not near-optimal. thus, enlarging the sample folding space will likely increase the sensitivity. however, using a large number of sub-optimal structures can increase the computational cost. thus, a better algorithm is needed to achieve a better tradeoff between sensitivity and running time. this is an important part of our future work.

there are more pseudoknot-free structures available than pseudoknot-containing structures. to achieve a reliable svm model, more training data is desired. we used k <dig> for feature selection. this may cause knotshape to have slightly lower predictive performance on pseudoknot-containing than pseudoknot-free sequences. nonetheless, the features used in knotshape does not heavily rely on the free energy value, which is different between pseudoknot-free and pseudoknot-containing structures. instead, the feature set is based on multiple rna properties shared among homologous sequences.

extensive analysis of rna properties based on svm allows us to identify important features related to abstract shapes. the combination of mass data analysis and svm-based feature ranking makes knotshape a promising tool for shape prediction. by combining the predicted shapes and the multiple structural alignment strategy, knotstructure demonstrates higher accuracy in pseudoknot structure prediction.

competing interests
the authors declare that there are no competing interests.

authors' contributions
ys initiated the project and participated in its design and coordination. ra designed the shape prediction algorithm, developed both knotshape and knotstructure, and conducted the experiments. ra and ys are both responsible for writing the manuscript.

declarations
the publication costs for this article were funded by nsf dbi- <dig> and ios- <dig> 

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2013: selected articles from the eleventh asia pacific bioinformatics conference : bioinformatics. the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/14/s <dig> 

