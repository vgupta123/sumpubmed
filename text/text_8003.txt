BACKGROUND
introduction
many problems related to systems biology remain computationally hard , meaning that a brute force computational approach will only be tractable for small instance sizes. despite apparently ever-increasing available computational power, in order to take full advantage of computational methods it is still necessary to apply them judiciously. this means balancing the requirements of precision and accuracy and finding meaningful abstractions which optimise them.

representing signalling networks as dynamical systems of interacting populations of molecules offers the tantalising prospect of being able to predict the future behaviour of such networks by simulation. precision in the model is high, but such systems are critically dependent on the accuracy of their parameters to produce valid predictions of reality. for relatively small subsystems  it has nevertheless been possible to construct mathematical models that adequately reproduce the results of experiments, thus validating the model. with many such dynamically modelled pathways available in the literature and databases, it thus seems plausible to combine them into larger models able to better predict the behaviour of the whole system. this turns out to be not so easy. dynamical parameters optimised in isolation and with respect to a particular set of experimental conditions will not necessarily be optimal in combination with other pathways. moreover, the assumptions of external substances in excess or at equilibrium used to mathematically isolate the model may mask complex mechanisms as yet unmodelled. thus, blindly re-connecting the disparate systems is not valid and experimental validation of every combination of pathways is impractical.

in order to take advantage of the vast repository of accumulated data and the easy availability of computational power, we have devised an efficient systematic approach that allows automatic analysis and verification of large dynamical models in a meaningful way. noting that oscillatory behaviour is ubiquitous in biological systems, we present a new automated analysis technique based on frequency domain analysis, able to measure precisely the behaviour  of interacting systems. to demonstrate the utility of this approach we apply it to a novel coupled oscillatory model of p <dig>  nf-kb and the mammalian cell cycle. in what follows we first describe the background to the modelling process and explain our methodology in detail, we then present and discuss our results and finally draw conclusions. an additional file contains further background to the modelling and analysis process, plus detailed descriptions of the models we have created.

biological context
it is well-known that signalling pathways that govern cellular death are of critical importance for normal tissue development, homeostasis and function  <cit> . many pathological implications are associated with dysregulation of the delicate balance between cell life and death. in mammalian cells, various signals, such as hormones, cytokines, and cell-cell interfaces, elicit changes at the gene expression levels, mediated by inducible transcription factors that provide feedback loops upon their signalling pathways. these feedback genes, generally thought to functionally terminate the signalling action of the transcription factor, create the potential for the transcription factor activity to oscillate between active and inactive states over a period of hours  <cit> .

oscillations are necessarily ubiquitous in biology and are found, for example, in the pulse of the heart, the circadian rhythm, in the signal transduction that involves adenosine 3',5'-cyclic monophospate  and in the chemotaxis of dictyostelium discoideum  <cit> . in the present context it is important to note that oscillatory behaviour is evident in the cell cycle, nuclear factor-κb  and p <dig>  <cit> ). however, the precise significance of all such oscillations is still unclear; how the cell uses oscillations to differentiate input conditions and send specific signals to downstream genes have been central questions in the study of signalling pathways. this strongly motivates the need for an engineering approach to quantify these effects in biological systems exhibiting emergent oscillation.

in the literature, qualitative descriptions of the components and mechanisms of oscillatory signalling systems have greatly improved our understanding of how cells function and have given insights into their behavioural properties, along with how to intervene therapeutically when such signals are mis-communicated  <cit> . theoretical studies have shown that many important biological effects can be adequately modelled as simple processes of information transfer on top of assumptions of equilibrium concentrations of metabolites and thus pathways have been successfully examined in this fashion  <cit> . in reality, the architecture of signalling pathways is much more complex, involving time, space and frequency. to account for the complex, multi-dimensional behaviour now observed in experiments, some simplifying assumptions  can no longer be treated as valid and a greater level of complexity must be considered  <cit> . it is this paradigm shift and the demand for increased fidelity and predictive accuracy of models that makes understanding signalling in general a challenging task and that have made it necessary to include the many non-linearities present in reality.

technical motivation
full mathematical analysis of interesting biological systems is usually impractical; the simplifications that are effective for small systems are generally not scalable. moreover, low dimensional explanations of highly complex behaviour seem to defeat the purpose of constructing large models. for large systems we require a systematic approach, so here we present an automated analysis technique based on fourier transformation of simulation traces. by transforming the time series produced by stochastic simulations into the frequency domain, it is possible to characterise mathematically the behaviour of both oscillatory and non-oscillatory systems over time. the use of stochastic models is motivated by the presumption that the underlying mechanism of molecular interactions is discrete and that such models therefore more accurately represent reality. as a consequence, our technique reveals more information about the system than may be possible to extract from deterministic simulations ; variance plays both qualitative and quantitative roles. improved computer hardware and the development of simulation algorithms has made stochastic simulation computationally viable: it is now usually possible to complete multiple parallel simulation runs of large systems in a matter of minutes. taking advantage of this, we construct frequency spectra from multiple simulation runs in order to characterise the average simulated behaviour. in contrast to deterministic simulations, these spectra contain detailed  information about variance. measures over these spectra may then be used to quantify differences and similarities between different systems, different parts within a system, different models of the same system or different simulation algorithms etc. in the present investigation we use this technique to analyse the crosstalk between linked oscillatory systems and the effects of stochasticity. we do this by measuring the differences between combinations of the coupled and uncoupled systems and by measuring the differences between stochastic and quasi-deterministic models . the component subsystems have different characteristic frequency 'signatures' that allow us to identify which system are responsible for a particular perturbation, in addition to characterising its magnitude.

the model
to demonstrate the ideas and power of the proposed method, we apply it to theoretical models of transcription factors identified to play critical roles in cell differentiation and cell death. aberrant nf-κb , best known for its role in immune and inflammatory responses, is an active growth- and division-promoting transcription factor  <cit> . by contrast, the activation of the p <dig> transcription factor  in response to dna damage and hypoxia, transcribes a series of genes that initiates cell cycle arrest, apoptosis or senescence, eliminating clones of cells with dna damage and the resultant mutation. thus the p <dig> response to its stress is the opposite of the nf-κb response to infections or cytokines. that is not to say that there is no overlap in the functions of nf-κb- and p53-regulated genes. under appropriate stress signals the nf-κb have been shown to initiate programmed cell death  <cit> , while p <dig> initiates the transcription of several cytokines  <cit> . in general, however, these two systems respond to stress signals using very different and often mutually exclusive transcriptional mechanisms  <cit> .

we have extended the chosen models to include their involvement with the cell cycle. for example, an immune response to a foreign organism results in the promotion of the target gene cyclin d1; and a response to a high mutation or error rate brought about by dna damage results in the transcriptional upregulation of target gene p <dig> via p <dig> to initiate cell cycle arrest. cyclin d <dig> promotes cell cycle progression through g1-phase by forming active holoenzymes with cdk   <dig> and cdk <dig>  cdk <dig> and  <dig> phosphorylate the rb   <cit>  and cause rb to release the e2f transcription factor which can then activate genes essential for g1-s transition and s-phase  <cit> . by contrast, association of p <dig> with cyclin d-cdk4/ <dig> inhibits rb phosphorylation and induces cell cycle arrest in g <dig>  through its negative effects on various cdks, p <dig> inhibits both the g1-to-s and the g2-to-mitosis transitions. p <dig> also associates with and inactivates e2f, leading to cell cycle arrest and cellular senescence. considering the deregulation of nf-κb and p <dig> pathways, it is not surprising that an extensive crosstalk between both pathways exists at various levels  <cit> .

methods
we are principally interested in the interactions of the processes generating oscillation, so our approach is to find simple models which nevertheless capture the fundamental characteristics of their oscillatory behaviour at a mechanistic level. we considered published mathematical models of the ikb-nf-kb  <cit> , mammalian cell cycle  <cit>  and p53-mdm <dig>  <cit>  systems that describe their evolution in time. our aim was then to construct a simple, unified model that captures faithfully the important elements of the original systems, including stochasticity, thus facilitating efficient analysis and accurate predictions.

model creation
models  taken from the literature and databases often contain elements not crucial to the observed behaviour but included as the valid results of research and experiments. with judicious pruning , such elements may be safely removed; in addition to simplifying the task of simulating and analysing such networks, removing unimportant parts reduces the possibility of over-fitting experimental data when inferring dynamical parameters  <cit> . it is important to note, however, that such simplification is not a requirement of the frequency domain analysis we will present below. the computational cost of our technique tends to increase as a low order polynomial with respect to system size , while the cost of model creation  tends to scale exponentially. to generate our combined model, we reduced experimentally validated models of the individual pathways and linked them with plausible coupling reactions. traditionally for the nf-kb pathway, removal of the other isoforms of the canonical ikb is a common simplification in computational analysis of the pathway  <cit> , however it tends to overlook the fact that ikbα negative feedback alone exaggerates oscillations. to focus on the processes we were interested in, models from  <cit>  and  <cit>  were chosen as our starting point, with some specific parameter changes: rate values for relevant reactions involved in the creation or destruction of the ikb isoforms were averaged or summed , so that only one ikb isoform was utilized in the end. since the inhibitors have been shown to maintain the dynamic - oscillatory - behaviour observed for the nf-kb pathway  <cit> , all rate equations governing their reactions have been taken into consideration as the system is reduced. since current knowledge of the p <dig> system is incomplete, we analysed the simplest consistent model, combining features of  <cit>  and  <cit> , where the assumption is that a protein downstream of p <dig> inhibits a signalling protein that is upstream of p <dig>  which may or may not undergo oscillatory dynamics. this assumption was inspired by the observation that phosphorylated atm, an upstream regulator of p <dig>  <cit> , responded to double-stranded dna breaks , showing a pulse of activity  <cit> . the model  uses two negative feedback loops, one direct feedback and one longer loop that impinges on an upstream regulator of p <dig> 

for their involvement with the cell cycle, the two pathways were connected via components whose regulation is activated by one pathway but coupled to substrates belonging to the g1/s phase of the cell cycle network. such components are the promoter activity of cyclin d <dig> molecules  that have been shown to be activated by nf-kb transcription factor  <cit> ;, the p <dig> molecules  activated by p <dig> molecules, and finally the p14-arf  known to inhibit mdm <dig> activity.

stochastic modelling
in designing the linked systems, both deterministic and stochastic methods were utilized. up-to-date models were taken from the literature in the form of ordinary and delay differential equations. links were hypothesised based on a literature search and the models were simplified and parameterised using the assumptions outlined above and in additional file  <dig>  to validate our simplifications, deterministic simulations were performed to verify that the key behavioural characteristics of amplitude and period of oscillation were consistent  with those of the original, experimentally verified, models. further simulations were performed to verify that the behaviour of the coupled models was equally consistent. the models were then converted into quasi-deterministic and fully stochastic forms for simulation using the method of arbitrary partial propensities , an 'exact' variant of the gillespie direct method  <cit> . in the case of the quasi-deterministic models, the transformation is essentially a conversion of the ordinary differential equations  from continuous concentrations into discrete numbers of molecules. although in theory our frequency domain analysis also works with fully deterministic simulations, deterministic spectra contain no information about variance  and often contain arbitrary artefacts arising from the practical limits of numerical precision  and the adaptive nature  of numerical solvers. the inherently 'spiky' nature of these spectra potentially make measurements more fragile in comparison to those of stochastic spectra. additional file  <dig> figure s7b illustrates the spikiness of a deterministic spectrum and its relationship to non-deterministic spectra of corresponding stochastic and quasi-deterministic models. to discretise both the quasi-deterministic and stochastic models the initial concentrations were multiplied by a constant  having units of l mol- <dig> that was also used to transform the rate constants . to create the fully stochastic models, the terms of the differential equations were separated to form elemental reactions of the form a + b → c + d, using mass action kinetics. note that three of the reactions of the p <dig> system, one of the nf-κb system and the coupling between the nf-κb and the cell cycle systems employ kinetics that are not mass action and are converted to reactions with parameters that respect their specific kinetic functions. while it may be desirable to reduce the entire system to elemental reactions in order to preserve the physical assumptions made by the stochastic simulation algorithm  <cit> , this is not necessary from the point of view of our analysis. indeed, the questions raised by not using elemental reactions may be answered by our technique and motivates the inclusion here of quasi-deterministic versions of our models. it is important to note, however, that our conversion procedure guarantees that for any specified initial state, the instantaneous magnitude and direction of the average rate of leaving the state in the stochastic and quasi-deterministic models is identical  to that of the deterministic model. the subsequent traces would, of course, be different, but by maintaining local consistency we are justified in re-using the dynamical parameters of the original models.

stochastic simulation
simulation is a very simple means to get an idea of the behaviour of a dynamical system. in a deterministic framework the evolution of concentration in time produced by numerically solving a set of odes is a direct characterisation of its average behaviour, but individual stochastic simulation traces may be quite different from one another. there is often an intuitive notion of average behaviour, apparently related to the solution of the corresponding ode, but this is merely coincidental. since such an ode defines the behaviour of the stochastic system taken to the thermodynamic limit  <cit> , it is not in general the average of the stochastic process. importantly, the noise in stochastic simulations is not merely superimposed on an underlying deterministic trajectory, but is created by the mechanism of the system and is therefore intrinsic to the trajectory. additional file  <dig> figure s7b illustrates the significant differences between deterministic and stochastic models constructed from the same reactions and kinetic parameters.

the stochastic models we consider here are governed by the chemical master equation , which is a linear differential equation that describes the evolution in time of the probability of the system being in any particular state, considering all possible evolutions from the initial state. it is possible to solve the cme numerically and thus obtain the distribution of values that a molecular species may assume at a given time point. such a distribution is with respect to all evolutions and does not consider how an individual trajectory may have arrived at a particular value . causality is lost. solving the cme is therefore not useful in describing oscillatory behaviour: neither the oscillations nor their properties may be evident in the resultant distributions.

thus, while the choice of a discrete stochastic framework offers the potential to investigate chemically reacting biological systems in the most precise way, in order to draw general conclusions about a model's behaviour from stochastic simulations it is necessary to characterise some kind of average trajectory that preserves the behaviour. averaging the time series of multiple stochastic simulation runs, however, does not produce an average trajectory: the amount of a molecular species at a given time point in different simulation runs is a random variable, the distribution of which being defined by the cme. the consequence of this is that averaged oscillatory behaviour of stochastic time series tends to disappear with increasing time because as time progresses the system is less likely to be in a unique state. this is illustrated in additional file  <dig> figure s7a, where it is clear that behavioural information is progressively lost to the averaging process. by considering the average frequency spectra, however, we avoid this limitation and can take full advantage of the information contained in the stochastic traces.

statistical measures over frequency spectra
we make multiple simulation runs , having identical initial conditions and length of simulated time, and the resulting time series are converted to complex frequency spectra using the discrete fourier transformation :

  fω= ∑n=0n-1xne-2iωnn 

fω is the ωth frequency component  and xn is the nth  time sample of a given molecular species. in practice, this will be achieved efficiently by using a standard fast fourier transform  algorithm. stochastic simulations resulting from a variant of the gillespie algorithm  <cit> , as used in our investigations , produce time series having irregular time spacing between points. hence, to apply equation , which assumes constant time steps, it is necessary to sample the stochastic time series at regular time intervals. the method adopted is to calculate xn = xt | max, where xt is the simulation point having value x at time t and δt is the desired sampling time step. intuitively, this formula gives the last value recorded prior or equal to the required sample time. the combination of n and δt define the overall time that the system is observed , the frequency resolution -1), and the maximum observable frequency -1). to maximise the range and the precision of the analysis it is generally desirable to have large n and small δt, however these must be optimised with respect to the phenomena being investigated; in addition to the computational cost of excessive range and precision, there may also be an unforeseen loss of resolution. a reasonable lower bound of δt might seem to be the time of the shortest individual reaction event found in the time courses, however this is often excessively short, extending the frequency spectrum orders of magnitude above the interesting phenomena. similarly, lengthening the overall simulation time, thus increasing n and the low frequency resolution of the analysis, may allow parts of the system to demonstrate atypical or uninteresting behaviour. the potential consequence is that the quantitative significance of the interesting phenomena are reduced in the resulting frequency spectra, reducing the sensitivity of the technique. for the results presented here, values of n =  <dig> and δt =  <dig> minute were chosen, corresponding to a frequency resolution of  <dig>  cycles per minute and a maximum observable frequency of  <dig>  cycles per minute.

the result of the dft is n complex numbers per simulation run, containing real and imaginary parts ]) for each of the n frequencies. since these frequencies correspond exactly between runs , the data can be combined to give an average distribution. note, however, that it is not sufficient to simply find the mean of the complex spectra. since the dft is a linear transformation, averaging the fourier-transformed time series is equivalent to performing a fourier transformation on the average of the time series. the result would suffer the same loss of behavioural information described above and illustrated in additional file  <dig> figure s7a. we overcome this problem by finding the mean of the amplitudes of the spectral data, where the amplitudes are given by:

  f^ω=2+ <dig> 

f^ω is the ωth component of the amplitude spectrum, fωℜ and fωℑare the real and imaginary parts of fω, the ωth component of the complex spectrum resulting from equation . the average amplitude spectrum is then defined:

  f˜ω=1k∑ikf^ω,i 

k is the number of simulation runs, f˜ω is the ωth component of the average amplitude spectrum, f^ω,i is the ωth component of the amplitude spectrum from the ith simulation run. by thus discarding the average phase information , it is possible to reveal the average oscillatory behaviour in an intuitive way. we have found the average phase information to be less informative , although it can be examined independently, if required.

the spectra created in this way form distributions which tend to characterise the observed behaviour in a compact, informative form. although the frequency spectra contain as many points as a single simulation run and may also contain noise, the processes of transformation and averaging serve to resolve and elucidate the characteristic behaviour. moreover, we are then able to measure and compare the spectra so produced. in particular, we use a discrete space version of the kolmogorov-smirnov  statistic  <cit>  as a measure of similarity between distributions:

  d= max 

fn <dig> and fn <dig> are cumulative probability distributions of two frequency amplitude spectra ) containing n elements. d is then a value in the interval  <cit> , where  <dig> corresponds to identical distributions. our choice of this measure is based on the facts that its convergence characteristics are well understood, it has good discriminatory power and its calculation is efficient. the k-s statistic  is usually implemented in mathematical software as a function which takes the amplitude spectra directly as arguments. note that to quantify the influence one species has on another it might be more appropriate to use information-theoretic measures such as mutual information or cross entropy.

the following procedure is used to generate average frequency spectra to characterise a set of simulations for the purpose of visual comparison or analysis of stochasticity.

procedure a:

 <dig>  perform a number of simulation runs which are long enough to demonstrate a phenomenon of interest.

 <dig>  generate average frequency amplitude spectra for each molecular species:

a. sample each simulation trace according to n and δt, chosen to suit the interesting phenomenon, and calculate a frequency amplitude spectrum based on equations  and  using an fft algorithm.

b. calculate term-wise means of the amplitude spectra according to equation .

 <dig>  iterate  <dig> and  <dig>  adding new simulations to the average as necessary .

the following procedure is used to measure the difference between alternative systems or alternative simulation algorithms.

procedure b:

 <dig>  perform a number of pairs of simulation runs, where

a. each pair comprises the two alternative systems/algorithms and

b. the number of runs is designed to take an acceptable amount of time.

 <dig>  generate average frequency amplitude spectra for each molecular species of the alternative systems/algorithms, as per procedure a 2a and 2b.

 <dig>  for each molecular species of interest, calculate d according to equation  applied to its average amplitude spectra from the alternative systems/algorithms, using a k-s test.

 <dig>  iterate 1- <dig>  adding new simulations to calculate d, until all ds are known with sufficient precision.

the number of simulation runs required ) is dependent on the inherent stochasticity of the systems under consideration and the resolution required. insufficient simulation runs produce average distributions whose noise may obscure subtle differences in d. informally, the number of simulations may be considered sufficient when the average spectra look smooth or when adding further simulations does not alter the order of the calculated values of d above some desired resolution threshold. in the present investigation,  <dig> runs reliably resolved differences in d of  <dig> . for models which have a prohibitive computational cost of simulation it may be desirable to formalise the criteria for additional simulation runs to avoid unnecessary computation. one criterion might be to set a minimum acceptable coefficient of variation for spectral component means . alternatively, a sequential hypothesis test  <cit>  could be used as the stopping criterion in procedure b. the idea would be to set the supposed pair-wise order of various ds as null hypotheses and define desired probabilities of falsely rejecting a null hypothesis or falsely accepting the alternative. each iteration would either confirm or reject the hypotheses, until the stopping rule indicates that the result is known with sufficient confidence. see  <cit>  for details.

efficiency
our analysis methodology scales efficiently with respect to model size , especially in comparison to numerical techniques for finding the probability distribution of states in markov chains   <cit> . since the state space scales exponentially with model size, such techniques rapidly become intractable. moreover, expressing properties of behaviour in terms of frequency using these techniques is cumbersome at best. statistical approaches based on the same measures, but which circumvent enumerating the state space by using simulation, suffer the same limitation when expressing frequency. the principal computational cost of our technique is the simulation runs: the dft is performed by a standard fast fourier transform  algorithm on only a small subset of points from each simulation trace. the size of this subset is essentially independent of the number of molecules and reactions in the system and is only related to the bandwidth of the phenomena being compared. the length of a simulation run is the total number of reaction events that take place. in a system comprising isolated subsystems, the total number of reaction events is the sum of the reaction events in each subsystem - linear scaling. in a system where the subsystems are coupled, additional reaction events take place when the subsystems interact. if such reactions apply to just a few coupling species and the behaviour of the subsystems does not change radically , the overall effect of coupling on efficiency is minimal. under other circumstances, the increase in computational cost still only scales with a low order polynomial.

RESULTS
our crosstalk experiment considers the vector of change comprising the changes in behaviour of molecular species in the cell cycle resulting from connection to the nf-κb and p <dig> systems, relative to their behaviour when the external systems are not connected. precise details of the models we constructed are given in additional file  <dig>  while figure  <dig> contains a diagrammatic representation of the fully coupled system.

we applied procedure b  with pairs of k =  <dig> simulation runs to calculate values of d ) for every species in the cell cycle model; for the cell cycle coupled to the p <dig> pathway alone, the cell cycle coupled to the nf-κb pathway alone and the cell cycle coupled to both. the numerical values are tabulated in additional file  <dig> table s <dig> and illustrated in figure  <dig>  in what follows we use the term perturbation to mean these values and equivalently refer to perturbation by p53a and nf-κbn, since p53a and nf-κbn are the molecular species which link the respective systems to the cell cycle in our model. in order to validate our choice of parameters for the coupling reactions we also investigated the effects of double and ten times increased coupling strength. the results of this are tabulated in additional file  <dig> tables s <dig> and s <dig> and illustrated in additional file  <dig> figures s <dig> - s <dig> 

previous work  <cit>  has shown that the technique of frequency domain analysis applied here is especially revealing when applied to stochastic simulation traces; the variance found in reality being absent in deterministic simulations. while most of our results therefore concern stochastic simulations, we duplicated many of our experiments using quasi-deterministic models and used the presented technique of frequency domain analysis to investigate the differences. the quasi-deterministic models are constructed from exactly the same reaction scheme and kinetic parameters, however the kinetic functions for production and consumption of a particular species are combined in a single, resultant, function, as in the case of deterministic simulations . this function is then simulated stochastically , but produces much less stochasticity than the reaction-based model. by maintaining the same discrete state space and simulation framework between the two types of models, it is possible to resolve the effects of stochasticity more clearly and avoid the artefacts sometimes created by deterministic solvers. moreover, we are able to visualise and quantify the often cited 'inaccuracy' of not converting systems to elemental reactions. the artefacts of deterministic solvers and the relationship between deterministic, quasi-deterministic and stochastic simulations are illustrated in additional file  <dig> figure s7b.

it is immediately apparent from our results that the nature of crosstalk is at times counter-intuitive in terms of causality. for example, the species directly influenced by nf-κbn is only weakly perturbed while the point of maximum perturbation is three steps away from nf-κbn. such phenomena are perhaps to be expected in coupled non-linear dynamical systems. nevertheless, we wished to investigate whether there is in fact a simpler explanation of crosstalk, based on network topology, that can be inferred without simulation. in figures  <dig> and  <dig> the nodes are linked by lines indicating the direction and nature  of the influence one species has on another. in general, species a has a positive influence on species b when a is a substrate or enzyme for the production of species b: the more a that exists, the more b is produced. species a has a negative influence on species b when b is consumed in a reaction and a is either an enzyme or substrate in the same reaction: the more a that exists, the more b is consumed. using this network abstraction we evaluated the correlation between the distance from the source of influence to each species in the network and the crosstalk measured using our frequency domain analysis technique. figure  <dig> charts the results considering the minimum distance  and the weighted distance . figure 4a shows that the relatively simple measure of minimum distance  is apparently able to adequately characterise the measured perturbation caused by connecting the cell cycle to the p <dig> system. by contrast, figure 4c demonstrates that the minimum distance is a completely inadequate model of the perturbation caused by the nf-κb system; the corresponding coefficient of determination  value of  <dig> indicates that the minimum distance has no predictive power in this case . by including the influence of all possible paths between nf-κbn and cell cycle species the predictive power of the model improves . in the case of influence by p53a , however, considering all paths actually reduces the predictive power of the model . in the fully coupled model  we observe a similar diminution; considering all paths has only weak predictive power.

thus the prediction afforded by the minimum distance may at times appear to be good but at other times is completely erroneous, while the weighted sum of paths gives an overall weak performance. these results clearly indicate the dangers of using heuristics without validation by a reliable benchmark. we also considered  weighted distances incorporating the nature  of interactions, such that the length of any path is taken to be either positive or negative depending on the cumulative nature of the individual steps along it. despite this additional information, however, we found that this was less satisfactory than when we excluded such phase considerations. since the rates of reactions and the concentrations of species may effectively  alter the topology of the network, it is not surprising that it is difficult to encapsulate the subtle non-linear frequency-dependent interplay when these are excluded.

CONCLUSIONS
a key challenge of systems biology is to assemble the disparate information gathered over years of experimentation and research into a coherent whole. to avoid the intractable computational cost of re-parameterising existing models, heuristic techniques, such as those of network analysis, may be employed to simplify the task. to evaluate the performance of these heuristics and verify what is created, efficient, meaningful, high resolution analytic techniques must be developed. this document presents one such: a systematic technique for characterising behaviour and for measuring the interactions and connections between and within signal transduction pathways using frequency domain analysis. we have constructed a novel dynamical model of communicating oscillatory networks of p <dig>  nf-κb and the g1/s phase of the cell cycle and have applied our technique to investigate it. in doing so, our investigation has revealed complex counter-intuitive dependencies and has demonstrated that the methodology is reliable, precise and capable of distinguishing the effects of multiple interactions.

as general conclusions for the model we have found that  p <dig> and cyca-cdk2-p <dig> are the species most strongly influenced by the p <dig> network and that the perturbation is primarily at the principal oscillatory frequency of p53a and local to the perturbation;  p <dig> and cyca-cdk2-p <dig> are only weakly perturbed by the nf-κb network;  e2f-rbpp is the species most strongly perturbed by the nf-κb network and the perturbation is indirect and from the low frequency transient of nf-κbn, rather than its higher frequency oscillations;  increased coupling strength tends to reinforce trends in crosstalk; however  e2f-rbpp is moderately perturbed by p53a with single coupling strength, less perturbed with double strength coupling and again moderately perturbed with ten times coupling strength;  species e2f-rb, p <dig>  rb and skp <dig> remain unperturbed for all combinations of perturbations and coupling strengths. in the case of skp <dig> this can be immediately inferred from the topology; it is not influenced by other species. we might also expect p <dig> to be only weakly perturbed because it has both positive and negative influence derived from a single species . positive and negative influence do not in general cancel each other  and we have shown that network topology alone is an unreliable indicator of influence.

quantifying in detail the extent to which molecular species are robust or sensitive to perturbations potentially indicates the mechanisms by which the system may be manipulated in experiments and therapeutics. strictly, the dependencies we have discovered are features of the models we have used, the simulation algorithm we have chosen and the links we have hypothesised . there are clearly many additional interconnections with other pathways that we  have not yet modelled , but given that the individual models with which we started are experimentally validated and of high quality, that we guarantee our conversion procedure maintains their original properties while making them more closely respect the underlying physical processes and that our simulation algorithm is rigorous, it is reasonable to assume that our results say something about the real biological systems.

we have described how our methodology is efficient with respect to the standard numerical techniques used to investigate markov chains and have observed that, in addition, such techniques are cumbersome in describing behaviour in comparison to ours. to add weight to these claims and as a further demonstration of the utility of our benchmark technique, we have shown the results of investigating two network-based heuristics, finding that they are not adequate in describing the complex frequency-dependent interplay in our model and may give misleading results. it is important to note here that our methodology is a precise means of measuring and comparing simulation time series and that it has no obvious inherent prejudice with respect to the type of model or means of simulation. there are practical considerations, relating to the efficacy and precision of numerical algorithms, which make certain combinations of model and simulation algorithm infeasible, but these considerations are independent of our methodology. in our investigation of the cell cycle - p <dig> - nf-κb system, we have used an exact stochastic simulation algorithm, but have chosen to investigate both a model which is, as far as possible, reduced to elemental reactions  and one which is essentially a stochastic interpretation of the differential equations . while the qualitative differences between these two cases is clear, our methodology is able to provide a quantification of the differences and, importantly, can do so when the differences are not known a priori.

our focus has been stochastic models, but there are well-established techniques used to investigate the dynamics of deterministic systems that can be seen as potential alternatives to our methods . algebraic analysis tends to become infeasible for dynamical systems of greater than five dimensions , hence the principal deterministic analytic technique is simply to numerically solve the set of differential equations that describe the system, by simulating a trajectory in time from some initial state. phase plane analysis can reveal the qualitative features in the state space  which account for the dynamics of systems with two dimensions or which can be reasonably simplified to two dimensions. this represents a very small class of systems and such techniques do not scale. bifurcation analysis of a system may be used to find the critical dependence of its equilibria and fixed points  on parameters, however this does not necessarily quantify or characterise the typical behaviour of the system. sensitivity analysis is often used with deterministic models to identify their most important parameters by quantifying the changes of behaviour  with respect to changes of the parameters. such an approach is not limited to deterministic systems and would, we suggest, be more effective using our frequency domain-based definition of behaviour. overall, existing techniques used on deterministic systems tend to be somewhat ad hoc, depending on the intuition of the investigator, and do not allow the convenient quantification of behaviour that our methodology provides.

given the vast repository of individual models in the literature and in online databases that await combination and validation, we have shown that our methods have great potential for application in systems biology. we also envisage further improvements and refinements to our techniques. biological systems often contain processes working at orders of magnitude different scales of time and size. although transformation into the frequency domain has here proved to be both effective and intuitive, in order to integrate and analyse large multi-scale systems, we feel it may be efficacious to consider the more abstract wavelet transformation.

competing interests
the authors declare that they have no competing interests.

authors' contributions
aeci created the models and co-wrote the manuscript. sas performed the simulations and analysis and co-wrote the manuscript. the authors read and approved the final manuscript

supplementary material
additional file 1
supplementary material. the supplementary material contains supplementary results and methods, including details of the mathematical models employed and other examples of the application of frequency domain analysis.

click here for file

 acknowledgements
this work has been partially funded by firb project rbpr0523c <dig>  and by fondazione capiplo and fondazione caritro under the nobel project . the authors wish to thank colleagues at cosbi, ivan mura, attila csikasz-nagy and matteo cavaliere, as well as external colleagues neil perkins and stefano pluchino, for valuable discussions.
