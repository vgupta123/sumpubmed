BACKGROUND
profile hidden markov models  are sensitive tools for remote protein homology detection. unfortunately, current implementations of the viterbi and forward scoring algorithms, which are commonly used to compare a sequence to a profile-hmm, require considerable time. scoring an average length profile-hmm against the ncbi nr database  using the forward algorithm takes approximately  <dig> hours on a  <dig>  ghz desktop using hmmer  <cit> . in comparison, the heuristic pairwise sequence comparison method wu-blast is greater than 200-fold faster  <cit> . wu-blast achieves this speed, in part, by using several incremental steps to determine whether a database sequence is sufficiently similar to the query. if a database sequence fails at any of these stages, the sequence comparison is halted and the next database sequence is examined. this fast elimination of the majority of database sequences contributes to the significant reduction in search time  <cit> .

such sequence-level filtering can be easily and simply combined with existing profile hidden markov model search strategies. in this study, we describe a series of filtering steps that are applied prior to the viterbi and forward profile-hmm scoring algorithms as implemented in an exploratory branch of the hmmer <dig> software package, hmmer  <dig> . <dig>  these filtering steps were selected with the goal of reducing profile-hmm search time against large sequence databases while minimizing the reduction in remote homology detection.

this scoring heuristic was then utilized in an iterative profile hidden markov model search method. iterative search methods perform multiple searches of a sequence database. once novel homologous sequences are identified, they are incorporated into the statistical model of the query sequence. this new model is then re-searched against the sequence database. iterative search approaches have been utilized for sequence to position-specific scoring matrix comparison methods, e.g. psi-blast, as well as profile hidden markov model to sequence scoring, e.g. sam's target2k  <cit> . at the core of these methods is a probabilistic model of the query protein built from multiple homologous sequences. one major factor in the sensitivity of these methods is how well these homologous sequences represent the diversity of the protein family being modelled. in principle, by incorporating distant homologous sequences, while avoiding contaminating non-homologous sequences, into the model after each search, iterative methods are able to build a more diverse and potentially more sensitive model of the query protein.

current iterative methods for profile hidden markov models are dependent on creating a subdatabase from a larger sequence database using a less sensitive pairwise sequence comparison method, such as wu-blast. this subdatabase is then used in the iterative searches due to the speed issues inherent in using profile-hmm scoring algorithms on large databases  <cit> . however, using a less sensitive pairwise sequence method in the creation of the subdatabase presents a potential limitation to current iterative profile-hmm methods. by taking advantage of our newly developed search heuristic, we have eliminated the requirement of this subdatabase. in order to determine any sensitivity loss by our search heuristic and to measure the performance of our iterative search method, we have created a remote protein homology benchmark.

methods
non-redundant ncbi nr database, nrdb90
the non-redundant database, nrdb <dig>  used in this study was created from ncbi's nr, 1/12/ <dig>  database which was filtered to remove sequences with greater than 90% identity using holm and sander's method  <cit> . the script used is available at: http://ekhidna.biocenter.helsinki.fi/downloads/rsdb/nrdb <dig> pl.

remote protein homology benchmark
one crucial aspect of a remote protein homology benchmark is a set of trusted protein homologs. current datasets of homologous proteins primarily utilize either protein structure or sequence conservation to infer homology  <cit> . since using a sequence-based protein homolog dataset to test sequence-based homology detection algorithms could be a source of confounding circularity, we chose to use the structure-based scop database as a trusted source of true homologs. it should be noted that this database consists of single domain proteins that are relatively less compositionally biased and repetitive than those in the large sequence repositories. similar to several other studies, we used the astral compendium version of the scop  <dig>  database filtered for 40% identity  <cit> .

in order to generate multiple sequence alignments for each test sequence, we utilized an approach similar to that used by madera and gough  <cit> . each test sequence was searched against a non-redundant version of ncbi's nr database, nrdb <dig>  using wu-blast blastp  <dig>  mp-washu  <cit> . those nrdb <dig> sequences that matched the test sequence with an e-value less than  <dig> × 10- <dig> were aligned, with the test sequence, using clustalw  <dig> . these multiple sequence alignments were then used in the construction and calibration of profile hidden markov models using hmmer  <dig> . <dig>  and sam  <dig>  in the hmmerhead benchmarking studies. however, in benchmarking the iterative methods, each program was given the individual test sequence and allowed to iteratively search nrdb <dig> to build a model.

almost as crucial as a set of true homologs in a remote protein homology benchmark is the set of true non-homologs. a common utilization of the scop classification system in a protein homology benchmark is to declare that those proteins that share the same scop superfamily classification are homologs  <cit> . those proteins that belong to different scop fold classifications are considered non-homologous.

we, as well as others, have observed complications with using the scop classification scheme to distinguish non-homologous proteins  <cit> . using several different sequence comparison methods, we observed highly significant scores between specific models and sequences with different scop folds. later versions of the scop database reclassified these sequences as being in the same superfamily. this raises the important issue that one can not be positive two sequences are not homologous just because of their current scop fold classification. in previous studies, the authors excluded hits between certain folds from their benchmarking results due to the similarity and high level of cross-fold hits they observed. instead of selectively excluding hits between certain folds, we decided to utilize shuffled scop sequences as a trusted source of non-homologous sequences. the program shuffle, from the hmmer  <dig> . <dig> squid library, was used to create five different shuffled copies of each astral sequence.

under our benchmarking scheme, those proteins that share the same scop superfamily classification will be considered a true homologous relationship. those scop superfamilies that consisted of one sequence were discarded from our benchmark. any hit between a model and a shuffled scop sequence is considered a false homologous relationship and a hit between scop sequences not of the same superfamily are considered ambiguous. given the above design and homology criteria, we have produced a benchmark of  <dig>  query alignments and a test database of  <dig>  sequences. by comparing each query to the test database, there exists a total of  <dig>  true homologous pairwise relationships and  <dig> , <dig> non-homologous relationships.

sensitivity and specificity measures
the most common measures of sensitivity and specificity used in our studies was true positives identified versus errors per query. errors per query, epq, is calculated by false positives divided by the number of search queries,  <dig>  thus, the epq of  <dig>   <dig>   <dig>   <dig>   <dig>  and  <dig> false positives are  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig> , and  <dig> .

for the studies examining hmmerhead parameter settings effects on performance we used minimum error rate to measure sensitivity and specificity in a combined metric  <cit> . we calculated minimum error rate as the minimum sum, over all possible choices of e-value threshold, of false positives and false negatives.

bootstrapping
in order to assess the significance of the performance differences between algorithms on our benchmark, we have utilized a bootstrapping approach  <cit> . we measure the performance of a program on  <dig> replicate query sets which were generated by sampling the test database models with replacement. the performance of each method, e.g. hmmer or jackhmmer, was assessed for each query set. therefore, for each query set we were able to calculate the  <dig> values of tp1-tp <dig>  where tp <dig> is the number of true positives identified at a given value of errors per query by method  <dig>  e.g. hmmer. tp <dig> is the same value using method  <dig>  e.g. jackhmmer. we then calculated a 95% confidence interval on the difference in true positives detected by the two different methods. this was accomplished by taking the  <dig>  ×  <dig> =  <dig> middle values. if this distribution does not overlap zero, there is a statistical difference in the performance of these two methods.

hmmer  <dig> .1
hmmer  <dig> . <dig> is an exploratory branch of the hmmer <dig> software where the major changes relevant to hmmer  <dig> . <dig> are the incorporation of entropy weighting of sequences in the input alignment and the capability of calibrating a model's e-values using either viterbi or forward scoring. all models in this study were built using entropy weighting.

hmmerhead filtering algorithm
hmmerhead's initial step is the generation and identification of significant "words". this step consists of identifying ungapped four residue words from a profile hidden markov model's match state emission scores that possess a score above some threshold, θ. a word score is calculated as the sum of the log-odds emission scores of the word amino acid residues, as determined from the profile-hmm model. these words are then identified in the database sequences using a deterministic finite automaton.

in the next filtering step, each word identified in a database sequence is the seed for an ungapped alignment between the sequence and the profile-hmm. the alignment extension starts at the left end of the word and proceeds until the alignment score drops a threshold, δ/ <dig>  amount below the optimum score observed. since this is an ungapped alignment, the alignment score is calculated as the sum of the match emission scores for the observed residues in the corresponding region of the profile-hmm. this extension is then performed on the opposite end of the word. those extended-word alignments that possess a score above a threshold, μ, are passed on to the remaining filtering steps. those database sequences that contain at least two qualifying extended-word hits are then examined further.

the final step consists of performing gapped viterbi alignment between the sequence and the profile-hmm in the region between the two extended-word hits. if the viterbi score is greater than the threshold, η, the sequence is then scored using hmmer's specified full scoring algorithm. i.e. viterbi or forward.

the hmmerhead search heuristic is accessible as a command line option in the hmmer  <dig> . <dig> hmmsearch program. execution of hmmer's hmmsearch program with the option "-h" will produce a full list of hmmsearch and hmmerhead command line options. for the hmmerhead benchmarking, models were built and calibrated from the benchmarking alignments using hmmer  <dig> . <dig> hmmbuild and hmmcalibrate.

jackhmmer
the jackhmmer procedure begins by identifying initial homologs to a single query sequence using either a default, or with user-defined parameters, ncbi or wu-blast database search. subsequences of database targets identified with e-values less than  <dig> × 10- <dig> are extracted and aligned using clustalw. a hidden markov model is built from this alignment and calibrated using hmmer. this model is then searched against a large sequence database, preferably filtered for fragmented and redundant sequences to decrease runtime, using hmmerhead viterbi. novel homologs are identified at each iteration and then aligned to the existing profile-hmm. the model is rebuilt and further searches are performed until no additional homologs are identified in the database or the maximum number of iterations has been performed.

the jackhmmer iterative search method is implemented as a stand-alone perl script in hmmer  <dig> . <dig>  jackhmmer relies on several additional programs, such as either wu-blast or ncbi-blast, hmmer, and clustalw. paths to these programs are specified in the jhmmer_params file in the hmmer  <dig> . <dig> src/directory and should be edited to the relevant locations of these programs in a user's file system. execution of jackhmmer with no arguments will provide a full list of command line options.

jackhmmer performance in this study was determined using wu-blast and the non-redundant database nrdb <dig>  initial wu-blast hits with an e-value less than or equal to  <dig> × 10- <dig> were aligned with the query using clustalw. this multiple sequence alignment was used to build a hmmer local/local model using hmmer's hmmbuild, with default parameters, and calibrated using hmmer's hmmcalibrate, using  <dig> random sequences. this profile-hmm was searched against nrdb <dig> using hmmerhead viterbi with default parameters. the default e-value thresholds used in the iterative hmmerhead searches are  for iterations  <dig> to the maximum number of iterations. the default maximum number of iterations is seven. the final alignment created from the jackhmmer iterative procedure was then used to build a local/local model, calibrated for forward scoring, and searched against the test database.

wu-blast and wu-blast fps
the wu-blast searches used in the hmmerhead studies utilized wu-blast blastp  <dig>  mp with default settings. wu-blast fps used the family pairwise search method  <cit> . this method consists of comparing a 'family' of sequences to a database using a pairwise sequence comparison method. in a family pairwise search, when more than one 'family' sequence hits the same database sequence, their e-values are combined. we compared the performances of several methods of combining the e-values in this approach, such as mean log e-value, mean e-value, and minimum e-value. since they provided the best performance on our benchmark, we used minimum e-values.

ncbi psi-blast
ncbi psi-blast version  <dig> . <dig> was used in this study. psi-blast models were built by iteratively searching, using default settings, nrdb <dig> with the maximum number of iterations set to seven. the final psi-blast model was then searched, using default settings, against the test database.

sam  <dig> 
sam version  <dig>  was used in this study. sam's iterative search program target2k was searched against nrdb <dig> using default parameters. the alignments produced from this procedure were then used to build profile-hmms using sam's buildmodel using default parameters. these models were then calibrated and searched against the test database using sam's hmmscore and submodel to subsequence  scoring. model to subsequence scoring  calibration and searching was performed but did not perform as well on our benchmark. likewise, sam's various model building scripts were all tested on our benchmark and it was found that the model building script w <dig>  performed the best . this script was used to construct the sam profile-hmms used in our study.

computational resources
all computational experiments in this study were performed using the hhmi janelia farm's compute resources. the compute cluster consists of  <dig> nodes with  <dig>  cores where each core is a  <dig>  ghz intel gainestown x <dig> processor. all nodes have  <dig> gb ram and are running rhel  <dig> 

RESULTS
hmmerhead
we assessed whether we could reduce hmmer's search time by applying a series of filtering steps to the sequences in a large database . the full viterbi or forward scoring algorithms would be performed on only those database sequences that passed all the filtering steps. a hmmer search performed with these filtering steps is referred to as hmmerhead viterbi or hmmerhead forward, according to the full scoring algorithm is performed if a sequence passes the filtering steps.

hmmerhead parameter settings
in order to assess the effect of the various parameter settings, we randomly selected  <dig> benchmarking models to be used in database searches where the four hmmerhead parameters, θ, δ, μ, and η, were varied. parameter effects on runtime were determined by searching the models against a non-redundant version of ncbi's nr database and effects on sensitivity and specificity, as measured by minimum error rate   <cit>  , were determined by searching against our benchmarking database using both hmmerhead viterbi and forward scoring. while the data shown below are for the hmmerhead viterbi searches, hmmerhead forward closely mirrors these results. all possible combinations of the following parameter settings were tested: θ =, δ = , μ = , and η = .

to select hmmerhead's default parameters, we eliminated parameter settings that resulted in a greater than  <dig> % increase in mer relative to hmmer's default search performance. we then selected the parameter settings that yielded the fastest runtime from the  <dig> different parameter combinations that passed the mer cutoff. this resulted in the hmmerhead viterbi and forward parameter settings of θ =  <dig>  δ =  <dig>  μ =  <dig>  and η =  <dig>  for hmmer models built using default settings.

examination of individual parameter settings revealed that the θ and η parameters had the most effect on runtime and mer . plotting mean search time versus minimum error rate for the various θ and η settings reveals a strong increase in minimum error rate relative to a minor decrease in mean search time for θ and η parameter values greater than  <dig> and  <dig>  respectively . this further supports our choice of these parameter values for hmmerhead's default settings.

hmmerhead search times
in order to assess hmmerhead's improvement in search time, we randomly selected  <dig> benchmarking models and searched them against nrdb <dig> using forward and viterbi final scoring. the average time of these hmmerhead searches were then compared against the average default hmmer  <dig> . <dig> search times to determine the average fold speedup .

average search time for  <dig> benchmarking models was calculated using hmmerhead forward or viterbi with several different filtering thresholds. this average time was then compared to the average search time of default hmmer  <dig> . <dig> forward or viterbi,  <dig>  and  <dig>  seconds, respectively. hmmerhead forward provides the greatest speed improvement, ~24x, due the increased average time of this scoring algorithm.

only  <dig>  comparisons, out of  <dig> , <dig>  passed the hmmerhead filtering steps. this reduced the effective database size that the full scoring algorithms were performed on by  <dig> %. hmmerhead forward provides an approximate 20-fold speedup versus default hmmer  <dig> . <dig> forward scoring. hmmerhead viterbi is approximately 6-fold faster. hmmer's forward implementation is approximately 4-fold slower than viterbi and explains the difference in hmmerhead speedup between algorithms.

remote homology detection of hmmerhead versus hmmer  <dig> .1
since hmmerhead's speed gain is due to the utilization of search heuristics, we determined the cost of these heuristics on sensitivity. using our remote protein homology benchmark, we compared the sensitivity and specificity of hmmerhead versus hmmer  <dig> . <dig> for forward and viterbi scoring. in addition, we included the performance of wu-blastp and the wu-blast family pairwise search method. this method has been previously described and consists of comparing a 'family' of sequences in a pairwise fashion to a database  <cit> . the e-values of any shared targets are then combined  to determine the similarity between the sequence family and database targets.

on our benchmark, hmmerhead forward detects an average of  <dig> fewer true positives than hmmer  <dig> . <dig> forward across the measured specificity range . while this is a statistically significant amount, as determined using bootstrapping and a 95% confidence limit, this represents only a 4% loss in the number of true homologs identified by hmmer  <dig> . <dig> forward. hmmerhead viterbi detects an average of  <dig> fewer true positives than hmmer  <dig> . <dig> viterbi on our benchmark . again, this is a statistically significant amount but represents only a 2% loss in the number of true homologs identified by hmmer  <dig> . <dig> viterbi. both pairwise comparison methods were significantly outperformed by hmmer  <dig> . <dig> with and without hmmerhead. the hmmerhead speed gains of 20x and 6x compared to the sensitivity losses of 4% and 2% were deemed to be acceptable tradeoffs.

jackhmmer
we implemented an iterative profile hidden markov model procedure that took advantage of our development of hmmerhead. this allowed us to iteratively search over a large sequence database instead of using the subdatabase approach utilized by other iterative profile-hmm implementations  <cit> . we refer to our iterative search procedure as jackhmmer.

jackhmmer performance
the individual benchmarking sequences were used in iterative searches against nrdb <dig> using jackhmmer, sam's target2k, and ncbi's psi-blast. the final models created by these iterative methods were then searched against the benchmarking database to determine the sensitivity and specificity of each method.

on our benchmark, jackhmmer is able to detect an average of  <dig>  more remote protein homologs than target2k and an average of  <dig>  more homologs than psi-blast across the measured specificity range . thus, on our benchmark, jackhmmer is able to detect 14% more true homologs than target2k and 28% more than psi-blast. using bootstrapping and a 95% confidence limit, these increases in homolog detection are statistically significant.

discussion and 
CONCLUSIONS
in this study, we have implemented several heuristic database filtering steps, hmmerhead, in an effort to decrease the time required to score profile hidden markov models against a large protein sequence database. utilizing four filtering steps, we have managed to decrease the search time by  <dig> or 20-fold relative to using traditional viterbi or forward scoring. this decrease in search time is achieved with only a 2% or 4% loss in true homologs identified on our benchmark. this study demonstrates such heuristic database filtering steps can be successfully utilized to speedup scoring profile hidden markov models against large sequence databases with a minimal loss in sensitivity.

additionally, we have developed an iterative profile-hmm approach, jackhmmer. jackhmmer takes an initial query sequence and is capable of iteratively searching over a large sequence database. due to the length of time utilized by full profile-hmm scoring algorithms, previous published iterative profile-hmm approaches required the creation of a subdatabase using a less sensitive pairwise sequence comparison method. we have leveraged hmmerhead's speed gains to eliminate this step from our iterative search method. utilizing our protein homology benchmark, jackhmmer detects 28% and 14% more remote protein homologs than ncbi's psi-blast and sam's iterative profile-hmm method, target2k, which are statistically significant improvements.

availability
hmmer  <dig> . <dig>  which contains both hmmerhead and jackhmmer, is available for download from http://selab.janelia.org/publications/johnson10/hmmer <dig> . <dig> tar.gz.

the multiple sequence alignments, test database, and perl scripts used in our benchmark are available as a compressed tar archive at http://selab.janelia.org/publications/johnson10/scripts_aln_dbs.tar.gz.

authors' contributions
lsj contributed to the design and testing of the hmmerhead algorithm, designed and tested the jackhmmer algorithm, and drafted the manuscript. ep conceived of and contributed to the design and testing of the hmmerhead algorithm. sre oversaw the design of this study. all authors read and approved the final manuscript.

