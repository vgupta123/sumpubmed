BACKGROUND
despite being an aging technique, real-time quantitative polymerase chain reaction ‚Äîarguably one of the most significant biotech discoveries of all time‚Äîis still heavily used in molecular biology  <cit> . qpcr is an extremely sensitive and cost effective technique to amplify and quantitate the abundance of dna and rna using a taq polymerase that for rna analysis are preceded by a reverse transcriptase conversion into template dna. in life sciences, qpcr is typically applied to quantify candidate gene transcripts that are biomarkers of diagnostic, prognostic, and even predictive value in e.g. infectious diseases and cancer. in the slip stream of high-volume omics-data, another very important application of qpcr has arisen. here, qpcr is the gold standard validation tool for the most promising gene transcripts generated by high-throughput screening studies such as microarrays or sequencing. for validation experiments in particular the ability to control the type i error rate is very important. unfortunately, important statistical details are often omitted resulting in a failure to obtain the desired type i error probability. validation without such an ability cannot be considered very meaningful and therefore conservative approaches should be taken.

the so-called ŒîŒîcq quantity is the normalized relative expression of a target gene of interest between treated  and untreated samples  accounting for undesired variations using one or more endogenous reference genes  assumed to be approximately unchanged due to the treatment. the ŒîŒîcq-value is usually based on the assumption of perfect aes for both the target and reference gene. however, the target and reference genes might be subject to different ae which yield biased ŒîŒîcq-values. in turn, the ŒîŒîcq has been modified to ae corrected versions .

despite the tremendous success of qpcr, ‚Äòstatistical inference considerations are still not accorded high enough priority‚Äô  <cit> . we find this particular true for the estimation of the ae. although efficiency calibration has been extensively treated by  <cit>  or in the more generalized model by  <cit> , there seems to be a lack of systematic studies of the unavoidable influence of the uncertainty of the ae estimate on the conclusions of qpcr experiments based on formal statistical inference. the current ae adjusted ŒîŒîcq methods do not account for the uncertainty of the estimated ae and thus effectively assumes the ae to be estimated with infinite precision. this assumption entails a systematic underestimation of the standard error of ŒîŒîcq leading to too narrow confidence intervals, decreased p-values, and thereby increased type i error rates. if the ae is poorly determined, this underestimation can drastically increase the standard error of ŒîŒîcq and similar quantities.

recently, some effort has been devoted to studying error propagation in qpcr . nordgaard et al.  <cit>  studied error propagation primarily on the cq-values including the effect of the ae uncertainty. this study was, however, statistically informal and made no attempt to quantify the effect on the ŒîŒîcq and inference hereof. furthermore, they  <cit>  considered ae estimation from the amplification curve  and not from separate dilution experiments. tellinghuisen and speiss  stressed and discussed the importance and negative impact of improper error handling, including ae estimation, although again with emphasis on determining cq-values and the florescence level at the hypothetical cycle zero using different methods. in this paper, we explicitly discuss only the ae estimation from dilution curves, which assumes a constant ae across certain genes. while this assumption has been contested and alternatives by branching processes suggested , the problem still exist as ae estimates from individual amplification curves also have an associated error which affect all ‚Äòdown-steam‚Äô estimated quantities and inference. the numerous estimated well-specific aes arguably amplify the problem as even more errors‚Äîone for each well‚Äîis propagated further on.

the work by svec et al.  <cit>  also recently assessed the impact of ae uncertainty as a function of the number of technical replicates at each concentration and the qpcr instrument. they conclude that a minimum of 3‚Äì <dig> replicates at each concentration are needed and that a significant inter qpcr instrument effect is present. however, they do not gauge the effect of the number of concentrations used‚Äîan important variable as additional technical replicates rarely contribute with much information to determine the ae. nonetheless, svec et al.  <cit>  also do not address the impact of ae uncertainty on formal statistical inference on the ŒîŒîcq, as this paper intends.

aims
primarily, we aim to highlight the common problem of disregarding the uncertainty of the ae estimate in statistical inference of the ŒîŒîcq-value in qpcr experiments. and we propose and benchmark different off-the-shelf and novel solutions to this problem.

to this end, we employ a statistical model which allows such formal inference. this covers statistical model formulation, confidence intervals, hypothesis testing, and power calculation, with special emphasis on false positive rates. simultaneous estimation of the uncertainty of the ae estimate and mean cq-values by linear mixed effects models , which allows a more appropriate handling of the technical and sample errors, is described. we investigate the use of the statistical delta method, monte carlo integration, or bootstrapping to correctly perform inference on the value of ŒîŒîcq.

note two important observations: first, the problem exists for all statistical models and methods which incorrectly disregard the uncertainty of the ae estimate and is not limited to lmms. secondly, the problem exists not only for ŒîŒîcq-values, but also all similar quantities, e.g. Œîcq and cq, and the statistical inferences based on these.

the idea of using lmms for qpcr experiments is not new . for example,  <cit>  and  <cit>  have used mixed effects modeling to identify candidate normalizing genes. the work by  <cit>  applied the related generalized estimation equations to handle intra and inter group variation. however, the usage of lmms combined with the statistical delta method, monte carlo integration, or bootstrapping to handle uncertainty stemming from the efficiency estimation seems to be novel and provides a general statistical framework for qpcr experiments and may be considered an extension of the strategy by  <cit> . others use the mixed models primarily for the cq-value estimation  <cit> .

we demonstrate that considering the uncertainty of the ae is, unsurprisingly, highly important when the ae is determined with inadequate precision and vice versa. we do so by three application examples and a simulation experiment. in the first two applications, the consideration of the ae uncertainty is largely unimportant for ŒîŒîcq inference due to a large number of dilution steps and well-determined ae. in the last application, we see that the ae uncertainties have a drastically different impact on ŒîŒîcq inference. in a simulation study, we show that the methods proposed indeed control the false positive rate better than the conventional approach and provide further insight into the problem.

in the first application, we also verify that multiple myeloma cancer cell lines differentially express the mgst <dig> gene depending on the abundance of culture initiating cells. in the second application, the approaches are also used to design and analyze a study which results turned out to support the hypothesis of  <cit>  that mirna- <dig> is differentially expressed between testicular and nodal dlbcl.

methods
observational model
in order to approximate the standard error of the ae adjusted ŒîŒîcq we model the amplification process in the following way 
  fcq=Œ∫n0cq, 

where fcq is the fluorescence measurement at the cq‚Äôth cycle, Œ∫ is a sample-specific proportionality constant, n <dig> is the number of transcripts of interest in the initial sample before amplification, and 2Œ± is the ae from which Œ± is interpreted as the percentage growth on the log scale. in practice, the transcript abundance level is determined by the cycle cq for which a given fluorescence measurement fcq is reached. please note, by sample-specific we mean inter sample variations, like pipetting error, which should be accounted for by the reference genes. we rearrange  and notice that cq can be expressed as Œ±cq=log2fcq‚àílog2Œ∫n <dig>  in order to estimate the relative amount of target  gene transcripts between case and control  samples, we assume the amount of the reference  gene template is the same in both the case and the control, n <dig> ref,case=n <dig> ref,ctrl, and that the ae only vary between the target and reference gene. we then arrive at the following expression for the log2-fold change of the target gene template between case and controls: 
 log2n <dig> tgt,casen <dig> tgt,ctrl=log2Œ∫casen <dig> tgt,case‚àílog2Œ∫casen <dig> ref,case‚àílog2Œ∫ctrln <dig> tgt,ctrl+log2Œ∫ctrln <dig> ref,ctrl=‚àíŒ±tgtcq,tgt,case‚àíŒ±refcq,ref,case‚àíŒ±tgtcq,tgt,ctrl‚àíŒ±refcq,ref,ctrl,  assuming that the cq-values have been determined by a common florescence level fcq. this method of estimating the log relative abundance between case and controls is often referred to as the ŒîŒîcq-method  <cit> , after the double difference appearing in the expression: 
  ŒîŒîcq:=Œ±tgtcq,tgt,case‚àíŒ±refcq,ref,case‚àíŒ±tgtcq,tgt,ctrl‚àíŒ±refcq,ref,ctrl. 

thus we have 2‚àíŒîŒîcq as the relative abundance of the original target transcript corrected for the ae.

statistical model
we study the problematic aspects of ignoring the uncertainty of the ae estimate. note, however, that this problem persists for all statistical models and methods which na√Øvely ‚Äòplug-in‚Äô the ae estimate from dilution curves into formulae concerning the ŒîŒîcq.

for ease of notation we use the abbreviations i‚àà{tgt,ref} for gene types target and reference; j‚àà{case,ctrl,std} for sample types case, control, and standard curve; s‚àà{ <dig> ‚Ä¶,nij} for samples in the ij‚Äôth group; and k‚àà{ <dig> ‚Ä¶,kijs} for dilution steps for each sample. to estimate ŒîŒîcq of , estimates of Œ±i are needed. a popular way of estimating the ae is by ordinary linear regression. i.e. by regressing cq,ij against a series of increasing values 0=x1<‚ãØ<xk, defined by n <dig> ijk=n <dig> ij2‚àíxk, and na√Øvely plugging Œ±^i into  and thus disregarding its uncertainty. here, k denotes the dilution step and xk the number of 2-fold dilutions . the cq,ij-values and Œ±i can then be estimated simultaneously when formulated as a lmm  <cit> ; 
  cq,ijsk=Œºij+ajs+Œ≥ixk+Œµijsk, 

where Œºij is the group means, ajs is a random effect from sample s under the j‚Äôth sample type, and Œ≥i=Œ±i‚àí <dig> is the inverse log2-ae. that is, 
 aei=21Œ≥i=2Œ±i. 

the random effects ajs of  are n <dig> œÉs2-distributed and the error terms Œµijsk are independent and n <dig> œÉj2-distributed with a sample type specific variance œÉj <dig>  the random effects account for the paired samples across tgt/ref for each j. lmms provide a more correct quantification of the sources of variation and thereby a more correct estimate of the uncertainty of Œºij and their derived quantities.

in one application we shall relax the assumption that the ae is independent of j and consider group-specific aes Œ±ij=Œ≥ij‚àí <dig> 

although, variation due to technical replicates should be modeled in  as an additional random effect term, we average out technical replicates for simplicity. for further simplicity of this paper, we refrained from using multiple reference genes simultaneously in the ŒîŒîcq estimation although our the framework and methods easily extends to this case.

inference for ŒîŒîcq by the delta method and monte carlo integration
we first consider hypothesis testing and confidence intervals for ŒîŒîcq by the statistical delta method. let the maximum likelihood estimates of the fixed effects 
 Œ∏=Œºtgt,case,Œºtgt,ctrl,Œ≥tgt,Œºref,case,Œºref,ctrl,Œ≥ref‚ä§  be denoted by Œ∏^=‚ä§. we wish to test the hypothesis h0:c= <dig>  where c is the continuously differentiable function of the fixed effects given by 
  c=Œºtgt,caseŒ≥tgt‚àí1‚àíŒºref,caseŒ≥ref‚àí1‚àíŒºtgt,ctrlŒ≥tgt‚àí1‚àíŒºref,ctrlŒ≥ref‚àí <dig>  

the main task of this paper is to approximate the standard error of c and thereby account for the uncertainty of ŒîŒîcq. that is, the standard error, 
  se=ùïçarc, 

is of central interest. the standard error is used in the statistic for testing h <dig> given by t=c/se. from a first order taylor expansion of c around Œ∏, 
 c‚âàc+‚àác‚ä§,  where ùïçar is the variance-covariance matrix and ‚àác is the gradient vector, the variance can be obtained by 
 ùïçarc‚âà‚àác‚ä§ùïçar‚àác. 

notice, this expression coincides with the formula for error propagation in tellinghuisen and speiss . hence we approximate t by 
  t=c‚àác‚ä§ùïçar‚àác. 

according to , t is approximately t-distributed with Œ∑ degrees of freedom. the degrees of freedom of multilevel mixed effects models are non-trivial to obtain in general. we do not pursue this further and restrict ourselves to the case of balanced experimental designs where Œ∑ is obtained relatively straight-forwardly.

on the basis of , an approximate  <dig> % confidence interval of c can then be given by 
 c¬±tŒ±/ <dig> Œ∑‚àác‚ä§ùïçar‚àác. 

likewise, p-values can be obtained by computing p where t is t-distributed with Œ∑ degrees of freedom.

alternatively to , the variance ùïçarc can be evaluated by monte carlo integration. one way is to simulate a large number n of parameters Œ∏ <dig> ‚Ä¶,Œ∏n from a multivariate normal distribution using the estimated parameters n <dig> and compute the sample variance of c,‚Ä¶,c.

both maximum likelihood  and restricted maximum likelihood estimation  of lmms is implemented in the r-packages lme <dig> and nlme  <cit> . the packages readily provides the estimate Œ∏^ and ùïçar and we use these in the construction of test and confidence intervals for the ŒîŒîcq as described above. the needed gradient in  is computed straight-forwardly from .

we note that the division by Œ≥j in  is problematic as Œ≥^j is normally distributed and values near zero can increase the variance dramatic. in practice, this is only problematic if the standard error of Œ≥^j is sufficiently large. one way to solve this problem is to use the log <dig> concentration as the response and the cq-values as the explanatory variables in a regression model of the standard curve to estimate Œ±j directly. this approach is not without conceptual problems as this puts the errors on the explanatory variables. to this end, note that the hypothesis h0:Œ≥tgtŒ≥refc= <dig>  can be equivalently tested for which the standard error of the test-statistic can be worked out exactly.

if Œ≥tgt‚àí <dig> and Œ≥ref‚àí <dig> are assumed to be one  then  becomes a simple linear hypothesis for which the standard error is easily calculated. this corresponds to leaving out the terms in  involving these parameters and thus ignoring dilution data. if Œ≥tgt‚àí1=Œ≥ref‚àí1= <dig> is assumed, we shall refer to the obtained estimate as the na√Øve lmm. if Œ≥tgt‚àí <dig> and Œ≥ref‚àí <dig> are assumed known  we refer to the obtained estimate as the efficiency corrected  estimate. the estimate where the uncertainty of the ae is considered is referred to as efficiency corrected and variance adjusted by either the delta method  or monte carlo integration .

inference for ŒîŒîcq by the bootstrap method
we now consider hypothesis testing and confidence intervals for ŒîŒîcq by bootstrapping as an alternative approach. the bootstrap, which avoids calculating gradients, is often cited to perform better in small sample situations  <cit> .

the basic idea of the bootstrap is that inference on ŒîŒîcq can be conducted by re-sampling the sample data with replacement to obtain an approximate sampling distribution of the statistic and thereby its properties. in the usual qpcr setup with paired samples and dilution data, straight-forward bootstrapping will quickly fail. we propose non-parametric block bootstrap samples for the case-control data generated by sampling matched pairs of tgt/ref genes with replacement for cases and controls, respectively. however, as we have only got a single observation for each dilution step we chose to re-sample residuals from a simple linear regression model and subsequently adding the residuals to the fitted values from the linear regression. hence the b bootstrapped datasets consists of the re-sampled matched pairs and the residual bootstrapped standard curve. for each dataset, Œ¥^1=ŒîŒîcq,‚Ä¶,Œ¥^b=ŒîŒîcq are computed to obtain the bootstrap distribution from which confidence intervals and p-values can be obtained. the standard error of ŒîŒîcq is estimated by the sample standard deviation of the bootstrap distribution. a  <dig> % confidence interval can be computed as ,Œ¥^) where e.g. Œ¥^ denotes the Œ±/2-percentile of Œ¥^ <dig> ‚Ä¶,Œ¥^b. the p-value for the null hypothesis of Œ¥= <dig> is computed by 
  

while the bootstrap is an intuitive and excellent method for estimating the standard error, it quickly becomes computationally heavy. the rather complicated designs of qpcr experiments with paired samples, dilution data, and other random effects also makes the bootstrap less attractive as good bootstrap sampling schemes are hard to produce.

alternatively, parametric bootstrap can be used by simulating datasets from the fitted model. here, both new random effects and noise terms are realized and added to the fitted values to generate new datasets.

re-sampling methods for qpcr data have previously been proposed by  <cit>  to infer the relative expression directly by permutation testing. unlike the permutation testing of  <cit> , the bootstrap is here used to estimate the mean and standard error of ŒîŒîcq and not directly test the stated hypothesis. the bootstrap approach suggested here also allows for constructing confidence intervals.

applications
we applied the described approaches to two qpcr validation experiments regarding culture initiating cells  in multiple myeloma  and non-coding micrornas in diffuse large b-cell lymphoma . in both experiments, the cq-values were extracted for both the reference and target transcripts with automatic baseline and threshold selection  <cit> . we also illustrate the method on a public available qpcr dataset concerning the differential gene expression in arabidopsis thaliana grown under different conditions. in order to gauge the performance of the methods we subsequently performed a simulation study.

cic study
introduction
a cell is culture initiating if it can initiate a sustained production of cells when cultured in vitro. the viability potential of a cell population can be assessed by measuring the number of culture initiating cells . this number can be estimated by a dilution experiment where cells are seeded in decreasing numbers. the ratio of cics can then be estimated by e.g. poisson regression  <cit> . cics are of particular interest in cancer research as cancers with high culture initiating potential seemingly have stem cell like properties making them resistant towards chemotherapy  <cit> .

in search for genes associated with a high culture initiating potential in mm we made limiting dilution experiments of  <dig> mm cell lines and divided them into  <dig> cell lines with low and  <dig> cell lines with high culture initiating potential. gene expression profiling by microarrays identified genes mgst <dig> and mmset to be differentially expressed between cell lines with high and low abundance of cics. as gene expression detection by microarrays can be hampered by high false positive rates, the purpose of this experiment was to validate the findings of the association of mgst <dig> and mmset with culture initiating potential by qpcr.

sample and data preparation
for this,  <dig> mm cell lines  with > <dig> % cics, and  <dig> mm cell lines  with < <dig> % cics were used. the fraction of cics was determined by the limiting dilution method, see  <cit> . total rna was isolated from frozen cell culture pellets, using a combined method of trizol  and mirvana spin columns . isolated rna was reversed transcribed into complementary dna  synthesis using superscript iii first-strand synthesis supermix . as input into the total cdna synthesis of  <dig> ng total rna was used. equal amounts of random hexamers and oligo were used as primers. quantitative real-time reverse transcriptase polymerase chain reaction was performed on a mx3000p qpcr system  using the taqman universalpcr master mix, no amperase ung, and taqman gene expression assays . the following taqman gene expression assays were used : mgst <dig> , mmset . the two reference genes beta-actin  and gapdh were used as endogenous controls, assay ids 4333762- <dig> and 4333764- <dig>  respectively. for each target and reference transcripts a standard curve based on seven 2-fold dilutions was constructed on a reference sample consisting of material from the amo- <dig> cell line.

dlbcl study
introduction
the association between oncogenesis and micro rnas , short non-coding rna transcripts with regulatory capabilities, has recently prompted an immense research activity. the possibility to change treatment strategies by transfecting antisense oligonucleotide to control abnormally up-regulated mirnas in malignant tissue is of particular interest  <cit> . in that respect up-regulated mir- <dig> and mir- <dig> in testicular dlbcl have shown treatment changing potential  <cit> . however, as the number of screened mirnas was high and the sample size was low in robertus et al.‚Äôs work invoking high risk of false discoveries we set out to validate the differential expression of mir- <dig> and mir- <dig> in tissues from our own laboratory using our improved qpcr analysis workflow.

sample and data preparation
for this study, dlbcl samples were collected from  <dig> testicular  and  <dig> nodal  paraffin embedded lymphomas at aalborg university hospital. the lymphoma tissues were collected during the diagnostic procedure in accordance with the research protocol accepted by the health research ethics committee for north denmark region . total rna was isolated using a combined method of trizol  and mirvana spin columns . an amount of  <dig> ng total rna was synthesized into first strand cdna in a  <dig> Œºl reaction using taqman microrna reverse transcription kit  according to the manufactures instruction. in total  <dig>  Œºl cdna was used as template in the real time pcr amplification performed by mx3000p qpcr system  with sequence specific taqman primers . as reference transcripts we chose rnu-6b and rnu- <dig>  which were less variable and equally expressed across nodal and extra-nodal samples among a larger list of candidate reference genes. for each target and reference transcripts a standard curve based on seven 2-fold dilutions was constructed on a reference sample consisting of pooled material from all  <dig> lymphomas.

arabidopsis thaliana study
introduction
in order to illustrate the effect of applying variance approximations in a dataset with a limited number of dilution steps and samples we considered the arabidopsis thaliana dataset published by  <cit> . the dataset contains one gene of interest, mt <dig>  potentially differentially expressed under two growth conditions of the plant arabidopsis thaliana and two reference genes ubiquitin  and tublin.

sample and data preparation
the arabidopsis thaliana plant growth, rna extraction, and qpcr experiments were carried out as described in  <cit> . the cdna was diluted into 1-to- <dig> and 1-to- <dig> serial dilutions. real-time pcr experiments was performed in duplicates for each concentration  <cit> .

due to the study design, we naturally fitted estimation efficiencies Œ≥ij=Œ±ij‚àí <dig> for each group. because of the few samples we omitted the, in this case, meaningless random sample effect of the lmm.

simulation study
in order to properly benchmark statistical test procedures one needs to have an idea of the false positive rate , or type i error rate, as well as the true positive rate , or sensitivity. as ground truth is usually not available in non-synthetic data, we use simulation experiments to determine the error rates of the discussed statistical procedures.

in our setting, the fpr of a statistical test is the probability that the test incorrectly will declare a result statistically significant given a vanishing effect size or difference of c= <dig> between case and controls; i.e. fpr=p|t|>t1‚àíŒ±/ <dig> Œ∑|c= <dig>  on the other hand the tpr of the statistical test is the probability that the test will correctly declare a result statistically significant given an non-zero effect size Œ¥=c between case and controls; i.e.tpr=p|t|>t1‚àíŒ±/ <dig> Œ∑|c=Œ¥.

a straightforward way to obtain an estimate of the tpr is to simulate a large number n of datasets under the alternative hypothesis of c=Œ¥, fit the model for each dataset, and compute t-values t <dig> ‚Ä¶,tn. from these t-scores the tpr can estimated by 
  

where  is the indicator function. hence, the estimated tpr is the fraction of tests correctly declared significant.

likewise, an estimate of the fpr is obtained by simulating n datasets under the null hypothesis of c= <dig> and obtaining t-values t <dig> ‚Ä¶,tn from which fpr is estimated by 
  

i.e. the fraction of tests incorrectly declared significant.

simulating under the log-linear statistical model described above, we estimate the fpr and the tpr for each discussed method under different choices of sample sizes and number of dilutions whilst fixing the size of the sample and experimental variations. these constant sample and experimental variations corresponds to homoscedastic errors on the log-scale. no technical replications are simulated.

RESULTS
cic study
the cq-values and dilution curves for the cic study are depicted in fig.  <dig> panels a‚Äìb, respectively. the simple linear regressions show well-determined standard curves with small standard errors on the estimate of the slopes.
fig.  <dig> overview of cic experiment data. a raw c
q-values for different cell lines  for each gene type and sample type. the point type and colour differentiates the different gene types. b dilution data for reference genes  and target genes 



the values of the considered estimators for ŒîŒîcq are seen in table  <dig>  the table also shows results of tests for difference in gene expression assessed by the ŒîŒîcq for both target genes mgst <dig> and mmset normalized to each of the reference genes gapdh and actb. we used four different methods to estimate and perform inference:  ec: efficiency corrected lmm estimate ignoring the uncertainty of the efficiency estimates.  ec&va1: ec and variance adjusted lmm estimate using a first order approximation.  ec&va2: ec and variance adjusted lmm estimate using monte carlo integration.  bootstrap: estimate by the bootstrap described in section ‚Äúinference for ŒîŒîcq by the bootstrap method‚Äù fitting the lmm and using the ec estimate.Œî
c
q-value


ec efficiency corrected lmm estimate ignoring the uncertainty of the efficiency estimates. ec&va <dig> ec and variance adjusted lmm estimate using the delta method. ec&va <dig> ec and variance adjusted lmm estimate using monte carlo integration. bootstrap estimate by the bootstrap described in section ‚Äúinference for ŒîŒîcq by the bootstrap method‚Äù fitting the lmm and using the ec estimate. bootstrap shows the mean and standard deviation of  <dig> bootstrap samples using the ec estimate. the last two columns show the  <dig> % lower and upper confidence interval limits



consider the first section of table  <dig> where tgt mgst <dig> is normalized against the reference gapdh. the tests for a vanishing ŒîŒîcq are all highly significant with comparable  <dig> % cis. as expected, the efficiency corrected estimates are unchanged due to the variance adjustment, and only the standard deviation of the estimate is increased. the increase of the standard error is very small resulting in small but unimportant increases of the absolute t- and p-values. the results remain significant for the mgst <dig> gene. very similar results are obtained if actb is used as reference. in conclusion, there is good evidence that mgst <dig> is differentially expressed between cell lines with high and low abundance of cics.

for the target gene mmset normalized with respect to both reference genes, all estimates are not significantly different from zero. again, the various methods all agree and no substantial inter-method differences are seen and we find no evidence for differential expression of mmset between cell lines with high and low abundance of cics.

in all instances, the bootstrap distribution mean agree well with the estimates obtained using the delta or monte carlo methods while it seems to provide a larger standard error. this tendency have one or more probable explanations. the first order delta method and monte carlo approximations may underestimate the standard error and the bootstrap, corresponding to a higher order method, more correctly quantify it. more likely, the data deviate slightly from the model assumptions and the bootstrap is sensitive to this slight misspecification.

we see that the large number of dilution steps, as recommended and expected, ensures a low impact of the ae on the standard error and thus on the inference of the ŒîŒîcq.

dlbcl study
the cq-values and dilution curves for the dlbcl study are depicted in fig.  <dig>  panels a‚Äìb, respectively. analogous to the previous section, the differences in gene expressions assessed by the ŒîŒîcq for the target genes mir- <dig> and mir- <dig> with respect to each reference gene rnu6b and rnu <dig> were estimated using the four different methods. again  <dig> bootstrapped samples were used. the results are seen in table  <dig> 
fig.  <dig> overview of dlbcl testis data. a raw c
q-values for different patient samples for each gene type and sample type. the point type and colour differentiates the different gene types. b dilution data for reference genes  and target genes 
Œî
c
q-value


ec efficiency corrected lmm estimate ignoring the uncertainty of the efficiency estimates. ec&va <dig> ec and variance adjusted lmm estimate using the delta method. ec&va <dig> ec and variance adjusted lmm estimate using monte carlo integration. bootstrap estimate by the bootstrap described in section ‚Äúinference for ŒîŒîcq by the bootstrap method‚Äù fitting the lmm and using the ec estimate. bootstrap shows the mean and standard deviation of  <dig> bootstrap samples using the ec estimate. the last two columns show the  <dig> % lower and upper confidence interval limits



we notice the efficiency corrected estimates are exactly equal with and without variance adjustment, while the standard deviation of the estimate and the p-values are higher for the adjusted values as expected. the size of the increase is again undramatic hinting at well determined ae using the dilution curves.

for all combinations of reference genes the estimates for mir- <dig> are significantly different from zero at the usual  <dig> % significant level, but not at the  <dig> % significance level. the mir- <dig> estimates are not significantly different from zero. despite the very small increase in standard error, the p-values increase at the second digit.

the bootstrap method provides a standard deviation similar to the delta method and monte carlo integration for both mir- <dig> and mir- <dig> 

regarding the biological interest, we conclude there is evidence for a difference in mir- <dig> expression between testicular and nodal dlbcl whilst the data is not compatible with difference in mir- <dig> expression. while the ae estimate had no influence in these cases a change in significance is easily imagined in other cases.

arabidopsis thaliana data
the cq-values and dilution data for the arabidopsis thaliana data are shown in fig.  <dig> 
fig.  <dig> overview of arabidopsis thaliana data  <cit> . c
q-values against the dilution step for case and control samples. dilution data are present for both the target  and reference genes 



the estimated difference in gene expression between case and control of the target gene mt <dig> normalized to either reference  is seen in table  <dig>  the table shows the efficiency corrected method with and without variance adjustment by the delta method. in both cases, we see a dramatic increase in the standard error, p-values, and size of the confidence intervals. when using variance adjustment there is no longer a highly statistical significant difference in mt <dig> expression between case and ctrl growth conditions.Œî
c
q-value


ec efficiency corrected lmm estimate ignoring the uncertainty of the efficiency estimates. ec&va <dig> ec and variance adjusted lmm estimate using the delta method. the last two columns show the  <dig> lower and upper confidence interval limits



the results may be surprising at first sight when considering the relatively small standard errors of the slopes in the simple linear regressions shown in fig.  <dig>  one might imagine that the uncertainty of the ae is negligible and thus perform the usual analysis. however, we see the contrary for several reasons. first, using only  <dig> dilutions steps leaves very few degrees of freedom left in each group as we are left with few samples and a high number of parameters to be estimated. secondly, as dilution curves are used for each group the four group-specific ae estimates will all contribute to increasing the standard error of the ŒîŒîcq. while this example was selected as a worst-case scenario, it should illustrate that although the standard curves are seemingly well determined, it is hard to intuitively predetermine the combined effect on the standard error of ŒîŒîcq.

we note here, that no pre-averaging of the technical replicates for each concentration was done. instead, the technical replicates where modeled as a random effect.

simulation study
first, we present results of a simulation study for a two-sided test for the null hypothesis of a vanishing ŒîŒîcq at a  <dig> % significance level. we simulated  <dig> datasets under both the null and alternative hypothesis with  <dig> samples in each case and control group and standard curves with  <dig> dilution steps. the effect size under the alternative was set to Œ¥=10/ <dig>  the sample and experimental standard deviations were set to œÉs= <dig> and œÉ= <dig>  respectively. the ae for the target and reference genes were set to  <dig>  and  <dig> , respectively. the parameters were primarily chosen to conveniently yield estimates and error rates on a sensible scale whilst secondarily being comparable to estimated quantities in the applications.

the four discussed methods were applied to the 2√ó <dig> datasets and the p-value testing the null hypothesis were computed. the results of these tests are summarized in table  <dig> from which the fpr and tpr can be computed at the  <dig> % cutoff. from table  <dig>  we see the estimated fprs are  <dig> ,  <dig> , and  <dig>  for the efficiency corrected lmm , the efficiency corrected lmm with variance adjustment using the delta method , and the bootstrap, respectively. we omitted ec&va by monte carlo integration here due to the computational cost and the similar results with ec&va <dig> in the previous. as expected, the ec method does not control the fpr at the  <dig> %-level. the variance adjusted estimator is consistent with controlling the fpr at the  <dig> % level. by construction, the variance adjusted will always perform at least as good as the ec in terms of fpr. surprisingly, the bootstrap has the worst performance in terms of fpr.p-value threshold

h
0
h
a
h
0
h
a
h
0
h
a



the used estimators are the lmm with efficiency correction , the lmm with ec and variance adjustment , and the bootstrapped lmm approach



secondly, the tpr are estimated to be  <dig> ,  <dig> ,  <dig>  for three methods ec, ec&va <dig>  bootstr., respectively. as expected, we notice that an improved fpr comes a the cost of a decreased tpr for a given statistical procedure.

the above simulations were repeated for sample sizes  <dig> or  <dig> in both case and control groups in combination with  <dig> or  <dig> dilution steps with the same simulation parameters. figure  <dig> shows the performance of the methods in terms of fpr and tpr. each panel corresponds to a given number of samples and dilutions. in each panel the p-value cut-off is varied between  <dig> ,  <dig> , and  <dig> . overall, we see that the ec&va estimate is the only procedure consistent with controlling the fpr at the nominal chosen significance level. likewise, for many dilutions, the difference between the ec and ec&va procedures diminish as the uncertainty of the ae is relatively low. as expected a decrease in fpr corresponds to a decrease in tpr.
fig.  <dig> method performance. plot of the false positive rates  and true positive rates  and their  <dig> % confidence intervals achieved simulation experiments for each method at various p-value cut-offs  shown by solid red horizontal lines. the fpr and tpr are computed completely analogous to table  <dig>  the rates are plotted for each combination of  <dig> or  <dig> samples with  <dig> or  <dig> fold dilution curves



to gauge when the standard error of  is determined with adequate precision, we simulated 2√ó <dig> datasets and computed the mean standard error of the ŒîŒîcq for the ec and ec&va procedures as a function of the number of dilutions and samples. we varied the number of dilutions in the range 4‚Äì <dig> for a number of samples in the range 4‚Äì <dig> with the same settings as above. figure  <dig> shows these results. as expected, increasing the number of samples or the number of dilutions yield a smaller standard error. also unsurprising and as already seen in the applications, the differences in the standard error for the ec and ec&va methods are very substantial for a small number of dilutions and vanish as the number of dilutions steps increase. the differences in the standard error seems to be larger under the alternative than the null hypothesis. similar figures might also aid in designing qpcr experiments and help determine if investing in additional dilutions or samples is preferable‚Äîobviously with properly chosen simulation parameters in the given context.
fig.  <dig> standard error comparison. the mean standard error of the Œî
Œî
c
q for two methods  over  <dig> repeated simulations under the null  and alternative hypothesis  as a function of the number of dilution steps for a different number of samples in each group



discussion and 
CONCLUSIONS
the commonly used efficiency corrected ŒîŒîcq and many other approaches to the analysis of qpcr data disregards the uncertainty of the estimated ae leading to increased false positive rates. as qpcr experiments are often used for validation this is highly undesirable. our primary approach based on the statistical delta-method to approximate the variance of the efficiency adjusted ŒîŒîcq, shows that it is possible to perform statistical inference about qpcr experiments whilst more properly accounting for the ae uncertainty. we stress that the problem is not limited to the ŒîŒîcq statistic, but all statistics that depend on the ae.

in this paper, we focus on the widely used dilution curve approach as it is complex enough to capture the most important variations but also simple enough to be easily interpretable. this is probably also the reason dilution curves, when carefully used, are still very popular in qpcr experiments. however, this approach has been criticized in the literature as it relies on a number of assumption . first, the dilution curve approach assumes the ae to be constant up to the cq‚Äôth cycle. a way to check this is to assess whether the dilution curves are reasonably linear, as non-constant behaviour up to the cq‚Äôth cycle in our dynamic range would cause the dilution curves to level off. in our data examples, we do not see any violation of the linear behaviour. secondly, one also assumes the ae varies between wells. however, if we assume that the actual reciprocal ae Œ≥a varies around a true reciprocal ae value Œ≥, by a random variation Œì, say, which could be assumed to be gaussian distributed with mean  <dig> and variance œÉŒì <dig> one arrives at the following model for cq cq=Œº+n0+Œµ=Œº+Œ≥n0+‚èüerror term 

from this follows the proposed cycle dependent variation is captured by the error term in the lmm. we note, however, due to the multiplication with n <dig> a variance heterogeneity could be present. we have therefore assessed the lmms by plotting the residuals against the fitted values and noticed no variance heterogeneity to be present. in conclusion we find our model sufficient to capture the variation for the problems we have at hand.

in practice, the approach was used to:  validate that mgst <dig> is differentially expressed between mm cell lines of high and low abundance of cics,  analyze and study the hypothesis that mirna- <dig> is differentially expressed between testicular and nodal dlbcl, and  illustrate the effect of a small number of dilution steps.

in the latter application, we saw a dramatic increase in the standard error of the estimate when the variance approximation was introduced, potentially leading to a change of significance for the presented dataset depending on the desired significance level. this illustrates the importance of considering the ae uncertainty when conducting ae correction of qpcr experiments.

although not in the context of ŒîŒîcq estimation, tellinghuisen and speiss  <cit>  concluded that uncertainty as well as bias of the ae estimate substantially impacts subsequent quantities. they highlight that some methods achieve very good performance as measured by the low standard errors by tacitly assuming the ae known and fixed to  <dig>  this is an unsurprising consequence as it is essentially the same as disregarding the ae uncertainty. we also note, as seen in this paper, that a low standard error in itself is not always a proper benchmark of procedures.

problems with uncertainty in ae estimates should be handled by establishing well-estimated dilution curves as argued elsewhere  <cit> , however even in this case the presented method also allows for design guidelines for power calculations and assessing the influence of the estimated dilution curves.

it is also noteworthy that model based estimation of the ŒîŒîcq also allows for model checking by e.g. residual plots.

lastly, we note that the algorithm  <cit>  we used for threshold selection and cq-value extraction in the cic and dlbcl studies may not be optimal‚Äîcf.  <cit> , and improvements by  <cit> ‚Äîas it can be affected by the ae.

nonetheless, this has no bearing on the stated problem of this paper. the estimated standard error of ŒîŒîcq is still affected in a similar manner by the uncertainty of the ae and thus too optimistic.

despite the extensive use of qpcr, more statistical research is needed to establish qpcr more firmly as a gold standard to reliably quantify abundances of nucleic acids. researchers analyzing qpcr experiments need to model their experiments in detail, e.g. via linear or non-linear  models, as the propagation of uncertainty needs to be carefully assessed and accounted for. this is necessary for making valid inferences and upholding the common statistical guarantees often erroneously assumed to be automatically fulfilled. we recommend the conservative and proper approach of always accounting for the uncertainty of the ae.

supplementary material and software
the statistical analysis were done using the programming language rv <dig> . <dig>  <cit>  using lme <dig>  all data, r code, latex, and instructions for reproducing this present paper and results are freely available at http://github.org/aebilgrau/effadj/ using knitr, an extension of sweave  <cit> . functionality from the packages hmisc  <cit> , lattice   <cit> , epir  <cit> , snowfall  <cit> , and gmcm  <cit> , were used for tables, figures, fdr/tpr confidence intervals, parallel execution of simulations, and multivariate normal simulations, respectively.

competing interests

the authors declare that they have no competing interests.

authors‚Äô contributions

aeb developed statistical methods, implemented and carried out analyses, and drafted manuscript. sf aided in method development and analysis. ap conduced the dlbcl experiment and provided data. mk conduced the cic experiment and provided data. js, he, md provided experimental aid and biological feedback. mb provided statistical and methodological feedback, interpretation, and assisted in authoring the manuscript. all authors read, commented, and approved the final manuscript.

