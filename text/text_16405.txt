BACKGROUND
dna sequence comparison is a well studied problem in biology and bioinformatics  <cit> . recently, a new dna sequencing technology  has been developed which does not measure each base directly, but instead measures dna bases in pairs in an encoded form  <cit> . this technology has the potential to have greater error tolerance by differentiating biological variants from sequencing errors. in this manner, homer et al.  previously developed an algorithm to compare an encoded dna sequence to a target reference  <cit> , with a similar method independently derived in rumble et al.   <cit> . these two algorithms do not significantly differ and therefore the proposed algorithm is compared to the algorithm presented in homer et al. . this two-base encoding and resulting local dna sequence comparison algorithm can be utilized with global search strategies  <cit>  for whole-genome sequencing with next-generation sequencing technology  <cit> .

the central advantage of the two-base encoding scheme is that the false discovery rate of a single nucleotide polymorphism  is reduced, since two specific adjacent errors are required to produce a snp call. in fact, only one-fourth of all adjacent errors would result in a false call. this significantly reduces the probability of falsely observing a snp, with current machines exhibiting a color read error rate less than 5%. nevertheless, the currently implemented two-base encoding is not the only possible encoding. therefore a generalized k-base encoding scheme is presented, whereby k consecutive bases are simultaneously observed. the algorithm of homer et al.  is extended to solve the dna sequence comparison problem of comparing a k-base encoded dna sequence and a target reference dna sequence. intuitively, with greater k, the number of errors required to falsely discover a snp also becomes greater, thus allowing machine errors to be accurately identified, and even corrected, while retaining sensitivity to detect real base changes. simulations are performed to explore the improved power of higher order k-base encoding schemes, as well as the performance time when utilizing these encodings. these simulations explore the case for adapting k-base encoding schemes in ligation-based next generation sequencing technology.

RESULTS
simulations were performed to explore the power and performance of k-base encoding as well as the k-base encoding local alignment algorithm . reads were simulated using sequences both with a uniform error-rate, as well as using sequences with an error-rate modeled after real-world data. in this discussion,"1-base encoding" and "no encoding" are used interchangeably. the power to align a sequence with or without snps is defined as the fraction of reads where the read sequence is aligned to the reference with the same alignment score as if the sequence were aligned to the correct location . the fraction of reads where the read is aligned to call a snp, and where the original sequence had no snp, defines the false positive snp discovery rate. similarly, the fraction of reads where the read is aligned not to call a snp, and where the original sequence had a snp, defines the false negative snp discovery rate.

plotted in figure  <dig> is the power to align encoded sequences of varying length  with 0- <dig> snps or base substitutions given a fixed uniform error rate for k =  <dig> .. <dig> . the power decreases similarly for all read lengths as the error-rate increases given a fixed number of snps. furthermore, the power decreases substantially when the number of snps in the sequence is increased at a fixed error-rate and read length. the power of 1-base encoding, observing each base directly, does not diminish as much as k-base encoded sequences  when more snps are introduced. this is due to snps and observational errors being equivalent in the 1-base encoding case. in these simulations, k-base encoding is more powerful when k >  <dig> for  <dig> snps, when k >  <dig> for  <dig> snp, and when k >  <dig> for  <dig> snps and longer read lengths. it is important to note that in many cases when the alignment score between the best alignment and correct alignment differ, the decoded base sequences match. therefore, the false positive and false negative snp discovery rates are examined later.

to assess the power of k-base encoding utilizing real-world error rates, the color error  rates were estimated from a previous run of an abi solid v <dig> sequencer . the power of aligning such sequences was assessed in the presence of 0- <dig> snps for k =  <dig> .. <dig> . for sequences with no snps, the power of k-base encoding increases as k increases. however in the context of an increasing number of snps and for k >  <dig> the power of k-base encoding is more ambiguous. for one snp, k =  <dig> performs more poorly than no encoding, while k >  <dig> improves on the lower width encodings. for two snps, both k =  <dig> and k =  <dig> perform more poorly than no encoding, with only k >  <dig> having better power than no encoding. thus, error correction is increased with greater k when no snps are present. however, if the goal is to find variants, a large enough k must chosen carefully to justify the penalty in performance.

power calculated as the fraction of reads that correctly align.  <dig>   <dig> simulated  <dig> bp reads from the e. coli genome were generated with an estimated real-world error rate.

the false positive snp discovery rate is evaluated for  <dig>   <dig>  and  <dig> base-pair reads . with no encoding, snps and errors are not distinguishable, and therefore k =  <dig> is omitted from this discussion. as expected, the false positive snp discovery rate decreases as k increases. nevertheless, only above a five percent error rate does 2-base encoding begin to find false snps, and at approximately ten percent error rate do all encodings considered begin to falsely discover snps. assessed in figure  <dig> is the false negative snp discovery rate. similarly to figure  <dig>  the false positive snp discovery rate, the false negative snp discovery rate decreases as k increases. for low error rates, both of the above metrics are either zero  or are less than 20% . thus, the settings can be interpreted as being conservative, sacrificing power to find true snps for decreasing the false positive snp discovery rate.

to illustrate the flexibility of k-base encoding to be tuned for specific scenarios, the power of  <dig> base encoding is examined when the score for a color substitution is varied, and for  <dig>   <dig>  and  <dig> base-pair reads with  <dig> -  <dig> snps. intuitively, the various color substitution scores correspond to preferring a given number of color errors over a snp and possibly fewer color errors . as the color error score decreases, the encoding begins to prefer decoding with snps rather than with color errors. the various scoring schemes allow for a clear trade off in power to detect color errors over the power to detect snps . for example, the color substitution score of - <dig> allows the full correction of  <dig> bp reads with up to a 20% error rate. however, once a snp is introduced it has zero power. alter-natively, the color substitution score of - <dig> finds snps in the low error case, but with higher error data the power to detect only the given snp is confounded as more snps are falsely detected. with zero snps, color scores of - <dig>  - <dig>  and - <dig> have almost perfect power.

the performance time of k-base encoding scales exponentially with increasing k . this is confirmed by plotting the timing information from the previous uniform error-rate simulations . since the optimizations found in homer et al.   <cit>  are not pursued, increased variability was observed when the number of snps increased. however, an exponential increase in running time occurs as the encoding width  increases. this has practical implications, whereby producing empirical data that is k-base encoded is possible, but is computationally infeasible to decode as the number of short-reads is in the millions, if not billions for typical experiments.

performance time  of k-base encoding assuming a real-word per-base error-ate on  <dig> bp reads presented in table  <dig> 

nevertheless, this exponential increase in running time could be significantly reduced at the cost of completeness by using methods initially adopted for protein similarity search and sequence comparison  <cit> . a global search strategy is employed to put constraints on the possible search paths thereby significantly reducing the search space. typically these constraints force the alignment path to proceed along diagonals in the dynamic programming matrix, reducing the dimensionality of the problem. these constraints are specifically used in the implementation of bfast for both 1-base and 2-base encoded data  <cit> . the positions where the read and reference match during the bfast's global search strategy are annotated and aggregated such that in the local alignment the read and reference must match . in bfast's case, the global search strategy searches over an 2-base encoded reference for k =  <dig> constraining the color transitions. the constraints employed by bfast could be applied for k greater than two, yielding significant but unknown speed improvement.

CONCLUSIONS
the generalized k-base encoding scheme and resulting local alignment algorithm presented here have the ability to more powerfully differentiate between encoded sequencing errors and true dna variants. these schemes can be used in practice to tolerate high error rates in the raw data. alternatively, the per-base accuracy of sequencing can be improved. the goal in most sequencing projects is to sensitively and specifically detect variants. the technology and encoding scheme must not only have sufficient power to detect variants but to also not overwhelm the true variants with false variants. the results demonstrate that higher encoding schemes not only improve the power of detecting variants, but also significantly reduce the false positive snp discovery rate. having multiple observations of a specific variant or genomic co-ordinate  is in most cases able to overcome sequencing error. nevertheless, these encoding schemes could allow low coverage data to accurately detect variants. furthermore, for cancer specific studies, where the sample may be a heterogeneous population of cells, these encodings could reduce the minimum detection level  in the cancer cell population as the fewer observations can be more confidently trusted.

currently a two-base encoding system is used by abi solid sequencing technology. some other next-generation sequencing technologies could also adopt an encoding system to improve their performance and accuracy. furthermore, algorithms that perform multiple sequence alignment or local reassembly could also utilize the power of the encoding scheme presented here. it is interesting to note that error correction utilizing encoded dna sequence could be performed if single bases or sets of bases were observed more than once. utilizing various encoding schemes, this error correction would necessarily not rely on a target dna reference comparison, thereby eliminating the expensive exponential increase in time for higher order encodings . future investigation of such pre-alignment error correction schemes and algorithms is intended.

