BACKGROUND
a wide range of mass spectrometry techniques is available, of which matrix-assisted laser desorption and ionisation  and surface-enhanced laser desorption and ionisation   <cit>  coupled with time-of-flight  tubes are widely used for proteome screening. in both of these techniques a biological sample of interest, e.g., a serum sample, is applied to a plate or chip, left to incubate and subsequently co-crystallised with a matrix material. a laser is then fired at the co-crystallised mixture, causing it to desorb. the energy of the laser beam is transferred via the matrix to the analyte sample, thereby ionising it. an electrical field causes the desorbed and ionised material to fly through the tof tube. lower mass peptides travel faster through the tube than higher mass peptides, causing the former to arrive earlier at a detector placed at the end of the flight tube. using a quadratic equation, the mass to charge ratio  of a peptide can be calculated. because of the indirect  ionisation, laser desorption and ionisation is considered to be a "soft" ionisation method. as a consequence, most peptides will be single-charged, i.e., z =  <dig> 

the main difference between maldi and seldi is that the latter normally uses a chip with a chromatographic surface, making the purification of the sample implicit. for maldi, the purification needs to be done before application to the plate, for example through the use of chromatographic beads. data resulting from mass spectrometry measurements usually contain a substantial amount of noise and show large inter-measurement variation  <cit> . technical variance in mass spectra can be caused by a number of factors, including the pre-processing of samples in the wet-lab and the mass spectrometer itself. the best way to get maximal power from a statistical analysis is to minimise the level of experimental error and noise. variance introduced during the pre-processing stages should therefore be minimised as much as possible using strict lab protocols. furthermore, it makes sense to perform multiple replicate measurements of the same patient. doing so will give a better estimation of the "true" spectrum of a patient, leading to a better characterisation of the population.

independent of whether replicate measurements are performed or not, normalisation is usually conducted in order to increase comparability of spectra resulting from different measurements. normalisation of mass spectra typically entails subtracting an  offset and dividing by a scaling factor. such offset and scaling parameters can be defined and applied globally, over the full spectrum, or locally, using a sliding window, encompassing a contiguous subset of spectral positions. the rationale behind this is that the global approach may be better able to capture the general characteristics of the data, whereas the local approach may be beneficial for spectra with varying  noise levels.

although extensive effort has been devoted towards understanding and modeling the noise  <cit>  and variation  <cit>  observed in mass spectra, it is unclear which normalisation method is most favourable. here we perform an extensive comparison of  <dig> normalisation methods. please refer to the methods section for an overview of the methods evaluated. in a comparison of normalisation methods one should employ a measure of the reduction in inter-spectra variation after normalisation to assess the performance of different normalisation methods. however, this may actually promote degradation of the signal in case normalisation entails dividing the original spectrum by a quantity that is proportional to itself. in such a case, the resulting coefficient of variance will be low, although the amplitude of the remaining signal, will, of course, be very low as well; a situation that is clearly highly undesirable.

seldi and maldi are typically used for proteome profiling with the goal of finding biomarkers capable of discriminating between different classes of patients, for instance between healthy controls and cancer variants. to accomplish this, various classification techniques can be used to find  peaks with maximal discriminatory power. to safe-guard the presence of signal after normalisation, in this paper, classification performance is an important measure to compare normalisation methods, in addition to spectral variance. with the above in mind, we define a good normalisation method to be one that adheres to the following objectives:

 <dig>  minimises the variance between spectra;

 <dig>  maximises the classification signal, i.e., the association of spectra with their respective class labels.

to assess the first objective, the coefficient of variance between spectra is used. the second objective is measured using the performance of three classifier, or "classifier-like", systems. these are the globaltest, the support vector machine  with a radial basis kernel and a decision tree .

note that we assess both objectives separately, yielding two performance indicators, instead of combining them to yield one objective score. the reason for this is that the used objectives are partly conflicting, in the sense that a reduction in variance does not neccessarily lead to an improvement in classification performance. this makes it non-trivial to combine them in a straight-forward manner and forces one to attach weights to each of them, as also illustrated in additional file  <dig>  instead of choosing these weights ourselves, we prefer to let the reader decide which of the two objectives is most important.

RESULTS
for this comparison, four different real-world datasets representing two-class diagnostic problems have been analysed, before and after normalisation. for robustness, the pre-processing of spectra was performed using  <dig> different configurations, the product of seven methods for baseline correction and six peak detection approaches. normalisation of spectra using the  <dig> methods under study was carried out after baseline correction and prior to peak detection.

for each of the  <dig> configurations, both objectives, i.e., inter-spectra variance minimisation and classification performance maximisation, were assessed for each of the normalisation methods as well as for unnormalised data. this results for each normalisation method in two vectors of  scores, one for each objective, across all  <dig> pre-processing approaches and four datasets. please refer to the methods section for a detailed explanation of how these vectors  are obtained.

we used non-parametric paired wilcoxon signed rank tests on these vectors to compare all normalisation methods in terms of the two objectives. paired tests have been used to control for effects from the baseline correction methods, peak detection approaches and datasets used. we used one-tailed tests to obtain information on relative differences in scores between any two normalisation methods, i.e., whether one method is better than the next, an indicator of the performance of one method versus another. using two-tailed tests would only provide us with information on whether they perform significantly different. figure  <dig> depicts the results of this analysis, for both of the objectives. some methods perform consistently poorly for both objectives . others show a large difference in performance between the two objectives. a good example of this is the "local min range" method, which reduces the variance between spectra more efficiently than any other method, however this has consequences for the classification performance, which is very poor compared to other methods. this illustrates the shortcoming of exclusively minimising the inter-spectra variance and the need for a second objective to safe-guard signal quality. however, note that this second objective should also not be used exclusively, because it is biased towards the classification methods employed and is dependent on the actual datasets used, unlike the inherently unbiased first objective.

comparison to no normalisation
another way of looking at these results is by comparing all normalisation methods to the case where no normalisation is performed, i.e., the columns indicated by 'no normalisation' in figure  <dig>  figure  <dig> contains a quadrant plot, illustrating the performance of each normalisation method against unnormalised data in terms of both objectives, in more detail. the lower left area indicates improvement in both objectives, the lower right area improvement in variance reduction but a deterioration in classification performance and the upper right area a deterioration in both objectives. the shaded bands along the lines where p =  <dig> indicate regions where p â‰¥  <dig> , i.e., where differences in scores between the methods in these regions and using unnormalised data are not significant.

as becomes apparent from the figure, the majority of normalisation methods lie within the  lower left region, indicating that they significantly outperform the case when no normalisation is used. an interesting observation here is that the default normalisation method used by most seldi users  slightly reduces the variance but does not improve classification performance significantly with respect to unnormalised data.

per-classifier performance
in order to study what the contribution of individual classifiers is to the overall results, we repeated the statistical analysis for each classifier separately. since the classifiers employed were chosen from a wide range of classification modalities, this analysis will yield insight into the effect of the choice of classifier on the overall ranking of the methods. the results are depicted in figure  <dig>  we notice that some normalisation methods cause signal degradation for svm, placing them in the lower-right area of the quadrant, albeit not significantly worse than employing no normalisation. we further notice that none of the methods perform significantly better than using no normalisation for all classifiers. this is largely due to the cart classifier, which has most of the normalisation methods in the  shaded areas. as indicated by the range of p-values on the x-axes of the quadrant plots, the increase in classification performance due to normalisation is much lower for cart than it is for the globaltest and svm, suggesting that cart is less sensitive to normalisation or is simply incapable of finding the 'good' features, and can therefore not exploit the features where normalisation does show an effect. a paired one-tailed wilcoxon signed rank test on the raw, i.e., unranked, cross validation classification errors yielded by svm and cart reveals that svm performs significantly better than cart overall , suggesting the latter.

global vs. local normalisation methods
the normalisation methods we studied employ two parameters, an offset and a scaling parameter. the methods can be divided into two groups, depending on whether they are based on global or on local estimates of characteristics of the data. to study whether this parameter  has a significant effect on the two performance objectives, we compared the performance of these two groups of methods. this was done by pairing the performance ranks obtained for local methods with those of their global counterparts, e.g., "local zero mean" was paired with "global zero mean", for each of the two objectives. we then used the wilcoxon signed rank test to test the null-hypothesis that the number of cases in which a method from one group outperforms its paired method from the other group is equal to the number of cases in which the opposite is the case.

we used one-tailed tests to be able to assess which of the two groups performed statistically significantly better. this resulted in two p-values per objective, which were corrected for multiple testing using the bonferroni method. figure 4a shows these values, also indicating the used pairings between local and global methods. global methods are shown in black and local methods in red. we see that for both objectives local methods provide an advantage over global methods . note that this may not be obvious from looking at figure 4a alone, particularly for the classification performance, because the placement of methods in this figure indicates the performance relative to using no normalisation.

offset and scaling parameters
a number of the normalisation methods studied use a zero-valued offset parameter. to study the influence of this on the performance, we again divided the methods into two groups, i.e., methods that employ a non-zero parameter versus those for which this parameter has been set to zero. we used a two-sample wilcoxon rank sum  test to test the null-hypothesis that the two groups outperform the case in which no normalisation is performed, an equal number of times. as before, we tested both tails separately for both objectives, resulting in four p-values, again corrected for multiple testing using the bonferroni method. figure 4b shows these values, indicating no significant effect for either of the two objectives.

the same analysis was done for the scaling parameter, which can also be divided into two groups; one containing methods that use the central location of the data  and another containing methods that use some measure of dispersion of the data around that central location  range). figure 4c shows that there is a significant difference here; in terms of both variance reduction  and classification performance  it is beneficial to choose a scaling parameter based on the dispersion of the data.

CONCLUSIONS
we have performed a systematic comparison of  <dig> normalisation methods for  mass spectrometry data. for robustness, a large number  of configurations for baseline correction and peak detection methods was used, as well as multiple datasets. we used two objectives to assess the benefit of applying a particular normalisation method, namely minimisation of inter-spectra variance and maximisation of classification performance. the latter has proven to be very helpful in safe-guarding against methods that reduce the variance between spectra but at the same time do not improve, or even worsen, the amount of meaningful signal left after normalisation.

we have shown that in the general case, normalisation of mass spectra is beneficial to both objectives; most methods we compared performed significantly better than the case in which no normalisation was used. we have shown that normalisation methods that scale spectra by a factor based on the dispersion  of the data clearly outperform those where a factor based on the central location  is used. additional improvements in performance are obtained when these factors are estimated locally, using a sliding window within spectra, instead of globally, over full spectra. the underperforming category of methods using a globally estimated factor based on the central location of the data includes the method used by the majority of seldi users, i.e., "global zero mean".

