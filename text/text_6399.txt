BACKGROUND
in the past decade, genetic locus discovery for human traits and diseases has been advanced via genome-wide association studies . recent improvements in technology to produce genotype data in a very cost- and time-effective manner and powerful easy-to-use software tools have played a major role in these advances, facilitating fast analysis of constantly increasing amounts of data. clearly, the next advances in the field of genomics will be based on large-scale sequencing and other high-dimensional omics data. a key challenge for successful utilisation of these data lies, once again, in the availability of powerful methods and user-friendly software tools, thus enabling researchers to make rapid discoveries  <cit> .

large-scale sequencing efforts, such as the  <dig> genomes project  <cit>  or more recently the uk10k project  <cit>  and the haplotype reference consortium  <cit> , have enabled better characterization of variation in the human genome, especially in the low-frequency and rare variant range. here, we denote all variants with minor allele frequency, maf < 5%, by rvs. imputation based on variant density detected by these projects yields high-quality genotype data even down to  <dig> % allele frequency  <cit> . large scale sequencing data generation encourages method and software development for elucidating rv effects, since traditional single-variant methods are underpowered to detect rv associations. several methods and related software tools have been proposed, including burden tests using collapsing techniques, variance-component tests and combinations of the two  <cit> .

there has also been increasing interest in addressing analysis of high-dimensional phenotypic and omic data, such as metabolomics, in relation to human genome variation. multi-phenotype analysis , i.e. joint analysis of multiple phenotypes, is an example of recent developments in the field. several methods and related software for single-variant mpa, including bayesian and frequentist approaches, have recently been published  <cit> . the mpa approach is motivated by several factors: 1) it boosts power for locus discovery ; 2) it provides more precise parameter estimates  <cit> ; and 3) it has biological advantages including the possibility to identify multi-phenotype effects, including pleiotropy  <cit> , when one locus affects multiple phenotypes. the power improvement by the mpa approach is especially relevant from a computational point of view, because to enable the discovery of further loci for complex traits, the analyses will need to be based on hundreds of thousands of individuals, such as those available from the uk biobank and other new large-scale efforts based on sequencing. storage and computational load for such amounts of data will pose a challenge, and alternative strategies for boosting power for locus discovery other than that of increasing sample size, clearly bring an enormous advantage.

we propose a novel tool marv for rv mpa, which enables joint analysis of both large-scale high-dimensional genomic and phenotypic data. it extends the burden test for rvs to high-dimensional phenotypic data by applying the mpa approach. recently, methods designed for mpa of rvs have been proposed , but these have several limitations regarding scalability and ability to combine continuous and discrete phenotypes, and more importantly, the associated software: they either lack an easy user-interface or are computationally inefficient – key features to facilitate fast discoveries. our software tool marv enables analysis of both continuous and binary phenotypes, as well as genotyped, imputed or sequenced data. marv is computationally efficient for large-scale data. from a user point of view, it enables standard formats of data as used in other gwas software, and the analyses are run using a command line interface, also familiar from widely used gwas software such as plink  <cit>  and snptest  <cit> , thus enabling researchers quickly and effortlessly to transit from the standard single variant, single phenotype gwas to region-based analysis of multiple phenotypes.

implementation
the method on which marv is based is briefly introduced in methods, and is extensively described, including power simulations, elsewhere  <cit>  . marv is written in c++ and has a command line user-interface. a single run of marv consists of just one step and the required input files, commands and the resulting output files are described below.

data input and commands
marv requires three files for a successful run: sample, genotype and genomic region input files . the sample and the genotype input files should be in the snptest v <dig>  <cit>  format. the genomic region file should contain three columns: the name of the region, and the start and the end positions for the region. it is important that the positions in this file correspond to the positions of the genotype file, i.e. the same genome build for these two should be used .fig.  <dig> workflow of a marv run including required files, commands and resulting output files


fig.  <dig> examples of the required input file formats for marv and the resulting output files




the user then needs to specify the phenotypes to be analysed , corresponsing to a column name in the sample file, and the method to use for the analysis, i.e. whether to analyse the genotype dosages derived by the software from the imputation probabilities  or whether to use the thresholded genotypes based on a pre-defined cut-off  . additionally, the user may specify several other options, such as individuals or snps to extract or exclude from the analysis. it is important to specify the threshold used for the minor allele frequency . all the available options of the latest version of marv can be found from the online manual of marv.

data analysis
marv works across the genome by going through the specified gene regions one by one. based on the gene boundaries and desired rare variant cut-off, it calculates, for each individual, the proportion of minor alleles at rare variants within the region  <cit> . after this calculation is performed for all individuals, a linear regression is fitted using the proportion as the outcome and the listed phenotypes as its predictors. the likelihood contribution of each individual is further weighted by the number of successfully genotyped/imputed rvs in the region of interest. for each genomic region, weighted linear regression is performed for all different phenotype combinations, i.e. if a user specifies phenotypes pheno_a and pheno_b, three different models for the proportion are fitted with the following predictor combinations: 1) pheno_a + pheno_b, 2) pheno_a, 3) pheno_b. marv calculates the bayesian information criterion  for each model to help the user in identifying the best fitting phenotype combination.

output files
marv produces three files by default:.error file,.log file and.result file . the error file will be empty if the run was completed successfully; otherwise details about problems during the run are reported . the log file will give specific details of the analysis, including the number of samples in the sample file and genotype file, and the number of phenotypes used for the analysis. it will also include the variants included for the analysis of each genomic region, along with their mafs. the results file will include one row for results per each genomic region. if the user specifies printing of all the possible model combinations  there will be as many rows per gene as there were different model combinations fitted. this file will inform the log likelihood and bic of the model as well as the p-value for each model. we note that the p-value is uncorrected for any multiple testing. if the user is interested in the effect estimates and their standard errors for each of the model members, i.e. phenotypes included in the fitted model, a separate.betas file can be requested  . a complete list of the columns in the output file with their meanings is provided in the online tutorial of marv.

case study
to illustrate the use of marv across the genome, we have applied it to data from the northern finland birth cohort  <dig> , which covers over 96% of all births in the two northernmost provinces of finland in  <dig>   <cit> . we included data from  <dig>  cohort members who had participated in the 31 year clinical examination and had genetic data as well as data on triglycerides , fasting insulin  and waist-to-hip ratio . the ethics committees of the university of oulu and northern ostrobothnia hospital district have approved the study. individuals used for the analyses have provided written, informed consent.

motivation for the selection of the traits comes from a common variant single-trait gwas, which has shown an enrichment of fi associations among snps preselected on metabochip for tg and waist phenotypes  <cit> . for the selected traits, we applied the following criteria: 1) fg: exclude non-fasting individuals and/or those having type  <dig> or  <dig> diabetes mellitus or on diabetes treatment or having fasting blood glucose ≥ 7 mmol/l and/or being pregnant, 2) tg: exclude non-fasting and/or individuals known to be on lipid lowering medication. we modelled each trait on sex, body mass index and the first three principal components derived from the genetic data to control for potential population structure. an inverse normal transformation was further applied to the residuals of whr and tg to reduce skewness.

dna was extracted from blood samples drawn after overnight fasting at the 31 year clinical examination. genotyping was performed with the illumina humancnv370duo analysis beadchip platform at the broad institute, usa, with beadstudio algorithm being used for genotype calling. detailed genotyping and sample quality control  of the first set of data have been reported before  <cit> . additional samples were genotyped afterwards, resulting in  <dig>  subjects and  <dig>  snps available for analysis. the  <dig>  genomes project “all ancestries” reference panel  was used for imputation, resulting in ~38 m snps for analysis.

we analysed the transformed residuals in marv with the method “threshold” , i.e. genotypes with probability of  <dig>  or higher were considered called, whilst all others were considered missing. the gene list from the university of california santa cruz   <cit>  was used to define gene regions, and a level of significance of  <dig>  × 10− <dig> was adopted based on a bonferroni correction for  <dig>  genes. we analysed all variants irrespective of their annotation across autosomal chromosomes using the following cut-offs: maf < 5% and imputation quality >  <dig> .

RESULTS
case study
the three selected phenotypes, fi, tg and whr, were modestly correlated with each other . the multi-phenotype analysis of the three phenotypes revealed genome-wide significant associations covering two gene regions on chromosome 11: at apoa <dig>  and at znf <dig>  genes . besides the full model, marv also provides parameter estimates and tests of associations for each phenotype combination, including the single phenotype models. therefore, we were able to compare the results from the joint analysis against traditional single phenotype analyses. additionally, the bic provided by marv for each sub-model served for selection of the phenotype combination providing the best fit. at apoa <dig>  the best fitting model according to bic contained tg only , while at znf <dig>  the model with fi and tg provided the lowest bic and hence support for the best fit  . the model with fi and tg provided a lower p-value compared to those obtained from univariate models , suggesting that at least the association with fi would have been missed in univariate analyses. the effects of tg and fi on the rare allele load were in opposite directions: while the increase in tg levels was associated with a greater proportion of minor alleles within znf <dig>  the opposite was true for fi. this was true also for the univariate models . all results files outputted by marv are available as additional files  <dig>   <dig>   <dig> and  <dig> table  <dig> results for loci reaching genome-wide significance in the multi-phenotype rare variant analysis of nfbc <dig> . regression coefficients with their standard errors  are reported, followed by the p-value and the bayesian information criterion  for the analysed model. tg, triglycerides; ln, natural logarithm transformed fasting insulin; whr, waist-to-hip ratio

apoa5

znf259

tg + ln + whr, full model a
univariate b

a for a genome-wide joint analysis, the level of significance is p <  <dig>  × 10− <dig> after bonferroni correction for  <dig>  genes


b for univariate analysis, the level of significance is p <  <dig>  × 10− <dig> after bonferroni correction for  <dig>  genes and three phenotypes


fig.  <dig> qq-plot of marv analysis results on triglycerides, fasting insulin and waist-to-hip ratio in the nfbc1966


fig.  <dig> manhattan plot of marv analysis results on triglycerides, fasting insulin and waist-to-hip ratio in the nfbc <dig>  genes reaching genome-wide significance  are annotated




common variants at these two identified genes have previously been associated with tg, total cholesterol, high-density lipoprotein, low-density lipoprotein, apolipoprotein a <dig> and b, coronary heart disease, coronary artery disease, plasma viscosity, lp-pla <dig> activity, prostate cancer, and circulating vitamin e levels . a recent large-scale gwas also reported rv associations at znf <dig> with triglyceride levels  <cit> . our analysis pointed to multi-phenotype effects with tg and fi. a recent study in japanese individuals showed evidence for associations between variation in znf <dig> and type  <dig> diabetes  <cit> , making this locus of interest for further investigation in the pathogenesis of the disease. interestingly though, in our mpa the effects of tg and fi on the rare allele load at znf <dig> were in opposite directions, contrary to our expectations, since elevated tg levels usually correlate with elevated rather than decreased fi levels.

running time and memory
we measured running time and memory usage of marv by performing additional analyses on the nfbc <dig> data with different number of individuals, phenotypes and on different sized chromosomes. for these analyses, we used  <dig>  and  <dig>   individuals with complete data on eight continuous phenotypes. we analysed a combination of two, four and eight continuous phenotypes and used  <dig> genomes imputed chromosomes  <dig> and  <dig> data for the association analyses. all analyses were run and their performance data were collected using imperial college hpc cluster. compute nodes were equipped with intel xeon cpu e5- <dig> v <dig> @  <dig> ghz machine.

the results are summarised in table  <dig>  we observe that the size of the genomic region to be analysed notably affects the running time. however, there is not a linear relationship between the number of phenotypes and the computation time required. for example, the increase in time for chromosome  <dig> is just under 3 h  even when the number of phenotypes is doubled from four to eight and the number of models to be fitted is more than 20-fold. doubling the sample size roughly triples the runtime.table  <dig> computational time and peak memory usage of marv by varying sample size, chromosomal size and number of phenotypes






the memory usage of marv is more related to the size of the genetic data and number of individuals to analyse rather than the number of phenotypes to analyse. in our example, the peak memory usage was almost constant for all chromosome  <dig> and  <dig> analyses when the sample size remained the same, independent of the number of phenotypes in the model . considering the size differences of these two chromosomes , we note that the increase in memory usage is not linear, however.

CONCLUSIONS
our novel tool marv allows for rv analysis of multiple phenotypes in a computationally efficient and user-friendly manner. the data input formats and the command line interface familiar from widely-used gwas software will offer researchers a quick setup for the analyses. moreover, the feature of analysing all phenotype combinations within one run and the calculation of bic to help in model selection will pave the way for rapid discoveries and novel insights into biology of complex traits.

