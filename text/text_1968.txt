BACKGROUND
the ability to determine genotypes using molecular markers has provided a wealth of genetic information in numerous fields of study. in many biological fields genotype information is now critical in the decision making process. due to the time and cost associated with these decisions, having accurate and reproducible data is essential. technology improvements and reduced costs have resulted in genotype information increasing exponentially. as datasets grow larger it is inevitable that genotyping errors will occur
 <cit> . genotyping errors can be defined as a situation in which the observed genotype differs from the real genotype of an individual
 <cit> . however, determination of the actual genotype of an individual is rarely possible and therefore genotyping errors are more often assayed by comparing genotypes obtained independently from the same individual. while genotyping error is understood to be a common occurrence in molecular genetic studies, few studies within the current literature document error rates associated with experiments
 <cit> . the causes of genotyping errors can be numerous but are often associated with human error, scoring limitations, and biochemical anomalies
 <cit> . as the number of samples and reactions increase, it can be expected that the number of erroneous genotypes within a dataset will also rise. methods for controlling and identifying genotyping errors include standard experimental design procedures of randomization, replication, and proper controls
 <cit> . as a result of these efforts genotyping error can be reduced, but is rarely eliminated within dna marker datasets.

amplified fragment length polymorphism  is a popular dominant dna marker technique that has been used for many different applications since its introduction nearly twenty years ago
 <cit> . the technique is based on cleaving whole dna using restriction enzymes, followed by pcr amplification of a subset of the cleaved fragments using selective primer combinations. scoring of aflp markers is subsequently based on the presence or absence of an amplified fragment. an aflp locus is defined as a specific fragment size having either the present or absent allele. applications of aflp markers and their analysis have been thoroughly reviewed in the literature
 <cit> . while next-generation sequencing has created a wealth of genetic information, the aflp technique continues to provide useful information for numerous experimental questions. this continued use of the aflp technique is largely due to its ability to screen a large number of genomically representative markers at a substantially lower cost compared to other techniques within non-model species with few genomic resources
 <cit> .

the introduction of aflp fragment analysis using capillary electrophoresis has increased both the throughput and the quality of aflp data
 <cit> . this system has also increased the resolution at which fragments can be separated and therefore has resulted in a substantial increase in the number of fragments that can be used in analyses relative to gel electrophoresis. with the development of automated scoring software, fragments can now be compared at an ever-increasing resolution and error at the genotype calling stage can be greatly reduced
 <cit> . despite the error reduction at the genotype calling stage increased resolution may lead to the use of spurious fragments and other non-reproducible data. both of these situations could contribute to an increased error rate within the dataset.

within current aflp literature, the existence of relatively high genotyping error is well documented
 <cit> . despite the high potential of genotyping error, reporting of error rate within aflp datasets is rare. being a dominant marker, only the presence or absence of a band is observable within aflp datasets, therefore, error rate is estimated by calculating the ratio of observed differences between replicate samples and the total number of comparisons
 <cit> . use of all available loci in an analysis likely includes loci that have multiple erroneous alleles, possibly leading to incorrect conclusions or potentially increased amounts of noise within the dataset.

if error rate varies between loci, it is desirable to be able to identify those loci that have greater estimated amounts of error and remove those from the dataset. previous studies have demonstrated inaccurate population substructure patterns in both datasets with high genotyping error rates and datasets using selected loci with very low error rates
 <cit> . these results suggest that a tradeoff exists between reducing error rate and maintaining loci with high information content.

the objective of this paper is to outline a logical and computationally simple method for selecting loci that accounts for differences in error rate based on the frequency of present alleles at a given locus. it is hypothesized that by selecting loci using this method, error rate within an aflp experiment can be reduced, thereby reducing the number of erroneous genotypes within a dataset while maintaining genomic diversity. this reduction in erroneous genotypes is expected to increase discrimination between differing samples and improve the ability to detect genetic differences of interest.

RESULTS
selection of loci with reduced error rate
big bluestem is a warm season grass native to the north american prairie. from a geographically diverse panel of  <dig> big bluestem samples previously used in a study of genetic diversity,  <dig> samples were replicated and used in independent aflp analyses
 <cit> . samples represented individual plants from  <dig> populations originating from three groups . nine ecori/msei primer combinations were used for selective amplification resulting in  <dig> polymorphic loci with a mean of  <dig>  loci per primer combination. locus-specific error rate ranged from 0% - 62%, although more than half of the loci had error rates less than 10% . the estimated error rate per primer combination ranged from  <dig> % -  <dig> % with a mean of  <dig> %. the number of present alleles per locus ranged from  <dig> to  <dig>  with a mean frequency of  <dig> .

simple regression using a second-degree polynomial term was used to model the relationship between error rate and the frequency of present alleles. the resulting model for this analysis was y= <dig> + <dig> x − <dig> x <dig>  . using this model all loci with error rates greater than predicted by the model were removed from the analysis. a total of  <dig> loci were removed using this procedure . the removal of these loci resulted in a reduction of the mean error rate to  <dig> %, a 29% reduction in error rate compared to using all loci. the mean frequency of present alleles increased slightly to  <dig> .

following the same procedures regression analysis was repeated on the  <dig> loci selected under the first model. this analysis resulted in a second model predicting error rate from the frequency of present alleles, y=− <dig> + <dig> x − <dig> x <dig>  . again, those loci with error rates greater than predicted by the model were removed from the analysis. using this procedure  <dig> loci were removed, reducing the number of loci to  <dig> . the mean error rate of the remaining loci was  <dig> % and the mean frequency of present alleles was  <dig> . additional rounds of selection were not initiated due to the limited numbers of loci that would have been available after further rounds of selection.

for comparison, locus selection was also conducted using fixed thresholds of 20%, 10%, and 5%. using these thresholds, all loci having error rates greater than the threshold were removed from analysis. mean error rate was reduced dramatically, deceasing to less than 2% using the most conservative threshold . while using a fixed error rate threshold reduced error and maintained a high number of loci, it came at the expense of a decrease in the mean allele frequency, reducing the mean from  <dig>  per locus to  <dig>  per locus. this reduction in mean allele frequency indicates that by using a fixed error rate threshold the dataset becomes dominated by loci with low allele frequencies.

testing
significance of the observed changes due to selection was tested by permutation test, randomly selecting  <dig> loci from the original  <dig> loci. this procedure was repeated  <dig> times, creating a distribution of error rate for randomly selected loci . the mean error rate of the permuted selections ranged from  <dig> % -  <dig> %, with a mean of  <dig> %. error rate of the loci selected using model  <dig> was  <dig> %, significantly different from the bounds of the permuted null distribution .

implementation
analysis of molecular variance analysis  was used to test the practical significance of the observed reduction in error rate. three separate analyses were conducted on  <dig> big bluestem samples using different subsets of loci:  the original loci,  the loci selected under model  <dig>  and  the loci selected under model  <dig>  samples represented individual plants from  <dig> populations originating from three geographic groups 
 <cit> . variance was partitioned in a hierarchical manner among groups, among populations within groups, and plants within populations. using loci selected under model  <dig> amova analysis demonstrated an increase in the variance explained among groups, increasing from  <dig> % to  <dig> % . using loci selected using model  <dig> the percentage of variance explained by populations within groups increased from  <dig> % to  <dig> % and variance among groups increased from  <dig> % to  <dig> %. the observed changes in the amount of explainable variance demonstrate that the locus selection procedure has practical effects, in this example resulting in increased power to detect difference between groups and populations. due to the geographic isolation of the populations tested in this example some amount of genetic divergence was expected. by removing more error prone loci from the dataset evidence of this divergence is more apparent.

all variances were significant  based on permutation test.

using the fixed rate error thresholds, changes to the amount of variance explained within in the amova analysis differed from those observed using the moving error rate threshold. variance explained by populations within groups increased as the error rate threshold became stricter, from  <dig> % to  <dig> % . in contrast, variance explained among groups decreased from  <dig> % to  <dig> % by using a more strict error rate threshold . this decrease in the amount of explainable variance and the observed difference from the results using the moving error rate threshold may be due to the major reduction in moderate frequency alleles that resulted from using a fixed error rate threshold.

all variances were significant  based on permutation test.

discussion
increasing numbers of aflp loci require that discretion be used in selecting loci for further analysis. ideally, selected loci should be reproducible and have as low of error rate as possible while maintaining genomic diversity. it is therefore essential that a method be in place for determining which loci best fit these requirements. the method proposed in this paper uses a simple regression approach to implement a moving error rate threshold that is optimized based on the frequency of present alleles at a given locus. by using the frequency of present alleles and simple regression models an error rate threshold can be set that is both computationally simple and accounts for the relationship between the frequency of present alleles and error within a given dataset. with the widespread use of the aflp technique in various species and differing equipment with various protocols, a customizable error threshold accounts for technical marker variation that may be unique to an individual dataset.

the need for a moving error rate threshold can be demonstrated within the example dataset of replicated big bluestem aflp markers. when a fixed error rate threshold  is used the majority of the selected loci are those with extremely high or low frequencies of present alleles. this effect is easily observed within a scatterplot showing the relationship between frequency of present alleles and error rate . using the fixed rate threshold of 20% reduces the frequency present alleles by 48% to  <dig>  . this reduction is even more drastic if a threshold of 5% is used, reducing the frequency of present alleles to  <dig>  . use of a fixed error rate threshold effectively eliminates loci with moderate frequencies of present alleles, therefore introducing bias into the selection process. it is important that these moderate frequency alleles be included, as those loci having high or low frequencies of present alleles only represent relatively rare alleles. in contrast, loci having a moderate frequency of present alleles represent common alleles. these common alleles are often those that are important for distinguishing differences between groups and populations of samples that differ largely in allele frequencies. if loci with moderate frequencies of present alleles are removed, the ability to distinguish between populations may be diminished.

the effectiveness of the proposed locus selection method for reducing error rate was demonstrated using an aflp dataset resulting from experiments to test the genetic diversity of the prairie species big bluestem. by using a simple regression model with a second-degree polynomial term to set the error rate threshold, error rate within the dataset was reduced from  <dig> % to  <dig> %. applying the same technique to selected loci resulted in an additional decrease in error rate to  <dig> %. overall the use of the proposed methods reduced error rate by more than one half. prior to locus selection this dataset had an error rate that would have been considered relatively high. by using model  <dig> to select loci, the error rate was lowered to a level that is within the range typically found in an aflp datasets
 <cit> . comparatively, the use of fixed rate error thresholds was very effective at reducing error rate, reducing error rate to  <dig> %,  <dig> %, and  <dig> % for respectively for thresholds of 20%, 10%, and 5% . despite these large decreases in mean error rate, one must consider the tradeoff that is made between reducing error rate and maintaining genomic diversity. the use of fixed error rate thresholds dramatically decreased the mean frequency of present alleles compared to the use of a moving error rate threshold in model  <dig> and model  <dig> . this reduction indicates that the majority of loci conserved using fixed error rate thresholds have very low frequencies of present alleles. by using theses loci in further analyses much of the genomic diversity that exists within the dataset is lost. previous studies have demonstrated that larger datasets having higher error rate can yield greater information than a small number of loci with little error
 <cit> . this reduction in information content may be related to the reduction of loci with moderate allele frequencies, as a result of using fixed error rate thresholds.

equally important to lowering error rate to acceptable levels is the effect that reduced error can have on the ability to eliminate noise in the dataset and increase the ability to detect differences between samples. in the example shown in this paper, locus selection resulted in increased differentiation between samples from differing groups under model  <dig>  using model  <dig> the ability to differentiate between samples from differing populations within groups also increased. in contrast, the use of fixed rate error thresholds decreased the amount of observable differentiation among groups to levels lower than observed without locus selection. in this example the differences in differentiation observed using the moving error rate thresholds made a major contribution to the understanding of big bluestem diversity in the tested samples
 <cit> . it can be expected that results of a similar magnitude will be observed in other aflp datasets.

CONCLUSIONS
high error rates within aflp datasets can cause increased noise and possibly incorrect conclusions. using an arbitrary error rate threshold to remove loci with high error rates can bias locus selection by removing moderate frequency alleles. this paper demonstrates the use of simple regression to model the relationship between error rate and the frequency of present alleles. these models create moving error rate thresholds that can be subsequently used for selecting loci for use in future analyses with reduced error rates. in the present example, using loci selected with the proposed method resulted in a reduction in mean error rate for aflp markers in big bluestem. in addition to reducing error, the removal of loci with high error rates from the dataset increased differentiation between samples from differing groups and populations.

genotyping errors within aflp datasets have been shown to be nontrivial. despite this, error rates for aflp datasets are rarely measured or reported. the use of a locus selection procedure such as those proposed carries with it an inherent tradeoff between reducing error rate and maintaining genomic diversity. this tradeoff must be balanced as the reduction of genomic diversity resulting from arbitrary or strict locus selection may introduce bias in a dataset by removing informative alleles. equally, the inclusion of substantial genotyping error may reduce power to detect differences within a dataset and will reduce repeatability. within the example dataset in this paper two rounds of selection were considered appropriate due to the large number of loci, high initial error rate, and the goals for this data. within other datasets the number of rounds of locus selection may need to change in order to meet the objectives of an individual study and the mean error rate that is acceptable for a given study. the proposed methods provide a tool that researchers can use to better understand genotyping error within aflp datasets, leading to improved reproducibility and greater ability to discern genetic differences.

