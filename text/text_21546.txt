BACKGROUND
to identify a set of proteins as a functional protein complex is essential for understanding molecular systems in living cells. several proteins form a complex and work as a transcription factor, whereas there exist another type of proteins that work as enzymes. hence, to identify proteins that constitute such transcription factors is useful for uncovering gene regulatory networks and metabolic pathways. many computational methods have been developed for predicting protein complexes from protein-protein interaction networks  <cit> . enright et al. developed the markov cluster  algorithm  <cit> , which repeatedly executes two operators called expansion and inflation to a matrix whose element represents the transition probability from a protein to another. the expansion operation takes the power of the matrix, and the inflation operation takes the hadamard power of the matrix. mcl is fast and efficient because of these operations. macropol et al. developed the repeated random walks  method  <cit> , which iteratively expands a cluster depending on the probabilities in steady states of random walks with restarts. maruyama and chihara improved the rrw method by weighting the restart probabilities and proposed the node-weighted expansion  method  <cit> . bader and hogue developed the molecular complex detection  method  <cit> , which uses a modified clustering coefficient defined by edge density in a subset of the original and adjacent vertices to find densely connected regions. king et al. developed the restricted neighborhood search clustering  method  <cit> , which selects clusters generated by a cost function according to the cluster size, density and functional homogeneity. altaf-ul-amin et al. developed dpclus  <cit> , which tries to find densely connected regions. chua et al. developed the protein complex prediction  method  <cit> , which finds maximal cliques using the functional similarity weight based on indirect interactions. liu et al. developed the clustering based on maximal cliques  method  <cit> , which generates all maximal cliques from the protein-protein interaction networks, and assembles highly overlapped clusters based on their interconnectivity. wu et al. developed the core-attachment based  method  <cit> . most methods basically focus on finding densely connected subgraph in protein-protein interaction networks. hence, it is considered to be difficult that they detect small protein complexes because, for instance, the edge density of two interacting proteins is always  <dig>  even if the proteins do not form a complex.

however, protein complexes with small sizes occupy a large part of whole known protein complexes. cyc <dig> is a comprehensive catalogue of  <dig> manually curated yeast protein complexes  <cit> . in the catalogue,  <dig> complexes  are heterodimeric, and  <dig> complexes  are heterotrimeric as reported also in  <cit> . in our previous study, hence, we developed a method using our proposed kernel for predicting heterodimeric protein complexes  <cit> , which outperforms an existing method using the naive bayes classifier  <cit> . in this paper, we propose prediction methods for heterotrimeric protein complexes by extending techniques in our previous method on the basis of the idea that heterotrimeric protein complexes are not likely to share the same protein with other heterotrimeric protein complexes. for that purpose, we apply supervised learning methods twice such as support vector machine   <cit>  and relevance vector machine   <cit> . tatsuke and maruyama developed the proteins' partition sampler  method based on the metropolis-hastings algorithm, which generates clusters whose sizes follow a power-law distribution, and outperforms other existing methods in f-measure for whole protein complexes  <cit> . for prediction of heterotrimeric protein complexes, they reported that the f-measure of nwe was better than those of the existing methods, mcl, mcode, dpclus, cmc, coach, rrw, and ppsampler. we perform 10-fold cross-validation, and calculate the average f-measure. the results suggest that our proposed methods outperform the existing method nwe.

methods
in this section, we propose prediction methods for heterotrimeric protein complexes. more accurately, we consider the following problem: given a network of protein-protein interactions weighted by some reliability, determine whether or not three distinct proteins that are connected in the protein-protein interaction network form a protein complex. let g be an undirected graph with a set v of vertices and a set e of edges, representing the protein-protein interaction network. here, a vertex represents a protein, an edge  represents an interaction between proteins pi and pj, and the weight wij represents reliability and strength of the interaction between pi and pj. in this paper, we use the wi-phi database  <cit>  as edge weights, which has been calculated from heterogeneous biological experimental data. we call pi a neighboring protein to pj if  ∈ e. then, our proposed methods use the support vector machine , its discriminant function, and the relevance vector machine .

support and relevance vector machine
we briefly review the support and relevance vector machines  <cit> . suppose that n training data {xi, ti} with target ti ∈ {- <dig>  1} are given. for our purpose, xi corresponds to a set of three distinct proteins, ti =  <dig> corresponds to the case that the set forms a heterotrimeric protein complex. then, we consider linear models represented by the form

  y= ∑i=1maiϕi+b, 

where ϕi denotes a basis function, m denotes the number of basis functions, ai denotes the coefficient, and b denotes the bias parameter. in the svm, ϕi is implicitly defined as k with a positive semidefinite kernel function k, m is equal to n, and ai and b are determined by maximizing the margin. new sets x of proteins are classified according to the sign of y. we make use of this discriminant function y in our proposed methods.

the rvm is a bayesian sparse kernel technique for classification and regression, and shares some characteristics of the svm. as well as the svm, the basis functions of the rvm are given by kernels, which are not required to be positive semidefinite. it, however, is known that training time of the rvm is in general longer than that of the svm. in the rvm, a hyperparameter γi for each parameter ai and a prior distribution over parameters ai are introduced to obtain a sparse model. for the classification, the model in eq.  is transformed as σ), where σ denotes the logistic sigmoid function 1/, and ai and b are determined by maximizing the marginal log-likelihood with respect to γ.

extension of feature space mapping
in our previous study, we proposed seven feature space mappings for prediction of heterodimeric protein complexes  <cit> . these are based on the idea that the reliability of the interaction in a heterodimer should be high and conversely the reliability of the interaction between a protein in a heterodimer and a protein not in the heterodimer should be low. we extend the feature space mappings for two interacting proteins to mappings for three proteins. table  <dig> shows detailed extended mappings for three distinct proteins pi, pj, and pk that are connected in the protein-protein interaction network. here the fifth mapping in the previous study is eliminated because more neighboring proteins increase the maximum of differences close to the maximum of neighboring weights denoted by .  and  denote the maximum and minimum of the weights of interactions between pi, pj, and pk, respectively. the first feature in the previous study is the weight of the interaction between two proteins. since there are at least two interactions for three focused proteins and we cannot use all the weights as elements of our feature vector without changes, we take the maximum and minimum of the weights . in addition, the proteins in a heterotrimer should interact with each other, and , which is the minimum of the weights, is expected to be high.  and  denote the maximum and minimum of the weights of interactions between either of pi, pj, pk and a neighboring protein pr, respectively, where r ≠ i, j, k and  ∈ e,  ∈ e, or  ∈ e. it is considered that , which is the maximum of the neighboring weights of a heterotrimer, should be lower than the weights of interactions in the heterotrimer. consider the case that a protein pr interacts with two of proteins pi, pj, and pk, where pr is not any of pi, pj, and pk . if the weights of both interactions are large, these proteins including pr may form a complex. we introduce the maximum of smaller weights of interactions with neighboring proteins pr denoted by .  and  denote the maximum and the minimum of the numbers of domains contained in pi, pj, and pk, respectively. the number of domains in a protein complex is expected to be large because domains are considered as mediators of protein-protein interactions.

in addition to the extended features, we examine the domain composition kernel developed in our previous study  <cit> . we defined equivalence =d between two proteins pi and pj as the condition that pi consists of the same domains of pj , and defined equivalence =c between two sets xi and xj that consist of {pi <dig> ⋅⋅⋅,pin} and {pj <dig> ⋅⋅⋅,pjn}, respectively, as ∃σ∈픖n∀k), where 픖n denotes the symmetric group of degree n on the set { <dig>  ⋯, n}. then, the domain composition kernel kc was defined by

  kc= <dig> . 

two-phase learning approach
our proposed methods take two-phase learning approach. the basic idea for designing our methods is that heterotrimeric protein complexes are not likely to share the same protein with other heterotrimeric protein complexes. we estimate model parameters of svm using training data in the first phase, and predict whether or not the training data and the neighboring sets sharing at least one protein with the training data are heterotrimeric protein complexes, respectively. then, the second phase predictor makes use of the discriminant values obtained by the first phase predictor. it is expected that the discriminant values for a target set of proteins and its neighboring set do not become large together if heterotrimeric protein complexes do not share the same protein.

suppose that the training data set comprises n sets xi of three distinct proteins with the corresponding label ti ∈ {- <dig>  1}. for each xi, we calculate 7-dimensional feature vector f using ,…, shown in table  <dig> and the kernel matrix whose -th element is 〈f, f〉 + αkc, where α is a constant and ⋅,⋅ denotes the inner product. then, we obtain the model parameters in eq.  by applying the svm to the training data set. let nxbe all sets of three distinct proteins that are neighboring to x and connected in the protein-protein interaction network, where we call xi a neighboring set to xj if xi and xj share the same protein and xi is not xj . for each xi, we calculate the discriminant values y and y for all x∈nxi. since the discriminant values may include outliers, by taking the averages of positive and negative discriminant values separately, we define four feature space mappings for xi,

  f=y, 

  f=1|{x∈n|y>0}|∑{x∈n|y>0}y, 

  f=1|{x∈n|y<0}|∑{x∈n|y<0}y, 

  f=1|n|∑x∈ny, 

where |s| denotes the number of elements in the set s. here, we define f  =  <dig>  =  <dig>  f  = 0) if |{x∈n|y>0}|=0|y<0}|= <dig> |n|=0). we compose 11-dimensional feature vector f  using f , f , f , f  and f , calculate the kernel matrix with the -th element 〈f , f 〉 + αkc, and we apply some supervised learning method. it should be noted that our methods use only training data to estimate model parameters. for test data x, we calculate 〈f , f 〉 + αkc for training data xi, and determine whether or not x is a heterotrimeric protein complex according to the second classifier.

computational experiments
data and implementation
to evaluate our proposed methods, we performed computational experiments and compared them with the existing method nwe  <cit> . we used the wi-phi database  <cit>  containing  <dig> interacting protein pairs except self interactions as input weights of interactions, which is available at the supporting information web page of the paper. the weights were obtained from high-throughput yeast two-hybrid data  <cit>  and several biological databases such as biogrid  <cit>  and bind  <cit>  by using a log-likelihood score  to each dataset and the socioaffinity  index  <cit>  that measures the log-odds score of the number of times that two proteins are observed to interact to the expectation value from the dataset.

we prepared datasets using heterotrimeric protein complexes in cyc <dig> protein complex catalogue  <cit> , which contains  <dig> heterotrimeric protein complexes, and is available at http://wodaklab.org/cyc2008/. we restricted positive and negative examples to sets of three distinct proteins that form a single connected component in the input protein-protein interaction network. thus,  <dig> heterotrimers were eliminated, and we used  <dig> heterotrimers as positive examples. for negative examples, we extracted  <dig> sets of three proteins included in protein complexes with size more than three of cyc <dig>  and we selected uniquely at random  <dig> examples from the sets because our methods require many neighboring sets of three proteins for an example in the second phase. it is considered that negative examples selected from such sets are more difficult to be classified than those selected from all sets of three proteins except heterotrimers.

for nwe, we set some options related with the size of complexes so that nwe output protein complexes with size two or more from the wi-phi protein-protein interaction network in the same way as  <cit> , and extracted only protein complexes with size three from the result.

for measuring the performance, we used accuracy, precision, recall, and f-measure defined by

  accuracy=tp+tntp+tn+fp+fn, 

  precision=tptp+fp, 

  recall=tptp+fn, 

  f - measure=2⋅precision⋅recallprecision+recall, 

where tp, fp, and fn mean the number of true positive, false positive, false negative examples, respectively.

we used 'libsvm'   <cit>  and 'sparsebayes' package   <cit>  as implementations of svm and rvm, respectively.

RESULTS
we performed 10-fold cross-validation, and took the average of accuracy, precision, recall, and f-measure. furthermore, we repeated this procedure  <dig> times for other datasets with randomly selected negative examples, and took the average. table  <dig> shows the results on the average of accuracy, precision, recall, and f-measure by our proposed methods and nwe. 'svm+svm' and 'svm+rvm' denote two-phase methods using svm and rvm as the second classifier, respectively. 'svm' denotes usual svm using only features f . α denotes the coefficient of the domain composition kernel kc. we examined α =  <dig>  because the case was best for prediction of heterodimeric protein complexes in our previous study  <cit> . nwe predicted  <dig> protein complexes with size three from the wi-phi protein-protein interaction network, and  <dig> of them were actual heterotrimeric protein complexes in the cyc <dig> protein complex catalogue. we can see from the table that the f-measure by svm+svm, svm+rvm, svm for both α =  <dig>  and  <dig>  were higher than those by nwe, respectively. furthermore, the accuracy and f-measure by the two-phase method svm+svm were higher than those by usual svm with f , respectively. the accuracy and f-measure by svm+rvm, however, were lower than those by svm, respectively. it implies that rvms may be less useful than svms for these problems that svms can be applied. thus, the results suggest that our proposed methods svm+svm, svm+rvm, and svm outperform the existing method nwe. the results also suggest the usefulness of the second phase.


α
'svm+svm' and 'svm+rvm' denote two-phase methods using svm and rvm as the second classifier, respectively. 'svm' denotes usual svm using only features f. α denotes the coefficient of the domain composition kernel kc. note that the accuracy is not defined for nwe because it is unsupervised, and predict protein complexes of various sizes. the precision and recall for nwe were calculated as tp divided by the numbers of predicted and known heterotrimers, respectively.

CONCLUSIONS
we proposed prediction methods by two-phase learning for heterotrimeric protein complexes. in the methods, we extended the feature space mappings in our previous study for prediction of heterodimeric protein complexes, and made use of the discriminant function for neighboring sets of three proteins. to validate our proposed methods, we performed 10-fold cross-validation computational experiments. the results suggest that our two-phase prediction methods and svm with the extended features outperform the existing method nwe, which was reported to outperform many other existing methods such as mcl, mcode, dpclus, cmc, coach, rrw, and ppsampler, although our methods are limited to prediction of heterotrimeric protein complexes. for further evaluation, we would like to perform computational experiments for other datasets if such data become available.

we have some possibility to further improve the prediction accuracy. for instance, we can use sequence information for designing feature space mappings as well as domains contained in proteins. in addition, we can introduce some probabilistic model such as conditional and markov random fields to neighboring sets of three proteins although in this paper we considered kernels between neighboring sets.

competing interests
the authors declare that they have no competing interests.

authors' contributions
pr and mh developed and implemented the methods. mh drafted the manuscript. om and ta participated in the discussions during the development of the methods and helped draft the manuscript. all authors read and approved the final manuscript.

