BACKGROUND
a gene regulatory network  consists of a set of genes and regulatory relationships among them. tremendous amount of microarray data that measure expression levels of genes under specific conditions are obtained from experiments. it is a challenging problem in systems biology to reconstruct or "reverse engineer" grns by aiming at retrieving the underlying interaction relationships between genes from microarray data. various approaches have been developed to infer grns from microarray data. most of them can be classified into two categories: parametric or model-based methods and nonparametric or dependency-measure-based methods. commonly used models include ordinary differential equations  <cit> , gaussian graphical models  <cit>  and bayesian networks  <cit> . dependency measures include partial correlation coefficient  <cit> , mutual information  <cit> , and z-score  <cit> .

the reconstruction of grn is a non-trivial problem. on the one hand, the number of possible network topologies grows exponentially as the number of genes increases. on the other hand, the information in the microarray data is quite limited. the data contain a lot of inherent noises generated from the devices or the experiment processes. for large-scale networks, the number of observations is usually much less than that of genes, also known as "dimensionality problem"  <cit> . the lack of observations and the high dimensionality of the data prohibit the direct application of traditional methods and make the inference task extremely challenging.

as more and more microarray datasets on the same species are produced from different laboratories, their integration leads to more robust and more reliable results. the methods that integrate multiple datasets could synergize the strength of each dataset and either infer a more accurate network if all the integrated datasets are in high qualities or infer a robust network which is better than the worse one that is from a single dataset. however, multiple time-course datasets can not be simply combined as one dataset as there is no temporal dependencies between the datasets. wang et al.  <cit>  proposes a linear programming framework to integrate multiple time-course gene expression data to infer a network topology that is most consistent to all datasets. in their method, the regulatory strengths between genes is assumed to be the same across all datasets. however, different datasets may be produced under different circumstances, which may result in different regulatory strength between genes. another problem is that the value of the tuning parameter in their method, which controls the degree of sparsity of the inferred network, is only determined intuitively. chen et al.  <cit>  infer one grn from each time-course data separately, and combine edges of inferred grns using a strategy similar to majority vote. for this method, using each dataset separately in the inference process may miss the opportunity of taking advantage of information in other datasets and the tuning parameter is also determined intuitively.

this study focuses on inferring the topologies of grns from multiple time-course gene expression datasets based on an autoregressive model. we assume that one grn corresponds to one dataset and these grns share the same topology across all datasets. by assigning the parameters representing the regulatory strengths of the same edge into the one group, the group lasso  <cit>  can be applied to find the sparse network topology. microarray data typically contain noises and outliers, which could severely affect the quality of inferred results. rosset and zhu  <cit>  proposes a robust version of lasso by replacing the squared error loss of lasso with huber loss. we propose to use the huber loss to extend the group lasso such that the new method, huber group lasso, is more resistant to the large noises and outliers.

to solve the huber group lasso, a new algorithm is developed in our previous work  <cit> , which combines the idea of auxiliary function minimization  <cit>  and the block coordinates descent method  <cit> . the proposed algorithm is efficient and can also be adapted for solving the group lasso problem without the orthogonality restriction. in this study, we analyze the convergence of our proposed algorithm and show that the sequence the algorithm generated indeed converges to the optimal solution of the huber group lasso problem. instead of picking a specific value for the tuning parameter which corresponds to a determinant network topology as in our previous work  <cit> , in this study, we adapt the "stability selection"  <cit>  strategy to our method to find a network consisting of edges with probabilities or scores. the huber group lasso is applied to both simulation data and real experimental data and its performances are compared with those of the group lasso in terms of areas under the receiver operating characteristic  and areas under the precision-recall . results show that the huber group lasso outperforms the group lasso and therefore demonstrate the effectiveness of our proposed method.

briefly, the remainder of the paper is organized as follows. in model section, we introduced the model for the grn, based on which the network topology is inferred. in result section, our proposed method is applied to the both simulation data and real experimental data. the results demonstrate the effectiveness of our method. then, we conclude this study and point out the future work along this research in conclusion section. details of the method and its theoretical analysis can be found in method section.

model
a model for grn consisting of p genes is used in this study  <cit> :

  x.=cx+sr,r=f, 

where x=t∈rp is the vector of mrna concentrations; c=diag∈rp×p is a diagonal matrix with ci > <dig> the degradation rate of gene i; the vector r=t∈rm represents the reaction rates, which is a function of mrna concentrations and s∈rp×m is the stoichiometric matrix of the network. we assume that reaction rate r is a linear combination of mrna concentrations,

  r=fx, 

where f∈rm×p. then,  becomes

  x.=cx+mx, 

where m=sf∈rp×p. the elements of m = 1≤i, j≤p indicate the network topology or regulatory relationships between genes. mij ≠  <dig> if gene j regulates the expression of gene i. otherwise, mij =  <dig>  gene j does not regulate gene i.

since the gene expression levels are sampled at several time points, by using zero order hold discretization method, system  is discretized as

  xk=axk- <dig> 

where a = ecΔt + c−1m. note that ecΔtand c− <dig> are both diagonal matrices and their diagonal elements are all positive. thus, the off-diagonal elements of a = 1≤i,j≤p have the same zero and nonzero pattern as those of m. in this study, we focus on inferring relationships between genes and do not consider self-regulations. as mentioned above, this can be achieved by identifying the nonzero off-diagonal elements in matrix a, which can be interpreted as regulatory strengths. multiple time-course gene expression datasets for a grn may be collected under different circumstances. one dataset is assumed to correspond to one inferred grn topology, and all inferred grns should share the same network topology as their corresponding datasets are generated from the same underlying gene network. our purpose is to reverse engineer the underlying network topology from these multiple datasets. more specifically, suppose we have m time-course gene expression datasets for a gene network: x˜,…,x˜, each of which is measured at nk + <dig> time points, i.e., x˜∈rp×. according to the model , these datasets should satisfy

  y=ax+e,k= <dig> …,m, 

where y=x˜ <dig> …,x˜nk+ <dig>  the last nk observations; x=x˜ <dig> …,x˜nk, the first nk observations, a∈rp×p, the regulatory matrix for the kth dataset and e, the errors or noises. all a's are required to have the same structure. i.e., zero and nonzero pattern, but do not need to have the same value for every nonzero position because gene network is dynamic and regulatory strength may be different under different circumstances. in this study, we propose to use group lasso penalty to implement this requirement and to use huber loss function to take into account the robustness. details of the proposed method are shown in the method section.

RESULTS
to study the effectiveness of the proposed method, the huber group lasso is applied to inferring grns from both simulation datasets and real experimental datasets and the results of huber group lasso are compared with those from group lasso in both area under receiver operating characteristic  curve and area under the precision and recall  curve.

simulation example
a small-grn consisting of  <dig> genes is considered in this example. the corresponding true network topology matrix is

 a0=+-+00-+00+0++00+-0+0000++, 

where + and − indicate the existence and regulation types of the edge. we randomly generate m stable regulatory matrices a, k =  <dig>  . . . , m, according to the template a <dig>  such that sign) = sign. then, m simulated time-course gene expression datasets, each with the number of time points, nk , are generated from  with randomly chosen expression values at the first time point. the simulated error follows a mixed gaussian distribution: with probability of  <dig> , it has the distribution n  and with probability of  <dig> , it has the distribution n . in this way, the simulated data contain large errors and outliers. to investigate the performances of our methods in different situations, we vary the values of m and nk and apply the group lasso and huber group lasso respectively to these generated datasets and compare the results from these two methods.

data are generated under three situations ,  and . using the stability selection procedure that is introduced in the method section, network typologies consisting of edges with scores or probabilities are inferred by huber group lasso and group lasso. for the first two situations, we set the number of bootstrap samples as  <dig> and the moving block length as  <dig>  for the third situation, we set the number of bootstrap samples as  <dig> and the moving block length as  <dig>  varying the threshold, the roc plots and precision-recall plots of each method for different situations are obtained and illustrated in figure  <dig>  the areas under the rocs  and precision-recall curves  are calculated and reported in table  <dig>  from figure  <dig> and table  <dig> we can see that for each situation, the huber group lasso outperforms the group lasso, i.e. the auroc and aupr of huber group lasso are larger than those of group lasso. roc plots in figure  <dig> also show that both methods have better performances than the random guess. for the case of m =  <dig> and nk =  <dig>  the huber group lasso even achieves the maximum value of auroc and aupr. it can also be seen that for each method, the more the observations or the more the datasets, the larger auroc and aupr can be obtained. this is in accord with the intuition because, in this example, more observations or datasets indicate more information as these simulated data are generated under quite similar circumstances. all the simulation results have demonstrated the effectiveness of our proposed method.

se: group lasso. huber: huber group lasso.

in vivo reverse engineering and modeling assessment  data
the data used in this example come from the in vivo reverse engineering and modeling assessment  experiment  <cit> , where a network composed of five genes  was synthesized in yeast saccharomyces cerevisiae, in which genes regulate each other through a variety of regulatory interactions. the network is negligibly affected by endogenous genes and it is responsive to small molecules. galactose and glucose are respectively used to switch on and off the network. in this study, we use the irma time-course data consisting of four switch off datasets  and five switch on datasets .

the huber group lasso and the group lasso are applied to these data in three cases:  switch on datasets,  switch off datasets and  all datasets, i.e., combing switch on and switch off datasets. in the stability selection procedure, the number of bootstrap samples is  <dig> for all cases and the moving block length is  <dig> for the second case and  <dig> for the other cases. the roc plots and precision-recall plots for the huber group lasso and the group lasso for each case are illustrated in figure  <dig> and the corresponding aurocs and auprs are summarized in table  <dig>  it can be seen that except the group lasso for the switch on datasets, the performances of the methods are better than random guesses. the huber group lasso outperforms the group lasso in both aurocs and auprs. all methods for the switch off datasets perform better than for the switch on datasets. the group lasso for all datasets has better performance than for the switch on datasets but is not as good as for the switch off datasets. the huber group lasso for all datasets has the best performance among all cases. this indicates that combing multiple datasets may lead to either the best result or a robust result which is better than the worst case. the network topology with false positive rate   <dig>  of the huber group lasso for all datasets is shown in figure  <dig> and the corresponding true positive rate  is  <dig>  with precision  <dig> , in which the red edges represent true positives while black edges are false positives. the results show the effectiveness of our method for the irma data.

se: group lasso. huber: huber group lasso.

e. coli sos network
in this example, we apply the proposed method to identify the real grn, e. coli sos dna repair system as shown in figure  <dig>  this network is responsible for repairing the dna after some damage happens. lexa acts as the master repressor of many genes in the normal states. when a damage occurs, reca acts as a sensor and binds to single-stranded dna to sense the damage and mediates the autocleavage of lexa. the repressions of the sos genes are halted by the drop in lexa levels. the sos genes are activated and start to repair the damages. when the repair is done, reca level drops and stops mediating the autocleavage of lexa. then, lexa accumulates and represses the sos genes to make the cell go back to the normal state.

four time-course gene expression datasets of sos dna network are downloaded from the uri alon lab , which are produced from four experiments for various uv light intensities . each dataset contain  <dig> genes and their measurements at  <dig> time points. as other literature did, e.g.  <cit> , only  <dig> genes, i.e., uvrd, lexa, umud, reca, uvra and polb are considered because they are well studied and the gold standard network of these genes are illustrated in table  <dig>  details of the gold standard can be found in  <cit> . in this study, we do not consider the signs and the self-regulations.

as the conditions for the first two experiments are different for the last two experiments, we consider applying the method to three cases:  datasets of experiment  <dig> and  <dig>   datasets of experiment  <dig> and  <dig> and  all experiment datasets. in the stability selection procedure, the number of bootstrap samples is  <dig> and the moving block length is  <dig> for all cases. the roc plots and precision-recall plots for the huber group lasso and the group lasso for each case are illustrated in figure  <dig> and the corresponding aurocs and auprs are illustrated in table  <dig>  from the roc plots and aurocs, it can be seen that the huber group lasso performs significantly better than random guess while the group lasso method is only a little bit better than random guess. obviously, the huber group lasso outperforms the group lasso both in aurocs and aupr for all cases. the huber group lasso using experiment  <dig> and  <dig> datasets has the best performance. performance of the huber group lasso using all datasets is between that in the first case and that in the second case. it can be considered as a robust result because of the using of multiple datasets. the network topology with fpr  <dig> and tpr  <dig>  of the huber group lasso for all datasets is shown in figure  <dig>  in which all inferred edges are correct. these results demonstrate the effectiveness of our method for the e. coli sos data.

coli sos datasets. se: group lasso. huber: huber group lasso.

s. cerevisae cell cycle subnetwork
a cell cycle regulatory subnetwork in s. cerevisae is inferred by the proposed method from  <dig> experimental microarray datasets. as in  <cit> , the subnetwork consists of  <dig> genes including  <dig> genes for producing transcription factors  and  <dig> genes for producing cyclin and cyclin/cdk regulatory proteins . the time-course datasets we use include cell-cycle alpha factor release, cdc <dig>  alpha factor fkh <dig> fkh <dig>  fkh <dig>  alpha factor and elutriation, which are all downloaded from stanford microarray database . we apply the huber group lasso and the group lasso respectively to infer the network from the datasets.

in order to demonstrate the effectiveness of the proposed method, the inferred results are compared with the interaction network of the chosen  <dig> genes, drawn from biogrid database  <cit> . the network in the database has  <dig> interactions, not including the self-regulations, and we take it as the gold standard regulatory network. in the stability selection procedure, the number of bootstrap samples is  <dig> and the moving block length is  <dig>  the roc plots and precision-recall plots are illustrated in figure  <dig> and the aurocs and auprs are shown in table  <dig>  we can see that both methods have better performances than random guess and the huber group lasso outperforms the group lasso. one network from huber group lasso with fpr  <dig>  and tpr  <dig>  is shown in figure  <dig>  in which red edges are those inferred edges having been identified in the database and grey edges might be either false positives or novel discovered regulatory relations. although the gold standard network extracted from the database may contain false edges or not be complete, this shows the effectiveness of our method to some extent.

se: group lasso. huber: huber group lasso.

CONCLUSIONS
a novel method, huber group lasso, has been proposed to integrate multiple time-course gene expression datasets to infer the underlying grn topology. as an extension to the group lasso, it is robust to large noises and outliers. an efficient algorithm which combines the ideas of auxiliary function minimization and block descent is developed to slove the involved optimization problem. the convergence analysis of the algorithm shows that the sequence generated from the algorithm indeed converges to the optimal solution of the problem. instead of selecting a specific tuning parameter corresponding to a determinant network topology, an adapted stability selection procedure is used to lead to a network consisting of edges with scores. the applications of the proposed method to the simulation datasets and real experimental datasets show that huber group lasso outperforms the group lasso in both auroc and aupr. it also shows that the integration of multiple time-course gene expression datasets by the proposed method lead to reliable inferred network typologies.

the information in the gene expression data is quite limited. one direction of the future work along this study is to extend the method to be able to integrate other types of data with the gene expression data.

