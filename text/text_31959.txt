BACKGROUND
genotype by sequencing  is a powerful, cost-effective method to obtain genome-wide variability information for populations composed by hundreds of individuals . in brief, a gbs protocol starts with a digestion of the dna using one or more known restriction enzymes, aiming to reduce the complexity of the genome to be sequenced. then, fragments of suitable lengths  are ligated to adapters, amplified and sequenced in a high throughput illumina platform  <cit> . multiple samples can be sequenced in one single lane adding appropriate barcodes  <cit> . sequenced reads can then be demultiplexed and either analyzed de-novo or aligned to a reference genome if available. in the latter case, variants can be identified using analysis pipelines similar to those used for analysis of whole genome resequencing data  <cit> . the main feature of this protocol is that a relatively small, yet reasonably well distributed and reproducible, portion of the entire genome is sequenced, which allows to identify and genotype thousands of genomic variants across the genome and across different samples. gbs is becoming the method of choice for several applications in plant genomics and plant breeding  <cit> , such as the analysis of population dynamics  <cit> , construction of high density genetic maps  <cit> , genetic mapping of complex traits through genome-wide association studies   <cit>  and estimation of breeding values in genomic selection  <cit> .

a key component of any gbs protocol is the bioinformatics pipeline required to analyze the reads and to obtain polymorphic sites within the sequenced population. widely used packages such as bwa  <cit>  or bowtie <dig>  <cit>  for short read alignment and samtools  <cit>  or gatk  <cit>  for variants detection and genotyping have been used to analyze gbs data  <cit> . more recently, custom packages such as stacks  <cit>  or the tassel gbs pipeline  <cit>  have been developed specifically for analysis of the types of reads produced by gbs technologies. the main advantage of these methods over previous approaches is that they can still work in the absence of a reference genome  <cit> . tassel in particular takes advantage of the nature of gbs reads to perform a highly efficient calculation of genomic variants.

we recently developed the software package ngsep as an accurate, efficient and easy-to-use alternative for analysis of high throughput sequencing  data and we demonstrated its advantages over other commonly used packages using benchmark whole genome sequencing  data on humans, yeast and rice  <cit> . here we describe the new functionalities implemented in ngsep for analysis of gbs data and we compare the performance of ngsep with other commonly used methods for variants detection and genotyping on three different breeding populations of cassava and beans.

RESULTS
novel functionalities implemented in ngsep
deconvolution
the deconvolution process allows to distribute the reads obtained from fragments barcoded and sequenced in one illumina lane, producing one separate file for each sample. it receives a fastq file with the lane information and a text file describing the link between barcodes and samples. although deconvolution can be generally applied to any type of sequencing in which samples are identified by barcodes, it is particularly important for gbs data because in gbs experiments  <dig> samples  are sequenced per lane to achieve cost efficiency. we also included an option in this module to identify a user-defined tag on each read and then trim the read from the starting point of this tag. this allows to remove contamination of adaptor sequence on the three prime end of the reads, which we have identified as the most important issue affecting the quality of the reads produced by the elshire protocol for gbs .

one step wizard for parallel multisample analysis
the ngsep wizard is a new functionality which, starting from raw sequencing data, embodies all steps required to obtain a population variants file with only one execution screen. this functionality greatly reduces the amount of work needed by researchers to obtain variation datasets over populations and also helps to standardize parameters for read aligment and variants detection across different samples. figure  <dig> shows an schematic of the user interaction needed to run this functionality. the wizard starts when users select a folder including raw sequencing data in fastq format for different samples. users then select the samples to process and choose parameters and output directories for read alignment, variants identification and genotyping and finally submit the entire pipeline. for error control, the wizard either has the option of skipping samples with problems in any step and trying to finish the process including only the successful samples, or it can also cancel the entire execution in case that one sample fails. for both cases ngsep will notify about the samples with problems both through execution logs and showing a popup alert summarizing errors across the different samples. although the ngsep wizard can in principle be applied to hts reads obtained from any type of sequencing protocol, it is particularly useful to facilitate to users the process of obtaining variation datasets from raw reads in gbs experiments in which hundreds of samples are sequenced in just a few lanes and hence execution parameters need to be standardized across samples. this wizard covers a large part of the bioinformatic analysis steps included in currently used gbs protocols  <cit> .
fig.  <dig> ngsep wizard. one step wizard to obtain population variability datasets



filtering and conversion of vcf files
we expanded the variants call format  filtering module to include most of the filtering strategies that can be employed to achieve the balance between variant genome coverage and genotype quality required for different applications. genotype calls can be filtered based either on genotype quality  or total read coverage. genomic regions can be either selected or filtered out, which is useful to remove markers in undesired regions  or to focus on a particular region of the genome, such as a quantitative trait locus  or a gene. samples can also be either selected or filtered out, which allows users to remove samples that were sequenced at lower coverage or to focus on subpopulations within the whole dataset. single nucleotide polymorfisms  can then be selected based on several criteria such as number of individuals genotyped, minor allele frequency , distance between markers and functional annotations. to select snps ameanable for other high throughput snp genotyping platforms , users can also select limits on the gc-content of the region surrounding each particular snp. all these filtering approaches can be applied to any vcf file using minimal computational resources, which facilitates users trying several different options for downstream analysis. we also expanded the conversion module to allow users to translate the genotype data to the input formats needed by tools such as darwin to build distance-based dendograms  <cit> , joinmap for construction of genetic maps  <cit> , and the r package rrblup to perform estimation and cross validation of breeding values in genomic selection  <cit> .

statistics on genotyped populations
we added three modules providing several statistics on the genotypes included in a vcf file. summary statistics include counts of number of variants discriminated as biallelic snps, biallelic indels and other  variants, the maf distribution and the distribution of snps genotyped in different numbers of individuals. it also includes counts of genotype calls per sample, including number of genotyped variants, non-reference genotype calls and heterozygous calls. counts per sample are also discriminated by gene functional annotations. the diversity statistics module calculates for each variant common statistics for population genomic analysis such as maf, expected and observed heterozygosity, and deviation from hardy-weinberg equilibrium. users can provide a text file indicating a clustering of samples in subpopulations, which allows this module to calculate diversity statistics for each subpopulation, facilitating the calculation and genome-wide analysis of f-statistics. finally, a third function allows to compare the genotype calls on two vcf files , and calculates the number of differences between every pair of samples. this allows to identify potentially duplicated materials or direct parental relationships.

imputation
one of the main issues of gbs, compared to high throughput genotyping platforms, is the relatively high percentage of missing data produced by the random distribution of read coverage both across samples and across genomic sites. although several bioinformatics methods have been developed to perform genotype imputation , most of these tools have been developed in the context of imputation on human populations of unrelated individuals. even though imputation on populations of inbred materials and biparental or multiparental populations is relatively easier because these populations generally have larger linkage disequilibrium  blocks  <cit> , very few bioinformatic tools are available to perform accurate genotype imputation on these cases. keeping this in mind, we reimplemented the haploid version of the hidden markov model  implemented in fastphase  <cit>  to perform imputation in populations of inbred lines, either unrelated or members of a breeding population. our implementation receives and produces its output as a vcf file which allows users to directly integrate imputed genotypes in gwas analysis using the format conversion module of ngsep.

comparison of methods on cassava f <dig> breeding populations
we evaluated the performance of ngsep compared to some of the most widely used pipelines for snp discovery and genotyping, namely gatk  <cit> , samtools  <cit>  and tassel  <cit> , on gbs reads previously sequenced and used to generate a dense snp based cassava genetic map  <cit> . these reads were obtained from gbs experiments performed on two biparental full-sib cassava families of f <dig> crosses termed the k family  <cit>  and the nxa family  <cit>  . because cassava is a naturally outcrossing species, its cultivars hold high levels of heterozygosity. hence, cassava f <dig> populations make a useful benchmark to assess the accuracy of different pipelines to identify both homozygous and heterozygous genotypes, using mendelian rules of segregation as a gold-standard for expected genotype calls. we classified snps based on their observed heterozygosity  and minor allele frequency  in four different categories : 1) monomorphic , 2) homozygous/heterozygous , 3) double heterozygous , and 4) segregating . distributing the snps on these categories is useful to understand the behavior of each method, the amount and main sources of errors and also the consequences of these errors for downstream analysis. for each category we calculated as measures of sensitivity the number of genotype calls in categories  <dig>   <dig> and  <dig> and, as measures of specificity, the number of segregation errors and the number of snps in category  <dig>  figure  <dig> shows that the distribution of ho and maf on datasets with relatively equivalent quality obtained running the four pipelines is generally consistent with expected segregation patterns. this figure also suggests that all methods included in this comparison are able to provide thousands of snp markers genotyped with high accuracy.
fig.  <dig> maf and h
o distributions. statistics on filtered snps obtained running the four discovery pipelines compared in this study on the k family gbs data. a distribution of observed heterozygosity b maf distribution in snps useful to build a genetic map , c maf distribution on highly heterozygous snps , and d percentage of filtered snps useful to build a genetic map that appear at the filtered , and unfiltered  datasets obtained running each method



we compared the number of shared snps between the different methods after keeping genotype calls with comparable genotype quality , and applying the same filters on number of individuals genotyped, repetitive regions and observed heterozygosity, retaining snps consistent with the categories useful to build a genetic map . we found that, among filtered datasets, ngsep, gatk and tassel share over  <dig> % of their predicted snps, whereas only up to  <dig> % of the snps reported by samtools are shared by the other methods . whereas ngsep identifies  <dig> and  <dig> % of the snps reported by gatk and tassel respectively, gatk and tassel respectively identify  <dig> and  <dig> % of the snps reported by ngsep. differences in the snps retained by the four methods can occur due to genotype calls confidently predicted by one method and not called by other method that produce changes in the number of individuals genotyped, or due to discrepancies in the genotype calls that produce different estimates of observed heterozygosity. to rule out the latter option, we calculated the percentage of snps in the filtered datasets that are contained in the non filtered datasets provided by each method  and we found that close to  <dig> % of the filtered snps identified by each method are identified by at least other method. whereas over  <dig> % of the snps within the samtools or the gatk filtered datasets appear in the ngsep non filtered dataset, only  <dig> and  <dig> % of the snps within the filtered ngsep dataset appear in the non filtered datasets of gatk and samtools respectively. moreover, we verified that more than  <dig> % of the genotype calls contained by a filtered dataset are consistent with genotype calls predicted by other methods. the largest difference between methods  was observed between the filtered samtools dataset and the unfiltered tassel dataset. the percentages of inconsistency between the genotype calls shared between the filtered ngsep dataset and the unfiltered datasets of gatk, samtools and tassel are  <dig>  %,  <dig>  % and  <dig>  % respectively. over  <dig> % of these discrepancies are genotypes called homozygous by one method and heterozygous by another method. a similar comparison performed with the datasets obtained from the nxa family shows results consistent with this comparison.

as a starting point for the comparison of different methods, we calculated the number of genotypes and the number of errors as a function of the minimum quality score  because this score should be related to the confidence assigned by each method to each genotype call. we found that quality scores of gatk and samtools tend to be smaller than those of ngsep . on the other hand, most of the quality scores reported by tassel are higher than those of ngsep, ranging between  <dig> and  <dig> 

similar to previous benchmarks  <cit> , we contrasted the number of genotype calls in snps useful to build a genetic map  against the number of errors detected within these categories. figure 3a and d show that the four methods provide roughly equivalent high accuracies in this analysis, being ngsep and tassel slightly more accurate than gatk and samtools in the k family and gatk slightly more accurate than ngsep and samtools in the nxa family. samtools is the most conservative algorithm reporting at q≤ <dig> about the same number of snps than ngsep at q≥ <dig>  however with more errors.
fig.  <dig> quality assessment for cassava f <dig> families. top figures: number of genotype calls in snps classified in the categories that are useful to build a genetic map  contrasted with the number of segregation errors identified in such categories in a the k family and d the nxa family. middle figures: number of genotype calls in snps segregating the two parents  contrasted with the number of  homozygous genotypes called in snps catalogued in this category in b the k family and e the nxa family. bottom figures: number of genotype calls in snps classified in the categories c <dig> and c <dig> contrasted with the number of genotyping errors identified in snps predicted to be monomorphic in c the k family and f the nxa family. for each pipeline the dots represent datapoints obtained filtering genotype calls at different minimum quality scores. values in all figures are thousands of genotype calls



although snps in category  <dig> are in principle not useful for construction of genetic maps from f <dig> populations, we performed the same analysis for the snps in this category to assess the behavior of each method in highly heterozygous sites. in this case tassel and ngsep more clearly outperform gatk and samtools . we believe that the reason for this outcome is that samtools and gatk assume that snps tend to be in hardy-weinberg equilibrium   <cit> , which is not the case for snps in categories  <dig> and  <dig>  for the case of samtools, the strand bias filter, which we could not deactivate, can also be a reason for reduced sensitivity, taking into account that an important percentage of the genome covered in a gbs experiment is only sequenced in one strand, and only fragments with lengths equal or smaller than the read length are sequenced in the two dna strands. tassel up to this point seems to have the best accuracy, although we could not assess this pipeline using the nxa family data. finally, because we filtered out snps monomorphic for the alternative allele, the remaining predicted snps with low observed heterozygosity  are likely to be called due to genotyping errors. in this comparison tassel showed the worst behavior generating  <dig>  spurious snps at q≥ <dig>  compared to  <dig>  spurious snps produced by ngsep at q≥ <dig> and about  <dig>  produced by gatk and samtools at q≥ <dig> and q≥ <dig> respectively. figure 3c and f show the number of predicted erroneous genotype calls in monomorphic sites contrasted with the number of genotype calls useful to build genetic maps as a measure of sensitivity. ngsep tends to produce more singleton errors than gatk and samtools but the assignment of quality scores given by ngsep seems to be more effective than that given by tassel to filter out these errors. overall, these results suggest that tassel has a tendency to call heterozygous genotypes over homozygous genotypes which makes it appear as having the best accuracy on the highly heterozygous sites at the expense of having the worst accuracy on monomorphic sites. results obtained with the bean population  seem to confirm this hypothesis.

as a final assessment of the accuracy of the ngsep pipeline, we built a draft genetic map for the nxa population using as input one of the most high-quality datasets obtained with ngsep, which includes  <dig>  snps. consistent with previous studies  <cit> , we obtained  <dig> linkage groups, which we could uniquely map to the  <dig> chromosomes assembled in the latest version of the reference genome available in phytozome  <cit> , having only  <dig> snps inconsistent with the chromosome assignment of each linkage group. sorting of snps within each linkage group largely coincides with their predicted physical positions in the reference genome . the number of snps mapped to each chromosome was on average  <dig> , ranging from  <dig> mapped to chromosome  <dig> to  <dig> mapped to chromosome  <dig>  the total length of the map  was relatively close to the  <dig>  cm reported by the international cassava genetic map consortium  based on the consensus of nine genetic maps  <cit>  and the  <dig> cm reported by  <cit>  for the k family. the average intervals between two adjacent mapped markers was  <dig>  cm. the largest group, with a total length of  <dig>  cm, was mapped to chromosome  <dig>  whereas the smallest group, with  <dig>  cm, was mapped to chromosome  <dig>  chromosome  <dig> also contains the highest marker density, with an interval average of  <dig>  cm, whereas the least saturated group maps to chromosome  <dig>  with an interval average of  <dig>  cm. the longest interval between adjacent snps is observed on chromosome  <dig> with a value of  <dig>  cm.

comparison of methods on a common bean magic population
as a benchmark for comparison of methods on populations of inbred lines, we present here preliminary results on gbs of a common bean multiparental advanced generation intercross  population  <cit>  developed by the bean program of the international center for tropical agriculture . we analyzed one of the lanes sequenced for this project, including a subset of the population composed by  <dig> parental lines and  <dig> siblings. after running the different pipelines and filtering using different quality scores, we removed snps in regions masked as repetitive in the bean reference genome  <cit>  as well as variants with less than  <dig> individuals genotyped and variants with maf below  <dig> . in this case we have more variability in allele frequencies and therefore we can infer less information from the structure of the population. however, assuming that the development of the population achieved random mating of the eight parental lines, we can infer that the percentage of heterozygous genotypes per site ranges from  <dig> to  <dig> %. after the four rounds of inbreeding performed to obtain f <dig> plants the percentage of heterozygosity should range from  <dig>  to  <dig> %. hence, we assumed for this quality assessment that most of the heterozygous genotype calls predicted by the different pipelines would be errors and we contrasted the total number of genotypes predicted by each method with the number of those that were heterozygous. figure 4a shows that ngsep provided the best accuracy on this comparisons whereas tassel produced the largest number of probably false heterozygous calls.
fig.  <dig> quality assessment for the bean magic population. a total number of genotype calls obtained from sequencing data for the bean magic population contrasted with the number of heterozygous genotype calls. for each pipeline the dots represent datapoints obtained filtering genotype calls at different minimum quality scores. b total number of snps obtained in the same experiments as a function of the number of snps with observed heterozygosity larger than  <dig> . c distribution of observed heterozygosity for datasets obtained with the four pipelines compared in this study. d distribution of imputed genotype calls for different datasets obtained with ngsep and imputed with ngsep and with beagle. the green line represents the percentage of the total dataset that imputed genotype calls represent for each dataset



we verified if heterozygous genotypes are clustered in a few particular snps, which could happen due to repeats not identified in the reference genome or even due to balancing selection, or if they are spread over the whole dataset as expected for errors. we contrasted the total number of snps obtained by each method against the number of snps with observed heterozygosity  larger than  <dig> , which in this subset of the population would correspond to snps in which at least  <dig> individuals are heterozygous. figure 4b shows that ngsep also achieved the best behavior in this comparison mainly because most of the heterozygous genotype calls predicted by ngsep are clustered in about  <dig> % of the snps, whereas heterozygous genotype calls predicted by gatk, samtools and tassel are spread over more than  <dig> % of the snps. figure 4c shows that only ngsep produces an ho distribution consistent with the expected percentage of heterozygous calls for this population. in the case of samtools and gatk, the most likely explanation for this behavior is the effect of the assumption of hardy-weinberg equilibrium which in this dataset does not hold due to inbreeding. tassel on the other hand is probably overcalling heterozygous genotypes because, unlike the other pipelines, it does not take into account base quality scores during genotype calling.

finally, we performed a comparison between the imputation module developed in ngsep for inbred populations against beagle  <cit> , which is one of the most widely used tools for genotype imputation and, to the best of our knowledge, the only imputation tool able to process files in vcf format. we considered six different scenarios combining filters on quality and minimum number of individuals. figure 4d shows that the same calls are predicted by both methods in about  <dig> % of the imputed genotypes and that between  <dig> and  <dig> % of the differences  happened because beagle imputed heterozygous genotypes. although a better gold-standard dataset and more algorithms should be considered to perform a formal comparison between methods for imputation on inbred populations, this initial result suggests that the hmm implemented in ngsep can provide genotype calls with accuracies similar to other state-of-the-art software tools for genotype imputation.

discussion
genotype by sequencing  is a powerful and cost-effective protocol to assess the variability of entire populations. however, maximizing the information obtained from gbs experiments requires a bioinformatics pipeline able to understand the particular nature of the reads produced by this protocol and adaptable to optimize its behavior on populations with different characteristics and in particular different distributions of variability and heterozygosity. here we report the novel functionalities of ngsep that were designed and implemented to facilitate the analysis of gbs data, and we demonstrated that ngsep is a powerful and adaptable framework to genotype populations of an outcrosser highly heterozygous species such as cassava as well as populations of inbred individuals such as the bean magic population. for the complete magic population, we assembled a highly curated dataset of about  <dig>  snps which is now being used to perform genetic mapping of complex agronomically relevant traits in bean . besides the populations described in this study and recent works on analysis of whole genome sequencing data in rice  <cit>  and peanut  <cit> , the ngsep pipeline has been used by different collaborators to obtain genomic variation datasets from wgs, gbs and rad-sequencing data taken from different populations of landraces, breeding materials and even wild relatives of rice, cassava, beans, potato, lettuce and sugar cane.

we compared the accuracy of ngsep against that of other widely used software packages for analysis of high throughput sequencing  data such as gatk and samtools, which were originally optimized for low coverage wgs data in humans, and the tassel gbs pipeline which was specifically built for the gbs protocol developed at cornell. we believe that this effort itself is a novel contribution to the field because, to the best of our knowledge, comparisons of methods for snp discovery and genotyping using formal benchmark datasets as a baseline are generally missing from current literature, especially for gbs data and non-model organisms. our comparisons show that ngsep provides the best overall accuracy under different scenarios.

comparison against tools commonly used for snp discovery in human genetics shows that ngsep outperforms gatk and samtools mainly because optimization of these tools for high accuracy on low coverage wgs data included the assumption of hardy-weinberg equilibrium  which does not hold on highly heterozygous sites commonly found on f <dig> populations, or sites with low heterozygosity such as most of the variable sites in populations of inbred species. strand bias filters are also not generally adequate for gbs data which probably explains why samtools reported the lowest sensitivity in these experiments, taking into account that this tool was among the best ranked in our previous benchmarks with wgs data  <cit> .

compared to tassel, which is currently the preferred tool for analysis of gbs data, ngsep also provides better overall accuracy mainly because tassel seems to overcall heterozygous genotypes. the most likely reason explaining this behavior is that, unlike the other pipelines and for efficiency reasons, tassel disregards the information included in base quality scores, which restricts to relative allele counts the information to call genotypes. hence, even sequencing errors tagged during primary analysis with low base quality scores could produce false heterozygous genotypes. we believe that this is the main reason explaining the unexpectedly high number of predicted variants with low maf in the cassava f <dig> populations and the large percentage of heterozygous calls in the bean magic population. other difficulty we found while trying to compare tassel with other tools was that we could not find a way to run the pipeline on the nxa cassava population because the raw reads were already distributed per sample and were paired-end and not single-end. this issue makes a clear advantage for ngsep, samtools, and gatk over tassel in terms of usability because these pipelines can be directly used on data produced by different gbs protocols.

in our experiments tassel is the most efficient tool for gbs data analysis, followed by samtools. however in both cases the improved efficiency comes at the cost of lower accuracy. this difference can be critical in applications such as gwas because several markers with different allele frequencies need to be accurately genotyped within each genomic region to increase the chance of discovering true correlations between genomic and trait variation.

we are currently carrying on different efforts to improve the usability of ngsep, to allow more researchers acquire the capacity to analyze hts data with lower technical support. among other improvements, we released for our graphical interface a wizard that greatly simplifies the amount of workload needed to obtain datasets of variants from hts, and in particular gbs data. most of the functionalities of ngsep can also be deployed in a command line environment or integrated in a web portal solution such as galaxy  <cit> . we are also working with major bioinformatics software integration platforms such as cyverse  <cit>  to allow more users to benefit from the integrated analysis of entire populations achieved by ngsep.

CONCLUSIONS
bioinformatic analysis of gbs data with ngsep provides a powerful framework for discovery and genotyping of thousands of genetic markers in entire populations. analysis of several populations of different crops shows that ngsep currently provides a great balance between completeness, accuracy, efficiency and usability compared to other software packages. we expect to keep expanding ngsep with novel functionalities to facilitate genetic mapping of complex traits and to assist the genetic improvement of staple crops through the use of molecular breeding techniques such as genomic selection.

