BACKGROUND
in the beginning of  <dig>  oxford nanopore technologies  released miniontm, the first dna sequencing device based on biological nanopores, in a limited access program that enabled researchers to use the technology for the first time. miniontm is one of the few single-molecule sequencing technologies available that produces very long reads. moreover, miniontm constitutes the first portable high-throughput sequencer. it is the size of a smartphone and connects through a usb port to any internet-connected computer. while the technology initially produced data with a substantial amount of noise, recent practical applications have significantly demonstrated improved data quality  <cit> . in addition, a recent report has also revealed remarkable improvements in accuracy due to enhancement of the sequencing chemistry, to the present level of 85 % for dna reads from both strands  <cit> . the low cost, portability and the production of very long reads, along with a clear improvement in the quality, makes this technology one of the most promising high-throughput sequencing technologies available  <cit> . nanopore sequencing has been successfully used to sequence bacterial genomes  <cit> , viral genomes  <cit>  and eukaryotic genomes, such as yeast  <cit>  or drosophila  <cit> , either alone or, in combination with short read technologies  <cit> . also, nanopore sequencing technology has demonstrated its efficacy in clinics for real-time pathogen surveillance  <cit> , because it can rapidly identify strains  <cit>  and detect resistance genes  <cit> , or even detecting structural variation in cancer  <cit> .

initially, the use of the miniontm sequencer was restricted to windows laptops using specific cloud-based software, metrichor, for data handling and variant calling. the sequencer outputs binary files in the hdf <dig> format , which once called result in 30– <dig> thousand binary files. however, there was no software available for accessing the data. very recently, alternative solutions for data management and visualization have been proposed that provide more data management and visualization options and expand its use to other computer environments by using r   <cit> . however, the software available was devised for managing small individual projects with a relatively low throughput, corresponding to the present-day version of the miniontm instrument. new instruments, such as the promethiontm and the gridiontm are expected to be released during this year. such devices are parallelized versions of the miniontm instrument, with an expected throughput which will overrun those of short read technologies. ont anticipates that the current minion mki will be able to generate up to  <dig> gigabases per run, the minion mkii up to  <dig> gigabases per run, and the promethion up to  <dig>  terabases per run . with the aim of being scalable to cope with the foreseeable increasing amounts of data generated by this technology in the near future, here we present hpg pore, a scalable toolkit for exploring and analyzing nanopore sequencing data that can run on both single computers and the hadoop distributed computing framework.

implementation
the miniontm data format
the miniontm sequencer outputs binary files in the hdf <dig> format . the calling process generates one file for each miniontm read, which amounts between  <dig> and  <dig> thousands of individual fast <dig> files . such files can contain a template read, and a complement read or a two-direction  read , alone or in any combination. the template reads are derived from the first of the two dna strands presented to the nanopore. in the process of sequence reading, a processive motor enzyme, ligated to the leader adapter, slows down the template strands. hairpins permit reading of the complementary strand, which produces the complement read. the change between these two sequences is recognized by the pore because an ap  site located in the hairpin produces a specific signal. a different enzyme  has the mission of slowing down the complement strand. the optimal operation of the miniontm is attained when all these molecules are present and the hairpin successfully ligates both dna strands, which then traverses the pore producing the 2d reads  <cit> .

in addition, a fast <dig> file also contains meta-information for that read and the electronic signal measured over time as a dna molecule passes through the nanopore. a fast <dig> file contains a set of hierarchical groups , datasets and attributes  and all the required model parameters used by the hmm for base calling. the content of fast <dig> files can be visualized using the hdfview application .

data management
hpg pore can run both, on individual computers with a local or distributed posix file system such as lustre, or on a cluster of computers by implementing the map-reduce paradigm in a hadoop environment, the most popular open-source implementation of the map-reduce  <cit> , a distributed programming model for processing large datasets containing relatively independent data items . it divides data between processing nodes by splitting them into chunks  that are then processed separately. users specify a map function that processes a key-value pair to generate a set of intermediate key-value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key.

in the hadoop environment, a hadoop mapfile is used to store the individual fast <dig> files into the hadoop distributed file system . a mapfile is a sorted hadoop sequencefile with an index to enable lookups by using a key. a sequencefile is a flat file containing key-value pairs within hpg pore. here, the fast <dig> filename is stored as the key and the fast <dig> file content as the value. further, the hadoop map-reduce framework automatically splits the mapfile into key-value pairs and calls the user map function with these pairs. the creation of the hadoop mapfile from the fast <dig> files is accomplished by executing the import command in the hpg pore suite:

./hpg-pore.sh import --in/local/path/to/fast5/folder --out/path/to/hdfs/file 

the most important command provided by hpg pore is the stats command to analyze and visualize the fast <dig> files contents.

./hpg-pore,sh stats --in/path/to/fast5/--out/local/path/to/save/stats 

to run the stats command on a hadoop cluster, the --hadoop option is used. in this case the --in argument corresponds to the hadoop mapfile containing the fast <dig> files, otherwise, it corresponds to the local fast <dig> files folder. the --out argument indicates the folder where the results are saved: a subfolder for each run. table  <dig> describes the resulting files.table  <dig> files generated  by the stats command in hpg pore, where seq can be a template, a complement or a 2d read











extracting plotting events as well as fastq and fasta files
the events command extracts raw data from the electronic signal measured for a given miniontm read, and the signal command plots that signal over time .fig.  <dig> electronic signal measured for each nanopore translocation event over time for a given miniontm template read



finally, users can also extract the sequences in fastq and fasta formats by executing the fastq and fasta commands respectively:

./hpg-pore.sh fastq --in/path/to/fast5/--out/local/path/to/save/fastq/sequences 

./hpg-pore.sh fasta --in/path/to/fast5/--out/local/path/to/save/fasta/sequences 

availability
the hpg pore is open source. this cross-platform software is written in java and is available on github at http://github.com/opencb/hpg-pore. a tutorial and further documentation are available at http://github.com/opencb/hpg-pore/wiki

RESULTS
features
hpg pore has a number of features in common with the pore and poretools programs, but also implements several useful unique features related to quality control and other parameters of the sequence obtained, such as mean read quality, %gc, as well as plots per base sequence content and read quality histograms, among others. some of the features that differentiate the programs originate in the different ways in which data files are managed. for instance, pore produces one individual file for each sequence in the hdf <dig> file, which can cause problems with file systems quotas if a large number of reads are present in the hdf <dig> file. in contrast hpg pore produces three files containing the three types of reads , which is more convenient for further mapping with other software. table  <dig> summarizes the hpg pore features and compares them to those implemented in pore and poretools.table  <dig> comparison of hpg pore to the other tools available

 <dig> poretools does not display the nucleotide content percentage, only counts

 <dig> poretools returns the occupancy of pores, not the reads per channel



like pore and poretools, hpg pore produces fastq files that can be used for downstream analysis with any conventional tool for read mapping and further variation  analysis, genome assembly  <cit> , etc. recently appeared programs, such as nanook  <cit> , provides built-in downstream analysis with an environment in which alignment can be carried out and different statistics can be obtained. however, the optimal benefit would be obtained in a near future scenario in which downstream analysis tools can natively run in the hadoop environment. in order to avoid the transfer of hdf <dig> and fastq files to a local file system, we are currently implementing read mappers, such as hpg aligner  <cit> , in hadoop clusters.

runtimes and scalability
since different programs calculated different statistics, running times have been calculated for the generation of fastq files from the original hdf <dig> files. the programs were ran in a hadoop cluster with  <dig> nodes with  <dig> cores each  and 64 gb of ram and 12 tb distributed in  <dig> disks of 500gb.. we have included this information in the paper. our study shows that runtimes in pore, poretools and hpg pore  are approximately linearly dependent on the number of sequences in the fast <dig> file, with a trend towards an increased slope for high numbers of sequences. hpg pore runs the fastest, followed by poretools, while pore presents remarkably slower execution times . a specific problem with pore is that the large amount of sequence files that it produces causes disk quota excess errors. to run the program with high number of reads this parameter must specifically be changed in the file system.fig.  <dig> runtimes of the three programs, pore, poretools, and hpg pore, as a function of the number of sequences in the fast <dig> file



when hpg pore runs in hadoop mode it is faster than poretools and pore, despite an initial delay due to the preparation of the hadoop nodes and, as expected, the speed is even faster when more nodes are available, thus it outperforms the other two programs when running in local mode . the latency of the hadoop framework  causes the paradox that the stand alone version of hpg pore results slightly slower than the hadoop counterpart running on one node.

since reads are randomly distributed across nodes in the hadoop environment we do not expect from parameters such as read length any specific effect of runtimes or performance.

the hadoop environment allows storage as well as speed to be scaled up. figure  <dig>  shows how runtimes decrease as the number of nodes available in the cluster increases in four different scenarios: with  <dig> ,  <dig> ,  <dig>  and  <dig> million sequences in the fast <dig> file. the speed-ups are always over the ideal expected acceleration , and the increase in speed is clearly higher for larger data sizes .fig.  <dig> runtimes  and increase in speed  as the number of nodes increase in the hadoop system in two different scenarios: fast <dig> file containing  <dig>  ,  <dig>  ,  <dig>   and  <dig> million  sequences. dotted line in the lower panel represents the ideal speed-up according to the number of nodes used. speed-ups have been calculated using  <dig> nodes as the starting point given that the  <dig> million reads could not be calculated for <dig> only one node



CONCLUSIONS
nanopore miniontm technologies present several advantages, such as low cost, portability and the capability to produce very long reads  <cit>  that allow anticipating an extensive use in the near future. recently, new tools such as poretools  <cit> , pore  <cit>  and nanook  <cit>  have expanded the possibilities for nanopore data management and its use in operating systems other than microsoft. however, such programs are designed for the relatively low throughput of current nanopore devices, and even present limitations for large datasets. moreover, the foreseeable production of enormous amounts of nanopore data by increased throughput in the future by improved versions of miniontm , as well as new nanopore instruments which have been announced , will soon require of scalable computational technologies to cope with these data. here we present hpg pore, the first scalable bioinformatic tool for exploring and analyzing nanopore sequencing data that can run both individual computers and in the hadoop distributed computing framework. the hadoop environment allows virtually unlimited scaling up in data size and provides better runtimes for datasets containing a large number of reads. hpg pore allows efficient management of huge amounts of data and thus constitutes a practical solution for data analysis needs in the near future as well as a promising model for the development of new tools to deal with future genomic big data.

availability and requirements
project name: hpg pore

project home page:http://github.com/opencb/hpg-pore

operating system: linux centos release  <dig> 

programming language: java

other requirements: in hadoop mode requires hadoop installation

license: apache license

any restrictions to use by non-academics: no

abbreviations
2dtwo-direction read

apapurinic/apyrimidinic

hdf5hierarchical data format version 5

hphairpin

hpghigh performance genomic

ontoxford nanopore technologies

competing interests

the authors declare that they have no competing interests.

authors’ contributions

jt, ag and va developed and tested the code, im conceived the software and participated in the development, and jd participated in the conception of the software and wrote the paper. all authors read and approved the final manuscript.

