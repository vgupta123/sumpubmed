BACKGROUND
ant colony algorithm  belongs to the class of problem-solving strategies derived from nature. dorigo, maniezzo, and colorni  <cit> , using the traveling salesman problem   <cit>  as example, introduced the first ac algorithm. with the further study in this area, ant colony algorithm is widely applied to the problems of quadratic assignment problem   <cit> , the frequence assignment problem   <cit> , the sequential ordering problem  and some other np-complete problems. it demonstrates its superiority of solving complicated combinatorial optimization problems.

ac algorithms have been inspired by colonies of real ants, which deposit a chemical substance called pheromone on the ground. this substance influences the choices they make: the more pheromone is on a particular path, the larger the probability is that an ant selects the path. artificial ants in ac algorithms behave in a similar way. thus, these behaviours of ant colony construct a positive feedback loop, and the pheromone is used to communicate information among individuals finding the shortest path from a food source to the nest. ant colony algorithm simulates this mechanism of optimization, which can find the optimal solutions by means of communications and cooperation with each other.

the essence of the optimization process in ant colony algorithm is that:  <dig>  learning mechanism: the more trail information an edge has, the more probability of it being selected,  <dig>  updating mechanism: the intensity of trail information on the edge would be increased by the ants passing it and decreased by evaporation,  <dig>  cooperative mechanism: the communications and cooperation between individuals by trail information enable the ant colony algorithm to have strong capability of finding the best solutions.

however, the classical ant colony algorithm also has its defects. for instance, since the moving of the ants is stochastic, while the population size is large enough, it would take quite a long time to find a better solution. m. dorigo et al. improved the classical ac algorithm and proposed a much more general algorithm called "ant-q system"  <cit> . this algorithm allows the path which has the most intensive trail information with much higher probability to be selected so as to make full use of the learning mechanism and stronger exploitation of the feedback information of the best solution.

in order to overcome the stagnation behaviour in the ant-q system, t. stutzle et al. presented the max-min ant system  <cit>  in which the allowed range of the trail information in each edge is limited to a certain interval. wu qinhong et al. adopted the mutation mechanism in the ant colony algorithm to overcome the stagnation and to get fast convergence speed at the same time  <cit> . on the other hand, l. m. gambardella et al. proposed the hybrid ant system . in each iteration of has, local probe is made for each solution constructed by ants was used so as to find the local optimal. the previous solutions of the ants would be replaced by these local optimal solutions so that the quality of the solutions could be improved quickly.

however, pursuing a most quick convergence speed may cause problems such as super individual phenomena. super individuals refer to the ants which have much higher fitness values than other individuals, they overwhelm the solution set and their components often have high pheromone density. after some iteration, the new generations may be constructed mostly by these super individuals or by the components of them, and this will lead to the termination of the search process of the ant colony, that is to say, the algorithm is trapped into local convergence. these super individuals may reduce the global search capability of the ants, since it can only obtain local optimal solutions, i.e. premature solutions.

the other drawback of the classical ant colony algorithm is the close racing problem. if the fitness values and the structures of the individuals in the solution colony are close or approximate with each other, i.e. the spots corresponding to these individuals in the solution space are closed to each other  <cit> , the ants' search ability would be reduced, and the process of finding optimal solutions of the ant colony algorithm may be limited into a close local space, which may lead to the stagnation and close race problem. the major factor causing the two problems mentioned above is its lack of a diversity protection mechanism, which can keep the balance between the convergence speed and the quality of the solutions.

on the other hand, the research of ant colony algorithm at present was mainly focused on the human brain intelligence and its learning mechanism, but these personification methods can hardly take into account another hidden intelligence system named immune system. for the immune system of the organism has a high level of intelligence, and lots of superiorities such as immune selection, immune memory, immune metabolism, density control etc. these mechanisms and design optimization algorithms can be used to solve some complicated problems.

RESULTS
mapping the relationship of antibody and antigen to optimization problems
antibodies generated in the immune system are usually used to resist or eliminate the antigens, and if it maps this relationship into the optimization problem, looking at the object function as the antigen, moreover, the optimal solution of the given problem will be looked at as the antibody. meanwhile, the characteristics of the immune system will play an illumination role in improving the performance of the ant colony algorithm. in this paper, we simulate the behaviours of immune recomposition, immune memory, immune selection and density control etc.; design dgaa to solve different kinds of optimization problems.

diversifying solutions using immune strategy
in this algorithm, the individuals are selected to have crossovers and mutation operations according to their fitness value and the diversity of the solutions, and the mutation probability is determined by the diversity of the solutions. at the same time, the isolation niche technique separates the ant colony into several sub-colonies to execute the evolutionary course. in the search process, these sub-colonies are independent with each other and maintain their own features; hence, the algorithm becomes more and more flexible. experimental results on tsp  showed in fig.  <dig>  fig  <dig> and table  <dig>   <dig> and  <dig> demonstrate that our algorithm has strong optimization capability; it has diversified solutions, high convergence speed, and succeeds in avoiding the stagnation and premature phenomena.

discussions
we want to provide a diversity guaranteed ant colony algorithm  by adopting the immunogenic methods to ant colony algorithm and simulating the behaviours of biological immune system. this new type of ant colony algorithm uses the immunogenic methods of immune selection, immune memory, immune metabolism, density controlled strategy and isolation niche technique. but how to integrate immune strategies into ant colony, how to verify its performance is still an open problem for us.

the ant colony algorithm is mainly composed by an iterative algorithm including generation and verification operation, and the global search often realized by the pheromone feedback of the individuals in the colony, so that each individual can has an evolutionary chance or tendency, but meanwhile it may also be degenerated inevitably, even this degeneration is evident under some circumstances.

according to the conception and theory of immunology  <cit> , to maintain the eminent performance of the classical algorithm, we make full use of the characteristic of the problems and coalesce the specialty of the immune system to restrain the degeneration in the iteration.

CONCLUSIONS
the method for improving the performance of traditional ant colony algorithm presented here was performed on a pentium pc. the experiment results showed in fig.  <dig> and fig.  <dig> was carried out by applying the algorithm to symmetric and asymmetric tsp benchmarks provided by tsplib. these tsp benchmarks were also tested using the classical ant colony algorithm to compare its performance with our algorithm.

in dgaa the probability of ants selecting the vertexes and the increment of pheromone updating are adaptively adjusted according to the solutions of the former iteration of the ants. this makes the system never intensify the pheromone on the best path excessively, while the ants can make their evolutionary search towards the correct directions to get strong "mountain climb" capabilities in all directions of the solution space, and obtain optimal solution efficiently.

in addition, dgaa takes into account the polarization of the colonies, and adaptively adjusts the distribution of the solutions obtained by the ants. this makes the solutions more diverse so as to avoid the stagnation and premature. therefore, our algorithm makes a dynamic balance between convergence speed and stagnation, and this also shows that it is suitable for solving large scaled optimization problems.

