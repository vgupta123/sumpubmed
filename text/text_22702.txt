BACKGROUND
modern biomedical research is an increasingly knowledge-intensive endeavor. new experimental technologies and high-throughput analysis methods produce vast quantities of data with each experiment. systems biology approaches investigate biological processes on a large scale, relying on the measurement and analysis of thousands of variables in order to elucidate the structure and behavior of complex biological systems. online databases store an exponentially increasing amount of information, from raw dna sequences to high-level observations on genotype/phenotype correlations. the shift from hypothesis-based to hypothesis-free research that is made possible by these technological and methodological advances opens up unprecedented new opportunities for studying biological systems on a large scale, at a low cost, and with a holistic perspective that promises to expand our understanding of biological processes and of their connections with clinically relevant outcomes.

in order to take advantage of this paradigm-changing evolution, researchers will increasingly need effective, practical tools to handle very large volumes of heterogeneous data, both generated by their own experiments and retrieved from publicly available repositories of genomic knowledge  <cit> . integration, exploration, manipulation and interpretation of such data therefore need to become as automated as possible, since the "traditional" data inspection and analysis methods are quickly becoming inadequate in a scenario in which an investigator can sample hundreds of thousands of variables in parallel, and an entire new genome can be sequenced and annotated in a matter of days.

while a large amount of work is under way to develop ad-hoc analysis methods, able to address the well-known problems related with the statistical significance of results based on a very large number of observations, it is apparent that all phases of the scientific discovery process  will have to be adapted to this new reality. the post-genomic era will increasingly require methods and tools able to automatically link new observations and findings to preexisting knowledge.

finally, new data storage and retrieval systems will need to be developed and adopted in order to handle the unprecedented volumes of data and information being generated in an efficient and productive way. knowledge and data are represented using nomenclatures, classification schemes and annotation formats that are constantly evolving and often incompatible with each other. creating, storing and manipulating datasets consisting of hundreds of thousands of records, integrating knowledge from multiple heterogeneous sources, combining and mining data in novel ways for exploratory research, are all tasks that can represent a significant bottleneck for an average researcher who is not an expert in database usage or programming  <cit> .

the ability to effectively address the challenges outlined above will have a direct, dramatic impact on the speed, accuracy and effectiveness of scientific progress in all areas of the life sciences. we are therefore working on developing tools to facilitate the discovery process in high-throughput biomedical research, by providing high usability and effective automation of complex tasks through an easily accessible and intuitive interface. this paper describes genephony, a powerful online tool designed to assist the non-technical user in creating and manipulating large datasets of genomic information.

implementation
genephony is a web-based application whose main purpose is to allow the user to easily build sets of biological objects. sets can be created by providing identifiers or query terms, or can be derived from other sets through appropriate transformations. the system automatically keeps track of the relationships among sets, and allows the user to freely navigate through them via a simple, consistent and intuitive user interface. genephony is designed to be highly interoperable with other online tools: it accepts a wide variety of common formats in input, it provides extensive data export capabilities, and it features a soap server interface  <cit>  that allows other software tools to programmatically interact with it.

the knowledge base
genephony is able to handle a wide variety of object types, including genomic entities , classifications and taxonomies , experimental identifiers , computational predictions , and high-level genetic and phenotypic data .

the system relies on a local, integrated database of genomic information that includes information about most of the object types mentioned above and, when practical, on real-time access to online resources. it is important to note that genephony does not try to reproduce exactly the entire contents of all the source databases it uses: doing so would be extremely impractical and ultimately not very useful. genephony's local knowledge base, instead, represents a selection of the most commonly used object types and data elements, a selection that reflects the needs and requirements of an "average" genomic study. since the system is based on a modular and general architecture, the default knowledge base described here can easily be replaced with alternative ones that are focused on alternative domains, by defining new object types and new relationships among them.

the choice of maintaining a local database implies an effort to ensure its contents are up to date, through scripts that periodically check the source databases for new data releases. on the other hand, the alternative solution of retrieving the data from the source databases in real time is not practical for a variety of reasons: to start, most online resources enforce a limit on the number and frequency of queries that they accept from a client, making it impossible to work on large volumes of data; not all resources provide interface to access their data in an efficient and machine-friendly way; and finally, accessing very large datasets over the internet is usually too slow for practical uses.

data and object representation
biological objects are internally represented as data structures composed of several slots, each of which contains a single element of information. for example, snps  may be represented by an object containing slots for the snp identifier , its genomic location , its alleles, and its validation status. each object possesses a unique identifier. usually this will be the "natural" identifier of the entity being described, when available ; otherwise one will be internally generated by the system.

a set is a collection of objects of the same type. sets are created by the user by entering query terms, by uploading files, or by performing operations on existing sets. there is no a priori limit on the number of objects that a set can contain, or on the number of sets that can be created, and the system is optimized to handle sets containing a very large number of objects. sets can then be browsed, filtered, annotated and exported in a variety of ways. the next section provides detailed information on all the dataset operations available in genephony.

RESULTS
to start working with genephony, the user creates a session, giving it a unique identifier. no password is currently required, although one may be optionally used to protect data privacy. once a session has been established, the user can populate it by creating new sets in one of the following ways:

1) manually entering one or more identifiers. the system is able to automatically recognize a large number of common identifiers; this is accomplished by a set of autodetect procedures that examine the supplied identifiers and determine their possible meanings . when multiple identifiers are entered, the system will select the autodetector that applies to the majority of them; although the user has the option of overriding autodetection by manually specifying how to interpret identifiers, this is rarely necessary. after decoding all supplied identifiers, the system creates a set containing the corresponding objects.

2) by uploading a file containing identifiers. the system accepts delimited text files and excel spreadsheets, and handles both zip and gzip compression. the user needs only specify the column that contains the identifiers of interest; the identifiers are then parsed and translated into objects using the same procedure described in 1).

3) by deriving them from an existing set, or combining two existing sets. in a derive operation, a new set is generated using the data from a single existing one. for example, given a set of genomic regions, it is possible to generate the set of all snps belonging to them. in a combine operation, the data contained in two existing sets is used to generate a new one.

when a set is created, it is initially populated only with the identifiers of the objects it should contain; the object themselves are actually created the first time they are accessed, for efficiency . the data used to create the object are usually retrieved from the local database through highly optimized queries, although in general they could come from other sources as well .

all generated datasets are permanently stored in the current session. the system keeps track of how each set was generated, and of which other sets were generated by it. it is therefore always possible to reconstruct the path through which any individual dataset was produced, and the user has the option of navigating back to previously-generated sets at any time, in order to examine the data they contain or to generate new sets by following alternative derive or combine paths. moreover, the system records the relationships among individual objects in datasets that are derived from each other. for example, when a set of snps is derived from a set of genomic regions as described above, the system will create a table associating each snp with the genomic region  it belongs to, and each region with the snps it contains. in general, these will be many-to-many relationships, and will allow the user to determine how an individual object was produced or how many derived objects were produced by an object in the starting set. these data structures are also used by the annotate command as described below.

user interface
genephony's main interface window, shown in figure  <dig>  is divided into three panels. on the left is the workspace, which lists all the sets in the current session. the user can "focus" any one of the sets in the session by clicking on its name in the workspace panel; the currently focused set is shown in bold face. the top right panel displays information about the currently focused set: its name, a description, the number and type of object it contains, how it was generated, and how many other sets it is a parent of . this panel also contains the buttons through which the user can perform all available operations. finally, the bottom panel is used to display information about the contents of a set, or about its relationships with other sets; it is also used to get input from the user when running certain commands. for example, when the user clicks on the button for the derive command, the bottom panel will display the list of derive operations available for the current set.

the new command opens the initial page and allows for the creation of a new set. the info command displays additional information about the current set that would not fit in the top panel, such as the complete list of sets that were derived from it. the derive and combine commands are used to generate new datasets from the current one as described above.

the browse command displays the contents of the current set as a table in which each row represents an object in the set and each column contains one of the fields of the objects. several commands are available while browsing: the user may hide or show any column in the table, and sort the set contents by the value of any field by clicking on the header of the corresponding column. clicking on a table row brings up a page containing detailed information about the object it contains, including the set of "parent" objects that generated it. for instance, considering again the example described above, the page for an individual snp object would contain the complete list of fields with their values, and the list of genomic regions that contain it . the user may then choose to restrict the display to a manually-selected subset of the rows; the remaining objects in the set are effectively filtered out, as described below.

the filter command can be used to hide the objects in a set that do not meet a specified condition. once a dataset is filtered, all subsequent operations only apply to its visible elements. for example, a set of regions may be filtered to display only the ones belonging to a specified chromosome. if the user then applies the derive command to derive the set of snps they contain, the operation will be applied only to the visible regions, and the resulting set of snps will contain only the ones belonging to the regions on the specified chromosome. filters can be inverted, to select only objects that do not meet the filter condition, and multiple different filters can be applied at the same time, in order to select the objects that meet all specified conditions at the same time . finally, filters can be removed bringing the set back to its initial state, with all objects visible.

a very powerful feature offered by genephony is the annotate command that allows the contents of a dataset to be added to any one of its "parent" or "child" datasets. for example, a set of snps can be used to annotate the set of genomic regions it was derived from: the system will keep track of the relationship between each snp and the region it belongs to, so that when browsing or exporting the set of regions, the system will automatically associate each region with the set of snps it contains and display the contents of both datasets side by side . it is important to note that this feature works across any number of derive steps, in both directions: a set can be used to annotate its parent, its parent's parent, its child, its child's child and so on. combined with filtering and with the ability to select individual fields of the objects, the annotate feature can be used to create richly annotated datasets in a few simple steps.

the export command allows the user to retrieve the contents of a dataset in a variety of different formats, including tab- or comma-delimited text files, excel spreadsheets, and html tables. the files can be directly downloaded or received by email, with optional zip or gzip compression, or submitted to the galaxy online tool  <cit> . datasets containing objects that represent chromosome regions can also be automatically uploaded to the ucsc genome browser and displayed through its well-known interface. finally, the corresponding dna sequences  can be exported in fasta, genbank or embl format.

interoperability
in order to facilitate the exchange of data with other applications, genephony is designed to accept and to generate datasets encoded in the most common formats, including comma- and tab-delimited text files, excel spreadsheets, and html tables. in addition, genephony provides a soap server interface allowing external programs to use its capabilities independently of the web interface. the soap interface is self-documenting and is fully described in the system's help pages. its wsdl definition is also provided to enable the automatic generation of client programs.

example of use
in this section we present a detailed example of how genephony can be used to perform a complex data integration and annotation task. let us imagine we have performed a genotyping experiment on a large set of snps, and that statistical analysis of the results has identified a subset of snps that are significantly associated with the presence of a phenotype of interest. in order to better characterize our results, we would now like to determine which of these snps are located in genes that are known to be related to the phenotype. in the example described here, we used a dataset of  <dig>  snps, and we chose insulin-dependent diabetes mellitus  as the disease under study .

our strategy will be to query a database of genotype-phenotype correlations, such as omim or gad, for genes contained in regions known to be associated with the disease, to extract the snps contained in their transcripts, and to intersect this set of snps with the original set. to start, we create a new session and upload the input file using the "create dataset" form, specifying that the identifiers are in column  <dig>  the system automatically parses the "rs" identifiers contained in the file and creates an initial set of  <dig>  snps, that can be displayed using the browse command . next, we turn to the problem of identifying genomic regions associated with diabetes. one possible way to do this is by querying the omim database: we return to the "create dataset" screen and enter the query term "mim:diabetes" in the "enter region or identifier" field . this results in a set containing the  <dig> omim entries containing the word "diabetes" in their title. we then use the browse command to display the contents of this dataset, locate the row containing omim entry  <dig>  "diabetes mellitus, insulin-dependent, iddm", and select it by shift-clicking on it. clicking on the "click to filter" command appearing at the top of the browse window, we filter the omim set restricting it to this single entry. we can now exploit the information on genomic regions associated with phenotypes provided by omim to create a set of regions, using the appropriate derive command; the result in this case consists of the six genomic regions. with a further derive operation we create the set of all  <dig> transcripts contained in these regions and, in turn, of the  <dig>  snps contained in them.

in order to answer our original question, we just need to find the snps that appear both in this set and in the one uploaded at the beginning of this session. this is accomplished using the filter command, since one of the available filters restricts the set to the snps that also appear in another set. we apply this filter together with a second one that only displays validated snps, as shown in figure  <dig>  and the result is the set of  <dig> snps shown in figure  <dig> 

to conclude, we would like to annotate the resulting set of snps with information about the genes they belong to. we start by creating the set of transcripts containing the snps and the set of genes producing these transcripts, using two more derive operations . to simplify the display, we use the "choose columns" menu to select just the geneid, gene symbol, and gene name columns. then, using the "annotate" command we annotate these genes with the set of snps they were derived from. to view the resulting annotated dataset, we select the set of  <dig> snps from the workspace window, browse it, and select the set of genes from the "annotations" menu .

to summarize, using genephony we were able to quickly identify a set of snps belonging to genes that are known to be involved in iddm and for which we have genotype data in our dataset, a task that would have otherwise required accessing at least three different databases and performing complex data integration steps on large datasets.

CONCLUSIONS
as the life sciences increasingly become knowledge-intensive disciplines, every effort aimed at facilitating the production, organization and dissemination of new knowledge is bound to have a profound effect on the speed, accuracy and effectiveness of scientific research, and of genome-wide, hypothesis free research in particular. data and information production in this new era is measured on extraordinarily large scales: just in the field of sequencing, massively parallel dna sequencing systems have increased our sequencing capacity to hundreds of millions of base-pairs per process run. microarray technology for gene expression or genotype analysis is undergoing a similar evolution, with modern platforms now reaching one million simultaneous measurements. parallel advances are taking place in proteomics, transcriptomics and metabolomics. this is having a profound effect on genomics-based research throughout the full range of biological science: whole-genome studies that were once unfeasible are now within the possibilities of any medium-sized laboratory, the distinction between model and non-model organisms has been blurred, and it is now possible to directly sequence entire collections of microbes, and viruses.

genephony is an online tool aimed at researchers who need an easy, practical way to annotate, integrate and explore genomic knowledge and data resulting from large-scale experiments. the system is robust, efficient and extremely easy to use: it automatically determines which operations are applicable on each dataset, and presents them to the user in a detailed, readable form. identifiers are automatically recognized and converted in order to establish relationships between different datasets. interval operations are available for all objects that represent regions on chromosomes . very complex sequences of data manipulations can thus be performed in just a few steps, and no knowledge of the structure of the underlying database is required.

compared to similar systems such as galaxy  <cit> , david  <cit> , or biomart  <cit> , genephony offers a more explicit and general representation of biomedical object types and of the relationships among them , a flexible workflow model that does not constrain the user on a predefined analysis or annotation path, leaving him/her free to generate and combine datasets in an exploratory way, and powerful data reuse and interoperability features. moreover, genephony does not enforce a limit on the size of the datasets the user can use, thus making it possible to operate on the entire contents of a set at once regardless of its dimensions.

genephony does not currently offer graphical output capabilities, since its main focus is on knowledge and information management, but it provides flexible ways of exporting the contents of its datasets in standard formats for use in external visualization and data manipulation tools such as the ucsc genome browser and galaxy. although it is not an analysis tool, its rich knowledge base makes it suitable for scenarios ranging from basic genomic data annotation to translational research applications aimed at establishing links between the genomic level and medically relevant phenotypes.

the manipulation and interpretation of very large datasets represents a significant bottleneck for researchers who are not experts in database technology and programming. by providing them with effective tools to perform these increasingly common tasks, genephony has the potential to accelerate the process of turning experimental data into verifiable hypotheses and biomedically relevant findings. genephony could also be used as a platform for the dissemination of domain-specific knowledge, since its modular nature facilitates the creation of customized knowledge bases. it can therefore be helpful in making biomedical information available and accessible outside the boundaries of research community, resulting in an added benefit for the general public.

availability and requirements
• project name: genephony

• project home page: 

• access policy: the system is freely available to anybody. users are asked to enter a session identifier to start using the system. using an e-mail address as the identifier is preferable, but is not required.

• operating system: platform independent

• programming language: common lisp, java

• any restrictions to use by non-academics: freely available.

authors' contributions
ar designed the genephony system and was responsible for its implementation. an contributed to the development of the soap interface and other interoperability features. both authors read and approved the final manuscript.

