BACKGROUND
as an individual research laboratory we began high-throughput dna sequencing in  <dig>  accumulated experience with five independent expressed sequence tag  projects , bac shotgun sequencing, and a variety of ad hoc applications, including processing of sequences produced by other laboratories or sequencing centers, led to a system redesign in  <dig>  the result was the creation of a modular approach to a genomic, integrated and comprehensive database  and its interfaces, which is designed for gene discovery and expression applications  <cit> . magic-spp, which is the focus of this contribution, was created to meet our need for a database-driven sequence processing package, many parameters of which could be controlled by biologists using a web-based graphical user interface . while magic-spp can function as an independent tool, maximum value is realized when it is used as an integral part of the complete magic system .

arguably the most widely used independent tool for sequence processing today is lucy  <cit> , which has become part of the data processing pipelines of several genome sequencing centers  <cit> . estprep is a more recent independent tool for pre-processing raw cdna sequence reads, identifying features such as cloning vector and restriction sites, and assuring that only high-quality reads proceed to later stages of data analysis  <cit> . sequence processing tools have also been developed as part of more comprehensive packages, including the staden package  <cit> , mtt  <cit> , hopper  <cit> , gasp  <cit> , and mgi  <cit> . these packages typically include additional functionalities such as clustering and annotation. recently, packages have also been developed specifically for working with ests. pipeonline is an automated pipeline that transforms large collections of raw cdna sequences into a unigene est data set  <cit> . partigene is a generic and automated pipeline for processing raw trace files into a partial genome database  <cit> . estap is a set of analytical procedures for verifying, cleaning and analyzing ests  <cit> , while estweb is an internet-based package designed for processing and storing est data  <cit> . all use a relational database to store the processed data, having adopted different methods for processing raw sequences. these packages individually, however, do not provide a comprehensive package of platform independent guis that a biologist with few or no informatics skills requires to fully manage a diversity of dna sequencing projects, from creation, through quality control in the laboratory, to completion.

magic-spp has been developed in part to fill this latter need and in part to create an improved sequence processing pipeline. thus, it provides not only a flexible and automated sequence processing pipeline controlled by a relational database, but also a laboratory information management system  and a comprehensive set of interfaces to administer sequencing projects, explore sequences, monitor quality control, and troubleshoot problems in the laboratory. it consists of an oracle 9i database, a perl processing pipeline, and interfaces implemented with either javaserver pages  or a java gui. magic-spp is robust, having already processed more than  <dig>  sequences into magic db, of which  <dig>  were produced by four other sequencing facilities. these sequences have been processed for  <dig> independently defined projects, each typically consisting of a bac or a cdna library. its implementation at the university of georgia currently serves  <dig> user accounts organized into  <dig> access groups at a total of  <dig> universities or government laboratories. the package has also been installed at three additional sites. when magic-spp is used in conjunction with the comprehensive magic db system, it is integrated with tools for clustering ests, for mining and visualizing the results of such clustering, for electronic annotation of sequences, and for integration with miame-compliant microarray data  <cit> . it is ideally suited for use by both individual research programs and core facilities, possessing a combination of features presently unavailable in any other single package. here we describe the schema and sequence processing pipeline of magic-spp, together with an introduction to the interfaces that are part of this package. about  <dig>  sequence reads produced with magic-spp can be explored at and downloaded from a publicly accessible implementation of magic db using magic seqview  <cit> .

implementation
database design
an entity-relationship data model  <cit>  was used in the conceptual database design phase. the complete entity-relationship diagram for that part of magic db utilized by magic-spp is presented in figure  <dig> of additional file  <dig>  figure  <dig> provides the magic-spp class diagram in unified modelling language  <cit> . because it was determined that the database should not only serve as a biologist's notebook and a repository of processed data, but should also support automated, flexible and intelligent software for processing dna sequences, many data objects in magic-spp are used to address the following issues: how to process, what to process and where to store information.

as shown in figure  <dig>  clone is the class representing the dna to be sequenced, while trace is a class describing trace files derived from sequencing dna clones. clone has a one-to-many relationship with trace, permitting multiple sequences to be obtained from the same target dna. trace files are processed by phred  <cit>  to create sequence reads, characterized by the class sequenceread. the magic sequence processing pipeline focuses on creation of one or more sequence reads from each trace file and identifies the locations of regions of good quality, vector and adapter fragments, poly-t and poly-a tails, and contaminating dna.

two classes, qualityanalysiscontrol and platecontrol, deal with the issue of "how to process" . qualityanalysiscontrol defines high-level control of processing, such as organism-specific processing, whereas platecontrol defines low-level processing, such as processing trace files for a particular plate or wells within a plate. the processing pipeline needs to know how many procedures or steps are required, which program and program version will be used for each procedure or step, which parameters should be applied, where the associated executable and input files are located, and so on. that is why qualityanalysiscontrol has been associated with, among others, the classes program, version, file and parameter. sequence quality analysis is also organism specific. for example, human sequences do not need to be screened for chloroplast dna whereas sorghum sequences do. similarly, sorghum sequences should be screened against its own mitochondrial genome sequence, not that of human. therefore, genus and species are associated with qualityanalysiscontrol as shown in figure  <dig>  as described further below, a key feature of qualityanalysiscontrol is that each qualityprocessid  defines a specific workflow or protocol for processing raw trace files. any change in any part of the sequence processing pipeline, such as a change in phred version or modification in parameters for vector/adapter screening, results in a new qualityprocessid.

platecontrol relates to both the "how to process" and "what to process" questions. each trace file must be associated with a specific well in a defined 96- or 384-well sequencing plate. in high throughput dna sequencing, plates are usually homogeneous with respect to template source, vector orientation, and primer usage. a single plate, however, can sometimes be heterogeneous with respect to these parameters. this latter situation is handled by the complex associations among plate, library, vector and primer classes as shown in figure  <dig>  the key feature of platecontrol is that it serves as a bridge to bring to a processing pipeline all low-level information about processing, such as the type of sequencing performed , the identity and type of library sequenced, the vector and primer used, the direction of a sequence with respect to vector and, if dealing with a cdna library, the associated est direction. this bridge facilitates accurate processing of individual trace files obtained from a single plate containing samples that are heterogeneous as well as homogeneous with respect to parameters such as those enumerated here.

it is often important to associate sequence reads with genotype. moreover, libraries to be sequenced are frequently prepared from a mix of two or more genotypes. thus, genotype is a self-associated class that is also associated with library . magic-spp utilizes gtcombinecode to define different genotype associations . embedding this gtcombinecode into sequence names has proven to be extremely useful for downstream data mining and visualization of features such as sequence polymorphisms, for which genotype information is critical. we are unaware of any other processing pipeline that includes this genotype-association feature as an integral component of the sequence name.

library has a one-to-many relationship with seqnameformat, which supports different conventions for naming trace files and resultant sequence reads. seqnameformat permits processing of trace files using any naming convention as long as the name is clearly defined in terms of delimiter and/or component positions. an example of the magic naming convention is em1_17_a <dig> b1_a <dig>  in which  and  are delimiters. essential components include project or library name , plate number , well identification , sequence direction relative to the vector , a numeral  that is incremented each time a new trace file is obtained from the same clone with the same sequencing primer, and the appropriate gtcombinecode , as described in the preceding paragraph. among them, a project or library name, plate number, well identification and sequence direction relative to vector are required to be present in the name of a trace file if it was named by any convention other than ours. when processing such an external trace file, all of these essential components can be obtained by parsing the trace file name and/or retrieving from the magic database information entered into it by means of user interfaces, if that information is not present in the trace file name. using the class seqnameformat, a new name in our convention is created as an external trace file is processed. consequently, for an external trace file a sequence read will then have two names coexisting in the database such that it can be accessed by either. in this way, all trace files processed into magic db by this pipeline can profit from downstream data mining/visualization tools without requiring a user to work with the magic naming convention.

many classes are used for storing processed data. as already noted, sequenceread describes sequence reads, including base calls and their associated phred quality scores. sequenceread describes the results from processing trace files using a specific workflow or protocol defined in qualityanalysiscontrol. sequenceread is also an aggregate class because it has a "whole-part" relationship with many other classes, including vector, adapter, polyt, polya, and so on. the table for sequenceread has a primary key of qualityprocessid and seqname , which is inherited as foreign keys in the tables for its component classes. this design allows sequence reads and associated information derived from different implementations of the sequence processing pipeline to coexist in the database, thereby facilitating comparisons among different sequence processing parameters and/or components, such as different versions of phred.

sequenceread and its component classes are designed to represent sequence features at the level of individual trace files. during a sequencing project, biologists need to monitor progress and quality control, and to troubleshoot problems in the laboratory in a timely fashion. platestatistics was created to assist with these activities via the platecontrol class. it hosts plate-level information about sequence processing, which has a many-to-one relation to plate.

software design
the core of magic-spp is the processing pipeline, which processes trace files in stepwise fashion as described in the next section. foundation classes serve as a layer of abstraction to the relational database by encapsulating various sql queries for retrieving information from the database and for updating the database as processing proceeds. because some third-party software such as phred  <cit> , cross_match  <cit>  and ssaha  <cit>  are used, wrapper classes have been created to execute the third-party software with the capability of adjusting parameters and parsing results. processing classes mediate between foundation and wrapper classes to accomplish a given processing step or procedure.

because the database not only serves as a data repository but also controls processing, several user interfaces have been developed to support and/or take advantage of these dual functions. figure  <dig> illustrates the relationships among the sequence processing pipeline, magic db, and the various interfaces that provide input to the database and facilitate typical database queries of interest to the biologists who use magic-spp. the relationship between magic-spp and the entire magic system is illustrated in figure  <dig> of additional file  <dig> 

magic admin is a gui designed to facilitate for a biologist the entry of information required for control of processing. this information includes genus, species, genotype, vector, primer, colony picking, sequencing targets, and so on . it is accessible only to users who have been granted administrative privileges for a given sequencing project. among other functions, this interface is also used to create access groups and user accounts, to control read and write access to projects by access group or by individual user account, and to enter information required for genbank depositions.

magic seq-lims automates and tracks sequencing activities, from picking bacterial colonies, through thermal cycling, to automatic database-directed creation of plate records for an abi  <dig> or  <dig> sequencer . it serves as a notebook for technicians as well as a tool to minimize human error and ensure that standard operating procedures are followed. magic seq-lims is not, however, required to utilize magic-spp. we have, for example, used magic-spp to process into magic db ~ <dig>  trace files produced by other sequencing centers. as already noted, the sequence reads could in these cases be accessed by both the original naming convention and the standard convention used by magic.

a third interface, sequence statistics, displays information about sequencing yield and quality for selected plates and/or for an entire project. for an example of the information provided, see figure  <dig> in additional file  <dig>  two additional interfaces, status report and plate viewer, monitor progress during the course of a project and provide an aid for troubleshooting problems in the sequencing laboratory. for examples of these two interfaces, see figures  <dig> and  <dig> in additional file  <dig> 

a java gui, magic seqview, displays both base calls and their individual phred quality scores  <cit> . it displays sequence reads by both their original name and that used by magic, as well as considerable other information about each sequence read. sequence reads can be trimmed in several ways and can be downloaded from the database in fasta format as trimmed. they can also be translated, viewed and downloaded in all six reading frames. this java gui can be explored in conjunction with a public implementation of magic db  <cit> .

sequence processing pipeline
an overview of the sequence processing pipeline is presented in figure  <dig>  new features here include introduction of a gap-join/seq-merge algorithm for extending the useful length of sequence reads, the concept of expected vector length, an additional adapter screen to identify instances of adapter concatenation, and automated organism-specific screening for contaminants facilitated by the database and magic admin.

 <dig>  determination of quality region – gap-join/seq-merge
inputs for this step are conventional fasta sequence and quality files. four types of moving windows, each with a step size of  <dig>  categorize each base call as either bad  or good , as illustrated in figure 4a for the fourth and final moving window. each of these four windows examines the array of phred quality scores, using  <dig> as the threshold for a base call to be considered passing. the first is moving_window , with a size of  <dig>  pivot start position of  <dig>  and threshold of 80/ <dig>  in this window the pivot start position is the first called base, although for the subsequent three windows it is in the middle. if  <dig> of the  <dig> base calls in this moving window have a quality score of  <dig> or greater, then the pivot base is categorized as good. if no base calls are categorized as good, then the sequence will not be examined further. sequences that pass this first window are subsequently examined by two additional windows of varying length to identify short regions of low quality called gaps. gaps between  <dig> and  <dig> nucleotides long are identified by moving_window , while those at least  <dig> nucleotides long are identified by moving_window . all gap information is recorded in the database.

the fourth and final window is moving_window , which is used to determine the final high quality region . it has a more stringent threshold for categorizing a base call as good than does the moving window that identifies long gaps . gap-join/seq-merge determines whether or not an internal gap or gaps will be included in the final high-quality region. within the new array of quality category , the first and last fragments of high quality that have a continuous string of at least  <dig> good base calls  are identified. starting from this first fragment and moving towards the last along the quality category array, each gap is examined with reference to its immediately following high-quality fragment. if the length of this high-quality fragment is at least twice the length of the gap, then the gap is merged with its two adjacent high-quality fragments into a longer fragment of high quality . otherwise, the gap is joined with one or more adjacent gaps into a larger gap as shown in figure 4b. this procedure is conducted iteratively until the last fragment is finished. in the end, only one high-quality region, called the q <dig> region, will remain. it is defined by q16start and q16stop in the table for sequenceread. this region could be only the first high quality fragment, or it could be the result of merging this fragment with one or more gaps and other high quality fragments.

 <dig>  vector/adapter screening
initial screening is done with the appropriate vector/adapter fasta file, the name and location of which is retrieved from the database. vector and adapter fragment are identified with cross_match  <cit> . simple heuristics are used to categorize a fragment as either vf <dig>  or vf <dig> . the concept of expected vector length, which is the expected length from the last nucleotide of the sequencing primer to the first nucleotide of the insert for a given library when sequenced with a given primer, is an important component of these heuristics.

the expected vector length is defined as the sum of the following two parts:

 the number of nucleotides from the end of the primer, but not including any nucleotide that is part of the primer, to the last nucleotide immediately prior to the sequence recognized by the restriction enzyme in the multiple cloning site closest to the primer. this number does not include any nucleotide that is part of the restriction enzyme recognition sequence.

 the number of nucleotides from the first nucleotide at the beginning of the first restriction enzyme in the multiple cloning site, which is the same enzyme as in  above, to the last nucleotide prior to the beginning of the insert. this last nucleotide will be one of the following:  the last nucleotide of the adapter, if one is used or  the last nucleotide of the strand that contains the primer sequence after the vector has been cut by the cloning enzyme.

both values are entered into the database with magic admin. by defining the values in this fashion, maximum flexibility is achieved with respect to different primer-vector combinations and different cloning strategies with the same vector.

if a sequence has a vector segment with a start position less than the expected vector length plus an allowance for sequencing error, then it is categorized as vf <dig>  otherwise it is categorized as vf <dig>  unless its offset is less than the offset of the q <dig> region. if the total length of vector fragments within the q <dig> region is at least 90% of that region, then the sequence is tagged as total vector . this threshold of 90% is user adjustable. a sequence tagged as vtot is set aside, whereas other sequences are subject to further processing. the high-quality region after masking for vector and adapter is termed the q16v region. for some sequences, this region is not completely free of vector and adapter due to low quality base calls and occasional concatenation of adapters during library construction. to address this potential problem, an additional adapter-screening step is performed on the q16v region.

 <dig>  additional adapter screening
this additional screening also uses cross_match  <cit> , but applies more stringent parameters. screening for an adapter sequence is done only in the expected location as defined by expected vector length. for this step an adapter fasta file consists of up to two adapter sequences, one for each end of an insert. the minimum requirement for cross-match to work properly is an adapter length of eight.

 <dig>  poly-a/t screening
when requested through magic admin, magic-spp can include this optional step. two major phases are involved: detection of all poly-a/t segments and identification of one that is valid. if desired, the identified poly-a/t segment can be removed from the q16v region. because poly-a and poly-t screening use a similar algorithm, we describe here only the latter. in the detection phase, all segments with a specified length of continuous t are detected. for each segment, an internal error for a specified number of bases is allowed. the default value for length is  <dig> with internal error of  <dig>  in the identification phase, magic-spp first tries to merge in sequential order individual poly-t segments using a defined criterion, starting from the beginning of each sequence. the criterion involves evaluating the phred quality scores for bases in each gap between two adjacent poly-t segments and comparing the sizes of gaps and poly-t segments. a simple heuristic identifies a valid poly-t tail after merging segments. if vf <dig> is detected, then to be valid a poly-t must follow vf <dig> immediately. if vf <dig> is not detected, then for a poly-t to be valid it must be within the expected vector length plus  <dig> nucleotides from the start of the sequence read. the value of  <dig> is user adjustable.

 <dig>  contaminant screening
contaminants might arise from many sources, including escherichia coli, mitochondria, chloroplasts and rrna. contaminant screening, which is controlled by the database, is organism specific. the processing pipeline executes different screening programs intelligently, using for different organisms and projects the predefined information entered into the database with magic admin. in addition, a user can easily turn on/off the optional screening modules that are organism or project specific. significant matches with potential contaminant sequences are identified with ssaha  <cit> . relevant sequences are tagged with reference to the source of contamination. when a sequence is tagged as rrna or as an e. coli contaminant, it is excluded from further processing. sequences identified as mitochondrial or chloroplast contaminants are tagged as such, but nonetheless optionally proceed to further processing. that part of a sequence read that is screened for contaminants is referred to as a q16vs region.

system implementation
magic-spp utilizes three servers: database, web and analysis. the production database is implemented with oracle 9i in a dell poweredge  <dig>  using windows  <dig>  a publicly accessible database  <cit> , as well as databases established for developmental and educational functions, are in dell optiplexes using redhat linux as <dig> . the web server uses tomcat version  <dig>  on a dell workstation . the analysis server is a second dell poweredge  <dig>  using redhat linux as <dig> . all three components have been bundled successfully in a single desktop machine with redhat linux version  <dig>  and above .

the processing pipeline has been developed with perl  <dig> . <dig>  user interfaces magic admin, sequence statistics, status report and plate viewer are implemented with jsp. magic seq-lims is also implemented with jsp, but xml-rpc  is used to make remote procedure calls within jsp. magic seqview is implemented as a stand-alone java gui delivered by java web start. all of these client user interfaces will run on redhat linux, mac x, and windows operating systems.

RESULTS
magic-spp is designed to be a database-driven dna processing package, in which the relational database not only serves as a data repository, but also controls processing. the extensive interaction of magic-spp with a database to control processing permits a biologist with little or no informatics background to administer sequencing projects using the interfaces provided with it . substantial effort has also been invested in addressing the issue of database performance and extensibility during the design phase. for example, the primary key  in the table for the aggregate class sequenceread is inherited as foreign keys in tables for its component classes. one advantage of this design is that it facilitates greater data normalization and minimization of linking tables. a similar design has been adopted independently by the arabidopsis information resource to improve database performance  <cit> . in addition, improvements have been made to the typical sequence processing pipeline. in this section, we will emphasize those features that distinguish magic-spp from other available options.

in recent years automated and flexible workflow designs have been developed for bioinformatics analyses downstream from sequence processing  <cit> . the inclusion of an administrative interface designed for use by a biologist, combined with database control of sequence processing, provides magic-spp with a comparable capability for processing dna sequences. for example, once a biologist has inserted into the database the appropriate information about a project, organism-specific screening is fully automated. similarly, if the seq-lims interface is used, then plate records for the sequencer are automatically produced by the database, thereby minimizing human error and ensuring that trace file and sequence read names are created correctly. moreover, inclusion of platecontrol and its associated classes extends this biologist-directed automation down to the level of individual wells in a plate, providing maximum flexibility in application of the sequence processing pipeline. the inclusion of seqnameformat ensures that magic-spp can also be used in similarly automated fashion with naming conventions other than its own, yielding sequence reads that can be identified by either convention. in addition, by letting a biologist specify the goals of a project, such as the total number of sequences to be obtained in each direction, the status report interface  automatically reports progress upon request for any selected time interval.

the inclusion of qualityprocessid in qualityanalysiscontrol provides, of course, a way to associate with each sequence read a wealth of information about how it was processed or obtained from a trace file. in addition, however, the combined use of qualityprocessid and seqname as primary key in the table for sequenceread facilitates reprocessing of a trace file without compromising database integrity. consequently, a biologist can directly explore in high throughput fashion different processing parameters, methods, and/or program versions. it becomes a trivial exercise to compare even tens of thousands of sequences processed by both new and old versions of phred to determine whether it is appropriate to switch to the new version.

accurate identification of vector and adapter fragments can sometimes be very difficult, especially because regions of low quality typically occur at the ends of sequences where these fragments are typically found. to address this problem lucy has been modified to handle special and/or difficult cases  <cit> . occasionally, this approach results in reciprocal conflicts that lucy then attempts to mediate. magic-spp deals with this problem, at least at the beginning of sequences where it is most severe, by instead introducing the concept of expected vector length. as defined in the vector/adapter screening subsection above, a biologist familiar with a project's vector, sequencing primers, and cloning chemistry enters into the database the two values required to determine this parameter. it not only facilitates accurate identification of vector and adapter fragments, but also permits their characterization as either vf <dig> or vf <dig>  even though only one vector fragment might be present and even though the vector fragment might be masked by low quality base calls or other problems. expected vector length also facilitates, in the absence of recognizable vector sequence, accurate identification of the expected adapter, of concatenated adapters that occasionally appear as a consequence of the cloning chemistry, and of a valid poly-t tail in a 3' est. we have found these features to be distinct improvements, especially for single-pass sequencing projects such as ests.

to evaluate magic-spp with respect to adapter detection, we compared its performance to that of lucy. a cdna library with a relatively high frequency of adapter concatenation was selected for this purpose. the adapter was  <dig> nucleotides long. a total of  <dig>  5' est sequences produced by the whitehead institute were trimmed by both lucy and magic-spp, using default parameters for comparison. the results are summarized in table  <dig>  in the case of lucy,  <dig> % of the passing sequence reads retained one or more adapter sequences after trimming, while with magic-spp only  <dig> %, or  <dig> sequence reads, did the same. a text editor was used to estimate how many of these  <dig> sequence reads might have retained one or more adapter sequences because the templates from which they were derived contained three or more concatenated adapters. the text editor, which identified only perfect matches and which counted each input sequence only once regardless of the number of adapters, revealed that  <dig> of the  <dig>  input sequences had a string of three or more. by extrapolation,  <dig> of the  <dig>  passing sequence reads after trimming with magic-spp would be expected to have had three or more adapter sequences. because the text editor requires a perfect match, it likely underestimates the number of input sequences with three or more adapters concatenated, since there might be an occasional base call error. thus, since magic-spp looks only for the first two adapters, then it appears that magic-spp has missed fewer than  <dig> –  <dig> =  <dig>  an obvious future goal thus becomes the conversion of this second adapter screen to an object-oriented module such that it can be used to detect concatenated adapters regardless of their length.

the gap-join/seq-merge algorithm introduced here is another novel feature that again has special value in single-pass sequencing projects. this algorithm is designed to deal in a more resourceful manner with the common problem of short low-quality regions, which are often found in dna sequences and are referred to here as gaps. commonly, high quality regions are identified by moving windows comparable to that used here. lucy, for example, when faced with two or more high quality regions separated by one or more gaps selects the longest high quality region  <cit> . the processing pipeline for magic-spp, however, uses two additional moving windows to identify short and long gaps, placing information about those gaps in the database. by means of a fourth moving window , gap-join/seq-merge then evaluates these gaps in sequential fashion with reference to the length of each following region of high quality. if the following region is sufficiently long, then the gap is merged into a growing region of high quality. if not, then the next gap together with the intervening region of high quality is added to the gap. the result is an intelligent inclusion of gaps when appropriate, and termination of the high quality portion of a sequence read when there is relatively little remaining to be saved by jumping over a gap. these longer dna sequence reads are especially beneficial for downstream processing, in particular for est clustering and annotation. because information about the gaps is stored in the database, together with phred quality scores for every base call, this downstream processing can utilize that information to avoid potential difficulties.

two examples are provided to illustrate how lucy  <cit>  and magic-spp, both using default parameters, differ with respect to deciding where to trim a sequence read. figure  <dig> displays both base calls and phred quality scores  <cit>  for a sequence read that is part of a demonstration data set for lucy  <cit> . the region highlighted in green is the final high quality region identified by lucy. the gap that terminates this region is centered at nucleotide 377; it consists of three base calls with a score of zero. the average error probability for lucy's default _window_size <dig> of  <dig> is thus greater than the default maximum of  <dig> , resulting in a division of the original high quality region into two segments. the shorter region is then discarded. in contrast, while gap-join/seq-merge would also identify this gap, it would nonetheless merge the two high quality segments into one longer read because of the additional  <dig> high quality base calls. conversely, figure  <dig> similarly displays a sequence read produced with magic-spp. in this example, magic-spp has chosen to jump over a short gap centered at nucleotide  <dig>  thereby adding an additional  <dig> high quality base calls to the final high quality read. in contrast, lucy would determine that the average error probability for the default _window_size <dig> of  <dig> is  <dig> , well over the maximum permissible default value of  <dig> . consequently, lucy would choose by default to divide the high quality region into two segments, choosing the longer as its final output. with lucy, it is of course possible to obtain longer sequence reads by increasing the value for maximum average error probability. doing so, however, will simultaneously increase the probability of including low quality fragments at the end of a sequence read because, unlike magic-spp, lucy does not consider the length of any following high quality region when deciding whether or not to terminate a high quality region.

the results presented in table  <dig> provide further evidence of the overall improvement that can be obtained with magic-spp as compared to lucy, at least for a data set that is less than optimal. the yield of passing sequences is  <dig> % with magic-spp as compared to  <dig> % for lucy, while magic-spp and lucy gave average trimmed sequence lengths of  <dig> and  <dig> nucleotides, respectively. consequently, magic-spp and lucy provided total sequence of  <dig>  and  <dig>  ×  <dig> nucleotides, respectively. since  <dig> % of all base calls in the sequence reads trimmed by magic-spp were equal to or greater than phred quality  <dig>  it is evident that the overall sequence reads are still of high quality. this increase in yield is especially important for single-pass sequencing. in the case of ests, for example, primary objectives include facilitating gene discovery and developing gene models to assist with genome annotation. when given a choice of which of two high quality segments to retain, it might sometimes be preferable to retain the shorter because of its position in the sequence read. moreover, discarding any substantial high quality region will have negative impact on achieving the two objectives noted here. consequently, we suggest it is better to record gap information while retaining as many high quality base calls as possible, without significantly compromising overall sequence read quality. for those who wish to do so, it is of course possible to change the parameters of gap-join/seq-merge to better support other objectives.

future goals are intended to address broader issues. while magic seq-lims deals with a relatively generic, low-cost alkaline lysis miniprep, it will be useful to make it more versatile. we also plan to adapt magic to one or more open-source relational database management systems such as mysql  <cit>  or postgresql  <cit>  so that the expense of oracle can be avoided when that is an issue. similarly, creating a simpler stand-alone system that uses configuration files in place of a relational database will make it useful to those who do not have access to the expertise needed to administer a relational database management system.

CONCLUSIONS
magic-spp has been designed to minimize human error in a variable and demanding sequence processing environment, while simultaneously offering versatility, flexibility and automation. its extensive interaction with a relational database, coupled with the unique combination of features introduced here, makes magic-spp a flexible and robust sequence processing package well suited to individual research laboratories and core facilities. presently, about  <dig>  sequence reads produced with magic-spp can be explored at and downloaded from a publicly accessible implementation of magic db using magic seqview  <cit> .

availability and requirements
project name: magic-spp

project home page: 

project e-mail: magic-spp@plantbio.uga.edu

operating system: redhat linux  <dig>  above

programming language: perl  <dig> . <dig> and above, java, jsp

other requirements: oracle 9i , sun's j2se version  <dig> .2_ <dig> or above, tomcat  <dig> , bioperl  <dig> , phred, phrap, ssaha

license: gnu gpl

authors' contributions
cl and m-mc-p designed the database schema, as well as the entire magic system. cl and fs implemented perl processing pipelines. cl, fs and hw implemented jsp interfaces. hw implemented java guis. jq contributed to database optimization and manuscript revision. jq, cl and fs developed the uml representation. rmf compared magic-spp to lucy. lhp and m-mc-p managed project development.

supplementary material
additional file 1
supplementary figures for "magic-spp: a database-driven dna sequence processing package with associated management tools"

click here for file

 acknowledgements
the authors thank dmitri kolychev, zheng xia, virgil edward johnson and robert sullivan for providing valuable assistance. this work was supported by grants from the national science foundation plant genome research program  and the national institutes of health .

figures and tables
