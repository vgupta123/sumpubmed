BACKGROUND
copy number variations  i.e. deletions and amplifications, are an essential part of normal human variability  <cit> . specific cnv events have also been linked to various human diseases  <cit> , including cancer  <cit>  autism  <cit>  and schizophrenia  <cit> . historically, large cnv events can be observed using fish  <cit>  but systematic, genome-wide discovery of cnvs started with microarray-based methods  <cit>  which can detect events down to 1 kb resolution. as with all hybridization based approaches, these methods are blind in repetitive and low complexity regions of the genome where probes cannot be designed. high throughput sequencing with next-generation technologies have enabled cnv detection at higher resolution , in whole-genome shotgun datasets  <cit> . however, despite decreasing costs, deep-coverage  whole-genome data is still prohibitively expensive for routine sequencing of hundreds of samples, and in low-coverage  datasets detection sensitivity and resolution is limited to long genomic events  <cit> .

targeted dna capture technologies combined with high-throughput sequencing now provide a reasonable balance between coverage and sequencing cost in a substantial portion of the genome, and full-exome sequencing projects are presently collecting ≥ 25× average sequence coverage in thousands of samples. cnv events in exonic regions are important because the deletions of one or both copies, or amplifications affecting exons, are likely to incur phenotypic consequences.

current algorithms for detecting cnvs in whole-genome shotgun sequencing data use one of four signals as evidence for an event:  aberrantly mapped mate-pair reads ;  split-read mapping positions ;  de novo assembly ; and  a significant drop or increase of mapped read depth . unfortunately, these methods are not generally applicable for cnv detection in capture sequence data without substantial modifications. sr, rp, and as based methods are sensitive only to cnvs in which mapped reads or fragments span the event breakpoint . in the case of exon capturing data, this restricts detection to cnv events where at least one breakpoint falls in a targeted exon. rd based methods suffer from large fluctuations of sequence coverage stemming from variability in probe-specific hybridization affinities across different capture targets  and sets of such targets , and from the over-dispersion of the read coverage distribution in the same target across different samples. presumably because of the technical challenges, and despite the importance of deletion or amplification events within exons, there are currently no reported cnv detection algorithms for targeted dna capture based exon-sequencing data .

in this study, we set out to develop a cnv detection algorithm for capture sequencing data. this algorithm is based on rd measurement, and detects samples with non-normal copy number in the capture target regions. as participants of the  <dig> genomes project, we took part in the data analysis of the “exon sequencing pilot” dataset  <cit> , where  <dig>  exons from over  <dig> genes were targeted and sequenced with a variety of dna capture and sequencing technologies.

RESULTS
brief algorithmic overview
our algorithm is an extended version of rd-based cnv detection that aims to mitigate the vast target-to-target  heterogeneity of read coverage by normalization procedures roughly corresponding to those employed in cnv detection methods from microarray hybridization intensity data. the overall workflow of our method is shown in figure  <dig> and described in greater detail in the methods section. for a given gene in a given sample , we define the read depth as the number of uniquely mapped reads whose 5’ end falls within any of the targeted exons within that gene. we compare this measurement with an expected read depth , based on a “gene affinity” calculated from measured read depth for that gene across all samples , and the overall read depth for the sample . we then use a bayesian scheme to determine whether the measured coverage is consistent with normal copy number , or aberrant copy number . we have included two algorithmic variants: one is suitable for cnv events that occur at a low allele frequency , and the other for capturing higher-frequency deletion events .

dataset
in this study we analyzed the exon capture sequencing dataset collected by the  <dig> genomes project exon sequencing pilot, including  <dig> genes processed with agilent liquid-phase and nimblegen solid-phase capture methods, and sequenced from  <dig> individuals with illumina paired-end and/or  <dig> technologies. the samples in the dataset have been sequenced by four different data collection centers  using different pairings of capture and sequencing technologies . as our method relies on an estimate of the gene-specific hybridization affinity, it requires that such affinities are consistent across all samples analyzed simultaneously. according to principal component analysis of the observed read depths, , target and genes affinities are inconsistent across data from different centers, and therefore we analyzed each dataset separately. we only considered datasets with at least  <dig> samples  so we can obtain sufficient sample statistics across genes. after filtering out genes and samples that didn’t meet our minimum read depth requirements , we were left with the following datasets: sc , bi , and bcm  . the number of genes that passed our filters was substantially lower in the bcm dataset both due to lower overall  <dig> coverage , and because the longer  <dig> reads result in lower rd  when compared to shorter illumina reads, even at equivalent base coverage.

population abbreviations:

ceu – utah residents with northern and western european ancestry.

chb – han chinese in beijing.

chd – chinese in denver, colorado.

jpt – japanese in tokyo, japan.

lwk – luhya in webuye, kenya.

tsi – toscans in italy.

yri – yoruba in ibadan, nigeria.

sample coverage and gene affinities
as a metric of coverage for each sample, we calculated the sample-specific median gene rd, referred to as “median read depth” ; see figure 1a and methods. mrd was highest for the sc samples , see figure 2b. mrd was somewhat lower for the bi samples , and much lower in the bcm dataset . as mentioned above, rd  is not determined by base coverage alone. base coverage was highest in the bi data , followed by sc . the much lower rd in the  <dig> reads from bcm corresponds to only somewhat lower base coverage .

for each target we define a quantity, the “target affinity”, intended to describe the number of reads  being mapped to a given target, relative to the sample-specific mrd over all capture targets. analogously, we define the gene-specific affinity as the ratio of the number of reads  mapped to the targets  belonging to that gene and the gene-specific mrd for that same sample . in general, tighter distributions of affinities, with mean and median as close to  <dig> as possible, are desirable because these correspond to more even target coverage. the observed gene affinities for our datasets  were as follows: sc , bi , and bcm . because of the more favorable gene affinities, we used the sc data as our primary dataset for method development and experimental validations.

cnv candidates detected in the data
according to our bayesian detection scheme, we call a heterozygous deletion event in a gene if the posterior probability value of cn =  <dig>  i.e. p ≥ h where h is a pre-defined probability cutoff value. similarly, a homozygous deletion is where p ≥ h. although we detected both deletions and amplifications in the analyzed datasets, deletion events  provide easier detectable signal than amplifications. for this reason we only discuss deletion events here and report candidate amplifications in table  <dig> 

using a cutoff value h =  <dig> , we detected deletion  <dig> events in the three datasets , all heterozygous deletions . the top ranked deletions are shown in figure 3a. most of the events were found in the tuscan population, which constituted about half of the sample set.  <dig> of  <dig> gene deletions in the sc dataset were found in two samples , clustered in a contiguous string of deleted genes extending approximately 3 mb on chromosome  <dig> and  <dig>  respectively, a genomic deletion event that we were also able to find in the  <dig> genomes project whole-genome low coverage pilot data  <cit>  from the same samples .

when two or more gene deletions are detected in close proximity, it is likely that these events are part of a single, longer genomic deletion spanning the genes. with this in mind, we searched the sequenced genes for deletion events at a lower probability cutoff value , but required that an immediate neighbor of a candidate gene be located within  <dig> mbp and also show evidence for a deletion at the same probability cutoff. this procedure produced  <dig> heterozygous deletion calls in the sc dataset,  <dig> calls in the bi dataset . the union of both callsets  resulted in a total of  <dig> unique deletion events .

we note that none of the events we detected in our data were at high allele frequency. in fact, even the most “common” events were only present in two samples, as heterozygotes.

call-set accuracy assessment
to assess the accuracy of deletion calls made in the sc dataset, we performed experimental validations on calls made with posterior probability ≥  <dig>  without neighbor information, using qpcr . the validation results are summarized in figure 3b. of the  <dig> calls made, we evaluated  <dig>  all  <dig> calls with posterior probability ≥  <dig>  and  <dig> out of  <dig> calls  with posterior probability between  <dig>  and  <dig>  were submitted for validation.  <dig> were considered positively validated as they appeared in an earlier publication  <cit>  and  <dig> were validated de novo using qpcr. the qpcr validations produced positive results for  <dig> calls  and negative results for  <dig> calls . the validation results for the remaining  <dig> were inconclusive. all the  <dig> neighbored calls with posterior probability ≥  <dig>  were selected for validation.  <dig> were considered valid per previous publication  <cit> ,  <dig> were positively validated de novo and none was found invalid; validation was not obtained for the remaining  <dig>  the union of those two callsets counted  <dig> calls and  <dig> of them were evaluated. among these  <dig> calls  <dig> were considered positively validated per previous publication  <cit> ,  <dig> were positively validated de novo,  <dig> were invalidated,  <dig> were inconclusive and  <dig> did not obtain the validation results. the numbers of validated calls are presented in table  <dig>  the selection procedure for site validation was as follows:  we selected sites for validation ;  we searched the literature, and removed from the validation list events that we found as validated in one of the publications we consulted;  events that remained on the list were sent for experimental validation. the overall fdr for the union of calls made with and without neighboring information can be estimated as  <dig> % .

sensitivity
we performed simulations to assess the detection efficiency of our method, both for individual gene and for pairs of neighboring genes deletions. specifically, in each sample we randomly selected   <dig> out of  <dig> genes in one simulation and   <dig> pairs of neighboring genes in another simulation. in the selected genes we down-sampled the actual read depth seen in the experimental data by a factor of  <dig> to simulate a heterozygous deletion. the results of those simulations are presented in figure 3c. of the  <dig> gene deletions, we detected  <dig> . of the  <dig> gene-pair deletions we detected  <dig> . we also performed simulations on smaller subsets of the original  <dig> samples to assess the impact of sample size on detection sensitivity. reduction of sample size did not substantially degrade detection sensitivity as long as the number of samples was > <dig>  therefore, our detection efficiency is 40-45% without using neighboring information and approximately 50-55% with the use of neighboring information, in the sc dataset.

in addition to simulations, we compared our dataset to a published study  <cit> . this study reported  <dig> heterozygous deletion events in samples and genes  that were part of our analyzed dataset. we detected  <dig> of these  <dig> events, which is broadly consistent with our overall sensitivity estimate.

finally, we investigated our sensitivity to common events  using simulations. figure 3d shows detection sensitivity as a function of gene-level affinity: for a gene affinity value of  <dig>  , sensitivity to common events  approaches 40%. note that the detection efficiency starts to decrease at high allele frequency  due to a reduction of the overall read depth because more samples have a deletion and a corresponding depleted read depth signal. we can also see that the median gene affinity is substantially lower than the mean because the distribution of gene affinity has a long tail at the high end . since sensitivity is directly related to the gene affinity, the simulated data with the substantially higher mean gene affinity  has better sensitivity than with the substantially lower median gene affinity .

the number of cnv events in the samples
we estimated the total number of gene deletions in the sc dataset from the number of detected events , the fdr  and the detection efficiency , as ~ <dig>  or a nominal  <dig>  deletions per sample. by projecting the per-sample number, corresponding to  <dig> % of the exome , onto the whole exome, our estimate for the average number of genic deletion events is  <dig> ±  <dig> per sample. this estimation is representative for the whole-exome sequencing data since the  <dig> genomes exon pilot project randomly selected all the exon targets from the ccds collection. our gene set is therefore a quasi-random sampling of known human genes, with no intentional enrichment for any given gene family. figure 4a and b show the distributions of exon length in the gene list used for our analysis and the full human exome. there is no significant difference between these two distributions: the median and the standard deviation of the exon length for our study are 125 bp and 236 bp, whereas the corresponding values for the whole exome are 127 bp and 264 bp. the similarity of these two distributions suggests that our estimation of the number of events per sample is unbiased and is representative for a whole-exome analysis.

detection efficiency as a function of data quantity and data quality
as discussed earlier, our algorithm’s sensitivity was ~45% at ~ <dig> % accuracy. both sensitivity and accuracy are considerably lower than achievable for snp detection in the same datasets  <cit> . this poses the more general question of how detection efficiency is influenced by sample size, data quantity, and data quality. our simulations show that sensitivity only modestly depends on sample size, above approximately  <dig> samples .

we found that the primary factors that determine detection efficiency are  sequence coverage, or more precisely, rd ;  the level of over-dispersion of the rd distribution for individual genes ; and  the shape of the distribution of rd across all genes in the dataset, determined by the gene affinities .

for each gene, we compute a quality index  taking into account the variance of the expected read depth for that gene , rdexp, and a over-dispersion factor, odf, that quantifies the over-dispersion of rd relative to the poisson expectation:

  qi=rdexpectedodf 

qi is directly related to detection sensitivity , as shown in figure 5b. according to our power calculations, for the posterior detection threshold value we used in this study , sensitivity is completely diminished for genes with qi <  <dig> . qi ≥  <dig>  is required to achieve 50% sensitivity, and qi ≥  <dig>  to achieve 90% sensitivity. this estimated sensitivity from qi is made only for heterozygous deletions. to achieve the same sensitivity for detecting higher copy number variation , higher qi value will be required since the difference of prior probability between higher copy and normal copy  is greater than that between heterozygous deletion and normal copy .

the distributions of qi values in our three datasets are shown in figure 5c. overall, qi was highest in sc:  <dig>  ±  <dig>  ; second highest in bi: qi =  <dig>  ±  <dig>  ; and lowest in bcm: qi =  <dig>  ±  <dig>  . the corresponding distributions of detection efficiency values are shown in figure 5a. because detection efficiency increases abruptly from  <dig> to almost  <dig> over a narrow range of qi values , the distribution of detection sensitivity  is strongly bimodal, with the vast majority of gss having either close to zero or close to 100% sensitivity. even in the sc dataset with the highest overall qi values, in less than half of the gss does the quantity and quality of the data support >80% detection efficiency. there was also very substantial variation across samples: only  <dig> of the  <dig> sc samples had sufficiently high coverage to support ≥ 90% overall sensitivity, and in  <dig> samples overall sensitivity was below 10%.

given that qi improves only with the square root of rd, over-dispersion can profoundly influence detection performance, as shown in figure 5b. the odf values we chose for this figure correspond to the 25th, 50th and 75th percentile, and the mean values  in the sc dataset. using the observed distribution of qi in the sc dataset, we predict ~46% sensitivity, in good agreement with our estimate based on simulations.

the qi formulation permits one to estimate cnv  detection power in any given exon capture dataset, based on the read mappings. one can also use the formulation to calculate the amount of base coverage required for a given level of desired power, to guide data collection. for example, using the distributions of qi values in the sc dataset, one would need to collect an overall 110× coverage, assuming 36 bp reads, to achieve 60% detection power, and 320× coverage to achieve 80% detection power. however, if dna capture methods improved to support a median odf= <dig>  assuming an accordingly scaled version of the observed distribution of qi in the sc dataset, one would only need to collect 33× coverage for 60% power, and 96× for 80% power. it is important to also point out that, in the case of whole-exome data, sensitivity would also improve just by virtue of the higher density of targeted genes, if one were to integrate in one’s pipeline neighbor-gene based detection.

methodology comparison with conifer
krumm and his colleagues recently published a method, conifer  <cit> , that also used read-depth signal to detect cnv in the exome capturing sequencing data. like our method, conifer normalizes the read depth signal in order to discover the cnv. however, it is quite different for these two algorithms in the approach of calling samples copy number variants on the basis that they present aberrant read depth. as we mentioned previously, our method deploys specific models for copy numbers  <dig>   <dig>   <dig>  and is capable of detecting both rare, intermediate frequency, and common cnv events. on the other hand, conifer deploys singular value decomposition  to remove noise from the read depth data, and interprets the first “k” singular values as noise in the data. this approach may identify systematic variance in the data caused by a high-frequency cnv event as noise and removes it. therefore conifer has limited power for detecting common cnv events. on the other hand, our method is capable of detecting cnv events on the entire frequency spectrum, and is therefore more generally applicable.

CONCLUSIONS
we have developed a novel, bayesian method to identify cnvs in exon-capture data. we applied this method  to the  <dig> genomes project exon sequencing pilot dataset. we were able to achieve reasonable sensitivity and specificity in a dataset that was optimized for snp discovery and, as discussed above, is far from ideal for cnv detection. the main accomplishment of this work is that we provide a statistically rigorous algorithm for cnv detection in exon capture data, backed by experimental validations, that can be applied to the thousands of exomes sequenced to date in various medical projects, and to nascent and ongoing projects targeting increasingly higher numbers of samples. our formulation allows investigators to assess detection power in existing datasets and to take into account cnv detection power during experimental design for future datasets. we also uncovered > <dig> heterozygous deletion events in the  <dig> genomes samples we examined, allowing us to estimate the average number of heterozygous deletions per exome . because we focused on algorithm development functional assessment of these sites is beyond the scope of this study. nevertheless, these and other gene deletions that will be found using our methods are very likely to uncover events with strong functional significance.

