BACKGROUND
detecting somatic mutations by next generation sequencing  is a critical part of cancer research and diagnostics. in tumor samples and circulating nucleic acids, mutations may be present in a very low fraction of dna molecules for reasons such as normal tissue contamination or mutations occurring in a small subset of tumor cells. these very low level somatic mutations have been the target of intense investigations in recent years, because they hold great promise for early detection of cancers, monitoring the effectiveness of targeted therapies and early intervention against drug resistant clones.

in order to detect these very low allele fraction mutations, deep sequencing coverage is normally required since mutations need to be observed on a sufficient number of reads to pass predetermined variant calling threshold. for example, to observe a  <dig> % variant on minimum two reads with 90% probability, a minimum of 200x coverage is required based on the binomial distribution. in practice, 1000x or higher coverage is recommended to call  <dig> % variants  <cit> . targeted sequencing enables researchers to focus sequence capacity on a small genomic region of interest, making it an appealing approach to achieve very deep coverage in a cost effective way. both hybridization capture and pcr amplicon based approach have been used in enriching specific genome regions. the pcr amplicon approach is preferred by many researchers due to its low dna input requirement, simple protocol and fast turnaround time. however, the inability to identify read duplication of the same sample fragment is an inherent limitation in typical pcr amplicon sequencing.

having deep sequencing coverage alone is not sufficient for detecting mutations at very low allele fractions. more importantly, researchers need enough original dna molecules sampled in the sequencing workflow. for example, detecting 1% mutations reliably from the starting materials of  <dig> genomes is extremely difficult, no matter how many read duplications are produced. this becomes a significant issue for damaged ffpe samples, as the optical measurement of the dna input does not reflect the real number of usable molecules. a target enrichment workflow needs to efficiently capture a large number of original dna molecules. furthermore, read duplication usually confounds the estimation of the number of dna molecules captured.

besides read depth and dna input, detecting mutations at very low allele fractions is challenged by errors introduced in many steps of the ngs process. in pcr-based targeted sequencing, target templates are bound with gene-specific primers and amplified via multiple pcr cycles. given enough input, a large amount of dna fragments will be captured so that even very low allele fraction mutations can be observed on plenty of reads. however, the reads often contain errors that are difficult to distinguish from true variants. the errors are accumulated during the critical steps of an ngs protocol, including library preparation, sequencing, and read alignment. for example, in pcr amplification, dna polymerases have an error rate of 10− <dig> per base  <cit> . sequencing errors typically occur at a higher rate. studies have shown that illumina miseq platform has an average error rate of  <dig>  to  <dig>  per base, depending on how far away the base is from the read start and other factors  <cit> . other literature indicates that the error rate is between  <dig>  to  <dig>  per base on general illumina platforms  <cit> . errors can also happen to the read alignment algorithms, especially when a read fails to span a repetitive region or covers a region containing complex variants near each other. low allele fraction and relatively high error rate together lead to poor signal-to-noise ratio, making it difficult to identify true variants without generating false positive variant calls. moreover, because dna fragments are not evenly amplified due to resampling bias  <cit> , the observed variant allele fractions are often skewed, which may ultimately lead to inaccurate variant calls.

molecular barcoding technology aims to reduce the impact of enrichment and sequencing artifacts and has the potential to improve mutation detection accuracy . in brief, each original dna molecule is tagged with a unique molecular barcode. after amplification and sequencing, the barcode sequence can be retrieved from the reads, allowing each read to be traced back to its original dna molecule. molecular barcoding has recently been implemented in several ngs target enrichment protocols and researchers have demonstrated its utility in somatic variant detection and rna quantification  <cit> . quantification of template molecules can be done by counting the number of unique barcodes rather than the number of total reads, which reduces pcr resampling bias and improves quantification accuracy. variant detection can also benefit from molecular barcodes because sequencing errors can often be identified by comparing across the reads containing the same barcode.

the progress in enrichment and sequencing technology brings about more complicated ngs data that require advanced bioinformatics tools to analyze. bayesian and other statistical models have been applied in variant calling algorithms such as snvsniffer  <cit> , fasd  <cit> , and mutect  <cit> . snvsniffer models the read counts of the observed genotypes using a multinomial distribution, and infers the true genotype that has the largest posterior probability calculated under a bayesian framework. mutect evaluates the likelihood of variant using the log odds score, which is the likelihood ratio of mutation versus wild type. fasd is a germline variant caller that evaluates the snp probability by calculating an alternative score from a binomial distribution-based model. however, these variant callers were developed for sequencing data without molecular barcode. appropriate analytical methods are needed to take full advantage of the molecular barcode information. a two-step approach has been proposed and has demonstrated utility in detecting variants as low as 1%  <cit> . at first, a consensus sequence is constructed for each barcode. next, downstream analyses  are performed on the set of consensus sequences with existing bioinformatics tools such as the aformentioned ones. there are several downsides to this approach. first, useful information may be lost when constructing the consensus sequences. for example, in vardict, the ratio between low quality and high quality reads is an important parameter in the variant calling algorithm  <cit> . however, the ratio will likely be skewed in the consensus sequence set. second, building a base quality score system for the consensus sequences that mimics the phred scores used in the raw reads is difficult. the downstream variant caller cannot achieve optimal performance if skewed quality scores are passed to it, because the phred base quality score is a centerpiece in most variant calling algorithms. third, from a practical standpoint, maintaining and updating software from different sources can be time consuming. for example, many trial-and-error iterations might be required to tune the parameters in both the consensus-generating algorithm and the third party variant caller to make them compatible. we believe that a full-fledged variant caller that integrates molecular barcode information into the statistical algorithm will be valuable to researchers in the field.

we have developed smcounter, a barcode-aware variant caller that detects single nucleotide variants  and short insertion and deletions  at very low allele fraction. smcounter applies a bayesian probabilistic model to evaluate the read evidence for each nucleotide as well as possible indels at a target position, and compares the strength of evidence with a preselected threshold to make variant calls. smcounter also implements several filters to further reduce false positive calls. using a simple protocol that integrates molecular barcodes into multiplex pcr enrichment, we have generated two targeted sequencing datasets from samples containing defined mutations at 1-5% allele fractions. smcounter has been run on both datasets and has demonstrated very good sensitivity and specificity in detecting coding region variants at 1% allele fraction.

RESULTS
multiplex pcr enrichment with molecular barcodes
we have developed a protocol that incorporates molecular barcodes into the multiplex pcr primer enrichment process . briefly, template dna is enzymatically fragmented and end repaired to approximately 300-500bp. then a modified illumina adapter containing molecular barcodes is ligated to the 5’ end of the dna fragments. after removing unused adapters, a few pcr cycles are conducted using an illumina adapter primer and a pool of single primers, each carrying a gene specific sequence and a 5’ universal sequence. during this process, each single primer repeatedly samples the same target locus from different dna templates. afterwards, additional pcr cycles are conducted using universal primers to attach complete illumina adapter sequences and to amplify the library to the desired quantity.
fig.  <dig> multiplex pcr enrichment workflow with single primer




compared to existing target enrichment approaches, our method relies on single end adapter ligation, which inherently has a much higher efficiency than requiring adapters to ligate to both ends of the dsdna fragment. more dna molecules will be available for the downstream pcr enrichment step. pcr enrichment efficiency using one primer is also better than conventional two primer approach, due to the absence of an efficiency constraint from a second primer. during the first pcr cycles, primers have repeated opportunities to convert  maximal amount of original dna molecules into amplicons. all three features help to increase the efficiency of capturing rare mutations in the sample. in addition, incorporated molecular barcodes in the amplicon are the key to estimating the number of dna molecules captured and to greatly reducing sequencing errors in downstream analysis. single primer enrichment also has the potential to discover unknown structural variants, such as gene fusions.

data generation
in order to develop and benchmark our barcode aware variant caller, we created dna samples with defined variants at low allele fractions, to simulate low fraction somatic mutations in tumors. dna from na <dig> was mixed at 10% and 2% with dna from na <dig>  the genotypes of both subjects have been extensively studied by the genome in a bottle consortium   <cit> . the high confidence set of na12878’s variants and an initial set of na24385’s variants have been released to the research community. for our variant calling purpose, we defined a “ground truth” variant set by masking the na <dig> variants from the high confidence na <dig> variants. this sample mixing approach has been adopted in several other studies for benchmarking variant callers  <cit> .

a first panel  was designed for algorithm development and optimization. this panel covers variant-rich hot spots by design in order to provide maximum number of variants to optimize sensitivity . the first enrichment library was prepared using 10% na <dig> admixture . later we also in silico diluted na <dig> molecules to 2% to simulate 1% variants for algorithm development. the in silico dilution procedure is described in additional file 2: supplementary methods. variant allele fractions before and after the dilution are illustrated in additional file 2: figure s <dig>  although suitable for algorithm development, n <dig> does not resemble a typical cancer sequencing panel because the enriched region contains many variants within short distance of others, and contains very little  coding region. therefore, a second gene panel  covering the coding region of  <dig> cancer-related genes was designed to reflect the intended application of cancer sequencing . enrichment and sequencing were done using 2% na <dig> admixture for this panel, so unique heterozygous na <dig> variants were at 1% allele fraction.

both libraries yielded highly uniform and specific coverage of the target regions, demonstrating the superior performance of our enrichment protocol. both sequencing runs achieved very deep coverage in terms of read depth as well as barcode depth. detailed information on the sequencing performance can be found in table  <dig> 



overview, development, and performance of smcounter
smcounter has two main components: a statistical model to evaluate the likelihood of a variant and several post-processing filters to further reduce false positives. at each target locus, posterior probabilities of the alleles  are first calculated on the barcode level, noted as p for the k
th barcode. assuming the locus is covered by n mutually independent barcodes, a prediction index i=−∑k=1nlog10) is given to each allele, representing the likelihood that the allele exists in at least one dna molecule. if a non-reference allele’s prediction index exceeds the preselected threshold, this allele is considered as a candidate variant. candidate variants will be confirmed only if they pass all the post-processing filters. details of the statistical model and filters can be found in the methods section.

the development of smcounter, including model establishment and refinement, filter design, parameter optimization, and data cleaning steps, was mainly based on over  <dig> variants in panel n <dig>  over 90% of n0015’s target loci are in non-coding region where repetitive sequences are much more abundant compared to typical coding regions. these challenging genomic regions provided rich training data for us to develop specific filters that significantly reduced the false positive rate in homopolymer, low complexity, and micro-satellite regions. in addition, we used the variants to refine the statistical model to take full advantage of the barcode information. in particular, we optimized the estimation of barcode level allele probability p to ensure that the estimated probabilities gradually degrade to zero as the read evidence weakens . we also used the barcode level allele probability to develop the “strong barcode” filter, which rejects candidate mutations lacking enough barcodes with good read evidence. smcounter achieved good overall performance in calling  <dig> and 1% snvs, showing higher sensitivity in coding region compared to non-coding region .
fig.  <dig> illustration of how barcode level read evidence is evaluated for a hypothetical barcode with  <dig> read pairs, assuming all reads have either t  or a  at the specific locus. the x-axis is the number of read pairs with the alternative allele a, ranging from  <dig> to  <dig>  the y-axis is − log10), the amount of read evidence for a assign to the barcode. overall, the amount of read evidence for a is close to  <dig> when less than half of the reads are a, and then gradually increases




given the good results from n <dig>  we then ran smcounter on the cancer-related gene panel n <dig> and benchmarked its performance against the giab ground truth set using rtg tools  <cit> . we also ran mutect  <cit>  and vardict  <cit>  for this panel to assess the variant calling performance under our enrichment protocol without using molecular barcode information . the receiver operating characteristic  curves for all three variant callers on n <dig> are presented in fig.  <dig>  the performance metrics  under the optimal cutoff, heuristically defined as the point on the upper-left corner of the roc curve, are listed in table  <dig>  the performance data from n <dig> demonstrate that smcounter is able to detect 1% snvs at over 90% sensitivity with less than  <dig> false positives per megabase of the target coding region. the performance data also show, with a lower confidence level due to small sample size, that smcounter can detect 1% indels at over 90% sensitivity with less than  <dig> false positives per megabase in the coding region. overall, smcounter achieved comparably high sensitivity as mutect or vardict but with much fewer false positives, demonstrating the value of molecular barcoding for low fraction variant calling.
fig.  <dig> variant calling performance on 1% variants in panel n <dig>  x-axis is the number of false positives per megabase and y-axis is sensitivity. solid lines, dashed lines, and dotted lines represent smcounter, mutect, and vardict respectively. each point on the roc curve represents a threshold value. a roc curves of smcounter, mutect, and vardict base on  <dig> snvs. b roc curves of smcounter and vardict on  <dig> indels. note that mutect does not call indels





variant calling on reduced barcode and read depth
in practice, variant calling accuracy may be limited by the amount of sample input and sequencing capacity. to characterize smcounter’s performance under imperfect sequencing conditions, we downsampled the n <dig> read set to  <dig>   <dig>   <dig>   <dig> and 10% of barcode depth  and the read depth to  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig>  per barcode. the performance of smcounter at all barcode depth and read pairs per barcode  combinations are demonstrated in additional file 2: figure s <dig> and s <dig>  snv calling results in a subset of this parameter space are highlighted in fig.  <dig>  we observe that smcounter’s performance degrades gradually as the barcode depth and rpb decrease. we also observe that  <dig> read pairs  per barcode is sufficient in most cases and additional read replications provide little additional value. the downsampling procedure is described in the additional file 2: supplementary methods.
fig.  <dig> smcounter performance on calling 1% snvs in n <dig>  based on reduced barcode depth and rpb. for better visualization, only a subset of barcode depth and rpb combinations are plotted. cutoff selection and detection limit estimation are also based on the same downsampled data. a roc curves at barcode depth of  <dig>  ,  <dig> , and  <dig> with rpb fixed at  <dig> . b roc curves at rpb of  <dig>  ,  <dig> , and  <dig>  with barcode depth fixed at  <dig> . c optimal cutoffs that give the maximum sensitivity while allowing no more than  <dig> fp/mb at varying barcode depth  and rpb . the dashed line is the linear regression equation of cutoff versus barcode depth across all rpb values. d estimated detection limit as a function of locus-specific barcode depth, overall average barcode depth, and false positive rate  allowed. the y-axis is the lowest variant allele fraction that can be detected with at least 95% probability based on a binomial distribution




cutoff selection
selecting the right cutoff is critical to achieving good performance for most variant callers. however, it is often unclear to users on how to choose the cutoff value, partly because the optimal cutoff usually correlates with the unknown amount of dna molecules captured. with molecular barcodes, we are able to provide users with a guideline on cutoff selection based on the barcode depth and the desired false positive rate. to illustrate the method, we define the optimal cutoff value as the one that gives the maximum sensitivity while allowing no more than  <dig> false positives per megabase. using the downsampled n <dig> data, we obtained the optimal cutoff values of smcounter at all barcode depth and rpb combinations. based on both visual inspection  and a one-way anova analysis, the optimal cutoffs do not differ significantly in different rpb groups . pooling all rpbs together, the optimal cutoff value has a strong positive linear relationship with the barcode depth . we propose a simple linear equation y=14+ <dig> x to predict a recommended cutoff value, where y is the recommended cutoff value and x is barcode depth. we also provide optimal cutoff values for other desired false positive rates, as shown in table  <dig> 
y=14+ <dig> x
y=15+ <dig> x
y=13+ <dig> x



variant detection limit
molecular barcodes allow us to estimate the locus specific detection limit, defined as the lowest variant allele fraction that will be called. the detection limit is mainly determined by the barcode depth at the locus, the average barcode depth of the sequencing run, and the false positive rate allowed. within a target region, loci with higher barcode depth will have lower detection limits , simply because the likelihood of observing real low fraction variants is higher. on the other hand, when comparing two different sequencing runs, a locus with the same barcode depth in both runs will have higher detection limit  in the read set with higher average barcode depth, because a more stringent cutoff value will be used to control the false positive rate, as proposed earlier. finally, the more false positives one allows, the lower detection limit one can achieve. the estimation of locus specific detection limit is illustrated in fig.  <dig> and explained in details in the methods section. similar to a coverage map, a detection limit map can be built for a region to provide a visual inspection tool . knowing this information is particularly important in guiding the proper interpretation of negative variant calls in ffpe samples. a desired detection limit may be achieved by simply increasing the dna input based on observed molecular barcode counts.

discussion
in this paper we presented a simple pcr based target enrichment protocol that integrates molecular barcodes in the sequencing reads. we demonstrated that our protocol can enrich a large genome region with high efficiency, specificity, and uniformity. the presence of molecular barcodes in the reads provides us with an effective means to estimate the number of unique dna molecules sequenced and to effectively distinguish true variants at very low fractions from sequencing errors in the reads. using our enrichment protocol and reference materials from the genome in a bottle consortium, we generated datasets containing defined dna variants at very low allele fractions. using this data, we developed our barcode aware variant caller and evaluated its performance.
fig.  <dig> an example of barcode and detection limit map on brca <dig> exon chr17:41222944- <dig> based on n <dig>  the maps were generated using ucsc genome browser




smcounter is the first full-fledged variant caller that integrates molecular barcode information into a statistical model and has demonstrated very good sensitivity and specificity in detecting 1% snvs and indels within targeted coding regions. still, we acknowledge several limitations of smcounter as well as the enrichment technology.

during the development of smcounter using n <dig> dataset, we observed decreased variant calling performance in non-coding regions compared to coding regions. in particular, the current version of smcounter has reduced power in detecting low allele fraction indels in non-coding regions . the decreased performance is mainly due to more repetitive sequences and additional nearby variants  within non-coding regions of n <dig> that caused read alignment errors. our design strategy for n <dig> panel to maximize the number of variants covered within a small target region likely resulted in over-representation of challenging genomic regions such as homopolymers, simple repeats, and low complexity regions . many of the true variants within or flanked by these regions are falsely rejected by our stringent filters. tuning the filter parameters towards more leniency will lead to higher sensitivity but also more false positives. a more practical approach is to train highly specific filters based on large amount of variants in the challenging regions using statistical or machine learning methods. fundamentally, higher variant calling accuracy in the challenging regions should be achieved by improving the read alignment quality. one promising advance in this field is to use graph-based genome representation for read alignment instead of commonly used linear representation of the reference genome  <cit> .

like other variant callers, smcounter’s performance is largely determined by the preselected threshold and the optimal threshold is an unknown function of numerous factors, including sample input, dna quality, sequencing depth, sequencing platform, etc. we have observed a linear relationship between the optimal threshold and the barcode depth and provided an empirical formula to predict the optimal threshold for a range of barcode depths and rpb levels. the robustness of the formula under the conditions outside the tested range is unclear. moreover, the predictive formula may need to be empirically modified under significantly different pcr chemistry or sequencing error rate due to platform change.

in the enrichment protocol we used, a complete barcoded amplicon is only formed after the first target specific primer extension event. in principle, any polymerase error introduced in this very first step cannot be distinguished from real variants based on individual barcode consensus. so variant detection is theoretically limited by the polymerase fidelity during the first pcr enrichment cycle. in fact, we have observed several false positive calls that cannot be easily explained by obvious reasons and were possibly due to early polymerase errors. in practice, we have leveraged additional information  to reduce this type of false positives. for example, two primers can be designed to target the locus in both sense and anti-sense orientations. the chance is extremely low that polymerase error happens at the same locus during primer extension events on both strands. thus, many false positives can be eliminated based on biased distributions between sense and anti-sense strand. a more elegant approach is to employ duplex sequencing  <cit>  by directly pairing the sense and antisense strand information at the single molecule level rather than at the population level. we are currently working on a scheme to integrate duplex sequencing into primer enrichment step, and we plan to report our results in a future publication.

our current enrichment protocol also has limited ability to distinguish dna damage induced artifacts from real variants. artifacts induced by base damage could be common in ffpe samples depending on how the samples are prepared  <cit> . to identify such artifacts, one must examine both strands of dna, because the damage to both stands is usually not identical. similar to dealing with early pcr errors, we can use biased distributions between sense and anti-sense strand to eliminate some artifacts. a better direction is to employ duplex sequencing.

accurate detection of very low fraction variants in dna holds big potential in our understanding of tumor heterogeneity and in early disease diagnostics. we believe our improved enrichment protocol, benchmarking dataset and barcode-aware variant caller will provide valuable resources for continued progress by the research community.

CONCLUSIONS
we developed a targeted dna enrichment protocol that integrates molecular barcodes into original dna molecules. we also developed smcounter, a somatic variant caller that integrates the molecular barcode information into a bayesian probabilistic model. we have demonstrated that, with our protocol and variant calling algorithm, we can detect 1% allele fraction variants in coding region with over 90% sensitivity and less than  <dig> false positives per megabase. we believe our method will be an important contribution to cancer sequencing and somatic mutation detection.

