BACKGROUND
identification of protein binding site has significant impact on understanding protein function. development of fast and accurate computational methods for protein binding site prediction is helpful in identifying functionally important amino acid residues and facilitating experimental efforts to catalogue protein interactions. it also plays a key role in enhancing computational docking studies, drug design and functional annotation for the structurally determined proteins with unknown function  <cit> .

protein binding site prediction has been studied for decades  <cit> . several machine learning methods have been applied in this field. these methods can be split into two groups: classification methods and sequential labelling methods. the essential difference between classification methods and sequential labelling methods is that the classification methods treat each residue as independent and ignore the extra information from neighbouring residues or constraints of a single sequence, i.e. treating the protein binding site prediction as a classification problem. in contrast, the sequential labelling methods are able to consider the correlations between labels, to include long-distance interaction and to model the protein sequence as a whole. an example of comparison of classification methods with sequential labelling methods for protein binding site prediction is shown in figure  <dig> 

classification methods, such as support vector machines   <cit>  and artificial neural networks   <cit> , treat the protein binding site prediction as a classification task. these methods are based on the sequence or structure characteristics of known protein binding sites, such as sequence conservation  <cit> , interface propensities  <cit> , secondary structure  <cit> , accessible surface area  <cit> , 3d-motifs  <cit>  and residue evolutionary information  <cit> . because none of the individual property carries sufficient information that can be used to make an unambiguous identification of interface regions or patches, a combination of some of them  is found to be effective in improving the accuracy of binding site prediction  <cit> . kim et al. presented a hybrid approach by using both sequential and structural features  <cit> . burgoyne and jackson analyzed the ability of different key physicochemical attributes and binding surface properties, such as surface conservation, to predict the binding interface  <cit> . to improve prediction robustness and accuracy, meta-ppisp  <cit> , a meta web server, combined results from different predictors including cons-ppisp  <cit> , promate  <cit>  and pinup  <cit> . although the classification methods yield exciting results, these methods separately study the target residues and do not take the relation between two labels  of neighbouring residues into consideration. some researchers noticed the importance of the inter-relation information between neighbouring residues for predicting protein binding sites and proposed several methods to use this information. yan et al.  <cit>  pointed out that interface residues tend to form clusters in the primary amino acid sequence and proposed a two-stage classifier. chung et al.  <cit>  used the clustering as a post-processing strategy to remove the isolated interface residues predicted by svm. although performance improvement is observed for these methods, they only use the local relation between neighbouring residues. in our previous study, we proposed a conditional random field -based method  <cit> , which treats the prediction of protein binding site as a sequential labelling task. in contrast to the traditional classification methods, such method uses the relation between neighbouring residues in a global fashion and shows better performance than traditional classification methods. surveys of the methods for protein binding site prediction have been performed by two studies  <cit> .

in this study, we introduce a novel machine learning scheme which overcomes several disadvantages associated with existing methods. the model is based on hidden markov support vector machine   <cit> , which treats the protein binding site prediction as a sequential labelling task based on the maximum margin criterion. hidden markov support vector machine  is introduced initially for solving the problem of labelling sequence data that arises in the scientific fields such as bioinformatics and natural language processing. in addition to hm-svm, some other methods also suit to label sequence, such as hidden markov model   <cit>  and conditional random field   <cit> . hmm is one of the most common methods for performing sequence labelling. hmm is able to model sequential dependencies by treating the label as a markov chain, which avoids direct dependencies between subsequent observations and leads to an efficient dynamic programming formulation for inference and learning. it is a generative model that maximizes the joint probability distribution p, where x and y are random variables whose values take on all observation sequences and corresponding labelling sequences, respectively. despite its success, hmm has at least three major limitations. 1) hmm is trained in a non-discriminative manner. 2) the conditional independence assumptions are too restrictive. 3) hmm is based on explicit feature representations and lacks the power of kernel-based methods. crf is another successful method for sequence labelling, which is a discriminative probabilistic model. crf uses a single exponential model for the conditional probability of all training labels, given the observation sequence. therefore, the weight of an arbitrary feature can be learned from its global interactions with all the other features. this means that the weights of all the features within crf can be traded off against each other. however, like hmm, crf is based on explicit feature representations and lacks the power of kernel-based methods. hm-svm follows the discriminative approach like crf to model and comprises two additional crucial properties inherited from svm: the maximum margin principle and a kernel-centric approach to learn non-linear discriminant functions. hm-svm has been applied to some common problems in natural language processing, such as named entity recognition and part-of-speech tagging  <cit> . the experimental results are significantly better than those from other sequential labelling methods such as hmm and crf. in this paper, three state-of-the-art methods including ann, svm and crf are compared with our method for protein binding site prediction. these methods are trained by using common features derived from protein sequences and structures including protein sequence profile and residue accessible surface area. when tested on different types of data sets, the results show that our method performs well and its running time is several orders of magnitude shorter than that of the compared methods.

RESULTS
comparison with related methods
through the experiments reported here, the performance of the three following methods is compared with our method: artificial neural network , support vector machine  and conditional random field . these three methods are state-of-the-art methods within the field of protein binding site prediction  <cit> . ann and svm are classification methods, while crf is a sequential labelling method. for detailed setup procedures of these methods please refer to the method section. table  <dig> summarizes the performance of the various methods on the six data sets and the roc cures are depicted in figure  <dig>  it is obvious that hm-svm outperforms the other methods in terms of auc for predicting protein binding sits. for each method, the performance on the homo-complex data sets is better than the performance on the hetero-complex data sets, which is consistent with previous study  <cit> . generally speaking, the sequential labelling methods are consistently better than the classification methods. on the six data sets, hm-svm yields the best performance according to mcc, f <dig> and auc, which indicates that hm-svm can obtain better trade-off between specificity+ and sensitivity+ automatically. another sequential labelling method crf gets the second best performance. the classification methods svm and ann are worst according to our experiment and svm is better than ann.

specificity+ = tp/; sensitivity+ = tp/; f <dig> =  <dig> × specificity+ × sensitivity+/; accuracy = /; mcc = /; auc: area under roc curve  <cit> . where tp is the number of true positives ; fp the number of false positives ; tn the number of true negatives; fn the number of false negatives.

avalues in parentheses are randomly predicted values. the specificity+ of random prediction is calculated as: the total number of interaction sites residues/the total number of residues.

bvalues in parentheses are randomly predicted values. the sensitivity+ of random prediction is calculated as: the total number of predicted residues as interaction sites by each method/the total number of residues.

cthe total running time  for 5-fold cross-validation, including training and testing.

dtype i data set with minor interface as negative samples.

ethe mixed data set of hetero-complexes and homo-complexes.

ftype ii data set with minor interface as positive samples.

one important aspect of any protein binding site prediction method is its computational efficiency. we compare the running time of each method and the results are shown in table  <dig>  all the experiments are performed on a personal computer with cpu of intel pentium  <dig>  ghz and memory of 3g. concerning the computational time of different methods, only ann is comparable with hm-svm, but the prediction performance of ann is considerably lower than that of hm-svm. hm-svm is two orders of magnitude faster than crf and three orders of magnitude faster than svm. table  <dig> provides a qualitative estimation of computational costs of different methods.

l and h represent low computational cost and high computational cost, respectively.

influence of the number of training samples on the prediction performance and running time
in order to investigate the influence of the number of training samples on the prediction performance and running time for each method, we generate a series of training sets with different number of training samples. we randomly select about one fifth of the chains from mix i data set as the test set , and the remaining chains are used as the training set . different percentage of the whole training set is used as the training set. figure  <dig> shows the performance of different methods trained with different number of training sample. for different training size, hm-svm consistently outperforms the other methods in terms of f <dig>  mcc and auc. the curves of hm-svm are smoother than those of the other methods, indicating that even trained with small number of training samples, hm-svm can achieve stable performance. figure  <dig> shows the relation between the running time and the number of training samples. the running time of the three methods ann, crf and hm-svm approximately scales linearly with the number of training samples, while the running time of svm increases significantly with the number of training samples from small to large, especially for large training set. overall our method can be quickly trained on a large data set and get good results. additionally, even trained on small data sets, our method can achieve stable performance.

the inter-relation information between neighbouring residues is relevant for discrimination
to examine whether the inter-relation information between neighbouring residues learned by hm-svm is relevant for discrimination, we run a control experiment. in the experiment, each residue is taken as an observation sequence in order to remove the relationship between residues of a protein sequence in the original training set. hm-svm is trained on this modified training set and then tested on the original test set. the results on the six data sets are shown in table  <dig>  compared with the results obtained on the original data sets, the results of hm-svm on the modified data sets are lower in terms of f1-measure, mcc and auc. therefore, we conclude that the inter-relation information between neighbouring residues learned by hm-svm is relevant for discrimination.

the window size has not significant influence on the performance
for each labelled residue, its profile feature and asa feature are taken from a window containing n  nearest spatially neighbour residues . the window size is selected using embedded 5-fold cross-validation independently for each test set of the 5-fold cross-validation procedure. the influences of the window size on the performance of hm-svm on mix i data set are illustrated in figure  <dig>  the results show that the window size has not significant influence on the performance of hm-svm. when the window size is larger than  <dig>  hm-svm can achieve stable performance. the window size of  <dig> is used in this study, since it is the optimal window size for the svm-based methods suggested by two related studies  <cit> .

evaluation of the performance in the context of three-dimensional structures
to further evaluate the performance of our method, we examine predictions in the context of the three-dimensional structures. two proteins are selected from hetero-complex i data set and homo-complex i data set and the results are shown in figure  <dig> and figure  <dig>  respectively. as can be seen from figure  <dig>  most of the false positives predicted by the classification methods ann and svm locate on far away from the actual interface, while the false positives predicted by sequential labelling methods crf and hm-svm are roughly around the actual interface, especially hm-svm can successfully distinguish interface and non-interface residues for this protein. this result is not surprising. traditional classification methods separately study each residue without using the relation between two labels  of neighbouring residues. in contrast, sequential labelling methods take inter-relation information between neighbouring residues into consideration. similar results are also observed for homo-complex. as shown in figure  <dig>  the prediction results of sequential labelling methods are better than those of classification methods. among the four methods hm-svm achieves the best prediction performance.

discussion
methods which predict interface residues using amino acid sequence along with the structure of the target protein  are of interest, because relatively few experimentally determined structures of protein-protein complexes are currently available  <cit> . in this paper, a novel approach based on hm-svm is used to label surface residues as interface residues or non-interface residues. this method is especially useful in the case where the structure of the target protein is known but the structure of the complex formed by it with one or more proteins is unknown. our method does not only make full use of the relation between two labels  of neighbouring residues like crf-based method, but also shares the advantages of the svm-based method. upon validation with six types of data sets, the method yields better results and its running time is several orders of magnitude shorter than that of the compared methods. three factors contribute to the results. firstly, the relation between labels of neighbouring residues is useful for protein binding site prediction. secondly, the kernel trick is very advantageous to this field. thirdly, the complexity of the training step for hidden markov support vector machine is linear with the number of training samples by using the cutting-plane algorithm.

two points should be emphasized in evaluating the significance of the protein binding site prediction results. firstly, as shown in table  <dig>  for each method the performance on the data sets with minor interface as positive samples  is better than the performance on the data sets with minor interface as negative samples . the reason is that some of the false positives predicted on type i data sets are in fact binding sites on type ii data sets. although we consider all the known partners in the pdb file of a target protein on type ii data sets, some residues identified as false positives in performance measure of our method and the compared methods could in fact be residues that actually participate in contacts with proteins other than their known partners in the pdb file. secondly, it should be noted that the data sets have highly unequal numbers of positive samples and negative samples. as noted by yan et al.  <cit> , in such a scenario, matthews correlation coefficient  is a much better indicator of the performance of a method than accuracy, since accuracy favours the majority class. for example, if 80% of the residues are non-interaction residues, a predictor which always predicts a residue to be a non-interaction residue will achieve an accuracy of 80%. however, such a predictor is useless for protein binding site prediction. in addition, f <dig> is another good indicator, since it is a trade-off between specificity+ and sensitivity+.

recently, Šikić et al.  <cit>  developed a classification method based on random forests for protein binding site prediction. tested on a hetero-complex data set, the best results of their method are obtained when using a combination of sequence and 3d structure information. the method can achieve a specificity+  of  <dig> %, a sensitivity+  of  <dig> , an f <dig> of  <dig> % and an accuracy of  <dig> %. although performance comparison between our method and their method is rather difficult owing to the different definition of interface residue and different data set, our method seems to show better performance on our hetero-complex ii data set in terms of f <dig> . although their method shows higher accuracy, it should be noted that this performance measure is not a good indicator as discussed above. therefore, we have reason to believe that the overall performance of our method is better than or at least comparable with theirs.

our goal is to evaluate different machine learning methods and to show our method can effectively improve protein binding site prediction. although our discussion focuses on a single protein binding site prediction system using two basic features , other features can be added to our system to improve the performance. therefore, researchers who are interested in finding novel characteristic features of protein binding sites could use our system to validate the effectiveness of their features and our system would also benefit from these features.

CONCLUSIONS
successful application of hm-svm to protein binding site prediction is of great significance. there are many problems in the biology domain that can be formulated as sequential labelling tasks, such as protein disorder prediction  <cit> , protein secondary structure prediction  <cit> , kinase-specific phosphorylation site prediction  <cit> , dna binding site prediction  <cit> , rna binding site prediction  <cit> , prediction of cis/trans isomerization  <cit> , protease substrate site prediction  <cit> , disulfide connectivity prediction  <cit> , functional residue prediction  <cit>  and catalytic residue prediction  <cit> . most of them are considered as challenging problems. thus, these important sequential labelling tasks are potential areas for applications of hm-svm.

