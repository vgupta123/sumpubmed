BACKGROUND
it is well established that early detection of cancer often results in a better prognosis. this detection has relied on measuring the concentration of a particular protein or biomarker, such as cancer antigen - <dig> for ovarian cancer and prostate specific antigen  for prostate cancer. unfortunately, many of the commonly used biomarkers have a low sensitivity and/or specificity which necessitate the search for new biomarkers. clinically it is useful if the measurement of a biomarker be obtained from a readily available biofluid, such as blood, urine, tears, or mucous. bioinformatic analysis of data obtained from biofluids may result in identifying new biomarkers.

the standard procedure is to obtain biofluid samples from individuals with known histologies and perform an search of experimentally measured quantities, or features, to construct and test a classifier. this is done by dividing those individuals with and without a given disease into a training set and a testing set. the training set is used to construct a classifier from a subset of the features such that it accurately determines whether an individual has the disease. if such a classifier can be found, the testing samples are then examined to verify its accuracy. the goal of this procedure is to construct a classifier that can effectively be used on the underlying population; which ransohoff denoted as generalizability  <cit> .

while multiple biomarkers can classify a given individual better than a single biomarker  <cit> , and it has been argued that tens to hundreds of biomarkers may be required  <cit> , it is important to examine the way in which these markers are used in a classifier. while many forms of a classifier are possible, any classifier can be considered to lie between two possible extremes. at one extreme are classifiers denoted fingerprint-based classifiers, and at the other are classifiers denoted biomarker-based classifiers.

as the name implies, a fingerprint-based classifier is similar to the forensic procedure that determines whether or not a given individual was at a particular location. it uses a subset of the available features, or panel of markers, to construct a pattern and this overall pattern, or proteomic fingerprint, is used to identify the closest matching individual. in disease classification, if the match to an individual with a known histology  is sufficiently close, then the tested sample belongs to an individual with the same histology.

an example of a fingerprint-based classifier is the medoid classification algorithm  used in many studies from the laboratories of emmanuel petricoin and lance liotta  <cit> . this procedure scales the set of n selected feature values such that each training sample represents a point in an n-dimensional unit hypercube. a test sample is then scaled and placed in this hypercube, and if it is sufficiently close to one of the training samples it is given the same histology as this training sample. every sample in the testing set must have a sufficiently similar sample in the training set, or else a prediction cannot be made.

the other extreme for classifiers is represented by a standard biomarker-based classifier. here filtering methods are used to determine if the values of an isolated feature sufficiently distinguishes between diseased and healthy individuals. if a small number of such features are found, and their predictive ability is not caused by a bias in the study design, these features represent putative biomarkers and the classifier only uses these features. in a study of individuals with and without colorectal cancer it was found that the blood concentration of the complement c3a-desarg is elevated in individuals with either colorectal polyps or colorectal cancer  <cit> . other studies have shown that complement c3a-desarg is also elevated in individuals with benign prostate hyperplasia  <cit>  and type- <dig> diabetes  <cit> . therefore, a sufficiently low concentration of complement c3a-desarg in the blood may be sufficient to exclude any of these conditions; extra tests would have to be performed on an individual with a high blood concentration to correctly identify the condition.

a decision tree  classifier  <cit>  can be considered to be between these extremes. if a sufficiently accurate dt classifier only requires a single decision node, then the feature used by this node represents a putative biomarker and this is a biomarker-based classifier. since only the initial, or root node acts on all samples in the training set, any additional nodes only examine a subset of the training samples, and the members of this subset depends on the features used in any preceding nodes. the decision tree shown in figure  <dig> contains seven decision nodes  that produce eight terminal nodes . if a feature used in decision node  <dig> is changed to another feature, for example, then the samples that are passed to nodes  <dig> and  <dig> would be changed. this would affect the quality of the discriminators for these latter nodes and the quality of the classifier. in other words, the optimal features to use in nodes  <dig> and  <dig> depend upon which features are used in nodes  <dig> and  <dig>  while the optimal features in nodes  <dig> and  <dig> depend upon what features are used in nodes  <dig> and  <dig> 

the main point is that a fingerprint-based classifier depends on the pattern of feature values across all n features used in the classifier. changing one of the features used in an mca classifier would necessarily change the location of all training samples in the n-dimensional unit hypercube and may drastically alter the classification accuracy for the testing samples. a multi-node dt has some of this property in that changing the features used in nodes  <dig> through  <dig> in figure  <dig> will change some or all of the sample subsets passed to decision nodes  <dig> through  <dig>  and therefore change the classification accuracy and the optimal features to use in these latter nodes.

it is understood that if bias can be removed from consideration, a single feature that correctly distinguishes healthy from diseased individuals represents a putative biomarker that may be directly involved with the disease progression or with the host's response to this disease. gillette and coworkers  <cit>  have argued that the proteomic pattern or fingerprint associated with a panel of markers can be thought of as a single biomarker. therefore, it has been stated  <cit>  that if a fingerprint-based classifier is able to sufficiently predict the histology of individuals in an independent testing set, then this classifier must reflect some underlying biological principles. this assumption of accurate predictions being a necessary and sufficient condition for biological significance is tested in this manuscript. if any given classifier is able to accurately classify both a training set and a testing set using a panel of markers from a dataset that contains no biological information, then this association between good results being a necessary and sufficient condition for an underlying biological principle is disproved.

a random number generator is used to construct  <dig> datasets that contain no biological information. as described in the methods section, each dataset contains the same number of cases and controls and each sample contains random values for  <dig> features. current microarray and mass spectroscopic studies generate far more than  <dig> features, so this study investigates the flexibility of a classification algorithm instead of exploring the "curse of dimensionality." the number of cases and controls were set to  <dig>   <dig>   <dig>   <dig>   <dig>  and 300; and five random datasets were constructed for each number of cases and controls. therefore the smallest five datasets contained random feature intensities for  <dig> cases and  <dig> controls, and they represent situations where a chance fitting  <cit>  of the data may be possible. the largest five datasets contain  <dig> features and  <dig> samples  and a chance fitting of the data is not expected. all  <dig> datasets are available on the web  <cit>  and any algorithm that produces good classification results can only do so by chance. any acceptable classification disproves the sufficiency condition between accurate classification results and biological information. in other words, this "proof by counter example" argues against the contention that an accurate classification is sufficient to assume a biological relevance, and may underline the disconnect between many accurate classification studies and the lack of biomarkers that have been approved by the fda.

in this study, the dt and mca methods are used to examine these  <dig> different datasets. the dt procedure uses the symmetric decision tree shown in figure  <dig> with seven decision nodes and eight terminal nodes, though for some runs pruning is performed for a putative classifier prior to determining its classification accuracy. the mca method is used to construct classifiers containing five, six, or seven features from the set of  <dig>  a complete analysis of these datasets would require an exhaustive testing of all possible sets of seven features in all possible orders for the dt method and all possible sets of five, six and seven features for the mca method. since this is not computationally feasible, a modified evolutionary programming  algorithm  <cit>  is used to search for near-optimal sets of features. this procedure selects sets of features that are passed to the dt and mca algorithms to construct putative classifiers. this ep algorithm uses the classification accuracy of the putative classifiers to construct a final population of classifiers that accurately predict the histology of the samples.

since the ep procedure is a stochastic search algorithm that samples a small subset of the available sets of features, finding the best set of features in a given run is not guaranteed. therefore, for each classification method and dataset, multiple runs are performed. the dt procedure is run four times for each dataset, each with a different seed to the random number generator. in two of the runs no pruning is performed and in the other two a decision node is converted to a terminal node of it contains less than 4% of either the cases or controls. each dataset is also examined twice by the mca method for each number of features . these two runs not only use different seeds to the random number generator but use a different ordering of the samples since  the final result depends upon this ordering. since finding the best set of features is not guaranteed, the results presented here should be taken as a lower bound, or minimum estimate, of the sensitivity and specificity that would be obtained for each procedure if an exhaustive search were performed.

RESULTS
a summary of the classification results for these artificial datasets is shown in table  <dig>  the first column lists the number of cases and controls and the rows correspond to the best results obtained from the five corresponding datasets. the first section of results in table  <dig> lists the highest quality  for the dt algorithm. since each dataset was examined four times, the qualities represent the best results over  <dig> runs . the dt classification accuracy for the best and 200th best classifier for each of the four runs using each dataset is listed in additional file  <dig>  the second section of results in table  <dig> lists the highest quality  for the mca classifier using five, six or seven features. since each dataset was examined twice for a given number of features, these results represent the highest quality obtained over  <dig> runs . the mca qualities for the best and 200th best classifier in each of the six runs for each dataset are listed in additional file  <dig> 

the reported quality is the largest sum of the sensitivity and specificity  found across the five random datasets for each number of cases and controls for a decision tree  using at most seven decision nodes and the medoid classifier algorithm .

it should be noted that, for the mca algorithm, each time the cases were examined before the controls all  <dig> classifiers produced a sensitivity of 100%, while each time the controls were examined before the cases the specificity was always 100%, independent of the number of cases and controls. this is a design feature of the mca algorithm. each time a sample is examined it is either placed in an existing cell or it becomes the medoid of a new cell. if only cases are initially examined, they have to be placed in an existing case-cell or create a new case-cell. either situation produces a correct classification of this case sample. though the exact sensitivity and specificity depend upon the order of the samples examined, their sum is relatively constant for the different ordering .

the dt classifier shows that the accuracy of the best identified classifier decreases as the number of samples increases. all of the  <dig> runs for the smallest datasets  identified at least one decision tree whose average sensitivity and specificity was 95% or better and three of the  <dig> runs found at least one decision tree that produced perfect results . in fact one of these runs identified at least  <dig> unique decision trees that yield perfect results .

for the datasets with  <dig> cases and  <dig> controls, the runs identified at least one decision tree whose average sensitivity and specificity ranged from 85% to over 89%. the overall results for the best decision tree and a hypothetical division into a training set and a testing set is shown in table  <dig>  the training set has a sensitivity and specificity of  <dig>  and  <dig> %, respectively, while the testing set has a sensitivity of  <dig> % and a specificity of  <dig> %. it should be stressed that this division is not the only one that places  <dig> cases and  <dig> controls in the training set and  <dig> cases and  <dig> controls in the testing set while preserving the character of the eight terminal nodes as case-nodes or control-nodes: there are approximately  <dig>  ×  <dig> unique ways that these  <dig> samples can be placed into this specific division.

overall placement of  <dig> cases and  <dig> controls  in the eight terminal nodes of the best decision tree shown in table  <dig> and a hypothetical distribution between a training set and a testing set. features  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>  and  <dig> are used in decision nodes  <dig> through  <dig> , respectively.

for the datasets with  <dig>   <dig>  and  <dig> cases and controls, at least one run identified a decision tree with an average sensitivity and specificity above  <dig> ,  <dig> , and  <dig> %, respectively. the best results presented in table  <dig> should be taken as lower bounds to the accuracy for a random dataset containing no biological information due to the small population size and number of generations in the modified evolutionary programming  search  <cit>  and a modest search for the optimum cut points for each decision tree.

significantly better results are obtained when the mca method is used to fit the random datasets. if only five features are used, which is the minimum number considered in many previous publications  <cit> , all  <dig> runs found at least one classifier that produced perfect results  for the datasets with  <dig> cases and  <dig> controls . when six or seven features are used, all  <dig> runs again found at least one perfect classifier, with two of the six-feature runs and four of the seven-feature runs producing final populations with at least  <dig> perfect classifiers. when the number of cases and controls is increased to  <dig>  the best results yielded an average sensitivity and specificity of  <dig> %, independent of the number of features. for  <dig> cases and  <dig> controls, both the five-feature and six-feature runs found at least one classifier with an average sensitivity and specificity of over  <dig> %, while the seven-feature runs found at least one classifier with an average sensitivity and specificity of  <dig> %.

as described in methods, the mca classifier is constrained so that at most two-thirds of the cases and controls are used to establish case and control proteomic fingerprint patterns, respectively. this means that at least one-third of all cases and controls are not needed to establish these fingerprints and can represent a testing set.

these results are for the same dataset as in table  <dig> after a single mixing of the order of cases and controls after a hypothetical division of the samples into a training set and a testing set. the first classifier uses features  <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and  <dig>  and the second uses features  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>  and  <dig> 

for the datasets with  <dig>   <dig>  and  <dig> cases and controls, the mca results show a monotonic decrease in the average sensitivity and specificity as the number of samples increases. for the largest dataset , at least one seven-feature classifier produced an average sensitivity and specificity above  <dig> %.

it has been argued that good classification results for a test set that in no way is used to determine the classifier necessarily implies that the classifier is based on some underlying biological information  <cit> . the results presented here show that good classification accuracy is not a sufficient condition to imply a biological basis for studies that use a dt or mca classifier. if a good classification result implies a sensitivity and specificity of at least 85%, a decision tree with at most seven decision nodes can obtain this result from a random dataset containing more than  <dig> cases and  <dig> controls. if this threshold is increased to 90%, a decision tree can achieve this accuracy for a random dataset containing fewer than  <dig> cases and  <dig> controls, while a medoid classification algorithm achieves this accuracy with a pattern of seven features for a dataset containing  <dig> cases and  <dig> controls.

these results show that the quality of these classifiers will not decrease if more features are used in the fingerprint. increasing the number of features into the hundreds  <cit>  assures that a dataset containing even greater numbers of samples can be fit by chance  <cit>  using a fingerprint-based classifier. it is important to note that these results are obtained for datasets containing only  <dig> features for each sample. current separation technologies which yield multiple mass spectra for each sample as well as microarray studies produce many times more features per sample than considered here. increasing the number of available features for each sample will also increase the quality of the classification using a dt or mca, whether or not the dataset contains any biological information.

in a response to criticism that different studies used different features to accurately classify individuals with a given disease  <cit> , it was stated that "the generation of multiple combinations of diagnostic features from the same starting data is a logical consequence of the complexity of the information content"  <cit> . the results in tables  <dig> and  <dig> demonstrate that this statement is not absolutely true. three classifiers each used seven features to accurately classify the same dataset that contains no biological information and only feature  <dig> was used in both the dt and an mca classifier. the second mca classifier used a set of seven features that were completely different from the  <dig> used in the other two. this is not a result of the complexity of the information content of the dataset, since it is designed to contain no information, but is due to the flexibility of the classifiers and their ability to generate a good fit only using noise.

it should be stressed that this investigation only examines the classification accuracy of fingerprint-based classifiers. in a fingerprint-based classifier, different combinations of features are examined and the "panel of markers" that produces the best result can be considered a single biomarker  <cit> . there is no point in examining each feature in this panel, since it is their concerted action that produces the classifier, and identifying the specific protein responsible for each of these peaks  <cit>  would not be sufficient to claim that they represent biomarkers. pre-screening potential features for their discriminating ability before using them in the final classifier  <cit>  is representative of a biomarker-based classifier and is outside the scope of this investigation. in a fingerprint classifier, the proteomic pattern obtained from the panel of markers is what determines whether or not the individual has a given disease independent of the discriminating ability of individual features within the panel. for example, zhang and coworkers used a panel of seven features in a decision tree classifier to diagnose patients with diffuse large b-cell lymphomas   <cit> , and none of these features showed significant differences between individuals with and without dlbcl. the mca procedure  <cit>  is an example of a pure fingerprint-based classifier. in this investigation, the decision tree classifier was also cast as a fingerprint-based method since no metric was used to determine which feature or cut point would be used at a particular decision node. even if a metric such at the gini index or information gain were used, the final decision tree would still have some fingerprint qualities in that the feature selected for a given decision node is highly dependent upon which feature was selected for the preceding decision node. the more concerted the action of the features becomes, the more the classifier becomes fingerprint-based.

the final point is that the results presented here can be considered a chance fitting of the data  <cit> , but the additional files  <dig> and  <dig> show that there is no luck involved. for datasets with  <dig> features and  <dig> cases and  <dig> controls, the dt classifier was able to find several different classifiers with an average sensitivity and specificity of above 85% for each dataset. at least  <dig> unique 7-feature mca classifiers produced an average sensitivity and specificity above 90% for each of the five datasets with  <dig> cases and  <dig> controls. the good classification results are simply due to the mathematical flexibility of the classifier.

CONCLUSIONS
a previous publication has shown that a very accurate fingerprint-based classifier constructed from a finite number of samples is not necessarily generalizable to the underlying population  <cit> . this report extends these results to show that the high accuracy of a fingerprint-based classifier does not necessarily imply any underlying biological information since accurate results are obtained for a decision tree and a medoid based classifier using random datasets with no biological information. a classifier that correctly fits the data is a necessary condition to reveal biological relationships, but it is not sufficient.

it has been argued that the measured change in classification accuracy for a dataset and the same dataset with the class labels  permuted may be a way to measure the significance of the original classification  <cit> . though this will be examined in detail in a later publication, preliminary results suggest that the drop in classification accuracy for the permuted dataset may be exaggerated if a filtering method is used to identify putative biomarkers prior to constructing the final classifier and the original dataset contained a putative biomarker. therefore, comparing the classification accuracy for a given dataset against the accuracy of a comparably sized dataset containing random features  may be a better test.

all  <dig> random datasets are available online  <cit>  so that other classification algorithms can be examined. included with the datasets is information that more thoroughly describe the dt and mca results. in addition, a more extensive description of the dt and mca algorithms used here as well as the actual programs is available  <cit> .

