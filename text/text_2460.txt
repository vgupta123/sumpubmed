BACKGROUND
humans are able to organize perceptually meaningful elements from the mixture of competing sounds in the environment. albert bregman has described this phenomenon in the well-known framework of auditory scene analysis  <cit> . the vast majority of researchers interpret the streaming effect in terms of tonotopic organization of the auditory system  <cit> . according to this interpretation, frequency-distant sounds are processed into distinct neural populations and therefore heard as separate streams, and frequency adjacent sounds are processed in neighboring neural channels leading to their perceptual integration into one unified auditory object. however, it has recently been shown that streams compiled from frequency-remote tones can no longer be heard as distinct sound streams if the tones are presented synchronously rather than successively, despite the enhanced neural activity  <cit> . therefore, the tonotopic organization per se does not explain completely the perception of streaming  <cit> . the formation of different auditory streams requires temporal integration of sound input over time  <cit> .

on the other hand, numerous studies have evaluated the use of the event-related oscillations to indicate the process of sensory integration in the brain  <cit> . lins & picton, for instance, found that multiple auditory stimuli evoke steady-state activity following their repetition rate  <cit> . more recent research showed that selective attention could modulate the steady-state responses within the auditory system  <cit>  and between different sensory modalities . in addition, an electroencephalographic study by nozaradan and colleagues demonstrated that musical beat could elicit a steady-state response tuned to the beat frequency and, furthermore, that binary and ternary metric interpretation of this beat evoked frequencies tuned to the corresponding imagery meter  <cit> .

with regard to auditory stream segregation, it has been demonstrated that attending to a certain rhythm enhances the magnitude of the steady-state response corresponding to its presentation rate  <cit> . nevertheless, these authors investigated the neural representation of two recurring sound sequences separated by a relatively large inter-tonal frequency difference  <cit>  paradigm which primarily produces two auditory streams. an intriguing question, therefore, is how different degrees of inter-tonal frequency separation between the sounds, and respectively different perceptual states, affect the spectral distribution of one and the same polyrhythmic structure.

the present study used magnetoencephalography  to address this question. experimental block of three subsequent parts was carried out in which the rhythmic elements were kept constant but the frequency separation between the sounds was systematically manipulated. specifically, in the first two parts a variation of the standard aba-triplet paradigm was used  <cit> , wherein the b-tones were set temporally closer to the first a-tones than to the second a-tones, forming dissimilar rhythms within the same sequence. in the first part, two extreme frequency separations between a- and b-tones, which are respectively known to form the perception of one stream vs. two streams  <cit> , were contrasted . in the second part, small  vs. intermediate  frequency separations were opposed, ensuring bi-stable perception  <cit> . in order to keep sustained attention during all these conditions, the participants were asked to follow the presentation of the b-tones and indicate the switching of their perception from the aba-rhythm to two separate a- and b-tone streams by pressing a button. a combination of time-frequency analysis on a sensor space level and source analysis were used to analyze the results. we anticipated that in the first part our analysis would capture activity corresponding to the temporal distribution of the a-b and b-a-tone intervals of the aba-triplets in the single-stream condition . in the streaming condition  presentation frequencies of clear b-tones and a-tones were expected. in the second part  all presentation rates were expected in the spectrum . therefore, the present design provides a complementary model for investigation of stream integration versus stream segregation by varying the inter-tonal frequency separation between the a- and b-tones in a classical streaming task. accordingly, based on the different presentation rates we could access different perceptual states  by capturing the corresponding frequencies to these different rates in the time-frequency spectrum. additionally, for the first two parts, source waveforms synchronized to the b-tones of the aba-structure were extracted, in order to be associated with the time-frequency data.

the third part consisted of a sequence compiled from two independent, simultaneously presented a- and b-tone streams . in this part the participants were not required to follow any of the rhythms. the a- and b-tones of the two presented sequences appeared always at different temporal relation to each other. conversely, the temporal distributions between the a- and the b-tones per se were always regular. the auditory system prefers to organize separate streams based on regularities such as pitch  <cit>  and regular temporal arrangement  <cit> . on the other hand, it has recently been demonstrated that streaming can occur without any difference in the fundamental frequency  <cit>  and an integrated percept can occur with irregular arrangements  <cit> . therefore, if the auditory system is capable of integrating simultaneously the a- and b-tones into separate streams, based on their regular presentation rates and identical tone-frequencies, then two steady-state responses related to their frequency distribution would be captured in the spectrum.

methods
participants
fourteenth right-handed participants , aged between  <dig> and 30 years, participated in this study. none of them had a history of otological or neurological disorders. a normal audiological status was verified by pure-tone audiometry in terms of air conduction hearing thresholds less than 10 db. pure-tone thresholds were measured for octave frequency from  <dig> to 4000 hz. all participants gave a written, informed consent in accordance with the declaration of helsinki. the study protocol was approved by the ethics commission of the university of münster, germany .

experimental procedures
the experiments were organized as experimental block of three following parts. 5 min. silent gaps divided the parts. non-regular aba-triplet sequences were used in the first two parts. the stimuli were sinusoidal tone-pips of 25 ms duration, including 10 ms rise and decay times. the loudness of the stimuli was set to 60 db above the individual hearing thresholds. the duration of each trial was 5 s. the inter trial interval  was set to 3 s and the total recording time of one experimental part was  <dig>  minutes.

in the first part, the single auditory-stream  condition was compared with the streaming-condition , with the exact ordering of these conditions randomized. the second part compared small  versus intermediate  ∆f, in the same way. in all conditions, the frequency of tone a was 500 hz, but the b-tones were 500 hz , 561 hz , 630 hz  and 891 hz for the streaming condition, figure 1a. in the first two parts, the sound onset asynchrony  between the successive a-tones was always 250 ms, which corresponds to a presentation rate of  <dig> hz. the soa between the successive b-tones was 500 ms, which corresponds to 2 hz presentation rate. the soa linking the first a-tone and the next b-tone of the asymmetric aba-structure was 100 ms, thus the soa between the b-tone and the second a-tone was 150 ms, which corresponds to presentation rates of 10 hz and  <dig>  hz, respectively. the soa between the aba- triplets was also set to 250 ms , figure 1a. in each experimental part,  <dig> trials were presented:  <dig> trials of each condition. the presentation order of the first and second parts was counterbalanced across subjects.

the asymmetric aba-triplet paradigm used in this study allows two competing perceptual states . in order to provide an objective estimate of stream integration versus stream segregation we manipulate the ∆f between the a- and b-tones whilst keeping sustained attention. therefore, before the main experiment, the participants were exercised with  <dig> trials of each condition that allows perceptual streaming  from parts  <dig> and  <dig> in order to segregate the asymmetric aba- structure into separate a- and b-streams at the very first moment and to keep the perception as stable as possible. accordingly, the participants were instructed to focus on the b-tones sequence  and to indicate if their perception switched from the repeated aba-objects to two segregated b- and a-tone streams by pressing a mouse button after the presentation of each trial. however, we were not interested in the overall level of performance of this task but in maintaining sustained attention. moreover,  <dig> of the present  <dig> participants took part in our previous research in which all of them were able to hear two streams in case of 2-, 4- and 10-semitones conditions  <cit> . the 0-semitones condition is assumed to be always heard as one object.

in the third part, two sequences of independent a- and b-sound-streams  were presented simultaneously for 5 seconds with an iti of 3 seconds . the presentation rate of the a-tones, therefore, corresponded to 8 hz  and the b-tones to 4 hz . the frequency separation was set each time to 10-semitones , figure 1b. the subjects were not supposed to pay attention to the stimuli and, instead, watched a silent movie of their choice. however, before the main experiment all of the participants had reported that they can hear two streams in that condition. in additional five-minute part, the spontaneous brain activity was recorded in order to distinguish between the spectral power that corresponds to the expected target frequencies in the third part and the resting brain-state  <cit> . during the resting state recordings the same experimental design as in part  <dig> was presented to the participants, however, without audio output to the meg-room. in that way the same conditions’ triggers were available for further epochnig.

meg data acquisition
the meg recording was performed using a 275-channel whole-head system , sampled at 600 hz. the participants were seated comfortably in an upright position. the sensors were configured as first-order gradiometers with a baseline of 50 mm. in addition to the meg, the electrooculogram  was recorded for subsequent artifact rejection. the participants’ head positions were determined at the beginning and at the end of each recording block by means of  <dig> localization coils fixed to the nasion and the entrances of both ear canals. alertness and compliance were verified by video monitoring. the acoustic stimuli were delivered through a nonmagnetic and echo-free acoustic transmission system  to silicon earpieces placed into the ear canals.

time-frequency analysis
in this study we examined whether sequential auditory scene analysis relies on brain oscillations entrained to the stimulus presentation rates. for that purpose we investigated the hypothesized brain frequency oscillations by means of time-frequency analysis. the following meg processing steps were performed using matlab-2011a  and the fieldtrip toolbox . before starting the analyses, the continuous data were separated into epochs of 6 s . epochs containing signals larger than  <dig> pt were considered as artifact-contaminated and excluded from the analysis. in the present study time-frequency representation of power was calculated based on fourier analysis using a sliding  window approach . in order to reduce spectral leakage and to control the frequency smoothing prior to power calculation the data were multiplied with a single taper . the length of the sliding window was set to a fixed number of periods resulting in shorter time windows with increasing frequency. to compensate the expense of frequency smoothing for higher frequencies whilst keeping a constant time window  we chose to independently analyze the data for two separate frequency ranges: one from  <dig> to 6 hz and another one from  <dig> to 14 hz. frequency-dependent time window of 2 cycles was used to calculate the activity of the first range  and frequency-dependent time window of 13 cycles to calculate the second range . for each range the time-frequency power representation was calculated using a frequency resolution of  <dig>  hz and a temporal resolution of 50 ms.

the topographic maps were also analyzed across the conditions depicting the averaged time course of each stimulus condition and each frequency range , although the goal of the present study was not to focus on concrete brain structures. based on the prior assumption of different hemispheric specialization in streaming  <cit>  and the obtained dissimilar distribution of the grand averaged topography maps, the magnitudes of the proposed frequency ranges were analyzed separately for the left and right hemispheric channels . the external frontal channels  and the eog-channels were excluded from further analyses in order to additionally diminish the effects of eye blinks and frontal muscle activities. the most occipital channels were less active related to the other channels and therefore excluded from further analyses. at the end,  <dig> channels of each hemisphere were analyzed. the large number of channels used minimized the side effects of possible individual channel deviation. it should be noted here, that in order to avoid canceling the activities locked to stimulus rate in case of phase difference, the time-frequency representations were calculated for every trial of each individual  before averaging the data across the different conditions and participants. therefore, we expected to capture the activity of approximately 2 hz  and 4 hz  that corresponds to streaming in the cases of the 10-, 4- and 2-semitones conditions  into the first frequency range. in contrast, the activity reflecting the processing of a-b  and b-a  time intervals of the unified aba objects was expected into the second frequency range. the same frequency ranges were analyzed for the third part and the resting state measurements, in order to capture the steady-state activity corresponding to the independent presentation rates of a- and b-tone streams and the relevant spontaneous activity at 8 hz and 4 hz. the time-frequency analyzed epochs were then averaged for each condition  across the channels. this was done independently for the left and right hemispheric channels. in order to extract unrelated outstanding noise, such as spontaneous brain activity, baseline-normalization was applied in terms of relative change of spectral power . the rcsp expresses, for each frequency, the relative increase or decrease of the raw power values with respect to the power in the baseline interval. thus, if pa is the spectral power of the post-trigger time-period  and pb is the spectral power of the pre-trigger period  the rscp value is calculated as:

 rcsp=pa−pb/pb. 

in addition, the analyzed mean epochs of each condition were averaged across all the participants with the intention of presenting the group-averaged effects. this procedure provided the grand average rcsp values, separately for the two frequency ranges , in the time window from − <dig> to 5 s, for each condition and hemisphere. it has been shown that the formation of different auditory streams needs a variable amount of time to build-up  <cit>  therefore averaging across the participants could lead to cancelation of some effects based on the dissimilar individual percept over time. thus, time-frequency responses of one participant were additionally analyzed .

before entering statistical analysis, the mean rcsp values in the time window from  <dig> to 5 s post-trigger period were collected for each participant, condition and hemisphere in the following way:  for parts  <dig> and  <dig>  the activity was extracted and averaged between  <dig>  and  <dig>  hz and between  <dig>  and  <dig>  hz, looking for the 2 hz b-tones and the 4 hz a-tones related steady-state evoked activity;  the activity was also averaged between  <dig>  and 8 hz and between  <dig> and  <dig>  hz, to identify frequencies of approximately  <dig>  hz and 10 hz corresponding to the distribution of the tone intervals in the asymmetric aba-triplets;  for part  <dig>  the frequency bands between  <dig>  and  <dig>  hz and between  <dig> and  <dig>  hz were used, with the expectation of finding 4 hz b-tones and 8 hz a-tones related steady-state evoked activity. the mean rcsp values of the resting state measurements between  <dig>  and  <dig>  hz and between  <dig> and  <dig>  hz were also averaged from the additional resting-state part, in order to compare them with the relevant activity derived from part  <dig>  the calculated mean values of the baseline corrected spectral power for each target frequency were then entered into statistical analysis.

to investigate whether the activity related to the distribution of the aba-structure depends on the activity related to separate perception of a- and b-tone-streams , the mean spectral power values of the different target frequencies across the different conditions were entered into 4 ×  <dig> repeated-measure anova using within-subject factors target frequency  and condition . thereafter, the mean spectral power of each target frequency from part  <dig> and part  <dig> were separately entered into a 2 ×  <dig> repeated-measures anovas, using within-subject factors hemisphere  and conditions . thus, we were also able to explore how the spectral power of identical target frequencies changes across conditions, as well as their effects between the hemispheres.

additionally, the mean values of the baseline corrected spectral power from part  <dig> were compared with the relevant mean values of spontaneous activity derived from the resting state-part . therefore, a separate 2 ×  <dig> model anova was applied here using within-subject factors hemisphere  and activity .

when significant, post hoc pairwise comparisons were performed using paired-samples t-tests. the alpha level was set at  <dig>  and bonferroni correction was applied in all analyses.

analysis of source waveform data
the analysis was performed using the besa software package  and matlab-2011a , waveform-toolbox. before starting the preprocessing procedure, the data were high pass-filtered with the lowest frequency limit of 1 hz. the data were separated into epochs corresponding to the b-tones of the aba-triplets, starting 50 ms before and ending 400 ms after the b-tone onset. epochs containing signals larger than  <dig> pt were considered as artifacts and excluded from further analysis. before averaging, the response signals were low pass filtered at 30 hz. each different condition was then averaged, in order to achieve the best signal-to-noise ratio. these procedures were performed only for the first two parts. the data of part  <dig> could not be epoched because no baseline could be derived as a result of the independent presentation of a- and b-tone streams.

the signal space projection technique  <cit>  was used for the analysis of the meg data. the interval used for the ecd fit  was placed around the local maximum of the n <dig> component of the aef. the n <dig> dipolar sources evoked by b-tones of the aba-triplets were less variable across conditions compared to the p <dig>  p <dig> or n <dig> sources and, thus, provided a better signal-to-noise ratio. each n <dig> dipole parameter was represented by the average of all data points  around the maximum of the global field power of the magnetic field calculated across the respective subsets of channels. thereafter, the source space projection method was applied to calculate the components of the transient evoked response   <cit> . for each participant and condition, two ecds  were determined by their dipole moment, orientation and spatial coordinates , a technique justified by other authors .

a time window of 30 ms was placed around the individual peaks of p <dig> and n <dig> of the calculated aefs in order to collect their amplitudes and latencies for further statistical analysis. two participants in which the expected n1-responses could not be fitted into two dipoles were excluded from further analysis hence the responses of eleven participants were entered into statistics. the averaged amplitudes and latencies of p <dig> and n <dig> components at the 30 ms interval were then entered into repeated measures anova with the within-subject factors hemisphere  and conditions . when significant, post hoc pairwise comparisons were performed using paired-samples t-tests. bonferroni correction was applied for all analyses.

RESULTS
time-frequency data
interactions between the spectral distribution of the aba-structure and a- and b-streams
the polyrhythmic structure used in the present study consisted only of two tones  organized as an asymmetric aba-triplet. these two tones could form different rhythms, depending on the listener’s current perceptual state  <cit> . this perceptual state is directly influenced by the inter-tonal frequency separation between the a- and b-tones. therefore, when the perception is integrated as an aba-stream, one would expect to capture the corresponding presentation frequencies into the spectrum. conversely, in case of segregation , one should be able to capture, separately, the temporal distribution of the a- and b-streams in the spectrum. hence, by varying the inter-tonal frequency separations, we expected to access integrated versus segregated percepts in the time-frequency spectrum.

as shown at the group data-plots , the presentation rate of the b-tones of the aba-triplet sequences elicited a clear increase of the spectral power at about 2 hz in the streaming  and in the intermediate frequency separation  conditions from the first and second parts. additionally, the a-tones presentation elicited a steady-state like activity at about 4 hz in the intermediate  and small frequency separation  conditions. the asymmetric aba-objects induced enhanced activity in all four conditions  at approximately 10 hz and 6 hz .

the anovas revealed significant interaction between the spectral distribution of the aba-objects and those of the separated a- and b-streams on the basis of the different frequency separation between the competing tones  =  <dig> , p < .001], target frequency  and interaction conditions x target frequency ).

post hoc pairwise comparisons showed that the mean spectral power corresponding to separate perception of a- and b-streams has lower amplitude compared to the activity related to the distribution of the aba-triplets in the conditions of small inter-tonal frequency separation. in particular, the b-tones related activity  of the non-streaming scenario  was significantly lower compared to spectral power of the a-b  and b-a  tone intervals, t = − <dig> , p < . <dig> and t = − <dig> , p < . <dig>  the a-tones  related spectral power of the same condition was also significantly lower compared to the activity related to the distribution of the aba-triplets  = − <dig> , p < .001] and b-a , ). furthermore, the 2 hz spectral power  in the small frequency-separation condition  was significantly lower compared to the spectral power corresponding to a-b ,  = − <dig> , p < .05) and b-a tones  , = − <dig> , p < .001). regarding the 2-semitones condition, the corresponding activity to a separate a-stream perception at approx. 4 hz was also significantly lower than the 10 hz  = − <dig> , p < .001) and  <dig>  hz  =  <dig> , p < .001) spectral power. similarly, concerning the intermediate frequency separation condition , post hoc comparisons revealed decreased activities corresponding to separate presentation of a-tones  and b-tones  as compared to spectral power of the a-b target frequency ,  = − <dig> , p < .05) and  = − <dig> , p < .05), respectively.

in order to understand better the source of significant interactions from the previous 4 ×  <dig> anova and to explore the effect between the hemispheres, four additional anovas were conducted wherein the mean spectral power of each target frequency was entered separately into repeated-measures 2 ×  <dig> anova using within-subject factors hemisphere  and conditions .

activity related to a perception of separate a- and b-streams 
the time-frequency outcome demonstrated that the 2 hz activity  in the 10-semitones condition evolved at about  <dig>  s and reached its maximum at about  <dig>  s and 2 s. this was not so well pronounced in the case of 2- and 4-semitones and did not occur during 0-semitones condition .

arh-right hemisphere; blh-left hemisphere; csa- baseline corrected spontaneous brain activity.

regarding the 2 hz activity , the anovas revealed a significant difference between the conditions  =  <dig> , p < .001]). the following post hoc pairwise comparisons showed that the activity at approx. 2 hz  increased significantly with increasing the inter-tonal frequency separation between a- and b-tones. the 2 hz-activity of the 10-semitones condition was significantly greater than in the 0-semitones condition  = − <dig> , p < .05) and the 2-semitones condition  =  <dig> , p < .05). the mean spectral power at 2 hz of the 4-semitones condition was also significantly higher compared to the 2-semitones condition  = − <dig> , p < .05) and the 0-semitones condition  = − <dig> , p < .05). the comparison of the mean spectral power at 2 hz, between the conditions with close inter-tonal frequency difference, did not reveal significance; 2-semitones vs. 0-semitones  = − <dig> , p = .431) and 10-semitones vs. 4-semitones  = − <dig> , p = .080).

as seen on the group level time-frequency plots, the 4 hz-activity  showed greater enhancement in the second part , wherein the frequency difference between the a- and b-tones was relatively small  when compared to the first part. the power of the signal at approximately 4 hz was therefore more pronounced and better visible than at 2 hz in the second part . the baseline corrected mean spectral power here differed significantly across conditions  =  <dig> , p < .05]). post hoc comparisons revealed that the spectral power at 4 hz in case of 4-semitones was significantly greater than in case of 2-semitones condition  = - <dig> , p < .05), the 10-semitones condition  = − <dig> , p < .05) and the 0-semitones condition  = - <dig> , p < .05). the 4 hz-activity was also significantly greater in case of 2-semitones compared to t 10-semitones  = - <dig> , p < .05).

figure  <dig> summarizes the differences of the spectral power related to the separate perception of the a-tones  and b-tones  of all conditions  across the participants. error bars indicate the 95% confidence intervals for the within-subject effect   <cit> .

activity related to distribution of the tone intervals in the asymmetric aba-triplets 
the activity corresponding to a-b and b-a intervals of the aba-triplets  appeared to be sustained during the 0-semitones condition and transient in the conditions that allowed perceptual streaming , figure 2ab.

the anovas revealed that the mean values of the baseline corrected spectral power at around 10 hz  in the first and second part did not change significantly between the conditions  =  <dig> , p = .067]). the activity between the hemispheres, however, differed significantly  =  <dig> , p < .001]). post hoc pairwise comparisons showed that the spectral power at 10 hz was generally greater in the right hemisphere  than in the left hemisphere ,  = − <dig> , p < .001).

regarding the  <dig>  hz target frequency, the anovas revealed significant main effect condition  =  <dig> , p < .05). the following post hoc pairwise comparisons showed that the activity at approximately 6 hz  was significantly greater in the case of 2-semitones compared to 10-semitones t =  <dig> , p < .05). there were no other significant comparisons in the 8 hz target frequency  =  <dig> , p = .073], 2- vs 4-st. , 4- vs. 10-st , 0- vs. 4-st.  and 0- vs. 2-st ).

activity related to the independent presentation of a- and b-tones 
unlike the aba-structure from the first two parts this scenario could not provide two alternative perceptual states . therefore, the participants were not required to pay attention to the ongoing presentation. the auditory system prefers regular arrangements  <cit>  and hence two steady-state responses corresponding to presentation rates of the two sequences were expected in the time-frequency spectrum. as shown at the plots , the non-attended condition  elicited an activity enhancement at about 8 hz and 4 hz, corresponding to the independent a- and b-tones presentation rates. the baseline corrected mean spectral power values of the third part vs. the spontaneous activity at 8 hz and 4 hz, across hemispheres, are shown in table  <dig> 

the anovas showed a significant difference between the different activities  =  <dig> , p < .001]). post hoc pairwise comparisons revealed that the spectral power corresponding to an independent presentation of a- and b-streams  during the stimulation was significantly greater than the spectral power at 8 hz and 4 hz during the resting state measures ,  =  <dig> , p < .001).

source waveform data
clearly identifiable evoked responses were obtained from all subjects. the magnitude of the p <dig> component of the responses to b-tones of the aba-triplets raised with increasing the frequency separation  =  <dig> , p < .001]), figure 4ab. post hoc comparisons revealed that the magnitude of the p <dig> component across the trials was significantly greater in the 10-semitones condition than in the 0-semitones  = - <dig> , p < .05) and 4-semitones conditions  =  <dig> , p < .05). additionally, the amplitude was significantly greater in the case of 4-semitones than in the 2-semitones  = − <dig> , p < .05) and 0-semitones  = − <dig> , p < .05). there were no other significant comparisons regarding the p <dig> amplitude  =  <dig> , p = .075] and 2- vs 10-st. ).

the n <dig> component also increased following the increased frequency separation, however not significantly  =  <dig> , p = .250]). the two components did not show any effects or interactions concerning the hemispheres: p1-effect hemisphere  = . <dig>  p = .694) and n1-effect hemisphere  = . <dig>  p = .746). despite the fact that p <dig> and n <dig> were not entered into statistical analyses, it should be noted that they appeared to be enhanced in the case of streaming and intermediate ∆f, compared to single-stream and small with the lowest frequency limit of 1 hz.∆f conditions, respectively . these components likely represent the activity related to the second a-tone of the aba-triplet.

discussion
the present study combines time-frequency analysis on a sensor space level with source waveform analysis by means of magnetoencephalography  to explore the underlying neural activity behind the processing of an aba-triplet streaming-task. we furthermore challenge the perception by contrasting four degrees of inter-tonal frequency separation and thus enabling the formation of different perceptual states in one and the same polyrhythmic structure. in order to keep sustained attention, the participants were instructed to focus on the slowest rhythm . the results of the first two parts  revealed a clear increase of the spectral power at approximately 2 hz that corresponds to the b-tones presentation rate in the streaming  and intermediate frequency separation  conditions. this was in line with our hypothesis. additionally, the a-tones presentation rate elicited steady-state like activity at approximately 4 hz. the aba-triplet sequence used in the present study is usually heard as a galloping rhythm and the a- and b-streams are enclosed into the aba-pattern  <cit> . hence the a- and b-tones related activities at 4 hz and 2 hz are only accessible in the spectrum if the two streams are segregated. our results, therefore, likely reflect the selective segregation of the polyrhythmic aba-pattern into two monorhythmic a- and b- streams. the activity at approximately 10 hz and 6 hz that corresponds to a-b and b-a-tone intervals of the aba-triplets also increased across the trials in the first two parts. in the light of the present findings, one might speculate that the neural representation of different auditory sequences relies on neural entrainment of the temporal intervals between the composed stimuli. therefore, when the perception is in favor of one-stream condition  one could capture the corresponding presentation rates in the spectrum , whereas the other rhythms would be suppressed  and vice versa in the case of segregation . additionally, the time-frequency results demonstrated that the responses to the aba-frequency distribution  appeared to be sustained across the entire presentation of the non-streaming condition , whereas the b-tone related activity  emerged at approximately  <dig>  s and reached its maxima at approx.  <dig>  s and 2 s only during the streaming condition . conversely, the spectral power at 10 hz and  <dig>  hz was rather transient in all other conditions that allowed perceptual streaming . the streaming phenomenon is cumulative  <cit>  and needs variable amount of time to build-up  <cit>  and therefore the appearance of the 2 hz activity at about  <dig>  s in the time-frequency plots likely reflects the streaming built-up period. alongside this, the vanishing of the activity at approx. 10 hz and 6 hz could match the periods wherein the perception alternated in favor of stream segregation. indeed, the statistical analysis revealed that the spectral power corresponding to the a-b and b-a time intervals of the aba-triplets is significantly enhanced compared to the responses tuned to the separated a- and b-tones in the non-streaming scenario  and the conditions of small and intermediate inter-tonal frequency separations .

the statistical analysis showed furthermore that the steady-state activity related to the attended b-stream  increased significantly with enlarging the inter-tonal frequency difference between a- and b-tones . this result lends further support to the idea that attention is a crucial factor in auditory streaming because it biases the auditory system towards particular grouping or binding of sound-source elements in favor of the listener’s intention  <cit> . a previous study by xiang and colleagues, for instance, explored the mechanisms of temporal integration and its interaction with attention in the auditory system by using a streaming paradigm with two competing tones  <cit> . the authors demonstrated that focusing the listeners’ attention on one of the two competing tempi enhances significantly its steady-state power. however, the two competing tones they used could primarily produce two auditory streams  <cit> , unlike the asymmetric aba-triplets used in the present study. furthermore, it has been demonstrated previously that the steady-state responses could be modulated by attention  <cit> . our experimental design, therefore, allowed us to explore the interaction between the temporal rates in one integrated polyrhythmic pattern and two segregated monorhythmic streams in one and the same tone-sequence. on the other hand, our results revealed a higher spectral power tuned to the a-tones presentation rate  in comparison with the b-tones related responses  in the cases of intermediate and small frequency separation between tones, although the attention was focused on the b-rhythm. it might be suggested that in cases of small frequency differences between tones, such as those used in the second part , the perception of the b-tone is not able to dominate the perception of the a-tones, and that this produces considerably higher activity at approximately 4 hz target frequency. it could be speculated therefore, that a greater effort is needed to segregate the aba-structure onto separate a- and b-tone streams in the cases of small and intermediate frequency differences than in the pure streaming condition . in addition, it might be more difficult to follow the slower b-stream  instead of the twice as fast a-stream  in the cases of intermediate and small frequency separations than in the greater frequency differences. besides that, previous studies showed that the steady-state responses are stronger in low frequency rates  when mediated by attention  <cit> . although the attention was focused on the b-tones in our experiment, changing the inter-tonal frequency separation into the aba-tone pattern revealed dissimilar efficiency of temporal integration of separate a- and b-streams. it has been demonstrated previously that the p <dig> and n <dig> components of the human aefs are larger when listeners perceive two segregated streams than one integrated stream and this magnitude augmentation is consistent with the increasing frequency separation between the a- and b-tones  <cit> . however, these authors showed that the b-tones’ related responses were always enhanced, regardless of the attended stream   <cit> . similarly, it has been proposed that the frequency separation between different sound sources of a polyrhythmic sequence is sufficient to provide the selective processing of a particular musical instrument; however, the selective attention to one or another spatially separated element of this rhythm could additionally improve the segregation process  <cit> . these findings together support the idea that the attention in auditory streaming is not merely an intrinsic mechanism that augments the neural responses but its effects are based on a specific interaction between the physical attributes of the stimuli  <cit> . additionally, the present outcome is in line with the hypothesis that distinct neuronal populations are involved in the processing of a- and b-tones and suppression of one population might underlie the stream segregation phenomenon  <cit> .

assuming that the steady-state activity at low frequency bands is generated by the periodic appearance of the evoked components in response to the a- and b-tones, we tested whether the source waveform of the response signal triggered by the attended b-tones of the aba-triplets represents any significant effects regarding the evoked peaks. moreover, the modulation of the source waveforms’ components synchronized to each triplet of the aba-streaming task is a traditional way to investigate the auditory streaming phenomenon . the analysis revealed higher amplitude of the evoked components with increasing the frequency separation, a finding that is in line with prior studies  <cit> . specifically, the p <dig> evoked component to the b-tones enhanced significantly as the inter-tonal frequency difference increased. this implies that the enhancement of the evoked fields in the source space level together with the b-tones related activity derived from the time-frequency results likely reflect the selective segregation of the attended b-stream. however, the source-wave forms comprise more than one harmonics in the spectrum and it is thus difficult to separate the streaming-related effects from the activities related to the physical features of the sounds. elhilali and colleagues, for instance, demonstrated that frequency-distant spectral components are no longer heard as separate streams if presented synchronously rather than consecutively, while the neural activity increases with increasing frequency separation between tones  <cit> .

hence, the auditory evoked fields per se are not capable of fully explaining the perception of streaming.

in apparent contrast to the first two parts, two recurring a- and b-tone-streams were presented in the third part. here, the temporal distribution between the a-b and b-a-tones was always different, whereas the presentation rates of the a-tones and the b-tones per se, were always regular, corresponding to 8 hz and 4 hz, respectively. the results demonstrated clear non-attentive steady-state activity at approx. 8 hz and 4 hz. indeed, it has been shown that the auditory system prefers regular arrangements  <cit> . moreover, the integration of auditory streams, based on their regularities, could take place automatically. the mismatch negativity component  of event-related potentials, for instance, automatically detects changes in the regular stimulus pattern  <cit> . additionally, it has been found that the mmn operates also on the basis of auditory objects and that the integration of objects occurs pre-attentively in the auditory system  <cit> . the experimental design applied in the third part could not provide two complementary percepts , such as aba-triplets. it could be speculated, therefore, that the two auditory streams were formed of the very first moment of their presentation. on the other hand, it has recently been demonstrated that stream-integration can occur with irregular arrangements  <cit> ; however, it is likely that in the absence of active awareness, the auditory system integrates tone patterns based on their physical regularities.

in summary, the present findings suggest that neural encoding of a streaming task relies on an oscillatory entrainment of the stimulus presentation rates. however, two separate effects of the time-frequency data must be distinguished: the first is represented in our results by the distribution of the intervals between the a-b  and b-a  tones of the aba-triplets . the second effect is represented by the 2 hz and 4 hz steady-state responses related to the b- and a-tones derived from the conditions that allow perceptual streaming , alongside the steady-state effects of non-attentive listening . the present effects cannot be directly ascribed to the underlying mechanisms responsible for various perceptual states, because the participants were not required to make streaming judgments during the trials. nevertheless, these effects might be grounded to physiological hallmarks of the process, which precedes the formation of one vs. two streams percept. hence, further study is necessary to show the differences in the spectral distribution of identical tonal-frequency separation in conditions of perceptual validation during integration vs. segregation.

CONCLUSIONS
the present findings are consistent with previous studies suggesting that the perceptual organization in sequential auditory scene analysis relies on oscillatory entrainment to task-driven sound input. the results showed that increasing of the frequency separation between a- and b-tones of the aba-pattern correlates with a greater magnitude of the steady-state responses tuned to the attended b-tones. alongside this, the p <dig> evoked fields’ component, synchronized to the b-tones, increased in amplitude with raising the inter-tonal frequency difference. furthermore, the asymmetric aba-objects, spontaneously elicited sustained activity, which corresponded to the temporal distribution of the constituent tone intervals. the results also revealed that the efficiency of temporal integration of separate streams is dissimilar depending on the degree of frequency separation between the competing sounds. the steady-state responses tuned to the b-tones dominated the responses tuned to the a-tones in the case of great frequency difference between tones. conversely, the representation of the a-tones dominated the b-tones in the cases of small and intermediate frequency separation, in which the task required greater effort. overall, the present outcome suggests that the neural effects of auditory stream integration and segregation could be directly captured in the time-frequency spectrum and measured with significance tests at the sensor space level.

competing interests
the authors declare that they have no financial or any other competing interests.

authors’ contributions
ic, rd and cp conceived of the study designed the experimental setup and the auditory stimuli. ic acquired the data. ic performed the data & statistical analyses. all authors participated in the data evaluation and interpretation and in writing the manuscript, and have approved the final version of the manuscript.

supplementary material
additional file 1
two separated plots show the grand averaged topographic maps  and the neural responses of one representative subject .

click here for file

 acknowledgements
we are grateful to janning herman for preparation of the time frequency analyses to evangelos paraskevopoulos for the helpful comments and karin berning for technical assistance. we are very grateful to ross parfitt for proofreading the grammar and wording of the paper.

funding
this work has been supported by “deutsche forschungsgemeinschaft”, . the funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.
