BACKGROUND
as the metabolic phenotype of the cell, the flow of material through intracellular reactions  represents the sum total of all underlying cellular processes. the accurate determination of metabolic flux is becoming increasingly important for assessing the impact of metabolic engineering or feeding strategies on cellular metabolism  <cit> . in lieu of in vivo observation, the inference of intracellular fluxes is commonly accomplished through metabolic flux analysis . at its most basic, mfa refers to the process of modeling intracellular flux via a stoichiometric balance of metabolic reaction and transport rates   <cit> . the original applications of the technique centered on using simple element balances as a means to correct unreliable measurements  <cit> . however, the increasing availability of data from multi-omic technologies has led to the development of metabolic flux models that extend far beyond these foundations.

the basis of mfa is the stoichiometry matrix. in the typical arrangement, rows represent balances on molecular species, with each column encoding the stoichiometry of a reaction . as cellular reaction networks generally have more reactions than species, the resulting stoichiometry matrix is typically underdetermined. the estimation of a single flux profile requires that the number of unknown reaction rates be equal to or less than the number of molecular species, and this has traditionally been accomplished by observing as many extracellular transport rates as possible. however, the growing availability of genomic data has opened the door to developing models that may contain thousands of reactions, complicating the calculation of a unique flux profile.

a considerable amount of metabolic information can be gathered without calculating a unique flux profile through constraint-based reconstruction and analysis  methods. the combination of mass balance constraints from stoichiometric relations as well as other factors such as enzyme capacity and reaction thermodynamics can be used to generate a feasible solution space for cellular metabolism. if a unique flux profile is required, one can be estimated by assuming an objective function such as cell growth maximization. however, it is also possible to study the solution space directly . the popularity of cobra methods has resulted in the development of a large number of software packages that have considerably simplified analysis . however, the complexity of genome-scale models remains an on-going challenge.

despite the recent advances, the process of translating genomic information to cellular reactions is still under development. even the well-studied genomes of escherichia coli and saccharomyces cerevisiae had approximately  <dig> % of their open reading frames  uncharacterized as recently as  <dig>  <cit>  and the development of reaction networks requires a significant amount of curation . furthermore, the relation between the presence of a gene sequence and enzymatic activity is not always obvious  <cit> . a combined transcriptomic-metabolomic modeling study of e. coli has revealed the existence of redundant gene expression where no flux was observed  <cit> . meanwhile, a study of lysine-producing corynebacterium glutamicum metabolism suggested that while the expression of some genes appears tightly coupled to metabolic fluxes, others can remain practically constant despite considerable changes in metabolic flux  <cit> . the popular chinese hamster ovary  cell line has an added problem of high genetic variability that may question the generality of a given model  <cit> . taken together, these issues add a considerable amount of uncertainty to modeling efforts, especially for less studied expression systems.

the addition of isotopically labelled substrate and the analysis of resulting metabolites through 13c-mfa can be a powerful means to gain better understanding of a metabolic system. but despite the ready availability of algorithms and software packages to assist with everything from identifying optimal labelling strategies to final analysis , 13c-mfa is not always practical. isotopic labelling is expensive, especially for large volume bioreactor cultivation, and can not be used to monitor ongoing production processes. moreover, studying transient labelling patterns requires accurate intracellular metabolite quantification, which is not always straightforward  <cit> , and increased computational resources  <cit> .

as such, one approach to dealing with genome-scale model uncertainty and complexity has been to simplify the models to a level where they can be solved directly from measured extracellular transport rates  <cit> , continuing the use of traditional overdetermined mfa. the simplification can be aided by software such as cellnetanalyzer that can deal with both underdetermined cobra models and overdetermined mfa formulations  <cit> . recent developments have also led to an automation of the model simplification process  <cit> . despite increasing model size, overdetermined mfa has continued to see use over the last  <dig> years , especially for less commonly used cell lines that lack well curated genomic and transcriptomic data. however, the reduction of genome-levels models in this fashion is an inversion of the original mfa foundations. in contrast to the use of a simple, reductive model for the reconciliation of questionable data, it is the accuracy of the model that is becoming increasingly variable – making it necessary to rigorously assess the validity of model simplification.

a number of strategies are currently available for model validation. the stoichiometric matrix can be probed directly by checking its condition number  <cit>  or by determining the sensitivity of calculated fluxes to measurement error  <cit> . the incorporation of measurement flux uncertainty allows the use of gross measurement error detection  <cit> , which identifies whether deviations between observed and fit data are normally distributed through a χ2-test. while useful for identifying singular errors of large magnitude, this statistic does not asses the overall quality of fit – errors may be unreasonably large while remaining normally distributed. despite the increasing consideration of confidence intervals around calculated fluxes in recent studies  <cit> , the question of whether a set of data fits a given metabolic model has thus far remained open.

in this work, we propose the use of a standard t-test as a natural extension of the least-squares calculation that underpins traditional mfa calculation. applying mfa to a chinese hamster ovary  cell culture, t-tests were used to determine whether each calculated flux could be deemed sufficiently distinct from zero. once non-significant fluxes were identified, we explored whether the uncertainty in calculated fluxes could be explained by measurement uncertainty alone, or if a lack of model fit could be to blame. to do this, the solution space of the stoichiometric model was constrained by observed flux ranges and hypothetical flux profiles were generated directly from the model. the profiles were perturbed by measurement error and collected to establish a baseline of calculated flux significance given perfect model fit.

methods
theoretical principles1
the material balance on molecular species that forms the basis of mfa is typically expressed as 
  <dig> sv= <dig> 

where s is the stoichiometric matrix and v is the vector of fluxes that correspond to reactions defined by columns of s. this formulation proceeds from a pseudo steady-state assumption that changes in metabolite pools  are much smaller than metabolite production and consumption fluxes and can therefore be ignored. the sv matrix can be be separated into scvc+sovo, where c stands for calculated flux and o for observed flux. 
  <dig> scvc+sovo= <dig> 

  <dig> −sovo=scvc 

since vo is a vector of observed data, sovo can be calculated directly. the dimension of sc depends on how many fluxes can be observed, i.e., the length of vo. sc must have no more columns than rows to calculate a unique flux profile, although the observation of more fluxes  is useful for error estimation <dig>  pooling cyclic or parallel pathways may be required in the initial formulation of s to ensure the required form of sc is obtained.

assuming that an overdetermined form of sc can be formulated , eq.  is equivalent to linear regression and can be solved in a similar fashion.

y=xβ+ε
−sovo=scvc+ε

β^=xtx−1xty
v^c=−sctsc−1sctsovo


with this formulation, ε represents the deviation between observed and calculated fluxes that may be the result of either measurement error or lack of model fit. equation  assumes ε is independently and identically distributed, which is unlikely to be the case. the variance-covariance matrix cov can be expressed as a scalar σ <dig> multiplied by a matrix of relative covariance terms v, i.e., cov=σ2v. if observed fluxes do not covary and have equal variance, then v=i, where i is the identity matrix. otherwise, eq.  needs to be rescaled by the matrix square root of v. taking v=pp, the scaled form of eq.  is: 
  <dig> −p−1sovo=p−1scvc+p−1ε 

where p−1ε now satisfies the assumptions of linear regression. formally, this is equivalent to generalized least squares  regression; however, incorporating p− <dig> directly into each term allows the use of all ordinary least squares techniques. letting p−1so=so′, p−1sc=sc′, and p−1ε=ε′: 
  <dig> v^c=−sc′tsc′−1sc′tso′vo 

the calculation of p− <dig> requires the estimation of cov from the variance of observed fluxes. calculating the covariance-variance matrix of both sides of eq. : 
  <dig> cov−sovo=covscvc+ε 

  <dig> cov=socovsot 

since cov=σ2v for any value of σ, σ is set to  <dig> so that v=cov. in practice, cov need only capture the relative magnitudes of observed flux variances as σ^ is estimated during regression. balances around molecular species that do not include an observed flux vo will have a row of zeros in cov, which prevents the calculation of a matrix inverse . although this mathematically equates to a variance of zero for those balances, a better interpretation is that there is an unknown variance around the “observation” of no net flux. the simplest solution is to add a small non-zero value to each diagonal entry of cov, representing the confidence of the calculated fluxes being fully balanced. if there is more uncertainty around some balances than others, this information could be encoded in the magnitude of the added variance. p can then be calculated via a matrix square root of estimated cov. since a variance  matrix is positive semi-definite, p is known to be unique.

whereas calculated fluxes v^c are commonly estimated using a very similar “weighted” least squares approach, the use of validation methods that are part of the regression framework have yet to be explored. the common χ <dig> test can still be used to detect gross measurement errors in estimated residuals ; however, the validation of a regression model also requires the use of t-tests to ensure the significance of calculated fluxes. confidence and prediction intervals are also highly relevant to mfa. estimated fluxes require a confidence interval to report the uncertainty of calculation, while a prediction interval around a predicted balance can be used to judge the validity of that balance being closed. the calculation of a t-statistic follows from normal regression:

tβ^i=β^ise
tv^c,i=v^c,ise


thus: 
  <dig> tv^c,i=−sc′tsc′−1sc′tso′voiσ^sc′tsc′i,i− <dig> 

the estimated standard deviation of ε  is calculated as follows: 
  <dig> σ^2=∑ε^i′2nb−nc− <dig> 

where: 
  <dig> ε^′=−so′vo+sc′sc′tsc′−1sc′tso′vo 

and nb is the number of balances  while nc is the number of fluxes to be calculated . if the model is correct and cov was correctly estimated, σ^ <dig> should be approximately equal to  <dig>  once the t-value is calculated, a flux can be judged statistically significant if |tv^c,i|≥tα/ <dig> nb−nc− <dig> where α is the significance level.

the identification of non-significant flux may be interpreted in two ways. the measurement error around observed fluxes may be too high to allow robust flux calculation. in that case, non-significant fluxes should be treated as having a flux of zero and excluded from the model or further analysis. alternatively, non-significance may be the result of excess variability from a lack of fit between the model and observed data, requiring model correction. to distinguish between these cases, it is necessary to separate model error from measurement uncertainty. one way to accomplish this is to reduce measurement uncertainty through added replication; however, the required effort can make this approach practically infeasible. another solution is to simulate a set of feasible fluxes directly from the stoichiometric model  for comparison to the observed data.

the simulation of feasible fluxes can be simplified by eliminating flux equality constraints expressed by the stoichiometry matrix. essentially, only nc−nb fluxes have to specified in order to generate all the other values. more formally, the relationships between the fluxes can be succinctly summarized through the nullspace  of s, which describes all flux balance conservations in the model. this makes it possible to calculate all fluxes from a smaller set of variables referred to as the basis. unlike fluxes, which must satisfy constraints imposed by sv= <dig>  the basis can take any arbitrary value to generate fluxes that satisfy all required constraints. expressed mathematically, 
  <dig> null=k 

  <dig> kb=v 

where b is a basis vector of any value with the same number of rows as columns of k. while all values of b satisfy sv= <dig>  it is still necessary to constrain fluxes to a set of realistic values representative of a cell cultivation. the space of all feasible fluxes v can be constrained by defining upper and lower bounds on each observed flux: 
  <dig> v=kbsubject tokib≤vi+a·sdkib≥vi−a·sd 

where vi is an observed flux, ki is the corresponding row of k, and a is a scaling constant that can be set to tα/ <dig> df to specify a confidence interval around vi. as the basis solution space is only constrained by inequalities, it is readily amenable to stochastic sampling. all values of v that satisfy eq.  represent feasible fluxes that would perfectly satisfy the stoichiometric model while remaining within measurement uncertainty of real observations. if the resulting space is infeasible, then the observed data does not fit the specified model. otherwise, a random sample of feasible fluxes can be taken for comparison to observed results. if the addition of measurement error to simulated fluxes results in less uncertainty than from observed results, then model error is to blame.

cell culture
cho-bri cells were grown in a  <dig> l bioreactor  in serum-free biogro-cho media  with an in-house amino acid supplement . the culture was seeded at  <dig> · <dig> cells/ml with a working volume of  <dig> l. temperature, ph, dissolved oxygen, and agitation speed were held at  <dig> °c,  <dig> ,  <dig> %, and  <dig> rpm respectively. samples were taken three times a day for offline analysis. cell density was determined using a coulter counter z <dig>  calibrated to results from trypan blue exclusion analysis. aliquots were centrifuged, with the supernatant collected and stored at - <dig> °c until nuclear magnetic resonance  analysis. dry cell mass was calculated by vacuum filtering  <dig> ml of cell culture through a type a/d glass filter  and weighing the filter after drying it for  <dig> hours at  <dig> °c.

metabolite quantification
nmr spectra acquisition, metabolite quantification, and internal standard correction are described in  <cit> . in brief, samples were scanned on a bruker avance  <dig> mhz spectrometer using the first increment of a 1d-noesy pulse sequence with metabolite quantification carried out using chenomx nmr suite  <dig>  . glutamax™ was added manually to the software library using the chenomx nmr suite’s ‘compound builder’ tool. all compounds were profiled in triplicate. ammonia measurements were taken using an orion star™plus ise meter .

mfa model
a cho cell mfa model was taken from  <cit> . new transport fluxes were added for acetate, formate, pyruvate, citrate, malate, pyroglutamate, and glutamax™ . the transport of glutamax™ was grouped together with the conversion of the dipeptide into glutamine and alanine. the transport of cystine was grouped together with the reduction of cystine into cysteine. a new reaction was added for the conversion of glutamate into pyroglutamate  <cit>  . new reactions were also added for acetyl-coa hydrolase and formate-tetrahydrofolate ligase to explain acetate and formate production. along with a systems biology markup language  representation of the model, a full list of reactions and an outline of metabolite flow are provided as additional files  <dig>   <dig> and  <dig>  as in the original formulation, a number of unbalanced species were removed from the model before analysis, including o <dig>  co <dig>  atp, nadh, nadph, and fadh .

flux estimation
metabolite and cell concentration timecourse data was fit by a regression spline with  <dig> cubic basis functions . measurement error was estimated by calculating the variance of observation deviation from the fit.  <dig> predicted concentration timecourses were simulated for each trend by adding normally distributed error corresponding to the sum of regression and measurement variance. a new regression split fit was calculated for each of the simulated timecourses. metabolite transport fluxes were calculated by dividing the derivative of the metabolite concentration fit by cell concentration . the mean and variance of the simulated fluxes at each time-point were used for all mfa analysis. biomass fluxes were calculated as in  <cit> , with the exception that dry cell mass measured to be  <dig>  mg/  <dig> cells. a single mid-exponential time-point of  <dig> hours was chosen for mfa analysis to fulfill pseudo steady-state conditions.

implementation
all mfa calculations, validation, and sampling were carried out using the omfapy python package, developed in-house. the package as well as analysis code is available on github . basic functionality was based on theoretical principles presented in  <cit> . sampling of a feasible flux space was implemented using the random direction algorithm  <cit>  as well as the mirror algorithm presented in  <cit> . although slower, the mirror algorithm was able to generate more even coverage of the sampling space.

RESULTS
identification of model error
observed uptake fluxes and their corresponding coefficients of variation  <dig> hours post inoculation are shown in table  <dig>  with overall metabolite concentration profiles and cell density in fig.  <dig>  as usual for cho cells, the metabolic profile was dominated by large fluxes of glucose and lactate. considerable fluxes of alanine, glutamaxtm, ammonia, and glutamine were also observed. the median coefficient of variation was found to be  <dig>  %. although this was similar to previously reported estimates for concentration quantification via nmr  <cit> , incorporating the uncertainty of derivative calculation resulted in a somewhat larger probability of high variance values. as in  <cit> , the singularly high variability of glutamate flux was primarily due to its low concentration and heavy spectral convolution.
fig.  <dig> observed time-course trends. the presented data depicts all metabolic trends from a cho cell cultivation carried out in a batch reactor . a single timepoint of  <dig> hours was chosen for mfa analysis, corresponding to the midpoint of the exponential phase . panels depict a metabolites that changed by more than  <dig> % of their maximum concentration, b those that changed by less than  <dig> %, and c cell density. all metabolite concentrations are expressed as fractions of their maximum value. curves were calculated from cubic regression spline fits constrained to  <dig> basis functions. grey area designates  <dig> % prediction interval used for sampling



the incorporation of the observed fluxes into the mfa model showed no issues using typical metrics. the condition number of the reduced stoichiometry matrix was considerably below  <dig> and the χ2p-value was  <dig> , indicating little evidence of gross measurement error. however, t-test analysis on the calculated fluxes using the gls framework revealed that only  <dig> of  <dig> fluxes were statistically significant . the statistically significant fluxes were primarily those that related to glycolysis – offering only a shallow look at cellular metabolism. all of the tca and many of the amino acid degradation fluxes were deemed non-significant. to determine whether measurement variability or model error was to blame,  <dig> flux profiles were sampled from the stoichiometric matrix bounded by  <dig> % confidence intervals on the measured fluxes . ninety-nine percent intervals were chosen to include practically all possible flux values. the sampled fluxes had good coverage of the constraint space, suggesting that the model was flexible enough to fit fluxes similar to those observed. each balanced flux profile was then perturbed  <dig> times using normally distributed noise generated from observed flux standard deviations. the result was  <dig>  <dig> sets of fluxes subject to observed measurement error but no model error.
fig.  <dig> comparison of flux rejection between observed and simulated data. panels depict a calculated flux magnitude and b the percent of simulations in which the calculated fluxes were found to be non-significant . simulated data was drawn from the stoichiometric model described in the methods section, constrained by  <dig> % confidence intervals on fluxes observed at  <dig> hours post inoculation.  <dig> balanced flux profiles were generated with  <dig> random generated sets of measurement error applied to each. see additional file  <dig> for reaction definitions



effect of measurement noise
an extended simulation was carried out to determine whether the lack of statistical significance was due to measurement variability. the flux constraints were extended beyond  <dig> hours post inoculation to consider the broader applicability of the model.  <dig> % confidence intervals were generated for all fluxes 18- <dig> hours post inoculation with the minimum and maximum values for each flux used to bound the flux solution space.  <dig> balanced flux profiles were generated with  <dig> sets of measurement error drawn from a normal distribution using  <dig>   <dig>   <dig>  and  <dig> % coefficients of variation for each flux. the  <dig> calculated fluxes spanned more than  <dig> logarithms of values from approximately  <dig>  nmol106cells·h to  <dig> nmol106cells·h . fluxes had variable magnitudes across the simulations, so all analysis was performed as a function of flux rank, where a rank of  <dig> indicates the smallest magnitude flux in a given flux profile.
fig.  <dig> comparison of fluxes simulated with different measurement errors. panels depict a flux magnitude, b median error, and c percent non-significance. simulated data was drawn from the stoichiometric model described in the methods section, constrained by  <dig> % confidence intervals on fluxes observed between  <dig> and  <dig> hours post inoculation.  <dig> balanced flux profiles were generated with  <dig> random generated sets of measurement error applied to each. each balanced flux profile was ordered according to increasing absolute flux magnitude to generate an associated rank from  <dig> to 45



all the simulated flux profiles were subject to a χ <dig> test, with only  <dig> % of the simulations rejected . the remainder of the fluxes are shown in fig.  <dig>  as the simulated fluxes included both observed and calculated values, a percent error could be calculated for each calculated flux. despite passing the χ <dig> test, most fluxes were characterized by median errors of 10– <dig> % , increasing with measurement variability. it should be noted that the median is a relatively conservative statistic. by definition, half of the calculated fluxes featured much greater errors than the reported values. the pronounced jump in error for flux ranks of  <dig> to  <dig> was traced to the tca fluxes, which had high error despite large flux magnitudes. similar to median error, the percentage of fluxes identified as non-significant increased with measurement variability . however, even measurements with  <dig> % coefficient of variation resulted in rejection rates of  <dig> % or more across practically all fluxes. the tca fluxes in particular  were rejected as non-significant  <dig> % of the time or more . the high level of flux rejection at low levels of measurement variability suggested the uncertainty in mfa calculation using observed data was primarily due to model structure rather than the uncertainty of observed data. despite passing traditional validation tests, the simulation of stoichiometrically balanced fluxes revealed that the model is incapable of explaining observed metabolic profiles with an acceptable degree of confidence.

effect of model structure
to test the influence of model structure on the significance of calculated fluxes, we simulated the effect of a broken electron transport chain – allowing a closed balanced on nadh and nadph. essentially, nadh and nadph were reintroduced into the model and assumed to be balanced by the defined stoichiometric relations. although arbitrary, this assumption is consistent with largely anaerobic metabolism of cho cells  and allowed the addition of balances around intermediate compounds participating in many reactions. incorporating the modified model into analysis of the observed fluxes at  <dig> hours post inoculation revealed no sign of gross measurement error  and decreased the number of non-significant fluxes from  <dig>  to  <dig>  as before,  <dig>  <dig> sets of fluxes were simulated from  <dig> % confidence intervals around the observed measurement fluxes, subject to observed measurement error . in comparison to figs. 2b, fig. 4b reveals a considerable increase in significance across a large number of fluxes, consistent with the idea that model structure plays an important role in uncertainty around calculated fluxes. the impact was particularly drastic for tca fluxes, most of which changed from entirely non-significant to significant. despite the improvement in model fit, some model error could also be observed – too many of the low magnitude fluxes calculated from observed data were found to be non-significant when compared to the simulated results.
fig.  <dig> comparison of flux rejection between observed and simulated data following model modification. panels depict a calculated flux magnitude and b the percent of simulations in which the calculated fluxes were found to be non-significant . simulated data was drawn from a modification of the stoichiometric model described in the methods section , constrained by  <dig> % confidence intervals on fluxes observed at  <dig> hours post inoculation.  <dig> balanced flux profiles were generated with  <dig> random generated sets of measurement error applied to each. see additional file  <dig> for reaction definitions



the modified model was also tested with an extended simulation . as with the original model,  <dig> % confidence intervals were generated for all fluxes 18– <dig> hours post inoculation with the minimum and maximum values for each flux used to bound the flux solution space. the most pronounced impact of the modification was on the rate of flux rejection . at  <dig> % measurement variability, approximately two thirds of the fluxes were always significant. the remaining third of the lowest magnitude fluxes were significant at least  <dig> % of the time. in comparison, none of the fluxes calculated with the original model were significant for more than  <dig> % of the simulations. to get a better idea of how the t-test metric related to flux inaccuracy, median errors were separated for significant and non-significant fluxes. at  <dig> % coefficient of variation, fluxes deemed statistically significant had a constant median error of less than  <dig> % , while non-significant fluxes had considerably higher errors . increasing coefficients of variation resulted in dramatic increases in overall rates of flux rejection . however, the median error of statistically significant fluxes also increased, diminishing the ability of the t-test metric to identify inaccuracy in higher magnitude fluxes . in comparison, the typical χ <dig> test retained a  <dig> % rejection rate for all measurement errors .
fig.  <dig> comparison of fluxes simulated with different measurement errors following model modification. panels depict a flux magnitude, b median error, and c percent non-significance of fluxes simulated with different measurement errors. simulated data was drawn from a modification of the stoichiometric model described in the methods section , constrained by  <dig> % confidence intervals on fluxes observed between  <dig> and  <dig> hours post inoculation.  <dig> balanced flux profiles were generated with  <dig> random generated sets of measurement error applied to each. each balanced flux profile was ordered according to increasing absolute flux magnitude to generate an associated rank from  <dig> to 45

fig.  <dig> comparison of median error of significant and non-significant fluxes  simulated with different measurement errors. simulated data was drawn from a modification of the stoichiometric model described in the methods section , constrained by  <dig> % confidence intervals on fluxes observed between  <dig> and  <dig> hours post inoculation.  <dig> balanced flux profiles were generated with  <dig> random generated sets of measurement error applied to each. each balanced flux profile was ordered according to increasing absolute flux magnitude to generate an associated rank from  <dig> to 45



discussion
taken together, the results of the simulations suggest that both measurement uncertainty and model structure have an impact on mfa results that are not assessed by typical validation methods. the structure of the model may lead to a considerable amount of uncertainty around calculated fluxes despite a high level of measurement precision. mathematically, this impact can be seen in the sc′tsc′− <dig> term that stems from the variance of estimated regression parameters, i.e., cov. less formally, it may be intuitive that a model featuring a balance on important intermediate metabolites such as nadh and nadph would be able to estimate intracellular fluxes with a greater degree of confidence than a model without the extra information afforded by the balance. naturally, the addition of isotopically labelled substrates can add a much greater degree of certainty. indeed, an important application of the proposed testing and simulation framework is to provide a rigorous assessment of when extra information from sources such as labelled substrate would be essential for accurate flux calculation.

the proposed framework integrates a number of validation steps. while the t-test offers a straightforward post-regression significance test, combining the t-test with balanced flux simulation provides a convenient assessment of practical model identifiability  <cit> . in addition, comparing the results from simulated and observed values can identify a lack of fit between model and measured data. model fit is particularly important in the context of overdetermined mfa due to the large degree of simplification involved in model generation. our findings suggest that the results of such simplification may be poor identifiability and lack of fit. these issues are rarely considered outside of “gross measurement error” detection. the combination of t-test validation and balanced flux simulation offers a simple and practical approach that avoids the assumption of model validity in the determination of significance. although this validation strategy was developed for the analysis of simplified metabolic models, it should be equally useful at larger scales provided that enough observations are available.

it is important to note that the gls framework for validation is more robust to estimated measurement error than the standard χ <dig> test. gls regression only requires an estimate of relative measurement variance and covariance in the form of v. residual variance magnitude  is still estimated from the model. on the other hand, variance scaling in the χ <dig> test allows for large measurement variance to reduce the χ <dig> statistic. effectively, high variability leads to a lower confidence that deviations are not normally distributed. given that variance does not factor into any other aspect of validation, assuming a large variance can serve as a way to avoid dealing with lack of fit.

following the case study presented in this work, we recommend the following validation procedure. before any experiments are carried out , construct reasonable limits around each observable flux from literature or other available data. simulate flux profiles from the constrained flux space and perturb them with a range of measurement errors. if the flux space is infeasible, there is considerable disagreement between fluxes and the model that needs to be resolved. otherwise, generate confidence intervals around the calculated fluxes and calculate the proportion of simulated fluxes that are non-significant. if many high magnitude fluxes are found to be non-significant in the majority of simulations , then the model may have structural issues that need to be resolved. alternatively, extra flux information may be required. if the model is sound, then experiments can be carried out and collected data analyzed via mfa. apply the model and generate confidence intervals around calculated fluxes. construct limits in close vicinity of observed values, simulate flux profiles, and perturb them with estimated measurement error. if the confidence intervals of simulated fluxes are considerably smaller than those of observed fluxes, then the model may have errors resulting in a lack of fit.

CONCLUSIONS
the interpretation of mfa through the gls framework underscores the need for robust validation methods. the mathematical equivalence of mfa and regression suggests that the failure to follow good practices of regression analysis can lead to questionable results. this work highlights the application of simple t-tests for the detection of error due to measurement variability and presents a means to directly assess model error via flux profile simulation. at the same time, we bring attention to the impact of measurement variability on model identifiability, underlining the need for better reporting. although this work has focused on the validation of a traditional mfa model via t-test analysis, the overall framework is likely to be just as applicable to other regression validation methods or alternative mfa formulations .

endnotes
 <dig> a more detailed discussion of the theoretical principles, including a worked example and some proofs, is available as an additional file  <dig> 

 <dig> it is typically assumed that sc is sufficient for the estimation of all vc values. however, failure to observe a key metabolite may result in a case where not all values of vc can be estimated despite sc appearing determined or overdetermined. see  <cit>  for details on stoichiometry matrix classification.

additional files
additional file  <dig> extended theoretical principles. to make the proposed protocol as accessible as possible, the theoretical section has been extended with a number extra details as well as a simplified example model. 



additional file  <dig> detailed model description and metabolic map. definitions of all reactions included in the metabolic model. 



additional file  <dig> sbml file. an sbml representation of the metabolic model. 



abbreviations
atpadenosine triphosphate

chochinese hamster ovary

cobraconstraint-based reconstruction and analysis

fadhflavin adenine dinucleotide

glsgeneralized least squares

mfametabolic flux analysis

nadhnicotinamide adenine dinucleotide

nadphnicotinamide adenine dinucleotide phosphate

nmrnuclear magnetic resonance

sbmlsystems biology markup language

tcatricarboxylic acid 

