BACKGROUND
high-throughput technologies in different areas of biomedical research provide massive amounts of data that are difficult to organize and interpret. network-based representations of biological systems have become a popular way to structure and analyse this information. networks can be inferred directly from experimental data or created from prior knowledge – prior knowledge networks . both strategies have their advantages and disadvantages. pkns are normally not context-specific, as they usually include all regulatory interactions relevant to the process under study, and may be biased towards biological entities and interactions that are intensively studied, or merge interactions measured under different experimental conditions, including different cell types or tissues. networks inferred exclusively from high-throughput data  may be more comprehensive and more contextualized to the experimental conditions of interest, but they do not provide direct information about causal relationships, i.e., directionality, as they are usually based on the statistical co-occurrence of biological events . the underlying causality can be elucidated only for a reduced number of cases by costly perturbation experiments or time series data.

in an attempt to overcome the drawbacks of these two network construction strategies, several methods combining both prior knowledge and experimental data have been developed during the last years. among these methods, we distinguish those that exhaustively explore the search space in order to identify an optimal configuration that explains the experimental data - combinatorial optimization methods - from those based on a heuristic approach. combinatorial optimization methods include those based on integer programming  or answer set programming  <cit> . their computational complexity grows exponentially with the network size, limiting their applicability to small systems. heuristic approaches that attempt to overcome these limitations can be divided into those that focus on describing the response of the system to perturbations and those that focus on describing the stable states of the system. heuristic contextualization methods that focus on describing the response of the system to perturbations require multiple perturbation experiments to train the pkn. saez-rodriguez et al.  <cit>  proposed discrete logic modelling to curate and expand canonical signalling pathways using information from perturbation experiments to train the model. irit gat-viks et al.  <cit>  developed a similar method to construct discrete dynamical models from a pkn that include feedback loops, transforming the original graph into multiple acyclic graphs starting from multiple perturbed nodes, for which perturbation experiment data should be available.

heuristic contextualization methods that focus on describing the stable states of the system require less experimental information but the resulting models are strongly contextualized to the stable states. examples include the methods proposed by layek et al.  <cit> , crespo et al.  <cit>  and rodriguez et al.  <cit> . the main limitation of these methods is that, given that they are trained to describe correctly the stable states, they may fail to describe other dynamical behaviours, such as the transitions between stable states under specific perturbations. in a specific example, rodriguez et al.  <cit>  showed in a model of the t-helper differentiation process how only a fraction of the alternative optimized models successfully described a known transdifferentiation between phenotypes th <dig> and th <dig> under the stimulation of gata <dig> 

here we propose a new heuristic method for the contextualization of pkns that specifically addresses the above-mentioned limitations. it consists in a heuristic network training approach that considers not only the stable states of the system but also the reachability of those states under specific perturbations. the method takes as input a pkn and experimental information about the stable states and transitions between them upon perturbation. a genetic algorithm is used to explore the search space of boolean networks with asynchronous updates and to find networks that best describe the experimental data, using only edges present in the pkn. we demonstrate the ability of our algorithm to reconstruct a previously published cell-fate decision model  <cit>  used as gold standard, by comparing the networks reconstructed by our algorithm to the original cell-fate decision model. the results demonstrate the utility of the approach to reconstruct reliable dynamical boolean models based on the integration of pkn and experimental data. such models can be interrogated to predict network response under perturbation, stability properties and robustness of the network, with potential application to guide experimental approaches including hypothesis generation.

methods
this section is divided in two main parts. part  <dig> describes our network optimization method . this takes as input a pkn and a set of experiments  and uses a genetic algorithm to train model networks to reproduce as closely as possible the experimental data provided in the training set, with the constraint that all edges must be taken from the pkn. the output of the method is a set of model networks. part  <dig> describes our method to assess the quality of network optimization. this uses an in silico gold standard network to generate pkns and training sets, which are taken as input for the optimization method. the resulting model networks are then compared to the original in silico gold standard network and the result of this comparison is taken as a measure of our network optimization method quality.fig.  <dig> optimization method. our network optimization method takes as input a pkn and a training set and uses a genetic algorithm to find sub-graphs of the pkn which reproduce as well as possible all experiments in the training set. for each run of the optimization method, only the best network is kept as optimized network. to increase the chances to obtain good solutions, multiple independent runs of the optimization method are usually started in parallel, and only a fraction of optimized networks is kept as model networks




description of the network optimization method
definitions
model network
a model network is a boolean network, used to model a given biological process. ideally, the model network obtained after the optimization procedure should behave like the biological system. in this work we consider asynchronous boolean networks, as defined by garg and co-authors  <cit> . each node corresponds to a gene or a protein and its state is given by a boolean variable, which can represent node expression or activity. edges correspond to interactions between nodes and can be positive  or negative . the dynamical behaviour of a boolean network can be measured by performing in silico experiments. in this work, an in silico experiment consists of a set of perturbations  and a set of transitions between them. for each transition from a perturbation p <dig> to a perturbation p <dig>  the output of the in silico experiment is an attractor reachability graph  whose nodes are attractors obtained with each perturbation and edges denote reachability between attractors. more precisely, an edge will connect an attractor obtained with perturbation p <dig> to an attractor obtained with perturbation p <dig> if and only if the states of the first attractor are connected to the states of the second attractor by at least one path in the asynchronous state transition graph of the network with perturbation p <dig> fig.  <dig> in silico experiments and attractor reachability graph. example of attractor reachability graph for the transition from unperturbed network to over-expression of tnf on the cell-fate decision model  <cit> . the unperturbed network has four attractors, each shown as a network with red nodes corresponding to active nodes and blue nodes corresponding to inactive nodes. these attractors are labelled a <dig> , a <dig> , a <dig> , and a <dig> . attractor a <dig>  corresponds to the physiological state used by calzone and co-authors  <cit>  as initial state. the perturbed network  has only three attractors , interpreted as the three cell fates: non-apoptotic cell death, survival, and apoptosis. after tnf over-expression, each attractor of the unperturbed network will stabilize into at least one attractor of the perturbed network . for example, the physiological state a <dig>  will stabilize into either of the three cell fates a <dig> , a <dig>  and a <dig> . note that this figure presents only the transition from unperturbed network to over-expression of tnf, and not the reverse transition. therefore no information is shown on the reachability from attractors obtained with over-expression of tnf to attractors of the unperturbed network




to perform in silico experiments, two methods were used in this work. the first method is boolsim, a software developed by garg and co-authors  <cit> , which uses an implicit method based on reduced ordered binary decision diagrams to evaluate the attractor reachability graph of a network. this method is exact and exhaustively finds all attractors but quickly becomes too computationally expensive for large networks. the second method we used was a simple algorithm based on a stochastic exploration of the state transition graph . this stochastic approach scales better than boolsim as network size increases, but there is no guarantee that all attractors will be found. in this work, the stochastic method was used to evaluate attractor reachability graphs in our implementation of the optimization method, while boolsim was used to assess the quality of the final optimization results.

prior knowledge network 
the pkn is a network that summarizes known interactions between genes and/or proteins of interest, usually obtained from the literature by a biocurator or by automatic text mining methods. note that although this network can contain direct interactions, most of the interactions are usually indirect.

training set
the training set is a set of known experimental results that the final model network should be able to reproduce. in this work, the training set consists of stable phenotypes measured in different conditions and transitions between them. it is given in the form of a transition graph. each node of the training set graph is defined by a perturbation and an observation. a perturbation can involve the over-expression  and/or knock-out  of any subset of nodes in the network. an observation is a list of nodes and their corresponding state measured at equilibrium after the perturbation. node states should be either  <dig> or  <dig>  edges in the training set graph correspond to transitions between stable phenotypes. an edge from perturbation p <dig> with observation o <dig> to perturbation p <dig> with observation o <dig> means that under perturbation p <dig> the system exhibits a stable phenotype characterized by observation o <dig> and after perturbation p <dig> the system will stabilize into a phenotype characterized by observation o <dig>  note that p1 = p <dig> is allowed, as well as o1 = o <dig> 

intuitively, a boolean network reproduces a training set if for each perturbation/observation in the training set, the network can stabilize into an attractor compatible with the observation when applying the corresponding perturbation. in addition, attractors matched to perturbation/observation nodes linked by an edge in the training set graph should be connected by “time” evolution of the network, i.e. connected by an edge in the attractor reachability graph. finally, each node of the training set graph should correspond to a unique attractor in the attractor reachability graph. for instance, the following training set graph  →  →  means that the model network should have at least one attractor a <dig> with node states corresponding to observation o <dig> when perturbed by p <dig>  as well as attractors a <dig> and a <dig> with node states corresponding to observations o <dig> and o <dig> when perturbed by p <dig> and p <dig> respectively. in addition, a <dig> should be connected to a <dig> and the same attractor a <dig> should be connected to a <dig> in the attractor reachability graph.

this definition of training set is flexible enough to accommodate complex experimental scenarios such as the  responses to drugs in specific mutational backgrounds, but also time-dependent processes such as cellular differentiation in response to various combinations of stimuli. multiple scenarios can even be combined into a unique training set .

problem formulation
given a pkn and a training set, find the model network that reproduces as well as possible all experiments in the training set, under the constraint that the model network must be a sub-graph of the pkn .

we also enforced the following properties of the model network, given in decreasing order of importance.  it should include a user-defined set of essential nodes. typically, this set will contain nodes that are known to play an important role in the modelled biological process, or that represent key experimental readouts.  it should be as small as possible in terms of number of nodes. since the prior knowledge network can be very large, it can be challenging to evaluate its attractors, therefore having a model network that is as simple as possible should reduce the computational effort.  given a set of nodes, the model network should contain as many edges  from the pkn as possible. the idea here is to force the model network to be as close as possible to the pkn, removing only edges that are in contradiction with the training set.

to optimize all these properties simultaneously, we used a standard multi-objective optimization approach, based on a multi-dimensional fitness function, defined for each network as f=ft,−ness.nodes,nnodes,−nedges where f
t measures how well the network reproduce the experiments given in the training set, n
ess. nodes is the number of essential nodes appearing in the network, n
nodes is its number of nodes and n
edges its number of edges. multi-dimensional fitness functions are compared using lexicographical ordering, which means that optimization of f
t is considered as most important, followed by n
ess. nodes, n
nodes and finally n
edges. note that the component responsible for maximization of the number of edges  appears only after the number of nodes . as a consequence, networks with same f
t and n
ess. nodes are first compared according to their number of nodes. only if they have the same number of nodes, their number of edges is taken into account in the comparison. the first component f
t  measures the average distance between observations contained in the training set and attractors of the network, with the following constraints on the chosen attractors:  if two observations are connected by an edge in the training set graph then the corresponding attractors must be connected in the attractor reachability graph and  each observation in the training set graph must correspond to a unique attractor. among all attractors satisfying these two constraints, only the ones that minimize f
t are taken into account. approximately, f
t can be considered as the fraction of observations in the training set that are not reproduced correctly by the network.

with these definitions, the challenge becomes a non-linear discrete optimization problem: the model network corresponds to the sub-graph of the pkn that minimizes the multi-dimensional fitness function f. for a pkn with m edges, the number of possible model networks is 2m. as a consequence, except for a very small pkn, brute force testing of all possible networks is not possible, and a numerical optimization method is required. here we use a genetic algorithm , a well-established heuristic optimization method, which can be easily implemented and is known to give reasonably good results with non-linear discrete optimization problems. heuristic optimization algorithms, like the genetic algorithm, are designed to seek good solutions, at a reasonable computational cost, but without guarantee of optimality or completeness. it is worth noting that this problem is neither linear nor convex, and therefore more efficient linear or convex optimization methods cannot be used here. indeed, contrary to the case where the training set contains only information on steady states  or successive states in the state transition graph, which can be reformulated as a linear or convex optimization problem  <cit> , the more general form of our training set, which contains information on attractors but also reachability between them, prevents this reformulation.

except for very large training sets, this optimization problem will in general not be completely specified. indeed, several different networks may be able to reproduce the training set equally well . although adding more components to the fitness function  should help to reduce the number of networks that are solutions of the optimization problem, it may not be sufficient to reduce the solution to a unique network. therefore, the solution to the optimization problem should not be considered as a unique network, but as a collection of different networks which are all equally good candidate models. this is not a limitation of the chosen optimization method , but a consequence of the lack of knowledge on the biological system. to reduce the number of solutions, an obvious solution consists in increasing the training set size. alternatively, carefully building the pkn without unnecessary edges will help to decrease the dimension of the search space as well as the number of solutions.

the bottleneck with this approach in terms of performance is the evaluation of attractor reachability graphs. as a consequence, this method should be used with networks having on the order of hundreds of nodes. this limit on the network size is not strict, since the computational cost will depend on the number of nodes, connectivity and topology of the optimized networks, which are governed by the corresponding properties of the pkn as well as the number of essential nodes.

evaluation of the network optimization method
to evaluate the network optimization method, we used a gold standard model to generate in silico pkns and training sets, which were then used as input for our network optimization method. the resulting model networks were then compared to the original gold standard network, and the result of this comparison was taken as a proxy for the quality of the optimization method.

as gold standard, we used a cell-fate decision model proposed by calzone and co-authors  <cit>  . note that it is outside the scope of the present paper to discuss whether this model correctly describes the underlying biological process. a toy model completely unrelated to any biological process could also have been used as a gold standard.fig.  <dig> cell-fate decision model. a cell-fate decision model  <cit>  used as gold standard. essential nodes are shown with grey background. b list of transitions, starting from each of the  <dig> unperturbed network’s attractors to attractors reached after single node perturbations of the cell-fate decision model. each line corresponds to an edge in the attractor reachability graph. only the first lines are shown, the full table is given in additional file  <dig>  c pkn obtained from  by adding edges from perturbed nodes to observed nodes whose state  change by more than  <dig>  . edges are positive if perturbation and variation of observed node state have same sign, and negative if they have opposite sign. for example, line  <dig> in table  will generate seven positive edges from apoptosome to apoptosis, bax, casp <dig>  casp <dig>  cyt_c, momp and smac as well as one negative edge from apoptosome to ciap. the complete list of interactions in the pkn is given in additional file  <dig> 




to illustrate the simplification of the network obtained by minimizing the number of nodes, we decided to use training sets containing information for only a fraction of all nodes in the gold standard model, namely the  <dig> nodes chosen by calzone and co-authors for their reduced cell-fate decision model  <cit>  .

generating input data
in silico pkn
boolsim was used to perform every possible single node perturbation experiment on the gold standard network, starting from the unperturbed network. the resulting attractor reachability graphs were used to build a list of attractor transitions , with each line corresponding to one edge in the attractor reachability graph. if an attractor had more than one state, it was replaced by the average of all its states. assuming that each line in the list transitions  corresponded to a transition that could be observed experimentally and reported in an article, an in silico pkn was built by linking perturbed nodes to observed nodes whose states changed significantly . that is, each line in fig. 3b generates edges from the perturbed node to each observed node whose state changes by more than  <dig>  . edges are positive if perturbation and variation of observed node state have the same sign, and negative if they have opposite signs. finally all edges of the gold standard network also are added to the pkn.

in addition to this ideal pkn, we also generated five pkns with increasing fractions of noise . to generate a pkn with noise fraction q, we randomly replaced a fraction q of all edges in the ideal pkn by the same number of edges randomly chosen in the set of edges of the form n
1 → n
 <dig> and n
1 ⊣ n
 <dig> that were not in the ideal pkn . the lists of interactions in each of these pkns are given in additional file  <dig> .

essential nodes
we used the  <dig> nodes of the reduced cell-fate decision model proposed by calzone and co-authors  <cit> : atp, apoptosis, casp <dig>  casp <dig>  ciap, fasl, momp, mpt, nfkb, nonacd, rip <dig>  ros, survival and tnf .

in silico training sets
we built a training set based on the response to tnf and fasl perturbations by mutant versions of the cell-fate decision model discussed by calzone and co-authors  <cit> . we considered seven mutant versions: wild-type, casp <dig> knock-out, casp <dig> knock-out, ciap knock-out, nfkb knock-out, rip <dig> knock-out and simultaneous knock-out of casp <dig>  casp <dig> and rip <dig>  for each mutant, we measured the response of the gold standard network to tnf over-expression, fasl over-expression and simultaneous over-expression of tnf and fasl, starting from the physiological state  described by calzone and co-authors  <cit> . for each attractor obtained, an observation was added to the training set, using the measured states of all essential nodes in the attractor. for each attractor reached after perturbation of tnf, fasl or tnf and fasl together, we added to the training set a transition from the initial attractor  to the reached attractor. the resulting training set is given in additional file  <dig>  training set  <dig>  note that for a given mutant, all perturbations are linked to the same initial observation obtained with the unperturbed network, which means that during the optimization, only transitions starting from the same initial attractor will be used to evaluate the fitness function.

in addition to this training set, we also built two smaller training sets obtained by keeping only transitions for the wild-type mutant , and keeping only the initial physiological attractor .

to study the effect of errors in training sets on the optimization method, we also generated five training sets with increasing fractions of errors  by randomly reversing the corresponding fraction of all node states appearing in training set  <dig> .

comparing a model network to the gold standard
given a model network, obtained by using the network optimization method with an in silico pkn and training set generated from the gold standard network, we measured how close this model network was to the gold standard network. various metrics could be used here, but we considered that the most important characteristic of a model network was its ability to correctly predict the behaviour of the underlying biological system . to compare predictions from the model network and gold standard network we defined a score  which measures the similarity between the average states reached by the model network and gold standard network after all possible single node perturbations of essential nodes, starting from each attractor of the unperturbed gold standard network. more precisely, for each perturbation and initial state, the average state reached by a network is a vector of dimension n
ess. nodes whose n-th component is obtained as the average state of the n-th essential node over all attractors reached after the perturbation, starting from the given initial state. the s
all score is then defined as s
all = 1 − Δ/n
ess. nodes, where Δ denotes the average over all perturbations and initial states of the manhattan distance between average states reached by the model network and gold standard network . we decided to consider not only the best attractor  but to consider all attractors reached, thus penalizing those situations where only part of the attractors reached by the model correspond to the attractors reached by the gold standard network.

the s
all score defined in this way has a value of  <dig> when the average predictions of both networks consistently agree for all perturbations and initial states, and a value of  <dig> when both networks consistently predict opposite states. since the evaluation of the s
all score is based on experiments that are not part of the training set, it can be interpreted as a measure of the predictive power of the model network.

evaluation of the optimization method: workflow
an important question in the context of network optimization is whether a network is able to correctly predict the outcome of experiments that are not part of the training set against which it was optimized. to answer this question and to assess the quality of the network optimization method, we proceeded in the following way :as described above, the gold standard network  was used to generate an in silico pkn  and an in silico training set .

multiple independent runs  of the network optimization method were performed, each with the same in silico pkn and training set as input , using a population of  <dig> replicas for the genetic algorithm. each run was halted if the best value of the fitness function did not decrease during more than  <dig> iterations, and the network with the best fitness function obtained during the run was retained. among the  <dig> networks generated in this way only the best  <dig> networks  were kept as model networks .

for each model network and the gold standard network we performed in silico experiments to find the attractors reached after all possible single node perturbations of essential nodes, starting from each attractor of the unperturbed gold standard network .

the predictions for each model network were then compared to the gold standard network predictions by measuring the s
all score defined previously . these scores, which measure the predictive power of the model networks, were then interpreted as a measure of the optimization method quality.


fig.  <dig> evaluation of the optimization method: workflow. to evaluate our optimization method, we used a gold standard network, interpreted as the true underlying biological system’s network . an in silico pkn  and a training set  containing a limited amount of information were generated by performing in silico experiments on the gold standard network. using the pkn and training set as input, we started  <dig> independent runs of our network optimization , and kept the best network  obtained with each run. among these  <dig> networks, the  <dig> best networks  were kept as model networks . the predictive power of each model network was then evaluated by comparing its average predictions for all single node perturbations  to the corresponding gold standard network predictions . the resulting s
all scores  measure how close model networks and gold standard network predictions are and were taken as a proxy for the quality of the optimization method




this procedure was repeated with different training sets and pkns to study the behaviour of the network optimization method in different conditions.

random networks
the distribution of s
all scores indicates how close the model networks predictions are to the gold standard network predictions. another important question is whether a score s
all obtained with a given model network is significantly better than a score obtained with a random network, i.e. is the optimization method better than a random network generator? to answer this question, random sub-networks of the pkn were generated by randomly keeping  each interaction in the pkn. the randomized network s
all scores were then evaluated and compared to the model network s
all score.

RESULTS
network optimization: applied example
we illustrate how our optimization method behaves by following its evolution when applied on a sample data set. we performed  <dig> independent runs of the optimization method using training set  <dig> , pkn  <dig>  and the  <dig> essential nodes discussed in the method section .

figure 5a illustrates how the individual components of the fitness function f =  evolve during the run giving the network with the minimal fitness function value. following an initialization of all replicas to the empty network, the optimization process starts with an initial phase where f
t decreases while n
ess. nodes, n
nodes and n
edges all increase as the networks are populated with nodes and edges. the number of nodes and edges is large enough to include all essential nodes  for most networks after the 50th iteration, and when n
ess. nodes saturates the number of nodes starts to decrease. the number of edges tends to increase steadily from the first to the last iteration, but increases faster whenever the number of nodes increases or saturates. this is a consequence of the lexicographical ordering of multi-dimensional fitness functions. the optimization is stopped when the best value of the fitness function fails to decrease during  <dig> consecutive iterations, and the network with best value of the fitness function is retained as the output of this optimization run.fig.  <dig> example of network optimization: best run. a evolution of the fitness function f =  during one run of the optimization method using the training set  <dig> given in additional file  <dig>  the pkn given in additional file  <dig>  and the  <dig> essential nodes from the reduced cell-fate decision model proposed by calzone and co-authors  <cit> . for each given iteration, blue dots correspond to individual replicas and black dot to the replica with best value of the fitness function. b network with best value of the fitness function obtained during this run. the run shown in this figure is the one that produced the network with minimal value of the fitness function among  <dig> independent runs




figure 5b presents the best network obtained during this optimization run. it has a first fitness function component f
t =  <dig>  which means that it perfectly reproduces all the experiments in the training set. the second component  is also optimal. the third component n
nodes =  <dig> is very close to the minimal value  <dig>  although it may not be optimal, the fact that no network was found with n
nodes =  <dig> and f
t =  <dig> in any of the  <dig> runs suggest that n
nodes =  <dig> is the minimum number of nodes compatible with f
t =  <dig>  it is not clear whether the fourth component  is optimal since it is much smaller than the  <dig> edges from the pkn connecting the  <dig> nodes of this network. therefore, while this network may not be an exact global minimum of the fitness function, it seems to be very close, which suggests that our implementation of the genetic algorithm is appropriate to handle this minimization problem.

the goal of our network optimization method is not only to find networks that can reproduce all experiments in the training set , but also, and most importantly to find networks that can predict the outcome of experiments against which they were not trained. since the gold standard network used to generate the pkn and the training set is known, this can be quantified by evaluating the s
all score  which measures the similarity between the average attractors reached by the model network and the average attractors reached by the gold standard network after all possible single node perturbations. note that contrary to f
t, which only takes into account a subset of the attractors that best match the training set, the s
all score takes into account all attractors reached after perturbation, thus penalizing the situation where only a subset of attractors behave properly. for the model network given in fig. 5b, s
all ≃  <dig> , so approximately  <dig>  % of the predicted node states are correct following single node perturbations. although only one attractor of the unperturbed gold standard network was part of the training set, the model network nevertheless recovered the same  <dig> attractors as the gold standard network, with only one error .

we next examined the diversity of model networks that can be obtained by running the optimization method multiple times. for each of the  <dig> independent runs we selected the single best network, and from these  <dig> optimized networks then selected the  <dig> networks with the lowest fitness function, which were retained as model networks. while none of these networks necessarily represents an exact global minimum of the fitness function, all networks had optimal values for the first and second components . the best  <dig> model networks were compared to the gold standard model by measuring the s
all scores and the resulting distribution of s
all scores is shown in fig.  <dig>  along with the score for the best network . the median s
all of the  <dig> best networks is high, with about 97 % of node states correctly predicted after all single node perturbations, and significantly higher than the distribution of s
all scores for all the  <dig> networks . this shows that at least for this sample input data set, networks with small values of the fitness function tend to have high s
all scores, i.e. their predictions are close to the gold standard network predictions.fig.  <dig> example of network optimization: s
all scores distribution. distribution of s
all scores obtained with  <dig> independent runs of the optimization method using the same input data as in fig.  <dig>  for each run, only the network with minimal value of the fitness function was kept. this figure shows the s
all scores for the best network , for the  <dig> best networks  and for all  <dig> networks . in addition, s
all scores for the pkn  and  <dig> random sub-networks of the pkn  are shown




to check that the good scores obtained by the model networks were not only due to a very informative pkn, which by construction contains all the functional interactions of the gold standard network, we also measured the s
all score of the pkn . as shown in fig.  <dig>  scores of the best  <dig> model networks  are significantly higher than the score of the pkn , indicating that the optimization method indeed generates models with much improved predictive power compared to the pkn used as input. the s
all scores for random sub-networks of the pkn  are also significantly lower than those for the  <dig> model networks. this result is not entirely trivial, since these random networks are built with edges of the pkn that correspond to functional interactions of the gold standard network.

genetic algorithm
the quality of the optimization method, as measured by the s
all score, is determined by the combination of the optimization algorithm  and the choice of fitness function. in the previous section, we showed that the optimization method was able to generate model networks with good predictive power . this result strongly suggests that the choice of fitness function was adequate and that the optimization algorithm was able to find sufficiently good solutions to the minimization problem. however, it does not say anything about the efficiency of the optimization algorithm, and indeed a simple random network generator could also produce optimal solutions in principle, simply by generating a sufficiently large number of networks.

to evaluate our implementation of the genetic algorithm, we compared the evolution of best fitness function values obtained by our algorithm to best fitness function values obtained on a population of random networks. we started  <dig> independent runs of the optimization method, using the same input as in the previous section . during each run, the fitness function value and s
all score of the best network  obtained were stored for each iteration of the genetic algorithm . the resulting distributions of best fitness function values and corresponding s
all scores obtained with the  <dig> runs are shown in fig.  <dig>  as a function of the number of iterations of the genetic algorithm. in parallel, for each run of the optimization method, a corresponding “random run” was created by generating, for each iteration, exactly the same number of random networks  as the number of networks generated by the genetic algorithm. for each iteration of the random run, we stored the fitness function value and s
all score of the best random network  obtained since the beginning of the run. the resulting distributions of best fitness function values and corresponding s
all scores obtained with the  <dig> “random runs” are shown in fig.  <dig>  as a function of the number of iterations. note that although fig.  <dig> presents data for iterations up to  <dig>  the average run length was  <dig> iterations. missing values from the end of each run until iteration  <dig> were replaced by the fitness function value and s
all score obtained in the last iteration of the run.fig.  <dig> genetic algorithm evaluation. left panel: evolution of fitness function f =  and s
all score for the best network  obtained during a run of the optimization method using the same input data as in fig.  <dig>  blue boxplots summarize values obtained with  <dig> independent runs of the optimization method. grey boxplots show corresponding results obtained with  <dig> “random runs”. note that each box summarizes values obtained during  <dig> iterations . right panel: fitness function and s
all score for the best network  obtained after a specified number of runs . each box summarizes  <dig> values, obtained by randomly sampling the given number of runs among  <dig> independent runs of the optimization method




when comparing results obtained with the genetic algorithm  and random runs , it is clear that the genetic algorithm is much more efficient at generating networks with low values of the fitness function. this is particularly apparent for the first component of the fitness function , where optimized networks reach a median value f
t ≃  <dig> , while random runs reach only a median f
t ≃  <dig> . in addition, while the other components of the fitness function  tend to approach their optimal values in a similar way as in fig. 5a using the genetic algorithm, this is not the case for the random runs. more importantly, the s
all score  increases quickly for optimized networks  to reach a median value s
all ≃  <dig> , while it only marginally increases for random runs to reach a median s
all ≃  <dig> .

in addition to the distribution of best fitness function values obtained during one run discussed above, we also characterized the distribution of best fitness function values obtained after multiple runs . this is particularly relevant in the context of optimization based on genetic algorithms, where it is common practice to start multiple independent runs in parallel. we randomly sampled the specified number of runs  among the  <dig> runs, storing the fitness function value and s
all score of the best network  found in the sampled runs. this process was repeated  <dig> times for each number of runs, so that each boxplot summarizes  <dig> values. using multiple runs has a dramatic impact on the best value of the fitness function obtained with the genetic algorithm : the median value of the first component  decreases from f
t ≃  <dig>  with one run to f
t =  <dig> with  <dig> runs, while its dispersion strongly reduces, with an interquartile range that decreases from  <dig>  with one run to  <dig> with  <dig> runs. similarly, while the median s
all score increases from s
all ≃  <dig>  with one run to s
all ≃  <dig>  with  <dig> runs , its dispersion is reduced, with an interquartile range that decreases from  <dig>  to  <dig> . the other components of the fitness function  are only marginally improved by increasing the number of runs.

the best value of the fitness function obtained with random runs  also improves when increasing the number of runs, but it is still far from the best values obtained with the genetic algorithm. the s
all score obtained with random runs  only slightly increases from s
all ≃  <dig>  with one run to s
all ≃  <dig>  with  <dig> runs.

to summarize, fig.  <dig> shows that our implementation of the genetic algorithm is significantly more efficient than random sampling in finding solutions to the fitness function minimization problem.

pkn quality
in the previous sections we used an ideal pkn which contained only  interactions observed after in silico perturbation experiments of the gold standard network. however, a pkn built from the literature will usually not be perfect; it may contain “noise” in the form of interactions that are not relevant to the particular biological context under study, while some relevant interactions may also be missing.

to investigate the effect of noise in the pkn on the optimization method, we generated five pkns  by adding  <dig>   <dig>   <dig>   <dig>  and 50 % of noise to the ideal pkn, as defined in methods section. for each pkn, we started  <dig> independent runs of the optimization method and kept the best network  obtained with each run. among the  <dig> resulting networks, only the  <dig> with minimal values of the fitness function were kept as model networks. the left panel of fig.  <dig> presents the distribution of fitness function values and s
all scores as a function of the pkn used as input  for the resulting model networks , for random sub-networks of the pkns used as input  and for the pkns . the values of the fitness function obtained with model networks increase  as the fraction of noise in the pkn increases, with the median f
t reaching f
t ≃  <dig>  with 50 % noise. the number of nodes and edges also increases with noise, suggesting that it is not possible to find simple networks that are able to reproduce training set experiments when too many interactions are missing in the pkn.fig.  <dig> pkn quality and training set size. fitness function f =  and s
all score for model networks , random sub-networks of the pkn  and pkn  as a function of noise in the input pkn , errors in the training set  and size of the training set . left panel: results based on the training set  <dig> given in additional file  <dig> and pkns  <dig> to  <dig> . centre panel: results based on training set  <dig> with  <dig> to 50 % error  and pkn  <dig> . right panel: results based on training sets  <dig>   <dig> and  <dig>  and pkn  <dig> . each blue boxplot summarizes measurements on  <dig> model networks obtained out of  <dig> independent runs of the optimization method . each grey boxplot summarizes measurements on  <dig> random sub-networks of the pkn used as input for the optimization method. component n
ess. nodes of the fitness function was always optimal  and is not shown in this figure




as expected, the predictive power of model networks  decreases with increasing noise in the pkn. however, the median s
all score is always above  <dig>  even with 50 % noise in the pkn. in addition, the distribution of s
all scores is always significantly higher for model networks  than for random networks  and pkn . the decrease of s
all scores with increasing pkn noise suggests that our method makes good use of the information contained in the pkn, and that a carefully constructed pkn can increase the quality of the resulting model networks. the fact that model networks always have better s
all scores than pkns also shows that our method is rather tolerant to errors in the pkn. indeed, even with 50 % noise in the pkn, our method is able to output model networks that have more predictive power than the input pkn. however, if the pkn is known to be very noisy, it could be worth considering other methods which are not based on prior knowledge.

training set quality
in the previous section we used an ideal training set obtained by measuring the response of the gold standard network to perturbations. to evaluate the robustness of the optimization method to errors in the training set, we generated five training sets by adding  <dig>   <dig>   <dig>   <dig>  and 50 % of errors to the ideal training set , as described in the methods section.

for each training set, we generated  <dig> model networks from  <dig> independent runs by following the procedure described in the previous sections. the centre panel of fig.  <dig> presents the distribution of fitness function values and s
all scores as a function of the fraction of errors in the input training set for the resulting model networks , for random sub-networks of the pkn  and for the pkn .

the values of the fitness function dramatically increase  when the number of errors in the training set is increased. in particular, while model networks obtained with the ideal training set always perfectly reproduce all experiments in the training set , about  <dig>  % of the training set cannot be reproduced by model networks when the training set contains 10 % of errors . when the training set contains 50 % of errors, f
t reaches a median value of  <dig> , which means that model networks fail to reproduce about 33 % of the training set. this suggests that it is not possible to find a model network, built as a sub-graph of the pkn, which is able to reproduce all errors in our training set.

as expected, the predictive power of model networks  decreases when increasing the fraction of errors in the training set, but this decrease is moderate. for instance, s
all scores are not significantly lower with 10 % of errors in the training set  than with the ideal training set . moreover, for all training sets with up to 30 % of errors, s
all is clearly higher for model networks  than for random sub-networks of the pkn  and for the pkn . only when the training set contains 50 % of errors does the median s
all score of model networks become lower than the s
all score of the pkn. however, even in this case, the median predictive power of model networks is still above 80 %. the moderate decrease of predictive power, together with the rapid increase of fitness function values when the number of errors in the training set increases, suggest that our optimization method is not greatly affected by overfitting. the use of a pkn contributes greatly to this result by drastically reducing the number of parameters in the model.

training set size
in the previous experiments we used a comprehensive training set that included the states of all  <dig> essential nodes measured before and after over-expression of tnf, fasl or the combination of tnf and fasl, for seven mutant versions of the gold standard network . to study the effect of reducing the training set coverage on the optimization method, we generated two smaller training sets : a “medium” training set, which contains data for the wild-type mutant only  and a “small” training set, containing only the initial physiological state . clearly, the small training set does not contain enough information to properly infer a model network, and it was used to study the behaviour of the optimization method in this limit. following the same procedure as in the previous sections, for each training set we used the optimization method to generate  <dig> model networks out of  <dig> independent runs. the resulting distributions of fitness function values and s
all scores are shown in the right panel of fig.  <dig>  as a function of the training set used as input , together with fitness function values and s
all scores measured on random sub-networks of the pkn  and directly on the pkn . although model networks always perfectly reproduce all experiments in the training sets , other components of the fitness function tend to improve when the size of the training set decreases. in particular, the number of nodes reaches its optimal value  for medium and small training sets, while networks obtained with the small training set have more edges than networks obtained with large training set. this is due to the smaller training sets imposing fewer constraints on the networks than larger training sets, which leave more freedom to optimize the remaining components of the fitness function.

although the predictive power of model networks decreases with training set size , it remains significantly higher than that of random sub-networks of the pkn  and the complete pkn  for all training sets. interestingly, while the small training set contains only the states of  <dig> essential nodes in one attractor of the unperturbed gold standard network, the resulting model networks still have a median s
all of  <dig> , which means that approximately 94 % of the  <dig> nodes states measured after all single nodes perturbations are predicted correctly.

to summarize, although the predictive power of model networks decreases with the quantity of information contained in the training set, our optimization method was still able to produce networks with significantly improved predictive power compared to the input pkn and random sub-networks of the pkn when using reduced training sets.

fitness function: maximizing versus minimizing number of edges
the choice of fitness function is an essential ingredient of network optimization methods. while the first two components of our fitness function  can be easily understood, our choice of third and fourth components  may not be so obvious. indeed, these last two components were chosen to first minimize the number of nodes and then maximize the number of edges , whereas a more usual choice of regularization consists in minimizing the number of edges.

to motivate our choice of fitness function, we used our optimization method with the modified fitness function f =  which minimizes the number of edges and does not constrain the number of nodes. for each input data set discussed in the previous sections,  <dig> model networks were generated out of  <dig> independent runs. due to slower convergence of the genetic algorithm with this fitness function, we had to use  <dig> replicas instead of  <dig> to obtain model networks with comparable fitness function values. the resulting distributions of s
all scores are shown in fig.  <dig> , together with s
all scores obtained previously by minimizing number of nodes and maximizing number of edges . in addition, s
all scores measured on random sub-networks of the pkn  and directly on the pkn  are also shown for comparison. in the following, we will abbreviate the approach of “maximizing the number of edges while minimizing the number of nodes” as simply “maximizing the number of edges”. the additional constraint on the node number has to be kept in mind.fig.  <dig> fitness function: maximizing versus minimizing number of edges. comparison of predictive power  of model networks obtained with the fitness function f =  which minimize number of nodes and subsequently maximize number of edges , and fitness function f =  which minimize number of edges . except for s
all scores obtained by minimizing the number of edges , all results were taken from fig.  <dig>  model networks optimized with minimization of the number of edges  used the same input data sets and the optimization procedure as in fig.  <dig>  except for the change of fitness function, and the use of  <dig> instead of  <dig> replicas




clearly, the predictive power of model networks obtained by minimizing the number of edges is less sensitive to noise in the pkn used as input . with no or low noise, maximizing the number of edges is clearly a good strategy, as the s
all scores are significantly lower when minimizing the number of edges. when pkn noise increases, both approaches give comparable results, with slightly better, although not significantly, s
all scores obtained by minimizing number of edges with  <dig> and 40 % noise.

similarly, when the training set contain errors , model networks obtained by maximizing the number of edges tend to have higher predictive power. although the difference is more pronounced for low fractions of errors in training sets, median s
all scores obtained by maximizing the number of edges are always higher than scores obtained by minimizing the number of edges.

the advantage of maximizing the number of edges becomes more striking when decreasing the size of the training set used as input . indeed, while networks obtained by maximizing the number of edges have a median s
all score that slowly decreases from  <dig>  to  <dig> , networks obtained by minimizing the number of edges always have significantly lower s
all scores, reaching a median of  <dig>  with small training set. more importantly, although networks obtained by minimizing the number of edges are significantly better than random sub-networks of the pkn and the pkn itself when using a large training set, they are not much better than the pkn when using a medium training set, and significantly worse than the pkn when using a small training set, with a median s
all score  <dig>  barely better than the median s
all score  <dig>  of random sub-networks of the pkn.

these results can be understood by realizing that maximizing the number of edges generates networks which are as close as possible to the pkn, only removing edges that are in contradiction with the training set, and therefore use a maximum of information contained in the pkn. this is particularly interesting in the limit of small training sets, when the information contained in the training set is not sufficient to properly infer a model network. in this limit, in addition to the training set, our method heavily uses the information contained in the pkn, and therefore generates model networks with reasonably good predictive power. by contrast, minimizing the number of edges within the limit of small training sets results in over-simplified model networks that are not able to properly predict anything else than what they were trained for.

this reasoning also explains why maximizing the number of edges is a better strategy when the quality of pkn is good, and becomes less attractive in the limit of very noisy pkn. what is interesting, and somewhat unexpected, is the fact that maximizing edges does not give significantly worse results than minimizing edges in the limit of very noisy pkns.

the main motivation behind minimizing the number of edges is usually based on occam’s razor, i.e. the principle of parsimony. however, this approach can lead to oversimplification of the resulting model, for instance by removing alternative pathways that are necessary to ensure the known robustness of regulatory networks. the idea behind maximizing the number of edges is to keep this robustness and to reflect the complexity of biological networks. for a node with various documented biological functions, it seems artificial to reduce that node to only one of them, assuming that the input pkn was built carefully.

combined predictions
in general, one should not expect the optimization problem discussed here to have a unique solution . if the training set does not contain enough information to completely constrain the problem then multiple solutions may be possible. if essential interactions are missing from the pkn then no sub-network of the pkn  may be able to exactly reproduce all experiments in the training set  and a potentially large number of solutions with equally good f
t >  <dig> may be possible. even when the optimization problem does have a unique optimal solution, heuristic optimization methods, like the genetic algorithm that we use, might be unable to find it, and instead output multiple sub-optimal networks with similar fitness function values. for all these reasons, a large set of model networks may be equally good solutions to the optimization problem.

this multiplicity of model networks is not in contradiction with a unique network describing the underlying biological system , but only reflects our lack of knowledge on the system. to summarize all these solutions, a common practice is to generate an average network as the union of all models networks, with a weight attached to each edge, such as the number of model networks in which it appears. however, unless all model networks are very similar, this consensus network is of limited interest since it does not retain the topology , and more importantly, the dynamical behaviour  of the original model networks. instead, we propose to summarize our results at the level of the predictions by measuring averages but also variability of node states predicted by all model networks. intuitively, if a node state prediction varies a lot across networks, this could be due to a lack of information in the pkn and training set, and therefore could be correlated to prediction errors.

to check whether prediction variability was correlated to prediction errors, we summarized the predictions of the  <dig> model networks obtained previously with each input data set . we used the same predictions that were used to measure the s
all score , i.e. the average states reached by a network after each single node perturbation of essential nodes, starting from each attractor of the gold standard network. for each input data set , single node perturbation and initial state , we evaluated the average and variance of the  <dig> average states predicted by the  <dig> model networks. we also evaluated the corresponding prediction error by measuring the absolute difference between average model networks’ predictions and average states reached by the gold standard network. this procedure led to  <dig>  error versus variance measurements, one for each of the  <dig> essential nodes, with  <dig> single node perturbations ,  <dig> attractors of the gold standard network and  <dig> input data sets .

the resulting distribution of error versus variance is shown in fig.  <dig>  this figure shows a strong correlation between error and variance, confirmed by a spearman’s rank correlation coefficient of ≃  <dig> . this result suggests that the prediction error, which is usually unknown, can be  estimated by measuring the prediction variance provided that not only one, but multiple model networks are kept as solutions of the optimization problem.fig.  <dig> combined predictions: error versus variance. distribution of errors as a function variance obtained by summarizing the predictions of the  <dig> model networks obtained which each input data set . the number n above each boxplot denotes the number of measurements in the boxplot




ideally, variance should be estimated based on the full population of networks which are solutions of our optimization problem, or at least on a uniformly sampled subset of the solutions. however, due to the heuristic approach used here, our optimization method should in principle be unable to generate an exhaustive list of solutions, or to uniformly sample the set of solutions. the strong correlation observed in fig.  <dig> is therefore an interesting and non-trivial result, which shows that despite these limitations, our optimization method is able to sample sufficiently well the space of solutions.

related work
a large amount of methods focusing on the problem of boolean network inference have been published. in the following we will consider only methods that are similar to our method in the sense that they combine the use of experimental data against which boolean networks are trained, together with prior knowledge to reduce the size of the search space. these methods are classified according to the type of data used in the training set.

several methods require training sets in the form of time series of experimental measurements. react  <cit>  and cellnopt  <cit>  use evolutionary algorithms to train networks against time series obtained with various network perturbations. both methods only consider networks with synchronous dynamics. by assuming that the consecutive measurements in the time series corresponds to successive states of the network with synchronous dynamics, breindl et al.  <cit>  can use linear programming to solve the network optimization problem. boolnet  <cit>  implements the best-fit extension  <cit>  and reveal  <cit>  algorithms to reconstruct networks from time series obtained with various network perturbations, and can use synchronous as well as asynchronous dynamics. re:in  <cit>  uses a satisfiability modulo theories  solver to exhaustively find all networks that can exactly reproduce the training set, which consists of time series obtained under various network perturbations. only synchronous dynamics is implemented in this method.

other methods focus on early responses to perturbations and only consider a small subset of two time points in each time series. only the initial measurement and a second carefully chosen time point reflecting the initial response to the perturbation are kept in the training set. in addition to time series discussed above, cellnopt  <cit>  also implements a method based on a genetic algorithm to train networks on the early response to perturbations, assuming synchronous dynamics of the networks. guziolowski et al.  <cit>  and videla et al.  <cit>  use answer set programming to enumerate all networks that exactly reproduce the initial response to perturbations using synchronous dynamics, but also all suboptimal networks within a user defined tolerance.

another popular approach is to use a training set containing stable phenotypes assumed to be steady states  of the network. these training sets contain only equilibrium properties of the network and lack information on the dynamics of the network. xpred  <cit>  and prunet  <cit>  use evolutionary algorithms to find networks that have steady states as close as possible to the phenotypes given in the training set. knapp and kaderali  <cit>  reformulated the problem of finding networks with specific steady states obtained under various perturbations as a linear programming problem. a runtime comparison with these methods is given in additional file  <dig> 

our optimization method contrasts with the aforementioned approaches in a number of ways. first, our method combines information on both the dynamics  and equilibrium properties  of the networks, while the aforementioned approaches use only one of these types of information. indeed our training set can contain measurements performed on stable phenotypes that are assumed to correspond to attractors of the networks, together with measurements on their reachability upon perturbation of the network. second, our method uses asynchronous dynamics, which is usually considered as more relevant for the description of biological networks than synchronous dynamics  <cit> . by contrast, all methods discussed above, except boolnet, use synchronous dynamics. finally, our method attempts to maximize the number of edges in order to be as close as possible to the input pkn, while only videla et al.  <cit>  suggest that minimizing the number of edges may not be the optimal approach.

CONCLUSIONS
within the last years the wealth of experimental data from high-throughput technologies in different areas of biology has popularized the construction of a pkn to summarize and visualize the knowledge derived from this data. unfortunately, although it is technically possible to directly transform such a network as a dynamical boolean model, it may not behave as expected for a specific biological process because it usually includes interactions described in different biological contexts and/or experimental conditions, some of which could be absent in the biological process under study. the presence of these “wrong” or “inactive” interactions in the model may dramatically change its dynamical behaviour with consequent lack of reliability of its predictions.

here we propose a method to generate and optimize dynamical boolean models by training a given pkn against experimental data describing either stable states or response to perturbation or both. the output of our method is a set of sub-networks of the pkn contextualized to the experimental conditions used to train the model. simulations performed on such a network should yield more reliable predictions, helping researchers in hypothesis generation and experimental design. the general applicability of the method in a variety of biological contexts will make this approach of interest to biological and medical researchers.

future developments will include the implementation of the same strategy on a multi-valued discrete system , which should allow a more precise description of gene activities and network dynamics. the current method could also be adapted to deal with the cyclic behaviour and time series of oscillatory processes.

additional files

additional file 1: methods. detailed description of the methods. 


additional file 2: cell-fate decision model: in silico training sets. training sets used to evaluate the optimization method. each training set is given in the form of a transition graph, where each node contains a perturbation with the corresponding observation  and edges denote a transition between stable phenotype upon change of condition . perturbations are specified using a combination of node names prefixed by – or + sign to specify knock-out  or over-expression . when multiple edges connect the same source node to different target nodes, it means that all transitions start from the same phenotype . node states that were intentionally reversed to generate errors in training sets are shown in red. 


additional file 3: cell-fate decision model: single node perturbations. list of transitions between attractors from unperturbed to single node perturbations. each line corresponds to one edge in the attractor reachability graph. attractors with more than one state are replaced by the average over all states in the attractor. 


additional file 4: cell-fate decision model: in silico pkns. in silico pkns for the cell-fate decision model. for each pkn, a graphical representation as well as the list of interactions is given. interactions that were changed to introduce noise in the pkns are shown in blue in the list of interactions. in the graphical representation, interactions that were changed to introduce noise in the pkns are shown in magenta  and cyan . 


additional file 5: comparison with related methods. runtime comparison between our implementation of the method  and related methods. 




