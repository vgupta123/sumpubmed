BACKGROUND
a number of multiclass classification methods for microarray data have been developed in the recent years  <cit> . however, their ability to scale well to the number of classes and to provide accurate and sparse multiclass classification models essentially free of model selection-bias remain challenging issues  <cit> . sparse multiclass classification models of microarray data samples are useful; they involve a reduced number of input genes and thus are easy to compute with and to interpret  <cit> .

in this paper, a new gene selection method valid for binary mediated multiclass classification approaches of microarray data samples and able to implicitly model a gene selection sparsity constraint is presented. we rely on the use of output coding  <cit>  methods allowing the binary reduction of m-multiclass classification into n binary classification tasks. we assume a model of independent genes, independent binary classifiers and a principle of information content equipartition among binary classifiers to derive a bound on the maximum number of genes that can be handled by binary classifiers in binary mediated multiclass classification approaches of microarray data samples. the derived bound scales with the inverse n thus providing a way to tackle the computational complexity of finding accurate and sparse multiclass classification models of microarray data samples: just increase the number n of binary classifiers and perform bounded optimum gene selection on lists of predictive genes for individual binary classifiers. in other words, the blessing face of dimensionality might be solution for the problem of accurate and sparse multiclass classifiers of microarray data samples; we just need to guarantee the induction of a large number n of independent binary classifiers. however, the induction of a large number n of independent binary classifiers by means of output coding methods may be hard to achieve when training data is scarce like in microarray data analysis. hence, we may be forced to accept the best n with regard to the key independence factor  <cit>  of general output coding methods. just in case the best n is sufficiently large, the design of accurate and sparse multiclass classifiers of microarray data samples would be feasible.

output coding embodies the design of well-known one against all   <cit>  multiclass classifiers allowing the division of m - multiclass classification problems into n = m binary classification tasks, each binary task dealing with the problem of discriminating a given class against the others. a further generalization of oaa classifiers leads to the design of error correcting output coding  classifiers  <cit>  allowing the division of m - multiclass classification problems into n binary classification tasks, n being determined by the size of some error correcting code. ecoc classifiers can then be used to explore the feasibility of accurate and sparse multiclass classifiers of microarray data samples by letting n approach to infinity. in this paper, the recently introduced  <cit>  class of ecoc classifiers based on ldpc codes  <cit>  is considered. hence, ecoc classifiers based on ldpc codes of size n up to ⌈15·log2m⌉ and oaa classifiers of size n = m are evaluated. for oaa as well as ecoc classifiers, binary linear support vector machines   <cit>  classifiers are assumed. for the purposes of selecting most important genes at core svms, univariate ranking information  <cit>  based on the widely used s2n metric  <cit>  is assumed. using the above setting, a complete experimental protocol is presented for the design of accurate and sparse multiclass classifiers for microarray data samples essentially free of model selection-bias  <cit> . our approach is evaluated on  <dig> benchmark microarray datasets. experimental results confirm the feasibility of our proposed method.

RESULTS
an upper bound on the number of genes per binary classifier
how much information can a set of p independent genes convey about a set of m phenotypes? being aware of such a fundamental limitation could be crucial in the design of accurate and sparse multiclass classifiers of microarray data samples. let s be a microarray dataset comprising q samples from m ≥  <dig> classes, each sample defined by the gene expression measurements of p genes . hence, the average information content per class sample in s can be upper bounded by hm = log2m.

in addition, let us assume that genes behave as a collection of p independent identically distributed binary random variables, i.e., a kind of probabilistic boolean model of gene expression is considered  <cit> . hence, each gene is in state  <dig>  with probability f and in state  <dig>  with probability  <dig> - f, each state representing gene activity above or below some threshold for an effect. thus, in this model of gene expression, each gene conveys on average h = - f · log <dig> f -  · log <dig> bits of information. furthermore, let us assume an output coding strategy over s able to induce n independent binary datasets and correspondent binary classifiers. hence, under a principle of information content equipartition, hb=hm/n=log2mn bits of information will be available at each binary classifier. finally, let us assume that each binary classifier is allowed to select a fraction q of the complete set of genes. hence, after the selection of q · p genes, at most q · p · h bits of information will be available at each binary classifier and this quantity cannot exceed hb

  q⋅p⋅h≤log2mn 

eq.  <dig> nicely estimates the maximum fraction of genes  that can be selected by any binary classifier in terms of main parameters characterizing any binary mediated multiclass classification problem plus an unknown parameter f. to estimate f, we now turn to the problem of estimating the probability f that a biased coin will come up with heads in a sequence of q independent coin tosses provided k heads have been observed. the maximum likelihood estimate of f, i.e., the value of f with the largest probability for the observed data, is given by k/q. to obtain k, we just need to count the number of expressed genes across the collection of q samples. however, aiming to obtain a more general bound, we would like to avoid overwhelming data dependent counts. if we further assume that averages of gene expression over a sufficiently large population of individuals are equal to averages over many genes, i.e., an ergodic behavior of genes  <cit>  is considered, the fractional f should equal the fraction of genes k*//p that are expressed at any individual. assuming that k*/p <  <dig>   and recalling that h  is a monotonic increasing function in , we get h ≈ h ≥ h and the following q upper bound  can be derived

  qmax≈ log2mp⋅n⋅h 

overall, eq.  <dig> suggests that the computational complexity of finding sparse multiclass classifiers of microarray data samples could be overcome with the induction of a large number n of independent binary classifiers, a requirement which gets easier to satisfy as the number of training samples increases. the evolution of qmax with respect to n on benchmark microarray datasets used in this paper is shown in figure  <dig>  before moving onto the next subsection, we notice that a more formal derivation of qmax is given in the appendix.

bounded optimum s2n gene selection
for a fixed n, we now face the problem of finding the optimum number of genes in the list of top p* qmax most discriminative genes for each binary classifier. such optimum will follow from a partial search scheme and thus, we provide no guarantee of identifying the optimal gene set  <cit> . but as n increases, finding such optimum implies finding a sparse representation of a high dimensional feature space from a small number of training samples. because sparsity is key structural property of most genomic studies involving disease classification, we conjecture that the proposed gene selection method could indeed be a solution for the problem of designing accurate and sparse multiclass classifiers of microarray data samples.

letting n approach to infinity cannot be realized in practice. hence, some bounded exploration of the n dimension must be assumed in advance. in this paper, the exploration of n dimension from nmin = ⌈log2m⌉ +  <dig> up to nmax = ⌈15·log2m⌉ is considered. notice that n = ⌈15·log2m⌉ +  <dig> is not considered; it would entail the use of parity codes only able to detect  binary classifiers errors. for practical n ranges, the exhaustive exploration of p* qmax most important genes for each binary classifier may still be too computationally demanding. thus, a multi-scale resolution approach for the q-dimension was devised. firstly, the q dimension was coarsely quantized with a base  <dig> logarithmic scale, i.e., q ∈  was assumed. secondly, each logarithmic segment, except the last one, was linearly quantized into  <dig> equal parts; the last logarithmic segment was quantized into  <dig> equal parts. finally, genes at each binary classifier were ranked according to their s2n value  with respect to the response variable and mapped to the formerly quantized q-dimension for further selection. as a result, for a fixed computational budget, more computational effort can be put into the exploration of highly discriminative genes, i.e., top ranking genes, than into those of poor discriminative power.

results on real data
we first note that the application of the shapiro-wilk test to the empirical distributions of performance measures  of either ecoc or oaa classifiers frequently rejected the null hypothesis of normally distributed data at the  <dig>  α level of significance, thus justifying the use of the more conservative kolmogorov-smirnov  and mann-whitney  u tests.

the classification performance of ecoc classifiers of size at most ⌈η·log2m⌉ and oaa classifiers under bounded optimum s2n gene selection over  <dig> runs of montecarlo 4: <dig> train-test partitions. m and n respectively denote the median number of binary classifiers at ecoc and oaa classifiers. error-ecoc and error-oaa respectively denote the median classification errors attained by ecoc and oaa classifiers. error-ecoc and error-oaa are denoted as f and g for purposes of ks tests, respectively.

a p-values of two-sided ks tests, one-sided ks tests and one-sided mw tests. the alternative hypothesis of two-sided ks tests is "the error of ecoc classifiers is different from that of oaa classifiers", i.e., the relationship between cdfs is f ≠ g. the alternative hypothesis for one sided ks tests is "the error of ecoc classifiers is greater than that oaa classifiers", i.e., the relationship between cdfs is f <g. the alternative hypothesis of one sided mw tests is "the error of ecoc classifiers is less than that of oaa classifiers".

the number of genes selected by oaa and ecoc classifiers of size at most ⌈η·log2m⌉ under bounded optimum s2n gene selection over  <dig> montecarlo 4: <dig> train-test partitions. m and n respectively denote the median number of binary classifiers at oaa and ecoc classifiers. b-ecoc and b-oaa respectively denote the median number of genes per binary svm at ecoc and oaa classifiers. g-ecoc and g-oaa respectively denote the median overall number of genes selected at ecoc and oaa classifiers. g-ecoc and g-oaa are denoted as f and g for purposes of ks tests, respectively.

a p-values of two-sided ks tests, one-sided ks tests and one-sided mw tests. the alternative hypothesis of two-sided ks tests is "the number of genes selected by ecoc classifiers  is different from that of oaa classifiers ", i.e., the relationship between corresponding cdfs is f ≠ g. the alternative hypothesis for one sided ks tests is "the number of genes selected by ecoc classifiers  is greater than that oaa classifiers ", i.e., the relationship between corresponding cdfs is f <g. the alternative hypothesis of one-sided mw tests is "the median number of genes selected by ecoc classifiers is less than that of oaa classifiers".

the stability of gene selection attained by ecoc classifiers of size at most ⌈η·log2m⌉ and oaa classifiers under bounded optimum s2n gene selection over  <dig> montecarlo 4: <dig> train-test partitions. m and n respectively denote the median number of binary classifiers at oaa and ecoc classifiers. s-ecoc and s-oaa respectively denote the stability of gene selection attained by ecoc and oaa classifiers measured by the salton's coefficient. s-ecoc and s-oaa are denoted as f and g for purposes of ks tests, respectively.

a p-values of two-sided ks tests, one-sided ks tests and one-sided mw tests. the alternative hypothesis of two-sided ks tests is "the stability of gene selection in ecoc classifiers  is different from that in oaa classifiers ", i.e., the relationship between corresponding cdfs is f ≠ g. the alternative hypothesis for one sided ks tests is "the stability of gene selection in ecoc classifiers  is lower than that oaa classifiers ", i.e., the relationship between corresponding cdfs is f >g. the alternative hypothesis of one-sided mw tests is "the median stability of gene selection in ecoc classifiers is higher than that of oaa classifiers".

b difficult to definitely compare. highly significant p-values for both one-sided ks tests.

for the sake of completeness, we also report the performance of oaa and ecoc classifiers of size at most ⌈η·log2m⌉  on two benchmark microarray datasets with a public train-test partition . results agree with observed trends of the classification error in montecarlo evaluations. although both ecoc and oaa classifiers seem to be highly effective in the gcmrm dataset, suggesting that ecoc classifiers may be worthy of exploring in such case, only oaa classifiers perform well on the gcm dataset. since the gcmrm dataset is just a subsample of the gcm dataset to which a more robust preprocessing protocol has been applied, so that fewer samples, fewer classes and fewer genes than in the original dataset are involved, these results raise the question to what extent specific preprocessing protocols could be a affecting the strength of gene selection attainable with ecoc classifiers.

the performance of oaa and ecoc classifiers of size at most ⌈η·log2m⌉ on benchmark microarray datasets under bounded optimum s2n gene selection and a public train-test partition. m and n respectively denote the number of binary classifiers used by oaa and ecoc classifiers. g-oaa and g-ecoc respectively denote the overall number of genes selected by oaa and ecoc classifiers. error-oaa and error-ecoc respectively denote the classification error attained by oaa and ecoc classifiers.

CONCLUSIONS
the divide and conquer approach to the design of multiclass classifiers for microarray data samples which we have presented offers the hope that accurate and sparse multiclass classifiers can be constructed without incurring in undesirable forms of gene selection bias hidden in the selection of optimal gene subsets of restricted or unrestricted size  <cit> . generalized binary reductions of m-multiclass classification problems into n binary classification tasks and bounded explorations of resulting gene spaces are advised to accomplish this objective. at each binary classifier, the maximum number of genes that can be selected scales with the inverse of n, thus providing a way to accomplish optimum gene selection at affordable computational costs, provided n is sufficiently large.

in this paper, the power of oaa and ecoc binary reductions in the design of accurate and sparse multiclass classifiers for microarray data samples has been evaluated. without loss of generality, we have restricted ourselves to the class of ecoc classifiers based on ldpc codes, linear svm binary classifiers and univariate s2n gene selection. experimental results show that dimensionality exchange between input and output domains of binary mediated multiclass classifiers of microarray data samples is indeed possible: the larger the size of candidate ecoc classifiers, the greater the chance of selecting smaller sets of genes. although promising, the dimensionality reduction performance exhibited by ecoc  classifiers is not enough to definitely improve naive oaa classifiers, which remain the best practical option.

from an overall view, experimental results suggest that improving the dimensionality reduction ratio of oaa classifiers with ecoc classifiers may not be as easy as it seems. we note, however, that a consensus approach to gene selection and classification on a set of diverse ecoc classifiers under bounded optimum gene selection could finally boost their dimensionality reduction factor beyond that of oaa classifiers. briefiy, provided individual ecoc solutions are good enough compared to oaa classifiers, a consensus approach to gene selection on a set of diverse ecoc classifiers should preserve most relevant genes and reject a great proportion of irrelevant ones. since ecoc classifiers based on ldpc codes seem to be closely related neighbors of oaa counterparts, this hypothesis will be focus of future research. finally, further dimensionality reduction improvements may still be attainable with more elaborated forms of gene selection like svm-rfe  <cit> .

overall, our results provide evidence that bounded optimum gene selection in high dimensional binary output domains induced by either oaa or ecoc classifiers may be a solution for the problem of accurate multiclass classification of microarray data samples based on a reduced number of genes.

