BACKGROUND
multiple sequence alignment  is a ubiquitous task in biology, and has a wide variety of applications including homology detection  <cit> , predicting residue couplings  <cit> , finding evolutionarily important sites  <cit> , oligonucleotide design  <cit> , and phylogenetics. a multiple sequence alignment may reveal many aspects about a gene: which regions are constrained, which sites undergo positive selection  <cit> , and potentially the structure of its gene product  <cit> . many of these applications depend on the correct alignment of thousands of diverse sequences. a variety of methods have been developed to provide more accurate alignments , yet many of these approaches are not amenable to aligning thousands of sequences in a reasonable amount of time. furthermore, performance tends to decrease dramatically beyond a certain point as more sequences are added to the input set  <cit> . thus, the accurate alignment of large numbers of sequences remains an unsolved challenge that is frequently encountered in modern datasets.

it is generally believed that the poor scalability of alignment can be attributed to the build-up of error or the increasing level of ambiguity as more-and-more sequences are aligned. two main strategies have been proposed to combat the loss in quality as alignments grow in size. the first strategy is to use a chained guide tree, which is efficient to construct and allows reasonable accuracy to be maintained on large empirical datasets   <cit> . however, this approach performs poorly on simulated sequence alignments  <cit> , and may not be applicable for phylogenetic analyses  <cit> . the second strategy is to use an iterative divide-and-conquer approach that shows good performance on simulated sequence sets, but performs comparably to other methods on large empirical protein benchmarks  <cit> . a possible third strategy, proposed here, is to shift reliance onto structural information as alignments become larger. since structure is more conserved than primary sequence, it is possible that structure-based alignment will maintain accuracy even as sequence-based alignment loses integrity.

msa programs are typically optimized and assessed based on their ability to recreate the alignments in benchmark datasets. in this way, benchmarks determine the objective to which alignment programs strive to attain. there is an ongoing debate over whether simulated, structural, or other types of benchmark are preferable  <cit> . simulated alignments are generated by “evolving” sequences along a predetermined tree under a model of substitution. therefore, the complete evolutionary history of the sequences is known and the entire alignment can be used as a reference. in typical simulations, the choice of insertion and deletion rates across sites is specified, a substitution matrix is used, covariation between positions is ignored, and there is no selective pressure on the tertiary structure. furthermore, real sequence sets often include spurious  sequences, sequencing errors, uneven taxon sampling, rearrangements, and uneven lengths that have largely been neglected in studies relying on simulations.

in contrast, many structural benchmarks have been built from related rna or protein tertiary structures that have been superimposed to provide an empirical alignment that is free of many of the simplifications of simulated alignments. by this definition residues in the same column of an alignment should occupy the same structural position in space. a major downside of structural benchmarks is that “gappy” regions are typically not considered in scoring because they are not superimposable in space  <cit> . some downstream applications of multiple sequence alignment may be especially sensitive to false homologies in gappy regions, such as tree building and the detection of positive selection  <cit> . nevertheless, structural benchmarks have generally been preferred over simulated benchmarks, resulting in an emphasis on the maximization of true homologies in “core blocks” , with less regard for false homologies.

the focus on maximizing true homologies has been furthered by a reliance on q-score for performance comparisons with structural benchmarks. q-score is defined as the average pairwise fraction of reference homologies that are also found in the test alignment . q-score does not directly penalize for aligning positions that are unaligned in the reference, also known as over-alignment  <cit> . over-alignment can be quantified using the modeler score , which is the fraction of aligned homologies that are also aligned in the reference  <cit> . a higher m-score indicates fewer false homologies, and vise-versa. the m-score does not penalize for under-alignment  <cit> , as the correct alignment of only one position would result in a perfect m-score . hence, it is necessary to compare both true and false homologies when judging alignment performance.

assessment of over-alignment is one step in the ongoing effort to create more biologically meaningful alignments  <cit> . other efforts have focused on specific sequence features that may be present in some alignments but are neglected by most alignment programs. this has resulted in specialist alignment programs for different mutational events, such as long tandem repeats  <cit> , domain rearrangements  <cit> , and inversions  <cit> . prevalent sequence features, such as short repeats and the local sequence context around insertions and deletions, have been identified as informative, yet are largely ignored by alignment programs  <cit> . in contrast, one source of information that has received significant attention is the use of secondary structure to provide a stronger biological basis for the alignment process. those programs that have integrated secondary structure predictions into alignment have shown noteworthy gains in q-score .

however, these gains have come at a cost because secondary structure is time consuming to accurately predict, which prevents these methods from scaling to a large number of sequences. presently none of the alignment programs that use predicted secondary structure can align a thousand or more sequences in a reasonable amount of time  <cit> . this inefficiency is due to the need to find and align many sequences that are related to each sequence for which secondary structure is being predicted. using the most accurate secondary structure predictions in sequence alignment therefore indirectly incorporates more sequence information into the alignment process. an alternative to this approach is to directly add more sequences to those being aligned, which has also been shown to substantially improve the accuracy of aligning small sequence sets  <cit> . both of these approaches leverage large external databases of sequences that may not provide additional information when the input set is already large or all-encompassing.

in this study, i began by comparing the accuracy of structural benchmarks that would form the foundation for the rest of the study. next, i investigated whether it was possible to efficiently integrate secondary structure predictions with negligible added time and no additional sequences other than those being aligned. to do this i relied on less accurate, but very fast, predictions made using the gor method  <cit>  for secondary structure prediction. the gor method provides the probability of a residue being in helix , β-sheet , or coil  conformation based on local sequence context. drawing inspiration from the gor method, i created a model of gap placement that was also based on local sequence context. these features became the basis of a new program for multiple sequence alignment named decipher. finally, i compared decipher’s performance with that of other popular alignment programs on high-quality structural benchmarks.

methods
secondary structure assignments
to compare empirical benchmarks, secondary structure assignments according to dssp  <cit>  were downloaded from pfam  <cit>  for proteins with solved structures. pairs of sequences in each reference set were replaced with their corresponding secondary structure to generate an alignment of secondary structure states. a multiple alignment of n sequences therefore resulted in / <dig> different pairwise alignments. the pairwise secondary structural identity of each of these alignments was calculated and used to compare benchmarks. secondary structure identity was defined as the number of columns with matching secondary structure  normalized by the maximum number of matches possible. the large number of data points was simplified for plotting by finding the shortest contour line on the kernel density surrounding 75 % of points. the r programming language  <cit>  was used for all analyses. p-values were calculated using the wilcoxon signed rank test in r  <cit> .fig.  <dig> comparison of structure-based benchmarks commonly used to rank sequence alignment programs. each contour line surrounds the densest 75 % of points representing pairwise alignments in the benchmark. structural identity is based on matching 8-state dssp  <cit>  secondary structure assignments . perfect secondary structure agreement would result in a score of  <dig> on the y-axis. reference alignments exhibit decreased structural similarity as the distance between sequence pairs increases. realignments using mustang  <cit>  showed improved quality in some cases, especially relative to the original sabmark  <cit>  reference alignment



for secondary structure predictions, the gor method was re-implemented as the decipher function “predicthec”, and used automatically during alignment of amino acid sequences. the gor method was trained on the dataset in li et al.  <cit> , which was reduced from 8-states to 3-states according to the convention: h = , e = e, c = other  <cit> . in the gor method, probabilities at a site are assigned to each of the three states while taking into account a window of seven residues to either side of the site. contributions from single residues and pairs of residues were considered, as in version iv of the gor algorithm  <cit> . probabilities were normalized relative to the background distribution in accordance with version v of the algorithm  <cit> , which results in a modest improvement over version iv predictions. only unaligned single sequences were used in the calculation of 3-state probabilities that were used in sequence alignment.

multiple sequence alignment benchmarks
homstrad  <cit>  multiple alignments were downloaded on february 20th,  <dig> from the website mizuguchilab.org/homstrad. the homstrad alignments were realigned using mustang   <cit> . all other benchmarks were downloaded as part of the bench  collection from www.drive <dig> com/bench. this collection includes oxbench  <cit> , prefab   <cit> , and transitively-consistent alignments from sabmark   <cit>  in both their original form and realigned with mustang  <cit> . these benchmarks were compared , and prefab and homstrad were selected for benchmarking msa programs due to their high quality and breadth of sequence identities. the selected benchmarks required slight modification before they could be used to assess the alignment of large numbers of sequences.

to create homstrad-mod, columns of the alignment that were in agreement between the original and mustang alignments were kept uppercase to define core blocks. therefore, homstad-mod alignments are identical to those of homstrad in the regions used in scoring. alignments with  less than 25 % of their length in core blocks,  a total width of less than  <dig> sites, or  having greater than 80 % average pairwise identity were removed. benchmarks were supplemented with full-length pfam  <cit>  sequences downloaded from each set’s corresponding pfam family. the matching pfam homologous region was required to be less than three times the width of the respective reference sequences. reference sets with fewer than  <dig> supplemental sequences were removed. prefab-mod reference pairs were left untouched from the original prefab sequences realigned with mustang. the final benchmarks contained  <dig> and  <dig> reference sets in homstrad-mod and prefab-mod, respectively. all benchmarks created for this study are available from decipher.cee.wisc.edu/download.html.

when comparing performance, input reference sets were generated by randomly selecting a predefined number of supplemental sequences from the pool of available pfam sequences. these supplemental sequences were added to the reference sequences to reach the intended total number of sequences in each input set . after alignment, the supplemental sequences were removed and the remaining  sequences were tested for alignment accuracy. only one randomly selected set of supplemental sequences was used per alignment size, up to the maximum number of sequences available for each set. the smallest sets of  <dig> sequences were created by randomly selecting a pair of sequences from each reference set. all alignments were scored using qscore  <cit>  with optional parameters “-ignoretestcase -cline -modeler”. these parameters specify that only uppercase letters  in the reference alignment are used in scoring, and that qscore should output the cline shift-score  <cit>  and modeler score   <cit> .

gap databases
sequence pairs in the one gap database  <cit>  were translated and realigned with the objective of creating a high accuracy unbiased set of aligned sequences with gaps. the realignment procedure, described as follows, did not include a model of gap placement. first groups of sequences were used to create a multiple alignment. the most similar pairs of sequences with different internal gap patterns were then realigned to remove any artifacts from the multiple alignment. pairs with gaps remaining after pairwise alignment were kept, and their gaps were marked to prohibit the reuse of gaps in the same position in other pairs. this process was repeated for each protein family to generate a large set of pairwise alignments with different internal gaps.

to prevent incorrect gap placements, sequence pairs were required to contain gap events separated by at least  <dig> residues, and have greater than 50 % sequence identity. to mitigate the effect of ambiguous gap placements in repetitive regions, the sequence pairs were realigned in reverse orientation and then reversed again to generate a complementary alignment. finally, local alignments that were equivalent  were expanded into all possible permutations and weighted to split the permutations evenly. the same process was repeated with pfam families to generate a complementary set of high quality gap placements. the final sets contained  <dig>  gaps from the one gap database, and  <dig>  from the pfam database. observed residue frequencies were converted into log-odds in third-bits based on the formula: log*3/log. log-odds scores were highly correlated between the two datasets , so the average score was used for model parameters.

alignment programs
decipher is an r  <cit>  package with functions for primer design  <cit> , probe design  <cit> , and other bioinformatics tasks. in this study the decipher software was extended to include multiple sequence alignment with the function “alignseqs”, which can align a set of dna, rna, or amino acid sequences. decipher also includes functions for alignment of dna sequences via their translation , and the merging of two existing alignments . see the additional file  <dig> text for a complete description of the decipher algorithm. decipher was written in the c and r programming languages, and is available from decipher.cee.wisc.edu or bioconductor  <cit> .

the following programs were compared in this study:clustal omega   <cit> 

decipher 

mafft   <cit> 

muscle   <cit> 

pasta   <cit> 

promals  <cit> 



default parameters were used for all programs with the exception of muscle and pasta, which required changing the maximum number of iterations. for muscle, “maxiters” was change from  <dig> to  <dig> for sets of  <dig> or more sequences as recommended by the developers. for pasta, the parameter “iter-limit” was changed to  <dig> for sets of  <dig> or more sequences. attempts to use the default value of  <dig> proved prohibitively time consuming on larger sets. for mafft the “auto” option was used to automatically switch between different progressive and iterative strategies based on the number and length of input sequences. timings for all sets were determined on a  <dig>  ghz intel core i <dig> with 8 gb of ram using a single processor. for consistent timing comparisons, pasta and promals were configured to use only one processor.

RESULTS
choosing high quality reference alignments for benchmarking
different benchmarks often result in contrasting optimal parameters  and an incompatible performance ranking of alignment programs  <cit> . for these reasons, the choice of benchmark is of utmost importance when developing and comparing algorithms for sequence alignment. to choose alignment benchmarks for this study, i began by comparing secondary structure concordance across common benchmarks. this method of comparison requires that the secondary structure of reference sequences be available, which excludes the popular balibase benchmarks  <cit>  because the corresponding secondary structure of most balibase sequences is unknown  <cit> . although secondary structure agreement alone is insufficient to ensure a high quality benchmark, a lack of agreement can be an indication of alignment inaccuracy.

it is expected that better reference alignments will have a greater percentage of aligned residues with identical secondary structure. however, some disagreement in secondary structure is anticipated due to both intrinsic difficulties in assigning secondary structure  <cit>  and challenges inherent to aligning distantly related tertiary structures  <cit> . figure  <dig> shows the fraction of secondary structure agreement versus pairwise sequence identity for four common amino acid benchmarks. the sabmark  <cit>  and prefab  <cit>  benchmarks contain the greatest fraction of their sequences in or below the “twilight zone” of  <dig> to 35 % sequence identity, while the emphasis of oxbench  <cit>  is on less challenging alignments. prefab appears to be significantly better aligned overall than sabmark, despite both references covering a similar range of sequence identities. for sequences with less than 10 % identity, prefab has  <dig>  % greater structural identity  than sabmark. these findings are in agreement with a previous study  <cit>  that found prefab to be the best benchmark designed specifically for comparing msa programs, although prefab is known to contain errors  <cit> .

all columns of the alignments were used to assess the overall accuracy of each benchmark rather than only using core blocks , which are typically delineated by uppercase letters. the choice to use the entire alignment was made because:  the definition of core blocks varies between benchmarks,  some scoring procedures make use of the entire alignment  <cit> ,  pairwise distance is calculated using the whole alignment, and  the homstrad  <cit>  and sabmark benchmarks do not delineate core blocks. core blocks in prefab were assigned based on the agreement between two different structural alignment programs. this motivated me to look at the difference between the original benchmarks and the same sequences realigned with the sequence-independent structural alignment program mustang  <cit> . realignments with mustang exhibited greater secondary structural congruence than the original benchmarks, except in the case of homstrad . in particular, sabmark had  <dig>  % higher secondary structure identity after realignment with mustang . this result supports the use of the homstrad database as an alignment benchmark even though it was not originally intended for this purpose.

since the number of sequences with known structure is small relative to the number of available sequences, most benchmarks are supplemented with additional unaligned sequences that are not considered in scoring. prefab reference alignments are supplemented with additional sequences found using psi-blast searches  <cit>  with the reference sequences. homstad sequences are commonly supplemented with other sequences belonging to the same pfam  <cit>  family  <cit> . i compared these two approaches by randomly selecting sequences from the pfam family corresponding to the prefab reference sequences. after generating an alignment with the same number of supplementary sequences, a neighbor joining tree was constructed to determine the breadth of the added sequences. the average tree length was  <dig>  times longer for random pfam sequences than those included with prefab . this indicated that extending the input set in a way that is not directly dependent on the reference sequences results in the greatest diversity of supplemental sequences.

it is unclear which reference benchmark most adequately reflects a typical user’s sequences, and the wide diversity of msa applications probably spans most of the alignment scenarios found in benchmarks. sabmark sets cover a narrow range of sequence identities, while oxbench focuses on closely related sequences that are easier to align. due to both alignment quality and breadth of sequence identities, i chose to continue the rest of this study with slightly modified versions of the original prefab and homstrad datasets, called prefab-mod and homstrad-mod . to supplement the modified benchmarks, i added full-length sequences belonging to the same pfam family. full-length sequences were used rather than only the shared domain to make the alignments more challenging and to represent a greater variety of potential usage scenarios. oftentimes sequences being aligned have varying lengths because they cover overlapping regions of a gene, or were trimmed differently based on their quality scores at each terminus.

scalable incorporation of secondary structure into alignment
despite the close connection between secondary structure and sequence alignment, most popular protein alignment programs do not predict structural information. the main drawback of secondary structure prediction is that it is slow to accurately compute, which prevents it from scaling to the alignment of hundreds of sequences in a reasonable amount of time  <cit> . less accurate secondary structure predictions can be obtained very rapidly using single-sequence approaches that do not rely on constructing a multiple alignment with homologous sequences. the gor method is one of the most accurate given a single sequence  <cit> . in this method secondary structure is assigned to one of three states: helix , sheet , or coil  based on the local sequence context surrounding a residue. this approach has the advantage that it is extremely fast , provides a probability value for each state, and offers about 65 % accuracy  <cit> .

to integrate secondary structure predictions into the dynamic programming framework for profile-profile alignment, i added a new  <dig> ×  <dig> symmetric matrix representing the log-odds of aligning an h, e, or c in one sequence with another position assigned to h, e, or c in a second sequence. coupling this matrix with the probability assigned to each of the three structural states allowed for profile-profile alignment of the secondary structures. the score obtained from aligning secondary structure profiles augmented the traditional substitution matrix based score determined from the primary sequences . in this way, primary and secondary structure agreement can be maximized simultaneously.

figure  <dig> displays an example alignment of the lactate/malate dehydrogenase protein family  obtained using this approach. the dssp  <cit>  assignments are in general agreement across the homstrad-mod alignment, which is based on the known tertiary structures of these proteins. predictions made with the gor method reflect these secondary structure assignments with some discrepancies. the gor predictions guide the decipher alignment, which exactly matches the reference alignment in regions defined as core blocks, denoted by uppercase letters in the upper alignment of fig.  <dig>  regions of the reference alignment that fall outside of core blocks are not used in determining accuracy and differ from the decipher output in some columns.fig.  <dig> c-terminal end of alignments of the lactate/malate dehydrogenase protein family  colored by predicted secondary structure. the top alignment  is from the homstrad-mod benchmark colored by dssp assignments  <cit> , with upper-case letters denoting core blocks. the lower alignment shows the same sequences  realigned with decipher and colored according to 3-state probabilities predicted by the gor method  <cit> . columns of the lower alignment in bold exactly match columns of the upper reference alignment



one advantage of using a small  <dig> ×  <dig> secondary structure matrix is that the number of free parameters is far outnumbered by the number of informative data points, which makes estimation error negligible . to find optimal values for each of the  <dig> distinct parameters in the matrix, i performed a grid-search for the solution that resulted in the best-scoring alignments based on the sum of q-score and m-score on a subset of homstrad-mod consisting of  <dig> reference sets. at the optimum between over-alignment and under-alignment, any gain in q-score is outweighed by the corresponding loss in m-score, and vise-versa. the optimized secondary structure matrix is shown in fig. 3a. e-states are very likely to be aligned, as reflected in the large contribution of e/e pairings to the secondary structure score. the gor method tends to under-predict β-sheets, resulting in a low fraction of e-states in most sequences  <cit> .fig.  <dig> 
a optimized structure matrix for pairings between helix , β-sheet , or coil  states. b repeated values are grayed-out since the matrix is symmetric. after incorporating this matrix into alignment, the average improvement in q-score on pairwise alignments was greater for distant pairs. c alignments using the structure matrix  showed little decline in accuracy as the number of input sequences increased relative to alignments made without structural predictions . across all alignment sizes, the use of secondary structure improved q-score . similarly, the improvement in q-score  increased as more sequences were aligned



next, i asked whether incorporation of secondary structure improved sequence alignment, and how this scaled with the number of sequences being aligned. averaged across all sizes of sequence sets, incorporation of secondary structure resulted in a  <dig>  % improvement in q-score on prefab-mod and  <dig>  % on homstrad-mod. this substantial increase in q-score came at the expense of a  <dig>  % decrease in m-score on prefab-mod and a  <dig>  % decrease on homstrad-mod. therefore, the fraction of homologies that are correctly aligned slightly decreased, while the total number of correctly aligned homologies substantially increased. unsurprisingly, the largest gains were on divergent reference sets where there is the most room for improvement, and essentially no gain was made on references with less than 60 % average distance between pairs . secondary structure predictions provided a greater benefit on prefab-mod because a larger fraction of its reference sequences are over 60 % distant.

interestingly, the improvement from incorporating secondary structure increased as more sequences were aligned . on the smallest sets of  <dig> sequences there was a  <dig>  % improvement on prefab-mod and  <dig>  % on homstrad-mod. on large  <dig>  sequence sets the advantage increased to  <dig>  % and  <dig>  %, respectively. therefore, incorporating secondary structure partially counteracted the decrease in score that is typically observed with larger alignments  <cit> . this behavior mirrored that of secondary structure prediction, where accuracy increases as more sequences are used in the calculation  <cit> . for this reason, the most accurate secondary structure prediction algorithms make use of multiple alignments. similarly, here the initial secondary structure predictions lack accuracy since they are obtained from single sequences. as more sequences are aligned, these probabilities are averaged to increase their accuracy and better guide the alignment. this is in contrast to primary sequence, where additional sequences inevitably result in more ambiguity, which in part causes a loss of signal that manifest in poor quality alignment of ambiguous profiles.

including a model of indel probability to improve gap positioning
motivated by the improvement obtained from incorporating local sequence context via secondary structure predictions, i next asked whether the same approach could be applied to gap placement. previous research has revealed that insertions and deletions  are more likely to occur adjacent to certain amino acids  <cit>  and in exposed coil regions  <cit> . for this reason it is common to decrease the cost of opening a gap in hydrophilic stretches  <cit> , or alternatively to increase the cost in hydrophobic regions  <cit>  that are likely to be buried in the protein’s constrained core. to my knowledge, a more sophisticated model of gap likelihood based on local context has not been applied to sequence alignment. to this end i used the one gap database  <cit>  to calculate the relative frequency of indel events based on the residues to the left and right of a central gap. this frequency information was then converted into log-odds scores according to the background frequency of each amino acid.

figure  <dig> shows the contribution of nearby amino acids to the likelihood of a gap at position zero. as expected, hydrophobic residues  greatly decrease the likelihood of a gap. hydrophilic and “structure-breaking”  residues increase the chance of an adjacent gap, albeit with less of an effect than hydrophobic residues. since the log-odds scores are in the same units as the substitution matrix , they can be directly applied to modulate gap-opening and gap-closing costs at any position based on its local sequence context . i evaluated different window sizes for including this information, and found that the best window stretched from position - <dig> to + <dig> relative to the central gap. hence, the cost of creating a gap at any position is the original gap cost plus a score that is modulated based on the residues to either side of the gap .fig.  <dig> contribution of local sequence context to the cost of opening a gap in the alignment. hydrophobic residues greatly decrease the likelihood of a gap, whereas hydrophilic and “structure-breaking” residues increase the likelihood of a gap. in the gap model, positions located within four residues were used to modulate the cost of opening a gap at position zero



next, i calculated log-odds scores for the residues opposing the gap , and found that these positions displayed a small bias in amino acid content . there was a moderate correlation between the log-odds scores for positions to the left or right of the gap and the residues opposing the gap . however, in this case there was no apparent difference between locations within the gapped region. for this reason i chose to simply modulate the gap extension cost based on the average scores for the “gapped” residues in a position-independent manner. altogether, this probabilistic model of opening and extending a gap adjusts the gap penalty within a range of about +/- 20 % at each position.

to expand this model of gap placement based on local sequence context, i next investigated the effect of short sequence patterns. repeats are a major source of length variation in biological sequences  <cit>  and are commonly found across all branches of life  <cit> . repeats have a wide variety of forms, including short microsatellite repeats of a single codon and longer tandem repeats of regions that may evolve through mutation to become mismatched over time  <cit> . longer repeats can be aligned with specialized programs  <cit>  that employ tandem repeat finding algorithms  <cit> . short patterns are typically neglected as insignificant by these programs due to their frequent occurrence in sequences. however, chang and benner  <cit>  found that short dipeptide repeats  were more common than expected around gaps, potentially offering a means of modulating gap costs. to investigate this effect, i examined the occurrence of different sequence patterns in the one gap database.

dipeptide repeats  surrounding gaps were only slightly more likely  than expected by chance. however, gaps were substantially more likely to occur around runs of three or longer , as shown in additional file 1: figure s <dig>  this effect was particularly pronounced in the sequence without the gap, indicating that gaps are often present because one sequence has a longer run than another. surprisingly, gaps were less likely to occur at the position after the start of a run in the opposing sequence , regardless of the run’s length. although the mechanism for this occurrence is unknown, it may be due to a biological role for dipeptide repeats that results in their conservation. a similar investigation of heteropeptide repeats with periodicity  <dig>  to  <dig> did not reveal a strong bias towards gaps . therefore, i chose to extend the gap model to modulate the gap opening cost at positions before and immediately after the start of a run in the opposing sequence.

overall, employing this model of gap placement resulted in a modest improvement of  <dig>  % on prefab-mod  and  <dig>  % on homstrad-mod . the improvements in q-score were matched by  <dig>  % increases in m-score on both benchmarks. these changes in score were unexpected, as structural benchmarks do not consider most gapped regions since they often occur in parts of the structure that are difficult to superimpose  <cit> , and repeats tend to be found in disordered protein regions  <cit> . although, evolutionary simulations offer a means of scoring gapped regions, such simulations currently do not include a context dependent model of gap likelihood. therefore, it is possible that the placement of gaps improved more than reflected by the modest increase in scores, but there currently exist no adequate way of measuring the actual advantage of incorporating a sophisticated gap model into alignment.

comparison of decipher to other programs for msa
having successfully integrated context-awareness into the decipher software for sequence alignment, i next compared its performance to other state-of-the-art alignment programs. first, i chose to benchmark decipher against three popular programs capable of efficiently aligning thousands of sequences: clustal omega  <cit> , mafft  <cit> , and muscle  <cit> . these programs are regularly employed in a variety of different studies, and have become the de facto standard for comparison on benchmarks. figure  <dig> shows the performance of each program relative to decipher for increasing numbers of input sequences. the performance ranking is in strong agreement between the homstrad-mod and prefab-mod benchmarks, yet there is a greater spread between programs on prefab-mod because it contains a larger fraction of sequences in or below the twilight zone.fig.  <dig> performance of popular multiple sequence alignment programs relative to decipher on the homstrad-mod  and prefab-mod  benchmarks. promals  <cit>  exhibited the best performance on the smallest sets of two sequences. mafft  <cit>  had the best performance on small input sets of  <dig> sequences, where it uses a much slower consistency-based strategy. muscle  <cit>  showed the worst performance on larger sequence sets. decipher’s performance relative to other programs improved as more sequences were aligned



when only two sequences were aligned from each benchmark, the alignment programs all gave similar results, with mafft showing the lowest accuracy. in the sets of  <dig> sequences, decipher is ranked second behind mafft. for input sets of this size, mafft uses its most accurate consistency-based algorithm  that is not scalable to larger sequences sets. beyond  <dig> input sequences, decipher clearly outperforms the other three programs , and its lead improves as more sequences are aligned . this reflects the fact that decipher’s accuracy stays relatively constant with increasing numbers of sequences , which is partly attributable to its use of secondary structure during alignment. clustal omega, mafft, and decipher all have similar m-scores across the range of input sizes . muscle had the poorest performance, with substantially worse q- and m-scores for all but the smallest input sequence sets. furthermore, although q-score, total column score , and cline shift-score  <cit>  sometimes give conflicting performance rankings, these three statistics strongly agreed on both benchmarks .

over-training to a single reference set has been a concern for some alignment programs  <cit> , although both reference sets used here showed similar results. however, other programs may be better trained on the original benchmarks that are not based on the outputs of the mustang structural alignment program. to verify that decipher was not over-trained to mustang’s outputs, i repeated the analysis using the original prefab reference pairs, which were aligned independently of mustang. the unmodified prefab reference sequences showed strong secondary structure concordance, and therefore provide a high-quality alternative benchmark. nevertheless, the results  were very similar for both sets of reference sequences, indicating that decipher’s performance was not closely tied to mustang’s outputs.

i next compared decipher to pasta  <cit> , which is a program intended to extend the accuracy of less-scalable algorithms to large alignments. pasta works by dividing an alignment up into overlapping sub-problems that are each aligned with an accurate strategy, by default mafft’s l-ins-i consistency-based approach. these sub-alignments are merged using transitivity, and the process is repeated starting from a new guide tree. interestingly, pasta outperformed decipher on sets of  <dig> and  <dig> sequences on homstrad-mod , but was statistically indistinguishable on larger sets . however, decipher substantially outperformed pasta on prefab-mod, and its lead increased as more sequences were aligned. furthermore, pasta showed a large drop in accuracy with increasing alignment size. table  <dig> shows that decipher’s performance diminished the least of all alignment programs as alignment size increased.table  <dig> change in average q-score according to the number of sequences being aligned

homstrad-modb
prefab-modb

ascores for aligning two sequences are listed as “n/a” because pasta cannot perform pairwise alignment


bresults for the subset of reference alignments with at least  <dig>  reference sequences are shown 



finally, i compared decipher’s performance to promals  <cit> , which is a program that relies on more accurate secondary structure predictions obtained from psipred  <cit> . promals first performs psi-blast searches with representative sequences from the input set, and then uses accurate secondary structure predictions with a consistency-based approach to align the sequences. promals greatly out-scored all of the other alignment programs on the smallest sets of two sequences, but its advantage disappeared once other sequences were added to the input set . furthermore, it was several orders of magnitude slower that the other aligners , and testing input sets larger than  <dig> sequences proved prohibitively time consuming. more recent approaches that make use of solved protein structures are available, such as promals3d  <cit> . however, it is unclear how to test such approaches on structural benchmarks, because the reference sequences are likely present in the same structure databases used by these programs.fig.  <dig> average execution time according to the number of sequences being aligned . promals  <cit>  was substantially slower than the other programs that do not rely on a large external database of sequences. mafft  <cit>  was the fastest program for large sequence sets. pasta was the slowest program tested for aligning large sequence sets, requiring an average of  <dig>  h to align  <dig>  sequences. a noteworthy speed improvement was obtained with decipher by using multiple processors



decipher was neither the slowest nor fastest program benchmarked for aligning each of the sequence sets . mafft was generally the fastest program, except for the smallest sequence sets where it uses slower, more accurate strategies for alignment. the change in elapsed time is dramatic for mafft and muscle beyond  <dig> sequences where more efficient strategies were used. pasta was the slowest program, and required an average of  <dig>  h to align  <dig>  sequences. both clustal omega and decipher were able to align  <dig>  sequences in about half an hour on average. since guide tree computation is the limiting factor for large sequence sets, parallelization may be useful in such circumstances. for example, decipher was about twice as fast when  <dig> processors were used . decipher’s maximal memory use was 2gb when aligning  <dig>  sequences.

discussion
the accurate alignment of very large numbers of sequences has been a long-standing goal for sequence alignment programs. decipher exhibited excellent performance in the range of hundreds to thousands of sequences, with little decrease from maximal accuracy. this number of input sequences is common in current investigations harnessing next generation sequencing or large online sequence repositories. even greater numbers of sequences are often available, but the scalability of these techniques to ultra-large alignments was not assessed in this study for two reasons. first, extremely large sequence sets can likely be reduced to a more manageable size through the clustering of highly similar sequences into groups represented by consensus sequences. second, it is questionable whether there currently exists a reasonable empirical benchmark for ultra-large alignments . the popular strategy employed here, of extending structural benchmarks with supplemental sequences, suffers from a dilution problem as the number of supplementary sequences begins to greatly outnumber the reference sequences.

it has been previously established that the vast majority of information indicating whether to align two positions is contained directly in the amino acid pairing. this has led to the assumption of positional independence that is the primary means for efficient alignment algorithms  <cit> . however, the results of this study show that local sequence context can be efficiently harnessed to further improve alignments. gor secondary structure predictions are based solely on local residues, and are therefore an indirect means of incorporating contextual information. previous direct attempts to break the independence assumption have been based on substitution matrices with quadruplets of amino acids  <cit> . however, direct approaches have failed to show an improvement in alignment quality, possible due to the extremely large number of parameters required to estimate the substitution matrix of all possible dipeptides . very large datasets such as blocks  <cit>  are still insufficient to accurately determine the frequency of many amino acid quadruplets  <cit> .

my own attempts to construct a substitution matrix based on amino acid triplets also showed signs of estimation inaccuracy. however, testing this matrix did reveal a small improvement in q-score, albeit far less than that of using secondary structure predictions. the gor  method employed here uses two matrices of parameters, one based on single residues and the other on pairs of residues, which can be accurately estimated due to their relatively small size. furthermore, reduction to a three-letter  alphabet that reflects an important property of the alignment enables local sequence context to be efficiently harnessed, because the contextual information only needs to be computed once per site and can then be reused under the dynamic programming approach to alignment. in contrast, using large substitution matrices requires re-computing the covariation score at every site, which is very inefficient and is not suitable for large sequence sets  <cit> .

CONCLUSIONS
the main finding of this study is that fast secondary structure predictions can be employed in a scalable manner to counteract the drop-off in accuracy associated with aligning more sequences. this effect can be explained by the fact that structure is more conserved than sequence and therefore remains a reliable predictor even as sequences diverge greatly. secondary structure prediction algorithms exhibit a similar increase in accuracy as more sequences are used in the prediction. for example, accuracy of the gor algorithm increases by 6 % when multiple sequences are used for prediction  <cit> . the same logic was applied in this study, as profiles of secondary structure predictions are progressively merged while sequences are aligned along the guide tree, resulting in improved group-level predictions that assist alignment. at the top of the guide tree, where the sequence profiles being merged are highly divergent, the secondary structure probabilities are more accurate because they are based on the entire group’s consensus prediction.

there is an inherent trade-off between true and false homologies, and the results of this study advocate for the comparison of both in the development and benchmarking of alignment algorithms. while it is common to report q-score and tc-score, these two statistics are strongly correlated. in contrast, q-score and m-score are not linearly related, and beyond a certain optimum one must be lowered to raise the other. analyses of alignment performance have often focused solely on quantifying true positives , which has the potential to paint an unbalanced picture of alignment performance. similarly, the choice of alignment benchmark was carefully analyzed in this study. the results showed that not all reference sets are equally well aligned, and therefore benchmarks should be compared in addition to alignment programs  <cit> . treating all benchmarks as intrinsically equivalent risks developing algorithms that are trained for the wrong goal.

additional files
additional file 1: 
this supplementary file contains a description of the decipher algorithm, figures 
s1–s <dig>  and tables
s1–s <dig>  



competing interests

the author declares that he has no competing interests.

authors’ contributions

ew designed the study, performed all research, and wrote the manuscript.

authors’ information

not applicable.

