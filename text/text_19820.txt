BACKGROUND
an important first step of any microarray experiment is the normalization of the samples. although the relative impacts differ from platform to platform and sample preparation, non-biological differences in microarray signals can stem from a variety of factors, such as: global constant background noise, non-specific binding signal, non-linear signal response between samples, bad spots on the chip due to dust or bubbles or rare manufacturing defects, labeling efficiency, hybridization efficiency, and rna quality. while some can be difficult or impossible to detect and correct for computationally, most can be addressed to some extent by how the raw data is processed in order to yield the final transcript intensities. thus, the methods used to post-process the raw data can have a large impact on the final biological signal. we also here want to make a clear distinction between what is commonly called “batch-effects” and the kind of variance that should be minimized with a good normalization method. batch effects are as real as any biological signal, and are indistinguishable from biological signal without post-normalization interpretation of experiment-related metadata. as such, they are not suitable for removal by chip normalization methods. there are other tools which specifically focus on removing batch effect after initial chip post-processing, such as combat  <cit> , and our focus in this manuscript will be on removing non- batch-related technical variation.

the three most commonly used software packages for processing affymetrix microarrays, as evidenced by recently querying the geo  <cit>  and arrayexpress  <cit>  microarray repositories, are: rma  <cit> , mas <dig>  <cit> , and dchip  <cit> . each of these employs different methods for background subtraction, signal normalization, and probeset summarization . a flowchart of these pipelines is given in figure  <dig>  there are various theoretical and empirical advantages and disadvantages to the various steps in each processing pipeline, many of which have been discussed previously  <cit> , and will be further discussed below.

we present here a new pipeline, iron , which combines what we consider the most desirable steps of each pipeline, and further improves upon the normalization approach of dchip. we introduce a novel method for normalization of affymetrix arrays based on rank-invariant probesets, combined with steps from both the rma and mas <dig> pipelines . our design goals for iron include  the ability to incrementally normalize additional data,  the ability to process as few as two chips without negatively impacting quality,  provide robust normalization under noisy or systematic effects as commonly seen in biologically complex datasets , and  efficiently handle large numbers of samples. iron seeks to avoid limitations of existing algorithms where possible, and selects the algorithm that best incorporates our design goals. each step of the normalization and summarization algorithm is motivated by empirical examples and demonstrates the utility of the iron approach.

this pipeline is implemented in the freely available libaffy c library and associated applications. a generic pipeline, lacking affymetrix-specific modules, is also provided for use on non-affymetrix datasets.

RESULTS
rma background subtraction does not introduce low-intensity variability
the choice of background subtraction methodology can have a large impact on the final processed signal intensities. for affymetrix arrays, mm  probes differ from pm  probes by a single base in the center of the 25-mer. these probes were originally intended for use in estimating non-specific binding signal. however, the subtraction of mm intensities from pm intensities, exemplified by mas <dig>  has been shown to be less than optimal, due to the amount of target-gene specific binding present in the presumably non-specific mm signal  <cit> . although choe et al.  <cit>  and irizarry et al.  <cit>  arrived at opposite conclusions regarding the suitability of mas <dig> background subtraction, this can largely be explained by differences in the methodology used to determine differentially expressed genes. both manuscripts agree that mas <dig> background subtraction introduces high variability into low-intensity probes, which agrees with subjective visual inspection of resulting probeset scatterplots .

rma background subtraction deconvolves, in log2-space, a low-intensity normally distributed background from an exponentially decaying signal, ignoring the mm probes entirely. the assumption of normal and exponential background and signal distributions generally holds in practice, is justified from physical binding considerations, and the resulting background-subtracted signals preserve the overall shape and patterns of the unprocessed scatterplots without introducing additional low-intensity variability . dchip uses a probeset-level probe-specific background model , trained from all chips within a dataset, and defaults to using mm-subtracted pm intensities. as a result of the model-based approach, this method generates differing results depending on the populations of chips processed together. although it is comparable to either mas <dig> or rma  <cit>  in spike-in experiments, dchip does not support background subtraction prior to probe-level normalization and probeset summarization. thus, rma background subtraction was chosen for use in iron, due to its non-specific binding signal deconvolution methodology, lack of introduced noise, and chip independence.

pair-wise iterative rank-order normalization minimizes introduced artifacts in biologically complex data
there are three major normalization methods that are commonly employed: linear scaling , quantile normalization , and pair-wise rank-invariant normalization . linear normalization is the simplest of the methods, which applies a global scaling factor to each chip  in order to scale all chips to the same trimmed mean intensity. quantile normalization ranks the intensities for each chip, then replaces the intensities at each rank with the mean intensity for all probes of that rank across all chips, effecting a non-linear rank-dependent normalization. pair-wise rank-invariant normalization normalizes all chips against a single reference chip by identifying a different subset of rank-invariant genes for each sample/reference chip pair, fitting a curve through the training set, then adjusting the intensities of the target chip in an intensity-dependent manner so that the fit curve will lie on the sample vs. reference diagonal of the scatterplot.

linear normalization is unable to correct for non-linear, intensity-dependent differences in gene expression between chips, but can be applied to a single chip, independently of other chips. quantile normalization assumes that differential gene expression is symmetric, in that there will be a roughly equal number of up and down regulated genes with equal magnitude distributions. due to its population-based signal, it requires a moderately large number of chips in order to work well, and may introduce unexpected artifacts, particularly in outlier samples, in small experiments, or experiments in which different cell/tissue types are represented. rank-invariant normalization makes similar assumptions to those of quantile normalization, since both are rank based, but can be applied to as few as two chips.

since linear normalization performs the least amount of manipulation to the original data, it is arguably the least destructive when its assumptions are violated. quantile and rank-invariant normalization perform well when the symmetric distribution assumption holds, but can dramatically distort the data when this assumption is violated . iron normalization attempts to provide as flexible a solution as linear and traditional rank-invariant normalization, which are not limited to large homogenous datasets, while minimizing errors introduced from violations of the underlying assumptions of the algorithm.

large numbers of genes changing in a single direction, and/or large magnitudes of change in one direction, displace the ranks of unchanged genes, causing the unchanged genes to exhibit large changes in rank. this is evident in figure  <dig>  where ~10% of the probes are highly up-regulated in sample gsm <dig> of geo  <cit>  dataset gse <dig>  creating an upper “arm”. both traditional fixed-cutoff rank-invariant fitting , as well as quantile normalization , effectively fit a line passing between the true high density diagonal and the secondary distribution arm. iron iteratively decreases the rank difference cutoff, starting at the maximum observed difference in the dataset, until convergence to a set of probes that differ by ≤ 1% rank. this differs from previously described iterative rank-invariant methods, which iterate a fixed cutoff, or, in the case of dchip, a narrow range of strict cutoffs, until convergence. the iterative use of a gradually more stringent cutoff largely eliminates the problem of asymmetric changes inducing false-positive shifts in rank, since most of the offending outlier points are iteratively discarded before they can negatively impact the final rank-order analysis . interestingly, dchip, despite its average-rank dependent cutoff between  <dig> %– <dig> %, produced results that were more similar to iron than to fixed-cutoff rank-invariant normalization .

to observe the effects of background subtraction  on probe-level normalization, we also examined normalization as it would occur within the iron and rma pipelines . the same effects of violation of the symmetry assumption are observed in the background-subtracted figures as in the non- background-subtracted figure . since dchip subtracts background after probe-level normalization, and mas <dig> normalizes at the probeset level, background-subtracted probe-level normalization comparisons are not applicable.

mas <dig> probeset summarization reduces both false-correlation and removal of biological signal
probesets, often a collection of  <dig> or more pm/mm probe pairs, must be summarized into a single intensity value representative of the behavior of the set of probes as a whole, which reflects the expression of the target transcript. the most commonly used approaches are tukey’s biweight  and median polish . tukey’s biweight is a weighted average of the individual log <dig> probe intensities, down-weighting probes more distant from the median of the probeset. this should be more tolerant of outlier probes/spots than an unweighted average  <cit> . rma probeset summarization fits a linear additive model of signal + probe-affinity + error terms, using median polish to estimate the model parameters for each probeset across all chips. giorgi et al. <cit>  have shown that rma probeset summarization introduces false correlation, via the median polish procedure in high variability probesets yielding identical values across chips.

additionally, we have observed that median polish often blurs the differences between biologically distinct groups of samples. this is exemplified in figure  <dig>  where we compare the results from a principle component analysis  on the same dataset using four different post-processing pipelines: iron, dchip, mas <dig>  and rma. the separation between the two classes is completely in the first principle component for the iron and mas <dig> normalized data, while the separation of the two classes is spread between both components one and two for the dchip and rma normalized data. dchip separates the samples similarly to iron, suggesting that mbei may not remove as much variation as median polish. substituting median polish probeset summarization into the iron pipeline produces a similar result to that seen for rma , indicating that median polish probeset summarization may degrade biological signal. this, together with the findings of giorgi et al. <cit> , suggests that median polish may be overcorrecting by removing biologically-derived variation in addition to technically-derived variation. given the undesirable behaviors of lack of chip-independence, introduction of false-correlation, and removal of biological signal, tukey’s biweight was chosen over median polish as the default iron probeset summarization method.

probeset-level normalization corrects further intensity-dependent differences
regardless of the background subtraction, probe-level normalization, and probeset summarization method used, we have observed that the resulting probeset intensities often exhibit similar patterns of non-linear intensity-dependent differences in signal levels as those of their underlying raw unprocessed data. choe et al.  <cit>  also commented on the high frequency of this occurrence, and demonstrated marked improvement in signal quality by applying an additional pass of pair-wise normalization at the probeset level. we observed similar positive effects, both visually and biologically . thus, iron performs a final pass of pair-wise normalization at the probeset level, after all other processing has been performed.

comparison of techniques on spike-in benchmarks
the affycomp iii  <cit>  and golden spike  <cit>  spike-in benchmarks were used to compare the iron pipeline to existing techniques. the affycomp spike-ins are a small number of symmetrically altered transcript concentrations in a common background, with little normalization required between samples. the golden spike experiment, on the other hand, spikes in uni-directionally varying concentrations of  <dig> out of  <dig> transcripts , resulting in significant violations of the symmetry assumption inherent to many normalization methods. as such, differences in affycomp metrics may be driven by choice of background subtraction and probeset summarization methodology, while differences in the golden spike dataset results are driven by the ability of the normalization method to cope with violations of the symmetry assumption  <cit> .

due to its combination of rma background subtraction and tukey’s biweight probeset summarization, iron performs somewhere between mas <dig> and rma in the affycomp benchmark . iron is closer to rma performance for metrics dominated by background subtraction , and closer to mas <dig> in metrics dominated by probeset summarization . the iron approach thus performs similarly in affycomp to mas <dig>  rma, and dchip. auc measurements of spike-in detection on the golden spike experiment  show iron as the top-performer , followed closely by dchip . both iron and dchip perform noticeably better than mas <dig>  and rma . due to the asymmetric properties of the golden spike dataset, the performance of iron and dchip can be attributed to the ability of their respective normalization procedures to accommodate asymmetric gene expression changes.

iron generally performs in-between mas <dig> and rma, as expected, due to the mix of rma background subtraction  and tukey’s biweight probeset summarization . metrics 1– <dig> are closer to rma due to the use of rma background subtraction, while metrics 11– <dig> are closer to mas <dig> due to the use of tukey’s biweight probeset summarization.

comparison of auc measurements across the spike-in literature can be difficult, due to differences in how differentially expressed probesets are identified. these differences can lead to opposite and seemingly contradictory conclusions. as noted by choe et al.  <cit> , and also shown by irizary et al.  <cit> , mas <dig> can perform significantly better or worse than rma, depending on whether fold-change or variance-based metrics are used to determine differentially expressed  probesets. fold-change based methods are highly sensitive to variation within the low-intensity region, where small  changes in intensity can result in overly-large fold-changes. these probesets are identified as differentially expressed, which, in turn, results in low auc measures. thus, methods that minimize variation perform well in affycomp, which uses only fold-change to determine de probesets. variance-based evaluation methods, such as those used in choe et al. and irizary et al. , as well as in this manuscript, do not implicitly favor minimization of low-intensity variation. post-processing techniques in which variation is not as aggressively reduced could then potentially lead to increased sensitivity. direct comparison of auc results from different evaluation methods can be challenging, and we believe that evaluation must be performed in the larger context of how the various methods affect background-subtracted intensities, signal normalization, probeset summarized intensities, and other biological-signal related methods.

application
the simple, ideal spike-in experiments are far from capturing behavior observed in biologically complex data, particularly when it comes to heterogeneous samples such as human tumors. we have frequently observed difficulties with cancer datasets, particularly in publicly available data. the combination of tumor heterogeneity, batch effects, and differing protocols for generating the microarrays leads to less than ideal conditions for analysis. the choices in iron for background subtraction, normalization, and probeset summarization were made on both theoretical grounds and empirical observations of behavior in existing datasets. our goal is an algorithm that seeks to best preserve true differences between samples, including batch effects, while minimizing technical variation and processing-introduced artifacts. we have shown that the resulting combination of microarray normalization pipelines provides a robust method that is suitable for diverse datasets.

a challenge in expression normalization is the existence of large patient cohorts or cell line datasets that must be processed together. for instance, igc  <cit>  consists of ~ <dig> tumors, the arrayexpress  <cit>  cancer cell line dataset e-mtab- <dig> has  <dig> samples, and our institution has collected over  <dig>  genechips from tumors  <cit> . there are clearly diminishing returns from estimating model parameters  from such large datasets  <cit> . the need for dataset-specific parameters/normalization is arguably necessary for specific tumor types. iron addresses these issues by avoiding multi-chip calculations without sacrificing the advantages in precision from these approaches. the algorithm identifies a single median chip to normalize the set against. this is the only global analysis performed, and the remaining processing can be done serially or distributed across many parallel nodes.

increased focus has been placed on avoiding methodological biases in analysis of gene expression. one area that is not typically highlighted is the normalization step. a validation of a gene expression signature should be completely independent of the process of generating the signature. however, in the case of rma, building separate models of normalization for both training and test sets can lead to systematic differences due to the process. iron avoids this difficulty through the use of a single reference sample. by incorporating this approach, any single sample can be successfully classified by normalizing against the median sample. while it is possible to take parameters from an existing rma model  <cit>  and apply them to new data, the drift in expression from the initial training set could negatively impact normalization of new samples. by normalizing against the median  sample, this difficulty is minimized. we have observed little difference in gene expression estimates based on selection of the reference sample, so long as the chosen reference sample is not an outlying sample .

the iron algorithm is amenable to distributed processing. the selection of the median chip is disk and memory intensive, since it requires an all vs. all chip comparison which is difficult to efficiently parallelize. however, this is generally not a limiting step, as we have performed median chip analysis of ~ <dig>  chips  on a single cpu core, using  <dig>  gb of memory in less than  <dig> hours. if, in the future, data size scales more rapidly than memory capacity, the memory limitation could be easily addressed through techniques such as sparse sampling of probes and probesets with minimal impact on the accuracy of median chip selection. the normalization itself can be run in a highly parallel fashion in which every chip is processed independently. each pair-wise normalization does require an iterative procedure that must converge. however, both in computational time and memory requirements, the maximum amount needed scales linearly with the number of samples analyzed, normalizing greater than four affymetrix hg-u <dig> plus  <dig>  chips per minute, per core, on modern hardware.

CONCLUSIONS
each of several commonly used microarray normalization pipelines , contain background subtraction, normalization, and probeset summarization algorithms that are more or less desirable compared to others. the new pipeline presented here, iron, recombines these algorithms, extending the pair-wise normalization procedure with a new iterative rank-order method, so as to limit the amount of potential harm to the processed data while maintaining the ability to correct for common technical artifacts. the intensities of each chip, while still dependent on the choice of reference chip, are independent from those of other chips, allowing for processing of small numbers of samples , and avoiding the problem of outlier chips negatively impacting the quality of other chips. iron should be generally applicable to any dataset, whether it contains large or small numbers of samples, and whether it contains highly similar or dissimilar samples.

iron is implemented as part of the libaffy c library and set of tools  <cit> . source code for these tools, along with pre-compiled binaries for selected platforms, is available at  under the gnu public license .

