BACKGROUND
the spotted cdna microarray technology  <cit>  is a widely used tool for examining gene expression profiles across experimental conditions. it measures the messenger rna  levels of thousands to tens of thousands of genes in the sample. scientists typically conduct the experiments in logical sets, such as time course profiling of yeast cell cycles  <cit> , or comparing cancer to normal tissues  <cit> . one feature of these experiments is the small number of replicates : three or less are common, and six or more are rare. despite the vast improvement of the technology in recent years, missing values are still a common feature of spotted array experiments. missing values arise from e.g. blemishes on the chips; a few percent to more than  <dig> percent of the values of a chip may be missing. yet most data analysis procedures require a complete data set. thus missing values need to be imputed, and numerous imputation algorithms have previously been proposed  <cit> . all these studies used only the numerical data from the microarray experiments for imputation. two recent studies  <cit>  incorporated external biological knowledge to improve the estimate.

we begin by briefly reviewing the cdna microarray technology, for the purpose of introducing a common notation for the rest of the discussion. the spotted cdna microarray experiments usually follow the two-dye protocol, where the red channel is the sample under study and the green channel is the reference pool  <cit> . after the microarray experiments are completed, the data of a logical set of g genes examined under c experimental conditions are collected in a g × c matrix, which we will denote by a. each row g ∈ { <dig>  …, g} corresponds to a gene, and each column c ∈ { <dig>  …, c} corresponds to a particular microarray sample. after background subtraction and normalization  <cit> , every entry in a is the base-two logarithm of the ratio of the red and green intensities.

if a gene g ∈ { <dig>  …, g} has missing values in some columns c ∈ { <dig>  …, c}, most imputation methods will try to borrow strength from other genes g' ∈ { <dig>  …, g} with "similar" expression profiles to g, across replicate experiments or experiments under several conditions. for example, knnimpute  <cit>  first selects the k  genes from { <dig>  …, g} with the shortest euclidean distances to g, d, where

d=∑c∈{ <dig> …,c}:g,g′ not missing−g′) <dig> 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgkbazcqggoaakcqwgnbwzcqggsaalcuwgnbwzgaqbaiabcmcapiabg2da9maaqafabagaeiikagiaem4zacmaeiikagiaem4yammaeiykakiaeyoei0iafm4zacmbauaacqggoaakcqwgjbwycqggpaqkcqggpaqkdaahaawcbeqaaiabikdayaaaaeaacqwgjbwycqghiiizcqgg7bwecqaixaqmcqggsaalcqwivlctcqggsaalcqwgdbwqcqgg9bqfcqgg6agocqwgnbwzcqggoaakcqwgjbwycqggpaqkcqggsaalcuwgnbwzgaqbaiabcicaoiabdogajjabcmcapiabbccagiabb6gaujabb+gavjabbsha0jabbccagiabb2gatjabbmgapjabbohazjabbohazjabbmgapjabb6gaujabbeganbqab0gaeyyeiuoakiabc6cauaaa@6951@

that is, the distance between genes g and g' is calculated in the non-missing dimensions. we denote the set of the k genes with minimum euclidean distances to g by s. then, each of the missing values of gene g is estimated by a weighted average of expression values for the k similar genes. for each c such that gis missing, we impute by the value g˜
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacuwgnbwzgaacaaaa@2e12@, where

g˜=∑g′∈s)−1g′∑g′∈s)− <dig> 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacuwgnbwzgaacaiabcicaoiabdogajjabcmcapiabg2da9maalaaabawaaabeaeaacqggoaakcqwgkbazcqggoaakcqwgnbwzcqggsaalcuwgnbwzgaqbaiabcmcapiabcmcapmaacaaaleqabagaeyoei0iaegymaedaaogafm4zacmbauaacqggoaakcqwgjbwycqggpaqkasqaaiqbdeganzaafagaeyici4saem4uamlaeiikagiaem4saskaeiykakcabeqdcqghris5aagcbawaaabeaeaacqggoaakcqwgkbazcqggoaakcqwgnbwzcqggsaalcuwgnbwzgaqbaiabcmcapiabcmcapmaacaaaleqabagaeyoei0iaegymaedaaaqaaiqbdeganzaafagaeyici4saem4uamlaeiikagiaem4saskaeiykakcabeqdcqghris5aaaakiabc6cauaaa@5dca@

the reciprocal of the euclidean distance is used to measure the similarity in expression profiles. most imputation algorithms are variations of this scheme; they differ by how many genes in { <dig>  …, g} are used to impute, and how the weights are calculated.

in this study, we put forth the idea that the matrix a may not be the most suitable to impute its own missing values. intuitively, imputation is best done with a lot of replicates. yet the logical set is an aggregate of samples under various conditions, with few replicates for each condition. the performance of the imputation method will very much depend on the similarity of the set of genes g' to g. in the case of small logical sets, the limited replicate information or experimental profile information may not be sufficient to determine which genes g' are indeed similar to g. thus, this study explores the possibility of using microarrays from different logical sets for imputation. we compare each column c in the matrix a to hundreds of experiments in databases in the public domain, and we seek experiments with similar expression profiles across the genes to c. we will use this richer data source to improve on the identification of genes g' that are similar to gene g with a missing value in c, with the aim of improving imputation accuracy. we demonstrate this meta-data based imputation method using saccharomyces cerevisiae , caenorhabditis elegans , and arabidopsis thaliana  as the model systems.

to proceed, we need to obtain data from a large number of microarray experiments. this is facilitated by microarray data depositories offering public access, such as the stanford microarray database   <cit> . we downloaded the data of more than two thousand microarrays from smd, and after some pre-processing, extracted a database matrix for each species. the data to be imputed are in the matrix a, and its columns will be imputed one by one using "similar" columns in the database matrix. this is where our approach differs from the usual imputation paradigm, under which the matrix a is used to impute itself. for computational efficiency, we need to select a subset of the columns from the database matrix to impute a column c of a. we use the absolute value of column-wise pearson correlation as a measure of similarity between data columns. through simulations, we find that imputation via  <dig> database columns with the highest similarity to the column c strikes a good balance between computation efficiency and imputation accuracy, which is measured by the normalized root mean squared error .

our results  support the use of the absolute value of column-wise pearson correlation as a measure of similarity,  support the choice of using  <dig> database columns for imputation, and  demonstrate the superiority of our meta-data based approach  to the usual paradigm . furthermore, for each column c in the matrix a, we designate the most up-regulated ten percent genes and the most down-regulated ten percent genes as potentially significant. the rmse of these genes is generally a lot less than that of non-significant ones. in addition, the meta-data imputation greatly improves rmse for significant genes compared to the usual paradigm. researchers often use only this filtered subset of genes for clustering and classification, and small perturbations of the estimated gene effects can have a huge impact on these downstream analyses  <cit> . thus the database imputation provides high quality data for subsequent analyses. the findings in this study are incorporated in a web-based software tool for yeast, worm, and plant cdna microarray data imputation  <cit> .

methods
let the microarray data be represented by a matrix, where the g rows correspond to the genes and the c columns correspond to the samples. we previously described gmcimpute  <cit> . briefly, the rows of the matrix are clustered into  <dig>   <dig>  ..., q-component gaussian mixtures . for each q-component model, we assume that the expression data are generated from a mixture distribution

∑j=1qπjn,
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaadaaewbqaaggaciab=b8awnaabaaaleaacqwgqbgaaeqaaogaemota4kaeiikagiae8hvd02aasbaasqaaiabdqgaqbqabagccqggsaalcqqhjowudawgaawcbagaemoaaogabeaakiabcmcapawcbagaemoaaomaeyypa0jaegymaedabagaemycaehaniabgghildgccqggsaalaaa@41ff@

where πj is the mixing proportion, μj = μj, …, μj is the j-th component mean expression profile across the c columns, and the c × c covariance matrix Σj summarizes the relationship among the c columns. the mixture models are fit to the data by the classification expectation-maximization algorithm   <cit> ; then the missing values are estimated by the expectation-maximization algorithm  <cit> ; for each missing value, the estimate by gmcimpute is the simple average of the q estimates. if the cem algorithm takes i iterations to converge, then gmcimpute takes o time. if gene g has a missing value in column c, we use the information in the other columns {g, c' ≠ c}, and the estimated relationship among the columns, to impute the value g˜
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacuwgnbwzgaacaaaa@2e12@ via a weighted average of the component-wise conditional expectations of g|{g, c' ≠ c}. that is,

g˜=1q∑q=1q+ΣjΣj−1−μj)t]),
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacuwgnbwzgaacaiabcicaoiabdogajjabcmcapiabg2da9maalaaabagaegymaedabagaemyuaefaamaaqahabawaaewaaeaadaaewbqaaggaciab=d7aonaadaaaleaacqwgnbwzcqwgqbgaaeaacqwgxbqcaagcdawadaqaaiab=x7atnaabaaaleaacqwgqbgaaeqaaogaeiikagiaem4yammaeiykakiaey4kasiaeu4odm1aasbaasqaaiabdqgaqbqabagccqggbbwwcqwgjbwycqggsaalcqghsislcqwgjbwycqggdbqxcqqhjowudawgaawcbagaemoaaogabeaakiabcufabjabgkhitiabdogajjabcycasiabgkhitiabdogajjabc2fadnaacaaaleqabagaeyoei0iaegymaedaaogaeiikagiaem4zacmaeiikagiaeyoei0iaem4yammaeiykakiaeyoei0iae8hvd02aasbaasqaaiabdqgaqbqabagccqggoaakcqghsislcqwgjbwycqggpaqkcqggpaqkdaahaawcbeqaaiabdsfaubaaaogaay5waiaaw2faaawcbagaemoaaomaeyypa0jaegymaedabagaemycaehaniabgghildaakiaawicacaglpaaaasqaaiabdghaxjabg2da9iabigdaxaqaaiabdgfarbqdcqghris5aogaeiilawcaaa@7b34@

where ηgjq
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiigacqwf3oaadaqhaawcbagaem4zacmaemoaaogabagaemycaehaaaaa@32ab@ refers to the posterior probability of gene g with respect to component j in the :

rmse=mean{2}mean{a2},     
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqqgsbgucqqgnbqtcqqgtbwucqqgfbqrcqgh9aqpdagcaaqaamaalaaabagaeeyba0maeeyzaumaeeyyaemaeeoba4maei4easnaeiikagiaemyqaekaeyoei0iafmyqaekbauaacqggpaqkdaahaawcbeqaaiabikdayaaakiabc2ha9bqaaiabb2gatjabbwgaljabbggahjabb6gaujabcuha7jabdgeabnaacaaaleqabagaegomaidaaogaeiyfa0haaiabcycasawcbeaakiaaxmaacawljawaaewaaeaacqaixaqmaiaawicacaglpaaaaaa@4fe8@

where a <dig>  for example, is component-wise. we have found that gmcimpute is competitive in terms of imputation rmse, and in terms of its effect on downstream significance and clustering analysis, and it is also computationally efficient  <cit> . traditionally, a' is computed solely from a. in our meta-data imputation, when we apply gmcimpute to the missing values in the matrix a, the columns that are used by gmcimpute are not necessarily limited to only those of a. let us assume that we impute missing values in a column c ∈ { <dig> ..c} from matrix a. we will identify the m columns, from a or from the database matrix d, with the largest absolute pearson correlation to column c. we will then use these m columns in gmcimpute.

in july  <dig>  we downloaded from smd  <cit>  the data of  <dig> ,  <dig>  and  <dig> cdna microarrays for yeast, worm, and plant, respectively. raw data processing  was performed by smd. each entry in the data is the base-two logarithm of the ratio of the red and green intensities. if an experiment used the dye-swap design  <cit> , the two channels were swapped back so that the numerators of the ratios were always the samples under study. the data deposited in smd over the years came from different microarray platforms. thus we need to establish the correspondence of genes across the platforms. yeast has  <dig>  or so nuclear open reading frames , and they are uniquely identified by their orf systematic names promulgated by the saccharomyces genome database  <cit> . for the worm, the genes are identified by the clone identifiers maintained by the wormbase  <cit> . for the plant, the genes are identified by their genbank accession numbers. the data we downloaded from smd will be used to construct the database matrix d .

to examine the performance of meta-data imputation, we need a gold-standard data set on which to conduct a simulation study. we will thus create a data set without missing values. we will then randomly mask values in the gold-standard data set, pretend that they are missing, and apply imputation. since the true values of these artificial missing entries are known, we can compare and validate imputation methods. for the yeast data, we use yeast orf systematic names as the row labels, and obtain a  <dig> ×  <dig> matrix. some entries in this matrix are flagged by the experimenters as missing, and we have to remove rows and columns with too many missing values. after their removal, we obtain a  <dig> ×  <dig> matrix. this matrix still has  <dig>  missing values , and we use the following steps to impute them;  we order the columns by the numbers of missing values in them, from the smallest to the largest ;  for each column c in the order prescribed in step  <dig>  we identify the  <dig> columns  that have the highest absolute values of pearson correlation to c;  we impute missing values in c using these  <dig> columns by gmc impute;  we repeat steps  <dig> and  <dig> ten times . finally, the  <dig> ×  <dig> matrix with  <dig> % imputed values is the database matrix d for yeast. when steps  <dig> and  <dig> are iterated, the imputed values in a column ci may be used to impute the missing values in a different column cj. the reason why we order the columns by the way described in step  <dig> is to control the propagation of imputation errors presumably from the smallest to the largest. the imputed values are changing from one iteration to the next, because they are used to impute one another. thus we need to iterate steps  <dig> and  <dig> some number of times till the change becomes small enough, presumably reaching a  optimum. the worm and plant database matrices are similarly prepared. the worm database matrix is  <dig> ×  <dig>  with 2% imputed values; the plant database matrix is  <dig> ×  <dig>  with  <dig> % imputed values.

in practice, researchers may submit their data for imputation without removing columns or rows with many missing values. however, we recommend a basic quality-control screening. if a sample  has an excessive number of missing values, it may be better to eliminate it from the logical set.

RESULTS
we first use the yeast data to develop the algorithm and fine-tune the algorithmic parameters; the parameters are the number of mixtures in gmcimpute and the number of columns from the database matrix d selected for use in gmcimpute. then we use yeast, worm, and plant data to compare imputation via database matrix d to imputation within logical sets.

measuring similarity by the absolute value of pearson correlation
we use cross-validation to investigate the imputation accuracy of database columns selected by the absolute values of their pearson correlation to the column to be imputed. for each column c of the yeast database matrix d, we randomly generate 2%, 4%, 8%, and 16% missing values in c . thus the true values of the artificial missing values are known. then for each instance of c with artificial missing values, we select the  <dig> columns  that have the largest absolute values of pearson correlation to c. the missing values are then imputed by gmcimpute of  <dig>   <dig>  and  <dig> clusters via the  <dig> selected columns. the simulation is repeated  <dig> times for each of the four proportions of missing values. the mean rmse is plotted in figure  <dig>  the mean absolute pearson correlation and the imputation rmse are highly negatively correlated. this suggests that imputation via the database matrix is a viable approach, as long as there are sufficiently many columns with large absolute pearson correlation to c. moreover, this result is stable across the full range of 2% to 16% missing values, as shown in figure  <dig> and table  <dig>  figure  <dig> shows that the rmses for 2% and 16% missing values are highly correlated, and table  <dig> contains the pearson correlation coefficients of the rmses for the four proportions of missing values.

for imputation within a logical set a, the performance of imputation decreases as the proportion of missing values increases. this is well documented in the literature by many authors and us. the reason is simple. when imputing a column c from a, both c and the rest of a have missing values. meta-data imputation is different. it uses information from the database matrix, in addition to the data matrix. the columns from the database matrix are complete, independent from the amount of missing values in c. figure  <dig> and table  <dig> show that the performance of meta-data imputation barely decreases with 2% to 16% missing values.

number of columns from the database matrix
if few database columns exhibit strong correlation to c, imputation rmse is large. thus one might think that there is a cut-off for the optimum number of database columns to be used for imputation, and that rmse performance may deteriorate if weakly correlated database columns are included in imputation. we use simulation with increasing numbers of database columns to look for such a cut-off, but do not find one before reaching the limitation of gmcimpute. the limitation is that it becomes difficult to reliably estimate the cluster variances when the data dimension  increases while the number of clusters and thus the numbers of genes in the clusters are held constant. we find that, regardless of strong or weak correlation, the more database columns that are used, the lower the rmse, as long as the gaussian mixtures can still be computed. specifically, we generate 2%, 4%, 8%, and 16% missing values in c, and then use  <dig>   <dig>   <dig>   <dig>  and  <dig> yeast database columns with the largest absolute pearson correlation to c to impute them. the mean rmse  of  <dig> independent runs are plotted in figure  <dig> for  <dig> randomly chosen c's. the plots for the other proportions of missing values exhibit the same characteristics. for almost every c, rmse always decreases when the number of database columns increases, although the decrease from  <dig> to  <dig> columns is small. in light of these results, we choose to use  <dig> database columns for imputation as a reasonable trade-off between imputation accuracy and computation efficiency.

comparing imputation via the database matrix to imputation within logical sets
the most critical issue is whether imputation via the database matrix is better than imputation within a logical set. the  <dig> columns of the yeast database matrix are partitioned into  <dig> logical sets, based on their smd annotation. as an example, one of the logical sets is the time course profile of yeast cells treated with  <dig>  mm h2o <dig>  consisting of  <dig> columns labeled by  <dig> to  <dig> minutes after treatment. the largest logical set has  <dig> columns, and the smallest has three. as before, 2%, 4%, 8%, and 16% missing values are randomly generated for each of the columns, and then each column c is imputed via  <dig> other database columns. the simulation is repeated  <dig> times. in each independent run, we also impute c via its own logical set, and thus obtain paired comparison of imputation accuracy between meta-data imputation and logical-set imputation. we find that meta-data imputation is always superior to logical-set imputation. the results for 16% missing values are plotted in figure  <dig>  in particular, the set of h2o <dig> treatment has  <dig>  rmse by meta-data, compared to  <dig>  rmse by logical-set. this is one of the smallest improvements among the  <dig> logical sets, because time course data are highly correlated and thus the two imputation approaches use almost the identical core set of columns. for one of the logical sets with  <dig> columns, imputation within itself has  <dig>  rmse, and imputation with the database has  <dig>  rmse, an astonishing improvement. note that meta-data imputation improves imputation accuracy for both large and small logical sets, and that in general the improvement is substantial for experiments with few replicates.

comparing imputation via the database matrix to imputation via one external logical set
a recent paper  <cit>  also examined imputation via external logical sets. the main finding is that the performance of the local least squares imputation  <cit>  can be consistently improved when extra data, along with the rest of the original data where the sample came from, are included in imputation. five logical sets are employed in their study. there are  <dig> samples  in total; the largest set has  <dig> samples, and the smallest has four. unlike our approach, which completely breaks up the boundaries of logical sets, their approach either includes or excludes a logical set in entirety. with their approach in mind, we next investigate whether there is any benefit in keeping a logical set together in our setting. we use the time-series of h2o <dig> treatment, which has  <dig> columns, as the reference set. among the remaining  <dig> columns of the yeast database matrix, some of them, such as the  <dig> mm md treatment, the heat shock treatment, and the hypo-osmotic shock treatment, are parts of the same study of yeast environmental stress response as the h2o <dig> set  <cit> . we assume that they should benefit from the information in the later. in the simulation, for each of the remaining  <dig> columns, we generate 16% missing values, and impute them via the  <dig> h2o <dig> columns as well as via the  <dig> columns selected from the database matrix using our method. as shown in figure  <dig>  breaking up the boundaries of logical sets is always better than using a logical set in entirety in our setting. furthermore, it is not a trivial exercise to identify the logical sets that lead to good imputation. in contrast, our approach is a simple and very effective method that identifies individual samples from the database for imputation.

rmse of significant and non-significant genes
in significance analysis of differential expression  <cit> , statistical procedures are applied to identify genes that are consistently up- or down-regulated across the microarray replicates. among the thousands of genes in a microarray, only a small portion is declared significant. for imputation to be a useful tool, its impact on downstream analyses should be minimized. since available analysis tools commonly require a full data matrix, imputed data are usually treated as if truly observed. when imputation is done within a logical set, or, even more extremely, within a gene as in the case of row-mean imputation, this can be quite hazardous as the gene-specific variances are underestimated and can lead to many false positives in the list of significant genes. in other downstream analyses such as clustering, only the subset of genes declared significant are examined. many of these clustering approaches are sensitive to small perturbations of the estimated gene effects. thus, imputation accuracy is especially important for the potentially significant genes. in  <cit>  we discussed how imputation can affect significance analyses; in  <cit>  we discussed the impact on clustering.

in this study, we designate for each column the most up-regulated ten percent genes and the most down-regulated ten percent genes as potentially significant, and calculate one rmse for these genes and another rmse for the non-significant ones. as before, 2%, 4%, 8%, and 16% missing values are randomly generated for each of the columns, and then each column is imputed via  <dig> other database columns. the simulation is repeated for  <dig> times.

for the yeast data, the mean rmses of significant and non-significant genes are plotted in figure  <dig> for the case with 16% missing values. each point corresponds to a column of the database matrix. the  line is x = y; the  points below the line are samples where significant genes have less rmse than non-significant ones; the  points above the line are samples where significant genes have more rmse than non-significant ones. we find that the significant genes generally have much smaller rmse than the non-significant ones.

in figure  <dig>  we compare rmses of meta-data imputation to logical-set imputation for the significant genes  and the non-significant genes . this figure offers detailed views of the data presented in figure  <dig>  our method improves the imputation accuracy for both significant and non-significant genes with few exceptions. thus, we can safely deduce that meta-data imputation will have a smaller impact on downstream analyses than the standard approach.

for the worm and plant data, all the simulation results are very similar in shapes and trends to the yeast results. thus we present only the most critical ones, those of the rmse of significant genes. the top panel of figure  <dig> compares rmse of significant worm genes by meta-data imputation to logical-set imputation, and the bottom panel is for the plant data. in particular, the top panel  shows that there are a number of columns that have rmse less than  <dig>  by meta-data imputation, compared to rmse from more than  <dig>  up to  <dig>  by logical-set imputation.

discussion
a logical set of microarray experiments assays mrna in samples under different conditions, and there are usually few replicates for each condition in the set. missing value estimation in the literature is mostly confined to imputation within a logical set. however, intuition suggests that imputation would be best done with a lot of replicates. we hypothesize that imputation accuracy for a logical set can be improved by incorporating information from other logical sets of experiments. we download all the saccharomyces cerevisiae , arabidopsis thaliana , and caenorhabditis elegans  cdna microarray data from the stanford microarray database  <cit> , and construct database matrices from them. through rigorous cross-validation and simulation, we validate the new meta-data based imputation with the following results.

first, when a column c  has missing values and when few replicates are available, the next best source of information would be highly correlated columns. bø et al.  <cit>  observed that negative correlation was also helpful in imputation. thus we use the absolute value of column-wise pearson correlation to select  <dig> other columns from the database matrix to impute c. figure  <dig> shows that absolute pearson correlation is a useful measure of similarity in that the higher the correlation, the smaller the imputation rmse. second, we find imputation via  <dig> database columns strikes a good balance between computation efficiency and imputation accuracy. using more columns does improve rmse, but the improvement diminishes. third and the most important, we compare logical-set imputation to meta-data imputation. we find that the meta-data approach always performs better, and the superiority can sometimes be astonishing . fourth, we calculate rmse for significant and non-significant genes separately, and we find that the former is generally a lot less than the later. that is, the meta-data approach provides smaller rmse for the important set of potentially significant genes, and thus lessens the impact of imputation on downstream analyses. sometimes the improvement in rmse is very dramatic. when combined, these results provide strong support for the application of meta-data imputation before data analysis.

a potential issue in meta-data imputation is the possible presence of lab-specific effects. typical normalization may not totally remove these effects. to investigate this issue, one would need data from similar experiments conducted in different labs with some within-lab replicates. then the within-lab and between-lab effects can be properly delineated. at the moment there are not enough data in the public domain to facilitate such an analysis. this is an issue that may further improve imputation.

we construct a simple-to-use web-based tool for meta-data imputation of yeast, worm, and plant cdna microarray data. users need to prepare their data in a tab-delimited file format where the first row gives each column a label , the first column identifies the rows by unique identifiers, and the rest of the entries are pre-processed and normalized microarray data. the unique identifiers are yeast orf names, worm clone identifiers in the wormbase, or plant genbank accession numbers. missing entries are left blank or filled with "nan" . the file can be uploaded at the website and imputed data are displayed in the webpage. the computation time is linearly proportional to the numbers of rows and columns, and the number of missing entries. for the yeast with  <dig>  orfs, one column with  <dig>  missing entries takes less than  <dig> seconds to finish, if the load on the server is light.

CONCLUSIONS
the meta-data imputation is a general approach. its consistently superior performance for yeast, worm, and plant data suggests that it can be applied to other species as well. it is implemented in matlab scripts. academic researchers may obtain the scripts by contacting us, and then they can prepare their own database matrices and conduct high quality imputation without transmitting their new data over the internet.

authors' contributions
rj and mo designed the study. mo and hw wrote the matlab scripts and conducted the simulations. mo constructed the web tool. all authors participated in the preparation of the manuscript and approved its final form.

