BACKGROUND
gene regulatory networks  represent the interactions among genes which control the abundance levels of gene products that are necessary to respond to the cellular environment. grn reconstruction from expression data is a challenging problem in systems biology, not only because it suffers from high dimensionality and low sample size, as the number of genes is generally much larger than the biological samples, but also because biological measurements are extremely noisy. a variety of computational methods have been suggested to address this problem including regression methods  <cit> , graphical gaussian models  <cit>  and bayesian networks  <cit> . despite considerable progress in the field, current methods still give relatively poor results due to the noisy and sparse nature of the data or cannot be run on large datasets. hence, the problem is still an active field and much remains to be done to improve the reliability of the solutions without increasing the computational cost. the readers are referred to  for comprehensive reviews on the field.

exploiting other sources of knowledge is one reasonable way to address these issues. recent advances in biology provide various data sources such as chip-seq data, pathway data and sequence data, each of which can shed more light on the cellular processes underlying grns. for instance chip-seq data can reveal potential target genes for transcription factors . each of these sources is of course limited and noisy, and only gives a partial picture of gene regulation. however, taken together, they can help build a more robust description of the regulatory mechanisms, and reduce the effects of noise and sparsity in expression data. these pieces of information can be included in the process of grn reconstruction in the form of prior knowledge, i.e. a subjective  belief about how the network should look like. hence, the use of prior information in network inference is a growing trend in computational biology .

prior knowledge can be applied by discarding edges that are a priori unwanted, and enforcing edges that are a priori wanted. however we do not always have this level of confidence, particularly in biology where associations are difficult to establish. another way is to set a prior to  <dig> when an edge is wanted, and to  <dig> when an edge is undesirable. however not all sources of prior knowledge are reliable, and when combining several, there may be inconsistencies to resolve, so potential errors should be accounted for and uncertainty modeled. in addition, not all of the edges have the same level of confidence. for instance when using chip-seq data, not all potential target genes for a specific tf have the same probability to be functional. in this case, the binding affinity of tf to tf binding sites is a proper proxy for functionality which can be converted into a probability. we believe that soft priors, which represent the probability of existence of an edge, are better suited for our application.

prior information about gene interactions in grns is typically converted into a prior knowledge matrix b, in which each entry bij represents the confidence about the existence of an interaction between two nodes xi and xj  <cit> , where nodes represent genes. entries in b range from  <dig> to  <dig>  where  <dig> stands for the strongest belief in the absence of an edge and  <dig> for the strongest belief in the existence of an edge. if no information about the edge between xi and xj is available, bij is set to  <dig> . how to include this prior matrix into the reconstruction process depends of course on the algorithm used to construct the grn.

one of the most popular tools to model grns is bayesian networks . a bn is a graphical representation for probabilistic relationships among a set of random variables v={x <dig> …,xn}. the first component of a bn is its structure g, represented by a directed acyclic graph . a dag is a graph containing only directed edges and no cycles, and the skeleton of a dag is the dag itself where directionality has been removed. nodes correspond to the random variables in v and edges encode conditional dependencies over v. the second component of a bn is a set of distributions {pi)} that are respectively conditioned on the parents of xi in g, where a parent of xi is a node xj such that the edge xj→xi is in g. together, g and {pi} define a joint probability distribution p over v, written p=∏ipi).

a dag g and a probability distribution p are reciprocally faithful if and only if the conditional independencies  among the variables in v with respect to p are exactly those encoded by g. the faithful assumption in bns implies that there is an edge between nodes xi and xj in the skeleton of g if and only if for all y⊂v∖{xi,xj}, xi and xj are conditionally dependent given y. by logical negation, there is no edge between nodes xi and xj in g if and only if there exists a set of nodes y⊂v∖{xi,xj} such that xi and xj are conditionally independent given y. two variables xi and xj are conditionally independent with respect to a probability distribution p given a set of variables y, if p=pp which denoted as  and can be estimated from the data with a conditional independence  test.

learning methods to reconstruct the structure of bns mostly fall into two categories: score-based methods and constraint-based methods  <cit> . score-based methods search the space of all possible dags to identify the network which maximizes a penalized likelihood function. such algorithms include prior knowledge naturally through a prior distribution over the structure which can also serve as penalization. however these methods are computationally expensive and do not scale well.

constraint-based methods involve the repeated use of ci tests. under the assumption of faithfulness, if there is no y⊂v∖{xi,xj} such that  holds true, there is an edge between xi and xj. the naïve algorithm decides on the presence of an edge by conditioning on all possible y. however, the naïve approach scales poorly and becomes infeasible for large networks due to the super exponential growth of the number of tests with respect to the number of nodes.

most algorithms that allow prior knowledge fall into the class of bns. indeed bns can include prior information very naturally via a prior distribution over network structures. for instance imoto et al.  <cit>  define a prior distribution on network structures as a gibbs distribution in which the prior knowledge is encoded via an energy function. werhli et al.  <cit>  have extended their work to integrate multiple sources of prior knowledge and for each source express the energy function as the absolute difference between the network structure and prior knowledge matrix. however, these algorithms are not applicable for large networks because of their complexity. some other methods fall into the class of regularized regression where regularization is applied to regression methods to infer a limited number of edges, thereby favoring important ones  <cit> . one can also use prior information to define the training dataset for a supervised method which uses this information in order to guide the inference engine for the prediction of new interactions  <cit> .

the pc algorithm  <cit> , or pc, is a popular constraint-based method which drastically reduces the number of ci tests by avoiding unnecessary ones, thereby allowing the reconstruction of larger networks. in fact, it has been shown  <cit>  that pc scales well for sparse graphs and that, in the case where the number of nodes is much larger than the sample size, it is asymptotically consistent for finding the skeleton of a dag, assuming the data follows a multivariate gaussian distribution. however, by nature, the performance of pc relies heavily on the accuracy of its inner ci tests, which is not guaranteed in the presence of limited sample size and noisy data. if erroneous decisions are made, the output of pc depends on the order in which the variables are given.

in this work, we modify the pc algorithm to include prior knowledge. we first exclude the unlikely edges and then exploit the order dependency of pc by favoring unwanted edges for early testing, thus holding wanted edges out for late testing. the resulting algorithm is referred to as priorpc. prior knowledge is particularly advantageous when the quality of the ci tests is questionable, for example as mentioned above when data is high-dimensional and few samples are available, as is typical for gene regulatory networks.

the area under the receiver-operating characteristic curve  noted auroc and the area under the precision recall curve  noted auprc are used to evaluate all presented algorithms. following greenfield et al.  <cit> , our method priorpc is evaluated on one dataset containing bacillus subtilis expression data  <cit> , and two datasets from the dream  challenge, and for the e. coli and b. subtilis datasets only the nodes that are linked to at least one other node in the gold standard are considered for evaluation.

our results show that the precision of the networks obtained with priorpc is greatly improved over that of the networks obtained with pc, for every dataset. the performance further increases as the amount of prior increases, which shows consistency of our method. additionally, the method performs better than pc even when noisy priors are included in the prior matrix, which shows robustness. finally, the part of the network which is not subjected to prior knowledge is not negatively affected by the prior information on other edges. we also compare our result to a recently published work  <cit>  where they modify regression methods to incorporate the prior knowledge.

methods
the pc algorithm
the original pc algorithm is an unsupervised method which consists of two main steps: building the skeleton of the graph and determining the orientation of the edges. in the remainder of this manuscript, we will consider the skeleton only, and pc will stand for the first part of the original pc algorithm.

pc takes as input a set of variables v and an ordering order over v, and returns the skeleton of the graph g. it starts with a complete undirected graph, where all the nodes in v are connected to one another, and edges are then removed iteratively based on cis. for every ordered pair of adjacent nodes , all cis  where y is a subset of all nodes adjacent to xi are computed in order to find a set y∗ such that  holds true.

y is at first the empty set , then each variable xd in turn following order , then all possible pairs of potentials variables  following order  and so on, until a y∗ is identified or possible conditions have been exhausted. if a y∗ is found, then the edge between xi and xj is deleted. as the algorithm proceeds, the number of adjacent nodes decreases, and fewer and fewer tests are needed. assuming a faithful distribution to g and perfect ci tests, pc correctly infers the skeleton of g  <cit> , regardless of order.

the worst-case complexity of pc is o, where maxo is the maximum order reached in the algorithm. if we denote q the maximum number of neighbors of a node in g, then maxo∈{q− <dig> q}  <cit> . for reasons of computational effect, we set the maximum order q to a value of  <dig>  for sparse networks we expect this figure to exceed the number of actually occurring higher-order interactions, and, in fact, in all cases we have studied the algorithm finished before reaching it.

although order determines in which order the cis should be tested, it has no effect on the output if the ci tests are always correct. the standard choice, used in most implementations, is then the lexicographical ordering. in practice however, ci tests must be performed on the available dataset, containing a limited number of samples for all the nodes in v.

the distribution of the variables is assumed to be a multivariate gaussian, so cis can be inferred by testing for zero partial correlation  <cit> . let cor be the sample partial correlation between xi and xj given a set y⊆v∖{xi,xj}, obtained from any method including regression, inversion of part of the covariance matrix or recursion, and z=12log1+cor1−cor the fischer’s z-transform. the null hypothesis ℋ0:cor= <dig> is then rejected against the two-sided alternative ℋa:cor≠ <dig> at significance level β if |z|n−|y|−3>Φ−11−β <dig>  where Φ denotes the cumulative distribution function of a standard normal distribution  <cit> . in other word, pc uses the condition |z|n−|y|−3≤t to decide whether  holds true where t=Φ−11−β <dig>  in this manuscript we used corpcor r package  <cit>  to estimate the partial correlation.

the use of small-sample-sized and noisy datasets  in ci tests can induce many false positives and false negatives. moreover, in the presence of imperfect ci tests, the output of pc also depends on the significance level β, which allows to tune the sparsity of the resulting network but also increases the potential for errors. because of these inevitable mistakes, edges may be wrongly removed or kept, thereby changing the adjacency structure and affecting the edges that are considered for deletion and the ci tests that are further performed. therefore, the output of pc does depend on order, particularly when the number of nodes is large. this dependency has a cascading effect that can lead to a drastically different skeleton, rendering pc unstable. we use this weakness to our advantage and modify the ordering to include prior knowledge or/and data-based knowledge.

priorpc
priorpc injects prior knowledge into the learning process. it first defines a confidence score for each edge representing the initial belief about existence of the edge. if we know a priori that some edges do not exist in the network, removing them in the early stages of the algorithm leads to more reliable neighborhoods and to a better set of ci tests in the rest of the algorithm. similarly if we know a priori that some edges ought to be part of the network, keeping them as long as possible can lead to different neighborhoods and therefore to a different resulting skeleton. priorpc uses confidence score first to discard the worst edges and then to rearrange the ci tests such that edges which are less likely to reflect a real interaction are considered for ci testing first, while edges with a high belief to belong to the network are subjected to ci testing last.

including prior knowledge
we introduce a confidence score for each edge indicating the initial belief of existence of the edge which can be simply the prior associated with the edge. however, we do not have prior for all edges and sometimes the prior is not correct and we need the support of data for the edge as well. we define data score dij as the normalized multiplication of two z-scores resulting from the deviation of the correlation cor from the two distributions of correlations cor and cor. if c denotes the absolute correlation matrix, the unnormalized score is written eij=cij−μiσi×cij−μjσj, where μi and σi  are the mean and standard deviation of the correlation values between xi  and all other variables. this is similar to the clr score mij−μiσi2+mij−μjσj <dig>  <cit>  with correlation instead of mutual information. the data score is then obtained using dij=eijeiiejj=cij−μicii−μi×cij−μjcjj−μj. for the data score to be high, the observed correlation between xi and xj must be far from the average correlation involving xi and from the average correlation involving xj.

we define the confidence score sij of an edge xi−xj as sij=α×bij+×dij, where 0≤alpha≤ <dig>  bij is the prior associated with the edge and is directly read from the prior matrix b, and dij is a data-based score. while bij encodes our belief in the existence of the edge, dij indicates how well the edge is supported by the data. to have a high confidence score, an edge must be supported by the prior or the data. which source matters most depends on α.

discarding the worst edges
edges are ranked by decreasing confidence score sij. all edges after the top ne≃3×|e|, where |e| is the number of expected edges, are discarded. this number stems from the idea that the network should be sparse  <cit> , and from the three tier structure of the algorithm developed in the next section. this bold step replaces the zero-order ci tests in pc. indeed, the zero-order ci tests can also be seen as a deletion step where edges are ordered by decreasing marginal correlation rather than confidence score, and deleted one by one until the ci test reaches the desired threshold. this step is also comparable to a high penalty on the number of edges.

3-tier structure
after discarding the worst edges, the remaining ne edges are divided into three categories. we convert pc into a 3-tier algorithm, where in each tier a specific category of edges is tested for cis. we consider the top  <dig> of ne edges to be strong candidates, the bottom  <dig> to be weak candidates, and the remaining  <dig> to be average candidates. while pc runs all zero-order ci tests for all edges, then proceeds with the first-order ci tests and so on, priorpc performs all ci tests of order  <dig> to  <dig> for all weak candidates first, then for average candidates, and finally for strong candidates.

if the confidence score of a candidate edge and the subsequent group in which it falls is a good indicator, 3-tier pc can remove more false edges, and faster. for instance, if there is a false edge xi−xj for which  holds true, pc must perform several unnecessary first-order and second-order ci tests before getting to the relevant one. this is not only computationally expensive but also undesirable, because these unnecessary ci tests can cause multiple errors and lead to strong effects as discussed previously. instead priorpc removes the worst candidates at the very beginning, and the weak candidates earlier than the other candidates. this also leads to a more reliable neighborhood and ci tests when assessing strong candidates.

edge ranking by bootstrapping
to build smooth roc and pr curves, the algorithm can provide as output a ranking of the edges. note that this ranking is not the same as the one given by the confidence score. instead this ranking can be seen as a ranking a posteriori, where prior information and data structure have both been processed by the algorithm.

pc and priorpc do not naturally allow for such a ranking. to remedy that issue, we have chosen to apply bootstrapping and to post-rank the edges by their frequency of appearance when running a chosen algorithm several times. k sub-datasets dk are constructed from the original dataset d using bootstrapping  and then a chosen algorithm is applied to all k datasets. if k-fold bootstrapping is applied to pc for example, k networks are obtained, and an edge can appear any number of times between  <dig> and k. this number is used to create a ranking a posteriori of the edges and to produce the desired roc and pr curves.

we set k to  <dig> for all experiments. one could use the confidence score of edges to break the ties, however we rank them lexicographically. note that, to produce a network in the first place, a threshold for the ci tests is required. as detailed in supplementary material section  <dig> , this threshold was fixed to  <dig>  for all experiments and optimized neither for priorpc nor for each data set.

synthetic prior knowledge
for each experiment and for each dataset, the prior information matrix b is simulated from the gold standard network available depending on the needs. to assign a true prior to an edge xi−xj, we check the existence of that edge in the gold standard network. if the edge is present, the prior bij is randomly sampled from . to assign a non-informative prior to xi−xj, bij is set to  <dig> .

RESULTS
datasets
for the evaluation of the priorpc, we used three different datasets. two of them are from dream challenge. the dream challenge is an annual reverse engineering competition with the aim of fair comparison of network inference methods. participants are asked to generate a network structure for each dataset with a confidence score for each edge. in the following, we explain the three datasets in more detail. note, each dataset contains both time-series data and steady state data and we only use the steady state data. we used the gold standard of each data set to synthesize prior knowledge. 
a synthetic dataset from the dream <dig> competition . the data consists of  <dig> genes where any gene can be a regulator. the gold standard contains  <dig> interactions. the normalization was done by the dream organizers.

a real dataset from the dream <dig> competition  <cit> . the data includes a compendium of microarray experiments measuring the expression levels of  <dig> e. coli genes  under  <dig> different experimental conditions. normalization was done using rma  <cit> . dream <dig> challenge also provides a gold standard mainly come from regulondb  <cit>  consisting of  <dig> established gene regulatory interactions.

a set of  <dig> expression measurements of b.subtilis genes in response to a variety of conditions  <cit> . greenfield et al.  <cit>  normalized the data and compilated the overlapping probes into intensities and we used the data provided by them. the gold standard comes from subtiwiki  <cit>  which is repository of information for b.subtilis contains  <dig> interactions.



note that pc is not feasible for large networks with a small threshold for the ci tests and we compare priorpc to pc-lite. pc-lite is a variation of pc that removes edges with low correlation and keeps the ne edges with the highest correlation instead of doing zero-order tests , and then applies pc to these edges only. as it is shown in supplementary material sections  <dig> and  <dig> , pc-lite always outperforms pc. we set ne to  <dig>   <dig>   <dig> for dream <dig>  e. coli and b.subtilis respectively. in addition, in the supplementary material section  <dig>  we compare the results of the various steps taken between pc and priorpc in order to see the effect of each step.

effect of the parameter α
the value of α determines the degree of influence of the prior knowledge in the ranking of the edges. while α= <dig> means ranking the edges using prior knowledge only, α =  <dig> means using data only. figure  <dig> shows the performance of priorpc for different values of α. in this experiment, the prior matrix b contains only true priors, i.e. priors sampled in  for absent interactions.
fig.  <dig> performance of priorpc against α. the left subplot shows auprc, while the right subplot shows the auroc. pc-lite is plotted with triangles, while priorpc is plotted with circles. the different colors represent the different datasets. for priorpc, all edges have a true prior. priorpc outperforms pc-lite and its performance increases with α




priorpc performs well above pc-lite, even though priors were simply sampled between [ <dig> .5) or . these lists can be used as input for cytoscape  <cit>  to visualize the corresponding networks.

effect of the amount of prior knowledge
in order to assess the effect of the prior on the resulting network, the algorithm was given different amounts of prior knowledge. initially,  <dig> % of the edges were randomly selected and assigned a true prior as stated in section “synthetic prior knowledge”. for all other edges, the prior was set to  <dig> . the percentage of the edges with a true prior was then gradually increased until it reached  <dig> %. figure  <dig> shows the results for α= <dig> 
fig.  <dig> performance of priorpc against the percentage of edges with a prior. the left subplot shows the auprc, while the right subplot shows the auroc. pc-lite is plotted with triangles, while priorpc is plotted with circles. the different colors represent the different datasets. priorpc outperforms pc-lite and its performance increases with the percentage of edges with a true prior



here again, priorpc performs well above pc-lite, even though priors were simply sampled between [ <dig> .5) or  and bij be the true prior for the edge xi−xj, then bij^=bij−|eij| if xi−xj is a true edge and bij^=bij+|eij| if xi−xj is not a true edge. we assigned noisy prior to all edges with various standard deviations σ. clearly, the effect of the amount of noise  depends on the value of α. figures  <dig> and  <dig> show the effect of noise on the auprc and the auroc, respectively, for different values of α. the results indicate that priorpc is robust to a reasonable amounts of noise. clearly, the higher the amount of noise, the worse the performance. naturally, the results are less sensitive to noise for smaller values of α. indeed, when α is small, priorpc is still better than pc. based on the figs.  <dig> and  <dig>  if the reliability of the prior is not well known, we recommend α= <dig>  because this choice leads to a gain in prediction quality up to σ= <dig> .
fig.  <dig> performance of priorpc against σ for various αs in terms of auprc. all edges have a true prior. gaussian noise is added to all priors with various standard deviations σ. the different colors represent the result for various αs. the performance of pc is plotted in green and with full squares for comparison. for small standard deviations, priorpc performs better than pc-lite. this effect is not seen for large standard deviations since most priors are flipped

fig.  <dig> performance of priorpc against σ for various αs in terms of auroc. all edges have a true prior. gaussian noise is added to all priors with various standard deviations σ. the different colors represent the result for various αs. the performance of pc is plotted in green and with full squares for comparison. for small standard deviations, priorpc performs better than pc-lite. this effect is not seen for large standard deviations since most priors are flipped



for a fair comparison, we also followed the experimental set-up given in  <cit> .  <dig> % of the true edges were randomly selected and were given a prior in  which shows that priorpc is robust to false prior up to a ratio of true priors to false priors between 1: <dig> and 1: <dig>  depending on the value of α.

comparison of priorpc to men and bbsr
recently published work  <cit>  suggests two methods to use prior knowledge. for both methods, they limited the number of potential regulators for each gene to the union of the  <dig> highest-scoring predictors based on tlclr and all predictors with prior knowledge. the first method called men  is a modification of elastic net where prior knowledge is expressed as a modifier of the l <dig> constraint incurred on each single regression coefficient. this leads to less shrinkage on the regression coefficient corresponding to a putative regulation.

the second method called bbsr  is based on bayesian regression with a modification of zellner’s g prior. in this framework the prior on the regression coefficients follows a multivariate gaussian distribution centered at an initial guess with the empirical covariance matrix that is scaled by a chosen factor g, where g encodes the belief about the initial guess. they extend the original formulation of g and define a vector with one entry per predictor to allow for different levels of confidence for different entries in the initial guess. they use a criterion based on bayesian information criterion  to select the final model. since it is not feasible to compute all regression models, they reduce the set of potential regulators to the  <dig> best predictors based on average expected bic. for both methods, bootstrapping is applied in order to provide a final ranking of the edges.

bbsr and men take as input both steady state data and time series data and the output is a matrix with confidence level for directed edges. for a fair comparison we just take the skeleton and assign the highest confidence of corresponding directed edges to undirected edge.

the prior used in bbsr and men is not probabilistic, instead it is a hard score stating the strength of belief in the presence of an edge, with  <dig> for belief and  <dig> for no belief . the score  <dig> is assigned to the edges found in the gold standard network only. the rest of the edges are assigned the score  <dig>  the two methods are compared with their respective core methods and with state-of-the-art algorithms which do not contain any prior information. in each case, the inclusion of prior knowledge improves the accuracy of the inferred network.

we compare priorpc to these two methods. table  <dig> and  <dig> show the auprc and auroc results, respectively, from men and bbsr for different  parameters corresponding to the low and high use of prior as well as the results of priorpc for two different values of α. for the sake of comparison, we followed greenfield et al.  <cit> :  <dig> % of the true interactions in the gold standard network are selected and assigned a true prior .
e. coli
b.subtilis
for all three methods,  <dig> % of the edges present in the gold standard network were randomly selected and assigned a true prior . for priorpc, α is given in brackets. men and bbsr also use time-series data. results are comparable across the three algorithms

e. coli
b.subtilis
for all three methods,  <dig> % of the edges present in the gold standard network were randomly selected and assigned a true prior . for priorpc, α is given in brackets. men and bbsr also use time-series data. results are comparable across the three algorithms



the results show that on average priorpc performs as well as bbsr and men even without the use of time-series  data and merely using soft prior. note that none of priorpc’s parameters were tuned. priorpc is also fast and one bootstrap takes 1: <dig>  39: <dig>  6: <dig> min for dream <dig>  e. coli and b. subtilis respectively, when α= <dig> .

CONCLUSIONS
we presented priorpc, a variation of the pc algorithm which uses prior knowledge. priorpc defines a confidence score for each edge reflecting the prior knowledge. based on this confidence score, priorpc discards the most unlikely edges. this leads to a more reliable neighbourhood for doing the ci tests later in the algorithm. in the next step it exploits the order dependency of pc by rearranging the ci tests in order to favor less probable edges for early testing and to keep more likely edges for late testing. this dependency of pc is due to sparse and noisy data which affects negatively the performance of the ci tests. the larger the number of variables, the more impact the order has.

priorpc uses soft priors which assign to edges a probability of existence, rather than hard priors which give edges an existence state. we believe soft priors are more desirable as they can summarize the level of uncertainty the source associates with the edge, and the level of uncertainty associated with source itself.

priorpc is evaluated on three different datasets. although parameters are never tuned at any point of the experiments, priorpc produces a significant improvement in structural accuracy over pc for every dataset at hand. this improvement consistently increases with the amount of prior. moreover, in the presence of partial prior knowledge, the part of the network that has no prior is not badly affected by the partial prior.

the robustness of the algorithm to noise in the prior matrix, which is not avoidable in the context of biological data, was tested. the results show that in the presence of noisy priors, priorpc still performs better than pc up to a level of noise of  <dig> . this transition level depends on how strong the dependency to prior knowledge is, i.e. how high α is. similarly, if priors are flipped  rather than noisy, priorpc performs better up to a ratio of true priors to false priors between 1: <dig> and 1: <dig>  again this ratio depends on α. in practice, if the reliability of the available prior knowledge is questionable, it is advisable to use α= <dig> . this choice leads to prediction gain for reasonable amount of noise and false prior.

priorpc is fast and scales well while most bayesian network reconstruction methods which use prior knowledge are not feasible for large networks. these methods are mostly in the class of score-based methods and usually involve markov-chain-monte-carlo algorithm which is computationally expensive.

synthetic priors were generated in order to assess the algorithm. positive priors were randomly sampled between . as future work, it would be interesting to see how performance changes when using real priors. prior knowledge can be obtained from different sources including experimental data like chip-seq data, pathway databases such as kegg, protein-protein interaction data and even information derived from relevant literature. all theses sources of information can be included in a prior knowledge matrix representing the aggregated belief about gene interactions.

employing new experimental data for validation and testing of the algorithm is difficult because it would require yet another level of experimental data as a gold standard. this is why in this paper we have focused on synthetic data and on the dependence of the results under different kinds of perturbations. it remains an open question how to translate this to the real world, in that we cannot tell what noise level, e.g., a real chip-seq experiment would correspond to.

in this manuscript, we focused on the structure of the network and did not consider edge directionality. the accuracy of direction assignment critically depends on the structure. after a better skeleton is obtained, the second phase of the original pc algorithm can be applied to partially assign directions. it is also possible to adopt a hybrid  algorithm  <cit>  by first using priorpc to obtain an estimate of the grn structure and then use a score-based method to assign the direction and find the final network.

additional files
additional file  <dig> 
supplementary material. 

 additional file  <dig> 
list of the edges for dream <dig> data with
a
l
p
h
a
=0
.
 <dig>  

 

additional file  <dig> 
list of the edges for
e. coli
 data with
a
l
p
h
a
=0
.
 <dig>  

 

additional file  <dig> 
list of the edges for
b.subtilis
 data with
a
l
p
h
a
=0
.
 <dig>  

 

abbreviations
aurocarea under the receiver-operating characteristic curve

auprcarea under the precision recall curve

bnbayesian network

ciconditional independence

dagdirected acyclic graph

dreamdialogue for reverse engineering assessments and methods

grngene regulatory network

prcprecision recall curve

rocreceiver-operating characteristic curve

tftranscription factor

competing interests

the authors declare that they have no competing interests.

authors’ contributions

mg conceived and implemented the method and ran the experiments and drafted the manuscript. jl and mv contributed to the design of the study and edited the manuscript. all authors read and approved the final manuscript.

