BACKGROUND
the yeast saccharomyces cerevisiae, known popularly as bakers' or brewers' yeast, has been used extensively in aging research. it is a unicellular organism whose dna is packaged into chromosomes that are localized in a subcellular structure called the nucleus. since  <dig>  it has emerged as an important model organism for the dissection of the biological aging process at the genetic and molecular levels. saccharomyces cerevisiae was the first eukaryotic genome that was completely sequenced  <cit> .

nowadays, the word yeast is widely given to the species saccharomyces cerevisiae because of the place it occupies in biological research. large amounts of data related to it are genereted by life science and stored in multiple databases. biologists are brought systematically to query these sources in order to analyse the results of their experiments. they usually perform the following tasks during query formulation and execution:  look for appropriate sources where it is possible to find helpful data and specify their location,  identify the focus of each source,  query each convenient source independently using its specific access method and query language,  navigate through the sources to obtain complementary data, and  manuallymerge the results obtained from different sources. this is a tedious and time-consuming task for biologists, most of whom are not bioinformatics experts, and reduces the advantage that can be took of the available information.

the challenges of modern bioinformatics research is not only storing data in repositories, but also processing and integrating them. multiple solutions to biological data integration have been developed. researchers have come up with some approaches that integrate diverse biological data sources. two common approaches have being used to interoperate biological databases: data warehousing  approach  <cit>  and federated/mediator-based  approach  <cit> .

the data warehousing approach is adopted by numerous biological integration systems like gus  <cit> , atlas  <cit> , biosql  <cit> , biomart  <cit> , biowarehouse  <cit> , and chado  <cit> . this approach uses a data warehouse repository that provides a single access point to a collection of data, obtained from a set of distributed, heterogeneous sources. data from the remote heterogeneous databases are copied on a local server and the user will use a unique interface within the system to allow multi-database queries to be issued to this single interface. data warehousing requires the use of extraction, transformation and load   <cit>  tools to load data, and map it to a materialised global schema. in fact, warehousing requires that all the data loaded from the sources be converted through data mapping to standard unique format before it is physically stored locally. relying less on the network to access the data clearly helps to eliminate various problems such as network bottlenecks, low response times, and the occasional unavailability of sources. furthermore, using materialised warehouses allows for an improved efficiency of query optimisation as it can be performed locally  <cit> . another benefit in the data warehouse integration approach is that it allows the system to filter, validate, modify, and annotate the data obtained from the heterogenous sources and this has been noted as a very attractive property for bioinformatics. this approach however has an important and costly drawback in terms of reliability of results and overall system maintenance caused by the possibility of returning outdated results. warehouse integration must indeed regularly check all the underlying sources for new or updated data and then reflect those modifications on the local copy of the data  <cit> .

virtual integration  concentrates on query rewriting: it rewrites the user query, into queries that are understood by the integrated sources. the mediator uses the relationships between sources and a global schema to translate queries on the mediator schema to the data source schemata. the two main approaches for establishing the mappings between each source schema and the integration schema are global-as-view  and local-as-view   <cit> . in the gav approach the mediator relations are directly written in terms of the source relations. the gav approach greatly facilitates query reformulation as it simply becomes a view unfolding process. in lav approach every source relation is defined over the relations and the schema of the mediator. it is therefore up to the individual sources to provide a description of their schema in terms of the global schema, making it very simple to add or remove sources but also complicating the query reformultaion and processing role of mediator.

the mediator-based approach has several strengths compared to data warehouse. it does not have the updating problem as the query goes directly to the original source. mediators can be seen as a cheaper and more effective approach since they use schema or view integration, rather than having to have huge storage capacity to store copied data from all the involved data sources.

this paper presents a mediator-based system called yeastmed  <cit>  that aims to provide transparent access to disparate biological databases of yeast. it provides a unique interface between the user who submits a query, and a set of five data sources accessible via web protocols. yeastmed relies on sb-kom  <cit>  to perform the query transformation needed to reach the integrated data sources. these sources are: sgd  <cit> , yeastract  <cit> , cygd-mips  <cit> , biogrid  <cit>  and phosphogrid  <cit> . they provide complementary data on biological entities . with yeastmed, we aim to help biologists to get relevant data to understand and explain the biological processes of interest by using an integrative system.

this paper is organised as follows: an overview on some biological data integration systems is given in the next section. then, a general overview of the system and the resources used in yeastmed are given before to describe the integration process components along with some explanatory schemas. a detailed use case is then sketched describing how yeastmed proceeds when a user query is submitted. at the end, we discuss some advantages and limitations of the current version of yeastmed before to conclude the paper.

related work
works specific to the integration of yeast data sources are not abundant. however a variety of data integration systems especially tailored to cater for bioinformatics applications have been developed. these systems can broadly be classified as: data warehouses, federated/mediator-based systems and xml-based systems.

data warehouse systems
several attempts have been made to create integrated environments for storing and analysing biological data. for the sake of brevity, we sketch here two of them due to their relation to yeast.

cell cycle database  <cit>  is an integrated data warehouse for systems biology modelling and cell cycle analysis based on yeast and mammalian organisms. the system integrates information about genes and proteins involved in the cell cycle process. it stores complete models of interaction networks and allows the mathematical simulation over time of the quantitative behaviour of each component. the database integration system consists of a series of programs used to retrieve the data from several different external databases, transform and load them into the warehouse data model.

yeasthub  <cit>  is a prototype application in which a data warehouse has been constructed in order to store and query different types of yeast genome data provided by different resources in different formats including the tabular and rdf formats. once the data are loaded into the data warehouse, rdf-based queries can be formulated to retrieve and query the data in an integrated fashion. yeasthub is implemented using sesame  <dig>   <cit> . the tabular-to-rdf conversion is written using java.

these two systems present some limitations: they store the extracted data locally in a data warehouse or database which render the updating process a tedious task. yeasthub presents another problem where sesame does not have a way to identify the source of the triples  once they are loaded into the repository. in contrast, yeastmed accesses and interrogates data in its original data sources, and provides the user with the possibility to choose which data source entry to return. if the user doesn't make a choice, the system explicitly gives the provenance of the result entries.

federated and mediator-based systems
other alternative solutions have been proposed in biological data integration adopting a virtual approach. among them we can cite:

kleisli  <cit>  is as a mediator system encompassing a nested relational data model, a high-level query language, and a powerful query optimiser. it runs on top of a large number of light-weight wrappers for accessing various data sources. the kleisli system is highly extensible. it can be used to support several high-level query languages by replacing its high-level query language module. kleisli supports the collection programming language   <cit>  and a nested relational version of sql. however kleisli does not use any global schema or ontology over which a user can formulate queries. a query attribute is bound to a matched attribute in single source, so there is no integration across different sources.

discoverylink  <cit>  is a wrapper-oriented bioinformatics integration system built on the garlic project technology  <cit> . it serves as a middleware between the applications and a set of wrappers. applications connect to discoverylink and submit an sql query on its global schema. the wrappers provide source-specific information about query capabilities that help the optimiser to determine which parts of a query can be submitted to each source. the query optimiser considers the speed of various sources, their network connections, and the size of their data to predicate the costs of different plans. discoverylink, however, cannot deal with complex source data such as nested data. most biological data, unfortunately, are highly nested. therefore, there is a significant amount of mismatch between most data sources and discoverylink. furthermore, it is hard to add new data sources or analysis tools to discoverylink. in addition, discoverylink requires sql as its query language, which is not easy for biologists to write.

tambis  <cit>  is a mediator-based and ontology-driven integration system, it has three layers: the conceptual model, the mapping model and the physical model. in tambis, the formulation of queries is done through a graphical interface where user needs to browse through the different concepts defined in the global schema and select the suitable ones for particular query. as the first step, the system expresses the graphical query in grail  <cit> . then, the query is translated into a query internal form , which is in turn translated into a source-dependent query execution plan in cpl  <cit> . the global ontology is a unified conceptual-level representation of its registered component resources. it provides a global schema as well as an abstract framework for relating, reconciling, and coordinating the concepts in the sources. the mapping model converts a query phrased in terms of the conceptual layer into executable plans in terms of each source. the physical model submits the executable plans to different sources and retrieves the results. although tambis is more of an upper level solution than other systems, but its graphical interface is very complicated and requires that a user understands the query language. biomediator  <cit>  is a federated data integration system based on xml. it uses a mediated schema which allows for more flexible data modelling. the central component of biomediator system is its source knowledge base, which consists of descriptions of the various data sources, mappings from the source to the mediated schema, and the mediated schema itself. the system include also wrappers that conduct syntactic translations by translating the returned data results into an xml document, a metawrapper that conducts semantic translations by mapping the returned xml document onto the mediated schema, and a query processor that queries  against the mediated schema. biomediator is thus dedicated to users who know the xquery language and is not willing to be used by external research groups.

compared to these systems, yeastmed is the first data integration system which adopts the mediation approach to integrate yeast-specific data sources. it has a domain ontology which plays the role of the global schema and supports the user queries. unlike the systems cited above, yeastmed has an easy-to-use ontology driven interface where users express their requests in simple natural language. users do not need to know a specific query language to use it. in addition, due to its modular design, yeastmed furnishes the possibility to add easily new data sources or analysis tools.

xml-based systems
despite the possibility to use standard approaches for data integration  <cit> , specific approaches based on the employment of xml in bioinformatics have been proposed: 

automed  <cit>  is a heterogeneous data transformation and integration system which offers the capability of handling virtual, materialised and hybrid data transformation/integration across multiple data model. automed uses xml datasource schema  as a common representation language and schema type supporting the annotations for each source by suitable ontologies. an xmldss schema can be automatically extracted from an xml document or automatically derived from an accompanying dtd/xml schema if one is available.

the system approach is based on:  xml as a common representation format;  xmldss as the schema type for the xml documents input to and output by services;  correspondence to available ontologies; i.e. the services inputs/outputs are annotated with correspondences between the xmldss schema and some existing ontologies; and  automed toolkit to automatically transform the xmldss schema to output of a given service to the xmldss schema of the input of another service. 

swami  <cit>  defines a rich middleware architecture that integrate different databases, formats and computational resources. its architecture design includes a presentation layer that receives user requests, passes them to the core workbench application, and returns application results to user by the same route. the core application consists of four major components: the user module which receives data and instructions from the presentation layer. the broker module which interacts with the others modules via apis and serves as coordinator using a registry service that maintains information about all available services and databases. then the tool and data modules, which are conceptually identical, abstract respectively applications and databases, and perform their functions by orchestrating a series of services. xml is used for the declarative specification of services.

methods
yeastmed is a mediator-based system that consists of several components contributing to the data integration process in different ways. in this section we talk in detail about the process for creating the system by giving descriptions of its components and the role of each of them.

yeastmed overview
the general architecture of the yeastmed system is shown in . it consists of a set of components that have been implemented independently and play different roles. the access point to the system is a web interface that furnishes two search forms:

▪ a quick search form where scientists can quickly submit their requests based on some keywords . this type of search does not make use of the mediator. it exploits the yeastmed web services to look for information in the integrated data sources.

▪ an ontology-driven search form which allows biologists to express their requests in terms of the yeastmed ontology. these terms are presented in natural language to ease the query formulation process for biologists most of whom are not familiar with knowledge representation and query languages.

yeastmed relies on sb-kom  <cit>  to perform query transformation at execution time. once the user submits a request from the web interface, yeastmed generates a conjunctive query. sb-kom decomposes this query into suitable sub-queries to individual sources based on a set of mapping rules. these sub-queries are expressed in xquery, because the sources are accessed through web services using this query language.

yeastmed have a set of web services : one for each integrated source. these components receive xqueries from sb-kom and return xml documents. the role of the web services is to allow yeastmed to use wrapper functionalities to find and extract solicited information from data sources through their web pages or ftp mechanisms. answers, materialised by xml documents, to xqueries are sent to the mediator which combines them into a yeastmed ontology instance expressed in rdf. the final result is provided for the user in html format. data sources are also an important component in the yeastmed architecture because they are the providers of the biological information.

integrated data sources
in its current version, yeastmed integrates five yeast databases. they have been selected for having the most appropriate properties for studying saccharomyces cerevisiae, because they provide complementary data concerning genome, proteome, metabolome and reactome. these sources are:

▪ sgd database  <cit> : it contains the sequences of yeast genes and proteins, descriptions and classifications of their biological roles, molecular functions, subcellular localisations, links to literature information and tools for analysis and comparison of sequences.

▪ yeastract database  <cit> : it is a repository of regulatory associations between transcription factors and target genes, based on experimental evidence which was spread throughout bibliographic references. each regulation has been annotated manually, after examination of the relevant references. the database also contains the description of specific dna binding sites for a sub-group of transcription factors.

▪ mips-cygd  <cit> : aims in general to present information on the molecular structure and functional network of saccharomyces cerevisiae. in addition, the data of various projects on related yeasts are also used for comparative analysis.

▪ biogrid  <cit> : it is an online interaction repository with data compiled through comprehensive curation efforts. all interaction data are freely provided through the search index and available via download in a wide variety of standardised formats.

▪ phosphogrid  <cit> : records the positions of specific phosphorylated residues on gene products. where available for specific sites, phosphogrid has also noted the relevant protein kinases and/or phosphatases, the specific condition under which phosphorylation occurs, and the effect that phosphorylation has on protein function.

yeastmed user interface
the fact that biologists are familiar with html forms when interrogating biological databases, and in order to make yeastmed easy to use, we have adopted the same strategy that most biological databases are using to receive queries: a simple html-form-based interface has been developed permitting the queries to be expressed in natural language. it is an ontology driven interface. users formulate their queries by selecting items from the form fields. these items have their equivalents in the yeastmed ontology  and are written in natural language. for example the concept bibref in the ontology is translated in the form fields as bibliographic reference and the datatype property hasproductdesc as having product description. we are convinced that it is very easy for users to express in natural language their requests by using implicitly triplets composed of, those designed in the terminology of ontologies by, domain, property and range. for example, the user interested in the set of genes regulated by the transcription factor having the standard name adr <dig>  can express it using the two assertions: "gene regulated by transcription factor" and "transcription factor has standard name adr1". in this context, we have designed the yeastmed interface to capture these kinds of expressions. the query form proposes three fields per line. each line represents the triplet formed by: domain, property and range. range can be either a concept to select from the third field in a line or a literal value to introduce in a field that appears at the bottom of the second field if a datatype property has been selected in it. the example above can be captured in yeastmed interface using two field lines as follows: in the first line "gene" "regulated by" "transcription factor" and in the second line "transcription factor" "having standard name" "adr1" . when submitted, the system makes use of the equivalents of these in the ontology and creates the conjunctive query: ans:= gene, regulatedby, transcriptionfactor, hasstandardname before to send it to the mediator component.

the yeastmed web site also gives the possibility for users to use a quick search form to interrogate the five integrated databases without using the mediator. users simply enter their keywords in an input field, select the databases to be looked up and the system takes advantage of the yeastmed data services to access and extract data from the underlying sources.

data integration in yeastmed
yeastmed has a set of modules that depend heavily on xml and semantic web technologies to integrate syntactically and semantically biological data. in what follows, we give detailed information on these components.

source schemas
the knowledge modelling of the application domain of yeastmed constitutes the corner stone for an efficient integration. to that end, a detailed study of the sources has been carried out with the goal of establishing a standard terminology to describe the data. each data source has been modelled by an exported xml schema . an exported schema refers to translated source schema in the yeastmed ontology. these schemas are considered as models describing data and their organisation in data sources and define a structure under which results will be returned by data services.

data services
yeastmed uses a set of web services  to access data sources. we have developed one data service for each integrated yeast source. these components hide technical and data model details of the data source from the mediator. they receive xqueries from sb-kom and return xml documents in addition to other metadata. the role of yeastmed data services is twofold:

▪ allowing yeastmed to use the wrapper functionalities to find and extract solicited information from data sources using html protocols or ftp mechanisms. this means providing the ability to solve xqueries and return answers in xml format.

▪ exporting semantic information about data schemas and data provenance. this allows mainly yeastmed to keep track of the returned information when combining them and also which source is being interrogated.

it is common knowledge that a wrapper is an interface for a data source that translates data into the common data model used by mediators  <cit> . because the goal of yeastmed is to integrate databases accessible via web protocols, it is completely normal that a wrapper is considered as the most important component of the architecture of yeastmed data services. it is an interface that receives xqueries generated by sb-kom, accesses a specific data source, extracts data and translates them into the common data model used by sb-kom, i.e. xml .

in addition to the wrapper's query service, the web services encapsulate an application programming interface . it is the access point for sb-kom to the functionality of the web service. this api publishes three methods: getquery that passes to the wrapper the xquery q and returns its answer in an xml format. the xml structure of this answer must satisfy the constraints of the source schema. the other two methods, getschema() and getprovenance(), provide access to the metadata that the web service stores. the former returns the xml data schema and the latter provides information on the underlying data source. in order to use these methods correctly, sb-kom finds all the necessary information about them in a wsdl  document.

the data services have been implemented in java. they receive xqueries from sb-kom via the getquery() method of the api which passes it to the wrapper. this is materialised by a set of java classes that define several methods. the incoming xquery is analysed to identify precisely what information is solicited from the underlying data source. the wrapper then generates a source-adapted query following the query capabilities of the source already specified for each data source. then it establishes a connection to the data source via html or ftp protocols. in the case of html protocol, the data source is interrogated through its web interface using its query engine. the answer is one or several web pages which are parsed on the fly to extract the solicited data. in the case of ftp protocol, the data source is interrogated through its available flat files which are also parsed on the fly. a set of methods are defined to extract data from source answers and organize them as an instance of the xml source schema before to send it to the sb-kom in the form of an xml document.

yeastmed is able to reflect data provenance by calling the method getprovenance() which returns information about a source or through the xml document returned by data services: it contains by default a description of the interrogated data source. thus, instances with the integrated data can be annotated with the data provenance of each piece of information. in this way, the user interface could show users the provenance of each part of the results.

yeastmed ontology
as mentioned before, the goal of the yeastmed system is to help scientists to get information from multiple yeast data sources by providing a single access point. to that end, we have equipped yeastmed with a domain ontology. the primary purpose of this ontology is to support the user queries. queries are phrased in terms of the ontology and yeastmed converts these to xquery requests to the appropriate sources via data services. the yeastmed ontology has been constructed from scratch by reconciliating the different data source schemas into a single, coherent ontology.

the yeastmed ontology  <cit>  ensures semantic encapsulation of data sources by defining a concepts hierarchy. this is a classification of all the biological entities manipulated by the system. it represents a knowledge model that captures biological and bioinformatics knowledge in a simple hierarchical conceptual framework constrained by parent-child relationships : a child is a subset of a parent's elements; each child inherits all of its parent's properties but has more specialised properties of its own. overall, the ontology concepts can be classified into two categories: the purely biological concepts category and the source-related concepts category.

▪ the purely biological concepts category, which is a union of all the classes modelling biological entities found in the integrated data sources. as an example of this category, we cite chromosomalfeature concept. it is the superclass of  <dig> classes representing different types of chromosomal features .

▪ the source related concepts category is represented by concepts referring to sources. for example the concept source represents the five integrated data sources and the concept entry refers to entries in data sources. adding this category to the ontology has as the objective to permit scientists, when using yeastmed, to express their preferences on data sources. so, giving the possibility to determine which source entry they want yeastmed to return if a result is found rather than the system making its own choice.

to convey additional semantic information about the concepts, the ontology defines two types of properties. the first one is defined by a set of object properties that model the relationships that can hold between two individuals belonging to one or two different classes of the ontology. the second type concerns data properties: these are relationships linking an individual to a literal data.

to further illustrate the role of properties in conveying semantics to the yeastmed ontology, we detail a real-world example . swi <dig>  <cit> , having the systematic name yer111c, is a gene coding for a dna binding component of the sbf complex , a transcriptional activator that in concert with mbf  regulates late g1-specific transcription of targets including cyclins and genes required for dna synthesis and repair, an example is topoisomease i  <cit>  . from this we can make the following assertions:

▪ swi <dig> and top <dig> are two genes having the systematic names yer111c and yol006c;

▪ swi <dig> and top <dig> code respectively for a transcription factor and an enzyme;

▪ swi <dig> regulates the transcription activity of top1;

▪ both swi <dig> and top <dig> code for proteins .

these assertions let one define:

▪ four concepts: gene, protein, transcriptionfactor, and enzyme;

▪ four object properties: codesfor and its inverse property codedby linking gene to protein, in addition to the property regulates and its inverse regulatedby linking transcriptionfactor to gene;

▪ two datatype properties: hassystematicname and hasstandardname linking transcriptionfactor and enzyme to literal values of type string ;

▪ enzyme and transcriptionfactor as child concepts of protein.

in yeastmed, we have chosen owl  <cit>  as a standard ontology language to represent the ontology. owl is, like rdf  <cit> , taking advantage of the syntactic universality of xml. based on the rdf/xml syntax, owl provides a way to write web ontologies. it is different from the couple rdf/rdfs in the sense that is just a language of ontologies: if rdf and rdfs bring the user the ability to describe classes  and properties, owl incorporates, in addition, comparison tools for properties and classes: identity, equivalence, contrary, cardinality, symmetry, transitivity, disjunction, etc. thus, owl offers for machines a greater capacity of interpretation of the web content than rdf and rdfs  <cit> , with a wider vocabulary and a real formal semantics. to be more precise, we have contented ourselves with using owl-lite  because we have envisaged from the beginning to equip yeastmed with a simple domain ontology showing a simple concepts hierarchy and simple constraints.

mappings
having a domain ontology facilitates the formulation of queries to the system. the users simply pose queries in terms of the ontology rather than directly in terms of the source schemas. although this is very practical and effective in terms of the system transparency to the user, it brings the problem of mapping the query in the mediated schema to one or more queries in the schemas of the data sources. in yeastmed, this problem is solved using the functionality of sb-kom. so in addition to modelling the ontology and the sources, we needed to establish associations between the concepts in the ontology and the appropriate elements representing the information in the sources. these associations are materialised in yeastmed by the mapping rules.

sb-kom is designed to decompose queries based on gav approach-based mappings. that means each concept  in the ontology is a view defined in terms of the source schemas' elements. this view specifies how to obtain instances of the mediated schema elements from sources. in this context, the mapping rules we have used are defined as pairs . p is one or a couple of path expressions on a source schema expressed in xpath, and q a conjunctive query expressed in terms of the ontology terms. three kinds of mappings have been defined:

▪ class mapping: it maps ontology classes to source schemas. it has the following form:

xpath-element-location, ontology-class-name, correspondence-index

where xpath-element-location is the location of an element in the source schema, expressed in xpath; ontology-class-name is the name of the corresponding class in the ontology and correspondence-index is an integer value that informs on the correctness of the mapping instance. in yeastmed, this index is always  <dig> since all the mappings are done manually and not automatically. an example which maps the protein class to the sgd schema is as follows:

result/entries/entry/protein, protein,100

▪ datatype property mapping: it maps ontology datatype properties to source schemas. it has the following form:

xpath-domain-location; xpath-value-location, ontology-domain-name; property-name, correspondence-index

xpath-domain-location is the path to the element in the source schema which is mapped to the domain of the datatype property; xpath-value-location is the path to the element where the property takes the value of its range and ontology-domain-name and property-name are respectively the domain and the name of the property. the following example concerns the datatype property hasname:

result/entries/entry/protein; result/entries/entry/protein/sysname, transcriptionfactor;has name, <dig> 

 ▪ object property mapping: it maps ontology object properties to source schemas. it has the following form:

xpath-domain-location; xpath-range-location, ontology-domain-name; ontology-range-name; property-name, correspondence-index

xpath-range-location is the path to the element in the source schema which is mapped to the range of the object property. ontology-range-name is the range name of the property. the following example shows how the object property hasbibref is mapped to the source schema:

result/entries/entry/protein;result/entries/entry/literature, protein;bibref;hasbibref,100

sb-kom
yeastmed relies on sb-kom  <cit> , to perform query transformations at execution time. komf is a generic infrastructure to register and manage ontologies, their relationships and also information relating to the resources. this infrastructure is based on a resource directory, called semantic directory  <cit> , with information about web resource semantics. komf has been successfully instantiated in the context of molecular biology for integrating biological data sources  <cit> . sb-kom mediator is composed of three main components: the controller, the query planner and the evaluator/integrator.

the controller component receives requests coming from the yeastmed web interface and evaluates them to obtain a result for the requests. the controller creates different threads for different user requests, and assumes the role of the middleware between the mediator components. queries are expressed as conjunctive predicates  <cit> , with three main types of predicate: classes in terms of yeastmed ontology which is registered in the semantic directory, datatype properties that link individuals to data values, and object properties that link individuals to individuals. the results of these queries are instances of the yeastmed ontology which the query was expressed in.

the query planner component is by far one of the most fundamental pillars in elaborating one or several query plans to solve the query from different data sources. plans generated by this component specify the data sources from which the information can be retrieved and in which order they must be accessed. the evaluation of these queries depends on the query plans themselves.

according to the query , there will be different types of mapping in the semantic directory. classes will be connected to the xpath of one or several xml schema resource elements. on the other hand, datatype properties will be connected to those two expressions: the first one corresponds to the class and the second to the property. the object properties will be related to the active xpath classes in the property.

the query planner runs following a simple algorithm that receives as entry a conjunctive query expressed in terms of the yeastmed ontology  and returns a set of possible plan trees. the algorithm steps are enumerated below :

 <dig>  get all the query predicates  and distribute them in two groups based on the number of the arguments: Ɠ <dig> will contain predicates having one argument  and Ɠ <dig> will contain predicates having two arguments .

 <dig>  construct a set Ƈs of combinations between the two groups based on common arguments, add all the elements of Ɠ <dig> and Ɠ <dig> to it and eliminate the repeated ones.

 <dig>  eliminate from Ƈs the elements that do not have a representation in the mapping rules registered in the semantic directory.

 <dig>  for each instantiated variable in the predicate arguments, elaborate a plan tree:

a. the instantiated variable will construct a root node.

b. the elements that contain a predicate specifying a value for the instantiated variable and the elements that contain only the instantiated variable  will be passed to the current node and eliminated from Ƈs.

c. the elements that contain, in addition to the instantiated variable, another variable will constitute the edges leaving the current node to new nodes and eliminated from Ƈs. the newly created nodes will be represented by the other variables which will be the instantiated variables.

d. if there are still more elements in Ƈs and for each new instantiated variable we continue from the step  <dig> b.

the elvaluator/integrator is the third component of sb-kom mediator. it analyses the query plan , and performs the corresponding calls to the data services involved in the sub-queries  of the query plan. to answer yeastmed query, this component first executes the data services in the order specified by the query plan. then, it obtains the instances from the data service results. these instances are not interconnected because they have been produced by different data services. in order to retrieve a set of interrelated instances we need to establish relationships between them. this can be achieved by the object properties defined in the ontology that are used as relationships between services in the query plan. finally, these interrelated instances are filtered in order to eliminate the information not required.

use case
in this section, we show how a user query is solved by yeastmed, and how its different components take part in this process. let us take the case of a biologist who is using yeastmed to find information about two kinds of proteins. the first one is represented by dna topoisomerase iii, and the second one is indicated by some transcription factors regulating the expression of the first kind. the biologist is interested in the phosphorylation sites that are found in the sequences of the transcription factors of dna topoisomerase iii, especially the one  whose gene is located on the chromosome  <dig>  in addition, the biologist also aims to get all the literature on dna topoisomerase iii. as stated previously, yeastmed provides a web interface that allows biologists to express this kind of requests in terms of the ontology. the user can formulate its request in the yeastmed interface by selecting fields' items as follows:

"protein", "having description", "dna topoisomerase iii";

"protein", "having bibliographic reference", "bibliographic reference";

"protein", "regulated by", "transcription factor";

"transcription factor", "belongs to", "chromosome";

"chromosome", "having name", "16";

"transcription factor", "having phosphorylation site", "phosphorylation site".

to specify to the system what to return, the user should add checkmarks by clicking on the boxes above the fields where "bibliographic reference" and "phosphorylation site" were chosen before to submit its query.

the fragment of semantics that is implied directly in the formulating process of that query is shown in . from this fragment, a conjunctive query is generated automatically:

ans:= protein,hasdescription, bibref,hasbibref, hassystematicname, regulatedby,hasname,transcriptionfactor,chromosome,hasname, belongsto,phosphosite, hasphosphosite;"

this conjunctive query includes as predicates five ontology classes , three datatype properties  and four object properties . this query will return instances of phosphosite and bibref that satisfy its constraints.

as a subsequent step, the conjunctive query will be sent to sb-kom, received by the controller which will pass it to the query planner. this component has an algorithm that, based on the query predicates and the mappings of the semantic directories, will generate a set of sub-queries and also a plan to execute them. the predicates of the conjunctive query are divided into two sets: a set that contains predicates with a single argument and another that contains predicates with more than one argument. the predicates from the two sets which have common arguments are then grouped together into groups represented by the combination of two or more predicates. the groups that are not represented in the semantic directory mappings are discarded. the remainder is added to the first set allowing a group to be present only once.  lists all resulting groups.

for each group the mapping source is given.

from this set, the planner will try to construct potential trees of the execution order. it selects groups with variables instantiated in order to set a root for a tree. the order of the plan execution depends on the instantiated variables: the group containing an instantiated variable is executed first, then the groups that are related to those variables, and so on until all the groups are executed. in our case, g <dig> and g <dig> are selected. g <dig> cannot serve as a root, because there is no other group that depends on its instantiated variable which keeps the other groups without execution. this is not the case for g <dig> which serves as a root for the tree shown in . it is the first to be executed. this returns the protein that has as description "dna topoisomerase iii". then g <dig> and g <dig> are executed in parallel because they depend on the instantiated variable of g <dig>  from these simultaneous executions, the algorithm will determine all the objects that are related to protein by means of the relationships regulatedby and hasbibref. once those objects are obtained, it will check whether they satisfy g <dig> and g15: that means checking if the objects obtained from g <dig> and g <dig> are respectively of the type transcriptionfactor and bibref. based on the result of g <dig>  groups g <dig> and g <dig> are executed but not simultaneously. sb-kom has a plan optimisation module that might change the order of the initial plan execution as is the case here: since g <dig> has a variable instantiated  and is related to g <dig> via g <dig>  this one is executed before g <dig>  and the result is used by the group to be executed. the arcs of the planning trees generated by the planer represent object properties, while the nodes are ontology concepts or instances of these. each node and arc contains all the necessary information for the evaluator/integrator to execute sub-queries. that is: the xquery  corresponding to the sub-query of the node or the arc, the names and the urls of the data service of interest. an example is shown in .

the yeastmed data services are executed by the evaluator/integrator following the plan, after optimisation, generated by the planner. in our case, sgd data service receives the first sub-query, because the object property hasdescription is mapped to the sgd schema. top <dig> is returned as an answer of this sub-query and then is used by the sub-query regulatedby to find instances of transcriptionfactor. the yeastract data service is invoked this time because the property is mapped to the yeastract schema. three instances of the type transcriptionfactor are returned: fhl1p, hsf1p and swi4p. for each of these instances, the yeastract data service is called again. it receives this time the sub-query represented by the property belongsto that contains the two arguments instantiated: the first one is one of the three instances returned by the previous query, and the second argument is instantiated by the name of the chromosome  <dig>  this sub-query checks whether the transcription factor has its coding gene on the chromosome  <dig>  only the instance fhl1p is maintained. finally the sub-query hasphosphosite is executed on the phosphogrid data service that returns all the phosphosite instances of the transcription factor fhl1p. at each execution, the evaluator/integrator receives results in xml format from the target data services.

these results are instances of the xml schemas of the underlying sources. based on the mapping between the elements of the source schemas and the elements of the ontology, these xml schema instances are translated into ontology instances which are not interconnected because they have been produced by different data services. to associate them, the evaluator/integrator uses just the instances of the domain and range classes of the object properties. the final result is an ontology instance that includes all the data extracted from the interrogated data sources. that is all the instances of the concepts bibref of the protein top <dig> and all the phosphosite objects of the transcription factor fhl1p.

RESULTS
we have conducted a usability assessment in order to grade how well biologists can learn and use yeastmed to achieve their goals and how satisfied they are with the system. we have also conducted a performance study of the system to reveal how run times behave towards the increase of the number of implied data sources in queries. in this section we present results obtained from these two studies.

system usability
a variety of methods have been reported in the literature for assessing the perceived usability of interactive systems. we can particularly cite quis  <cit> , sus  <cit> , csuq  <cit>  and microsoft's product reaction cards  <cit> . tullis and stetson  <cit>  reported a study that compared these methods and showed that the accuracy of the analysis increases as the number of participants gets larger  and that the accuracy of sus increases quicker than the others. for that, we have used sus method in our study. the sus questionnaire consists of  <dig> items to which participants rate their level of agreement. odd-numbered items are positively worded and even-numbered items are negatively worded. a 5-point scale of agreements numbered from  <dig>  to  <dig>  is used for each. each item's score contribution will range from  <dig> to  <dig>  for odd-numbered items, the score contribution is the scale position minus  <dig>  for even-numbered items, the score contribution is  <dig> minus the scale position. to get the overall sus score, which is the indicator of usability, the sum of the item score contributions is multiplied by  <dig> . sus scores ranges from  <dig> to  <dig>  with  <dig> representing a perfect score.

the usability study we conducted had two objectives:  having a general indicator on the usability of yeastmed, and  assessing the evolution of the system usability with the level of familiarisation to biological databases. this is represented, in our study, by the frequency of using biological databases of the participants. these objectives will let us  to grade how well biologists, in general, can learn and use the system and  how well we have succeeded to furnish an easy-to-use system for biologists who are familiar with html forms of biological databases.

there were a total of  <dig> participants. each one tested yeastmed before completing the sus questionnaire. all the participants are biologists spread over  <dig> groups with different levels of familiarisation to biological databases. these groups contained between  <dig> and  <dig> participants and are named following the participants frequency of using biological databases, i.e. never, rarely, sometimes, usually and always. for each participant we have calculated the individual sus score and then the mean score for each group was determined. as shown in , the usability of yeastmed increases with the familiarisation to biological databases: the mean sus score passes from  <dig>  for biologists who never used biological databases to  <dig>  for biologists who are always using biological databases with an overall sus score of  <dig> . with these scores, we can say that yeastmed, with its simple html form-based interface, is a system easy-to-use for biologists who are familiar to biological databases interfaces with a relatively lower usability for biologists with lower familiarisation.

system performance
to illustrate the performance of yeastmed, we present, in this section, the result of a study conducted on the run times of the three main stages of the yeastmed query processing: planification, execution and integration. the study concerned  <dig> queries distributed on  <dig> groups following the number of data sources participating in the query answer . all queries were run on a dual-processor  <dig>  ghz pentium  <dig> processor machine with  <dig> gb of memory. the objective of this study is not to provide a thorough performance analysis, but simply to show how run times behave towards the increase of the number of implied data sources. each query was executed in three instances before to calculate its mean run times for the three stages. the data sources implied in the multi-sources queries are called exactly one time for each query. this had the objective to give certain uniformities to the study.

 illustrates the obtained results. it shows that there are no big changes in the planification times when the number of the implied sources increases. the planification time passes from  <dig>  seconds for queries implying one source to  <dig>  seconds for others that call  <dig> sources. in contrast, the execution time behaves differently. it increases with the number of the implied sources. this was expected because the execution of sub-queries in yeastmed makes use of a set of web services which are not called simultaneously but serially due to the fact that the call of a web service might depend on the result of another. as to the integration run time, it shows also some increases but small compared to the execution run time. it passes from  <dig>  seconds for one-source-based queries to  <dig>  seconds for queries implying  <dig> data sources. in yeastmed, the integration stage is solicited even if just one source is implied. this is because, in addition to the integration process, it performs the transformation of the xml result returned by the web services to an rdf instance of the yeastmed ontology.

discussion
dynamic integration is a very important issue for traditional mediator-based systems. they are usually developed as monolithic systems and their architecture based on wrappers involves a high degree of coupling among the system components. they usually do not provide scalable and reusable solutions. by the modular design and the uncoupling of all the components of yeastmed, we have sought to break out of traditional mediation architecture and provide a flexible platform for integrating yeast data sources. the modular structure of the system reduces the costs of the system maintenance. the system can be easily extended to cover other sources. it is not required to rebuild the system from scratch. the new source components are built independently and then integrated in the system, i.e. publishing a web service underlying that source, adding semantic views on the source to the ontology, and publishing its mapping rules in the semantic directory. the rest of the system components are not touched. on the other hand, the fact that the system adopts a mediation approach avoids the updating problem when a change is made in a source at the level of data, because the system does not have a local copy of data. but when the change touches the structure of the flat files or the html pages from which yeastmed extracts data, the system will need to reflect this on its components, but only on the modified-source components: the modified-source schema, the mapping rules implying that source, the source-related entities in the ontology and also the web service of the source. the other source components are not modified and the system is not rebuilt from scratch.

relying on data services rather than classical wrappers offers the possibility of reusing them by other mediators or any other data accessing application. this is the case of the quick search service we are proposing in the web site of yeastmed. this service is an added value of the system architecture. it makes use independently of the data services to look for entries and direct access to the integrated data sources without passing through the system mediator.

while some mediator-based systems require a specific query language or propose a complicated graphical user interface  <cit> , the yeastmed mediator receives conjunctive queries expressed in terms of the ontology. even though we estimate that these are not very complicated for biologists to express their requests, we have proposed a simple interface where requests are expressed using natural language through simple forms. all the required translations to conjunctive queries are hidden from users.

it is known that biologists have their own preferences toward databases  <cit> . in yeastmed we take this into account by giving users the possibility to specify from which database they prefer to get answers. the yeastmed ontology includes some source-related concepts which permit the user to express preferences on data sources. for example, a user can specify sgd as a source from which to get entries by selecting sgdentry in the query form. specifying a data source does not mean reducing the constraints to be only applied on the data of that source. users can specify a source from which to get entries and apply constraints on related data from other sources. for example a user can ask for entries from sgd describing a chromosomal feature regulated by a transcription factor having the standard name rtg <dig>  this is translated into the following conjunctive query:

ans := sgdentry,describes, chromosomalfeature, regulatedby,transcriptionfactor,hasname;

in this conjunctive query, sgd entries are solicited, but all the constraints are made on data residing in yeastract . if the sgd entry has not been specified, the result entries will be returned by default from yeastract. yeastmed is able to find the equivalent of such entries  in sgd.

CONCLUSIONS
we have described yeastmed: an xml and mediator-based system that integrates five yeast databases which have the most appropriate properties for studying saccharomyces cerevisiae.

data services play an important role in the integration process of this system, where they are considered as an interface which receives queries, accesses to a data source, extracts data and translates them into a common data model used by sb-kom. in yeastmed, data services extract data mainly from flat files because most of the integrated data sources are accessible via ftp mechanisms and provide data in tabular or xml format. this reduces the costs of the maintainability of the system because flat files structures are not frequently target to changes.

in our system, the schema integrator is an ontology and the results are ontology instances. the use of the ontology and instances enables basic reasoning processes  to be later included. this will permit yeastmed to infer new relationships between the instances of the ontology when solving a user query and thus, discover new knowledge for the query answers. the final result is an ontology instance that includes all the data extracted from the integrated data sources. it is converted to an html format before to be presented to users.

the objectives expected from the yeastmed system are not yet all met. the system is still in its natal phase and additional work is undertaken to improve it. the system does not yet make all its ontology available to users when formulating queries. this is because it is not yet able to answer queries expressed in terms of some part of the ontology. in addition, the fact that the system answers only conjunctive queries limits the user requests expression; i.e. it is not able to answer queries using disjunction quantification .

list of abbreviations
api: application programming interface; cds: coding sequence; cpl: collection programming language; csuq: computer system usability questionnaire; cygd: the comprehensive yeast genome database; dtd: document type definition; etl: extract, transform, load; ftp: file transfer protocol; gav: global as view; go: gene ontology; gus: genomics unified schema; html: hypertext markup language; lav: local as view; mips: munich information center for protein sequences; owl: web ontology language; qif: query internal form; quis: questionnaire for user interaction satisfaction; rdf: resource description framework; rdfs: resource description framework schema; rna: ribonucleic acid; sb-kom: system biology khaos ontology-based mediator; sgd: saccharomyces genome database; sql: structured query language; sus: system usability scale; tambis: transparent access to multiple bioinformatics information sources; xquery: xml query language; xml: extensible markup language; xmldss: xml datasource schema: wsdl: web service description language.

competing interests
the authors declare that they have no competing interests.

authors' contributions
jfam, bdrh and kl carried out the initial purpose of using mediation-approach to integrate yeast data, followed and tested the work. ab and km performed the technical design, implemented and tested the system and drafted the manuscript. ind performed the design task and helped to draft the manuscript. ak ensured technical supervision and support. all authors read and approved the final manuscript.

