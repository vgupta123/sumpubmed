BACKGROUND
drug-target networks are receiving a lot of attention in late years, given their relevance for pharmaceutical innovation and drug repositioning purposes . although the amount of known interactions between drugs and target proteins has been increasing, the number of targets for approved drugs is still only a small proportion  from the human proteome  <cit> . recent advances on high-throughput methods provide ways for the production of large data sets about molecular entities as drugs and proteins. there is also an increase in the availability of reliable databases integrating information about interactions between these entities. nevertheless, as the experimental verification of such interactions does not scale with the demand for innovation, the use of computational methods for the large scale prediction is mandatory. there is also a clear need for systems-based approaches to integrate these data for drug discovery and repositioning applications  <cit> .

recently, an increasing number of methods have been proposed for drug-target interaction  prediction. they can be categorized in ligand-based, docking-based, or network-based methods  <cit> . the docking approach, which can provide accurate estimates to dtis, is computationally demanding and requires a 3d model of the target protein. ligand-based methods, such as the quantitative structure activity relationship , are based on a comparison of a candidate ligand to the known ligands of a biological target  <cit> . however, the utility of these ligand-based methods is limited when there are few ligands for a given target  <cit> . alternatively, network based approaches use computational methods and known dtis to predict new interactions  <cit> . even though ligand-based and docking-based methods are more precise when compared to network based approaches, the latter are more adequate for the estimation of new interactions from complete proteomes and drugs catalogs  <cit> . therefore, it can indicate novel candidates to be evaluated by more accurate methods.

most network approaches are based on bipartite graphs, in which the nodes are composed of drugs  and biological targets   <cit> . edges between drugs and targets indicate a known dti . given a known interaction network, kernel based methods can be used to predict unknown drug-target interactions . a kernel can be seen as a similarity matrix estimated on all pairs of instances. the main assumption behind network kernel methods is that similar ligands tend to bind to similar targets and vice versa. these approaches use base kernels to measure the similarity between drugs  using distinct sources of information . a pairwise kernel function, which measures the similarity between drug-target pairs, is obtained by combining a drug and a protein base kernel via kernel product.
fig.  <dig> overview of the proposed method. a the drug-target is a bipartite graph with drugs  and proteins . edges between drugs and proteins  indicates a known drug-protein interaction. the drug-protein interaction problem is defined as finding unknown edges  with the assumption that similar drugs  should share the same edges. b kronrls-mkl uses several drugs  kernels to solve the drug-target interaction problem. distinct kernels are obtained by measuring similarities of drugs  using distinct information sources. c kronrls-mkl provides not only novel predicted interactions as it indicates the relevance  of each kernel used in the predictions



the majority of previous network approaches use classification methods, as support vector machines , to perform predictions over the drug-target interaction space  <cit> . however, such techniques have major limitations. first, they can only incorporate one pair of base kernels at a time  to perform predictions. second, the computation of the pairwise kernel matrix for the whole interaction space  is computationally unfeasible even for a moderate number of drugs and targets. moreover, most drug target interaction databases provide no true negative interaction examples. the common solution for these issues is to randomly sample a small proportion of unknown interactions to be used as negative examples. while this approach provides a computationally trackable small drug-target pairwise kernel, it generates an easier but unreal classification task with balanced class size  <cit> .

an emerging machine learning  discipline focused on the search for an optimal combination of kernels, called multiple kernel learning   <cit> . mkl-like methods have been previously proposed to the problem of dti prediction  and the closely related protein-protein interaction  prediction problem  <cit> . this is extremely relevant, as it allows the use of distinct sources of biological information to define similarities between molecular entities. however, since traditional mkl methods are svm-based  <cit> , they are subject to memory limitations imposed by the pairwise kernel, and are not able to perform predictions in the complete drugs vs. protein space. moreover, mkl approaches used in ppi prediction problem  <cit>  and protein function prediction  <cit>  can not be applied to bipartite graphs, as the problem at hand. currently, we are only aware of two recent works  <cit>  proposing mkl approach to integrate similarity measures for drugs and targets.

drug-target prediction fits a link prediction problem  <cit> , which can be solved by a kronecker regularized least squares approach   <cit> . a single kernel version of this method has been recently applied to drug-target prediction problem  <cit> . a recent survey indicated that kronrls outperforms svm based methods in dti prediction  <cit> . kronrls uses kronecker product algebraic properties to be able to perform predictions on the whole drug-target space, without the explicit calculation of the pairwise kernels. therefore, it can cope with problems on large drugs vs. proteins spaces. however, kronrls can not be used on a mkl context.

in this work, we propose a new mkl algorithm to automatically select and combine kernels on a bipartite drug-protein prediction problem, the kronrls-mkl algorithm . for this, we extend the kronrls method to a mkl scenario. our method uses l <dig> regularization to produce a non-sparse combination of base kernels. the proposed method can cope with large drug vs. target interaction matrices; does not requires sub-sampling of the drug-target network; and is also able to combine and select relevant kernels. we perform an empirical analysis using drug-target datasets previously described  <cit>  and a diverse set of drug kernels  and protein kernels .

in our experiments, we considered three different scenarios in the dti prediction  <cit> : pair prediction, where every drug and target in the training set have at least one known interaction; or the ‘new drug’ and ‘new target’ setting, where some drugs and targets are present only in the test set, respectively. a comparative analysis with top performance single kernel approaches  and all competing integrative approaches  <cit>  demonstrates that our method is better or competitive in the majority of evaluated scenarios. moreover, kronrls-mkl was able to select and also indicate the relevance of kernels, in the form of weights, for each problem.

methods
in this work, we propose an extension of the kronrls algorithm under recent developments of the mkl framework  <cit>  to address the problem of link prediction on bipartite networks with multiple kernels. before introducing our method, we will describe the rls and the kronrls algorithms .

rls and kronrls
given a set of drugs d={d <dig> …,dnd}, targets t={t <dig> …,tnt}, and the set of training inputs xi  and their binary labels yi∈ℝ , with 1<i≤n, n=|d||t| . the rls approach minimizes the following function  <cit> : 
  j=12n∑i=1n)2+λ2∥f∥k <dig>  

where ∥f∥k is the norm of the prediction function f on the hilbert space associated to the kernel k, and λ> <dig> is a regularization parameter which determines the compromise between the prediction error and the complexity of the model. according to the representer theorem  <cit> , a minimizer of the above objective function admits a dual representation of the following form 
  f=∑i=1naik, 

where k:|d||t|×|d||t|→ℝ is named the pairwise kernel function and a is the vector of dual variables corresponding to each separation constraint. the rls algorithm obtains the minimizer of eq.  <dig> solving a system of linear equations defined by a=y, where a and y are both n-dimensional vectors consisting of the parameters ai and labels yi.

one can construct such pairwise kernel as the product of two base kernels, namely k,)=kdkt, where kd and kt are the base kernels for drugs and targets, respectively. this is equivalent to the kronecker product of the two base kernels  <cit> : k=kd⊗kt. the size of the kernel matrix makes the model training computationally unfeasible even for moderate number of drugs and targets  <cit> .

the kronrls algorithm is a modification of rls, and takes advantage of two specific algebraic properties of the kronecker product to speed up model training: the so called vec trick  <cit>  and the relation of the eigendecomposition of the kronecker product to the eigendecomposition of its factors  <cit> .

let kd=qdΛdqdt and kt=qtΛtqtt be the eigendecomposition of the kernel matrices kd e kt. the solution a can be given by solving the following equation  <cit> : 
  a=vec, 

where vec is the vectorization operator that stacks the columns of a matrix into a vector, and c is a matrix defined as: 
  c=−1vec. 

the kronrls algorithm is well suited for the large pairwise space involved on the dti prediction problem, since the estimation of vector a using eqs.  <dig> and  <dig> is a much faster solution compared to the original rls estimation process in such scenario. however, it does not support the use of multiple kernels.

kronrls mkl
in this work, a vector of different kernels is considered, i.e., kd= and kt=, pd and pt indicate the number of base kernels defined over the drugs and target set, respectively. in this section, we propose an extension of kronrls to handle multiple kernels.

the kernels can be combined by a linear function, i.e., the weighted sum of base kernels, corresponding to the optimal kernels kd∗ and kt∗: 
 kd∗=∑i=1pdβdikdi,kt∗=∑j=1ptβtjktj,  where βd=βd <dig> …,βdpd and βt=βt <dig> …,βtpt, correspond to the weights of drug and protein kernels, respectively.

in  <cit> , the author demonstrated that mkl can be interpreted as a particular instance of a kernel machine with two layers, in which the second layer is a linear function. his work provides the theoretical basis for the development of a mkl extension for the closely related kronrls algorithm in our work.

the classification function of eq.  <dig> can be written in matricial form, fa=ka  <cit>  and applying the well known property of the kronecker product, vec=vec <cit> , we have: 
 fa=ka=kd∗⊗kt∗vecqtcqdt=kt∗qtcqdtkd∗t. 

this way, we can rewrite the classification function as kt∗akd∗t, where a=unvec. using the same iterative approach considered in previous mkl strategies  <cit> , we propose the use of a two step optimization process, in which the optimization of the vector a is interleaved with the optimization of the kernel weights. given two initial weight vectors, βd <dig> and βt <dig>  an optimal value for the vector a, using eq.  <dig> is found, and with such optimal a, we can proceed to find optimal βd and βt. more specifically, eq.  <dig> can be redefined when a is fixed, and knowing that ∥f∥f2=atka  <cit> , we have: 
 u=y−λa <dig>   then, 
  j=12λn∥u−ka∥22+12at. 

since the second term does not depend on k , and, as y and a are fixed, it can be discarded from the weights optimization procedure. note that we are not interested in a sparse selection of base kernels as in  <cit> , therefore we introduce a l <dig> regularization term to control sparsity  <cit>  of the kernel weights, also known as a ball constraint. this term is parameterized by the σ regularization coefficient. additionally, we can convert u to its matrix form by the application of the unvec operator, i.e., u=unvec, and also use a more appropriate matrix norm . in this way, for any fixed values of a and βt, the optimal value for the combination vector is obtained by solving the optimization problem defined as: 
  minβd12λn∥u−mdβd∥f+σ∥βd∥ <dig> 

  md=kt∗akd1t,kt∗akd2t,…,kt∗akdpat 

while the optimal βt can be found fixing the values of a and βd, according to: 
  minβt12λn∥u−βtmt∥f+σ∥βt∥ <dig> 

  mt=kt1akd∗t,kt2akd∗t,...,ktptakd∗t. 

the optimization method used here is the interior-point optimization algorithm  <cit>  implemented in matlab  <cit> .

data
the datasets considered were first proposed by  <cit>  and used by most competing methods  <cit> . each dataset consists of a binary matrix, containing the known interactions of a determined set of drug targets, namely enzyme , ion channel , gpcr and nuclear receptors , based on information extracted from the kegg brite  <cit> , brenda  <cit> , supertarget  <cit>  and drugbank databases  <cit> . all four datasets are extremely unbalanced, if we consider the whole drug-target interaction space, i.e., the number of known interactions is extremely lower than the number of unknown interactions, as presented in table  <dig> 


in order to analyze each type of entity from different points of view, we extracted  <dig>  distinct kernels from chemical structures, side-effects, amino acid sequence, biological function, ppi interactions and network topology .


protein kernels
here we use the following information sources about target proteins: amino acid sequence, functional annotation and proximity in the protein-protein network. concerning sequence information, we consider the normalized score of the smith-waterman alignment of the amino acid sequence   <cit> , as well as different parametrizations of the mismatch   <cit>  and the spectrum   <cit>  kernels. for the mismatch kernel, we evaluated four combinations of distinct values for the k-mers length  and the number of maximal mismatches per k-mer , namely mis-k3m <dig>  mis-k3m <dig>  mis-k4m <dig> and mis-k4m2; for the spectrum kernel, we varied the k-mers length . both mismatch and spectrum kernels were calculated using the r packagekebabs  <cit> .

the gene ontology semantic similarity kernel  was used to encode functional information. go terms were extracted from the biomart database  <cit> , and the semantic similarity scores between the go annotation terms were calculated using the csbl.go r package  <cit> , with the resnik algorithm  <cit> . we also extracted a similarity measure from the human protein-protein network , obtained from the biogrid database  <cit> . the similarity between each pair of targets was calculated based on the shortest distance on the corresponding ppi network, according to: 
 s=aebd,  where a and b parameters were set as in  <cit>  , and d is the shortest hop distance between proteins p and p′.

drug kernels
as drug information sources, we consider  <dig> distinct chemical structure and  <dig> side-effects kernels. chemical structure similarity between drugs was achieved by the application of the simcomp algorithm  <cit>  , defined as the ratio of common substructures between two drugs based on the chemical graph alignment. we also computed the lambda-k kernel   <cit> , the marginalized kernel  <cit>  , the minmax kernel  <cit> , the spectrum kernel  <cit>   and the tanimoto kernel  <cit>  . these later kernels were calculated with the r package rchemcpp  <cit>  with default parameters.

two distinct side-effects data sources were also considered. the fda adverse event reporting system , from which side effect keywords  similarities for drugs were first retrieved by  <cit> . the authors introduced two types of pharmacological profiles for drugs, one based on the frequency information of side effect keywords in adverse event reports  and another based on the binary information  of a particular side-effect in adverse event reports . since not every drug in the nuclear receptors, ion channel, gpcr and enzyme datasets is also present on aers-based data, we extracted the similarities of the drugs in aers, and assigned zero similarity to drugs not present.

the second side-effect resource was the sider database <dig>  <cit> . this database contains information about commercial drugs and their recorded side effects or adverse drug reactions. each drug is represented by a binary profile, in which the presence or absence of each side effect keyword is coded  <dig> or  <dig>  respectively. both aers and sider based profile similarities were obtained by the weighted cosine correlation coefficient between each pair of drug profiles  <cit> .

network topology information
we also use drug-target network structure in the form of a network interaction profile as a similarity measure for both proteins and drugs. the idea is to encode the connectivity behavior of each node in the subjacent network. the gaussian interaction profile kernel   <cit>  was calculated for both drugs and targets.

competing methods
we compare the predictive performance of the kronrls-mkl algorithm against other mkl approaches, as well as in a single kernel context . in the latter, we evaluate the performance of each possible combination of base kernels  with the kronrls algorithm, recently reported as the best method for predicting drug-target pairs with single paired kernels  <cit> . this resulted in a total of 10×10= <dig> different combinations. the best performing pairs were then used as baselines in our method evaluation, selected according to two distinct criteria: the kernel pair that achieved the largest area under the precision recall curve  on the training set, and, a more optimistic approach, which considered the largest aupr on the testing set.

besides the combination of single kernels for drugs and targets, two different kinds of methods were adopted to integrate multiple kernels:  standard non-mkl kernel methods for dti prediction, trained on the average of multiple kernels ;  actual mkl methods specifically proposed for dti prediction.

non-mkl approaches
we extend state-of-the-art methods  for the dti prediction problem for a multiple kernel context. for this, initially we average multiple kernels to produce a single kernel . once we have a single average kernel , we adopt a standard kernel method for dti prediction, i.e., the base learner. in our experiments, two distinct previous combinations strategies are used: the mean of base kernels and the kernel alignment  heuristic, previously proposed by  <cit> . we will briefly describe the base learners, followed by a short overview of the two combination strategies considered.

the bipartite local model   <cit>  is a machine learning based algorithm, where drug-target pairs are predicted by the construction of the so called ‘local models’, i.e., a svm classifier is trained for each drug in the training set, and the same is done for targets. then, the maximum scores for drugs and targets are used to predict new drug-target interactions. since blm demonstrated superior performance than kernel regression method   <cit>  in previous studies  <cit> , we did not consider krm in our experiments.

the network-based random walk with restart on the heterogeneous network   <cit>  algorithm predicts new interactions between drugs and targets by the simulation of a random walk in the network of known drug-target predictions as well as in the drug-drug and protein-protein similarity networks. laprls and netlaprls are both proposed in  <cit> . both are based on the rls learning algorithm, and perform similarity normalization by the application of the laplacian operator. predictions are done for drugs and targets separately, and the final prediction scores are obtained by averaging the prediction result from drug and target spaces.

as said previously, most previous svm-based methods found on the literature can be reduced to the pairwise kernel method   <cit> , with the distinction being made by the kernels used and the adopted combination strategy. pkm starts with the construction of a pairwise kernel, computed from the drug and target similarities. given two drug-target pairs,  and , and the respective drug and target similarities, kd and kp, the pairwise kernel is given by k,=kd×kp. once the pairwise matrix is computed, it is then used to train a svm classifier.

the pkm  <cit> , kronrls, blm, nrwrh, laprls and netlaprls algorithms cannot cope with multiple kernels. for this reason, we consider two simple methods available for kernel combination: the mean of base kernels and the kernel alignment  heuristic  <cit> . the mean drug kernel is computed as kd∗=1/pd∑i=1pdkdi, and the same can be done for targets, analogously. ka is a heuristic for the estimation of kernel weights based on the notion of kernel alignment  <cit> . more specifically, the weight vector, βd for instance, can be obtained by: 
  βdi=akdi,yyt∑h=1pdakdh,yyt, 

where yyt stands for the ideal kernel and y being the label vector. the alignment a of a given kernel k and the ideal kernel yyt is defined as: 
  ak,yyt=k,yytfn〈k,k〉f, 

where k,yytf=∑i=1n∑j=1nijyytij. once such combinations are performed, the resulting drug and protein kernels are then used as input to the learning algorithm. we refer to the mean and ka heuristics appending the -mean and -ka, respectively, to each base learner.

multiple kernel approaches
similarity-based inference of drug-targets   <cit>  constructs a feature vector with the similarity values, where each feature is based on one drug-drug and one gene-gene similarity measure, resulting in a total of pd×pt features. each one is calculated by combining the drug-drug similarities between the query drug and other drugs and the gene-gene similarities between the query gene and other target genes across all true drug-target associations. the method also performs a feature selection procedure and yields the final classification scores using a logistic regression classifier.

gönen and kaski  <cit>  proposed the kernelized bayesian matrix factorization with twin multiple kernel learning  algorithm, extending a previous work  <cit>  to handle multiple kernels. the kbmf2mkl factorizes the drug-target interaction matrix by projecting the drugs and the targets into a common subspace, where the projected drug and target kernels are multiplied. normally distributed kernel weights for each subspace projected kernel are then estimated without any constraints. the product of the final combined matrices is then used to make predictions.

wang et al.  <cit>  proposes to use a simple heuristic to previously combine the drug and target similarities, and then use a svm classifier to perform the predictions. only the maximum similarity values of drug and target kernel matrices are selected, resulting in two distinct kernels. they are then used to construct a pairwise kernel, computed from the drug and target similarities. once the pairwise matrix is computed, it is then used to train a svm classifier. this procedure is also known as the pairwise kernel method   <cit> . for this reason, we refer to the approach proposed by  <cit>  by pkm-max.

the authors in  <cit>  suggest as further work a weighted sum approach. they suggest to learn the optimal convex combination of data sources maximizing the correlation of the obtained kernel matrix with the topology of drug-protein network. this objective can be achieved by solving a linear programming problem, as follows: 
 maxβdcorr,  where kd∗ correspond to the optimal combination of drug kernel matrices with weight vector βd, dist is the drug-drug distance matrix in the dti network, and corr represents the correlation coefficient. analogously, the same can be done for targets. we call this method wang-mkl.

experimental setup
previous work  <cit>  suggest that, in the context of paired input problems, one should consider separately the experiments where the training and test sets share common drugs or proteins. in order to achieve a clear notion of the performance of each method, all competing approaches were evaluated under  <dig> runs of three distinct 5-fold cross-validation  procedures: 
‘new drug’ scenario: it simulates the task of predicting targets for new drugs. in this scenario, the drugs in a dataset were divided in  <dig> disjoint subsets . then the pairs associated to  <dig> folds of drugs were used to train the classifier and the remaining pairs are used to test;

‘new target’ scenario: it corresponds in turn to predicting interacting drugs for new targets. this is analogous to the above scenario, however considering  <dig> folds of targets;

pair prediction: is consists of predicting unknown interactions between known drugs and targets. all drug-target interactionswere split in five folds, from which  <dig> were used for training and  <dig> for testing. some of the competing methods  were trained with sub-sampled datasets, i.e., we randomly selected the same number of known interactions among the unknown interaction set, since these methods cannot be executed in large networks  <cit> . although balanced classes are unlikely in real scenarios, we also performed experiments in context , using a sub-sampled test set, obtained by sampling as many negative examples as positive examples  <cit>  from the test fold. this experiment is relevant for comparison to previous work, since most previous studies on drug-target prediction performed under-sampling to evaluate predictive performance .2



the hyperparameters of each competing methods were optimized under a nested cv procedure, using the following values: for the svm-based methods , the svm cost parameter was evaluated under the interval {2− <dig> …,23}; for the kronrls-based methods, the λ parameter was evaluated in the interval {2− <dig> − <dig> …,230}. the σ regularization coefficient of the kronrls-mkl algorithm was also optimized in the interval { <dig> . <dig> . <dig> . <dig> }. the number of components in kbmf2mkl was varied in the interval r∈{ <dig> ,…,40}, and for the laprls and netlaprls we varied βd,βt∈{ <dig> , <dig> ,…,1}. in netlaprls we also considered two distinct values for γd <dig> γt2∈{ <dig> , <dig> }. for nrwrh the restart probability was evaluated in the set { <dig> , <dig> ,…, <dig> }. after the hyperparameters were selected for each method, the outer loop evaluated the predictive performance for the test set partition with the model built using the selected hyperparameters.

the evaluation metric considered was the aupr, as it allows a good quantitative estimate of the ability to separate the positive interactions from the negative ones. according to  <cit> , this metric provides a better quality estimate for highly unbalanced data, since it punishes more heavily the existence of false positives . this is specially true for the datasets considered, as demonstrated on table  <dig>  in which all datasets are extremely unbalanced.

RESULTS
paired kernel experiments
as a base study, we evaluate the performance of kronrls on all pairs of kernels . the aupr results of all pairs of kernels for the nuclear receptors, gpcr, ion channel and enzyme datasets are show in more detail in the supplementary material .

the performance of kronrls varies drastically with the kernel choice, as clearly demonstrated by the average performance of each kernel on the single kernel experiments . for nuclear receptors, the best kernel pair combination was spec-k <dig> and gip, while gip and sw performed best in all other data sets. it is also important to notice the impact of different parametrizations of the mismatch sequence kernel. its performance decreases as more mismatches are allowed inside a k-mer. overall, both versions of aers, simcomp, gip, minimax and sider drug kernels showed better performance, while lambda, marg, spec and tan performed worse. for targets, gip, go, mis-k4m <dig>  spec and sw kernels performed better than other target kernels.
fig.  <dig> average performance of each single kernel with the kronrls algorithm as base learner. the boxplots shows the aupr performance of drug and protein kernels across different kernel combinations



comparative analysis
in this section, we compare the competing methods in terms of aupr for all datasets. concerning kronrls, we will use the best kernel pair  with largest aupr as described in the previous section. this will serve as a baseline to evaluate the mkl approaches. results are presented in table  <dig>  in the pair prediction scenario, kronrls-mkl obtained highest aupr in all datasets. its results are even superior than the performance in comparison to the best kernel pair under the optimistic selection. the results of kronrls-mkl in pair prediction are statistically significant against all other methods , except from kronrls-ka and kronrls-mean, according to the wilcoxon rank sum test . concerning the subsampled pair prediction, kronrls-mkl achieved highest aupr in the nr and ic data sets, and sitar performed best in the gpcr and enzyme data. there it performed second, just after sitar . the highest aupr values obtained in the subsampled data sets in comparison to the unbalanced data sets clearly indicate that performing predictions in the complete data is a more difficult task. moreover, the number of positive examples was negatively correlated to the dataset size for the complete datasets.
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
best performing methods are indicated in bold. standart deviation is indicated in brackets. training of the pkm, sitar and wang algorithms was done with the balanced training set


†best on training


∗best on testing



in the ’new target’ scenario, blm-ka performed best in  <dig> of  <dig> datasets, followed closely by blm-mean and kronrls-mkl, demonstrating that the local svm model is more effective in such scenario. blm-ka performed better than all evaluated methods with the exception of blm-mean, kbmf-mkl, kronrls-ka, kronrl-mean and kronrls-mkl . in the ’new drug’ problem, kronrls-mkl obtained higher aupr in the nr and gpcr datasets, while blm-ka had higher aupr values in the ic and enzyme data. both kronrls-mkl and blm-ka had statistically significant higher aupr  than all other competing methods. in order to give an overview of the performance of the evaluated methods, an average ranking of the aupr values obtained by all methods across the four datasets is presented in table  <dig> 
single †
single ∗

†best on training


∗best on testing



methods also displayed distinct computational requirements. memory usage was stable accross all methods, except from the svm-based algorithms, which demonstrated quadratic growth of the memory used in relation to the size of the dataset . this is in part due to the construction of the explicit pairwise kernel . this fact turns such methods inadequate for contexts in which subsampling of pairs is undesirable.

we now discuss about computational time in the pair prediction scenario. the precomputed kernels approaches  were overall the fastest on average, with pkm-based methods requiring less time to train and test the models , followed by kronrls-based and laprls-based algorithms. kbmf2mkl and blm were the slowest, requiring more than  <dig> min on average at the same task. the lower computation time of the heuristic-based methods is explained by the absence of complex optimization procedures to find the kernel weights. kronrls-mkl took a little less time than kbmf2mkl, taking an average over the four datasets of  <dig> min. .

predictions on new drug-target interactions
in order to evaluate the quality of final predictions in a more realistic scenario, we performed an experiment similar to that described by  <cit> . we estimate the most highly ranked drug–target pairs as most likely true interactions, and performed a search on the current release of four major databases  and chembl  <cit> . as the training datasets were generated almost eight years ago, new interactions included in these databases will serve as a external validation set. we exclude interactions already present in the training data.

we trained all methods with all interactions present in the original datasets. in the specific case of blm and nrwrh, one model for drugs and another for targets was trained, and then the maximum score for each dt pair was considered for prediction. then, we calculated the aupr for each dataset separately, discarding already known interactions . the low aupr values of all methods indicate the difficulty in performing predictions in such large search space. an average ranking  of each method across all databases indicates that kronrls methods as best performing algorithms followed by single kernel approaches. it is also important to highlight the poor performance of blm-ka and blm-mean in this task. this indicates a poor generalization capacity of the blm framework to the drug-target prediction problem .
fig.  <dig> mean aupr ranking of each method when compared to the new interactions found on updated databases. the kronrls-based methods achieved superior performance when compared to other integration strategies



next, a more practical assessment of the predicting power of kronrls-mkl is done, by looking to the top  <dig> ranked interactions predicted by our method . we observe that the great majority of interactions  have been already described in chembl, drugbank or matador. we focus our discussion in selected novel interactions. for example, in the nuclear receptor database, the 5th ranked prediction indicates the association of tretinoin with the nuclear factor rar-related orphan receptor a . tretinoin is a drug currently used to treatment of acnes  <cit> . interestingly, its molecular activity is associated with the activation of nuclear receptors of the closelly related rar family.

medroxyprogesterone acetate
estrogen receptor 1
mifepristone
estrogen receptor 1
norethisterone
estrogen receptor 1
estradiol
progesterone receptor
tretinoin
rar-related orphan receptor a
metoprolol
adrenoceptor beta  <dig>  surface
clozapine
dopamine receptor d3
theophylline
adenosine a2a receptor
theophylline
adenosine a <dig> receptor
adrenaline
adrenoceptor beta 3
riluzole
glutamate receptor, ionotropic, kainate 2
verapamil
atp-binding cassette, sub-family c 
halothane
cytochrome p <dig>  family  <dig>  subfamily e, polypeptide 1
nifedipine
cytochrome p <dig>  family  <dig>  subfamily c, polypeptide 9
anhydrous caffeine
cytochrome p <dig>  family  <dig>  subfamily a, polypeptide 7
deferoxamine
cytochrome p <dig>  family  <dig>  subfamily a, polypeptide 11
methoxsalen
cytochrome p <dig>  family  <dig>  subfamily a, polypeptide 1
interactions found in kegg, drugbank, chembl and matador are marked as k, d, c and m respectively



this is also a good example to illustrate the benefits for incorporation of multiple sources of data. both rora and tretinoin do not share nodes in the training set. all targets of tretinoin have a high go similarity to rora  despite of theirr low sequence similarity . in addition, one of the targets rora is nr0b <dig> . this protein is very close to rora in the ppi network .

concerning ion channel models, prediction ranked  <dig> and  <dig> indicate the interaction of verapamil and diazoxide with atp-binding cassete sub-family c . abbcc <dig> is one of the proteins encoding the sulfonylurea receptor  and is associated to calcium regulation and diabetes type i  <cit> . interestingly, there are positive reports of diazoxide treatments to prevent diabetes in rats  <cit> .

evaluation of kernel weigths
the kernel weights given by kbmf2mkl, kronrls-mkl and wang-mkl, as well as the ka heuristic, can be used to analyze the ability of such methods to identify the most relevant information sources. as there is no guideline or gold standard for this, we resort to a simple approach: compare the kernel weights  with the average performance of each kernel on the single kernel experiments . first, it is noticeable that the ka weights are very similar to the average selection . this indicates that no clear kernel selection is performed. wang-mkl and kronrls-mkl give low weights to drug kernels lambda, marg, minimax, spec and tan and protein kernel mis-k3m <dig>  these kernels have overall worst aupr in the single kernel experiments, which indicates an agreement with both selection procedures. although the weights assigned by kbmf2mkl are not subject to convex constraints, as indicated by the larger weights assigned to all kernels, they also provide a notion of quality of base kernels. we can observe a stronger preference to the gip kernel, in all datasets, even though the algorithm assigned a high weight for the lower quality mis-k3m <dig> in three of the four datasets.
fig.  <dig> comparison of the average final weights obtained by the kernel alignment  heuristic, kbmf2mkl, kronrls-mkl and wang-mkl algorithms. as one can note, the ka heuristic demonstrated close to mean weights, while kronrls-mkl and wang-mkl effectively discarded the most irrelevant kernels



CONCLUSIONS
we have presented a new multiple kernel learning algorithm for the bipartite link prediction problem, which is able to identify and select the most relevant information sources for dti prediction. most previous mkl methods mainly solve the problem of mkl when kernels are built over the same set of entities, which is not the case for the bipartite link prediction problem, e.g. drug-target networks. regarding predictions in drug-target networks, the sampling of negative/unknown examples, as a way to cope with large data sets, is a clear limitation  <cit> . our method takes advantage of the kronrls framework to efficiently perform link prediction on data with arbitrary size.

in our experiments, the kronrls-mkl algorithm demonstrated an interesting balance between accuracy and computational cost in relation to other approaches. it performed best in the “pair” prediciton problem and the “new target” problem. in the ’new drug’ and ’new target’ prediction tasks, blm-ka was also top ranked. this method has a high computational cost. this arises from the fact it requires a classifier for each dt pair  <cit> . moreover, it obtained poor results in the evaluation scenario to predict novel drug-protein pairs interactions.

the convex constraint estimation of kernel weights correlated well with the accuracy of a brute force pair kernel search. this non-sparse combination of kernels possibly increased the generalization of the model by reducing the bias for a specific type of kernel. this usually leads to better performance, since the model can benefit from different heterogeneous information sources in a systematic way  <cit> . finally, the algorithm performance was not sensitive to class unbalance and can be trained over the whole interaction space without sacrificing performance.

endnotes
1http://sideeffects.embl.de/.

 <dig> nrwrh cannot be applied to the pair prediction  <cit> , by which this method was not considered in such context.

additional files
additional file  <dig> 
figure. single kernel experiments on the nuclear receptor dataset with the kronrls algorithm as base learner. the heatmap shows the aupr performance of different kernel combinations; red means higher aupr. 



additional file  <dig> 
spreadsheet.
p-values under pairwise wilcoxon rank sum statistical tests of all competing methods in pair, drug and target prediction tasks. 



additional file  <dig> 
supplementary tables. aupr results of competing methods under pair prediction setting considering subsampled test sets ; aupr results of predicted scores against new interactions found on current release of kegg, matador, drugbank and chembl databases ; average memory  usage during training and testing of competing methods ; average time  required to train and test the models with the competing methods . 



competing interests

the authors declare that they have no competing interests.

authors’ contributions

conceived and designed the experiments: an rp ic. performed the experiments: an. analyzed the data: an rp ic. all authors read and approved the final manuscript.

