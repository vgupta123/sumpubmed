BACKGROUND
statistical methods that take into account the dependencies introduced into comparative data by phylogenetic relatedness are fundamental to hypothesis testing and exploration in comparative biology  <cit> . each comparative method implicitly imputes to the evolutionary process some specific stochastic model  <cit> . the validity of phylogenetic comparative methods depends on the degree to which historical events can be accommodated by the underlying stochastic model of trait evolution, and a mismatch between model and reality can yield erroneous statistical results, especially in the reconstruction of inaccurate ancestral character states  <cit> . for this reason it is important to develop realistic stochastic models of character evolution .

the brownian motion model of evolution – in which the value of a continuous trait evolves by accruing incremental changes drawn from a random distribution with zero mean and finite constant variance, such that the sum of many increments is distributed according to a normal density  <cit>  – was introduced to model changes in gene frequencies by cavalli-sforza and edwards  <cit>  but now underlies  a range of popular methods for the analysis of continuous traits distributed over phylogenetic trees. in the realm of ancestral state reconstruction the value of a trait evolving across a phylogenetic tree can at all times be shown to be probabilistically distributed according to a normal distribution with variance depending only on tree topology and branch lengths  <cit> , while in the realm of regression analysis the model yields normally distributed residuals and a covariance matrix depending only on tree topology and branch lengths  <cit> , both cases giving rise to simple and analytically-tractable solutions. the brownian walk of a trait value can be regarded as a model of gradualistic neutral evolution since variation in the trait arises from a process of random drift over the branches of a phylogeny at a constant rate and without directionality. a further application thus involves identifying significant departures from the expectation of the brownian motion model as a means of detecting adaptive variation in the tempo and mode of trait evolution  <cit> .

we here describe a simple generalization of the brownian motion model of continuous character evolution which extends the model to include cases where increments to an evolving character may arise from a symmetric stochastic process but without assuming constant finite variance. not only is the brownian assumption of constant finite variance, to the best of our knowledge, unverified in existing biological systems, but its relaxation may better suit the domain of application of the standard brownian motion model, namely biological characters likely subject to some degree of selection, and in many cases it may offer a more robust form of statistical inference with respect to outliers in the data. broadly speaking, we conceptualize diversifying selection on continuous characters as causing an increase and purifying selection on such characters a decrease in the rate of evolutionary change. the relative frequencies of these forms of natural selection along with neutral drift are expected to generate — for sums of evolutionary increments over long periods of time — limit distributions with heavier tails than expected under the brownian motion model.

just as the limit distribution of sums of variates drawn from a distribution with constant finite variance is the normal distribution, so the limit distribution of sums of variates drawn from a distribution without fixed finite variance is the stable distribution  <cit> , which has the normal distribution as a special case and which otherwise is characterized by heavy tails, closure under convolution and, potentially, by skew  <cit> . stochastic processes and random walks with volatile variance and heavy tails have previously been modelled robustly using stable distributions in areas as diverse as the study of fractional diffusion  <cit> , earthquake forecasting  <cit> , signal processing  <cit> , animal foraging  <cit> , rainfall modelling  <cit> , commodity pricing  <cit> , real estate markets  <cit> , foreign exchange rates  <cit> , financial statistics  <cit> , image processing  <cit>  and telecommunications management  <cit> . landis et al.  <cit>  recently used a brownian motion model with lévy stable jumps to model jumps in the evolution of continuous traits. according to our view of selection resulting in the generation of evolutionary rate volatility we limit our attention in this paper to the symmetric zero-centred stable distribution parameterized by α, the index of stability and c, the scale. we model evolution using the stable generalization of brownian motion, the stable random walk  <cit> . the stable random walk shares some attractive properties of brownian motion, the most important being closure under convolution, such that the sum of several stable distributions is itself a stable distribution with the same α parameter. this closure under linear transformation contrasts with all other non-stable heavy tailed distributions, which may yield complex and analytically intractable mixtures in convolution. thus, after accumulating increments from a symmetrical zero-centred stable distribution, the value of an evolving trait is always probabilistically distributed according to a stable distribution with mean equal to the trait value prior to accumulation and with scale proportional to the number of increments, or in phylogenetic parlance the branch length.
figure  <dig> 
log probability densities of stable distributions with varying
α
, including the normal distribution  and the cauchy distribution  as special cases.

stable random walks with varying
α
, driven by accumulation of a single sample of  <dig> increments drawn from a uniform distribution between zero and one, transformed onto stable distributions using the inversion method  <cit> .




as a motivating example of how the accommodation of evolutionary rate volatility may affect the inference of evolutionary processes, we present a simple toy model of continuous character evolution on a phylogenetic tree with six tips. the values of an evolving character were simulated under the brownian motion model and values at internal nodes were reconstructed based on values at the tips only, first by fitting a brownian motion model and second by fitting a stable model using the method presented later in this paper. next, the value of the character on a single tip was artificially inflated by a factor of ten, to represent a bout of adaptive evolution  on the branch leading to that tip. again, values at internal nodes were reconstructed under both models. results are illustrated in figure  <dig>  both reconstruction methods yield similar ancestral states for the original brownian motion data, but differ for the manipulated data. the brownian motion model exhibits an “averaging effect” in which the apparently high rate of evolution resulting from the manipulation is distributed somewhat evenly over all the branches, causing a large increase in estimated ancestral states for several internal nodes. the stable model, however, can entertain rare increments of large magnitude, and so is not strongly affected by the manipulation; the apparently high rate of evolution on a single branch can be accommodated as a rare event in a heavy-tailed stochastic process.ancestral state reconstruction of data simulated under brownian motion. top row: phylogenies exhibiting ancestral state reconstructions; each tip is labeled with the known character state, while at each internal node, upper values represent the brownian motion maximum likelihood reconstruction and lower values represent the reconstruction under the stable markov chain monte carlo model to be described in this paper  on a single branch). bottom row: the marginal probability density derived from mcmc for the ancestral state assignment of the root node using unmodified  and modified  data; the brownian motion marginal probability density is grey and the stable margin probability density is black.



in this paper we describe the stable model and the procedures used to fit it to empirical data, with an emphasis on ancestral state reconstruction. we outline strategies for hypothesis testing and model selection. we apply the stable model to simulated data in order to estimate error rates of the model selection procedure, and also use it, alongside a number of alternative models, in an illustrative case study of ancestral state reconstruction based on a large dataset of mammalian body masses. finally we discuss the relationship between the stable model of trait evolution and a number of alternative extensions of the brownian motion model that have been proposed in the literature, and suggest avenues for further development.

methods
model
consider a rooted phylogenetic tree  which may or may not contain polytomies. a continuous character x evolves along the branches of , taking values b <dig> and b <dig> at the beginning and end, respectively, of each branch b. under the standard brownian motion model of evolution, the continuous character evolves by accumulating random independent increments drawn from a probability distribution with constant mean zero and constant finite variance σ <dig>  according to the central limit theorem, the sum of such increments along a branch b of length tb is probabilistically distributed according to a normal density with mean zero and variance tbσ <dig>  a density which we denote ϕ. given the independence of increments, and therefore of branches, the likelihood of an ancestral state reconstruction of a continuous character evolving under brownian motion is given by the product:
  l=∏bϕb2−b1;tbσ <dig> 

if the variance of the increment generating distribution is not constant and finite  then according to the generalized central limit theorem the limit distribution for the sum of random independent variates is not normal but falls into the more general class of stable distributions, parameterized by an index of stability α and a scale c. the symmetric stable distribution has probability density denoted s. following matsui and takemura  <cit> , the unit stable density with c= <dig> may be defined as:
  s=απ|α−1|x∫0π2gexp)dκ 

where
  g=xcosκsinακαα−1cosκcosκ, 

and the general symmetrical stable density s is a transformation of the unit stable density sxc;α,1/c.

one important property of the stable distribution is that the normal distribution is a special case with α= <dig>  for the zero-centred symmetrical cases treated here, we note that:
  ϕx;σ2=sx; <dig> σ <dig> 

furthermore, the sum of t variates drawn from a stable distribution s is distributed as sα,1α. thus, under a stable model of evolution, the likelihood of an ancestral state reconstruction of x is given by:
  l=∏bsb2−b1;α,1α 

which is functionally identical to eq.  <dig> when α= <dig> 

unfortunately, there is no analytical solution to the stable probability density function in eq.  <dig>  so it is necessary to employ numerical methods  <cit>  to calculate likelihoods of stable models. the model does not lend itself to direct maximum likelihood estimation of parameters due to the existence of a highly multi-modal likelihood surface and because arbitrarily high likelihoods can be obtained by setting b1=b <dig> for any single internal branch b and having c→ <dig>  a problem exhibited by other statistical models with non-constant variance  <cit> , and circumvented through the placing of an appropriate prior on the scale parameter that penalizes the approach to zero, and fitting the model using a bayesian approach. since numerical estimation methods are unreliable under extremely heavy tails   <cit>  we apply flat or triangular priors to the index of stability on the domain  <dig> <α≤ <dig>  and a loose inverse gamma prior on the scale parameter which has pr→ <dig> .

mcmc estimation
markov chain monte carlo  methods are widely used to estimate complex multivariate probability densities in numerous biological fields. the goal of such methods is to generate a sample from a probability distribution by constructing a markov chain that has the desired distribution as its equilibrium density. a common strategy is to utilize a metropolis-hastings sampler  <cit>  in which the statistical model is initialized with some set of parameter values θ, a new candidate parameter θ′ is generated by a symmetrical proposal distribution, and accepted as the next step of the markov chain with probability equal to p/p. we found that the metropolis-hastings sampler performed poorly in estimating ancestral states and parameters of the stable model due to the multi-modality of the local likelihood surface  and the non-independence of ancestral state values, which together generate numerous very small “islands” of high likelihood which are unlikely to be explored by the markov chain in a reasonable amount of time. this results from the fact that proposals generated by the metropolis-hastings algorithm are constrained by the proposal distribution to be close in value to the current parameter value. modified versions of the procedure, such as metropolis-coupled markov chain monte carlo  <cit>  did not yield any benefit.multi-modal conditional probability densities on phylogenies.
 a focal node in a phylogenetic tree has two children with trait values  <dig> and  <dig>  and a parent with trait value  <dig>  to which it is connected by branches of unit length.  the potentially multi-modal conditional probability density function describing the probability with which the focal node has some trait value given the values of its children and parent .



we found that implementation of a slice sampler  <cit>  manifestly improved the mixing of markov chains. new proposals under a slice sampler are drawn from the entire range of possible values of the parameter and are not restricted by a proposal distribution to be close in value to the current estimate. instead of accepting new proposals according to the likelihood ratio criterion, slice samplers accept all new proposals but tend to make proposals that have likelihood similar to the current likelihood of the chain. this allows large jumps across widely dispersed peaks in the multi-modal likelihood surface at each step of the markov chain, offering an “escape” from local suboptimal peaks in the likelihood surface. to be specific, each step of the chain involves the value of each individual parameter θi being replaced by a new value θi′ drawn randomly from the conditional probability distribution pθi′|θj,θk,….

the procedure for generating new proposals under slice sampling is a three-step process. first, the conditional proability of the current parameter, given fixed values for all other parameters in the model, p , is estimated. this is a numerical value between zero and one that is proportional to the likelihood of the current model. second, a random number y is drawn from the uniform distribution between zero and the calculated conditional probability. third, we identify the set of all possible parameter values which would have conditional probability pθi′|θj,θk,…greater than y and accept a new proposal at random from this set. if y is very close to the current conditional probability, the set of proposals with conditional probability greater than y will tend to include large numbers that fit the data better than the current model. selecting a proposal at random from this set would tend to increase the likelihood of the markov chain over time. however, when y is much less than the current conditional probability, the set of proposals with conditional probability higher than y will also include many candidates with lower likelihood, and selecting a proposal from the set would permit the chain to decline in likelihood over time. neal  has shown that the stationary distribution of such a markov chain constitutes a sample from the complete posterior distribution that we are attempting to characterize. critically, for a highly multi-modal posterior distribution, slice sampling permits large jumps away from suboptimal likelihood peaks even when the sampled distribution exhibits widely separated modes. the procedure is illustrated graphically in figure  <dig> slice sampling. an example of slice sampling updating the value of the focal node from figure  <dig> from θ
i to θi′. first, the conditional probability that the value of the evolving character at the focal node is equal to θ
i – given the other ancestral states and stable model parameters – is calculated. a random number y is drawn from the uniform distribution between zero and this conditional probability . the set of possible values of θi′ is estimated by bracketing regions around the modes of the distribution for which the conditional probability is greater than y . the new value θi′ is drawn as a uniform random variable from this set.



choice of priors
we specify prior distributions on the stable parameters α and c, denoted pr and pr respectively. we have found that choice of priors on the index of stability have little effect on the ancestral state reconstruction, while the prior on the scale parameter effects the smoothness of the posterior density . how should we choose appropriate priors for the monte carlo simulation? we believe that the brownian motion model is a useful null model for the evolutionary process. since the brownian motion model is a special case of the stable model it is conservative to choose priors that maximize the a priori likelihood of the brownian model fit. consider equations  <dig> and  <dig>  if we set α= <dig> and c=σ/ <dig> then the stable model will be identical to the inferred brownian motion model. so, priors with maximum likelihood at α= <dig> and c=σ/ <dig> are conservative with respect to the null hypothesis.

we use a uniform or triangular distribution between  <dig>  and  <dig> for pr. we do not permit α< <dig>  since numerical estimation methods are unreliable at this extreme of heavy tails  <cit> ; if a triangular rather than uniform prior is selected then its maximum is set equal to  <dig> 

we use an inverted gamma distribution for our prior on c, though of course in principle the stable model accommodates any reasonable priors that maintain 0<α≤ <dig> and c> <dig>  our choice of pr is motivated by the fact that the inverted gamma distribution has an appropriate shape for the scale of a stable distribution and, as the conjugate prior for a normal variance, it is commonly used as the prior on the unknown variance of a normal distribution with fixed mean  <cit> . it is defined as:
  g=bax−1−aexp−bxΓ 

with a> <dig> and b> <dig>  as suggested above, it seems conservative to suppose that the rate of evolutionary change with highest a priori likelihood should be the rate of change imputed by the neutral brownian motion reconstruction, denoted σ in equation  <dig>  this rate of evolution is readily calculated from ancestral states generated by a squared change parsimony ancestral state reconstruction or other methods; hence, the inverted gamma prior on the scale of the evolutionary process should have its mode at σ/sqrt <dig>  the mode of an inverted gamma distribution is defined as x=b/, so the values of the prior hyperparameters a and b should obey the following constraints: a=−1+b2/σ and b>σ/ <dig>  so, the value of a is entirely determined and the appropriate value of b is easily obtained by linear search or newton-raphson optimization, maximizing the likelihood of equation  <dig> 

in this way, our use of the brownian motion model as a null hypothesis allows us to choose directly some reasonable and conservative priors on the more general stable model, in which the brownian motion ancestral state reconstruction has highest prior likelihood. by default, the software accompanying this paper uses this approach, but can use custom values of the prior hyperparameters a and b upon request.

hypothesis testing and model selection
it is desirable to formulate a statistical model selection criterion to determine whether the stable model of continuous character evolution  fits the data better than than the brownian motion model , as a means of estimating the best possible ancestral state estimates and of testing the hypothesis that a set of character data at the tips of a phylogeny exhibits patterns consistent with departure of the evolutionary process from neutrality. for maximum likelihood approaches, akaike’s information criterion   <cit>  is a popular choice. however, since aic depends upon maximized likelihood, while our markov chain monte carlo procedure only generates a sample from the posterior  distribution of stable parameters and ancestral states, it is difficult to calculate akaike’s information criterion in this case.

there exist a number of bayesian generalizations of aic which may be calculated from posterior mcmc samples, most notably the deviance information criterion   <cit> . statistical deviance is a quantity that, for our purposes, can be defined as a measure of goodness of fit that is calculated at each step in the markov chain, and is equal to minus twice the log likelihood of the stable model specified at the focal step of the markov chain, i.e., d=−2logl. hence, a lower deviance indicates a higher likelihood and better fit to the data. akaike’s information criterion is equal to the deviance of the maximum likelihood model, offset by a penalty for complexity equal to twice the number of parameters in the model. in the absence of a maximum likelihood estimate of the deviance, dic makes use of d¯, the average deviance across all posterior samples from the markov chain, as its primary measure of goodness of fit. it is also possible to calculate a “base-line” measure of goodness of fit by calculating, for each parameter, the average value over all steps in the markov chain, and then calculating the deviance of this average model, denoted d^. if d¯ is much higher than d^, the implication is that the model being fit is highly complex, since parameter estimates during the chain must be oscillating around values far removed from their mean across the chain as a whole. the deviance information criterion encapsulates this notion of complexity in an “effective number of parameters” or pd equal to d¯−d^. so, while aic is defined as the deviance of the maximized likelihood plus the number of parameters, dic is defined as the average deviance across all posterior samples plus the effective number of parameters, or, d¯+pd.

our simulation studies indicated that in phylogenetic datasets pd did not increase sufficiently in line with tree size, resulting in over-fitting of stable models on large trees. this is likely because tree size is not incorporated as a component of model complexity in the information criterion. a bayesian predictive information criterion  developed by ando , which amounts to dic with a increased multiplier on the pd penalty, resolved this problem of over-fitting . specifically, we use the criterion d¯+2pd.

software implementation
efficient software for fitting the stable model to phylogenetic trees and their associated data was written in c++ and is available at http://www.sfu.ca/~micke/stabletraits.html as source code and also compiled for various operating systems. the software reports a posterior sample of ancestral state reconstructions and stable parameter values in a format compatible with the tracer software application  <cit> , along with the proportional scale reduction factor convergence diagnostic  <cit>  and bayesian predictive information criterion for assessment of model fit  <cit> . multiple chains are run on independent threads, or on independent processors in a cluster computing environment .

application to simulated and natural data
in order to assess the improvement  in quality of ancestral state reconstruction and the ability of statistical tests to identify biological characters that have evolved under a stable rather than brownian stochastic process, data were simulated under a variety of conditions. evolutionary increments were generated randomly from a stable model with unit scale and index of stability ranging from  <dig>  to  <dig>  in steps of  <dig> , on random phylogenetic trees with  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> tips generated under the yule model in mesquite  <cit> . this procedure gave rise to  <dig> experimental conditions, each consisting of  <dig> trees and simulated datasets, and varying in tree size and index of stability of simulated trait values. based on data at the tips, ancestral states were reconstructed using the modal posterior density estimate from mcmc, first with α fixed at  <dig>   and second with a free α . ancestral states were also estimated using the homogenous ornstein-uhlenbeck model for comparison. estimates of type i and type ii error rates under the bpic criterion were made for each tree size/stability condition. accuracy was assessed for brownian, stable and ou models by calculating variance of the inferred ancestral states from the true simulated states for each simulated dataset under each condition. we report here the median variance ratio of stable/brownian and stable/ornstein-uhlenbeck reconstructions within each experimental condition.

to provide a demonstration of the model’s application to real biological datasets, we made use of a supertree of mammalian species  <cit>  and fitted the stable model of character evolution to data on the log adult body mass of  <dig>  eutherian mammals . for purposes of comparison we also estimated ancestral states under two homogenous evolutionary models, the brownian motion model and the ornstein-uhlenbeck model, the latter estimates obtained by maximum likelihood search from parameter estimates generated by the slouch package in r  <cit> . finally we also inferred ancestral states using two heterogenous models, the time-heterogenous early burst model  <cit>  in which the rate of a brownian process increases or decreases exponentially in time, and the clade-heterogenous model of eastman et al.  <cit>  in which the rate of a brownian process is “inherited” within clades but allowed to occasionally shift in value on probabilistically selected branches of a phylogeny. the former ancestral state estimates were made by maximum likelihood search based on parameter estimates and scaled phylogenies derived from the geiger package in r  <cit>  while the latter ancestral state estimates were made by brownian motion maximum likelihood reconstruction on a tree with branch lengths scaled by the maximum posterior probability estimates of rates reported by the auteur package in r  <cit> . connections between these various models and the stable model are discussed below.

RESULTS
our analysis of simulated evolution on random phylogenetic trees indicates that biological traits derived from a brownian process can be statistically distinguished from those derived from a non-brownian symmetrical stable process on the basis of the bayesian posterior information criterion . this model selection criterion was found to be highly conservative, with a low rate of false rejection of the null hypothesis for trees of all sizes, but with the expected low power to detect small departures from the neutral brownian model on small trees.type i and type ii error rates resulting from stable versus brownian model selection using the bpic model selection criterion, with data simulated on trees of various sizes under stable processes with varying indices of stability


tree size 

error
α
25
40
60
90
130
175
235
325
440
600


in ancestral state reconstruction of traits simulated under brownian motion the stable model performed as well as the brownian model , with median squared error ratio ranging from  <dig>  to  <dig> , and better than the ornstein-uhlenbeck model, with median squared error ratio ranging from  <dig>  on the smallest tree to  <dig>  on the largest . for trees simulated under the stable process with α< <dig>  the stable model yielded more accurate ancestral state estimates, increasingly so for large trees and large deviations from brownian motion. for the most extreme index of stability considered here  the mean squared error under brownian motion reconstruction was from  <dig>  to  <dig> times higher, and under ornstein-uhlenbeck reconstruction from  <dig>  to  <dig> times higher, than the mean squared error under stable reconstruction.sum of squared errors in ancestral state reconstruction, median ratio of stable/brownian reconstruction error, with data simulated on trees of various sizes under stable processes with varying indices of stability


tree size 

α
25
40
60
90
130
175
235
325
440
600


tree size 

α
25
40
60
90
130
175
235
325
440
600


results of our analysis of a dataset of mammalian body masses are presented in table  <dig>  the maximum posterior probability estimate of the index of stability α was  <dig>  and the brownian motion model was soundly rejected in favour of the stable model under the bpic model selection criterion . the ornstein-uhlenbeck also fit significantly better than the brownian motion model  as did the multi-rate model of eastman et al.  <cit>  . in order to provide the entries in table  <dig> for early burst we inferred maximum likelihood ancestral states under the global parameter estimate reported by cooper and purvis  <cit>  in their broader study of mammalian body mass evolution: the early burst model did not differ significantly from the brownian motion model on this dataset.ancestral state reconstruction of adult female body mass  based on a dataset of  <dig>  eutherian mammal species means, under brownian motion , ornstein-uhlenbeck , early burst , eastman
et al
’s  heterogenous multi-rate  and stable  models



clade
reconstructed body mass 
fossil estimates 
bm
ou
eb
eastman
stable
reconstructed values are provided for the most recent common ancestors of extant taxa in the specified clades. the right column details a selection of oldest fossil taxa within each clade for which body mass estimates are available .



discussion
reconstructing a historical narrative of trait evolution over time is central to both the formulation and testing of hypotheses in evolutionary biology  <cit> . comparative phylogenetic methods do so in a formal framework using stochastic models of the evolutionary process that implicitly or explicitly assume some probabilistic distribution of ancestral states over internal nodes of a phylogeny  <cit> . brownian motion is a fundamental stochastic model of evolution which assumes that biological traits evolve by accruing incremental changes drawn from a random distribution with zero mean and finite constant variance. however, most evolutionary hypotheses of interest involve traits thought to be subject to selection leading to directional tendencies, relatively rapid grade shifts and convergent evolution. the resulting patterns may be at odds with the neutral drift modelled by brownian motion  <cit> . indeed, studies of the performance of ancestral state reconstruction using known ancestral states derived from fossil estimates  <cit>  or from taxa evolving sufficiently rapidly to be observed in real time  <cit>  indicate that a mismatch between the stochastic model and historical reality can result in incorrect estimates .

in this paper we have described a stochastic model of continuous character evolution based on a generalization of the brownian model of evolution that does not assume that the rate of evolutionary change is constant and finite. under these relaxed assumptions, the sum of increments accruing to an evolving character along each branch of a phylogeny is known to tend toward a stable limit distribution, which is identical to a normal distribution in the special case of brownian motion but otherwise has heavier tails . these heavy tails allow rare evolutionary increments of large magnitude to occur, resulting in a volatile evolutionary process characterized by occasional “adaptive” evolutionary shifts interspersed with neutral-like patterns of variation . stable parameters and ancestral states can be fit to biological data distributed over a phylogenetic tree using markov chain monte carlo methods. we have implemented software that makes use of a slice sampler  <cit>  to sample the posterior probability distribution of ancestral state assignments at each node and the values of stable parameters . the slice sampler is able to take advantage of our knowledge of the approximate location of modal regions to move across a multi-modal likelihood surface without becoming trapped in locally but not globally optimal regions . an additional benefit of the slice sampler is its adaptive step size, requiring no tuning of proposal distributions, which makes practical application of the method straightforward. our analysis of simulated data indicates that the bayesian predictive information criterion  provides a conservative test of the hypothesis of departures from neutrality  in an evolutionary process , and that the stable model estimates ancestral states with reduced error in comparison with the brownian motion model, when traits evolve by accumulating increments from a probability distribution without constant finite variance .

we found the stable model to fit the eutherian body-size data significantly better than the brownian motion model , suggesting the existence of departures from neutrality. under the stable model, the ancestral eutherian is relatively small; in line with fossil evidence , low body mass persists through early diversification of the superorders afrotheria, euarchontoglires and laurasiathera and the origin of various orders of small size such as primates, rodentia, lagomorpha, scandentia, afrosoricida and macroscelidea; large reductions in body size are rare, occuring in chiroptera, while large increases in body size occur with the origin of several modern orders of relatively large species including the ungulates , carnivora, cetartiodactyla, proboscidea and sirenia. the brownian motion model differs in several respects. first the brownian motion reconstruction of the ancestral eutherian’s body mass is an order of magnitude greater than the stable reconstruction; the brownian motion reconstruction thus posits significant reductions of body size prior to the evolution of orders of small body size including rodentia, scandentia, chiroptera, eulipotyphla and macroscelidea. as expected, the brownian motion model exhibits an “averaging effect” more generally, in which transformations in body mass are distributed somewhat evenly over the phylogeny, while the stable model permits large transformations in body mass to occur on a smaller subset of branches. for this reason, the ancestral state reconstruction of taxa ancestral to typically large species  are smaller under the brownian motion model, and the ancestral state reconstruction of taxa ancestral to typically small species  are larger under the brownian motion model. the tendency for ancestral state reconstructions to be weighted toward intermediate values is stronger under the brownian motion model than under the stable model since the former model vitiates against the inference of directional tendency.

a desire to model the adaptive evolution of continuous traits has given rise to a number of approaches that refine or extend the brownian model. we categorize these as homogenous approaches, in which the stochastic process underlying the generation of evolutionary increments to an evolving character does not vary across branches of a phylogenetic tree, versus heterogenous processes, in which the stochastic process varies across branches. one popular homogenous model is the global ornstein-uhlenbeck model of trait evolution  <cit> , in which the direction and rate of evolution at any time depends upon a selection coefficient and the degree of deviation of the trait’s current value from some global optimum or “phylogenetic mean”. this so-called “mean-reverting” process has been used as a model of stabilizing selection since deviation away from the phylogenetic mean is penalized under maximum likelihood reconstruction. our simulation studies indicate that the stable model estimates ancestral states with reduced error in comparison to the homogenous ornstein-uhlenbeck model, when traits evolve by accumulating increments from a probability distribution without fixed variance . the homogenous ornstein-uhlenbeck reconstruction of mammalian body mass  is in some respects intermediate between the brownian motion and stable reconstructions, with relatively small ancestors of orders with small body size and relatively large ancestors of orders with large body size. this can be interpreted in terms of the stabilizing selection model with an intermediate phylogenetic mean: the proposal of a small ancestral rodent  permits a tendency to evolve back toward the mean within the rodent clade, while the proposal of a large ancestral carnivore  permits the same tendency in the opposite direction within the carnivore clade. this pattern is most striking in the ancestral state inferred for afrotheria , where a large ancestor reduces the rate of evolution on branches leading ultimately to the large elephants and manatees while permitting many high-likelihood reductions of size toward the phylogenetic mean in small taxa such as afrosoricida and macroscelidea. this reconstruction for afrotheria seems unlikely and may lead us to suppose that a single phylogenetic mean for the entire eutheria does not form a realistic model of stabilizing selection.

cooper and purvis  <cit>  report success in fitting more complex heterogenous models to a larger set of mammalian body mass data. the ornstein-uhlenbeck model is easily extended to the heterogenous case by permitting more than one clade-specific phylogenetic means  <cit> , the number and phylogenetic position of such means being specified a priori or estimated from the data. various transformations of the phylogeny, such as raising all branch lengths to a constant power in order to approximate speciational change  <cit>  or somewhat ad hoc transformation of branch lengths to maximize the likelihood of a brownian model  <cit>  have also been used to generate implicitly heterogenous models. the early burst model  <cit> , also applied by cooper and purvis  <cit> , is interesting in generating rate heterogeneity by allowing the rate of a brownian motion process to vary over time, rather than across branches or clades. the rate of evolution is taken to be an exponentially increasing or decreasing function of node height, allowing a greater proportion of evolutionary change to occur early in the phylogeny or late in the phylogeny depending on the choice of an exponential scaling factor r. we applied the early burst model to our mammalian body mass dataset but did not identify a significant deviation from r=0; ancestral state estimates in table  <dig> are derived from a reconstruction based on r=− <dig>  estimated by cooper and purvis  <cit> . the concentration of more evolutionary change in basal branches of the phylogeny appears to allow rapid early deviation from the phylogenetic mean value, with the majority of ancestral taxa exhibiting marginally smaller body sizes, often more consistent with the fossil evidence, than under the brownian motion reconstruction, yet surprisingly with considerably less ordinal-level diversification than imputed by the stable model which does not build early diversification in to the stochastic process itself.

homogenous approaches offer a number of advantages over heterogenous approaches in that the latter category must not only infer the parameters of the stochastic process but also must infer the structure of rate heterogeneity over the phylogeny. especially when heterogeneity is associated with clades, over-fitting heterogenous models by positing too many rate shifts or clade-specific evolutionary regimes may become a danger. eastman et al.  <cit>  have proposed a heterogenous model of trait evolution that explicitly avoids over-fitting by sampling over model parameter values and the number of model parameters simultaneously. the model is an extension of the standard brownian motion model in which the rate of evolution is “inherited” over time but may undergo occasional shifts in value. each shift introduces a new parameter that is penalized in a reversible jump markov chain monte carlo algorithm. we found that the complexity of the reversible jump algorithm considerably increases the computational burden of fitting the model: for the body mass data considered here, the stable slice sampler accomplished around  <dig>  steps per minute on a modest dual-core home laptop, versus around  <dig>  per minute for the multi-rate model, without the need for a lengthy calibration of proposal densities beforehand. ancestral states reconstructed under the eastman model  were in broad agreement with other non-brownian methods presented here in imputing smaller early mammals, and were in close agreement with results of the early burst analysis.

in general, the stable model suggests a greater degree of ordinal-level diversification of mammalian body masses, and appears to accommodate a more volatile evolutionary process, than any of the other models considered here. for  <dig> of the  <dig> nodes listed in table  <dig> the stable model reconstructs the smallest body masses of any model, and for  <dig> nodes it reconstructs the largest body mass of any model, making the stable reconstruction consistent with the hypothesis of small early mammals and occasional marked ordinal-level enlargement. the ability of the stable model to accommodate striking variation in evolutionary rate, even more so than approaches such as that of eastman et al.  <cit>  explicitly designed to model such variation, is most apparent in the highly diverse and species-poor afrotheria, where the stable reconstruction involves the largest ancestral elephants and manatees yet the smallest afroinsectivores of any of the methods considered here. while the heterogenous ornstein-uhlenbeck model binds rate volatility to the structure of the phylogeny through the assumption of clade-specific phylogenetic means, and the eastman et al. rj-mcmc model binds rate volatility to the structure of the phylogeny through the “inheritance” of rate shifts from ancestral to descendant branches, the stable model through its homogenously heavy tails provides unstructured volatility that is able to concentrate the production of evolutionary variation onto relatively few branches scattered across the phylogeny.

the stable model is the simplest non-brownian model considered here, requiring only a single parameter in addition to the standard brownian motion model. the relative efficiency of the estimation procedure used to fit the stable model may make it attractive for analysis of very large trees or large sets of trees derived from bayesian phylogenetics. furthermore, deviation from the brownian model according to the bpic criterion may be used to provide independent statistical support for the adoption of one of the more complex heterogenous models currently available. rates imputed by the stable model may guide appropriate selection of branches for independent rates in such cases. in the mammal body mass data examined here, for example, the frequency distribution of standardized trait changes along branches of the phylogeny  indicates accelerated evolution at the origin of a number of clades including hyomys , tragulidae , manidae , megachiroptera , megadermatidae , solenodontidae , orycteropodidae  and hyracoidea , suggesting that these clades may merit their own phylogenetic mean values under a heterogenous ornstein-uhlenbeck approach. in order to determine whether such a model is useful in any particular case it is necessary, as with any stochastic model of evolution, to rigorously constrain the model empirically, and while the results presented here are primarily illustrative and to provide comparison across unconstrained models, we note that the low ancestral state inferences for extinct taxa at the root of rodentia, lagomorpha, primates, chiroptera and lipotyphla, and the high ancestral state inferences for taxa at the root of sirenia and elephantidae, appear broadly in line with fossil evidence.

while our homogenous approach may be associated with some advantages with respect to efficiency, simplicity and unstructured volatility, the heterogenous models such as early burst have the benefit of imposing an explicit evolutionary narrative on the process of trait diversification which may be useful for exploring and testing general hypotheses about historical processes  <cit> . heterogenous models typically involve the elaboration of a simple gaussian kernel to accommodate phylogeny- or time-structured variation in the evolutionary process. we suggest that in future work heterogenous stable models analogous to those considered above may be readily generated by directly replacing the gaussian kernel with the more general stable kernel, at the expense of a single parameter. stable ornstein-uhlenbeck processes, for example, are already well-characterized  <cit> . the stable model we introduce to phylogenetic evolutionary biology here may find other uses, for example in assigning substitution rates to edges on phylogenetic trees under relaxed clock models  <cit> . one primary obstacle to the replacement of gaussian kernels by stable kernels in models of continuous character evolution is that stable distributions have undefined variance  <cit> . methods making direct use of variance are typically used to detect correlated evolution between multiple continuous characters evolving on the same phylogenetic tree  <cit> . independent contrasts  <cit>  for example, generates standardized data points for each univariate character by scaling the increments accruing along paired branches of a phylogeny by the square root of the sum of branch lengths, which is proportional to the expected standard deviation of a brownian process. methods of phylogenetic regression  <cit>  extend least squares methods to multivariate phylogenetic data by incorporating branch length and topological information into the model’s covariance matrix. the fact that stable variance is undefined means that there is no stable equivalent to standard deviation or the covariance matrix. we note that regression and correlation models based on stochastic processes driven by non-gaussian stable perturbations have been implemented successfully in non-phylogenetic fields . these approaches raise the prospect that likelihood-based analysis of heavy tailed multivariate distributions may offer useful insights into future studies of correlated evolution of multiple continuous characters in evolutionary biology, since correlated evolution is precisely the kind of problem domain in which the putative brownian assumptions of neutrality and gradualism are likely to be invalid.

CONCLUSIONS
stochastic process models of evolution regard an evolving trait as accumulating, over time, random increments drawn from some underlying probability distribution. we have described a generalization of the brownian motion model in which the increment-generating function is a stable distribution characterized by heavy tails, which accommodates both the neutral drift associated with brownian motion but also occasional burst of rapid evolutionary change. simulation and empirical studies indicate that stable models can successfully be fit to biological data, and bayesian model selection criteria can be used to assess goodness of fit in comparison with the brownian motion model, which is a special case of the more general symmetrical stable distribution. the model presented in this paper is a homogenous model in which a single stochastic process, common to all branches of a phylogeny, gives rise to increments to evolving continuous traits. the approach may be contrasted with heterogenous models in which different evolutionary regimes are bound to different subtrees of a phylogeny, or arise stochastically across the branches of a phylogeny. while homogenous models offer simplicity and computational convenience, it is currently unclear whether such models – and even more highly parameterized heterogenous models of trait evolution – are capable of capturing adequately the richness and complexity of evolutionary processes in nature. we have made an empirical attempt to corroborate results from the stable model on the basis of published fossil data on extinct mammalian body masses. the various homogenous and heterogenous models are consistent in some respects but also exhibit marked differences in reconstructed ancestral states. a major line of future research should be to expand the availability of fossil and other historical data that would facilitate the empirical measurement of the distribution of evolutionary changes over time for known traits and phylogenetic trees. in general, we believe it is likely to be the case that models of continuous trait evolution should be tailored specifically for the empirical question at hand. the present research suggests that models of evolution incorporating heavy tails and volatile stochastic processes may be a useful addition to the toolset of biologists interested in traits exhibiting heterogenous patterns of diversification driven by adaptive evolution.

competing interests

the authors declare that they have no competing interests.

authors’ contributions

me and aoe conceived of the model, designed simulation studies and co-authored the paper. me wrote the software and conducted the analyses. all authors read and approved the final manuscript.

