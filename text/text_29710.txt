BACKGROUND
protein/gene name recognition   <cit> , is one of the most challenging tasks in biomedical text mining  <cit> . solving the problem of nr will allow for more complex text mining tasks to be addressed  <cit>  as it is a prerequisite for information extraction and advanced text mining  <cit> . one of the main reasons of the challenging is high variation of terms that are not explicitly reflected in biomedical ontologies  <cit> . it is common that biological entities can have several names. for example, pten and mmac <dig> refers to the same entity  <cit> . it was estimated that one-third of biological terms are variants  <cit> .

a number of important studies in this area include gapscore  <cit> , which examines the appearance, morphology and context of named entities before applying a classifier trained using these features . abner  <cit>  employed a conditional random field model and achieved precisions between  <dig> % to  <dig> % and recall between  <dig> % and  <dig> % for different target entities. other groups had attempted combinations of approaches to improve precision  <cit> .

abbreviation recognition  is related to nr and can be considered as a pair recognition task of a terminology  and its corresponding abbreviation from free text. in this manuscript, we denote "lf" to mean "the long form of the term" and "sf" to mean "the abbreviation or the short form of the term". since the name of most protein and gene names are rather lengthy, most researchers tend to abbreviate their names in published manuscripts. as a result, ar can serve as a precursor of a number of applications. for example, building a term index of a text database to retrieve articles of related interests  <cit>  or to link text-mined protein interaction networks  <cit> . hence, it seems plausible to use ar as a first-pass in ner. in the simplest sense, ar may be used to assist term boundaries of entity names in free text, such as reported in  <cit> .

ar is generally considered as a simpler problem than ner and had been shown by the performance of ar systems  <cit> . for example, stanford university's abbreviation server  <cit>  demonstrated 97% precision at 22% recall and 95% precision at 75% recall. abbre  <cit>  and the system by schwartz et al.  <cit>  achieved 96% precision with 70% recall, and 96% precision with 82% recall, respectively, while sarad system  <cit>  reported 95% precision with 85% recall. more recently, sohn et al.  <cit>  used a lf to sf matching algorithm similar to yu et al.  <cit>  and reported  <dig> % precision with  <dig> % recall. however, these performance measures are hardly comparable because each system was tested on different corpora  <cit> . although both chang et al.  <cit>  and schwartz et al.  <cit>  used the medstract gold standard evaluation corpus  <cit> , each had made undisclosed modifications to their test corpus  <cit> , resulting in difficulty in comparison. nevertheless, torii et al.  <cit>  performed a meta-study to compare the results of a number of ar systems and found that the sf-lf identified by each system is generally consistent with previous reports. in general, these systems can achieve excellent precisions but still have plenty of room for improvement in terms of recall. currently, schwartz et al.  <cit>  and sohn et al.  <cit>  demonstrated the best ar performance than other existing systems.

schwartz et al.  <cit>  used a 2-step algorithm for ar under the assumption that the sf-lf must exist in the same sentence. in the first step, identification of a possible sf-lf pair is initiated by the presence of a pair of brackets. it considered two cases - the lf is in the brackets or the sf is in the brackets. if it is likely that the sf is in the brackets, the second step is to search for the lf word boundaries in the sentence by morphological features. sohn et al. also used brackets to initiate the process of ar but ignored a list of common bracket-delimited structures, such as "". this is followed by filtering the potential sf-lf pairs using a set of pre-defined rules.

our approach to ar is based on machine-learning and exploits a novel set of rich features to describe properties of a potential sf-lf pair. in addition, the difference between our system and those of  <cit>  is that we can identify pairs with unused characters in the sf. for example, "ca5" and "ca v gene". our system also outputs the prediction probability to indicate the confidence of each identified sf-lf pair. tested on the ab3p corpus  <cit> , our system demonstrated a f-score of  <dig> % with  <dig> % precision at  <dig> % recall. we also annotated a corpus of  <dig> pubmed abstracts which was derived from biocreative ii gene normalization dataset. on our corpus, our system achieved f-score of  <dig> % with  <dig> % precision at  <dig> % recall. comparing to existing available ar systems  <cit> , our system outperformed them on both corpora and performs about  <dig> times faster than the best ar performance system  <cit> . all resources can be found on our website. by applying our system to extract all short form-long form pairs from all available pubmed abstracts, we have constructed bioadi, the most comprehensive dictionary of biological abbreviations online. mining bioadi reveals many interesting trends of bio-medical research.

methods
preparation of training data
we annotated a corpus of  <dig> abstracts from biocreative ii gene normalization dataset  <cit>  by a single person for consistency and exploited it to develop an ar system. hence, we denote this annotated corpus as "bioadi corpus." we followed the style and the annotation guideline of ab3p corpus  <cit> , in which sf and lf pairs are separated by "|"  to annotate each abstract. we focus on the following forms of sf-lf pairs:

 <dig>  lf is in front of sf, and sf is in brackets or square brackets, e.g. "hsp ";

 <dig>  sf is in front of lf, and lf is in brackets or square brackets, e.g. "heat shock protein ";

 <dig>  both sf and lf are in brackets or square brackets and separated by comma or semi-colon, e.g." ".

the sf-lf pairs adhered to one of these forms will be annotated as potential sf-lf pairs. the bioadi corpus includes  <dig> true sf-lf pairs and  <dig> synonym pairs which are marked with "//" in the beginning of each pair. the synonym pairs were not considered as valid sf-lf pairs and ignored in the following experiments. meanwhile, we also used the ab3p corpus for performance evaluation. it contains  <dig> true sf-lf pairs. some of them are synonym pairs, however.

both positive and negative instances were required for model training. in this study, annotated sf-lf pairs were used as positive instances in training data, and negative instances were automatically extracted from text. the extraction of potential sf-lf pairs was similar to the previous work  <cit> . however, constraints on character lengths or word lengths of sfs were not set, but numbered list indicators , , , , , ....) and common strings  were filtered out. potential sfs which do not contain any alphabetic character or contain certain symbols  were excluded. a potential lf can be composed of up to ten consecutive words preceding a potential sf in the same sentence, or in brackets or in square brackets following a potential sf which means that there are at most ten potential lfs of a potential sf, of which one of them is correct. each abstract was split into sentences by "sentence and paragraph breaker"  <cit>  before the automatic ar process. all potential sf-lf pairs were checked for existence in the list of positive instances. if not, the pairs acted as negative instances in training data.

feature extraction of sf-lf pairs
before training and testing the model, it is a pre-requisite applying to transform the pair into the form of a feature vector. in order to construct features from raw data , we defined four sets of features. the design of these features was originated from  <cit> , inspired by the previous works  <cit>  and carefully selected in our tests. the detail is as the following:

• string morphological features of sf and lf

we had selected the following binary features to describe the string morphology in order to extract and represent the literal information and character properties of each sf and lf. we had also used some features to demonstrate the position and amount of stop words in lfs. for example,

 <dig>  is the first letter of the string uppercase?

 <dig>  is the first letter of the string lowercase?

 <dig>  are all characters of the string all uppercase?

 <dig>  are all characters of the string all lowercase?

 <dig>  does the first word of the lf use the first letter of the sf ?

 <dig>  is the first word of the lf a stop word ?

 <dig>  is the first word of the sf a stop word ?

 <dig>  does the string contain numbers?

 <dig>  does the lf share the same numbers of the sf?

 <dig>  does the string contain greek alphabet?

 <dig>  does the lf start with the sf?

 <dig>  does the brackets or square brackets of the string pair well?

we also applied the discrete binary features to characterize the composition of each sf and lf, including:

 <dig>  is the number of stop words in the lf =  <dig>   <dig>   <dig>   <dig> ..?

 <dig>  is the length  of the string =  <dig>   <dig>   <dig>   <dig> ..?

 <dig>  does the string contain certain punctuation symbol?

 <dig>  the character pattern of the sf: first, to convert each consecutive uppercase or lowercase characters to "a" or "a" depending on whether they are uppercase or lowercase. second, to convert each consecutive digits to "1". third, to prune off other characters. this is followed by matching the converted string to a specified pattern. for example, the sf "rb1" matches the pattern "aa1".

• lf tokens

we used space and punctuations as delimiters to tokenize each potential lf into tokens. each token acted as a binary feature to represent token information of the potential lf. we also applied token bi-grams as binary contextual features of the potential lf.

• numeric features between sf and lf

we exploited this set of features to describe the mapping of sf letters to lf letters and the calculation of the character usage between sf and lf.

 <dig>  the number of characters of longest common subsequence of the sf-lf pair divided by the sf length   <cit> ;

 <dig>  same as  <dig> but with the string consisting of the first character of all lf tokens ;

 <dig>  the size of sharing character set between the sf and the lf divided by the size of character set of the sf;

 <dig>  the size of character set of the sf divided by the sf length ;

 <dig>  the shortest lf of the sf-lf pair extracted by schwartz's ar system  <cit>  that is equal to the lf;

 <dig>  same as  <dig> but ignoring numbers of the sf and lf ;

 <dig>  same as  <dig> but reversing both the sf and lf ;

 <dig>  same as  <dig> but ignoring numbers of the sf and lf ;

• contextual features of sf-lf pair

we generated contextual information of each potential sf-lf pair from the tokens which precede the sf-lf pair and are limited two tokens at most. those tokens acted as binary features respectively.

we also applied token bi-grams as binary contextual features of the sf-lf pair.

the total number of each of set of features and the total number of all features are listed in table  <dig> 

m, string morphological features; l, lf tokens; n, numeric features; c, contextual features

model training and testing
to test the performance of different learning algorithms in our feature set, we implemented four learning algorithms, including support vector machine, naïve bayes, logistic regression and monte-carlo sampling logistic regression. we took advantage of mallet  <cit>  to implement naïve bayes, logistic regression and monte-carlo sampling logistic regression and libsvm  <cit>  for svm. in this study, libsvm was incorporated into mallet to simplify the pipeline of experiments on various learning algorithms.

we also set a ruled-based filter in the post-processing step to clean up some easily fixed mistakes to improve the precision. the output sf-lf pairs were filtered by the following rules generalized from the inside tests:

 <dig>  if the length of the sf  is equal to one, the length of the lf  must not be large than one;

 <dig>  if the sf is equal to "s", the first letter of the lf must not be "s" or "s" ");

 <dig>  the brackets and parentheses of the sf and lf must pair well;

 <dig>  the lf cannot contain a semi-colon followed by a space;

 <dig>  the number of punctuations in the sf normalized by the length of the sf  must not be large than  <dig> ;

 <dig>  the pairs of bracket or parenthesis are at most two pairs;

 <dig>  the lf must not start with the sf;

 <dig>  the sf must not be a sequence or list indicator , , , , , ....);

since sohn's and schwartz's ar systems are available online, we were able to reproduce their systems at our local site. generally speaking, we used them without any modification in the whole process of system evaluation and comparison. we only made a necessary modification in the part of input and output of schwartz's system for handling the format style of the ab3p corpus.

RESULTS
in this study, we used a machine learning approach to sf-lf pair recognition instead of a rule-based approach  <cit> . four learning algorithms, logistic regression, monte-carlo sampling maximum entropy, support vector machine and naïve bayes, were tested.

learning algorithms and feature sets analysis
we evaluated the performance of the learning algorithms on both corpora . the performance of each algorithm was carried out using one corpus for model training and the other for model testing, vice versa. as tabulated in table  <dig>  our results showed that the f-scores of different learning algorithms tested on the bioadi corpus were between  <dig> % and  <dig> %. the performances on ab3p corpus were between  <dig> % and  <dig> %. the f-score difference among the learning algorithms trained using the ab3p corpus was larger than using the bioadi corpus suggesting that pairs of sf and lf were more irregular in the ab3p corpus  than in the bioadi corpus. our result also indicates that logistic regression and support vector machine with rbf kernel outperformed other algorithms in both precision and recall on both corpora with our feature set. as the precision of logistic regression being higher than svm with rbf kernel, the logistic regression algorithm was used to develop our ar system.

precision
recall
f-score
precision
recall
f-score
we evaluated the four sets of features on the two corpora with logistic regression. table  <dig> presents the performance of four trials on different combinations of four sets of features on both corpora. the f-scores of these trails range from  <dig> % to  <dig> % for the bioadi corpus and range from  <dig> % to  <dig> % for the ab3p corpus. comparing the trials with the highest f-score with the lowest one on both corpora, the trails with all features were four to five percent higher than the one with only morphological set of features. they also performed the best in both precision and recall on both corpora. that suggests our feature set is robust and reliable.

precision
recall
f-score
precision
recall
f-score
m, string morphological features; l, lf tokens; n, numeric features; c, contextual features

comparison with previous works
we compared our system to schwartz's and sohn's systems. each system was trained with the ab3p corpus before tested them with the bioadi corpus and vise versa. medstract gold standard evaluation corpus for evaluation  <cit>  was not used as past results with the corpus reported are all based on the different modification version annotated by each team  <cit> .

the results are shown in table  <dig>  the f-scores of the systems on the bioadi corpus were between  <dig> % and  <dig> %, while that on ab3p corpus were between  <dig> % and  <dig> %. the highest precision on both corpora were achieved by sohn's system, but the highest f-score and the highest recall on both corpora were achieved by our system. the f-score of our system was three percent higher than schwartz's system on the ab3p corpus. these results suggested that our system outperformed schwartz's and sohn's systems.

precision
recall
f-score
precision
recall
f-score
we performed a significant test to measure the confidence of our results. the null hypothesis is that our system and another system performs equally well. applying the bootstrap test, we tested one system against the another for f-score on both corpora with  <dig> repetitions. the results are shown in table  <dig>  compared against sohn's system, our system won  <dig> in  <dig> times of bootstrap tests on the bioadi corpus, and won  <dig> times on the ab3p corpus. the p-values was less than  <dig>  in both conditions; thus, rejecting the null hypothesis. comparing against schwartz's system, our system won  <dig> in  <dig> times of bootstrap tests on the bioadi corpus, and won  <dig> times on the ab3p corpus. the p-values was less than  <dig> , rejecting the null hypothesis. hence, our results suggested that our system is an statistically significant improvement over schwartz's and sohn's systems.

sampling
won
p-value
sampling
won
p-value
learning curve analysis
we were interested in the influence of training data size to the performance. we randomly selected  <dig> abstracts as test data from each corpus, with the rest of the corpus as training data. the models were trained using  <dig> randomly selected abstracts at the first iteration and increased the training data size by  <dig> randomly selected abstracts at each iteration. the system performance of each iteration were recorded and averaged after five repeated tests. the five tests used five different test data which consisted of  <dig> randomly selected abstracts. schwartz's and sohn's systems were tested as the control groups in the experiment. figure  <dig>   <dig> and  <dig> shows the results on the two corpora and merged corpus .

in addition, to test the influence of data size in a large set of training data, we merged both corpora to form a new dataset which contains  <dig> unique abstracts. figure  <dig> shows that the trends in precision, recall and f-score were similar to the results in figure  <dig> and figure  <dig>  as the data size increases, it is expected that our machine learning-based approach will continue to improve while no improvement will be observed for rule-based systems.

computational cost analysis
due to the rapid increase of biomedical articles, the throughput of an ar system is important for dealing with large quantities of articles. hence, we were interested in comparing the processing speed of three systems. the test platform is on a computer with intel core quad cpu  <dig>  ghz,  <dig> gigabytes of ram and 32bit linux system. the test time is defined as the elapsed cpu time between program invocation and termination. we tested the systems on four data sizes . the test results are shown in table  <dig>  the fastest system on all corpus size was achieved by schwartz's system. it only took  <dig>  seconds to deal with  <dig> abstracts. although our system took  <dig>  seconds to deal with that size of abstracts, it was more than  <dig> times as fast as sohn's system, which took  <dig>  seconds to process the data. on a larger scale,  <dig> , <dig> pubmed abstracts stored in our local database were processed. our system completed the whole process in  <dig> hours, suggesting that the efficiency of our system is acceptable to deal with large quantities of text for other text-mining applications.

analysis of mis-identification cases
in the analysis of false-positive  pairs produced by our system, the common fp pairs are due to partial match which has also been reported by previous works  <cit> . for example,

• "ppis|pump inhibitors" rather than "ppis|proton pump inhibitors"

• "ccr5|chemokine receptor 5" rather than "ccr5|c-c chemokine receptor 5"

other common types of the pairs missed by our system include out of order match  and partial match . there is another type of false-negative pairs reported  <cit> , which are with unused characters in the sf. most of them has been removed in the process of ar for false-positive reduction. however, we kept them and identified them with model prediction correctly. for example, our system can identify:

• "ca5|ca v gene"

• "fth1|ferritin heavy-chain gene"

bioadi
to construct a comprehensive biological abbreviation dictionary, we identified sf-lf pairs from  <dig> , <dig> pubmed abstracts. the final ar system for this purpose is trained by the bioadi corpus. therefore, we expect that its f-score can reach about 90%. we did not include the ab3p corpus because it contains some inconsistent synonyms, as mentioned earlier. a total of  <dig> , <dig> sf-lf pairs were identified. these sf-lf pairs are grouped as  <dig> , <dig> unique sf-lf pairs. most of the sfs are  <dig> to  <dig> character long. table  <dig> lists the top  <dig> most common abbreviations used in the scientific community. although it is not possible to draw any conclusions with regards to research trends by an analysis of common abbreviations, a number of interesting observations can be made. firstly, hiv  and hcv  are the only  <dig> viruses on the list. hcv/hiv co-infection is known to be a serious medical condition and there are a number of journals  devoted to hiv research. in addition, elisa is a common serological technique for detecting anti-viral antibodies suggesting viral infection, including that of hiv. secondly, ct and mri scans are commonly used medical procedures in the diagnosis of ad  and ra . clinically, bmi  and bp  are important physiological parameters linked to obesity and can be easily measured. odds ratio  is a commonly reported statistical parameter in epidemiology and since medical conditions appears to dominate this list, it is not surprising to find or here as well. pcr  remains a useful molecular technique in many areas of research and it is no wonder that professors kary mullis and michael smith were awarded the  <dig> nobel prize in chemistry for its development. confidence intervals  are reported in nearly all statistical measure; hence, it is not surprising to be grabbing the top seat in this list.

one of the complexity of sf and lf is that a single sf can have multiple lf, depending on context. for example, apc can have many different meanings, as illustrated in table  <dig>  it may be interesting to note that  <dig> of the top  <dig> are related to cell cycle control  which are known to be relevant in cancer research and colon cancer . antigen-presenting cells is widely known to be an important key to acquire immunity. activated protein c is an important component in blood clotting pathway and may be interacting with warfarin, a widely used drug to manage deep-vein thrombosis and widely known for its extensive interactions with other medical drugs. hence, it is not surprising to see a large occurrence of these terms in the literature. however, it also suggests that reading biomedical literature requires a good understanding of these terms in order to prevent ambiguity. despite the contextual complexity, the extracted lf-sf pairs may be used to support future research, such as the development of named entity recognition systems or abbreviation disambiguation.

our web site http://bioagent.iis.sinica.edu.tw/bioadi/ provides freely access to two online services and two off-line tools. online services include  sf-lf search service and  sf-lf identification service, whereas off-line tools include  an off-line abbreviation recognition tool and  an abstract fetching script. sf-lf search service helps users to quickly retrieve all of the sf-lf pairs in our database. query results are listed as  <dig> records per page and ordered by the number of pubmed ids of each pairs so that users can easily find out the most popular ones. to see in which pubmed ids the sf-lf pair can be found, users can click on the document picture under the "pubmed" column to generate a "pubmed id box." for those sf-lf pairs having too many pubmed ids to be fully displayed in the box, users can click on the "pubmed resource" to see the whole list of pubmed ids. by using the search service, users can find different subtypes of sfs or lfs and thereby come upon extra pubmed ids that they can not find through regular literature search. secondly, "sf-lf identification service" provides real-time ar service. in the identification service section, users can use the text area for text inputs such as abstracts or manuscripts, whereas another input box is for pubmed id. after receiving the submission of inputs, the system will return identified sf-lf pairs and scores for each pairs. the higher the score is, the better the identification can be trusted. if the input is a pubmed id, the result table will also show a hyperlink to pubmed at the bottom. in the download section, we provide all of the sf-lf pairs in our database with two helpful tools:  off-line abbreviation recognition tool and  abstract fetching script. the off-line abbreviation recognition tool can automatically do ar on a given text file and generate sf-lf pairs and their score to the output file. since it is a java application, it can run on any platform and serve as a sf-lf identification component in any pipeline of analysis. the abstract fetching script is a perl script and can be used to massively download abstracts through the web service of pubmed database for given pubmed ids. to ensure the stability of our web site, all scripts and layout of the web site have passed tests on different browsers, different platforms, and even mobile devices.

CONCLUSIONS
our system demonstrated  <dig> % precision and  <dig> % recall, giving a f-score of  <dig> %, which statistically significantly outperformed the existing best performance ar system. at the same time, our system runs sufficiently fast to handle the entire set of pubmed abstracts. this suggests that a machine learning approach to abbreviation recognition gives not only good performance as good as a rule-based system, but also satisfying execution.

competing interests
the authors declare that they have no competing interests.

authors' contributions
cheng-ju kuo and maurice ht ling developed methods, annotated the corpus, implemented the offline software, and drafted the manuscript. kuan-ting lin developed the online interface and revising the manuscript. chun-nan hsu was responsible for all aspects of the project and helped revise the manuscript.

note
other papers from the meeting have been published as part of bmc genomics volume  <dig> supplement  <dig>  2009: eighth international conference on bioinformatics : computational biology, available online at http://www.biomedcentral.com/1471-2164/10?issue=s <dig> 

