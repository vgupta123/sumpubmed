BACKGROUND
evolutionary models seek to describe the process by which dna changes over time, while sequence alignment is the computational task, given two or more sequences of dna, of determining which stretches of nucleotides may have arisen from a common ancestor. it seems logical to combine these goals, and we present an attempt to do so here. we specifically address non-coding dna of unknown function, but it is straightforward to include functional models of dna , and we hope in the future also to extend this approach to protein-coding dna and amino-acid sequences.

the motivation for using an evolutionary model in multiple sequence alignment is this: rather than simply optimise the "similarity" of two sequences by some "metric", we want to assess which similarities are unlikely to have occurred by chance. in other words, given two sequences, or two sets of sequences, we want to know whether or not to align them, by estimating the likelihood of observing such sequences under two hypotheses: that they are related ; or that they are not related.

this is less of an issue in aligning protein-coding genes, which tend to be rather well conserved. non-coding dna, however, can contain strongly conserved regions  interspersed among weakly-conserved regions. in an extreme case, we recently found  <cit>  that the centromeric regions in two closely-related yeast species have no detectable homology, even though the neighbouring orfs are well-conserved and syntenous, and most intergenic regions are well-conserved too. it is important that a sequence alignment program, when used on non-coding dna, be able to distinguish genuine ancestral relatedness from chance similarity.

we start with a quick review of several evolutionary models, but it is important to note the difference in motivation: while most previous researchers have been interested in estimating evolutionary distances and constructing phylogenetic trees based on observed substitution patterns, we are interested in using known or estimated evolutionary history to evaluate differing hypotheses relating to the evolution or function of individual subsequences. specifically, we have recently, in the motif-finder phylogibbs,  <cit>  used an evolutionary model, as described in methods, to evaluate the competing hypotheses that short stretches of sequence may be "regulatory" or "background". here we use a similar evolutionary model to perform multiple sequence alignment by evaluating the hypotheses that two  subsequences from two longer  sequences may, or may not, be homologous. the word "homology" is used, throughout, in the sense of "evolutionary relatedness"  <cit> , and not merely "similarity". a principal goal of the alignment program described here is that alignments reported by it should indicate homology, to a high degree of confidence.

most evolutionary models trace their lineage to the work of jukes and cantor  <cit> . their model assumes neutral evolution, independent evolution of nucleotides and a uniform mutation rate from any nucleotide to any other. improvements to that model have largely consisted of using realistic mutation matrices that take account of differing mutation rates between different nucleotides: in particular, the fact that transitions  are much more common than transversions . kimura  <cit>  accounted for differences in transition and two types of transversion rates. further work along these lines has been done by tamura  <cit> , tamura and nei  <cit>  and others. the most general reversible model was described by tavaré  <cit> , and the general 12-parameter model was discussed by rodríguez et al.  <cit> . meanwhile, felsenstein  <cit>  introduced a model, that we discuss further below, where mutation rates represent equilibrium frequencies for nucleotides. hasegawa et al.  <cit>  amended this method to take account of differing frequencies of transition and transversion. heterogeneity of sequence and differing rates of fixation at different loci have been considered by various authors, starting from uzzell and corbin  <cit> . we do not consider this problem in detail here, but our model can be modified to include prior knowledge of sequence function and heterogeneity of sequence composition.

one shortcoming of such models is that they do not explain some significant observed features of dna, the most basic of which is the fact that nucleotides are correlated, not independent. if one considers abundances of neighbouring nucleotides , they differ significantly from what would be expected from their individual frequencies: for example, aa is usually over-represented while cg is underrepresented . attempts have been made to address this by various authors. arndt and hwa  <cit>  use dinucleotide substitution matrices instead of single-nucleotide matrices. while sufficient to account for the most important effects, this assumes that the mutation of certain dinucleotides is preferred. sometimes this is true , but in other cases selection forces  could well be operating. also, such an approach still does not account for longer-ranged correlations in dna, which exist to significant distances in non-coding dna, as first noted by peng et al.  <cit> . baele et al.  <cit>  observe complex substitution behaviour, and argue that incorporating context-dependent substitution effects is worthwhile.

we argue that, even in the absence of known function, mutating intergenic sequence can have a cost in fitness, and selection and fixation could be operating on large parts of the genome--perhaps the majority. in a recent study of centromeric dna in two candida species  <cit> , we calculated a substitution rate of 27% between those species from synonymous codon substitutions; correcting this with known codon biases gave a substitution rate of 42%, which was our best estimate at a neutral rate. however, the substitution rate in conserved intergenic sequence is much lower than either of these estimates . meanwhile, the centromeres appear to have diverged much faster than our best neutral rate would suggest--implying either that the centromeres evolve neutrally while the rest of the genome is under significant selection pressure, or that centromeres evolve at a "faster than neutral" rate, or both. it is possible that structural and stability requirements, the necessity to bind nucleosomes  <cit> , and other biophysical considerations constrain the evolution of dna.

we recently used an evolutionary model, in the context of the motif finder phylogibbs  <cit> , that represents the polar opposite of neutral evolution: it assumes that fixation of nucleotides after mutation is perfect--that is, the distribution of mutated nucleotides matches the distribution found in sites elsewhere of similar function . a similar approach was used in the cis-regulatory module predictor stubb  <cit> . this is in fact the model of felsenstein  <cit> , with a slightly different interpretation and a very different motivation. the model is reviewed in methods, "evolutionary model". however, while it is important to consider fixation , the assumption of perfect fixation may be extreme and unrealistic. we address that issue here, thereby connecting with other models from the literature: we have a model that resembles the "general reversible model", with the inclusion of fixation but not "perfect fixation".

we then use this evolutionary model to address the problem of sequence alignment: specifically, we use this model to calculate the log-likelihood ratio of sequences being related, to being unrelated. we modify our previously published multiple sequence alignment program sigma  <cit>  to use this as a scoring scheme. the key goal of sigma is to minimise spurious alignments , a significant issue in non-coding dna, where highly conserved segments can be interspersed with long insertions and deletions. this was achieved by calculating the p-value for the score of each locally aligned region, that is, calculating the probability of observing such a score under the "null hypothesis" that the sequences are not ancestrally related: only matches with sufficiently low p-values are considered for alignment. while one other program that we are aware of, dialign  <dig>  <cit> , also used a p-value as a criterion, our calculation of the p-value is different in details, as described in methods. we tested several programs in the earlier paper  <cit>  and showed that they produce spurious alignments even for randomly-generated dna, and show significant error rates in aligning synthetic sequence; while sigma  was much less sensitive , we showed that the motif finder phylogibbs  <cit>  exhibited better performance when its input data was aligned with sigma- <dig>  suggesting that its alignments were biologically more realistic.

sigma- <dig>  the modification of sigma- <dig> that features the evolutionary model described here, proves to be substantially more sensitive than sigma- <dig> on synthetic data , while maintaining a very low error rate and refusing to align sequence that is not related. we demonstrate this on both synthetic and genomic  dna. the results indicate the benefits of including selection and fixation in an evolutionary model, of basing the problem of multiple sequence alignment on such a model, and of comparing results with the "null model" of unrelatedness, and insisting on stringent p-values to report alignments.

ours is not the first attempt to include evolutionary considerations in sequence alignment, but it differs in details. thorne et al.  <cit>  have previously considered including an evolutionary model in pairwise sequence alignment. their main focus was the treatment of insertions and deletions. steel and hein  <cit>  extended that approach to sequences on a tree. the focus of our work is different: we focus on gapless local alignments, assuming that non-coding dna will contain large insertions and deletions which will be accounted for by assembling the gapless alignments; and rather than consider the overall "maximum likelihood" alignment, we insist on a stringent p-value for the log-likelihood-ratio that we calculate for each local alignment. below we benchmark our program against ten other widely-used multiple sequence alignment programs.

RESULTS
we performed three sets of benchmarks, on synthetic and real  data, comparing sigma- <dig> with eleven other programs: the previous version of sigma , dialign-tx version  <dig> . <dig>  <cit> , t-coffee version  <dig>   <cit> , clustalw version  <dig> . <dig>  <cit> , kalign version  <dig>   <cit> , mlagan version  <dig>   <cit> , muscle version  <dig>   <cit> , pcma version  <dig>   <cit> , fsa version  <dig> . <dig>  <cit> , pecan version  <dig>   <cit> , mavid version  <dig>  build  <dig>  <cit> .

benchmark on yeast data: discriminativeness
while synthetic benchmarks are better quantifiable, real dna exhibits complexities difficult to capture in synthetic data. here we describe the performance of sigma- <dig> and other programs on yeast data. "reference alignments" being unavailable, we measure performance indirectly: we compare the alignments produced by various programs for orthologous dna, with alignments by the same programs for non-orthologous dna.

we used  <dig> genes for saccharomyces cerevisiae for which there existed a kilobase of upstream intergenic  sequence, and for which the orthologous genes in four other species  also had a kilobase of upstream non-coding sequence. thus, the benchmark consisted of aligning  <dig> files, each containing  <dig> bp of orthologous non-coding sequence. we also generated  <dig> "shuffled" files, that contained the same upstream sequences from the same five species in each file, but entirely non-orthologous: that is, each sequence in the original set was present in exactly one shuffled file, but no two sequences in a given shuffled file were orthologous. this was accomplished by ordering the genes and the species, and selecting upstream sequence from the n + 100k'th gene for the k'th species .

while we cannot quantify the accuracy of alignment on the orthologous sequences, we can say with some confidence that very little sequence from the "shuffled" set is likely to be genuinely homologous; so a program whose alignments indicate homology rather than mere "similarity" should not report significant similarity in the second set of sequences. at a minimum, there should be significant gap in results on the two sets.

performance in the yeast benchmark, described in the text, of  <dig> programs .  <dig> genes were selected, each of which had  <dig> bp of non-coding upstream sequence in s. cerevisiae and four other species. each upstream sequence and its four orthologues were aligned . in addition,  <dig> "scrambled" files were prepared each of which contained sequence from each of the five species, including no orthologous sequences, and these were aligned . "matches per base" indicates the average number of nucleotides in other species that each nucleotide in the input data was aligned with . the difference between the "orthologous" and "scrambled" numbers is a measure of how discriminative the program is to genuine orthology.

all programs were run with their default command lines, except as follows: for sigma- <dig>  a file providing background dinucleotide frequencies, and another file providing transition rates, both files derived from yeast, were supplied. for sigma- <dig> . <dig>  only the background file was supplied. dialign-tx was run with the parameter - <dig>  the most stringent  mode. fsa was run with the parameter --gapfactor  <dig>  which increases its specificity. mavid was run using the bundled perl script to automatically generate the phylogenetic tree. pecan was fed the phylogenetic tree , s. kud), s. bay)).

performance on the yeast benchmark of a subset of the programs in table  <dig> when command-line parameters are varied. in sigma, "no bg" indicates a background model where each nucleotide is equally probable; "no tr" indicates a "uniform" transition matrix where a nucleotide can mutate to any other nucleotide with equal probability. in fsa, "gap5" indicates the command line option --gapfactor  <dig>  in dialign, - <dig>  <dig> is the most stringent setting. mavid tree options are as described in the text.

of other programs, fsa and dialign-tx still show substantial gaps between orthologous and shuffled sequence sets when run with their default settings; however, at their most stringent settings, both align much more shuffled sequence than sigma- <dig> does at the least stringent setting tested above. mavid was run with a tree corresponding to the yeast alignments, but the results did not greatly differ from the automatically-generated tree.

if the most basic task of a sequence alignment program is to distinguish homologous and non-homologous sequence, it seems that all but a few programs fail badly at that task, and sigma- <dig> is by far the most stringent in rejecting non-homologous sequence.

finally, one can ask: even in the alignment of orthologous sequence, to what extent do various programs agree with one another? we consider four programs that perform the most discriminative alignments in table  <dig>  namely sigma  <dig>  fsa, dialign-tx and pecan. in the orthologous set,  <dig> pairs of nucleotides in total were identified by sigma- <dig> as orthologous. of these,  <dig> were identified by fsa,  <dig> by dialign-tx and  <dig> by pecan. in other words, nearly 20% of the nucleotide pairs aligned by sigma were not aligned by the other programs. we then ask, what about the alignments made by other programs and not by sigma-2?  <dig> pairs of nucleotides are aligned by fsa and not by sigma. of these,  <dig> are also aligned by pecan, but only  <dig> by dialign-tx. meanwhile, dialign-tx aligns many nucleotides that are omitted by sigma- <dig> and fsa, and pecan aligns many nucleotides that are omitted by all three programs. this level of disagreement, in a task of aligning five closely-related yeast species, indicates the difficulty of underlining non-coding dna and the desirability of a conservative approach.

motif-finding benchmark on yeast data
to test our motif-finder phylogibbs  <cit>  and phylogibbs-mp  <cit> , we benchmarked its ability to identify transcription factor binding sites in yeast from the scpd database  <cit> . conversely, in the previous paper on sigma  <cit> , we measured the performance of phylogibbs  <dig>  in detecting binding sites using sequence alignments generated from various programs. we repeat that benchmark here, using phylogibbs-mp. the reason to use scpd is that it is a large database of experimentally validated binding sites. so measuring the performance of a motif finder in detecting these sites is an objective measure of its performance in the real world. while this benchmark does not directly measure the quality of the alignment, it is hoped that a more "correct" alignment will improve the performance of a motif-finder. we use a recently retrieved version of the scpd database, after filtering out sites smaller than  <dig> bp. we were left with  <dig> sites upstream of  <dig> genes. up to  <dig> bp  was extracted for each gene in s. cerevisiae and its orthologues from s. paradoxus, s. bayanus, s. mikatae and s. kudriavzveii. these were aligned using each of the alignment programs studied here, phylogibbs-mp was run on the aligned files individually , and its site predictions compared with the annotated sites. since the scpd sites vary greatly in length , while our assumed motif width was  <dig> bp, an overlap of a single basepair was counted as a "hit".

the results are plotted in figure  <dig>  which shows the "precision" of phylogibbs-mp's predictions  as a function of "sensitivity" . the sensitivity is varied by changing the "cutoff" for the significance score reported by phylogibbs-mp. while not too many conclusions should be drawn from this limited benchmark. both versions of sigma perform well over most of the sensitivity range, as does dialign-tx. other good performers are kalign and t-coffee. with several alignment programs, however, the motif-finding performance of phylogibbs-mp is surprisingly poor. meanwhile, sigma- <dig> mostly seems to fare better than sigma-2: our hypothesis is that, though it is less sensitive in alignments than sigma- <dig>  it performs well in aligning functional binding sites  and this, in turn, helps bias phylogibbs-mp towards those sites . perhaps this argument also helps explain the better performance of sigma- <dig> compared to most other programs; but it does not explain the poor performance of fsa and pecan. we cannot directly conclude from this benchmark that sigma's alignments are more "correct" than others, but we can view it as supporting the use of sigma in real-world applications where the correctness of the alignment is important.

benchmark on synthetic data
we generated sets of synthetic dna that conformed to the evolutionary model described above, where each set was evolved from a  <dig> bp ancestral sequence and contained five descendants, each descendant sequence had a proximity q to the ancestor, and substitutions from the ancestor were made according to equation  <dig>  with dinucleotide frequencies and an inverse substitution matrix estimated from yeast data. values of q from  <dig>  to  <dig> , in increments of  <dig> , were considered. in addition, insertions and deletions of short stretches of sequence  were made with a small probability : in other words, around  <dig> insertions or deletions were expected per sequence. each insertion and deletion applied only to a single descendant sequence . for each value of q,  <dig> independent sets of  <dig> sequences each were generated. this method of generating sequences also gave us the theoretical "correct" reference alignment for each set of sequences. alignments were assessed on sensitivity to the reference alignments , but also on the error rate  and the precision . that is, if there are nref aligned nucleotide pairs in the reference alignment, ncorrect aligned pairs in the reported alignment that are also aligned in the reference alignment, and nincorrect aligned pairs in the reported alignment that are not aligned in the reference alignment, we define

  sensitivity=ncorrectnref 

  error rate=nincorrectnref 

  precision=ncorrectncorrect+nincorrect 

CONCLUSIONS
benchmarking on synthetic data is of limited benefit in analysing real-world performance, but it is quantifiable. kim and sinha  <cit>  recently did an exhaustive benchmark of six programs, and claim that their method generates data that "truly represent the variability observed in genomic data in terms of the difficulty of the alignment task". they observe degradation in performance with insertions, which is probably attributable to our observation that most programs spuriously align non-homologous sequence. they also observe that pecan is not susceptible to this problem and that its performance was superior to all other programs, in agreement with what we see in yeast data , but in contrast with our observation in these synthetic data benchmarks. this supports their claim that their generated data are biologically realistic.

however, our "homology discrimination" benchmarks on yeast data are, we believe, of greater interest because of their simplicity and the somewhat unexpected results. arguably the goal of sequence alignment should be to detect homology and not similarity, since the former is a well-defined biological concept meaning "having a common ancestry"  <cit>  and the latter is not always unambiguous or even meaningful. we argue further that a sequence alignment program should err on the side of caution, that is, though it may fail in some cases to detect genuine homology, it should not incorrectly claim homology where none exists. other than sigma- <dig>  all programs tested here fail, in differing degrees, on this criterion. the most effective at rejecting spurious alignments is fsa with a stringent gap factor. the only other programs that strongly distinguish the homologous sequences from the shuffled sequences are pecan and dialign-tx, but they still spuriously predict a homologous nucleotide for half, or more, of the nucleotides in the shuffled set. this performance, meanwhile, is far superior to all the other programs tested, which predict over two homologues per nucleotide in the shuffled set, and in some cases predict more homology in the shuffled set than in the genuinely homologous set. we feel therefore that these programs should not be used to align non-coding dna . this is particularly important since it is increasingly important to align, not just non-coding dna, but whole genomes, and some of the programs described here have been used for that task; and the error rates seen here on the shuffled yeast data are a matter of concern.

with the default settings of sigma- <dig> , it predicts just under  <dig> homologues per nucleotide in orthologous sequence. with the loosest settings that we tested--a p-value of  <dig>  for alignment, uniform background model, uniform transition matrix--sigma- <dig> predicts close to  <dig>  homologues per nucleotide in shuffled sequence  and over  <dig>  homologues per nucleotide in non-shuffled sequence. fsa, run with a gapfactor of  <dig>  performs worse on both counts: it predicts fewer homologues in the orthologous set and more homologues in the shuffled set. other programs predict more homologues in both sets. based on the predictions by sigma- <dig>  fsa, pecan and dialign-tx, we estimate that the true conservation rate between these species is probably around  <dig>  homologues per nucleotide, and the significantly higher predictions of the other programs are unreliable. this is probably because of the abundance of insertions and deletions in intergenic sequence.

sigma- <dig> was originally designed to reject such spurious alignments, and benchmarks on synthetic and real data showed that it performed well on this criterion, but was also less sensitive than other programs in detecting genuine homology . here we have shown that the incorporation of an evolutionary model into sigma's scoring scheme improves its sensitivity to the point where, on synthetic data, sigma- <dig> is competitive with all other programs; while its precision is much higher, and error rate much lower, than all other programs that we tested.

meanwhile, the motif-finding benchmark shows sigma to be one of the best performers in a real-world application.

