BACKGROUND
semantic similarity and relatedness measures
although technically they refer to different notions of relatedness, the terms similarity and relatedness are often used interchangeably  <cit> . this is in part due to the fact that these measures are applied to the same types of text processing tasks and evaluated on the same benchmarks  <cit> . semantic similarity is a type of semantic relatedness, namely taxonomic relatedness, e.g. lovastatin is-a statin  <cit> . semantic relatedness can refer to non-taxonomic relatedness such as antonymy, meronymy , frequent association, and other functional relationships   <cit> .

knowledge based semantic similarity measures include random walk, path finding, and intrinsic ic based measures. these measures generate a concept graph from a taxonomy or semantic network in which vertices represent concepts and edges represent semantic relationships. path finding and intrinsic ic based measures utilize taxonomies, i.e. an acyclic, directed concept graph in which edges represent taxonomic relationships. a taxonomy suitable for use with semantic similarity measures can be derived from a knowledge source by taking a subset of hierarchical semantic relationships, and removing relations that induce cycles. concepts that are generalizations of other concepts are referred to as parents or hypernyms; specifications of a concept are referred to as children or hyponyms.

path finding based semantic similarity measures compute similarity as a function of the length of the shortest path between two concepts. one limitation of path finding measures is that they give equal weight to all relationships  <cit> . information content  based measures attempt to correct for this by weighting edges based on ic, a measure of concept specificity  <cit> . relationships between specific concepts, e.g. lovastatin is-a statin, should be weighted more heavily than relationships between general concepts, e.g. lovastatin is-a enyme inhibitor. intrinsic ic based measures compute the information content of concepts from the taxonomic structure. the assumption underlying this approach is that the taxonomic structure is organized in a meaningful way, such that concepts with many hyponyms and few hypernyms have lower ic  <cit> .

random walk measures compute the relatedness between a pair of concepts via random walks on a concept graph  <cit> . in contrast to path finding and intrinsic ic measures, random walk measures can utilize graphs that contain undirected edges, non-taxonomic relationships, and cycles. instead of defining relatedness as a function of the shortest path between concepts, random walk methods measure the overall connectivity between concepts. we focus on the personalized pagerank  algorithm that achieved state of the art performance on general language semantic similarity benchmarks, but has not been evaluated on biomedical semantic similarity tasks  <cit> . for a given concept, ppr generates a score vector that represents its connectivity to other concepts. the relatedness between a pair of concepts is defined as the cosine of the angle between their score vectors.

distributional based measures utilize a domain corpus in conjunction with a knowledge source; these include corpus ic and context vector measures. corpus ic based methods are analogous to intrinsic ic based methods, but estimate the information content of a concept from its distribution in a corpus.

context vector measures of semantic relatedness are based on the assumption that words that appear in similar contexts are related  <cit> . this approach starts by creating word vectors from a corpus that represent word co-occurrence. then descriptor terms for a concept are derived from a knowledge source such as a dictionary or thesaurus, and can be further expanded to include descriptor terms from related concepts  <cit> . the word vectors corresponding to a concept’s descriptor terms are then aggregated to construct a context vector <cit> . the similarity between a pair of concepts is defined as the cosine of the angle between their context vectors.

in the biomedical domain, a study by pedersen et al. that utilized a large medical corpus to estimate concept distributions showed that distributional measures outperformed taxonomy based path finding measures  <cit> . a more recent study by sanchez et al. showed that knowledge based intrinsic ic measures outperformed distributional measures  <cit> . however, methodological differences in this latter study prevent a direct comparison between knowledge based and distributional based measures.

previous work in the general language domain suggests that distributional measures of similarity suffer from limitations that stem from the imbalance, sparseness, and textual ambiguity of corpora  <cit> . more recent work that utilized a large  web corpus, processed using substantial computational resources , demonstrated that utilization of large corpora enable distributional measures to overcome these limitations, allowing distributional measures to achieve the same performance as knowledge based measures  <cit> .

however, it is not clear if these results obtained via distributional methods in the general language domain are applicable in the biomedical domain, due to the lack of large, publicly available clinical corpora  <cit> . furthermore, the computational resources required to process large corpora pose a practical challenge to the implementation of distributional measures.

evaluations of similarity measures in the biomedical domain used private, institution-specific corpora of clinical notes  <cit> . large corpora of clinical notes are not publicly available due to the sensitivity of the data contained therein, and smaller, publicly available corpora may bias concept frequency estimates  <cit> . alternatively, it is possible to utilize a publicly available biomedical corpus such as medline, which contains over  <dig> million abstracts from biomedical journals  <cit> . however, evaluations of context vector measures based on  <dig>  medline abstracts demonstrated poorer performance than measures based on a clinical corpus  <cit> . using a larger subset of medline may overcome this problem, but processing this corpus represents a technical challenge that may be prohibitive for many applications. furthermore, to compute corpus ic-based measures, text must be mapped to concepts. automated concept mapping errors may bias concept frequency counts, negatively impacting the accuracy of corpus ic based measures  <cit> .

biomedical knowledge sources – snomed ct, mesh, umls
snomed ct is a comprehensive clinical ontology maintained by the international health terminology standards development organisation . mesh is a controlled vocabulary thesaurus maintained by the national library of medicine  and used to index articles for the medline database. the umls metathesaurus is a compendium of over  <dig> biomedical vocabularies including snomed ct and mesh  <cit> . in this paper, when we refer to the umls, we are in fact referring to the umls metathesaurus. all of these knowledge sources assign concepts unique identifiers, associate concepts with lexical variants , and define hierarchical is-a relationships between concepts. snomed ct and the umls also enumerate additional semantic relationships, e.g. part-of and treated-by.

advantages of the umls with respect to snomed ct or mesh include robust tool support and broader concept coverage. several popular natural language processing  tools map free text to umls concepts, facilitating the application of similarity measures based on the umls  <cit> . if a concept is missing from a knowledge source, then it is not possible to compute its similarity: use of multiple umls source vocabularies enables the computation of similarity measures not possible with a single source such as snomed ct or mesh.

however, the umls introduces potential problems that may affect the accuracy of semantic similarity measures. the umls representation of source vocabularies may change concept granularity and/or distort relationships between concepts, thereby negatively impacting semantic similarity measures. for example, snomed ct distinguishes between morphological abnormalities and clinical findings: the glomus tumor  and glomus tumor  represent distinct concepts in snomed ct; in the umls, these represent the same concept  <cit> . clarifying the impact of using the umls versus original source vocabularies is one of the goals of this study.

semantic similarity benchmarks
previous comparisons of semantic similarity and relatedness measures in the biomedical domain were performed on a benchmark of  <dig> snomed ct concept pairs created by pedersen et al.   <cit> . nine medical coders and three physicians assessed the semantic relatedness of these medical concept pairs. pedersen et al. evaluated similarity measures against similarity scores for the coders, physicians, and the average of scores between groups ; on this evaluation, distributional measures achieved the highest correlation with human raters.

subsequent evaluations of semantic similarity measures in the medical domain utilized pedersen’s benchmark. however, these comparisons may be flawed due to the difference in snomed ct versions used, and differences in the methods used to compute correlation between similarity measures and the reference standard: in their original study pedersen et al. used snomed ct  <dig> and the non-parametric spearman rank test to measure the correlation between semantic similarity measures and the reference standard, as annotators rated concept similarity on an ordinal scale  <cit> . subsequent studies used later snomed ct versions, and used the pearson correlation coefficient, which is not comparable to the spearman rank correlation coefficient  <cit> . in addition, the limited size of this reference standard may lack the power to detect significant differences between different measures.

recently, pakhomov et al. developed larger benchmarks for semantic relatedness and similarity using umls medical concept pairs. in the ‘mayo’ benchmark, the same  <dig> medical coders and  <dig> physicians that supplied ratings for the pedersen benchmark rated a set of  <dig> umls concept pairs for semantic relatedness on an ordinal scale  <cit> . in the ‘umn’ benchmark, eight medical residents ranked a set of  <dig> and  <dig> umls concept pairs on a continuous scale for relatedness and similarity respectively  <cit> . because the umn ratings follow a multi-modal distribution, pakhomov et al. used the spearman rank correlation to evaluate semantic similarity and relatedness measures.

in the present study, in addition to the pedersen benchmark, we evaluated semantic similarity measures on the mayo and umn benchmarks as they potentially have the power to detect significant differences in the accuracy of different measures.

methods
semantic similarity measures
in this section, we define the semantic similarity measures evaluated in this study. we modified some measures so that they conform to the universal definition of similarity presented by lin  <cit> : measures are limited to the interval  <cit> , and the similarity between a concept and itself is  <dig> 

path finding measures
we focus on the path <cit> , leacock & chodorow   <cit> , and wu & palmer <cit>  path finding measures that are based on the shortest path separating concepts. let p=path, the number of nodes in the shortest path separating two concepts, c <dig> and c <dig>  the shortest path between two concepts traverses their least common subsumer ), i.e. their closest common parent. the depth ) of a concept is defined as the number of nodes in the path to the root of the taxonomy; and d represents the maximum depth of a taxonomy.

path defines the similarity between two concepts simply as the inverse of the length of the path separating them  <cit> :

  simpathc <dig> c2=1/p 

lch is based on the ratio of path length to depth, but performs a logarithmic scaling  <cit> . originally, lch was defined as

  simlchunscaledc <dig> c2=−logp/2d=log2d−logp 

as proposed in  <cit> , we scale lch to the unit interval by dividing by log. dividing by a constant value has no effect on the spearman correlation with benchmarks: the relative ranks of concept pair similarities remain the same.

  simlchc <dig> c2=1−logplog2d 

wu & palmer scales the depth of the lcs by the length of the path between two concepts  <cit> :

  simwpunscaledc <dig> c2=2×depthlcsc <dig> c2pathc <dig> lcsc <dig> c2+pathc <dig> lcsc <dig> c2+2×depthlcsc <dig> c <dig> 

one problem with this definition is that the similarity of a concept with itself is less than  <dig> ) + path) = 2). instead, we adopt the definition of wu & palmer used in the natural language toolkit  <cit> :

  simwpc <dig> c2=2×depthlcsc <dig> c2p−1+2×depthlcsc <dig> c <dig> 

under this definition, if c <dig> = c <dig>  then p- <dig> =  <dig>  and the similarity measure evaluates to  <dig> 

ic based measures
information content can be estimated solely from the structure of a taxonomy , or from the distribution of concepts in a text corpus in conjunction with a taxonomy   <cit> .

the corpus ic ) of a concept is defined as the inverse of the log of the concept’s frequency  <cit> . the frequency of a concept is recursively defined using a taxonomy: it is based on the number of times the concept c occurs within a corpus ), together with the number of times its children occur:

  iccorpusc=−logfreqc 

  freqc=freqc,c+∑cs∈childrencfreqcs 

we follow the intrinsic ic definition proposed by sanchez et al.  <cit> :

  icintrinsicc=−log|leavesc||subsumersc|+1max\_leaves+ <dig> 

where leaves is the set of leaves  that are descendants of the concept c; subsumers contains c and all its ancestors. the ratio of leaves to subsumers quantifies the information a concept carries– the more leaves a concept has relative to the number of ancestors, the less information it carries; this is normalized to the unit interval by max_leaves, the total number of leaves in the taxonomy.

the ic based lin measure compares the ic of a concept pair to their lcs’s ic: the greater the lcs’s ic , the more ‘similar’ the pair of concepts.

  simlinc <dig> c2=2×iclcsc <dig> c2icc+icc <dig> 

sanchez & batet redefined path finding measures in terms of information content  <cit> . path finding measures are defined in terms of the path length p and the maximum depth d. sanchez & batet proposed redefining the maximum depth d as icmax, the maximum information content of any concept; and proposed redefining the minimum path length p between two concepts in terms of jiang & conrath’s semantic distance  <cit> :

  distjcc <dig> c2=icc1+icc2−2×iclcsc <dig> c <dig> 

the ic-based lch measure is obtained simply by substituting distjc and icmax for p and d in equation  <dig> :

  simlch\_ic*c <dig> c2=1−logdistjcc <dig> c2+1log2×icmax 

one problem with this definition is that the ic-based lch can assume negative values. we modify this as follows:

  simlch\_icc <dig> c2=1−logdistjcc <dig> c2+1log2×icmax+ <dig> 

both sanchez & batet’s and our definitions of the ic-based lch are monotonically decreasing functions of distjc, and thus produce identical spearman correlations with benchmarks.

the ic-based path measure is obtained simply by substituting distjc for p :

  simpath\_icc <dig> c2=1distjcc <dig> c2+ <dig> 

personalized pagerank
the pagerank algorithm, originally developed to rank web pages, is a general method for the ranking of vertices in a graph based on importance  <cit> . the pagerank algorithm models web surfing as a markovian process, with a user randomly jumping across links  to other pages . the pagerank algorithm produces a probability distribution over vertices : it assigns to each vertex a score that represents the portion of time a random surfer will spend there. the personalized pagerank algorithm biases random jumps toward a set of vertices  <cit> . in its application to semantic relatedness, a graph is created in which vertices represent concepts and undirected edges represent semantic relationships  <cit> . for a given concept, a probability vector is computed via the personalized pagerank algorithm with random jumps biased towards the given concept. the relatedness between two concepts is defined as the cosine of the angle between their probability vectors.

the personalized pagerank algorithm models a knowledge source as a graph g with n vertices v1…vn corresponding to concepts, and undirected edges between concepts that represent semantic relationships  <cit> . let di be the outdegree of node i. let m be a nxn transition probability matrix, where mji = 1/di if a link from i to j exists, and  <dig> otherwise. the pagerank vector p is obtained by resolving the following equation:

  p=cmp+1−cv 

in the pagerank algorithm the vector v is an nx <dig> vector whose elements are 1/n, and c is the damping factor, a scalar value in  <cit> . the first term cmp represents navigation across the edges of the graph, and the second term v represents the probability of jumping to any vertex. the damping factor weights the combination of these terms; we used the default damping factor of  <dig> .

in the personalized pagerank  algorithm, probability mass is concentrated on a set of entries in the vector v, biasing the jumps towards certain vertices  <cit> . to compute the relatedness between a pair of concepts, for each concept, the vector p is computed using the ppr algorithm with vi =  <dig> for the corresponding concept, and  <dig> otherwise. the relatedness of a pair of concepts is defined as the cosine of the angle between their ppr vectors.

evaluation method
concept graph construction
we evaluated measures using current knowledge source releases: the july  <dig> international release of snomed ct; the  <dig> mesh descriptors and supplementary concept records; and the umls release 2011ab using a ‘default’ metathesaurus installation with snomed ct and all restriction-free  source vocabularies; this includes mesh and  <dig> other vocabularies. in this paper, when we refer to ‘the umls’ we are in fact referring to this default subset of the umls.

we compared similarity measures that utilize concept graphs derived from snomed ct, mesh, the umls snomed ct and mesh source vocabularies, and the entire umls. for each knowledge source, we constructed a taxonomy for use with semantic similarity measures; computed the depth and intrinsic ic of each concept; and implemented semantic similarity measures. we used is-a relationships in taxonomies derived from snomed ct; we utilized all hierarchical relationships in taxonomies derived from the mesh and the umls.

to evaluate the ppr, we constructed two types of undirected concept graphs: graphs that used only taxonomic relationships , and graphs that used all relationships from the respective knowledge sources . one major advantage of the ppr method is its ability to leverage non-taxonomic relationships to compute concept relatedness. evaluating the ppr on both types of concept graphs allows us to quantify the contribution of non-taxonomic relationships to the computation of concept relatedness. refer to additional file 1: appendix  <dig> for a detailed description of concept graph construction.

we evaluated measures on the pedersen, mayo, and umn similarity and relatedness benchmarks  <cit> . we also evaluated measures on a ‘high agreement’ subset of the umn relatedness benchmark: term pairs from this subset had a inter-class correlation coefficient of  <dig>  or greater, and had a distribution of scores and broad semantic types similar to the entire set  <cit> .

comparison between snomed ct/mesh and their umls representations
to determine the effect of the umls representation on similarity measure accuracy, we evaluated similarity measures on concept graphs derived from snomed ct, mesh, and the umls snomed ct and mesh source vocabularies. we evaluated measures based on snomed ct on the pedersen benchmark only. we did not evaluate measures based on snomed ct on the mayo and umn benchmarks, as the snomed ct concept mappings for the term pairs from these benchmarks are not available. these benchmarks provide umls concept mappings, and a single umls concept may map to multiple snomed ct concepts.

effect of source vocabulary selection
to determine the effect of umls source vocabulary selection on similarity measures, we evaluated similarity measures derived from concept graphs constructed from the umls snomed ct source vocabulary, umls snomed ct + mesh source vocabularies, and entire umls. we evaluated measures for these concept graphs on the pedersen, mayo, and umn benchmarks.

corpus vs. intrinsic ic
we compared the lin measure using both the intrinsic ic and corpus ic on taxonomies derived from mesh and its umls representation. we used mesh for the comparison of intrinsic to corpus ic due to the availability of concept frequencies: the  <dig> medline/pubmed baseline repository  provides the frequencies of mesh headings used to index medline articles. the  <dig> baseline contains frequencies from over  <dig> million citations  <cit> . we used these frequencies to compute the corpus ic for all mesh concepts as defined in equation  <dig> 

we adapted the pedersen, umn, and mayo benchmarks for use with mesh and its umls representation. several concepts from the pedersen benchmark are missing from the mesh vocabulary. to enable correlation with semantic similarity measures based on mesh, we used the ‘closest’ corresponding mesh header; e.g. we used the mesh header for ‘knee’ in place of ‘knee meniscus’. we used subsets of the umn and mayo benchmarks for which both members of the concept pair are found in the mesh. there is a many-to-one correspondence between concepts from the umls mesh source vocabulary and mesh descriptors; this allows the unambiguous mapping of umls concepts from the umn and mayo benchmarks to mesh descriptors.

we used different concept mappings for the pedersen benchmark and subsets of the umn and mayo benchmarks, therefore the mesh correlations are not directly comparable to correlations obtained using snomed ct or other umls source vocabularies. refer to additional file 1: appendix  <dig> for a detailed listing of term to concept mappings used for these benchmarks.

statistical analysis
we assessed accuracy using the non-parametric spearman rank, which computes the correlation ρ between two random variables from their relative ranks. the path finding lch and path are monotonically decreasing functions of the shortest path between concepts and therefore produce the same relative ranks and are thus identical for the purposes of evaluating their correlation. we applied the fisher r-to-z transformation to test the significance of difference in correlation between different measures and concept graphs, and to compare our results to previously published results obtained using distributional measures. the null hypothesis is that there is no significant difference in correlation between different measures. the probability of rejecting the null hypothesis when it is in fact false – the statistical power – is higher on the larger umn benchmarks. we used r version  <dig> . <dig> for all statistical calculations. we released all code and scripts required to reproduce our results as open source.

RESULTS
concept graph dimensions
concepts from the umls snomed ct source vocabulary are in general more coarse-grained than snomed ct concepts; thus, the taxonomy derived from the umls snomed ct source vocabulary is smaller than the taxonomy derived from snomed ct . in contrast, concepts from the umls mesh source vocabulary are more fine-grained than mesh headings: the taxonomy derived from the umls mesh source vocabulary is larger than the taxonomy derived from mesh. combining the umls snomed ct and mesh source vocabularies  is almost equivalent to the sum of the source vocabularies , indicating that there is little overlap between these source vocabularies. the combination of all umls source vocabularies results in a taxonomy that is substantially larger than concept graphs based solely on snomed ct and/or mesh.

the taxonomies include only those concepts that partake in taxonomic relationships. all concepts in the snomed ct and mesh knowledge sources partake in taxonomic relationships; thus the concept coverage for the ppr graphs is identical to that of the corresponding taxonomies. on the umls, the ppr concept graphs that utilize all relationships from the umls have broader concept coverage than taxonomies constructed from the umls.

semantic similarity measure evaluation
we present the correlation for each combination of reference standard, concept graph , and measure in table  <dig>  we present the correlation for each combination of reference standard and measure for the concept graphs derived from mesh and its umls representation  in table  <dig>  we also include the results of previous evaluations, where they are comparable. we present the significance of the difference between the intrinsic ic based lch  and path finding based lch. refer to additional file 2: appendix  <dig> for a listing of the significance of differences between all pairs of measures, and between concept graphs.

+correlation not significant at  <dig>  level. significance of difference between intrinsic lch and path finding lch **< <dig> , *<  <dig> . abbreviations: lch - leacock & chodorow, ppr – personalized pagerank. refer to table  <dig> for concept graph descriptions.

abbreviations: lch - leacock & chodorow, ppr – personalized pagerank. refer to table  <dig> for concept graph descriptions.

differences between knowledge based measures
in general, intrinsic ic based measures outperformed path finding measures. on the larger mayo and umn reference standards, intrinsic ic based measures significantly outperformed path finding measures. the intrinsic ic based lch measure achieved the best performance, but the improvement relative to other intrinsic ic based measures was usually not statistically significant .

in general, the ppr measure computed with all relationships  achieved poor performance, and was significantly outperformed by path and intrinsic ic based measures. the ppr measure computed with taxonomic relationships  significantly outperformed path-based measures on the mayo reference standard, and significantly outperformed intrinsic ic based measures on the pedersen coders reference standard. on larger reference standards, this relationship was reversed: intrinsic ic based measures significantly outperformed ppr-taxonomy based measures on the mayo and umn datasets.

effect of umls representation
measures based on concept graphs derived from snomed ct and mesh outperformed their respective umls representations . we evaluated snomed ct only on the pedersen benchmark, in which the difference was significant only for ppr using all relationships . we evaluated mesh and its umls representation on all benchmarks . the difference in performance between measures based on mesh and its umls representation was significant for some benchmark/measure combinations.

effect of umls source vocabulary selection
increasing the concept graph size improved the performance of both path finding and intrinsic ic based measures: measure performance increased with the size of the concept graph. measures based on the concept graph derived from the entire umls achieved the best performance, and this difference was statistically significant and meaningful .

significance of difference between intrinsic ic based lch on different concept graphs *<  <dig> . refer to the additional file 2: appendix  <dig> for p-values.

knowledge vs. distributional based methods
pedersen
on the pedersen coders and combined benchmarks, there is no significant difference between the best knowledge and distributional based measures ; on the pedersen physicians benchmark, the context vector measure outperforms the best knowledge based measure .

umn.
all knowledge based measures significantly outperformed the context vector measure on the umn similarity and relatedness benchmarks . pakhomov et al. evaluated the context vector measure on the umn benchmark  <cit> . the context vector utilized a co-occurrence matrix derived from  <dig>  emr inpatient reports and had correlations of  <dig>  and − <dig>  with the umn similarity and relatedness benchmarks respectively; for comparison, the worst-performing path-based measures from our evaluations had correlations of  <dig>  and  <dig>  respectively.

umn relatedness subset.
liu et al. evaluated the context vector measure on a subset of the umn benchmark  <cit> . although they achieved a higher correlation, the difference to the best knowledge based measure was not statistically significant .

intrinsic ic vs. corpus ic.
we evaluated the corpus and intrinsic ic based lin measure using mesh. there was no significant difference in correlation between the intrinsic and corpus ic based measures on any reference standard. in general, the intrinsic ic based lin outperformed corpus ic based lin on umls mesh taxonomy ; however, these differences were not statistically significant .

system performance and interoperability
the system we developed is open source and written in the platform independent java language. it is a generalizable framework for the computation of semantic similarity measures from any taxonomy or semantic network; in this study we utilized snomed ct, mesh, and the umls metathesaurus. the system allows the declarative definition of concept graphs or taxonomies and stores these graphs in a binary format. for taxonomies, it computes the depth and intrinsic information content of each node. the system provides programmatic, command line, restful, and xml web services interfaces to users to compute similarity measures. we provide a publicly available web service to compute semantic similarity measures. notable aspects of our system include the ability to compute both intrinsic ic and corpus ic based measures, and the ability to compute similarity measures from a wide range of biomedical knowledge sources. the pure java implementation simplifies the integration of our system with popular java based text processing frameworks such as the unstructured information management architecture  and the general architecture for text engineering   <cit> .

the time and computational resources needed to generate concept graphs varies based on size. computing the intrinsic information content is the most computationally and memory intensive step in preparing a taxonomy. this required less than  <dig> minute with 1gb of memory for a small concept graph such as snomed ct; for the entire umls, this required  <dig> minutes with 8gb of memory. once created, the concept graph can be loaded and used to compute similarity measures. the time and resources needed to load the concept graph depends on its size; loading the taxonomy for the entire umls required  <dig> seconds and  <dig> gb of memory. all computations were performed on a 64-bit ubuntu  <dig> linux workstation with dual quad-core  <dig> ghz intel xeon processors.

computing path finding and ic based similarity measures on the umn relatedness benchmark  with the umls taxonomy required  <dig> seconds . the computation of relatedness via the personalized pagerank algorithm is computationally intensive, and increases with concept graph size. computing ppr for the umn relatedness benchmark with the umls concept graph required  <dig> hours.

discussion
effect of umls representation
our results suggest that the umls representation of source vocabularies such as mesh and snomed ct changes them in a manner that negatively impacts semantic similarity measure performance. however, the utilization of other umls source vocabularies in addition to the umls snomed ct and mesh source vocabularies more than makes up for this: using multiple vocabularies enables broader concept coverage, and significantly improves the correlation of similarity measures with human judgments.

differences between knowledge based measures
intrinsic ic based measures in general outperformed path based measures; in some cases, these differences were significant. intrinsic ic and path based measures compute similarity as a function of the distance between concepts in a taxonomy. ic based measures achieve higher performance than path based measures by weighting taxonomic links based on concept specificity.

the personalized pagerank algorithm achieved state of the art performance on general language semantic similarity tasks, but did not outperform simpler knowledge based methods on these benchmarks. furthermore, ppr is orders of magnitude more computationally intensive than simpler semantic similarity measures, and may be impractical for some applications. in contrast to other knowledge based similarity measures, ppr can utilize non-taxonomic relationships to compute concept relatedness. however, using non-taxonomic relationships significantly reduced ppr’s performance on these benchmarks. the umls contains many types of non-taxonomic relationships. it may be possible that using a subset of non-taxonomic relationships would improve ppr’s performance.

knowledge vs. distributional based measures
our results suggest that knowledge based measures can outperform distributional measures. knowledge based measures are also more practical than distributional measures, as they do not require a corpus from which word co-occurrence or concept frequencies must be estimated.

knowledge based measures significantly and meaningfully outperformed distributional vector based measures on the larger umn benchmarks. one limitation to our study is that we compared knowledge based methods to previously published distributional vector based measures: we cannot exclude the possibility that differences in the umls version used may have biased results. however, our reasons for not implementing context vector measures represent exactly their limitations: a large clinical corpus is not available to us; it is not clear if publicly available corpora such as medline abstracts are suitable for this purpose; and the processing of large corpora is computationally intensive.

distributional vector based measures in the biomedical domain may suffer from imbalance and sparseness due to limited corpus sizes  <cit> . use of a larger clinical corpus may rectify these issues, and improve the performance of vector based measures relative to knowledge based measures. even if performance could be improved with a large corpus, it is not clear what practical consequences this would have, as many applications of semantic similarity measures lack access to large clinical corpora.

our evaluation showed no significant differences between corpus ic and intrinsic ic based measures. we used mesh for the comparison of intrinsic ic to corpus ic, and estimated corpus ic using the frequencies of mesh headings derived from over  <dig> million medline abstracts. these results suggest that, given the ease with which ic can be estimated from a taxonomy, intrinsic ic based measures are a practical alternative to corpus ic based measures. one limitation of our study is that we only evaluated corpus ic based measures with mesh using concept frequencies estimated from a biomedical corpus. results obtained with snomed ct or the umls using concept frequencies from a clinical corpus may differ. however, for many applications, computing corpus ic may not be practical: in addition to the lack of availability of large clinical corpora, the estimation of concept frequencies requires an annotated corpus. automated concept annotation methods may be confounded by textual ambiguity, and manual concept annotation may be impractical for large corpora  <cit> .

future directions
strengths of our study include the evaluation of a wide range of measures using multiple benchmarks and knowledge sources, and the assessment of the statistical significance of differences between measures and across knowledge sources. previous evaluations of semantic similarity and relatedness in the biomedical domain utilized the pedersen benchmark of  <dig> concept pairs with snomed ct. on the smaller pedersen physicians benchmark, distributional vector based measures significantly outperformed knowledge based measures. in contrast, on the larger umn benchmark, intrinsic ic based measures significantly outperformed path finding and distributional vector based measures. these findings suggest that future evaluations of semantic similarity and relatedness measures in the biomedical domain should utilize larger benchmarks to ensure the reliability of results.

to facilitate the application of semantic similarity measures to text processing applications, we developed tools for computing semantic similarity measures; we integrated these tools with a popular clinical natural language processing pipeline; and we released them as open source, available under http://code.google.com/p/ytex. we are currently evaluating semantic similarity measures on word sense disambiguation and document classification tasks.

CONCLUSIONS
we evaluated knowledge based semantic similarity measures using different biomedical knowledge sources, and we compared the accuracy of these measures against benchmarks of semantic similarity and relatedness. we found that intrinsic ic based measures achieved the best performance across a wide range of benchmarks and knowledge sources; intrinsic ic based measures performed as well or better than distributional measures; and that measures based on the umls achieve significantly higher accuracy than those based on smaller knowledge sources such as mesh or snomed ct.

competing interests
the authors declare that they have no competing interests.

authors' contributions
vg conceived the study, implemented the algorithms, and performed the evaluations. vg and cb drafted the original manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
appendix  <dig> 

click here for file

 additional file 2
appendix  <dig> 

click here for file

 acknowledgements
this work would not be possible without the publicly available semantic similarity benchmarks and tools provided by bridget mcinnes, sergei pakhomov, and ted pedersen. we appreciate the feedback from our anonymous reviewers, whose insightful comments greatly improved the manuscript. this work was supported in part by nih grant t <dig> lm <dig> from the national library of medicine, ctsa grant number ul <dig> rr <dig> from the nih national center for advancing translational sciences , and va grant hir 08– <dig> hsr&d: consortium for health informatics.
