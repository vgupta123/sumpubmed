BACKGROUND
recent advances in microarray technology have made it feasible to rapidly measure the expression levels of tens of thousands of genes in a single experiment at a reasonable expense  <cit> . this technology has facilitated the molecular exploration of cancer  <cit> . for medical applications, gene expression profiling can be used to develop classifiers of prognosis or sensitivity to particular treatments. a large literature on the development and validation of predictive classifiers has emerged  <cit> . most of the classifiers developed have involved complex models containing numerous genes  <cit> . this has limited the interpretability of the classifiers and lack of interpretability hampers the acceptance of such diagnostic tools. classification models based on numerous genes can also be more difficult to transfer to other assay platforms which may be more suitable for clinical application. several authors have suggested that simple models could perform well in some cases of microarray-based cancer prediction  <cit> .

the development of a molecular classifier includes gene selection and classification rule generation. a variety of gene selection strategies have been used. these include univariate gene selection and more complex multivariate methods. in  <cit> ,  <cit>  and  <cit> , the authors investigated classification based on a small number of selected gene pairs. in  <cit> , the authors explored the use of one or two genes to perform tumor classifications. these investigations indicated that for the data examined, classifiers could be developed containing few genes that provided classification accuracy comparable to that achieved by more complex models. some more complex algorithms have been used to select few genes for classification, but often overfit the data  <cit> .

many different classification rules have been proposed for high dimensional predictive classification including support vector machines , diagonal linear discriminant analysis , artificial neural network , prediction analysis of microarrays , na√Øve bayes , k-nearest neighbor , nearest centroid , decision tree , random forest , rough set   <cit> , emerging pattern   <cit>  etc. most of these methods produce "black-box" models, in which class predication is based on mathematical formulae which are difficult to interpret.

in this study, we explored the usefulness of very simple single gene classification models for molecular classification of cancer. although in  <cit> , the authors have investigated the use of single genes for classification of cancer, the applicability of that method was limited in that the authors identified multiple single genes potentially having good classification performance instead of determining one which would be validated and used for cancer prediction.

we compared the performance of the single gene models to that of a wide variety of more standard models using eleven publicly available gene expression datasets   <cit> . we also compared the performance of single gene classifiers to a wide range of standard classifiers on the datasets evaluated in  <cit> .

RESULTS
method
note:

 <dig> sgc-t: single gene classifier with the t-test gene selection method.

 <dig> sgc-w: single gene classifier with the wmw gene selection method.

 <dig> for each dataset, the highest classification accuracy is highlighted with a single asterisk and the second highest is highlighted with a double asterisk.

from table  <dig>  we can see that the melanoma is an easily-classified dataset for which all the methods exhibit very high classification accuracy. in contrast, breast cancer  <dig> is a difficult dataset for which the standard methods show relatively low classification accuracy, whereas the single gene classifiers based on wmw and t-test show the best and second best results, respectively. in the brain cancer dataset, the t-test and the wmw single gene classifiers achieved the highest and second highest classification accuracy, respectively. in the breast cancer  <dig> dataset, the wmw and the t-test single gene classifiers show poorer accuracy than other methods. in the gastric tumor dataset, the wmw and the t-test classifiers show poorer accuracy than the k-nn, svm and rf classifiers but are comparable to the dlda classifier. in the lung cancer  <dig>  lung cancer  <dig>  myeloma and prostate cancer datasets, the classification results obtained by the wmw and the t-test single gene classifiers are close to those obtained by the other four methods. surprisingly, in the lymphoma and the pancreatic cancer datasets, the classification results obtained by the wmw and the t-test single gene classifiers are much better than those obtained by the other four methods. for the evaluations based on separating each dataset into training and test sets, we obtained similar conclusions .

the number of genes used for building the classifiers averaged across the loops of the cross validation is listed in table  <dig> for each method. from this table, we can see that the dlda, k-nn, svm and rf have used a large number of genes for constructing the classifiers in most of the eleven datasets. the number of genes in the classifiers constructed in the cases of separating samples into one training set and one test set is presented in table s <dig> and table s <dig> .

method
generally speaking, in the datasets with small sample sizes such as those for melanoma, brain cancer, lung cancer  <dig>  lymphoma and pancreatic cancer, the single gene classifiers showed better or comparable classification results compared with the standard methods. in the datasets with relatively large sample sizes like the lung cancer  <dig>  gastric tumor and myeloma, the single gene classifiers showed poorer results. one possible explanation is that complex models require larger datasets for training and in some cases may be overfit for smaller datasets. the comparative results were not very related to the number of genes in the dataset. all datasets included many thousands of genes and as noted in  <cit> , a good classifier from high-dimensional microarray data can involve a short gene list if there are many genes with large differences in expression between the classes. clearly, in the melanoma, gastric tumor, lung cancer  <dig>  lung cancer  <dig> and prostate cancer dataset, there are many genes with large differences in expression between the classes so that it is not difficult to find a single gene on which to base a good classifier. in such cases, it is unnecessary for the standard algorithms to use so many genes in constructing classifiers for these datasets . actually, the single gene classifiers achieve near-optimal classification results in these datasets. in contrast, if there are very few genes with large differences in expression between the classes, it will be difficult to build an effective single gene classifier because the gene selected may be the noise-gene with the greatest apparent degree of differential expression. in some cases, however, it might be equally difficult for complex algorithms to produce good classifiers for this sort of dataset, particularly when the sample size is small and overfitting is likely to occur. this might explain why the single gene classifiers performed better than complex classifiers in some difficult small sample datasets like the brain cancer, lymphoma and pancreatic cancer.

single gene classifiers are more influenced by selection of noise genes than standard methods. some ''noise'' genes could have good t-test or wmw test statistics in the training set, and if such genes were selected for building the single gene classifiers, the performance of the classifiers would be poorer than the classifiers built based on a longer gene list. in the breast cancer  <dig> and myeloma datasets, it was likely that the selection of ''noise'' genes had contributed to the poor results of the single gene classifiers. in fact, in the breast cancer  <dig> dataset, we found one gene in the list of five genes with the smallest t-test p-value, which could result in 73% classification accuracy, and in the myeloma dataset, we found one gene in the list of  <dig> genes with the smallest t-test p-value, which could result in 92% classification accuracy. both results are much better than those obtained by using the present gene selection methods . therefore, sometimes it might be better to include a longer gene list in classifiers to prevent from falling into the trap of noise genes.

parameter
note:

athe minimum univariate t-test p-value for the genes significantly different between the classes.

bthe absolute value of the t-test statistic corresponding to the left smallest p-value.

cthe maximum fold change in the geometry mean of gene expression between the classes,

dthe total number of genes significantly different between the classes at  <dig>  significance level.

ethe mean classification accuracy of the four standard classifiers.

fthe mean classification accuracy of the two single gene classifiers.

we also evaluated single gene classification on the datasets studied in  <cit> . in  <cit> , the authors compared the classification results produced by some standard classifiers including those used in this study. they built classifiers based on selecting the  <dig>   <dig>   <dig>   <dig> and  <dig> genes with the largest absolute t- and wilcoxon statistics as well as all genes to conduct four classification experiments in two datasets  <cit> . table s <dig> is a summary of results for those two datasets .

we preprocessed the data as described in  <cit> , and then performed a complete loocv to obtain the honest estimates of classification error. table s6- <dig> list classification results for the single gene classifiers as well as part of the results presented in  <cit>  for comparison . these tables show that for the two datasets in  <cit> , error rates for the single gene classifiers are generally close to those produced by standard methods. the one exception was the high error rate for the single gene classifier based on the wilcoxon statistic in the breast tumor estrogen dataset .

two-gene classifiers have attracted a broad interest for their simplicity and interpretability, among which the top-scoring pair  classifier was based on decision rules induced by comparing mrna abundance in gene pairs  <cit> . we applied the tsp classifier to the eleven gene expression datasets and compared its performance to that of our single gene models . table  <dig> demonstrates that the classification performance of our single gene classifiers is comparable to that of the tsp classifier. our single gene classifiers have a substantial advantage over the tsp classifier in time efficiency for development and evaluation in cross validation.

method
note: the number of gene pairs selected is set as one for the tsp classifier.

the stability of the genes selected across the cross validation  loop is also an important criterion to evaluate the usefulness of simple classifiers which involve a small number of genes. table  <dig> presents all the genes selected and their occurrence percentages across the cv loop by the single gene classifiers in every dataset. generally speaking, the genes selected across the cv loop with our methods are relatively stable .

note: in breast cancer  <dig>  the genes are denoted by clone id; in breast cancer  <dig> and gastric tumor, the genes are denoted by genbank accession number; in all the others, the genes are denoted by probe set.

discussion
in contrast to most of the data investigated in traditional machine learning and data mining applications which are often composed of low-dimensional attributes and high-dimensional instances, microarray data are composed of high-dimensional attributes  and low-dimensional instances . consequently some traditional machine learning and data mining algorithms which are effective for the former become ineffective for some p > n problems like microarray classification. excellent classification can in some cases be achieved with a small number of genes, even a single gene selected from thousands of candidates. optimal complexity depends on the degree of differential expression among the classes and sample size. complexity is not, however simply the number of genes in the classifiers. complexity also depends on gene selection criteria and classification rules employed. simple models typically involve a simple feature selection scheme and simple classification rule. in contrast, complex models often involve sophisticated feature selection procedures and/or complicated classification rules. models based on complex algorithms for multivariate gene selection and complex classification rules may contain few genes but overfit the data. empirical comparisons have indicated that complicated wrapper methods such as aggregated classification trees sometimes perform poorly compared to simple classifiers such as dlda and k-nn in some cases  <cit> .

gene selection is critical in building good classifiers and there is no simple completely general answer to the question of how many genes a good classifier should include? for interpretability and ease of porting to assay platforms more suitable to use in clinical practice, it is advantageous to include a small number of genes in the classifier. the optimal number of genes depends on the sample size, the number of differentially expressed genes, their degree of differential expression and correlation structure and the type of classifier used  <cit> . in some cases, the number of genes or other aspects of classifier complexity can be regarded as tuning parameters to be optimized by an inner-loop of cross-validation  <cit> . our results indicate that single-gene models should be included as candidate classifiers in such optimization.

in  <cit> , the authors explored the sensitivity to number of features for some standard classifiers, and found only limited changes in performance when varying the number of genes used with a lower limit of  <dig> genes. classification accuracy with  <dig> genes was in most cases as good as or better than accuracy with more genes. although the univariate feature selection approach used by dudoit and fridyland was simple compared to some of the complex multivariate feature selection approaches that have been used, the former often outperformed the latter  <cit> .

we have found that single gene classification models are frequently of commensurate accuracy as more complex classifiers. for problems with genes that are quite differentially expressed, single gene classifiers appear to do well. for more difficult problems without highly differentially expressed genes, it can be useful to include more genes in the model instead of using the single most extreme gene which may be noise. in some of these cases with small number of samples, however, the single gene model might do as well because models with more genes may overfit the data.

for most of the datasets examined, the single-gene classification methods appear to work as well as more standard methods such as dlda, svm, k-nn and rf, based on a larger number of genes, and two-gene classifiers such as the tsp classifier. here the classification results used for comparison obtained by dlda, svm, k-nn and rf might not be optimal as we have pre-specified their model parameters rather than optimized these parameters. thus, we re-examined the classification results obtained through optimizing the parameters of the compared classification models. for k-nn, we compared the three groups of classification results obtained by1-nn, 3-nn and the nearest centroid, respectively. these results were close to each other . furthermore, we re-classified the eleven data sets using the dlda, k-nn and svm classifiers with the optimized gene selection significance level which was chosen from the grid  <dig> ,  <dig> ,  <dig> , and  <dig>  in order to minimize the cv error rate. table s <dig> presents the classification accuracies attained with the optimized and no- optimized parameter for all of the datasets , suggesting that their gap is minor. in addition, we examined the classification results achieved under varied values of tuning parameter cost for svm for selected datasets and found no change. finally, we investigated the performance variation of the rf classifier by tuning its two parameters: the number of trees and the number of genes randomly sampled as candidates at each split. we found that the performance variation was minimal. in summary, the classification performance with the pre-specified parameters is close to that with the optimized parameters for dlda, svm, k-nn and rf, and therefore the conclusions gained from the comparison analyses of our single-gene classifiers and the standard classifiers are justified.

our single gene classifier for a training set was developed by applying the entropy-based discretization method to find the optimal cut point for the single gene selected based on the t or wmw statistics . of course, the cut-point finding could also be included in the single gene selection like the methods proposed in  <cit> . however, our experiments have indicated that the cut-point based feature selection for all genes would greatly compromise the time efficiency of the algorithm for high-dimensional gene expression data which generally contain thousands of attributes. additionally, the gene selection methods involved in discretization may miss the most informative genes because the discretization procedure itself could cause the partial loss of the information hidden behind data. by contrast, the t-test or wmw based gene selection approach can avoid of this kind of information loss, and therefore is more likely to select the most informative genes. including optimal discretization in gene selection could also result in overfitting the training set. this issue could be addressed in future research.

CONCLUSIONS
to deal with high-dimensional gene expression data, simple classifiers should be preferred to complicated ones for their interpretability and applicability. in the present study, we developed extremely simple single-gene classifiers. we examined a large number of datasets and a large number of previously published classifier algorithms and found that our single gene classifiers have comparable performance to more complex classifiers in most cases examined. our algorithm for development of single gene classifiers is computationally efficient and the single gene developed appears reasonably stable. although single gene classifiers are not always successful, their examination is worthwhile because of their advantages for interpretability and applicability for biological study and medical use.

