BACKGROUND
high-throughput sequencing  technologies enable the detection of rare and common variants at the genome-wide scale for thousands of individuals  <cit> . in addition, with population-specific reference panels comprised of detected variants from hts, low-frequency variants can be imputed accurately from single-nucleotide polymorphism  array genotype data  <cit> . thus far, associations between snps and disease phenotypes have been studied for genotype data from hts and snp arrays, and the recent focus has moved to rare and low-frequency variants. unlike common variants, the power of rare and low-frequency variants on single-variant association tests is low because of the lack of allele counts, even with thousands of individuals.

to address this issue, rare and low-frequency variants are often grouped at the gene or pathway level, and the effects of multiple variants are evaluated. this type of strategy is called collapsing, and the sequential kernel association test   <cit>  is one of the most effective collapsing methods  <cit> . because the p-values based on skat are derived from an asymptotic distribution of its statistics, the p-values for datasets with an insufficient number of samples may be inaccurate, which causes inflation or power loss. to obtain accurate p-values, resampling methods such as the permutation test can be implemented in skat. however, resampling requires a huge amount of computation time to obtain high-resolution p-values for the correction of multiple comparisons, and hence a more efficient resampling method is necessary.

therefore, we propose an adaptive procedure, termed ap-skat, for the highly efficient calculation of skat statistics. this procedure adaptively stops the permutation test when the significance level is outside some predetermined confidence interval for the estimated p-value. in this evaluation, we propose the following criteria to stop the permutation test and obtain a p-value:  when all permutation statistics are greater or less than the original statistic, the calculation is terminated when the probability of the event is less than the significance level, and  the calculation is terminated when the confidence interval of the estimated p-value does not include a significance level. to show the effectiveness of the proposed procedure, we first evaluate the power and sample size calculations of skat  <cit> , skat-o  <cit> , and the proposed procedure using a genotype dataset in the skat r package  <cit> . second, we also evaluate the type i error rate of skat-o and the proposed procedure using real whole genome sequencing  data from the  <dig> genomes project   <cit> . finally, computational experiments additionally using snp array data downloaded from the wellcome trust case control consortium   <cit>  and the international hapmap project  <cit>  show that the proposed procedure can calculate highly accurate p-values within a reasonable time. we conclude that the proposed procedure is applicable to recent sequencing and genotype imputed data with large amounts of phenotype data.

implementation
sequential kernel association test
let n and m be the number of individuals and grouped snps, respectively. a skat test statistic s is calculated as 
  <dig> s=′gwg′, 

where y is an n-dimensional vector of observed phenotypes, μ is an n-dimensional vector of predicted means under the null hypothesis, i.e., the target phenotype has no association with the genotypes, using the logistic and the linear models for case/control studies and quantitative trait analysis, respectively. g is given by ′, where gi is an n-dimensional vector including the genotypes of n individuals for the ith snp and w=diag is an m×m diagonal matrix consisting of weights wj for the jth variant.

in calculating skat statistics, we assume 
  <dig> yi=αi+β1g <dig> i+…+βmgm,i+εi, 

where yi is the ith element of y,α is a constant that is unrelated to genotypes, βj is the effect size of the jth snp, gi,j is the ith row and jth column of g, and εi is a noise term that obeys a gaussian distribution. a good property of s is that it corresponds to a mixture of chi-squared distributions, and we can calculate the p-values for the obtained statistics when the optimal conditions are satisfied  <cit> . however, it has been suggested that the distribution of s differs from the ideal one when the sample size n is insufficient and the phenotype data do not follow a gaussian distribution. thus, in case/control or cohort genome studies with limited samples, it is not valid to evaluate the test statistics based on a mixture of chi-squared distributions. in this case, lee et al.  <cit>  suggested to use the optimal adjustment technique termed skat-o to combine burden test and the moment adjustment technique to modify the distribution instead of using the permutation test, and wu et al.  <cit>  also proposed an alternative calculation procedure to efficiently and analytically calculate the adaptive sum of skat-o statistics. however, even when applying these techniques, the modified distribution includes residual biases. additionally, for the permutation test with more than  <dig>  snp sets, grouping snps into gene level and considering multiple test is not practical because it requires at least  <dig> × <dig>  or  <dig> × <dig>  tests for each snp set, where αp is the significance level. thus, we focus on obtaining detailed p-values for sets of rare snps associated with phenotypes around the predefined significance level αp through the permutation test, and efficiently calculate p-values by adaptively stopping the test for plausible/improbable sets.

distribution of estimated p-values in permutation test
in the process of a permutation test, let b and r be the number of permutations completed and the number of permutation statistics that are greater than the original statistic s using the observed data, respectively. in this case, we consider a binary random variable x, which takes a value of  <dig> when a permutation statistic is greater than s and  <dig> otherwise, according to a previous snp analysis  <cit> . we take the expectation and the variance of x corresponding to each of the permutations considered so far to be 
  <dig> exp=p^=r/b, 

  <dig> var=exp−exp2=p^, 

where p^ is the estimated p-value of an snp set on the bth permutation. thus, the bienaymé formula for the sum of variances gives the variance of the mean as 
  <dig> var=p^b. 

according to the central limit theorem, we consider p^ to correspond to a gaussian distribution n/b) and obtain dα as the distance between the α confidence interval of the distribution. in this binomial setting, we fix the number of permutations b and consider the numerator r as a random variable to estimate p^. then, we compare the α confidence interval of p^ with αp, where αp is a predetermined significance level considering multiple comparisons, and continue the permutation until either the α confidence interval does not include αp or b becomes b. figure  <dig> exemplifies this situation. in contrast, chen et al.  <cit>  used a negative binomial setting by fixing the total number of successes r and considering the denominator b as a random variable to estimate p^. they chose b and r to control the standard error of p^ at some determined values with αp, and continued the permutation until r became r or b became b.
fig.  <dig> a sample figure exemplifying the distribution of the expectation of the estimated p-value and the stop criteria in the proposed procedure. the α confidence interval d
α of the distribution of the estimated p-value p^ is colored gray. b and r are the number of permutations completed and the number of permutation statistics that are greater than the original statistic s using the observed data, respectively. the stop criterion is evaluated using p±d
α/ <dig> and α
p, which is the predefined significance level



however, when r is  <dig> or b, the variance becomes  <dig> and it is not reasonable to use the criteria for terminating the permutation test. thus, we adopt a negative binomial distribution. let y be a positive integer random variable indicating the number of trials and αe=αp×m, where m is the number of snp sets. assuming that the true p-value is at most αp  or at least αe , we attempt to obtain the probability of b occurring with r and finish the permutation test at αp. hence, when r is  <dig>  if the probability nb is less than αp, which gives an αp confidence level of p^=αp, the permutation test can be stopped and we obtain p^=1/b. similarly, when r is b, if the probability nb is less than αp, the permutation test can be stopped and we obtain p^= <dig> 

if more precise p-values are needed for significant snp sets, we can ignore the stop criterion if p^<αp and proceed with b permutation tests to obtain the minimal p^=1/b.

adaptive skat
our proposed procedure adaptively stops the permutation test when the significance level αp is outside the α confidence interval of the estimated p-value using the binomial distributions described in the previous subsection. the proposed procedure is described in algorithm  <dig>  the following values are taken as input parameters: the significance level αe , maximum number of permutation tests b, which must be at least 1/αp, and significance interval α for the gaussian distribution. note that, in practice, we should also set the number of tests performed in the same loop to m for computational efficiency. we recommend to set b=5/αp,α=αp, and m= <dig> as those used in the results section.



in practice, when snps are grouped at the gene level, the number of snp sets exceeds  <dig> . although our proposed procedure can handle a few phenotypes on a single processor within a reasonable time, multiple phenotypes and their combinations will entail a huge computational cost. as in many association testing procedures, we therefore recommend using parallel computation to calculate the p-value for each snp set on a different core.

RESULTS
we first examine the comparison of power and sample size calculation of skat, skat-o, and the proposed procedure. in these experiments, according to the skat r package and previous literatures  <cit> , we adopted the following settings; we used a numerical matrix of  <dig>  haplotypes over a  <dig>  base pair region, where each row represents a different haplotype and each column represents a different snp marker. the matrix was generated by the calibration coalescent model  base on the ld structure of european ancestry  <cit> . as with the skat r package, to evaluate the power of the above methods, we simulated datasets under the alternative model; thus, we repeatedly and randomly selected  <dig> kb regions from a broader region, and then randomly set causal variants from the rare variants with a minor allele frequency  of less than  <dig>  in each simulation. for generating phenotypes, we considered  <dig> % of the rare variants were causal variants and  <dig> % of βj to be positive and the rest to be negative, and set max effect size as { <dig> , <dig> , <dig> , <dig> , <dig> }. the results of  <dig>  simulations at αe = { <dig> ,10− <dig> −4} and the sample size { <dig> , <dig> , <dig> , <dig> ,500} are summarized in tables  <dig>   <dig>   <dig>   <dig> and  <dig>  these results show that the proposed procedure can perform relatively higher power than skat and skat-o even when the sample size and the effect size are small, and also could retain the competitive power when these are high values, which can achieve type ii error of almost  <dig> . even when the phenotype is not according to the idea distribution, the proposed procedure could control the lower type i error than that of skat-o.


additionally, we evaluated the type i error rate of skat-o and the proposed procedure when {β <dig> …,βm are  <dig> and ε in eq.  is according to the student’s t -distribution with  <dig> degrees of freedom; thus, the distribution of phenotypes is a heavier tailed distribution than the ideal normal one. in this setting, we applied illumina wgs data for  <dig>  samples from  <dig> populations across africa, east and south asia, europe, and the americas in the  <dig> genome project  <cit>  and performed  <dig> experiments for each sample size of { <dig> , <dig> , <dig> ,000}, which are randomly extracted from the data. the results of the number of false positives in using skat-o and the proposed procedure are concluded in table  <dig> and it indicates that the proposed method can reduce the number of false positives even when the distribution has heavier tails than the normal ones.


finally, to validate the proposed approach, we compared the computation times and estimated the p-values given by the permutation test  and the adaptive procedure. for this comparison, we prepared genotype data on the previous wgs data from  <dig> genome project, illumina infinium  <dig> snp beadchip for  <dig>  samples from the  <dig> british birth cohort in the wellcome trust case control consortium  <cit> , and on the illumina snp chip for  <dig>  individuals from  <dig> populations, including  <dig> of the original  <dig> phase i and phase ii individuals in the international hapmap project  <cit> . their quantitative phenotype data were synthetically generated according to a gaussian distribution and snps were grouped at the gene level. note that only those snps annotated as ‘high’ and ‘moderate’ by the snpeff tool  <cit>  were selected as plausible ones for 1000gp, because wgs data include a lot of less significant snps. all snps were grouped at the gene level for the data from wtccc and hapmap. in these experiments, we also consider snps with maf of less than  <dig> . the combination of significance levels α,b, and m were set to { <dig> , <dig> ×10− <dig> .5×10−11},{ <dig> ,…, <dig> ×107}, and min{n/ <dig> }, respectively. all computations were performed on  <dig> nodes of an intel xeon cpu e5- <dig> v <dig> @  <dig>  ghz  in our supercomputer system.
fig.  <dig> comparison of computation times between the standard and permutation procedures using  <dig> genomes project data, wtccc, and hapmap. solid and dotted lines indicate the runtimes of the standard and adaptive procedures, respectively



in fig.  <dig>  the estimated p-values in the adaptive procedure clearly approach those of the standard procedure according to the spread of the confidence interval, and they are almost the same when the confidence interval is lower than  <dig> ×10− <dig>  even if the confidence interval was set to around  <dig> , the tendency of the p-values could be observed, enabling us to clarify whether the p-values of snp sets exceeded the threshold value. these results indicate that the proposed procedure can be applied at the whole genome scale to achieve arbitrary confidence levels within a reasonable time.
fig.  <dig> comparison plot with several confidential intervals using the  <dig> genomes project data, wtccc data, and hapmap data. the comparisons of estimated p-values for the  <dig> genomes project data, wtccc data, and hapmap data by the standard and the adaptive procedures with a significance interval of  <dig> , <dig> ×10− <dig> and  <dig> ×10− <dig>  solid and dotted lines are the base line and the bonferroni corrected significance level , respectively. circles indicate the estimated p-values of snp sets by the standard and the adaptive procedures, and the numbers of snp sets is  <dig> , <dig> , <dig> , respectively. both the vertical and the horizontal axes in these figures are logarithmic scale



CONCLUSIONS
in this paper, we proposed a novel rare variant association procedure that can calculate the p-values for sets of snps within a reasonable time. a comparison experiment showed that the proposed procedure significantly reduced the computational cost while maintaining the estimation quality at predefined significance levels, and can be bounded at a reasonable cost even if we select the highest significance level. this result demonstrates that the proposed procedure is capable of calculating p-values of snp sets for wgs data that cannot be evaluated by the standard permutation procedure. in addition, this procedure can be applied to other common/rare variant association tests  <cit> . the r code is available at http://nagasakilab.csml.org/data/askat.zip, for which input is either one of plink format files or a numeric matrix.

availability and requirements
project name: ap-skatproject home page: http://nagasakilab.csml.org/data/askat.zipoperating system: platform independentprogramming language: rany restrictions to use by non-academics: please contact authors for commercial use.

