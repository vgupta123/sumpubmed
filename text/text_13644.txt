BACKGROUND
scientific workflows management systems  <cit>  are increasingly used to specify and manage bioinformatics experiments. their simple programming model appeals to bioinformaticians, who can use them to easily specify complex data processing pipelines. however, as stated by recent studies  <cit> , while the number of available scientific workflows is increasing along with their popularity, workflows are not used and shared as much as they could be.

in this work, we have focused specifically on the taverna workflow management system  <cit> , which for the past ten years has been popular within the bioinformatics community  <cit> . despite the fact that hundreds of taverna workflows have been available for years through the myexperiment public workflow repository  <cit> , their reuse by scientists other than the original author is generally limited. some of the causes for the limited reuse have been identified in the sheer difficulty to preserve a workflow's functionality vis-a-vis the evolution of the services it depends on  <cit> . in addition to this, another factor that limits reuse is the complexity of workflow structure, that involves the number of nodes and links but is also related to intricate workflow structure features. several factors may explain such a structural complexity including the fact that the bioinformatics process to be implemented is intrinsically complex, or the workflow system may not provide appropriate expressivity, forcing users to design arbitrary complex workflows.

in the present work, the system considered is taverna. our approach aims at automatically detecting parts of the workflow structure which can be simplified by removing explicit redundancy and proposing a possible workflow rewriting. our preliminary analysis of the structure of  <dig>  scientific workflows collected from myexperiments reveals that, in numerous cases, such a complexity is due mainly to redundancy, which is in turn an indication of over-complicated design, and thus there is a chance for a reduction in complexity which does not alter the workflow semantics. our main contention in this paper is that such a reduction in complexity can be performed automatically, and that it will be beneficial both in terms of user experience , and in terms of operational efficiency .

our specific contribution is a method for the automated detection and correction of certain taverna workflow structures which can benefit from refactoring. we call these idiomatic structures 'anti-patterns', that is, patterns that should be avoided. our approach involves the detection of several anti-patterns and the rewriting of the offending graph fragment using a new pattern that exhibits less redundancy and simpler structure while preserving the semantics of the original workflow. we have then designed the distillflow algorithm and evaluated its effectiveness both on a public collection of taverna workflows and on a private collection of workflows from the biovel project.

the rest of the paper is organized as follows. the background section will continue by briefly summarize the taverna workflow system features. in the methods section we will introduce the anti-patterns we have identified and the transformations we propose to do while ensuring that the semantics of the workflow remains unchanged. we will then introduce the distillflow refactoring algorithm. in the results section, we provide the results obtained by our approach on a large set of real workflows.

workflows in taverna
as mentioned earlier, this work is specific to the taverna workflow model  <cit> , which we briefly summarize here. examples of taverna workflows are given throughout the paper. taverna combines a dataflow model of computation with a functional model that accounts for list data processing. a workflow consists of a set of processors, which represent software components such as web services and may be connected to one another through data dependencies links. this can be viewed as a directed acyclic graph in which the nodes are processors, and the links specify the data flow. processors have named input and output ports, and each link connects one output port of a processor to one input port of another processor. a workflow has itself a set of input and output ports, and thus it can be viewed as a processor within another workflow, leading to structural recursion.

the workflow depicted in figure  <dig> , for instance, has one input called name and two outputs named respectively average and standarddev. in turn, processor getstatistics_output has one input port named input and five output ports named average, kurtosis, skewness, standarddeviation and sums. we call the triple 〈< workflow name >, < workflow inputs >, < workflow outputs >〉 the signature of the workflow.

note that multiple outgoing links from processors or inputs are allowed, as is the case for the workflow input of figure  <dig>  which is used by two processors. also, not all output ports must be connected to downstream processors , and symmetrically, not all inputs are required to receive an input data .

input ports are statically typed, according to a simple type system that includes just atomic types  and lists, possibly recursively nested . the functional aspects of taverna come into play when one or more list-value inputs are bound to processor's ports which have an atomic type . in order to reconcile this mismatch in list depth, taverna automatically applies a higher-order function, the cross product, to the inputs. the workflow designer may specify an alternative behavior by using a dot product operator instead. this produces a sequence of input tuples, each consisting of values that match the expected type of their input port. the processor is then activated on each tuple in the list. there resulting "implicit iteration" effect can be defined formally in terms of recursive application of the map operator  <cit> .

methods
this section begins by illustrating the two main types of anti-patterns found by our workflow survey, by means of two use cases. the formalization of the anti-patterns and the distillflow algorithm will be then introduced.

use cases
the first use case ) involves the duplication of a linear chain of connected processors getstatistics_input, getstatistics and getstatistics_output. the last processor in the chain reveals the rationale for this design, namely to use one output port from each copy of the processor. clearly, this is unnecessary, and the version in figure  <dig>  achieves the same effect much more economically, by drawing both output values from the same copy of the processor.

in the second use case ), the workflow begins with three distinct processing steps on the same input sequence. we observe that the three steps that follow those are really all copies of a master get_image_from_url task. this suggests that their three inputs can be collected into a list, and the three occurrences can be factored into a single occurrence which consumes the list. by virtue of the taverna list processing feature described earlier, the single occurrence will be activated three times, one for each element in the input list. also, the outputs of the repeated calls of get_image_from_url will be in the same order as items in the list. therefore this new pattern achieves the same result as the original workflow. note that collecting the three outputs into a list requires a new built-in merge node ). similarly, a split processor has been introduced to decompose the outputs  into three single outputs.

these two examples are instances of the general patterns depicted in figures  <dig> and  <dig> . these are the anti-patterns we alluded to earlier, and our goal is to rewrite them into the new structures shown in the right hand side of the figures. in the rest of this section we describe this rewriting process in detail.

anti-patterns and transformations
the transformations aim at reducing the complexity of the workflow by replacing several occurrences of the same processor with one single occurrence whenever possible. although new processors are sometimes introduced in the process , on balance we expect a cleaner design, better use of the functional features of taverna  and lower redundancy, and thus fewer maintenance problems.

assumptions
the following four assumptions must hold for processor instances to be candidates for the transformations described below.

 <dig>  a processor must be deterministic: it should always produce the same output given the same input.

 <dig>  only processors implemented using the exact same code can be merged. determining that two processors are equivalent is an open problem  since it is directly associated to determining the equivalence of programs. in our setting, two processors are equivalent if they represent identical web service calls, or they contain the same script, or they are bound to the same executable java program. in practice, this condition is often realized, because processors are duplicated during workflow design by means of a graphical "copy and paste" operation.

 <dig>  only copies of processors that do not depend on each other can be merged, that is, if p and p are two occurrences of the same processor p, then there should not be any directed path between p and p, for p and p to be merged.

 <dig>  we will consider only two cases where we can be sure that the same input value li can be bound to the input port ai of r copies of p:  the input port ai is bound to a constant value which is identical across executions  of p, or  li has been produced by the output port of some processor qi and has been distributed to the r copies of p.

transformations
the two proposed transformations are shown in figures  <dig> and  <dig>  where each p  denotes an occurrence  of processor p, with input and output ports a <dig>  ..., ak and b <dig>  ..., bq, respectively.

anti-pattern a: in the first anti-pattern , the input ports ai of each processor occurrence p are all bound to the same value li, for  <dig> ≤ i ≤ k,  <dig> ≤ l ≤ r. it follows from our assumption of determinism that the output ports bj all present the same output value oj across all p, for  <dig> ≤ j ≤ q.

the rewriting replaces all p with a single occurrence, p.

treatment of the outputs: outgoing links are then added to ports bj as needed.

treatment of the inputs: for each input port ai of p, the unique input value li bound to ai is now either the constant value as previously in the  anti-pattern ), or it is one of the distributed values bound to some output port of some processor qi ) and in this last case processor qi does not need to distribute this output value more than once anymore.

illustration: one example of anti-pattern a is depicted on figure  <dig>  where the same workflow input is sent to two exact copies of the processor getstatistics_input. the workflow input plays the role of processor q. getstatistics_input and getstatistics_2_input are thus merged and the workflow input  is sent only once to the downstream of the workflow, that is, to the  single getstatistics_input processor. outputs are linked to the rest of the workflow and transformations must be applied as many times as necessary. in this example, three successive transformations are applied thus giving the workflow of figure  <dig> .

anti-pattern b: in the second pattern , the input ports ai of each processor occurrence p are bound to the same value li, for  <dig> ≤ i ≤ t while the input ports at +  <dig> to ak of each processor occurrence p are bound to different inputs lt+1l to lkl among occurrences,  <dig> ≤ l ≤ r. as for output values, let oil=p|bi denotes the output value produced by output port bi of the l-th occurrence of p. for the sake of generality, we consider here that processor p applies cross product to values on ports a <dig> to at and dot product to values on ports at +  <dig> through ak.

the rewriting replaces all p with a single occurrence, p.

input data that differ from one occurrence to another  have been merged using the merge processors provided by taverna  to construct lists of data from the original data items to exploit the implicit iterative process of taverna. as a consequence, the outputs of p are lists of data instead of single values in the original pattern. since p follows a dot strategy on ports at +  <dig> .. ak, o′i is the list o′ i=, for output port bi,  <dig> ≤ i ≤ q.

treatment of the outputs: for each output port bi of p, the rewritten pattern contains a list split processor called splitr to decompose the list obtained into r pieces so that the downstream fragment of the workflow remains unchanged. we get: o′il=p|bil <dig> …,lt,lt+1l,…,lkl.

treatment of the inputs: note that for each input port at+ <dig> ..., ak, input values lil are used in the same way both before and after the transformation . as for input ports a <dig> to at, instead of having r occurrences, each li has now one single occurrence,  <dig> ≤ i ≤ t .

illustration: one example of anti-pattern b is depicted on figure  <dig>  where there are three copies of processor get_image_from_url, each copy receiving input data from distinct processors. the three copies are then merged into one single copy.

the next section will provide more details on how the transformations are extended to the entire workflow.

safe transformations
in this subsection, we introduce the notion of safe transformation. intuitively, a transformation is safe if the semantics of the workflows is preserved .

more formally, let w <dig> be a fragment of a workflow w consisting of r occurrences p...p of a processor p such that there is no directed path between p and p . let w <dig> be a fragment of the workflow w consisting in one occurrence of p and possibly merge and split processors. a transformation that replaces w <dig> by w <dig> in the workflow w resulting in w′ is safe if and only if: given the same workflow input values in, for any execution of w using in, named w ˜, and any execution of w′ using in, named w ˜′, the workflow output values out obtained by w ˜ and w ˜′ are the same.

it is straightforward to prove that the two transformations we propose to perform are safe.

refactoring approach
the previous section has introduced transformations able to locally remove anti-patterns. in this section, we will present the complete refactoring procedure we propose to follow. in particular, we have chosen not to remove all possible anti-patterns when such rewriting operations can make the transformed structures becoming more intricate than the original structures. example of "simple" structures are series-parallel  graphs  <cit>  that are a specific kind of st-dags  which provide well-known advantages in terms of complexity and ease-of-use in various situations . sp-graphs have then naturally been used in the context of scientific workflows  <cit> . the challenge of our refactoring approach then lies in minimizing the presence of anti-patterns while ensuring that the number of structures which are not sp  will not increase. note that it may be the case that our procedure transforms some non-sp structures into sp structures.

without entering into the details, non-sp structures have some specific nodes called reduction nodes which cause the structure to be non-sp. intuitively, a reduction node prevents from ranking the nodes of a dag within series and parallel order. details are provided in  <cit> . we will see how we apply our transformations to such nodes and we go back to this point in the discussion section.

additionally, in the following, we will also make use of the notion of autonomous subgraph introduced in the context of sp structures  <cit> . intuitively, the autonomous subgraphs allow to restrict the initial graph to smaller components such that no edge comes in or goes out of the autonomous subgraph . several autonomous subgraphs can be nested. we will use this notion in order to apply transformations locally, without interaction with the rest of the graph.

principle of the algorithm
the refactoring algorithm takes in an st-dag g and produces an st-dag dsg from g by transforming the anti-patterns that can be removed from g while preserving its sp property. for it, the algorithm starts by identifying the set setau of autonomous subgraphs, and distills each of them, starting with the minimal ones, in a recursive way. once each autonomous subgraph has been distilled, the whole graph g must be distilled in turn. calls of the procedure distill are done from a starting node x that can be either the source of an autonomous subgraph or a reduction node, or the source of g. we consider all the successors p of x, and search among all the other successors  whether there is a processor q that would be a copy of p. if it the case, we merge p and q according to the transformation for anti-patterns  and . every time a transformation is performed, merging copies of a processor may give rise to new autonomous subgraphs, that lead to new distillations in turn. this last job is done by the procedure down-distillation.

 p and q are copies of each other;  p and q are involved in some anti-pattern  or  in gg;  for any autonomous subgraph g' of gg, every time p appears in g', q appears in g' too. this last condition ensures us that we do not remove an anti-pattern by a transformation that would make an sp-graph becoming non-sp.

illustration of the algorithm
we propose to illustrate the execution of the distillflow algorithm on the workflow depicted in figure  <dig> . we can see that it potentially contains several anti-patterns. indeed, it duplicates processors many times: # <dig>  # <dig>  # <dig>  # <dig>  # <dig>  # <dig>  # <dig> all perform the same operation, and so do # <dig>  # <dig>  # <dig>  # <dig>  # <dig>  # <dig>  # <dig>  the graph g representing the taverna workflow is shown in figure  <dig> . note that this graph contains examples of autonomous subgraphs which are g <cit> , g <cit>  and g <cit> , where g <cit>  is nested in g <cit> .

at line  <dig> of the algorithm, autonomous subgraphs g <cit>  and g <cit>  are identified in g. at the first iteration of line  <dig>  the procedure distill is called with g <cit>  and node # <dig>  during this recursive call, first nodes # <dig> and # <dig> are merged according to the transformation of anti-pattern , and then nodes # <dig> and # <dig>  according to transformation of anti-pattern . at the second iteration of line  <dig>  distill is called with g <cit>  and node # <dig>  during this recursive call, nodes # <dig>  # <dig> and # <dig> are first merged ), and then nodes # <dig>  # <dig> and # <dig> ). at line  <dig>  distill is called with g and s. a first recursive call with g and node # <dig>  does not change anything. recursive calls starting with g and node # <dig>  successively merge nodes # <dig> and # <dig> ), and then nodes # <dig> and # <dig> , figure  <dig> ). subsequent calls of distill with g and node # <dig>  or with g and node # <dig> do not imply any transformation. note that nodes # <dig> and # <dig> are not merged since oktransformation is false . figure  <dig>  shows the final workflow where almost all the anti-patterns have been removed.

RESULTS
anti-patterns in workflow sets
we have applied the refactoring approach on two workflow sets: the public workflows from myexperiments and the private workflows of the biovel project , a consortium of fifteen partners from nine countries which aims at developing a virtual e-laboratory to facilitate research on biodiversity. biovel promotes workflow sharing and aims at providing a library of workflows in the domain of biodiversity data analysis. access to the repository to contributors, however, is restricted and controlled. because of the restricted access and the focus on a specific domain of these workflows, they are broadly expected to be curated and thus of higher quality than the general myexperiment population.

for each workflow set, the total number of workflows, the number of workflows having at least one anti-pattern  or ) are provided in table  <dig>  note that it is possible that the same workflow contains the two kinds of anti-pattern.

interestingly,  <dig> % of the workflows of the myexperiment set contains at least one anti-pattern. although anti-pattern a appears in only  <dig> % of the total, it is particularly costly because it involves multiple executions of the same processor with the exact same input, therefore being able to remove it would be particularly beneficial. the prevalence of pattern b suggests that workflow designers may not know the list processing properties of taverna .

as for the biovel private workflows,  <dig> % include at least one anti-pattern, all of kind b and thus none contains any kind a. additionally, we have observed that a workflow from biovel contains, on average, fewer anti-patterns than, on average, a workflow from myexperiment.

results obtained by distillflow
in the set from myexperiment, distillflow is able to remove all the anti-patterns in  <dig> % of the cases and at least one anti-pattern in 98% of the cases.  <dig> workflows are not completely free of anti-patterns after the distillflow process. however, the majority of these workflows has only one or two remaining patterns as indicated in figure  <dig>  more generally, figure  <dig> shows that the number of remaining anti-patterns is low compared to the number of anti-patterns in original versions of workflows. interestingly, additional experiments showed that on average three copies of processors are removed per workflow and this number is even particularly high for some workflows .

in the biovel data set, distillflow is able to remove all the anti-patterns in  <dig> % of the cases and at least one anti-pattern in all the workflows . only five  workflows have remaining anti-patterns. all of them have actually one remaining anti-pattern, as indicated in figure  <dig>  additional experiments allowed us to state that on this corpus, distillflow removes one node per workflow on average, compared to three in myexperiment. in very large workflows of biovel , up to  <dig> nodes are removed, compared to  <dig> in myexperiment. in conclusion, the additional curation steps that occur in the biovel community clearly make the produced workflows being of better quality; however some of these workflows could still benefit from our distilling approach.

discussion
simpler structures
when all the anti-patterns can be removed by distillflow, the resulting workflow structures are particularly simpler, as illustrated in examples provided all along the paper, including the two use cases . figures  <dig> and  <dig> provide two additional examples. in figure  <dig>  we have highlighted the rewritten subgraph that is particularly simpler compared to the same fragment of the workflow in the original setting. in figure  <dig>  the global structure is also simpler. processors have been numbered so that the relationship between the two workflows  can be seen: in the original workflow pi denotes the ith occurrence of processor p and in the rewritten workflow, pi − ... − pj denotes the node resulting of the merging of occurrences pi − ... − pj. for example, f <dig>  f <dig>  f <dig>  f <dig>  f <dig>  f <dig> are all occurrences of the same processor which are replaced by one occurrence in the rewritten workflow . as a result of the refactoring process on the workflow of figure  <dig>  three split processors have been introduced and  <dig> unnecessary duplications of processors have been removed.

sp structures
as explained in the previous sections, distillflow acts carefully on the workflow structures, by removing anti-patterns  and  while never introducing new intricate structure as non-sp structure may be. removing anti-patterns may actually automatically transform a non-sp structure into an sp structure as illustrated in figure  <dig> in which the original workflow has two reduction nodes underlined in the figure . while these nodes have several input/output links in the original setting they have  one input link and one output link in the transformed version and they are not reduction nodes anymore.

more generally, in the myexperiment corpus, a total of  <dig> workflows had a non-sp structure before applying the refactoring algorithm and have an sp structure after.

however, it may also be the case that anti-patterns cannot be removed because removal would imply merging nodes which would create a new reduction node, making the structure of the transformed workflows more intricate. the number of reduction nodes is actually a commonly used metric to measure how far from an sp structure a structure may be  <cit> . in that sense, merging such nodes would make the rewritten workflow being further from an sp structure compared to the original workflow structure.

 <dig> workflows from the myexperiment corpus and five from the biovel data set are involved in such a situation. the illustrative example for distillflow of figure  <dig> is one such example: merging nodes # <dig> and # <dig> would introduce a new reduction node. in the original graph, node # <dig> appears in an autonomous subgraph while node # <dig> does not belong to this autonomous subgraph. if these two nodes were merged, the subgraph formed by all the paths from the split node to the node #  <dig> would have the structure of the subgraph responsible for non-sp structures ), and the merged node #9- <dig> would be the new reduction node. figure  <dig>  shows a schematic view of a fragment of the original graph of figure  <dig> while figure  <dig>  shows the structure obtained if nodes # <dig> and # <dig> were merged. it can be shown that in this graph ranking the nodes within series and parallel order is not possible anymore since the graph of figure  <dig>  is homeomorphic to the generic subgraph represented in figure  <dig>  which is the cause of non-sp structures  <cit> .

a similar situation occurs in the workflow of figure  <dig> in which nodes #e1-e2-e <dig> and #e4-e5-e <dig> cannot be merged by distillflow in order to avoid introducing one additional reduction node.

towards other kinds of patterns
another kind of situation that may occur is when the sp feature is not correlated at all with anti-patterns: the transformed workflows are free of anti-pattern but they still have non-sp structures.

a deep inspection of such workflows reveals that other kinds of patterns may be directly the cause of non-sp structures  <cit> . these patterns have a different nature from the anti-patterns considered so far in this paper in the sense that they cannot be removed while keeping the same workflow semantics. one of the most interesting pattern is probably the presence of intermediate processors which are directly linked to the workflow outputs. this situation occurs merely when users want to keep track of intermediate results and "forward" such results to the workflow outputs. we call such intermediate processors trace nodes and their outgoing edges linked to the workflow outputs are called trace links.

several workflows depicted in this paper have trace links. for example, in figure  <dig> on the top, the link that goes from the processor g <dig> directly to the workflow output oα is a trace link: when the workflow will be executed, the same data  will be sent both directly to the workflow output oα and to the downstream part of the workflow. by doing this, the workflow designer may want to keep track of the data produced by g <dig>  however, as the processor get_gi will consume oα to produce to its turn some data, these produced data will have oα in their provenance information. oα will thus be automatically tracked by the provenance module of taverna. the trace link from g <dig> to oα is then useless and could be removed. however, this removal should be done very carefully since removing trace links implies removing part of the workflow outputs. as a consequence, the signature of the workflow is changed which may have several consequences if the transformed workflow is used as a subworkflow within another bigger workflow that expects the subworkflow to provide given outputs. this kind of transformation should then be done in collaboration with the user so that s/he can estimate the impact of the changes.

CONCLUSIONS
in this paper we have presented an algorithm, distillflow, which refactors taverna workflows in a way that removes explicit redundancy making them possibly easier to use and share. distillflow is able to detect two kinds of anti-patterns, and rewrites them as new patterns which better exhibit desirable properties such as maintenance, reuse, and possibly efficiency of resource usage. this is achieved mainly by merging, under certain enabling conditions, multiple occurrences of the same workflow processors into one, while at the same time collecting the inputs to each of the original occurrences into a list. by virtue of taverna's functional style of list processing, this refactoring can be proven to preserve the original workflow behavior.

we applied distillflow to two workflow collections, the one consisting of myexperiment public workflows, the other including private workflows from the biovel project. very interestingly, the number of anti-patterns per workflow and the number of duplicated nodes involved in each anti-pattern is also much lower in the biovel workflow set than in the myexperiment workflow set. the additional curation and quality control effort that is placed on the biovel collection, compared to the more heterogeneous workflows in myexperiment, is then confirmed by our study. we have shown that both data sets may still benefit from our approach.

related work
to the best of our knowledge, this is the first attempt at introducing a refactoring approach aiming at reducing workflow redundancy in the scientific workflows setting based on the study of workflow structure.

more research is available from the business workflows community, where several analysis techniques have proposed to discover control-flow errors in workflow designs . more recent work in this community has even focused on data-flow verification  <cit> . however, this work is aimed primarily at detecting access concurrency problems in workflows using temporal logics, making both aims and approach different from ours. also, it would be hard to transfer those results to the realm of scientific workflows, which are missing the complex control constructs of business workflows, and instead follow a dataflow model .

with the increase in popularity of workflow-based science, and bioinformatics in particular, the study of scientific workflow structures is becoming a timely research topic. classification models have been developed to detect additional patterns in structure, usage and data  <cit> . more high-level patterns, associated to specific cases of use  have been identified in taverna and wings workflows  <cit> . complementary to this work, graph-based approaches have been considered for automatically combining several analysis steps to help the workflow design process  <cit>  while workflow summarization strategies have been developed to tackle workflow complexity  <cit> .

future work
we intend to continue this work in several directions.

a first direction of research deals with generalizing our approach to other workflow systems. in particular, in systems able to exploit multi-core infrastructures or run on grids or cloud environments  <cit> , our distilling approach could be highly beneficial. indeed, as it pushes the management of multiple activations to system runtime, it can more efficiently parallelize their execution when deployed on a parallel architecture.

another direction includes enriching the distilling approach with new patterns  and making it possible to choose whether or not such patterns should be transformed, in an interactive process. in such a framework, users might even have the choice to remove some anti-patterns even if the resulting workflow is non-sp, thus relaxing the sp-constraint. one of the challenges of such an approach will be to provide users with means to estimate the impact of their choices on the workflow structure and its future use.

instead of considering an automatic procedure, the distilling procedure would be used during the design phase in a semi-automatic way. the refactoring approach would thus be built into the scientific workflow system design environment. it may then be complementary to approaches like  <cit>  which help users find and connect tasks following an on-the-fly approach during the design phase or  <cit>  which supports workflow design by offering an intuitive environment able to convert the users' interactions with data and web services into a more conventional workflow specification.

the longer term goal would then be to propose guidelines for workflow authors to more directly design distilled workflows. this work will be achieved in close collaboration with workflow authors and will involve conducting a complete user study to collect their feedback on the distilling approach and possibly resulting in finding again new anti-patterns.

abbreviations
dag: directed acyclic graph; sp: series-parallel; st-dag: directed acyclic graphs with one single source and one single target; wf: workflows.

competing interests
the authors declare that they have no competing interests.

author's contributions
jc has proposed a first list of anti-patterns and has designed the distillflow algorithm under the supervision of chf and scb. he has implemented distillflow and provided the results on the two sets of workflows. chf and scb have mostly written the paper. they have formalized and generalized the anti-patterns and the transformations. pm has designed and implemented the first concrete examples of workflows in taverna involving transformations for anti-patterns; he has helped understanding some features of the functional model used in taverna and significantly contributed to the writing of the paper. cg has contributed placing this work in the context of other refactoring approaches for scientific workflows. ar has provided very valuable information on several technical aspects of taverna and helped understanding the results obtained in the biovel workflows set. all authors have contributed to the writing of the paper.

supplementary material
additional file 1
this document provides the complete pseudo-code of the downdistillation and distill procedures. this file can be viewed with: adobe acrobat reader .

click here for file

 acknowledgements
authors would like to thank the participants and chairs of the nettab  <dig> workshop for the very interesting feedback they gave on a preliminary version of this work. we deeply thank the reviewers of the nettab  <dig> supplement for their comments and suggestions. authors would also like to thank all the scientists collaborators and members of the group of carole goble  and in particular members of the biovel project who allowed us to use their set of workflows. j. chen has been supported by the china scholarship council. this work has been funded in part by the eps research council: epsrc grant ep/g026238/ <dig> "mygrid: a platform for e-biology renewal".

declarations
article processing charges for this paper have been paid from the university of manchester's rcuk block grant.

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2014: integrated bio-search: selected works from the 12th international workshop on network tools and applications in biology . the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/15/s <dig> 
