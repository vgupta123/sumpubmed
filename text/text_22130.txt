BACKGROUND
introduction
of the many challenging problems related to understanding the biological function of dna, rna, proteins, and metabolic and signalling pathways, one of the most important is comparing the structure of different molecules. the hypothesis is that structure determines function and therefore it should follow that molecules with similar structure should have similar function. evaluating the similarity of structures can be reduced to a comparison of a set of abstracted graphs if the biological structures can be abstracted as graphs.

using bioinformatic techniques, biological structure matching can be formulated as a problem of finding the maximum common subgraph. the solution to this problem has important practical applications in many areas of bioinformatics as well as in other areas, such as pattern recognition and image processing  <cit> . for example, protein threading, an effective method to predict protein tertiary structure  <cit> , and rna structural homology searching, a method for annotating and identifying new non-coding rnas  <cit> , both align a target structure against structure templates in a template database.

song et al  <cit>  makes the following definitions and proposes the following graphical models for rna structural homology searching: a structural unit in a biopolymer sequence is a stretch of contiguous residues . a non-structural stretch between two consecutive structural units is called a loop. a structure of the sequence is characterized by interactions among structural units. for example, structural units in a tertiary protein are α helices and β strands, called cores. given a biopolymer sequence, a structure graph h =  can be defined such that each vertex in v represents a structural unit, each edge in e represents the interaction between two structural units, and each arc in a represents the loop ended by two structural units. similarly, the target sequence can also be represented as a mixed graph g, called a sequence graph. based on the graphical representations, the structure-sequence alignment problem can be formulated as the problem of finding in the sequence graph g a subgraph isomorphic to the structure graph h such that the objective function optimizes the alignment score.

problem definition
throughout this paper, we will use the basic definitions and terminology from  <cit> : all graphs are simple, undirected graphs. two graphs are isomorphic if there is a one-to-one correspondence between their vertices and there is an edge between two vertices in one graph if and only if there is an edge between the two corresponding vertices in the other graph. if edge  is an edge connecting u and v, then an induced subgraph g' of a graph g =  consists of a vertex subset v' ⊆ v and for all edges  ∈ e where u, v ∈ v'. a graph g <dig> is a common induced subgraph of two given graphs g <dig> and g <dig> if g <dig> is isomorphic to one induced subgraph g' <dig> of g <dig> as well as one induced subgraph g' <dig> of g <dig>  a maximum common induced subgraph  of two given graphs g <dig> and g <dig> is the common induced subgraph g <dig> with the maximum number of vertices. similarly, the maximum common edge subgraph  is a subgraph with the maximum number of edges common to the two given graphs. the mcis  between two graphs can be further divided into a connected case and a disconnected case. all the different cases of the problem are useful within different biological contexts.

mces can be transformed into a formulation of mcis. interested readers are referred to  <cit>  for details of the transformation. here we focus on the maximum common induced subgraph  problem. for convenience, we call it the maximum common subgraph problem.

the maximum common subgraph problem is np-complete  <cit>  and therefore polynomial-time algorithms for it do not exist unless p = np. in fact, the maximum common subgraph problem is apx-hard  <cit>  which means that it has no constant ratio approximation algorithms. this problem is a famous combinatorial intractable problem. approaches for the maximum common subgraph problem and different variants of this problem are intensively studied in the literature  <cit> .

in this paper, we derive a strong lower bound result for the maximum common subgraph problem in the light of the current research progress in the research area of parameterized computation. we then design the approaches for addressing this problem.

methods
parameterized computation and recent progress on parameterized intractability
many problems with important real-world applications in life science are np-hard within the context of the theory of np-completeness. this excludes the possibility of solving them in polynomial time unless p = np. for example, the problems of cleaning up data, aligning multiple sequences, finding the closest string, and identifying the maximum common substructure are all famous np-hard problems in bioinformatics  <cit> . a number of approaches have been proposed in dealing with these np-hard problems. for example, the highly-acclaimed approximation approach  <cit>  tries to come up with a "good enough" solution in polynomial time instead of an optimal solution for an np-hard optimization problem  <cit> .

the theory of parameterized computation  <cit>  is a newly developed approach introduced to address np-hard problems with small parameters. it tries to give exact algorithms for an np-hard problem when its natural parameter is small . a parameterized problem q is a decision problem consisting of instances of the form , where x is the problem description and the integer k =  <dig> is called the parameter. the parameterized problem q is fixed-parameter tractable  <cit>  if it can be solved in time f|x|o, where f is a recursive function. the class fpt contains all the problems that are fixed-parameter tractable. in this paper, we assume that complexity functions are "nice" with both the domain and range being non-negative integers and the values of the functions and their inverses are easily computed. for two functions f and g, we write f = o) if there is a nondecreasing and unbounded function λ such that f = g/λ. a function f is subexponential if f = 2o.

for a problem in the class fpt, research is focused on identifying more efficient, parameterized algorithms. there are many effective techniques to design parameterized algorithm including the methods of "bounded search tree" and "reduction to a problem kernel". another example is the vertex cover problem.

definition
vertex cover problem: given a graph g and an integer k, determine if g has a vertex cover c of k vertices, i.e., a subset c of k vertices in g such that every edge in g has at least one endpoint in c. here, the parameter is k.

given a graph of n vertices, there is a parameterized algorithm that can solve the vertex cover problem in time o  <cit> .

accompanying the work on designing efficient and practical parameterized algorithms, a theory of parameter intractability has previously been developed  <cit> . in parameterized complexity, to classify fixed-parameter intractable problems, a hierarchy of classes  have been introduced in which the 0-th level w  <cit>  is the class fpt. the hardness and completeness have been defined for each level w  of the w-hierarchy for i =  <dig>  and a large number of w -hard parameterized problems have been identified  <cit> . for example, the clique problem is w <cit> -hard.

definition
clique problem: given a graph g and an integer k, determine if g has a clique c of k vertices, i.e., a subset c of k vertices in g such that there is an edge in g between any two of these k vertices, i.e., the k vertices induce a complete subgraph of g. here the parameter is k.

the clique problem can be solved in time o, based on the enumeration of all the vertex subsets of size k for a given graph with n vertices.

it has become commonly accepted that no w <cit> -hard  problem can be solved in time fno for any function f . w <cit> -hardness has served as the hypothesis for fixed-parameter intractability. an example is a recent result by papadimitriou and yannakakis  <cit> , showing that the database query evaluation problem is w <cit> -hard. this provides strong evidence that the problem cannot be solved by an algorithm whose running time is of the form fno, thus excluding the possibility of a practical algorithm for the problem even if the parameter k  is small as in most practical cases.

based on the w <cit> -hardness of the clique algorithm, computational intractability of problems in bioinformatics has been derived  <cit> , the author point out that "unless an unlikely collapse in the parameterized hierarchy occurs, the results proved in  <cit>  that the problems longest common subsequence and shortest common supersequence are w <cit> -hard rule out the existence of exact algorithms with running time fno  for those problems. this does not mean that there are no algorithms with much better asymptotic time-complexity than the known o algorithms based on dynamic programming, e.g., algorithms with running time nvk are not deemed impossible by our results."

recent investigation has derived stronger computational lower bounds for well-known np-hard parameterized problems  <cit> . for example, for the clique problem – which asks if a given graph of n vertices has a clique of size k – it is proved that unless an unlikely collapse occurs in parameterized complexity theory, the problem is not solvable in time fno for any function f. note that this lower bound is asymptotically tight in the sense that the trivial algorithm that enumerates all subsets of k vertices in a given graph to test the existence of a clique of size k runs in time o.

based on the hardness of the clique problem, lower bound results for a number of bioinformatics problems have been derived  <cit> . for example, our results for the problem's longest common subsequence and shortest common supersequence have strengthened the results in  <cit>  significantly and advanced the understanding on the complexity of the problems. we show that it is actually unlikely that the problems can be solved in time nγ for any sublinear function γ and the known dynamic programming algorithms of running time o for the problems are actually asymptotically optimal.

in the following section, we derive the lower bound for exact algorithms of the maximum common subgraph problem.

lower bound for maximum common subgraph problem
the formal parameterized version of the maximum common subgraph problem is described above; we choose the number of vertices in the common subgraph as the parameter. based on the reduction from the parameterized clique problem to the parameterized common subgraph problem, we derive the hardness result of the parameterized common subgraph problem.

an np optimization problem q is a four-tuple   <cit> , where:

 <dig>  iq is the set of input instances. it is recognizable in polynomial time;

 <dig>  for each instance x ∈ iq, sq is the set of feasible solutions for x, which is defined by a polynomial p and a polynomial time computable predicate π ; sq = {y: |y| = p and π};

 <dig>  fq is the objective function mapping a pair x ∈ iq and y ∈ sq to a non-negative integer; the function fq is computable in polynomial time;

 <dig>  optq∈ {max, min}. q is called a maximization problem if optq = max and a minimization problem if optq = min.

an np optimization problem q can be parameterized in a natural way as follows  <cit> :

definition
let q =  be an np optimization problem. the parameterized version of q is defined as:

 <dig>  if q is a maximization problem, then the parameterized version of q is defined as q = { | x ∈ iq ^ optq = k };

 <dig>  if q is a minimization problem, then the parameterized version of q is defined as q = { | x ∈ iq ^ optq = k}.

we now provide the definitions of the maximum common subgraph problem and the parameterized common subgraph problem.

definition
maximum common subgraph problem:

input: two graphs g <dig> =  and g2= .

output: the maximum common vertex-induced subgraph of the two graphs g <dig> and g <dig> 

definition
parameterized common subgraph problem:

input: two graphs g <dig> =  and g2= , and a positive integer k;

parameter: k;

output: "yes", if there is a common vertex-induced subgraph of k vertices, i.e., a common subgraph of size k of the two graphs g <dig> and g <dig>  otherwise, output "no".

lemma 1
the parameterized common subgraph problem is w <cit> -hard.

proof: we will give an fpt-reduction from clique to the parameterized common subgraph problem as follows.

given an instance  of the clique problem, where the graph g has n vertices and k is a positive integer, we construct an instance of the parameterized common subgraph problem as follows: let g <dig> be the graph g, and g <dig> a complete graph of k vertices. the problem can therefore be stated as "is a common vertex-induced subgraph of k vertices for the graphs g <dig> and g2?"

we can verify that the graph g has a clique of size k if and only if the graphs g <dig> and g <dig> have a common subgraph of k vertices. since the reduction may be finished in polynomial time o, the reduction is an fpt-reduction from clique to parameterized common subgraph problem.

to prove our main result, we will use the definition of linear fpt-reduction and w <dig> <cit> -hard  <cit> :

definition
a parameterized problem q is linear fpt-reducible, or more precisely, fptl-reducible, to a parameterized problem q' if there exist a function f and an algorithm a of running time fno that, on each -instance x of q, produces a -instance x' of q', where k' = o, n' = no, and x is a yes-instance of q if and only if x' is a yes-instance of q'.

linear fpt-reduction has the transitivity property  <cit> . the transitivity of the fptl-reduction is proved in the following lemma:

lemma 2
let q <dig>  q <dig> and q <dig> be three parameterized problems. if q <dig> is fptl-reducible to q <dig>  and q <dig> is fptl-reducible to q <dig>  then q <dig> is fptl-reducible to q <dig> 

proof: if q <dig> is fptl-reducible to q <dig>  then there exists a function f <dig> and an algorithm a <dig> of running time f1n1om1o, such that for each -instance x <dig> of q <dig>  the algorithm a <dig> produces a -instance x <dig> of q <dig>  where n <dig> = n1o, m <dig> = m1o, and k <dig> = c1k <dig>  where c <dig> is a constant.

if q <dig> is fptl-reducible to q <dig>  then there exists a function f <dig> and an algorithm a <dig> of running time f2n2o m2o, such that on each -instance x <dig> of q <dig>  the algorithm a <dig> produces a -instance x <dig> of q <dig>  where k <dig> = o, n <dig> = n2o, m <dig> = m2o.

we now have an algorithm a that reduces q <dig> to q <dig>  as follows: for a given -instance x <dig> of q <dig>  a first calls the algorithm a <dig> on x <dig> to construct a -instance x <dig> of q <dig>  where k <dig> = c1k <dig>  n <dig> = n1o, and m <dig> = m1o. then a calls the algorithm a <dig> on x <dig> to construct a -instance x <dig> of q <dig>  it is therefore obvious that x <dig> is a yes-instance of q <dig> if and only if x <dig> is a yes-instance of q <dig>  moreover, from k <dig> = c1k <dig> and k <dig> = o, we have k <dig> = o, and from n <dig> = n1o, m <dig> = m1o, n <dig> = n2o, m <dig> = m2o, we get n <dig> = n1o and m <dig> = m1o. finally, since the invocation of algorithm a <dig> on x <dig> takes time f1n1o m1o, the invocation of algorithm a <dig> on x <dig> takes time f2n2o m2o, k <dig> = c1k <dig>  n <dig> = n1o, and m <dig> = m1o, we conclude that the running time of algorithm a is bounded by f1n1o m1o, where f = f <dig> + f <dig>  by definition, a is an fptl-reduction from q <dig> to q3; i.e., q <dig> is fptl-reducible to q <dig> 

definition
a parameterized problem q is w <cit> -hard under the fptl-reduction, or more precisely wl <cit> -hard, if the weighted antimonotone cnf 2sat  problem is fptl-reducible to q.

in particular, it has been shown  <cit>  that the clique problem is wl <cit> -hard.

lemma 3
 unless all snp problems are solvable in subexponential time, no wl <cit> -hard problem can be solved in time fno for any recursive function f.

note papadimitriou and yannakakis  <cit>  have introduced the class snp which contains many well-known np-hard problems. some of these problems have been the major targets in the study of exact algorithms, but have so far resisted all efforts for the development of subexponential time algorithms to solve them. thus, it has been commonly agreed that it is unlikely that all snp problems are solvable in subexponential time. a recent result showed the equivalence between the statement that "all snp problems are solvable in subexponential time" and the collapse of a parameterized class called mini <cit>  to fpt, which is also considered as an unlikely collapse in parameterized computation.

lemma 4
the parameterized common subgraph problem is wl <cit> -hard.

proof: referring to the proof of lemma  <dig>  the reduction from a clique to a parameterized common subgragh problem is a linear fpt-reduction.

based on the transitivity property of the linear fpt-reduction of lemma  <dig>  and the fact that the clique problem is wl <cit> -hard, the parameterized common subgraph problem could not be solved in time fno, where k is the number of vertices in the common subgraph and f is any recursive function, unless some unlikely collapse  occurs in parameterized computation.

from lemma  <dig> and proposition  <dig>  we have the following theorem:

theorem
given two graphs g <dig> and g <dig> with each graph having n vertices, there is no algorithm of time fno for the parameterized common subgraph problem, where k is the number of vertices in the common subgraph and f is any recursive function, unless some unlikely collapse  occurs in parameterized computation.

in consideration of the upper-bound result, we now show that our lower-bound result for the maximum common subgraph problem presented here is asymptotically tight.

upper bound – clique based approaches
the following approach for the maximum common subgraph problem is based on the reduction  <cit>  from a maximum common subgraph problem to the maximum clique problem.

from two graphs g1=  and g2= , a new graph g=  is derived as follows: let v = v <dig> × v <dig> and call v a set of pairs. call two pairs <u <dig>  u2> and <v <dig>  v2> compatible if u <dig> ≠ v <dig> and u <dig> ≠ v <dig> and if they preserve the edge relation, that is, there is an edge between u <dig> and v <dig> if and only if there is an edge between u <dig> and v <dig>  let e be the set of compatible edges. a k-clique in the new graph g can be interpreted as a matching between two induced k-node subgraphs. the two subgraphs are isomorphic since the compatible pairs preserve the edge relations. the new graph g is called the modular product graph of the two graphs g <dig> and g <dig> 

we suppose n = |v1| = |v2| . from the construction of g, we have |v| = n <dig>  by a close observation of the new graph g, we can see that g is indeed an n-partite graph, where the vertices are partitioned into n disjoint partitions with each partition having n vertices.

we may use a matrix to denote the n <dig> vertices of the n-partite graph with n vertices in each partition.

v{ <dig> }, v{ <dig> }, ..., v{ <dig> n}

v{ <dig> }, v{ <dig> }, ..., v{ <dig> n}

... ...

v{n,1}, v{n,1}, ..., v{n,n}

the n vertices of the first row v{ <dig> i},  <dig> = i = n, belong to partition one of the n-partite graph. the n vertices of the second row v{ <dig> i},  <dig> = i = n, belong to partition two and so on.

there is no edge between any two vertices within the same partition. edges only appear between two vertices that are in two different partitions. so, at most one vertex from each partition  could be in a clique of the graph. therefore, to find a clique of size k, there will be nk possible ways for choosing the clique vertices. for each possible way, the algorithm needs o time to check if it constructs a clique of size k. therefore, this gives an algorithm of time o for the maximum common subgraph problem. we call this algorithm alg-common subgraph for the convenience of the following discussion.

this problem – when the maximum clique size k is equal to n – has been studied by sze et al  <cit> :

definition
given an n-partite graph g with n vertices in each part, the n-cliquenp problem finds an n-clique in the graph g.

for this problem, they developed a fast and exact divide-and-conquer approach. the basic idea of this novel approach is to subdivide the given n-partite graph into several n0-partite subgraphs with n <dig> < n and solve each smaller subproblem independently using a branch-and-bound approach as long as the number of cliques of size n <dig> in each subproblem is not too high. the reader is referred to  <cit>  for the details of this divide-and-conquer approach. however, their approach in the worst case still has the same upper bound.

given this o-time algorithm for the maximum common subgraph problem, the lower bound result of our theorem is asymptotically tight.

when the number of vertices in the common subgraph k is not very far away from the value of n, we define k = n – c, where c is a constant. we illustrate the basic idea for c =  <dig> as follows  <cit> : suppose the n-partite graph g has a clique c of size k- <dig>  we add one more vertex to each of the n partitions. and we also add edges from this vertex to any vertices  that are not in the same partition. now we get a new graph g'. g' is an n-partite graph with n +  <dig> vertices in each partition. the new graph g' has a clique c' of size n if and only if the original n-partite graph g has a clique of size . the vertices of this clique c' include the vertices of the original clique c and one newly added vertex.

for the newly constructed graph g', we can now apply the algorithm alg-common subgraph without any change. and we need time on n2). after we find the clique c', we just remove the newly added vertex and return the other vertices of c'.

similarly, if the n-partite graph g has a clique of size k – c, where c is a positive integer constant, we can find the clique by adding c new vertices and associated edges as described above and then applying the algorithm alg-common subgraph which runs in time on n2).

this simple idea of dealing with cliques of a size less than n is useful since it makes the algorithm alg-common subgraph work uniformly for finding cliques of different sizes on n-partite graphs. in the following, we give the following algorithm for finding cliques of size k – c.

algorithm for -clique
input: an n-partite graph g, with n vertices in each partition, and a small constant c, where c is a positive integer;

output: a clique of size no less than k – c;

step 1: for i =  <dig> to c do

• step  <dig> : construct a new graph g <dig>  by adding i new vertices to each partition of the graph g and adding edges from each of the new vertices to any vertices  that are not in the same partition.

• step  <dig> : apply the algorithm alg-common subgraph on the graph g <dig> 

• step  <dig> : if a clique c <dig> is found, then return "a clique c of size k – i has been found" .

• endfor

step 2: return "no clique has been found".

we now propose two approaches for the maximum common subgraph problem which are based on the relationship between the vertex cover problem and the clique problem:

algorithm 1: alg-approx-clique
input: an n-partite graph g, with n vertices in each partition, and a small constant c, where c is a positive integer;

output: a clique for the graph g.

step  <dig>  compute the complement graph g' of the modular product graph g =  of graph g <dig> and g2;

step  <dig>  apply the approximation algorithm for the vertex cover problem to get a vertex cover c;

step  <dig>  return v – c as the clique vertex set.

alg-approx-clique gives an approximate solution for the maximum common subgraph problem in polynomial time. this approach uses the following approximation algorithm for the vertex cover problem with an approximation ratio  <dig> in  <cit> :

alg-approx-vertex cover
input: a graph g = ;

output: a vertex cover c of approximation ratio  <dig> for the graph g.

step  <dig>  c ← Φ;

step  <dig>  e' ← e;

step  <dig>  while e' ≠ Φ

• step  <dig> . let  be an arbitrary edge of e';

• step  <dig> . c = c ∪ {u, v};

• step  <dig> . remove from e' every edge incident on either u or v;

step  <dig>  return c as the vertex cover set.

in this algorithm, alg-approx-vertex cover selects an edge from the set of edges of the graph g =  and adds it to c. repeating this procedure for  ∈ e and deleting edges from e' that are covered by u or v results in a running time of o.

algorithm 2: alg-exact-maxclique
input: an n-partite graph g, with n vertices in each partition, and a small constant c;

output: a clique for the graph g.

step  <dig>  compute the complement graph g' of the modular product graph g =  of graph g <dig> and g2;

step  <dig>  apply the parameterized exact algorithm for the vertex cover problem on g' and compute the minimum vertex cover c <dig> 

step  <dig>  return the maximum clique with the vertex set v – c <dig> 

alternatively, alg-exact-maxclique could apply in step  <dig> the current best algorithm for vertex cover  <cit>  which is of time o. by running the vertex cover algorithm for at most n times, we produce the minimum vertex cover of the product graph g.

RESULTS
in this paper we investigated the lower-bound result for the maximum common subgraph problem. we proved that it is unlikely that there is an algorithm of time fno for the problem, where k is the number of vertices in the common subgraph and f is any recursive function. we then presented the upper bound of algorithms which solve this problem: o time where k is the number of vertices in the common subgraph. in consideration of the upper-bound result, we point out that our lower-bound result for the maximum common subgraph problem is asymptotically tight.

CONCLUSIONS
parameterized computation is a viable approach with great potential for investigating many applications within bioinformatics, such as the maximum common subgraph problem studied in this paper. with an improved hardness result and the proposed approaches in this paper, future research can be focused on further exploration of efficient approaches for different variants of this problem within the constraints imposed by real applications.

authors' contributions
xh carried out the study on the lower bound and approaches for the maximum common subgraph problem and helped to provide background information on parameterized computation theory. jl and sfj participated in the design and expression of the algorithms for the maximum common subgraph problem. all authors have read and approved the final manuscript.

