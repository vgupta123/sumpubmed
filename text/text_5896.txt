BACKGROUND
mathematical models in modern molecular biology have become attractive as compactors of the massive amounts of multidimensional data produced by high-throughput techniques, thus following similar ideas that previously led from reductionism to quantitative inroads into physiology and ecology. in the smaller-dimensional world described by the model structure and its parameters, new experiments are easier to conceive, hypotheses can be tested with greater clarity, and knowledge can be extended with inexpensive computational effort  <cit> .

generally, mathematical models are implemented with a set of parameters, which give them the flexibility of mapping a range of behaviors into a unifying mathematical framework. except for singular cases where parameters are directly measured experimentally, parameter estimation from experimental data is an inevitable step in the process of constructing models  <cit> . a good, first-tier compromise between the need for a closed-form, computable representation of the biological process and the risk of ignoring meaningful parameters of mechanistic, hypothesis-driven reductions can be found in the use of generic, "canonical" modeling frameworks. specifically, within the framework of biochemical systems theory   <cit> , s-system models  offer a particularly convenient solution because their parameters more or less directly describe the interactions between the components of the system of interest  <cit> .

   

in the general s-system form , the time variation of the concentration or amount of each component xi of the system is given by the difference between production and degradation terms. the constant rates αi and βi represent the turnover rates of the production and degradation fluxes and the kinetic rates gij and hij quantitatively characterize the influence of the component xj on the production and degradation term of the system component xi, respectively  <cit> . thus, the network structure and the nature of the interactions driving the phenomenon under investigation are mapped essentially one-to-one onto the parameter values of the model. this modeling framework has been successfully applied to many biochemical systems  <cit>  and can generally be considered a good first default for representing complex biological systems, especially if the governing mechanisms are not well characterized  <cit> . automation of the estimation of the high-dimensional parameter set of an s-system model from multivariate time series data has therefore become a widely pursued computational challenge that has been addressed by a wide variety of optimization techniques: from relatively slow global heuristic optimization techniques like genetic algorithms and simulated annealing  <cit>  to fast local optimization algorithms such as alternating regression and eigenvector optimization  <cit>  among others  <cit> . most of these optimization algorithms share the strategy of decoupling the differential equation system into a larger, nonlinear algebraic system  <cit> . this strategy eliminates the need for numerical system integration at each step of the optimization process, which is expensive because s-systems can be numerically stiff, just like most other nonlinear models.

ironically, the difficulty of finding any numerically integrated s-system model that fits a given set of experimental time series data well is accompanied by the "opposite" problem: many recent publications have pointed out that multiparametric models tend to have the capacity of accommodating whole ranges of parameter values without much affecting the system dynamics  <cit> . furthermore, it was found that there are typically well-defined directions in the parameter space to which the system dynamics is insensitive, a phenomenon that was termed "sloppiness"  <cit> . since redundancy appears to be a wide-spread design feature of biological processes, exploring the admissible parameter space of a model and a dataset of interest has relevance that reaches well beyond typical sensitivity analyses of model parameters.

although the concept of sloppiness has been discussed quite intensely, little attention has been paid to the question of whether or not sloppiness can be translated into the structure of the biological system itself. in other words, is the biological system in reality more or less uniquely parameterized or is there such significant inter-individual variation that we could in principle find large "clouds" of parameter manifestations if we were able to determine the parameters in individual cells or organisms. the answer to this question is not without consequence, because it would affect the definition of what it means to have a good model fit to a given set of data.

in the case of s-systems, the question has further implications. if an admissible parameter cloud, defined by a sufficiently accurate overall fit of some data, permits some kinetic order parameter to be positive, zero, or negative, the interpretation of the estimated model becomes distinctly different. in the first case, the effect is activating, in the second it is negligible, and in the third it is inhibiting. is such a parameter cloud a computational artifact that would disappear if more data were available, or is it possible that a real biological system would actually allow such different effects of a variable on the system? to reformulate the question, do natural systems only allow for sloppiness in parameter values or also for sloppiness in structure? while the question itself is not new , it can presently not be answered in generality and with reliability.

in this report, we address the intrinsic redundancies in the interactions between biological system components by proposing an embedding method for s-system parameter space estimation based on a monte carlo process that is combined with an improved version of our previous parameter optimization algorithm. we apply this methodology to experimental time series data characterizing the glycolytic pathway in the bacterium lactococcus lactis  <cit> . in the same context we explore the concept of sloppiness in s-systems by studying the implications of admissible ensembles of models that dynamically represent the data well but lead to different interpretations.

neutral solution analysis
this section describes the concepts of the proposed analysis of neutral solution spaces, i.e., of multiple model parameter sets with similar dynamics; all technical details are presented in the later methods section. to characterize the neutral solution spaces, we propose a monte carlo  random walk process  <cit> , which is sped up by a nonlinear optimization algorithm that allows us to assess s-system parameter sets  that give the system a similar dynamical behavior as it had been measured experimentally in the form of time series data. differently from similar methodologies suggested in the literature  <cit> , the proposed approach is performed with the decoupled form of the system  <cit> , which allows analysis of one system equation at a time. in this fashion, problems with numerical integration of differential equations, which is otherwise needed at each step of the mc process, are avoided. thus, we suppose in the following that the time series of all components are available and have been smoothed, thus permitting the numerical estimation of their first derivatives at each point of the time series. for each system component, a series of steps is performed as follows.

first, using the smoothed time series of all components xi, as well as their numerically estimated derivatives, the system of differential equations is converted into a system of algebraic equations   <cit> . second, an optimization algorithm is applied to this algebraic system, leading to an optimal parameter set that matches the algebraic equations with the observed systems dynamics. this optimal parameter set is the starting point of the mc process. a cost function c is defined to quantify changes in behavior of the decoupled system resulting from perturbations in the parameter set . the hessian matrix of c is calculated at the optimal parameter set and used to guide subsequent, artificial parameter perturbations, which collectively form the mc random walk  <cit> . at each mc step, the parameter set is perturbed  and then used as initial guess for the optimization algorithm, however, with an earlier stop criterion. this premature termination prevents the algorithm from converging to the same local optimal point and is accompanied by a  residual error. the cost function c is evaluated with the new local parameter set, and this parameter set is accepted for the next iteration with a certain probability . any parameter sets satisfying the conditions of a predefined behavioral class  are recorded. at the conclusion of the mc process, the recorded collection of parameter sets contains solutions of the decoupled system that adhere to the specified behavioral class.

after the mc process has been run for each system component, instances from the collections of parameter sets for all variables are randomly sampled to recouple the models by means of numerical integration. although the decoupled, algebraic form offers the advantage of avoiding numerical integration problems, it is not guaranteed that the recoupled system will lead to an accurate, comprehensive solution. the methods and results sections provide detailed descriptions of the proposed techniques and outcomes.

RESULTS
after preliminary, successful tests with simulated data , we applied the proposed optimization algorithm to actual time series. these data consist of metabolite profiles from the glycolytic pathway of the bacterium lactococcus lactis, which were obtained with in vivo nmr experiments  <cit> . for modeling purposes, the concentrations of the metabolites were coded as follows: glucose – x1; glucose 6-phosphate  – x2; fructose  <dig>  6-bisphosphate  – x3; phosphoenolpyruvate  – x4; lactate – x5; acetate – x <dig>  as a pre-processing step for the parameter optimization, the time series were smoothed/denoised and their slopes  were estimated as shown in previous work on non-stationary noise filtering  <cit> .

initially, the proposed algorithm exclusively used the time series of all metabolites in the parameter optimization, representing the case where no knowledge about the network connectivity is at hand. the optimal parameter set of each metabolite was separately translated into the eigenspace of the solution and subsequently fed into the mc process. the parameters were then perturbed and an ensemble of models was created as described in the methods section. the parameter sets were selected based on a behavioral class  <cit> , which was defined by a residual less than  <dig> . as an example, figure  <dig> shows all parameter sets for the g6p production term that fall within the defined behavioral class. after ordering, these parameters have the same distribution pattern . similar results were found for all other metabolites.

as an alternative, we performed a mc random walk in the original parameter space, as opposed to the eigenspace. interestingly, although not surprising in the end, the results did not present as wide a range as was found in the exploration of the parameter set in the eigenspace. the difference in outcomes is explained by the compensation of errors between production and degradation terms: perturbations in the eigenspace of the matrix w affect both production and degradation terms while perturbing only one parameter does not always maintain the balance between the two terms. in other words, given one of the s-system's terms  and the vector of slopes, the complementary term can be obtained by multiple linear regression, which has been shown not to be sloppy  <cit> ).

as expected, eigenvalues of the hessian matrix fall within a sparse range  <cit> , thereby elucidating the stiff and sloppy directions . the region of the parameter space that produces similar dynamical model behaviors can be approximated as an ellipsoid whose main axes are given by the direction of the eigenvectors of the hessian matrix  and whose width is inversely proportional to the squared root of the corresponding eigenvalue  <cit> . a projection of the ellipsoid into three-dimensional space for the acetate production parameters g <dig>  g <dig> and g <dig> is shown in figure  <dig>  revisiting reasons discussed for other modeling frameworks  <cit> , sloppiness can be explained in the proposed approach by the neutral space of solutions for equation  <dig> and consequently equation  <dig>  specifically, given the "right" linear combination of the eigenspace of the matrix w, any vector resulting from stretching or shrinking this combination is also a solution of equation  <dig>  however with different parameter values.

ideally, all combinations of parameter sets found for the individual metabolites would generate recoupled models that fit the data upon numerical integration, within some error bound. given the large number of parameters , a full exploration of this statement is not possible. in order to ameliorate the expensive combinatorial issue of assessing the trajectories of the recoupled systems, the parameter set for each metabolite generated from the mc process was randomly selected and the resulting system numerically integrated. this process was repeated  <dig> times and the results are presented in figure  <dig> 

as can be seen from figure  <dig>  the uncertainties and bounds in the prediction for most metabolites are actually close to the observed data. a notable exception is lactate, where the measured data contain little noise. because pep is the main precursor of lactate in the model  <cit>  , the class of predictions of the pep dynamics was re-sampled for residuals less than  <dig>  furthermore, the newly sampled systems were integrated with glucose supplied in three different initial concentrations, namely  <dig>   <dig> and  <dig> mm. the results of these predictions are shown in figure  <dig>  for all three different scenarios the new ensemble model predictions provide accurate descriptions of the observed dynamics for the concentrations of lactate and the other metabolites in the model, except for the noticeable undershooting of pep .

although the models found by the proposed procedure accurately describe the dynamics observed in the experimental data, none of the parameter sets match well with the network topologies found in the literature, suggesting that distinctly different parameter combinations, and not just sloppy versions of some parameter set, area able to match these data. a variety of techniques can be applied to the ensemble in order to compare different models  <cit> , to cluster models by means of transformation groups, or even reduce them to a smaller subset  <cit> . one possible avenue for further analysis of this vast parameter space is by creating groups defined by different behavior classes based on biological and dynamical information  <cit> .

regardless of specific follow-up analyses, one of the purposes of this work is to demonstrate that the proposed optimization algorithm can be effectively applied to the parameter identification of specific networks, for instance, by taking kinetic parameters of some component xj out of the optimization process of xi. conversely, previous knowledge can be used to restrict the values of the g and h interaction parameters. for example, existing knowledge about lactococcus lactis primary metabolism  <cit>  provides precise clues about which interactions are reasonable. to analyze the benefit of information outside the time series data, we applied the proposed optimization algorithm to the same lactococcus lactis data, this time however constraining some parameter values with the pre-existing information. the simulation results with the resulting system  not only describe the data but also agree with the double pulse of glucose described in  <cit> .

exactly as described before, the system resulting from this combined approach could be used as the starting point of a mc random walk process, and the same analysis of sloppiness and behavior classes could be performed. in order to assess the accuracy of the solutions for large systems, the optimization algorithm was also tested with a symbolic genetic network model consisting of  <dig> components  <cit>  . because the algorithm performs the parameter optimization with the decoupled form of the system, its complexity is linear with the number of the system's components  <cit> . thus, rather than system dimension, the real limitation of the optimization algorithm is the time series dynamics. poor dynamical variability  and collinear time series will result in a conditioning deficiency of the matrix l, causing numerical problems with the inverse operations and misleading the convergence. despite the successful retrieval of the 30-dimensional system dynamics, the algorithm's limitation becomes more evident with large systems . this drawback is partially resolved with the regularization technique presented in the methods section. also, problems of this nature can be prevented by removing the collinear components from the matrix l or placing them as independent variables . of course, this issue is drastically diminished when a chosen network topology constraints the matrix l.

discussion and 
CONCLUSIONS
within the new field of systems biology, an extraordinary effort has been devoted to kinetic modeling with the aim of understanding biological processes better  <cit> . a very significant part of this effort has been directly related to the identification of model parameters  <cit> . until recently, the quality of the estimated parameter values was judged by the fit of experimental data. however, new analyses have pointed out the importance of other criteria, such as extrapolability and error compensation among terms  <cit> , which is in some sense related to the sloppiness of admissible parameter sets and the fact that different parameter values can generate similar dynamical behaviors in nonlinear biological systems models  <cit> . these observations have a direct impact on the robustness of models, which may translate into robustness of the biological system itself, which may become apparent in tolerance to mutations, changes in gene expression, and insensitivity to modest changes in environmental conditions. this need for physiological robustness implies that biochemical networks should be able to preserve their dynamical properties within reasonable ranges of their kinetic parameters  <cit> .

in this report, we present an extension of our previous optimization algorithm for s-system parameter identification from time series data  <cit> . the proposed method turned out to be faster and more accurate than its predecessor  and was used here in combination with a monte carlo random walk technique to explore the space of admissible parameter sets of s-system models. this strategy allowed us to explore the concept of sloppy models. the results indicate that both, a fully integrated and a decoupled model, can be sloppy. we also reanalyzed time series of the concentrations of six metabolites within the glycolytic pathway of the bacterium lactococcus lactis and demonstrated how a sloppiness analysis can elucidate the admissible parameter space and ultimately lead to more reliable estimates.

the central result reported here is that a diversity of parameter sets may produce quasi-isomorphic dynamics for s-system models. most of the parameter variations extended to both positive and negative parts of the parameter space . this result is interesting, because it could be the consequence of two distinctly different scenarios. first, it could reflect redundancy or sloppiness caused by insufficient data. in other words, the data are not informative enough to distinguish between alternative models that fit equally well. in the past, such situations have often been "resolved" by setting as many parameters to zero as possible with the set of admissible solutions, borrowing arguments of parsimony or ockham's razor. the important feature of this scenario is that further experimental data, maybe obtained under similar yet sufficiently different conditions, would declare one of the candidate models the  winner. the second possible root cause of distinct, well-fitting parameter sets is the actual natural co-existence of different regulatory signals between components  or different regulatory networks . thus, otherwise similar cells or organisms would function under slightly different regulatory regimens. the difference between these scenarios is conceptually similar to the distinction between uncertainty and variability, which was discussed intensely in the 1980s and 1990s within the fields of risk assessment and exposure analysis  <cit> . the former case of uncertainty  is only valid if the model is, in principle, uniquely identifiable and structurally distinguishable  <cit>  from among all feasible s-systems. this aspect raises the possibility that a sloppy model could be unidentifiable and that the sloppy directions, which are given by the possible parameter combinations  <cit>  could be a measure of non-identifiability  <cit> . for s-systems this argumentation can be extended. our results show that an ensemble of s-systems could be interpreted as a collection of structurally indistinguishable and unidentifiable models  <cit> . this conjecture would explain the range of variability  of the parameter sets that were found. furthermore, the identifiability characteristic of the mathematical framework could be associated with the robustness of the biological system to environmental changes. analogously, the structure distinguishability characteristic could be, in some sense, associated with the robustness of the biological system to mutations that change the network of interaction among components. a more rigorous study of s-system identifiability and distinguishability will be needed to reveal more concrete conclusions and mathematical implications  <cit> .

whether the distinction between parameter sloppiness and structural distinguishability in biological models is an important issue will have to await further investigation. nevertheless, it is clear that extrapolability in the generic network identification problem from time series data is a more complex task than the computational fitting of a model. one should expect that this observation is true for any model structure, but it was shown here that s-system models allow its exploration in a most translucent fashion.

the assessment of sloppiness provides valuable information that can be extracted from the prediction of the ensemble of models and through the investigation of behavioral classes that differ in their dynamical features . these classes may be further reduced by biological knowledge such as biochemical, physico-chemical, or thermodynamic constraints  <cit> . the proposed techniques could also serve as a powerful exploration tool for the testing of hypotheses and the design of new experiments. moreover, the union of the proposed optimization algorithm with statistical methods could also result in a robust network inference implementation  <cit> .

maybe the most important value of this report is the clear definition of a framework to explore sloppiness, robustness and evolutionary innovation  <cit> , where neutral parameter spaces  are merged with neutral networks  <cit>  into one unique structure. this approach could reveal insights into how different metabolic networks could possibly have been changed during the evolutionary process.

