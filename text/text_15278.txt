BACKGROUND
natural populations are often characterized by complex demographic histories. their effective sizes and ranges change over time leading to fission and fusion processes that leave signatures on their genetic constitution and structure. one promising prospect of current biology is that molecular data will help us to reveal the complex demographic processes that have acted on populations. the extensive availability of different molecular markers and increased computer power has promoted the development of inferential methods and associated software that have begun to fulfil these expectations  <cit> .

approximate bayesian computation  is a recent flexible class of monte-carlo algorithms for performing model-based inference  <cit> . estimations associated with demographic and genetic models often imply a full likelihood calculation, which is difficult for complex evolutionary scenarios. abc methods bypass exact likelihood calculations by using summary statistics and massive computer simulations and make it possible to handle large data sets, such as data for hundreds of individuals genotyped at tens of microsatellite loci. the development of abc has hence generated a sharp increase in the complexity of models used in various fields  <cit> . abc methods were recently successfully used to make inference on complex models in population and evolutionary biology  <cit> , infectious disease epidemiology  <cit>  and system biology  <cit> . such inferences mainly include model selection among a finite set of models  and inferences on the posterior distribution of the parameter of interest under a given model. whereas several studies have now shown that parameter posterior distributions inferred by abc are similar to those provided by full-likelihood bayesian approaches  <cit> , the approach is still in its infancy and continues to evolve, and to be improved . in statistical analysis assessing the "goodness-of-fit" of a model  with respect to a "real" data set is termed model checking. if a  model has a good fit then the observed data set should look plausible under the posterior predictive distribution of the model  <cit> . although useful when doing inferences, model checking is a feature of abc analyses that has been so far neglected .

until recently, the abc approach has remained inaccessible to most biologists because of the complex computations involved. since  <dig>  several abc softwares have been proposed to provide solutions to non-specialist users  <cit> . cornuet et al.  <cit>  developed the software diyabc in which a user-friendly interface helps non-expert users to perform historical inference using abc. diyabc allows considering complex population histories involving any combination of population divergences, admixtures and population size changes, with population samples potentially collected at different times. diyabc can be used to compare competing evolutionary scenarios and quantify their relative support, and estimate parameters for one or more scenarios. eventually, it provides a way to evaluate the amount of confidence that can be put into the various estimations. so far, diyabc applied only to independent autosomal microsatellite data and did not offer users to achieve model checking computation.

this article describes new developments of diyabc that mainly include  the extension of abc analysis to dna sequence data in addition or separately to microsatellite data and  the possibility to proceed model checking computation to assess the "goodness-of-fit" of a model within an abc framework. we used controlled simulated data sets generated under complex evolutionary scenarios to evaluate the interest of mixing autosomal microsatellite, mtdna and/or nuclear autosomal dna sequence data. we also used a set of scenarios often considered when making abc inferences on the routes of introduction of invasive species to illustrate the interest of the model checking option of diyabc to assess model misfit.

methods
new implementations in diyabc v <dig> 
the new version of the software allows the treatment of haploid in addition to diploid data. five categories of loci  can now be analyzed together or separately: autosomal diploid, autosomal haploid, x-linked, y-linked and mitochondrial. x-linked loci can be used for a haplo-diploid species in which both sexes have been sampled. the data for each type of markers may have been obtained from the same or different individuals. balanced or non balanced sex ratios can be considered.

four different mutation models can be chosen for dna sequence data. for all mutation models, insertion-deletion mutations are not considered mainly because there does not seem to be much consensus on this topic. concerning substitutions, we have implemented the following models: the jukes-cantor  <cit>  one parameter model, the kimura  <cit>  two parameter model, the hasegawa-kishino-yano  <cit>  and the tamura-nei  <cit>  models. the last two models include the ratios of each nucleotide as parameters. however, in order to reduce the number of parameters, these ratios have been fixed to values observed in the data for each dna sequence locus. consequently, this leaves two and three variable parameters for the hasegawa-kishino-yano  and tamura-nei , respectively. summary statistics can be chosen for dna sequence data among a set of  <dig> statistics detailed in the notice document available at http://www <dig> montpellier.inra.fr/cbgp/diyabc. as for microsatellite loci, dna sequence summary statistics are averaged for a type of sequence loci . this allows reducing the total number of summary statistics as the latter may quickly increase when considering summary statistics independently for each sequence locus.

with respect to microsatellite loci, the possibility of uneven insertion/deletion events  is now better taken into account in inferences as this type of mutation events is not considered anymore as a nuisance parameter but can be estimated by considering a mean mutation rate  drawn from various prior distributions and some individual locus mutation rates drawn from some gamma distribution with mean = mean μsni.

a new option called "evaluate scenario-prior combination" allows checking whether some of the models together with the chosen prior distributions have the potential to generate a subset of summary statistics close to the observed summary statistics . in the first analysis proposed by this option, a principal component analysis is performed in the space of summary statistics on at most  <dig>  simulated data sets and the target  data set is added on each plane of the analysis in order to evaluate how the latter is surrounded by the simulated data sets. in addition to this global approach, there is a second one in which each summary statistic of the observed data set is ranked against those of the simulated data set. this second analysis helps finding which aspects of the model  is problematic. for instance, a grossly underestimated genetic distance  may suggest a misspecification of the prior distribution of a divergence time between two populations or of the mean mutation rate of the markers. to our experience, using this new option before running a full abc treatment with diyabc is a convenient and easy way to reveal noticeable misspecification of prior distributions and/or models .

following gelman et al. , we implemented a new option in diyabc v <dig> , called "model checking", to measure the discrepancy between a combination of a model and parameter posterior distributions and a "real" data set by considering various sets of test quantities. these test quantities can be chosen among the large set of abc summary statistics proposed in diyabc v <dig> . details regarding these new computations are given below in the methods and results sections entitled model checking.

diyabc v <dig>  was written in delphi  <dig> and runs under a 32-bit windows operating system. it is worth stressing that this new version of the software was recoded in order to use a multithread technology allowing the exploitation of multicore/multiprocessor computers. this is especially useful when building the reference table and for several other intensive computation steps, such as the multinomial logistic regression. such improvements allow a substantial gain of speed for abc treatments when using multicore/multiprocessor computers, which now are found in most biology research laboratories.

mixing microsatellite, mtdna and/or nuclear dna sequence data
in order to evaluate the interest of mixing microsatellite loci with mtdna and/or nuclear dna sequence data, we used simulated data sets generated under three complex evolutionary scenarios similar to those presented in cornuet et al.  <cit> . these scenarios involved different number of divergence and admixture events that occurred at recent to ancient times . we evaluated the potential of different types of data sets  to compare the three competing scenarios and estimate parameters under each scenario.

prior distributions of demographic parameters were as followed: uniform for effective population sizes , uniform for t <dig>  uniform for t <dig>  uniform for t <dig>  t3a, and t <dig> , uniform for t <dig>  and uniform for r <dig> and r <dig>  for microsatellite markers, the ten loci were assumed to follow a generalized stepwise mutation model  with two parameters: the mean mutation rate  and the mean parameter of the geometric distribution of the length in number of repeats of mutation events  drawn from uniform and uniform prior distributions, respectively. each locus has a possible range of  <dig> contiguous allelic states and was characterized by individual μloc and ploc values drawn from gamma and gamma distributions, respectively  <cit> . for dna sequence loci , the sequences were assumed to follow the two parameter model of kimura  <cit>  with a fraction of constant sites  fixed to 10% and the shape parameter of the gamma distribution of mutations among sites equal to  <dig>  for each sequence locus , the mean mutation rate per nucleotide and generation was drawn in a uniform and a uniform for the mtdna and nuclear sequences, respectively  <cit> .

the summary statistics for microsatellite loci were the mean number of alleles, expected heterozygosity  <cit>  and allele size variance per population, fst values and genetic distance  <dig> between pairs of populations  <cit>  and the maximum likelihood estimate of admixture proportion  <cit> . the summary statistics for dna sequence loci were  the number of distinct haplotypes, the number of segregating sites, the mean pairwise difference, the variance of the number of pairwise differences ,  the number of distinct haplotypes, the number of segregating sites , and  the fst between pairwise samples  and an adaptation for sequence data of the maximum likelihood estimate of admixture proportion of choisy et al.  <cit> . mean values of such statistics were computed over loci grouped by category .

for each combination of marker type, we simulated  <dig> data sets for each of the three competing scenarios. for each competing scenario, we simulated  <dig> test data sets  drawing demographic and marker parameter values in the same distributions as those used to generate the reference table . for model comparison, we estimated the posterior probabilities of the competing scenarios using a polychotomous logistic regression on the 1% of simulated data sets closest to the observed data set  <cit> . posterior probabilities of the three scenarios were used to compute type i and ii errors in the choice of each scenario. for instance, let us consider the estimation of type i and type ii errors when choosing scenario  <dig> as the true scenario. to do so, we simulate  <dig> data sets according to scenario  <dig>   <dig> and  <dig>  then we count the proportion of times that scenario  <dig> has not the highest posterior probability among the three competing scenarios when it is the true scenario  or the proportion of times that scenario  <dig> has highest posterior probability when it not the true scenario .

we then estimated the posterior distributions of parameters under the most complex scenario  using a local linear regression on the 1% closest simulated data sets and applying a logit transformation to parameter values  <cit> . we evaluated the precision of parameter estimation by computing the median of the absolute error divided by the true parameter value of the  <dig> pseudo-observed data sets simulated under scenario  <dig> using the median of the posterior distribution as point estimate . all computations were processed using diyabc v <dig> .

model checking
a combination of a model and parameter posterior distributions is acceptable only if the observed data look similar to replicated data generated under this model-posterior combination . to put it another way, the observed data should look plausible under the posterior predictive distribution. this is really a self-consistency check: an observed discrepancy can be due to model misfit  or chance. following gelman et al. , we implemented an option in diyabc v <dig>  to evaluate the discrepancy between a model-posterior combination and a target  data set by considering various sets of test quantities. these test quantities are chosen among the set of abc summary statistics proposed in diyabc v <dig>  . for each test quantities , a lack of fit of the observed data with respect to the posterior predictive distribution can be measured by the cumulative distribution function values of each test quantities defined as prob. tail-area probability, or p-value, can be easily computed for each test quantities as prob and  <dig>  - prob  for prob  ≤  <dig>  and >  <dig> , respectively  <cit> . such p-values represent the probability that the replicated data  could be more extreme than the observed data . too many observed summary statistics on the tails of distributions would cast serious doubts on the adequacy of the model-posterior combination. because p-values are computed for a number of test statistics, we used the method of benjamini and hochberg  <cit>  to control the false discovery rate . an alternative way to combine p-values across test statistics has been recently proposed  <cit> .

one complication with inferences using abc is that at least some and sometimes all summary statistics used as tests quantities have already been used during the inference steps . there is a risk of over-estimating the quality of the fit by using the same statistics twice. this problem which clearly arises within an abc framework is actually a general one in statistical inference. as underlined in many text books in statistics , it is advised against performing model checking using information that have already been used for training . optimally, model checking should be based on test quantities that do not correspond to the summary statistics that have been used for previous inferential steps; this is naturally possible with diyabc as the package propose a large choice of summary statistics. the choice of the two sets of statistics remains a difficult issue that still needs to be thoroughly investigated . in practice, one could advise users to choose the set of statistics for the model discrimination and parameter estimation step and the set of statistics for the model checking step before they embark on the first step. moreover, it seems sensible that both sets include statistics describing genetic variation both within and between populations.

to illustrate this new model checking option of diyabc v <dig> , we have chosen a set of basic scenarios considered when making abc inferences on the routes of introduction of invasive species  <cit> . we considered three models in which two invasive populations originate from the same source population. these populations may be related through three different scenarios: the independent introduction scenario, the serial introduction scenario and the unsampled population scenario . in the independent or serial introduction scenarios, all the populations concerned were sampled, but in the unsampled population scenario, the two invasive populations were founded independently from an undetected and hence unsampled population, itself introduced from the source. it is worth stressing that although previous studies have shown that some invasive populations may remain undetected but may play important role in the invasion dynamics of some species  <cit> , the unsampled population scenario is often not considered. if only the traditional independent and serial introduction scenarios are compared, a "real" data set obtained under the unsampled population scenario will erroneously fit one of the two competing scenario with often a high posterior probability . here we used a single, randomly chosen, pseudo-observed test data set simulated under the unsampled population scenario to illustrate the interest of the model checking option of diyabc.

standard abc analyses  were first performed on the above test data set as described previously . we drew parameter values from the prior distributions described in the legends of figure  <dig> and used the summary statistics described in table  <dig>  model checking computations were then processed by simulating  <dig>  data sets under each studied model-posterior combination, with sets of parameter values drawn with replacement among the  <dig>  sets of the posterior sample. we computed two groups of test quantities: a first group of summary statistics already used for model discrimination and estimation of parameter posteriors and a second group of summary statistics not previously used for inferences. each observed summary statistics was then ranked and given cumulative distribution function values among the corresponding sample of summary statistics obtained through the above simulation, providing an estimation of p-value for each summary statistics. in addition, a principal component analysis  was performed in the space of summary statistics. principal components were computed considering  <dig>  data sets simulated with parameter values draw from the prior. then the target  data set as well as the  <dig>  data sets simulated from the posterior distributions of parameters were added to each plane of the pca. if the model-posterior combination fits well the observed data set, one should see on each pca plane a wide cloud of data sets simulated from the prior, with the observed data set in the middle of a small cluster of data sets generated from the posterior predictive distribution. all computations and illustrations were processed using diyabc v <dig> .

evolutionary scenarios  <dig>   <dig> and  <dig> are detailed in figure  <dig>  the single "pseudo-observed" test data set analyzed here was simulated under scenario  <dig>  the probability  given for each test quantities  was computed from  <dig>  data sets simulated from the posterior distributions of parameters obtained under a given scenario. corresponding tail-area probabilities, or p-values, of the test quantities  can be easily obtained as prob and  <dig>  - prob  for prob  ≤  <dig>  and >  <dig> , respectively  <cit> . the test quantities correspond to the summary statistics used to discriminate among scenarios and compute the posterior distributions of parameters or to other statistics. nal_i = mean number of alleles in population i, het_i = mean expected heterozygosity in population i  <cit> , mgw_i = mean ratio of the number of alleles over the range of allele sizes  <cit> , fst_i_j = fst value between populations i and j  <cit> , var_i = mean allelic size variance in population i, lik_i_j = mean individual assignment likelihoods of population i assigned to population j  <cit> , h2p_i_j = mean expected heterozygosity pooling samples from populations i and j, das_i_j = shared allele distance between populations i and j  <cit> . populations i and j correspond to populations s,  <dig> or  <dig> in figure  <dig>  *, **, *** = tail-area probability <  <dig> , <  <dig>  and <  <dig> , respectively. significant tail-area probabilities after applying the false discovery rate correction method of benjamini and hochberg  <cit>  are given in bold italic characters.

RESULTS
mixing microsatellite, mtdna and/or nuclear dna sequence data
results dealing with the discrimination among a finite set of competing complex scenarios are summarized in figure  <dig>  when considering the confidence in scenario choice for each type of markers taken separately, we found that the lowest error rates were obtained for different types of markers depending on the type of error and scenario considered. the lowest type i error rates were obtained with the nuclear sequences for scenarios  <dig> and  <dig>  and microsatellites or mtdna for scenario  <dig>  the lowest type ii error rates were obtained with mtdna for scenario  <dig>  the nuclear sequences for scenario  <dig> and microsatellites for scenario  <dig>  some differences in error rates between markers were small, however, and hence not significant using fisher exact tests . mtdna displayed contrasted error rates depending on the scenario considered, with sometimes large error values; for instance a type i error of  <dig>  for scenario  <dig> and a type ii of error  <dig>  for scenario  <dig>  these large error rates were probably due to the fact that mtdna data correspond to a single locus and hence to a single gene genealogy subject to substantial stochastic variation  <cit> . adding sequence data  to microsatellite data globally decreased type i errors  and type ii errors . for all three scenarios, the lowest type i and ii error values were obtained when combining the three types of markers.

results dealing with the estimation of parameters under scenario  <dig> are summarized in figure  <dig>  whatever the type and combination of markers, the molecular data provided substantial information for all parameters except the divergence times t <dig>  t <dig> and t <dig> for which the level of information remained low. for the latter parameters the relative median absolute errors  were only slightly lower than those computed as base level using only the prior information on parameters . this is not surprising since t <dig> corresponds to a very recent time of admixture  and t <dig> or t <dig> correspond to divergence times for which one of the two diverging populations has not been sampled.

we found that, depending on the parameter considered, cumulating the information provided by different markers translated into a decrease, an increase or, most frequently, an absence of noticeable variation of the rmae values compared to that obtained with the most informative genetic marker . although each category of markers is different and genealogically independent, the genetic variation at these markers is constrained by the fact that they share the same evolutionary history  so that information provided by each category is not expected to sum up. for all demographic parameters, the lowest rmae values were obtained, however, when combining the three categories of markers; but in many cases, one or the other category , taken alone, provided almost the same precision.

we found that adding sequence data substantially improved the quality of the estimations of some parameters in comparison to results obtained with microsatellites only. this was particularly true for the most ancient divergence time t <dig> for which rmae values decreased by 41%, 36% and 47% when adding a single mtdna sequence, five nuclear sequence and both types of sequences, respectively. only small decreases of rmae values were observed for moderately ancient events such as the divergence time t <dig> and the admixture rate r <dig>  this result underlines the interest of using low mutating and seldom homoplasious sequence data for making inferences on ancient historical events. in agreement with this, the two rmae values for t <dig> obtained with the mtdna data sets and the nuclear sequence data sets were lower than that obtained for microsatellite loci only. due to their mutation modalities , it is not surprising that microsatellite loci performed poorly for ancient evolutionary events  <cit> . on the opposite, microsatellite markers provided substantially better estimation than mtdna or nuclear sequence for the most recent admixture rate . the rmae values for the mtdna sequence and the nuclear sequences were two to three times larger than those obtained with microsatellite only for this parameter. as a result, the addition of mtdna or nuclear sequences to microsatellite data did not bring any progress in terms of rmae for r <dig>  this result holds to a lesser extent for the effective population size n.

model checking
when considering altogether the three scenarios in our model discrimination analysis, we found that our  pseudo-observed test data set generated under the unsampled population scenario  was unambiguously assigned to the correct scenario with a high posterior probability . when only scenarios  <dig> and  <dig> were proposed for posterior probability estimation then the same test data set generated under scenario  <dig> was assigned to the incorrect scenario  <dig> with a high posterior probability . additional abc treatments achieved on larger sets of pseudo-observed test data sets  confirmed that if only the traditional independent and serial introduction scenarios are considered, a data set obtained under the unsampled population scenario will erroneously be chosen, with often a high posterior probability to one of the two competing scenario; scenario  <dig> is chosen for 55% and 63% of the data sets generated under scenario  <dig> when simulating test data sets using the same fixed parameter values than the above single test data set and when drawing parameter values in the same distribution than those chosen as priors, respectively.

focusing on our single pseudo-observed test data set simulated under scenario  <dig>  we evaluated in details the interest of the model checking option of diyabc v <dig>  to assess model misfit. we found that none of the twelve test quantities had low tail probability values when applying the model checking option to the  scenario  <dig> . in contrast, one to several test quantities had low tail-area probabilities  when applying the model checking option to  scenarios  <dig> or  <dig>  hence casting serious doubts on the adequacy of the tested model-posterior combination. we found some indication of a risk of over-estimating the quality of the fit by using as test quantities the same summary statistics already used during the inference steps ; see table  <dig>  the proportion of test quantities with low tail-area probabilities was indeed larger when using summary statistics not previously used for inference. a close examination of which summary statistics displayed low tail-area probabilities provides some insights on which aspects of the models  <dig> and  <dig> are problematic. in the studied case, outlying statistics correspond to an overestimated genetic differentiation in simulated data sets compared to the observed one between the introduced populations  <dig> and  <dig> for scenario  <dig>  whereas it correspond to an underestimated genetic differentiation for scenario  <dig>  this pattern is in agreement with the specificities of the "true" scenario  <dig>  relatively to scenario  <dig>  and scenario  <dig> ; see figure  <dig> 

we further inspected the fit/misfit of models by performing several principal component analysis on the test quantities obtained with the different model -posterior combinations together with the pseudo-observed test data set simulated under the unsampled population scenario . in agreement with the quantitative results summarized in table  <dig>  the pca points of the test quantities obtained from the model-posterior combination corresponding to the  scenario  <dig> were nicely grouped and centred on the target point corresponding to the pseudo-observed test data set. this configuration holds when considering either previously used or unused abc summary statistics as test quantities. when considering scenarios  <dig> and  <dig>  we found that the target point of the "pseudo-observed" test data set was positioned at best on the border of the cloud of pca points of the test quantities corresponding to the summary statistics previously used for abc analyses. interestingly enough, the target point was clearly outside the cluster when considering unused summary statistics as test quantities.

the model checking analysis of other pseudo-observed test data sets provided results  similar to those presented in the table  <dig> and additional file  <dig> .

CONCLUSIONS
the software diyabc v <dig>  offers a user-friendly interface allowing non-expert users to perform additional and more accurate inferences using abc than its previous version. the new implementations allow the treatment of haploid in addition to diploid data and allow making inferences from dna sequence data  in addition or separately to microsatellite data. the possibility of mixing different types of molecular markers  should prove useful when considering complex evolutionary scenarios involving both recent and ancient historical events. finally, diyabc v <dig>  offers non-specialist users a handy way to achieve model checking computation , a feature of abc analysis that has been so far neglected. these new software developments significantly enlarge the tool box available to biologists to make abc inferences on more complex and hence more realistic demographic processes that have acted on natural populations. the main limitations of the current version of diyabc are the assumed absence of migration among populations after they have diverged, the impossibility to consider other reproduction systems than standard sexuality as well as evolutionary neutrality of markers. next developments will aim at progressively removing these limitations.

authors' contributions
jmc and ae carried out the analyses, wrote the paper and jointly developed the software diyabc v <dig>  with vr. all authors read and approved the final manuscript.

supplementary material
additional file 1
pre-evaluation of model-prior combinations: two examples. pre-evaluation of model-prior combinations: example  <dig>  a single test pseudo-observed data set  was first simulated under a model of a single population  with effective size n =  <dig> . microsatellite loci were assumed to follow a generalized stepwise mutation model  with a mean mutation rate  equal to  <dig> × 10- <dig> and a mean parameter of the geometric distribution of the length in number of repeats of mutation events  equal to  <dig> . each locus was given a possible range of  <dig> contiguous allelic states and was characterized by individual μloc and ploc values drawn from gamma and gamma distributions, respectively  <cit> . for abc analysis of the test data set, we used the same population and marker models, and prior distributions of demographic parameters were as followed: uniform  or uniform  for n, uniform and uniform for mean μ and mean p, respectively. we choose three summary statistics : mean number of alleles, mean expected heterozygosity  <cit>  and mean allele size variance per population. pca on summary statistics  and probability  for each summary statistics  were computed from  <dig>  simulations, randomly drawing parameter values from priors. pre-evaluation of model-prior combinations: example  <dig>  a single pseudo-observed test data set  was first simulated under a model of two populations  splitting at time t =  <dig>  generations from an ancestral population, without subsequent migration. for all populations the effective size was n =  <dig> . for abc analysis of the test data set, we used the same population and marker models, and prior distributions of demographic parameters were as followed: uniform  or uniform  for t, and uniform for n. the mutation model and priors for microsatellite markers are the same as in example  <dig>  we choose eight summary statistics : mean number of alleles, mean expected heterozygosity  <cit>  and mean allele size variance of each population sample, and fst values and genetic distances  <dig> between pairs of populations  <cit> . pca on summary statistics  and probability  for each of the summary statistics  were computed from  <dig>  simulaxtions, randomly drawing parameter values from priors.

click here for file

 additional file 2
evaluation of the variation of rmae values expected by chance between different replicates of  <dig> pseudo-observed data sets. relative median absolute errors  were computed for  <dig> replicates of  <dig> pseudo-observed data sets simulated under scenario  <dig>  the data sets include  <dig>  microsatellite loci and were generated under scenario  <dig> presented in figure  <dig>  parameter values were drawn from the same distributions than the prior distributions given in the legend of figure  <dig>  the demographic parameters n, t <dig>  t <dig>  t <dig>  t <dig>  t <dig>  r <dig> and r <dig> are detailed in figure  <dig>  standard deviation of rmae values were equal to  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig>  and  <dig>  for n, t <dig>  t <dig>  t <dig>  t <dig>  t <dig>  r <dig> and r <dig>  respectively. similar levels of rmae variation among replicates of  <dig> pseudo-observed data sets were obtained for other categories of genetic markers  and combinations of categories of markers .

click here for file

 additional file 3
principal component analysis of test quantities when processing model checking for the introduction scenarios  <dig>   <dig> and  <dig>  the scenarios  <dig>   <dig> and  <dig> are detailed in figure  <dig>  the pseudo-observed test data set analyzed here was simulated under scenario  <dig>  pca were processed on the test quantities corresponding to the summary statistics used to discriminate among scenarios and compute the posterior distributions of parameters  or on other statistics . the summary statistics used as test quantities are detailed in the legend of table  <dig> 

click here for file

 acknowledgements
we thank gaël kergoat, renaud vitalis and alexandre dehne-garcia for useful discussions. this research was financially supported by the french agence nationale de la recherche grants anr-09-blan-0145- <dig> to ae, jmc and vr and anr-07-bdiv- <dig>  to vr.
