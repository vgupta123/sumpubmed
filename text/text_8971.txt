BACKGROUND
amongst other high throughput techniques like dna microarrays and mass spectrometry, qpcr has become important in many areas of basic and applied functional genomics research. due to its high sequence-specificity, large dynamic range, and tremendous sensitivity it is one of the most widely used methods for quantification of gene expression. moreover, due to the adoption of robotic pipetting stations and 384-well formats, laboratories generate a huge amount of qpcr data demanding a centralized storage, management, and analysis application.

most software programs provided along with the qpcr instruments support only straightforward calculation of quantification cycle  values from the recorded fluorescence measurements. however, in order to get biological meaningful results these basic calculations need to undergo further analyses such as normalization, averaging, and statistical tests  <cit> .

to this end, a variety of different methods have been published describing the normalization of cq values. the simplest model  was developed by livak and schmittgen  <cit>  which assumes perfect amplification efficiency by setting the base of the exponential function to  <dig> and uses only one reference gene for normalization. the model proposed by pfaffl  <cit>  considers pcr efficiency for both the gene of interest and a reference gene and is therefore an improvement over the classic ΔΔ-cq method. nevertheless, it still uses only one reference gene which may not be sufficient to obtain reliable results  <cit> . hellemans et al.  <cit>  proposed an advanced method which considers gene-specific amplification efficiencies and allows normalization of cq values with multiple reference genes based on the method proposed by vandesompele et al.  <cit> . it should be noted that these methods could differ substantially in their performance, because of the different assumptions they are based on.

available software tools often cover only single steps in the analysis pipeline compelling researchers to use multiple tools for the analysis of qpcr experiments  <cit> . however, these tools do not share a common file format making it difficult to analyze the experimental data. additionally, no standardization of methodology has been established that would be needed for relatable comparison between laboratories  <cit> . recently, the minimum information for publication of quantitative real-time pcr experiments  guidelines  <cit>  were published which are intended to describe the minimum information necessary for evaluating and comparing qpcr experiments. based on a subset of these guidelines the xml-based real-time pcr data markup language   <cit>  was proposed which tries to facilitate the exchange of qpcr data and related information between qpcr instruments, analysis software, journals, and public repositories. these efforts could allow a more reliable interpretation of qpcr results if they were accepted in the qpcr community.

the lack of complete or partial assessment of error propagation throughout the whole analysis pipeline may result in an underestimated final error and could therefore lead to incorrect conclusions. moreover, the analysis of experiments using tools that make invalid biological assumptions can cause significantly wrong results as reported in  <cit> .

to the best of our knowledge, there is no single tool available which integrates storage, management, and analysis of qpcr experiments. hence a system enabling comparison of results and providing a standardized way of analyzing data would be of great benefit to the community. we have therefore developed qpcr, a web-based application which supports: a) technical and biological replicate handling, b) the analysis of qpcr experiments with an unlimited number of samples and genes, c) normalization using an arbitrary number of reference genes, d) inter-plate normalization using calibrators, e) assessment of significant gene deregulation between sample groups, f) generation of customizable charts, and g) a plug-in mechanism for easy integration of new analysis methods.

implementation
the qpcr system was implemented in java, a platform independent and object-oriented programming language  <cit> . the application is based on the java  <dig> enterprise edition  three-tier architecture consisting of a presentation-, business -, and database-layer. a relational database  is used as the persistence backend. the business layer consists of enterprise java beans  and is deployed on a jboss  <cit>  application server. the presentation layer is based on the model-view-controller  framework struts  <cit>  and uses java servlets and java server pages.

in order to enhance usability current web technologies have been extensively used in this application. ajax functionality has been incorporated into the application using the open-source library dwr  <cit> . this technology allows asynchronous loading of data without the need to reload the page thus providing a desktop like application behavior. multiple javascript libraries  have been used that allow executing functions on the client side and therefore remarkably improve the usability of the application. charts are generated using the open-source java library jfreechart  <cit>  and all charts are created either in the lossless png format or as a scalable vector graphic .

all algorithms, calculation methods, and data file parsers used by the application are integrated through a plug-in mechanism which allows simple extension with additional qpcr data formats and analysis approaches. for each class that uses the plug-in mechanism a specific interface needs to be implemented in order to support another vendor or implement an additional analysis method. the new java classes are then automatically detected by the qpcr application.

currently the data file parsers support files generated by applied biosystems  and roche lightcycler   <cit>  systems as well as a generic file format based on comma separated values . since not all fluorescence measurements can be extracted from data files created by the qpcr instrument systems, additional export files are required to parse all relevant data.

analysis methods that calculate cq and amplification efficiency values are computationally expensive and are therefore executed asynchronously and do not interfere with the qpcr web interface. they are designed to operate on a per well basis and report the current progress of the calculation. normalization methods and statistical tests are not time consuming processes and are therefore executed in real time.

the qpcr application has been designed using the unified modeling language   <cit> . the use of a uml representation improves maintainability as the application architecture is outright visible and provides an important part of the system documentation. we used the andromda framework  <cit>  to create basic ejb and presentation tier source code as well as configuration files based on the uml model. andromda minimizes repetitive coding tasks, allows to easily extend or edit the architecture of the application, and helps maintaining the consistency between design and implementation.

the stored data is secured by a user management system which allows the definition of several fine grained user access levels and offers data sharing and concurrent access in a multi-centric environment  <cit> . moreover, the application provides two configurations which assign the ownership of objects either to the submitter or to the submitter's institute. the latter setup provides the possibility to edit and analyze experiments by all users of an institute without the need to explicitly share objects.

RESULTS
qpcr is an application which integrates storage, management, and analysis of qpcr experiments into one single tool. implemented as a web application it can be accessed by a web browser from every network connected computer and therefore supports the often decentralized work of biologists. it parses files generated by qpcr instruments, stores data and results in a database, and performs analyses on the imported data. moreover, it allows conducting of statistical tests and provides several ways to visualize and export the calculated results .

parsing files and calculation of cq/efficiency values
data files are uploaded into the application using a single file upload dialog or an integrated java applet which supports uploading of multiple files at once. an upload zone lists all available files and allows querying and downloading of data previously uploaded. all files are stored in a user defined directory facilitating the backup of project critical files.

after uploading the exported files into the qpcr application, a list of all files which have not yet been processed is shown. the user can select single or multiple files for parsing. moreover, cq and amplification efficiency values can be automatically calculated after the files have been parsed using one or several different methods.

during parsing all relevant data is extracted, including plate setup, fluorescence measurements, and qpcr instrument specifications and stored in the database. in contrast to many available analysis tools the application is able to import qpcr data files without the need for additional file manipulations and therefore reduces error-prone and cumbersome manual work. in addition to the already existing data file parsers the application can be easily extended to support other vendors due to the modularity of the platform and the used plug-in mechanism.

once the data is parsed and stored in the database, cq and amplification efficiency values are calculated based on the fluorescence measurements. several published and widely-used algorithms were implemented; two different algorithms to calculate cq together with efficiency values, three different algorithms to calculate solely the amplification efficiency, and one method to calculate the cq value are available .

the progress of all active parser or analyzer background tasks is displayed on a view that automatically updates the current status. as soon as a process has finished a message is shown at the top of the page. for each process a log file is created which informs the user about the outcome of the performed job. a color scheme helps to quickly identify the jobs that have not finished successfully.

during parsing of uploaded files a run is created in the application which is a direct representation of the performed qpcr run. it stores information about the hardware, software, thermocycler profile, and category.

each run contains a plate which consists of multiple wells that store information about the sample, target, passive reference, task, and omitted status. the plate layout can be displayed in a list and each well can be edited to correct inconsistencies or to omit it from further analysis.

additionally, qpcr provides a graphical representation of the plate layout by showing a grid which displays sample, target, and status information of each well. by selecting an arbitrary number of wells, charts of amplification  and dissociation  curves are displayed . this view is helpful to evaluate the performance of the pcr for each well and is useful to perform a quick quality check of the conducted qpcr run.

analysis of experiments
after cq and efficiency values have been determined, experiments consisting of one or multiple runs are subjected to subsequent analysis steps. several plates can be combined into one experiment. in order to support a flexible and adaptable analysis of experiments, the application allows selecting of specific samples and genes to be used in subsequent analysis steps. moreover, the cq calculation method, the efficiency method, and the reference genes can be defined.

four different ways to consider amplification efficiencies in the analysis have been implemented:  setting a single efficiency value for all targets,  manually defining the efficiency for each target,  using efficiencies derived from dilution series for each target, and  using calculated efficiencies for each well. several different efficiencies values for a target, calculated by serial dilution series, can be stored in the database.

normalization of experiments is based on a method proposed by hellemans et al.  <cit>  and includes averaging of technical replicates, normalization against reference genes, inter-run calibration, and calculation of quality control parameters. technical replicates are averaged either within one plate or over all plates of the experiment depending on the analysis setting. in the next step all samples of one gene are referenced to the arithmetic mean cq value across all samples for this gene. thereafter the user selected type of efficiency is considered for each target and the samples are normalized to the selected reference genes. if reaction specific efficiency has been selected the efficiency is averaged for each target. depending on the analysis setting the application supports spreading of reference genes across multiple runs or uses reference genes for each run independently. finally, inter-run calibrators are automatically detected and are used to normalize results between different qpcr runs.

quality control parameters for reference genes are calculated based on a method described by vandesompele et al.  <cit> . when multiple reference genes are selected the coefficient of variation and the gene stability value m are calculated. these parameters are helpful for selecting and evaluating reference genes. additionally, qpcr performs outlier detection by calculating the difference in quantification cycle value between technical replicates and allows highlighting those that have a larger difference than a user defined threshold. moreover, quality control checks are performed to test if a no template control  is present for each target.

fold change ratios of the calculated normalized cq values can be calculated by referencing them to one or multiple samples. all analysis setup parameters are automatically stored in the database and are loaded when the experiment is analyzed again. additionally, each analysis setup can be stored under a user defined name. throughout the whole analysis process proper error propagation is performed using methods described in  <cit> .

during the development of the qpcr application special attention was laid on the accurate and user-friendly visualization of calculated results. therefore, the application allows to display and export results of every important analysis step. the generated figures are highly customizable and are designed to be usable in publications without further manipulation. among other parameters qpcr allows to define color, labeling, sort sequence, and data type to be used in histogram charts. cq values normalized by reference genes and calibrators are presented as histograms displaying results of one gene or multiple genes at once . every result throughout the analysis pipeline can be exported in tab-delimited or spreadsheet format  to be used in external applications.

conducting statistical tests
the final step in the analysis pipeline is the comparison of samples using statistical tests . the application allows to group samples into an arbitrary number of classes which are tested for their significant difference against one defined reference class. qpcr includes several statistical tests to compute p-values such as anova, student's t-test, and a permutation based test which makes no assumption on the distribution of the data. tests can be conducted on either untransformed or log <dig> transformed values. the application allows adjusting the calculated p-value by supporting several established correction methods for multiple testing  <cit> .

calculated test results are displayed for each class and can be exported for further analysis. moreover, the fold changes of samples are displayed in histogram charts in which samples of each class are grouped together. every class is assigned to a specific user defined color or shape that is used in different shades to group the samples of one class .

general data entry and query
the application provides views of every entity to  manually enter data and  list available items. entry views consist of mandatory and optional fields and use drop down selection lists to specify references to other entities. entered data is checked for validity and the user is informed about erroneous inputs. list views present the data in tabular form and support paging, sorting, and querying for any combination of the available attributes. moreover, queries can be stored in the database for later use.

discussion
we have developed an integrated platform for the analysis and management of qpcr experiment data using state-of-the-art software technology. the uniqueness of the application is defined by the support of various qpcr instruments, multiple data analyzers, and statistical methods, as well as the coverage of the complete analysis pipeline including proper error propagation. moreover, it provides a flexible plug-in mechanism to incorporate new parsers and methods and allows generation of highly customizable charts. a comparison of features between qpcr and several other popular qpcr analysis tools is provided in table  <dig> 

 abi  <dig>  abi  <dig>  abi 7900;  lightcycler  <dig> , lightcycler 480;  uses the suggested nomenclature;  microsoft excel based tool:  microsoft access based tool

the capability to import and parse data without the need for further file manipulations is an integral part of the application which avoids errors during the analysis and reduces the time to analyze the experimental data. as most of the available qpcr software tools rely on special formatted input files it was a prerequisite of the platform to be able to directly parse files generated by the qpcr instruments software suits. moreover, the system is not confined to a specific manufacturer and can therefore be used in laboratories equipped with qpcr instruments from different vendors.

qpcr includes established and widely used methods for the calculation of cq and amplification efficiency values and supports an easy integration of new algorithms. this framework does not limit the researcher to one specific approach and allows incorporation of newly developed analysis methods. furthermore, it is of great value as different experimental situations need to be considered separately and it remains up to individual researches to identify the method most appropriate for their experimental conditions  <cit> . qpcr allows to store several different analysis settings for each experiment and calculates quality control parameters which help to evaluate the performed analysis. incorporating several different methods to include the amplification efficiency enhances the flexibility of the application and allows adapting the analysis to the experimental conditions or laboratory practices. particularly, supporting the widely used calculation of efficiency based on serial dilution series increases the acceptance in the qpcr community.

an often underestimated drawback of using multiple tools to analyze qpcr experiments is the lack of support for assessment of error propagation. therefore the final error is often based solely on the standard deviation of biological replicates which can lead to false biological interpretations. the qpcr application addresses this problem and includes assessment of error propagation throughout the whole analysis pipeline covering technical replicate handling, normalization, inter-run calibration, referencing against samples, and biological replicate handling. the implemented method is based on taylor series expansion which allows direct calculation of the full probability distribution and is in contrast to monte carlo based methods computationally inexpensive  <cit> .

special focus was laid on the presentation of analysis results. qpcr provides an interface which uses state-of-the-art software technologies to generate highly customizable charts that are designed to be ready for publication. since many available tools do not provide a suitable graphical representation of the calculated results, microsoft excel is often used to create figures which require manual import and/or conversion of data. qpcr combines the calculation and presentation of results into one single tool which reduces analysis time and avoids additional potential error-prone steps. a flowchart displaying each analysis step and its suggested method is included into the user guide.

the recent developments of data exchange formats  and guidelines describing the minimum information about qpcr experiments  could become an important part in standardizing qpcr experimental data. qpcr already integrates the suggested nomenclature and rdml support will be implemented as soon as the relevant java libraries are available. once established in the qpcr community these initiatives will allow a standardized exchange of data between software tools and facilitate the comparison of qpcr experiments.

using three-tier software architecture that separates the presentation, the business, and the database layer enables not only easy maintenance but also allows distribution of the computing load to several servers. as more and more data needs to be analyzed this design may be very valuable in the future.

the use of a database allows easy querying and comparing of data and guarantees data integrity. the implemented plug-in framework, which is used for including data file parsers, analysis methods, and statistical algorithms, ensures that the application is adaptable to new developments and allows the effortless integration of innovative scientific methods.

CONCLUSIONS
we have developed qpcr, a system for the storage, management, and analysis of qpcr data. it integrates the complete analysis workflow, ranging from cq determination over normalization and statistical analysis to visualization, into a single application. the analysis time is significantly reduced and complex analyses can now be compared within a single or across multiple laboratories. optimal usability has been ensured by involving biologists throughout the entire development process and by extensive tests in a laboratory setting. given the incorporation of several analysis methods and the flexibility due to the use of standard software technology and plug-in mechanism, the developed application could be of great interest to the qpcr community.

availability and requirements
• project name: qpcr

• project home page: 

• operating system: solaris, linux, windows, mac os x

• programming language: java

• other requirements: java jdk  <dig> .x, oracle™ 9i or postgresql™  <dig> .x, a server with at least  <dig> gb of main memory  available to the application

• license: igb-tug software license

• any restrictions to use by non-academics: igb-tug software license

installation of the application is provided through an installer and should be completed within one hour provided the necessary database access rights are granted. we recommend installing the application on a central server by a system administrator. step-by-step instructions are provided at the projects web site together with the installer file. the reference installation of qpcr is running on a sun fire™ x <dig> m <dig>  <dig> × dual core opteron server  with  <dig> gb of memory running solaris and using a dedicated oracle  <dig> g database server. attached is a storage area network  with  <dig>  tbytes net capacity.

authors' contributions
sp designed the application and drafted the manuscript. he was responsible for implementation of the database, the development the data presentation and many parts of the business logic. ggt contributed to conception and design of the application and helped drafting the manuscript. rs improved the data file parsers and analysis methods. he gave valuable input regarding the usability of the platform. rr participated in the design and implementation of the application and helped drafting the manuscript. zt was responsible for the overall project coordination. all authors gave final approval of the version to be published.

