BACKGROUND
communities of natural microorganisms often encompass a bewildering range of physiological, metabolic, and genomic diversity. the microbial diversity in most environments exceeds the biodiversity of plants and animals by orders of magnitude. phylogenetic surveys of complex ecosystems such as soils and sediments have demonstrated that the multitude of discrete prokaryotic species represented in a single sample goes far beyond the number and phenotypes of known cultured microorganisms  <cit> . direct cultivation or indirect molecular approaches have been used to explore and to exploit this enormous microbial diversity. cultivation and isolation of microorganisms are the traditional methods. it has been estimated that less than  <dig> % of environmental microorganisms are culturable using standard cultivation methods. thus, only a tiny portion of the gene pool of natural microbial communities has been analyzed so far  <cit> .

to circumvent some of the limitations of cultivation approaches, indirect molecular methods, such as metagenomics have been developed. metagenomics is based on the direct isolation, cloning, and subsequent analysis of microbial dna from environmental samples without prior cultivation  <cit> . function- and sequence-based analysis of metagenomic dna fragments have resulted in the identification of a variety of novel genes and gene products  <cit> . in addition, partial sequencing of metagenomes, such as those from the acid mine biofilm   <cit> , minnesota farm soil   <cit> , and sargasso sea   <cit> , have provided a better understanding of the structure and genomic potential of microbial communities.

a major goal of metagenomic sequencing projects is the identification of protein coding genes. most genes in metagenomic fragments are currently identified by homology to known genes by employing other methods, e.g. blast  <cit> . the disadvantage of such an approach is obvious: it is impossible to find novel genes that way. particularly in cases where metagenomic studies aim to discover new proteins, homology search is an inadequate tool for gene prediction.

the computational ab initio prediction of genes from microbial dna has a long history, and a number of tools have been developed and employed for gene prediction and annotation of genomic sequences from single prokaryotic species . a minor restriction in the application of some conventional approaches to metagenomes is that they are based on the identification of open reading frames , which begin with a start codon and end with an in-frame stop codon. sequenced metagenomes comprise a collection of numerous short sequencing reads of varying length depending on the employed sequencing technique. a typical metagenomic fragment derived by sanger sequencing  <cit>  is approximately  <dig> bp long and contains two or fewer genes. the majority of these genes are incomplete, meaning one or both gene ends extend beyond fragment end. therefore, most orfs in metagenomic sequencing reads will be overlooked by orf-based gene finders. a more profound problem is that most gene finders for prokaryotic genomes rely on statistical sequence models that are estimated from the analyzed or a closely related genome. most metagenomic fragments do not bear sufficient sequence information for building statistical models able to distinguish coding from non-coding orfs. one might consider to derive models from a complete metagenome but the resulting gene prediction quality in fragments from underrepresented species in the metagenome is questionable.

up to now, there are three approaches for predicting genes from metagenomic dna fragments. one of these methods is based on blast search, where the search is not only applied against databases of known proteins but also against a library constructed from the metagenomic sample itself  <cit> . in principle, this computationally expensive approach is able to find novel genes, provided that homologues of these genes are contained in the sample. however, it is not clear whether interesting genes will always be conserved in a metagenomic sample. the first method that was developed for ab initio gene prediction in short and anonymous dna sequences is a heuristic approach of genemark.hmm that derives an adapted monocodon usage model from the gc-content of an input sequence  <cit> .

another method that was developed for ab initio gene prediction in metagenomic dna fragments is metagene  <cit> . similar to genemark.hmm, metagene employs gc-content specific monocodon and dicodon models for predicting genes. the time-efficient two step gene prediction algorithm first extracts orfs and scores them on the basis of statistical models estimated from fully sequenced and annotated genomes. subsequently, a dynamic program calculates the final orf combination from different scores. additionally, metagene utilizes orf length, the distance from the annotated start codon to the left-most start codon, and distances to neighboring orfs. two separate models were estimated from bacterial and archaeal genomes, respectively. the domain specific models are simultaneously applied to each fragment and the higher scoring model is selected for final gene prediction. results in randomly sampled fragments from annotated genomes indicate that metagene provides a high sensitivity in finding genes in fragmented dna, while the specificity of the predictions is slightly lower. in addition, the performance of genemark.hmm in  <dig> bp fragments and for complete genomes was investigated . comparable performance results were obtained for both methods for both types of input sequences.

here, we present a novel approach for gene prediction in single fragments, which is based entirely on machine learning techniques. in bioinformatics, state-of-the-art machine learning methods are usually applied to problems where, at most, several thousands of examples exist for training and evaluation. in our application, learning has to be performed on large data sets with millions of examples. this requires the use of a learning architecture that is capable of large-scale training and testing. here, we propose a combination of neural networks and linear discriminants. while linear discriminants are used for the extraction of features from high-dimensional data which characterize codon usage and potential gene starts, a small neural network is used for non-linear combination of these features with additional information on length and gc-content of gene candidates. neural networks in combination with linear discriminants or positional weight matrices have also been applied to other gene prediction problems, for instance in promoter recognition  <cit> .

to provide comparability in our experimental evaluation, we use a setup that is similar to the one used for the initial evaluation of metagene. we test our program on fragments from thirteen species. however, we provide some important extensions: we use a higher number of fragments which are randomly sampled from the test genomes to avoid any bias that may result from a particular fragmentation technique. the higher number of fragments is used to cope with the variance across different  sampling experiments. in addition, we provide a detailed analysis of the translation initiation site  prediction performance and we also investigate the ability to discriminate between complete and incomplete genes.

methods
most prokaryotic protein coding genes consist of a start codon, followed by a variable number of consecutive in-frame codons and are terminated by a stop codon. this particular arrangement of codons is commonly referred to as open reading frame . the sole identification of orfs is not sufficient for prokaryotic gene prediction because the majority of orfs in a genome are, in fact, non-coding.

in dna fragments, orfs frequently exceed the fragment ends. we therefore extend the orf definition to incomplete orfs.

the fact that start codons are identical to some regular codons results in a high number of related orfs that share a stop codon but have different start codons. we term such a set of related orfs an orf-set and we name the possible start codons of an orf-set translation initiation site  candidates. figure  <dig> illustrates possible cases of orf occurrence in a dna fragment: in case  <dig>  the complete orf-set is located in the fragment. additional tis candidates for this orf-set can not occur because of an upstream in-frame stop codon. predicted genes from this orf-set will always be complete. in case  <dig>  only tis candidates are located inside the fragment. the range for upstream tis is again limited by an in-frame stop codon. this candidate, if classified as coding, would result in the prediction of an incomplete gene. in case  <dig>  the stop is located in the fragment. some tis candidates are contained in the fragment but there might exist tis candidates outside the fragment. an orf-set of this type may result either in a complete or in an incomplete gene. case  <dig> is complementary to case  <dig>  only a stop codon is located inside the fragment. case  <dig> and  <dig> are fragment-spanning orf-sets, where  <dig> also includes tis candidates inside the fragment. predictions from case  <dig> will be incomplete but may have a start codon. case  <dig> and  <dig> can both result in the prediction of incomplete genes without start and stop codons.

our gene prediction algorithm is designed for the discrimination of coding from non-coding orfs. after the identification of all orfs in a fragment, we extract features from those orfs using linear discriminants. subsequently, we use a neural network that has been particularly trained for the classification of orfs as coding or non-coding. classification is based on a gene probability that the neural network assigns to every orf. because gene-containing orf-sets usually comprise of more than one candidate, several orfs of such an orf-set may be assigned a high probability by the neural network. the final gene prediction is achieved by a »greedy« method that selects the most probable orfs that overlap by, at most,  <dig> bases.

machine learning techniques
to predict whether a particular orf actually corresponds to a protein coding region or to a non-coding region, we use a neural network for binary orf classification. in the following sections, we will first describe the features utilized as inputs for the neural network. subsequently, we will depict the neural network architecture and the methods we used for large scale training and validation from labeled orfs in artificial fragments.

features
for realization of the neural network, we use seven features based on sequence characteristics of orfs. as network inputs, these sequence features are subject to a separate preprocessing step. below, we explain the methods for computation of these features in detail.

codon and dicodon usage
the perhaps most important features for the discrimination between coding and non-coding orfs can be derived from codon usage, in particular from  <dig> monocodon and  <dig> dicodon frequencies. these frequencies represent the occurrences of successive trinucleotides  and hexanucleotides , respectively. for the characterization of monocodon and dicodon usage, we compute two features based on linear discriminant scores.

linear discriminants were obtained from training with annotated sequence data. we used coding and non-coding regions from annotated genomes as positive and negative examples, respectively . examples are represented by vectors of frequencies of  <dig> and  <dig> possible monocodons and dicodons, respectively. in the following, we describe discriminant training for the monocodon case. the same training procedure was applied to the dicodon case.

for the i-th example, we denote a monocodon frequency vector as xmi∈ℝ <dig>  which is the i-th column of the data matrix xm, containing all training vectors. to remove length information from these data, all training vectors are normalized to unit euclidean norm. the corresponding label ymi ∈ {- <dig>  1}, which is the i-th element of the label vector ym, indicates whether the example represents a coding  or non-coding  region. for training of the discriminant weight vector wm, we use a regularized least squares approach, i.e. we minimize the following regularized error:

  e=1n∑i=1n2+λwm⋅wm 

where » · « denotes the dot product. the minimizer of e is obtained by  <cit> :

  wm=−1xmym 

with d × d identity matrix i and with upper t and - <dig> indicating matrix transposition and inversion, respectively. the computational cost scale linearly with the number of examples, which makes the approach well suited for large scale learning. doing the same for the dicodon frequency discriminant vector wd, we obtain two discriminant scores that serve as the first two input features of the neural network:

  x <dig> = wm · xm, x <dig> = wd · xd. 

to adjust the regularization parameter λ, we measure the discriminative power of the respective classifier by means of the area under precision recall curve  as explained in section »measures of performance«. thereby, we choose a λ ∈ {10m|m = - <dig>  - <dig>  ..., 6} to maximize the auprc on an independent validation set .

translation initiation site
a discriminant is derived from up- and downstream regions of translation initiation site  examples. here we use a  <dig> basepair  window centered on a potential start codon at window position  <dig> . we encode the trinucleotide occurrences in that window to yield binary indicator vectors. in each of its  <dig> dimensions , a vector indicates whether a certain trinucleotide occurs at a particular window position. training of the discriminant proceeds in the same way as for the previous two discriminants based on codon usage. again, we select the regularization parameter λ ∈ {10m|m = - <dig>  - <dig>  ..., 6} by maximization of the auprc on an independent validation set.

because not all genes have a potential tis region we do not use the tis score s = wt · xt directly, but instead we take the posterior probabilities of being a tis or not. for computation of the posterior probabilities, we use gaussian probability density functions of the score:

  p=12πσexp⁡2) 

where μ stands for mean and σ for standard deviation.

the features x <dig> and x <dig> were obtained from a mixture of two gaussians

  p = π+p + π-p 

with parameters estimated from scores of positive and negative training examples, respectively :

  x3=π+pp,x4=π−pp. 

if no tis candidate is present, both probabilities are set to zero for that orf. note that this case is different from the case of missing values, which can be solved by assigning a priori probabilities for true and false tis. here we encounter the possible case where we know that none of the two categories is adequate.

length features
another feature for discrimination between coding and non-coding orfs is the sequence length of the orf. here, it is important to distinguish between complete and incomplete orfs. for incomplete orfs, the observable »incomplete length« is merely a lower bound for the unobservable »complete length« of that orf and therefore should be treated in a different way. consequently, we use one »incomplete« and one »complete length« feature. for a particular orf, only the feature that corresponds to the type of orf has non-zero value. the value is simply the observed length divided by the maximal length lmax. in our evaluation, we set lmax to  <dig> bp. in this way we obtain two more features x <dig>  x <dig> ≥  <dig> for complete and incomplete length.

gc-content
as a last feature x <dig> ∈  <cit> , we use, for each orf, the gc-content estimated from the whole fragment in which this orf occurs.

neural network
we use standard multilayer perceptrons with one layer of k hidden nodes and with a single logistic output function. within a binary classification setup with labels yi =  <dig>  or yi =  <dig>  the output of the neural network can be viewed as an approximation of the posterior probability of the »true« class  <cit> . in our case, the »true« class represents coding orfs and therefore the network output can be interpreted in terms of a gene probability. for an input feature vector x, the k hidden layer activations zi based on input weight vectors wii and bias parameters bii are

  zi=tanh⁡. 

putting the zi into a vector z, the output of the network, i.e. its prediction function based on weight vector wo and bias bo, is

  g=11+exp⁡. 

given a training set x <dig>  ..., xn and a network with weight and bias parameters collected in the vector θ, we now write the corresponding network output as f, ..., f. with diagonal matrix a containing the regularization parameters, the training objective is to minimize the regularized error:

  e=∑i=1n−yi)2+θtaθ. 

the diagonal matrix a = diag of the regularization term involves four hyperparameters α <dig>  α <dig>  α <dig>  α <dig> >  <dig> for separate scaling of the parameters wii, bii, wo, bo. note that the regularization term penalizes the squared magnitude of the weights. for the adaptation of hyperparameters, we utilize the evidence framework  <cit>  based on a gaussian approximation of the posterior distribution of network weights. the evidence-based adaptation of hyperparameters can be incorporated into the network training procedure and does not require additional validation data. for the minimization of  with respect to weight and bias parameters, we use a scaled conjugate gradient scheme, as implemented in the netlab toolbox  <cit> . while weight and bias parameters were initialized randomly according to a standard normal distribution, the hyperparameters were initially set to α <dig> = α <dig> = α <dig> = α <dig> =  <dig> . the complete training scheme performs  <dig> iterations where each iteration comprises  <dig> gradient steps and two successive hyperparameter adaptation steps.

final candidate selection
application of the neural network to a certain fragment results in a list of potential gene candidates with a predicted gene probability above  <dig> . most of these predictions are mutually exclusive in terms of overlap. many predictions even belong to the same orf-set, differing only in the position of the start codon. in order to obtain a list g of final genes for a particular fragment, predictions with maximal probability are iteratively selected from the list of candidates c, which is successively reduced according to a maximum overlap constraint. starting with an empty list g and an initial list c containing all fragment-specific orfs i with gene probability pi = f  >  <dig> , we apply the following »greedy« selection scheme:

while c is nonempty do

• determine imax⁡=arg⁡max⁡ipi with respect to all orfs i in c

• remove orf imax from c and add it to g

• remove all orfs from c that overlap with orf imax by more than omax bp

in our evaluation, we set omax to  <dig> bp, which corresponds to the minimal gene length we consider for prediction.

training data
our machine learning approach for gene prediction in metagenomic dna fragments is based on learning the characteristics of coding and non-coding regions from  <dig> fully sequenced prokaryotic genomes  and their genbank  <cit>  annotation for protein coding genes. the training genomes correspond to the ones that were used for building the statistical models of metagene except that we excluded pseudomonas aeruginosa from the training set because a subset of reliably annotated genes that is valuable for the determination of tis correctness is available for this species. all training and test data sets described in this article are based on the initial extraction of orfs with a minimal length of  <dig> bp. two types of orfs are distinguishable: complete orfs begin with a start codon , and are followed by a flexible number of subsequent codons and conclude with a stop codon . incomplete orfs stretch from one fragment end to a stop or start codon or to the other fragment end without being interrupted by another in-frame stop codon .

in the following paragraphs, we first describe the preparation of training data sets for feature preprocessing and for training of the neural network. subsequently, we specify the compilation of a test data set for performance evaluation.

training data for feature preprocessing
monocodon, dicodon and tis feature extraction from orfs require a preprocessing step that is based on the separate training procedure described in section «codon and dicodon usage». training examples for feature preprocessing were randomly sampled from complete genomes to a coverage of  <dig> %. two separate training sets were compiled. for the mono- and dicodon frequencies training set, dna sequences of genes defined by their exact start and stop codon position served as positive examples . the longest candidate out of each non-coding orf-set was selected for the composition of negative examples .

training of the tis discriminant was carried out on symmetric  <dig> bp sequence windows around start codons. the sequence windows of annotated start codons served as positive examples  while the windows around other possible start codons of the same orf-sets were used as negative examples .

the examples for both training data sets were randomly split into  <dig> % for discriminant training and  <dig> % for validation of the regularization parameter.

training data for the neural network
the neural network was trained with the extracted features from orfs in  <dig> bp fragments that were randomly excised to a 1-fold genome coverage from each training genome. we define an n-fold coverage as the amount of sampled dna that is in total length  n times longer than the original genome sequence. annotated genes in these fragments were used as positive examples for coding regions  while one candidate out of each non-coding orf-set was randomly selected for the negative examples . the data sets were randomly split into 50% for neural network training and  <dig> % for validation of the network size .

test data and experimental evaluation
the performance of our gene prediction algorithm was evaluated on artificial dna fragments from three archaeal and ten bacterial species  whose genera were not used for training. fragments of the lengths  <dig> to  <dig> bp  were randomly sampled from each genome to a 5-fold genome coverage for each length. we used the fragments of all lengths to investigate gene prediction performance of our method, which was trained on fragments with the length  <dig> bp.

a more detailed analysis was carried out on  <dig> bp fragments , including a comparison to metagene. in order to determine statistical significance, we used  <dig> replicates of each randomly sampled fragment stack.

gene prediction performance was evaluated by comparing predictions of our method to known annotated genes in fragments. the genbank annotation for protein coding genes was used to measure general gene prediction performance. however, the genbank gene start annotation has previously been suspected to be inaccurate  <cit> . therefore, we used »reliable gene annotation subsets«  <cit>  for the evaluation of translation initiation site  prediction performance: all genes with an experimentally verified tis from »ecogene« for escherichia coli  <cit> , experimentally verified genes of the bacillus subtilis genbank annotation  and the »pseudocap«  annotation of pseudomonas aeruginosa  <cit> .

measures of performance
the capability of detecting annotated genes  was measured as sensitivity:

  sens=tptp+fn 

for gene prediction sensitivity, tpgene  denotes correct matches and fngene  indicate overlooked genes. we counted all predictions as tpgene that match at least  <dig> bp in the same reading-frame to an annotated gene.

in one experiment, we compared gene predictions to a subset of genes that have a reliably annotated gene start in the fragment. for this subset, we measured tis prediction sensitivity. here, tptis are genes with correctly predicted tis and fntis are genes whose correct start codons were not predicted.

the reliability of gene predictions was measured by specificity:

  spec=tpgenetpgene+fpgene 

gene prediction specificity was calculated with predicted genes that do not correspond to any gene in the annotation as fpgene .

to provide a suitable composite measure of sensitivity and specificity we use the harmonic mean, which corresponds to a particular realization of the f-measure  <cit> :

  harmonicmean=2∗sens∗specsens+spec. 

to measure the discriminative power of the codon usage and tis discriminants for feature extraction , we use the area under precision recall curve . the precision recall curve shows for each possible score threshold the relation of sensitivity  and specificity . sensitivity and specificity are not sufficient for measuring tis prediction performance. when applied to tis prediction, these measures rather reflect general gene prediction performance than accuracy of tis prediction. 'tis correctness' was therefore measured by the percentage of correctly predicted tis within a subset of true positive gene predictions tpgene that have an annotated start codon within the fragment :

  tis correctness=tptistpgene∗. 

accuracy of complete/incomplete gene type prediction was calculated on the basis of correctly predicted genes with an existing true tis:

  genetypeaccuracy=tpcomplete+tncompletetpgene 

where tpcomplete and tncomplete account for the number of genes within tpgene that have correctly been predicted as complete and incomplete.

RESULTS
in the following sections, we first describe and discuss the results of discriminant and neural network validation which led to the choice of a hyperparameter λ and a suitable number of nodes for the neural net. subsequently, we show and discuss gene prediction performance results of the neural network on several fragment lengths and in  <dig> bp fragments.

discriminant validation
training of the linear discriminants for monocodon, dicodon and tis features requires the validation of the regularization parameter λ . for each of the three discriminants, we chose λ from the set of values {10m|m = - <dig>  - <dig>  ..., 6} by maximizing the area under precision recall curve  on separate validation data. while for the tis discriminant, a well-defined maximum was achieved for an intermediate λ = 10- <dig>  for the monocodon and dicodon case the maximum was achieved for the smallest value λ = 10- <dig>  however, as shown in additional file  <dig>  for small λ values the auprc performance in these cases reaches a plateau and therefore we did not try smaller values. the resulting discriminant weights for the  <dig> monocodons are shown in additional file  <dig>  the high negative weights for the three stop codons taa, tag, tga are due to the large fraction of negative examples. because negative examples are, by a factor  <dig>  more frequent than positive examples in the training set, a negative shift of the discriminant score is induced by codons that, like stop codons, are present in any example in any of the two classes.

network validation
in principle, the evidence-based hyperparameter adaptation  obviates the search for an adequate size of the network, i.e. to find a suitable number k of hidden nodes. the network size has just to be large enough to provide maximum performance, while larger nets would automatically be subject to stronger regularization in terms of larger regularization parameters. nevertheless, network size is crucial in terms of computational cost for training and testing.

in order to find a small network with sufficient performance, we started to train networks of increasing size. trying networks with k =  <dig>   <dig>  ...,  <dig> nodes, we found the performance to reach a nearly flat plateau within that k-range, with only very slight increase above k =  <dig> . performance was measured in terms of the harmonic mean criterion , computed on an independent validation set . for the final predictions on the test data, we used the largest network with k =  <dig> nodes.

while training of neural networks is a time consuming process, computing predictions with a trained network on new data is very fast. in our case, training a network with k =  <dig> hidden nodes from ≅  <dig>  ×  <dig> examples took about  <dig> cpu hours . the training scheme described above was applied in parallel to  <dig> networks with different  initialization of parameters to avoid weak local minima of the regularized error . according to the lowest error, the best resulting network was selected for the final predictions within the test setup. in contrast, testing of the same number of examples, i.e. prediction on more than three million candidates, only took ≅  <dig>  seconds on the same machine.

the parameters of the neural network with  <dig> nodes that we used for further evaluation are given in additional file  <dig> 

gene prediction performance in dna fragments
to evaluate the performance of our machine learning approach, we tested the method on artificially fragmented genomes. in the following section, we present the results in general gene prediction performance on various fragment lengths. subsequently, we analyze gene prediction performance, tis prediction correctness and complete/incomplete gene type prediction accuracy in detail for fragments of length  <dig> bp, which corresponds to the fragment length on which the neural network was trained.

performance in fragments of different lengths
the predictions of our method in dna fragments with lengths ranging from  <dig> to  <dig> bp from thirteen species were compared to the genbank  <cit>  annotation for protein coding genes. note that on average  <dig> % of  <dig> bp fragments do not contain any annotated gene matching the  <dig> bp minimal length criterion , for  <dig> bp fragments, this fraction of fragments accounts  <dig> %, for  <dig> bp fragments  <dig>  %. the average percentage of complete genes within all annotated genes in our test fragments is  <dig> % for  <dig> bp fragments,  <dig> % for  <dig> bp fragments and  <dig> % for  <dig> bp fragments . the mean of gene prediction sensitivity and specificity for all fragment lengths is shown in figure  <dig>  on  <dig> bp fragments, our method has an average gene prediction sensitivity of  <dig> % and an average specificity of  <dig> %. sensitivity and specificity slightly increase with growing fragment size. this can be explained by the fact that orfs carrying distinct mono-/dicodon and tis signals occur more often in longer fragments. gene prediction performance decreases with length and sharply drops for fragments shorter than  <dig> bp.

before application of our method on real metagenomes, the neural network should be trained and thoroughly evaluated on fragments of a length that corresponds to the real fragments of interest. metagenomic sequencing projects differ in their aims and in the applied sequencing and annotation strategies. improved sanger sequencing from one or both vector insert ends is applied in many metagenomic projects  and yields sequencing reads roughly ranging from  <dig> to  <dig> bp. based on the current results, our method might be particularly useful for improving gene annotation and discovery on sanger sequencing reads. however, pyrosequencing  <cit>  has also been introduced to metagenomics  <cit> . the pyrosequencing approach does not involve any cloning step. with recent improvements, pyrosequencing now yields a read length between  <dig> and  <dig> bp  <cit> . in principle, it should be possible to predict genes in such short fragments with our fragment-based techniques but environmental pyrosequencing projects may rather be focused on phylogenetic studies and habitat comparison than on the discovery of new genes. in some metagenomic sequencing projects, long metagenomic inserts  are fully sequenced  <cit> . although gene prediction performance of the neural network does not decrease on longer fragments , other methods like metagene  <cit>  or genemark.hmm  <cit> , which also consider the context of putative genes , may be more suitable for fragments of this size.

performance in  <dig> bp fragments
predicted genes in fragments with a length of  <dig> bp from three archaeal and ten bacterial species were compared to the genbank annotation for protein coding genes. the mean and standard deviation for sensitivity, specificity and the harmonic mean of  <dig> repetitions per species are shown in table  <dig>  the neural network has high sensitivity  and specificity  in fragments from all species. we could not observe a major performance difference for sensitivity and specificity between archaeal and bacterial fragments but the variation between different species in general is large.

in comparison to metagene, the neural network has a higher specificity in fragments from all test species . on the other hand, metagene has a higher sensitivity in fragments from most species . the neural network only shows a higher sensitivity in bacillus subtilis and helicobacter pylori. the overall performance of both methods calculated by harmonic mean is very similar. for some species, the neural network yields a better overall gene prediction performance while metagene performs better on other species. in particular, metagene performs better in all tested archaea. all local pairwise differences in sensitivity, specificity and harmonic mean between the neural network and metagene are significant to a confidence level of  <dig> % according to wilcoxon's signed rank test  <cit>  .

a precise tis prediction is very important in metagenomics since the aim of many environmental sequencing projects is the identification and subsequent experimental investigation of novel genes. for example, the expression of a metagenomic protein in a host organism may fail or yield incorrect results if the predicted start codon is incorrect. accurate tis prediction is a difficult task, even for conventional gene finders on complete genomes  <cit> . this is because atg, ctg, gtg and ttg also occur inside genes.

one gene may for example contain several atgs but only one corresponds to a tis. our approach includes a tis-model that is based on a linear discriminant. we measured tis prediction performance of our algorithm for all correctly predicted genes that have annotated start codons within a fragment. first, we investigated tis performance on our complete set of test species fragments according to genbank annotation. the results are shown in table  <dig>  tis correctness of our algorithm varies remarkably between different test species. on some bacterial species, our algorithm reaches a tis correctness of  <dig> % . the lowest tis performance can be observed in fragments from the bacterium chlorobium tepidum . the average tis correctness of our algorithm is around  <dig> %. in comparison to this, the highest performance of metagene can be observed for fragments of prochlorococcus marinus , the lowest for fragments of bacillus subtilis . note that tis correctness depends on the number of correctly predicted genes with an annotated tis. therefore, tis correctness of our algorithm is not directly comparable to the one obtained by metagene, which detects a higher number of genes. however, the variation in tis correctness of both methods is large.

a reason for this variation might be that the genbank gene annotation contains many hypothetical and not experimentally verified genes  <cit> . therefore, we also evaluated tis prediction performance on »reliable annotation subsets« of the bacteria escherichia coli, bacillus subtilis and pseudomonas aeruginosa . evaluating gene prediction performance in fragments according to these annotation subsets, our algorithm achieves a highly consistent tis prediction performance between  <dig> and  <dig> % in fragments from all three test species. the tis prediction sensitivity varies from  <dig> % to  <dig> % . in comparison, metagene's tis performance shows a higher variation, ranging from  <dig> to  <dig> % while the tis sensitivity ranges from  <dig> to  <dig> %.

the nature of fragmented dna results in the occurrence of complete and incomplete genes. a gene may be incorrectly predicted as complete or incomplete if it has several tis candidates of which at least one is located outside the fragment. due to the short fragment length of  <dig> bp, the vast majority of annotated genes  in our test fragments is incomplete. the experimental strategy of many metagenomic projects relies on sequencing the fragment from one or both ends of the vector insert. although the insert is not always sequenced completely, sequencing of the entire fragment is possible in case the biologist is interested in further analysis of an incomplete gene. therefore, it is important to know whether a gene is contained in a sequencing read completely or incompletely.

we evaluated the percentage of genes that were correctly classified as complete or incomplete within the correctly identified genes according to genbank annotation. our method achieves an average accuracy of  <dig> % with little variation . it can be noted that metagene slightly more often misclassifies genes concerning their completeness. note here that the performance indices of the neural network and metagene in table  <dig> are not directly comparable because they rely on different numbers of correctly identified genes.

remarks on the experimental setup
the evaluation of computational methods for metagenomic gene prediction is troubled by the fact that reliably annotated metagenomes are not available. some metagenomes have been subject to annotation for several years by now, but their gene annotation is far from complete. particularly, the exact location of gene starts on metagenomes has been verified experimentally only in rare cases. currently, the only way to reliably investigate gene prediction accuracy is the evaluation on dna fragments from complete microbial genomes. for the evaluation of our method, we used an experimental setup similar to the one proposed by the authors of metagene in order to keep both methods comparable. metagene relies on statistical models built from  <dig> bacterial and  <dig> archaeal genomes. these species were selected to represent every genus from genbank in the year  <dig>  by now, species belonging to many additional genera have been fully sequenced and annotated. members of these genera should be included in the training set of a future gene prediction tool version in order to collect as much information about the characteristics of coding and non-coding orfs as possible.

it remains an open question, which criteria are most suitable for the selection of training species. in general, taxonomy does not reflect phylogeny properly. some species of different genera for example exhibit highly similar codon usage patterns. particularly for the identification of novel genes in metagenomes whose biological diversity is yet unknown, the transfer of the genbank bias toward single species should be avoided in the training data set. to reduce this bias, training genomes could be selected according to other criteria, e.g. gc-content, oligonucleotide frequencies or monocodon/dicodon frequencies in protein coding regions.

the experimental setup chosen here also differs from real metagenomes with respect to sequencing errors. the effect of sequencing errors in terms of base-changes on gene prediction performance of our method would depend on the frequency of such kind of error. the effect of a usually small number of base-errors  can be neglected. as for other alignment-free methods, like metagene, our method is susceptible to frame shifts. only certain alignment-based methods can be expected to be more robust with regard to this kind of error  <cit> .

CONCLUSIONS
large scale machine learning is well suitable for gene prediction in metagenomic dna fragments. due to performance results obtained with the current experimental setup, we suggest that our machine learning approach, with its high gene prediction specificity, tis correctness and complete/incomplete prediction capabilities, complements metagene with its high gene finding sensitivity well. thus, a combination of both methods should be considered.

software availability
linear discriminants and the trained neural network are available as matlab files for download at  <cit> . a command line tool for gene prediction in dna fragments  is available from the authors on request.

availability and requirements
orphelia: 

authors' contributions
kjh developed and implemented the combination of orf extraction and machine learning modules, assembled training and test data sets and performed the evaluation of the new algorithm and metagene. mt developed and implemented orf-set identification and extraction. kjh and mt contributed biological expertise, t.l. implemented fast versions of the discriminant scoring. rd contributed biological expertise on metagenomics and drafted parts of the manuscript. pm contributed machine learning expertise and designed and implemented the machine learning architecture. bm and tl supported the project and contributed conceptually. kjh and pm wrote the manuscript. all authors read and approved the manuscript.

supplementary material
additional file 1
tables with training genomes, discriminant weights, and network parameters. the tables list all genomes that were used for training the neural network , present the discriminant weights that were learned for all monocodons , and give neural network parameters .

click here for file

 additional file 2
supplementary figures. the figures show the area under precision recall curve for discriminant validation using different λ values , the neural network performance with increasing numbers of nodes , the percentage of complete genes within all annotated genes per fragment for different fragment lengths , and gene prediction performance on fragments ranging from  <dig> to  <dig> bp .

click here for file

 acknowledgements
we thank dr. heiko liesegang for supporting the development of our method. we are grateful to andrew woehler for proofreading the final version of our manuscript. k.j.h was supported by a georg-christoph-lichtenberg stipend granted by the state of lower saxony. t.l. was supported by bmbf project medigrid .
