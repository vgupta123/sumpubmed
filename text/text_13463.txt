BACKGROUND
many researchers have embraced microarray technology. due to extensive usage of microarray technology, in recent years there has been an explosion in publicly available datasets. examples of such repositories include gene expression omnibus , arrayexpress http://www.ebi.ac.uk/microarray-as/ae/ and stanford microarray database  is used to identify differentially expressed  genes which extends the deds method  <cit> . this new method makes use of multiple statistical measure across datasets to obtain a de list, but becomes a novel tool, with respect to deds with the ability to integrate multiple datasets. hence this meta-method concatenates statistics from datasets in question and is able to establish a gene list. such integration should be resilient to a range of complexity levels inherent in meta-analysis situations. the strength of mdeds as a meta-method over deds as a method for selecting de genes is highlighted by comparing these two approaches to one another in a meta-analysis context. throughout this paper the statistics used within mdeds and deds are the t and modulated t statistic  <cit> , sam  <cit> , the b statistic  <cit>  and fold-change  statistic, although any statistic can be chosen.

we also perform a comparison study of meta-analysis methods including the fisher's inverse chi-square method  <cit> , genemeta  <cit> , probability of expression   <cit> , poe with integrative correlation   <cit> , rankprod  <cit>   and mdeds as well as two naive methods, 'dataset cross-validation' and a 'simple' meta-method. for meta-methods with several varying parameters, we have made use of the suggested or default options.

the performance of the different meta-analysis methods is assessed in two ways, through a simulation study and through two case studies. for the simulation study performance is measured through receiver operating characteristic  curves as well as the area under these roc curves . the two different case studies vary in complexity and performance are assessed through predication accuracy in a classification framework. warnat et al.  <cit>  uses validation to evaluate performance while using multiple datasets. our validation method differs from their process slightly. their method takes a random selection of samples from multiple datasets to obtain a test and training set. we retain to original datasets, leaving them complete. our method aims to simulate real situations where an additional dataset would need to be classified after a discriminate rule was developed. although within this paper mdeds is used in a binary setting, mdeds is a capable multi-class meta-analysis tool, which is a concept examined by lu et al.  <cit> .

it is possible to consider meta-analysis at two levels, 'relative' and 'absolute' meta-analysis. 'relative' meta-analysis looks at how genes or features correlate to a phenotype within a dataset  <cit> . multiple datasets are either aggregated or compared to obtain features which are commonly considered important. meta-methods pertaining to this method include fisher's inverse chi-square, genemeta, rankprod and the 'dataset cross-validation' meta. 'absolute' meta-analysis seeks to combine the raw or transformed data from multiple experiments. by increasing the number of samples used, the statistical power of a test is increased. traditional microarray analysis tools are then used on these larger datasets. the 'simple' meta method is an example of 'absolute' meta-analysis approach.

in this paper we will begin by describing existing meta-analysis methods, then we will outline our proposed mdeds method. this is followed by the comparison study, where publicly available datasets are combined by different meta-analysis methods, examining their ability under varying degrees of complexity, as well as comparing mdeds to deds. finally, we provide discussion and conclusions of results.

existing meta-analysis methods
let x represent an expression matrix, with i =  <dig>  ..., i genes and j =  <dig>  ..., n samples. if there are k =  <dig> ..., k datasets, nk represents the number of samples in the kth dataset. for simplicity, and without loss of generality, we focus on dichotomous response; i.e., two-group comparisons. we designate groups as treatment t and control c. for two-channel competitive hybridization experiments, we assume that the comparisons of log-ratios are all indirect; that is we have nt arrays in which samples from group t are hybridized against a reference sample r, and we can obtain nt log-ratios,  = log2; j =  <dig>  ..., nt from group t. in an identical manner nc log-ratios are also calculated from group c. for affymetrix oligonucleotide array experiments, we have nt chips with gene expression measures from group t and nc chips with gene expression measures from group c.

fisher's inverse chi-square
fisher, in the  <dig> s developed a meta-analysis method that combines the p-values from independent datasets. one of a plethora of methods for combining the p-values  <cit> , is the fisher summary statistic,   

which tests the null hypothesis that for gene i, there is no differences in expression means between the two groups. the p-value pik is the p-value for the ith gene from the kth dataset. in assessing si, the theoretical null distribution should be . it is also possible to extend the fisher methods by producing weights for different datasets based on, for example, quality.

genemeta
one of the first methods that integrates multiple gene expression datasets was propose by choi et al.  <cit>  who describe a t-statistics based approach for combining datasets with two groups. an implementation of this method is found in genemeta <cit>  an r package containing meta-analysis tools for microarray experiments.

choi et al.  <cit>  described a meta-analysis method to combine estimated effect-sizes from the k datasets. in a two group comparisons, a natural effect size is the t-statistics. for a typical gene i, the effect size for the kth dataset is defined as   

where  and  represent the means of the treatment and the control group respectively in the kth study. spk is the pooled standard deviation for the kth dataset.

for k number of observed effect sizes, choi et al.  <cit>  proposed a random effects model  

where μ is the parameter of interest, sk denotes the within study variances and δ ~ n represents the between study random effects with variance τ <dig>  choi et al.  <cit>  further mentioned that when τ <dig> =  <dig>  δk denotes the between study effect in a fixed effect model. the random effects model is then estimated using a method proposed by dersimonian and laird  <cit>  and a permutation test is used to assess the false discovery rate .

metaarray
the r package metaarray contains a number of meta-analysis methods. the main function is a two steps procedure which transformed the data into a probability of expression  matrix  <cit>  and followed by a gene selection method based on 'integrative correlation'   <cit> .

given a study, the poe method transforms the expression matrix x to a matrix e that represents the probability of differential expression. each element in the matrix eij is defined as the chance of multiple conditions present across n samples within gene i. the transformed matrix, e, consists of three values - <dig>   <dig>   <dig> that represent the conditions 'under-expressed', 'not differentially expressed' and 'over-expressed'. after the transformation into a poe matrix, genes of interest are established using ic  <cit> . notice that this integrative correlation method is not restricted to be used with a poe matrix. the method ic begins by calculating all possible pairwise pearson correlations  between genes  across all samples within a dataset k. thus, we generated a pairwise correlation matrix p with  rows representing the number of pairwise correlation and k columns representing the number of datasets.

for a selected pair of datasets k and k', let us denote  and  as means of the correlations per study. gene-specific reproducibility for gene i is obtained by only considering comparisons that contain the ith gene. that is   

where i ≠ i'. when more than two datasets are being compared, all integrative correlations for a particular gene are aggregated. this method provides a combined ranking for genes across k datasets.

in this comparison study, two metaarray results are used. distinction will be made between them using the terms 'poe with ic' and 'poe with bss/wss' to indicate what type of analysis was performed after the construction of the poe matrix.

rankprod
rankprod is a non-parametric meta-analysis method developed by breitling et al.  <cit> . fold change  is used as a selection method to compare and rank the genes within each dataset. these ranks are then aggregated to produce an overall score for the genes across datasets, obtaining a ranked gene list.

within a given dataset k, pairwise fc  is computed for each gene i as   

producing nt × nc pfcl,m values per gene with l =  <dig>  ..., nt and m =  <dig>  ..., nc. the corresponding pfc ratios are ranked and we may denote this value as pfc, where i =  <dig>  ..., i represents the number of genes and r =  <dig>  ..., r represents the number of pairwise comparisons between samples. then the rank products for each gene i is defined as   

expression values are independently permuted b times within each dataset relative to the genes, the above steps are repeated to produce  where b =  <dig>  ..., b. a reference distribution is obtained from all the  values, and the adjusted p-value for each of the i genes is obtained. gene considered significant are used in future analysis.

naive meta-methods
two forms of naive meta-methods are used in the comparison study. the 'simple' meta-method takes the microarray expression matrices and simply combines the datasets together, forming a final matrix made up of all samples with no expression adjustment. the 'dataset cross-validation' meta-method takes one datasets and applies the analysis, these results are then used by the other dataset with the expectation that the results will be transferable. in a classification context this means that one dataset is used for feature selection and development of the discriminant rule and we predict the outcome of the other dataset via this rule.

method
algorithm - mdeds
'meta differential expression via distance synthesis'  is a meta-analysis method that makes use of multiple statistical measures to obtain a de list. it is aided by 'differential expression via distance synthesis', deds  <cit>  which is designed to obtain de gene lists. example de measures include standard and modulated-t stat  <cit> , fold change, sam  <cit>  and the b-statistic, amongst many others. the concept behind the proposed meta-method considers that truly de genes should be selected regardless of the platform or statistic used to obtain a de list.

the true de genes should score highly within a set of non-dominated genes, both within a dataset using de measures and also between datasets when the same de measures are used on different datasets across different platforms. consistently high ranked genes are then considered de via mdeds. this method endeavours to be robust against both measure specific bias, when different measure produce significantly different ranked lists, and platform specific bias where particular platforms produce results that are more favourable to particular gene sets.

 <dig>  let there be k =  <dig>  ..., k datasets and g =  <dig>  ..., g appropriate  statistics, hence there will be k × g statistics for each of the i =  <dig>  ..., n genes. let tikg be the statistic for the ith gene, from the kth dataset for the gth de measure. assuming large values indicate increased de genes, let the observed coordinate-wise extreme point be   

 <dig>  locate the overall  extreme point e:

 each of the k datasets is permuted b times by randomly assigning nt arrays to class 't' and nc arrays to class 'c', producing b =  <dig> ... b sets of k datasets. for each permuted datasets the g number of de statistics are recalculated yielding . obtain the corresponding coordinate-wise maximum:   

 obtain the coordinate-wise permutation extreme point ep by maximizing over the b permutations,   

 obtain e as the overall maximum: e = max.

 <dig>  calculate a distance d from each gene to e. for example, one choice for a scaled distance is   

where mad is the median absolute deviation from the median. order the distances, d ≤ d ≤ ... ≤ d.

batch correction can be performed by mdeds, by substituting datasets with 'batch groups' .

comparison study
eight meta-analysis methods are compared using a simulated dataset and two cases studies comprising of six publicly available datasets, pertaining to three breast cancer and three lymphoma datasets. the purpose of the comparison study is to establish how these meta-analysis methods perform under varying degrees of dataset complexity. dataset complexity refers to the level of difficulty present when combining multiple datasets. for example datasets being produced on the similar platforms  are less complex to analyse via meta-analysis then when analysing results across very different platforms. for this comparison paper two levels of dataset complexity are considered. case study  <dig>  implemented by the breast cancer data contains datasets from identical affymetrix chips, this is considered 'similar platform meta-analysis'. case study  <dig> which makes use of the lymphoma datasets contains samples that are hybridised using long oligo two colour platforms, affymetrix chips and the 'lymphochip'  <cit> , this is considered 'disparate platform meta-analysis'.

for the publicly available data, probe sets for each platform are mapped to the relative 'entrez ids'  <cit> . where multiple probes pertained to the same gene the mean gene expression level is used. probes with unknown 'entrez ids' are discarded. only the intersection of platform gene lists are used in further analysis. data is imputed using knn imputation with k =  <dig>  data analysis performed using r.

performance assessment
assessing the performance of different meta-analysis methods is important to evaluate and compare methods. although important, performance assessment of meta-analysis methods is non-trivial. typically meta-analysis methods will be evaluated using pre-published gene lists and noticing the concordance of the obtained de gene list and published material, this process however is subject to publication bias. to avoid such biases two forms of performance assessment will be applied in this paper.

 <dig>  receiver operating characteristic curves : for the simulated data where the 'true' de gene list is known, meta-analysis performance is measured via roc curves. roc curves are created by plotting the true positive rates verses the false positive rates for the obtained de genes. performance is indicated by how close the plots are to the upper left hand corner of the roc space. the auc is also used as a comparison tool, with auc values close to one indicating an accurate de list. because of the design of the simulation study the 'cross-validation' meta-analysis method can not be used.

 <dig>  prediction accuracy: for the case studies, prediction accuracy under a classification framework is used to asses performance of the de list. we will use the term de list for the consistency of this manuscript, although strictly speaking in a classification framework such gene lists are known as feature gene lists. to classify within the case studies, each consisting of three independent datasets, two datasets are combined via the meta-analysis methods and de genes are selected. when de gene selection is not part of the meta-analysis approach de genes are ranked via 'between sum of squares over within sum of squares' bss/wss  <cit> . using these two datasets, a discriminant rule is constructed by diagonal linear discriminant analysis   <cit> . the third independent dataset is classified using this rule. the ability for the meta-analysis method to collaborate information from the two distinct datasets is reffected in the ability to classify the third. prediction accuracy is used because the 'true' de list is not known. in these case studies, performance can only be judged relative to the other compared methods.

simulation study
to evaluate the performance of the different meta-analysis methods, data was simulated to represent three separate gene expression datasets. the simulation approach is adapted from an approach presented by ritchie et al.  <cit> . a non-parametric bootstrap simulation is used where a matrix of non-differentially expressed gene expression data is sampled from three different datasets. this 'background' noise contains the latent characteristics of an actual microarray data yet contains no biologically de genes. samples are constructed with replacement from the original data, such that an even binary class distribution is established.

de genes are simulated via a  <dig> fold increase in fold change. two types of de genes are simulated, 'true' de genes, and 'platform specific' de genes. 'true' de genes are identical genes within each dataset, representing biologically relevant de genes. 'platform specific' de genes simulate platform bias apparent within de genes from microarray experiments  <cit>  and are randomly selected from the genes in the datasets, with the exclusion of the 'true' de genes. this simulation taps into the important notion that a powerful meta-analysis tool will have the ability to correctly distinguish a true de gene which is de across multiple platforms from a de gene which is simply a platform phenomena.

case study  <dig> - breast cancer: similar platform meta-analysis
three publicly available affymetrix datasets are used for the breast cancer study, all three datasets use the affymetrix platform u133a. classification of the breast cancer samples aims to distinguish between the sample's estrogen receptor  status  as determined by the sample information provided with the datasets, we refer readers to the original manuscripts for more details regarding this status. in this case er status is being used simply as a response variable common throughout all considered datasets, it should be understood that predicting er status using gene expression data is not the same as immunohistochemistry. these datasets include the farmer et al. dataset  <cit>   which utilises the affymetrix u133a platform with  <dig> samples, comprising of  <dig> +ve and  <dig> -ve samples. the loi et al. dataset  <cit>  contains affymetrix samples from three platforms, u <dig>  and u133plus some of which underwent treatment and some which did not. samples from platform u133a which did not experience any treatment are used in this study, which totalled  <dig> with  <dig> +ve and  <dig> -ve samples . ivshina et al.  <cit> , developed breast cancer samples on affymentrix u133a arrays,  <dig> in total corresponding to  <dig> +ve and  <dig> -ve samples . the performance of the meta-analysis methods employed in a 'similar platform meta-analysis' context was assessed via classification. the farmer et al. and ivshina et al. datasets were combined via meta-analysis and used to obtain a de gene list and construct a classification model. the loi et al. dataset was classified using this gene list and discriminant rule.

case study  <dig> - lymphoma: disparate platform meta-analysis
an original lymphoma dataset was obtained from the department of haematology and stem cell transplant at st vincent's hospital sydney . gene expression levels have been gathered from  <dig> patients presenting with lymphoma cancers,  <dig> of these samples are follicular lymphoma  and  <dig> samples are diffuse large b-cell lymphoma . human  <dig> oligo array slides from the adelaide microarray consortium were used to obtain microarray expressions. two well known publicly available datasets were also analysed. the shipp et al. data  <cit>  contains  <dig> fl and  <dig> dlbcl samples, hybridised using the affymetrix platform hu <dig>  alizadeh et al.  <cit>  also contains  <dig> fl samples and  <dig> dlbcl samples, hybridized to the 'lymphochip' which is a custom designed cdna microarray. the performance of the meta-analysis methods employed in a 'disparate platform meta-analysis' context was also assessed via classification. the shipp et al. and alizadeh et al. datasets were combined via meta-analysis and used to obtain a de gene list as well as construct a classification model. the svh dataset was classified using this gene list and classification rule.

case study  <dig> - mdeds versus deds
to establish the success of mdeds as a meta-analysis method beyond the capabilities of deds, deds and mdeds are compared. the strength of deds comes from its ability to synthesise results from a range of statistics, mdeds goes beyond this to consider results from a range of statistics across multiple datasets. deds is a method for selecting de genes and to this end was used in the simple meta-method described in the 'existing meta-analysis methods' section. datasets from both the breast cancer study and the lymphoma study were used in the comparison of these meta-methods with the loi et al. and the svh datasets used as the independent test sets.

RESULTS
simulation
three datasets were simulated, with  <dig>   <dig> and  <dig> samples, each with  <dig> genes. the percentage of de genes varied between  <dig> %, 4% and 10%, with half the de genes on each platform being 'true' and the other being 'platform specific' de genes. figure  <dig> shows the roc curves for 5% true and 5% platform specific de genes. these results are indicative of all considered de percentages. table  <dig> contains the auc values for the three different de gene percentage levels for the different meta-analysis methods. genemeta, rankprod, poe with bss/wss and poe with ic appear to struggle with obtaining an accurate 'true' de list. fisher and mdeds perform competitively with the difference between fisher, simple and mdeds reducing as the number of genes in the gene list increases.

the auc values for the simulated datasets, for each meta-analysis method. de genes are simulated at  <dig> %, 4% and 10% levels, with half the genes being 'true' de genes and the other half being 'platform specific' de genes

case study  <dig> - breast cancer: similar platform meta-analysis
mean of error rates in the binary classification of three breast cancer datasets using dlda

case study  <dig> - lymphoma: disparate platform meta-analysis
mean of error rates in the binary classification of three lymphoma datasets using dlda.

case study  <dig> - mdeds versus deds
mean of error rates when comparing mdeds to the simple meta-methods when deds is used as a feature selection method. performance is assessed in the binary classification of the breast cancer and lymphoma datasets using dlda.

discussion
the simulation study coupled with the two cases studies of varying meta-analysis complexity offers insight into the eight meta-analysis methods compared in this paper. it is important to validate meta-analysis methods, although at times this is difficult to perform. some meta-methods are simple variants of common classical statistical methods, others offer more sophisticated responses to specific issues faced in the microarray environment. a large proportion of meta-research deals with de genes and the process of obtaining a de list from multiple datasets. unfortunately de gene lists are illusive because the biological de gene lists are not known. often for validation purposes de lists are compared to other published de lists with the level of congruency indicative of the success of the meta-method. this method suffers from publication bias  <cit>  as one is continuously publishing pre-published information, with little validation to the variations that are occuring. an alternative assessment criteria utilizing the classification framework offers an intuitive validation process with interpretable results. classification performance relies heavily on the accuracy of the classifier's feature list, which is traditionally taken from the de list. within this meta-analysis study independent dataset validation classification was performed, using dlda. dlda was chosen as dudoit et al.  <cit>  found that dlda was an effective, efficient and accurate classifier for microarray data. this study could have been conducted using any number of classifier s provided feature selection is not performed implicitly by the classifier. the varying de list obtained from the meta-methods are the only varying component in the comparison. therefore a reduction in classification error can be attributed to the meta-method.

meta-analysis offers a way to enhance the robustness of microarray technology. the 'dataset cross-validation' meta-analysis approach observed within this study encapsulates a very real problem with microarrays; gene lists selected from one platform or study have a limited ability to be transfered. this is highlighted by their inability to be used to classify samples generated by another platform or study, as demonstrated by the  <dig> % error rate obtained via this method . for both the breast cancer and lymphoma case studies some meta-analysis approaches were able to increase the accuracy of cross platform classification, at times the error reduced by as much as 33% which can be seen in table  <dig>  this indicates that the added power through meta-analysis produces more robust and reliable results, eventuating in a gene list that is not platform dependent but truly indicative of the disease.

cross platform meta-analysis multiplies the level of complexity in this particular analysis paradigm. the meta-analysis complexity is suggestive of the meta-method one should employ. within this study we have used two levels of meta-analysis complexity,  when meta-analysis is performed across similar platforms, for example affymetrix with affymetrix,  when meta-analysis is performed across disparate platforms, for example affymetrix with oligo arrays.

the breast cancer case study uses datasets from three identical affymentrix platforms. affymetrix's development and processing protocols offer a reduced variability in array comparison  <cit> . this feature of affymetrix arrays is highlighted with the success of the cross-validation meta-analysis method, producing a relatively low mean error rate within the breast cancer study. in this case poe with both bss/wss and ic, fisher's inverse chi-square and rankprod were able to classify competitively, hence they are able to highlight between dataset de genes. rankprod's success in this circumstance is similar to the findings by hong et al.  <cit>  where rankprod is shown to be powerful in both simulated and affymetrix based meta-analysis studies.

the lymphoma case study aims to distinguish between fl and dlbcl subtypes and the datasets used makes this analysis more complex. both cdna and oligonucleotide arrays are compared. these platforms vary remarkably with differences ranging from probe length to the presence of reference samples. as the complexity of the meta-analysis rises poe with bss/wss, genemeta and rankprod struggle to obtain a gene list robust enough for cross platform classification. two different reasons could attribute to the depletion in accuracy of the meta-methods as the level of complexity increases. the meta methods could be over-fitting the data, methods that model the data are particularly susceptible to this, for example genemeta. conversely, some feature selection methods may not capture the complexity of the data, this is potentially occuring in the poe with bss/wss case. fisher's inverse chi-square meta approach does not take into consideration the actual intensities of each spot on the microarray, albeit at times this method is ideal, for example when individual intensities are unknown, or when the characteristics of the study vary greatly  <cit> . this particular characteristic of fisher's inverse chi-square method is highlighted by the more complex lymphoma case study producing lower relative classification errors than when used in similar platform breast cancer analysis.

within both complexity environments mdeds is able to perform de analysis well, as this method makes use of the different datasets but does not try to fit a full parametric model to the data. our proposed mdeds uses multiple statistical measures while developing its ordered gene list. using multiple measures aids robustness as more of the variability can be encapsulated within the meta-method. the success of mdeds over deds as a meta-method highlights that the method of combining different statistics across datasets aids in the meta-analysis process. it is possible that the multiple platforms and multiple measures draw enough diversity to begin to transcend cross platform variability and produce a reliable gene list. the variation in some of the meta-method's abilities within classification suggests that different tools are beneficial depending on the researcher's current meta-analysis project.

one may speculate that mdeds can be used in a batch correction context. batch effect is a term given to non-biological experimental variation that occurs throughout an experiment. in most cases batch effects are inevitable as non-biological variations are observed simply through multiple, apparently identical, amplification and hybridisation. staggering ones hybridisation process is a practical reality of microarray experiments for two main reasons:  data is often prospective and may be collected and processed in stages,  there is a limit to the number of samples that may be amplified and hybridised at one time  <cit>  hence forcing batches to form. as a result, powerful batch correction methods are vital for microarray research. one could consider batches obtained separately with time delays, for example a year, as separate batches, which resemble individual datasets on similar platforms. by using mdeds one can borrow strength from the multiple batches yet avoid particular batch bias.

there are still many open questions within the meta-analysis paradigm. for example questions pertaining to mismatched probe sets across platforms and the handling of multiple probes for the same genes. more research within these areas would greatly aid meta-analysis for microarrays and ones ability to make use of the current plethora of information laying dormant in these public repositories. however, once more of these type of tools for meta-analysis have been developed, meta-analysis will save time, money and scientific resources.

CONCLUSIONS
we compared eight meta-analysis methods, which comprise of five existing methods, two naive approaches and our novel approach, mdeds. integrating datasets within microarray analysis has copious and clear advantages. this study adds in establishing which meta-analysis methods are more successful in their approach by comparing multiple meta-analysis methods, including the fisher's inverse chi-square, genemeta, poe with bss/wss, poe with ic, rankprod, a 'dataset cross-validation' meta and a 'simple' meta.

our proposed method; mdeds, has performed competitively and at times better than currently available meta-analysis methods. roc curves were used as a comparison in a simulated study and prediction accuracy within classification was used as an evaluation tool in two real biological case studies. these case studies differ in complexity regarding data being combined, the first demonstrating the combining of three datasets from similar platforms  and the second combining datasets from affymetrix, cdna and the lymphochip.

in both classification comparisons mdeds was used as a feature selection method and produced capable classifiers, with all else held constant. these results, coupled with results from the simulated data, are indicative of mdeds being used as a powerful meta-analysis method for cross laboratory and platform studies.

availability and requirements
the r code for mdeds is an additional feature within the deds package available at http://bioconductor.org.

authors' contributions
ac performed the analysis and wrote the manuscript. yhy conceived the study, supervised the analysis and participated in the preparation of the manuscript. both authors read and approved the final manuscript.

