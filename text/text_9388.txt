BACKGROUND
the increasing availability of next-generation sequencing  platforms has allowed for ngs technology to play a critical role in molecular biosurveillance and outbreak management . ngs techniques can give an unparalleled depth and range of detection in samples containing unknown pathogens. however, using ngs platforms for these applications requires not only sequencers and personnel to generate high quality and reliable sequencing data, but also the means to organize and interpret the large data sets generated. analysis typically requires significant investment in computer hardware, analytical software, and technical support. the website pathosphere  was created to provide both the hardware and software capabilities necessary to detect pathogens in ngs data . by creating a web-based capability, analysis and computational resources can be shared widely with direct engagement of the crowd-sourced biosurveillance community.fig.  <dig> pathosphere user interface. the web-based portion of pathosphere contains message boards, forums, user communities to share data and results, a live-chat messager, user and developer guides and faqs, as well a custom interfaces for the pathogen detection pipelines utilized by the current pathosphere users. this screenshot displays the user-defined parameters that are customizable for each pathogen detection run



next - generation sequencing technology has the potential to give an unbiased, in-depth snapshot of what exists in a sample. currently, the analysis of the data generated from ngs platforms can be a limiting factor for pathogen detection. identifying the pathogen sequences represented within large data sets is difficult both from the perspective of the hardware and software requirements. the rise of open source software and cloud computing has supported the proliferation of capabilities developed for ngs data analysis. recently developed computational analyses  can detect pathogens from samples derived in silico as well as from samples with potentially complex backgrounds. however, there is a need for local hardware support to run these analyses or the cloud-based availability for the hosting of software.

pathosphere is a free service designed to provide the larger bioinformatics community a means to source their software. current analytical capabilities include background taxonomic analysis of read files, sequence assembly, pathogen identification using databases such as ncbi, and reports that are easy to interpret. to facilitate pathogen detection by laboratories or entities that do not possess the hardware components or technical staff necessary for the process-heavy data analysis from ngs sequencing platforms, the pathosphere interface allows researchers to perform sequence data analysis globally by uploading data to a hosted cloud portal  <cit> . pathosphere also supports analytical automation, which allows for non-heavy users to upload data and then receive generated reports upon the completion of a chosen pathogen identification pipeline. while these pipelines are automated, the values used for pre-processing and analysis can be adjusted from the recommended defaults, adding another layer of flexibility for certain targeted applications that might be desired for genomic data analysis. analytical tools can be added by the community, and the plug-in compatibility of the pathosphere architecture allows for the addition of new open-source software to be integrated seamlessly over time. this design will ensure that pathosphere evolves as newer and improved analytical software and methods are developed. pathosphere is designed to allow for collaboration within groups, but also securely stores the communications and data that are uploaded for sharing and analysis. to date, pathosphere has  <dig> separate user accounts, with  <dig> users posting  <dig>  comments in  <dig> communities. pathosphere has been visited over  <dig>  times since its inception.

in this study, roche  <dig> pyrosequencing, ion torrent, and illumina data were generated from varying sample types as a test of pathosphere architecture and function. the capabilities of the pathosphere pipelines to analyze  <dig>  ion torrent, and illumina data generated from an identical sample were compared, and then the pathosphere analytical pipelines were tested for their ability to identify pathogens in diverse sample types in which no pathogen was detected using traditional methods. finally, the flexibility of pathosphere was demonstrated by integrating another analysis pipeline to do follow-on analysis of pathogenic samples not recognized initially. the evaluation of the pathogen identification and analysis pipelines provided by pathosphere will serve to introduce the capabilities of pathosphere while also highlighting gaps which the emerging infectious disease community can address in the future.

methods
pathogen isolate sample preparation
isolates sample preparation
samples  <dig> and  <dig> containing lujo virus were prepared from human isolates  <cit> . rna was extracted from the cerebrospinal fluid and serum of a liver transplant recipient. after digestion with dnase i to eliminate human chromosomal dna, rna preparations were amplified by means of reverse-transcriptase pcr  with the use of random primers  <cit> . amplification products were pooled and sequenced with the use of the  <dig> genome sequencer flx platform , but dna fragmentation was omitted. the zaria bat coronavirus samples  <dig> and  <dig>  were obtained from the gi tract of bats that tested positive  for coronavirus by pcr  <cit> . sample  <dig> containing gbv-d was obtained from bat serum  <cit>  and prepared as detailed previously. the isolated rna for both coronavirus and gbv-d samples was converted to cdna and the library was prepared similarly to the lujo virus isolates detailed above. the bat parvovirus sample,  <dig>  was obtained from the spleen of parvovirus pcr-positive bats , and dna was isolated and the prepared libraries were sequenced on the  <dig> flx . samples containing mers-cov   <cit>  were prepared as previously described  <cit> . viral cdna was made using random primer rt-pcr from nasal swabs of camels. further pcr amplifications were made using overlapping pcr primers spanning  <dig> – <dig>  kb fragments of mers-cov  <cit> . these amplification products were pooled and sequenced on the ion torrent pgm platform. the human serum spiked samples containing y. pestis, f. tularensis, and b. anthracis, ​b. mallei, and b. psuedomallei were prepared for sequencing as described previously  <cit>  and sequenced on  <dig> flx , ion torrent pgm , and illumina miseq platforms . sra information for each sample analyzed here are available through the nbci bioproject # prjna <dig> 

implementation
ecbc pipeline
the pipeline described below was designed to integrate a wide range of analytical tools into a single automated process fig.  <dig> summary of the analytical capability of the bioinformatics pipeline. data can currently be preprocessed by two tools, columbia university’s preprocessing procedure  or a taxonomy analysis based on ncbi taxonomy results. then, reads retained after the pre-processing manipulations are assembled de novo. nearest neighbors and snp profiling then occurs by comparing the identified contigs to ncbi databases. a reference map is created, and the snp profile from those mapping results provides a comprehensive comparison of the taxonomical near neighbors. finally, all the unmapped reads are extracted and used as input to the next iteration

.

ngs data is first run through quality control trimming using standard metrics as the default but allowing for user trimming flexibility. two preprocessing tools are currently available; columbia university’s preprocessing procedure  and a taxonomic analysis based on ncbi taxonomy results. cupp was developed to reduce the complexity and total size of a ngs dataset. in this procedure, all the reads in the sample are compared using bowtie <dig>  <cit>  to map reads against the cupp database and then remove host reads from the analysis. the host databases for cupp include anopheles gambiae , danio rerio , gallus gallus , homo sapiens rrna , homo sapiens chromosome , mus_musculus , sus scrofa , mitochondrion genome, and xenopus laevis  . the taxonomy analysis provides a lowest common ancestor for each read, thus providing a general description of bacterial, viral, and eukaryotic constituents in the sample. these procedures, cupp and taxonomy analysis, can be used individually or serially as part of an analysis request . these tools, and the code used to implement them into the analytical pipeline, are available as open-source software at .

the iterative analysis is designed to identify pathogens without assumptions about the sample identity or complexity. to fulfill this goal, a process has been constructed to perform a subtractive approach in searching for possible multiple pathogens or multiple chromosomal elements in a single sample. first, the genomic data uploaded to the system, or reads retained after the pre-processing manipulations, are processed through a de novo assembly. in the case of  <dig> data, the reads are assembled using the gs newbler  program  <cit> . for illumina data, the reads are assembled with velvet  <cit> . the de novo assembly produces longer contiguous lengths  of genomic sequences. a database search step then compares the contigs with genome sequences in the ncbi nt database to identify high quality matches. each query  results in a series of hits which are ranked by blast bit score. the resultant top hit per query is cumulatively ranked using bit score compared to the other top hits. the topmost ranked ncbi database genome sequence in the cumulative ranked list is selected as the nearest neighbor  sequence for the iteration.

in the next step, the taxonomical neighbors of this nn in the ncbi nucleotide database are collected according to the following procedure: if nn is ranked as subspecies, or its direct taxonomical parent is ranked as subspecies, all the database records belonging to the same ncbi taxonomic subspecies sub-tree are collected; if the total count of the collected records is less than  <dig> , then the species sub-tree the nn belongs to is searched and the additional database records that belong to this sub-tree  are collected. after the nn's neighbor genomes are collected, all the input reads for this iteration are mapped to each of those genome sequences by reference mapping.

in the final step of the first iteration, all the input reads used for de novo assembly are reference mapped to the nn reference, and the unmapped reads are extracted and used as input to the next iteration. for  <dig> data, the reads are referenced mapped using the gs newbler  program  <cit> . for illumina data, the reads are reference mapped with the bowtie <dig> program  <cit> . in the next iteration, the steps described above are repeated. the iterative analysis allows multiple chromosomes, plasmids, or inserted genomic elements to be identified and reported to the user for directed, manual analysis.

usamriid-wrair pipeline
the usamriid-wrair pipeline was designed to be modular and thus give it flexibility to integrate new software as it becomes available, replacing older versions for reasons such as speed and sensitivity. acceptable input formats include sff, fastq single or paired-end, and compressed gzipped files. step <dig> first decompresses the file and/or converts the file into fastq format if an sff file is the starting input. the converted fastq or paired-end fastqs are processed for host removal using bowtie <dig>  <cit> . the first iteration uses the host genome of choice for read removal followed by the host transcriptome. once host reads are removed, adaptors are trimmed and reads go through quality filtering using cutadapt  <cit>  and prinseq-lite  <cit> . reads are assembled into contigs using the de novo assembler ray meta  <cit> , followed by a contig assembly using cap <dig>  <cit>  to ensure the longest possible contigs.

identification of contigs and single reads  is achieved through an iterative blast search using the ncbi nt database. iterative blast  <dig> uses the contigs as the query and starts with a megablast followed by a discontiguous megablast. only the contigs that do not get identified in the megablast go on to the dc-megablast. iterative blast  <dig> is essentially the same except that the singletons are used as the input. these blast searching schemes ensure that highly homologous sequences  are matched appropriately, and that less homologous sequences  are identified within the dataset. the outputs are divided into contig and read reports. the output reports resemble a top blast output with the addition of reads that aligned to each contig. taxonomy is assigned using names and nodes files from ncbi.

architecture and web implementation
pathosphere is a practical implementation and reference design for scalable, secure web services for genomics processing. there are two main parts of the pathosphere system. the first is a cloud-based web interface provided by custom applets running inside of liferay . the second part of the system consists of any number of backend processing computers or clusters. this architecture separates the web interface, user collaboration tools, and result display mechanisms from the systems that actually process the data through pipelines. in this way, the pipeline design, construction, execution, along with any hardware configuration, is completely independent from the server providing the user interface. this allows for unlimited flexibility in the types of pipelines being integrated into the pathosphere system.

the cloud-based front end web server has relatively low system requirements, since this portion of the system only stores data and results, allows submission of jobs, and provides collaboration tools. this design keeps the computationally intensive processing tasks off of this server. currently, as jobs are submitted, they are processed serially, although a more sophisticated job management system could be implemented. the current pathosphere front end server resides on a single, mid-level server, but this portion of the system could be easily scaled up on more powerful servers if the user load were to increase in the future.

like the front end web server, the backend servers in the pathosphere architecture can also exist anywhere in the world with a network connection. these backend servers can range from single machines to large computational clusters, depending on the types of algorithms being processed. the pipelines described in this paper are set up to run on a computing cluster consisting of  <dig> blade servers, several supporting servers, and over 40 tb of shared storage. similar to the front end, the backend processing needs are built to be expandable to cloud based services  <cit>  when user load increases.

security features
communication between the client and web server is via https, using tls v <dig>  or higher. the public key infrastructure  certificate is a startcom signed rsa  <dig> bit key. this ensures secure communication between the client and the webserver. individual users are authenticated using usernames and passwords. the only information stored about a run is its sample name and title. the user should not enter identifiable patient information in these fields, as the system is not intented to store confidential patient data. only the data uploaded by a specific user is visible to that user, unless it is explicitly shared with another user. in order to join a community, a user must have permission from the group owner. the web server, mail server, and cluster all have network access restricted by external firewalls that limit access to only the expected network communication. the only access to the backend computing cluster is via a secure shell  connection, with a pki key, ensuring that the data remains secure in transit. data is not encrypted while stored on the computing cluster, but the cluster is located in a secure location on a military installation.

RESULTS
direct comparison of pathogen detection in  <dig>  ion torrent, and illumina sequenced samples using ecbc pipelines
to evaluate the pathogen identification capabilities of the ecbc pipeline with multiple types of sequencing data, a side-by-side comparison of three sequencing platforms was performed. a spiked human serum sample with y. pestis, b. anthracis, f. tularensis, b. mallei, and b. psuedomallei was sequenced and subsequently analyzed using the ecbc pipeline on pathosphere. when sequencing for pathogen identification, large amounts of background genomic material can complicate the analysis. to mitigate this, two preprocessing methods are available and used regularly as part of the analytical pipeline used for samples within complex backgrounds. cupp systematically removes host background reads from common organisms. human backgrounds are represented in this procedure, so cupp is used as a preprocessing method for all samples evaluated in this section. taxonomic analysis provides an indication of pathogens and near neighbors represented at lower concentrations: too low to produce an assembly. the source code for both preprocessing tools is open-source available on sourceforge .

to directly compare the performance of the ecbc pipeline on three different sequencing platforms, a complex sample containing human serum spiked with y. pestis , b. anthracis , f. tularensis , b. mallei , and b. pseudomallei  was processed, sequenced on roche  <dig>  ion torrent, and illumina miseq platforms, and then analyzed using the iterative analysis pipeline . these data sets are also available on the pathosphere homepage. the  <dig> and ion torrent files were similar in size, with the  <dig> raw data at  <dig> gb and the ion torrent data at  <dig> gb . the illumina data set was larger with 5gb in uncompressed paired-end read files. both the  <dig> and ion torrent datasets ran through the complete pipeline at about the same rate, with the  <dig> data slightly slower at 35 minutes compared to the 28 min of the ion torrent data. the large size of the illumina data set correlated with a longer analysis time, of 4 h and 11mins.table  <dig> ecbc pipeline analysis on non-host reads of samples containing b. anthracis, f. tularensis, y. pestis, b. pseudomallei, and b. mallei. unknown samples were created, sequenced on  <dig>  ion torrent, and illumina platforms and processed . datasets were then analyzed using the ecbc pathogen detection pipeline. table shading represents the positive and correct identification of the organism listed. unshaded cells represent the lack of single-read identification matching to the pathogens spiked


b. anthracis







f. tularensis







y. pestis







b. pseudomallei



b. mallei



the taxonomy assignments and iterative assemblies identified pathogens within the samples sequenced by all three platforms with similar efficiency . taxonomy assignments identified b. anthracis, f. tularensis, y. pestis, and b. pseudomallei in the  <dig> dataset, only b. anthracis, f. tularensis, y. pestis in the ion torrent dataset, while all five pathogens were detected in the illumina dataset . genomic elements  of y. pestis were detected in the early iterations of the  <dig> data while the genome sequence of b. anthracis and f. tularensis were detected in the later iterations . a similar trend was observed with the ion torrent data, as the y. pestis plasmid a <dig> was detected in the first iteration, followed by the genomic sequences of y. pestis, f. tularensis, and b. anthracis, respectively . the illumina dataset resulted in the detection of y. pestis genome and plasmids for the first six iterations, followed by a genome f. tularencis assembly and two  b. anthracis assemblies . many of the reads sequenced by  <dig>  ion torrent, and illumina were able to be assembled into large contigs that mapped accurately and provided sufficient coverage to identify the pathogens within the sample .

analytical pipeline identification of unknowns in complex samples using ecbc pipelines
the ecbc analytical pipelines on pathosphere identified pathogens  within a spiked sample background, so pathosphere was next evaluated using real-world samples containing pathogens. variability in sample quality and pathogen levels can be complicating factors when attempting to detect pathogens within complex backgrounds using traditional methods as well as ngs technology . in the following examples, human or animal material  containing pathogens difficult to detect using standard molecular techniques was prepared and sequenced . the presence of pathogens in each sample used here was confirmed in other studies  to validate correct pathogen identification during analysis on pathosphere. these raw datasets are freely available to all pathosphere members within a special tab located on the pathosphere homepage , along with all the detailed documentation.table  <dig> viral samples and non-host reads. samples collected from various sources were sequenced for pathogen detection. cupp removed host reads, leaving non-host reads for further iterative and taxonomic analysis. samples obtained had already been confirmed to contain or not contain indicated virus 




this pipeline detected the correct viral pathogens in all but one of the data sets, as shown in table  <dig>  samples will be evaluated in this section in the following order:  true negative  pathogens detected through iterative assembly  pathogens detected through taxonomic analysis and  samples that demonstrate gaps in ecbc analytical pipelines on pathosphere.

true negative
sample  <dig> was selected as the negative control. following cupp, the de novo assembler failed to construct contigs from the pre-processed reads. to ensure that pathogens were not missed because assembly was unsuccessful, a taxonomy analysis was selected. following the taxonomic analysis, assembly was still unsuccessful, and the taxonomic analysis revealed that none of the reads were positively identified as viral or bacterial in nature based on ncbi taxonomy. the taxonomy and prevalence of reads from different organisms help differentiate between sequencing artifacts, such as cross-contamination, and low-level infection.

pathogens detected through iterative assembly
the iterative analysis reported the presence or absence of pathogen correctly in tissue and stool samples from both human and zoonotic hosts. two samples in this category were previously reported as the old world arenavirus, lujo virus  <cit> . rna was extracted from the liver biopsy sample, and amplification was pursued using random primers  and an additional rrna depleting step . both samples were analyzed with cupp followed by iterative analysis to identify the pathogen. two iterations were completed, identifying the two segments of the lujo virus . on the third iteration, the assembly failed to produce contigs thereby ending the analysis.table  <dig> iterative analysis on non-host reads of sample  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>  and  <dig>  collected known samples  were analyzed using the ecbc iterative analysis pipeline for pathogen detection. de novo assembled contigs are used to generate nearest neighbors, then the nearest neighbors are used to map reads and generate consensus contigs from the mapped reads . upon completion, a new iteration begins using reads not mapped to the nearest neighbor. the cycle completes after no further reads exist for contig building or there are no matches reported



samples  <dig> and  <dig>  from the gastrointestinal tract of the bat species microchiroptera, contain a coronavirus. the pipeline analysis on the non-host reads of  <dig> produced  <dig> contigs, but only one contig has a match in the ncbi genbank database. a query of this contig produced a match for zaria bat coronavirus strain zbcov  <cit> . the reads that failed to map to zbcov still produced contigs in the next iteration. no database hits were found for these contigs, so the iterative pipeline analysis was terminated. sample  <dig> had a hit against bat host reads in the first iteration, but successfully assembled a contig matching to the zaria bat coronavirus during the second iteration . the other  <dig> contigs assembled did not have any hits in the database. the iterative pathogen identification analysis is completed after two cycles for this sample due to the lack of contigs mapping to any known pathogens.

samples  <dig> and  <dig> were nasal swabs from dromedaries in saudi arabia  <cit>  where rna was isolated and cdna made from the rna directly present within the swab. the samples were then sequenced using the ion torrent pgm platform. these data generated a large percentage of non-host reads , most likely due to high viral loads within the nasal cavities. the iterative analysis efficiently processed the ion torrent data, and mers-cov was the nearest neighbor identified during the first iteration in both samples . one contig was generated from the mapped reads to the identified nearest neighbor  reference, and this led to the subtraction of a majority of the reads hitting against mers-cov for subsequent novel contig generation.

pathogens detected through taxonomy analysis
the iterative analysis pipeline was unable to properly process sample  <dig> due to the low number of reads. only 2 % of the original reads are identified as non-host reads, and those non-host reads are assembled into  <dig> contigs. a blast analysis of the contigs did not identify any near neighbors. therefore the iterative analysis did not report a pathogen in this sample. in the follow-up analysis adding the taxonomy preprocessing step, the taxonomy analysis revealed that only  <dig> reads are assigned to the expected gbv-d virus  <cit> . unlike the negative control sample, the pathogen of interest is clearly identified through this analysis. the viral and bacterial reads are described in the short report produced by this analysis, and the user would be provided a clear indication of the pathogen in the sample for follow-on analysis.

samples that demonstrate gaps
in the case of sample  <dig>  multiple contigs were constructed, and the software identified several near neighbors during the iterative analysis. however, in each iteration, the near neighbor identified was mammalian, with most hits mapping to other bat species. no parvovirus hits were found for the contigs, despite the sample being confirmed as parvovirus positive. using cupp output as input to the taxonomy analysis, the pathogen was still not identified through the iterative analysis. unlike all other samples evaluated here, none of the reads derived from the pathogen could be identified by blastn. the pathogen present in this sample was not similar enough to match to anything in the nucleic acid reference database using the search parameters built into the pipeline.

analysis of unknown samples not detected by iterative analysis using usamriid-wrair pipeline
pathosphere was designed to host multiple analytical pipelines at once, especially as newer technologies and approaches emerge. this capability is demonstrated by using an ngs analytical pipeline designed by the comparative genomics sciences group at the united states army medical research institute of infectious disease  and the viral diseases branch at walter reed army institute of research . the usamriid-wrair pipeline is available on pathosphere via the pathogen detection tool, and was used to reanalyze the datasets corresponding to the samples containing gbv-d virus  and parvovirus  . the architecture of the usamriid-wrair pipeline differs from the iterative analysis pipeline tested above  and reports on the individual read and contig identification and blast mapping comparison. utilizing the usamriid-wrair pipeline to reanalyze samples  <dig> and  <dig>  pathosphere yielded identification of viral reads matching to the pathogen in both samples . sample  <dig> yielded  <dig> viral reads out of  <dig> blast identified non-host reads, all matching to gbv-d virus. sample  <dig> had  <dig> viral reads mapping to uncultured marine virus, gray fox amdovirus , aeromonas phage, and multiple herpesviruses out of  <dig> total blast identified reads. each of the correct pathogen reads are represented in table  <dig>  the read mapping to parvovirus was identified, but  <dig> other reads mapped to viruses that could potentially be in the sample. the usamriid-wrair pipeline offered a different analytical approach, identifying  <dig> gbv-d reads in sample  <dig> while identifying a single read mapping to a divergent parvovirus.table  <dig> usamriid-wrair pipeline reanalysis for pathogen reads from sample  <dig>   <dig>  pathosphere’s ability to host multiple pipelines was tested using a pipeline designed by usamriid and wrair to analyze datasets from samples  <dig> and  <dig>  the reanalysis resulted in viral hits against the correct agent  and against multiple viruses  with one correctly identified as a nearest neighbor



discussion
to compare the analysis capabilities of pipelines hosted by pathosphere, spiked human samples were first sequenced using  <dig>  ion torrent, and illumina platforms. each dataset was then analyzed by the ecbc-developed pipelines hosted on pathosphere . the pipelines had no issues identifying the more abundant pathogens in each dataset through both taxonomic assignment and iterative assembly. the taxonomic assignment is read-based classification, while the iterative assembly is a process that generates contigs and then maps reads against those contigs within the dataset. read-based taxonomic classification is useful, especially when looking at lower levels of pathogens. this was illustrated in the  <dig> and illumina datasets, where only the taxonomic classification identified the burkholderia species in low abundance. iterative assembly is a mechanism that allows for greater confidence in pathogen id within a dataset of interest, as contigs are generated that cover a greater percentage of the genome than single reads. overall, the ecbc pipelines performed well when analyzing low to intermediate levels of spiked pathogens after sequencing on multiple platforms.

pathosphere analysis of ngs datasets containing pathogens within complex sample backgrounds resulted in positive identification for each sample . however, the two samples with pathogens only detected in read-level taxonomy analysis represent critical sample processing and analysis gaps for how pathogens are detected in ngs samples. sample  <dig>  which contained gbv-d  <cit> , was identified using the taxonomic analysis but not the iterative analysis due to a low number of reads. utilizing another analytical pipeline hosted on pathosphere, built by usamriid-wrair, allowed for the detection in a sample with a single read mapping to a parvovirus . the low levels of pathogens present in many sample types can prevent contig assembly and mapping, but the taxonomy preprocessing tool and the usamriid-wrair pipeline can lead to successful pathogen identification. in cases of low pathogen load, the detection of any reads mapping to the actual virus within the sample can be extremely useful for pathogen detection. however, better sampling processing methods and tools to evaluate pathogens at lower read levels must be developed to automate the detection of pathogens at low-levels of infectivity.

the absence of parvovirus-matching sequence in the reads from sample  <dig> using the iterative assembly and taxonomy preprocessing highlights one of the major challenges facing sequence-based identification of pathogens; how to detect a pathogen with little or no homology to something already deposited into an available database? the use of other methods to identify homology when the ncbi nt database does not have adequate representation available will be the second major area of improvement for the analytical pipelines used in this study. further investigation of sample  <dig> revealed that, by using the discontiguous megablast searching algorithm against the ncbi nt database, or using blastx against the ncbi nr database, many reads show matches to parvovirus records. the issue revealed by samples like  <dig> is a major focus of the field going forward, and is something that can be addressed through pathosphere as novel tools for pathogen discovery are developed.

most pathogens identified to date have had some sequence homology to previously identified pathogens, so it is very possible that etiological agents are being missed due to the lack of homology to existing known sequences  <cit> . further, pathogen detection accuracy is important as environmental or sample contamination can lead to false pathogen discovery  <cit> . with increasing biosurveillance efforts in human and non-human populations, there will be large amounts of data generated that potentially contain novel pathogens with little or no homology to existing viruses  <cit> . less stringent nucleotide alignment approaches and blastx  have the potential to detect some of these less homologous pathogens. however, many of these algorithms, such as blastx, are too computationally intensive to implement without heuristics or substantial dedicated computational resources. as more efficient algorithms are developed, such as the newly described diamond  <cit> , they can be integrated into the existing analytical pipelines as well as pipelines developed elsewhere and hosted on pathosphere. the current pipelines bin total contiguous sequences for the user to analyze further. this provides an area for future development, as identifying unknown contigs remains a critical area for pathogen identification and discovery. pathosphere provides the necessary architecture to host the types of software programs that in the future will be needed to analyze data sets for unknown pathogens that contain little or no homology to pathogens described previously. providing the source code for the preprocessing tools  as well as the raw data sets utilized here  provides a standard starting point for the further evaluation of these pipelines as well as the integration of new tools into pathosphere.

sequencer platform of choice also plays a role in using ngs as a tool for pathogen detection. platforms like ion torrent will give longer read lengths, while illumina technology will give shorter read lengths  but can provide greater depth and coverage of all the genomic material present in a given sample  <cit> . technology from pacbio generates very long read length, making contig assembly less important. novel sequencing technology, such as portable nanopore sequencing, would benefit from centralized analytical tools that can be accessed and utilized remotely  <cit> . the ability of the pipelines tested here to detect pathogens in both  <dig>  ion torrent, and illumina sequenced samples demonstrates the utility of pathosphere to host pipelines meant for analysis of data from different platforms. as tools become available to better match reads to databases and to analyze data from varying sequencing platforms, the plug-in support of pathosphere will allow for the integration of these tools into the analytical pipelines.

the real-time detection of pathogens is an important step for more complete biosurveillance efforts worldwide and is critical when responding to an outbreak of unknown origin. collaborative crowd-sourcing has emerged as a tool to quickly identify pathogens during outbreaks, like during the enterohemorrhagic e. coli outbreak in europe during  <dig>  <cit> . despite this collaboration, determining strain level identification of certain agents from ngs datasets remains a major gap, although the field is creating tools  utilizing multiple read-level loci for strain identification . this becomes a greater challenge when the mechanisms of virulence are unknown, as the strain differences between the well-characterized o104:h <dig> ehec e. coli and other less pathogenic strains are still being explored  <cit> . similar efforts in the future will benefit from the centralized and adaptable analysis hub provided by pathosphere.

pathosphere differs from already available services like galaxy  <cit>  because its primary focus is the detection of pathogens in complex samples. tools have been developed for pathogen detection in ngs datasets, such as surpi  <cit> , but these tools are not hosted. further, pathosphere offers accessibility to bioinformatics software for users not familiar with these tools, which is a major gap in using ngs for public health applications and for guiding clinical diagnostic procedures  <cit> . the pipelines hosted are designed only for that purpose, and the variable outputs from these pipelines can range from simple taxonomy and contig id reports to more bioinformatically-intensive single read alignment files. this creates a pathogen-centric approach to sequencing data analysis that serves to focus both experienced and inexperienced users. pathosphere provides these services through a user-friendly, web-based portal that pulls data uploaded by researchers and performs the desired analyses using hardware supported remotely. the analysis reports are then communicated back to the user via pathosphere email alerts; and the pathogens contained within the sequence data can be identified. this setup can be advantageous in many situations, especially when the costly resources needed to run these analyses locally are unavailable or when the environment the data is collected in might not be optimal for software hosting  <cit> .

in addition to the pipeline analysis presented here, the hosting architecture of pathosphere has already had extensive peer use. pathosphere has a user base of over  <dig> individuals from organizations such as the cdc, the department of defense, mit, columbia university, and organizations based internationally. software available on pathosphere is hosted in collaboration with mitll, the university of houston, and optimetrics. pathosphere has been used by the community to facilitate international collaboration, and was instrumental in the genomic analysis of novel enterovirus isolates in south america  <cit> . the current ebola outbreak has highlighted the need for available tools for infectious disease personnel on the ground in western africa  <cit> . as the epidemic becomes more controlled and more personnel are established, genomic surveillance and molecular epidemiology will become key to understanding the dynamics of the current epidemic as well as to provide information for the prevention of the next ebolavirus epidemic . the remote capabilities of pathosphere could help fill these needs and remove the need for it personnel, bioinformatics specialists, and computing hardware at the epicenter of an outbreak.

CONCLUSIONS
pathosphere supports the evaluation of novel detection algorithms and other analytical tools by allowing users to run these potentially process-heavy applications using the hardware that supports the web interface. the users of pathosphere can communicate directly with the technical development team through forums and discussion boards on the web interface. this ongoing collaboration between pathosphere developers and users ensures that the most current and accurate ways to detect pathogens in traditional and ngs data are utilized in the analytical pipelines. the user-friendly features  built into pathosphere, its utility for detecting pathogens in complex samples, and its plug-in development architecture allow for it to evolve with novel technology and provide a comprehensive web interface for the detection of known pathogens and emerging infectious diseases worldwide.

additional file
additional file 1: 



availability and requirements

pathosphere can be accessed by creating a user name and password at http://www.pathosphere.org. access is freely available upon creation of a user name. preprocessing tools can be accessed at http://sourceforge.net/projects/pathosphere/. no local hardware requirements exist of utilization of the web interface.

competing interests

the authors declare that they have no competing interests.

authors’ contributions

ak, atl, mrw, jtl, mcm, es, wil, hsg, dlh, gfp, cnr designed and implemented the study and wrote the manuscript. ak, pc, sy, pr, js, gbd, etf, jmh, atl, mrw, jtl, bpp, oe, ap, ddj, tgv, mcm, pq, hsg, gfp, cnr developed and support preprocessing tools, the analytical pipelines, and the pathosphere.org web interface. oe, ap, pq, wil, hsg, dlh sequenced the sample material and provided novel datasets for analysis. all authors read and approved the final manuscript.

