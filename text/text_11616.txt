BACKGROUND
the importance of discovering the patterns and features in genomic sequences is motivated by a number of scientific contexts. the encyclopedia of dna elements project  seeks ‘to identify all functional elements in the human genome sequence’  <cit> . another context, the study of co-regulated genes, involves the analysis of the promoter sequences, introns, and untranslated regions  of genes that were determined by microarray experiments to be co-regulated. similarly, transcription factor binding regions identified by chip-chip and chip-seq experiments are examined to identify genomic patterns  <cit> . genome-wide pattern discovery studies, which seek to identify vocabularies of genomes  <cit> , provide yet another perspective on genomic data. large scale analysis of genomic data is also performed in the search for genomic signatures   <cit> . all of these problems require the discovery of patterns in genomic sequences.

several approaches have been developed for genomic pattern discovery. word enumeration methods are algorithmic techniques that systematically discover either substrings  or sets of related substrings  in dna sequences. most enumeration methods create a data representation of the input sequence that provides fast retrieval of elementary word statistics. the representation serves as a central data structure for a number of other analyses, including statistical word scoring, word-clustering, and motif discovery. a number of algorithmic techniques for word space enumeration have been proposed. each of the enumeration algorithms can be classified as either index-based <cit> , graph-based <cit> , or iterative <cit> .

index-based enumeration strategies create a data structure, called the index, and provide a mapping function, which maps the character composition of a word to a specific entry in the index data structure. index-based strategies differ in  the data structure used for the index and  the type of mapping function employed. popular index-based strategies employ hash functions, radix trees, and suffix trees. ymf <cit> , wordspy <cit> , and rmes <cit>  employ hash functions for enumerating the word space. an alternative to hash functions, radix trees require o space , and are among the fastest representations for the retrieval of words. seeder <cit>  and sms <cit>  are examples of approaches that utilize a radix tree for storing words. a third alternative for index data structure, suffix trees provide a semantically rich representation of a set of input sequences. they require o time and space, and enable a number of efficient and elegant string processing algorithms. many tools and algorithms based employ suffix trees, including speller <cit> , weeder <cit> , reputer <cit> , and verbumculus <cit> .

winnower <cit> , a graph-based approach, has been used for solving the planted  motif problem  <cit>  . the winnower algorithm reduces the problem of finding  motifs to the problem of finding large cliques in multi-partite graphs. the undirected winnower graph g contains nodes representing words, and edges representing a similarity relationship  between words. instead of finding maximal cliques, which is an np-complete problem  <cit> , pevzner and sze iteratively remove edges from g that are guaranteed not to be contained in a clique of size k, resulting in an algorithm of o, where n is the total number of nucleotides.

iterative approaches, such as teiresias <cit>  and mitra <cit> , incrementally concatenate short motifs from the input sequences to discover maximal motifs. these methods generate the set of maximal patterns without having to enumerate the entire word-space of an input sequence set. the teiresias algorithm divides the motif discovery process into two phases: scanning and convolution. during the scanning phase, a set of elementary patterns of length w, satisfying a user-defined quorum q, is enumerated for a specific length with a required number of non-mismatches l. during the convolution phase, the elementary patterns are combined pair-wise and the resulting patterns are added to the set of elementary patterns if they satisfy the quorum. during convolution it is necessary to consistently detect and remove patterns that are no longer maximal, but are instead part of larger patterns with the same quorum satisfaction. the complexity of the scanning phase is o, with n being the total number of nucleotides, and the complexity of the convolution phase is ,  represents the matches in a pattern t’, which is a maximization of a pattern t <cit> ). taking into consideration all calls to a maximization function, the worst-case time complexity of the teiresias algorithm is , where th is the time needed for locating hash entries, and p is a pattern to be inserted into the set of maximal patterns  <cit> .

while a number of algorithms and software tools have been developed to solve the word discovery problem, most do not provide the scalability needed to process large  data sets. for example, our single-processor enumeration methods, based on either a radix tree or a suffix tree, are unable to perform word enumeration for the ~ <dig>  core promoters of the arabidopsis thaliana genome for word lengths greater than 19bp .

the wordseeker software suite addresses this problem by providing scalable word discovery algorithms. the software described herein builds upon earlier work of the authors , which developed cache aware data layout and access strategies for a shared memory implementation of the radix tree data structure. wordseeker has been used to analyze the promoter regions of genes in the dna repair pathways of homo sapiens <cit> , the entire genome of arabidopsis thaliana <cit> , and regulatory regions involved in gravity response in arabidopsis thaliana <cit> . as reported in  <cit> , results of the wordseeker analysis of the arabidopsis thaliana genome have been incorporated into agris - the arabidopsis gene regulatory information server  <cit> .

the remainder of the manuscript presents a description of the methods employed by wordseeker, an experimental assessment of their effectiveness, and a discussion of results.

methods
this section presents the software design, the concurrent architecture, the open source repository and the deployment guidelines for the wordseeker software.

software architecture
the open word enumeration framework   <cit>  provides the ability to employ different motif discovery algorithms without changing the overall execution logic of the software system. for example, wordseeker can utilize a radix tree or a suffix tree for word space enumeration. this enables the selection of the “best” algorithm for a specific dataset at run-time, as necessitated by input parameters and dataset characteristics. for example, it is recommended that the suffix tree be used when enumerating long words  and that the radix tree be used when enumerating short words.

the owef controls a set of classes responsible for specific functions. a set of input sequences is processed by a word enumeration algorithm, which store the words in a data structure. the stored information structure is processed by the wordscoring function to form a statistical model. the model, and more importantly operations on the model, are provided to other classes via owefargs. other classes, such as sequenceclustering, worddistribution, cluster, modulediscovery and wordfamily, use the information to identify statistically significant words, which are used to discover motifs, modules, and sequence clusters.

distributed architecture
wordseeker uses a two-level parallelization strategy to achieve scalability with respect to input parameters, and with respect to the numbers of cluster nodes and processor cores. node-level parallelization  uses the message passing interface  for coordination and communication between nodes. a controller task coordinates the activities of worker nodes. during the word enumeration phase, the data structure representing the word space  is distributed to worker nodes. data partitioning is accomplished by creating a list of prefixes for each worker node . thus, each node builds a portion of the overall data structure.

during the word scoring phase, loop-level parallelism is exploited by partitioning statistical analysis among the cores of the worker nodes, each of which utilizes a distributed markov chain model for the computation of scores for a subset of the enumerated words. during word scoring, nodes share word occurrence information as needed. openmp compiler directives are used to define parallel sections and to add parallel loop constructs. this allows automatic generation of multi-threaded code, if the target compiler supports openmp extensions. 

open source implementation
wordseeker was developed in the ohio university bioinformatics laboratory on a 5-node cluster computer. each node contains 32gb ram,  <dig> cores, 2tb hard disk space  and a dual-channel, gigabit ethernet.

the public version of wordseeker, which can be accessed at http://word-seeker.org, is deployed on the ohio supercomputer center’s glenn cluster, an ibm e <dig> system with more than  <dig> opteron processor cores that are connected by  <dig> gbps or  <dig> gbps infiniband. wordseeker ‘jobs’ are started and controlled through the ohio supercomputer center’s job management system. the porting of the wordseeker software from the ohio university cluster computer to the glenn cluster was easily accomplished, by observing the open source policies that are highlighted in this section .

the wordseeker source code, released under gnu general public license v <dig>  is available at http://code.google.com/p/word-seeker/. access to the source code can be achieved through svn at http://word-seeker.googlecode.com/svn/trunk. the source code is documented using the doxygen code generator.

to build an executable version of wordseeker, the c++ compiler version,  <dig> * or higher is required, as well as openmp headers. the distributed version of wordseeker requires a working mpi environment with mpich <dig>  mpiexec and mpicxx installed. the visualization capabilities require perl  <dig> . <dig>  the perl tfbs module  and gnuplot, version  <dig>  or higher. wordseeker has been tested under ubuntu  <dig>  and the linux operating system provided in the ohio supercomputer center environment.

RESULTS
this section presents results of a comprehensive suite of tests performed to evaluate the performance and scalability of the different parallel and distributed modes of wordseeker. specifically, the evaluations considered the single-node version, the openmp-based shared-memory multiprocessors / multicore version, the mpi-based distributed  version, and a mixed shared-memory/distributed memory version. shared memory tests were performed on a 64-bit linux machine with  <dig> dual-core  <dig>  gigahertz amd opteron processors and  <dig> gb of ram. distributed memory tests were performed on a 64-bit linux machine with  <dig> quad-core  <dig>  gigahertz amd opteron processors and  <dig> gb of ram.

wordseeker was evaluated under diverse circumstances by varying  the size of the input dna sequence,  the length of dna words to be analyzed, and  the enumeration algorithm . the evaluation involved the measurement of  computational performance - the overall execution time of the software, and the execution times for specific functions;  speed-up - the sequential execution time divided by the parallel execution time; and  efficiency - speed-up divided by the total number of nodes  used.

performance
a set of experiments analyzes the overall performance of the wordseeker pipeline for the core promoters of the arabidopsis thaliana genome . the tests compare the single core version and the distributed version. the core promoters include  <dig> nucleotides directly upstream of  <dig>  transcription start sites. to determine the relationship between word length and performance, the complete run-times, as well as the run-times for the enumeration and the scoring stages, were computed for word lengths in the range . the rationale for choosing this range of word lengths is as follows. while eukaryotic transcription factors usually recognize 6-8bp long binding sites  <cit> , much longer functional binding sites have been discovered .

figures 5a and 5b compare the performance results for a multi-threaded version of wordseeker, which used  a single computing node and  five computing nodes. the single node version utilizes  <dig>   <dig>   <dig>  and  <dig> cores, and the five node version uses  <dig> cores/node, for a total of  <dig> cores. the plots of the overall execution times for the various word lengths demonstrate that the concurrent algorithms provide scalability by effectively utilizing the distributed hardware.

speedup and efficiency
speedup and efficiency experiments were performed to assess in detail the scalability and the performance boundaries of the wordseeker implementation. figures 6a and 6b show the speedup, and figures 6c and 6d show the efficiency, of shared memory implementations of the radix tree and the suffix tree on  <dig>   <dig>  and  <dig> processor cores.

the speedup and efficiency results show a drop in performance for very short words  and for very long words, , but yield good results for word lengths of 10bp and 20bp. the performance drop for short word lengths occurs because the parallelization overhead outweighs the computational benefit; for longer word lengths, cache inefficiency and front-side bus contention cause performance to decrease . the suffix tree performed similarly to the radix tree in terms of speedup and efficiency. the difference between figures 6c and 6d can be attributed to the cost of suffix tree construction.

CONCLUSIONS
wordseeker is a general purpose, scalable, open source approach to word enumeration. it supports an important set of use cases, has been applied to interesting case studies, and effectively exploits parallel and distributed computing hardware to provide scalable performance.

wordseeker is being used currently to perform complete word space enumerations on a genomic scale; to construct word and motif encyclopedias for whole genomes; to perform word-based characterizations of pathways, tissues, and co-regulated genes; and to identify motifs in chip-seq data. ongoing work includes the construction of openmotif, a project that combines a number of motif discovery open source projects into a cohesive framework.

list of abbreviations used
encode: encyclopedia of dna elements; dna: deoxyribonucleic acid; agris: the arabidopsis gene regulatory information server; utr: untranslated region; chip-chip: chromatin immunoprecipitation with microarray technology; chip-seq: chromatin immunoprecipitation with massively parallel dna sequencing; owef: open word enumeration framework; mpi: message passing interface; a, c, g, t: adenine, cytosine, guanine, thymine; raid: redundant array of independent disks.

competing interests
the authors declare that they have no competing interests.

authors' contributions
jl contributed to the design, implementation and validation of the algorithms and models, the generation of the results and the writing of this document. kk, ln, ljn contributed to the development and implementation of the models and algorithms and the generation of the results. xl, ra contributed to the generation of the results. jdw, ej and tb contributed to the development and implementation of the models and algorithms. ke and ssl contributed to the development of the models and algorithms. le contributed to the development of the biological models. in addition to conceptualizing the architecture employed in this research, fd and lrw contributed to the design and validation of models and algorithms, and to the writing of this manuscript.

