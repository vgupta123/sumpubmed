BACKGROUND
biomarker discovery has become one of the most significant research objectives in recent years. because biomarker discovery is typically modeled to determine the most discriminating features for classification, it can be described as a feature selection problem regarding class from the point of view of machine learning . feature selection is the step that involves identification of the most salient features for learning  <cit>  and enables the performance of the classifier to be enhanced by eliminating irrelevant features that cause inaccurate prediction or over-fitting problems. in addition, the time required for learning is reduced as feature selection serves to lower the dimensionality. although classification without a feature selection process may improve the classification performance, a large number of features would complicate interpretation of the result. in short, feature selection not only enhances the classification performance, it also improves the understanding and analysis of the data. the emergence of new high-throughput technologies has made genomic data, such as microarray data and rna-seq, widely available for biomarker discovery. however, the distinct characteristics of biomedical data, which often contain far more features than the number of samples, mean that conventional feature selection approaches might be problematic, especially with regard to reproducibility; small changes in the dataset could lead to large changes in the feature selection result, which should not be considered as important biomarkers. feature selection in the biomedical field should consider the stability of features, as well as the influence on the classification performance. some researchers have suggested the ensemble feature selection based on instance perturbation to address this problem . this study proved that the stability of selected features was significantly improved by performing feature selection on slightly different datasets and aggregating their results. furthermore, research that combines lasso regression with resampling was introduced  <cit> . the l
1-norm of lasso regression tends to force the solution to be sparse, and it shows high efficiency for feature selection in regression problems.

in this paper, we propose a stable feature selection method based on the l
1-norm support vector machine . the basic concept of l
1-norm svm is similar to that of lasso regression, but it is tailored for classification tasks, which is the model for many biomarker discoveries. l
1-norm svm efficiently reduces the number of irrelevant or redundant features to fewer than the number of samples; thus, it is appropriate for biomedical high-dimensional data. as our methods are applied over instance perturbation steps, the stability issue, which is one of the most critical problems of l
1-norm can also be managed. furthermore, the optimal subset of selected features was detected by applying backward feature elimination to our own ranking criteria. by eliminating features one by one based on our ranking criteria generated by the l
1-norm svm, a cross-validated classification score is calculated, and a subset of features that maximizes classifier performance is acquired.

the proposed method is tested for the classification of renal clear cell carcinoma stage classification. we used an rna-seq gene expression dataset of renal clear cell carcinoma samples from the cancer genome atlas  for our study. we compared our approach with three established feature selection methods, namely a fast correlation-based filter   <cit> , random forest  <cit> , and an ensemble version of support vector machine-based recursive feature elimination   <cit> , from the point of view of classification performance and the stability of selected features. the experiment showed that our method has considerable classification performance and stability.

RESULTS
datasets
the rna-seq gene expression data of renal clear cell carcinoma was obtained from broad gdac firehose, which is one of the genome data analysis centers of the tcga project  <cit> . level  <dig> rnaseqv <dig> datasets of kidney renal clear cell carcinoma  was used for experiments. we only took into account tumor-matched normal samples. the vectors of rna-seq by expectation maximization   <cit>  that are normalized by z-score were used as an estimate for the gene expression level. we discarded genes and samples that contain invalid or null values. the pathogenic stage information of renal clear cell carcinoma samples is retrieved from tcga clinical dataset biotab files and set as the class label of gene expression data. basically the stage is divided into four stages, i.e., stages i, ii, iii, and iv by tnm stage groupings, which take into account the size of the tumor, the lymph nodes involved and distant metastasis  <cit> . we took into account only two stages, i.e., stage i and stage iv, as renal clear cell carcinoma of stage i involves local tumors that only exist in the kidney, whereas tumors at stage iv have grown into other tissues outside the kidney or have spread widely to other lymph nodes; thus, the use of these stages could be a significant clue for tumor advance and tumor metastasis. samples of which the stage information is not clear were not included in the test. after the filtering steps, our dataset consisted of  <dig> samples, of which  <dig> and  <dig> were stage i and stage iv samples, respectively. each sample consists of the rsem vector for  <dig> genes.

although cross-validation is one of the most popular methods for classification tests on a biological dataset, it tends to produce a dataset-dependent result especially with a small sample size  <cit> . moreover, as the resampling step is part of the compared and proposed approach, a classification test on cross-validation might not hold significant meaning. hence, the classification performance should be evaluated by an independent data test. we ensured that the test remained independent of the dataset by randomly divided the original dataset into a training set  and a test set . the training set consisted of  <dig> and  <dig> stage i and stage iv samples, respectively, whereas the test set contained  <dig> and  <dig> samples, respectively. only the training dataset was utilized for the cross-validation test. the stability test was performed by randomly generating  <dig> subsets from the original dataset, each of which contained 80% of the whole samples. the fcbf feature selection test was implemented by using weka  <dig> . <dig>  <cit> , and the other experiments were all implemented with python, using the library scikit-learn  <dig>   <cit> .

feature selection
data perturbation was achieved by producing  <dig> bootstrap samples containing 80% of the data from the training set. then feature selection was performed by first calculating the regularization parameter c of l
1-norm svm by grid search, using 10-fold cross-validation on each bootstrap sample of training data. we determined the best value in the range of c∈{10− <dig>  10− <dig>  …,  <dig>  104}. because our dataset contains bias in class proportions, simply considering accuracy as a performance estimator is not appropriate. instead, we regard the area under the curve  as the main criterion for performing experiments. thus, the value of c resulting in the best auc score was selected for each bootstrap sample.

then l
1-norm svm was applied to  <dig> bootstrap samples to filter those genes whose coefficients are  <dig>  we calculate and record the 10-fold cross-validation score of reduced feature sets at this point to choose optimal feature sets for each bootstrap in the later step. these steps are repeated several times until no more feature reduction is available. the remaining genes were aggregated to one gene set and ranked by the number of bootstrap samples that finally remained.

subsequently, as a revising step, backward feature elimination is performed to find the optimal feature subset of which the classification performance is the best. again, we used the auc score as the main criterion for the classification performance. svm is selected as a classifier, and 10-fold cross-validation is applied for the test. the grid-search method is also applied to set the regularization parameter c and γ in the range of c∈{10− <dig>  10− <dig>  …,  <dig>  1010} and γ∈{10− <dig>  10− <dig>  …,  <dig>  103}, respectively.

then the mean auc score obtained from the cross-validation test is calculated. the score is recursively calculated by reducing the genes one by one, starting from the full gene sets, until a subset consisting of only one gene is tested. figure  <dig> demonstrates the alteration of the mean auc score by the backward feature elimination.fig.  <dig> backward feature elimination for optimal subset. backward feature elimination is performed based on our ranking criteria. svm with an rbf kernel is used as a classifier for calculating the cross-validation score. the x- and y-axes denote the size of the feature subset and the 10-fold cross-validation auc score, respectively. the red circle indicates the number of features with the highest auc score in our experiment, which is  <dig> features with auc =  <dig> 




the performance of our model was compared with three well-known feature selection methods, i.e., fcbf, random forest, and an ensemble version of svm-rfe. fcbf is a feature selection method that is used to remove irrelevant features based on symmetric uncertainty. although the stability was not considered in fcbf, we selected it as a comparison target because this feature selection algorithm was adapted from a previous study that classified stage progression of renal clear cell carcinoma based on the rna-seq dataset  <cit> . random forest is a method based on decision trees, and frequently has been used for both feature selection and classification. random forest deals with the stability issue by bootstrap aggregation  included in the algorithm. svm-rfe is a feature selection method that recursively eliminates the features whose weight magnitudes of l
2-norm svm are the smallest  <cit> , and it has been proven to deliver superior performance in many recent studies. however, svm-rfe is problematic in terms of stability when applied to a single dataset; thus, some previous researchers have tried to use the ensemble version of svm-rfe based on instance perturbation to address this problem.  <cit>  for the ensemble svm-rfe in our comparison experiment, the fraction ratio for elimination in each step was set to 20%, and a linear aggregation method that sums the rank over all bootstraps was used as  <cit> . the number of bootstraps was set to  <dig>  and regularization parameter c is optimized in the same way as our method. as random forest and svm-rfe provides only the ranking list of all features, we applied backward feature elimination method to find the optimal subset of features, similar to our method. the 10-fold cross-validation score is calculated by the classifier while adding features one by one, based on the feature rankings. then the optimal feature set which maximizes the cross-validation score is acquired. the random forest classifier and svm classifier with the radial basis function  kernel were used as classifiers for the random forest and the ensemble svm-rfe, respectively.

classification performance test
a cross-validation test as well as an independent dataset test is conducted for evaluation of classification performance. as described in the subsection on datasets, the data that was included in the independent test set was not used for the feature selection process at all. only the training set was used for the cross-validation test. four popular classification methods, i.e., adaptive boosting , logistic regression, random forest, and svm with an rbf kernel were used for performance evaluation. gene selection was performed by fcbf, random forest, ensemble svm-rfe, and our method before the classification tests. figure  <dig> demonstrates the number of genes and selected by each method. as random forest selects far more genes than other methods, an additional test with  <dig> genes is conducted using random forest, which is similar to the number of genes we used in the ensemble svm-rfe method and our method. then we assessed four performance measures, i.e., the accuracy, f <dig> score, matthews correlation coefficient , and area under the curve  for each classifier. tables  <dig> and  <dig> compare the classification performance of the approaches for the independent data test and cross-validation test, respectively. as seen in the tables, our algorithm shows the overall best performance for most classifiers among most performance indices, both in the cross-validation test and independent dataset test. especially, our method with the svm classifier demonstrated the best performance among all.fig.  <dig> number of genes selected by each method. the figure shows the number of genes selected by each feature selection method, i.e., fcbf, random forest, ensemble svm-rfe and our method


 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
the performance score is calculated on the independent dataset. the items that obtained the best score are highlighted in bold text. the numbers below the random forest classifier denote the number of genes selected for the performance test


 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
the mean performance score of 10-fold cross validation test is calculated. the items that obtained the best score are highlighted in bold text. the numbers below the random forest classifier denote the number of genes selected for the performance test




stability test
we carried out the stability test by creating  <dig> random subsamples from the original dataset, which is constructed with 80% of the data. the stability test was performed by using the tanimoto distance t. here, we also tested our method without bagging for the comparison. figures  <dig> and  <dig> demonstrate the mean and standard deviation of the tanimoto distance for each method, respectively. as we see in the figures, our method generally demonstrates high stability among all the methods. the ensemble svm-rfe shows the similar performance as our method. however, l
1-norm svm without instance perturbation shows remarkably lower scores than other methods, which proves the significance of the ensemble selection for l
1-norm-based methods. fcbf also displays a relatively lower stability score than other methods as it does not take into account the stability issue, although it shows the least variance, since it selects almost the same number of features within subsamples.fig.  <dig> mean tanimoto distance. the arithmetic mean of the tanimoto distance on  <dig> random subsamples is calculated as a stability score. the x-axis denotes the arithmetic mean of the tanimoto distance of each method


fig.  <dig> standard deviation of tanimoto distance. the standard deviation of the tanimoto distance on  <dig> random subsamples is calculated. the x-axis denotes the standard deviation of the tanimoto distance of each method




discussion and 
CONCLUSIONS
in this paper, we present a novel feature selection method based on l
1-norm svm over data perturbation efficient for biomarker discovery. the nature of the l
1-norm that leads to a sparse solution provides a fairly efficient way for feature selection for high-dimensional data. l
1-norm svm is also suitable for biomarker selection, as it delivers high performance in classification, and is applicable to diverse situations. however, the use of l
1-norm svm on a single dataset has difficulty in detecting closely correlated factors, which is common in biomarker detecting. in addition, it may produce a result that is subordinate to a certain dataset. in our experiments, the stability of features could be improved as l
1-norm svm is applied to a number of bootstrap samples, considering instance perturbation. instead of using the general ranking criteria of svm, we consider only the number of bootstrap samples that selected the feature as measure of the stability. by applying backward feature elimination based on our own stability score, we could determine an optimal subset of features that holds good performance for classification. we applied our approach to rna-seq data of renal clear cell carcinoma to find candidate biomarkers related to stage progress, which might be closely associated with tumor advance and the metastasis issue. through comparison with established feature selection methods, the performance of our algorithm was proved in terms of classification performance and stability.

the stability of feature selection is a significant issue and its importance has been underestimated for a long time; yet, many research efforts aimed at feature selection solely focused on the performance of the methods. however, as we can see from the case of non-ensemble methods in our experiment, feature selection algorithms designed without considering stability might find many different subsets of features, if the data changes even slightly. this causes low reproducibility in high-dimensional datasets, such as microarray data or rna-seq, and would make the result of the analysis less meaningful. thus, stable feature selection is an essential issue in biomarker discovery. of course, the performance of features should not be neglected because feature stability does not guarantee true biomarker detection.

although it is based on a simple idea, the proposed approach was moderately successful on datasets consisting of a very large number of features and relatively much smaller samples. our research proposes a general process for binary classification problems on high-dimensional data and we expect the proposed method to be applicable to many other kinds of biomarker discovery. however, although it generally demonstrated improved performance compared to conventional ways, the proposed method depends only on gene expression data. therefore, it would be necessary to integrate other datasets, e.g., pathways, gene interactions, and genomic variants as future work. in addition, as our method is not able to produce a deterministic result, we would have to consider more precise tuning of our model and its parameters.

