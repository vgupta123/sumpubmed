BACKGROUND
this paper concentrates on a practical situation that occurs frequently in microbiology research. it is a widely accepted principle regarding bacterial batch cultures that when cells are inoculated into a growth-favouring environment, this determines a maximum specific growth rate  <cit> . it is a common task to measure this rate, often with a view to comparison across species or environmental conditions. however various issues can make such measurements difficult. the problems can be biological or technical. for example, the window of exponential phase could be too small to derive a statistically significant conclusion for the maximum specific growth rate. also, differences in the rate of growth are often small, making the detection challenging, particularly when data is limited and noisy. in this paper we address these issues by taking advantage of existing experimental knowledge to improve detection.

the growth rate may be modulated by the state of the population: close to the inoculation, the cells are still adjusting to their new environment , while at higher densities they slow down and eventually stop growing . this behaviour is encapsulated in fig.  <dig>  during the lag phase, the specific growth rate is much less than its maximum and only a small amount of growth is detectable. to interpret growth measurements, a predictive mathematical model of bacterial growth can be used. such models provide a means to describe the growth behaviour of a species over time by reducing the system to a set of fundamental parameters . these parameters must be estimated in order to fit the model to a given dataset. in this paper we use the model of baranyi and roberts  <cit> , which is able to describe all three stages of bacterial growth . some background on this model is given in additional file  <dig>  for this model, the widely used logarithm of the bacterial concentration is sigmoidal, so that a relatively linear phase is both preceded and followed by a transition phase characterised by small specific growth rates, as shown in fig.  <dig>  a number of classical models  for the population size, x, /x is monotone decreasing”  <cit> ) have frequently been used for the logarithm of x too . the justification is that, applied in this way, such models show the expected sigmoid pattern on the logarithmic scale, although applying them on this scale makes their use purely empirical. the techniques described in this paper, however, may easily be extended to such cases.
fig.  <dig> the model of baranyi and roberts incorporates three stages of bacterial growth. an illustration of the three stages of bacterial growth  described in the model of baranyi and roberts  <cit>  . other classical models for the population size, x, incorporate only the exponential and stationary phases  on the logarithmic scale. the top panel shows how the specific growth rate changes with the logarithm of the cell concentration during the three stages, whilst the bottom panel demonstrates how these phases correspond to the familiar sigmoidal shape that is observed when plotting the log cell concentration over time



established traditional statistical testing methods typically consist of an f-test or akaike information criterion combined with a maximum likelihood optimisation approach which makes point estimates with the goal of finding the best fit to the data given the model or hypothesis. the  program microfit allowed for the statistical comparison of parameters between two bacterial growth data sets using an f-test. in the literature, one report used nonlinear regression techniques to fit the specific growth rates of strains of staphylococcus aureus and utilised both a maximum-likelihood based χ <dig> test and principal-component analysis reference to compare restricted models   <cit> . a separate study used linear spline regression to calculate growth slopes in measurements of different strains of escherichia coli and termed curves as significantly different if they lay outside an estimated  <dig> % confidence interval  <cit> .

despite their frequent use in curve fitting problems, maximum likelihood and other optimisation techniques can often be misleading. a discussion of problems relating to optimisation methods can be found in  <cit> . one issue is the possibility of overfitting due to inadequate representation of measurement errors in the data  <cit> , a problem that frequently leads to parameters being much more sharply defined than is justifiable given the data. another issue is that the point estimate approach of optimisation ignores the contribution from the rest of parameter space and may miss alternative solutions  <cit> . further, maximum likelihood approaches do not provide a framework to make use of prior knowledge to improve future estimation.

using the bayesian framework we may capture the full uncertainty of the problem, taking the whole of parameter space into account to make consistent predictions. we reduce the risk of overfitting since bayesian techniques inherently account for the trade-off between model simplicity and goodness of fit  <cit> . furthermore we may encapsulate existing knowledge through the prior probability and capitalise upon this knowledge to improve our inferences. in addition, the tools for model and hypothesis comparison are readily available through the calculation of the bayes factor  <cit> .

the success of bayesian methods for parameter inference in biological systems has promoted an exciting new research area. a good review of this area can be found in  <cit> . major developments in the application of bayesian methods in general have been possible due to advances in sampling techniques. nested sampling, as pioneered by skilling offers a large improvement over multi-dimensional approaches such as highly computationally expensive markov chain monte carlo methods, due to the reduction of the high-dimensional integrals that arise from bayesian analysis to integrals over a single dimension  <cit> . recent applications include simulations of potential energy surfaces for protein folding  <cit> , parameter inference for a model of circadian rhythms  <cit>  and the analysis of experimental data for mice infected with salmonella enterica, with relevance to alternative modelling techniques  <cit> . also using nested sampling, a recent study considered how bayesian analysis can address the problems associated with uncertainty when inferring parameters and comparing models for biological processes, particularly within the framework of experimental design  <cit> .

in this paper we employ a nested sampling based bayesian approach to infer parameters and compare bacterial growth curve data, in particular through comparison of the growth rate. our work makes use of the combase database  <cit> , which contains over  <dig>  microbial growth curves collected under many different experimental conditions.

methods
model for bacterial growth
in this paper we use the  <dig> parameter model of baranyi and roberts  <cit>  which encompasses both the lag to exponential and exponential to stationary transitions of bacterial growth. letting the bacterial concentration at time t be given by x, this model is described by 
  y=lnx=y0+μmaxa−ln1+eμmaxa−1e, 

  a=t−h0μmax+ln1−e−μmaxt+e−μmax, 

where y0= lnx and ymax= lnxmax, for xmax the maximum bacterial concentration. in addition μmax denotes the maximum specific growth rate and h0=λμmax, where λ is the length of the lag phase. more details on the background of this model are available in additional file  <dig>  we note that although the bacterial concentration must be transformed to the lnx scale for use in the model, the concentration and parameter set are transformed afterwards to the more usual log10x scale in all of our results.

parameter inference using bayesian analysis
key to the task of parameter inference using bayesian analysis is bayes’ theorem, which encapsulates our inference about the parameter set, p, when using some hypothesis or model, h, given the observation of some data, d, and any background information, i, by calculation of the posterior probability distribution, p, where 
  p=ppp. 

here, p ) is the likelihood, p ) is the prior probability distribution without knowledge of the data and p  is known as the evidence and can be thought of as the probability of seeing the given data if hypothesis h is correct.

the likelihood function
given a dataset with n independent data points with normally distributed errors, the appropriate log-likelihood function is 
  logℒ=−∑i=1nlogσi2π−12∑i=1n2σi <dig>  

where di is the y component of the i-th data point and yi denotes the y value obtained by applying the model using the t component of the i-th data point. the weighting or noise level is taken to be constant, so that σi=σ. this assumption can be justified by considering that all data was collected using a viable count method, for which colonies resulting from serial dilutions of bacterial suspensions are counted and the results used to determine the bacterial concentration  in the original sample  <cit> . since there is an optimum range of colony numbers for counting , one bacterial concentration that is  <dig> times bigger than another must be  <dig> times more diluted and the resulting error incurred by forward interpolation of the counted value will be  <dig> times greater. for this reason, we may assume that the errors in the measured bacterial concentration, x, are log-normally distributed, and therefore the errors in y= log <dig> are normally distributed. in our analysis σ may be prescribed  or inferred as a parameter  using the jeffreys prior  <cit> . in additional file  <dig> we compare these two cases and show that it may be disadvantageous to prescribe σ. we recommend that unless we are sure of the noise level associated with our data, σ should be inferred.

alternative measures may be used to include relevant data points for which the microbial concentration is too low to be detected by the given experimental method. depending on the sensitivity of the method used when collecting the data, the threshold below which values were considered undetected was taken to be either  <dig>  or  <dig>  on the log10x scale. for these values, rather than using the log-likelihood function , the probability was assigned by the uniform distribution between zero and the threshold, and zero above the threshold . in this way, we may account for a lack of knowledge  regarding the position of these points below the threshold and an absolute certainty that these points do not lie above the threshold.

the prior
we start by assuming a uniform prior probability , reflecting a lack of prior information for all parameters. in the case that we have prior knowledge available that we wish to take into account, we can use an appropriate prior distribution. in this paper we have used a gaussian or cauchy prior  to capture existing knowledge of the growth rate parameter. the informative gaussian prior is the usual candidate for expressing definite prior information about a variable  <cit> . the weakly informative cauchy distribution likewise encompasses a high probability region defined by prior information, but assigns more weight to values outside of this region, and so may be used when our prior information is less definite  <cit> . by making use of these three priors, we may decide whether to use clusters of pre-analysed growth curves as prior knowledge  and to account for the strength of a given cluster and our confidence in its relevance . a more detailed comparison and discussion on the choice of prior is given in the results section.

calculation of the evidence
in eq.  <dig> the evidence is essentially a normalisation factor and can be obtained through marginalisation by integrating over the parameters, 
  z=∫pℒπdp. 

this integral may be obtained using nested sampling. following references  <cit>  and  <cit> , we transform  into a one-dimensional integral over likelihood space. denoting the elements of prior mass as dx=πdp, we let x denote the proportion of the prior with likelihood greater than λ, so that 
  x=∫ℒ>λπdp. 

using this terminology, we may re-write  as 
  z=∫01ℒdx, 

where ℒ)≡λ. the algorithm preserves an active set of n objects p <dig> …,pn sampled across the prior. at each step the objects are sorted according to their calculated likelihood, the object with lowest likelihood  removed and a new sample point generated subject to the constraint ℒ>ℒ∗. this process is repeated until termination, moving the objects up the likelihood gradient to regions of higher likelihood, even if these regions become disconnected in parameter space. for a detailed description of the choice of all control parameters used during the process, see additional file  <dig> 

using the generated samples, the integral  can be approximated numerically by 
  z≈∑k=1nhkℒk, 

where hk=xk−1−xk is the width between successive sample points  and n is the total number of samples . summary statistics of the posterior distribution are also readily available. for example given a parameter, p, with sequence of samples, pk, each with associated weight, wk=hkℒk/z, the mean and standard deviation are given by 
 mean=∑k=1nwkpk,sd=∑k=1nwkpk2−mean <dig> / <dig> 

markov chain monte carlo methods produce samples from parameter space that are equally weighted and hence can be used to gain an understanding of the underlying posterior distribution. the same is possible with nested sampling; staircase sampling can be used to generate a number of equally-weighted posterior samples  <cit> . we make use of this technique to explore the posterior trajectories of inferred bacterial growth curves following analysis.

model comparison using bayesian analysis
given the evidence, bayesian analysis also provides a framework for model comparison. again making use of bayes’ theorem, we can write the posterior probability of some model or hypothesis given the data as 
  p=ppp. 

given two such models or hypotheses, h <dig> and h <dig>  to describe the same data, their respective posterior probabilities can be divided to obtain the ratio 
  pp=pppp, 

and assuming equal prior probabilities for the hypotheses =p), 
  pp=pp=z1z2=ℬ <dig>  

the ratio of evidences z1/z <dig> is known as the bayes factor and provides a metric for model comparison  <cit> . jeffreys’ scale  <cit>  provides a useful qualitative tool for interpretation of this factor ), as shown in table  <dig>  the table shows the grading of decisiveness of evidence to support or reject the hypothesis h <dig>  if the log-bayes factor is negative it can trivially be reversed to provide evidence against the competing hypothesis. it should be noted that in contrast to null hypothesis significance testing  the bayes factor provides the ability to rank hypotheses.

2lnℬ12


this model comparison framework is a useful and versatile tool. in additional file  <dig> we consider the application to bacterial growth model comparison. in this paper, however we focus on the application to the comparison of growth rates for a single model.

hypothesis testing to compare growth rates between two curves
as mentioned in the introduction, different bacterial strains or changes in the environment can result in different characteristic growth rates. given two growth curves, therefore, it is often of great interest to determine whether the two growth rates are significantly different. we compute the evidence and posterior probability for each of three possible hypotheses to describe a pair of curves. in the first hypothesis  the two curves are replicates and the same set of parameters can be used to describe each, in the second  the two curves have the same growth rate but differ in all other parameters and in the third  the curves share no common parameters. in all three cases both curves are fitted using the growth model of eqs.  <dig> and  and the likelihood function is given by combining the individual likelihoods for the two curves . the individual hypotheses may then be compared using bayes factor and the results interpreted using jeffreys’ scale. this gives us a standardised scale of confidence in which to place results and allows us to consistently decide how many parameters are necessary to describe the two curves.

in order to compare to a traditional statistical testing method, we perform a similar analysis on the two datasets using an f-test. we test using two different models. in the separated model, optimisation is used to fit the growth model to the two datasets separately. in the unified model, optimisation is performed on the combined dataset such that the model is fitted independently for each dataset, but the same growth rate is used for both. the null hypothesis is given by the statement the two curves have the same growth rate. the f-test statistic is given by 
  f=∑i=1n1+n2yiu−yis2∑i=1n1+n2di−yis2/, 

where the two datasets have n <dig> and n <dig> data points respectively, di is the y component of the i-th data point and yis and yiu denote the y value obtained by applying the separated and unified models respectively using the t component of the i-th data point. here the first degree of freedom is given by the difference between the number of parameters in the separated and combined models and the second degree of freedom by the difference between the total number of data points and the number of parameters in the combined model. the null distribution of the test statistic is the f-distribution and for each calculated statistic there is an associated probability density value. a commonly used threshold for the probability density value is  <dig>   <cit> , below which the null hypothesis is rejected. in this case the difference in growth rate between the two growth curves is considered to be significant.

implementation
all results in the following sections were computed using our implementation of the above methods, bayesfit and bayescompare; the former may be used for inferring the parameters of the model for a single growth curve and the latter for the detection of differences in growth rate . both provide the means to incorporate prior knowledge as part of the analysis and allow for the use of a range of growth models . we have made these functions available as part of the r package babar . details and examples regarding the functionality of the package are available online as part of the cran documentation. additional analysis and production of plots were performed using r   <cit>  and additional packages, ape  <cit> , gridbase  <cit> , corrplot  <cit> , plyr  <cit>  and ggplot <dig>  <cit> .

RESULTS
the growth rate is more precisely defined than the lag time associated parameter
plots from our analysis show that the marginal posterior distribution is approximately unimodal for all parameters  and can be represented, for the sake of comparison, by the means and variances of posterior samples . further, when using nested sampling to infer the parameters of a test curve, the correspondence with actual  parameter values is found to be good , as is the accuracy of the inferred noise level, σi .

through calculation of the coefficient of variation for all parameters over the combase database, the growth parameter, μmax, is found to be more constrained by the data than the lag time associated parameter, h <dig> . this observation agrees with the work of others in the literature, where the growth rate has been found to be characteristic of the bacteria  <cit> , whilst h <dig> has been found to be the least constrained by the data and therefore the most difficult to infer accurately  <cit> . given that the minimum and maximum bacterial concentration parameters, y <dig> and ymax, are largely influenced by experimental conditions , this also lends evidence towards the hypothesis that the growth rate is the most important parameter for the purposes of meaningful curve comparison.
fig.  <dig> the inferred growth rate, μ
max, is more precisely defined than the lag time associated h
 <dig>  boxplots for the coefficient of variation  for all parameters, calculated from the results of performing the bayesian analysis using the  <dig> parameter model of baranyi and roberts over the entire database of growth curves from the combase database. here the noise level, σ, is inferred for each curve. whiskers show the minimum and maximum of the results in each case. over the database, we find that the inferred growth rate, μ
max, is the most precisely defined when comparing to h
0=λ
μ
max 



it must be noted, however, that the degree of accuracy of any parameter is subject to the quality of data. for example, we can expect that in the case that we have ample data based around the growth region, our inference of the growth rate will be more accurate than in the case that we only have sparse measurements. in the latter case, the increased uncertainty will naturally result in less tightly constrained behaviour in terms of the inferred growth dynamics. this kind of difference in behaviour is captured as part of our analysis and reflected in the inferred parameter variances .

the bayes factor can be used to reliably detect differences in growth rate
the bayes factor allows us to compare differences in the growth rate parameter, μmax. figure  <dig> shows that the difference in growth rate that may be detected depends on the quality of the experimental data. here a perturbation analysis is performed by comparing two curves as the difference in growth rate between the two increases. following the methods definition of hypotheses  <dig> to  <dig>  the evidence is obtainined for hypothesis  <dig>  versus hypothesis  <dig> . during the analysis, two test curves  are generated, the first of which is fixed with growth rate  <dig> , and the second of which has a growth rate which may be varied. the analysis is repeated n times for each difference in growth rate and the second curve is computationally re-generated for each repeat, so that the n resulting curves can be thought of as replicates, each with different random noise associated. the mean and standard deviation of the bayes factor is calculated from the n repeats and this information, together with the known variance of the bayes factor from figure s <dig> in additional file  <dig>  can be used to illustrate the effect of lack of information on our analysis. we examine the effect of different noise levels, σ, datasets with different numbers of data points and different numbers of replicates. unsurprisingly, the greater the amount and the better the quality of experimental data, the smaller the difference in growth rate that can be detected.
fig.  <dig> the difference in growth rate that can be detected is data-dependent. the results of comparing two curves and calculating the log bayes factor, lnℬ <dig>  for hypothesis  <dig>  versus hypothesis  <dig>  as the difference in growth rate, Δ
μ
max, between the two is increased. here, the first curve is fixed, whilst the growth rate for the second is increased and n replicates with computationally random noise  are generated for each difference in growth rate. the solid lines and shading represent the mean and standard deviation respectively for each case. the dashed line represents the line below which we favour hypothesis  <dig> over hypothesis  <dig> based on jeffreys’ scale. the effect of using curves with different numbers of points and noise levels is explored, as well as using different numbers of replicates



given the above findings, it is interesting to see how bayesian analysis compares to traditional statistical testing methods under similar conditions. figure  <dig> shows a comparison between the results of testing using the f-test described in the methods section and testing using bayes factors. we consider the outcome of each testing method for two curves with and without the same growth rate at various different noise levels. here, similarly to above, the first curve is fixed whilst the second is computationally regenerated  <dig> times for each noise level, resulting in  <dig> replicate curves each with different random noise. initially, we consider the results when we use a uniform  prior and find that bayesian analysis produces more consistent results across the range of noise levels and correctly predicts equal growth rates more often than the f-test. the improvement in detection is more noticeable at larger noise levels , since by using bayesian analysis we may account for the noise level, σ. the same is true when the two growth rates are different; at larger noise levels there is a higher percentage of occurrences of correct detection when using bayesian analysis with a uniform prior. for a few of the smaller noise levels, however, the f-test correctly predicts a difference in growth rate more often. therefore, we next examine the effect of incorporating prior knowledge in our analysis to see if this provides a means to improve the overall level of detection.
fig.  <dig> bayes factor performs more consistently than an f-test when comparing growth rates. the results of using both an f-test  and bayes factors  on the same data to test whether two curves with  <dig> points have equal or different growth rates. we test two differences in growth rate, Δ
μ
max. the first curve is fixed, whilst for the second curve,  <dig> computationally random replicates are generated for each noise level σ
l. for the bayesian analysis, growth rates are considered to be different if there is substantial evidence for this  over equal growth rates . we also perform the analysis using prior knowledge  for both curves. here we make use of both the gaussian and cauchy priors and note that in the right hand plot the two are indistinguishable. detection when using bayes factors may be further improved by incorporating prior knowledge



prior knowledge can be used to improve detection of differences in growth rate
bayes’ theorem provides a framework to make use of existing experimental knowledge through the use of the prior probability. in the following we evaluate whether making use of such knowledge can further improve our results with regards to growth rate comparison.

after running the bayesian analysis over the large dataset of growth curves available at combase, an overall correlation of  <dig>  was found between the recorded temperature and the estimated growth rate . due to the expected dependence of growth rate on bacterial species, it is reasonable to expect this correlation to be stronger when filtering by bacterial organism. indeed, this is the case. for example, the  <dig> curves that were recorded at ph values of between  <dig> and  <dig>  for the organism salmonella spp. had a high correlation of  <dig>  between temperature and growth rate .
fig.  <dig> correlations between temperature and growth rate may be used to build clusters of growth curves.  growth curves for the organism salmonella spp. recorded at ph values of between  <dig> and  <dig>  show a strong correlation  between their estimated growth rate and the temperature conditions in which they were grown.  clustering by temperature reveals clear grouping and when coloured by estimated growth rate this is well maintained. clusters in the tree are labelled by temperature and the leaves coloured by growth rate. colours are the same in both the top and bottom plots . these clusters can therefore be used to give prior knowledge for improved parameter estimation



we next investigate whether such a correlation may be used to build clusters of growth curves which could pre-inform priors for improved parameter estimation. the bottom panel of fig.  <dig> shows the results of clustering the above-mentioned  <dig> curves by temperature, and colouring according to the inferred growth rate from our initial analysis. here we use the r function, hclust, to perform average linkage hierarchical clustering, taking euclidean distance as a metric. we see a good correspondence between the temperature clusters and their estimated growth rates, and similarly, when instead clustering by growth rate and colouring by temperature . this suggests that such clusters could be exploited to inform the prior for the growth rate parameter. this in turn may lead to improved parameter estimation for a new growth curve under similar conditions.

given justification in the methods section, we build informative gaussian or cauchy priors using the inferred means, μi, and variances, σi <dig>  of growth rates from n previously analysed curves in a cluster. the overall mean and variance, μcluster and σcluster <dig>  for the growth rate are calculated using 
  μcluster=∑i=1nμin, 

  σcluster2=∑i=1nμi2n−∑i=1nμin2+∑i=1nσi2n, 

where the variance is calculated using the law of total variance  <cit> . these values are then used in the prior .
fig.  <dig> the highest ranked prior depends on closeness of growth rate to the growth rate cluster. given two clusters of four simulated curves with parameters inferred by nested sampling, we plot the evidence, logz, for analysing a new curve using a uniform , gaussian  and cauchy  prior as a function of position in-between the two clusters . in the case of the gaussian or cauchy priors, the solid lines indicate that cluster a has been used for prior knowledge, whilst dashed lines indicate that cluster b has been used. data sets from cluster a had growth rates between  <dig>  and  <dig>  and cluster b had rates between  <dig>  and  <dig> . choosing a gaussian prior is appropriate when the target growth curve is near to the cluster, but loses evidence as curves become more dissimilar from their cluster. the cauchy prior can alleviate this to some extent, whilst the uniform prior has little change across growth rates



the improvement in parameter estimation when correctly using prior knowledge is found to be useful when comparing growth curves, as more precise estimation of parameters allows better detection of differences in growth rate. we return to the analysis of the previous section and fig.  <dig> and find that when making appropriate use of clusters during hypothesis comparison, there is a general improvement in the percentage of occurrences of correct detection for a difference in growth rates. due to this, the incorporation of prior knowledge results in a higher percentage of correct prediction than for the f-test in almost every case. as mentioned previously, this improvement is more noticeable for noisy data, where we may see up to a  <dig> % increase in correct prediction. when the growth rates are the same, it may be better to use a uniform prior. since in practice we do not know how similar the growth rates are, these results suggest running the analysis both with and without prior knowledge and looking at the evidence value for the most appropriate prior choice in each case. in fig.  <dig>  we show an example of the application of these techniques to curves from the combase dataset. here, we consider two clusters, each at a given temperature and ph value, and illustrate the subtle differences in growth rate that may be detected when comparing two curves, one from each cluster, using the rest of the curves as prior knowledge. in particular, whilst the difference between the two curves is too small to be deemed significant when using an f-test, for the bayesian analysis a large proportion of the evidence supports the curves having different growth rates. this shows that we are able to attribute statistical significance to differences that are too small to be detected by an f-test.
fig.  <dig> using prior knowledge we can attribute significance to subtle differences in growth rate. we take escherichia coli data from combase and use bayes factors to compare the curve ecbook16_22_c  with a curve with subtly different growth rate, ecgb_20_b , collected at a slightly different temperature and ph. the noise level, σ, is inferred and for each curve, we use prior knowledge from a cluster of previously analysed curves , measured at the same temperature and ph. growth rates are considered to be different if there is substantial evidence for this  over equal growth rates . due to the variability in the stochastic algorithm, we compute the bayes factor, b
 <dig>  for  <dig> runs  and compute the mean and standard deviation . whilst the outcome of testing differences using an f-test is to accept the null hypotheses that the two curves have the same growth rate, a large proportion of runs for the bayesian analysis result in the detection of a difference in growth rate



these results are encouraging and point to the importance of methods, such as bayesian analysis, which fully take into account both the quality of data and prior experimental knowledge when comparing growth rates between microbial response curves. using bayesian analysis we can improve on both the consistency and level of detection in our analysis, as well as answering the growing need to standardise statistical testing within a well-defined framework.

CONCLUSIONS
given the abundance of information available in many cases for bacterial response under differing environmental conditions, it is an appealing idea to use existing measurements to build a local model of environment space which may be used to address the challenging problem of detecting small differences in growth rate. we have shown that using bayesian techniques we can consistently detect such differences. these techniques make use of the evidence and the bayes factor as tools for ranking hypotheses. by taking into account prior knowledge through clusters of previous results under similar conditions and also by estimating the noise level of the data as part of the analysis, more subtle differences in growth rate may be shown to be significant. such differences may be missed by traditional statistical testing methods such as an f-test.

when using clusters of results as prior information, however, we highlight that one should be careful that the given cluster is relevant to the curve to be analysed, so as not to obtain to misleading results. this should involve taking into account both how close the environmental conditions of the new curve are to that of the cluster and how tightly-defined the cluster itself is. a tightly-defined cluster that is a distance away from the new curve is likely to have a detrimental effect on the results. this is especially true when using the highly informative gaussian prior. if it is suspected that this is the case, we recommend performing the analysis with both a uniform and gaussian or cauchy prior, in which case the evidence should be examined for the most appropriate choice. in some cases, it may be possible to combine clusters of results to form a more relevant but broader gaussian or cauchy prior.

we have also shown that the same framework can easily be used for model comparison . indeed, in general, the evidence and bayes factor are useful tools for conclusively testing hypotheses and models. we advocate the evidence as an alternative tool to traditional statistical testing methods and goodness of fit measurements in general.

there is scope for wider application of the techniques developed in this paper. the same methods may be used to analyse assays of bacterial growth in plants after, for example, spray inoculation. here, it would be important to take into account lack of information since frequently only a small number of bacterial concentration measurements are collected. optical density measurements also often lead to growth curves, which may be analysed by fitting to mathematical models such as those we have discussed  <cit> . although the present study has been restricted to bacterial growth curves, it is also possible to use the same techniques to analyse survival curves, for which there is a rich history of model development . further, the techniques presented in this paper can be applied outside of the field of microbial response entirely. accurate measurement and comparison of the rate of some quantity is needed in many areas of chemistry and biology. for example, the study of enzyme kinetics requires completion of enzyme assays which measure, for instance, the change in substrate or product concentration over time in order to calculate a reaction rate. the many models available for mathematical analysis of population dynamics also lend themselves to analysis using the methods we have described. another candidate for analysis is the estimation of real-time polymerase chain reaction curves using fluorescent reporters, for which the familiar phases of lag, growth and saturation can be observed  <cit> . in fact, many systems show a sigmoidal growth behaviour, introduced due to a combination of damping or disturbing factors that result in a levelling off of the rate for very small or large times, and could be analysed and compared using the models and techniques in this paper.

in the analysis of both bacterial growth curves and other systems showing similar growth behaviour, the growth rate is often the primary parameter of interest and other parameters may be thought of as noise since they are not strictly required as output. here, it may make more sense to integrate out these “nuisance parameters” prior to the analysis  <cit> . not only would this focus all efforts on accurate estimation of the rate, but, theoretically, it should also speed up the computation time. however, given the structure of models such as that defined by eqs.  <dig> and  <dig>  calculation of the likelihood function is likely to require numerical integration, which may in fact slow down the computation. it would be interesting, nevertheless, to determine whether such techniques could further improve detection of differences in growth rate.

availability of supporting data
the combase dataset is publicly available from http://www.combase.cc/.

additional file
additional file  <dig> 
contains: material on our choice of control parameters in the analysis, an illustration of performing model comparison using the same framework and supplementary figures and tables. 



competing interests

the authors declare that they have no competing interests.

authors’ contributions

lmr contributed results and figures, wrote package code, wrote the manuscript. np contributed results and figures, wrote nested sampling code, edited the manuscript. mh wrote nested sampling code, put package on cran. cz, sk participated in project design. jb provided combase data and growth curve models, participated in project design and coordination, edited the manuscript. rjm supervised the project, participated in project design, edited the manuscript. all authors read and approved the final manuscript.

