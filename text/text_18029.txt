BACKGROUND
the advent of the technology of dna microarrays constitutes an epochal change in the study, treatment, analysis, classification and discovery of different types of cancer. it is well understood that cancer classification is a crucial step for cancer diagnosis and treatment  <cit> . conventional classification of cancer has been based primarily on examination of the morphological appearance of tissue specimens, but this method suffers of serious limitations. it is subjective and depends on highly trained pathologists. moreover, tumors with similar histopathological appearances can follow different clinical courses and show different responses to therapy  <cit> . the information provided by dna microarrays allows to approach the problem of cancer diagnosis and treatment from a quantitative rather than qualitative point of view. the importance of the information embedded in gene expression data provided by dna microarrays for identifying new cancer classes and for automatically classifying tumors to known classes was firstly pointed out by golub in  <cit> . in tumor classification, the problem is to assign a label y, for example normal or cancerous tissue, to a new gene expression pattern x, starting from the knowledge of ℓ examples s = {, ,...} whose association between the gene expression pattern xi and its relative class label yi is known in advance. here x is a vector whose components indicate the gene expression levels provided by a dna microarray. under this perspective, the problem of cancer classification can be seen as a supervised learning problem, or a learning from examples problem  <cit> , in which the goal is to determine a separating surface, optimal under certain conditions, which is able to discriminate normal from cancer tissues, or to distinguish among different types of tumors. in this paper we focus only on two class classification problems, since multi-class problems can be seen as a straightforward generalization of two-class problems. before introducing the main aspects of our work, it is worth to point out that the ultimate goal of any classifier, and in general of any learning machine, is to generalize, that is to predict the correct output y relative to never seen before input patterns x, by using a training set s composed of a finite number of examples. thus the central problem is not classifying the training data in s, because any sufficiently complex learning machine could separate s without errors. the crucial problem is to design classifiers having low error rate on new data. in the context of classification of dna microarrays, such a problem is even more challenging because typically the number of examples is relatively small and the dimensionality, i.e. the number of genes whose expression levels are measured, is very large.

statistical learning theory  <cit>  provides a valuable non asymptotic theory for asking questions about the accuracy of models built when a limited amount of data is available. in this general framework, support vector machine  classifiers provide excellent performances in terms of generalization error in different application domains such as object detection in images  <cit> , odor classification  <cit> , pedestrian detection  <cit> , etc. in particular, in the context of cancer classification from gene expression data it outperforms many well known approaches  <cit>  and it has to be considered as the method of reference for evaluating new techniques. the basic idea of statistical learning theory is very simple: for a finite set of training examples, the search for the best model or approximating function has to be constrained by an appropriately small hypothesis space, that is the set of functions the machine implements. if the space is too large, functions can be found which fit exactly the data, but they will have poor generalization capabilities on new data. svm implements such an idea determining the classifier minimizing both the error on the training set  and the complexity of the hypothesis space.

another approach to classification and in general to the problem of approximating a multivariate function from sparse data and in the presence of noise is regularization theory  <cit> . also in this framework we need to constraint the hypothesis space for finding a suitable approximating function from a finite number of training examples. such a constraint takes the form of a smoothness functional measuring the complexity of functions belonging to the chosen hypothesis space. in this general framework, regularized least-squares  classifiers  <cit>  provide a highly viable alternative to svms because they enjoy a number of suitable properties such as simplicity and reliability.

a first comparison between svm and rls classifiers can be found in  <cit> . in their analysis, the authors used very simple bench-mark data sets having characteristics very different from the ones relative to the cancer classification problem by gene expression data. in fact, they used data sets having a ratio between number of examples and number of components ranging from  <dig>  for the sonar data set to  <dig> for the pima indian data set. such ratios are very far from the ratio of order of 1/ <dig> that is typical for the problem we are considering here. so from their study we can not infer any consequence about the performances of the rls classifiers on the problem at hand. in this paper we compare svm and rls classifiers for the specific problem of cancer classification by gene expression data. in the context of supervised learning models, as the ones we are considering here, particularly important is the quantity to measure for comparing two machines. we know that two machines have similar performances if their generalization errors are comparable. as we will show in the next sections  <cit> , a measure of the generalization error of any supervised learning machine is the risk and so models showing the same risk have comparable performances. however, the risk functional, as usually defined, has not a practical usefulness because it involves the knowledge of the probability distribution function underlying the data that is in general unknown. nevertheless, we can adopt the leave-one-out  procedure which uses the available data for evaluating the generalization error of a machine. in fact, as the luntz and brailovsky theorem shows  <cit> , the loo error is an almost unbiased estimator of the risk and so it is a practical procedure for assessing the performances of a supervised learning machine from a finite number of data. based on this estimator we show that rls and svm models have similar generalization abilities. the comparison involved three different data sets described in  <cit> . the experimental results suggest that we can benefit of the simplicity of rls machines maintaining the same prediction error of svm. the main advantage of rls machines is that for solving a classification problem we need to solve a single linear system of order equal to either the number of features or the number of training examples. this is in contrast to svm approach which requires the solution of a quadratic programming problem with linear constraints. moreover and more important, rls machines allow to get an exact measure of the leave-one-out error with just one training. in the case of svm, such important measure requires the training of a number of machines equal to the number of training examples. at the aim of fully assessing both the classification models, we analyze their performances with respect to the number of genes, selected with different gene selection strategies. note that the focus here is not on the determination of the optimal number of genes for classifying tissues belonging to a given tumor class. for this reason others and more sophisticated methodologies have to be adopted which take into account the bias selection problem  <cit> . here we want to show that both models have comparable performances even when a very few number of genes is used for classifying. following the statistical approach outlined by golub and its co-workers in  <cit> , we adopt non-parametric permutation tests for studying how many and what genes have to be used for classifying. the problem of identifying the gene signature concerning a particular type of cancer is out of the scope of the present work.

methods
classification models
due to the particular problem of cancer classification from gene expression data in which we have a small number of training examples, each one with very large dimensionality, we limit our attention to linear classifiers. nevertheless the methods we are going to illustrate can be easily generalized for designing non-linear classifiers.

we are given a training set  of size ℓ where xi ∊ ℝn and yi ∊ {- <dig> }, for i =  <dig> ,...,ℓ. in the simplest case of linearly separable set s, the classification problem consists of determining a hyperplane w·x + b =  <dig>  where w ∊ ℝn and b ∊ ℝ, such that: yi = sign for i =  <dig> ,...,ℓ, where sign  is  <dig> if x ≥  <dig> and - <dig> otherwise. actually, classification is an ill-posed problem  <cit>  because an infinite number of solution exist and then some constraint has to be imposed to the problem for making the solution unique.

svm classification
the constraint imposed by svm on the classification problem is the following: the solution has to maximize the distances with the closest points of s. the optimal separating hyperplane found by svm, in the case of linearly separable set s, is the one maximizing the margin m, where m = 2/||w|| is the distance between the hyperplane and the closest points of s. in the general hypothesis of non linearly separable classes, the optimal separating hyperplane w*·x + b* =  <dig> found by svm is solution of the following quadratic programming  problem p <dig> with linear constraints:



where d is a matrix of size ℓ × ℓ, with dij = yiyjxi·xj for i,j =  <dig>   <dig>  ...,ℓ and λ = ⊤ is a vector of ℓ non negative lagrange multipliers. the regularization parameter c is the only free parameter and its value can be chosen by using cross validation. let λ* be the solution of the considered problem p <dig>  so the optimal w* is:



and the optimal b* is given by:

b* = yi - w*·xi     

for each i such that  <dig> < <c. the points xi with  >  <dig> live on the margin of the classes and they are called support vectors. the classification of a new data x involves the evaluation of the decision function:

y = sign)     

where:



rls classification
rls models  <cit>  were proposed mainly for facing regression problems. the main difference between a regression and classification problem is that in the former the output variable y can assume any real value; in the latter, it can assume a finite number of possible values. in our case, y assumes only two values {- <dig> }. this means that every classification problem can be considered as a regression problem. in the case of linear regression, we want to determine the function f = w·x, with w ∊ ℝn, which approximates the examples in s in the least squares sense. this is equivalent to solving the following constrained minimization problem p2:



subject to ||w|| <dig> ≤ α

where α ∊ ℝ and ||w|| =  is the euclidean norm induced by the scalar product ·. note that the bias term is implicitly present in our model by including a component constant and equal to one to the input vectors. before solving the problem p <dig>  some considerations are in order. the objective function that we minimize, in this particular case, takes the form of the mean square error of the predictor y = w·x evaluated on the training data. here the error is expressed as the square deviation, εi =  <dig>  between the target value yi and the value of the predictor w·xi. let di be the square distance between the generic input data xi and the approximating hyperplane y = w·x, where by definition:



this equation shows that the smaller ||w|| <dig>  the better the deviation εi approximates the true distance di. this is the reason why we introduce the constraint ||w|| <dig> ≤ α. in this way the optimal approximating hyperplane solution of the constrained problem is the hyperplane minimizing the mean square distance with the training points. for determining w ∊ ℝn solution of p <dig>  let us consider the lagrangian function:



the vector w minimizing  is solution of the following linear system of order n:

 w = xy     

where x is a n × ℓ matrix having the examples xi as its columns, y = ⊤ and in is the n × n identity matrix. note that, since the matrix xx⊤ is positive semidefinite, then for λ >  <dig> the matrix xx⊤ + λℓin is definite positive and therefore invertible. then the vector w* solution of the problem p <dig> exists and it is given by:

w* = -1xy     

it is possible to show that the value of λ controls the influence of the noise present in the data on the estimation of the solution w*. the parameter λ, called regularization parameter, is the only free parameter and its value can be chosen by using cross validation. analogously to svm, the classification of a new data x involves the evaluation of the decision function:

y = sign     

as equation  shows, determining w* requires the solution of a linear system of n order, where n is the number of components of each xi. in some cases n could be extremely large and so any direct method can be adopted for estimating w*. this occurs in the problem at hand where the number of genes n of each specimen is order of tens of thousand and the number ℓ of specimens is order of ten or hundred. we will show that the models we are describing allow to rewrite a linear system of n order as a linear system of ℓ order, overcoming the difficulties connected to problems with a huge number of features. at this aim, let us suppose w to be expressed as linear combination of the vectors xi for i =  <dig> , ...,ℓ. this means that there exist ℓ coefficients c = ⊤ such that:

w = xc     

substituting  in  we have:

 c = y     

where k = x⊤x is a ℓ × ℓ matrix with generic element kij = xi·xj and iℓ is the identity matrix of ℓ order. also in this case, since k is a positive semidefinite matrix, then for λ >  <dig> the matrix k + λℓiℓ is positive definite and so invertible. then the vector c* ∊ ℝl solution of  is given by:

c* = -1y     

obtained by solving a linear system of ℓ order. note that the normal w* to the optimal approximating hyperplane can be recovered by using . in this case the classification of a new data x involves the evaluation of the decision function:



comparison between svm and rls classifiers
numerous differences exist between these two classification models, but we will only mention some of these which are relevant for our discussion. the first difference consists in the method employed for determining the optimal w. svm requires the solution of a qp problem with linear constraints of order ℓ, while rls requires the solution of a system of linear equation of order ℓ or n. in the former, the complexity in solving problem p <dig> is independent of n. moreover, when the number ℓ of examples is extremely large, decomposition methods can be applied for determining the exact solution  <cit> . in the latter, the complexity depends on ℓ and n. when both these quantities assume large values, iterative schemes have to be adopted for solving the system  or , so providing only approximated solutions.

the second difference consists in the representation of the optimal w. in svm ), the solution is sparse meaning that it is expressed as linear combination of a fraction of the training examples . in rls ), on the contrary, the solution is dense meaning that it is expressed as linear combination of all training examples.

leave-one-out error
as we have already said in the introduction, the ultimate goal of a supervised learning machine y = f  is to generalize, that is to correctly predict the output y corresponding to never seen before input patterns x. here α is a parameter vector which the machine depends on, for example c in svm and λ in rls classifiers. then a comparison between different classification models has to involve the comparison of their generalization errors. a measure of the generalization error of such a machine f is the risk r defined as the expected value of the loss function v) :

r = ∫v)pdxdy     

where p is the probability density function underlying the data. the particular form of the loss function depends on the problem at hand. in classification problems, the loss takes the form of:



in general the probability density function p is unknown and so we are not able to evaluate the risk. the only data we have are ℓ observations   of the random variables x and y drawn according to p. the leave-one-out  error provides a measure of the generalization error of a learning machine by using the ℓ observations in s. in fact, as the luntz and brailovsky theorem shows  <cit> , the loo error is an almost unbiased estimator of the risk  and it allows of assessing the performances of a supervised learning machine from a finite number of data. the computation of the loo error is very simple. for every i =  <dig>   <dig>  ..., ℓ, let  be the machine trained on the set si = {,...,, ,...,} obtained from s removing the i-th example. test the function  on the left out example  and measure the value of the loss function v). repeat this procedure for each of the ℓ examples of the training set and sum the errors made. this number is the loo error:



note that  is the quantity that we have to compute for measuring the performances of any supervised learning machine, because it provides an estimate of the risk or generalization error associated to the selected machine. moreover, this is the procedure of choice for estimating the unknown parameter vector α which the machine depends on. in fact, for a fixed training set, the generalization error of the machine is a function of α. then, the best parameter vector α* will be the one minimizing .

loo-error for rls classifiers
although the loo error enjoys several interesting properties, its computation is tremendously expensive because it requires of training a number of machines equal to the number of training examples. in the case of rls classifiers, the loo error can be calculated in an exact way just training a single machine by using all the training examples. in fact it can be showed  <cit>  that:



where fs is the machine trained on s and g = - <dig>  this is a fundamental property of the rls classifiers because it allows to evaluate the generalization ability of a classifier without any additional cost.

gene selection
a very important question in cancer classification problem is determining which genes are the most relevant in identifying a specimen or a particular disease. this is an open problem, relevant for several reasons both biological and computational. finding genes which expression levels correlate with a particular disease is important for understanding the disease and for choosing the most appropriate treatment. furthermore, classifying a specimen on the basis on few expression levels could in principle improve the performances of the classifier, eliminating the noise associated to irrelevant genes. gene selection is a particular instance of a more general problem known in machine learning as feature selection. in general, the methods for selecting features can be grouped in two main categories: filter methods and wrapper methods  <cit> . filter methods select features by using criteria independent of the ones used in the classification stage. wrapper methods, on the contrary, use the same or similar criteria as the ones used by the classifier. in this paper we focus on two different feature selection approaches. the first one  <cit> , known as signal-to-noise , is a filter method and it is based on the following statistic:



where j is the gene index. ,σ+1) and ,σ-1) are the mean and the standard deviation of the expression levels of the j-th gene in the positive and negative examples respectively. genes xj highly correlated with the class label or more relevant for classifying are expected to provide large values of |ts2n| the second approach we consider is a variant of recursive feature elimination  strategy proposed in  <cit> . it is a wrapper method and it is based on the following statistic:

tw = wj    j = l, <dig> ...,n     

where w is the normal of the optimal separating hyperplane found by svm or rls methods. the idea underlying this approach is very simple. we know that the label y associated to a new input x is given by . so, if the gene expression levels have similar ranges, genes having large values of |wj| are more important than others in determining the class label. instead of using a recursive approach for selecting the most relevant genes as suggested in  <cit> , we use a more greedy strategy consisting in training the machine one time only by using all the available genes and selecting the most informative features according to the obtained w. for this reason we call our approach not-rfe . in both strategies, the genes are ranked in decreasing order according to the selected statistic and the highest values correspond to the most relevant genes.

number of relevant genes
so far we have described two statistics for ranking genes based on their expression levels in both classes. now, in order to determine how many genes are really important for classifying a given specimen, we apply a common method in classical statistics named hypothesis testing . the idea is to hypothesize that there is no dependency between expression levels and class labels, and to consider relevant for the classification those genes which reject such hypothesis. at this aim, we define the null hypothesis h <dig> in which we assume that the random variables x and y are independent or equivalently that the class conditional probability density functions are identical. the goal of hypothesis test is to reject h <dig> at a given level of significance α, where α is the probability of rejecting the null hypothesis when it is true, that is of declaring that the x and y are uncorrelated when they are not. let t <dig> be the observed value of the statistic t as computed on the data set s, t <dig> = t, and let p <dig> = pt be the corresponding p-value, that is the probability that t is grater than or equal to t <dig>  note that pt is the distribution function of the random variable t under the null hypothesis. if p <dig> ≤ α then we reject h <dig> at level of significance α.

the application of the hypothesis testing method requires the knowledge of the density or distribution function of the adopted t statistic under the null hypothesis. when the density of the adopted statistic is unknown or when the data do not verify the hypotheses which the statistic is based on, then we have to the invoke nonparametric permutation tests  <cit> . this nonparametric technique allows to estimate the probability density function of any statistic, under the null hypothesis, from the available data. the reason which justifies this procedure for estimating the density pt is that under the null hypothesis, since the random variables x and y are independent, all the training set generated through permutations are equally likely to be observed.

RESULTS
data sets description
the above mentioned classification techniques have been applied to different cancer diagnosis problems. three benchmark data sets have been considered. the first one, named 'leukemia data set'  <cit> , concerns the classification of acute leukemias into acute myeloid leukemia  and acute lymphoblastic one . it consists of  <dig> bone marrow samples  obtained from acute leukemia patients at the time of diagnosis . these samples are used as training set. an additional set, composed of  <dig> aml and  <dig> all samples, is utilized to test the classifiers. each sample is a vector composed by  <dig> elements, each one corresponding to the log <dig> normalized expression value of a gene. this data set has been extensively analyzed in literature  <cit>  also by using machine learning techniques  <cit> . much more details about this data set and a complete breakdown of microarray composition can be found on the web site . the second data, named 'colon data set'  <cit> , regards the problem of classifying tumor and normal colon tissues. it is composed by  <dig> tumor and  <dig> normal colon tissue samples. each sample consists of  <dig> human gene expression levels. the data set and more detailed information on it are available on the web at site . the last analyzed data set is relative to the classification of different malignancies samples against normal tissue ones  <cit> , it will be identified as 'multi-cancer data set'. it is composed by  <dig> samples:  <dig> examples are relative to cancer tissues, spanning  <dig> common tumor types, the remaining  <dig> samples represent normal tissues. each example in this data set consists of the expression levels of  <dig> genes. complete details regarding patient samples, pathology, molecular biology protocols, data analysis and additional information are available at site . it is worth nothing that, in the present work, this data set is analyzed in order to perform a two-class classification problem .

results on the leukemia data set
first of all, we used all of  <dig> gene expression levels present in each specimen. we trained svm classifiers on the  <dig> samples in the training set for different values of c parameter, measuring for each one the empirical risk and the loo error given by equation . the training set is linearly separable and the loo error reaches its minimum value of  <dig>  in correspondence of c = 1e -  <dig>  then the best svm classifier on this training set is the one obtained with c = 1e -  <dig> because it is the machine minimizing the loo error. we tested such machine on the  <dig> points in the test set obtaining  <dig> error . the same results are reported in  <cit> , where the authors also noted that using svm with polynomial kernel functions did not improve the performances.

the same procedure was carried out by using rls machines. we trained rls classifiers on the training set for different values of λ parameter and for each one we measured the empirical risk and the loo error by using equation . the training set is linearly separable for each λ in the considered range. moreover, the loo error reaches its minimum value of  <dig>  in correspondence of λ =  <dig>  then the best rls classifier on this training set is the one obtained with λ =  <dig>  we tested such machine on the test set obtaining  <dig> error as reported in table  <dig> 

successively, in order to carry out a most accurate analysis and to have a most complete insight about the performances of svm and rls machines on this data set, we have computed the loo errors on the whole data set obtained putting together training and test examples. the values of the free parameters, corresponding to the best machines, are c =  <dig> and λ =  <dig> respectively. the loo errors obtained by the best machines are reported in table  <dig> where clearly results that svm and rls behave exactly the same. in order to understand the influence of irrelevant genes on the performances of the classifiers, we considered some subsets of features. we established the number of genes to select applying permutation tests to the data, by using ts2n and tw statistics. figure  <dig> depicts the values of ts2n statistic as computed on the actual data set and on randomly permuted class labels. the number of permutations of the labels was  <dig>  genes more highly expressed in all are shown in the left picture, and those more highly expressed in aml are shown in the right picture. the large number of genes highly correlated with the class distinction is clear from the picture. moreover, in both pictures, the curve of the observed statistic intersects the 5% curve about at  <dig> genes, indicating that in the data set there are  <dig> genes which reject h <dig> at significance level of α = 5%. then we ranked the genes according to the absolute value of ts2nand chose the top k genes, with k equal to  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> genes. a similar analysis has been effectuated by using tw statistic. here w was the parameter vector corresponding to the best rls classifier, that is the one minimizing the loo error on the current data set <dig>  as picture  <dig> shows, tw is unable to disclose the correlation existing between gene expression level and class label, as ts2n does. nevertheless, we equally measured the performances of svm and rls classifiers on genes selected by tw statistic. in fact, as noted in  <cit> , in some particular cases, some genes may be truly predictive of the class label despite the lack of statistical significance in permutation tests. at the aim of testing this experimental evidence, we ranked the genes according to the absolute value of tw and chose the top k genes, with k equal to  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> genes. in table  <dig> we report the performances of svm and rls classifiers obtained on the leukemia data set, for various number of genes selected by s2n and nrfe methods.

results on the colon data set
first of all note that in this case, as in the following data set, we do not have the distinction between training and test set, because we have a single data set. for this reason, we do not report the test error but the loo error only. we have primarily evaluated the performances of svm and rls classifiers on the colon data set by using all the gene expression levels present in each specimen, successively we have consider opportune subsets of genes. the experimental results on the whole and reduced data sets are summarized in table  <dig> 

the behavior of the empirical risk and of the loo error of svm and rls classifiers evaluated for different values of the regularization parameter are depicted in figure  <dig> for the whole colon data set. note that the data set is linearly separable. these plots give also a precious hint to fully understand the role of free parameters  by observing the empirical risk curves. in fact, increasing c in svm the empirical risk decreases, whereas increasing λ in rls the empirical risk increases. these behaviors of the empirical risk curves can be fully justified reminding that, in svm, the c parameter can be thought of as the cost the machine pays for each training error. on the contrary, in the rls machines, the same role is played by  .

in order to determine the number of relevant genes to be considered in the feature selection process, we have computed the ts2n statistic on the actual data set and in the hypothesis that h <dig> holds true. the number of label permutations was  <dig>  the observed statistic intersects the 5% curve in correspondence of  <dig>  so  <dig> is the maximum number of genes which reject the null hypothesis at significance level of 5%. then we ranked the genes according to the absolute value of ts2n and chose the top k genes, with k equal to  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> genes. a similar analysis has been effectuated by using tw statistic. also in this case, this statistic shows poor capacity of revealing the existing correlation in the data. as in the previous analysis, we ranked the genes according to the absolute value of tw and chose the top k genes, with k equal to  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> genes.

results on the multi-cancer data set
primarily, the  <dig> gene expression levels of each specimen have been used for classifying. the experimental results are summarized in table  <dig> 

the data set is linearly separable. the best svm corresponds to c =  <dig>  the best rls classifier corresponds to λ =  <dig> 

it is important to note that the errors obtained on this data set are much greater than the one achieved in the data sets previously analyzed, probably reflecting the large complexity of the data due to the great degree of biological variability in gene expressions.

the non parametric permutation test was carried on the multi-cancer data set, performing  <dig> random permutations of the class labels. the maximum number of genes which rejects the null hypothesis at significance level of 5% is  <dig>  then we ranked the genes according to the absolute value of ts2n and chose the top k genes, with k equal to  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> genes. the same numbers of genes were selected by using the tw statistic. the results on the reduced data sets are reported in table  <dig> 

discussion
some conclusions on the two classification algorithms can be drawn. the first and more important one is that, when the whole data sets are considered, both machines provide generalization errors comparable as the tables  <dig>   <dig> and  <dig> show. this indicates that rls approach is able to determine classifiers with good generalization ability even in the case of very small training set, with a huge number of features.

concerning the computational time, both techniques require a few seconds for determining the optimal classifier because, in the present context, the training involves only a few examples. the second consideration concerns the role of λ in rls machines. this parameter de-facto controls the generalization ability of the rls classifiers, exactly as c does in svm ones. the figure  <dig> depicting the behavior of the loo error shows this fact. we have observed similar behaviors of this quantity in all the experiments carried out which do not show for lack of space. moreover, our analysis shows that standard least-square machines, obtained setting λ =  <dig>  have very poor generalization abilities. in fact for λ =  <dig> all the considered rls classifiers separate correctly the training data, but they show a very large loo error. the main problem in machine learning is not to correctly classify the training data. the main problem is to generalize and rls classifiers guarantee high generalization ability for appropriate values of the regularization parameter λ.

the performances of svm and rls classifiers continue to be comparable even though the number of genes used for classifying a specimen is extremely reduced. tables  <dig>   <dig> and  <dig> confirm such a result. moreover, as noted in all three data set, also a statistic which is not able to reveal statistically significant differences in the data can however select genes which increase the performances of the classifier. this is not surprising. the fact that a gene is relevant for classifying a given specimen does not involve the statistic, it involves the classification process. so, a gene is relevant for a classifier if its usage reduces the generalization error of the classifier, as measured by the loo error. any gene selection strategy has to guarantee that the subset of genes selected is the most appropriate for the chosen classifier, that is it is the subset of features minimizing the loo error of the classifier. in this sense feature selection and parameter selection are two instances of the same problem which has as ultimate objective the one of reducing the generalization error of any learning machine.

CONCLUSIONS
in this paper we have shown that rls classifiers have performances comparable to the ones of svm classifiers for the problem of cancer classification by gene expression data. the comparison has been carried on measuring the leave-one-out errors relative to each classifier obtained on three different real data set. the classification performance analysis involved the whole set of genes as well as suitable subsets of genes selected by different gene selection strategies. our analysis suggests that rls classifiers are a valuable alternative to svm classifiers for the problem at hand due to their simplicity and low computational cost. moreover, rls classifiers show generalization errors comparable to the ones of svm classifiers also in the case the classification of new specimens involve very few gene expression levels.

list of abbreviations used
svm: support vector machines. rls: regularized least square. loo: leave one out.

note
1note that the tw statistic can be considered a filter method when the features it selects are input to svm classifiers, and a wrapper method when the features are input to rls classifiers.

