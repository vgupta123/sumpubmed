BACKGROUND
high-throughput sequencing  has become one of the most important tools in the arsenal of biomedical researchers in their quest for understanding the foundations of diseases with a strong genetic component like cancer  <cit> . sequencing technologies have significantly increased the amount of data produced by a single run of an instrument with their modern high-throughput versions producing more than 1tb in a single run. thus, in the case of the human genome, the scale of the sequencing experiments has been pushed into the realm of whole-exome  <cit> , whole transcriptome  <cit> , and even whole-genome studies  <cit> . the sheer volume of this data combined with the inherently random aspect of the sequencing process conspire to introduce uncertainties in the output of the experiments. furthermore, the intricate chemistry of the novel sequencing instruments often results in systematic errors, which can make artifacts indistinguishable from actual genetic lesions. although detecting such sources of non-random errors is an important part of analyzing the data produced by sequencing experiments, the purpose of this paper is to develop a framework for the correction of the random component in the noise introduced by the sequencers. furthermore, our goal is not to establish the biochemical sources of those errors, but to develop a statistical approach applicable in diverse scenarios in which the assumption about the random nature of the source of errors holds.

a major application of hts is to compare related samples, e.g. healthy vs. disease or various stages in the progression of a disease, based on their genetic makeup. many such examples are provided in cancer research, where identifying the genetic or epigenetic lesions that contribute to the oncongenic process is an important step towards better diagnosis, evaluation of prognosis, and treatment of the disease. thus hts has become a powerful unbiased approach to delineating the landscape of genetic alterations in different tumor types  <cit> . an often-applied technique involves identifying aberrant somatic alleles fixed in a population of cancer cells, which are absent from a control sample. the wisdom behind this technique is based soundly on the observation that the drivers of oncogenic processes are fixed by the clonal expansion  <cit> . from a more general perspective, and in addition to making a digital  present/absent call, one could strive for identifying the frequency of alleles in a given population of cells. the importance of this analysis to cancer research is immense since low frequency alleles can have a major contribution to the disease in later stages  <cit> , e.g. by conferring resistance to treatment. furthermore, detecting low frequency alleles at an early stage of the disease, and even before the disease has manifested itself, can be crucial for its prognosis.

the comparison of two temporally ordered samples with respect to the frequency of an allele could indicate either a gain or a loss of that allele. both of these alternatives could be the cause  or a consequence  of the biological process driving the phenotype. for example, a point mutation could inactivate the normal function of a tumor suppressor gene and lead to the formation of cells with a cancer phenotype . alternatively, the abnormal phenotype could be the result of a loss of heterozygosity . although, distinguishing driver from passenger alterations is an important part of the functional analysis of clonally expanding populations of cells, detecting such events regardless of their direction and relevance to the phenotype is the first step towards such analysis.

besides the clinical importance of diagnosing and treating cancer, having a detailed picture of the alleles present at different stages of the evolution of a population of cells is an important step towards understanding the intricate biological processes underlying its existence. several approaches have been used to identify the genetic alterations differentiating a set of related samples. some methods  <cit>  involve ad hoc thresholds on the number of reads reporting a variant allele, their quality and/or the total number of reads covering the position of the variant allele to produce a binary present/absent call for that variant. a comparison between different samples is then based on differences in those calls . arbitrary thresholds on the number of reads reporting a variant introduce biases due to the uneven distribution of depths along the genome. such methods can miss variants which have somewhat lower quality but high depth or lower depth, but high quality. furthermore, decisions based on a discretized view of the data depend strongly on the level of discretization and other parameters of the discretization process. this could be a problem if the samples being compared are not perfectly homogeneous, e.g. by contamination or the natural presence of tumor cells in the control sample. other methods  <cit>  assume allele distributions particular to a homogenous population of diploid genomes. similar to our approach, the algorithm snvmix  <cit>  uses a bayesian framework and is able to identify variants in samples with different ploidy and tumor cellularity. the algorithm employs an expectation-maximization for constructing a prior.

in this paper we present the statistical algorithm for variant frequency identification  developed in the course of analyzing data from sequencing experiments of cancer samples from nine hairy cell leukemia  patients and the corresponding paired normal samples. the initial findings are published in  <cit> . the algorithm is based on constructing bayesian posteriors distributions on allele frequencies and employs an iterative procedure for constructing an empirical prior from a given dataset. having posterior distributions lets us obtain a high credibility interval for the frequency of a particular allele as well as estimates on its expected and most likely value. in contrast to other applications of bayesian analysis to the problem of frequency estimation, our prior is not fixed to belong to a predetermined set that might not represent an accurate description of the data. our desire was to develop a method which is more empirically grounded and governed by the data itself as much as possible. with the advent of large datasets the significance of bayesian methods using priors based on empirical observations has increased  <cit> . thus our goal to tailor the prior to the data was naturally steered towards such considerations. empirical bayesian methods have been applied before in the context of gene expression in rna sequencing experiments  <cit>  and estimates of positive selection in tumors  <cit> . although, as outlined above, the techniques developed in this manuscript are quite general, we focus here on two important aspects of its application: detection and genotyping of variant alleles in a population of cells and comparing allele frequencies across different samples.

RESULTS
the methods described in this paper were developed to analyze the sequencing data from a study on hcl - a lymphoid malignancy in which bone marrow, spleen and liver are infiltrated by leukemic b cells showing abundant cytoplasm with characteristic "hairy" projections. in the study, the exome of samples from peripheral blood leukemic hairy cells and paired normal mononuclear cells from  <dig> hcl patients was sequenced with illumina gaiix and hiseq <dig>  genetic material from the exome of those samples was obtained by enrichment with sureselect. the mate-pair reads produced by the sequencer were aligned to the hg18/ncbi  <dig>  human reference using maq. on average around 27m of the 28m exonic positions reported in the ncbi  <dig>  ccds database were covered by reads with an average haploid depth of  <dig>  after filtering, described next, on average 16k exonic positions were determined to contain a variant. of those,  <dig>  were novel  and  <dig>  were in addition non-synonymous. finally, across all samples a total of  <dig> of the novel non-synonymous variants were predicted to be somatic. these variants were compared against a list of  <dig> tested variants  <dig> of which were confirmed to be somatic. fifty-six of the confirmed somatic variants were predicted and only  <dig> of the tested, but not confirmed variants, was predicted.

to analyze the variants produced by the sequencer we applied the bayesian framework outlined in the methods section. as discussed there, for every potential variant allele we obtained the number of reads confirming the variant, the average phred score of the nucleotides containing the variant, and the total number of reads covering its locus. assuming a binomial likelihood of the variant depth given a particular allele frequency, total depth, and a prior distribution on those frequencies, we obtained a posterior distribution for the allele frequency for every tentative allele using bayes theorem. in the following discussion, the priors and posteriors have precision 1% unless explicitly stated otherwise.

to construct a prior empirically we apply an iterative procedure based on the observation that a prior appropriate to a given set of observations should predict the empirically observed distribution of that data as a certain marginal distribution. the iterative procedure derived from this observation has as a fixed point a prior satisfying it. the details of the procedure are given in the methods section. figure  <dig>  shows the result of iterations  <dig>   <dig>  and  <dig> of the procedure starting with a prior uniform over all frequencies. as can be seen, the priors obtained from the procedure get consecutively better at picking up the salient features of the allele frequency distribution particular to a diploid genome compared to a haploid reference - most positions are homozygous for the reference, a number of positions are heterozygous, and that number is proportional to the homozygous variant positions. figure  <dig>  contains the kullback-leibler divergence between every two consecutive priors produced by the procedure. as can be seen in this plot, in our case the procedure is converging to a fixed point. analyzing the convergence properties of this procedure in more detail is certainly of high mathematical interest but beyond the scope of this paper.

detection of variants
given the posterior distribution for the frequency of an allele we obtained the posterior probability that the allele has a non-zero frequency. our decision was to consider as present variants whose posterior probability of having a non-zero frequency was at least 1-10- <dig> . figure  <dig>  shows in red the aggregated posterior obtained from variants determined to be present with the criterion that the hypothesis "frequency at least 1%" is credible at the 1-10- <dig> level and using the empirical prior. the plot also contains  the aggregated posterior corresponding to the uniform prior. a comparison between the two posteriors shows again the shrinking towards a common mean, this time towards the frequency 50% for heterozygous variants and towards 100% for homozygous variant alleles. also shown here are the aggregated posteriors for variants present in both the tumor and normal samples  and novel variants not documented in the ncbi dbsnp <dig> database .

next we analyzed the performance of the 1% criterion on positions reported in the dbsnp database. figure  <dig>  shows the aggregated posterior of the dbsnp locations for which an allele has been determined present with that criterion. in this figure such locations have been split in two disjoint datasets - those present in both the tumor and normal samples and those present in only one of the samples. our intuition is that that the variants confirmed in both samples are more likely to be genuine germline polymorphisms. an inspection of the figure shows that the posterior distribution of variants at known locations, which are detected in only one sample exhibits, a peak at low frequencies, confirming our intuition that those variants are likely to be sequencing artifacts. to remove such artifacts we considered the option of raising the cutoff frequency in the filtering criterion. more precisely, our strategy was to obtain for every potential variant the highest frequency f for which the hypothesis "frequency at least f" is credible a posteriori with confidence at least 1-10- <dig> - i.e. we obtained a one-sided credible interval for that level. next, for every possible cutoff frequency we obtained the contingency table for the test corresponding to the cutoff on that frequency vs. the known polymorphic locations present with frequency at least 1% with high posterior confidence in both samples. we computed the mutual information corresponding to that contingency table and chose the frequency cutoff which maximizes it. in our case a frequency cutoff of 2% was chosen. figure  <dig>  shows the result of this analysis and figure  <dig>  shows the roc curve for the frequency cutoff parameter, where the chosen cutoff frequency is marked in red. finally, we revisited the definition of presence of an allele and used a frequency cutoff of 2% at posterior credibility level 1-10- <dig>  the result of this filtering is shown in figure  <dig> . for comparison, in that plot we have also included the result of filtering with frequency cutoff 1%, which was shown in red in figure  <dig> . from the plot it is evident that the cutoff at 2% removes a small peak and some of the bulk at low frequencies of the posterior distribution, which we hypothesize are due to sequencing artifacts. a possible extension iterates the process with the newly established cut-off until the aggregated posteriors stop changing substantially as measured, for example, by the kullback-leibler divergence.

detection of somatic variants
to detect somatic variants we extend the method of detecting variants by obtaining a posterior probability for each possible difference of frequencies. figure  <dig>  shows the aggregated posterior of the allele frequency differences for locations not included in the ncbi dbsnp  <dig> database and restricted further to variant alleles resulting in a non-synonymous change in amino acid. those criteria were chosen because the goal of the sequencing experiments was to detect nucleotides changes relevant to the oncogenic process. the figure has a spike at difference 0%, which is expected since the majority of mutant alleles are germline variants present in both samples at equal allele frequency. the figure also contains smaller features at ±50% and ±100% due to potential candidates for somatic mutations.

similar to variant detection, the identification of somatic alleles is based on choosing a suitable cutoff on frequency difference. in the variant detection context our search for suitable frequency cutoff was guided by the frequencies of variants at known  locations observed in both tumor and normal samples. to establish a variant difference cutoff we leveraged the validation results of  <dig> potential somatic alleles  <dig> of which were confirmed to be genuine somatic mutations present only in the tumor samples.

the list of potential somatic alleles was chosen in the following way. first, starting from a uniform prior on frequencies 0%, 50%, and 100%, with the iterative procedure outlined in the methods section we constructed an empirical prior for those frequencies. next, amongst non-synonymous variants whose locations do not appear in dbsnp we selected those with posterior confidence of having zero frequency in tumor at most 10- <dig> and a posterior confidence of having non-zero frequency in normal at most 10- <dig>  finally, we restricted our attention to the variants having an observed frequency at least 25% in the tumor and observed frequency at most 5% in the normal. those  <dig> variants were subjected to validation by a direct sanger sequencing, and  <dig> were confirmed to be present in the tumor, but absent from the normal samples.

to select a frequency difference able to distinguish between the confirmed variants from those which were not confirmed in the validation experiment, we performed a mutual information analysis, similar to the one we used to obtain a variant frequency cutoff in the context of detection of variants. more precisely, for every possible frequency difference cutoff we compared the variants obtained at this cutoff with the result of the validation experiment and chose the cutoff for which the mutual information of the corresponding contingency table was maximized. in this way, a cutoff of 10% on frequency difference was chosen. figure  <dig>  contains the details of this analysis and figure  <dig>  contains the aggregated posterior of the validated variants, showing an increase in frequency of at least 10% with high posterior confidence. as designed, this cutoff was able to distinguish the confirmed from the non-confirmed variants quite well, so we went back and filtered the novel non-synonymous variants using this criterion. in addition, we filtered for variants for which a decrease of at least 10% in allele frequency was observed. our hypothesis was that such variants might be due to a loss of heterozygosity, which was confirmed subsequently. the aggregated posterior distribution of the frequency differences of the filtered variants is given in figure  <dig> .

CONCLUSIONS
we have presented an empirical bayesian framework for estimating allele frequencies in a given sample and for comparing such frequencies across samples. the method constructs an empirical prior through an iterative procedure with a fixed-point distribution predicting the empirically observed distribution on data as a marginal. given the prior, the method combines the data of a particular position with binomial likelihood to produce a posterior allele frequency distribution. we use high credibility intervals derived from that distribution to decide between the competing variant present/absent hypotheses and distinguish alleles existing in the sample from variants introduced as artifacts by the sequencing technology. for a particular sample involving the study of a human/cancer genome, the parameters of that decision can be inferred from the variants present at locations polymorphic in the human population. finally, when confronted with a pair of samples, we obtain a posterior distribution on the allele frequency differences between them and detect the alleles presenting a substantial differential. this differential can constitute the appearance of oncogenic alleles, as well as a loss of alleles, e.g. loss of heterozygosity, as a result of the oncogenic process. in our work we used a set of validated variants to deduce the cutoff on frequency difference and have shown that the chosen cutoff distinguishes variants confirmed to distinguish the samples, e.g. somatic variants, from those which do not, e.g. germline variants. regarding cutoffs we can make the general comment that although obtaining theoretical guarantees on those cutoffs is important, in experiments in which subsequent independent validation is available the stress is more on the cutoff parameter as setting a priority in the validation and leaving the decision of a cutoff to be guided by the design and the resources of the experiment.

this method was developed in order to analyze the sequencing data from tumor and paired normal samples from hcl patients and was successful in identifying important somatic mutations present in the tumor sample. the goal of the project is to obtain the mutational landscape of that disease and will be reported in a separate publication. we saw the study as an opportunity to explore the larger goal of estimating the frequency of alleles in a population of cells. our motivation for this was enabled by the ability of the novel high-throughput sequencing technologies to detect alleles at a growing depth, and hence at a decreasing frequency. the importance of this to the future of biomedical research is immense, since it will let us fine-tune to a higher precision our understanding of complex populations of cells. more precisely, it will let us detect low frequency alleles, which might have been or will be selected for a clonal expansion in the evolution of that population. furthermore, as is often the need in biomedical research, this approach will let us study in finer detail the differences between two samples as captured by their genetic makeup. this is important in contexts in which impurities in the sample might confound a more coarsely discretized view of the data. our conclusion is that the approach to analyzing sequencing data through estimating allele frequencies using empirical bayes methods is a powerful complement to the ever-increasing throughput of the sequencing technologies.

