BACKGROUND
we present prediction models for survival times built from high dimensional gene expression data. the challenge is to construct models that are complex enough to have high prediction accuracy but that at the same time are simple enough to allow biological interpretation. univariate approaches use single genes as covariates in survival time models, whereas multivariate models perform dimension reduction through gene selection . in addition, the combination of clinical data and gene expression data is a hot topic of research  <cit>  and is included in our model building procedure. analysis of the prognostic index  <cit>  and the brier score  <cit>  can be used to assess the predictive performance of the models.

here, we present models with higher interpretability by combining genes to gene groups  and then using these groups as covariates in the survival models. the hierarchically ordered 'go groups'  are particularly suitable  <cit> . the gene ontology  project provides structured, controlled vocabularies and classifications according to molecular and cellular biology. the current ontologies of the go project are biological process, molecular function, and cellular component. these three areas are considered rather independent of each other and we make use of the biological process ontology.

a problem when relating gene groups with gene expression profiles is that the genes in each gene group may have different expression profiles: interesting subgroups may not be detected due to heterogeneous or anti-correlated expression profiles within one gene group. we propose to cluster the expression profiles of genes in every gene group and preselect relevant clusters .

for statistical analysis, the cox regression model  <cit>  is a well-known method for modeling censored survival data. it can be used for identifying covariates that are significantly correlated with survival times. due to the high-dimensional nature of microarray data we cannot obtain the parameter estimates directly with the cox log partial likelihood approach. however, we can combine the cox model with selection and shrinkage procedures and compare the prediction performance of the obtained models. based on these models statistical selection procedures are applied. univariate selection and forward selection have been shown to have problematic performance in highdimensional settings. therefore we do not show their results in this work. we focus on presenting the results for ridge regression  <cit>  and lasso regression  <cit>  as shrinkage methods. note that lasso regression is a variable selection method as well.

in order to integrate the clinical information and microarray data in survival models properly, it is a common approach to handle the clinical covariates as unpenalized mandatory variables  <cit> . in addition to the genomic information, clinical covariates like age, tumor size and tumor stage may be important predictors for survival times of patients. these approaches show that the combination of genomic and clinical information may also improve predictions.

our aim is the combination of methods for survival prediction with biological a priori knowledge. on real gene expression data sets we evaluate the potential of including preclustered gene groups as covariates in survival models. models built with gene groups alone have equal or decreased prediction accuracy since many genes are not yet annotated to their corresponding functions. however, we will show that after adding the preclustering information to the gene groups the resulting models have improved interpretability while prediction performance remains stable.

in the next chapter we introduce the methods for analyzing survival data, for preclustering genes, for model selection, and for evaluating the prediction accuracy of the resulting survival models. then we present and discuss results on two real gene expression data sets.

methods
we first present the notation, the cox model and how the covariates are defined that are used in the cox models - especially the preclustering algorithm is presented. then we describe the log partial likelihood concept derived for the cox model and introduce model selection/shrinkage methods. since most methods for dimension reduction or shrinkage require the selection of a tuning parameter that determines the amount of shrinkage, finally, we describe how to choose the tuning parameter for each method.

cox model
in the following, we assume that we have a sample size of n patients, and a  survival time for the response. in order to cope with censored survival times data we use the cox model, also known as proportional hazards regression model  <cit> . cox suggested that the risk of an event  at time t for a patient with given covariate vector x =  is modeled as

  h=h0exp, 

where h <dig> is an arbitrary baseline hazard function and β =  a vector of regression coefficients. in the classical setting with n > p, the regression coefficients are estimated by maximizing the log partial likelihood

  l= ∑i=1nδiβ′xi- log∑j∈rexp. 

for patient i, this expression contains the possibly censored failure time ti, the indicator δi  and the vector of gene  expression values xi.

further, r is the risk set at time ti; this is the set of all patients who have not yet failed nor been censored. the value of β′xi is called prognostic index or risk score of patient i.

definition of covariates
in the following, we assume that the data consists of two different categories of covariates

clinical covariates z = : e.g. tumor size, tumor grade, age

genomic covariates x = : gene expression values of single genes or combined gene expression values for gene groups.

for a detailed analysis we consider three different types of cox models. we start with the simple model using only the clinical covariates

  h=h0exp. 

the second model consists of p genomic covariates x = . in our genetic regression models we use single genes, gene groups as well as preclustered gene groups as covariates. a gene group must be appropriately summarized in order to obtain one representative value for each individual . we summarize the gene expression measurements from all genes belonging to one go group or cluster via the first principle component of all genes that belong to this gene group. in the following we will consider three types of genomic models:

genes

groups

preclustered go groups.

in the last step, we combine the genomic models with the clinical model, which can be written as

  h=h0exp 

due to the small number of clinical covariates, the shrinkage and dimension reduction procedures will only be applied to the genomic covariates.

preclustering with pam
in order to find k homogeneous subgroups of genes within one go group containing n genes, we use the partitioning around medoids  cluster analysis . the pam procedure is based on the search for k representative genes, the medoids, among the n genes to be clustered. to achieve the goal of finding k medoids that minimize the sum of dissimilarities of the genes to their closest medoid

  ∑i=1nminj= <dig> ...,kd, 

where d is the dissimilarity of the ith and jth gene, the two following steps are carried out iteratively until convergence, starting with k sequentially selected genes as initial solution:

build: select sequentially k initial clusters and assign each gene to its closest medoid.

swap: minimize the objective function  by switching medoids with other genes of the same cluster.

to find correlated subgroups, the dissimilarity

 d=1-cor 

of the ith and jth gene with the gene expressions xi and xj is based on their pearson correlation. this yields small dissimilarities between positively correlated genes and large values for negatively correlated genes, respectively.

the number of clusters k for the pam algorithm has to be chosen in advance. to find tight clusters of highly correlated genes,  <cit>  suggest using the intra cluster correlation:

 icc=2n∑ici. 

here, the values ci are the elements of the lower triangle of the correlation matrix of the nj genes within a single cluster. the maximum mean icc among the k =  <dig> ..., n -  <dig> possible cluster configurations corresponds to the optimal number of clusters within one go group.

methods for dimension reduction
for comparing our results to those being published in the literature, we make use of the following two most established and successful shrinkage procedures: l <dig>  and l <dig>  penalized regression. univariate and forward stepwise selection do not produce satisfactory results for our high dimensional settings. we have compared these two methods in our analysis, and in agreement with previous results from boevelstad et al.  <cit>  prediction performance was always worse . we present the methods for the model containing clinical and genomic information.

l <dig>  and l <dig>  penalized estimation methods shrink the estimates of the regression coefficients towards zero relative to the maximum likelihood estimates. both methods are similar in nature, but the results of l <dig> and l <dig> penalization can be very different. we perform the penalization only on the high-dimensional genomic covariates, the clinical covariates are handled as unpenalized mandatory variables.

the lasso shrinks the regression coefficients toward zero by penalizing the absolute values instead of their squares. the penalized log partial likelihood thus becomes l-λ∑j=1p|βj|. <cit> .

ridge regression  <cit>  shrinks the regression coefficients by imposing a penalty on their squared values. the regression coefficients are estimated by maximizing the penalized log partial likelihood l-λ∑j=1pβj <dig> where λ∑j=1pβj <dig> is the penalty term and l is given by . applying an l <dig> penalty tends to result in many small but non-zero regression coefficients, whereas penalizing with the absolute values has the effect that many regression coefficients are shrunk exactly to zero. thus the lasso also is a variable selection method.

we applied both methods using the r package penalized  <cit> . in both methods the tuning parameter λ controls the amount of shrinkage and is obtained again by cross-validation.

choosing the tuning parameter
the model complexity of the prediction methods depends on a tuning parameter λ. we use m-fold cross-validation as proposed by  <cit>  for estimating λ. the m-fold cross-validated log partial likelihood  is given by

  cvpl= ∑m=1mlβ^m,γ^m-lmβ^m,γ^m, 

where l denotes the log partial likelihood given in  and lm the log partial likelihood when the mth fold  is left out.

the difference of the two terms compared in the formula is that in the right term the likelihood is evaluated without the mth fold, and on the left side it is evaluated with all patients. in both cases the parameters β and γ are estimated without the mth fold. the estimate of β and γ when the mth fold is left out is denoted by β^m and γ^m. the optimal value of λ is chosen to maximize the sum of the contributions of each fold to the log partial likelihood.

evaluation
next we describe how we evaluate the prediction performance of the models. we make use of three different model evaluation criteria. the whole procedure is applied to two well-known data sets. the basic idea is to split the data into a training set for model fitting and a test set for model evaluation, i.e. for determining the prediction performance. it is important to note that we have to consider several splits of the data into training and test sets due to the extreme dependence of the results on such a split .

evaluation procedure
in order to obtain a fair comparison of the prediction methods, we divide the data  <dig> times at random in a training and test set at the ratio of 2: <dig>  after computing the optimal tuning parameter λ^train by 10-fold cross-validation using the training data, we estimate the regression coefficients β^train and γ^trainon the whole training data set. for each split into training data and test data, we calculate on the test set the three evaluation criteria explained in the next subsections. the results are compared with the help of boxplots and prediction error curves.

logrank test
we assign patients to subgroups based on their prognosis, into one with good and one with bad prognosis. if the prognostic index β^xi+γ^zi of patient i is higher, the survival time is expected to be shorter. for this reason, a patient i in the test set is assigned to the high-risk group if its prognostic index is above the median of all prognostic indices calculated on the test set. we apply a logrank test on the two prognostic groups and use the p-value as an evaluation criterion for the usefulness of the grouping. boevelstad  <cit>  points out that a disadvantage of this criterion is that it does not consider the ranking of the patients within the groups and it may not be biologically meaningful.

prognostic index
the prognostic index β^xi+γ^zi is used as a single continuous covariate in a cox model. we fit the model hi=h0expαβ^xi+γ^zi. using the likelihood ratio test, we test the null hypothesis α =  <dig> versus α ≠  <dig> and assess the prediction performance with the obtained p-value. a small p-value indicates ability of the prognostic index to discriminate between short and long survivors.

brier score
the prediction performance can also be assessed based on the  brier score that was introduced by  <cit>  in survival context. the consistent estimate of the expected brier score bs is defined as a function of time t > <dig> by

  bs=1n∑i=1nŜ2⋅1Ĝ+)2⋅1Ĝ, 

where Ŝ⋅|xi,zi stands for the estimated survival for patient i and  denotes the kaplan-meier estimate of the censoring distribution. the estimation of Ŝ⋅|xi,zi is performed via the breslow estimator of the cumulative baseline hazard function . good predictions at time t are reflected by small brier scores. note that the brier score bs is dependent on the point in time t. the integrated brier score ibs, given by

  ibs=1t*∫ 0t*bsdt, 

is a score for the average predition performance for all time points in the interval [ <dig>  t
*]. in accordance with  <cit> , we calculate the ibs for the two data sets for t* =  <dig> years due to high censoring after  <dig> years of survival.

RESULTS
for investigating the relationship between microarray gene expression data and censored survival data, we analyze two published breast cancer data sets with the methods described above. in this section, we present the results for the evaluation procedure applied to these two data sets. standard approaches focus on single genes as covariates  <cit> . we integrate additional biological knowledge by building models with preclustered go groups as covariates. in order to assess the merit of this approach, we also present results for models using only genes or only go groups as explanatory variables and combine the genomic information with the clinical data. in order to obtain a fair comparison of models with different types of genomic covariates, we only use those genes that are annotated to go groups. we have to consider several splits of the data into training and test set due to the dependence of the results on such a split. we first present detailed results for one specific random split, then we present comprehensive results summarizing  <dig> random splits.

at this point we want to highlight that the proposed methods are computationally intensive. due to the nested cross-validation procedure for obtaining the optimal tuning parameter λ and the preclustering approach, we performed all computations on the lidong high performance computing cluster of tu dortmund university with  <dig> nodes and up to  <dig> gb ram per node. the calculation takes several weeks to accumulate all results for one high dimensional data set.

data sets
the dutch breast cancer  data set is a subset of the original data set with  <dig>  <dig> gene expression measurements from n =  <dig> women with breast cancer  <cit> . after data pre-processing as proposed by  <cit>  our analysis is performed with  <dig>  <dig> genes, that are annotated to at least one go group, according to the biological process ontology. we obtained the data from the website https://www.msbi.nl/dnn/people/houwelingen.aspx. in total, there are  <dig>  <dig> go groups to which at least one of these genes is annotated. the mean number of genes included in these go groups is approximately  <dig> genes, 90% of all go groups contain at most  <dig> genes. for  <dig> patients an event was observed. the clinical covariates are age, size, nodes and grade.

the mainz cohort  study consists of n =  <dig> node-negative breast cancer patients who were treated at the department of obstetrics and gynecology of the johannes gutenberg university mainz between the years  <dig> and  <dig>  <cit> . all patients underwent surgery and did not receive any systemic therapy in the adjuvant setting. gene expression profiling of the patients' rna was performed using the affymetrix hg-u133a array, containing  <dig>  <dig> probe sets, and the genechip system. the normalization of the raw data was done using rma from the bioconductor package affy. the raw. cel files are deposited at the ncbi geo data repository with accession number gse <dig>  for covariates in the survival models,  <dig>  <dig> genes and  <dig>  <dig> go groups are available. the mean number of genes included in these go groups is approximately  <dig> genes, 90% of all go groups contain at most  <dig> genes. there have been  <dig> events observed. the clinical data covers age at diagnosis, tumor size and grade as well as the estrogen receptor status.

exemplary analysis: one split into training and test data
we apply the model selection methods and three evaluation criteria to one specific random split of the mainz cohort study into training and test data. model building and evaluation are performed as explained in the evaluation procedure section. we split the  <dig> breast cancer patients into training set and test set, where 2/ <dig> of the patients  are assigned to the training set and 1/ <dig>  to the test set. we use the training data for estimating the tuning parameter λ^train and the regression coefficients β^traintrain and γ^train and the test data for evaluation. table  <dig> shows the results for the two prediction methods, using genes, go groups, or preclustered gene groups as covariates.

p
lr
p
pi
p
ibs
λ
results for the two prediction methods using  genes,  go groups, and  preclustered go groups. for ridge regression, nearly all covariates are kept in the model since parameter estimates are unlikely to get shrunken exactly to  <dig> lr= ^logrank test, pi= ^prognostic index,ibs= ^integrated brier score,sel.cov= ^number of selected covariates.

this example indicates that the predictive performance of models built with go groups alone and of models with preclustered go groups is comparable with classical models using only genes as covariates. the p-values for model assessment are similar, but in addition, we have more information in the final model; annotations of preclustered go groups can help clinicians to investigate the selected genes according to their biological function.

for illustration of the results presented in table  <dig> we show kaplan-meier curves for two prognostic groups of patients derived by dividing all patients according to the median prognostic index of the patients in the test set. here we used lasso regression for model selection and the logrank test for evaluation. we compare models with genes, go groups, and preclustered go groups as covariates .

for all three types of genomic covariates the two prognostic groups are clearly separated on the test data, with significant differences in overall survival  between the high-risk group and the low-risk group. the separation between the two groups is best when using a model containing preclustered go groups .

comprehensive analysis:  <dig> splits into training and test data
we have observed high variability of the chosen tuning parameters and the parameter estimates depending on the split into training and test data. in order to quantify which covariates are consistently selected in different splits and how stable the evaluation measures are, we calculated results for  <dig> random splits and compared the selected genes and go groups.

in figures  <dig>  and  <dig> , we present boxplots for the results for the two cancer data sets, after applying the evaluation procedure for lasso and ridge regression for each of the three types of genomic covariates . results for the clinical model are presented as a reference.

rows of the plots correspond to two model evaluation criteria, the prognostic index and the integrated brier score, and the columns correspond to two types of models: the genomic model and the genomic model with clinical covariates. results for the logrank test are nearly the same as for the prognostic index and therefore not shown here. in each plot we show the results for the two model selection methods. the p-values for the prognostic index are shown on the - log <dig> scale, thus a value of  <dig>  e.g., corresponds to a p-value of  <dig> . small values for the integrated brier score correspond to good prediction performance. for both evaluation criteria in all plots the horizontal line at the median indicates the reference model containing only clinical information.

the following main statements can be deduced from the plots:

lasso regression with preclustered go groups has the best prediction performance for the dbc data set, see the median of the p-values across  <dig> splits in figure  <dig>  in the mainz cohort study, we see the same result for the genomic model using the brier score for evaluation .

methods using go groups or preclustered go groups as covariates perform in general as well as models using only genes.

the prognostic index and the brier score yield similar results.

it is noticeable that for the mc study and prognostic index as performance measure the model using only genomic information is worse than the clinical model , but the clinical-genomic model is comparable to the clinical model.

the optimal tuning parameter varies considerably between the splits. the interquartile range for the number of chosen covariates for l <dig> regression and for all three different types of covariates ranges approximately from  <dig> to  <dig> for the mainz cohort study and from  <dig> and  <dig> for the dbc data set . there is a higher variance on the number of chosen covariates for the dbc data set. next, we have a closer look at the run of the curves of the brier score over time for l <dig> models with preclustered go groups in comparison to the other models. prediction error curves  <cit>   for models with the three different types of genomic covariates are shown in figure  <dig> and  <dig> for the dbc data set and the mc study, respectively. the performance of the clinical model serves as reference. for both data sets, the model with preclustered go groups has in comparison with the clinical model a better prediction performance over time. the preclustered models outperform the clinical models, starting at four years for the dbc data set and at three years for the mc study. the other two genomic models are also inferior to the preclustered models. furthermore, we investigate which preclustered groups are most frequently selected across all  <dig> splits. table  <dig> contains the numbers of the most frequently selected covariates, the corresponding go groups with go ids  <cit>  and further information concerning the medoid gene, the cluster size and the annotation for the go groups that are helpful for the biologist. we observe that most of the chosen cluster are subgroups of large go groups and consist of more  <dig> genes. the value of the effect indicates whether a high value of the corresponding covariate has an increasing  or decreasing  influence on patients' risk to die. for a detailed analysis of the effects the boxplots in figure  <dig> show the variation of the estimated regression coefficients in the cox regression model for the most frequently chosen clusters, represented via medoid genes. first of all, the direction of the effect among all splits into training and test data is stable. from this it follows that a detected cluster has a consistent effect on patients' survival - either positive or negative. the first two clusters  shown in table  <dig> are chosen in more than  <dig> percent of the splits into training and test data. their parameter estimates are negative, i.e. high expression values of the included genes lead to reduced risk to die and thus to longer survival.

names are genbank ids for the medoid genes and go ids for go groups  <cit> . the first column corresponds to the selected number for the covariate across  <dig> splits into training and test data for l <dig> regression on the mainz cohort study. the value of the effect indicates whether the covariate has an increasing or decreasing  effect on patients' risk to die.

discussion
the typical challenge when relating survival times to gene expression measurements is a relatively small number of individuals compared to a large number of predictors. in this case the use of classical approaches is not possible. in accordance with  <cit> , the lasso regression method seems most suitable and promising: its prediction performance is slightly better compared to ridge regression and the solution is sparse  <cit>  and  <cit> . show that ridge regression performs better than all the other methods. in our analysis, ridge regression leads in general to comparable but not better results compared to the lasso. however, an important disadvantage of this method is that it does not select variables. we observe relevant differences between high-risk and low-risk patients, but there are too many genes or go groups to be further investigated. the preclustering approach is beneficial concerning prediction performance in the lasso setting and leads to comparable results in the other models. however, a main benefit of preclustering is that we detect genes with similar expression patterns and that these gene subgroups are correlated with survival. in addition, we can have a detailed view on the go groups containing the preclustered subgroups. table  <dig> shows that the cluster sizes as well as the corresponding go groups are quite large. however, in this case the selection of the top  <dig> clusters is quite stable. for gaining further biological insight a more detailed analysis of the composition of these clusters is required and promising.

in terms of the brier score, we showed that the prediction performance of models using clinical, genomic or both information is comparable. it seems that these different kind of covariates contain an overlap of information for predicting survival.

CONCLUSIONS
our comparative study shows that different model selection procedures can be used to identify genes and  go groups related to survival outcomes and to build models for predicting survival times of future patients.

the integration of go groups is useful, since they contain aggregated information of biological function and thus are often more informative than single genes. it is encouraging that in terms of prediction performance, our results obtained with  go groups as predictors are comparable to those using only genes as predictors. thus the potentially improved interpretability makes these models with go groups competitive. we demonstrated that this result holds true also for models using go groups and not only genes. our agenda in the present work was:

constructing models with a relatively small subset of relevant covariates that are enriched with additional gene group information in terms of the gene ontology.

presenting a new approach of preclustering genes from one functional group due to different expression profiles within one go group.

comparing prediction rules for the three types of covariates .

adding clinical information and comparing the results to single use of genomic data.

the next step for improving our models is to integrate more detailed information concerning the hierarchically structured gene ontology. for coping with high correlations between go groups one can follow the approach of  <cit>  where correlations between neighboring go groups in the go graph are iteratively removed. finally, in future projects, the biological interpretation of the identified gene groups will include not only the interpretation of the  go groups according to overall function, but it is also helpful to take a closer look at the single genes contained in these gene groups.

availability
we make use of the r package penalized  <cit>  that provides algorithms for penalized estimation in cox proportional hazards models. the package is freely available from http://cran.r-project.org <cit> . r code for model selection and evaluation is available at http://www.statistik.tu-dortmund.de/survivalgo.html.

authors' contributions
kk and jr developed the ideas for the manuscript, kk and ml performed the statistical and computational analyses. ms and jgh generated and provided the mainz cohort data, all authors read and approved the manuscript.

