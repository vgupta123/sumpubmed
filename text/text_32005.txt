BACKGROUND
networks and graphs are well-studied constructs in computer science and applied mathematics. as the sizes and complexities of networks grow, however, critical limitations arise that restrict a scientist's ability to analyze a large network, both computationally and cognitively. from our observations, humans appear to be capable of comprehending networks that contain up to about  <dig> nodes. single-processor computers, on the other hand, can often process graphs of up to  <dig> s of nodes, depending on the algorithm. yet, in many scientific fields, networks often arise that may consist of millions to hundreds of millions of nodes. in a world of continually growing scientific data and information spaces, scientists need advanced new strategies, tools, and computer systems to effectively and efficiently process and analyze large-scale scientific networks.

data complexity and volume issues have recently become especially significant in biology as the result of high-throughput data production in genomics and proteomics. networks are a fundamental concept in biological systems, and their analysis is an essential capability. of great interest are methods for discovering bionetworks from diverse types of data, storing, representing, comparing, and extracting features from them, and computing upon dynamic bionetworks. yet, despite these trends, it is also increasingly common to hear biologists use the term "giant hairball" to convey their experiences working with large, complex bionetworks in research.

we believe that unlocking the real potential of these networks for biologists will require a significant investment in high-performance computing  and innovative computational systems and techniques. these approaches have been applied less often in biology, yet biological systems have many intriguing and ideal properties for driving the development of advanced computational strategies and high-powered solutions. biological computing involves critical issues in data-intensive computing, defined as "applications to explore, query, analyze, visualize, and in general process very large-scale datasets"  <cit> . in this context, scale relates to both absolute data size and the algorithms and applications that can process large-scale data.

in this paper, we introduce the biological graph environment , which offers novel graph approaches, techniques, and tools in an integrated framework to address data-intensive computing challenges associated with large-scale bionetworks. biographe will enable biology researchers and computational scientists to identify and deploy network analysis applications and to easily connect them to efficient and powerful computational software and hardware that are specifically designed and tuned to solve complex graph problems.

RESULTS
graph problems in genome biology
many areas of biological research are poised to benefit from advances in network analysis. sources of biological networks include protein-protein interactions, gene expression from microarrays, metabolic pathways, and signal transduction cascades. we have selected genome biology problems in this project for several reasons. these results are important to biologists in the study of how proteins function in the cellular machinery. we are able to build networks in genome biology in a highly tunable fashion: they can be made as large or small, as simple or complex as needed, in large numbers, and with correct biological encodings. the data is freely available in public databases with large quantities of nodes for these networks as well as diverse types of interconnections. edges based on homology can be defined in high-throughput using the blast  <cit>  algorithm and these comparisons can be performed very efficiently with the scalablast implementation  <cit> . other types of edges may also be retrieved from the databases. finally, we are able to extract right or wrong answers from these networks to provide useful feedback on the analysis.

we have produced a series of protein homology networks for testing biographe based on sigma  <dig> signaling pathways. sigma  <dig> regulatory proteins are of interest for bioenergy applications. sigma and anti-sigma factor proteins are modular protein pairs that function as on/off switches in many microbial signaling pathways. recently, we have shown that seemingly discrete clusters of anti-sigma factors are linked together by a previously unrecognized protein domain  <cit> . in a protein homology network this result can be detected as bridge proteins that link densely clustered regions of anti-sigma factor homology networks. we illustrate the use of several common graph algorithms with protein homology networks, including k-clique, subgraph matching, and k-coloring. protein families that are functional subtypes are often fully connected in a homology network, and thus, appear as cliques. figure  <dig> shows a similarity box  <cit>  visualization of the maximum cliques found from a bionetwork derived from chromosomal neighbors of sigma  <dig> proteins.

subgraph pattern matching is illustrated in figure  <dig>  the subgraph highlighted in green consists of gene products with a particular orientation in the chromosome near sigma  <dig> factors. the highlighted proteins are not randomly placed throughout the network, but rather fall within specific clusters that represent different protein families.

k-coloring is illustrated in figure  <dig>  the patterns in this graph identify subtle evolutionary relationships between proteins from three strains of rhodobacter sphaeroides, each marked in a different color. the 3-cliques display orthologous proteins based on bidirectional best hits, while proteins in the open subgraphs are homologs but not likely to be orthologs.

computational framework for large-scale graph analysis
graph algorithms are known to be computationally expensive for large graphs because they often involve comparisons of each node to every other node in the graph. as the number of nodes increase, the number of comparisons will often increase exponentially. in fact, many general graph problems such as k-clique, hamiltonian paths and cycles, and subgraph isomorphism are np-complete .

to facilitate complex, large-scale graph analysis, we seek a general solution and computational framework to enable scientists to deploy and integrate new graph algorithms and techniques as needed. rather than continuously building customized, one-off graph solutions, we wish to develop and provide an extensible and uniform analysis platform built on modern computational approaches and systems.

we introduce biographe as a high-performance computational framework for the analysis of complex networks from biology and potentially other domains as well. as shown in figure  <dig>  biographe is designed to integrate a variety of graph analysis applications into a common suite of tools. our approach is to identify relevant graph problems and reduce them into equivalent problems that may be addressed by efficient solver implementations. examples of potential general solvers are ones built for boolean satisfiability equations and integer linear programming. as an alternative to using a general solver, graph problems may also be directly solved by implementing specific solutions on high-performance systems.

to achieve the best performance, direct and indirect graph solvers should be implemented on high-performance computing  architectures such as compute clusters, shared-memory smp and numa platforms, as well as multithreaded architectures such as the sun niagara and cray mta- <dig>  to best utilize the features and capabilities of individual hpc platforms, computational solvers should utilize data structures and synchronization code that are most efficient for the individual platforms.

as a computational framework for bionetwork analysis, biographe has distinct benefits including:

• the biographe framework is extensible and allows core solvers to be added and new graph algorithms to be built on top of the algorithmic toolkit.

• core solvers should address well-studied problems in computer science, where efficient heuristics and algorithms are available. specific domain problems and applications, on the other hand, have had much less scrutiny and evolution, and thus, are much less likely to garner optimized solutions.

• core solvers should provide a very expressive language or interface to which many different kinds of graph problems may be translated.

• once the core solvers have been ported and optimized to run on a hpc machine, domain problems that are passed to the solvers should automatically gain the performance and benefits of the hpc machine without requiring recoding to that platform.

bionetwork analysis
when applying biographe to support bionetwork analysis, we had to make some choices regarding the software and hardware to be utilized. we sought a core solver that would be capable of efficiently solving np-complete problems, since many of the graph algorithms we wished to apply were also np-complete. we also sought a general solver that would accept a wide range of problems, had known formulations for graph problems, and had strong potential for code parallelization. for these reasons, we selected a modern solver for boolean satisfiability  equations called survey propagation   <cit>  as a core solver.

sat is a well-known np-complete constraint-satisfaction problem. various graph problems such as k-clique, k-coloring, and hamiltonian paths and cycles may be reduced to sat equations using known efficient reduction algorithms  <cit> . sp is a modern sat solver originally developed to study the physics of complex systems such as spin glasses. it has proven to be successful on many large satisfiability problems beyond the reach of other sat methods.

sat solving using survey propagation
given randomly generated formulas of m clauses of exactly k literals over n boolean variables, research has shown that hard instances of random k-sat exist when the formulas are near specific threshold values of α = m/n. k-sat problems moderately below α are under-constrained and easily satisfiable, while those moderately above α are over-constrained and generally unsatisfiable. k-sat problems near α identify a critical phase transition region where solutions are difficult and computationally expensive to obtain. in the case of random 3-sat, the α threshold value was found to be approximately  <dig>   <cit> . more specifically, α values between  <dig>  and  <dig>  were considered to represent the hard region for random 3-sat.

sp was designed to solve sat problems that fall within the hard region. to initially evaluate sp, we executed the algorithm on a personal computer running window xp on a single intel  <dig>  ghz pentium m processor. we tested randomly-generated 3-sat formulas consisting of various numbers of variables and the number of clauses equal to  <dig>  times the number of variables. thus, the 3-sat problems fell within the hard region. as shown in table  <dig>  the sp + walksat combination had increasingly better performance than executing walksat alone for 3-sat problems consisting of  <dig> variables and above. for every test, sp computed a partial solution with a subset of variables defined and clauses satisfied. with our test cases, partial solutions passed to walksat always had α values much lower than the critical range of  <dig>  and  <dig> , and thus, were easily satisfiable.

a number of issues should be noted when using sp to solve hard random k-sat problems. first, sp is a heuristic algorithm that has no guarantee of convergence, but still has been found to converge for many hard k-sat problems that other k-sat implementations were unable to solve. furthermore, sp has been found to be particularly effective in determining the satisfiability of k-sat formulas, but has some difficulty determining unsatisfiability  <cit> . finally, sp has mainly been tested for randomly-generated k-sat formulas. evaluations of sp's performance on nonrandom k-sat formulas have been limited.

parallel implementation of survey propagation
although rapid progress has been made in sat solvers, most are sequential and few are parallel  <cit> , and are thus limited to the capabilities of a single workstation. in order to enable the solution of very large sets of sat equations , we need the parallel processing capabilities and large aggregated memory spaces of hpc systems.

given the advantages exhibited by sp over traditional sat solvers for very large sets of equations, we implemented a parallel version of sp. sp operates by repeatedly updating weights associated with the variable and clause nodes until a fixed point is reached when the difference between successive updates falls below a specific threshold. the variables must be updated in a random order that changes at each iteration step. the fine-grained nature of the synchronization in this computation makes it more suitable for a parallel implementation on a multiprocessor with a shared address space than on a network of commodity workstations.

parallel computing environments
we implemented two versions of the parallel sp application:

• a portable, shared-memory openmp implementation.

• an experimental shared-memory, multithreaded version for the cray mta- <dig> and xmt systems  <cit> . the mta platform has been found to be very effective for irregular and graph-based applications  <cit> .

our testing platforms were a sun fire t <dig> server with an 8-core sun ultrasparc t <dig>  processor and a 40-processor cray mta- <dig> system located at the cray facilities. more details about these platforms can be found in  <cit> . on the sun niagara server, we executed the openmp version compiled with the sun compiler suite. on the mta- <dig> system, we executed our custom multithreaded version.

as part of our characterization of the sp algorithm, we tested both parallel implementations with a series of problems that are designed to fall in the "hard" sat space where sp is especially known to outperform other sat solvers. all of the cases we tested were random instances generated with α =  <dig>  that places the problem within the "hard" sat region. as shown by the actual clock times of figure  <dig>  the execution time of this algorithm implementation scales non-linearly with the size of the problem instance. overall, we found the mta- <dig> to have a  <dig>  to  <dig>  times improvement in execution times over the niagara. the speedup charts of figure  <dig> also illustrate that the parallel sp code exhibits an almost linear speedup within the same problem size when utilizing from one to eight processors on both the niagara and the mta- <dig>  the efficiency generally degrades on both machines, however, when the number of processors exceeds eight except in the case of the mta- <dig> running the largest sat problem . in this one case, mta- <dig> further exhibits linear speedup of up to sixteen processors. in addition, the mta- <dig> was able to achieve higher overall speedup rates than the niagara. for the largest sat problem, for example, mta- <dig> was able to achieve a speedup rate of up to  <dig> , while niagara's highest speedup rate was about  <dig> .

k-clique analysis of homology networks
as an initial, proof-of-principle problem, we chose to apply the k-clique problem on a collected set of protein homology networks, which are graphs where nodes represent proteins and edges represent similarity between proteins measured by the blast algorithm  <cit> . correspondingly, we have built software to perform the transformation or reduction of a protein homology network specification into a set of boolean satisfiability equations for finding a k-clique in the network. to test this software, we prepared a series of graphs that represent specific biological relationships that we understood well.

k-clique to sat reduction
we implemented a k-clique to sat reduction algorithm that takes a particular input graph and produces sat equations. the sat equations, in turn, will be solved by the sat solvers in biographe. a k-clique is a subgraph consisting of k nodes, all of which have edges to one another.

as shown in table  <dig> and  <dig>  we applied the k-clique to sat reduction to a number of homology networks. in the first set of test cases, we started by looking for 3-cliques in a specific homology network. to find the maximum clique, we incrementally increased the size of the clique until no cliques in the network were found. an interesting side effect of the reduction and sp algorithm was that the set of true variables produced by sp was always associated with the same clique in the network. we used this information to more efficiently adjust the size of clique for which we were looking. for instance, if we analyzed a homology network for 3-cliques and the sp algorithm returned eight true variables, then we should know that at least one clique of size eight existed in the network. we would immediately start searching for 9-cliques in the network on our way to finding the maximum clique.

in the second set of test cases, we applied sp to homology networks of different sizes. table  <dig> shows that the sat problem also rapidly increases with the overall size and complexity of the homology network.

in both the cases of increasing clique size k or the number of nodes n, a very large number of clauses are generated and the corresponding α values of the sat equations are very high compared to the  <dig>  phase transition region for 3-sat equations. one might expect the produced sat equations to be over-constrained and unsolvable. nevertheless, the sat equations from the reduction are generally solvable using sp. this interesting result requires further investigation as well as the exploration of alternative reduction strategies to generate sat equations from k-clique problems.

we should also note that the boolean formulas produced from the reduction are in the form of 2- and n-clauses. since most sat phase transition studies have focused on sat equations with fixed clause sizes , a relevant research effort would be to examine and characterize the phase transition region of our particular set of sat equations that evolved directly from bionetworks. part of this research should involve simplifying the sat equations to more efficient forms.

in addition, we are evaluating three additional reduction algorithms for k-clique in the literature  <cit>  that require a smaller number of variables for the reduction, as well as reductions for other graph methods. it is important to note that these more sophisticated reductions will not necessarily lead to faster execution speeds for the overall graph analysis procedure, since we expect the overall runtime to be dominated by the sp solver. in particular, the runtime should be dominated by how "hard" the sat instances are as defined by the ratio of clauses to variables. for 3-sat, it has been experimentally determined that a ratio of clauses to variables of approximately  <dig>  may lead to sat instances with exponential solution times. we are in the process of studying the behavior of our reduction-generated sat instances and characterizing them with respect to their solution difficulty.

parallel performance of survey propagation
in figure  <dig>  the performance of the parallel sp code is compared between the sun niagara and cray mta- <dig>  the parallel sp code was applied to sat equations that were generated by the k-clique to sat reduction algorithm. the k-clique problems were derived from the bionetwork analysis of protein homology networks.

the first problem was a 67-clique problem performed on a graph consisting of  <dig> nodes and  <dig>  edges. this clique problem reduced to sat equations consisting of  <dig>  variables and  <dig> , <dig> clauses. the second problem was a 3-clique problem performed on a graph consisting of  <dig>  nodes and  <dig>  edges. this problem reduced to sat equations consisting of  <dig>  variables and  <dig> , <dig> clauses.

as shown by the actual clock times of figure  <dig>  the parallel sp algorithm implementation scales non-linearly with the size of the problem instance. overall, the mta- <dig> had a  <dig>  to  <dig>  times improvement in execution times over the niagara. the speedup charts of figure  <dig> also show that the parallel sp algorithm exhibits an almost linear speedup within the same problem size when utilizing from one to eight processors on the niagara and from one to sixteen processors on the mta- <dig>  the efficiency generally degrades on both machines, however, after reaching those processor thresholds. furthermore, the mta- <dig> more than doubled the speedup rates of niagara for the larger sat problems when running on sixteen or more processors. for the bionetwork-related sat equations, mta- <dig> was able to achieve a speedup rate of up to  <dig> , while niagara's highest speedup rate was  <dig> .

CONCLUSIONS
in this paper, we introduced a high-performance computational framework for graph analysis called biographe. the general approach of biographe is to identify and deploy complex graph algorithms, which may be computationally- and/or data-intensive, and to integrate those algorithms with powerful and efficient computational solvers and hpc systems. the goal is to bring high-performance software and hardware capabilities to bear on challenging graph problem without requiring the scientist to become an expert of specific computing environments.

for our initial implementation, we selected a sat solver known as survey propagation  to serve as our first core solver. both sat and sp have desirable properties such as high expressivity, potential for parallelization, strong history of research, and existing tools and technologies. our initial findings on the performance of sat and sp were promising in that we were able to solve large k-clique problems and see definitive improvements in execution speed.

we will continue to optimize the parallel sp code to achieve the highest performance possible. we will also continue to study graph-to-sat reductions to better understand the phase transition of generated sat equations and how sat solving performance maps back to the structure and properties of bionetworks. also, we will continue to explore and experiment with other computational solvers to evolve and extend biographe's overall graph analysis capabilities.

