BACKGROUND
genome engineering  focuses on the modification of genomes in living organisms at specific loci of interest. examples of such modifications include insertion of a new gene into the genome, inactivation of existing genes via disruption of their sequences and replacement of a malfunctioning gene with a corrected version. ge has demonstrated its utility in basic research as well as in many industrial applications, for instance in agriculture and therapeutics  <cit> . one approach to ge is based on the use of sequence-specific nucleases to trigger dna modifications by generating dna double-strand breaks at the locus of interest. currently, the four most frequently used tools in ge to generate targeted dna cleavage are transcription activator-like effector nucleases   <cit> , crispr nuclease complexes  <cit> , zinc-finger nucleases   <cit>  and meganucleases   <cit> . these proteins have different properties , making it possible to match them with specific applications  <cit> .

meganucleases are naturally occurring endonucleases characterized by large recognition sites , which are almost unique in most genomes. the large recognition sites makes mns perfect tools for ge, but unfortunately the number of naturally occurring mns is quite limited and is not nearly sufficient to cover all potentially interesting loci. therefore there was a strong need for a method that would allow us to redesign existing mns to cut new dna sequences. existing redesign techniques include the creation of fusion chimeras from existing mn domains  <cit>  and alteration of mn specificity via direct mutation of protein residues in the dna binding scaffold  <cit> . one of the most used starting scaffolds for the design of new artificial mns is i-crei, a member of the laglidadg family, the largest of five known families of mns  <cit> . i-crei is a homodimeric endonuclease cutting a  <dig> bp pseudopalindromic target  with at least  <dig> known structures in the rcsb pdb  <cit>  showing an alpha-beta-alpha-beta-alpha fold  <cit>  . figure 1c illustrates which residues participate in the binding of dna  <cit> . in each monomer, residues r <dig> make direct contacts with base ± <dig> and ± <dig>  q <dig> with base ± <dig>  and r <dig> with base ± <dig>  while q <dig> and k <dig> make direct contacts with bases ± <dig> and ±7s respectively. positions ± <dig> make direct contacts with residue y <dig> and ± <dig> with q <dig> and n <dig>  the base pairs at positions ± <dig> and ± <dig>  do not make direct contacts with any of the protein residues. based on this interaction map, we previously defined four regions on the i-crei target: the central 2n <dig> part of the recognition site , where i-crei cuts the dna and three regions ±11n <dig>  ±7n <dig>  ±5n <dig> which constitute the binding sites  <cit> .

much effort has been made in the past to engineer i-crei  <cit> . we formerly reported a successful combinatorial approach relying on the division of the i-crei/dna interface into separate clusters of amino acids with different dna recognition regions. namely, the fact that there is no intersection between groups of residues binding the 5n <dig> and 11n <dig> regions  makes it possible to screen for proteins binding target variants in the 5n <dig> and 11n <dig> regions independently and then combine the mutations from these two protein sets to cut a hybrid 11n4-5n <dig> target  <cit> . while conceptually the combination of different clusters allows efficient mn design, one still needs to screen hundreds of molecules to find the optimal mn. in  <cit> , an assay based on single-strand annealing  was developed to perform such high-throughput screening as a routine assay. another example of a semi-rational experimental approach is based on the sequential design of i-onui derived mns  <cit> . here, we present a new method for mn engineering that significantly reduces the number of molecules screened without reducing the final success rate.

several studies have described the possibility of engineering mns using atomistic molecular modeling software such as foldx  <cit>  and rosetta  <cit> . these software packages build optimal mn structures by minimizing the binding energy of protein-dna complexes. most reported studies have limited the use of these packages mainly to the prediction of mns for single base substitutions, but in  <cit>  the authors reported successful mn prediction on targets with up to three base substitutions.

diverse applications of machine learning  approaches  <cit>  have positioned machine learning techniques as promising tools for solving complex biological problems. some of these applications, such as how to predict transcription factors, bear many similarities with the design of mns. a necessary condition for the application of a ml approach is the existence of data from which a ml algorithm can learn a model. over the years, we have gathered data on the cleavage activity of several hundreds of thousands of mn-dna target pairs, which we used to train a machine learning model.

in this manuscript we present a new efficient method of mn design based on machine learning techniques. this strategy presents the advantage of a competitive success rate compared to that of experimental combinatorial high-throughput screening, while significantly reducing the number of screened molecules by several orders of magnitude and at the same time significantly outperforming alternative in silico models such as rosetta and foldx. the experimental validation of the ml approach lead to the successful design of mns for  <dig> new dna targets.

RESULTS
cross–validation experiments
the principal dataset used to train/cross-validate the machine learning model and to compare the performance of various in silico models consisted of  <dig> pseudopalindromic   <dig> bp dna targets screened according to a combinatorial process  giving in total 293k protein-dna pairs of known activity .

in the first series of experiments we studied how in silico methods  performed on the combinatorial dataset by doing cross-validation experiments . to assess the quality of model predictions, we computed several performance scores for each target: auc score, top <dig> score, and %top <dig>  finally, the average value of each score over all targets from the test set was used as a global performance measure of in silico models .

figure  <dig> presents the cross-validation performance scores  for the following models: foldx , rosetta , mact , seqmact , seqmactfxstr . values of top <dig> score are given in additional file 1: figure s <dig>  foldx and rosetta did not use the information available in the training set; they made their predictions by estimating the binding energy of the protein-dna couple from a physical model. for a more detailed description of ml models, foldx and rosetta, see the corresponding sections of “materials and methods”.

overall mact had an auc score of around  <dig>  and was able to predict at least one positive protein in the top  <dig> for about 20% of targets. remarkably, the performance of the physical models  matched that of mact. it is worth noting that fx/rt do not use information on module cleavage activities and can be used ab initio without any preliminary steps . however, when we added the information on protein and target sequences into the ml model , we obtained a significantly better success rate, predicting at least one positive mutant in the top  <dig> for about 80% of targets, with an auc score of  <dig>  . the substantial difference in the success rates of mact and seqmact suggested that combining the best modules was not sufficient to get an active combined mutant; we also had to take into account protein and target sequence composition. another important conclusion was that by learning sequence patterns specific to active and non-active proteins, we could obtain much better predictions than by exploiting a general physical model. interestingly, when we combined seqmact and fx into a more general ml model  trained on sequence and structural features, we did not observe any improvement even though the two methods’ final protein rankings were not always the same.

machine learning performance scores presented in figure  <dig> correspond to the case when all available data in the training set were used to train the model . figure  <dig>  shows how top10%  of mact and seqmact varies with the size of the training set, with only 10- <dig> targets  seqmact already matches the performance of foldx and with  <dig> targets, it almost triples the performance. to make sure that seqmact generalizes well on targets which are significantly different from what we already have in the training set, we repeated the previous experiment but this time instead of random subsampling of targets from the training set, we kept only those that had at least  <dig> and  <dig> base pair difference with all test targets . figure  <dig>  shows how the performance varied with the minimal allowed distance between training and test sets, we observe a drop in performance when the minimal distance  is increased. however the decrease is almost identical when we randomly sample an equivalent number of targets meaning that the model predicts well on significantly different targets and the observed drop in performance is due to the reduced size of the training set. additional file 1: figure s <dig> presents the distribution of all possible mn targets with respect to their distance from our training set. a majority of targets were at most  <dig> nucleotides distant from the training set, indicating that we could safely apply our method to almost all potential mn targets.

another important question is how many molecules we needed to screen in order to have at least one positive mutant. additional file 1: figure s <dig> shows how the success rate of in silico approaches varied with the size of the screening pool. ten molecules seemed to provide a good compromise between the number of molecules tested and the corresponding success rate; six molecules were enough to have on average one active molecule and at least one active molecule for more than 50% of the targets tested.

key features in machine learning model
in this section we address why seqmact was more efficient than mact. as described in “cross-validation performance scores”, seqmact can be seen as an extended version of mact with additional features describing protein and target sequences. to determine whether any particular group of features contributed most to the performance boost, we tested alternative versions of seqmact trained on several subgroups of features:

• sm- <dig> : features encoding the p5n <dig>  part of proteins and dna sequences; no interactions between features; the relative performance of this model with respect to mact reflected the importance of the p5n <dig>  part of the sequences;

• sm-5_11: union of features from the two previous models; no interactions between features; the relative performance of this model with respect to sm- <dig> and sm- <dig> showed whether the combination of both parts  improved performance with respect to the individual use of each part;

• sm-m2m: all features from the sm-5_ <dig> model plus interactions between features encoding protein sequences; the relative performance of this model with respect to sm-5_ <dig> reflected the impact of simultaneous protein mutations, i.e. whether there were any combinations of protein mutations that were harmful  to protein activity on any target .

• sm-m2t: all features from the sm-5_ <dig> model plus interactions between features encoding protein sequences and features encoding target sequences; this reflected the importance of dependencies between protein and target sequences, i.e. whether there were any preferences between target and protein sequences in addition to the already known cleavage activities of the p5n <dig> and p11n <dig> modules on the corresponding targets;

• seqmact: union of all features used in previous models; the relative performance of seqmact and sm-5_ <dig> reflected the impact of 2nd order interactions between features encoding protein and target sequences, while the relative performance of seqmact, sm-m2t and sm-m2m could tell us if there was any particular group of 2nd order interactions  contributing most to the performance boost.

in addition to the m2m versus m2t split, we also split 2nd order interaction features into features encoding dependencies within the same ‘module’  - sm-intra, and 2nd order interaction features encoding dependencies between the p11n <dig> and p5n <dig> parts  - sm-cross.

the cross-validation performance of the alternative seqmact versions is presented in figure  <dig> . overall, the use of information on protein sequences tripled the average number of active proteins in the top  <dig> predicted and the number of targets with at least one positive protein in the top  <dig> . sm-5_ <dig> basically learned which protein mutations were bad and which were good independently of the target sequence, i.e. non-specific activity patterns. the performance of sm-5_ <dig> could be further enhanced by adding features describing simultaneous protein mutations . sm-m2m learned only non-specific activity patterns, but these patterns were more sophisticated: now the model also learned whether there were any particular combinations of protein mutations that were good or bad for overall performance. when we added target-specific interactions , we obtained an even higher performance boost. finally, when we combined all features , the result was a model that outperformed both the sm-m2t and sm-m2m models, meaning that both types of interaction were important in the final model.

the relative performance of the sm-cross and sm-intra models suggests that the major performance boost obtained after adding interaction features came from the features describing dependencies within the same modules.

examples of features with the strongest positive and negative impact in the model are given in additional file 1: table s <dig>  the negative impact of the 44f mutation could be probably explained by the enhanced rigidity of the second beta-strand due to the contemporaneous presence of the wild type 43f; on the contrary the mutation 32k could have triggered additional non-specific dna interactions. electrostatic repulsion between 44r and 77r may have been the cause of the negative effect of the simultaneous presence of these two mutations in the protein . most of the features describing protein-dna interactions corresponded to contacting positions, providing additional insights on which residues should or should not be used to target particular nucleotides.

activity versus specificity trade-off
cleavage activity on the target of interest is not the only parameter we would like to control in mn, another important characteristic is its specificity. since the prediction step was fast using the ml model compared to physical models, we could predict the activity of all candidate mutants on all possible targets in a matter of seconds and pick the mutant with the most specific profile or the mutant with the best trade-off between its predicted activity and specificity.

to assay experimentally a protein on all possible targets would require a tremendous amount of resources, so to validate our approach we used a set of  <dig>  proteins mutated at positions contacting the 5n <dig> region and screened them on all  <dig> possible 5n <dig> targets . screening all mutants on all targets enabled us to compute the specificity of all mutants in the same context . similarly to  <cit> , we computed the specificity of mutant pi on target tj as the ratio of the activity of pi on tj over the total activity of pi on all targets.

rather than simply predicting the most active mutant, we were able to alter our criteria to favor the prediction of active mutants that were at least as specific as the wild type i-crei on the same set of  <dig> 5n <dig> targets . to predict mutants that were active and specific at the same time, we first predicted the activity of the candidate mutants on all  <dig> 5n <dig> targets; we then computed the predicted specificity as the ratio of mutant activity on a given target of interest over the total activity on all  <dig> targets. finally, we ranked all candidate mutants according to the following score combining predicted activity and predicted specificity:

 rα=αa+1−αs 

where a and s are predicted activity and specificity, respectively.figure  <dig>  shows how the number of active mutants at least as specific as i-crei in the top  <dig> varied as a function of α. when we ranked the candidate mutants according to their predicted activity, we obtained only a few specific mutants , but when we output the most specific mutants we obtained very few active proteins. the results presented in figure  <dig> were natural in the sense that if we wanted to predict not only active but also specific mutants we had to use a combined score representing a trade-off between the predicted activity and specificity of candidate mutants.

de novo experiments: designing new custom mns
in the second series of experiments, we tested the ability of our ml model to predict mns on completely new dna targets. the experiments were done on two groups of targets, a first group sampled from the extended target space  , and a second group  sampled from the restricted target space   . the ets is defined by a set of constraints on the sequences of 2n <dig> and 7n <dig> regions and the existence of active p5n <dig> and p11n <dig> building modules, it corresponds roughly to one target every  <dig> base pairs. these constraints were necessary to ensure a good probability that the combinatorial approach would find an active mn  <cit> . the rts was defined as a subset of the ets with additional constraints on the set of 2n <dig> sequences , and 11n4-5n <dig> combinations , it corresponds to an average frequency of one target every  <dig> kbp.

for each target we predicted and tested  <dig> proteins . since the impact of 2n <dig> regions was independent of other regions and was not taken into account in the ml model, predicted mutants were also tested on variants of sampled targets with their 2n <dig> regions substituted by a gtac sequence . tests on gtac target variants enabled us to see the success rate of the ml model regarding the quality of prediction of the optimal mn binding interface independent of any influence of the 2n <dig> region.in the first series of experiments,  <dig> mns were predicted for  <dig> dna targets sampled from the ets. figure  <dig>  seqmact presents the success rate  of ml predictions on the first group of targets . orig and gtac denote the success rate over the original sampled targets and their gtac variants, respectively. we also report the proportion of orig targets with at least one strongly active mn: origstrong . overall, 62%  of gtac targets and 23%  of orig targets were cut. among the six orig targets cut, three had strongly active mns.

it is known  <cit>  that additional mutations such as i132v can help boost the activity of mns. in the second series of experiments  <dig> mns were predicted for another  <dig> targets sampled from the ets, and this time all predicted mns were synthesized with the additional mutation i132v. figure  <dig>  seqmact + shows the success rate of ml predictions with additional i132v mutations. although small sample sizes did not enable us to say that there was a statistically significant difference between success rates with and without the additional i132v mutation, the proportion of successfully cut gtac targets went up to 83%, targets with original 2n <dig> up to 58%, and strongly cut original targets up to 16%.as a comparative reference, we report the success rate of the combinatorial process  on a much larger body of  <dig> targets also sampled from the ets  comb). overall, using ml predictions provided us with a success rate that was competitive in relation to that of high-throughput screening, with  <dig> times fewer molecules tested.

in the last series of experiments, we hypothesized that we could still improve the success rate of ml predictions by choosing targets that would be expected to be the easiest to cut  <cit> . to this end,  <dig> targets were thus randomly sampled from the more stringent rts and assayed both with the original 2n <dig> and gtac ). indeed, the success rate on gtac targets and targets with the original 2n <dig> went up to 92% and 90% respectively . the success rate of comb on the rts was the same as on the ets.

discussion
apart from a significant boost in performance, relatively low performance of mact with respect to seqmact models provided additional evidence to the hypothesis of non-negligible interdependency between p11n <dig> and p5n <dig> protein domains  <cit> . furthermore the performance of alternative ml models trained on different subsets of features  suggested that the principal gain in performance was coming from a better selection of starting p11n <dig> and p5n <dig> modules that keep their activity profile when combined with each other, therefore providing a basis for the desirable factorization of the binding interface.

there are several explanations for the difference in performance between the ml approach and physical models. first, physical models rely on the computation of binding energy as the only important factor to predict active mns. however in reality there are other factors such as protein expression and cleavage activity that can greatly influence the final activity of mns. with the ml approach we directly model the final outcome, which may be much harder to handle with a physical model. second, existing physical models use many approximations and simplifications that significantly reduce computation time, but which may have a negative impact on precision. the majority of the computational studies predicting dna binding affinity for mns have used a very conservative approach, only one base has been allowed to change. in  <cit>  a triple base change was reported. in  <cit>  many possible reasons for the difficulty of generating new in silico mns are clearly discussed.

whereas the main in silico experiments with physical models were carried out using only one structure, we also studied the possibility of using more than one structure to build our models. on 20% of the original combinatorial dataset we tested the performance of the method using three different structures . no detectable improvements could be reported , suggesting that a much wider structural coverage of potential mn/dna target pairs is necessary to improve the success rate of physical models in large scale experiments.

concerning the application of ml approaches to the design of new dna-binding proteins, active learning methods  <cit>   as a more efficient way to collect the training data is an interesting direction for future research. such a method would be especially useful when starting data collection for a new binding scaffold since it would help to choose the most informative examples for sampling and to reach faster the optimal success rate.

CONCLUSIONS
in this study we address the application of a machine learning approach to the design of meganucleases cutting specific dna targets. our results are very promising in that the ml model significantly outperformed state-of-the-art in silico models such as foldx and rosetta. in addition, our method had success rates competing with those of combinatorial high-throughput screening, while reducing the number of molecules screened by several orders of magnitude. in experimental validation, the ml model successfully predicted active mns for  <dig> new dna targets. the boost in performance brought by the ml model comes with a price, as one needs a training set to learn the model, meaning it cannot be used completely ab initio. however, if a training set already exists, or if one is prepared to invest in building a new one, this could be considered a very interesting alternative to existing methods. in the case of mns, experimental results on  <dig> dna targets were already enough to train a machine learning model that outperformed existing in silico models.

