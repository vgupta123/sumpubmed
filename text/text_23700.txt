BACKGROUND
the use of current high-throughput genotyping technologies  provides information on alleles present at a locus of a diploid individual’s dna, but not on the assignment of alleles along the same chromosome defining a haplotype. knowledge of haplotypes of individuals from a population sample is important for inferring population evolutionary history  <cit> . besides, haplotypes are examined in disease association studies to map patterns of genetic variation to diseases  <cit> . in the context of unrelated hematopoietic stem cell transplantation , population-specific human leukocyte antigen  haplotypes and their respective frequencies are of particular interest in strategic donor registry planning  and donor searches for individual patients using hla matching algorithms .

haplotypes can be inferred using genealogical information in families combined with targeted typing . however, especially in large-scale studies this approach might not be feasible, as required information is not available or its provision is associated with additional costs. for instance, data as found in registries of unrelated potential hsct donors generally lack information on family pedigrees. as an alternative, haplotype frequencies can be estimated from population-specific genotype data using a maximum likelihood estimation via an expectation-maximization  algorithm .

estimating hla haplotype frequencies from potential hsct donor registry typing records faces particular challenges. these challenges include large data sets, the complex hla nomenclature  <cit> , the heterogeneous nature of typing data in donor registries which originates from genotype data being recorded over extended periods of time using different strategies for applied typing resolution and typing profile  <cit> , and genotyping ambiguities. genotyping ambiguities result from typing techniques not being able to identify exactly two potentially different alleles at an individual’s specific hla locus. two types of genotyping ambiguities exist  <cit> : allelic and phase ambiguities. the former can occur when the nucleotide sequence is not completely examined, the latter when the chromosomal phase between polymorphisms cannot be established.

typing results are recorded using designations assigned to hla alleles by the who nomenclature committee for factors of the hla system  <cit> . these designations consist of up to four colon separated fields with digits which give information on the underlying nucleotide sequences. in hsct, nucleotide sequences of exons encoding peptide and antigen binding domains are of particular importance  <cit> . hla class i  alleles with identical nucleotide sequences of exons  <dig> and  <dig>  are summarized as g groups, whereas hla class i  alleles with identical amino acid sequences of exons  <dig> and  <dig>  are summarized as p groups  <cit> . alleles can also be summarized as g groups  <cit> , which are defined analogous to p groups but include null alleles. the hla nomenclature  <cit>  provides hla codes for p and g groups but not for g groups.

it has been shown that high-resolution  hla matching is beneficial for transplantation outcome  <cit> . the relevance of sequence differences outside the antigen-recognition domain  is still under debate  <cit> . a summary of typing resolutions and allele groups together with their definitions is shown in table  <dig> table  <dig> definitions of hla typing resolutions and allele groups. for example, hla alleles whose names share the same first two fields code for identical amino acid sequence. hapl-o-mat is able to translate between these typing resolutions and groups

 <dig> fieldsa
 <dig> fieldsa

awithin the hla nomenclature,  <dig> field designations comprise more field designations if the  <dig> field designation actually groups more than one allele, only. if the  <dig> field designation is already the full length designation, it is used as equivalent to  <dig> and  <dig> field designations in this paper




the national marrow donor program  has developed a broadly used system for reporting typing ambiguities by the introduction of hla multiple allele codes known as nmdp codes  <cit> . if a typing yields an allelic ambiguity, all fields in the allele name except the first one are replaced by a letter code, currently comprising two to five letters, which encodes the possible alleles. additionally, some nmdp codes represent alleles of different allele groups. however, since nmdp codes only consider information included in the first two fields, their use leads to a loss of information beyond the amino acid sequence. furthermore, as nmdp codes do not include any phase information, phase ambiguities are transformed to and recorded as allelic ambiguities. this introduces new genotypes in addition to the original genotyping result  <cit> . an alternative to the nmdp code system are genotype list  strings  <cit> . gl strings represent genotyping results including allelic and phase ambiguities without any coding-induced loss of information. p, g, and g groups are multiple allele codes as well. however, unlike gl strings and nmdp codes that impose no or virtually no restriction to members of a specific code, p, g, and g groups are only available as sets of alleles matching specific criteria .

although several programs implement the em algorithm for estimating hla haplotype frequencies, none is able to entirely deal with the above mentioned challenges. one of the first freely available implementations of the em algorithm was the software “haplo”  <cit> . it handles incomplete typing data on some individuals and includes typing data from an individual’s relatives to complete or partially resolve the genotype. additionally, it estimates errors on the derived haplotypes using a jackknife approach or the binomial standard error. the software “arlequin”  <cit>  supports different types of input and output data and includes several methods for population genetics data studies. it provides the standard em algorithm and an extended version, the em zipper algorithm, where haplotypes are reconstructed locus-wise. furthermore, it supports the estimation of errors on derived haplotype frequencies using a bootstrap method. however, neither haplo nor arlequin are able to translate between different typing resolutions or to handle genotyping ambiguities. the software “pypop”  <cit>  includes several methods for performing population genetic analyses including the em algorithm and focuses on analyses across many population data sets. with regard to the challenges found in potential hsct donor registry typing records, pypop checks hla alleles in an input population for validity and can translate between typing resolutions of alleles but is currently restricted to a limited selection of possible translations. it is not capable of handling genotyping ambiguities. besides various population genetics methods, the set of gene  <cit>  programs includes a gene counting tool claimed to be equivalent to the em algorithm to estimate haplotype frequencies. optionally, the computation can include deviations from hardy-weinberg equilibrium  via an inbreeding coefficient. the tool is able to handle genotyping ambiguities. however, it does not support nmdp codes or gl strings but relies on its own syntax. furthermore, translations of allelic to other typing resolutions are not supported. all gene tools are executed online via a web service, only.

to meet the challenges encountered in hla haplotype frequency estimation from typical potential hsct donor registry data, we developed the open-source software hapl-o-mat  <cit> . hapl-o-mat computes haplotype frequencies from population samples with arbitrary numbers of loci using an em algorithm. although it is not restricted to, it is specifically developed for hla typing records . thus, it has the functionality of translating between various typing resolutions of a given hla gene. the result of an hla gene typing in a given resolution can be expressed by its comprised alleles or by a g, p, or g group  <cit>  or it can be reduced to fewer fields in the allele name. thus, typing records can be transformed to a uniform resolution rendering the typing resolution of input data for the em algorithm homogeneous. the typing resolution is specified per locus by the user according to his needs. furthermore, hapl-o-mat checks input data including hla alleles for validity and processes genotyping ambiguities recorded as multiple allele codes  or gl strings. finally, its efficient implementation in c++ makes the estimation of haplotype frequencies from large data sets of up to millions of unphased genotypes feasible.

in the following, we review the em algorithm and describe the implementation aspects hapl-o-mat uses to process genotype data and to estimate haplotype frequencies including translating between typing resolutions, resolving genotyping ambiguities, and initializing haplotype frequencies. we present hapl-o-mat validation results in terms of accurate haplotype frequency estimation using artificial data with known haplotype frequency distribution and comparisons with results provided by the software arlequin  <cit> . finally, we evaluate the computational performance of hapl-o-mat.

expectation-maximization algorithm
haplotype frequencies can be estimated from population data using an em algorithm. it computes the most probable set of haplotypes explaining the unphased genotype input data via a maximum likelihood estimation. starting from arbitrary initial haplotype frequencies, it calculates genotype frequencies under the assumption of hwe . after normalizing, these genotype frequencies are used to estimate haplotype frequencies . expectation and maximization steps are repeated until a stop criterion with predefined value is fulfilled.

the estimated likelihood is maximal within the precision of the stop criterion. however, the likelihood can reach multiple local maxima due to the non-linearity of the em algorithm. the chance of arriving at a global maximum can be increased by running the em algorithm several times with different initial haplotype frequencies.

implementation
the workflow of hapl-o-mat is divided into two major parts. first, hapl-o-mat preprocesses the input genotype data. this step includes resolving genotyping ambiguities and translating alleles to a uniform resolution per locus. second, hapl-o-mat computes the most likely set of haplotypes including their frequencies via the em algorithm. the workflow is illustrated in fig.  <dig> fig.  <dig> workflow of hapl-o-mat. the main process is divided into data preprocessing and estimation of haplotype frequencies via the em algorithm. the data preparation is illustrated for one individual mlg, which is split into several slgs. after all individuals are processed, the estimation of haplotype frequencies starts. expectation and maximization steps alternate until the stop criterion is fulfilled




data preprocessing
input data to hapl-o-mat is a population sample of genotype data. the data is read individual by individual and each multiple-locus genotype  is split into one genotype per locus ). the process of data preparation is exemplarily illustrated by two examples given in additional file  <dig> 

hapl-o-mat starts processing slgs by resolving existing genotyping ambiguities. if the genotyping result was produced by sanger sequencing-based typing, the number of resulting allele combinations can be reduced by applying an optional ambiguity filter. it only includes allele pairs that are possible but cannot be distinguished due to implicit ambiguities  <cit> . otherwise, alleles are combined via a cartesian product over both locus positions.

next, alleles at the slg are checked for validity. to this end, allele designations are compared to a list of all existing allele designations. this list is a copy of the allele designations database maintained by the who nomenclature committee for factors of the hla system  <cit>  and is simply extracted by running a script before starting hapl-o-mat.

in order to deal with heterogeneous typing data, hapl-o-mat transforms slgs to a uniform typing resolution. to this end, hapl-o-mat is capable of translating locus-wise between all typing resolutions and allele groups listed in table  <dig>  the translation process is explained in additional file  <dig>  if a translation yields several alleles per locus position, the alleles are combined via a cartesian product over both locus positions.

referring to the hla nomenclature, a hla typing with more fields contains more information on the underlying nucleotide sequence. however, translating typing results to a higher resolution is not associated with an information gain, since an expansion always includes all enclosed allele names equally weighted. on the other hand, translating to a lower resolution causes an information loss, due to the exclusion of fields from the allele designation.

after resolving genotyping ambiguities and translating to a uniform typing resolution, the resulting slgs are combined to a set of mlgs using a cartesian product. thus, the original genotype from one individual can split into several genotypes of the envisaged target resolution. these are weighted by fractions summing up to one, as an individual actually only carries one genotype. if the initial genotype splits into a large amount of target genotypes, corresponding fractions can become small. as the effect of occasional low-weighted genotypes in haplotype frequency estimation is negligible  <cit>  and additional genotypes are computationally expensive in terms of speed and memory requirements, hapl-o-mat discards genotypes which split into more target resolution genotypes than a user-defined number from further analysis.

finally, hapl-o-mat constructs diplotypes  and haplotypes from the resulting genotypes. these enter the second part of hapl-o-mat, the estimation of haplotype frequencies via the em algorithm.

haplotype frequency estimation
hapl-o-mat computes the most likely set of haplotype frequencies accounting for the unphased input genotype data via an em algorithm. it supports three different routines to initialize haplotype frequencies. first, frequencies are set to 1/nh with nh being the initial number of haplotypes. second, frequencies are initialized according to numbers of occurrence of the respective haplotypes. third, frequencies can be assigned randomly. the latter approach is implemented as adding a perturbation to frequencies initialized by the second method or as a completely random initialization. random numbers are generated by a mersenne twister pseudorandom number generator  <cit> .

after initialization, expectation and maximization steps are repeated until the maximal change in haplotype frequency between consecutive estimations is smaller than the stop criterion, a parameter specified by the user. after reaching the stop criterion, estimated haplotype frequencies smaller than a user-specified threshold are removed and, if specified by the user, the remaining haplotype frequencies are normalized. eventually, inferred haplotypes with their respective frequencies are saved in an ascii file format.

RESULTS
we validated hapl-o-mat by checking its estimated haplotype frequencies for correctness. as translating between allele resolutions and resolving genotyping ambiguities are not supported by other software for haplotype frequency estimation, we followed two approaches. first, we validated hapl-o-mat against artificial hla population data including different typing resolutions and genotyping ambiguities. for such artificial populations haplotype frequencies were known per construction. taking the complete population data as an input sample, we used hapl-o-mat to resolve genotype data and to reproduce haplotype frequencies. second, we compared results obtained from hapl-o-mat to results from the easy to use and well-established software arlequin  <cit> . we used real samples of typing records from the dkms donor center and artificial population data as input for both implementations. furthermore, we evaluated the computational performance of hapl-o-mat in general and in comparison to arlequin. the target resolution for all validation experiments are g groups unless noted otherwise.

for observables to compare haplotype frequencies and for the construction of artificial populations, see methods in additional file  <dig>  all results are summarized in table  <dig> table  <dig> comparison of haplotype frequencies using distanced, maximal absolute difference between frequencies \increment, and first rank with a relative deviation larger than  <dig> , ρ


d
∆
ρ
 <dig> ×10-4
 <dig> ×10-7
 <dig> ± <dig> 
4±1×10-3
14±6
 <dig> 
 <dig> ×10-3
1
 <dig> 
 <dig> ×10-3
1
 <dig> 
 <dig> ×10-4
106
 <dig> ± <dig> 
9±2×10-4
41±23
the observables were computed on basis of original and estimated haplotype frequencies. for the first artificial population, where we compared hapl-o-mat to population data, the column “remark” indicates details of construction. for the other two genotype data sets, it indicates the sets of haplotype frequencies that are compared to each other, e.g. “hapl-o-mat – population” means haplotype frequencies obtained from hapl-o-mat were compared to original population haplotype frequencies




first population model
the first artificial population was built by combinatorial construction of genotypes from all possible combinations of the  <dig>  most frequent german haplotypes with replacement, as explained in additional file  <dig>  the population was in almost perfect hwe as indicated by the effect size statistic wn= <dig> ×10- <dig>  to check translations between typing resolutions of hapl-o-mat, we replaced typing results with results in higher typing resolution including the original typing result, e.g. each occurrence of c*16: <dig> was randomly replaced by c*16:04: <dig>  c*16:04: <dig>  or c*16:04p or left unchanged as c*16: <dig>  we used hapl-o-mat to translate the modified typing resolutions back to g groups and to estimate haplotype frequencies. the distance between estimated and original population haplotype frequencies was d= <dig> ×10- <dig>  the maximal absolute difference was ∆= <dig> ×10- <dig>  and no relative deviation larger than  <dig>  was found. these results indicated reproduction of the original population haplotype frequencies. exact reproduction cannot not expected, as approximating genotype frequencies by integer numbers in the population data escapes floating point precision.

to validate the estimation of haplotype frequencies from genotype data including genotyping ambiguities, we introduced, in a second test, nmdp codes to the genotype population data. to this end, we randomly replaced 5% of typing results with nmdp codes. the codes were selected randomly except for the requirements to include the original typing and to have appeared in the original real population data. for example, all alleles typed as a*31:01 g were replaced with a*31:vscb, which encodes a*31: <dig>  a*31: <dig>  and a*31: <dig> yielding two additional alleles . hapl-o-mat with its ambiguity filter was used to resolve these ambiguities, translate the resulting alleles back to g groups, and compute haplotype frequencies. we repeated this procedure ten times to compute mean and standard deviation of observables.

comparison between estimated and original population haplotype frequencies showed an average distance of d= <dig> ± <dig> , and an average maximal absolute difference of ∆=4±1×10- <dig>  the average rank for the first haplotype with a relative deviation larger than  <dig>  was ρ=14± <dig>  compared to the first test, these larger values are explained by the occurrence of nmdp codes, which introduce additional alleles and thus mask real alleles. this obscures the identification of haplotypes by increasing the number of haplotypes not present in the original population set  and haplotypes only present in the original population set . the number of additional haplotypes is expected to be larger than the number of missing ones, since an nmdp code replaces only one allele but can yield several others when decoded. in the ten repetitions of the second test, on average 314± <dig>  haplotypes were “additional” and 50± <dig>  “missing”. these haplotypes made the major contribution to the difference between estimated and population haplotype frequencies. excluding additional and missing haplotypes from computing the distance yielded d= <dig> ± <dig> .

original population and estimated frequencies are shown in fig. 2a. as additional haplotypes have an original population frequency of hk= <dig> and missing haplotypes have an estimated frequency of hk= <dig>  additional and missing haplotypes are not shown in fig. 2a or in further log-log plots to come. major deviations in haplotype frequencies were due to the occurrence of nmdp codes. if a haplotype included an allele which was masked by an nmdp code, its estimated frequency was reduced. if, on the other hand, a haplotype included additional alleles from an nmdp code, its estimated frequency increased. only in few cases the frequency gain from additional alleles is transferred to haplotypes already present in the original population data. for this reason, almost no overestimation of haplotype frequencies  occurs in fig. 2a. however, the frequency loss from masked alleles belonging to haplotypes present in the original population data results in underestimation as found in fig. 2a. haplotypes which did not share alleles via nmdp codes only showed minor deviations between original population and estimated frequencies.fig.  <dig> haplotype frequencies from artificial population data. plot a shows haplotype frequencies estimated via hapl-o-mat compared to original population frequencies from the first population model including genotyping ambiguities. only one of ten runs is illustrated. plot b shows a comparison between original population haplotype frequencies and frequencies estimated via arlequin and hapl-o-mat on basis of the second population model. due to the logarithmic scales, both plots neither show additional nor missing haplotypes




the fact that some estimated haplotype frequencies have a constant offset with regard to their original population frequency follows from sharing alleles found in the same nmdp code. the frequencies are reduced in proportion to the number of additional alleles emerging from the nmdp code. as a consequence, frequencies of haplotypes including alleles from the same nmdp code are reduced by the same factor.

second population model
the second population was built by constructing genotypes from randomly combining two haplotypes according to their frequency distribution as explained in additional file  <dig>  the effect size statistic averaged over all loci for this population was wn= <dig> ×10- <dig> indicating no significant devation from hwe. we computed haplotype frequencies from these population data using arlequin and hapl-o-mat. the estimated and original population haplotype frequencies are shown in fig. 2b. the corresponding observables are given in table  <dig>  both implementations performed equally well demonstrating the correct implementation of hapl-o-mat. however, in contrast to the first population model, deviations between estimated and original population frequencies were much larger both for arlequin and hapl-o-mat. this resulted from applying the em algorithm to data with a large amount of genotype diversity. as the data consisted of only n= <dig>  individuals but included  <dig>  different genotypes, the em algorithm was not able to exactly reproduce the original population haplotype frequency distribution. for this reason arlequin and hapl-o-mat, both based on the em algorithm, showed similar deviations between estimated and original population frequencies as observed in fig. 2b.

real data samples
finally, we estimated haplotype frequencies from real population data. ten samples of n= <dig>  individuals were drawn from n= <dig> , <dig> individuals of self-assessed german origin registered with dkms donor center and typed for hla-a, -b, -c, -drb <dig>  -dqb <dig>  and -dpb <dig>  we only included typing results translating unambiguously to 2-field resolution in order to be able to include arlequin into analysis. by averaging over ten samples, we give mean and standard deviation of each observable. the effect size statistic averaged over all loci and samples was wn= <dig> ± <dig> ×10- <dig> indicating no significant deviation from hwe.

comparing resulting haplotype frequencies between arlequin and hapl-o-mat, the distance was darlequinhaplomat= <dig> ± <dig> , the maximal absolute difference between frequencies was ∆arlequinhaplomat=9±2×10- <dig>  and the first rank with a relative deviation larger than  <dig>  was ρarlequinhaplomat=41± <dig>  these values were of similar magnitude as results from comparing arlequin to hapl-o-mat on basis of the second artificial population model, see table  <dig>  indicating a correct implementation of hapl-o-mat. the similarity of estimated haplotype frequencies is depicted in fig.  <dig> fig.  <dig> comparison of haplotype frequencies estimated via arlequin and hapl-o-mat from one sample of real population data. due to the logarithmic scales, the plot neither shows additional nor missing haplotypes




computational performance
we evaluated hapl-o-mat in terms of computational performance by measuring its runtime for different amounts of input data and different target resolutions. all computations were performed using a computer running ubuntu linux  <dig> . <dig> with 768 gb ram , and  <dig> intel® xeon® cpu e5- <dig> v <dig> cores at  <dig> ghz. however, hapl-o-mat does not make use of parallelism, hence all runtime are in reference to a single core.

the runtime for estimating haplotype frequencies by hapl-o-mat from n= <dig> , <dig> individuals with self-assessed german origin was t≈ <dig> h with g groups as target resolution.

we further drew random subsamples of sizes n= <dig> , n= <dig> , n= <dig> , n= <dig> , and n= <dig> individuals. for more information on the composition of these data please refer to additional file  <dig>  the sampling process was repeated ten times per sample size and target resolution to compute average times for running hapl-o-mat. the target resolution was varied between g, p, and g groups. hapl-o-mat was run with activated normalization, without ambiguity filter, and starting from perturbed initial haplotype frequencies. the runtimes are illustrated in fig.  <dig> fig.  <dig> average runtimes with standard deviation of hapl-o-mat for different sample sizes and different target allele groups including g, p, and g groups




in order to compare the performance between arlequin and hapl-o-mat, we repeated the haplotype frequency estimation from real population data. we varied the sample size between n= <dig> , n= <dig> , and n= <dig>  and similarly included only samples with unambiguous 2-field translation. averaging both implementations over ten runs on the same machine yielded runtimes as given in table  <dig>  especially in the case of large sample sizes, hapl-o-mat was considerably faster demonstrating its efficient implementation.table  <dig> average runtimes of arlequin and hapl-o-mat for estimation of haplotype frequencies from real population data

242±4
10±2
24±5
6617±971
39±4
170±30
40539± <dig> 
83±10
488±65



we also evaluated hapl-o-mat’s abilities to cope with the heterogeneous and ambiguous nature of typing records. we recorded runtime and memory usage on the machine described above as we varied the share of nmdp codes we introduced in the genotype population data for the first population model in the same manner as described above for a varying fraction of masked alleles from  <dig> % to 50%. hapl-o-mat with its ambiguity filter was used to resolve these ambiguities, translate the resulting alleles back to g groups, and compute haplotype frequencies. we repeated this procedure ten times to compute mean and standard deviation of memory usages and runtimes. the results are visualized in fig.  <dig> fig.  <dig> performance of hapl-o-mat with regard to varying share of typing records containing nmdp codes. plot a shows average memory usage with standard deviations and plot b average runtimes with standard deviations for both; data preprocessing and haplotype frequency estimation




CONCLUSIONS
we have presented hapl-o-mat, an open-source software for hla haplotype frequency estimation. it is the first publically available software that meets the challenges encountered in hematopoietic stem cell donor registry data. it supports translations between typing resolutions, is capable of resolving genotyping ambiguities, and handles large-scale hla genotype data, due to its efficient implementation in c++. its conjunction of data preprocessing and em algorithm in one software offers a straightforward way of haplotype frequency estimation from hla population data.

additional files

additional file 1: examples for data preprocessing. 

 
additional file 2: translation between typing resolutions. 

 
additional file 3: methods. 

 


abbreviations
emexpectation-maximization

glgenotype list

hfhaplotype frequency

hlahuman leukocyte antigen

hscthematopoietic stem cell transplantation

hwehardy-weinberg equilibrium

mlgmultiple-locus genotype

nmdpnational marrow donor program

slgsingle-locus genotype

electronic supplementary material

the online version of this article  contains supplementary material, which is available to authorized users.

