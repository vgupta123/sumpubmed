BACKGROUND
we describe an algorithm that transforms a collection of flow cytometry  samples in order to stabilize the variance within cell populations in each fluorescence channel for the entire collection of samples. this transformation enables cell populations  with homogeneous variances to be easily compared with each other by standard statistical methods. between-population comparisons are important in detecting changes in populations across biological conditions, which might help us to diagnose diseases, develop new drugs, and understand the immune system in general . hence, our variance-stabilization algorithm could play a supporting role in automating biological discovery based on flow cytometry and similar imaging technologies.

fc technology measures morphology  and the expression of multiple biomarkers  at the single-cell level. an fc sample consists of hundreds of thousands or more of such single-cell measurements, and a study could consist of thousands of samples from different individuals at different time points under different experimental conditions  <cit> .

variance inhomogeneity is an inherent problem in fluorescence-based fc measurements and can be an obstacle both for manual data analysis performed by qualified cytometry operators and for automated multi-sample comparisons, which typically rely on an intermediate step of cell clustering using a plethora of approaches from modified k-means to non-parametric bayesian methodologies  <cit> . the origin of the problem is the physics of fluorescence signal formation and the detection processes that monotonically increase the variance of the fluorescence signal with the average signal intensity  <cit> . for example, fig.  <dig> demonstrates how the variances of cell populations increase with their mean fluorescence intensities  in a set of fc samples collected from several healthy individuals. owing to such signal-variance dependence, a cell population with higher levels of marker expressions  has higher variance than another population with relatively low levels of marker expressions . this inhomogeneity of within-population variance creates problems in extracting features uniformly and comparing cell populations with different levels of marker expressions.
fig.  <dig> mean fluorescence intensities  of one-dimensional cell populations  are plotted against the variances of the populations. blood samples were collected from five healthy individuals on different days and stained with labeled antibodies against five biomarkers . samples are compensated and gated for the lymphocytes, but no transformation is used. populations identified in each fluorescence channel are shown with the same symbol and color. we observe that without proper transformation, variance increases monotonically with mfi



in order to demonstrate the flowvs results we evaluate the pre- and post-processing cluster homogeneity, and quantify the improvement offered by our approach. we report the results using a simple measure of effect size, rather than through a hypothesis-testing framework. as an example, consider the population registration problem in which corresponding cell clusters from multiple fc samples are identified based on the average levels of markers expressed by the clusters . the clusters of cells representing the same immunophenotype identified in multiple samples are represented by a hypothetical metacluster . the existence of metaclusters is typically assessed by hemopathologists or other skilled fc operators on the basis of their experience and knowledge of previous examples of normal and aberrant immunophenotypes. the biological hypothesis behind assigning a cluster to a metacluster can be formulated as “all clusters in a metacluster represent the same cell type .” however, translating this hypothesis to a null stating “all clusters in a metacluster have equal mean” and using a traditional hypothesis-testing framework accompanied by p-values may not be appropriate. first, we know that such a null hypothesis is unrealistic: biological variability, technical variability of blood or bone-marrow sample measurements, and random effects associated with the biochemistry of antibody binding will certainly produce clusters of differing means. second, a hypothesis-testing framework addresses only the question of whether the clusters have the same location, but it is not designed to measure the magnitude of the difference or lack of homogeneity within a postulated metacluster. finally, the p-values are affected by both cluster size and metacluster homogeneity. thus, the p-values obtained would not be comparable for various metaclusters or different clusters within metaclusters.

variance stabilization  is a process for dissociating data variability from mean signals . other fluorescence-based technologies such as the microarrays stabilize variance by data transformation . however, unlike microarray data, explicit vs is not usually performed in fc data analysis. traditionally, fc data are transformed with nonlinear functions to project cell populations with normally distributed clusters – a choice that usually simplifies subsequent visual analysis . recently, finak et al.  <cit>  used the maximum-likelihood approach to explicitly satisfy normality of the cell populations. ray et al.  <cit>  transformed each channel with the asinh function whose parameters are optimally selected by the jarque-bera test of normality . while these transformations approximately normalize fc data, they might not stabilize variance, as may be seen in figs.  <dig> and  <dig> 

the vs problem in fc, however, cannot be solved directly by applying mature vs techniques from the microarray literature. in microarrays, each gene is measured multiple times  and the between-sample variance for each gene is stabilized with respect to the average expression of the gene across samples. by contrast, variance is defined by within-population cell-to-cell variation in fc, and this within-population variance is stabilized with respect to the average expression of markers within each population. these contrasting objectives prevent us from applying vs methods from microarray literature directly to flow cytometry.

we address the need for explicit vs in fc with a maximum likelihood -based method, called flowvs, which is built on top of a commonly used inverse hyperbolic sine  transformation. the choice of asinh function is motivated by its success as a variance stabilizer for microarray data  <cit> . flowvs stabilizes the within-population variances separately for each fluorescence channel z across a collection of n samples. after transforming z by asinh, where c is a normalization cofactor, flowvs identifies one-dimensional clusters  in the transformed channel. assume that a total of m 1-d clusters are identified from n samples with the i-th cluster having variance σi <dig>  then the asinh transformation works as a variance stabilizer if the variances of the 1-d clusters are approximately equal, i.e., σ12∼σ22∼…∼σm <dig>  to evaluate the homogeneity of variance , we use bartlett’s likelihood-ratio test  <cit> . from a wide range of cofactors, our algorithm selects one that minimizes bartlett’s test statistic, resulting in a transformation with the best possible vs. note that, in contrast to other transformation approaches, our algorithm applies the same transformation to corresponding channels in every sample. flowvs is therefore an explicit vs method that stabilizes within-population variances in each channel by evaluating the homoskedasticity of clusters with a likelihood-ratio test.

using a healthy-subject data set from purdue and publicly available immune tolerance network  data, we demonstrate that flowvs removes the mean-variance dependence from raw fc data and makes the within-population variance relatively homogeneous. we demonstrate that alternative transformation techniques might not stabilize variance. variance homogeneity is especially useful to build metaclusters from a collection of phenotypically similar cell populations across samples  <cit> . previous studies  shifted the distribution of each fluorescence channel to ensure homogeneity in metaclusters, but such shifting might hide useful biological signals present in the mfis of cell populations. by contrast, we can build homogeneous metaclusters from variance-stabilized populations without removing the differences in their mfis. hence, flowvs could provide additional flexibility in processing and analyzing a large collection of fc samples.

related work
vs has been a widely studied topic in applied statistics for its central role in making heteroskedastic data easily tractable by standard methods. heteroskedasticity appears in various data sets mostly because the data follow a distribution with correlated mean and variance, e.g., poisson or gamma; there are many more examples, but these two are relevant for fluorescence. for well-known distribution families, vs is usually performed by transforming data with an analytically chosen function f. for example, f=z+3/ <dig> works as a good  stabilizer for a random variable z following the poisson distribution  <cit> . variance stabilizers for several well-known distribution families are described in  <cit> . for unknown distributions, heuristic and data-driven stabilizers are often used .

however, traditional transformations are often inadequate for low-count  signals  <cit>  because of unknown error patterns in fluorescence data. past work developed ad hoc vs schemes for different types of fluorescence data. for example, in microarrays, the vs problem has been addressed by various non-linear transformations . most notably, the widely used approach by huber et al.  <cit>  uses an asinh transformation whose parameters are selected by a maximum-likelihood estimation.

for fc data, researchers have used various non-linear transformations, such as the logarithm, hyperlog, generalized box-cox, and biexponential  functions . in past work, parameters of these transformations were adjusted in a data-driven manner to maximize the likelihood , to satisfy the normality , and to comply with simulations . flowtrans estimates transformation parameters for each sample by maximizing the likelihood of data’s being generated by a multivariate-normal distribution on the transformed scale. flowscape optimizes the normalization factor of asinh transformation by the jarque-bera test of normality. fcstrans selects the parameters of the linear, logarithm, and logicle transformations with an extensive set of simulations. however, normalizing data may not necessarily stabilize its variance, e.g., for a poisson variable z, z+3/ <dig> is an approximate variance-stabilizer, whereas z2/ <dig> is a normalizer  <cit> . therefore, we consider an approach built upon the well-known asinh transformation and estimate transformation parameters for explicitly stabilizing within-population variations.

methods
motivation
consider two representative samples from the itn data set taken from the flowstats package in bioconductor. we gate the samples for lymphocytes, transform using an asinh transformation , and plot t-cell subpopulations and distribution of cd <dig> marker in fig.  <dig>  across these two samples, t-cell subpopulations have different proportions and mfis. for example, in subfig. 2a and 2c, cd8+ t-cell subpopulation is  <dig>  % of total t-cells with mfi  <dig> . by contrast, cd8+ t-cell subpopulation is  <dig>  % of total t cells with mfi  <dig>  in subfig. 2b and 2d. should we consider the differences between cd8+ populations in these two samples to be biologically significant? the answer to this question depends on our assumption about the data. if we assume that a cell type either expresses or does not express a biomarker and that the biological information lies only in the proportion of positively and negatively expressed cells, then mfi does not bear meaningful information other than defining positive and negative cells. in this case, we could consider the differences in mfis across cell populations of the same type as technical variations and eliminate them by aligning cell populations described by hahne et al.  <cit>  and finak et al.  <cit> . however, past work has shown that both cell proportion and mfi can possess biological information  <cit> . hence, aligning cell populations to a common mfi might remove meaningful biological signal from data. in the latter case, we want to compare mfis of cell populations to evaluate whether they are statistically different. a common statistical approach to compare average expressions of cell population is to use a statistical test in an anova model that explicitly requires that variance be approximately stabilized in populations. hence, vs is necessary to detect statistically meaningful changes across populations from different samples.
fig.  <dig> subfigs.  and  show the 2d-projections of t-cell subpopulations from two samples in the itn data set. distributions of cd <dig> marker are shown below the corresponding samples in subfigs.  and 



the goal of vs in flow cytometry
the aim of vs in fc is to make within-population variances of different cell populations approximately equal and thereby independent of the average marker expressed by populations. recall that the expression of a marker is measured by the intensity of light at a particular channel of fluorescence. vs therefore stabilizes the within-population fluorescence variance and makes it independent of the mfis of the cell populations. in this paper, we refer to fluorescence channels more frequently because the nature of fluorescence emissions – not the protein expressions – dominates the mean-variance relationship in fc data. we do not stabilize variance on the scatter channels because, as pointed out by finak et al.  <cit> , there are few benefits to transforming forward- and side-scatter channels.

channel-specific variance stabilization
we assume that correlations among fluorescence channels due to the overlap of spectra are removed by spectral unmixing before we transform data. even though the expression of biomarkers can still be correlated  <cit> , we do not incorporate such correlations in vs because the nature of such correlation is difficult to model. therefore, we assume that compensated fluorescence channels are independent and stabilize variance on each channel separately.

selecting an optimal transformation for fc data is a nontrivial problem because the accurate error model of fc data is often unknown. in previous work, researchers have successfully used a number of functions to transform fc data, such as logarithm, asinh, box-cox, logicle, etc.  <cit> . in our flowvs algorithm, we decided to use the asinh function to transform fc data. this choice of asinh function is motivated by its success in fc data visualization and normalization  <cit>  and in stabilizing variance in fluorescence readouts from microarray data  <cit> . stabilizing variance with other transformations can be performed using the same flowvs framework but is not discussed here.

to transform a fluorescence channel z, we use the asinh transformation with a single parameter c: 
  <dig> asinh=ln2+1). 

in this transformation, c is called the normalization cofactor, whose value is optimally selected to stabilize within-population variance in channel z. note that in a more general form asinh transformation is expressed with three parameters, a∗asinh, where in addition to the cofactor c, a denotes a scaling after transformation, and b denotes a translation before transformation. we set a= <dig> because scaling after transformation does not affect downstream analysis and set b= <dig> to avoid shifting cell populations. hence, we are left with a single parameter c whose value is estimated in order to stabilize the variance.

the flowvs algorithm
assume that we have a collection of n fc samples. then the objective of the flowvs algorithm is to transform each sample such that the within-population variance is stabilized in each fluorescence channel across n samples. here, we describe the algorithm for a single channel z; the process can be applied independently to other channels. first, we discuss the process of evaluating homoskedasticity of a transformed channel for a selected cofactor c by computing bartlett’s likelihood-ratio test. then, we elaborate the process of selecting an optimum cofactor that would stabilize variance when used with asinh transformation.

steps to compute bartlett’s statistic on channel z for a selected cofactor c
step1:transforming channel z in each sample. let zj be a vector denoting channel z in the j-th sample, where 1≤j≤n. we transform zj by the asinh function: zj′=asinh, where zj′ is the transformed channel.

step2:detecting 1-d density peaks . we estimate the density of zj′ by a kernel density estimation method . the peaks in the density of zj′ are identified as regions of high local density and significant curvature . we identify high-density regions in zj′ by the curv1filter function of the flowcore package  <cit>  in bioconductor. the boundaries of density peaks are identified by detecting minima between two adjacent density peaks. here, a density peak represents a 1-d cluster of cells. let pj be the collection of all density peaks identified in zj′.

step3:collecting density peaks from all samples. let p be the set of density peaks collected from all samples, i.e., p=∪1≤j≤npj. let p contain a total of m density peaks where the i-th peak contains ni cells with mean μi and variance σi <dig> 

step4:computing bartlett’s test statistic. let n=∑1≤i≤mni be the total number of cells in p and σp <dig> be the pooled variance of m density peaks. then we compute bartlett’s statistic as follows: 
  <dig> b=lnσp2−∑i=1mlnσi21+13∑i=1m1ni−1−1n−m. 

this statistic b is specific to the cofactor c used to transform the data and measures the degree of homogeneity across all 1-d clusters in the transformed channel z′.



finding a cofactor for optimum vs
the optimum variance-stabilizing cofactor c∗ is a cofactor giving the minimum value of bartlett’s statistic: 
  <dig> c∗=argminb. 

minimizing eq.  <dig> is a nontrivial optimization problem because bartlett’s test statistic b depends indirectly on the cofactor c and is not differentiable with respect to c. this prevents us from applying optimization methods from the gradient-descent family. therefore, we employ a piecewise minimization without derivatives  <cit> . let clow and chigh be the lowest and highest possible values of the cofactor on a logarithmic scale. by default, we set clow=− <dig> and chigh= <dig>  i.e., the lowest and highest values of cofactor is exp∼ <dig>  and exp∼ <dig>  respectively. users can also supply these extreme values. we assume that the optimum cofactor lies in the range . then the optimization procedure works as follows: 
 we divide the interval  into k= equal regions where the i-th region is defined by the interval  and ci+1−ci= <dig> 

 for the i-th interval, we look for a cofactor in the range  with minimum bartlett’s statistic. for each cofactor, we compute the bartlett’s statistic with the steps described in sec.  <dig>  for faster convergence, we call the optimize function from the stats package in r, which uses a combination of golden section search and successive parabolic interpolation  <cit> . interested readers might see the r documentation for a detailed description of the function. let ci∗ be the optimum cofactor in the i-th interval with the associated bartlett’s statistic b.

 we identify the overall optimum cofactor c∗ as follows: 
  <dig> c∗=argmini=1kb. 



equation  <dig> provides an approximate solution to eq.  <dig>  since we divided the search space into smaller intervals, the probability of having multiple local optima in an interval is small. hence, the procedure described above is expected to return a variance stabilizing cofactor. after we obtain the optimum cofactor c∗, channel z in each sample is transformed by asinh and used in subsequent analysis.

RESULTS
data sets
we demonstrate the use of flowvs and other related methods by using a healthy-subject data set from purdue university  and publicly available immune tolerance network  data. the original hd data set consists of  <dig> samples from five healthy individuals who donated blood on different days  <cit> . here, for simplicity, we used a smaller subset of the hd data set consisting of  <dig> samples from three healthy individuals, “a”, “c”, and “d”. from each individual, we keep samples from two  days and two technical replicates from each day. each hd sample was stained using labeled antibodies against cd <dig>  cd <dig>  cd <dig>  cd <dig>  and cd <dig> protein markers. in this paper, an hd sample “c_4_2” means that it is collected on day  <dig> from individual “c” and it is the second replicate on that day. the healthy data set is part of our bioconductor package flowvs. the itn data set is collected from  <dig> patients. it includes  <dig> patient groups with  <dig> samples each. each sample was stained using labeled antibodies against cd <dig>  cd <dig>  cd <dig>  cd <dig> and hladr. the itn data set is available in the flowstats package in bioconductor. we selected these data sets because they are available in standard r packages. hence, the results presented here can be easily reproduced.

we identify lymphocytes in each sample of the hd and itn datasets by using a two-step gating shown in fig.  <dig>  in this paper, we perform data transformation only on lymphocytes.
fig.  <dig> identifying lymphocytes by a two-step gating from a representative sample in the hd data set. a we select an approximate rectangular region in the lower left corner of side-scatter vs. forward-scatter plot. b a dense elliptical region within the rectangular gate defines lymphocytes



stabilizing variance in the hd dataset
at first, flowvs identifies an optimum cofactor for asinh transformation for each fluorescence channel of the hd dataset. this process is performed by identifying density peaks in each channel and minimizing bartlett’s statistic, as described in section  <dig>  the top row in fig.  <dig> shows bartlett’s statistic computed from density peaks of all samples after the data are transformed by asinh transformation with different cofactors. the range of values of the cofactor is selected by the automated algorithm described in section  <dig>  an optimum variance-stabilizing cofactor is obtained where bartlett’s statistic is a minimum. from fig.  <dig>  the variance-stabilizing cofactors for different markers are:   <dig>  for cd <dig>    <dig>  for cd <dig>    <dig>  for cd <dig>    <dig>  for cd <dig>  and   <dig>  for cd <dig>  for every channel except cd <dig>  we obtain a clear global minimum, denoting the existence of a unique variance-stabilizing cofactor with respect to bartlett’s test. for cd <dig>  we observe a sharp decrease in bartlett’s statistic at cofactor  <dig> . since cd <dig> is a common leukocyte marker, it is always expressed on lymphocytes – the subset of cells that we preselected for this study. hence, most cells are cd45+ in our preprocessed samples, which might produce a non-convex relationship between bartlett’s statistic and cofactors. for the same reason, the value of bartlett’s statistic at the optimum cofactor for cd <dig> is the smallest  compared to the minimum value of bartlett’s statistic achieved in other channels. note that the minimum bartlett’s statistic denotes the degree to which we are able to stabilize the within-population variance of a channel considering the between-sample variations.
fig.  <dig> transforming five fluorescence channels in hd data. subfigures in the top row show bartlett’s statistic computed from density peaks after data are transformed by different cofactors. an optimum cofactor is obtained where bartlett’s statistic reaches the minimum. the bottom row shows the density plots after the data are transformed by an asinh transformation with the optimum cofactors



we transform each sample of the hd data set by the asinh function with the variance-stabilizing cofactors and plot the density of the transformed channels in the bottom row of fig.  <dig>  in each channel, we observe that density peaks  have approximately equal width across all samples, which visually confirms the homogeneity of within-population variances in one-dimensional clusters. when both positive and negative peaks  are present in a channel, e.g., cd <dig>  cd <dig>  and cd <dig>  their variances are also approximately stabilized. note that the density peaks may not be well aligned owing to the between-subject variations. aligning density peaks across samples is not an objective of flowvs, because such shifting of density might potentially eclipse biological signals present in the mean expressions of a cell populations. when necessary, data normalization can be performed after variance stabilization, as was done by hahne et al.  <cit>  and finak et al.  <cit> .

stabilizing variance in the itn dataset
we stabilize variance in each channel of the itn dataset and show the results in fig.  <dig>  similar to the hd data set, the top row shows bartlett’s statistic computed from density peaks of all samples of the itn data set after each channel is transformed by asinh transformation with different cofactor for each one. from fig.  <dig>  the variance stabilizing cofactors for different markers are:   <dig>  for cd <dig>    <dig>  for cd <dig>  . <dig> for cd <dig>  and   <dig>  for cd <dig>  the curves showing the relationship between bartlett’s statistic and cofactors might have multiple local minima. nevertheless, a clear global minimum is obtained for channels in the itn dataset. we note that the variance-stabilizing cofactors for the hd data set are an order of magnitude greater than those of the itn data set. for example, the variance-stabilizing cofactor for the cd channel is  <dig> in the former data set, whereas for the same channel, variance is stabilized at a cofactor of  <dig>  in the latter. the primary contributing factor behind this difference is the maximum range of values in each channel. the maximum value of a fluorescence channel is  <dig>  for the itn data set, and  <dig> , <dig> for the hd data set. hence, variance is stabilized at higher cofactor values for the channels in the hd data set.
fig.  <dig> transforming four fluorescence channels in itn data. subfigures in the top row show bartlett’s statistic computed from density peaks after data are transformed by different cofactors. an optimum cofactor is obtained where bartlett’s statistic reaches the minimum. the bottom row shows the density plots after the data are transformed by the optimum cofactor



after identifying the optimum cofactors for each channel, we transform each sample of the itn data set by asinh functions with the variance-stabilizing cofactors and plot the density of the transformed channels in the bottom row of fig.  <dig>  similar to the hd data set , the density peaks have approximately equal variance across all samples, thus confirming the homogeneity of within-population variances in one-dimensional clusters.

comparing flowvs with other transformation methods
we compare flowvs with three automated methods developed for transforming fc data:  flowtrans  logicle , and  fcstrans. we selected these three methods because they automatically select parameters for different transformations. as discussed earlier, flowtrans estimates the parameters of different transformations  by maximizing the likelihood of data’s being generated from normal distributions  <cit> . in this paper, we chose the results of flowtrans with asinh transformation because it generated relatively better segregation of populations than the other options and is directly comparable to flowvs that also uses the asinh transformation. we generate our results by calling the flowtrans function of the bioconductor package flowtrans. next, we select the logicle transformation implemented in the flowcore package in bioconductor. to estimate the parameters of logicle transformation, we use the estimatelogicle function of the flowcore package. finally, fcstrans also uses the logicle transformation. we obtained the r source code of fcstrans from http://sourceforge.net/projects/immportflock/files/fcstrans.

the top row of fig.  <dig> shows the densities of the transformed cd <dig> channel of the hd data set after the samples are transformed by four methods using their optimum parameters. from visual inspection, we observe that the logicle and fcstrans stabilize variance of the cd4+ and cd4- populations separately. however, these two methods do not stabilize variances across cd4+ and cd4- populations. flowtrans fails to converge for six samples  and uses default cofactor= <dig> for these samples. hence, the peaks transformed by flowtrans are on different scales, and they are hard to compare against each other. by contrast, flowvs stabilizes variance across all peaks of cd <dig> channels, including cd4+ and cd4- populations. furthermore, flowvs selects a single cofactor for a channel across all samples in a data set, whereas flowtrans selects different parameters for different samples. thus, populations are more comparable after data are transformed by flowvs.
fig.  <dig> transforming cd <dig> channels in hd data by four transformation algorithms. the top row shows the density plots after the data are optimally transformed by different transformations. the bottom row shows the standard deviation of density peaks against the rank of mfi



next, we quantitatively compare the stability of variance across multiple transformation methods. this comparison, however, can not be performed on the actual transformed data because different transformations convert data to different scales. hence, we convert each transformed channel z to  <cit>  scale by rescaling each element zi with the following equation /. for each transformation, we identify the density peaks in the converted cd <dig> channel and plot standard deviations of density peaks against their ranks of mfi in the bottom row of fig.  <dig>  here we use rank of the means, instead of actual means, to distribute the points evenly along the x-axis. we observe that all four transformations are able to eliminate the systematic dependence of variance on mean, which is typically observed in untransformed fluorescence data, such as in fig.  <dig>  therefore, these transformations have inherent ability to stabilize variance, mostly owing to the properties of the underlying asinh and logicle transformations. however, flowvs is able to stabilize variance more evenly than other transformations, as can be seen in the bottom right plot in fig.  <dig> 

the comparison of different transformations on the itn data set is shown in fig.  <dig>  as before, the top row shows the densities of the transformed cd <dig> channel and the bottom row plots the standard deviations of the density peaks. as with the hd data set, flowvs stabilizes variance more evenly than other methods.
fig.  <dig> transforming cd <dig> channels in itn data by four transformation algorithms. the top row shows the density plots after the data are optimally transformed by different transformations. the bottom row shows the standard deviation of density peaks against the rank of mfi



normality of the variance-stabilized clusters
bartlett’s test assumes that the cell populations are normally distributed and is sensitive to departures from normality. density peaks  in data sets that we have studied approximately follow normal distributions. this normality assumption is typical for many fc data sets as well. hence, a vs approach based on bartlett’s test is expected to work well for most fc data sets. for example, in fig.  <dig>  we show the normality of cell populations in a representative sample of the hd data set with quantile-quantile plots   <cit>  of eight 1-d clusters. in each q-q plot, the distribution of a 1-d cluster is compared with the standard normal distribution by plotting their quantiles against each other. if a cluster is normally distributed , the points in the q-q plot lie approximately on a straight line. we observe that all eight q-q plots in fig.  <dig> show linearity in their central parts, except for small deviations at the ends, indicating that the 1-d clusters approximately follow normal distributions with heavier tails. therefore, flowvs based on bartlett’s statistic works well for this data.
fig.  <dig> the q-q plots for the eight 1-d clusters obtained from a representative sample in the hd data set. every q-q plot shows linearity in the central part, except for a little deviation at the end, indicating that the clusters approximately follow normal distributions with heavier tails



however, if cell populations deviate significantly from normality, we could use other likelihood ratio statistic that is less sensitive to departures from normality, such as levene’s  <cit>  or the brown-forsythe statistic  <cit> . in our experiments, we found bartlett’s approach working significantly better than levene’s, and therefore, did not show results of the latter method.

impact of variance stabilization in comparing cell populations
we now briefly demonstrate the impact of variance stabilization on the homogeneity of metaclusters . in metacluster homogeneity evaluation, the underlying assumption is that all clusters in a metacluster represent the same cellular immunophenotype. as mentioned before, the hypothesis-testing framework may not be appropriate for the described problem, since a null hypothesis claiming that all clusters in a metacluster have equal mean is essentially always false. moreover, when the number of cells  increases, the power of a statistical test such as a t-test or an f-test increases too. consequently, a statistical test would inevitably detect small  differences between clusters. for example, performing a t-test with cd4+ cell clusters from the first and the second samples of the itn data set, we observe p-values less than 10− <dig> for all transformations despite the fact that the tested cell populations are biologically identical .

therefore, we use an effect size measure rather than p-values to illustrate the impact of the proposed algorithm on metacluster homogeneity. we employ the ratio of between-cluster variation  to within-cluster variation   <cit> . consider a set of k clusters where the i-th cluster containing ni cells has mean μi and variance σi <dig>  if n is the total number of cells in all clusters and μ is the combined mean then the ratio of σb <dig> and σw <dig> is computed as follows: 
  <dig> σb2σw2=1n−k∑i=1k21n−k∑i=1kσi <dig>  

unlike the f-test for comparing multiple clusters, the above ratio does not depend on the sample size, and it is constructed so that the increasing homogeneity of a metacluster results in a progressively smaller value of the ratio. table  <dig> shows the σb2σw <dig> values of cd4+ metacluster and a biologically erroneous metacluster grouping cd4+ and cd4- cells. the values are computed after the data are transformed by four transformations considered in this paper. in this example, the flowvs transformation gives the best homogeneity within the cd4+ metacluster, and an increased heterogeneity of the cd4+/cd4- clusters mixture. thus application of flowvs not only results in the highest homogeneity of a set of known phenotypically identical cell clusters, but also provides the best discrimination between homogeneous and heterogeneous collection of clusters. the result demonstrates that the flowvs-based variance stabilization can help in performing comparison and alignment of phenotypically identical cell populations across different samples.
cd4+ cell populations are used in top two rows, and a mixture of cd4+ and cd4- cell populations are used in bottom two rows. small and large values of the ratio denote homogeneous and heterogeneous collections of clusters, respectively. in this example, flowvs transformation results in the highest homogeneity when only cd4+ clusters are considered, and highest heterogeneity when cd4+ and cd4- clusters are mixed together



application to microarray data
the vs approach based on optimizing bartlett’s statistic can also be used to stabilize variance in microarray data. however, the initial steps of flowvs need to be adapted for microarrays. assume that the expression of m genes are measured from n samples in a microarray experiment. after transforming the data by the asinh function, the mean μi and variance σi <dig> of the ith gene gi are computed from the expressions of gi in all samples. flowvs then stabilizes the variances of the genes by transforming data using the asinh function with an optimum choice of cofactor. unlike fc, a single cofactor is selected for all genes in microarrays.

we have applied the modified flowvs to the publicly available kidney microarray data provided by huber et al.  <cit> . the kidney data report the expression of  <dig> genes from two neighboring parts of a kidney tumor, using cdna microarray technology. for different values of the cofactor, flowvs transforms the kidney data with the asinh function and identifies the optimum cofactor by minimizing bartlett’s statistic. figure  <dig> shows that a minimum value of bartlett’s statistic is obtained when the cofactor is set to exp . the optimum cofactor is then used with the asinh function to transform the kidney data.
fig.  <dig> for kidney microarray data  <cit> , flowvs selects the optimum cofactor for the asinh transformation by minimizing bartlett’s statistic. the cofactors are shown in the natural logarithm scale



we compare the vs performance of flowvs with two software packages, vsn by huber et al.  <cit>  and ddhfm by motakis et al.  <cit> . similar to flowvs, vsn uses an asinh transformation whose parameters are optimized by maximizing a likelihood function  <cit> . ddhfm applies a data-driven haar-fisz transformation  <cit>  to stabilize the variance. both vsn and ddhfm are developed for stabilizing variance in microarray data and can not be applied to fc.

in subfig.  <dig>  we plot the mean and standard deviation of every gene before transforming the kidney data and after transforming it by flowvs, vsn, and ddhfm. in this figure, we have applied a loess regression to obtain smooth average curves. we observe in subfig.  <dig> that the standard deviation of the untransformed kidney data increases monotonically with the mean. both vsn and flowvs approximately stabilize the variance across all genes in this data. however, the haar-fisz transformation achieves good vs properties only for genes with higher levels of expression.
fig.  <dig> the standard deviation and mean of each gene from the kidney data are plotted before transformation and after variance stabilization by flowvs, vsn, and ddhfm. loess regression is used to smoothen the curves



to take a closer look at the transformed data by flowvs and vsn, we plot the variances of genes against the ranks of their means in fig.  <dig>  these figures are generated by the meansdplot function from the vsn package. here, the ranks of means distribute the data evenly along the x-axis and thus make it easy to visualize the homogeneity of variances. we also show the running median estimator of standard deviation by the red lines. both vsn and flowvs remove the mean-variance dependence because the red lines are approximately horizontal for both transformations. hence, flowvs performs at least as well as a state-of-the-art approach developed for microarray data.
fig.  <dig> variance stabilization of the kidney microarray data  <cit>  by  flowvs and  vsn  <cit> . each black dot plots the standard deviation of a gene against the rank of its mean. the red lines depict the running median estimator. if there is no mean-variance dependence, then the red lines should be approximately horizontal



CONCLUSIONS
we describe a variance-stabilization framework, flowvs, that removes the mean-variance correlations observed in cell populations from fc samples. this framework transforms each fluorescence channel by the asinh function whose normalization cofactor is optimally selected by bartlett’s likelihood-ratio test. variance homogeneity  is a desirable property for comparing populations across conditions, building metaclusters from phenotypically similar populations, and analyzing metaclusters in an anova model. however, unlike the earlier approach by hahne et al.  <cit> , flowvs does not artificially shift populations to align them in the marker space. by stabilizing the variances, flowvs homogenizes similar cell populations and establishes the foundation of biologically meaningful metaclusters and templates.

flowvs is built on several assumptions that limit our approach. first, flowvs stabilizes variance separately in each channel. thus it might be unable to stabilize covariances across multiple channels when they are correlated. second, flowvs identifies 1-d density peaks and evaluates the homogeneity of populations by the likelihood-ratio test. therefore, this algorithm might not perform well when density peaks are not easily identifiable. third, flowvs stabilizes variance more accurately when a number of samples are simultaneously passed to the algorithm. hence, this approach is not suitable for normalizing a single sample or stabilizing variances of sequentially arriving samples. finally, bartlett’s test used in flowvs assumes that the deviation from normality is relatively modest. if data deviate significantly from normality, other likelihood ratio tests can be employed, such as levene’s test  <cit>  or the brown-forsythe test  <cit> .

flowvs operates as an independent module in the fc data analysis pipeline. it does not depend on the preprocessing algorithms applied before vs nor on the post-analysis methods such as matching, metaclustering, and classification. hence, flowvs is capable of working with most automated clustering and metaclustering algorithms developed for flow cytometry.

abbreviations
asinh, inverse hyperbolic sine; fc, flow cytometry; itn, immune tolerance network; mfi, mean fluorescence intensity; vs, variance stabilization.

