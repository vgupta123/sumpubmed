BACKGROUND
the reproducibility and reliability of microarray data is a major issue that must be addressed before microarrays can reach their full potential as a clinical molecular profiling tool for personalized and predictive medicine  <cit> . the fda has completed phase-i of the microarray quality control  project, which demonstrated general reproducibility among different array platforms and pcr, but came just short of offering concrete guidance on which processing methods to use when analyzing microarray data  <cit> . recently published results from maqc-phase ii efforts demonstrate that well-designed microarray-based classification is reliable across experiments, and that in some cases, microarray-based classification can outperform existing clinical predictors  <cit> . the current status of microarray quality control , however, is still a relatively anecdotal and inexact science based around a handful of existing methods. tools such as dchip  <cit> , mas <dig>   <cit> , rmaexpress  <cit> , and plier  <cit>  have been developed to improve the accuracy of microarray gene expression data by taking advantage of affymetrix's high-density array design. these model-based tools use perfect match  and mismatch  information as well as the redundancy inherent in a probe set to generate estimates of gene expression, which are generally robust to failures of one or a few probes. while these tools use sensible methods of background correction, normalization, and statistical outlier detection, they fall short in two important areas. first, they do not incorporate adequate spatial information into the outlier detection methods and second, they do not incorporate outlier information into their normalization routines. cacorrect  <cit>  addresses these deficiencies and seeks to replace or augment existing methods to improve the reproducibility of microarray experimentation.

quality assurance  tools, such as smudgeminer  <cit>  and arraymagic  <cit>  provide intuitive images of damaged arrays through the use of heat maps, but they do not provide correction methods for observed errors. in fact, rma and dchip also readily provide similar visualizations of chip errors, but they do not use that visualized information during probe outlier detection. harshlighting  <cit>  is similar to cacorrect in that it identifies an assortment of compact and widely scattered artifacts, by leveraging techniques from the field of image processing, such as sliding windows and background assessment. harshlighting, however, defines a chip's "error image" as a simple residual  from the median. harshlighting therefore ignores the differing natural variance of probes and neglects to account for global chip-to-chip variation, which is usually correctable with a simple normalization step. the r implementation of harshlighting does allow for the input of user-generated error images, but this procedure is relatively skill-intensive. as a known issue, the authors of harshlighting point out the appearance of "ghosting" artifacts i.e. the false appearance of artifacts on clean chips as a result of comparison to a true artifact on another chip in the batch. whereas harshlighting attempts to correct for this phenomenon by using a median in its error heat map calculation , cacorrect avoids the ghosting problem by iteratively identifying artifacts and directly omitting them from calculations altogether.

the lpe and cpp adjustments  <cit>  have also been suggested as a way to correct spatial flaws on microarrays. artifact probes are identified by lpe and cpp similarly to cacorrect, i.e. their dklr* measure is analogous to cacorrect's zj and both methods use neighboring information. cacorrect, however, allows for iterative calculation of this score, and thus allows for the same probe location to be corrected on more than one chip in a batch, whereas the methods of arteaga-salas et al. do not  <cit> .

previously, we have shown that using cacorrect as a preprocessing step increases the reproducibility of biomarker selection as measured by similarity of ranked gene lists during independent cross-validation from large microarray datasets  <cit> . we have also shown that the spatial locations of proposed biomarkers  in published microarray studies often are correlated or anti-correlated with the location of chip artifacts identified using cacorrect  <cit> . finally, we have constructed cabig grid services for much of the functionality of cacorrect  <cit> . since these initial publications, improvements have been made to the cacorrect algorithms, which have allowed more conclusive validations. specifically, we have implemented a new bad-data-replacement algorithm , and we have made user-centered design changes to allow more seamless integration with existing gene expression calculation protocols. cacorrect's website currently offers gene expression output from rma, plier, and mas <dig> . for users who wish to use other methods, such as the popular tool dchip, they can run the tools directly, using the clean cel file output option provided by cacorrect. these validation results, which include the discovery of two biomarkers for renal cell carcinoma subtyping, as well as the description of improved methods are the subject of this manuscript.

RESULTS
artifact removal and replacement
many artifacts were easily visible using the heat map function provided by cacorrect, and one such example of mixed artifacts observed in published data is shown in figure  <dig>  the input and output of cacorrect's artifact identification procedure are visualized, demonstrating the process by which continuous scoring of the quality of individual probes  is combined to determine the binary classification of "artifact or not" . note that not every probe with a poor score was flagged as an artifact, as local areas of high variance are expected as a result of actual variance in gene expression among samples. for comparison, the artifact labels provided by harshlighting are shown for both diffuse and compact artifacts in panel c and d respectively, with black and white indicating artifacts. this example supports the general trend that cacorrect's automated artifact identification is conservative. it is our experience that human observers often consider a larger portion of a chip more objectionable than cacorrect does. harshlighting on the other hand, tends to be more aggressive in flagging regions of chips as artifactual. we chose conservative artifact identification over a more aggressive scheme because cacorrect was designed to identify spatial artifacts upstream of the more specific model-based outlier detection employed by most probe summarization methods, such as rma, plier, and mas <dig> . generally speaking, probe summarization is the fitting of a regression model to the probe intensity data from a chip or set of chips. while individual methods differ on how the model is set up , they are the same in that the model-fitting procedures allow for different weights or affinities for each probe's contribution to gene expression. during this model-fitting process, single outlier probes are easily detected and ignored because they do not fit the model well. cacorrect is not designed to detect or remove such isolated, single probe defects, because rma, mas <dig>  and plier are already very good at this task. with large artifacts that affect many probes, however, model-based outlier removal becomes much more difficult. to help users interpret the success or failure of the probe summarization  process, client software such as rmaexpress, and now cacorrect, visualizes the residuals  of every probe intensity from the model collectively as a heat map. close interpretation of these residuals reveals how well a particular model fits the data.

effect of artifact aware quantile normalization on synthetic artifact data
effect of applied artifacts and preprocessing on gene expression
we monitored the effect of applied quality insults on gene expression using the two popular probe summarization methods of rma and mas <dig> . figure  <dig> demonstrates the correspondence of gene expression, before and after introduction of artifacts by an independent third party. two phenomena are readily observable:

first, for the "black hole" artifacts which lower probe intensities on the microarray, the mas <dig>  algorithm has the tendency to call many of the genes 'absent', and report the gene expression abnormally low . cacorrect is able to almost completely reverse this trend, and is able to help mas <dig>  produce appropriate gene expression values for most of these probe sets.

second, for the "hot spot" artifacts that raise probe intensities on the microarray, the rma algorithm has the tendency to underestimate gene expression and lose accuracy for the genes most highly expressed in the sample . this is presumably a result of the warping issues related to quantile normalization discussed in the previous section. this phenomenon also happens to low-expressing genes in rma to a lesser extent for the black hole artifacts . chips processed first with cacorrect and then with rma do not exhibit either of these warping behaviors .

we then created our own synthetic insults in order to compare cacorrect with harshlighting for the ability to moderate effects of single artifacts on gene expression, as measured by the probe summarization methods rma, plier, and mas <dig> . as a control to these common methods, which include normalization and outlier detection inherently, we also measured expression with our simple xb,p,j = θp,jab,p + εb,p,j regression method "taxy" detailed in the methods section, which does not contain special considerations for outlier data. three conditions were tested for each method of gene expression measurement:  using original data that was not preprocessed;  using data that was processed with cacorrect; and  using data that was processed with harshlighting. we calculated the error caused by a given artifact as the average absolute difference, in the log domain, between the original gene expression and the expression measured after introduction of artifact. this measure is similar in concept to average relative error in gene expression in the linear domain.

for rma, cacorrect outperformed both harshlighting and unprocessed data for artifacts stronger than  <dig>  fold. for plier and mas <dig>  however, cacorrect outperformed unprocessed data only for intensity reducing artifacts. this suggests that cacorrect is not suitable for helping mas <dig>  or plier to identify subtle artifacts, but that in the case of such subtle artifacts, cacorrect does not reduce performance.

identification of differentially expressed genes
having established that cacorrect could improve the accuracy of gene expression derived from microarrays in the presence of spatial artifacts, we set out to determine if this improved accuracy of gene expression would translate to improved efficiency in identifying candidate genes to serve as biomarkers for disease. briefly, we first identified differentially expressed genes between subtypes of renal cell carcinoma from the schuetz et al. microarray data, then we performed a small pcr pilot study to verify these findings, and finally we tested a much larger cohort of genes and samples via a pcr core facility. while results could not be directly quantitatively compared between experiments, trends in gene expression, such as ratios among biomarkers were generally preserved. figure  <dig> shows the trends in gene expression for the two most reliable biomarkers identified during this process: nnmt and prkab <dig> 

during the first pcr pilot study, we found only anecdotal evidence suggesting that using cacorrect on real data could improve the reliability of biomarker selection. we believed that this could probably be attributed to the relatively high quality of the original chips in the schuetz et al. study, and thus decided to artificially reduce the quality of the data in order to amplify any affect that cacorrect may have. figure  <dig> shows examples of our synthetic artifacts  applied to the schuetz et al. dataset as well as the unaltered versions of those chips  as visualized by the post-cacorrect residual images. while the synthetic artifacts may appear more visually stunning than the artifacts "naturally" found in this dataset, they are comparable with those found on other microarrays, such as the one shown covering the left hand side of the chip in figure  <dig> 

affycomp
cope et al. have provided a benchmark  <cit>  by which to assess gene expression from two spike in datasets, one on the hg-u133a and the other on the hg-u95a platform  <cit> . their spike in arrays were all prepared using the same crna stock mixture, with the exception of  <dig> transcripts which were added in concentrations from  <dig> to  <dig> picomolar. these  <dig> transcripts were applied  in a cyclic latin square design. as a result, the fold change between any two arrays for these  <dig> transcripts is known, while the fold change for all other transcripts is expected to be  <dig> . the affycomp package, available from http://bioconductor.org/, provides many statistics and figures of merit with which to compare the accuracy of gene expression in the context of detecting known fold change between pairs of arrays. affycomp provides a uniquely public way to assess cacorrect without the need to synthetically worsen the data. figure  <dig>  panels a and b, show cacorrect's performance on the hg-u95a data set as a plot of false positive rate versus true positive rate . rma after cacorrect was the best overall performer, as measured by area under the curve  for less than  <dig> false positives . auc gains from cacorrect were most noticeable for the taxy method, which does not provide any additional outlier detection like that inherent in rma, mas <dig>  and plier . importantly, the poorest-quality chip  was thrown out by the original authors as part of the canonical affycomp benchmark-- a decision which was recently justified quantitatively  <cit> . still, examples of chips on which cacorrect has detected obvious artifacts  remain in the hg-u <dig> spike in data. for the hg-u133a spike in dataset, which had less detected artifacts, improvements due to cacorrect were more modest

it is almost never a good idea to run cacorrect on batches with  <dig> or fewer chips, although it is hard to imagine a reliable microarray experiment so small. affycomp data, however, followed a rarely achieved design in which there are  <dig> technical replicates of each sample. arteaga-salas et al. were able to apply their method for correcting small batches of replicates by splitting up the affycomp data set  <cit> . they have previously reported performance as the fraction of spike in genes from affycomp hg-u133a to have their rma-calculated fold-change rank improved or worsened as a result of correction. processing batches of  <dig> technical replicates at a time, they report  <dig> % improved ranks, while cacorrect, processing the entire dataset at once, improved ranks of  <dig> % of spiked in genes. however, they report  <dig> % worsened ranks, while cacorrect worsened the ranks of only  <dig> % spiked in genes. this result is consistent with cacorrect's conservative design, but suggests that arteaga-salas's correction method may also be appropriate for experimental designs with available technical replicates for every sample.

discussion
cacorrect is designed to correct spatial artifacts from batches of affymetrix microarrays and to provide a robust global normalization before gene expression is calculated from the multiple probe values. other sources of microarray noise which lack a spatial basis, such as rna degradation, are not expected to be detected or altered by cacorrect. because modern chip layouts have more or less random arrangement of probes, these outlier probes are unlikely to be arranged in clusters on the chip surface large enough to be counted as artifacts. this same property also protects natural biological up regulation or down regulation of genes from being marked as artifacts. cacorrect's performance is tied to both the size and quality of the batch being considered. first, the resolving power of artifact identification increases as the natural variance between samples decreases. thus, the more similar samples are in a batch, the more powerful cacorrect is. while technical or biological replicates are ideal, almost any cohort of arrays from the same study is an acceptable input. it is even possible to use cacorrect to combine chips from two or more studies as long as they are from the same platform. combination of data from different labs can easily introduce batch effects, however, and so this is generally not recommended. second, even though sample size is accounted for within cacorrect's variance score, the resolving power of artifact detection is diminished with smaller batches. for any size batch, but especially for those with less than  <dig> chips, we suggest watchful use of cacorrect. users should inspect the images provided by cacorrect to confirm the quality of the data set. for chips with excessive artifact coverage , we suggest removing them altogether to avoid relying too much on imputation. we realize that this is not an attractive option for many researchers with small experiments, in which case we recommend including more chips or using cacorrect only for quality assessment purposes.

while most existing gene expression algorithms include measures to remove artifacts, they are sub-optimal in that they ignore information about the spatial configuration of artifact probes. using a visible scratch as an example, we have shown that cacorrect's heat map-based outlier detection performs better than those methods that are purely based on statistical analysis of spatially-independent probe data. blemishes such as the ones shown in this case study are common in microarray data and should be ignored or down-weighted when calculating gene expression.

quantile normalization has been widely adopted by the microarray community as a way to remove global chip bias. we have shown that quantile normalization, while generally useful, can be counter-productive in datasets that have a chip with significant artifacts. first, good data from a chip with artifacts will be wrongfully displaced during normalization, i.e. high intensity artifacts will lead to underestimation for probe sets not in the footprint of the artifact. second, probe data from otherwise clean chips or clean regions on damaged chips may be corrupted or distorted during quantile normalization if artifact data appear anywhere in the batch. cacorrect alleviates this corruption by employing an artifact-aware quantile normalization scheme that is less susceptible to such data corruption or warping.

as an extension of the pitfalls of both the normalization and artifact identification schemes provided by modern microarray processing software, we show that cacorrect combines advances in these two areas to improve overall accuracy of gene expression calculation. when operating upstream of plier, mas <dig> , and rma algorithms, cacorrect reduces the error in gene estimation, especially for cases of expression-lowering artifacts in mas <dig> , and expression-raising artifacts in rma. the former effect is most likely influenced by mas <dig> 's tendency to declare transcripts as not present, while the latter trend is most likely due to rma's use of quantile normalization.

in contrast to cacorrect, harshlighting was observed to increase error in gene expression in most cases. although the artifact segmentation results of harshlighting are visually intuitive, the median based data replacement scheme appears to be unhelpful when used upstream of smart gene expression software. this is probably due to the fact that the median is a poorer estimate of the expected probe intensity than the replacement from model-based methods used by cacorrect and probe summarization software. this is consistent with troyanskaya et al.'s findings that singular value decomposition imputation outperforms mean replacement in the context of replacing missing gene expression values  <cit> . it appears that for most artifacts, the median replacement may imply false confidence, while a more extreme outlier, if left alone, may be detected and corrected by the simple methods inherent in rma, plier, dchip, or mas <dig> .

although we have shown that using cacorrect improves the accuracy of derived gene expression data and the assessment of fold-change between pairs of arrays, this improvement in gene expression data quality has yielded only modest improvement in the reliability of biomarkers identified from a cohort of rcc samples. specifically, we have shown using roc area under the curve analysis that cacorrect can improve the reliability of biomarkers identified from data affected by severe chip artifacts, without degrading performance on clean data. for the task of identifying differentially expressed genes from a cohort, much redundancy exists in the data themselves, and the impact of a single bad quality chip on the overall experiment is understandably small. the largest impact of cacorrect is expected in applications which are relatively data-poor, or where the information on a single array is precious. the affycomp benchmark is such a "data-poor" application where differential expression is assessed based on head-to-head comparisons. the evidence that cacorrect improves fold change assessment in the affycomp data thus supports the hypothesis that cacorrect may be more noticeable in data-poor situations. an application of this is a clinical scenario in which a cohort of arrays is used to train a predictive model, but a single microarray is used to determine diagnosis or treatment decisions for a single patient. while throwing out a poor quality array may be suitable practice during model training, it is not an option during testing. a method such as cacorrect could prove to be the difference between a correct and an incorrect clinical decision.

CONCLUSIONS
we have demonstrated two fundamental reasons why cacorrect represents a theoretical improvement over previous methods, as well as empirical evidence showing improved performance in gene expression accuracy and subsequent biomarker selection in the presence of severe artifacts and in the affycomp data. we expect that cacorrect will be helpful for new experimentation as well as for revisiting the conclusions of archived microarray data that may suffer from artifacts.

