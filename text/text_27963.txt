BACKGROUND
additively homomorphic encryption scheme
in this paper, we use an additive-homomorphic cryptosystem to design our protocol. the key feature of the additive-homomorphic cryptosystem is that it enables to perform additive operations on encrypted values. therefore, intuitively, any standard computation algorithm can be converted into the privacy-preserving computation algorithm, if operations used in the standard algorithm can be replaced by additions.

more formally, we use a public-key encryption scheme , which is semantically secure; that is, an encryption result  leaks no information about the original message   <cit> . here, keygen is a key generation algorithm for selecting a pair  of a public key pk and a secret key sk; enc denotes a ciphertext obtained by encrypting message m under the given pk; and dec denotes the decryption result of ciphertext c under the given sk. we also require the following additive-homomorphic properties:

• given two ciphertexts enc and enc of messages m <dig> and m <dig>  enc can be computed without knowing m <dig>  m <dig> and the secret key  ⊕ enc).

• given a ciphertext enc of a message m and an integer e, enc can be computed without knowing m and the secret key ).

for example, we can use either the paillier cryptosystem  <cit>  or the "lifted" version of the elgamal cryptosystem  <cit>  as such an encryption scheme; now the second operation ⊗ can be achieved by repeating the first operation ⊕. we notice that the range of plaintexts for those cryptosystems can be naturally set as an integer interval  for some sufficiently large n <dig>  n <dig> >0; therefore, the plaintexts are divided into positive ones, negative ones, and zero.

non-interactive zero-knowledge proof
below, we discuss the following situation: a user  wants to make a server  convinced that a ciphertext c generated by the user corresponds to a message m in { <dig>  1}, but does not want to reveal any information about which of  <dig> and  <dig> is m. this can be achieved by using a cryptographic tool called non-interactive zero-knowledge  proof. in the present case, it enables the user to generate a "proof" associated with c, so that:

• if m is indeed in { <dig>  1}, then the server can verify this fact by testing the proof .

• if m ∉ { <dig>  1}, then the user cannot generate a proof that passes the server's test.

• the server cannot obtain any information about m from the proof, except for the fact that m ∈ { <dig>  1}.

 besides the existing general-purpose nizk proofs, sakai et al.  <cit>  proposed an efficient scheme specific to the "lifted" elgamal cryptosystem, which we use below. 

method
the goal of this study is to design a protocol between a user and a server that enables the user to obtain the number of compounds in the server's database that are similar to the user's target compound. here, a fingerprint of compound is modeled as p →∈{ <dig> }ℓ . an equivalent way to refer to p → is the set of all indices i where pi =  <dig>  we denote such a set by p. the similarity of two compounds p, q is then measured by tversky index which is parameterized by α, β >  <dig> and is defined as:

 tiα,β=|p∩q||p∩q|+α|p\q|+β|q\p|. 

tversky index is useful since it includes several important similarity measurements such as jaccard index  and dice index   <cit> . first, we introduce the basic idea and two efficient techniques for improving database privacy. then, we describe our full proposed protocol.

basic idea
we firstly consider the simplest case that the user has  a target compound q as a query and the server's database consists of only a single fingerprint p. the case of a larger database is discussed later. the goal here is to detect whether or not the tversky index of p and q is larger than a given threshold  <dig> ≥ θ >  <dig>  the main idea of our approach is to calculate the score

  θ-1- 

from encrypted fingerprints p and q by an additive-homomorphic cryptosystem. the score is non-negative if and only if the tversky index of p and q is at least θ. now since |p \ q| = |p| − |p ∩ q| and a similar relation holds for |q \ p|, the score  is positively proportional to

 λ1|p∩q|-λ2|p|-λ3|q|, 

where λ <dig> = c, λ <dig> = cα, λ <dig> = cβ and any positive value c. we assume that the parameters and the threshold for the tversky index are rational numbers denoted by α = μa/γ, β = μb/γ and θ = θn/θd, where μa, μb, γ, θn and θd are non-negative integers. by using c = γθng− <dig> under this assumption, λ <dig>  λ <dig> and λ <dig> become non-negative integers where g is the greatest common divisor of γ + θn, θnμa and θnμb.

motivated by this observation, we define the following modified score, called the threshold tversky index:

definition  <dig> given parameters α and β and a threshold θ for the tversky index which are rational numbers denoted by α = μa/γ, β = μb/γ and θ = θn/θd where μa, μb, γ, θn and θd are non-negative integers, then the threshold tversky index ti¯α,β,θ=ti¯α,β,θfor fingerprints p and q is defined by

 ti¯α,β,θ:=λ1|p∩q|-λ2|p|-λ3|q|, 

and non-negative integer parameters λ <dig>  λ <dig> and λ <dig> are defined by

 λ1=γθng- <dig> λ2=γθng-1α,λ3=γθng-1β, 

where g is the greatest common divisor of γ+θn, θnμa and θnμb.

by the above argument, we have tiα,β ≥ θ if and only if ti¯α,β,θ≥ <dig>  therefore, the user can know whether or not his/her target compound q is similar  ≥ θ) to the fingerprint p in the database, by obtaining only the value ti¯α,β,θ.

in the protocol, the bits of the user's target fingerprint q and the value |p| held by the server are both encrypted using the user's public key. since ti¯α,β,θ can be computed by the addition of these values and multiplication by integers, the protocol can calculate  a ciphertext of ti¯α,β,θ, which is then decrypted by the user. for simplicity, we will abuse the notation and write ti, ti¯ without subscripts α, β, θ when the context is clear.

we emphasize that our protocol does not use time-consuming cryptographic methods such as gp-mpc and fhe, and data transfer occurs only twice during an execution of the protocol. hence, our protocol is efficient enough to scale to large databases.

database security enhancement techniques against regression attack
as discussed in introduction section, the server needs to minimize returned information in order to minimize the success ratio of the regression attack. that is, the ideal situation for the server is that the user learns only the similarity/non-similarity property of fingerprints p and q, without knowing any other information about the secret fingerprint p. this means that only the sign of ti¯ should be known by the user. however, in our basic protocol, the value of ti¯ is fully obtained by the user; database privacy is not protected from regression attacks.  in order to send only the sign of ti¯, we firstly considered using a bit-wise decomposition protocol  <cit>  for extracting and sending only the sign bit of ti¯. although this approach is ideal in terms of security, the protocol requires more than  <dig> rounds of communications, which is much more efficient than using gp-mpc or fhe, but rather time-consuming for large-scale databases. therefore, here we propose the novel technique of using dummy replies, which requires only one round of communication while sufficiently minimizing information leakage of p. in the proposed technique, besides its original reply t=enc), the server also chooses random integers φ <dig>  ..., φn from a suitable interval and encrypts those values under the user's public key pk. then the server sends the user a collection of ciphertexts t, enc, ..., enc that are shuffled to conceal the true ciphertext t, as well as the number sd of dummy values φk with φk ≥  <dig>  the user decrypts the received n +  <dig> ciphertexts, counts the number sc of non-negative values among the decryption results, and compares sc to sd. now we have ti¯≥ <dig> if and only if sc − sd = 1; therefore, the user can still learn the sign of ti¯, while the actual value of ti¯ is concealed by the dummies. we have confirmed that the information leakage of p approaches zero as the number of dummies becomes large; see the security analyses for pudding dummies section for more detailed discussion. ; see section  <dig> of additional file  <dig> for details.)

database security enhancement technique against illegal query attack illegal query attacks can be prevented if the server can detect whether or not the user's query is valid. to keep user privacy, the server must conduct this task with-out obtaining more information than the validity/invalidity of the query. in fact, this functionality can be implemented by using the nizk proof by sakai et al.  <cit>  mentioned in the non-interactive zero-knowledge proof section. the improved protocol requires the user to send the server a proof associated with the encrypted fingerprint bits qi, from which the server can check whether q is indeed a valid fingerprint ; the server aborts the protocol if q is invalid. here we use the "lifted" elgamal cryptosystem as our basic encryption scheme to apply sakai's scheme.  used by server's computation, then another nizk proof is necessary to guarantee the validity of the additional ciphertext, which decreases the communication efficiency of our protocol. hence our protocol requires the server to calculate enc by itself.) the formal definition of the valid query is given in the database privacy in malicious model section.

secure similar compounds counter
for the general case that the database consists of more than one fingerprint p, we propose the protocol shown in algorithm  <dig> to count the number of fingerprints p similar to the target fingerprint q. in the protocol, the server simply calculates the encryption of the threshold tversky indices for all database entries and, as discussed above, replies with a shuffled collection of these true ciphertexts and dummy ciphertexts, as well as the number sd of non-negative dummy values. then the value sc − sd finally obtained by the user is equal to the number of similar fingerprints p in the database.

algorithm  <dig> the secure similar compounds counter 

• public input: length of fingerprints ℓ and parameters for the tversky index θ = θn/θd, α = μa/γ, β = μb/γ

• private input of a user: target fingerprint q

• private input of a server: set of fingerprints p = {p, ..., p}

 <dig>  the user generates a key pair  by the key generation algorithm keygen for the additive-homomorphic cryptosystem and sends public key pk to the server .

 <dig>  the user encrypts his/her fingerprint q as a vector of ciphertexts: en →c:=,…,enc). he/she also generates v as a vector of proofs. each proof vi is associated with enc.

 <dig>  the user sends the vector of ciphertexts en →c and the vector of proofs v to the server as a query.

 <dig>  the server verifies the validity of en →c by testing the vector of proof v. if v does not pass the server's test, the user cannot move on to the next step.

 <dig> 

 the server calculates the greatest common divisor of γ + θn, θnμa and θnμb as g, and calculates λ <dig> = γθng− <dig> , λ <dig> = γθng−1α, and λ <dig> = γθng−1β.

 the server calculates enc=enc-∑i=1ℓqi from en →c:enc=-1⊗⊕i=1ℓenc.

 for j =  <dig> to m do

i. the server calculates -|p|=-∑i=1ℓpi and encrypts it to obtain a ciphertext enc|).

ii. the server calculates a ciphertext tj of threshold tversky index ti¯,q).

c ← enc

for k =  <dig> to ℓ do

if pk=1

c ← c ⊕ enc ▷ computing enc∩q|)

end if

end for

tj ← λ <dig> ⊗ c ⊕ λ <dig> enc|) ⊕ λ <dig> ⊗ enc

end for

 <dig> 

 the server generates a set of dummy values {φ <dig>  ..., φn} and counts the number sd of non-negative dummies φi ≥  <dig> 

 the server encrypts φi to obtain a ciphertext enc for i =  <dig>  ..., n.

 the server shuffles the contents of the set t = {t <dig>  ..., tm, enc, ..., enc}.

 <dig>  the server sends t and sd to the user.

 <dig>  the user decrypts the contents of t and counts the number sc of non-negative values.

 <dig>  the user obtains sc − sd as the number of similar fingerprints in the database.

parameter settings of the protocol
decrypting an encrytion of too large value needs huge computation cost if the lifted-elgamal cryptosystem is used. therefore, in order to keep the consistency and efficiency of the protocol, the range of ti¯ should not be too large. i.e., the integer parameters λ <dig>  λ <dig> and λ <dig> in the threshold tversky index should not be too large. in fact, this will not cause a problem in practice; for example, the parameters become λ <dig> =  <dig>  λ <dig> = λ <dig> =  <dig> for computing ti¯ <dig> , <dig>  which is a typical setting of a chemical compound search. in this case, a minimum value and a maximum value of ti¯ is - <dig> and  <dig> for  <dig> maccs keys, which is a sufficiently small range. 

security analyses
in this section, we evaluate security of sscc by several approaches.

in the area of cryptology, the following two standard security models for two-party computation have been considered:

• semi-honest model : both parties follow the protocol, but an adversarial one attempts to infer additional information about the other party's secret input from the legally obtained information.

• malicious model : an adversarial party cheats even in the protocol  in order to illegally obtaining additional information about the secret.

we analyze user privacy and database privacy in both the semi-honest and malicious models. for the database privacy, we firstly compare attack success ratios for the case of using our method which aims to output a binary sign and the other case of using the previous methods which aim to output a similarity score, and show that outputting a binary sign improves database privacy. we also evaluate security strength of our method against a regression attack by comparing attack success ratios for the case of using dummies and the ideal case that uses a versatile technique  to output a binary sign, and show that the security strength for the case of using dummies is almost the same as the ideal case under realistic settings.

user privacy
the semantic security of the encryption scheme used in the protocol  implies immediately that the server cannot infer any information about the user's target fingerprint q during the protocol. this holds in both the semi-honest and malicious models.

thresholding largely improves database privacy
we mentioned in the introduction section that minimizing information returned from the server reduces success ratio of regression attack. therefore, sscc aims for "ideal" case in which the user learns only the sign of ti¯ during the protocol. the previous methods that compute jaccard index aim for the "plain" case, in which the user fully learns the value ti. here we evaluate the efficiency of the thresholding by comparing success probabilities of regression attack for those two cases. we consider the general case in which the user is allowed to send more than one query and those queries are searched by jaccard index. we also suppose that the database consists of a single fingerprint p in order to clarify the effect of thresholding.

the goal of an attacker is to reveal p by analysing the results returned from the server. it is generally effective for the attacker to exploit the difference between the two outputs obtained by sending two different queries. in fact, when the server returns ti¯, ti¯ - ti¯ becomes positive if and only if pi =  <dig>  where q =  and  <dig> = . this means that the attacker can reveal any bit in p by sending the single query after sending the first query  <dig>  therefore, p can be fully revealed by sending only ℓ +  <dig> queries. on the other hand, there is no deterministic attack for revealing p from only the sign of ti¯, because two different inputs do not always lead to different outputs. since we know of a linear algorithm that fully reveals p in response to at most 2ℓ queries after making a "hit" query q such that ti¯> <dig>  here we evaluate database privacy by the probability of making at least one hit query when the user is allowed to send x queries.  this probability is denoted as

   ∑ppr⋅x), 

where fp, defined as follows, is the probability that the user makes one hit query with a single trial when p is given.

 fp:= ∑qpr⋅pr>0|y=q). 

for ease of calculation, we computed the upper bound of equation  for x =  <dig>   <dig>   <dig>  ...,  <dig> and θ =  <dig> ,  <dig> ,  <dig> ,  <dig> .  since publicly available  <dig> maccs keys are the most popular fingerprint for chemical compound searches, we set ℓ to  <dig>  from the results shown in figure  <dig>  we can see that the probability of making a hit query is sufficiently small for practical use even though the user is allowed to send a million of queries. considering that the user learns p by using no more than ℓ +  <dig> queries when he/she learns ti¯, we can conclude that database privacy is dramatically improved by thresholding. in other words, the proposed protocol, which aims to output only the sign of the similarity score, has stronger security than other previous methods, which directly output similarity scores.

security analyses for padding dummies
we showed that the output privacy in the "ideal" case is significantly improved from the "plain" case. here we experimentally evaluate how the actual situation of our proposed protocol is close to the "ideal" case.

before going into detail analyses, let us discuss how to generate dummies. it is ideal for the server privacy to generate a dummy according to the same distribution where ti¯ is generated from. however, this is not realistic because ti¯ is determined by both p and q which is user's private information. therefore, in our analyses, we assume that a dummy is generated from uniform distribution over possible values of ti¯. for example, if possible values of ti¯ is { <dig>   <dig>   <dig>   <dig>  5}, dummies are randomly selected from any one of them. the purpose of padding dummies is to mitigate the risk of leaking ti¯. in order to clarify the effect of the use of dummy values, we concentrate on the basic case; the database contains a single p, and there exist k possible values of ti¯. i-th value of the k possible values arises as the true ti¯ according to the probability wi. namely, true ti¯ is generated from the multinomial distribution with k different probabilities w = w <dig>  ...,wk, while dummies are generated from the multinomial distribution with equal probability 1/k. to conduct stringent analyses, we assume that the user knows w, and he/she also knows that dummies are uniformly distributed over k possible ti¯.

the security provided by our protocol can be formalized in the following manner. first we recall that, in our protocol, the server computes encryption of ti¯ and encryption of dummy values φ <dig>  ..., φn, and then sends the user the n+ <dig> encrypted values as well as the number of positive dummy values in φ <dig>  ..., φn. for the purpose of formalizing the security, we introduce a "fictional" server that performs the following: it first receives the encrypted values ti¯, φ <dig>  ..., φn from the real server. secondly, it gets the sign of ti¯.  thirdly, it generates another dummy value ti¯′ randomly, and independently of the values of ti¯, φ <dig>  ..., φn ), in the following manner:

• if ti¯ is positive, then ti¯′ is chosen randomly from positive values.

• if ti¯ is negative, then ti¯′ is chosen randomly from negative values.

finally, the fictional server sends the user an encryption of ti¯′ ) as well as the encrypted φ <dig>  ..., φn and the number of positive values in φ <dig>  ..., φn. we note that, when the user receives a reply from the fictional server, the user can know the sign of ti¯ which is the same as that of ti¯′, but cannot know any other information on ti¯ since ti¯′ is independent of ti¯. in the setting, the following property can be proven:

theorem  <dig> suppose that the user cannot distinguish, within computational time time, the sets of decrypted values of ciphertexts involved in outputs of the real server and of the fictional server. then any information computable within computational time time from the decryption results for output of the real server is equivalent to information computable within computational time time′ from the sign of ti¯only, where time′ is a value which is close to time.

proof let  a be an algorithm, with running time time, which outputs some information on the decrypted values for an output of the real server. we construct an algorithm a′ which computes, from the sign of ti¯ only, an information equivalent to the information computed by  a. the construction is as follows; from the sign of ti¯, a′ generates dummy values by mimicking the behavior of the fictional server, and then a′ inputs these dummy values to a copy of  a, say a*, and gets the output of a*. now if the output of a′ is not equivalent to the output of  a, then the definition of a′ implies that the probability distributions of the outputs of  a with inputs given by the decrypted values for outputs of the real server and of the fictional server are significantly different ; it enables the user to distinguish the two possibilities of his/her received values by observing the output of  a, but this contradicts the assumption of the theorem. therefore, the output of a′ is equivalent to the output of  a as claimed. moreover, the computational overhead of a′ compared to  a is just the process of generating dummy values by mimicking the behavior of the fictional server; it is not large  since the server-side computation of our proposed protocol is efficient. hence, the theorem holds.

roughly rephrasing, if the assumption of the theorem is true for a larger time, then the actual situation of our proposed protocol becomes closer to the "ideal" case provided we focus on any information available from efficient computation. as a first step to evaluate how the assumption is plausible , we performed computer experiments to show that some natural attempts to distinguish the actual and the fictional cases do not succeed, as explained below.

in this experiment, we evaluate the security of our protocol by comparing the probabilities that the user correctly guesses the value ti¯ in two cases: the case in which the user makes a guess based only on a prior knowledge w, and the other case in which the user makes a guess based on the observation of the search result under the condition that he/she knows w.

for the first case, the user's best strategy for guessing ti¯ is to choose the i0-th possible value, where

  i0=argmaxwi1≤i≤k. 

in this case, the success probability of the guess is wi <dig> 

let us consider the best strategy for the second case. as described above, we consider an practical case that n dummy values φ <dig>  ..., φn chosen from the k possible values uniformly at random, and the user makes a guess from the received n +  <dig> shuffled values φ <dig>  ..., φn, ti¯. now suppose that the user received the i-th possible value ai times for each  <dig> ≤ i ≤ k . since the choices of φ <dig>  ..., φn are independent of ti¯, the probability that the user received i-th possible value ai times for each  <dig> ≤ i ≤ k and that ti¯ is i0-th possible value is

 na <dig> …,ai0- <dig> …,ak1kn⋅wi0=ai0⋅wi0n!a1!⋯ak!kn. 

therefore, the conditional probability that ti¯ is the i0-th possible value, conditioned on the set of the user's received values, is

 na <dig> …,ai0- <dig> …,ak1kn⋅wi0∑i=1kna <dig> …,ai0- <dig> …,ak1kn⋅wi=ai0⋅wi0∑i=1kai⋅wi. 

this implies that the user's best strategy is to guess that ti¯ is the i0-th possible value, where

  i0=argmaxai⋅wi1≤i≤k. 

we estimated success probabilities of user's guess for the both cases by simulation experiments. here we assumed typical case when ti <dig> , <dig>  and  <dig> maccs keys are used. in this case, k =  <dig> and we performed the experiments for n =  <dig> ×  <dig>   <dig> ×  <dig>  ...,  <dig> ×  <dig> on three different distributions of ti¯ which were obtained by the following schemes:

 <dig> we randomly selected one fingerprint q from chembl and calculated ti¯ for all the entries in chembl and used the observed distribution as w. in our experiment, 177159-th fingerprint was selected as q .

 <dig> the same scheme as 1) was used when q was 265935-th fingerprint .

 <dig> we randomly selected a value from  <dig>  ..., k for m times and count frequency of i as hi and set wi = hi/m . we used k ×  <dig> as m.

all the distributions used here are shown in section  <dig> of additional file  <dig> 

we performed  <dig>   <dig> trials for each experiment. each trial consisted of choosing φ <dig>  ..., φn uniformly at random; choosing ti¯ according to w; deciding the user's guess i <dig> by formula  and formula  respectively ; and checking whether or not ti¯ was the i0-th possible value for both rules . the results of the experiment are given in table 1; they show that the user's attack success probability became significantly close to the ideal case when a sufficiently large number of dummies were used; therefore, our technique of using dummies indeed improves the output privacy.

security analyses for padding dummies for the case when the user is allowed to send more than one query

one might suspect that the attacker can detect the true ti¯ by sending the same query twice and finding the value which is appeared in both results. however, this attack does not easily succeed if n is sufficiently larger than k , and we consider that k is not too large in practice as we discussed in parameters settings of the protocol section.

in order to evaluate the security achieved by the padding dummies for the case when the user is allowed to submit l queries, we performed following analyses. here we evaluate the security achievement by comparing the case of using our protocol based on the padding dummy and the ideal case of returning only the sign of ti¯. in order to perform rigorous analyses, we assume the most severe case in which the attacker keeps sending the same query l times. for this case, the probability that ti¯ is the i0-th possible value after sending l queries on condition that frequency of i-th possible value of j-th query aii for j =  <dig>  ..., l is

   ∏j=1lai⋅wi∑h=1kai⋅wh. 

this implies that the user's best strategy is to choose i-th possible value which maximizes equation . as mentioned above, we compared the success ratio of the attack based on the above strategy and the ideal success ratio when the user makes the guess only from the given distribution w. we also assumed more realistic case that user did not know the exact distribution of dummy but knew the distribution that was similar to the actual distribution the server used. for the evaluation of this case, we generated dummies from the distribution u, which was slightly different from uniform distribution, while the user assumed that dummies were generated from uniform distribution. u was generated as follows:

 ui=r⋅1/k,wherer~n. 

we performed the experiment for l =  <dig>   <dig>   <dig>  ...,  <dig>  n =  <dig> ×  <dig>   <dig> ×  <dig>   <dig> ×  <dig> and δ =  <dig>   <dig> ,  <dig> ,  <dig> ,  <dig>  based on the same approach used in the evaluation of single query security. i.e., for each trial, n dummies were randomly chosen according to u , true value ti¯ was selected according to w and the attacker's guess was made based on the equation . we performed  <dig>   <dig> trials for each triplet of l, n and δ. those experiments were conducted for the same three distributions: wchembl- <dig>  wchembl- <dig> and wchembl-random. we compared the success ratio of the attack and the ideal success ratio when the user made the guess without seeing search results. the results are shown in figure  <dig>  the success ratio of user's attack decreased as the number of dummies increased and became closer to the ideal value when the sufficient number of dummies are given, even for the case that a large number of queries were sent. although an efficient method for dummy generation remains as a future task, the results also show that hiding the distribution of dummy is significantly effective for protecting database privacy and the user has to know it with high accuracy in order to steal extra information from the server.

database privacy in malicious model
for our protocol, the difference between the malicious and semi-honest models is that in the malicious model the user may use an invalid input q whose components qi are not necessarily in { <dig>  1}. if the user chooses q in such a way that some component qi is extremely large and the remaining ℓ −  <dig> components are all zero, then ti¯ will also be an extreme value  and depend dominantly on the bit pi; therefore, the user can almost surely guess the secret bit pi. since our protocol detects whether or not qi is a bit value without invading user privacy, it can safely reject illegal queries and prevent any illegal query attacks, including above case.

performance evaluation
in this section, we evaluate the performance of the proposed method on two datasets created from chembl.

implementation
we implemented the proposed protocol using the c++ library of elliptic curve elgamal encryption  <cit> , in which the nizk proposed in the previous study  <cit>  is also implemented.

for the implementation, we used parameters called secp192k <dig>  as recommended by secg . these parameters are considered to be more secure than 1024-bit rsa encryption, which is the most commonly used public-key cryptosystem. the implementation of

owing to the limitation of the range of plaintext, the implementation here does not include sign-preserving randomization. for the purpose of comparison, we also implemented a gp-mpc protocol by using fairplay  <cit> . in order to reduce the circuit size of the gp-mpc, we implemented s simple task that computes the sign of tversky index between a query and a fingerprint in the database, and repeated the task for all the fingerprints in the database. thus the cpu time and data transfer size of the implementation is linear to the size of database.

experimental setup
the jaccard index along with the threshold θ =  <dig>  were used for both protocols. for sscc, we used  <dig>  dummies. these two implementations were tested on two datasets: one, referred to as chembl  <dig>  was the first  <dig> fingerprints stored in chembl, and the other, referred to as chembl full, was  <dig> , <dig> fingerprints in the latest version of chembl. all the programs were run on a single core of an intel xeon  <dig>  ghz on the same machine equipped with  <dig> gb memory. to avoid environmental effects, we repeated the same experiment five times and calculated average values.

RESULTS
the results are shown in table  <dig>  despite the proposed method including elaborate calculation like the nizk proof, we can see from the results that both the cpu time and communication size of the proposed method are significantly smaller than those of the gp-mpc protocol. furthermore, it is clear that sscc provides industrial-strength performance, considering that it works, even on a huge database like chembl full, taking no more than  <dig> s and  <dig> s for the server and client respectively.

the experiment on chembl full by gp-mpc did not finish within  <dig> hours.

the experiment on chembl full by using gp-mpc did not finish within  <dig> hours. since both cpu time and communication size are exactly linear to the size of database for the gp-mpc protocol, the results of chembl full for gp-mpc are estimated to be more than  <dig> hours for both sides and  <dig> gbyte data transfer from client to server, considering the results of chembl  <dig> 

by using simple data parallelization, the computational speed will be improved linearly with the number of cpus. since all the programs were run on the same machine there was almost no latency for the communication between the two parties in these experiments. therefore, gp-mpc, whose communication size is huge, is expected to require far more time when it runs on an actual network that is not always in a good condition. the other important point is that sscc requires only two data transfers, which enables data transfer after off-line calculation. on the other hand, gp-mpc must keep online during the search because of the high communication frequency. we also note that it took less than  <dig> mb to compile sscc, while gp-mpc required more than  <dig> gb. considering these observations, sscc is efficient for practical use. it is known that several techniques improve the performance of gp-mpc and the previous work by pinkas et al.  <cit>  reported that free xor  <cit>  and garbled row reduction  <cit> , which are commonly used in state-of-the-art gp-mpc methods  <cit> , reduced running time and communication size by factors of  <dig>  and  <dig>  respectively when a circuit computing an encryption of aes was evaluated. though these techniques are not implemented in fairplay, we consider that gp-mpc is yet far less practical for the large-scale chemical compound search problem compared to our method which improved running time and communication size by factors of  <dig>   <dig> and  <dig>   <dig> 

CONCLUSIONS
in this study, we proposed a novel privacy-preserving protocol for searching chemical compound databases. to our knowledge, this is the first practical study for privacy-preserving  similarity searching in the fields of bioinformatics and chemoinformatics. moreover, the proposed method could be applied to a wide range of life science problems such as searching for similar single-nucleotide polymorphism  patterns in a personal genome database. while the protocol proposed here focuses on searching for a number of similar compounds, we are examining further improvements of the protocol such as the client being able to download similar compounds; we expect this on-going study to further contribute to the drug screening process. in recent years, open innovation has been attracting attention as a promising approach for speeding up the process of new drug discovery  <cit> . for example, research on neglected tropical diseases including malaria has been promoted by the recent attempt to share chemical compound libraries in the research community. in spite of high expectations, such an approach is still limited to economically less important problems on account of privacy problems  <cit> . therefore, privacy-preserving data mining technology is expected to be the breakthrough promoting open innovation and we believe that our study will play an important role.

competing interests
the authors declare that they have no competing interests.

authors' contributions
ks, ha, kn and ka designed the protocol inspired by the discussion with th. ks, kn, na and gh conducted security analyses. ks and sm implemented the protocol. ks evaluated performance of the protocol. all authors wrote the manuscript. all authors read, commented and approved the final manuscript.

supplementary material
additional file 1
supplementary text .

click here for file

 acknowledgements
ks thanks yusuke sakai and takahiro matsuda for fruitful discussions.

declarations
this work was supported by the japan-finland cooperative scientific research program of jst/amed  and jsps kakenhi grant number  <dig> . js and kt are supported by jst crest. kt is supported by jst erato, riken postk, nims mi2i, jsps kakenhi nanostructure and jsps kakenhi grant number 15h <dig>  js is supported by jsps kakenhi grant number  <dig> 

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2015: joint 26th genome informatics workshop and 14th international conference on bioinformatics: bioinformatics. the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/16/s <dig> 
