BACKGROUND
the main goals of research in systems biology are the development of quantitative models of intracellular pathways and the development of tools to support the modeling process. thereby, most of the available methods and models consider only a single "typical cell" whereas most experimental data used to calibrate the models are obtained using cell population experiments, e.g. western blotting. this yields problems in particular if the studied population shows a large cell-to-cell variability. in such situations inferring a single cell model from cell population data can lead to biologically meaningless results. in order to understand the dynamical behavior of heterogeneous cell populations, it is crucial to develop cell population models, describing the whole population and not only a single individual  <cit> .

this has already been realized by several authors, and it has been shown that stochasticity in biochemical reactions and unequal partitioning of cell material at cell division can lead to complex population dynamics  <cit> , such as bimodal distributions. besides these sources for heterogeneity also genetic and epigenetic differences have to be considered  <cit> .

for the purpose of this paper, heterogeneity in populations is modeled by differences in parameter values and initial conditions of the model describing the single cell dynamics  <cit> . the network structure is assumed to be identical in all cells. the distribution of the parameter values within the cell population is described by a multi-variate probability density function, which is part of the population model. this modeling framework is well suited for modeling genetic and epigenetic differences among cells  <cit> .

in the following, the problem of estimating the probability density of the parameters is studied. therefore, we employ population snapshot data , which provide single cell measurements at every time instance but which do not provide single cell time series data. a typical experimental setup which provides psd is flow cytometric analysis. in general, psd are a common data type in the experimental analysis of biological systems.

so far, there are not many methods available for the estimation of parameter distributions. in pharmacokinetic studies mixed effect models  <cit>  are used frequently. unfortunately, as in the problem we consider the number of individuals is very large  and the amount of information per individual very limited , these methods are computationally too demanding. furthermore, as in this study we are particularly interested in intracellular signal transduction, also methods which purely focus on the population balance  <cit>  cannot be employed. in  <cit>  methods are proposed which can in principle deal with the problem at hand. there, the considered estimation problem has been formulated as a convex optimization problem. unfortunately, these methods either require an extensive amount of measurement data  <cit> , and/or do not allow considering prior knowledge  <cit> . additionally, no methods to evaluate the reliability of the estimates are provided.

in this paper a novel bayesian approach  <cit>  for inferring the parameter density will be introduced. the approach is mainly based on the maximum likelihood methods presented in  <cit> , but can deal with sparse and noisy single cell data in addition to realistic measurement noise models. furthermore, one may directly access the remaining uncertainty of the estimation result and the prediction uncertainties via the calculation of bayesian confidence intervals  <cit> . it is shown that the posterior distribution can be determined efficiently employing a parameterization of the parameter density in combination with commonly used markov chain monte carlo  sampling techniques  <cit> .

to illustrate the properties of the proposed methods, a mathematical model of the tumor necrosis factor  pathway  <cit>  is analyzed using artificial experimental data.

methods
problem statement
cell population model
for the purpose of this work we consider intracellular biochemical reaction networks which are modeled by systems of ordinary differential equations. this modeling framework allows to describe metabolic networks as well as signal transduction pathways, as long as spatial effects and stochasticity of the biochemical reactions can be neglected. mathematically, the dynamic behavior of each single cell is determined by an ordinary differential equation in state space form   

with state variables , output variables , and parameters . the vector field  is lipschitz continuous and the functions  and  are continuous. if for example the concentration  is measured via flow cytometry, we would have , where c is a proportionality factor. the index i specifies the individual cells within the population. the parameters θ can be kinetic constants, e.g. reaction rates or binding affinities.

employing the definition of the single cell dynamics , a cell population model is given by the collection of n cells,   

the heterogeneity within this population is modeled by differences in parameter values among individual cells. the parameters are distributed according to the probability density function , with . this density function is part of the population model specification. the parameter vector of cell i is subject to the probability distribution   

note that interactions among individual cells influencing the analyzed pathway are not allowed. this is a restriction but indeed fulfilled in many in vitro lab experiments.

measurement data and noise
in this paper we consider experimental setups where measurement data are obtained in the form of population snapshots, e.g. via flow cytometry. population snapshots are taken at different times tj, and the jth snapshot contains measurements for the output y of mj cells. due to experiment setup, it can be assumed that any cell is present at most in one snapshot.

the cells in the individual snapshots are referenced through index sets: snapshot j contains all cells from the index set , with m <dig> =  <dig>  thereby,  in which  is the number of snapshots.

let the data point for the cell with index i be denoted as   

where t is the time at which the measurement was taken, and  is the measured, noise-distorted output as defined below. if cell i has been measured as part of the jth snapshot, then t = tj. the snapshot j is the set of all data points  with i ∈ ij, as depicted in figure 1:   

in the parameter estimation, only the union of all snapshots is considered, and the parameter density function Θ is fitted to all snapshots simultaneously. to this end, we introduce the collection of all data, denoted as   

in which  is the total number of measured cells.

we emphasize that experimental setups are considered in which cells are not tracked over time. these setups are very common in studies on the population scale. classical examples for measurement techniques yielding such data are flow cytometric analysis and cytometric fluorescence microscopy. these measurement techniques allow to determine protein concentrations within single cells. as the population is well mixed when the measurement is performed and no cell is measured more than once, the individual single cell measurements  are independent. this independence of  and    

in which  is the measured output and y is the actual output from . the multiplicative noise is denoted by η× ∈ ℝm and the additive noise s denoted by η+ ∈ ℝm. both, η× and η+ are in the following assumed to be vectors of log-normally distributed random variables with probability density functions   

for all j = {×, +}, k =  <dig>  ..., m. this noise model allows the study of relative and absolute measurement noise and describes the commonly seen noise distributions in biological experiments  <cit> .

from  the conditional probability of measuring  given y can be determined. as the different output errors are assumed to be independent the conditional probability density is   

with  being the value of the line integral   

which is illustrated in figure  <dig>  for this line integral no explicit solution can be given. in this paper its value is determined numerically using the adaptive simpson quadrature method  <cit>  implemented in matlab.

problem formulation
as mentioned previously, when studying heterogeneous populations the density of the parameters Θ is in general unknown but necessary to gain an in-depth understanding of the population dynamics. therefore, we are concerned with the problems:

problem  <dig> given the measurement data , the cell population model Σpop, and the noise model , infer the parameter density Θ*.

problem  <dig> given the measurement data , the cell population model Σpop, and the noise model , determine the uncertainty of the estimated parameter density Θ*.

unfortunately, the number of cells considered in a standard lab experiment is on the order of  <dig> to  <dig>  thus, simulating the population model  is computationally expensive. furthermore, it is hard from a theoretical point of view to deal with ensemble models such as . density-based descriptions of the population dynamics are far more appealing for solving problem  <dig> and  <dig>  therefore, in the next section a density description of the population is introduced.

density-based modeling of cell populations
to simplify the inference problems on Θ the population description is changed from an ensemble model  to a density model  <cit> . the variables of this new model are no longer states or outputs of the single cells but the density function ϒ of the output, with . and  this density function yields the probability of drawing a cell sample from the cell population with output ,   

in which  is an arbitrary subset of the output space. hence, y can be interpreted as a random variable which is distributed according to ϒ.

to compute the cell population response ϒ for a given Θ, s independent single cell trajectories y of the cell population  are calculated. the parameters for these cells are drawn from Θ and the initial conditions are computed according to x0). this yields  with distribution of y depending on Θ. given  an approximation of ϒ is   

in which  is the density of the applied kernel density estimator, with . this is illustrated in figure  <dig>  in this work multivariate log-normal kernels   

are used to conserve the property that all variables are positive. the positive definite matrix h is used to select the width of the kernel , and is chosen using the available rule of thumb described in  <cit> . the selection of h is crucial for achieving a good approximation of the probability density, and depends strongly on s.

approaches similar to the one we use to approximate ϒ are employed in  <cit> , in  <cit>  with a naive density estimator and in  <cit>  in the context of cell migration.

estimation of the parameter density
in the previous section an approach to determine the output density ϒ within the cell population for a given parameter density Θ is presented. based on this an approach for estimating Θ from the available data  is developed next.

bayes' theorem for heterogeneous cell populations
for learning the parameter density from the data bayes' theorem   

is used, in which p is the prior probability of Θ,  is the conditional probability of observing  given Θ,  is the posterior probability of Θ given , and  is the marginal probability of . as the different single cell measurements are independent  can be written as   

in which  is the conditional probability of observing  given Θ. note that due to the independence of  and , for i <dig> ≠ i <dig>  it is not necessary to distinguish between the cases that  the two cells are measured at the same instance  and that  the two cells are measured at different time instances . hence, merely the conditional probability of each individual single cell measurement has to be determined. for the considered process the  can be determined using the output density ϒ,   

as this equation cannot be solved explicitly the integral has to be approximated numerically. this could be realized using importance sampling  <cit> , but as drawing a independent sample from ϒ requires knowledge of ϒ in the first place,  is for computational purposes expressed as an integral over θ,   

in which , with y , θ) being the output at time t for a cell having parameters θ. this reformulation of  is possible as ϒ directly depends on Θ. this step simplifies the evaluation of  tremendously.

based on  and , the calculation of the posterior probability for a given probability density of the parameters Θ is possible. unfortunately, the inference problem nevertheless cannot be solved directly, as Θ is element of a function space, and hence further steps are necessary.

parameterization of parameter density
in order to avoid the infinite dimensional inference problem the parameter density is parameterized. Θ is modeled by a finite weighted sum of multivariate ansatz functions Λj,   

the ansatz functions  are themselves probability densities with . the weighting vector is denoted by , where nφ is the number of ansatz functions and  to guarantee that Θφ is a probability density. the weightings φj can be interpreted as parameters determining the probability density Θφ and are for the remainder also called density parameters.

note that the method presented in the following is independent of the choice of ansatz functions. nevertheless, a clever choice of the ansatz functions may improve the approximation of the true parameter density dramatically. in this work, the ansatz functions are chosen to be multivariate gaussians.

given a parameterization of Θφ, the output density can be simplified to  

in which ϒ  is the output density obtained for single cell parameters distributed according to Λj. this representation of the response is possible as the output density fulfills the superposition principle with respect to the parameter distribution Θφ. this reformulation has the advantage that computing the output density for arbitrary density parameters φ only requires the non-recurring computation of the responses ϒ  and summation of those.

reformulation of posterior probability
having parameterized Θφ and ϒ  the conditional probability  may be parameterized and expressed as the weighted sum,  

in which  is the conditional probability of observing  given the parameter density Λj. as the ansatz functions are predefined the conditional probability  can be evaluated,   

this in general high-dimensional integral is approximated employing monte carlo integration, yielding   

in which θ is drawn from Λj, θ ~ Λj, and sc is the total size of the monte carlo sample {θ}k. if Λj allows for an efficient drawing of samples, the computational cost of determining  is reasonable, requiring sc simulations of the single cell model .

given these precomputed 's, which are independent of the density parameters φ, the conditional probability can be simplified to   

in which  and 〈·,·〉 denotes the scalar product. employing  the posterior probability can be written as   

where the prior probability,   

enforces the satisfaction of the constraint of Θφ being a probability density. note that for parameter estimation often only the shape of the posteriori probability density is of interest, and not the normalization. therefore, we only consider   

in which  is the unnormalized posterior probability. sampling from  and  will yield the same distribution of sample members. furthermore,  and  have the same extrema.

computation of maximum posterior probability estimate
given the simplified unnormalized posterior probabilities  one important question is which parameter density Θφ maximizes . this is the most likely parameter density for the measured data and the prior knowledge.

this optimal parameter density  can be computed by solving the optimization problem   

in which the two constraints ensure that the obtained density is positive and has integral one. note that as Λj is a probability density,  is positive if all φj are positive. employing this and optimizing - instead of ,  can be simplified to   

this minimization problem can for concave p be solved rather efficiently, as in such case  is a convex optimization problem  <cit> . for this problem solvers exist which guarantee convergence to the global optimum in polynomial time, e.g the interior point method  <cit> .

uncertainty of parameter density
in the previous section a method is presented which allows the computation of the maximum posterior probability estimate . as measurement data are limited and noise corrupted this estimate will not be the true parameter density. hence, the uncertainty of the parameter density has to be evaluated.

sampling of posterior probability density
in order to analyze the uncertainty of the estimate, a sample of the posterior probability density  is generated. this is possible, as the unnormalized posterior probability of a distribution  can be evaluated efficiently given  - . in this work the sampling is performed with a classical metropolis-hastings method  <cit> . also gibbs or slice sampling approaches may be employed. compared to importance and rejection sampling these methods are well suited as they do not require the selection of an appropriate proposal density, a task which is difficult in this case.

the main point of concern when using mcmc sampling for the problem at hand is that the prior probability and the posterior probability respectively are only non-zero on a  -dimensional subset of the density parameter space . this is due to the fact that the sum over the elements of φ has to be one for Θφ being a probability density. if a standard proposal step was used, the acceptance rate would have been zero.

this problem can be overcome by performing the sampling in the -dimensional space, , and computing the remaining density parameter via the closing condition . according to this the update step for φ consists of two steps:

 <dig>  draw proposals  from the -dimensional reduced proposal density tr,   

 <dig>  determine  such that ,   

in this work, the reduced proposal density is chosen to be a multivariate normal distribution, , with covariance matrix .

this two-step proposal generation procedure is in the following denoted by φk+1~t. the proposed density parameter vector φk+ <dig> is accepted with probability   

the distinction of the two cases is hereby crucial to ensure that only probability densities  which are greater than zero for all  are accepted.

by combining update and acceptance step one obtains an algorithm which draws a sample of weighting vectors , or respectively parameter densities , from the posterior distribution. the number of sample members is thereby sφ. the pseudo code for the routine is given in algorithm  <dig>  in particular, the facts that

• the conditional probabilities  are only computed once in the beginning, and that

• every evaluation of the acceptance probability pa requires only a small number of algebraic operations,

ensure hereby an efficient sampling. without this reformulation the integral defining the conditional probability  would have to be computed in each update step. the resulting computational effort would be very large.

algorithm  <dig> sampling of posteriori distribution 

   require: data , prior p, model p, ansatz functions , initial point φ <dig> 

      calculation of conditional probabilities  employing p.

      initialize the markov chain with φ <dig> 

      for k =  <dig> to sφ do

         given φi propose φk+ <dig> from proposal density t .

         calculate posterior probability .

         generate uniformly distributed random number r ∈  <cit> .

         if r <pa then

            accept proposed parameter vector φk+ <dig> 

         else

            restore previous parameter vector, φk+ <dig> = φk.

         end if

      end for

end

bayesian confidence intervals
the sample  generated by algorithm  <dig> contains information about the shape of the posterior density . this information can be employed to determine the bayesian confidence intervals, also called credible intervals.

in this work an approach is presented which employs the percentile method  <cit>  to analyze the uncertainty of Θφ. the 100α-th percentile of a random variable r is the value  below which 100α % of the observations fall. accordingly, the 100-th percentile interval of r is defined as . the bayesian confidence interval is frequently defined as the 95-th percentile interval  <cit> . thus, the parameter is contained in  with a probability of 95% given the measurement data and the prior knowledge.

for the problem of estimating parameter densities, the 100α-th percentile is not simply a number but a function. as we are interested in the confidence intervals of Θφ, the percentiles are defined point-wise for every θ. the 100α-th percentile of Θφ is thus the function  which gives for every parameter vector θ the value under which 100α % of the observations fall,   

consequently, the 100% bayesian confidence interval  of Θφ is defined as   

as the sample  is given, an approximation of  and  can be obtained by studying the percentiles of the sample  <cit> . for instance the nearest rank method or linear interpolation between closest ranks can be used to determine .

predictions of output density
as the parameter density is not known precisely, also the model predictions show uncertainties. to evaluate the reliability of the population model and its predictive power, these prediction uncertainties have to be quantified. therefore, the bayesian confidence interval of the prediction around the output density with the highest a posteriori probability density,   

is determined.

the 100% confidence intervals of the predictions  are again defined via the percentile method,   

in which the 100α-percentile  of the predicted out put ϒ is defined as   

computing  for an experiment is a three step procedure. at first, the outputs ϒ  are computed. given ϒ and the sample from the posterior density , a sample from the predicted output density  is given by   

this sample can be used to approximate the prediction confidence interval . as the population model has to be simulated only nφ times, this calculation is computationally tractable.

to sum up, in this section a method for the estimation of parameter distributions in heterogeneous cell populations from population data has been presented. it has been shown that the optimal value as well as the bayesian confidence intervals can be computed efficiently employing a parameterization of the parameter density. also a method to determine prediction uncertainties has been presented. this allows an in-depth analysis of the reliability of the model. a summary of the procedure is shown in figure  <dig> 

RESULTS
to illustrate the properties of the proposed methods, artificial measurement data of a cell population responding to a tumor necrosis factor  stimulus will be analyzed. for illustration purposes, we consider a case where only one parameter is distributed in a first step. in a second step, we show that the method is also applicable in the case of multi-parametric heterogeneity.

in multicellular organisms, the removal of infected, malfunctioning, or no longer needed cells is an important issue. therefore, multicellular organisms developed different mechanisms to externally enforce cell death. thereby the signaling molecule tnf is one of the key players.

tnf can bind to specific death receptors in the cell membrane and is able to induce programmed cell death, also called apoptosis, via the activation of the caspase cascade. on the other hand, it promotes cell survival via the inflammatory response, specifically activation of the nf-κb pathway  <cit> . the proportion of the activation of these two signaling pathways decides about the fate of the single cell. in the following a simple model for the caspase and nf-κb activation is studied which reproduces the main features of the single cell response to a tnf stimulus.

model of tnf signaling pathway
the model considered in this study has been introduced in  <cit>  and is based on known activating and inhibitory interactions among key signaling proteins of the tnf pathway. a schematic is shown in figure  <dig>  besides active caspase  <dig>  and active caspase  <dig> , the nuclear transcription factor κb  and its inhibitor i-κb are considered in the model. the model is given by the ode system   

the state variables xi, i =  <dig>  ...,  <dig> denote the relative activities of the signaling proteins c8a, c3a, nf-κb and i-κb, in this order. the functions actj and inhj represent activating and inhibiting interactions, respectively. they are given by   

and   

the parameters aj and bj are activation and inhibition thresholds, respectively, and take values between  <dig> and  <dig>  the external tnf stimulus is denoted by u. initial conditions of the single cells are the steady states with c3a =  <dig> for u =  <dig>  all nominal parameter values are given in table  <dig> 

it is known from experiments that the cellular response to a tnf stimulus is highly heterogeneous within a clonal cell population. some cells die, others survive. the reasons for this heterogeneous behavior are unclear, but of great interest for biological research in tnf signaling, e.g. the use of tnf or related molecules as anti-cancer agent.

to understand the biological process at the physiological and biochemical level it is crucial to consider this cellular heterogeneity, using for example cell population modeling. here, we model heterogeneity at the cell level via differences in the parameters b <dig> and a <dig>  the parameter b <dig> describes the inhibitory effect of nf-κb via the c3a inhibitor xiap onto the c <dig> activity, and the parameter a <dig> models the activation of i-κb via nf-κb. studies showed that these two interactions show large cell-to-cell variability  <cit> .

univariate parameter density
for a first evaluation of the proposed method an artificial experimental setup is considered in which the caspase  <dig> activity is measured at four different time instances during a tnf stimulus,   

at each time instance the c3a concentration in  <dig> cells is determined, y = x <dig>  with measurement noise according to , where μ× =  <dig>  σ× =  <dig> , μ+ = log, and σ+ =  <dig> . this corresponds to an average noise level of about 15%. the generated artificial experimental data for a bimodal distribution in b <dig> are depicted in figure  <dig> 

as ansatz functions Λj for the estimation, we use nφ =  <dig> truncated gaussians   

where  = and sj such that . the center points μj are equidistantly distributed on the interval  <dig> <cit> . the prior probability p is chosen to be   

in which pβ is the probability density of the beta-distribution. the parameter αj and βj are selected such that pβ  has its extremum at  and convariance σ <dig>  the distribution of a sample {φk}k drawn from this prior is shown in figures  <dig> and  <dig>  note that the prior does not enforce a trend to smaller or larger parameter values of b <dig>  furthermore, it does not enforce a trend to unimodal or bimodal distributions Θφ . such distribution properties shall be inferred from the data.

given the ansatz functions Λj  the conditional probabilities  of observing  are determined using importance sampling, according to . this computation takes about three minutes, on a standard personal computer using a single cpu. thereby, 32% of the computation time are required for the simulation of the individual cells y) for individual parameter values θ, and 59% for the evaluation of the conditional probability . the rest is spent on pre- and post-processing. subsequently, mcmc sampling is performed to obtain a sample  of the prior , of the conditional, and of the posterior probability distribution. the sample has sφ =  <dig> members and the generation takes only four minutes. the computation is very fast, as the proposed approach simplified the evaluation of the conditional probability to a matrix vector multiplication. note, that all steps during the computation of the conditional probabilities and the mcmc sampling can be parallelized, yielding a tremendous speed-up for more complex models.

the results of the sampling are illustrated in figure  <dig> using parallel coordinates  <cit> . from this representation of  it can be seen that after the learning processes most of the density parameters still show large uncertainties. the uncertainty in the posterior distribution is a lot smaller than the uncertainty in the likelihood function, due to the stabilization via the prior. note that the visualization also uncovers pronounced correlations between some parameters, e.g. φ <dig> and φ <dig> are negatively correlated for . this indicates that the model of the density of b <dig> is over-parameterized with respect to the data. thus, the number of ansatz functions could be reduced while still achieving a good fit.

to analyze the uncertainty of Θφ in more detail the sample  is employed to determine the 80%, 90%, 95%, and 99% bayesian confidence intervals. the results are depicted in figure  <dig>  it can be seen that the confidence intervals for some values of b <dig> are rather small, indicating that the data contain many information about these regions. unfortunately, in particular for b <dig> >  <dig>  the confidence intervals are very wide showing that the parameter density in this area cannot be inferred precisely. but, although the amount of data is limited and the uncertainty with single φi's may be large, the posterior distribution of Θφ already shows key properties of the true parameter density, e.g. the bimodal shape, which has not been provided as prior information. this bimodal shape is also seen in the likelihood function, but there the uncertainties are larger than in the posterior probability distribution.

besides the uncertainty of Θφ also the predictive power of the model can be evaluated. this is exemplified by studying the confidence interval of  and  for the previously considered experimental setup. the bar indicates that the distribution of the noise corrupted output  instead of the true output y is considered. this allows the direct comparison of the prediction with the data. the predictions are shown in figure  <dig> 

it is obvious that, although the parameter distributions show large uncertainties, the predictions are rather certain. this is indicated by tight confidence intervals. furthermore, the mean predictions  and the predictions with highest posterior probability  agree well with the true output distribution , for measured output c3a and predicted output nf-κb. the small prediction uncertainties can be explained to be sloppiness  <cit>  of the density parameters φi parametrizing the distribution of b <dig>  a detailed analysis indicates  that the number of ansatz function can be decreased, still ensuring a good approximation of the distribution of b <dig> 

multivariate parameter density
in many biological systems several cellular parameters are heterogeneous and different cellular concentrations can be measured  <cit> . therefore, we show in this section that the proposed method can also be employed to estimated multivariate parameter densities from multi-dimensional outputs. furthermore, the influence of the choice of the prior on the estimation result is analyzed.

to perform this study we considered the same experimental setup as above. the only difference is that two concentrations are measured, c3a and nf-κb, y = t. the considered artificial experimental data of  <dig> cells are depicted in figure  <dig>  the ansatz function for Θφ are nφ =  <dig> truncated multivariate gaussians equivalently to . the covariance matrix is  <dig>  · i <dig> and the extrema are equidistantly distributed on a regular 2-dimensional grid which is aligned with the axes.

given this setup, the convergence rate is studied in terms of the integrated mean square error,   

of true distribution and distribution with highest posterior probability . the imse is computed for amounts of measured cells per time instance and different priors. the priors are thereby again beta-distributions . the extrema φext are chosen as in the last section such that the prior is flat. the standard deviation on the other hand is reduced step-wise from σ =  <dig>  . given this requirements, the values αi and βi of the prior  are determined. the result for different numbers of measured cells sampled from the available data set is shown in figure  <dig>  note that the imse is a stochastic quantity as the selection of measured cells is a stochastic processes and hence also the estimated density  is stochastic. to account for this stochasticity, several realizations are performed and the mean is computed.

from figure  <dig> it becomes clear that the imse strongly depends on both, amount of data and informativeness of prior. for uninformative priors, the outcome for little data is highly uncertain and the imse is large and shows large variations. on the contrary, if the prior is very informative but wrong, the number of measurement data required to obtain a good estimate is tremendous. for the right choice of σ, one observes a fast convergence of the  to Θtrue, as shown in figure  <dig>  and only little variation for small amounts of data. hence, the usage of prior knowledge, even if it is only partially correct, yields for more stable estimates and faster convergence. furthermore, this study suggests that the typical number of cells measured by flow cytometry  is informative enough to infer key features of population heterogeneity.

CONCLUSIONS
in this paper a bayesian approach for inferring the parameter density for heterogenous cell populations with single cell resolution from population data is presented. we show that the proposed model can deal with limited and noisy measurement data as well as realistic noise models. the method utilizes a parameterization of the parameter density which, in combination with a reformulation of the conditional probability, allows a computationally efficient evaluation of the posterior probability. compared to other methods for cell populations this approach does not rely on the approximation of the measured population response using density estimators.

for sampling from the posterior probability the metropolis-hastings algorithm is used. here it has been adapted to be applicable to the considered constraint problem. using this sampling strategy a sample from the posterior probability density is determined. this sample is employed to compute bayesian confidence intervals for the parameter distribution, as well as for the model predictions. also summary statistics like mean parameter density and mean predicted output density can easily be determined. for concave prior distributions we could even show that the calculation of the parameter density for the highest posterior probability is a convex problem.

the properties of the proposed scheme are evaluated using artificial data of a tnf signal transduction model. it could be shown that the proposed method yields good estimation results for a realistic experimental setup. furthermore, although the remaining uncertainties are large, the predictions showg only small uncertainty indicating sloppiness of parameters.

concerning the choice of the prior distribution it could be shown that the regularizing effect is beneficial if only little data is available. on the other hand, if the amount of available data increases, informative but not carefully chosen priors slow down the convergence.

authors' contributions
jh, sw, and ps developed the problem formulation. jh developed the methods and implemented the algorithms. jh, sw, nr, and fa contributed to the systems dynamics and statistics. jh, sw, and fa constructed the application example and jh applied the proposed method. md and ps contributed to the selection of the studied biological system, the choice of the addressed biological questions, and the interpretation of the results. jh, sw, and nr wrote the article. all authors read and approved the final manuscript.

