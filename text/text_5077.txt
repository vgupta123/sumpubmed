BACKGROUND
biotechnology has developed to allow the production of genetically modified organisms carrying specific characteristics of interest. for example, plants can be made tolerant to a herbicide, thus facilitating traditional chemical weed control, or can be induced to produce an insecticidal protein, thus reducing the need for external chemical treatment. because of its novelty, concerns exist regarding the safety of genetic modifications .

in europe, genetically modified organisms  and derived products are allowed on the market after passing an approval system in which the safety for humans, animals and the environment is assessed. this safety assessment is performed by the gmo panel of the european food safety authority , that has issued guidance for applicants who seek to bring gmos onto the european market  <cit> . these guidelines advocate a risk assessment strategy known as the comparative approach  <cit> . comparative risk assessment is based on the idea that typically there are organisms that are very similar to the gmo, which have a history of safe use as foods. such organisms can be used as comparators for the gmo, and the purpose of the comparative analysis is to identify similarities and differences between the gm crop-derived food/feed and its non-gm counterparts. in the first step agronomic and morphological characteristics of plants are considered as well as their chemical composition. the general idea is that a comparative risk assessment can establish equivalence between the gmo and its non-gm counterpart for characteristics other than the intended effects of the genetic modification. equivalence in this context is defined as the absence of differences other than those due to natural biological variation. however, little guidance is available how to perform equivalence testing for gmos in practice. although the efsa guidance document  <cit>  discusses general principles for risk assessment and recommends the use of appropriate statistical tools, detailed protocols for the design of experiments and statistical analysis are not provided.

in practice, applicants have been using widely differing protocols to carry out field trials and very different models for the statistical analysis . oberdoerfer et al.  <cit>  applied equivalence tests using fixed but arbitrary equivalence limits of ± 20%. in a later paper by hothorn and oberdoerfer  <cit>  this fixed value was described as rigid and not reflecting the difference in variability between components, and component-specific safety ranges were proposed to be proportional to the variance of the concurrent control in the same field trials, which method ignores the amount of background variation found between commercial varieties. hammond et al.  <cit>  and park et al.  <cit>  only applied difference tests, which ignores the question which difference would be relevant biologically. special pleading for significant results was needed in the first of these publications to arrive at their conclusion that the gmo was as safe and nutritious as reference varieties. mcnaughton et al.  <cit>  and herman et al.  <cit>  adjusted p values of difference tests using the false discovery rate method which is a method developed for multiple difference tests. however, this method is simply not appropriate in the context of equivalence testing because it is only concerned with false discoveries and not with false non-discoveries. in any case, whatever the advantages and disadvantages of the methods, the application of different statistical approaches and models may lead to different conclusions regarding the risk assessment of gmos and derived foods/feeds. therefore a working group of the efsa gmo panel investigated whether more detailed guidance could be provided to applicants regarding the use of appropriate statistical models for the analysis of the data from field trials for compositional, agronomic and phenotypic studies and animal feeding trials, and regarding the design of field trials. this paper is based on the report of the working group  <cit> , and is restricted to the statistical analysis of data on the chemical composition of plants obtained in field trials. we will not further discuss the experimental design of such field trials . whereas typically many plant characteristics are analysed in such field trials, the scope of the statistical tests in this paper is restricted to the analysis of single characteristics. however, a simultaneous display of test results for multiple plant characteristics is advocated.

equivalence testing is commonly used in biomedical and pharmaceutical statistics  <cit> . for example, pharmacokinetic parameters of alternative drug formulations have to be shown to be within a factor  <dig>  of the value for the reference drug. in words, the null hypothesis of the equivalence test is  "there is a difference between the gmo and its reference of a certain minimum size" against the alternative hypothesis: "there is no or only a small difference between the gmo and its reference". in this testing procedure we need a significant result  in order to conclude that the gmo and the reference are equivalent. thus there is a limited error i probability  that equivalence is concluded whereas a difference larger than the limit value exists in reality.

specific questions exist for equivalence testing of gmos. first, how can equivalence limits for gmo mean characteristics relative to reference mean characteristics be defined given that no generally agreed equivalence factor  exists? secondly, how should equivalence limits be estimated given that appropriate data from field trials will describe typical biological variation rather than the maximum allowable variation? thirdly, can the equivalence testing procedure be adapted to the typical large biological variation usually found in field studies?

equivalence testing requires the determination of equivalence limits to enable its implementation. for each chosen characteristic, or for groups of them, equivalence limits for the true difference are effectively the limiting values for an acceptable difference. in this paper we will determine equivalence limits as relative deviations from the overall mean of the reference varieties. in current practice, equivalence limits have almost never been established satisfactorily before the experiment. therefore, we suggest that commercial reference varieties are included in field experiments, to allow a direct comparison with the gmo. as will be explained, this can be seen as a test of the difference between gmo and the population of commercial references. an alternative view is that the reference varieties in the experiment allow the estimation of equivalence limits, which are subsequently used for assessing the equivalence of the gmo. inclusion of both the conventional counterpart and reference varieties in field or animal experiments for gmo safety testing is not new, and papers on such experiments have been published . however, as far as we know data from such studies have not been used before for setting limits for equivalence testing in the manner proposed here.

RESULTS
equivalence testing for gmos
we developed a statistical methodology to assist in the comparative risk assessment of gm crops. the novelty of the method is the simultaneous assessment of both differences and similarities . to detect unintended effects, it is optimal to study the differences of the gmo with its non-gm counterpart. however, to assess similarities and equivalence, a characterization of natural biological variability is needed. we propose that the gmo can be viewed relative to the background variation shown by common varieties  used as references. for this dual purpose of difference and equivalence testing we propose the use of field trials using not only the gm crop and its non-gm counterpart, but also a range of reference varieties. designs using a wide range of varieties have been used previously, showing that this is a feasible approach in principle .

when testing for differences  the null hypothesis and alternative hypothesis are:

 h0: Δgc=0h1: Δgc≠ <dig> 

where Δgc is the true difference on an appropriate scale between the gmo and the conventional counterpart. student's t-test is a common tool for simple comparisons, but for the statistical analysis of data from more complicated designs linear mixed models are appropriate, as are also used in this paper . for testing statistical significance of differences an alternative procedure is to construct a confidence interval for the difference, and observe whether this includes the value zero. this method is preferred because it gives the bonus of a quantification of the estimated difference and its uncertainty.

a statistically significant test result identifies a difference, whether it is biologically relevant or not. moreover, whereas for tests with confidence level 1-α there is a limited error i probability  that a significant result is obtained  whereas no difference exists in reality, these tests do not restrict the error ii probability  of finding no significance whereas in reality there is a difference. so the absence of a significant difference is not a proof for equivalence of the gmo and the counterpart, or ''absence of evidence is not evidence of absence''  <cit> . this motivates supplementing the difference test with an equivalence test.

for equivalence testing the state of non-equivalence needs to be put as a null hypothesis, thus assigning the restricted error i probability α of the test to the event of falsely declaring equivalence . this requires the use of equivalence limits as maximum acceptable deviations because the simple inequality Δ≠ <dig> does not qualify as a testable hypothesis. thus, when testing for equivalence of a gmo and a reference the null and alternative hypotheses become:

 h0:   |Δgr|  ≥el h1: |Δgr| <el 

where Δgr is the true difference between the gmo and the reference, and where el is the equivalence limit for this difference. note that the hypotheses above assume symmetrical lower and upper equivalence limits , but this can be easily generalised if needed. using this set of hypotheses it can be seen that the observed difference between gmo and reference mean should be small to reject the null hypothesis . large differences will not lead to significant test results .

with prior specified equivalence limits, both the difference test and the set of equivalence tests can be implemented using a single confidence interval. this is in the spirit of the two one-sided tests  approach of schuirmann  <cit> . both implied null hypotheses of non-equivalence  are rejected if the confidence interval lies entirely between the equivalence limits. in equivalence studies the choice of a 90% confidence interval is customary  <cit>  as it corresponds with the customary 95% level for statistical testing of equivalence. however, it should be stressed that preference for specific levels of confidence is not a statistical decision, but one to be made by risk managers. for simplicity of the approach we nevertheless propose to calculate by default two-sided 90% confidence intervals rather than calculating confidence intervals separately with different confidence levels for the difference and the equivalence tests. this proposal implies that each  difference test will have a 90% confidence level, and each equivalence test a 95% confidence level.

the statistical procedure needed for gmo equivalence testing is however more complicated than this. a single test would be sufficient with fixed equivalence limits, using e.g. a generally agreed equivalence factor . lacking this we estimate equivalence limits from field studies with concurrent reference varieties, which are typically the same studies in which also the gmo and its non-gm counterpart are tested. we therefore have a two-step procedure, at least in principle. the first step is the setting of equivalence limits , the second step is their use for assessing equivalence .

as practical limits on background variation we consider appropriate percentiles  of the distribution of reference variety characteristics as the true equivalence limits. being based on limited data, the estimated equivalence limits in step l are always uncertain. in principle, equivalence limits could be calculated in one of the following three ways: 1) as point estimates of the true equivalence limits; 2) as 'inner' confidence limits ; or 3) as 'outer' confidence limits . in this paper the third option is chosen, because typical variation between reference varieties is smaller than maximum allowable variation, which would ideally underlie the setting of equivalence limits. consequently equivalence limits based on the typical variation between reference varieties in the field trial are not true safety limits but only specifications of limits on natural background variation. therefore their uncertainty can be allowed to be included in the width of the equivalence interval as in the chosen third option. the efsa gmo panel considered that specifying minimum requirements for the experimental design  <cit>  was enough to limit the inevitable estimation errors to reasonable levels.

the second step of the equivalence testing procedure  consists of comparing the gmo mean to the equivalence limits obtained in step l. again there are three options for testing:  direct comparison of the point estimate for the gmo to the equivalence limits;  a true test of equivalence ; and  a true test of non-equivalence . borrowing some terminology from quality inspection theory , test e <dig> controls the 'consumer's risk' because it has a limited probability of accepting non-equivalent varieties, and test e <dig> controls the 'producer's risk' because it has a limited probability of rejecting acceptable varieties. test e <dig> will find 'equivalence' more often than test e <dig> but less often than test e <dig>  for which reason we will refer to test e <dig> as a 'shared risk' test. 'shared' here means that a borderline variety has a 50% probability to be classified as either equivalent or non-equivalent using this test procedure . we propose to classify the results of test e <dig> as 'equivalence more likely than not' or 'non-equivalence more likely than not'.

in traditional equivalence testing  <cit>  e2-type tests are being used. however, these may have a low power in case of a large residual variation, which is typical for agricultural field studies. therefore, addressing our third question , it is proposed here not only to rely on test e <dig>  but to apply all three tests. this provides a richer view on equivalence than obtained by using only one test. therefore the final outcome of the equivalence assessment is not just binary, but it is one of four equivalence categories, for which we propose the following labels:  equivalence;  equivalence more likely than not;  non-equivalence more likely than not; and  non-equivalence.

the outcome of test e <dig> discriminates category  from ++. similarly, the outcome of test e <dig> discriminates category  from ++. the outcome of test e <dig> discriminates + from +. in the method section exact calculations will be defined, and it will be shown that the proposed test e <dig> applied to estimated equivalence limits is actually just a test of difference, with the null hypothesis that gmo and reference means are equal, but allowing for variability between genotypes . on the other hand, tests e <dig> and e <dig> are truly two-step procedures, where the null hypothesis value of the test is only established after step l. consequently, statistical properties of such tests can only be defined conditionally on the outcome of step l.

for the interpretation of results we recommend a graphical display, similar to those suggested by others  <cit> . however, certain adjustments are needed to account for the fact that equivalence limits are estimated values, and these are described in detail in the methods section. figure  <dig> presents a schematic simplified example of the display, showing the possible outcomes for a single characteristic. for any given characteristic there are then fundamentally seven possible types of outcome. among these seven types there are four where the mean value of the gmo lies between the adjusted equivalence limits , and three where it lies outside the equivalence limits . it is assumed here that the line of no difference is in between the adjusted equivalence limits. if not, then the selected conventional counterpart is itself non-equivalent to the reference varieties and a separate, non-statistical discussion should consider the place and relative importance of difference and equivalence testing in the risk assessment.

the results of the four tests are easily derived from the graphical presentation as in figure  <dig>  the test of difference will give a significant result if the confidence interval bar does not cross the line labelled "no difference". therefore in outcome types  <dig>   <dig>   <dig> and  <dig> there is a significant difference between the gmo and the counterpart. the test of equivalence consists of three subtests as explained before. first, when the point estimate of the gmo vs. counterpart difference falls within the adjusted equivalence limits then the conclusion is that the gmo variety is not significantly different from the reference varieties and equivalence is more likely than not . second, a stronger conclusion can be given and the null hypothesis of non-equivalence will be rejected  when the confidence interval bar falls entirely within the adjusted equivalence limit lines . finally, when the confidence interval bar lies completely outside the adjusted equivalence limits , the null hypothesis of equivalence can be rejected and the reasonable conclusion is that of non-equivalence.

the interpretation of the outcome types 3- <dig> with respect to gmo risk assessment may be more difficult than for types  <dig>   <dig> and  <dig>  and may need further safety evaluation, possibly using alternative statistical methods. for example, if differences, even if not statistically significant, were consistent over multiple situations, this could indicate the occurrence of unintended effects. outcome types  <dig> or  <dig> may easily be obtained for characteristics that are stable and precisely measured within each genotype, but that have a large natural variation among reference genotypes. outcome types  <dig> or  <dig> may easily result when the measurement precision or within-genotype stability is low in comparison to the natural variation.

we propose to display as many of the analysed characteristics as is feasible simultaneously, on the same graph . more than one graph is required if characteristics are analysed on different scales, and/or if some are transformed and others not.

testing the method by simulation
the performance of difference and equivalence tests was investigated using simulation. the simulation settings were based on the real field trial data .

in the first simulation study  the gmo mean was a random draw from the same distribution as the reference varieties, thus mimicking a stochastic equivalence between gmo and reference varieties. when the counterpart mean was chosen equal to the gmo mean, the theoretical size of the difference test  was reproduced. when the counterpart mean was a random draw from the reference distribution or was set equal to the reference mean, there were almost always true differences between gmo and counterpart, and these were detected with a power around 80%. the performance of the equivalence tests was independent of the choice of the counterpart mean. equivalence was detected with 95% probability using test e <dig> and with 76-77% probability using test e <dig>  non-equivalence was detected with less than 1% probability in test e <dig> 

true reference mean mr =  <dig> in all cases. "~ n" refers to a random draw from a normal distribution with the specified mean and variance. lsd refers to the theoretical least significant difference calculated using equation  <dig> with theoretical variances and infinite degrees of freedom. number of iterations was  <dig> . values in bold can be compared to theoretical values .

in the second simulation study  the gmo was chosen at the border between equivalence and non-equivalence, mr+lsd . the border value  <dig>  on ln scale corresponds to a relative difference between gmo mean and reference mean of 100* =  <dig> %. as in the first study the theoretical size of the difference test  was reproduced when the counterpart mean was chosen equal to the gmo mean, and again, the results for the equivalence tests did not depend on the choice of the counterpart mean. under this null-hypothesis both the proof of equivalence test  and the proof of non-equivalence test  were rejected in about 5% of the simulations, which is the theoretical size of the tests. the shared risk test  accepted equivalence in 50% of the simulations, as expected.

the results of the third simulation series are shown in figure  <dig>  here the gmo mean was varied systematically, deviating between dif = 0% and dif = 65% from the reference mean, and the counterpart mean was set equal to the reference mean. for the case dif = 0% the size of the difference test  is reproduced, in all other cases there are true differences, and it can be seen that the power of test d quickly rises to effectively 100% at dif = 10%. figure  <dig> also shows the behaviour of the three equivalence tests. the proof of equivalence and proof of non-equivalence tests  are seen to have the nominal size  at the equivalence/non-equivalence borderline value dif =  <dig> %. the equivalence test based on testing the difference between gmo and reference varieties, resulting in a statement whether  equivalence is more likely than not  was not designed as a real proof of equivalence test. as expected, test e <dig> has a probability of 50% to conclude equivalence for dif =  <dig> %. in comparison to test e <dig> it has higher power to find true equivalence, but of course pays for this by also having a larger probability to state 'equivalence more likely than not' when in fact there is non-equivalence. finally, it can be noted that between 5% and 25% the gmo is still often found to be equivalent to the reference varieties, although it is very likely that at the same time a significant difference with the conventional counterpart is found.

field trial example
the proposed methods are illustrated by an example using real data provided by efsa. since this paper is not intended to contribute to the risk assessment of specific cases, the data are presented anonymously . the precise calculations are described in the methods section. a graphical overview of the results of the comparative analysis is shown in figures  <dig> and  <dig>  more detailed results are given in figure  <dig>  and in tables  <dig> and  <dig> 

the 90% confidence limits  are expressed on the scale of ratio gmo to counterpart mean. seds are on ln scale, ratio and 90% confidence limits are back-transformed. the 95% equivalence limits  calculated on the scale of the ratio of gmo to reference mean. the point estimate of this ratio itself is given in the column ratio. the width of the equivalence interval depends on sedgr; <dig> , given on the logarithmic scale, and the degrees of freedom for equivalence  calculated by the kenward-roger method. see text for further explanation.

 <dig> for ash and phytic acid the equivalence intervals are not trustworthy, because the estimate of the variance between reference genotypes was  <dig> and sedgr; <dig> is based on lower strata .

figures  <dig> and  <dig> show the relative differences of the gmo with respect to the conventional counterpart for  <dig> plant characteristics. for example, relative large deviations are seen for acid detergent fiber , ferulic acid , folic acid , neutral detergent fiber , niacin  and total dietary fiber . however, depending on the variability and uncertainty underlying them, large differences may not be statistically significant , while smaller differences may be . note that the significance tests are based on a standard error of difference  which is calculated from the residual variance vε  as sedgc;1=vε, where  <dig> and  <dig> are the number of replications in this experiment for gmo and counterpart, respectively. the number of degrees of freedom, estimated by the kenward-roger method, varies between  <dig>   and  <dig>  .

in total there were twenty-three analytes with a significant difference between gmo and counterpart . these analytes are shown in blue  in figures  <dig> and  <dig>  and some examples of boxplot representations  <cit>  of these data are shown in figure  <dig> to assist further interpretation. note, however, that these boxplot representations ignore some aspects of the model, such as site and replication variation. therefore, the boxplots alone cannot provide a complete overview.

the variation between reference varieties has been used to calculate equivalence limits. although conceptually there is just one set of equivalence limits, the limits were calculated on three different scales. each scale is useful for a specific purpose.

 <dig>  the first scale is the natural scale which allows food/feed experts to recognize values most easily. for instance, niacin has an equivalence interval  when back transformed on this natural scale. these intervals are shown in the boxplots .

 <dig>  the second scale is the ratio scale where the gmo is compared to the mean of the reference varieties . this scale provides the most direct view whether the difference between gmo and references is significant . this scale is therefore best for distinguishing between equivalence categories  and  . for niacin the equivalence interval on this scale is , so indeed the difference is significant and non-equivalence is more likely than not.

 <dig>  finally, the equivalence interval can be expressed on the adjusted scale where both gmo and references are compared to the conventional counterpart ; this scale allows a simultaneous presentation of the results for both the comparison of gmo with the counterpart and the comparison of gmo with the reference lines. therefore it is the easiest scale for performing a test of equivalence by the graphical equivalent of the tost procedure advocated in this paper . for the example of niacin the equivalence interval on this adjusted scale is . this interval overlaps with the confidence interval for the comparison of the gmo with its counterpart , therefore neither equivalence nor non-equivalence has been proven for this analyte .

in any case, the three intervals are just adjusted versions of each other and completely equivalent for statistical testing as explained more fully in the method section. in the current example two cases were found where, on applying test e <dig> the gmo point estimate falls outside the calculated equivalence limits, or, in other words, there was a statistically significant difference between the gmo and the references . for these analytes non-equivalence is more likely than not. for further interpretation boxplots are given in figure  <dig>  it can be seen that for 16: <dig> palmitic both the gmo and the counterpart are higher than the reference range, therefore on this single characteristic gmo and counterpart seem to present the same hazards, if any. it is outside the scope of this document to discuss the risk assessment of such cases. for niacin the situation is different. niacin is found 24% lower in the gmo than on average in the reference varieties, and the result is also significantly lower  than what is found for the counterpart.

a problem occurs when the variance component between reference genotypes is estimated as zero. in the current example dataset this occurred with ash and phytic acid. in these cases the calculation of standard errors of difference will be based on the assumption that there is no variation between the reference genotypes, and standard errors and degrees of freedom are derived from a model which omits the random factor for genotypes. this is not a truly believable model: too many degrees of freedom will be assigned to the standard error of difference  leading to equivalence intervals which are typically too narrow.

accepting the calculated equivalence limits as null hypothesis values in a test of equivalence for the remaining  <dig> analytes leads to the conclusion that  <dig> are proven to be equivalent to the reference varieties, whereas for  <dig>  the equivalence is more likely than not, but not strictly proven at the 95% confidence level. for further interpretation boxplots can be given, see examples in figure  <dig> 

discussion
difference testing and equivalence testing can both contribute to a meaningful comparative assessment. first, the gmo can be different from its appropriate non-gm counterpart, and a difference may constitute a hazard  which should be subject to further safety evaluation. this is why the proof of difference is sometimes referred to as "proof of hazard", but this is a misleading term because there are many differences that present no hazard for human health. secondly, a gmo can be equivalent to appropriate references, such as a range of commercial varieties. established equivalence of a gmo has been interpreted as relevant for subsequent toxicological risk assessments. it should be stressed that statistical approaches should never be used for automatic decisions of food safety, but as tools providing the appropriate context for the final safety assessement.

for testing of differences and equivalences two-sided tests  is the most common case, but if it is a priori known that differences can only be in one direction, then it can be easily adapted to one-sided versions .

not always will there be datasets from field trials with reference varieties in their trial design. use of literature data may occasionally be considered as an alternative source for quantifying background variation, but may present great difficulties both regarding the representativity of the data and the possibilities to discern the different components of variation. further discussion is given in  <cit> .

we described how the simultaneous application of difference and equivalence testing can lead to seven possible types of outcome . with respect to the necessity of further evaluation to assess a possible impact of gmos on human/animal health, the patterns of significant differences  should be inspected for biologically relevant signals. cases with a clearly established non-equivalence in test e <dig>  and cases where non-equivalence is found more likely than not in test e <dig>  require further evaluation. risk assessors may also require further evaluation for cases where equivalence is more likely than not according to test e <dig>  but not significant in the formal equivalence test e <dig> . risk characterization will then be used by assessors to specify what further evaluation is needed, based on considerations linked to patterns of observed results and biological or toxicological relevance.

experiments should be designed to have sufficient statistical power to be able to reject the null hypotheses being tested for relevant magnitudes of effect. however, the use of observed power, which is power estimated from the data arising from the experiment itself, is not a valid alternative. it has been proposed that equivalence can be concluded for a non-significant difference, provided that the observed power of the difference test for a difference at the equivalence limit is at a specified high level. however, tempelman  <cit>  pointed out how with those criteria a poorly executed experiment would be rewarded a greater chance of concluding equivalence than an experiment with a better precision. power analysis must therefore be done prior to the experiment.

it can be noted that for difference and equivalence testing approaches power analysis has a different purpose. first, risk assessors should require that a difference test will find true differences of a specified magnitude in a substantial probability of cases . secondly, applicants for introducing a gmo on the market have an interest that a truly equivalent gmo will pass the equivalence test with high probability. this requires a power analysis where the relevant effect level is for example a zero or small difference between the gmo and the mean of the reference varieties.

in this paper the focus is on comparing characteristics averaged over environments. in the biomedical literature on equivalence testing this is known as an approach for average equivalence. alternative approaches are based on the idea of individual equivalence related to the question of switchability of the treatments  <cit> . in the context of field trials this can be translated to requiring equivalence in the population of environments . in the linear mixed model approach the genotype by environment interaction would have to be estimated  <cit> , which is typically easy to do . however, the consequences for safety assessment are still unclear, for example would it be possible to declare a gmo equivalent in some environments and not in others? more discussion on such issues is needed before a statistical approach can be devised.

commercial reference varieties have also been included in animal feeding studies . in principle our proposed method can be used there as well. however, when it is expected that the investigated characteristics  do not vary at all between reference varieties used in the feed, this would not conform to the basic idea proposed here of using observed variation between genotypes as a basis to determine equivalence limits. further research on such cases is needed.

the method proposed in this paper may contribute to an objective and transparent process of risk assessment. however, several issues remain to be solved. first, the approach should be adapted for data which cannot readily be transformed to normality, such as counts, quantal or ordinal data. second, research is needed for the power analysis of mixed model tests. more research is needed to characterize the coverage probability of the estimated confidence intervals for small sample sizes, such as three plots, two years, and four sites, because the available models are asymptotic. moreover, research is needed for an optimal design, i.e. optimal numbers of plots and sites for a most powerful decision on equivalence. statistical analysis may need to be adapted to more complicated designs . and last but not least, these methods may be adapted to the simultaneous assessment for multiple characteristics. when performing many simultaneous tests spurious significant results can be expected both in proof of difference and proof of equivalence. there is little experience with multivariate tests of equivalence . multivariate analysis may give an alternative approach to the multiplicity issue. although some discussion of these issues is given in  <cit> , more research is needed.

CONCLUSIONS
safety assessment of gmos is ultimately a complex undertaking in which the interpretation of compositional data is only one element. and even in this restricted setting the role of statistical methodology is limited to provide a context for the final biological interpretation of results. nevertheless, this interpretation can benefit from a standardised statistical approach that clearly shows differences and equivalences in a comparable manner.

the main purposes of the comparative assessment are twofold: to demonstrate whether the gmo and/or derived food/feed is different from its appropriate non-gm counterpart and/or to demonstrate whether it is equivalent to appropriate reference varieties, apart from the intended changes. this paper proposes a statistical methodology that is not focussed exclusively on either differences or equivalences, but that provides a richer framework within which the conclusions of both types of assessment are allowed simultaneously. the approaches are complementary: statistically significant differences may point at biological changes caused by the genetic modification, but which are not relevant from the viewpoint of food safety. on the other hand, equivalence assessments are used to classify differences as being inside or outside the range of natural variation. a procedure combining both approaches will aid the subsequent interpretation of the statistical results.

a simulation study using realistic variance values validated the expected probabilities of the tests proposed. an important conclusion is in a typical situation of variabilities a range of deviations exists, say between 5% and 25%, where the gmo is still equivalent to the reference varieties, although it is very likely to find a significant difference with the conventional counterpart. this illustrates that the application of equivalence testing is a useful complement to the traditional practice of performing difference tests.

the conclusions drawn for the example field trial dataset can be summarised as follows. for  <dig> out of  <dig> analytes there were statistically significant differences  between gmo and counterpart. the differences varied between -13% and +14%. for two analytes, 16: <dig> palmitic and niacin, a statistically significant deviation  from the mean of the reference varieties was found, and non-equivalence was more likely than not. further evaluation is required. for five analytes, lysine, phosphorus, potassium, vitamin b <dig> and vitamin e, equivalence was more likely than not, but a strict proof of equivalence cannot be given. further evaluation may be required. for two analytes, ash and phytic acid, no proper conclusion on equivalence can be formulated because of lack of observable natural variation in the reference varieties. further evaluation may be required. for  <dig> analytes  equivalence was established in a formal test of equivalence  using the estimated equivalence limits.

