BACKGROUND
a key step in the post-transcriptional modification process is called splicing and consists of the excision of the intronic regions of the premature mrna  while the exonic regions are then reconnected to form a single continuous molecule, the mature mrna. a complex regulatory system mediates the splicing process which, under different conditions, may produce alternative mature mrnas  starting from a single pre-mrna molecule. alternative splicing , i.e. the production of alternative transcripts from the same gene, is the main mechanism responsible for the expansion of the transcriptome  in eukaryotes and it is also involved in the onset of several diseases  <cit> .

a great extent of work has been performed to solve two basic problems on as: characterizing the exon-intron structure of a gene and finding the set of different transcript isoforms that are produced from the same gene. some computational approaches, based on transcript data, for these crucial problems have been proposed; indeed good implementations are available  <cit> . recently, some tools related to the problem, but limited to the specific task of predicting splice junctions from next-generation sequencing  data, have been designed  <cit> . these tools are computationally intensive and would require a post-processing step to filter the correct data that can be related to the alternative exon-intron structure of a gene. moreover, the literature provides efficient solutions for computing a specific spliced alignment of an est against the genome . however these tools are designed to compute only spliced alignments and not to directly provide the complete exon-intron structure of a gene and its full-length isoforms.

in this paper we provide a specifically designed algorithm - efficient from both a theoretical and an empirical point of view - to predict the exon-intron structure of a gene from general transcript data that is optimal with respect to constraints derived by the input data. the algorithm is implemented in a tool, called pintron. similarly as recent programs  <cit> , pintron is a method for exon-intron structure prediction, but differently from these tools is able to efficiently process complex genes or genes associated with a large cluster of ests. indeed, the accurate prediction of the exon-intron structure of a gene is a computational hard task when the redundancy of the information given by est data must be taken into account. more precisely, combinatorial methods for the problem are highly accurate when they are able to combine two different steps:  producing putative spliced alignments of ests against the gene region and  selecting among the different putative spliced alignments of each est those confirming the same gene structure under some optimization criteria. this second step has been proved to be np-hard  <cit>  thus requires efficient heuristics.

on the other hand, finding putative spliced alignments  could be a challenging task when more than one alignment exists for the same transcript. indeed, for instance, there could be different possible splicing junctions between consecutive exons because of the presence sequencing errors or repeated genomic regions. as a consequence, choosing the correct spliced alignment of a single est sequence requires to perform a multiple comparison between several spliced alignments of all the est sequences in order to find the ones that support a common putative gene structure. in  <cit>  a detailed discussion of this issue is provided.

methods
in this paper we show how to efficiently solve the integration of the two steps of finding the  spliced alignments of a cluster of transcripts and using them to compute a common gene structure.

overall, our new combinatorial method for exon-intron structure prediction can be summarized as a four-stage pipeline where we:

 <dig>  compute and implicitly represent all the spliced alignments of a transcript sequence  against a genomic reference sequence by a novel graph representation, called embedding graph, of the common substrings of the transcripts and the genome. in this paper we provide efficient algorithms for building and, subsequently, visiting the embedding graph.

 <dig>  filter all biologically meaningful spliced alignments. this step is performed with a carefully tailored visit of the embedding graph.

 <dig>  reconcile the spliced alignments of a set of correlated transcript sequences into a maximum parsimony consensus gene structure. to complete this task we use the minimum factorization agreement  approach  <cit>  applied to the data produced by the previous step. indeed, the mfa approach gives an effective method to amalgamate some spliced alignments into a consensus gene structure .

 <dig>  extract, classify, and refine the resulting introns in order to provide a putative gene structure supported by transcript evidences.

we point out that our implementation also has a fifth step where it predicts a set of full-length isoforms by employing the graph-based method in  <cit> .

our method computes a consensus gene structure minimizing the number of exons, called maximum parsimony consensus gene structure. such a structure is strictly associated to a set of spliced alignments for each sequence in the cluster of transcript data that is also output by our algorithm. informally, a gene structure  is the description of the location of coding  and noncoding  regions along the genomic sequence. due to alternative splicing events, such as exon skipping, intron retention and competing exons, a portion of the genomic sequence could be both coding and noncoding with respect to different transcripts.

in this paper, we will evaluate all steps of the pipeline. accuracy and efficiency of pintron have been assessed by an experimental comparison with aspic  <cit>  and exogean  <cit> . the experimental results show that pintron is much faster than aspic and competitive with exogean. pintron scales much better than exogean  when processing genes with a large number of transcript sequences. the predictions made by pintron are more accurate than those by aspic and exogean. moreover, pintron is the only tool that is able to successfully complete all genes that have been considered. finally, our results indicate that pintron also improves the reconstruction of exact transcripts when compared with the other two tools.

in this experimental comparison, we focused on human genes given their excellent annotation status. however, pintron has been conceived to facilitate genome annotation in a variety of organisms in which expressed sequences as well as the reference genome are available. given the experimental results we summarized above, our program enables the investigation of the impact of alternative splicing on large-scale.

the rest of this section is devoted to present each algorithmic step of our four-stage pipeline.

implicit computation of spliced alignments
the first stage of our gene structure prediction method computes the set of all possible spliced alignments of a transcript  sequence against the genomic sequence.

a spliced alignment is a particular kind of alignment that takes into account the effects of the excision of the intronic regions during the rna splicing process. the spliced sequence alignment problem requires to compute, given a sequence p  and a reference sequence t , two sets fp = {f <dig> ..., fk} and ft={f1′,...,fk′} of strings such that p = f <dig> ... fk, t=pf1′i1f2′i2⋯fk-1′ik-1fk′s, and for each i, the edit distance between fi and fi′is small. the sequence of pairs  is called composition of p on t, each factor fi is called spliced sequence factor , and each fi′ is called genomic factor . allowing a small edit distance between the two factors is justified by the fact that est data contain mismatches  against the genome because of sequencing errors and polymorphisms. unfortunately, this also makes computationally harder the spliced alignment problem, especially when the transcript and the genomic sequence are large.

in our novel alignment method, we exploit the small edit distance between each pair  of corresponding factors: in fact, in this case, there must exist a sequence of some sufficiently long common substrings of the est factor fi and the genomic factor fi′. we call the sequence of the occurrences of perfectly matching substrings an embedding of the est sequence p in the genomic sequence and, clearly, it reveals the basic "building blocks" of the spliced alignment. our alignment algorithm is based on the construction of a compact and implicit representation of all the embeddings by means of a graph called embedding graph. such a graph can be efficiently computed from the est sequence p and the genomic sequence t in time o, where v is its vertex set, and it can be used in the second stage of our pipeline in order to efficiently enumerate all the biologically meaningful compositions.

in the following we detail the notion and construction of the embedding graph. let us first recall, that according to the traditional notation, given a string s = s1s <dig> ... sq, we denote with |s| its length and with s the substring sisi+ <dig> ... sj.

a fundamental notion is that of pairing of two strings. more formally, a pairing  of two sequences p and t  represents the positions p on p and t on t of a common substring p = t of p and t. in other words, a pairing  represents a common substring x of p and t, called factor induced by the pairing, such that x is of length l starting in positions p and t on p and t respectively. the positions p and t are called starting positions, while p + l and t + l are called ending positions.

we say that a pairing v1= is contained in a pairing v <dig>  if the positions p <dig> and t <dig> of v <dig> can be extended to the left or to the right on both the sequences p and t in order to obtain v <dig>  clearly, the factor induced by v <dig> is a substring of the factor induced by v <dig>  moreover, we say that v <dig> is a prefix-pairing  of v <dig> iff v1≼v <dig> and v <dig> shares the same starting  positions on  p and  t of v <dig>  this fact implies that the factor induced by v <dig> is a prefix  of the factor induced by v2on p and t. a pairing v is maximal if and only if there does not exist a distinct pairing containing  v. in other words, v is maximal if and only if the common factor induced by  v cannot be "extended" neither to the left nor to the right on both p and t.

a sequence of non-overlapping pairings  is called an embedding . given two embeddings ε=〈v <dig> …,vn〉 and ε′=〈v1′,⋯,vm′〉, then  ε is contained in ε'  if and only if for each vi in  ε there exists a pairing vj′ in ε' such that vi≼vj′. given the set  of the embeddings of p in t, we say that ε∈e is maximal iff there does not exist ε′∈e, ε≠ε', such that ε≼ε′.

not all embeddings induce a biologically meaningful composition. for example, an embedding made of several short pairings "scattered" along the genome cannot be considered a valid spliced alignment. in order to restrict embeddings to be useful for building a spliced alignment, we fix three parameters ℓe, ℓd and ℓi. intuitively, the parameter ℓe is the minimum length of a pairing, ℓd limits the maximum number of consecutive mismatches that can appear in a single exon, and ℓi represents the minimum length of an intron. then a representative embedding is a maximal embedding ε=〈v <dig> …,vm〉 such that li ≥ ℓe, pi+ <dig> -pi - li ≤ ℓd, and either  |ti+ <dig> -ti - | ≤ ℓd or  ti+ <dig> - ti -  ≥ ℓi is true. it is easy to see that only representative embeddings might induce a biologically plausible composition.

indeed, a careful choice of the three parameters ℓe, ℓd and ℓi allows to recover a spliced alignment of p in t with a fixed  error rate from some representative embeddings. therefore, we propose the problem of finding all representative embeddings of p in t, formalized as the representative embedding problem , where we are given a pattern p, a text t, and three parameters ℓe, ℓd and ℓi. the goal is to compute the set εr of the representative embeddings of p in t.

in this first stage of the pipeline, we tackle the re problem by using the embedding graph defined as follows.

definition . given a pattern p and a text t, the embedding graph of p in t is a directed graph g =  such that the vertex set v is the set of maximal pairings of p and t that are longer than ℓe. two pairings v <dig> =  and v <dig> =  are connected by an edge  ∈ e if and only if:  p <dig> -  ≤ ℓd, and  |t <dig> - t <dig> - | ≤ ℓd or t <dig> - t <dig> -  ≥ ℓi.

basically the conditions of the definition of embedding graph ensure the following crucial property: two maximal pairings v <dig> and v <dig> are connected by an edge in the embedding graph if and only if there exists a representative embedding  ε in which there are two consecutive pairings vi′ and vi+1′ such that vi′ is contained in v <dig> and vi+1′ is contained in v <dig> 

we will use this property to build representative embeddings from an embedding graph. observe that such a property derives from the maximality of the representative embeddings and from the uniqueness of the maximal pairing containing a pairing which belongs to a representative embedding.

we designed an algorithm that builds the embedding graph of a pattern p and a text t in time o. the algorithm is composed of two steps. in the first step, the vertex set v is computed by visiting the suffix tree of the text t. this step requires o time for the suffix tree construction and o time for the computation of maximal pairings. in the second step, edges are then computed by checking the conditions of the definition of embedding graph on each pair of maximal pairings, leading to an o procedure. since the number of maximal pairings is usually very small compared to the length of p and t, the embedding graph construction procedure is efficient even on large patterns p and texts t.

extraction of relevant spliced alignments
the next stage of our pipeline is devoted to analyzing and mining the embedding graph to compute the representative embeddings that also induce distinct biologically meaningful compositions. indeed, it must be pointed out that different representative embeddings can induce the same compositions or spliced alignments. algorithm computecompositions is a two-step procedure. initially it extracts a subset of representative embeddings by performing a visit of the embedding graph. then the algorithm computes the compositions by merging consecutive pairings that are separated by short gaps.

embedding graph visit
the first step of computecompositions is a recursive visit of the embedding graph starting from a subset of vertices that we call extended sources.

such a procedure visits the embedding graph examining and extracting only pairwise-distinct representative embeddings that are biologically meaningful . more precisely, the visit of a vertex vk from the extended source s reconstructs the set  of biologically meaningful representative embeddings that are induced by the path p=〈s,v <dig> ...,vk〉 traversed during the visit of the embedding graph.

we will now explain the main steps of the procedure. during the visit of vertex vk, we examine each outgoing edge  and we "extend" each embedding ε=〈e <dig> …,ek〉 of . how the extension is performed depends on the relative position, on p and t, of ek in  ε and the new vertex vk+ <dig> that are depicted in figure  <dig>  in the exposition of the different possible cases, let ek =  and vk+ <dig> = . observe that given two pairings that are connected by an edge in the embedding graph, the corresponding factors might be overlapping in the text or in the pattern. to simplify the notation, in the following we identify a pairing with the factor it induces.

case . factors ek and vk+ <dig> overlap on both t and p. two different sub-cases must be analyzed. the first case occurs when the distance between the two initial positions of the factors ek and vk+ <dig> on p differs from the same distance on t of a value  less than ℓd, while the second case occurs when such a distance differs of a value greater than ℓi. if the first case occurs when | - | ≤ ℓd then the two pairings may belong to the same factor of the induced composition. thus, the algorithm replaces pairing ek in  ε with the shortest maximal prefix-pairing ek′ of ek and the longest maximal suffix-pairing ek+ <dig> of vk+ <dig> such that they do not overlap and that both ek′ and ek+ <dig> are at least ℓe long. the second case occurs when  -  ≥ ℓi. this case deserves a special discussion from the biological point of view since it could be related to an intron as well as to a tandem repeat in t. then factor ek could be extended to include the repetition in vk+ <dig> to produce a unique factor  of the embedding  ε.

case . factors induced by ek and vk+ <dig> overlap in t but not in p. this case is equivalent to the first sub-case of case .

case . factors ek and vk+ <dig> overlap in p but not in t. just as in case  two different sub-cases must be analyzed, that is either | - | ≤ ℓd or tk+ <dig> -tk -  ≥ ℓi. the first case is solved as in case . notice that when the second subcase occurs then the splice site placement is ambiguous because a suffix of the donor exon is equal to a prefix of the acceptor exon. also in this case, basic biological criteria are used to reduce the impact of the ambiguity.

case . factors ek and vk+ <dig> do not overlap neither in p nor in t. let gt and gp be the two substrings which separate ek and vk+ <dig> in t and p, respectively. since gp and gt do not form a pairing, they must contain a certain number of mismatches; we must determine if they support the possibilities that  ek and vk+ <dig> are part of the same factor or  there is an intron between ek and vk+ <dig>  similarly to case , two different sub-cases may arise. if | - | ≤ ℓd, then ek and vk+ <dig> might belong to the same factor of the induced composition. more precisely, ek and vk+ <dig> belong to the same factor if the edit distance between gt and gp is below a certain threshold - in which case vk+ <dig> is added to embedding  ε, otherwise the edge is discarded from the visit. instead, if tk+ <dig> -tk - pk+ <dig> + pk ≥ ℓi, the two pairings are separated by an intron, and we must determine the splice sites of such an intron. in this case, the algorithm computes a prefix gt′ and a suffix gt″ of gt that minimize the edit distance between gp and the concatenation of gt′ and gt″. also in this case, if the resulting edit distance is larger than an acceptable threshold, the edge  is discarded, otherwise vk+ <dig> is added to  ε. notice that computing the edit distance is not too expensive, since all strings involved are no longer than 2ℓd.

the definition of embedding graph allows the presence of directed cycles, which potentially might be troublesome. however, we claim that the embeddings, computed from a path  containing a cycle , would induce compositions with essentially the same set of factors of the compositions induced by the embeddings computed from the visit of the simple path p\c. the visit performed in the first step of algorithm. computecompositions guarantees that each possible representative embedding is analyzed. however, the biological criteria that we employ allow to consider only pairings belonging to biologically meaningful embeddings. since the visit computes pairwise-distinct representative embeddings and every case presented above requires o time, the overall computational complexity of the visit is clearly bounded by o, that is the total size of the representative embeddings that have been computed during the visit.

composition reconstruction
the set  of representative embeddings computed by the visit of the embedding graph directly leads to a set c of compositions. in fact, the visit guarantees that two consecutive pairings of a representative embedding are either separated by a small gap due to errors or by a large gap representing an intron of the spliced alignments. hence, the algorithm simply merges into a factor a sequence of factors induced by consecutive pairings vk =  and vk+1=  separated by small gaps, that is |tk+ <dig> - tk - pk+ <dig> + pk| ≤ ℓd. finally, the composition is retained if the edit distance between each est factor and the corresponding genomic factor is not larger than a fixed acceptable threshold.

building a gene structure
the first two stages of our pipeline are applied separately to each transcript sequence pi of the input data  computing a set c of biologically meaningful compositions for each pi. the main goal of the third stage is to extract a composition for each transcript that explains the putative gene structure. as stated before, informally a gene structure is the description of the location of coding and noncoding regions along the genomic sequence, where by a coding region we mean an exon and by noncoding region we mean an intron. note that the boundaries between an exon and an intron is called splice junction or splice site.

we aim to produce a maximum parsimony consensus gene structure for  which consists of a minimum set of genomic exons or coding regions compatible with a high quality composition ci for each transcript data pi. the minimization criteria is used to avoid overprediction of splice junctions. for this task we propose a formalization of the problem of finding a putative gene structure, called consensus gene structure problem  and discuss a solution of this problem. the input of the cg problem consists of a set c of compositions for each transcript pi in a set  and a finite ordered set f = 〈f <dig>  f <dig> ..., f|f|〉 of genomic factors induced by the compositions in ∪c. ordering of factors is assigned by considering their left splice junctions. then cg asks for the minimum cardinality subset f' of f such each pi has a composition with all genomic factors in f'. in other words f' is the minimum set of exons explaining a spliced alignment of each est data.

now, the cg problem can be faced by using the approach  <cit>  called minimum factorization agreement . more precisely, we use the mfa problem to compute a gene structure minimizing the number of exons.

let us recall the definition of the mfa problem. let f = 〈f <dig>  f <dig> ..., f|f|〉 be a finite ordered set of sequences over alphabet Σ, called factors and let s be a set of sequences over alphabet Σ. given a sequence s ∈ s, a factor-composition  of s consists of the sequence f=〈fi <dig> fi <dig> ⋯,fin〉 such that s=fi <dig> fi <dig> ⋯,fin and ij < ij+ <dig> for  <dig> ≤ j < n. then the set {fi <dig> fi <dig> ⋯,fin} is called the factor set of f and is denoted as f. while the notion of f-composition depends on the set of factors, such set of factors is usually clear from the context and is therefore omitted. please notice that a sequence s can admit different f-compositions: thus let f be the set of compositions of s. moreover, by extension, we will denote by f the set ∪s∈sf of all f-compositions of a set s of sequences. given a subset f' ⊆ f of factors and the set f, then f' is a factorization agreement set for f if and only if for each sequence s ∈ s, there exists a f-composition f in f whose factor set is a subset of f', i.e. f ⊆ f'.

the minimum factorization agreement problem, given a set f of factors and a set s of sequences, asks for a minimum cardinality subset f' ⊆ f such that f' is a factorization agreement set for f. then the cg problem can be reduced to the mfa problem by posing s to be the cluster of transcript sequences pi and f is the set of all genomic factors  used to produce the compositions c for each pi, i.e. f consists of all the compositions of each sequence in s. then the consensus gene structure consists of a minimum factorization agreement set for the set of compositions of the transcripts data. when solving the mfa problem on such data, the solution f' provides a minimum set of factors explaining all transcript sequences and a single composition of each transcript can be obtained from set f'.

by applying the algorithm in  <cit>  we can filter efficiently a set of spliced alignments agreeing to the same gene structure that are successively refined by the intron reduction step.

intron reduction
although the intron boundaries of the est spliced compositions are computed by finding the best transcript-genome alignment over the splice site regions and the most frequent intron pattern  according to  <cit> , the set of predicted introns may still contain false positives very close to true predictions. thus, we designed a procedure for comparing the intron set computed by the est spliced compositions in order to correct and reduce the set of false positives.

in the following, let the pair  denotes a genomic intron  and a spliced composition of an est s supporting the intron i, i.e. the composition has two consecutive factors fj, fj+ <dig> inducing intron i when aligned to the genome. then, given an error bound b, we say that  is b-reducible to  iff there exists a boundary shift of factors fj and fj+ <dig> of a new spliced composition of s inducing intron i' with at most b additional errors with respect to the previous alignment of the two factors against the genome. to improve the accuracy of the step, we also consider if the intron is supported by a refseq transcript and if it can be categorized as an u12/u <dig> intron. a refseq sequence is a validated full-length mrna stored and annotated in the ncbi refseq database. u <dig> and u <dig> refers to two intron categories for which the excision is mediated by the major spliceosomal pathway or the minor spliceosomal pathway, respectively. notice that refseq transcripts are usually full-length and error-free, that gt - ag, gc - ag and at - ac are the most frequent rules  <cit>  and those rules are associated to u12/u <dig> introns  <cit> . hence we assume that only introns that do not follow one of the u12/u <dig> rules and are not supported by a refseq transcript should be reduced. the input of our intron-reduction procedure is a set x of pairs  computed by the previous steps. then, r is the set of pairs in x such that s is a refseq, c <dig>  c <dig>  c <dig> and n are the set of pairs in x \ r following the gt - ag, gc - ag, at - ac and a non-u12/u <dig> rule respectively. our procedure basically tries to reduce elements in n to some intron in r and, if this is not possible, it tries to reduce to some element in the first set of the sequence c <dig>  c <dig>  c <dig> that allows the reduction.

RESULTS
we implemented the approach described in the previous section as a set of programs in the software package pintron. pintron receives a genomic sequence and a set of transcripts - ests and/or mrnas - and computes a representation of the exon-intron structure of the gene as well as a set of predicted full-length annotated isoforms. pintron outputs the list of the predicted introns with information such as relative and absolute start and end positions, intron lengths, the donor and the acceptor splice sites, and intron types . the output gives the composition as exons of each isoform and, for each exon, the start and end positions as relative and absolute coordinates, if a polya signal is present, and the length of 5'utr and 3'utr. moreover several additional information are given for each predicted isoform, such as its length, the cds starting and ending positions, the refseqid  and the length of the associated protein.

pintron source code and binaries are available under the gnu agplv <dig> license at http://www.algolab.eu/pintron.

in the following, we discuss an experimental in-silico analysis on real human data aiming to evaluate our approach. such an experimental evaluation is organized in two parts. the first part has been designed to assess the prediction accuracy of pintron, while the aim of the second part is to show the scalability of our method and its effectiveness on genes that are very large or complex and are currently outside the comfort zone of the most used methods.

we have assessed the accuracy achieved by pintron by comparing it with aspic  <cit>  and exogean  <cit> . in particular, aspic is a well-established software to predict alternative isoforms by multiple est/mrna alignments against the corresponding genomic regions. for each input est, the aspic algorithm attempts to compute a single spliced alignment with the minimum number of exons. instead, pintron implicitly provides several candidate spliced alignments for each est, among which the best one is selected by using the mfa agreement approach, thus allowing a greater accuracy in predicting the putative gene structure. moreover, pintron is much faster than aspic because of the more efficient data structure used for performing the est alignments . for this reason, aspic requires a genomic sequence trimmed at the borders of a single gene locus, while pintron is able to efficiently process a large region of the genome  and a large set of expressed sequences.

exogean is a gene prediction tool based on pre-aligned  ests/mrnas or proteins. exogean resulted one of the most accurate gene finding system in the last egasp competition  <cit> . in exogean, gene structures are reconstructed according to a graph-based strategy mimicking the human annotation process.

the accuracy assessment has been performed on  <dig> encode human regions  <cit>  used as training set in the egasp competition. the regions have been chosen since they present different gene density and different conservation to the mouse genome. this dataset contains  <dig> well-annotated gene loci, supported by  <dig>   <dig> unigene transcripts for a overall length of approximately  <dig> mb . the  <dig> encode regions represent, approximately,  <dig>  mb of the human genomic sequence. supplementary table s. <dig> in additional file  <dig> reports the complete list of the genes used in this experimental evaluation along with some of their main characteristics. ests and mrnas related to each gene were obtained from unigene database.

the results of our first assessment are summarized in table  <dig>  while the details are presented in supplementary tables s. <dig>  s. <dig>  s. <dig> in additional file  <dig>  the three tools have been evaluated according to two dimensions: prediction quality and time efficiency. the first important observation is that only pintron was able to predict the gene structures for all  <dig> encode loci, while aspic and exogean completed  <dig> and  <dig> genes, respectively. moreover, pintron has been the fastest of the three in the experiment over the whole set of genes, producing its results in about  <dig> minutes . on the genes that have been successfully processed, instead, exogean took  <dig> minutes and aspic more than  <dig> hours. such results clearly indicate a computational improvement of pintron over exogean and especially aspic in processing genes that are critical in terms of number of ests. indeed table  <dig> shows that pintron scales much better than exogean and aspic when the number of transcripts is over  <dig> , thus making our new software implementation particularly amenable to analyze large est clusters. notice that the running time of exogean includes the preprocessing time required by blat to align the transcripts. however, the preprocessing time is almost negligible compared to the time required by exogean. in fact, blat required approximately  <dig> minutes  to process all the genes.

the best value of each row is highlighted in boldface.

† exogean did not successfully compute a gene structure for fhit.

prediction quality has been evaluated by calculating sensitivity  and specificity  between encode annotations and predictions at nucleotide, exon, intron, and transcript level, according to burset and guigó  <cit> . we adhered to the nomenclature established in the literature aimed to the evaluation of gene structure prediction tools, even if the definition of specificity that we use here is called positive predictive value in statistical literature  <cit> . as shown in table  <dig> and figure  <dig>  pintron appears the most accurate program at diverse prediction levels. moreover, pintron exhibits sensitivity and specificity levels that are quite similar. this fact, which is highly desirable in any prediction tool, shows that pintron does not advantage any of them to the detriment of the other one. in addition, our results  indicate that pintron improves the reconstruction of exact transcripts when compared with aspic and exogean. moreover, we want to recall that pintron has completed the analysis of all  <dig> input genes, while exogean and aspic did not complete the task for  <dig> and  <dig> genes respectively.

our second experimental analysis is devoted to evaluating the efficiency and the scalability of our approach on a subset of critical human genes that are particularly hard to analyze with the currently available programs because those genes have  a particularly complex gene structure , or  a particularly large cluster of expressed sequences, or  a large genomic sequence.

to this aim, we selected  <dig> "critical" genes and we processed them with pintron and exogean on a 4-node linux cluster running centos  <dig> . each node is equipped with a quad-core  <dig>  ghz cpu and  <dig> gib of ram. the genomic sequence has an average length of about  <dig> kb, and is longer than  <dig> mb for  <dig> of the  <dig> genes. moreover, the selected genes have on average more than  <dig>  transcripts, and  <dig> genes have more than  <dig>  transcripts. the total running time was  <dig> minutes for pintron and  <dig> minutes for exogean. in this evaluation, we did not take into account aspic since it was not able to give a solution for any of these genes within an acceptable time. table  <dig> reports the complete list of genes considered in this experimental part along with their main characteristics and the running times of pintron and exogean. while exogean and pintron running times were both acceptable, pintron averaged  <dig> sec/gene and exogean  <dig> sec/gene. this is remarkable, since exogean is based on the fast progressive est-to-genome mapping program blat and does not take into account potential alignment errors at splicing sites which, in turn, is likely to result in predictions that are not as accurate as those given by pintron. the comparison of running times confirms our previous observation: pintron, although slower than exogean on genes with small transcript clusters, scales significantly better than exogean when the cluster size increases. in fact, pintron was systematically faster than exogean on the subset of genes whose transcript cluster is composed by more than  <dig>   <dig> sequences , while it was slower than exogean on the other genes. in almost all the cases where pintron was slower than exogean, the difference between the running times of the two tools is small. thus the running time of pintron can be considered acceptable also on these genes. one notable exception is gene ttn where pintron took about  <dig> minutes to predict the gene structure, while exogean required only a few seconds. the likely reason is that the input transcript set of ttn contains sequences that are more than  <dig> kb long. since est sequences have a lower quality than mrna sequences, computing their spliced alignment requires a considerable amount of computational resources.

we want to point out that our second experiment has limited scope. in fact a complete comparison of pintron and exogean would also include the accuracy dimensions. the results of the first experiment suggests that pintron is more accurate than exogean. if confirmed, the greater accuracy would justify the small increase in the running times that we have observed.

the analysis of the running times of the first and the second part of the experimentation has not shown any significant correlation between the length of the genes and the running times, hence confirming our conjecture that the behavior of our algorithm depends on some properties of the embedding graph, and not on the size of the instance. in particular, the structure of the embedding graph is strictly related to the quality of the transcripts and to the presence of repetitions and highly duplicated regions in the genomic sequence that, in turn, could influence the size of the graph. also these results have confirmed our beliefs, since the average running time of the second experiment  is not too far from the running times on the smaller genes of the first experiment, where the average value is  <dig> sec/gene. a fundamental observation is that pintron has successfully completed the analysis of all  <dig> "critical" genes, while exogean did not complete the analysis for fhit.

CONCLUSIONS
in this work, we presented a new computational pipeline - pintron - for predicting the gene structure into exons and introns from a cluster of transcript  sequences. pintron combines two ideas: a novel algorithm of proved small time complexity for computing spliced alignments of a transcript against a genome, and an efficient algorithm that exploits the inherent redundancy of information in a cluster of transcripts to select, among all possible factorizations of est sequences, those allowing to infer splice site junctions that are largely confirmed by the input data. pintron is freely available at http://www.algolab.eu/pintron under gnu affero general public licence . the experimental evaluation of pintron has shown that it has been able to compute accurate predictions  while achieving a good scalability to critical genes, especially if associated with a large transcript cluster.

competing interests
the authors declare that they have no competing interests.

authors' contributions
yp and rr designed the algorithm, developed the pipeline, designed and helped to perform the experiments, and drafted the manuscript. ep helped to design and to perform the experiments, and interpreted the results. gp helped to design the experiments and supervised the interpretation of the results. gdv helped to design the algorithm, to develop the pipeline, and to draft the manuscript. pb designed the algorithm, helped to draft the manuscript, and supervised the research. all authors read and approved the final manuscript.

supplementary material
additional file 1
supplementary tables. characteristics of the first dataset and detailed results obtained in the experimental comparison.

click here for file

 acknowledgements
we thank marcello varisco for the implementation of some parts of the pipeline. this research was supported in part by far miur 60% grant "algorithmic methods and combinatorial structures in bioinformatics"  to yp, rr, gdv, and pb, grant "dote ricerca applicata" 21_ara  to yp, and ministero dell'istruzione, dell'università e della ricerca, italy: fondo italiano ricerca di base, "laboratorio internazionale di bioinformatica" , "laboratorio di bioinformatica per la biodiversità molecolare" , prin 2009; progetto strategico regione puglia ps 012; progetto epigen  to gp.

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2012: selected articles from the first ieee international conference on computational advances in bio and medical sciences : bioinformatics. the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/13/s <dig> 
