BACKGROUND
generation of meaningful multiple sequence alignments  of biological sequences is a well-studied np-complete problem, which has significant implications for a wide spectrum of applications  <cit> . in general, the challenge is aligning n sequences of varying lengths by inserting gaps in the sequences so that in the end all sequences have the same length. of particular interest to computational biology are dna/rna sequences and amino acid sequences, which are comprised of nucleotide and amino acid residues, respectively.

msas are generally used in studying phylogeny of organisms, structure prediction, and identifying segments of interest among many other applications in computational biology  <cit> .

given a scoring scheme to evaluate the fitness of an msa, calculating the best msa is an np-complete problem  <cit> . variances in scoring schemes, need for expert-hand analysis in most applications, and many-to-one mapping governing elements-to-functionality  make msa a more challenging problem when considered from a biological context as well  <cit> .

generally, three approaches are used to automate the generation of msas. the first offers a brute-force method of multidimensional dynamic programming  <cit> , which may find a good alignment but is generally computationally expensive and, therefore, unusable beyond a small n. another method uses a probabilistic approach where hidden markov models  are approximated from unaligned sequences. the final method, progressive alignment, is possibly the most commonly used approach when obtaining msas  <cit> .

a progressive alignment algorithm begins with an optimal alignment of two of the n sequences. then, each of the remaining n sequences are aligned to the current msa, either via a consensus sequence or one of the sequences already in the msa. variations on the progressive alignment method include praline  <cit> , probcons  <cit> , mafft  <cit> , muscle  <cit> , t-coffee  <cit> , kalign  <cit> , psalign  <cit> , and the most commonly used clustalw  <cit> . in most cases, the algorithms attempt to generate accurate alignments while minimizing computational time or space. advances in dna sequencing technology with next generation sequencers such as abi's solid and roche's gc flx provide vast amount of data in need of multiple alignment. in case of large sequencing projects, high number of fragments that lead to longer contigs to be combined are generated with much less time and money  <cit> . in addition, as more organisms' genomes are sequenced, approaches that require msa of the same gene in different organisms now find a more populated data set. in both cases computational time in msa is becoming an important issue that needs to be addressed.

this work presents gramalign, a progressive alignment method with improvements in computational time. in particular, the natural grammar inherent in biological sequences is estimated to determine the order in which sequences are progressively merged into the ongoing msa. the following sections describe the algorithm and present initial results as compared with other alignment algorithms.

methods
a general overview of the gramalign algorithm is depicted in figure  <dig>  the set of sequences to be aligned, s, are regarded as input to the algorithm with s = {s <dig> ...,sn}, where si is the ith sequence and i ∈ { <dig> ...,n}.

distance estimation
the first step in the procedure involves the formation of an estimate of the distance between each sequence sm and all other sequences sn ∀ n ≠ m. the distance used in gramalign is based on the natural grammar inherent to all information-containing sequences. unfortunately, the complete grammar for biological sequences is unknown, and so cannot be used when comparing sequences. however, we do know that biological sequences have structures which correspond to functions. this in turn implies that biological sequences which correspond to proteins with similar functions will have similarities in their structure. therefore, we use a grammar based on lempel-ziv  compression  <cit>  used in  <cit>  for phylogeny reconstruction. this measure uses the fact that sequences with similar biological properties share commonalities in their sequence structure. it is also known that biological sequences contain repeats, especially in the regulatory regions  <cit> . when comparing sequences with functional similarity, non-uniform distribution of repeats among the sequences poses a problem to assess sequence similarity. as shown below, the proposed distance naturally handles such cases, which are difficult to be accounted for by alignment or sequence edit based measures.

an overview of the grammar-based distance calculation is shown in figure  <dig> where a dictionary of grammar rules for each sequence is calculated. initially, the dictionary gm <dig> = ∅ is empty, a fragment f <dig> = sm is set to the first residue of the corresponding sequence, and only the first element sm is visible to the algorithm. at the kth iteration of the procedure, the kth residue is appended to the k -  <dig> fragment and the visible sequence is checked. if fk ∉ sm then fk is considered a new rule, and so added to the dictionary gmk=gmk−1∪{fk}, and the fragment is reset, fk = ∅. however, if fk ∈ sm , then the current dictionary contains enough rules to produce the current fragment, i.e., gmk=gmk− <dig>  in either case, the iteration completes by appending the kth residue to the visible sequence. this procedure continues until the visible sequence is equal to the entire sequence, at which time the size of the dictionary is recorded along the diagonal of the grammar elements matrix, em, m = |gm|. as will be shown, calculating the distance between sequences requires only the number of entries in the dictionary.

in the next step shown in figure  <dig>  each sequence is compared with all other sequences. in particular, consider the process of comparing sequences m and n. initially, the dictionary gm,n <dig> = gm is set to that of sequence m, a fragment f <dig> = sn is set to the first residue of the nth sequence, and the visible sequence is all of sm. the algorithm operates as described previously, resulting in a new dictionary size em, n = |gm,n|. when complete, more grammatically-similar sequences will have a new dictionary size with fewer entries as compared to sequences that are less grammatically-similar. therefore, the size of the new dictionary em,n will be close to the size of the original dictionary em,m.

in the final step, the distance between the sequences is estimated using the dictionary sizes. five different distance measures were suggested in  <cit> . this work used the distance measure

  dm,n=em,n−em,m+en,m−en,nem,n+en,m <dig>  

where m, n ∈ { <dig> ...,n} are indices of two sequences being compared. this particular metric accounts for differences in sequence lengths, and normalizes accordingly. thus, the final distance matrix d is composed of grammar-based distance entries given by . smaller entries in d indicate a stronger similarity, at least in terms of the lz-based grammar estimate. intuitively, sequences with a similar grammar should be pairwise aligned with each other in order for progressive combining into an msa.

to further improve the execution time, d is only partially calculated as follows. an initial sequence is selected and compared with all other sequences. the resulting distances are split evenly into two groups based on d, one containing the smallest distances, and the other containing the largest distances. the process is repeated recursively on each group until the number of sequences in a group is two. the benefit is that only n log distances need to be calculated. the validity of only calculating these sets of distances stems from the transitivity of the lz grammars being inferred. that is, if the grammar-based distances di, j and dj, k are small, it is likely that di, k is also small. by recursively dividing groups of extreme distances, only those distances which would likely be used in the spanning-tree creation process will actually be calculated.

sequence alphabet
the distance between sequences m and n as determined by  is based on how many additional rules need to be added to each grammar in order to generate both sm and sn. because the real grammars are unknown, gm and gn are approximated by scanning the only observations available . the grammar approximation improves as the length of the observed sequences increases. and so, the distance calculations are a function of sequence lengths, becoming more accurate as the sequences increase in length. in practice, this calculation works well for dna sequences, even of shorter lengths, because the approximated grammar of a dna sequence can only contain rules involving words composed of combinations of elements from the alphabet {'a','c','g','t'}. this small alphabet allows for a rapid generation of a reasonable grammar since there are a relatively small number of permutations of letters. from a grammar perspective, amino acid sequences are generally much more difficult to process correctly using . the reason being the alphabet contains  <dig> letters, where each element is not equally different from all other elements. due to the relatively large alphabet size, much longer sequences are necessary to generate a reasonable grammar approximation. thus, the accuracy of distances calculated for sets of short amino acid sequences are diminished. additionally, consider the substitution scores of 'l' and 'm' as taken from the gonnet <dig> and blosum <dig> substitution matrices in figure  <dig>  notice in  and , that 'l' receives a relatively high positive value when aligned with any of {'i','l','m','v'}. similarly, in  and , 'm' receives a relatively high positive value when aligned with any of the same set. additionally, both 'l' and 'm' generally receive high negative values when compared to letters other than {'i','l','m','v'}. when taking this type of scoring into account, the elements 'l' and 'm' could be considered the same letter in a grammatical sense.

thus, gramalign offers the option to use a "merged amino acid alphabet" when calculating the distance matrix. the merged alphabet contains  <dig> elements corresponding to the  <dig> amino acid letters grouped into the sets {'a','s','t','x'}, {'b','d','n'}, {'c'}, {'e','k','q','r','z'}, {'f'}, {'g'}, {'h'}, {'i','l','m','v'}, {'p'}, {'w'}, and {'y'}. these groupings were determined by considering all  <dig> rows of the blosum <dig>  blosum <dig>  blosum <dig> and gonnet <dig> substitution matrices, and only grouping elements that had a strong similarity across the entire row in all four matrices. the merged alphabet has the benefit of containing fewer elements allowing for more accurate distance estimates based upon shorter observed sequences. also, the resultant merged-alphabet substitution matrices are more consistent in that a merged-letter score is high only when compared to itself. in practice, the average alignment scores increased when aligning the same data sets using the merged alphabet within the distance calculation, as compared to using the actual alphabet . in either case, once the distances have been calculated, a tree based on these distances is used to determine which sequences should be pairwise aligned.

tree construction
the next step in the algorithm consists of constructing a minimal spanning tree t based on the distance matrix d. in particular, consider a completely connected graph of n vertices and n <dig> edges, where the weight of an edge between vertices i and j is given by the th element of the distance matrix, di, j. this work uses prim's algorithm  <cit>  to determine a minimal spanning tree t which may be used as a guide in determining the order for progressively aligning the set of sequences s.

align sequences
the minimal spanning tree t along with the set of sequences s, are processed by the "align sequences" block in figure  <dig>  this block is presented in more detail in figure  <dig>  the first two sequences from s to be aligned are given by t as the root sequence of t and the nearest sequence in terms of the lz grammar distance. at the conclusion of the pairwise alignment process, the resulting alignment is stored in an ensemble of sequences.

in the following we describe the pairwise alignment procedure, the scoring system and the method for progressive alignment.

dynamic programming
at the core of most progressive msa algorithms is some method for performing pairwise alignments between two sequences. this work uses a version of the  <cit>  dynamic programming algorithm with affine gap scores as discussed in  <cit>  to generate each pairwise alignment.

scoring system
a significant ambiguity regarding the dynamic programming procedure is the scoring function used when comparing two elements, or when comparing an element with a gap.

typically, the pairwise scoring function c() is simply a matrix of values, where each column and row represent one element in the alphabet. in this way, each cell of the matrix corresponds to some measure representing the likelihood that two sequence elements should be aligned with each other. the most well-known amino acid scoring matrices are the percent accepted mutation   <cit> , block substitution matrix   <cit>  and gonnet  <cit> . gramalign defaults to the gonnet <dig> substitution matrix for the scoring function c(), as other progressive alignment algorithms generally use it as the default choice .

determining the best gap-open and gap-extension penalties is a challenging problem, made more difficult by introducing two different penalties to account for the beginning and ending tail gaps of alignments. the default gap penalties used by gramalign have been adjusted to perform well based on the alignment sets presented in the results section.

progressive alignment
the ensemble is implemented as a doubly-linked list, where each node of the list represents a single column of the alignment. each node of the ensemble contains an array of letters corresponding to the respective column alignment, a tally of gaps in the column, a weighted combination of substitution scores, and two gap penalties. once the initial ensemble a is constructed between the first two entries in t, the remaining sequences need to be added to the ensemble in the order defined by t. this is accomplished by checking t for the next sequence not already in the ensemble, call it sequence sj where j corresponds to the order in which the sequence was added to t; that is, j is the priority of the sequence. to progressively add sj to the alignment, a pairwise alignment between the ensemble a and sj is created via the afore mentioned dynamic programming algorithm. while the algorithm used is a pairwise alignment algorithm the distance calculated at each step of the pairwise alignment is an average of the distances between the particular position being aligned in the new sequence and the corresponding amino acides or bases in the ensemble at that node. the new pairwise alignment is merged into the ongoing ensemble based on the trace-back. the process continues until all sequences have been added to the ensemble of sequences. when sequence sj is added to the current ensemble a, each node is updated to reflect the new column element.

gap adjustment
once all n sequences have been progressively aligned, the final post-processing block in figure  <dig>  "adjust msa gaps", is used to cluster gaps together. the adjustment is further detailed in figure  <dig>  where the ensemble a is scanned so a histogram h of gaps-per-column is generated.

the histogram h is scanned using an equidistant, user-adjustable sliding window about each column. for each column, when the number of gaps is greater than a user-adjustable threshold percentage of gaps-per-column, the following steps are taken. for each row in the column under consideration:

 <dig>  if the current row has a gap, move to the next row;

 <dig>  otherwise, scan the current row of the neighboring columns within the window, beginning with the nearest columns and work outward;

 <dig>  if a neighboring column has a gap in the current row and the neighboring column has fewer total gaps than the center column, shift the gap from the neighboring column into the column under consideration.

as an illustration, consider a portion of the ensemble

 a:{…x <dig> i−2x <dig> i−1− <dig> ix <dig> i+1x <dig> i+2……x <dig> i−2− <dig> i−1− <dig> i− <dig> i+1x <dig> i+2……x <dig> i−2− <dig> i−1− <dig> i− <dig> i+1x <dig> i+2……− <dig> i−2x <dig> i−1x <dig> i− <dig> i+1x <dig> i+2……x <dig> i−2x <dig> i−1x <dig> i− <dig> i+1x <dig> i+2… 

where xm, n represents any element other than a gap in column n of sequence m, and -m, n represents a gap in column n of sequence m. and so, the gap histogram for this section of ensemble is h = {..., <dig>   <dig>   <dig>   <dig>   <dig> ...}. assuming the gap threshold is  <dig> , then only columns with more than two gaps will be considered for adjustment. in the example, h is scanned until column i is identified as having three gaps. following the procedure, each row in column i is checked until a non-gap entry is found. in the example, the first non-gap entry x <dig>  i is in row four. assuming the gap window is  <dig>  elements in the fourth row of the neighboring columns are checked for gap entries. in particular, column  is checked first, with a gap entry - <dig>  i+ <dig>  however, no shift occurs because a quick check of h shows that column  has more gaps than column i. continuing the scan, columns  and  are checked before another gap is found in column . in this case, h indicates column  has fewer gaps compared to column i, and so a blind shift of entries between  and i occurs, resulting in the ensemble

 a:{…x <dig> i−2x <dig> i−1− <dig> ix <dig> i+1x <dig> i+2……x <dig> i−2− <dig> i−1− <dig> i− <dig> i+1x <dig> i+2……x <dig> i−2− <dig> i−1− <dig> i− <dig> i+1x <dig> i+2……x <dig> i−2x <dig> i− <dig> i−2− <dig> i+1x <dig> i+2……x <dig> i−2x <dig> i−1x <dig> i− <dig> i+1x <dig> i+2… 

where original indices are kept to depict which entries are shifted into which locations.

the result is a blind movement of sparse gaps into dense regions of gaps. numeric simulations have shown this post-processing stage does not affect alignment scoring based upon the method used in the results and discussion section . and so, the user-defined parameters are set to a threshold of  <dig>  and a window of  <dig> columns by default thereby disabling the gap adjustment block. should it be known there are conserved regions of gaps, the user may decide to enable this process to encourage gap grouping.

algorithm complexity
the algorithm complexity of gramalign may be broken into five pieces, beginning with the generation of each sequence grammar dictionary, gi for i ∈ { <dig> ...,n}, where n is the number of sequences. suppose the average sequence length is l, then each gi results in complexity o, so all dictionaries are generated with complexity o. next, the distance matrix d is formed by recursively extending a grammar by all other sequences within it's neighborhood, each of which results in complexity o, then splitting the neighborhood into two halves, resulting in a complexity o). the spanning tree t is constructed by searching over d with a complexity of o. the tree is used as a map in determining the order in which to perform n -  <dig> pairwise alignments, each requiring a complexity of o. thus, the progressive alignment process takes o. the alignment ensemble is scanned and has gaps shifted in o time. thus, the entire time complexity for gramalign is o + n <dig> + l2n + ln), which simplifies to o.

RESULTS
in this section, example alignments are used to study the possible advantages of gramalign. all results were generated by compiling and executing the respective msa programs on the same computer; specifically, an apple ibook with a powerpc g <dig> operating at  <dig>  ghz with  <dig>  gb system memory and  <dig> kb l <dig> cache. two sets of experiments were conducted. the first set of experiments were conducted using the unaligned fasta files from the balibase  <dig>   <cit>  data-set, a well-accepted benchmark database containing example amino acid sequences. the resulting aligned fasta files from each algorithm were scored using bali score, a program provided with the balibase distribution that generates a sum-of-pairs  score and a total-column  score based on predetermined reference alignments. the size of the sequences in the balibase distribution are relatively small and, therefore, not very useful in demonstrating the advantages to be obtained using a fast algorithm. the second set of experiments were conducted using sequences generated by rose version  <dig>  to demonstrate algorithms' capabilities on large data sets containing either long or numerous sequences. rose is a software tool that implements a probabilistic model of sequence evolution, so that a user is able to generate families of related sequences from a common ancestor sequence via insertion, deletion and substitution  <cit> . rose allows for many parameter adjustments including rate of mutation, desired average final sequence length and number of desired sequences. the tool outputs the unaligned sequences, as well as the real alignment based on how mutations occur, and an evolutionary tree. the set of sequences generated by rose were based on the default seed file provided with the rose software distribution, where the seed file is the method used to input parameters to rose.

note the use of simulated data here is to demonstrate the speed advantage of gramalign, while maintaining a similar qualitative score. the default values were used to generate the data and the algorithms were not tuned to the data. the use of simulated data may actually provide a biased advantage in quality score to any given alignment program, depending on how the simulated data is generated. a wider breadth of simulated data, such as was done in  <cit> , would provide a better assessment of overall alignment quality.

balibase experiments
alignment files in the balibase database are separated into five categories , each exhibiting different classes of alignment issues . the first class is further divided into two subcategories labeled rv <dig> and rv <dig>  the results presented in table  <dig> and table  <dig> respectively detail the average sp and tc scores over each category as aligned by gramalign version  <dig>  , clustalw version  <dig> , t-coffee version  <dig> , psalign using probcons as the tree generation , kalign version  <dig> , mafft version  <dig> , and muscle version  <dig> . additionally, a fast version was tested for clustalw, mafft, muscle and mafft version  <dig> . in particular, the command line options used were clustalw -quicktree, mafft --retree  <dig>  muscle -maxiters  <dig> -diags -sv -distance <dig> kbit20_ <dig> and mafft --retree  <dig> --parttree --partsize  <dig> to incorporate high-speed progressive options. in all cases the default parameters were used for each program. in general, there are no significant differences in the performance of gramalign and other algorithms as far as the sp and tc scores are concerned. as may be seen, gramalign provides similar alignments in terms of the quality determined via the scoring method used.

average sp score for each algorithm for each category offered by the balibase test suite. the bold entries indicate the lowest and highest scores.

average tc score for each algorithm for each category offered by the balibase test suite. the bold entries indicate the lowest and highest scores.

presented in table  <dig> are the execution times necessary to generate the entire data presented in table  <dig> and table  <dig>  gramalign finishes in approximately  <dig> % of the time needed by psalign, which generated the highest scoring alignments in five out of the six balibase categories as far as sp scores are concerned. psalign's average sp and tc score on the other hand were  <dig>  and  <dig> % better than gramalign's scores, which was approximately  <dig> times faster. out of the four approaches mafft, mafft v <dig>  mafft , muscle , which were  <dig> ,  <dig> ,  <dig> , and  <dig> % faster than gramalign, respectively, only mafft had a 2% better average sp score than gramalign. all other average sp and tc scores were equivalent or worse than that of gramalign. further, the gramalign alignments scored equal-to or greater-than  <dig> ,  <dig> ,  <dig> , and  <dig> % of the trials based on tc score, compared to mafft, mafft v <dig>  mafft , and muscle  . gramalign finishes in 33% of the time required by clustalw using -quicktree, and only 8% needed by clustalw, possibly the most widely used msa program.

execution time necessary to align all trials in the balibase test suite.

experiments with large data sets
long sequence experiments
in order to compare the performance of msa algorithms on long data sets, two sets of seven fasta files each containing ten sequences were generated using rose version  <dig> . the first set of seven fasta files contains protein sequences and the second set contains dna sequences. in both sets, the first file contains sequences with an average length of  <dig>  residues, with each file increasing the average sequence length by  <dig>  residues. thus, the seventh file contains ten sequences with an average sequence length of  <dig>  residues.

figures  <dig> and  <dig> depict the execution time required for the fastest algorithms to align the seven large protein and dna sequence sets, respectively. as the average length of sequences increases, the difference in time required by gramalign compared to the other algorithms also increases. in particular, at an average sequence length of  <dig>  residues gramalign completes the alignments in  <dig>  and  <dig>  seconds, while the nearest algorithm  requires  <dig>  and  <dig>  seconds. that is, gramalign finishes in 32% and 44% of the time required by the next fastest algorithm.

muscle in fast mode encountered a segmentation fault during the root alignment step while running on the longest test sequences, and so the execution time is not included in figures  <dig> and  <dig> 

numerous sequence experiments
in order to compare the performance of msa algorithms on data sets with many sequences, two sets of seven fasta files each containing sequences with an average length of  <dig> residues were generated using rose version  <dig> . the first set of seven fasta files contains protein sequences and the second set contains dna sequences. in both sets, the first file contains  <dig> sequences, with each file increasing the number of sequences up to the seventh file, which contains  <dig>  sequences.

as shown in  <cit> , the authors of mafft added a new heuristic method for generating a spanning tree referred to as "parttree". the increase in performance is dramatic and intended for data sets involving many sequences. thus, for this set of experiments, mafft version  <dig>  was added with the command line mafft --retree  <dig> --parttree --partsize  <dig>  which matches the fastest algorithm presented in  <cit> . figures  <dig> and  <dig> depict the execution time required for the fastest algorithms to align the seven large protein and dna sequence sets, respectively. as the number of sequences increases, the difference in time required by gramalign and mafft v <dig> compared to the other algorithms also increases. in particular, on the sets containing  <dig>  protein and dna sequences gramalign completes the alignments in  <dig> and  <dig> seconds and mafft v <dig> completes the alignments in  <dig> and  <dig> seconds, while the next closest algorithm, muscle in fast-mode, requires  <dig> and  <dig> seconds. that is, gramalign finishes in 26% and 15% of the time required by the next fastest algorithm other than mafft v <dig> 

the results imply the promising viability of the proposed algorithm, especially when aligning either long or numerous sequences such as in whole-genome applications. further, better alignment scores may be achieved with little change in execution time via the user-alterable parameters.

CONCLUSIONS
the primary goal of this work was to introduce a computationally-efficient progressive alignment algorithm which can be used for aligning large data sets. the grammar-based distance work presented in  <cit>  was adapted to generate an estimation of the proper order in which sequences are to be aligned. additionally, a merged amino acid alphabet was determined to allow an improved grammar-based distance when operating on protein sequences. results from extensive alignments were presented in an attempt to study the overall quality of the resultant alignments as well as the computation time necessary to achieve the alignments. correctly aligning multiple biological sequences in an efficient amount of time is an important and challenging problem with a wide spectrum of applications. in this work, we adapt existing ideas in a novel way introducing innovative improvements. the proposed algorithm achieves reasonable alignments compared to existing methods while significantly reducing execution time. future work will focus on determining the best set of user-defined parameters for generating the highest overall sp and tc scores.

availability
the current version of gramalign may be run on-line, or the source code may be downloaded from the web server .

authors' contributions
djr thought of applying the natural transitivity of the lz grammars to the recursive division of the distance matrix, implemented the entire algorithm, performed all evaluations and drafted the initial manuscript. hho conceived the idea of using an lz grammar for progressive alignment. ks collaborated with hho and djr in the development of the algorithm and preparing the final manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
an archive of the source code for the version of gramalign at the time of publishing. an executable may be generated by unzipping this file and using an ansi c compiler to build the code.

click here for file

 acknowledgements
we would like to thank the national institutes of health  for partial funding of this work. we would also like to thank the editor and anonymous referees for their insightful comments. ks thanks nih for support under grant k25ai <dig> 
