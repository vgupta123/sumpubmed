BACKGROUND
one common goal of a genome wide association  study is to search the entire genome for single nucleotide polymorphisms  and copy number variations  associated with a disease or some other phenotype. in this article, we focus our analysis on snps. the two possible alleles at a snp are arbitrarily labeled a and b, and association is often tested by measuring and comparing the frequencies of the genotypes aa, ab, and bb, in case and control groups. as technology currently allows close to one million snps to be examined simultaneously, there is a need for fast, automated methods to test for association. as only a small minority of snps are expected to be associated with the disease, even a modest false positive rate could bury true associations beneath those occurring by chance.

using affymetrix  <dig> k genechips as an example, each of the  <dig> + snps is represented by a series of probes on a pair of arrays. each probe is an oligonucleotide designed to bind to either the a or b allele. a subject's fluorescently labeled dna is allowed to hybridize with these probes, and then a spectrometer measures the relative fluorescent levels between the a and b probes. each genotyping algorithm  summarizes the fluorescence information, or the likelihood a subject has allele a at that snp, by its own statistic. in any population, these statistics usually cluster into three groups, corresponding to the three genotypes. studies have noted that 1) the mean and variance of these clusters, or the shape of their distribution in general, varies by snp and 2) for a single snp, because of differences in processing or duration of storage, the shape of the statistic's distribution can differ between the case and control groups  <cit> .

the current test of association requires calling, or assigning a genotype, to each snp for each study subject and then comparing the called genotypes between the case and control groups. the majority of snps are easy to call and any of the available methods will call them correctly. unfortunately, there is a difficult minority that cannot be easily clustered into three distinct groups. because there can be as many as  <dig>  snps, this minority can greatly inflate the type i error rate and cause the large, characteristic, deviations from the x = y line in the qq-plots of test statistics. most studies assume these consequences are the unavoidable results of population substructure and poor data. in this paper, we dispel the myth that these are the sole issues. in fact, the inflated type i error rate and general misbehavior of the test statistic may also result from the act of genotype assignment and a poor choice of statistical methodology.

the goal of this manuscript is two-fold. first, our primary goal is to show that genotyping overlapping clusters can lead to potential problems that we have yet to see fully acknowledged in the literature. the proportions of each called genotype need not equal their true proportions in the population, even as the number of subjects grows infinitely large. as we compare genotype calls, p-values from tests of association will be anti-conservative when the distribution of the summary statistic differs between cases and controls. moreover, the called genotypes for two subjects need not be independent, even when their true genotypes are independent. therefore, p-values from tests of association can be anti-conservative, even when the distributions of the summary statistic for the cases and controls are identical, a fact we believe has yet to be fully demonstrated. although previous studies have examined the effects of genotyping error on tests of association  <cit> , studies has neither fully explored the effects caused by case/control differences in distributions nor dependence of error. second, we discuss two new tests that can circumvent these potential problems. one test compares calls made from a genotyping algorithm designed to minimize the type i error. the second test compares the fluorescence distributions, instead of the called genotypes. we start the methods section by discussing currently available methods for genotyping snps and testing for association. concurrently, we introduce logicall, our new genotyping algorithm, and the likelihood ratio-based test of association. in the results and discussion section, we start by showing that the proportion of genotypes called aa, ab, and bb need not converge to the true population proportions. then we discuss how the called genotypes can be dependent. we conclude the section by comparing the proposed tests of association with the current standards through both simulation studies and real data analysis. then a short conclusions section summarizes the key points.

methods
calling genotypes
there is currently a wide variety of programs available for genotyping snps. the most popular supporting affymetrix are rlmm  <cit> , brlmm  <cit> , crlmm  <cit> , chiamo  <cit> , sniper-hd  <cit> , and mams  <cit> . the most popular program for illumina is their own proprietary software, beadstudio, but other methods have been recently suggested by moorhead et. al.  <cit> , teo et. al.  <cit> , and dunning et. al.  <cit>  . to introduce these methods, we start by defining notation. let there be n subjects. let gij ∈ {aa, ab, bb} be the true genotype of snp j in subject i,  <dig> ≤ i ≤ n. for affymetrix chips, assume there are np probe quartets representing each snp on an array, and let i→ijk≡{ipmaijk,immaijk,ipmbijk,immbijk} be the normalized probe intensities for subject i, snp j, and probe k. here, the subscripts pma and mma signify the perfect match and mismatch probes for allele a. pmb and mmb are similarly defined for allele b. the log transformed intensities will be y→ijk=log <dig>  to maintain notational consistency, for illumina chips, we denote the beadstudio intensity values of the two snp alleles by {ipmaij,ipmbij}. as we will only discuss a single snp for the majority of the paper, we will omit the superscript "j" from all future notation.

1indicates use of mismatched probes

2parameters were estimated by experimental or training data. for experimental data, under the null, cases and control genotype proportions could be linked or unlinked. * indicates optional.

3distance can be mahalanobis, w eighted likelihood, or unweighted likelihood

with the exception of dynamic modeling   <cit> , all calling algorithms share the same general form, and we exploit this form to summarize their key features. the process of transforming raw signal into genotypes can be divided into four steps: 1) normalize the intensity values; 2) describe the normalized intensity values by a single, possibly multivariate, summary statistic; 3) estimate the mean and variance of the summary statistic for the three possible genotypes, aa, ab, and bb; and 4) compare the value of the statistic from a subject to the group parameters found in the third step to make the call. the universal first step, normalizing the intensity values, is tangential to our discussion here. the second step is to choose a statistic, si that summarizes the intensities. for example, rlmm models the probe intensities as ypmaik=ζai+βak+εaik and ypmbik=ζbi+βbk+εbik. then, si≡{ζai,ζbi}. in the updated version, crlmm models sense and antisense probes separately, resulting in a 4d statistic, si≡{ζa+i,ζa−i,ζb+i,ζb−i} each method assumes that the distribution, φm, of their statistic in a given population q is a mixture of multivariate normal distributions where θ, to be defined below, are the parameters characterizing the distribution in population q. when it is clear we are discussing only a single population, we will omit the superscript q. although problems can arise when the distribution is not a true mixture of normals, those complications are beyond the scope of this paper  <cit> . for completeness, we point out that a minority of programs, including crlmm, allow these parameters to vary within a group . ignoring that some methods allow for an additional null distribution, the general form is

  ϕm=paaϕ+pabϕ+pbbϕ 

where ψ is the multivariate normal density. the three mean vectors, μ≡{μ→aa,μ→ab,μ→bb}, variance matrices, Σ ≡ {Σaa, Σab, Σbb}, and probabilities, p ≡ {paa, pab, pbb}, correspond to the three possible genotypes, aa, ab, and bb. define θ≡{μ→,Σ,p→} and later, we let Φ and Φm be the cumulative distribution for a normal variable and a mixture of normals. the third step is to estimate θ. some algorithms, such as rlmm, use a training data set, where the genotypes are known. other algorithms, such as sniper-hd, use no training data, and find the best estimates that describe their experimental values. the fourth step is to assign a genotype, gˆij, to snp j in subject i. often, for a given value of si, the assigned genotype maximizes a similarity function: gˆi = argmaxg d. the similarity function is usually a modified version of one of the following three quantities: mahalanobis distance: −Σg−1t, unweighted likelihood: ϕ, or the weighted likelihood: pgϕ. the similarity function is also modified to ensure monotonicity of assignment. when we let si = {mi, ai}, we force d = d =  <dig> if mi ≤ μaa, d =  <dig> if μaa ≤ mi ≤ μab, d =  <dig> if μab ≤ mi ≤ · μbb, and d = d =  <dig> if mi ≥ μbb, where μg, in this case, is the mean of mi when gi = g. this modification is standard in calling algorithms. as we do not know the true value of the parameters in experiments, we replace d by d. a subject's snp may not be called, or assigned a missing value, if the difference or ratio between d and d is not large enough, where g2iis the genotype with the second largest value of d. a snp may be omitted from further study if too many values were set to missing. table  <dig> describes the details of the four steps for popular methods. for many purposes or to understand the details of the method, especially in handling rare alleles, this table will seem an oversimplification. for our purposes here, it highlights the features of interest.

tests of association
the current tests of association start by calling genotypes for a given snp j in a group of subjects with the disease and in a group of controls. they then compare the resulting proportions, pˆa≡{pˆaaa,pˆaba,pˆbba} and pˆu≡{pˆaau,pˆabu,pˆbbu}, from these affected and unaffected groups using either a cochran-armitage test or logistic regression. here pˆgq≡1nq∑i:qi=q <dig>  where the indicator function is defined by  <dig> =  <dig> if x is true,  <dig> otherwise, qi ∈ {a, u} is the disease status for individual i, and nq is the number of subjects with disease status q. in this manuscript, any 'p-value' from a genotype-based association test will be calculated using anova on the logistic regression model with qi and genotype  as the dependent and independent variables.

standard tests tend to err anti-conservatively as we will discuss below. we will propose four alterations that can reduce type i error rate, with only a minimal decrease in power. these are the four differences that separate logicall from standard methods. the first is based on the observation, which is discussed later, that the likelihood profile of φm will have multiple local maxima near the overall maximum. when estimating θ, the em algorithm converges to multiple solutions. for many of those solutions, the resulting parameter set, θˆlm, satisfies ∏iϕm≤∏iϕm+τn. for each parameter set satisfying this inequality, we will make a new group of genotype assignments, {gˆilm}. if more than 10% of such assignments disagree with gˆi , we label that subject's call as questionable. we also continue the practice of marking calls with small values of d/d as questionable. the second alteration is that we do not discard questionable calls, an act which can create false positives. instead, we assign questionable si so the proportions of genotypes in the cases and controls are as similar as possible, which is defined as minimizing ∑g|pˆgu−pˆga|, with the restriction that the final call for subject i must be either gˆi or g2i. here, we let g2i be the genotype which is either the runner-up in terms of distance or the most common genotype among the dissenting calls, depending on why the genotype was labeled as questionable. the third alteration, which is already incorporated into other programs is to perform the em algorithm under the null hypothesis that the genotype proportions in the two populations are identical  <cit> . the fourth is the use of a weighted mahalonobis distance, which is defined later. given these changes, logicall then compares the estimated genotype proportions in cases and controls using logistic regression. note that none of the changes affect calls for the vast majority of snps.

we also introduce a completely new method for testing association based on a likelihood ratio statistic. for our method, steps  <dig> and  <dig>  normalization and choice of summary statistic, can mimic any of the previously described methods. as our real data to be analyzed was collected on illumina chips, we choose the statistic from moorhead, et al.  <cit> , s=1sinhsinh for exposition. we then assume that si follows the mixture model described by equation , but allow the parameters to differ by disease status:

  ϕaum≡{ϕm,qi=aϕm,qi=u 

and θ = {θa, θu}, where

 θa={paaa,μaaa,σaa2a,paba,μaba,σab2a,pbba,μbba,σbb2a}θu={paau,μaau,σaa2u,pabu,μabu,σab2u,pbbu,μbbu,σbb2u} 

although θ contains  <dig> parameters, it has only  <dig> degrees of freedom  because paaq+pabq+pbbq= <dig> for q ∈ {a, u}. our new test will reject the null hypothesis of no association, when lr, the likelihood ratio, is large, where

  lr=maxθˆr∈Ωr∏ϕaum) 

clearly, the restricted parameter space, {Ωr:paaa,paau,paba=pabu,pbba=pbbu} is a subset of the unrestricted parameter space, Ω. in an ideal scenario, the distribution of 2log would converge to a chi-squared distribution, fχ <dig>  with  <dig> degrees of freedom. therefore, the 'p-value' from a likelihood ratio-based test will be calculated as  <dig> - fχ22).

data source
to demonstrate the problems of genotyping and compare the genotype- and likelihood ratio-based tests of association, we use three types of data. first, for discussion, we may assume a hypothetical study measuring a one dimensional summary statistic, si, for a snp j with only two possible genotypes, gi ∈ { <dig>  1}. furthermore, to show problems can exist even under the best conditions, where model and truth coincide, we assume that si follows a normal distribution given qi and gij, and that the full distribution can be described by ϕm=p0ϕ+p1ϕ.

we compare our two new tests of association to a standard method using simulated data. the standard method mimics the general bead-studio approach by a) fitting parameters with the em algorithm; b) calling genotypes based on the mahalanobis distance; c) removing all calls where d/d >  <dig> ; and d) comparing the two sets of resulting estimates, {pˆaaa,pˆaba,pˆbba} and {pˆaau,pˆabu,pˆbbu}. we generated  <dig> simulated datasets, containing  <dig> subjects  and  <dig>  snps for each of  <dig> scenarios. for each gene j and each subject i, we generated a 2d summary statistic . the distribution of mji depended on genotype. if gji = aa, then mji ~ 2x -  <dig>  and if gji = bb, then mji ~ <dig> - 2x, where x ~ beta. if gji = ab, then mji also followed a beta distribution, but the parameters varied by snp, disease status, and scenario. for all snps and all subjects, aji ~ n . we generated three types of snps, background, shifted, and influential. first,  <dig>  background snps were generated and included in all  <dig> ×  <dig> =  <dig> data sets. for each snp, a single minor allele frequency was generated from a uniform distribution and genotype probabilities  were generated assuming hardy-weinberg equilibrium. here, e  =  <dig> and was independent of disease status. these snps, which formed three distinct clusters, can be easily identified and represent a well-behaved group. for  <dig>  shifted snps, maf ~uniform and genotype probabilities  were generated assuming hardy-weinberg equilibrium. here, e  ∈ {- <dig>  +  <dig> , -  <dig>  +  <dig>  -  <dig>  +  <dig> }, where we note e  = - <dig>  and e  - e  ∈ { <dig>   <dig> }. this group represents difficult to call snps. for  <dig> influential snps, maf ~uniform and genotype probabilities  were chosen so that, under a disease prevalence of  <dig>  and a model of additive effects, the genotype relative risk for subjects homogeneous for the minor allele, p/p  ∈ { <dig> ,  <dig> ,  <dig> }. combing the degree of shift for poor quality snps and the effect size of truly associated snps, we have a total of  <dig> scenarios used in our simulation.

the next set of data is from a recent gwas of inflammatory bowel disease  that compared  <dig> subjects with ibd to  <dig> subjects without the disease. using illumina microarrays,  <dig>  snps on the autosomal chromosomes were tested. jewish and non-jewish cohorts, approximately equal in size, were analyzed separately, a practice continued here. details have been previously published  <cit> . because the overwhelming majority of the snps are easy to genotype, as any of the summary statistics neatly divide into three clusters, we chose a  <dig> difficult snp subset where at least two clusters overlap . because association was tested separately in jewish and non-jewish cohorts, a total of  <dig> ×  <dig> =  <dig> tests were possible. to demonstrate called genotype dependency, we bootstrapped  <dig> samples, ignoring case/control status, of  <dig> subjects for each snp. a sample would be discarded, and replaced by another random selection, if one or both of the groups were lacking an aa  or a bb  genotype.

we defined difficult snps as follows. for snp j, we first estimated the density, fˆ nonparametrically using the r function 'density'. in theory, fˆ is a mixture of three normal distributions, corresponding to the three genotypes. if the snp is well-behaved, then the three underlying densities will not overlap, and the empirical density fˆ will attain minima near  <dig> in the valleys between μjaa and μjab and between μjab and μjbb. if either of these minima exceeded  <dig> , then at least two of underlying densities overlapped, and that snp was defined as difficult. to speed the process, we found that approximating the center of the peaks  by the median values of mj. in the three windows, {mj. ≤ - <dig> ; - <dig>  ≤ mj. ≤  <dig> , mj. ≥  <dig> }, worked well.

RESULTS
two genotype example: parameters
we choose to use the hypothetical, two-genotype, study, to highlight that the estimated parameters can be inconsistent even in the simplest scenario, where the summary statistic is distributed normally and our fitted model is correct. when dealing with only a single population, we define the parameter p <dig>  to be the probability that a subject's true genotype is  <dig> .

  p <dig> ≡ p  and p <dig> ≡ p 

we define the parameter p0n* to be the probability that a subject's called genotype is  <dig> .

  p0n*≡p and p1n*≡p 

probabilities of called genotypes implicitly depend on the number of subjects in the sample. we then define the parameter c* to be the point which is equidistant to the two genotype groups when θ is known.

therefore, μ <dig> ≤ c* ≤ μ <dig> is defined to be a solution to equation 6

  d = d 

for the remainder of the paper, we shall assume such a c* exists. this assumption is safe in practice as genes with extremely rare minor alleles are discarded. when d is the mahalanobis distance, c* is a solution to

  2σ02=2σ <dig> 

we define the final parameter, p0*, to be the probability that a subject's si value is less than c* given their true genotype is  <dig> .

  p0*≡pp1*≡p 

our first goal in this results section is to show that

  p0*≠p <dig> 

may be true when two clusters, {si:gi = 0} and {si:gi = 1} overlap. we will refer to p0* - p <dig> as asymptotic bias, or bias, and we note that it depends on d, p <dig>  and the magnitude of the overlap. here, we also define c, our estimate for c*, to be the solution to the equation

  d=d 

such that μˆ0≤c≤μˆ <dig>  if no such c exists, to be consistent with monotonicity of assignment, we let c=μˆg where d is the smaller of the two measures when μˆ0≤si≤μˆ <dig>  the variable c is the cut-point or threshold value of s which separates  <dig> and  <dig> calls. therefore, by monotonicity of assignment, si <c ⇒ gˆi =  <dig> and si > c ⇒ gˆi =  <dig>  if si = c, we assign the genotype randomly. in the specific example of the mahalanobis distance, c is usually the solution to

  2σˆ02mle=2σˆ12mle 

therefore, by convergence of the mle, we know that

  limn → ∞ c →p c* 

which will useful for the next section.

two genotype example: p0*≠p0
we start by assigning genotypes according to their mahalanobis distance, as done in brlmm. recall, we assign subject i to genotype  <dig> if si <c, and to genotype  <dig> otherwise. therefore, the probability, pmn, that a subject with genotype  <dig> is misclassified as genotype  <dig> will be pmn = p, and in the limit, we know pmn→Φ≡pm*. now, it's easy to show that pm* must also be the limiting probability that a subject with genotype  <dig> is assigned as genotype  <dig> 

  p=1−Φ=1−Φ=1−Φ=Φ=Φ≡pm* 

therefore, given the genotype, the limiting conditional probabilities, p and p are equal. if p <dig> > p <dig>  then the unconditional probabilities cannot be equal, specifically

  p=pp0>pp1=p 

obviously the opposite inequality holds if p <dig> <p <dig>  therefore, with the mahalanobis distance, the bias will be

  p0*−p0=pm*p1+p0−p0=pm* 

clearly, when p <dig> = p <dig> =  <dig> , p0* for all values of pm*. however, when p <dig> ≠ p <dig>  the bias is a non-zero function pm*, and therefore depends on the parameter group, {μ1−μ <dig> σ12/σ02} . as shown by figure  <dig>  the bias can be quite large when either pm* and/or |p <dig> -  <dig>  | is large.

next, assume that genotype assignments are based on a likelihood, or weighted likelihood measure. for a value ω ∈ c, the probability that φg exceeds ω, or 2Φg)− <dig>  changes with σg <dig>  where ϕg− <dig> returns a value greater than μg. therefore, φ <dig> = φ <dig> does not imply anything about the relationship between Φ <dig> = Φ <dig>  we illustrate the potential for bias by a simple example where μ <dig> =  <dig>  σ <dig> =  <dig>  and μ <dig> =  <dig>  let p <dig> = p <dig> =  <dig> . then, for any value of σ12≠ <dig> −Φ)≠Φ). equivalently, when two normal densities intersect at the threshold value, the probability of misclassifying a genotype  <dig> subject will not equal the probability of misclassifying a genotype  <dig> subject, and therefore limn→∞pˆ0≠ <dig> =p <dig>  for a given threshold, c*, we can define the bias by p0*−p0=p0Φ0+p1Φ1−p0=p0−1)+Φ <dig>  unlike the previous example, with the mahalanobis distance, figure  <dig> shows that describing the bias as a function of σ <dig> and p <dig> can be difficult. in current tests of association, this inequality shows that it possible for p0n*a≠p0n*u even when p0a=p0u, which as we will see, will lead to an inflated type i error and too many low p-values. start by noting that gwas test a surrogate hypothesis, h0*:p0n*a=p0n*u, not the true hypothesis of interest, h0:p0a=p0u. because p0n*a need not equal p0n*u when the distributions for cases and controls differ, h0*, the tested hypothesis, can be false even when h <dig> is true. let t* be a standard test statistic for h0*, which is believed to have the following property, p=α. let us make the reasonable assumption that the difference between p and p is small, or, in words, when h0* is known to be true, the validity of h <dig> has little effect on the distribution of t*. then,

  p=pp+pp≈αp+β)>α 

here β is a measure of the power to reject h0* and we assume β > α. therefore, the current method of rejecting h <dig> whenever t* > tα* is actually anti-conservative if the stated p-value is α

two genotype example: inconsistency
as with any gwas experiment, we can estimate p <dig> and p <dig> by

  pˆ0n≡1n∑i1 and pˆ1n≡1n∑i <dig> 

for presentation, we will omit the superscript n, writing pˆ0n and pˆ1n as pˆ <dig> and pˆ <dig>  as gˆi, from equation  <dig>  is equivalent to e , we know that

  limn→∞p0n*→p0* and limn→∞p1n*→p1* 

therefore, by the convergence of p0n* and p1n* to constants and the convergence of the mle, we have

  limn→∞pˆ0→pp0* and limn→∞pˆ1→pp1* 

having just discussed cases where equation  holds, our standard estimates of p <dig> and p <dig> are not consistent. specifically,

  limn→∞pˆ0↛pp0 and limn→∞pˆ1↛pp <dig> 

for these scenarios.

return of consistency: modifying the mahalanobis distance
the mahalanobis distance, d, measures the conditional probability of getting a value as extreme as si given genotype g. therefore, we could achieve the same results using

  d†≡p2σg2>2σg2|μg,σg2) 

where g ∈ { <dig>  1} and si is again presumed to be normally distributed. as we saw, the current estimators suffer because they don't account for the genotype probabilities. borrowing bayesian terminology, we simply need to weight our distance measure by the prior probability of a subject having each genotype. therefore, returning to step  <dig> of our genotyping process, we now define gˆi = gmax where gmax maximizes the function pgdg†, a weighted version of the mahalanobis distance. let c† be the point such that p0d0†=p1d1†. then we are guaranteed consistency as

  p0*=p0p+p1p=p0)+ <dig> p1d1†=p <dig> 

with this change, our estimate pˆ0≡1n∑i <dig> would now be consistent.

dependence/correlation of called genotypes
if we knew {g <dig> ..., gn}, the true genotypes for a group of n subjects at snp j, as opposed to only knowing their called genotypes, {gˆ <dig> ...,gˆn}, it would easy to construct a test of h0: h0:p0a=p0u with a specified α level. reject h <dig> if t>tα. here,p˜gq≡1nq∑i:qi=qgi,tα is the 1-α percentile of a χ <dig> distribution, and

  t2−np˜0up˜0u−2) <dig> 

the central limit theorem allows us to be confident that we have an α-level test because n≈n) when {g <dig> ..., gn is a vector of independent bernoulli random variables. again, we have returned to the two genotype scenario to simplify our discussion.

by statements about the perceived α-levels of t, {gˆ <dig> ...,gˆn} are often implicitly treated as the true genotypes and are assumed to be a vector of independent bernoulli random variables. the truth, however, is that gˆi <dig> is not independent of gˆi <dig>  specifically if c, the threshold for calls, is relatively small, then both p and p are relatively large. using this common dependence on c, it is simple to show that gˆi <dig> and gˆi <dig> are positively correlated.

  p=∫c=−∞∞pfdc=∫c=−∞∞fdc=∫c=−∞∞)2fdc+∫c=−∞∞)2fdc≥)fdc)2+)fdc)2=2+ <dig> 

this proof, which uses jensen's inequality, clearly shows that the two variables, gˆi <dig> and gˆi <dig>  are not independent as that would have implied

p=p+p=2+ <dig>  the consequence of this dependence is that n does not follow a n) distribution, and in turn, that t neither follows a χ <dig> distribution nor has p > tα) = α.

we next examine the behavior of pˆ0a,pˆ0u, and t. first, as is common, the dependence increases the variance of these estimates. for any population,

  varn)=ne+nvarn|c]) 

the first term, ne, represents the uncertainty in the true number of subjects with genotype  <dig>  and can be roughly approximated by pˆ0− <dig>  the second term, nvarn|c]) reflects that there will be a subpopulation, of a random size ~n|Φm - Φm |, that is assigned the 'non-ideal' genotype, where a call is labeled 'non-ideal' if it would have been different had the threshold been e . we can approximate this second term, the overall increase in the variance, by nvar) if p ≈ Φm and the cor ≈  <dig>  in experiments, we can estimate nvar) by bootstrapping samples of c or Φˆm.

to focus on the distributions instead of just the variances, we decompose n as

  n=n−e)=n−Φm)+Φm−Φm)+−e)) 

note that pˆ0≡Φˆm and p0n*≡e. the appropriate multiple of the first term, n - Φm), should be well approximated by x-e , where x ~binomial. from our own experience, we have seen that the third term,  - eΦˆm]), is a constant close to  <dig>  the second term,  - Φm) is the variable which causes deviation from normality. again, we could approximate the distribution of this term by bootstrapping c.

next, we offer an example to demonstrate the effect of dependence among called genotypes. specifically, using the ibd data, we show that a n) is a poor approximation for the distribution of n. because we will use real data, we have purposely chosen to discuss n/e− <dig> instead of t . there are many reasons that t may not follow a χ <dig> distribution, including pg* being a poor estimate of pg, the distributions of si being far from normal and population substructure. however, for large n, the only reason that n/e− <dig> will not be approximately normal is if {gˆ <dig> ...,gˆn} are not independent. also, we chose to focus on the ab genotype as this is certain to be one of the genotypes with an overlapping cluster.

for each of our  <dig> snps in the ibd data, we bootstrap  <dig> samples of  <dig> subjects, and calculate  <dig> values of n/e− <dig>  where e is estimated by 140∑k=140pˆab. the qq-plot in figure  <dig> compares these  <dig> ×  <dig> values with a n. the distribution is far from normal, which implies that {gˆ <dig> ...,gˆn} are dependent. some snps were more likely to contribute skewed values than others, but the top and bottom  <dig> values  are from  <dig> different snps, indicating that no one snp, or small number of snps, is responsible for the deviation in the qq plot. in contrast, the qq-plot from well-behaved snps, where the contributions to the density of s from the three genotypes were separated, was the expected straight line, showing that it was not the normal approximation skewing the results . because the magnitude of the observed values were larger than predicted by theory, the practical implication is that tests based on the statistic, t, estimated by fχ <dig>  will be anti-conservative under the null hypothesis. here we also note that if si were truly normal, the impact of the dependency would be much less. for more details on the origin of dependency, please see table  <dig> 

comparing tests of association
simulated data sets are full described in the methods section. the shift is the distance between the and μaa and / <dig>  the difference is the distance between μaba and μabu. rr is the genotype relative risk for subjects homogeneous for the minor allele.

in gwas, each marker is tested for association with the disease. here, we compare four methods for testing the  <dig> chosen snps in the ibd study. in the first method, we let bead-studio call the genotypes and perform its standard cochran-armitage test. default settings were used to assign calls as missing and remove poor quality snps. in the second method, we call the snps using logicall and test for association using logistic regression, although using cochran-armitage would not change our conclusions. in the third method, we calculate the likelihood ratio statistic comparing θˆj and θˆrj from equation  using all snps, and in the fourth method, we calculate the lr statistic using only those snps where θˆj and θˆrj yield identical calls, and hardy-weinberg equilibrium, for controls alone, is not violated at a statistical significance level of < 10- <dig>  for each method, we calculated the proportion of 'p-values' that were less than  <dig> ,  <dig> , and  <dig>  .

1) beadstudio . 

2) logicall. 

3) likelihood ratio  using all snp.

4) likelihood ratio  using only snp where calls were the same for restricted and unrestricted parameter sets.

when genotyping all snps and all subjects, the proportion of bead-studio 'p-values' below the three thresholds far exceeded  <dig> ,  <dig> , and  <dig> . even after removing low quality snps and allowing missing calls, the proportion of 'p-values' below the three thresholds were  <dig> ,  <dig> , and  <dig> . in contrast, logicall eliminated nearly all false positives. the proportion below the three thresholds were  <dig> ,  <dig> , and  <dig> . if the majority of these snps are presumed to be null associations, logicall appears to be the superior method, so long as the power loss is minimal. assigning conservative 'p-values' to problematic snps is nearly equivalent to removing them. however, because of the tendency for there to be multiple, nearly equivalent, maximum likelihood estimates, the relative distances to the aa, ab, and bb genotypes using the single set of maximum likelihood estimates may not be adequate in identifying questionable calls. therefore, logicall gains an advantage by combining two methods for identifying suspect calls. additionally, it avoids false positives caused by differential bias, where the proportion of missing calls differs between cases and controls. this new method simplifies testing by requiring no preprocessing and testing all snps. the power loss from logicall depends on the quality of the data. when the statistic for a snp cleanly separates into an aa, ab, and bb group, there is no power loss. in our ibd example, the 'p-values' reported for rs <dig> and rs <dig>  the two snps that are believed to be truly associated with ibd were similar for the two methods, bead-studio  and logicall . among those subjects meeting the 96% bead-studio call rate, logicall found no questionable calls.

the likelihood ratio method had mixed results. clearly, when the distribution of the summary statistic is a mixture of normals, the estimated genotype proportions are asymptotically unbiased. unfortunately, this method still resulted in an increased number of false positives. however, if we removed those snps where at least one call changed when switching from θˆ to θˆr, the false positive rate decreased to the expected level. in theory, all calls should be identical and only the resulting likelihoods should differ. when assigning genotypes, the cost, in likelihood, incurred from forcing the vectors of genotype proportions to be equal should be far less than the cost of switching calls. when the reverse is true, and calls switch, the statistic for the three groups cannot be well separated, and the p-value is suspect.

CONCLUSIONS
in genome-wide association tests, under the null hypothesis, the test statistic rarely follows the expected chi-squared distribution. this deviation tends to result in an excess of false positives. unfortunately, the investigation into the origin of this deviation has yet to be completed. the problems associated with poor signal quality and population substructure have been thoroughly explored. however, the overlap of fluorescent signals has only been identified as a serious problem, and has yet to be fully explained. in this paper, we have provided two reasons, parameter inconsistency and called genotype dependency, that help explain how overlap causes this deviant behavior. furthermore, we propose two methods, logicall and a method based on the likelihood ratio statistic that better handle the problems of inconsistency and dependency. these methods will perform similarly to the common, genotype-based, test statistics for the well-behaved snps and appear to create fewer false positives for the difficult-to-call snps. we have also identified a new characteristic of some false positives, that the call differs when using θˆrj vs. θˆj, that will help distinguish which low p-values represent significant disease/marker association.

we have demonstrated that increasing sample size alone will not eliminate type i error, as genotyping, in its current form, leads to inconsistent estimates of population parameters. to alleviate this inconsistency, the distance measure used for assignment would need to be switched to pgdg†, defined in the results and discussion section. moreover, we have proven that the called genotypes can be dependent under certain conditions, and that tests based on called genotypes need to account for the increased variance caused by dependence. finally, we illustrated that the likelihood profile of the data can be relatively flat near the mles. therefore, judging the quality of calls from distances based only on the mle may not provide an adequate means to identify questionable calls. hence logicall, which looks at all locally-maximal likelihood estimates of the parameters can reduce the type i error rate. testing association by the likelihood ratio statistic is another promising method for addressing the problems associated with overlapping signals.

availability and requirements
computer programs are available on author's website, .

authors' contributions
js identified the original problem. both js and hz developed the problem. js drafted the manuscript. both authors read and approved the final manuscript.

