BACKGROUND
reverse transcription quantitative pcr  has long become the gold standard for quantifying relative gene expression to study normal and pathological cell processes. low density rt-qpcr arrays improve the throughput without losing the benefit of individual pcr reactions  <cit> . although some data-driven normalization methods, such as quantile  <cit>  and rank invariant  <cit>  procedures, have been proposed and applied  <cit> , the most common practice is based on the endogenous internal references, often referred to as “housekeeping” genes as for individual rt-qpcr experiments. comparison to reference genes offers multiple practical advantages but the use of this strategy relies on the premise that these genes are expressed at the same level across a number of experimental conditions under investigation. however, no endogenous controls have been found to be constantly expressed across all different tissues, developmental stages, and study conditions  <cit> . thus, a large number of papers focus on identifying stable references for various organisms, tissues, and conditions  <cit> , given the critical nature of the quality of the comparisons and the implications for hypothesis testing of expression levels.

conventional normalization of rt-qpcr data entails first identifying the appropriate reference genes, then subtracting the ct  values of the best reference gene or the ct mean of several reference genes from all the target genes to obtain the normalized  Δct for further comparison  <cit> . this type of normalization is based on the assumption that the ct values of the target genes have a linear relationship with those of the reference genes and that the regression coefficient is  <dig>  in this paper, we show, with rt-qpcr array data collected from rheumatoid arthritis patients, that the relationship is linear but the coefficient is not  <dig> and varies among different reference genes. under this circumstance, Δct is biased. using a variety of publicly available datasets, we show that this bias is widespread and not related to the physiologic or pathologic process under analysis. furthermore, we demonstrate that pcr amplification efficiency varies substantially across genes, which is likely the cause of this bias. methods have been proposed to take into account of the amplification efficiency in the normalization  <cit> ; however, they involve estimating amplification efficiencies of targets and references using dilution series, which is not practical for rt-qpcr arrays. we propose a simple regression method for removing Δct bias. this method can be applied not only to rt-qpcr arrays but also assays for individual genes.

RESULTS
Δct normalization introduces bias
the commonly used normalization method for rt-qpcr data is subtracting the ct values of the internal reference genes from those of the target genes to obtain the difference in the ct . the premise is that differences in the loading amount of template would be represented by the different ct values of the reference genes. therefore, subtracting the ct of the reference genes  would adjust for these rna loading differences. to assess the validity of this premise, we plotted the mean ct values of the target genes from a low-density pcr-based array , which represent the average signal strength of the target genes, against the reference gene ct values. if the premise were correct, there would be a positive correlation. as expected, the mean ct values of the target genes were indeed positively correlated  with the ct values of the reference genes . however, after subtracting the reference gene ct values, a negative correlation  was generated between the mean of the Δct values of the target genes and the ct values of each reference gene . this finding indicates a systematic over-correction . if there were no bias, there would be no significant correlation between the mean Δct values of the target genes and the reference gene ct values. all five reference genes showed similar negative correlation although the degree varied, which indicates that this is a general phenomenon instead of the property of a particular reference gene. the negative correlation remained present  when the geometric mean of multiple reference genes  was used .figure  <dig> 
mean c
t
values of the target genes from each sample are positively correlated with the c
t
values of the reference genes on the array. results are shown from the rheumatoid arthritis sab dataset. the lower right panel is based on the ct means of all five reference genes while the others are based on individual reference gene. ref, reference; r, pearson correlation coefficient; p, p value from testing the correlation coefficient against  <dig> 
negative correlation between the mean of the Δc
t
values from the target genes and c
t
values of the reference genes after normalization via conventional subtraction. the lower right panel is based the ct mean of all five reference genes while the others are based on individual reference gene. ref, reference; dct, Δct; r, pearson correlation coefficient; p, p value from testing the correlation coefficient against  <dig> 



regression on reference genes
the negative correlation bias shown in figure  <dig> indicates that the target genes measurements are linearly related to the reference genes but the coefficients are less than one. when direct subtraction is used, a negative relationship is generated from over-correction. a simple way to solve this problem is to run a linear regression to estimate a coefficient and then adjust the reference gene ct values with the estimated coefficient. regression analysis can be performed either on any selected individual reference gene or on the mean ct values of all reference genes. the latter approach has the advantage of minimizing the potential undesirable effect of a single reference gene. however, a more comprehensive method is to run a multiple regression including all the reference genes to estimate coefficients for each of them and remove the dependency together . this multiple regression approach is feasible when the number of samples is sufficient ; otherwise, there is the risk of model over-fitting.figure  <dig> 
multiple regression based normalization removes dependency of target c
t
means on reference genes. no obvious correlation is observed between normalized target gene ct means and ct values of reference genes.



similar bias from other mrna rt-qpcr array datasets
to assess whether the Δct bias exists with other pcr-based mrna array datasets, we examined another of our datasets  generated from a different array as well as three publicly available datasets from gene expression omnibus . table  <dig> shows the regression coefficients of the reference genes from these datasets against the mean target ct values from each sample. the coefficients range from  <dig>  to  <dig>  but are generally less than  <dig>  it is interesting that different experiments show quite different coefficients even for the same reference gene, which necessitated the estimation of regression coefficients in each experiment. for coefficients close to  <dig>  Δct does not generate much bias, but for the coefficients far from  <dig>  the bias can be substantial.table  <dig> 
reference gene regression coefficients from gene expression datasets



genes
gse <dig> gpl8370
gse <dig> gpl6933
gset <dig> gpl6926
ra-sab
ra-abi
na, not assayed.



similar bias from microrna pcr array datasets
rt-qpcr based low-density arrays are also widely used to assay the expression of microrna . internal controls built on the array, such as rnu <dig> and rnu <dig>  are similar to the reference genes on the low-density mrna arrays. there is evidence that normalizing against the global mean is better than against internal controls for mirna array data  <cit> . however, the majority of studies still rely on internal controls for normalization. we analyzed four publicly available datasets for regression coefficients in the same fashion as for the mrna datasets. the results showed that the coefficients for the internal controls are even smaller  than those from the mrna rt-qpcr array datasets. therefore, the bias resulted from Δct normalization would be even more prominent.table  <dig> 
control gene regression coefficients from microrna datasets



controls
gse <dig> gpl9732
gse <dig> gpl10522
gse <dig> gpl15765
gse <dig> gpl11239
na, not assayed. nl, no significant linear relationship.



regression coefficients vary among target genes
to this point, our analyses used the ct means of all target genes on the array from each sample for examining the relationship to the reference genes. when individual target genes were examined, their ct values all showed positive correlations with the reference genes but their regression coefficients varied widely . only a small number of genes had coefficients close to  <dig>  in which case Δct is not biased. the majority of the target genes have coefficients substantially smaller than  <dig>  for which bias will be introduced from the direct subtraction of reference gene ct values in the Δct normalization.figure  <dig> 
histograms of single-gene regression coefficients  of target gene c
t
values on mean reference c
t
values.




amplification efficiencies differ among genes
the deviation of the regression coefficients from  <dig> is very likely due to amplification efficiency differences between target and reference genes. to check the amplification efficiency, we selected  <dig> genes  and measured their efficiency in  <dig> clear samples that were used in generating ra datasets in a dilution series. a simple regression of ct values on the log <dig> transformed dilution factors showed that the amplification efficiencies are quite different across genes but fairly similar across samples  in our experiment. when the target genes are regressed onto the reference genes, the differences in amplification efficiencies resulted in coefficients deviating from  <dig> .table  <dig> 
regression coefficients of c
t
values on dilution factors



samples
rps9
gapdh
rpl13a
ifngr1
irf1
ly96
dilution factors were log <dig> transformed. the ideal 100% efficiency corresponds to coefficient of − <dig> 
regression coefficients between targets and references vary based on the amplification efficiency of both target and references. the dilution series from all four samples were used to obtain the regression coefficient for each pair of target and reference control.



impact on differential expression analyses
to assess the impact of the Δct bias on differential gene expression analysis, we compared the regression-based strategies  with the conventional Δct method for difference in expression fold change and p values using the ra-sab dataset. for convenience, we only examined the  <dig> target genes without any undetectable values from a subset of the samples with the most extreme differences in clinical phenotype  using the wilcoxon rank sum test. the fold change estimations  from the three methods are highly correlated . those from the ct mean regression are simply shifted by a constant from the Δct method. on the contrary, the per-gene regression method generated smaller fold changes than the other two methods . when p values were compared, the Δct and ct mean regression methods identified almost exactly the same genes as being differentially expressed between the two groups of subjects; however the p values tended to be larger from the ct mean regression . in contrast, the per-gene regression method identified fewer significantly differentially expressed genes and the p values were larger than those from the other two methods.figure  <dig> 
fold change and p value comparisons between Δc
t
and regression-based normalization methods. fc, fold change. for the Δct method, the normalization factor is the mean ct of the  <dig> reference genes; for the regression-based method, normalization factors are the multiple regressions of the mean ct values of target genes  or the ct values of each target gene  against the mean ct of reference genes. the dashed line is the identity line. the vertical and horizontal lines in the right panel mark the significance level of nominal p value  <dig> .



we conducted some simple simulation studies to compare the fold change estimates and false/true positive rates between Δct normalization and per-gene regression normalization. our results showed that the per-gene regression normalization increase the precision of fold change estimates  and the power for detecting differential expressions especially when the regression coefficient is far from  <dig> and the variation is not too large. the false positive rate of the regression normalization is well controlled around the expected level while that of the Δct normalization is inflated when there is a mean ct difference between the comparing groups for the control gene . the inflation of false positive rate from Δct normalization enlarges along the decrease of target gene ct variance and the increase of sample size.

discussion
our study showed that even with a universally constant reference gene, the Δct method tends to introduce large bias. although the ct values of the target genes are positively correlated with the reference gene, the regression coefficients are often substantially different from  <dig>  we believe that a more appropriate method is to estimate the coefficient using regression and then subtract the reference gene ct values adjusted by the regression coefficient.

using three target genes and three reference genes as example, we demonstrated that the rt-qpcr amplification efficiencies are different among genes, which results in the deviation of the regression coefficients from  <dig> for some combinations of target and reference genes. under ideal conditions, all primers/probes pairs should have amplification efficiency at close to 100% . otherwise, the amplification efficiency should be estimated  <cit>  and incorporated into the normalization procedure. unfortunately, dilution curves or amplification dynamics for estimating the amplification efficiency of each gene is not a pragmatic method in rt-qpcr experiments. given the cost of low density rt-qpcr arrays, it is even less practical to run dilution curves. therefore, a simple remedy is to use regression for each target gene in the normalization instead of direct subtraction of ct values.

linear regression is a simple and effective way to estimate the normalization coefficients. however, one potential downside is that it can be easily affected by outlier data points. in our analysis, we removed outlier data points before normalization to avoid this problem. an alternative way is to apply a robust regression to combine these two steps together. attention is also needed when combining rt-qpcr datasets. when individual datasets are normalized separately, the regression coefficients and intercepts can be different. if this is the case, the normalized data based on different regression coefficients will still have potential mean differences, which needs to be adjusted before combining the datasets.

when multiple reference genes are used as controls, they do not always give similar regression coefficients. we showed that using the mean ct values of all reference genes for regression can achieve most of the normalization goal. however multiple regression analysis does a better job at simultaneously removing all dependency on all reference genes. we have found that the coefficients for some reference genes are fairly large while they are close to zero for others . therefore, using only the reference genes with large coefficients will usually work well. one downside of multiple regression is that when the sample size of the rt-qpcr experiment is small, for example no bigger than the number of reference genes, the multiple regression will over-fit due to the lack of degree of freedom for residuals. in this situation, the number of reference genes used has to be reduced by selecting the best one or using the average. it is important to point out that multiple regression normalization is less stringent than global mean normalization because it does not force the mean ct values of all samples to be the same. it only removes the correlation with reference genes.

when regression-based normalization is conducted for low density rt-qpcr array data, there is the choice of using the mean target ct values of all target genes for a single regression or regression for each target gene on the array. our results from the ra-sab dataset showed that the mean regression was just one constant shift from the Δct normalization when fold change is concerned. the per-gene regression resulted in more differences due to the regression coefficient differences among genes. the fold changes obtained from the per-gene regression normalization were smaller and p values were larger than those from conventional subtraction normalization. this is likely the result of bias removal. when correlation between normalized target gene ct and control ct is introduced by subtraction normalization, fold change has two components, the true fold change between the two comparing groups and the difference related to the mean control difference. for example, even if two groups have equal mean expressions, the two group means of the normalized Δct values will still be different when the data points from the two groups are located in different areas in a panel of figure  <dig>  the size of this difference depends on the slope of regression and the mean difference of the control gene ct values. therefore, Δct normalization gives larger fold changes, which results in smaller p values. our simulation results largely confirmed this speculation. bias related to Δct normalization could be one reason for larger fold changes obtained from rt-qpcr than those from other high-throughput technologies, such as microarrays. given that rt-qpcr has been considered as “gold standard” for quantifying gene expression, the general thoughts about this discrepancy have been that microarray somehow “squashes” the fold changes. given our findings in this study, an alternative explanation is that rt-qpcr sometimes inflates fold changes due to Δct bias. this is consistent with the observations that fold changes from microarray and rna-seq have been found to be very similar in some studies  <cit> .

one limitation of our regression-based normalization is that it works well when the sample size of the experiment is fairly large, such as our example  and the geo datasets . it can be problematic for very small sample sizes, such as just a few. our simulations showed that the reduction of false positives and gain of power diminishes when total sample size goes down to  <dig> when variation is large. for rt-qpcr experiments on single or a few genes, dilution series are needed and practical for estimating amplification efficiencies, which can then be taken into account in normalization. for rt-qpcr array experiments with small number of samples, dilution series is less practical due to the cost. in this case, the amplification efficiency can be estimated based on the pcr kinetic curve  <cit> . however, kinetic curves have to be obtained for each gene from the pcr machine, which is not a standard practice of rt-qpcr. if these methods are not applied, investigators need to be aware of the existence of potential bias associated with Δct normalization in differential expression. in addition, we recommend use regression-based normalization when a statistically significant correlation between the ct values of target genes and controls is detected; otherwise, the regression-based normalization is not beneficial.

CONCLUSIONS
the Δct normalization method often introduces bias due to amplification efficiency differences, which affects the estimation of fold change and the identification of differentially expressed genes. this bias can be effectively corrected by estimating the regression coefficient for each target gene and adjusting their Δct values accordingly.

