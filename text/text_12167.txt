BACKGROUND
thromboembolic disease diagnosis
the role of computed tomography  in diagnosis has been growing as a result of advances in technology imaging including the recent emergence of multidetector and dual-energy ct. pulmonary ct angiography  has become the first-line diagnostic imaging modality in most patients with suspected pulmonary embolism . similarly, ct venography  which concurrently follows cta has also rapidly been adopted in the workup of pe for diagnosing deep vein thrombosis   <cit> . following the introduction of helical and multi-slice pulmonary cta, many research studies were conducted to assess the contribution of ctv and reached different conclusions  <cit> . in a first group of studies, cta-ctv improved the diagnostic yield in comparison with cta alone . in a second group  <cit> , the added yield of ctv was found too marginal to justify the additional irradiation. furthermore, some of these studies suggested that ctv should be considered for patients at higher risk of venous thromboembolism  or for patients with a high clinical probability of pe  <cit>  as well as in postpartum patients with suspected pe  <cit> . overall, the role of ctv is less established than that of pulmonary cta and questions remain about the utility of ctv.

the hôpital européen georges pompidou  is a national reference center for vascular diseases. patients with acute pe and who do not require fibrinolysis are directly oriented to the center. at hegp, cta is the first-line examination for patients suspected of having pe  and indirect ctv is often performed following cta  <cit> . as a result, the hegp clinical data warehouse contains a large corpus of patient records with both cta and ctv reports. this corpus is a valuable resource to analyze the contribution of each method in the diagnosis.

clinically relevant incidental findings
the increasing availability of imaging technologies has led to a growing number of incidental findings. incidental findings are asymptomatic lesions that are discovered through routine radiographs  obtained for other reasons . for instance, a lung nodule in a patient with no history of lung cancer examined for suspected pe is considered an incidental finding. we focused our attention on the incidental clinically relevant findings that require clinical or radiologic follow-up, also called “incidentaloma”. these include: a nodule or mass located in an organ, including the lungs, liver, spleen, kidneys, bone, thyroid gland, pancreas, adrenal glands, and stomach; any lymph node > 1 cm and not associated with an infiltrate, or any lymph node > 3 cm, or multiple lymph nodes  <cit> . in a study conducted at an emergency department  <cit> , the estimated prevalence of these incidentalomas in chest cta ordered to diagnose pe was 24%  while the prevalence of pe was only 9% . the evaluation of such findings from radiology reports places a huge burden on the health care system. the absence of an automated system to identify and track incidental findings is an important barrier to ensuring timely follow-up of patients especially with incidental findings on imaging examinations. in this study we designed an automated method to identify these medical findings related to thromboembolic disease and incidental findings from free-text radiology reports written in french using natural language processing methods, and evaluated the system on the hegp corpus.

natural language processing for clinical free-text
the answers to important questions regarding thromboembolic disease diagnosis and incidental findings can be found in radiology reports. these are huge sets of free-text documents: for example hegp radiologists produce about  <dig>  reports each year. nlp has the potential to provide the means to analyze large quantities of documents rapidly and accurately, including clinical text  <cit> . clinical narratives written in english have received a lot of attention from the nlp community in the past decades through the development of dedicated tools   <cit> , ctakes  <cit> ) or repurposing of tools initially meant for processing the literature . biomedical texts in languages other than english have received considerably less attention. french nlp teams regularly participate in the annual i2b <dig> challenges. some of their work initially designed for the english language, was successfully transferred to french. tools for automatic translation of terms from english to french have been developed . zweigenbaum et al.  <cit>  worked on a project to pool lexical resources scattered among several sources in a unified medical lexicon for french . namer  <cit>  described a method which enables neoclassical compound nouns and adjectives of a biomedical specialized corpus to be automatically related by synonymy, hyponymy and approximation links. grabar et al.  <cit>  developed a method for automatically acquiring synonymy resources. deléger et al.  <cit>  developed a medication extraction system for french clinical texts. grouin et al. were able to compute the cha2ds2-vasc score, which predicts the thromboembolic risk for patients with atrial fibrillation, using the automatically extracted medical concepts  <cit> .

the purpose of the study presented herein was to analyze ct reports to automatically determine thromboembolic diagnosis and the technique used to reach it, as well as automatically identify clinically relevant incidental findings. we had the following specific aims: 1/set up a machine-learning based framework for automatic report analysis 2/assess the benefit of using nlp to extract clinically relevant concepts, modalities and relations between concepts 3/produce valuable resources to develop nlp tools able to automatically extract concepts, modalities and relations.

methods
in this section we describe the corpus, natural language processing tools and machine learning methods used in our work.

this study was approved by the institutional review board at hegp which waived the need for informed consent .

corpus selection and pre-processing
the corpus selection was performed in two steps. in the first step, our objective was to extract the features of the reports associated with cta/ctv in the context of pe. we queried the hegp i2b <dig> clinical data warehouse using the label of the imaging procedures stored in the i2b <dig> observation blob field corresponding to the ct of vascular system performed in the year  <dig>  we obtained a set of  <dig>  radiology exam reports. among them, many documents reported on procedures corresponding to anatomical sites that were not of interest for our study . in the second step, we drew a list of  <dig> key terms for ctv  and  <dig> for cta . we used these lists of terms to select the cta/ctv prescribed for pe. specifically, we built a refined query that selected reports containing at least one term from each list. among the  <dig>  radiology exams retrieved by the initial query, only  <dig> were selected by the new query. we will use the term “corpus” to refer to that set of  <dig> reports.

we manually reviewed  <dig> randomly selected reports from the  <dig>  initially retrieved to assess the performance of the refined query. we found that  <dig> reports were selected by the refined query. all corresponded to cta and ctv prescribed in the context of pe . among the remaining  <dig> reports,  <dig> corresponded to another indication or exam  and  <dig> corresponded to relevant reports not selected by the query . overall, the query detected relevant reports with a precision of 100%, recall of 61% and f-measure of 68%. further error analysis revealed that the query omitted to select reports that did not include the name of the exams performed, reports that used a different spelling from our list of keywords , or reports that exhibited technical errors in the text conversion from the original record format.

the corpus was automatically de-identified using a ruled-based de-identification tool called medina   <cit> . the system replaced patient and physician names by surrogate data and shifted dates within the report by a uniform random number of days so as to preserve the interval between dates. the results of the automatic de-identification process were validated by a physician . then, a simple sentence segmenter  and a tokenizer  were applied to our corpus. the corpus comprised a total of  <dig>  tokens . report average length was  <dig> tokens. although our radiology reports were in free-text format, the content was structured into five sections to describe: patient identification, indication of exam along with clinical information, exam protocol details, results, and conclusion. each report displayed a section title followed by the corresponding free-text contents. we used a rule-based algorithm relying on regular expressions to split the reports into sections.

analysis of the radiology reports and design of an annotation scheme
the corpus of reports was manually reviewed by a physician  to label each report as: positive  cta for presence  of pe, positive  ctv for presence  of dvt, and presence  of an incidental clinically relevant finding. this labeled data set was used as a gold standard for further machine learning classification evaluation .table  <dig> 
distribution of thromboembolic diagnosis and incidental finding in the  <dig> radiology reports



cta/
ctv

incidentaloma

cta = computed tomography angiography.


ctv = computed tomography venography.



we designed a knowledge representation scheme  that could be transposed to an annotation scheme modeling the diagnosis using three types of concepts: medical conditions , clinically relevant findings  and post-partum status  ), affected body location  and diagnostic procedure . thromboembolic diseases could be qualified with three modalities: positive, negative, hypothetical. clinically relevant findings could also be qualified with two additional modalities: previously known and incidental. finally, we considered relations between the medical conditions and affected anatomy parts  and relations between exams and medical conditions .figure  <dig> 
the annotation scheme used in our project.




lexicons for each concept type were compiled to help with the annotation task, with the following steps:identification of core concepts: an initial set of terms related to thromboembolic disease and its related anatomy location was obtained by pooling french mesh terms from the anatomy category, available synonyms  <cit>  and the french translation of the foundational model of anatomy  <cit> .

lexicon enrichment: as the terms in literature-oriented terminologies often did not reflect the way the same concepts were referred to in clinical narratives, we needed to add clinically-oriented term to the lexicon. manual additions from a web-based thesaurus of terms linked to icd- <dig> gm codes called medcode  <cit>  were added to our lexicon. terms from medcode were highly representative of the narratives of our radiology reports, listing abbreviations of terms, acronyms and narratives dialectal expressions of anatomy and thromboembolic disease.

identification of clinically relevant finding terms within the reports required the help of a radiologist .  <dig> radiology reports with incidental clinically relevant finding were identified. terms that recalled clinically relevant findings such as “nodule” , “masse” , or “adénopathie”  were added to our lexicon which compiled a total of  <dig> terms.



the lexicon comprised a total of  <dig> terms, including  <dig> terms for anatomy,  <dig> for thrombopathology, and  <dig> for incidental findings.

based on a recent survey of annotation tools for the biomedical domain  <cit> , the brat  <cit>  interface was found to support annotation of entities, relationships and modalities, and allow the use of pre-annotations. after applying a simple lexicon matcher for concept recognition, annotations of the corpus were revised manually through the brat interface.

two annotation strategies were considered: “full annotation” and “light annotation”. the full annotation strategy consisted in thoroughly revising the concept pre-annotation on the entire reports , as well as creating modality and relation annotations on the entire reports. the light annotation strategy consisted in reasonably revising the concept pre-annotation , as well as creating modality and relation annotations. for thromboembolic diseases the annotation task focused on the conclusion section with attention given to the results section only if conclusion was incomplete. a conclusion was considered incomplete when it did not contain important findings described in other sections of the report. typically, the conclusion section re-iterated the important findings of the exam  with respect to the indication. incidental findings  were often stated in the results section, but not in the conclusion. for clinically relevant findings, the annotation covered the entire report.

a computational linguist with extensive annotation experience  annotated two sets of  <dig> radiology reports using the two strategies and calculated the annotation time. for the “full annotation”, the average annotation time was 20 minutes per report. the “light annotation” reduced the annotation time to 7 minutes per report. due to time constraints, light annotation was performed on the entire corpus by a physician . figure  <dig> shows a sample text with concept pre-annotations automatically produced by the lexicon matcher and the final annotations produced by the physician. inter-annotator agreement  was then computed on the ten reports that were processed in common by the two annotators.figure  <dig> 
sample annotated text using brat. top: pre-annotated text using the automatic lexicon matcher. bottom: final annotations produced by the physician after revising the pre-annotations.



classification of radiology reports
at the hegp university hospital, the estimated prevalence for pe was around  <dig> % and 15% for dvt  <cit> , all patients with suspected embolism considered. because of this, our extracted data set was highly imbalanced, with many more reports of negative cta/ctv than positive cta/ctv. to prevent our statistical model from over-predicting negative cases, we multiplied the number of positive cases and adjusted it to the number of negative cases. a 10-fold cross-validation to train the classifier could not be used as copies of a same positive case having a non negligible probability to be in the training set as well as in the test set, thus biasing the results. therefore, we designed a test and a training set as follows: we first randomly selected  <dig> reports from our initial data set to form the test set. with the remaining set, we tripled the positive reports , and adjusted the number of negative reports  to the number of positive reports. the test set remained imbalanced in order to reflect the reality of the data in the hospital. for the incidental findings classification, the positive cases from the training set were multiplied by  <dig>  we validated this choice by testing other balancing parameters  and obtained similar results.figure  <dig> 
test and training set for cta/ctv classification.




to perform the automatic classification of our radiology reports according to diagnosis, we used open-source tools: the waikato environment for knowledge analysis  tool  <cit> , and wapiti  <cit> . our data was formatted into an attribute-relation file format  using perl scripts. initially we used a weka naïve bayes classifier to test several feature sets and validate the usefulness of the annotations as features. using binary encoding, the most useful features were: baseline plain text , plain text with the adjunction of annotations, and finally text segmented by report section with the adjunction of annotations. other features that we tested were: text tokens with filtering of unigram, filtering of uni- and bigrams, filtering of frequent and non-discriminating unigram stopwords, filtering of frequent and non-discriminating uni- and bigrams stopwords. in one model, we incorporated report section information by typing text and annotation features according to the section of the report they were extracted from. in another model, we only included text and annotation features coming from selected report sections.

once the optimal feature sets were identified using the naïve bayes classifier, we developed an optimized classifier, using wapiti implementations of support vector machine  and maximum entropy  algorithms.

evaluation
we evaluated our classification models using precision, recall, and f-measure. precision was computed as the number of documents correctly classified as reporting a positive diagnosis over the total number of documents classified as reporting a positive diagnosis. recall was computed as the number of documents correctly classified as reporting a positive diagnosis over the total number of documents reporting a positive diagnosis according to the gold standard. the f-measure was computed as the harmonic average between precision and recall.

iaa was used as a quality measure for the knowledge representation and the annotation task. it was computed as f-measure, which was shown to be equivalent to cohen’s kappa for our type of annotation task  <cit> . iaa was obtained using the nicta tool, an open-source tool made available by the national information and communication technology research center of australia  <cit> .

RESULTS
annotated corpus
table  <dig> presents the distribution of the thromboembolic diagnosis, exams used to make the diagnosis and incidental findings. table  <dig> presents the results of the “light annotation” of the entire corpus for concepts, modalities and relations. table  <dig> shows the inter-annotator agreement between the computational linguist and the physician on the subset of  <dig> radiology reports that were doubly-annotated. the overall inter-annotator agreement for entities was  <dig>   and  <dig>  , and for relations,  <dig>   and  <dig>  . agreement is shown for the subset of relations that occurred in this small subset .table  <dig> 
distribution of annotations in the  <dig> radiology reports



anatomy
location_of reveals
negative

reveals
positive

exam
known

incidental

hypothetical
*thrombopat for thrombopathology concepts.

*k for clinically relevant findings.

*pp for post-partum.
inter-annotator agreement on a sample of  <dig> radiology reports 



  
anatomy
  
  
exam
  

  
  

iaa = inter-annotator agreement.

*thrombopat for thrombopathology concepts.

*k for clinically relevant findings.



automatic classification of diagnosis and findings
the performances of the naïve bayes and maxent classifiers were evaluated on the  <dig> reports of the test sets . first, we used the naïve bayes classifier on a baseline model relying on plain text features and an enriched model using plain text and annotations for concepts, modality and relations. once the optimal feature sets were identified using the naïve bayes classifier, svm and maxent algorithms were applied. we obtained the highest precision  and recall  for the identification of pulmonary embolism, using the maxent classifier. precision was  <dig>  and recall was  <dig>  for dvt. as for incidental findings, precision ranged from  <dig>   to  <dig>  , and recall ranged from  <dig>   to  <dig>  . results obtained with the svm classifier were similar to the maxent classification but slightly inferior . overall results for the maxent classifier showed great improvements over the naïve bayes. nonetheless result trends were similar to what we obtained with the naïve bayes classifier: using annotations improved the performance over the baseline in all cases.table  <dig> 
performances of the naïve bayes versus the maximum entropy classifiers on the cta/ctv and incidentaloma test sets



nb: naïve bayes; me: maximum entropy.


pe: pulmonary embolism; dvt: deep vein thrombosis.

*results and conclusion sections.


nc: not calculated.



discussion
contribution of automated analysis of radiography reports to the characterization of patients admitted for pe
cta and ctv are routinely used at hegp to evaluate patients with suspicion of pe. this manuscript reports on the very good performance of an automated approach to determine the thrombotic status from unstructured ct reports. this approach may be used in many applications, such as eligibility screening in clinical trials or analysis of retrospective e-cohorts.

this study showed that in  <dig> reports out of  <dig> a diagnosis of thromboembolic disease was reached with ctv while cta did not show any evidence of thromboembolism. similarly, cta helped reach a diagnosis of dvt in  <dig> cases while ctv was negative . these results suggest that the two techniques are complementary. the classification method used in this study has the potential to help clinicians extract the reports providing crucial information on diagnosis yield and evaluate the contribution of each technique.

ct exams have the ability to detect unexpected non-vascular findings, with clinical, ethical and financial implications of incidental imaging findings. a significant proportion of these findings may be serious and need to be adequately managed. an increasing amount of attention has been paid to incidental findings, e.g., the acr incidental findings committee ii recently published four papers, based on repeated reviews and revisions and a collective review and interpretation of relevant literature  <cit> . in this context, the automated analysis of patient records provides a valuable data driven approach to characterize the incidence and prevalence of such findings , describe the lesions most frequently seen on cts performed on patients admitted for suspicion of thromboembolism, and develop protocols for follow-up and treatment.

contribution of knowledge representation and nlp to the analysis of radiography reports
the annotation of a large corpus of cta/ctv reports showed that relations between disease concepts and anatomy concepts are explicitly stated in the reports . this means that automatically extracting these relations using nlp can provide very specific information about the anatomic site of the thrombus. in contrast, in most cases, the relations between exams and diseases are implicit: there were only  <dig> “reveals” relations between exams and diseases in the study corpus. interestingly, when the “reveals” relations are removed from the feature set in the best models, there is no difference in performance . the modality annotations  show that a high number of concepts are assigned a negative  or hypothetical  modality, compared to a positive modality . this highlights the need for an analysis that goes beyond concept extraction  <cit> . in this study, we established an annotation schema as a method to provide both medical and linguistic knowledge representation to model diagnosis  <cit> . machine learning using a simple naïve bayes classifier was able to automatically detect thromboembolic diagnosis with high precision and recall . a more advanced classifier obtained even better results  with f-measure above  <dig> . the use of concepts, modalities and relations as features significantly improved the results, especially for dvt where f-measure increased from  <dig>  to  <dig>   in the naïve bayes model.

identifying incidentaloma initially proved more difficult  but the use of concepts, modalities and relations still contributed to increase f-measure from  <dig>  to  <dig>  . the maximum entropy classifier provided results on par with thromboembolic diagnosis classification . it is important to point out that there are no specialized lexicons for incidental findings. imaging signs are not represented in established terminologies such as mesh. shore et al. incorporated a total of  <dig>  terms for imaging signs into the rsna’s radlex ontology of radiology terms  <cit> . this ontology is available for english and german, but not yet for french. a contribution of the corpus annotation performed in this study is that it allowed us to gather some of these terms. a comprehensive set of terms for imaging signs should help to normalize clinical reporting and indexing and improve the power of nlp tools to understand the content of narrative radiology reports.

comparison to other work
a similar study which aimed to identify exams ordered to rule out pe and then access and review the characteristics of the resulting exam was conducted by chapman et al.  <cit> . they developed a text processing application using pycontext annotations to perform rule-based classification of cta reports in english and achieved a precision of  <dig>  and a recall of  <dig>  for pulmonary embolism, which is comparable with our recall of  <dig>  but less than our precision of  <dig> .

along with the context of incidentaloma, two studies addressed the automatic identification of clinically important follow-up recommendations from radiology reports in english  <cit> . yetisgen-yildiz et al.  <cit>  used a maxent algorithm and measured the impact of data imbalance between positive and negative classes and several feature types: unigram, ngram, syntactic, knowledge-based, and finally structural features. the latter highlighted the potential importance of section header information in the classification decision. in our model, we also focused our classification processing on specific sections. their best achieved f-score was  <dig> , with precision of  <dig>  and recall of  <dig> . dutta et al.  <cit>  undertook a prospective study on automatically identifying incidental clinically important follow-up recommendations on a larger corpus  using an nlp algorithm based on keywords.

limitations of this study
a limitation of this study lies with the corpus selection. the refined query used to perform the final corpus selection only achieves 61% recall on a test sample of  <dig> documents. while the content of the relevant reports that were not selected  did not look different from those that were selected, a bias may remain. it can also be noted that the proportion of documents selected by the query on the test sample  is higher than overall . however, overall, the refined query achieved our goal of retrieving 100% of reports corresponding to cta and ctv prescribed in the context of pe. furthermore, the distribution of reports in the corpus was 22% pe, and 18% dvt, which did not differ significantly from the expected distribution from the literature, respectively  <dig> % and 15%  <cit> . in future work, we will be able to leverage the whole set of ehr data  from the data warehouse.

due to time constraints, we performed a “light annotation” of the  <dig> health records in the study corpus. while these “light” annotations proved to be useful features for the automatic classification of the radiology reports, in order to fully automate the classification process, we need to generate the annotations for concepts, modalities and relations automatically. the annotated corpus produced in this study is a valuable resource that we will use in future work for developing appropriate statistical annotation models. error analysis will also be performed on a larger and richer data set.

CONCLUSIONS
electronic health records are becoming increasingly prevalent in hospitals. as much of the clinical data is available in free-text format, processing clinical narratives has become a major challenge and an enabling technology for improving clinical research and patient care. our project shows that nlp can be useful to carry out a large-scale retrospective study in the field of thromboembolic diseases. our project provides automatic classification of reports that is not possible to obtain from the coding of patient records. in future work, we want to develop an end-to-end automatic system that can automatically annotate the reports as well as perform classification. we also plan to extend our project on incidental findings. indeed, the identification of potentially serious incidental finding is by no means limited to cta in the context of pe. developing a text processing pipeline for identifying incidental findings for epidemiological surveillance would help clinicians clinically examine their use of new imaging techniques.

abbreviations
nlpnatural language processing

ctcomputed tomography

ctacomputed tomography angiography

ctvcomputed tomography venography

pepulmonary embolism

dvtdeep vein thrombosis

hegphôpital européen georges pompidou

iaainter-annotator agreement.

competing interests

the authors declare that they have no competing interests.

authors’ contributions

adp carried out the extraction, selection, manual de-identification and annotation processes, participated in the formatting of the reports, the automatic classification and the evaluation of the classifier. an participated in the design of the study, supervised and helped in the de-identification and the annotation process, carried out the formatting of the reports, the automatic classification and the evaluation of the classifier. tl helped in the formatting of the reports and participated in the automatic classification and the evaluation of the classifier. dy helped in the identification of the incidentaloma from the radiology reports. oc and gm participated in the conception of the study and provided the corpus. rm participated in the methodological design of the study. ab conceived the study, carried out its design and coordination. all authors read and approved the final manuscript.

