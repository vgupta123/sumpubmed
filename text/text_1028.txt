BACKGROUND
in the design, analysis and interpretation of experiments, biomedical and clinical
researchers encounter the problem of evaluating and summarizing prior knowledge on
the subject under investigation. traditional solutions include examining articles in
scientific journals, primarily via pubmed access to medline, and interrogating
www-based sources such as entrez gene  <cit>  and online mendelian inheritance in man   <cit> . consider a scenario in which a researcher seeks enhanced knowledge about
a protein implicated in aging. typically, the steps involved in addressing this
problem include interrogating structured data resources: searching protein sequence
databases to identify homologs in other species, querying warehouses of genomic
information to determine key non-coding regions and polymorphisms, examining
collections of high-throughput molecular profiling data sets to ascertain genes with
similar patterns of expression, probing ontologies such as the gene ontology   <cit>  to uncover other genes with similar patterns of annotation, and so on.
the entire procedure is accompanied by examination of the literature to determine,
for example, classes of proteins mentioned in the same article as the putative
gerontogene.

advanced techniques and sophisticated tools for interacting with structured data are
well known, widely available and include blast  <cit>  for sequence databases, ensembl  <cit>  and the ucsc browser  <cit>  for genomes, geo  <cit>  for transcript profiles, and tools available from the go that allow
navigation of terms in the ontology. this is less true for the scientific
literature. given the time-consuming yet critical importance of synthesizing
information in text corpora such as medline, the problem of making data
interpretation a more systematic and automated endeavor is emerging as an important
topic of research . the development of strategies capable of providing a user the ability
to assimilate and act upon information present in resources of structured and
unstructured data remains an important goal.

the primary aim of biomedical text mining is the systematic analysis of document
collections such as medline abstracts and full-text journal articles with the goal
of generating useful and unanticipated scientific discoveries . examples of tasks addressed by text mining methods include identifying
literature relevant to specific molecules, finding associations between genes and
diseases, determining putative functions for proteins, and predicting regulatory
networks.

a common approach to text mining is to treat the problem as one of natural language
processing   <cit> . nlp methods concentrate on the linguistic structure of documents and
make explicit use of syntactic, relational, and ontological knowledge. in biology,
such approaches  <cit>  have been employed for information extraction: the task of ascertaining
facts, relations, and entities in unstructured written language such as
protein-protein interactions, protein subcellular location, and gene names. tools
based on these ideas include textpresso  <cit>  and telemakus  <cit> . elsewhere, nlp has been used in conjunction with locuslink and go to
compare omim to medline  <cit> .

recently, nouns extracted from medline abstracts tagged with parts of speech were
combined with knowledge from other sources, principal component analysis, and means
linkage clustering to find associations between genes and phenotypes  <cit> . in general, nlp can be effective in circumscribed domains where
linguistic knowledge is available and the terminology evolves slowly, is consistent,
largely unambiguous, and relatively simple. however, the paucity and incomplete
nature of such information for biomedical corpora suggests that the full potential
of text mining in biology remains unrealized.

an alternative to nlp is to frame the problem from the perspective of information
retrieval   <cit> . statistical ir methods explore large quantities of information and often
involve capabilities for clustering, classifying, categorizing, summarizing, and
detecting novel, similar and relevant objects. the most successful testaments to the
real-world utility of ir techniques are internet search engines. thus, statistical
ir models of biological document collections could reveal rich, complex, and
previously unappreciated relationships. such results would complement insights
derived from analysis of molecular profiling, protein-protein interaction, gene
knock-out, and similar types of data. with systematic deployment of ir tools, the
interrogation of biomedical corpora could become as routine and indispensable a part
of research as analyzing genomic and genetic data is today. the analogy is more than
superficial and extends to the direct use of ir techniques such as singular value
decomposition in bioinformatics . thus, the common mathematical foundations for algorithms that underpin
ir and genome analysis make it possible to envision integrated procedures that
combine primary biological data with biological corpora.

this work describes an application of statistical ir methodology to the analysis of a
biomedical text corpus, the caenorhabditis genetic center 
bibliography . the specific model at the heart of
this study is the latent dirichlet allocation  model  <cit> , a hierarchical bayesian model employed previously to analyze text
corpora and to annotate images  <cit> . recently, lda has been used to extract and analyze the topics present in
a document corpus consisting of articles published in the journal proceedings of
the national academy of sciences  <cit> .
form.

in general, ir methods assume that the order of words in a document can be neglected
and view documents as "bags of words." the loss of information incurred by ignoring
word order is offset by the ability to devise efficient computational algorithms
that are viable for large corpora. although there is no theoretical justification
for casting a document in this manner, the practical benefits and utility of doing
so are considerable. the lda model considered here is a model for a corpus viewed as
a collection of bags of words. it assumes that each word of each document is
generated by one of several "topics"; each topic is associated with a different
conditional distribution over a fixed vocabulary. the same set of topics is used to
generate the entire set of documents in a collection but each document reflects
these topics with different relative proportions. thus, lda is a mixture of mixtures
model, i.e., the mixture components are shared across all documents but
each document exhibits different mixture proportions. as a generative probabilistic
model, the lda can handle unseen or novel data, i.e., a document that was
not one of the bag of words used to estimate the model.

the fundamental entities in lda, random variables representing topics and words, are
grouped together in such a way to form a corpus, i.e., a group of groups of
words. the hierarchical nature of the model stems from the fact that documents are
modeled as probability distributions across topics, and topics are modeled as
probability distributions across words. a notable virtue of lda is that a given
topic can occur with high probability in multiple documents, and that a given word
can occur with high probability in multiple topics. topics are treated as latent
variables, namely entities that are not present explicitly in the data , but are presumed to be present implicitly and are to be
inferred by statistical analysis.

to analyze the cgc bibliography, each item in the corpus was recast as a bag of words
and the resultant data set of documents was used to estimate the parameters of three
different statistical ir models. the predictive performance of the lda model was
better than that of two simpler bag of words models, a unigram model and a mixture
of unigrams model, trained on the same data set. the potential of lda in assisting
biological studies was illustrated by considering the phenomenon of nematode aging.
in order to illuminate the hidden factors permeating a corpus and captured by the
topics discovered by a trained cgc lda model, lda topics were labeled via an
automated process that assigned words from the cgc vocabulary 
and go terms  to each topic. examination of these labels
indicated that the cgc topics captured meaningful and plausible facets of nematode
biology. to investigate aging, topics whose corpus-based labels included many cgc
words corresponding to the names of genes known to influence life span were
identified. for the two topics with the greatest number of such cgc-based topic
labels, novel candidates for age-related genes were equated with other cgc-based
topic labels that corresponded to gene names . finally, an
lda-based measure of pairwise document similarity was devised and used to address
the problem of searching a database of documents to determine topic-space homologs
of a query document. inspection of the "document homologs" of the cgc item shown inthe clk- <dig> gene.

this work highlights the potential and utility of lda in organizing and exploiting
one type of widely available information resource, a collection of documents in the
form of free or unstructured text. however, researchers are faced with a plethora of
resources including images and structured data such as molecular sequences,
transcript profiles, disease information, and so on. thus, there is a compelling
need for techniques and systems able to condense, integrate and present large
amounts of disparate data to a user. this paper concludes with a discussion of how
the family of probabilistic graphical models, of which lda is a specific example,
provides a framework for integrating heterogeneous data and thus meets this
challenge.

RESULTS
lda outperforms mixture of unigrams, unigram and random models
in order to compare different models of text, a data set of c. elegans
related documents was created. in particular, each cgc bibliography
free-text item was transformed into a bag of words yielding a corpus of m
=  <dig>   <dig> documents and a v =  <dig>   <dig> word vocabulary.

the generalization performance of three statistical models was assessed: an lda
model , a mixture of unigrams model , and a "baseline" unigram model . a model was trained using 90% of the  <dig> 
documents in the cgc corpus and tested on the remaining 10%. lda and mixture of
unigrams models with k =  <dig>   <dig>   <dig>   <dig>  and  <dig> latent topics were
estimated; a single unigram model was estimated because such models harbor no
notion of topic. the perplexity  of the
held-out test set of j =  <dig> documents  was computed for
each trained model. figure  <dig> shows the generalization
performance of each model as a function of the number of latent topics. lda has
consistently smaller perplexity scores than the two extant models indicating
better performance on unseen documents. since the perplexity of 50- and
100-topic lda's is low and similar, a latent space with  <dig> topics appears to
provide a parsimonious description of the cgc corpus.
variational distribution used to approximate the posterior in lda
  <cit> . lda defines a distribution on a collection of documents in
much the same manner that a profile hidden markov model yields a
distribution on a set of  sequences  <cit> . the corpus
depicted contains m documents and each is a sequence of n
words. open circles are parameters  or latent
variables . the shaded circle is the
observed word variable  and boxes  represent
replicates. the dirichlet parameter, α, and topic-word
matrix, β, are corpus-level parameters sampled once in the
process of generating a corpus. the topic proportions, θ,
is a document-level variable sampled from αonce per document.
the topic, z, is a word-level variable sampled from θ
once for each word in a document. formally, a k-topic lda
specifies a two-level probabilistic process that generates a document as
follows,  a k-dimensional vector, θ, is chosen
from the distribution p, and  words
are sampled repeatedly from the document-specific mixture distribution,
p. exact inference and parameter
estimation involve calculating the posterior distribution on a document
p. this is intractable because the latent variables are
coupled via the edge between θ and z. the
posterior can be approximated by computing the variational dirichlet
parameter γ and the variational multinomial parameter
φ for each word in the document. the subscripts
m, n, and k on a parameter  or variable 
donate the m th document, nth word and kth topic
respectively. note that the dirichlet variable α is a
distinct component of the probability model and not merely an expression
of uncertainty about a parameter. this differs from profile hidden
markov models where a mixture of dirichlet distributions is used as a
prior for amino acid/nucleotide probability distributions.
latent topics  and a unigram model . the corpus
depicted contains m documents and each is a sequence of n
words. open circles represent latent variables or
parameters . each shaded circle is an
observed word variable . boxes  represent
replicates. the subscripts m, n abd k on a
parameter  or variable  donate
the mth document, nth word and kth topic respectively.a mixture of
unigrams generates all the words in a given document from exactly one
topic, z. this differs from the lda model where a single
document can express multiple topics . note that the naive
bayes model used to cluster transcript profiling data  <cit>  has the
same topology as the mixture of unigrams but the observed variables are
continuous-valued expression measurements rather than discrete
words.
and evaluated on the cgc corpus. the score of test documents is shown
against the number of latent topics .

the ability of three specific models to retrieve a set of  <dig> aging-related
documents in the collection of  <dig>  cgc documents was assessed: a 50-topic lda
model estimated using all documents in the corpus, a 50-topic mixture of
unigrams model estimated using all documents, and a model which ordered all
documents randomly. for each model, an average precision/recall  curve was
constructed by computing the ranking of other documents given each aging-related
document as a query, and the average f <dig> measure was computed. figure  <dig> shows average pr curves for the three models. the average
f <dig> measure  for the lda model, the mixture of unigrams model and
a random model is  <dig> ,  <dig> , and  <dig>  respectively. although the f <dig> values
for the lda and random models are similar, the smaller standard error of the lda
model indicates its superiority to the random model. in addition, the average pr
curves indicate that the lda places more of the age-related documents higher up
its rankings than the random model. thus, of the three models investigated, lda
is best able to retrieve the set of related documents. overfitting by the
mixture of unigrams model results in a performance worse than the random
model.
documents . precision is the fraction of documents in a list that are
relevant  whereas recall is the fraction of relevant
documents in the list. for a desired level of recall, for example 70%,
there is a corresponding precision. the graph shows average precision
against average recall. although each point is a mean of  <dig> pairs of
precision and recall values, the standard error is negligible and so not
depicted.

all subsequent discussion of an lda model and/or a mixture of unigrams model
pertain to a k =  <dig> topic model estimated using all m =  <dig>  225
cgc documents in the corpus.

lda latent topics embody concepts associated with nematode biology
a systematic strategy for clarifying the nature of the hidden factors permeating
a corpus was devised and applied to a cgc lda. topic annotation 
is defined as an automated process that creates a verbose  description
of an lda topic. the method designed to annotate and label topics exploited the
corpus-level parameter β . the
k × v topic-word matrix β collates the
multinomial distributions over the v words in the vocabulary that
characterize the k topics. for a given lda model of a particular
corpus, the kth row specifies the topic-specific word distribution for
topic k and an element, βkv, denotes
the likelihood of the vth word given the kth topic. for each
of the k =  <dig> topics in the cgc lda model, the v =  <dig>  971
βkv values were ordered and used to
generate a word rank versus topic-specific word probability plot. in every case,
the  <dig> top-ranked words accounted for most of the probability mass. thus, these
 <dig> high probability cgc words were designated topic annotation words .

two different approaches were used to create labels for each topic. corpus-based
topic labels are topic annotation words that are unique to a topic and represent
descriptors applicable to only one topic. cgc-based topic labels were equated
with topic annotation words that were not assigned to any of the other 49
topics, i.e., the  <dig> sets of cgc-based topic labels formed disjoint
subsets of words from the cgc vocabulary. ontology-based topic labels are the
outcome of filtering topic annotation words using an external knowledge source
and represent descriptors applicable to one or more topic. the ontology
exploited here was the go. the relationship between go controlled vocabulary
terms can be depicted as a directed acyclic graph . each node corresponds
to a term from one of three aspects, for example, "exodeoxyribonuclease,"
"mitochondrial derivative" and "ethylene mediated signaling pathway" are
exemplars of go terms from the "molecular function," "cellular component" and
"biological function" aspects respectively. the structure of the dag
underpinning the go vocabulary defines semantic relationships amongst terms so
that, for example, the node for the go term "intracellular" is a parent of the
node for the more specific go term "nucleus." recall that the topic annotation
words for topic k are the  <dig> words from the cgc vocabulary that best
characterize the topic. these  <dig> words were mapped to nodes in the go dag. a
node where a topic annotation word coincided with a go term was designated an
explicit node. go-based topic labels were equated with the go terms for both
explicit nodes and the children and grandchildren of explicit nodes.

examination of the automatically generated cgc- and go-based labels suggests that
lda topics capture meaningful and coherent facets of the molecular, cellular,
and behavioral biology of c. elegans. figure 6
shows results for four selected cgc topics . the hidden factors
permeating the cgc corpus include one pertaining to sexual reproduction , chromosome structure and function , cell death  and
locomotion .
lda model estimated from a corpus with  <dig>  documents and a vocabulary
of  <dig>  words. each panel shows results for a particular topic. the
y-axis of the graph is topic-specific word probability
and words are arranged along
the x-axis according to this likelihood. only the  <dig> topic
annotation words are plotted since the remaining words in the vocabulary
have negligible probabilities. the words displayed explicitly are
unigrams in the cgc vocabulary, including the names of c. elegans
genes, and go terms. the position of a word along the
x-axis represents its rank; the staggering of words along the
y-axis is not significant and is designed only to improve
legibility. the graph legend lists two types of automatically-generated
topic labels. cgc-based topic labels are a subset of the  <dig> × 500
topic annotation words that are unique to a topic and are words from the
cgc vocabulary; these labels are ordered according to decreasing
βkv values. go-based topic labels
are the parents and grandparents go terms of go terms that are also
topic annotation words. only go terms that occur four or more times are
given and are listed in decreasing frequency . a cgc-based label is
unique to a topic whereas a go-based label can be applied to one or more
topic.

ontology-based topic labels derived from structured knowledge for domains other
than molecular and cellular biology are needed to clarify the nature of some cgc
hidden factors. figure  <dig> shows topics that have cgg- but
no go-based labels. inspection of the cgc-based labels for topics  <dig>   <dig>   <dig>  and
 <dig> suggest the presence of hidden factors that are concerned with scientific
protocols and procedures that are independent of any biological question, and
that allude to evolution.
factors in the cgc corpus that pertain to the practical aspects of
investigating biological mechanisms and processes. topics are
represented in the same manner as in figure  <dig> 

interrogation of lda topics provides insights into genes influencing life
span
a guilt-by-association approach was devised to identify genes that may be
involved in a phenomenon of interest and the procedure illustrated using genes
implicated in modifying life span. a "gene word" is a word in the  <dig>  word
cgc vocabulary that corresponds to the name of a c. elegans gene.
cgc-based topic labels are the ≤  <dig> words in the vocabulary that best
characterize a topic. if a number of the topic labels are gene words and most of
the genes are known to be associated with a specific phenomenon, then the other
gene words can be equated with genes likely to be involved in the same
phenomenon. one factor influencing the biological insights that can be derived
from this approach is the human curation component of the process used to create
the cgc bibliography, i.e., the individual who defined the set of genes
in the genes record believed to be discussed in the abstract record. in addition
to limitations in the data used to estimate a statistical model of text, the lda
remains a model based on the simple bag of words representation of a document.
while this lda-based approach is not an automated method for formulating
sophisticated and detailed hypotheses, it does highlight how a model that
ignores syntax and semantics can organize information in a manner that provides
a user the ability to exploit their background knowledge and enhance
understanding of the subject in hand.
life span and designated aging-related gene words. inspection of the two cgc lda
topics with the greatest number of cgc-based labels that are aging-related gene
words suggests that akt- <dig>  akt- <dig> and ges- <dig> may be associated
with aging. figure  <dig> shows these two topics, topic  <dig> and
topic  <dig>  in decreasing topic-specific word probability and with genes listed ingene words are age- <dig>  clk- <dig>  mev- <dig>  daf- <dig>  fer- <dig>  clk- <dig>  gro- <dig> 
daf- <dig>  akt- <dig>  akt- <dig>  clk- <dig>  pdk- <dig>  rad- <dig>  sod- <dig>  old- <dig>  ctl- <dig>  tkr- <dig> 
daf- <dig>  sod- <dig>  sir- <dig>  daf- <dig>  cln- <dig>  ins- <dig>  age- <dig>  and
spe- <dig>  the genes depicted in a normal font have properties similar
to known life span modifying genes such as dauer  phenotypes . for example, the wormbase  <cit>  annotations for akt- <dig> and akt- <dig> include "protein
serine/threonine kinase" and "inhibition of both akt- <dig> and akt- <dig> leads to
dauer-constitutive phenotype."
words . each topic is represented the same
manner as figure  <dig>  in the graph, words in bold are the gerontogenes
listed in table  <dig> 
is taken from the genes database of sageke
http://www.sageke.org

the mechanisms of action of putative gerontogenes suggested by different topics
may not be identical. for topic  <dig>  the cgc-based labels that are gene words are
ges- <dig>  osm- <dig>  osm- <dig>  che- <dig>  osm- <dig>  lov- <dig>  pkd- <dig>  daf- <dig>  che- <dig> 
unc- <dig>  che- <dig>  che- <dig>  osm- <dig>  che- <dig>  che- <dig>  pho- <dig>  dyf- <dig>  che- <dig>  and
pkd- <dig>  ges- <dig> is a gut-specific carboxylesterase, a molecular function
not ascribed by wormbase to life span modifying genes. since many topic labels
are associated with the osm phenotype, osmoregulation may be a feature that
differentiates topic  <dig> aging-related genes from those of topic  <dig> 

exhibition of multiple latent topics by an lda document reflects the
complexity of issues discussed in documents
by virtue of its superior generalization performance and retrieval ability, an
lda model of the cgc corpus is a better statistical model of text than a mixture
of unigrams model. a distinct advantage of lda is that although both models are
generative, an lda document is the manifestation of many topics whereas a
mixture of unigrams document is the product of only one topic. the subject
matter of  documents is rarely limited to a single area so the
benefit of a cgc lda is that words in a single document could come from, for
example, a combination of topic  <dig>  and topic  <dig> . the mixing of lda topics in a cgc item was investigated
by examining the document-specific, word-level parameter φ . the variational posterior topic probability
φn indicates the extent to which the nth word is associated
with the kth topic. a value that is both large and significant is an
indicator of the topic most likely to have generated the word.

the cgc item shown in figure  <dig> is primarily a mixture of
two topics. figure  <dig> shows the topics most likely to have
produced words in the document discussing the life span modifying clk-2
gene . of the assigned words,  <dig> have
posterior probabilities peaked on the aging-related topic  <dig>  and  <dig> on the general purpose topic  <dig> . three words are allocated to topic  <dig>  two to topic  <dig> 
two to topic  <dig>  and one to topic  <dig> 
 <dig>  a word is identified with the topic k given in parenthesis
when the document-specific, variational posterior topic probability
exceeds a threshold,
φn >  <dig> . as illustrated by "telomere ", identical words
within a document are generated by the same topic. note that only the
title, genes and abstract records were concatenated and processed to
generate the bag-of-words document used to estimate the lda.

utility of lda in formulating hypotheses: insights into clk- <dig> function
searching a document database to identify homologs of a query document yields
insights that can complement those obtained from sequence-, structure- and
function-based analysis of genes and proteins. prior studies of clk-2
revealed that it encodes a sequence homolog of tel <dig>  a protein required for
normal telomere length regulation in yeast . to enhance knowledge of how clk- <dig> might influence life
span, homologs of a document discussing clk- <dig>  were identified by computing the topic-space pairwise similarity
score between this query q and every cgc document t . although a given gene may appear in the genes record of many cgc
items, the results described below are based on analysis of document homologs of
the single cgc item shown in figure  <dig>  figure  <dig> shows the three most related items, cgc documents with
the three largest  values. figure  <dig> shows the three topics most associated with them. the third best
homolog is relatively uninformative: the text indicates a general review of
aging mutants and topic  <dig> labels are general words pertaining to life span.
clk- <dig> item is used as the query document, the three items
shown have the largest topic-space pairwise similarity scores,
. the documents are
depicted in the same format as figure  <dig>  as illustrated by "elegans"
and "elegans" in the first and second top-ranked documents,
identical words may be attributed to different topics in different
documents.
the clk- <dig> query shown in figure  <dig> 

lda-based analysis leads to the hypothesis that clk- <dig> may have a role in
coordinating signals between the outside and inside of cells. since the top two
topic-space document homologs discuss nuclear receptors, clk- <dig> may have
a direct or indirect involvement in receptor biology. topics  <dig> and  <dig> include
the go-derived labels "host cell plasma membrane," "regulation of fgf receptor
signaling pathway" and "regulation of beta  <dig> integrin biosynthesis."
circumstantial evidence supports a possible role for clk- <dig> in signal
transduction and tissue biology. fgf- <dig> regulates telomerase activity in human
endothelial cells  <cit> . integrins are cell surface receptors important in communication
between the extracellular environment and the nucleus  <cit> . the suggestion that clk- <dig> may influence telomere length via
a mechanism not involving direct physical association with telomeres is
plausible since a recent genome-wide screen for saccharomyces cerevisiae
deletion mutants that affect telomere length identified genes with very
diverse functions   <cit> . recent experimental results support a connection between vacuolar
protein-sorting genes and telomere length homeostasis  <cit> .

discussion
this study demonstrates how a specific statistical ir model, an lda model, can be
employed to infer the hidden factors permeating a biomedical text corpus and
exploited to synthesize and organize information about complex biological phenomena.
the results indicate that despite being estimated from a simple bag of words
representation of items in the cgc bibliography, the intra-document statistical
structure captured by an lda model is sufficient for the model to be used to enhance
understanding of c. elegans biology. for example, analysis of the corpus-,
document- and word-level parameters of a trained lda model enabled the exploration
and creation of hypotheses about known and putative nematode aging-related
genes.

the cgc corpus studied here had m =  <dig>   <dig> documents and a v =  <dig> 
 <dig> word vocabulary. estimating a 50-topic lda model from such training data took 3
hours on a macintosh powerbook g <dig>  it should be straightforward to estimate a model
for larger corpora such as medline where the number of documents is many orders of
magnitude greater  and the vocabulary size is only one
order of magnitude larger . in estimating an lda, the
computational bottleneck is the variational e-step, i.e., computing the
posterior topic dirichlet distribution for each document. fortunately, this
procedure can be parallelized because given a model, the posterior for each document
can be assessed independently. thus, it is feasible for the techniques described in
this study to be applied to other corpora and to address questions other than life
span modification.

from an applications perspective, it is possible to envisage a scenario involving the
creation of a library of lda models where each constituent model was estimated from
a user- and/or computationally-defined corpus of documents focused on a specific
area such as "aging," "cancer," "yeast biology," "response to stress,"
"antibiotics," "hiv," "parkinson's disease," "kinases," and so on. a query document
would be compared to each subject-specific lda in the collection as opposed to a
single model as described here. this approach seeks to mirror a common strategy in
sequence analysis whereby a query sequence is rated against a library of hidden
markov models   <cit>  estimated for domains of interest, for example, the pfam database of
protein families  <cit> . since seaching a database of probabilistic models of proteins in order
to identify "remote" sequence homologs is known to be effective, an analogous
approach could prove useful in retrieving distant document homologs.

the ideas discussed in this work can be extended and improved in a variety of ways.
currently, the number of latent topics in an lda model k is a user-defined
parameter but recent research has examined the task of choosing k  <cit> . in particular, if the lda is augmented with a non-parametric bayesian
prior known as a hierarchical dirichlet process, both topic probabilities and the
number of topics can be estimated from data. under the hierarchical dirichlet
process prior, the number of topics grows as data are added to a collection  <cit> . the significance and practical importance of this feature
is that when modeling scientific documents, the nature and size of the corpus is
evolving constantly meaning that discovering topics is an ongoing task. further
studies are required to devise rigorous methods for determining a set of words best
able to characterize a topic: the current approach is somewhat arbitary in that
corpus-based topic labels were defined as the  <dig> words in cgc vocabulary with the
highest values for the likelihood of the word given the topic.

in the lda model, topics represent entities that are presumed to permeate a corpus
and these latent variables are to be inferred by statistical analysis. these
implicit concepts are assumed to be equally related to one another, i.e.,
the topics are not organized in any way and form a "flat structure." it seems
reasonble to believe that, for example, topics embodying the concepts of "dna
repair" and "chromosome structure and function" should be more related to each other
than to a topic focused on "locomotion." thus, a model in which topics were
themselves arranged as a hierarchy could prove useful and inspection of the
relationship between topics might be informative. the current lda model
represents a model for a particular instantiation of a corpus. it might be
interesting to formulate dynamic models of corpora which sought to capture how a
collection such as the cgc or medline changes over time. in addition to theoretical
studies of their properties and behavior, such models might be useful not only for
biomedical researchers and clinicians, but also policy makers, historians, and
sociologists interested in the evolution of biology and its disciplines.

statistical ir models are applicable not only to "traditional" document collections,
but also to genome-scale biological data. in one example of such an lda model,
"documents" could correspond to genes, "topics" to regulatory networks and "words"
to motifs. since lda does not require mutually exclusive clustering, a given gene
can participate in several networks and a given motif can appear in several genes.
merging this type of analysis with that described here would result in evidential
support for the functional behavior and role of a gene being derived both from
primary biological data and from corpus-based analysis. this capacity to fuse
support from disparate sources has been illustrated using a variant of lda known as
"correspondence lda" and in the context of automated image annotation  <cit> .

CONCLUSIONS
lda is a special case of the family of probabilistic graphical models. this family
includes a wide variety of other models that have proved useful in biology such as
hmms, phylogenetic trees, and pedigrees  <cit> . the graphical model formalism allows such graphical components to be
combined into heterogenous, large-scale statistical models that integrate evidence
from multiple sources. doing so would yield a system for facilitating the
formulation of ideas that could be interrogated and verified experimentally.

