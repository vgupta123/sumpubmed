BACKGROUND
the explosive growth in the number of sequenced proteins has created a glut of proteins that are sequenced but whose structure and function are as yet unknown. a common way to tackle this problem is to use database searches to find proteins similar to a newly discovered protein, thus inferring protein function. this method is generalized by protein clustering or classification where databases of proteins are organized into groups or families in a manner that attempts to capture protein similarity. such classification into families is a critical component in structural and functional genomics  <cit> . the number of protein families comprising the entire protein-space has been conjectured to range between  <dig> - <dig> , excluding rare and peculiar single proteins  <cit> . various expert-based databases provide a good description of certain selected families but are limited in scope to thoroughly studied proteins . other methods for classification strongly rely on 3d-structural information as in the case of scop  <cit> , cath  <cit> , fssp  <cit>  and others.

classifying the entire protein space into families serves not only as a method for large-scale protein annotations but also to support functional and structural genomic initiatives  <cit> . some prominent examples for protein classification efforts are protomap  <cit> , picasso  <cit> , systers  <cit> , iproclass  <cit>  and protonet  <cit> . these systems are based on a variety of algorithmic paradigms, each yielding a distinct hierarchical classification of proteins into families.

amongst the clustering methods listed above only protonet attempts to generate a global hierarchical arrangement of the entire protein space via agglomerative hierarchical clustering. the sequence similarity between every pair of protein sequences is taken as the blast  <cit>  e-value between a given pair of proteins. next, the proteins are clustered using a given merging strategy. the strategy used is unweighted pair group with arithmetic mean , whereby in each iteration, the two most similar clusters  are merged. protonet   <cit>  provides a classification hierarchy of over  <dig> , <dig> proteins including the swissprot and trembl protein databases  <cit> . most proteins included in the swissprot database are manually validated and furthermore, the degree of biological knowledge associated with them is much higher in comparison to the proteins archived in trembl. thus, this work concerns only the  <dig>  proteins in the swissprot database . an extended version that includes over one million protein sequences is available in the form of an interactive website at . for the swissprot-based tree, there are  <dig>  clusters . the classification provided by protonet provides the full range of cluster granularity: from single proteins to huge protein clusters that carry no biological relevance . we test the biological validity of protonet, by its examination from different perspectives, using external-defined protein keyword annotations. four different annotation sources are used  in order to be able to validate different biological aspects. first, we demonstrate that it is possible to match the majority of such external-defined protein families to specific clusters within the protonet clustering. second, we show that the hierarchy of the protonet tree represents a valid functional hierarchy and correlates well with the go hierarchical structure.

as mentioned, protonet contains  <dig>  clusters, which is obviously much more than the upper estimate of  <dig>  protein families  <cit> . therefore, we seek to cleverly discard those clusters that have less biological relevance. compression of the protein space offers many advantages. it can yield a smaller set of biologically meaningful clusters, which will allow for a more manageable handling of the entire protein space. furthermore, if this compression's correspondence to external, independent annotation sources can be validated, then this compression can be used to replace the original hierarchical structure, without sacrificing much information originally present in the whole system.

in this paper we describe methods for the unsupervised compression of the protonet tree, by using intrinsic tree-based parameters of the clusters that correlate well with biological validity. by preserving the unsupervised nature of the protonet data, we prevent biasing towards previously discovered findings and better allow for future generalizations, in addition to maintaining the automation of the process.

finally, automatic functional annotation to proteins is of great importance. in protonet, an automatic method for assignment of biological annotation to the protein clusters is used, yielding high-confidence functional assignments for a large majority of the proteins' clusters.

RESULTS
correspondence of clusters to external biological sources
in order to measure the correspondence between a given cluster and a specific annotation, and allow for supervised validation of the protonet clusters, we define the notion of a correspondence score . the cs for a certain cluster and a given keyword measures the correlation between the cluster and the keyword, using the well-known intersect-union ratio.

let c be a cluster in the protonet tree, and k be a keyword  that annotates  the proteins in the system; let c be the set of annotated proteins in cluster c; let k be the set of proteins in the system annotated by keyword k; we define:



the cluster receiving the maximal score for keyword k is considered the cluster that best represents k within the protonet tree . the score for a given cluster on keyword k ranges from  <dig>  to  <dig> .

in order to assess the clustering's biological validity, the mean best cs on all annotations was examined for each of the following sources: interpro, scop , go  and enzyme . the results  show a high level of correspondence between the protonet clusters to the various keyword sets of each of the external sources.

it can be argued that a good fit between a set of keywords and the protonet set of protein clusters could happen by chance. in order to assess the statistical significance of these results, the mappings of the keywords to the proteins were randomized, creating a new group of random keyword sets that have the same size distribution but do not represent any biological features. for each random keyword set, the mean best cs was calculated. this randomized test showed a normal distribution, allowing the calculation of an approximate p-value for the mean best cs obtained by protonet for the external sources. the results showed an extremely high level of statistical significance for all sources . note that even for the scop fold level, which is associated with proteins that may be extremely remote in sequence, protonet's relative success is extremely high .

to avoid trivial correspondences between a keyword and a cluster, such as the assignment of a keyword that annotates only one protein to its singleton cluster, we tested our success only with keywords that annotated at least two proteins . for interpro and go, we selected a threshold of  <dig> proteins per keyword, as the majority  of the annotations is included above this threshold, thus allowing the test to focus on the more significant keywords.

correspondence of protonet hierarchy to external biological sources
in order to validate the hierarchical structure of protonet, we compare it with the hierarchical structure of go as described in figure  <dig>  to do this, we select, for each go term, the best matching cluster in protonet according to the cs. the subset of all terms that have highly matching clusters  was selected. in graph-theoretic terminology, this set of terms can be represented as vertices in a graph. we consider two possible sets of directed edges between the vertices: those defined by go as the parent-child relationship of the clusters' respective terms, and those of the protonet hierarchy. thus we wish to compare these two sets of graph edges. we use a very conservative test, counting the number of edges that are common to both graphs.

a total of  <dig> go terms were selected as described, with  <dig> edges between them according to the go hierarchy.  <dig> out of  <dig>  edges that were produced by the protonet hierarchy appear in the go hierarchy. this number is highly significant considering the fact that there exist over  <dig> , <dig> possible edges between the  <dig> vertices in the graph . it should be noted that there are some terms in go that are connected to many other vertices. these vertices may bias the results of this test. in order to confirm that protonet performs well without these vertices as well, the vertices were removed manually and the test was repeated, with similarly significant results .

compression by using an intrinsic parameter
in order to allow unsupervised automatic compression of the protonet tree, we searched for an intrinsic parameter of the clustering process that would specify clusters of biological validity. by applying such a parameter one could dispose of clusters that do not pass a certain threshold value, remaining with clusters of high biological validity. once we remain with a subset of biologically valid clusters, the new hierarchy amongst them can be reconstructed according to the original tree hierarchy.

the agglomerative hierarchical clustering scheme defines a set of terms that are intrinsically associated with the process. in such a scheme, each cluster is created from smaller clusters, which are captured as its descendants in the clustering tree. the protolevel  ranges from 0- <dig> and is used as a standard quantitative measure of the relative height of a cluster in the merging tree. the pl of a cluster is defined as the arithmetic average of the blast e-score of the pairs of its proteins. the pl of the leaves of the tree is defined as  <dig>  whereas the pl of a root equals  <dig>  the larger the pl, the later the merging that created the cluster took place. therefore, the pl scale is considered as an internal monotonic timer of merging, during the clustering process. as mentioned above, a cluster is said to be created when the merging of its two children clusters forms it. the pl at this point is said to be the birthtime of this cluster. the deathtime of a cluster is defined as the pl at its termination, i.e. the point at which it merges into its parent cluster . the lifetime  of a cluster is defined as:

lt = deathtime - birthtime

therefore, the lt of a cluster reflects its remoteness from the clusters in its "vicinity" in protein sequence space.

we examined the lt distribution of the set of interpro best clusters in comparison with the lt distribution of all clusters in protonet . the results suggest that the best clusters have a substantially higher lt than other protonet clusters. this poses the lt as a possible candidate that could allow a biologically-valid tree compression by disposing of all clusters with lt below a certain threshold value.

in order to search for a reasonable lt threshold value , several threshold values were examined . the results show that by using a lt threshold for cluster elimination, in addition to removing the singleton clusters,  <dig> % of the clusters may be eliminated with only a minimal reduction in performance , leaving only  <dig>  clusters. furthermore, we compare the lt threshold scheme with a random elimination of similar amounts of clusters. the lt threshold convincingly outperforms the random elimination.

the mean best cs was examined for all four external sources . the results show that the mean cs of protonet were only slightly reduced, while the random mean cs are significantly reduced due to the much smaller amount of clusters.

automatic functional annotation of clusters
the following scheme was used to annotate the protein clusters: for each cluster c and keyword k we define the following score:



where tp is the amount of true positives , fn is the amount of false negatives  and fp is the amount of false positives .

for each cluster, we search against all keywords of go and interpro for the keyword with the highest as. if the as of the cluster is greater than  <dig> , the cluster is assigned that keyword as its annotation. the logic behind the score and the threshold is as follows: the score is determined by two parameters, the specificity and the sensitivity; let us consider the two worst-case limit cases. in the first case, specificity> <dig>  and sensitivity = 1: a majority of the proteins of the cluster share the keyword, and there exist no other known proteins that have the keyword. in the second case, specificity =  <dig> and sensitivity> <dig> : all proteins of the cluster share the keyword and they constitute more than 1/ <dig> of the total proteins known to have this keyword. in both cases, the keyword can be assigned to the protein cluster with a high degree of confidence. all other clusters fall in between these cases.

using this method, all  <dig>  clusters that contain  <dig> or more proteins and that remain after the compression were tested.  <dig>   clusters passed the high confidence threshold and were therefore given an annotation. figure  <dig> shows the plot of the highest as score for each of the clusters and the threshold function. naturally, by relaxing the threshold it would be possible to obtain a higher level of annotation.

cation channels: a biological example
CONCLUSIONS
the challenge of protein classification by using sequence similarity has been addressed extensively by several different methods. in order to assign function to proteins, advanced methods  have been used to learn sequence-based patterns on "seeds", manually validated alignments of known protein families. the widely-used blast algorithm is considered to be a reliable tool for sequence alignment, but has been shown to lack sensitivity for weak similarities that may be detected by signature detection methods. we show here that by using an unsupervised bottom-up clustering method based on blast e-values, we have been able to construct a global hierarchy of the swissprot proteins that can be validated by external biological sources, merely by undertaking a global view of the protein space.

the four different external sources that were used for validation reflect different aspects of the protein space: interpro annotation is predictive and is based on various signature detection methods; go annotation assignments are both based on prediction and from known research, while the go hierarchy was constructed completely manually; scop is a semi-manual classification of structures that is not necessarily reflected in sequence; the enzyme database supplies enzyme commissions, which constitute a hierarchy that is based on the enzymes' chemical reactions. protonet successfully constructs clusters that correspond highly to all four of the sources. even high levels of scop , which are considered to have no detectable sequence similarity, are partially matched . notably, the correspondence of protonet to interpro is generally higher than the correspondence to the other sources. this is not surprising, considering the fact that interpro is based on prediction from sequence. however, it is worthwhile to note that the interpro families may be reconstructed almost perfectly without using the various sensitive detection methods that interpro uses, and more importantly without using the manually constructed seeds.

after validating the biological relevance of the protonet clusters by using external sources, we examined the hierarchy of protonet. the test showed that the hierarchy presented by protonet significantly corresponds to the manually-constructed biological hierarchy of go. it is important to note that the method used by protonet is not expected to fully recapture the go hierarchy due to the fact that protonet is structured as a collection of trees while go is structured as a dag. in this sense, the approach of protonet may be limited in the portrayal of evolutionary complexity . however by using a domain-based clustering approach, allowing multiple entities of each protein in the hierarchy, a substantial improvement in the cs quality measure may be achieved .

an intrinsic parameter that reflects the stability of clusters during the clustering process was used in order to compress the cluster sets, leaving  <dig> % of the clusters; removing the singletons clusters as well leaves  <dig> % of the clusters. as mentioned above , the entire protonet scaffold contains  <dig>  clusters that are represented by  <dig> roots; following this condensation, there are only  <dig>  clusters that are represented by  <dig>  roots. we show that although a massive portion of the clusters is discarded, very little performance is lost by this condensation process. it is obvious that prior to the condensation process, protonet holds within it both clusters that correctly represent biological groups and clusters that are irrelevant artifacts of the clustering process . therefore, by allowing a major reduction without significant loss of biological coherence protonet seems to present a more correct view of the protein world.

an automatic unsupervised method for the classification of proteins has some important advantages over supervised methods : first, an unsupervised method is unbiased in automatic assignment of function to proteins, a major goal in bioinformatics. also, it allows high-throughput analysis of whole genomes and enhances understanding of global biological systems without the need for the manual annotation of every protein. using an automatic annotation method, we are able to successfully annotate  <dig> % of the major protein clusters  that remain after the compression of the protonet tree. the annotation uses a relatively conservative threshold and therefore yields high-confidence annotations. this further suggests that the clusters remaining after the condensation process are relevant biological clusters and not mere artifacts.

one aspect that we have rigorously examined is the robustness of the protonet tree: given a different set of proteins to cluster or a different clustering method, would the resulting tree be significantly different, or are its properties maintained? interestingly, changing the underlying protein databases , the substitution matrices used for the preliminary blast, or the merging strategy  <cit>  produced very similar trees , suggesting that the performance of protonet is not due to a specific computational method but perhaps to the robust properties of the protein sequence space.

