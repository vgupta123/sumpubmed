BACKGROUND
for a number of years phylogenetic construction has been considered to be a problem of statistical inference. one of the most popular methods of inferring phylogenetic relationships is maximum likelihood . it has often been considered that one of the advantages of ml over parsimony based methods is that it allows for the use of different models of evolution depending on the dataset being examined. therefore knowing the process of evolution and being able to construct realistic models of evolution is the foundation for being able to infer accurate phylogenetic relationships among species. currently one of the major challenges in phylogenetics is to accurately model the process of nucleotide or amino acid substitution and to choose among our set of models in order to infer accurate phylogenies. felsenstein  <cit>  was the first to show in simulations that overly simplistic models that underestimate multiple substitutions can result in inconsistency during phylogeny estimation in certain situations . further simulation studies have shown that even when using ml analysis, underestimation of nucleotide substitutions  leads to long-branch attraction and inconsistency in the felsenstein zone  <cit> . these results have also been duplicated in real datasets where the use of inadequate models can lead to long-branch attraction  <cit> . however it was also shown in simulations that violations of the model can also favour the true tree in certain situations   <cit> . it was later shown in simulations and real data that this can only happen in a very limited number of cases and in general using overly simplistic models should be avoided  <cit> . one fact that is most certainly true is that the accurate estimation of node support is strongly affected by the use of simplistic models in simulated and real datsets  <cit> . it is clear that unless we can be totally sure that a dataset fits into one of the categories mentioned above, then the use of overly simplistic  substitution models can negatively bias our phylogenies.

almost all models of amino acid replacement assume that all amino acids sites evolve independently according to the same markov process. it is assumed that the markov process is stationary and homogeneous, so that all rates of substitution are constant across time. each of the protein substitution models consists of a  <dig> Ã—  <dig> instantaneous rate matrix which includes the set of original amino acid frequencies  obtained from the dataset that was used to generate the model. the  values represent the equilibrium or stationary frequencies of the  <dig> amino acids and the matrices are often modified to include the set of observed frequencies in the dataset being examined. models that take into account the observed amino acid frequencies are often denoted by the '+f' suffix  <cit> . if we assume that the substitution process is reversible then the number of free parameters is reduced to from  <dig> to  <dig>  however due the computational burden imposed by optimising all  <dig> free parameters of the instantaneous rate matrix with large datasets and the risk of overfitting the matrix parameters when analysing small datasets has meant that most phylogeny programs rely on empirical models of protein evolution. dayhoff et al.  <cit>  were the first to develop a general model of amino acid substitution using the limited amount of sequence data available at the time. since then, several additional models have been developed from other datasets and using different techniques, such as maximum parsimony and maximum likelihood  <cit> .

there has been a great deal of research into various techniques for performing model selection on nucleotide data  <cit> . in the past, three measures have been used to select the best-fit substitution model. the hierarchical likelihood ratio test  consists of a tree hierarchy where the best-fit model is selected by performing a number of pairwise likelihood ratio tests and navigating the tree to arrive at the final model  <cit> . however the hlrt is only suitable for models which can be defined as subsets of each other, therefore is generally only applied to nucleotide model selection. for example, the f <dig> model  <cit>  is a subset of the hky model  <cit>  with the transition and transversion rates set to be equal. as the different amino acid matrices do not have any free parameters, it is not possible to define a similar tree hierarchy as with nucleotide models. the akaike information criterion   <cit>  and bayesian information criterion   <cit>  belong to a different class of model selection measures that compare all of the models simultaneously according to some measure of fitness. although these measures have been used for many years in nucleotide model selection, only recently have programs such as modelgenerator  <cit>  and prottest  <cit>  been specifically developed to perform statistical analyses of the complete set of available amino acid substitution models.

until now many phylogenetic analyses of multiple datasets from a fixed set of taxa have assumed a single substitution model for all sets of homologs . we argue that if it is assumed that a single amino acid matrix is the best-fit matrix for all genes in a dataset, then there is the possibility that the method may encounter situations like the one mentioned previously and produce suboptimal phylogenies. we have performed experiments using real datasets in order to determine if it is correct to build phylogenies from different genes using the same amino acid matrix. this issue has never been examined before and our results show a large differences in best-fit protein models within all of the datasets analysed. the results presented in this paper raise the question of whether we should be performing full protein model selection analyses prior to any amino acid phylogeny estimation.

RESULTS
to investigate the potentially harmful effects of a non-statistical approach to choosing protein models, we built two phylogenies with two arbitrarily selected protein models using a single gene family alignment consisting of  <dig> taxa  taken from the dataset of philip et al.  <cit> . figure  <dig> shows how it is possible to obtain two different tree topologies both with equally high bootstrap support by arbitrarily choosing the protein substitution model. in situations like this, the high bootstrap support values of both trees might indicate that either one of these alternate trees is optimal. however, bootstrap values can be misleading  and cannot be used to infer information about the suitability of the substitution model  <cit> . therefore without detailed prior knowledge of the phylogenetic relationships or first determining the best-fit model from the set of available models, it is difficult to determine the optimal ml tree.

the likelihood is calculated as the probability of obtaining the data  given the model of evolution . ideally we would prefer to use the true tree when performing our model selection as this would remove any conflicting signals from an incorrect base tree. however on real datasets the true tree is unknown so we must use some approximation of the true tree for the model selection procedure in order to estimate the model parameters  <cit> . in the following sections, we provide the results of simulations to investigate the effects of using varying base trees, alignments lengths, among-site rate variation  parameters, and amino acid frequencies in amino acid alignments on the selection of protein models. for all of the simulations, we used the same  <dig> taxon clocklike tree  used by posada and crandall  <cit>  to generate our simulated alignments. we also took a number of previously published real datasets for which the model of amino acid substitution is suspected to follow a particular matrix  in order to test the accuracy of the selection method. we then examined the extent of amino acid matrix variation among three large sets of orthologs from each of the domains of life.

base tree sensitivity
the results of the simulations using different base trees  for the model selection procedure are presented in table  <dig>  the most important observation from the table is that the recovery rates are significantly reduced for almost all models when a random tree is used compared to either the true tree or the nj tree. however there is one notable exception to this where many of the +i+g alignments display slightly higher recovery rates with a random tree than with either the true tree or nj tree. further analysis of our results  shows that this appears to be due to the fact that when a random tree is used, the model selection procedure tends to generally favour over-parameterised models which is consistent with the findings of a previous study on nucleotide sequences  <cit> . there is very little difference between using the true tree and an nj tree which confirms previous findings for nucleotides that a relatively good tree is sufficient for estimating accurate model parameters  <cit> . it is also very interesting to note that the correct amino acid matrix was selected in almost every case  regardless of the base tree, indicating that the only area of uncertainty in these simulations is the correct choice of asrv.

we next examined the difference in the models selected using the likelihood values from the quick nj-jtt base tree and those of fully optimised ml phylogenies produced using all of the individual models . there is very little difference  between the model selection accuracy when model selection was carried out using a full ml tree search using each available model and the models selected by the quicker nj-jtt method . for the proteobacteria dataset, the nj-jtt model selection procedure differed to the full ml analysis selections in fewer than 7% of cases, with most of the different selections being due to selecting the same amino acid rate matrix and different asrv parameters. the nj-jtt model selection procedure and ml analysis achieved closer to full agreement in the archaea dataset, where the model predictions given by the two procedures differed in fewer than 5% of cases. there was a similar pattern with the vertebrate dataset where the nj-jtt model selection procedure differed in fewer than 9% of cases compared to the full ml analysis procedure. table  <dig> shows that in the majority of cases where different models were selected, the same amino acid matrix was selected with the difference being due to different selections of optimal asrv parameters.

sequence length
one of the factors that is believed to affect the results of the nucleotide model selection is sequence length  <cit> . we wanted to investigate what effect  sequence length would have on amino acid model selection by performing the model selection procedure on varying length alignments. table  <dig> shows the recovery rates of each of the three measures  for the three different alignment lengths . as expected, the rates for the longer sequences are increased compared to the shorter sequences. one noticeable feature with the  <dig> character dataset is that the number of times the correct model was selected when a +i+g asrv was present was significantly reduced for all matrices. further examination of the results shows that this is almost always due to the model selection procedure picking the +g version of the model. this is due to the fact that the difference in likelihoods between the +i+g and +g models is quite small at short sequence lengths and not significant enough for the measures to prefer the more parameterised +i+g models. in these cases, we have observed that the Î± parameter of the gamma distribution is generally estimated to be less than  <dig>  in order to accommodate the invariable sites. when the sequence length is increased to  <dig> characters, the difference between the likelihoods of the +g and +i+g models increases and is enough for the model selection measures to prefer the +i+g models. as the bic takes into account sample size , it is not affected to the same extent by this phenomenon . again the correct amino acid substitution matrix was selected in almost every case regardless of sequence length .

among-site rate variation parameters
asrv parameters can vary greatly in real datasets therefore it is important to investigate if the model selection procedure is affected in any way by varying asrv's. table  <dig> shows the results of the simulations where the gamma shape parameter was varied. the most noticeable trend in the table is the reduction in recovery rates of the +g simulations with higher values of Î±. a closer examination of the results shows that this is due to the model selection measures incorrectly selecting the +i+g asrv where the true asrv is +g. it is quite noticeable that the bic is the least affected measure as it associates a much higher cost for adding more parameters to the model than either of the aic metrics. therefore we attribute this reduction in accuracy to be a property of the aic. this phenomenon is also matched by better results in the +i+g simulations as the values of Î± are increased. this increase in accuracy is consistent with our earlier result  meaning that at high values of Î±, such as  <dig>  or  <dig> , the separate invariable sites parameter is explicitly required by the model to account for the proportion of invariable sites. just like in the previous tables, the correct amino acid matrix was selected in almost every case.

amino acid frequency perturbation
each of the protein substitution models consists of an instantaneous rate matrix  which includes a set of original amino acid frequencies  obtained from the dataset that was used to generate the model. if we use the observed amino acid frequency parameters of the dataset being examined  instead, then we include  <dig> extra free parameters when evaluating each model. we were interested in investigating what effect the change in amino acid frequency proportions would have on the model selection procedure and whether the corresponding '+f' versions of the models would be selected. we would expect our model selection procedure to be robust enough to select the corresponding amino acid matrix despite the variation in amino acid frequencies. table  <dig> shows that when the original model amino acid frequencies were randomly perturbed, there was a definite trend among all of the model selection measures to select the corresponding '+f' version of the particular model over the original models. the recovery rates are extremely high across all categories with only a few exceptions. when amino acid frequencies deviate from the default amino acid frequencies of a particular model, there is a trend towards the '+f' version of the same model.

expected model selections
some of the amino acid substitution matrices were developed specifically for use with certain types of datasets. for example, the mtrev  <cit>  and mtmam  <cit>  models were developed from different mitochondrial datasets. the rtrev matrix was developed specifically for use with retroviral and reverse transcriptase datasets  <cit> . indeed the rtrev authors presented a study showing how the rtrev matrix consistently produced higher likelihoods than other matrices such as jtt and wag for specific datasets. consequently it is expected that these matrices will perform quite well during model selection when applied to datasets of similar origin to the original datasets used to develop these models. the results of the model selection procedure for a number of datasets where the substitution process is known are outlined in table  <dig>  we have provided a column that describes the expected amino acid matrix . it is clear that there is a noticeable bias in each of the datasets towards some form of the expected amino acid matrix.

model variation among multi-gene datasets
model selection and tree accuracy
in real datasets, the true tree is unknown and therefore it is impossible to know with certainty if we have found the true tree. one possible indication as to whether the choice of model is improving the inferred phylogenies might be to take a large dataset of orthologs and measure the level of congruence among the inferred trees. it would be expected that the congruence among the trees would increase as the optimal models are used to build the trees. we took our proteobacteria dataset  and built phylogenies using fixed amino acid matrices and also built phylogenies using the optimal protein model for each alignment. table  <dig> shows that for the proteobacteria dataset when the optimal models were used to infer the trees, the median rf distance was lower than using a fixed model in the majority of cases.

discussion
we have studied the influence of various factors on protein model selection. our simulations have confirmed previous work showing that the model selection procedure performs quite accurately using an approximate tree for model selection. one of the most interesting results that we have shown using real datasets is that less than 9% of the time was a different matrix selected using a full ml analysis than those selected using a quick nj-jtt method. this further strengthens the recent results presented by sullivan et al.  <cit>  showing that successive-approximation methodologies to phylogeny estimation does not suffer from any significant loss in accuracy. our simulations have also shown that protein model selection is not as sensitive as nucleotide model selection to sequence length differences. recovery rates remain relatively constant over different sequence lengths with the only exception to this being at short sequence lengths when the difference in likelihood values can result in an overly-simplistic model being selected . we have also shown that when amino acid frequencies deviate from the default amino acid frequencies of each model, there is a clear trend towards the '+f' version of each model. this phenomenon was also observed in the results of the real dataset analysis presented in table  <dig> with many of the real datasets being best described by '+f' versions of the expected models. one constant trend across all of the simulations we have performed is that the correct amino acid matrix is selected by both measures close to 100% of the time regardless of factors such as base tree accuracy, sequence length, asrv variances, or amino acid frequencies.

it should be emphasized that many of the current set of models of amino acid or nucleotide substitution make many unrealistic assumptions such as reversibility, amino acid composition stationarity, and homogeneous substitution rates. however much work is currently taking place to develop methods to loosen many of these restrictions  <cit> . while the focus of this work has been to demonstrate the usefulness of performing protein model selection, it must be stated that model selection measures can only provide information on which of the given set of models best-fits the data and cannot give any indication of how close a particular model is to reality.

we have highlighted an example where two highly-supported and topologically different phylogenies were produced from the same alignment using two arbitrarily selected amino acid substitution matrices . the likelihood values of the two trees are - <dig> for the mtrev tree and - <dig> for the wag tree with the extremely high bootstrap support values providing evidence that the observed trees are not due to a stochastic error . to further rule out any source of stochastic error, the corresponding likelihoods for the mtrev tree with the wag matrix is - <dig> and - <dig> for the wag tree with the mtrev matrix, thereby confirming that both matrices favor different tree topologies. a tree constructed using the optimal model for this alignment  agrees with the wag tree. at first glance, our particular example may seem slightly unrealistic as we have used a mitochondrial model to construct a tree from nuclear genes. however, as we have shown, one of the best models for proteobacterial and archaeal genes is frequently  a model that was derived from retroviral pol proteins. therefore, ad hoc model selection, even when using arguments about the origin of the model  are still ad hoc arguments. the maximum likelihood principle suggests the use of the best of the available models and in some cases, the best performing model can be surprising.

the results of our cross-domain substitution model analysis are interesting as there are noticeable differences in the groups of models selected by each dataset with no single matrix emerging as the best for any of the datasets. the large diversity of amino acid matrices cannot come as a great surprise as it would seem intuitively unreasonable to assume that a very large group of independently evolving gene families from a fixed taxon set followed an identical amino acid substitution pattern. perhaps one of the most significant findings is that the rtrev matrix  <cit>  features so prominently in both the proteobacteria and archaea datasets. the wag matrix  <cit> , for instance was derived from a globular protein dataset and was shown to produce higher likelihood values in general, compared with the jtt matrix for the dataset from which it was derived. this seemed to indicate that choosing a matrix based upon the method or the data used to derive the matrix might be a good idea. however, our finding that for so many alignments from cellular life, the best matrix was derived from viral sequences is surprising and the consequence is that ad hoc arguments for choice of matrix may not reasonable.

CONCLUSIONS
in this study, we have analysed the ability of the aic and the bic to select the appropriate evolutionary model in cases where the model is known. we have shown that both methods are suitable for this purpose. we have also shown that none of the currently available models is universally preferred for all alignments and that there is considerable variation in the substitution process across protein families. what we have not attempted to show is that for any given alignment the selected model is the actual model that gave rise to the observed data. however, on the basis of our results we can speculate on the appropriateness of the models. considering that a viral model is one of the most preferred models for these cellular sequences, perhaps none of the models are really capturing the data. the models are homogeneous across the tree and this is likely to be a simplification. therefore, even though we have produced a robust method of model selection, it is likely that the models themselves need to be improved.

