BACKGROUND
rapid advancements in biology, molecular biology and biomedicine have led to the development of a range of factual and experimental databases. apart from structured data related to sequences, expressions, etc., the significant body of biomedical knowledge is stored in the domain literature. the size of textual archives is increasing so rapidly that it is impossible for any user to locate and assimilate new knowledge without automated help. in particular, efficient curation of biological databases relies essentially on the ability to search and manage published articles rapidly and cost-effectively. this fact has spurred huge interest in designing text mining methods that can help users in locating, collecting and extracting relevant knowledge represented in an unstructured, free-text format.

the biocreative evaluation was organised to assess the performance of current text mining systems in two tasks. task  <dig> was protein name identification in free text   <cit> . task  <dig> addressed a set of related tasks based on functional annotation of human proteins by assigning relevant gene ontology  terms from a corpus of full-text documents  <cit> . task  <dig> was generally designed to be analogous to the process by which expert annotators curate and update records in resources such as swiss-prot and genomic databases. it was divided in three subtasks. task  <dig>  addressed the problem of selecting relevant textual evidence from a given document to support the annotation of a given protein name with a given go term , assuming that the document is relevant for both the protein and the go term in question. task  <dig>  was about selecting both a relevant go term and a corresponding text segment from a given document for a given protein . as in task  <dig> , the relevance of the document was also presupposed in task  <dig> . finally, task  <dig>  represented the most complete, realistic and challenging problem amongst the three sub-tasks. in task  <dig> , systems were expected to assign appropriate go terms and to select relevant passages for a given protein identifier, but relevant documents had to be identified automatically from a given corpus.

in this article we present our approach used within the framework of biocreative task  <dig>  we participated in all three subtasks. we considered task  <dig>  as the most general one, and the other two subtasks as its nested problems : for solving task  <dig> , tasks  <dig>  and  <dig>  were approached as subtasks. more precisely, to solve task  <dig> , we need only a method to assign relevant go terms, and once we have obtained them, we can apply the methods from task  <dig>  to retrieve supporting text. similarly, for task  <dig>  we need to solve the document retrieval problem, and once we have relevant documents selected, the methods from task  <dig>  can be employed.

although the main idea of biocreative task  <dig> was to provide help for human annotators with the time-consuming curation of biological databases , we approached the task as a knowledge discovery problem. more precisely, our approach aims at mining associations from a corpus even when an explicit statement  relating a protein to a go term is not present . the approach follows an original and renowned example of "hidden links" presented by swanson and smalheiser  <cit>  . we have previously developed related methods for combined retrieval and classification of a protein's sub-cellular location using support vector machines  and a bag-of-words approach  <cit> , as well as for classification of yeast genes using eleven classes of the upper part of the go ontology  <cit> . the approach we used for biocreative task  <dig> was largely derived from that work.

in the remainder of the paper we firstly describe the methods that were used to solve the task. then, we present and discuss the evaluation and results.

methods
we employed a supervised machine learning approach to assignment of go terms to proteins, together with an extensive terminological processing of documents . we based our method on svms, which have been demonstrated to perform well at the document classification task  <cit> , as we construed the protein function assignment task as a modified form of this problem . the approach is mainly based on the idea that biological entities  that co-occur in text with a protein of interest are indicative of its function, and that proteins with similar co-occurrences of terms have related roles. consequently, learning relevant and informative co-occurring terms for a given go term should give clues for assignment of that go term to proteins that have similar distributional patterns.

assignments of go terms  were based on collecting "weak" co-occurrence evidence within documents, rather than on explicit statement of protein function. therefore, an important facet of our approach was that go assignments were not derived from a single, "relevant" passage or sentence, but from document relevant to a given protein. further, selection of supporting passages  was based on a similar idea. each paragraph pertaining to a given protein was assessed with respect to a given go term, and the highest scoring passage was selected. more specifically, the employed method involved three steps: a) pre-processing of documents and feature selection, b) training the svms on the released training data, and c) predicting go terms and selection of paragraphs for target  genes.

a) document pre-processing, feature selection and weighting
for task  <dig>  a corpus of around  <dig>  full-text sgml-encoded documents  from the journal of biological chemistry was distributed by the organisers. document pre-processing involved several steps. firstly, we parsed the sgml documents to remove experimental, methods and reference sections of each document body, as we considered that these were unlikely to contain information on protein function and might introduce unnecessary noise. we also removed non-textual elements , but retained figure legends, as they might have some useful information and clarification . all remaining sgml tags  were removed . the problem with sup tags  and for marking references to footnotes) was ignored, i.e. these tags were removed and their content concatenated to the preceding text . sgml entities  were replaced with the appropriate ascii equivalents , collected from available dtds. then, the whole corpus was pos tagged using a general-language tagger .

extraction of features used for protein classification  was the next step. as features, we used automatically extracted terms  that co-occurred with a given protein within the same document. since terms represent the most important concepts in a domain, we hypothesised that they might be useful features for the annotation task. also, we have previously shown that using biological terms as classification features improves performance when compared to single words  <cit> . however, terms from controlled vocabularies  are extremely sparse in free text , not only due to lexical variation but mainly because they are typically descriptors rather than real names i.e. terms . further, the high neology rate of other relevant terms makes existing glossaries incomplete for dynamic searching, and thus automatic term extraction tools are needed for efficient term identification  <cit> .

in order to automatically recognise terms in text, we used an enhanced version of the c-value method  <cit> . the method has been previously used to recognise terminology in many biomedical sub-domains . the input to the original c-value is a pos tagged corpus, and the output is a list of suggested terms, ranked according to their likelihood of representing relevant domain concepts. we modified the method so that the information on paragraphs and documents in which recognised terms appeared was also produced.

in order to suggest possible terms, the c-value method combines linguistic formation patterns and statistical analysis. the linguistic part includes extraction of term candidates by using a set of formation patterns, and a stop list to eliminate frequent false term candidates. term formation patterns act as linguistic filters to a pos tagged corpus: filtered sequences are considered as potential realisations of domain concepts. for the biocreative task we used the simplest term formation pattern + n, where a and n denote an adjective and a noun respectively), which has proven to have the best precision/recall ratio  <cit>  for the biomedical domain. note that this approach can also collect terms from controlled vocabularies  that appeared in text, but we did not give any extra credits to such terms .

since many biological concepts are designated by more than one surface lexical representation, extracted term candidates were post-processed and normalised in order to link equivalent term variants . in order to conflate equivalent surface expressions, we carried out linguistic normalisation of individual term candidates . for the biocreative task, we normalised typo-orthographic  and inflectional variants . each term candidate was then mapped to a normalised canonical representative , and consequently we established an equivalence relation, where two term candidates were related if and only if they shared the same cr. the partitions of this relation are denoted as synterms : a synterm contains various surface term representations sharing the same cr. further, an acronym recognition and conflation module  <cit>  was used to link acronyms and their variants to respective crs , and these were also included in corresponding synterms .

finally, synterms were statistically analysed, and each set was assigned likelihood to represent a domain specific concept . termhood  of a given synterm is based on a statistical measure that amalgamates the cumulative frequency of occurrence of its elements in the corpus, the frequency of occurrence of its cr as a form nested within other crs , the number of such candidate synterms, and the average length of term variants included in the synterm. synterms that were top-ranked  according to their c-values were selected as features for classification. using synterms  as features instead of individual term representations aims at neutralisation of lexical variation across documents and authors . for task  <dig>  we extracted  <dig>  million distinct synterms from the corpus, and stored them in a database .

for weighting synterm features, we used a form of inverse document frequency  that took account of the number of documents considered relevant to a given protein. more precisely, the weight of a feature w for protein p is given by



where rp is a set of relevant documents for the protein p, fj is the frequency of w in document j, and nw is the global frequency of w in the whole collection of documents. note that the assignment of relevant documents was based on the released training data for the learning phase, while for the prediction phase we used either pre-selected documents  or we employed a retrieval method .

b) learning a svm for each go term
in the learning phase, we trained svms for go terms on term vectors formed from document-protein pairs from the initially released training data. for task  <dig>  the training data included  <dig> triples of the form , meaning that assignment of the go term to the protein is supported by the document, with  <dig> distinct go terms . this means that we had on average only  <dig>  examples per go term. therefore, for each go term, we collected positive learning examples from all training triples with go terms that matched or were descendant from the go term concerned. for these examples, we collected relevant documents  and corresponding term-features  were used as pertaining to the given go term. the negative training examples were obtained by taking an equivalent number of examples  from sibling go terms and their children.

apart from the released go terms, we trained additional go classifiers for a whole subtree of go formed from the root to go terms occurring in the training data . using the hierarchy of the go, we were able to extend the original  <dig> go classifiers to create the total of  <dig> .

the svm classifiers were trained using the svm-light package  <cit> , and support vectors  were stored in a database for efficient access in the next phase. more precisely, as the decision function in svm classification is the weighted sum of the kernel function evaluated between a test case and support vectors, this means that we can evaluate the decision function within the database management system. once trained, the classification system was entirely contained within the database which greatly simplified calculation of predictions .

note, however, that – while we had the training data for assignments of go terms to proteins – there were no data provided for training on selection of relevant paragraphs . therefore, we used the same svms for both problems .

c) prediction of go terms and selection of passages
the prediction of go terms for a target protein was performed in two steps. first we created a feature vector for a given target protein by collecting all synterms from given/relevant document. for tasks  <dig>  and  <dig> , the set of relevant documents for a given protein was pre-selected , while for task  <dig>  we employed an ad-hoc retrieval method to obtain documents from the corpus . in the second step, we tested the feature vector against respective go classifier, and selected the go term associated with the top-ranked classifiers .

a similar approach was employed for detection of relevant passages: each paragraph pertaining to a given protein  was formed into a term vector and tested against the relevant go classifier. the highest scoring passage was assigned as pertaining to the protein/go annotation. note that here we did not consider "similarity" between paragraphs and a testing protein, i.e. the relevant paragraph was selected only as being related to the go term in question .

more specifically, the testing procedures for each of the subtasks were as follows:

task  <dig> : selection of supporting passages from a specified document for a given go term
for a given  pair we tested all the paragraphs from the specified document against the corresponding go classifier , and the top-ranked paragraph was selected. however, note that we could select supporting paragraphs only for the go terms that appeared in training examples or were on a path from a training go term to the root. we generated two submissions for this subtask. in submission  <dig>  if we did not have the corresponding go classifier trained, the testing example was skipped. in submission  <dig>  we used a classifier trained for a nearest neighbour go term if the exact one was not available, in an attempt to improve recall. informally, we climbed up through the go hierarchy from the given go term until we found an available classifier. more formally, the nearest neighbour node was selected as the lowest common ancestor  for the test go term and the original training data, and it was used to select a relevant passage.

task  <dig> : prediction of go terms and selection of supporting passages from a specified document
for a given protein, we generated its feature vector from a specified, pre-selected document, and tested it against all available go classifiers. we then selected go terms corresponding to the top-ranked classifiers . then, for each  pair obtained, we applied the procedures used in task  <dig> , submission  <dig>  in order to select a relevant paragraph . we also generated submission  <dig>  where we used  go classifiers derived from a new training set composed jointly from the initially released training data for task  <dig> and the test data for task  <dig>  . we reasoned that additional classifiers might improve recall, and since the test sets for tasks  <dig>  and  <dig>  were distinct, we believed this was a fair approach to obtain more training data. we re-trained the svm classifiers  with the new data, obtaining additional  <dig> go classifiers . so, in submission  <dig> we used the same methodology as in submission  <dig>  but with additional go classifiers.

task  <dig> : prediction of go terms and selection of supporting passages from a corpus
in this subtask, the main challenge was to retrieve a set of relevant documents for a testing protein. during the pre-processing phase, we collected human protein names from swiss-prot/trembl, and stored them in a database . we implemented an ad-hoc retrieval approach that used a variant of the inverse document frequency weighting  <cit> . we scored each document in the corpus against a query formed from all the words of the de  and gn  fields of the swiss-prot/trembl entries of each testing protein. in addition, if a document contained an exact phrasal match to a  term from the de field, the weight contribution from this term was raised to a power proportional to the length of this match. once top-ranked documents were assigned to a given protein as its relevant documents, the methods from task  <dig>  were applied to assign relevant go terms and retrieve supporting passages. analogously to task  <dig> , we generated two submissions; submission  <dig> with the original training go classifiers, and submission  <dig> with the data from task  <dig>  used as additional training examples.

evaluation and 
RESULTS
evaluation of the results was performed by database curators from the european bioinformatics institute . it is obvious that it was a huge challenge to define and apply a consistent and meaningful evaluation approach. in the accepted framework, the focus was mainly on "usefulness" of a selected passage for deriving a given go annotation of a given protein. the passages were assessed both from the perspective of the relevance to the suggested go term and the relevance to the protein in question. "high" judgments were assigned when go terms or proteins were highly related to the selected passage, and "low" judgements were assigned when there was no relevance. in "perfect" predictions, both the go term and the protein were marked as "high". if a passage was generally related to a given go term , the evaluators assessed such results as "general". in case of proteins, "general" marks were assigned to cases where the selected passage was not exactly relevant for a specific protein, but was relevant to the protein family or a homologue. we present the results for each subtask separately.

task  <dig> : selection of supporting passages from a specified document for a given go term
there were  <dig> test examples in this subtask. the results were modest . in general, only one quarter of selected paragraphs were deemed highly relevant for either a go term or for a protein, or for both. note that, however, there was a high discrepancy i.e. low overlap between the testing and training sets of go terms: 43% of the testing examples for this subtask referred to a go term that did not occur in the training set , and even 50% of the distinct go terms in the testing data were absent from the available training data. since we used a supervised machine learning approach, we were clearly unable to make judgements related to testing examples containing such go terms. still, by using a classifier of a more general, nearest-neighbour go term when no classifier for the actual go term was available , we substantially improved recall  without sacrificing precision . compared to submissions from other participants, precision of our submission  <dig> predictions was poor , but recall was ranked in the upper half . for predictions marked as "general", precision of all participating systems was in the range 5–6%, with recall for our system in the top  <dig> .

task  <dig> : prediction of go terms and selection of supporting passages from a specified document
there were  <dig> test examples  pairs) in this subtask. the results for this subtask were disappointing. in submission  <dig>  precision was only  <dig> % . the inclusion of classifiers derived from task  <dig>  data used as additional training examples , improved both precision and recall substantially , which indicates that the method might be more effective if the coverage of training data was broader. still, we believe that one of the main causes of such poor performance was the lack of data on which the predictions were based . compared to submissions from other participants, in this subtask we were ranked as 6th and 12th  for "general" and "perfect" predictions respectively, while our system was 4th and 9th with respect to recall .

task  <dig> : prediction of go terms and selection of supporting passages from a corpus
only  <dig> testing proteins have been distributed for this task, and – in our case – only  <dig> of them  were evaluated. therefore, the assessment of performance in task  <dig>  and comparison to subtasks  <dig>  and  <dig>  are limited. still, the results for task  <dig>  were encouraging: on average, 50% of assigned go terms and selected passages were deemed relevant for a given protein . in submission  <dig>  we used additional training data  in order to improve recall. however, we only got more predictions, with recall remaining almost the same, which consequently decreased precision. for this subtask we were unable to compare our performance to other systems, as such results were not available.

in this subtask, the prediction of go terms was based on evidence that has been collected from several documents , and not from a single article as in subtasks  <dig>  and  <dig> . still, the results of task  <dig>  were quite variable for individual proteins. for two proteins , precision of assigned go terms was very high , while it was very poor for other two proteins . we believe that a plausible reason for such discrepancy was the relevance of retrieved documents: for the first two proteins, almost all collected documents were relevant to the proteins , while for the second pair, only few retrieved documents were related to the proteins in question . we further discuss this below.

discussion
to our mind, there were at least two separate problems that were part of task 2: assignment of go terms that describe protein function , and selection of a supporting passage for a given  pair . also, an additional, non-trivial problem is automatic retrieval of relevant documents . the results obtained in response to these problems are quite different: in many cases we have relatively good assignment of go terms to proteins , but the selected paragraphs are typically non-relevant.

prediction of go terms
for protein function assignments, we rely on capturing a substantial body of relatively weak evidence from document, rather than on a rare but explicit statement of protein function. therefore, it is essential to obtain substantial data to support predictions . for example, task  <dig>  results show that – when several relevant documents are used to make predictions – significantly better performance can be achieved . the average number of documents retrieved for each protein in task  <dig>  was  <dig>  compared to a single document approach in task  <dig> . thus, the results from task  <dig>  show that relevant latent information can be inferred from weak evidence when several documents are analysed, and that single documents are not always sufficient to automatically predict specific associations using the method we applied: assignments that have been derived from many documents were more reliable than assignments based on a single document. further, while supporting documents improve precision of go annotations, availability of training data can improve the overall performance  resulted in significantly improved precision and recall of predicted go terms).

selection of supporting text
selection of a relevant passage to support a  pair is a huge challenge, as – in particular for assignment of functional annotations – supporting information can be distributed over several paragraphs or documents. from a biologist's point of view, short passages often cannot give unambiguous assignment of function without domain knowledge gleaned from other sources. existing resources, for example swiss-prot, typically provide whole documents as supporting evidence. analogously, the biocreative training data also indicated only relevant documents. therefore, as training examples for supporting passages were not available, it was impossible to automatically learn characteristic features on the paragraph level, and, consequently, we used svm-classifiers trained on the document level. for the method that we applied, an additional problem  was that passages  were typically too short, and consequently they contained few features . therefore, as methods that rely on collecting sufficient amount of weak information cannot capture evidence from short textual segments, we could not provide accurate selection of paragraphs. also, as longer passages have more features, our approach typically suggests lengthy paragraphs, rather than short sentences. still, a promising outcome  is that using more general go classifiers for passage extraction does not decrease precision.

retrieval of relevant documents
as indicated earlier, it is essential to provide an accurate set of relevant documents on which predictions will be based. to our mind, task  <dig>   is the most interesting and realistic problem, as it does not require pre-selection of documents and go terms for annotation of a certain protein. while go terms could be assigned to proteins using some non-textual data-mining methods , "pre-selection" of  relevant document that is "guaranteed" to be relevant to both the protein of interest and the go term to be assigned is a highly challenging task. if such documents are selected automatically, analysis  of relevant go terms has to be taken into account as part of the process , while manual pre-selection of such documents by human annotators  is non-realistic. we further believe that it is rarely the case that a single document can be guaranteed to be self-contained and relevant to both the protein of interest and the go term to be assigned. when human annotators derive functional annotations from such documents, they would almost certainly make use of significant background knowledge. this knowledge needs to be "captured" by an automated system in one way or another. this can only happen if there is a sufficient number of relevant documents to be considered for prediction, or if some additional knowledge source is used.

our experiments have confirmed that selection of relevant  documents for a given protein is not a trivial task , but a task of great relevance for mining protein function. in order to retrieve relevant documents for task  <dig> , we firstly experimented with exact dictionary look-up  to match protein names in text. for  <dig> proteins from the list supplied in task  <dig> , we retrieved documents  for only  <dig> proteins  using  <dig> available synonyms for these proteins from swiss-prot/trembl. the main reason for such poor recall was extensive variability of protein names. therefore, we implemented a retrieval method that did not rely exclusively on exact match, but also took into account individual words that comprised terms. the method worked well for simpler protein names  and brca1-associated ring domain protein  <dig> or bard <dig> ), where relevant documents were retrieved with very high precision . however, retrieved sets for complex protein names were typically not accurate, as documents were rarely related to proteins in question. for example, retrieval precision was around 10% for task  <dig>  proteins p <dig>  and q9byw <dig> . we believe that the relevance of the retrieval sets significantly influenced the quality of predictions for the respective proteins . an additional challenge for the retrieval of relevant documents is to ensure that the documents correspond to correct species. for example, in task  <dig>  in four cases  we got high quality predictions, but the associated documents  were not about human proteins.

discovering and linking knowledge
results of task  <dig>  have also shown that – when a sufficient body of documents is available – we were able to mine annotations from texts even when statements of certain relationships have not been clearly or explicitly stated. in such cases, relationships among proteins and go terms were typically "discovered" by using a transitive closure of co-occurrence features collected from many documents . for example, our method correctly linked the go term dna-directed rna polymerase ii, holoenzyme to the bard <dig> protein , although the documents in the protein's retrieval set did not contain an explicit statement of this relationship. instead, the go term was loosely linked to the brca <dig> protein in this set of documents, and using the co-occurrence of the two proteins  with other terms, we were able to mine the association between bard <dig> and the go term. the mined annotation was afterwards confirmed in an article with the explicit statement of the relationship  <cit> , but this article was not present in the training and testing document collections used in biocreative. consequently, our approach suggested the annotation without the need that this relationship has been explicitly established and published in an article. of course, it is obvious that in this case no appropriate supporting passages could be selected, as such information is distributed over several documents and is not presented explicitly.

this example illustrates that predictions  can be indeed mined and inferred from existing "hidden" and weak evidence that is present in literature, and not only from explicit statements. we believe that similar types of latent information are very common. for example, a statement of interaction between two proteins implies their cellular co-location; hence, knowing the location of one is sufficient evidence for location of the other. further, some background knowledge can be used to infer additional associations. for example, evidence that a protein is involved in the tricarboxylic acid cycle implies that the protein is located in the mitochondria.

possible improvements
there is obviously significant room for improving the methods that we used for task  <dig>  for example, we treated all terms extracted from text equally, but additional credits could have been given to particularly relevant features for the task in question  when found as co-occurring with proteins/paragraphs of interest. also, as we approached the protein function assignment task as a modified form of the document classification problem, the role of a protein was "limited" only to pre-selection of documents that would be analysed . once the documents have been selected, training and classification were performed without further protein "input", and we used a whole document as a context surrounding a protein in question, from which the features  came. as documents may be too wide as relevant contexts, we will experiment with classification features that are collected from a narrower context of a protein , or when feature weights depend on the distance from the protein occurrences. still, spotting a mention of a protein in a paragraph is to a great extent a problem addressed in biocreative task  <dig>  and thus integration of successful methods from that task could be beneficial. also, this could help in locating relevant passages from the perspective of relevance to proteins . furthermore, we believe that combination of our approach and some type of assessment of "lexical" similarity  between a paragraph  and a go term entry can further improve the selection of relevant passages.

additional knowledge and data sources might also be useful in improving the methods that we used for task  <dig>  in the current implementation, we approached the task in a "closed" manner, i.e. we relied only on released training resources, and no other data was used . for example, we could have used a set of go classifiers that we have previously trained on yeast data  <cit> , and incorporated them into the generated pool of human classifiers, thus probably improving the coverage, or generated additional  training data using annotations from existing resources . also, we could have used additional documents  to collect more features for released positive examples, thus possibly improving precision. furthermore, additional documents could be used to support predictions . for example, we could have used a larger set of documents to make prediction of go terms , but supporting paragraphs could be still selected from documents specified by the assessors. these possibilities are directions for our further experiments with the biocreative data.

CONCLUSIONS
automatic extraction of concise information on protein function from literature is undoubtedly a task of great relevance and utility to molecular biologists. in our approach to mining protein function from text, we used svms and features derived from terms co-occurring with a given protein to assign go terms. we approached the problem as a variant of document classification, where go assignments were not derived from relevant passages, but from relevant documents.

the evaluation of the results shows the capabilities and limitations of supervised machine-learning approaches in text mining. firstly, they can yield good performance only if sufficient training data is obtained, and significant amount of supporting data is used for prediction. the results show that performance improves as the number of relevant documents to a particular protein increases, while the method works poorly on short passages and/or single documents. the main reason is that short textual units often do not contain necessary information to infer protein function without information from other sources. this implies that our go assignments  may be largely accurate and with relatively good recall, but finding the relevant passage may be difficult. apart from a significant body of training examples , such methods need to incorporate either some background knowledge , or to analyse a substantial quantity of relevant text to learn or acquire such knowledge, or both. in our case, since we do not use any additional domain knowledge to support predictions, our method requires several documents for each protein in order to be effective. of course, retrieval of relevant documents is an additional challenge, mainly because of lexical variability and ambiguity of protein names. on the other hand, we have shown that this approach can "discover" some associations from text even when an explicit statement relating a protein to a go term is absent. in that sense, we believe that machine-learning approaches are more suited for addressing knowledge discovery tasks.

there is obviously space for future improvements and experiments as discussed in the previous section. despite moderate results, the biocreative exercise was very valuable, in particular for the identification and clarification of user requirements and open challenges, and concrete progress on how best to evaluate and interpret the results of text mining. further, distribution of correct testing data  will be one of the valuable results of the evaluation. finally, one of the main lessons learnt is that the two biocreative task should not be viewed as isolated problems: for a successful solution to biocreative task  <dig>  successful methods from task  <dig> will be of great help.

