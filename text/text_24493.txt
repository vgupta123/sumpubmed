BACKGROUND
the immune epitope database and analysis resource  contains epitope information and analysis tools  <cit> . scientific articles and direct submissions from researchers provide the content from which iedb curators manually extract epitope related information and enter it into the database  <cit> . the database is freely available to the scientific community.

the iedb journal article triaging process goes as follows. four times each year a query is run containing multiple epitope-specific keywords and logical operators  <cit>  to identify new references for curation in pubmed. the abstracts of references that have not been previously introduced to the iedb's internal database  are evaluated and hierarchically classified . relevant references must contain epitope-specific data and an epitope structure  <cit> . irrelevant, or uncuratable, abstracts are entered into the iebd's internal database but are not further processed . next, each article containing epitope information is categorized into one of seven level  <dig> categories, namely allergy, autoimmunity, infectious disease, transplantation, cancer, hiv, and "other" . references in the other category do not meet the criteria for placement into the remaining six categories yet contain relevant epitope information  <cit> . curation priorities of the iedb, established by the national institute of allergy and infectious diseases , are references in the allergy, autoimmunity, infectious disease, and transplantation categories. level  <dig> classification assigns each reference to a more specific category . an autoimmune reference, for example, may be categorized into the beta-amyloid, diabetes, general autoimmune, lupus, multiple sclerosis, myasthenia gravis, or rheumatoid arthritis category. the final level of classification breaks these down further . for example, diabetes references may be assigned to one of seven level  <dig> categories: glutamic acid decarboxylase, heat shock proteins, insulinoma-associated protein- <dig>  islet-specific glucose-6-phosphatase catalytic subunit-related protein, insulin/proinsulin, other, or various/multiple for abstracts that refer to several diabetes categories. the level 1- <dig> categorizations of the references in the iedb, first presented in  <cit> , are in additional file  <dig> 

we have previously described our implementation of a naïve bayes classifier to automate the level  <dig> classification of curatable vs. uncuratable references  <cit> . the additional categorization of curatable references into disease specific subsets was added more recently and performed manually. the main goal of the present study was to develop and implement classifiers to reduce the amount of time required for an article to proceed from the query to curation and maintain consistency in the criteria used to evaluate the references.

there are two approaches to classify references into a hierarchical categorization scheme. either, references are assigned the final category in a single step, or classification is done stepwise, deciding at each level which category of several distinct siblings is the most appropriate. the latter process, classification that occurs in several stages, involves the construction and implementation of hierarchical classifiers  <cit> . hierarchical classification permits increased specificity in feature selection because classification is conducted on small groups of related references instead of in one step among all references in a dataset  <cit> . dumais and chen  <cit>  implemented a hierarchical svm classification system to classify a set of pages from looksmart. hierarchical svm classifiers based on the support vector clustering method for automatic document classification resulted in improved classification accuracy compared to the k-nn and decision tree systems  <cit> .

the iedb has processed a large dataset of  <dig>  references classified by a human expert. torii and liu  <cit>  built an ensemble of svm classifiers and compared their performance to multinomial naïve bayes and single svm classifiers using several published datasets, including a dataset from the iedb  <cit> . when applied to references in the iedb dataset  <cit> , the ensemble of svm classifiers outperformed naïve bayes and single svm classifiers  <cit> . we therefore implemented and compared naïve bayes and svm classifiers for performance on discriminating between curatable and uncuratable references in our dataset. svm non-hierarchical classifiers and a hierarchical application of svm classifiers were subsequently built and compared for performance on predicting level 1- <dig> category assignments. using the output scores from the hierarchical application of svm classifiers, neural network classifiers assigned level 1- <dig> categories to each reference. finally, cost sensitivity was incorporated into the design of the hierarchical application of svm classifiers to minimize misclassifications of priority references. we tested our design on an independent dataset of  <dig>  references. here we report our results which highlight the superior performance of the cost sensitive hierarchical application of svm classifiers as applied to the reference evaluation process in the iedb. for the purposes of the work performed in this paper, any use of the term "hierarchical svm" refers to our system which used a hierarchical application of svm classifiers.

RESULTS
naïve bayes and support vector machine classifier training for level 0
the first step in the curation of references retrieved by automatic queries of the pubmed library is to determine whether or not a reference is relevant to the scope of the iedb database. we previously implemented a naïve bayes classifier to automate this step, referred herein as "level 0"  <cit> . based on a report  <cit>  that svm classifiers can outperform naïve bayes classifiers on our published dataset  <cit> , we compared the performance of naïve bayes and svm classifiers for the iedb's document classification purposes. for the curatability prediction we wanted to maintain a false negative rate of less than 5%, a value that corresponds to the inherent disagreement rate for an abstract scan between two human experts  <cit> . at a false negative rate of 5% or less, we then wanted to maximize the true positive rate. we adapted the svm code in  <cit>  into python scripts and used  <dig>  curatable  and  <dig>  uncuratable  abstracts previously classified by a human expert to develop a svm training algorithm to build a set of models to automate level  <dig> 

we evaluated the performance of the naïve bayes and svm classifiers with 10-fold cross-validation and used the area under the curve  values to compare performance . an auc value of  <dig>  was obtained for the svm classifier compared to a naïve bayes auc value of  <dig> . at a false negative rate of 5% the true positive rate for the svm classifier was  <dig> % and  <dig> % for the naïve bayes classifier. based on these results we transitioned from a naïve bayes to svm classifier for all subsequent applications.

support vector machine classifier training for subsequent levels
next, curatable abstracts are assigned to one of seven level  <dig> categories: allergy, autoimmunity, infectious disease, transplantation, cancer, hiv, or other. in order to automate the level  <dig> assignments a training dataset of  <dig>  abstracts assigned to one of the seven level  <dig> categories by a human expert was used to build seven svm classifiers. the classifiers were trained such that all abstracts from a single category received a "yes" and the remainder of the abstracts received a "no." for example, the autoimmunity training set had "yes" for  <dig>  abstracts and "no" for the remaining  <dig>  abstracts. the seven level  <dig> classifiers underwent 10-fold cross-validation and, as shown in table  <dig>  all seven classifiers consistently achieved auc values above  <dig> .

performance was evaluated with 10-fold cross-validation. an auc value was calculated for a given category, where documents assigned by the expert to be of that category are considered "positive" while documents assigned to any other category are negative. to evaluate the performance of the document classification by the multilayer perceptron  into specific categories, we calculated the percent agreement of categories. the auc and category prediction accuracy values are entered for each level  <dig> category in addition to the total prediction accuracy.

we tested different algorithms in weka  <cit>  to find the optimal function that takes as an input the scores from the seven svm classifiers and returns as an output the level  <dig> category assignments. we tested these algorithms in the same cross-validation setup used to evaluate the individual svm classifiers. to evaluate the performance of this multi-category classification problem, we cannot use auc values that we use for the individual category svm classifiers. instead, we compare the accuracy of classification in each category. the multilayer perceptron algorithm  <cit>  returned the strongest results, predicting correct level  <dig> categories for  <dig> % of the references. furthermore, it correctly predicted  <dig> % of the references falling into high priority level  <dig> categories. it was therefore decided to implement the multilayer perceptron algorithm into our design at levels 1- <dig> 

in level  <dig> abstracts from each level  <dig> category are further assigned to finer categories. the autoimmunity category, for example, contained  <dig>  curatable training abstracts assigned to one of seven finer categories: beta-amyloid, diabetes, general autoimmune, lupus, multiple sclerosis, myasthenia gravis, and rheumatoid arthritis. svm classifiers were trained only on the abstracts that had been assigned into the same level  <dig> category. for example, training data for the diabetes classifier consisted of positive examples for diabetes references and negative examples containing all remaining abstracts categorized as autoimmune references. the level  <dig> classifiers underwent five-fold cross-validation and yielded satisfactory auc and category prediction accuracy values which are displayed in table  <dig> for the autoimmunity level  <dig> categories. auc values above  <dig>  were consistently achieved.

performance was evaluated with five-fold cross-validation. the auc and category prediction accuracy values are entered for each autoimmunity level  <dig> category.

finally, svm models were trained to assign level  <dig> categories to abstracts. one hundred fifty-five classifiers were designed for level  <dig>  for example, abstracts placed into the autoimmunity category  and assigned to the diabetes category  received an assignment to the glutamic acid decarboxylase , heat shock proteins , insulinoma-associated protein- <dig> , islet-specific glucose-6-phosphatase catalytic subunit-related protein , insulin/proinsulin , other , or various/multiple  level  <dig> category. svm classifiers were trained only on the abstracts that had been assigned into the same level  <dig> category. for example, training data for the heat shock proteins classifier consisted of positive examples for heat shock protein references and negative examples containing all remaining abstracts categorized as diabetes references. in table  <dig> we present the auc and category prediction accuracy values for the diabetes level  <dig> category classifiers. prediction performance for the oth and var categories was much lower  than the remaining categories . this reflects that references in those categories are much more heterogeneous.

the auc and category prediction accuracy values are entered for each diabetes level  <dig> category.

performance comparison between a non-hierarchical and a hierarchical application of svm classifiers
having trained the hierarchical application of svm classifiers to predict categories we compared their performance to non-hierarchical classifiers. the construction of  <dig> non-hierarchical svm classifiers would have required a substantial amount of time and computer power so we limited the comparison to the autoimmunity category to build non-hierarchical svm classifiers and compare their performance against a hierarchical application of autoimmunity svm category classifiers. for example, to train the non-hierarchical svm classifiers to predict diabetes abstracts into the diabetes category we used the  <dig> diabetes training abstracts as positive examples against the remainder of the  <dig>  curatable abstracts . the hierarchical application of svm classifiers for the diabetes references were trained with the  <dig> diabetes abstracts  against the remainder of the  <dig>  curatable autoimmunity abstracts . training time for the hierarchical classification approach is much shorter because only abstracts within the same category are considered. furthermore, positive and negative training examples were less imbalanced in the hierarchical scheme. the performance of hierarchical versus non-hierarchical classifiers was compared using the same cross-validation set up as before. performance was compared separately for each of the seven level  <dig> categories under autoimmunity. auc values were used for each category to evaluate the ability of the classifier to distinguish documents belonging to that category from documents belonging to any of the other six categories. the auc values for the autoimmunity non-hierarchical and hierarchical application of svm classifiers are shown in table  <dig>  the average auc value for the non-hierarchical classifiers was  <dig>  and the average auc value for the hierarchical application of classifiers was  <dig> . this difference is significant with a p-value of . <dig> . based on these results the hierarchical application of svm classifiers are not only faster to train but also outperformed non-hierarchical classifiers.

auc values from the non-hierarchical and hierarchical autoimmunity category svm classifiers.

implementation of cost sensitive matrices
the iedb was funded to curate allergy, autoimmunity, infectious disease, and transplantation references, which makes hiv, cancer, and other references a low priority for our curation. there is a substantial cost associated with misclassifying a high priority reference into a low priority category since abstracts placed in the low priority categories undergo no further review by a human expert and are not curated. thus these misclassifications result in missed high priority references. to reduce the number of high priority references misclassified into the low priority categories, cost sensitive classification was implemented by specifying cost matrices for the category selection step performed by the multilayer perceptron neural network. there were seven categories in level  <dig>  so we built a  <dig> ×  <dig> cost matrix  with a cost of zero for all correct category assignments; a cost of  <dig>  for an abstract that was predicted into a low priority category and the human expert identified a different low priority category ; a cost of one in the instance that the classifier and human expert placed an abstract into one of the four high priority categories but the human expert overruled the classifier's category prediction ; and a cost of five for an abstract that the human expert placed into a high priority category but the classifier predicted into a low priority category . the multilayer perceptron is trained to minimize total cost, and will therefore specifically avoid placing high priority abstracts into a low priority category.

using the  <dig>  curatable training abstracts we compared outcomes for the level  <dig> category assignments with or without cost sensitivity . with the implementation of cost sensitivity at level  <dig> there was a decrease in the number of high priority references misclassified into low priority categories, from  <dig> to  <dig>  as desired by our curation process. as expected, at the same time the number of references incorrectly classified as high priority went up from  <dig>  to  <dig> . essentially, the classifiers will now rather assign a borderline reference into a high priority category, which is exactly what we wanted to achieve.

the number of references predicted into the level  <dig> categories with and without cost sensitivity. in the cost sensitive scenario, there was a decrease in the number of high priority references misclassified into low priority categories.

cost sensitivity was applied in level  <dig> or  <dig> classification when "other" was present as a category. this was implemented in order to reduce incorrect predictions into this category and maximize predictions into the more specific categories. as an example, the cost matrices at level  <dig> for diabetes references are shown in additional file  <dig>  in table  <dig> we compare the results of applying no cost and cost sensitive svm classifiers for the diabetes level  <dig> category assignments. with the implementation of cost sensitivity, fewer references were predicted into the other category. overall category prediction accuracy decreased but category prediction accuracy into the well-defined categories improved with the cost sensitive svm classifiers.

the number of correct predictions and category prediction accuracy for no cost and cost sensitive classification of training level  <dig> diabetes references.

testing performance of cost sensitive hierarchical svm classifiers on an independent benchmark dataset
using the methodology identified as optimal in cross-validation in the previous sections, we tested the performance of our approach on an independent dataset of  <dig>  abstracts retrieved on september  <dig>   <dig> that were not part of the cross-validation datasets. the svm based main classifier  predicted that  <dig> of the  <dig>  references were curatable using the previously determined cutoff aimed at achieving 95% sensitivity. a human expert evaluated the classifier's performance and confirmed that  <dig> of the  <dig> references were curatable. of the  <dig> references predicted to be uncuratable, the human expert identified  <dig> that were indeed curatable. that corresponds to a sensitivity of  <dig> % with a specificity of  <dig> % which is in our desired range. these results reflect the thresholds purposely set to maximize sensitivity in order to avoid discarding curatable references.

we compared the classifier's predictions for the  <dig> curatable abstracts against the human expert's assignments. table  <dig> shows a matrix of the classifier's category predictions and human expert's assignments for the  <dig> abstracts confirmed as curatable. the classifier correctly predicted  <dig>  of the level  <dig> category assignments. of the  <dig> curatable abstracts,  <dig> were predicted into high priority categories by the classifier. the human expert assigned  <dig> of the abstracts to high priority categories and of those, confirmed that  <dig> % of the classifier's high priority category predictions were correct. of the  <dig> references predicted into low priority categories, only four references were classified as high priority categories by the human expert. three references predicted into low priority categories were reassigned to different low priority categories.

columns represent predictions by the classifier and rows represent the level  <dig> category assigned by a human expert. for example, one reference predicted as transplant was actually cancer. the total incorrect row represents the total number of references that were predicted into level  <dig> categories by the classifier that differed from the decision of the human expert. of the  <dig> abstracts predicted to be curatable,  <dig> abstracts were overruled as uncuratable which can be seen in the uncuratable row. of the  <dig> curatable abstracts,  <dig> % were assigned to the correct level  <dig> category.

next, we compared the level  <dig> and  <dig> assignments of the human expert with the hierarchical classifier system  for the  <dig> curatable abstracts. this shows, for example, that the human expert placed  <dig> of the curatable abstracts into the level  <dig> autoimmunity category. the autoimmunity classifiers predicted the correct category for  <dig> of the curatable abstracts at level  <dig> and  <dig> of the curatable abstracts at level  <dig>  the percent of correct predictions for the high priority categories at levels 1- <dig>  exceeded those for the low priority categories at levels 1- <dig>  as desired based on our cost assignments.

transplantation and cancer do not receive level  <dig> category assignments. hiv does not receive level  <dig> or  <dig> category assignments.

for benchmarking purposes, we are making the entire cross-validation and independent datasets available as additional files .

discussion
here we present a practical application of automated document classification for the purposes of the iedb. this was prompted by the desire to increase efficiency in the review process of the several thousand abstracts retrieved from querying pubmed each year. the abstract review process assesses relevancy to the database and places curatable abstracts into a disease-specific category. we automated the assignment of categories to make this a more efficient process. in this process, we tested different methodologies and tools, and believe that our results should prove useful to researchers working on similar tasks.

in the past, we used a naïve bayes classifier to predict curatability  <cit> . svm classifiers were reported to outperform other classifiers  <cit>  and one group  <cit>  showed high svm performance on our previously published dataset  <cit> . we compared performance between naïve bayes and svm classifiers and confirmed that svm outperformed naïve bayes classifiers when distinguishing between curatable and uncuratable abstracts. in our original publication  <cit>  we also attempted to use svm classifiers but achieved much poorer performance, most likely due to sub-optimal choice of parameters. after our present extensive tests, we conclude that svm classifiers are overall superior to naïve bayes classifiers for our abstract classification task.

we also compared the performance of a non-hierarchical and a hierarchical application of svm classifiers in order to determine the best approach for automating the disease category assignments. based on the higher auc values achieved using the hierarchical application of svm classifiers we adopted the hierarchical strategy for classifying the abstracts. our results confirm previous findings  <cit>  that at least if there is a sufficiently large base of data, hierarchical classifiers perform better. we believe that this is primarily due to the higher homogeneity of the abstracts encountered when making category assignments, which will improve the ability to reliably make finer distinctions between related categories.

cost-sensitive classification had a major positive impact on the practical performance of our predictions. as all references predicted to be in high priority categories will be manually reviewed as part of the curation process, it was most important for us to ensure that few high priority references were misclassified as being low priority. we accomplished this by simply assigning different costs to the errors made by the multilayer perceptron that assigns categories based on the svm output scores. a similar approach was taken by cai and hofmann  <cit>  when they implemented cost sensitive document categorization with hierarchical svm classifiers on the wipo-alpha collection and included interclass relationships.

the ability to not only identify relevant references, but also group them into related subject areas, has benefits for curators and management. grouping articles enables coordinated curation of related content, the prioritization of particular subject areas over others, and the assignment of specific curators to categories that require certain expertise. management can account for progress on particular subject areas and can re-direct effort to priority references. for example, in light of the  <dig> h1n <dig> pandemic, the iedb re-directed curation priorities to immediately curate all influenza related articles  <cit> . this was eased by the ability to quickly identify the relevant articles based on their available categorization.

the cross-validation and independent test datasets we compiled are made available as additional files . we strongly encourage the use of this corpus for benchmarking purposes, as has been done with our previous published dataset  <cit> . our dataset has been carefully manually inspected. all abstracts were reviewed by a senior immunologist and for those abstracts deemed curatable, the full text reference was retrieved and reviewed in detail by an iedb curator. the size of our dataset, the application of hierarchical classification, and the expert assignments make this a unique and practically relevant corpus of data for biomedical text categorization.

CONCLUSIONS
since the inception of the iebd, over  <dig>  abstracts have been evaluated for curatability. a human expert requires constant time to evaluate thousands of abstracts while an automated classifier can learn from past decisions and will surpass the expert in speed. automating the categorization of documents enabled us to expedite the preparation of documents for curation and coordinate curation efforts, both of which are time efficient and cost effective approaches. we also took into consideration our curation priorities and implemented cost sensitivity to reduce the possibility that high priority abstracts were misclassified. our datasets and methods may be relevant to other database and prediction methods developers with similar goals.

