BACKGROUND
an elementary flux mode  represents a unique and non-decomposable sub network of metabolic reactions that works coherently in steady state  <cit> . elementary flux mode analysis has proven to be a powerful method to understand the structural properties of metabolic networks . for example, this approach can be employed to assess which reactions and educts are involved in producing a certain compound, to determine optimal yields or to analyze the consequences of certain reactions taking a zero value as invoked by metabolic engineering or changes in the cellular environment  <cit> .

the material balances of a metabolic network in steady state take the form of a system of linear algebraic equations:  <dig> 0=s⋅v with s the metabolic network stoichiometric matrix  = nc × nv) and v a vector of reaction fluxes  = nv). a set of i =  <dig>  …, nd flux distributions v = {vi} = nv × nd) obeying to eq.  can be further expressed as a non-negative linear combination of ems:  <dig> v=e⋅p=∑i=1mei⋅pi with e a matrix of m ems and p a matrix of weighting factors that quantify the contributions of the ems to the observed fluxes v  <cit> . nonzero values in pi indicate how the ei contribute to flux-phenotype  <cit> . investigating which of the p’s have nonzero contributions for a given phenotype is useful for two reasons  <cit> : 1) the biological interpretability of em-based pathway analysis is improved, which can help to focus on studying physiologically active processes; and 2) changes in the physiological state of the cell can be quantified, enabling the causes of change to be elucidated.

different methods have been proposed to analyze those p’s which have nonzero contributions. ferreira et al.  <cit>  outlined that different principles, such as network connectivity and stoichiometry  <cit> , thermodynamics  <cit> , or enzyme kinetics  <cit> , can be used to identify ems that cannot be active. though these approaches are good to reduce the number of ems beforehand, they do not provide specific values for p’s, the contributions from the remaining ems.

several methods have been proposed that combine nonlinear programming and experimental data . palsson and co-authors  <cit>  suggested a method for maximizing and minimizing the contributions of extreme pathways  for a given steady-state flux distribution using linear optimization. this yields ranges of possible non-negative contribution values associated with the extreme pathways, the so called alpha spectrum. the alpha spectrum typically indicates that many extreme pathways could be active simultaneously. however, several studies suggest that the regulation problem is of low dimensionality , wherefore only a reduced set of extreme pathways or ems can be expected to be active. wang et al.  <cit>  proposed to randomly sample u ems several times, each time minimizing a least square functional consisting of the flux data and a flux distribution simulated with u ems, in order to identify which set of u active ems explains the flux data best. different values of u have to be tested to identify how many ems are active. since the number of theoretically possible combinations of ems grows with increasing the number of ems and almost exponentially with increasing values of u , the number of times the random sampling has to be executed also grows with increases in both m and u. nookaew et al.  <cit>  suggested to use mixed integer linear programming to determine the active ems and their contributions from yield data. however, also for this algorithm the number of em combinations that have to be evaluated increases with the number of ems and active ems.

ferreira et al.  <cit>  proposed a method that maximizes the variance between data of the extracellular environment and data of the reaction fluxes. while this approach allows inferring which ems are active under certain environmental conditions, the identification of the nonzero p contributions is dependent on the appearance of evidence in the environmental data that indicates changes in the p contributions. barret et al.  <cit>  performed a basis rotation on the loadings obtained from principal component analysis of flux data to find the “eigenfluxes” – sets of independently-operable reactions, which allow for a biological interpretation of the principal components. however, different basis rotation approaches can yield different eigenfluxes for the same loadings  <cit> .

in this study, the aim is to infer the nonzero p contributions directly from reaction flux data. the decomposition of the flux distributions into ems is not straightforward  <cit> . it is for instance not possible to regress the flux matrix with all ems, since the number of ems is typically much greater than the number of experiments in which fluxes were measured, such that the system of linear equations, eq. , is underdetermined. in addition, the ems are typically not orthogonal to one another so that the summation of contributions obtained when regressing two ems, one at a time, yields a different result than when regressing both simultaneously . in what follows, a methodology is proposed, which identifies the combination of ems that best captures the patterns observed in reaction flux data, i.e. the principal ems , given a specific number of pems.

methods
the difficulty in interpretation of principal component analysis   <cit>  data was the main motivation for the development of the principal elementary mode analysis  method proposed here. in pca a matrix of data, x, is decomposed into matrices of loadings w and scores t such that a maximum amount of variance of the data is captured in an underlying latent space for a specified number of latent variables, nlv:  <dig> x=w⋅t=∑nlvwnlv⋅tnlv. 

the scores describe the patterns in the data in the underlying  latent space and the loadings describe the relationship between the latent space and the patterns in the data. the pca loadings are determined in an iterative procedure from the data, x, such that for each latent variable a maximum of variance in the data can be captured  <cit> .

the structural resemblance between the em equation  and the pca equation  is obvious. however, in pca the principal components  are loose structures determined by measured flux data in the sense of variance maximization. in contrast, pema is constrained by all possible loading combinations, i.e. the complete  set of ems, which are fixed a priori and determined by the metabolic network structure. thus the challenge in pema is to identify the minimal subset of “active” ems, i.e. the principal ems , that maximize the explained variance of flux data, vmes.

the principal elementary mode analysis  method
the pema algorithm consists of three steps. at first the available ems are analyzed by comparing with one another and with respect to the available flux data, which allows reducing the number of feasible em combinations. in the second step, a greedy approach is used to determine a best first combination, which serves as a lower bound in the following, step  <dig>  the branch and bound em selection method.

step 1: pre-selection and analysis of the ems
each ei has size dim = nv fluxes. however, the number of measured fluxes  is typically much lower than nv, comprising only a subset of fluxes. this has direct consequences for the identification of the active ems, since it will not be possible to distinguish between ems that have zero or equal contributions in the em entries of the measured fluxes, termed hereafter ambiguous ems. thus, at this stage, the ems are filtered with respect to this ambiguity , but the information about which ems are ambiguous is saved for analysis of the selected ems, in case that an ambiguous em is selected by the algorithm.  determined  or 2) underdetermined  for the specified measured fluxes, with the set of flux distributions v=vmesvest and vest the matrix of unmeasured fluxes).

in the next pre-selection step the directions of the em contributions are analyzed. due to the non-cancelation principle  <cit> , i.e. a reaction can only be active in one direction at one time, the flux contributions of the ems that can be chosen must obey the direction imposed by the measured flux data vmes. thus, possible errors in the direction of the measured flux data must be addressed before filtering the ems.

step 2: a “best first” em combination by means of a greedy approach
a “best first” combination is obtained employing a greedy approach that iteratively decomposes the flux patterns of vmes identifying which em contributes the most until the given number of ems that should be combined  is reached. in the beginning each em i of all m ems is divided by its 2-norm value, i.e.:  <dig> ei,n=eiei2∀i= <dig> .m where ei,n is the norm-scaled ith em and m the number of ems. this scaling makes the following manipulations easier and it does not change the ratio between the elements of each em vector, but it only scales the weights of the ith em by its norm: pi,n = pi ⋅ ‖ei‖ <dig>  in each iteration, the vectors of scaled weights, pi, are determined by regressing the flux matrix viter with the respective em, which for the ith em gives:  <dig> pi,n=ei,nt⋅viter, because ei,nt ⋅ ei,n =  <dig>  some of the values in the vectors of weights, or even all, might be negative, which is in conflict with the definition that the weights need to be greater or equal than zero  <cit> . in order to account for this constraint the negative values in the vectors of weights are replaced by zeros. the consequence of replacing negative weight values with zeros, is that the variance related to the negative values is not extracted from viter. in the next step pi,n is used to calculate the contribution of the ith em to the fluxes, vest,i:  <dig> vest,i=ei,n⋅pi,n. 

the flux contributions for each of the ems are then compared to the measured flux values using the explained variance criteria:  <dig> ϑi=1−∑k∑jvmes,j,k−vest,i,j,k2∑k∑jvmes,j,k <dig>  

where k sums over the number of data points, j sums over the number of fluxes and vmes,j is the measured flux j. it is shown in the additional file  <dig> that this equation can be simplified to:  <dig> ϑi=∑k∑l=1ipl,n2∑k∑jvmes,j,k <dig>  

according to the calculated explained variance values the ems can be ranked. the em, which yields the greatest variance value, is selected in each iteration. then the captured patterns are subtracted from the flux matrix, such that only the unexplained patterns remain:  <dig> viter+1=viter−vest,selected, where vest,selected is the flux contribution of the selected em. thereupon a new iteration is started. in the first iteration viter = 1 = vmes. the iterative procedure is stopped if either the number of measured fluxes or the user defined number of ems that should be combined for explaining the variance in the flux data  is reached.

step 3: a branch and bound procedure for the identification of the pems
in contrast to pca, the ems selected by the greedy approach are not necessarily orthogonal to one another, wherefore in contrast to pca, the ems selected by the greedy approach cannot be guaranteed to capture the most variance for a given number of factors, i.e.: another combination of ems with the same number of factors might explain more variance. therefore, it becomes necessary in principle to exploit all possible combinations of ems for all factors, which means that a number of combinations ncomb=m!nfac!⋅m−nfac! need to be evaluated. thus, the em selection procedure will have to deal with a combinatorial explosion in the evaluation of possible combinations for an increasing number of factors and ems. here, a branch and bound technique is used to reduce the number of evaluations of em combinations. the steps of the algorithm are visualized in fig.  <dig>  the procedure starts with calculating the captured variance for each em i, using equations  <dig>   <dig> and  <dig>  with viter = 1 = vmes. for the second factor all possible combinations of em i with each em j of the remaining ems need to be evaluated. for the following factor all possible combinations of ems i, j with the remaining ems need to be evaluated and so forth until nfac is reached. it can be seen that the algorithm performs the combinatorial search by calling itself for each increase in factor and possible elementary mode combinations. however, if the sum of the variances captured at any level for a combination of nfac ems does not reach the lower bound, then this combination is not evaluated, since it cannot capture more variance than had been captured before. the sum of variances calculated for  em combinations at any factor ifac is such an upper bound. the upper bound is reached if the  ems are independent, but since this is typically not the case the actual variance is lower. the lower bound is raised every time a combination is encountered that can capture more variance.fig.  <dig> schematic representation of the branch and bound pem selection algorithm



a matlab implementation of the algorithm can be found in the additional file  <dig> 

RESULTS
the proposed method was applied to three case studies, one study with simulation data and two others with experimental data. in the simulation study the flux data were generated using ems of the metabolic network of pichia pastoris, such that the active ems are known. different numbers of ems are involved in the experimental studies on pichia pastoris and saccharomyces cerevisiae,  <dig> and  <dig> ems respectively. in all studies the results obtained with the proposed method were compared to results obtained with pca, which is the standard tool to analyze the latent structure of flux data.

pichia pastoris simulation case study
this case is based on the metabolic network of pichia pastoris, which originates from tortajada et al.  <cit> . it describes the central carbon metabolism of p. pastoris during growth on glucose, glycerol and methanol, comprising the embden-meyerhoff-parnas pathway, citric acid cycle, pentose phosphate and fermentative pathways. it contains  <dig> compounds  and  <dig> reactions, yielding a total number of  <dig> ems  <cit> . flux data were generated simulating the growth of pichia pastoris for twelve different cultivation conditions by choosing appropriate sets of active ems . the active ems were assumed to contribute randomly to the flux pattern. for more details see the additional file  <dig>  this allows comparing the set of ems identified with pema to the active ems that were used for data generation, hereupon termed “active ems”. this case study also enables the study of the impact of noise on the ems identification and performance. only the uptake and secretion flux data were used thus mimicking the experimental study. for each flux the data values, as well as their respective entry in the ems, were scaled by the mean value of this flux in order to reduce the impact of differences in magnitudes between values of different fluxes.

analysis of the performance without noise
the results obtained with pema and pca are shown in table  <dig> in case of no noise added to the data. it can be seen that the number of the selected ems varies when increasing the number of nfacs from one to six. for further increases in number of nfacs, it can be observed that systematically the same  ems are selected. from six up to nine nfacs the ems selected with pema all belong to the set of active ems. however, the 10th identified em does not belong to the set of active ems. it can also be observed that from the 9th em on the increase of explained variance is negligible . while more than 97 % of the variance can be explained with the identified first nine ems, the seven ems that remain to be identified, generate in total less than 3 % of variance in the  <dig> simulated experiments. since there is only little evidence for the activity of these ems in the data, it will be extremely difficult to identify them, particularly when noise is present in the data. the identified set of ems therefore is not exclusive.table  <dig> selected ems and the respective captured variance  values for one to  <dig> number of n
facs obtained for the simulated data without noise


n
fac
the set of truly active ems for data generation was ems =  <cit> . bf* best-first identification by the greedy approach. n
lv
** number of latent variables for pca



when comparing the pema final results to the best-first solution , shown in the last rows of table  <dig>  it is obvious that up to the fifth em the performance of the best-first solution in terms of captured variance is comparable to the final result, though the first, third and ninth identified ems do not belong to the set of “active ems”. the misidentified ems pose an inductive bias onto the identification of the following active ems, wherefore the performance for greater number of nfacs becomes inferior. this was expected as outlined in the method section and the reason why the here proposed pema method was developed.

from the results obtained with pca, also shown in table  <dig>  it can be concluded that the simulated data can be described on a latent variable space of lower dimension, at maximum nine latent variables are required. while the performance of pca in terms of explained variance is superior to pema, its loadings w have no biological meaning, which makes the biological interpretation of the results more difficult.

analysis of the pca loadings and pems
the contributions of the active normalized ems  and unidentified ems) to each flux are shown in fig.  <dig> together with the contribution of the pca loadings and basis rotated pca loadings. the basis rotation of the loadings allows for a more biological interpretation of the principal components  <cit> . different orthogonal basis rotation methods were used, namely varimax, orthomax, quartimax, equamax and parsimax. these methods rotate the loadings according to different objectives, for more details see  <cit> . in case of the identified ems it can be seen that the ems contribute to all fluxes. it appears that, in case of pca, none of the loadings contributes to the ethanol and pyruvate fluxes, but in fact their respective values are only very small. however, the contributions of the pca loadings to the fluxes are very difficult to interpret. for instance, the negative contributions of w <dig> to the methanol flux paired with positive contributions of this loading to the glycerol and the oxygen flux does not make sense from a biological point of view, since this would either mean that i) glycerol and oxygen are produced using other compounds, such as methanol, however the glycerol and oxygen uptake reactions are irreversible in the simulation model; or ii) that methanol is produced from glycerol and oxygen, but the utilization of methanol in fact consumes oxygen. in contrast, the ems enable a rational interpretation of the flux data structure  <cit> . for instance, it can be deduced from the first principal em, e <dig>  that methanol is, under the consumption of oxygen and the release of carbon dioxide, mainly transformed to ethanol . the results obtained by the different method for the rotation of the pca loadings w <dig>  w <dig> and w <dig> are equal, suggesting their association to glycerol uptake, methanol uptake and co <dig> release, respectively. different results are given by the different methods for the rotations of the loadings w <dig> and w <dig>  for w <dig> the results of the methods agree in so far as that glucose uptake is predicted in each case. the results of varimax, orthomax and quartimax in addition suggest that citrate release is also associated to this loading, wherefore this loading seems to be similar to the active e <dig>  the results for loading w <dig> suggest a biomass growth association in case of varimax and orthomax, an oxygen uptake association by quartimax and parsimax and an association to ethanol secretion in case of equamax. thus, despite the fact that the rotated loadings are easier to interpret than the original loadings, it is not clear in some cases to which reaction the loading is really associated, i.e. the methods yield different results. in comparison to the selected ems, the rotated loadings do not, in general, seem to reproduce the correlation between substrate uptake and product secretion, hence they do not provide the same level of insight as the identified ems.fig.  <dig> plot of the active ems-normalized , on the upper right the unidentified ems) and the first five pca loadings, as well as the basis rotated loadings . the corresponding reactions are shown on the right, where => signifies irreversible reactions, whereas <=> reversible reactions



analysis of the impact of noise on the performance
the impact of noise on the em selection was studied by adding 2 % or 10 % gaussian noise to the simulated data. the respective performances of pema and pca are shown in table  <dig> of additional file  <dig> and table  <dig>  in the case of 10 % gaussian noise, the ems identified with pema are identical to the case of no noise and also the explained variance values are very similar, differing by less than 1 %. comparing the results obtained with pca it can be seen that they are also very similar. the observation that the performance in terms of explained variance did not significantly deteriorate for both pema and pca when adding noise to the data is partially due to the cancelation of noise when compressing the data via the loadings or ems into a latent space.table  <dig> selected ems and the respective variance  values for one to  <dig> number of n
facs obtained for the simulated data with 10 % gaussian noise


n
fac
the set of truly active ems for data generation was ems =  <cit> . n
lv
** number of latent variables for pca



the selection of the number of latent variables to be included into the pca model can be nontrivial, because once all data underlying “true” patterns have been extracted, the pca will start to model noise patterns. typically, one analyzes the changes in captured variance to decide upon what number of latent variables to use. the choice of the number of factors in the case of pema seems to be easier. it can be seen that pema reaches a plateau at a value of  <dig>  % of explained variance in both the cases no noise  and 10 % noise . once pema extracted all main features in the data, the method will “choose” between the various ems such that the patterns remaining in the data are explained. though the method then starts to capture noise patterns as well, the changes in explained variance values are very low, less than those observed for pca for the same amount of captured variance. the reason is that, unlike pca, the entries of the ems vectors are fixed a priori and not adapted to the data as in the case of the pca loadings. however, in the case of 10 % noise, table  <dig>  the explained variance value increases by  <dig>  % from nine to ten nfacs, erroneously suggesting that the 10th em would also belong to the set of active ems. thus care must also be taken when choosing the number of pems. in the present study either a number of nine pems seems to be appropriate to describe the data and a number of four or five latent variables in the case of pca. the estimations obtained with one to eight pems  and five latent variables  are shown in fig.  <dig> for the case of 10 % noise. the estimations of the fluxes improve for an increasing number of pems and also the differences in the contributions of the pems to the flux estimations can be noted. for all eight pems a good agreement between the data and estimations can be found. it suggests however that the zero values of the glucose, glycerol, citrate and methanol fluxes are not so well approximated. this might be due to the fact that these values do not have a big impact on the estimation performance. in the case of citrate it can also be observed that its uptake is not considered by the selected pems, as the negative flux data values are estimated to be zero. again the reason for this might be the magnitude of these values and their low contribution to the estimation performance. in the case of pca, the estimations match the data very well for all fluxes.fig.  <dig> normalized flux estimations over normalized flux data for pca with five latent variables and each of the  <dig> identified ems by pema in the case of 10 % gaussian noise



analysis of the number of evaluated ems combinations and computation time
the greater the number of nfacs  the greater the number of possible em combinations that have theoretically to be evaluated, as shown in fig. 4a. however, in the case of the proposed branch and bound method fewer combinations are evaluated for an increasing number of nfacs, ranging from 5 % of evaluated to possible combinations for two factors to about  <dig>  % for  <dig> factors. the number of evaluated combinations varies slightly for different levels of noise, but the number of evaluations, for all levels, remains far below the theoretically feasible number of combinations, i.e.: at most 5 % of the theoretically possible combinations were evaluated. the computation time increases fairly linearly with the number of ems combinations that were evaluated. on average it takes  <dig>  × 10− <dig> s to evaluate how much variance is explained by one em, fig. 4b.fig.  <dig> 
a number of combinations of ems, n
f, on the left axis and computation time for the evaluation of the combinations, t
f on the right axis against numbers of factors, n
fac. black circle and continuous line: theoretical possible number of combinations; black/gray plus and continuous line: combinations evaluated/computation time by the branch and bound approach in case of no noise; black/gray square and dashed line: combinations evaluated/computation time by the branch and bound approach in case of 2 % noise; black/gray star and dashed-dotted line: combinations evaluated/computation time by the branch and bound approach in case of 10 % noise. b computation time for the evaluation of one em, t
f/n
f. black plus and continuous line: no noise; black square and dashed line: 2 % noise; black star and dashed-dotted line: 10 % noise



pichia pastoris experimental case study
this case uses the same metabolic network of pichia pastoris as the simulated case, containing a set of  <dig> ems  <cit> . the aim in this case study is to evaluate the performance of the pema under real experimental conditions, potentially revealing which metabolic pathways are active. the flux data used in this study stem from tortajada et al’s collection of flux data from the literature  <cit> . the set of ems also originated from tortajada et al’s study  <cit> , where they were analyzed with respect to possible substrate conversion to biomass and compared to experimental yield data. in table  <dig> the ems selected with the proposed approach and their respective explained variance values for different numbers of factors are shown. it can be seen that from four factors on, the same one to nfac- <dig> ems are chosen, which, in accordance with the findings in the simulated case study, indicating that a set of truly active ems is identified. for the fourth factor two ems are given, because e <dig> and e <dig> are indistinguishable given only the measured flux values . for more than six factors the explained variance value does not further significantly increase, which suggests that the ems identified for greater number of factors might not be biologically significant, i.e. they are used to explain the noise patterns. the clear plateau in the variance values, which can be observed in all studied cases for pema, helps in the choice of the number of factors, as the results indicate that the appropriate number of ems is the one, which explains the most variance before reaching the plateau. thus, a set of six pems is identified, which can explain about 99 % of the variance observed in the data. the choice of the number of latent variables in the case of pca seems to be harder than the choice of the number of pems in pema. while typically a number of latent variables that explains about 90 % of the variance would be chosen in the case of pca , the variance values are still increasing significantly for an increasing number of latent variables . thus, two or three latent variables could be appropriate to explain the variation in the data with pca.table  <dig> selected ems and the respective captured variance  values for one to ten number of n
facs obtained for experimental data given in tortajada et al.  <cit>  and the best first solution of the greedy approach 


n
fac

n
lv
* number of latent variables for pca



the estimations obtained with one to six ems  and the three latent variables  for the flux data are shown in fig.  <dig>  the contributions of the selected pems to each of the flux estimations can be clearly observed and the flux estimations with six pems are close to the experimental flux data. in case of the carbon dioxide and oxygen fluxes some of the estimations do not approximate the data well, which is most probably due to the overall magnitude of the carbon dioxide and oxygen flux values  and consequently their low impact on performance. also slight mismatches can be observed in the case of low glycerol flux values, most probably due to the same reason. the pca estimations match the data very well for all fluxes. the number of evaluated em combinations is, as in the simulated case, much lower than the theoretically possible number of combinations ranging from 36 %  with two factors to  <dig>  × 10−6 % with ten factors, see fig.  <dig> fig.  <dig> normalized flux estimations over normalized flux data for pca with three latent variables and each of the six identified ems by pema

fig.  <dig> number of combinations of ems, n
f, over numbers of factors, n
fac. black circle and continuous line: theoretical possible number of combinations; black squares and continuous line: combinations evaluated by the branch and bound approach



biological interpretation of the pems
the advantage of pema is that the predominantly active pathways can be identified by looking at the selected pems. the metabolic network, which was adopted from tortajada et al.  <cit>  and used in this study, is shown in fig.  <dig>  together with the predominantly active pathways as indicated by the pems which are represented in different colors. it can be seen that e <dig>  e <dig> and e <dig> describe biomass growth using either glucose, glycerol or methanol, respectively. these three ems have the shortest paths for growth of biomass on the respective substrate while also adhering to the secretion rate constraints, i.e. the shortest distance between biomass and the respective substrate, where the length of a path/em is the number of reactions that it comprises. shorter distances between two compounds are favored from an evolutionary point of view  <cit>  and the selected ems such seem to make sense. also shorter ems can carry higher fluxes  <cit> , which in case of the three selected ems might allow higher growth rates.fig.  <dig> the metabolic network of pichia pastoris considered in this study and adopted from tortajada et al.  <cit> . the different colored arrows correspond to the pems of the experimental case study



the e <dig> describes the uptake of glycerol and release of citrate and is involved in the reduction of nad+ to nadh. it is the shortest em for production of citrate from glucose, which again might mean that this path is evolutionary favored  <cit> . as can be taken from fig.  <dig>  this em is inactive for most experiments. in the ambiguous case of e4/e <dig>  methanol is consumed using oxygen thereby releasing carbon dioxide. both ems seem to be involved in the generation of reducing equivalents, reducing nad+ to nadh via reactions  <dig> or  <dig>  either in the cytosol  or mitochondria , respectively. however, the length of em <dig> of  <dig> is significant shorter than e <dig> with  <dig>  wherefore it could be hypothesized that e <dig> is more likely to be “really” active. the production of energy and nadh from glycerol is described by e <dig>  which has a length of  <dig>  for reactions  <dig>   <dig> and  <dig>  the direction of e <dig> is opposed to e <dig> and e <dig>  which seems to violate the non-cancelation principle  <cit> . however, looking at the weights in fig.  <dig>  it can be observed that the opposing contributions of the ems generally differ by one order of magnitude. for different experiments the ems are weighted differently, i.e. a distinct em activity pattern can be observed for every experiment. thus, it seems that for each experiment the cancelation principle is retained. other opposing contributions of ems to reactions in the pentose phosphate pathway, which were analyzed in the same way, also seem experimentally to adhere to the cancelation principle. in future, the introduction of a hard constraint into the branch and bound part of the algorithm that accounts explicitly for the cancelation principle might help to reduce the number of evaluations of em combinations further.fig.  <dig> intensities of the scaled weights, p, for each identified em and for each of the experiments are shown. in all experiments vglc =  <dig>  and vcit =  <dig>  except for d <dig>  vmet =  <dig>  in experiments a <dig> and b <dig>  vgly =  <dig>  in c <dig> and d <dig>  veth =  <dig> for all experiments. for more details see tortajada et al.  <cit> 



none of the pems is predominantly active for all experiments . this might be due to the algorithm, which requires sufficient excitation/variation in the data for the identification of the ems, whereas constantly active ems might show a rather low variation. however, the variations in the activity patterns might be due to changes in the cellular environment. for instance, experiment d <dig> was the only one in which glucose uptake and citrate secretion were present, which is reflected by much greater activity of e <dig> than in the other experiments. therefore, it seems that the cell responds to the changing environment by regulation of the activity of different pathways, reflected by the activity of the different ems, as is captured by pema.

saccharomyces cerevisiae experimental case study
a metabolic network for saccharomyces cerevisiae proposed by hayakawa et al.  <cit>  and fluxome data from  <cit>  and  <cit>  was used in this study . the network describes the central cytosolic and mitochondrial metabolism of s. cerevisiae, comprising glycolysis, the pentose phosphate pathway, anaplerotic carboxylation, fermentative pathways, the tca cycle, malic enzyme and anabolic reactions from intermediary metabolites into anabolism  <cit> . a biomass synthesis reaction was incorporated from  <cit>  replacing the single reactions for every biomass component, in order to bundle the flux contributions for biomass growth . the network contains  <dig> compounds  and  <dig> reactions, yielding a total number of  <dig> ems, which were calculated using the efm toolbox  <cit> .

the objective in this case study is to evaluate the performance of pema on fluxome data and for a case with a greater number of ems, i.e.  <dig> ems in this case in comparison to  <dig> ems in the prior cases. the observed behavior in the explained variance for one to six factors is similar to the one observed in the other case studies, i.e. a shift from an initial selection of the same  <dig> to nfac- <dig> ems  to a second selection of the same ems for four to six factors . however, in the present case the combination of selected ems changes several times for further increases in the number of factors. only for eight and nine factors the same  <dig> to nfac- <dig> ems are selected again. for nine factors all reactions are represented for the first time in the selected ems, as can e.g. be seen in fig.  <dig> , wherefore nine factors seem to provide a minimal base. however, the explained variance value increases by  <dig>  % from nine to ten factors, which in comparison to the behavior observed in the cases before, seems to indicate that more than nine factors should be chosen. the percentage of the explained variance of the greedy solution is found to stabilize around 91 % from ten factors on  and the explained variance seems to converge towards 92 % for an increasing number of factors, which agrees with the behavior observed in the previous cases. the computation time required for the evaluation of combinations with  <dig> factors stalled as described later, which is most likely due to the very low differences in the explained variance values between different combinations of ems. hence, it might be that the increase in the explained variance value from ten factors on is describing noise rather than the underlying behavior. for pca, the total explained variance is slightly higher than in case of pema, which matches the observation in the other cases. three or four latent variables can be chosen for pca.table  <dig> selected ems and the respective captured variance  values for one to ten number of n
facs obtained for experimental data extracted from  <cit>  and  <cit> 


n
fac

n
lv
** number of latent variables for pca. bf* best first solution obtained by the greedy approach

fig.  <dig> reaction estimations over data of the exchange reactions for pca with five latent variables and for pema with eight, nine and ten factors. the units of the reactions are in mmol/gcdw/h except for specific biomass growth 1/h. the corresponding reactions are shown on the top, where => signifies irreversible reactions



the estimated flux values for the exchange reactions with eight, nine and ten factors in case of pema and for pca with four latent variables are shown in fig.  <dig> . the fit of the estimates to the experimental data is generally good for all these numbers of factors, however sam production is only modeled from nine factors on. the greatest discrepancies can be observed in case of the malate reaction for both pema and pca. with ten factors pema estimates the acetate and glycerol reactions significantly better than with nine factors, thus the pema solution with ten factors is preferred over the one with nine factors.

biological interpretation of the pems
the active ems and their contributions to each experiment are shown in fig.  <dig>  the conversion of glucose to ethanol described by e <dig> was repeatedly selected by pema across different factors. this em has a particularly high contribution in experiments six and seven, which were performed at high glucose consumption rates. it has a length of nine, which is the shortest em for the conversion of glucose to ethanol. the shortest em is also selected for transforming glucose into acetate, e <dig>  this em is active in experiments one, two and five to seven. the contributions are particularly high in experiments six and seven. as mentioned before, shorter ems are assumed to be evolutionary favored  <cit>  and they can carry greater fluxes  <cit> .fig.  <dig> the entries in the active ems selected by pema with ten factors for the reactions. zero valued entries are shown in grey. the contributions of the active ems to the seven experiments. experiments  <dig> to 4: strains s288c and kyokai  <dig> at specific growth rates  <dig>  and  <dig>    <cit>  and experiments  <dig> to 7: strain atcc  <dig> at specific growth rates  <dig> ,  <dig>  and  <dig>    <cit> 



three ems, e <dig>  e <dig> and e <dig>  describe the conversion of glucose to biomass growth via different routes. the lengths of the ems are  <dig>   <dig> and  <dig>  respectively. the shortest ems for biomass growth have a length of  <dig>  the longest are  <dig>  and the average length is  <dig>  in experiments five to seven e <dig> is not active. since the yield of biomass as a function of glucose varies between the experiments, two/three ems are required to describe biomass growth. this also explains the variation in the length of the three selected ems, which results in different yields of biomass growth on glucose of ems, e <dig>  e <dig> and e <dig>  i.e.:  <dig> ,  <dig>  and  <dig> , respectively.

energy generation is described by e <dig>  which seems to be more active in experiments five to seven . the conversion of glucose to lactate and succinate, e <dig>  can be observed to be predominantly active in experiments one and three, which both have a low specific biomass growth rate. lactate and succinate formation were assumed to be zero for experiments five to seven and at the same time e <dig> is hardly active. this em is the only one which transforms glucose to lactate and succinate and it is interesting to note that the flux goes through the pentose phosphate pathway. it was described in  <cit>  that during oxidative growth the pentose phosphate pathway alone is sufficient to completely supply nadph for anabolism, which might explain why the flux goes through this pathway.

the conversion of glucose to glycerol and the generation of energy are described by e <dig>  which due to the involvement in both processes has a length of  <dig> and such is longer than ems that only describe glucose conversion. this em is majorly active in experiments six and seven, in agreement with the observed higher glycerol formation. the e <dig> was repeatedly selected by pema across different numbers of factors and it describes the formation of citrate and malate from glucose. the flux goes through the pentose phosphate pathway, thus it is longer  than the shortest option . in experiments five to seven citrate and malate formation was assumed to be zero and consequently this em is not active for those experiments.

the production of s-adenosyl-l-methionine , malate and glycerol is described by e <dig>  this em is particularly active in experiments three and four, the experiments with the high sam producing strain kyokai  <dig>  the increased activity of the tca cycle observed in these experiments  <cit> , is partially reflected by e <dig>  in that malate is produced via the tca cycle.

analysis of the number of evaluated ems combinations and computation time
the number of theoretically possible combinations of em increased significantly due to the greater number of  <dig> ems opposed to  <dig> ems in the cases before, i.e.  <dig>  ×  <dig>  opposed to  <dig>  × 10+ <dig>  for  <dig> factors, respectively. the number of evaluated combinations and the computation of the branch and bound method also increased in the present case, but the average time to evaluate how much variance is explained by one combination decreased to  <dig>  × 10− <dig> s in comparison to  <dig>  × 10− <dig> s in the simulated case, fig. 4b and fig. 11b . thus, in this case the combinations are evaluated about  <dig> times faster . the reason for this improvement in performance is the way the algorithm can be implemented, using vector and matrix multiplications. only two operations are required to evaluate m − ifac ems, i.e.: computing the results for eqs.  and . thus, it can be expected that in cases of a greater number of ems a solution can still be obtained with reasonable computation time. however, critical for the computation time is increases in the number of factors, as can be seen in fig. 11a. this also becomes evident looking at the theoretically possible number of em combinations:  <dig> ncomb=m!nfac!⋅m−nfac!=∏i=1nfacm−i−1nfac!≈mnfacnfac! fig.  <dig> 
a number of combinations of ems, n
f., on the left axis and computation time for the evaluation of the combinations, t
f, on the right axis over numbers of factors, n
fac. black circle and continuous line: theoretical possible number of combinations; black/gray plus and continuous line: combinations evaluated/computation time by the branch and bound approach. b computation time for the evaluation of one em, t
f/n
f




the increase in the number of factors results in an exponential increase in the number of combinations. the numbers of evaluated combinations do increase much more slowly, however the number of evaluated combinations and computation time for more than ten factors are not shown, since the computation time exceeded two weeks. the reason for the drastic increase in computation time from ten to  <dig> factors is most likely that the differences in the explained variance values between the combinations is not as distinct as in the previous cases, wherefore many more combinations need to be evaluated and compared. this assumption is also supported by the observation that the explained variance values produced by the greedy approach stabilize around 91 % from ten factors on . thus, the proposed branch and bound approach seems to work efficiently even for greater number of ems as long as the differences in the explained variance values for a given number of factors are sufficiently distinct. however, increases in the number of ems by several orders of magnitude have not been studied here and it might be that even with the proposed branch and bound approach the number of evaluations is so elevated that the application of approximation techniques, such as relaxation, becomes necessary.

CONCLUSIONS
a method that analyzes reaction flux data using combinations of elementary  modes  has been proposed. the method avoids the evaluation of all possible combinations of ems by using a branch and bound approach. it was shown that pema identifies the principal elementary modes , which are those combinations of ems that account for most of the variance in the flux data, and that pems are a faithful representation of active pathways. from studies in which  <dig> and 10 % gaussian noise was added to the data, it can be concluded that the performance did not deteriorate for the correct identification of the pems. also the performance in terms of explained variance did not decrease significantly for increasing levels of noise. in comparison to pca it was observed that pca can explain more variance in the data with fewer latent variables, but in contrast to pca latent structures, the pems have a biological meaning. it also appears to be easier to choose the number of pems than the number of principal components in pca. in addition, it was shown that the analysis of the pems might reveal insights into the regulation of the pathways. the set of pems is not exhaustive as only those pems can be identified that have a traceable footprint in the flux data, whereas other ems might be active that do not contribute to the footprint significantly and thus are probably of minor interest.

declaration
ethics approval and consent to participate
not applicable.

consent for publication
not applicable.

availability of data and material
all data are publically available, either from the additional files or the original articles, which are cited in this article.

additional files
additional file 1: additional mathematical details of the algorithm, details for the generation of the simulation case data and additional results for the simulated pichia pastoris and saccharomyces cerevisiae case study 

additional file 2: matlab implementation of the proposed algorithm. 

additional file 3: data of the simulated pichia pastoris case study. 

additional file 4: data of the saccharomyces cerevisiae case study. 



abbreviations
emelementary flux mode

pcaprincipal component analysis

pemprincipal elementary flux mode

pemaprincipal elementary mode analysis

sams-adenosyl-l-methionine

competing interests

the authors declare that they have no competing interest.

authors’ contributions

the project was conceived by sfa and ro. experiments were performed by mvs, cma and ml. the algorithm was developed and implemented by mvs. algorithms benchmarking and data analysis was performed by mvs, cma and ml. manuscript writing was performed by mvs, cma, ml, sfa and ro. all authors read and approved the final manuscript.

acknowledgements & funding
the authors would like to acknowledge professor steve bull for his comments on the manuscript. further, the authors would like to acknowledge financial support by the portuguese fundação para a ciência e a tecnologia . the author mvs acknowledges financial support by the portuguese fundação para a ciência e a tecnologia  and by the portuguese fundação para a ciência e a tecnologia and the deutscher akademischer austausch dienst, reference number:  <dig> 
