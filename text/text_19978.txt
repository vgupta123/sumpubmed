BACKGROUND
lung cancer is one of the most frequent cancers worldwide. similar to breast cancer in female, lung cancer is the leading cancer in males, with 17% of the total new cancer cases and 23% of the total cancer deaths. the prognosis of lung cancer is still poor, with five-year survival rate of approximately 10% in most countries. lung cancer can be classified as small cell lung cancer  and non-small cell lung cancer . nsclc accounts for the majority  of lung cancer  <cit> . two major types of nsclc are adenocarcinoma  representing about 40% and squamous cell carcinoma representing about 25–30%  <cit> . accurate classification and survival analysis can provide assistance for personalized treatment planning and prognosis.

histopathology images serve as a golden standard for lung cancer diagnosis since they can provide a comprehensive view of the disease and its effect on human tissue  <cit> . figure  <dig> shows some representative images of squamous cell carcinoma and adenocarcinoma. currently, pathologists make diagnosis decision based on cellular and inter-cellular level morphology. most of current pathology diagnosis is still based on subjective opinions of pathologists and the varying abilities of doctors could result in large interpretation errors or bias. the proposed framework, which focuses on automated quantitative analysis of histopathology images, could alleviate the subjectivity in nsclc diagnosis and provides supports to doctors in lung cancer classification and patients’ survival analysis.figure  <dig> 
example images of squamous cell carcinoma  and adenocarcinoma . notice:  <dig>  elongated or spindle cells are more abundant in squamous;  <dig>  squamous has more clear cell boarders;  <dig>  squamous usually are more pink while adeno are more purple or blue.



recently, there are much active research in imaging informatics . before computer-aided lung cancer diagnosis and survival analysis, usually accurate image segmentation  <cit>  is a prerequisite. sometimes the explicit segmentation may not be required for the applications when the tumor microenvironment is critical for tumor classification; however, in our study, we find that explicit cell localization and cellular features are important for nsclc classification and survival analysis.

because crowding and overlapping cancer cells often present significant challenges for most traditional automatic segmentation methods. a vast variety of algorithms based on watershed and its variants , graph cut  <cit> , and active contour models  have been proposed. however, none of these methods could robustly handle touching cell segmentation challenges exhibited in lung cancer images. lu et al.  <cit>  has proposed a supervised learning-based segmentation algorithm to support new image features extraction and polyp detection on ct images, and a flexible, hierarchical feature learning framework integrating different levels of discriminative and descriptive information is presented in  <cit> . supervised learning is a potential approach to tackle these challenges, but it requires a lot of labeled training data provided by experienced pathologists. for computer-aided classification, genetic algorithms  and support vector machines  have been combined for multi-class cancer identification based on microarray dataset  <cit> . partial least square regression  and support vector machine with recursive feature elimination  have been applied to lung cancer subtype classification  <cit> . in  <cit> , the lung cancer image classification is modeled as a multi-class multi-instance learning problem, and an adaboost algorithm has been used to perform classification with a bag of feature model. none of these studies correlated image features with the patient survival information.

survival analysis is related to death in biological organisms and failure in mechanical systems. several commonly used survival analysis methods are the kaplan-meier method for estimating the survival function  <cit> , the log-rank test for comparing the equality of two or more survival distributions, and the cox proportional hazards  model for examining the covariate effects on the hazard function  <cit> . in survival analysis, one important issue that needs to be considered is censoring problem . cox proportional hazards model  <cit>  is one of the most commonly used multivariate approaches to analyze the survival time data in medical research. it is a semi-parametric method that does not need a specific baseline hazard function and has the capability to effectively handle censoring problem. in other words, it is not necessary to specify a survival distribution to model the effect of the explanatory variables on the duration variable.

in survival analysis, researchers also considers clinical factors or other environmental information . for example, standard cox proportional hazards survival model with a spatial random effect extension has been applied and proved that the long-term exposure to combustion-related fine particulate air pollution is an important environmental risk factor for cardiopulmonary and lung cancer mortality  <cit> . gene signature expressions have also been used as covariates to conduct survival analysis  to search for pairs of genes  that are significantly related to patient death.

in this paper, we will present an integrated framework that investigates the prognostic effects of image markers. first, a novel seed detection-based repulsive deformable model is proposed to separate touching cells; secondly, a set of geometry, pixel intensity, and image texture features are extracted to describe cellular morphological properties; thirdly, eight different classification techniques are comparatively analyzed for computer-aided diagnoses of nsclc; finally, survival analysis is conducted based on a cox model fitted by component-wise likelihood based boosting. the entire system is designed to assist doctors for more objective and accurate diagnoses and prognoses of nsclc. unlike gene sequencing, histopathological slides are always available for each lung cancer patient in routing clinical diagnosis, and therefore the adoption of the developed prediction model does not require any changes to current clinical practice.

the experiments in the paper are conducted using the adenocarcinoma and squamous cell carcinoma lung cancer images downloaded from the tcga data portal. tcga  is a collection of cancer specimens, with additional clinical information about participants, metadata about the samples, histopathology slide images from sample portions and molecular information derived from the samples. it is supervised by national cancer institute  and national human genome research institute  and freely available to researchers.

methods
cell detection and segmentation
seed detection is the first critical step for marker-based segmentation methods. motivated by  <cit> , we have proposed a multi-scale distance map-based voting algorithm for cell detection. the newly developed method can efficiently handle relatively large cell size and shape variation. for each point , we define a cone-shape voting area a with vertex at  and votes towards the negative gradient direction of the vertex. a 2d gaussian kernel k is introduced to weight the voting points:  <dig>  

where c <dig> is the normalized constant, s represents the set of all voting points, ac denotes the cone-shape voting area with vertex  and scale c. the voting area at each scale is defined as the radial range  and angular range Δ,   is the mean of the gaussian kernel. Σ=σ2i <dig>  is the covariance matrix.  is the indicator function:  <dig> for ∈ac and  <dig> otherwise. gd represents the euclidean distance map. after the confidence map v is calculated, we remove those points with relatively lower voting values, which locate near the cell boundaries. in order to achieve a robust seed detection, we apply mean shift  <cit>  to locate the final positions of cell seeds.

using the boundaries of detected cell seeds as initializations, a novel repulsive balloon snake  algorithm based on a deformable model  <cit>  is used to seek the cell boundaries. rbs is a parametric model which can naturally preserve cell topologies and prevent contours from splitting or merging with one another.

a snake is an active curve as v=,y),s∈ <cit> , moving through the image domain to minimize its energy functional, under the influence of internal and external forces. to enforce snakes to inflate or deflate, a pressure force to propose the balloon snake  model was introduced  <cit> . the external force  is calculated by:  <dig>  

where n represents the normal vector  to the curve at the specific point on v and ∇eext) is defined as image force, where eext)=-||∇i)|| <dig> ) is the original image). γ and λ are the weighting parameters controlling pressure force and image force, respectively.

balloon snake  model can not be directly used for touching object segmentation. if all balloon snakes move independently, they will cross with one another. based on these observations, we introduce an interactive scheme to form a rbs model for touching cell segmentation. the intrinsic idea of rbs is based on the following: the cell contour should be driven by its own forces as well as extrinsic forces from other deformable contours; both amplitudes and directions of these extrinsic forces should vary with respect to the distance between snakes. when two snakes are far away, their movements should be dominantly controlled by their own driven forces ; when they get closer, each snake should receive repulsive forces from all other adjacent snakes. as a result, the extrinsic force will prohibit snakes from crossing or merging.

given an image i with n cells , the new repulsive external force  for vi is defined as:  <dig>  

where dij=||vi-vj|| <dig> is the euclidean distance between vi and vj. f> <dig> x∈, represents a monotonic decreasing function =x- <dig> in our case), and ω weights the repulsive force. for a specific point vi, the closer it moves to other snakes, the more repulsive forces it will receive. unlike the original balloon snake, rbs moves contours under the influence of their own driven forces and extrinsic repulsive forces from other snakes. when these two types of forces achieve a balance, snakes stop evolving.

feature extraction
based on the segmented cell boundaries, three groups of cellular features are extracted for subsequent classification and survival analysis. in total we have extracted  <dig> image morphometric features, which are represented as the candidates of image markers. the detailed notations of feature names and descriptions are listed in the table  <dig> table  <dig> 
the image features and their descriptions


the 1- <dig> in each image feature represent the mean, median, variance and three frequency values of the histogram for each intensity and geometric feature, respectively. csac, tfcm, lbp and texton histogram features are high dimensional feature vectors, therefore we calculate their moment statistics to reduce the dimensionality. in total we have extracted  <dig> geometric, pixel intensity, and image texture feature variables for each patient. all variables are normalized before further classification and survival analysis.



group 1: geometry features. five geometry features are calculated for each segmented lung cancer cell, including area acell, contour perimeter pcell, circularity , major-minor axis ratio, and contour solidity that is defined as the ratio of cell area region over the convex hull defined by the cell boundary.

group 2: pixel intensity statistics. this group of features are calculated based on the pixels in the segmented cells, including intensity mean, standard deviation, skewness, kurtosis, entropy, and energy. we use lab color space for better color representation.

group 3: texture features: this group of features contains co-occurrence matrix  <cit> , local binary pattern   <cit> , texture feature coding method   <cit> , center symmetric auto-correlation   <cit> , and texton features  <cit> . the co-occurrence matrix  <cit>  is an estimation of the joint probability distribution of intensity of two neighboring pixels. lbp  <cit>  is a measure of local textures. each pixel in the input image patch is assigned a binary code by comparing the intensity of this pixel to those of its neighbors. similar to lbp, in tfcm  <cit> , each pixel is assigned a texture feature number . the tfn of one pixel is generated by comparing this pixel with its neighbors in four directions: 0°, 45°, 90°, and 135°. a histogram is calculated based on the tfns of one image patch. csac is a measure of the local patterns with symmetrical forms. we calculated a series of local auto-correlation and covariance introduced in  <cit> , including symmetric texture covariance  and variance , and within-pair variance  and between-pari variance . 3× <dig> pixel unit of each channel is considered for csac feature. texton  <cit>  is a discriminative texture representation. the calculation of texton feature is based on unsupervised learning. we randomly picked some cells in each image as training samples. these cell patches are filtered by texton filter bank. k-means clustering is then applied and the centers of the clusters are defined as textons. to generate the texton histogram for a new image, the image is first filtered by the same texton filter bank, then each pixel is assigned to one texton to build the final texton histogram.

nsclc classification
after calculating the aforementioned image features, we first perform the nsclc subtype classification. in this stage, several conventional machine learning methods and recently published state-of-the-art algorithms that can handle high dimensional data are compared, which include multiple support vector machine recursive feature extraction  algorithm  <cit> , l <dig> penalized logistic regression  <cit> , random forest  <cit> , naive bayesian  <cit> , adaboost  <cit> , sparse coding spatial pyramid matching  alogrithm  <cit> , locality-constrained linear coding   <cit> , and nearest class mean  classifier  <cit> . msvm-rfe is an iterative feature selection method that uses a backward elimination procedure. resampling scheme is introduced to stabilize the feature rankings. at each iteration, the feature ranking score is computed based on the weight vectors of multiple linear svms trained on subsamples of the original training data and the feature with the smallest ranking score is removed from the model. l <dig> penalized logistic regression provides an efficient lasso regularization path for logistic regression, which enables feature shrinkage and selection for high dimensional data. random forest is an ensemble learning method for classification, which can generate a score by permutation to rank the importance of variables in classification problem. naive bayesian classifier is a simple probabilistic classifier based on the bayes theorem with naive feature conditional independence assumptions. the adaboost algorithm employs the idea of sequentially applying a classification algorithm to reweighted versions of the training data and then taking a weighted majority vote of a ensemble of weak classifiers. adaboost can provide an importance score for each weak classifier that corresponds to one selected feature. scspm is an extension of spatial pyramid matching  <cit>  and the algorithm uses selective sparse coding followed by multi-scale spatial max pooling and svm. llc is another feature representation method that applies locality constraint to project each feature into a sparse code. ncm is a distance-based classification with projecting the features into a low-dimensional space for classification. these three recent algorithms have already made remarkable successes on a range of nature image classification benchmarks.

survival analysis
before survival analysis, dimension reduction is a widely used approach to avoid the “curse of dimensionality”. common examples of linear dimension reduction methods, such as principal component analysis , are proposed to minimize the variances. meanwhile, least absolute shrinkage and selection operator   <cit>  method is another classic method of feature shrinkage and selection for regression that can potentially handle high dimensional data. least angle regression  is proposed for variable selection in the linear regression setting for high dimensional data  <cit> . the lars selects predictors by its current correlation or angle with the response, where the correlation is defined as the co-correlation between the predictor and the current residuals. moreover, elastic net is proposed as a new regularization and variable selection method for feature selection  <cit> . boosting is another widely used feature selection approach. it applies the idea of fitting an ensemble of weak learners to the data. furthermore, component-wise boosting has been proposed to estimate the model with intrinsic variable selection  <cit> . the term component-wise means each base learner only consists of linear function of one component . for each covariate, a base-learner is specified and only the best base-learner is updated in each boosting step. finally only part of base learners are chosen to ensemble the strong classifier when the optimal boosting iteration is reached. the algorithm can generate a strong classifier and a sparse set of selected features.

given the observations ,i= <dig> ,…,n, where ti is the observed time to the event of interest for individual i, di equals  <dig> if an event occurred at that time and  <dig> if the observation has been censored, and xi is vector of covariates obtained at time  <dig>  the component-wise likelihood based boosting algorithm for high dimensional survival analysis is based on the cox proportional hazards model:  <dig>  

where λ <dig> is the baseline hazard and x is covariate vector. for estimation, the baseline hazard λ <dig> is left unspecified and the estimate of β is obtained by maximizing the partial log likelihood.  <dig>  

for high dimensional data, penalized regression methods like lasso  <cit> , ridge regression  <cit> , would add a penalization term into the partial log likelihood function and the penalized partial likelihood is maximized by techniques such as quadratic programming.

in this paper, we apply component-wise likelihood based boosting  <cit>  to dimensionality reduction, which adapts from the offset-based boosting approach from  <cit> . in each iteration the previous boosting steps are incorporated as an offset in a penalized partial likelihood estimation. component-wise indicates that only one single parameter, i.e., one covariate, is updated in every iteration by maximization the l <dig> penalized partial log likelihood with respect to each candidate covariate.  <dig>  

where ip is a diagonal matrix to penalize each covariate separately, with diagonal elements equal to  <dig> for each candidate and  <dig> for the rest corresponding to penalization and no-penalization. the candidate covariate that can best improve the overall fitting will be selected for updating. as the number of boosting steps increases, more feature variables will be selected and chosen with respect to their relevances in predicting survival rates. the result is expected to be sparse with many coefficients equal to zero. the coefficient paths of component-wise boosting are expected to be more stable than lasso based approaches  <cit> . in addition, it has two major advantages over lasso: 1) it allows for unpenalized mandatory covariates; 2) it can handle correlated covariates by including pathway information  <cit> .

RESULTS
cell detection and segmentation
the cell detection and segmentation results are displayed in figure  <dig>  it can be observed that even for heavily touched regions, cells are still accurately detected and segmented automatically. it is worth mentioning that the proposed cell detection algorithm can handle relatively large size variations, and the repulsive snake models can prevent contours from overlapping with one another.figure  <dig> 
cell detection  and segmentation  results. please note that the cells with small areas correspond to non-tumor cells, and are automatically removed after the boundaries are extracted. those false detected seeds locating in the lymphocyte regions are also removed using a simple intensity threshold before cell segmentation is conducted.



we have compared the proposed voting method  presented in  <cit>  and the phase-coded hough transform  based on quantitative measurement. in our evaluation a positive detection is counted if a detected seed locates within a 8-pixel circle around a ground truth seed; otherwise, a miss is counted. to measure the accuracy of the cell detection algorithms, we compute the mean, variance, maximum and minimum of the distance between the detected seeds and their corresponding ground truth seeds. in addition, we also show miss rate  and false positive rate  in table  <dig>  the ground truth seeds are manually generated for comparison. as one can see, the improved voting approach produces the best performance in comparison with other two methods.table  <dig> 
the pixel-wise seed detection accuracy compared with ground truth


 <dig> 
 <dig> 
 <dig> 
 <dig> 
the best performance measured in each metric is marked in boldface.



to evaluate the performance of the segmentation algorithm, we define precision  and recall , where seg represents the segmentation result and gt represents the manually-generated ground truth. we show the mean, variance and 80% in table  <dig>  the segmentation algorithm can effectively handle touching cells and provide accurate segmentation results with high precision and recall rates.table  <dig> 
the performance of segmentation measured by precision and recall




nsclc classification
precison, recall, and accuracy have been used as prediction performance metrics for nsclc classification. the training  and testing  datasets have been randomly selected and repeated five times to test the accuracies of classification using the tcga dataset consisting of  <dig> nsclc patients. table  <dig> shows the average recall, precision, and accuracy using eight classifiers. the experiments indicate that the random forest and adaboost provide the best results.

to assess the relative importance of the  <dig> image markers, we have applied adaboost to the entire dataset and generated the frequency score for the variable selected in each boosting iteration. the results are shown in figure  <dig>  higher importance score indicates a more representative feature variable for nsclc classification.table  <dig> 
the average recall, precision and accuracy of nsclc classification


mr: msvm-rfe, pl: l <dig> penalized logistic regression, nb: naive bayesian, rf: random forest, ab: adaboost, llc: locality-constrained linear coding, sc: sparse coding spatial pyramid matching, ncm: nearest class mean classifier.
the feature importance of the  <dig> image morphometric features. only the top  <dig> image features are shown here. the x-axis represents the frequency score and y-axis denotes the name of each feature variable.



the top  <dig> features selected by adaboost are  <dig> lbp features,  <dig> solidity features, and area <dig>  kurt <dig> and peri <dig> features. among the top  <dig> features, lbp, area, solidity, axis, tfcm, energy, correlation and contrast are most commonly selected image features. peri, kurt, std and circularity all have one feature been selected. the ranking suggests that the image texture features and geometric features are representative markers to distinguish between two subtypes of nsclc: adenocarcinoma  and squamous cell carcinoma . the results also indicate that 1) there are more elongated cells for scc than ac; 2) ac usually has a relatively larger intensity variation inside cells than scc; 3) scc cells are often over-stained and exhibit more clear boundaries; 4) ac cells usually exhibit more inhomogeneous texture than scc.

survival analysis
the tcga nsclc dataset contains complete patients’ histopathological image information. it has been randomly divided into training  and testing set . the training set is used to build a cox regression model with component-wise likelihood based boosting for feature selection. among  <dig> image features, we first conduct univariate cox regression and abandon those with wald test p value less than a threshold . the rest image features are chosen as candidate markers to conduct component-wise likelihood based boosting for cox proportional hazards model. after the univariate cox regression step,  <dig> image features have been selected as candidates. the penalty parameter λ, which determines the size of the boosting steps, is determined based on cross validation. six-fold cross validation on the training set has been performed to choose the number of boosting steps m . the final representative image markers selected are energy <dig>  lbp <dig>  lbp <dig>  homo <dig>  homo <dig>  tfcm <dig> and skew <dig> with corresponding coefficients - <dig> ,  <dig> ,  <dig> ,  <dig> , - <dig> ,  <dig>  and - <dig> . please note that all these feature covariates selected belong to pixel intensity features and texture features. this demonstrates that cell staining and inhomogeneity inside the nuclei, which may indicate the protein structures of the cancer cells, hold strong potential to predict nsclc patients’ survival.figure  <dig> 
 the plot of mean partial log likelihood against the number of boosting steps using six-fold cross validation and  the plot of coefficient paths, i.
e. the parameter estimation plotted against the boosting steps until the optimal steps were reached. m =  <dig> is used since it minimizes the mean partial log likelihood. since we use an offset-based update mechanism, the same image feature might be reselected and its coefficient would be updated. we use branch-out for illustration purpose when one specific image feature is selected.



after the prediction model training procedure, we have employed the time dependent roc curves for uncensored data and auc as criteria to select the best thresholds for risk scores and assess how well the model predicts patients’ survival outcome. at time t, larger auc indicates better predictability of time to event measured by sensitivity and specificity. after classifying patients into low- and high-risk groups, we can estimate and compare their kaplan-meier survival curves. the performance of such a binary classifier is generally evaluated in terms of the overall predictive accuracy.

with the approach mentioned above, the seven-feature prediction model and a binary classifier have been applied to distinguish between the low- and high-risk groups for both training set  and testing set . kaplan-meier survival curves have been estimated and plotted in figure  <dig>  the log rank test shows significant difference between two groups. the p value on testing set is slightly larger than the training set. the good performance demonstrates the accurate survival prediction power using this set of discovered image markers.figure  <dig> 
kaplan-meier survival curves of two groups classified by predicted risk scores for training  and testing dataset . the p value of log rank test for training is  <dig> , and for testing is  <dig> . the x axis is the time in days and the y axis denotes the probability of overall survival.



using a multivariate cox proportional hazards model, we have assessed the image markers related risk score in the context of other measured prognostic factors, including age, gender, cancer type, smoking history, and tumor stage. the results are presented in table  <dig> and table  <dig>  the p value of wald test of each covariate coefficient suggests that nsclc subtype and tumor stage are significantly related to survival rate in the multivariate cox regression without the image marker related risk score. however, when the image marker related risk score is introduced, it becomes the most significant variable in the model. to further quantify how much improvement is gained in survival analysis after the risk score is added, akaike information criterion  and bayesian information criterion  of these two models are computed. the experiments show that aic= <dig> , bic= <dig>  for the first model compared to aic= <dig> , bic= <dig>  for the model including the risk score. the clear difference demonstrates strong evidence in favor of the prognostic model with image marker related risk score. hazard ratio is also measured and reported in table  <dig> and table  <dig>  a hazard ratio greater than one, or equivalently, a value of coefficient greater than zero, indicates that as the value of this covariate increases, the event hazard increases and thus the length of survival decreases. given the proposed comprehensive prediction model, for each nsclc cancer patient with h&e stained diagnostic pathology image and clinical information, we can offer a personalized survival function and automatically group the individual into low- or high-risk group with an estimated risk score.table  <dig> 
 multivariate cox proportional hazards analysis of all clinical covariates without the image feature related risk score




smoking history is a continuous variable representing years of smoking history. gender is a binary variable . cancer type is also a binary variable . tumor stage is a three level categorical variable .



to measure the robustness of the feature selection, we have conducted the bootstrap analysis. we have resampled the whole dataset  <dig> times with replacement, performed the boosting feature selection procedure on each sample and counted the frequency of selecting one specific feature variable. the top  <dig> most frequently selected image markers are: peri <dig>  homo <dig>  homo <dig>  homo <dig>  skew <dig>  lbp <dig>  lbp <dig>  csac <dig>  csac <dig> and tfcm <dig>  among the top  <dig> image features that are most highly associated with survival,  <dig> are pixel intensity features,  <dig> are image texture features and only  <dig> belongs to geometric feature. moreover,  <dig> out of the  <dig> significant features previously selected in the training set are from the top  <dig> features in bootstrap analysis on the whole set, which shows good consistence of the proposed algorithm.

univariate survival analysis has been conducted to validate the feature variable selection procedure by showing that the selected features are closely related to lung cancer patients’ survival time. we choose the median of each image marker as the threshold to group the patients and plot the kaplan-meier curves for those two groups. log rank test is conducted to test the difference of the two curves. it is shown that  <dig> out of the top  <dig> image markers selected from the bootstrap analysis can achieve significant log rank test outcome at α= <dig>  level while the others is still acceptable even though they do not reach statistical significance for this naive approach . in addition, no single image marker can achieve the same prediction power as the combined risk score using the set of discovered image markers.figure  <dig> 
kaplan-meier survival curves of the developed prognostic model for tcga nsclc dataset. high value  groups are plotted as red lines, and low value  groups are plotted as blue lines. the x axis represents the time in days and y axis denotes the probability of overall survival.  survival curves of two groups with distinct values of feature peri <dig> with a log rank p value =  <dig> .  survival curves of two groups with distinct values of feature homo <dig> with a log rank p value =  <dig> .  survival curves of two groups with distinct values of feature homo <dig> with a log rank p value =  <dig> .  survival curves of two groups with distinct values of feature homo <dig> with a log rank p value =  <dig> .  survival curves of two groups with distinct values of feature skew <dig> with a log rank p value =  <dig> .  survival curves of two groups with distinct values of feature lbp <dig> with a log rank p value =  <dig> .  survival curves of two groups with distinct values of feature lbp <dig> with a log rank p value =  <dig> .  survival curves of two groups with distinct values of feature csac <dig> with a log rank p value =  <dig> .



discussion and 
CONCLUSIONS
in this paper, we have investigated novel image markers for both computer aided diagnosis and prognosis of non-small cell lung cancer. we propose an integrated framework that consists of cell detection, segmentation, feature extraction, classification, discovery of image markers, and survival analysis for nsclc. a multi-scale distance map-based voting algorithm is first introduced to localize individual cells, and a repulsive deformable model is proposed to segment the cells using the previous detection results as initializations. a complete set of cellular features are extracted, and several advanced classification techniques are compared using the image markers calculated in previous steps. finally, a cox model fitted with component-wise likelihood based boosting is applied and several survival analysis approaches have been conducted to evaluate the discovered image features. through extensive experiments, we have found a set of diagnostic image markers that are highly correlated to nsclc subtype classification. in addition, we have also discovered a set of prognostic image markers  to predict nsclc patients’ survival. we statistically prove that the developed comprehensive image marker related risk score is a strong predictor for patients’ survival than traditional clinical factors. together with clinical information, it provides significant clinical values for patients’ prognosis.

competing interests

the authors declare that they have no competing interests.

authors’ contributions

hw conducted the classification and survival analysis experiment. fx and hs conducted the image collection, segmentation and feature extraction experiment. ly participated in the design of study and and coordination and helped to draft the manuscript. as participated in the design of the study and the statistical analysis section. all authors read and approved the final manuscript.

