BACKGROUND
tumor progression is a complicated biological process that comes with enormous genetic and molecular changes, such as chromosome aberration, gene mutations, and activation or inhibition of transcriptional pathways. the abnormal genetic changes often show high variability even among tumors within the same histopathological subtype and anatomical origin, which may lead to variation in clinical outcomes. for example, a subtype of colorectal cancer, hereditary nonpolyposis , is characterized by dominant genetic defects in dna mismatch repair pathway and hnpcc patients have higher 5-year survival than other subtypes of colorectal cancer patients <cit> . when genetic aberration is specific to a subset of tumors, it provides potent targets for chemotherapy. examples include trastuzumab and lapatinib for treating her2-positive breast cancers  <cit> , tamoxifen for treating er-positive breast cancers <cit> , and gefitinib and erlotinib for non-small cell lung cancer with egfr mutations  <cit> .

dna copy number aberration is a striking feature of tumor cell. during tumor progression, chromosome is subjected to dramatic change in that dna segments are amplified, deleted, or translocated. comparative genomic hybridization  technology has been a widely used tool for detecting changes in chromosome fragments. the advancement of array technology has enabled researchers to conduct array cgh  study for profiling genome-wide chromosome variations using high density array, such as single nucleotide polymorphism  array that contains from 100k to 3m snp markers  <cit> . such high dimensional dna copy number data reveals genomic heterogeneity in many cancer types, ensuring biomarker discovery for each genomic subtype at snp copy number level  <cit> .

multiple clustering methods, including hierarchical clustering , naive bayes, k-nearest neighbours, support vector machine, probability model-based clustering, and nonnegative matrix factorization , have been developed and applied for acgh data to identify tumor subtypes based on the dna copy number aberrations  <cit> . we have previously developed a revised version of nmf that showed improved performance for acgh clustering when testing on three tumor types, non-small cell lung carcinoma, colorectal cancer and malignant melanoma  <cit> . however, all these aforementioned methods fail to account for the spatial correlation between snps, and the correlation between adjunct snps could be as high as  <dig>  for high density snp array such as affymetrix 500k. we therefore developed a mixture model based clustering method for tumor subtype classification that uses hidden markov model  to account for the spatial correlation in acgh data.

shah et al.  <cit>  have proposed a similar hmm based clustering method to account for spatial correlation, but is fundamentally different from our clustering method in a number of ways first, the models are different. they proposed a bayesian hierarchical model, nonetheless we fit a hidden markov model to the data directly, therefore it has less unknown variables and decreases the risk of model overfitting. secondly, they use expectation maximization  like algorithm to estimate variables, and we use maximum likelihood based method that is computationally more efficient. thirdly, our algorithm automatically finds the optimal number of groups and converges to the optimal grouping. fourthly, we developed a machine learning clustering algorithm and have implemented it using c++ parallel programming for fast computation. finally, we pre-process the raw acgh data by segmenting the chromosome prior to clustering. the segmentation step normalizes acgh data that usually contains high frequency of intensity noise. we show the performance of the proposed hmm-based clustering  method by applying it to simulated data and acgh glioma data.

methods
we first describe the data pre-processing procedure, our hmm model and the model fitting for a cluster of acgh samples. then we describe the machine learning algorithm that uses hmm models to cluster tumors. finally, we introduce our fast implementation for the clustering algorithm and the approach to find the optimal number of groups.

acgh data segmentation
raw data from affymetrix snp array was preprocessed using the open source r package aroma.affymetrix with the default parameters  <cit> . the resulting snp-level copy numbers were segmented using circular binary segmentation  method within aroma.affymetrix  <cit> . the break points predicted by cbs at each sample were then summarized across all samples and the segments between pairs of adjunct break points were identified and the mean copy number of each segment was calculated for clustering analysis. because tumor specimen is often contaminated with normal tissues that are adjacent to them, which would complicate the analysis and introduce false negatives, it is necessary to conduct quality control to remove the normal contamination first. we developed a machine learning algorithm to identify and filter out contaminated samples based on segmented copy number data. to conduct the quality control, we first chose two groups of samples; one with the highest number of copy number alteration regions and the other being normal samples. these two groups of samples served as a training dataset for a random forest classifier  <cit>  that was used to distinguish tumors and normal samples and identify signatures for tumor samples. the out of bag error rate of this classifier is usually very low . the trained classifier was then applied to all acgh samples and a score of probability to be contaminated was calculated for each sample. samples with a probability of more than 50% of contamination were excluded from further clustering analysis.

hmm model fitting
we use a mixture hmm model to represent the clusters of tumor samples in that each cluster or subtype of tumors is modelled by a single hmm. let t =  <dig> .., t, denote the dna segments of acgh data. suppose there are g clusters in total and there are ng samples in cluster g, where g =  <dig> ..., g. the hmm model for cluster g is demonstrated in figure  <dig>  the hidden state at segment t is denoted as xg, which is the true copy number of segment t and is unknown. the observed mean copy number for segment t and sample j is denoted as ygj where j =  <dig>  ..., ng. the transitional probability from state t- <dig> to t is denoted as pg and the emission probability from state t to observation ygj is denoted as pgj.

based on the distribution of segmentation copy number data, we choose  <dig> states, xx{ <dig> ,  <dig> ,  <dig>   <dig>   <dig>  5}. the transitional probabilities between states are given in a multinomial distribution that was empirically estimated from the raw data. for example, for the  <dig> glioma samples we discuss in the results section, the transitional probability between the same states is  <dig> , and is  <dig>  otherwise. lognormal distribution is widely used to model dna copy number  <cit> . we let the emission probability follow a log-normal distribution with the hidden state value being the mean of the normal distribution. the standard deviation of the normal distribution was empirically estimated from raw data using the mean standard deviation of segment copy number across all samples. viterbi algorithm is used to fit this hmm model to a cluster of tumor samples. viterbi algorithm is an efficient algorithm that uses a dynamic programming approach to estimate the hidden states from segment  <dig> to t and to calculate delta value, Δg, which is the log-likelihood for the model fitting of cluster g. we have implemented viterbi algorithm in both r and c++ programming environment.

sample clustering
the optimal clustering is determined by the maximum sum of delta values from all groups. it is computationally infeasible to perform hmm fitting and calculate delta sum values for every possible clustering because the number of clustering for n samples g groups is gn. we have developed a computationally efficient algorithm for finding the clustering optima.

the algorithm searches the optimal clustering as follows. first, for a given number of groups g, we run a nmf algorithm that was developed earlier to preliminarily cluster the samples. the nmf algorithm has been described previously  <cit> . though nmf classifies acgh data without considering the correlation between markers, it has been shown to discover genomic signatures in various types of tumors  <cit> . thus, the clustering result of nmf serves as a starting point for hmm clustering. secondly, we fit a hmm for each cluster from the previous step and calculate the sum of delta values, Δ <dig>  ..., Δg. this is the log-likelihood for the current optimal clustering. thirdly, based on the current optimal clustering, we randomly select  <dig> samples, and re-assign the group labels to them. we then perform hmm model fitting and calculate the log-likelihood for the new clustering. if the new log-likelihood is greater than the optimal log-likelihood, we update the optimal clustering with this new clustering. fourthly and finally, we repeat the last step a number of times, and stop until the optimal log-likelihood remains unchanged for m times of consecutive random clustering. we find that m = n <dig> is sufficient for hmmc to converge to the optimal clustering. this workflow of clustering procedure is illustrated in figure  <dig> 

we have use both r and c++ to implement this clustering algorithm. as step  <dig> can be performed simultaneously for multiple random clustering, we implemented a parallel computing version of hmmc to decrease the computation time. this was accomplished using the openmp package  <cit>  within c++ to allow the random clustering and hmm fitting to be carried out across multiple threads in a multi-core machine. each thread can update the optimal clustering and all threads share the same optima. we have tested this program in dell poweredge r <dig> workstation that has 32-cores and the parallel computing increased efficiency by an order of magnitude.

model selection
one of the most difficult questions about clustering problem is to determine the number of groups, g. our hmmc algorithm relies on a given g to find the optimal clustering. thus model selection is needed to determine the best number of groups.

we use the bayesian information criterion , a widespread statistical tool to conduct model selection. bic is defined as follows:

 bic=-2lnl+k× ln, 

where l is the likelihood which measures how good the hmm model approximate the data, k is the number of parameters used in the model, and n is the number of samples. the second term, kln, serves as a penalty on the number of parameters used in the model to avoid overfitting. thus, the magnitude of penalty increases as the number g increases. a preferred model is selected upon a lower bic value that indicates relatively higher likelihood as well as relatively lower risk of overfitting.

the sum of delta values is the log-likelihood for hmm model fitting,

 lnl= ∑g=1gΔg, 

where Δg is the delta value of the gth group. because the parameters for transitional and emission probability are empirically estimated, the number of unknown parameters k in bic is equal to the number of hidden states. for an acgh dataset with g groups and t segments, the number of parameters is equal to t × g. thus, the bic for hmm is defined as

 bic=-2∑g=1gΔg+t×g× ln. 

we run hmmc for a range of values of g, and select the optimal g with the smallest bic.

cross-validation for testing stability of hmmc
to assess the stability of hmmc results, we conduct a cross-validation as described earlier  <cit> . after completing hmmc for the entire dataset, we perform cross-validation as follows. we randomly leave 10% of samples out and apply hmmc to the remaining 90% of samples and compare the clustering results with the original one. the number of samples that are assigned to a different subgroup other than the original result is counted as errors. we repeat this procedure  <dig> times and calculate the error rate, which represents the stability of the clustering algorithm with respect to the permutation of samples.

RESULTS
simulation study
in order to test the performance of hmmc, we conducted simulation study to compare hmmc with nmf clustering. we created two groups of acgh data with  <dig> samples per group and  <dig> segments per each sample. for the first group, all data were generated from a normal distribution with mean equal to  <dig> and standard deviation equal to s, which was variable between different experiments. for the second group, the copy number of all segments followed a normal distribution as well. this normal distribution was the same as the first group, except that  <dig> segments in the middle of genome had a mean equal to  <dig> such that these  <dig> segments were amplified. in order to introduce random noise, we randomly drew  <dig> segments in all samples and increased their copy number values by  <dig> . thus these  <dig> segments were randomly amplified segments. furthermore, ar correlation was introduced into the data. considering the high correlation between snps in the high density snp array, we set the pho value of ar to be  <dig> .

we used hmmc and nmf to cluster the two groups with s value varying from  <dig>  to  <dig>  for each s,  <dig> acgh datasets were generated and the number of samples misplaced for either method was counted. the error rate curves are shown in figure  <dig> 

the error rates of both hmmc and nmf increase as the standard deviation s increases. the error rates of hmmc are in the range of 3% to  <dig> %, whereas those for nmf are between  <dig> % and  <dig> %. therefore, the chance for hmmc to incorrectly classifying samples is less than half of that for nmf in our simulation study.

glioma data
glioma tissue acgh data were acquired from repository for molecular brain neoplasma data   <cit> . we obtained affymetrix 500k snp array data and the corresponding clinical information for  <dig> glioma patients. the acgh data was first processed using aroma.affymetrix software and was then segmented using circular binary segmentation method. this preprocessing step reduced the number of markers from 500k to  <dig> segments. the segmented data was used for further analysis.

the first question to be addressed is the computational performance of hmmc when it is applied to high-dimensional data. we first test the convergence rate of hmmc for glioma acgh data assuming  <dig> groups. as shown in figure 4a, the log-likelihood of hmmc increases rapidly in the first  <dig>  cycles of clustering, and it remains stable after  <dig>  cycles. the log-likelihood reaches its maximum at approximately  <dig>  cycles, and the computation stops after an additional  <dig> =  <dig> cycles.

secondly, we tested the computation time for different number of samples. random samples were drawn from the  <dig> glioma data. the numbers of random samples was from  <dig> to  <dig> and the number of groups was assumed to be  <dig>  we used a dell poweredge r <dig> to run  <dig> threads simultaneously for this test. figure 4b shows the curve of computation time. for  <dig> samples, it took less than  <dig> minutes. for  <dig> samples, it took about  <dig> hours to find the optimal clustering. the computation time is approximately linear to the number of samples ). therefore, our clustering algorithm is computationally efficient and it achieves o for the computational complexity.

to find the optimal number of groups, we conducted model selection using bic. we ran hmmc for the number of groups g from  <dig> to  <dig>  and calculated the corresponding maximum log-likelihood and bic. the results are shown in table  <dig>  the maximum log-likelihood increases as the number of groups increases because the model has a better fit for the data as the number of parameters increases. the bic value was - <dig>  for  <dig> groups, then it decreased to - <dig>  for  <dig> groups, and then increased as the number of groups increased. thus, the optimal number of groups is  <dig> because it gave the minimum value of bic.

to verify the clustering results, we performed survival analysis to the  <dig> groups. the kaplan-meier curves are shown in figure  <dig>  the blue line is group  <dig>  the green is group  <dig> and the red is group  <dig>  the median survival time for group  <dig> is  <dig> days, whereas those for group  <dig> and  <dig> are  <dig>  and  <dig>  days, respectively. group  <dig> has a significant lower overall survival than group  <dig> and  <dig>  the overall p value by log-rank test is less than  <dig> . therefore, hmmc successfully clustered glioma samples based on acgh data and the resulting tumor subtypes were associated with clinical outcomes. as discussed previously, group  <dig> manifests with large segments of deletion in chromosome  <dig>  thus genomic signature is identified for poor clinical outcome and they can serve as prognostic biomarkers. upon identification of genes located in these abnormal genomics regions, we can discover the potential target for cancer therapy.

discussion
genomic information has been increasingly used for molecular classifications of tumors because it provides a more objective view than histopathological approach and it sheds light on the molecular mechanisms of tumor heterogeneity. the global gene expression of major tumor types has been extensively studied for subtype identification  <cit> . the fast development of snp array has made it possible to characterize tumor subtypes based on the genomic dna copy number, nonetheless, the computational and statistical methods in this area is still under-developed. in many aspects, dna copy number is better than rna expression data in terms of genomic signature and diagnostic or prognostic biomarkers. dna is much easier to store than rna because dna is a stable molecule whereas rna is transient and easy to degrade. in addition, rna has to be collected from fresh tissues whereas dna can be isolated from frozen or paraform tissues even after years of storage. furthermore, dna aberration is preserved in the cell and can be passed to daughter cells via mitosis, whereas rna expression is unstable and rna levels are affected by many factors such as cell cycle, environmental and physiological factors. therefore, tumor classification and genomic signature identification based on dna copy number have extensive applications and improvements in the computational and statistical methods are needed to extend research in acgh data analysis.

most current statistical and data mining methods for acgh data were developed from expression microarray analysis. an important difference between acgh data and mrna expression data is the high spatial correlation between neighboring snps in the acgh data. the correlation between genes in expression microarray is relatively less and ignored by most methods that have been developed for such data. thus most methods developed for expression microarray may yield significant false positives and false negatives when applied to the acgh data. here we proposed a clustering algorithm that relies on hmm to take into account of the correlations between acgh markers . we found our hmmc algorithm to perform better than the nmf clustering method, which is one of the most widely used methods used for acgh sample clustering.

though hmm has been widely used in modelling correlated data, such as dna copy number data, it is widely known to be computationally very slow, especially for the analysis of high dimensional data such as the acgh data. in order to overcome this problem, we have used various approaches to increase the computational efficiency and speed. first, in the clustering procedure, we conduct a preliminary nmf clustering and the resulting groups are used as the starting point for hmmc.

secondly, instead of performing exhausting search, we only disturb the current optimal clustering with a few random labelling. thirdly, we implement the algorithm in c++ that is much faster than r and matlab. furthermore, we have developed a parallel computing version of the program, and it increases the speed by over 10-fold our server computer. our testing on  <dig> glioma samples showed that hmmc rapidly converges to its optimal clustering and the computation time is linear to the sample size.

CONCLUSIONS
in this manuscript we proposed a hmm-based clustering algorithm for identifying tumor subtypes using acgh dna copy number data. this approach properly models the high spatial correlation between acgh markers. clusters of tumor samples are modelled with a mixture of hmm models where each hmm fits a cluster of samples. we have developed a computationally efficient and fast clustering algorithm that takes only a computational time of o. we have shown that this hmmc algorithm has less than half the error rate of nmf clustering and it can locate the optimal number of groups automatically while applying to glioma acgh data. the resulting clustering of glioma samples has strong association with overall survival time. this hmmc algorithm would potentially have wide applications in tumor subtype identification, genomic signature discovery, and diagnostic and prognostic biomarker search. we will conduct future research in extending hmm-based modelling to other high dimensional biological data analysis, such as copy number variation, gene set enrichment analysis, and sequencing data analysis such as chip-seq data processing.

competing interests
the authors declare that they have no competing interests.

authors' contributions
kz conceived the study, developed the hmmc algorithm and implemented it in r environment. yy wrote the c++ code for the methodology and performed test for glioma data. vd and yd provided constructive suggestions. kz, vd, lx and ds wrote the manuscript with input from all authors. all authors read and approved the final manuscript.

