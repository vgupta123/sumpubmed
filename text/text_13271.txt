BACKGROUND
in contemporary biological research, organisms are often identified by firstly sequencing one or more of their genes and then comparing the sequences with those of known species, either by inferring phylogenies or by database searches  <cit> . once a sequence is available it may be used to design oligonucleotide probes, and these are used for most routine dna diagnostic work, because probe hybridisation tests are far less expensive and less technically complex than sequence analysis. specific oligonucleotide probes are used that are complementary in sequence to, and hence hybridise with, selected regions of the dna, rna or cdna of the target species or genotype. most such routine tests aim to identify specimens of a single species, or only a very few. each probe is at least  <dig> nucleotides long and often twice as long, and is chosen so that it is unique and only hybridises with a single target. as a result, at least one specific probe is required for every target, although usually several different probes are used for each. in some tests, sets of species- or genotype-specific probes are deposited as arrays on solid supports, so that it is possible to check simultaneously if an unknown organism belongs to one or other of many different taxa or genotypes; this strategy is widely used for gene expression analysis. 'high density arrays' of such probes have been used on occasion for identifying pathogens  <cit> , but they are not used routinely because, like sequence analysis, they are costly and technically complex  <cit> , nonetheless the potential market for identifying pathogens in this way is very large .

by contrast, in traditional taxonomy, specimens are rarely identified using characters specific for an individual target, but, instead, by using combinations of characters shared by different members of a set of target organisms. in practice the characters are used to devise a series of presence/absence questions arranged as a 'dichotomous taxonomic key', so that answering these questions sequentially leads to the identification of a specimen. the main advantage of this strategy is that far fewer characters and questions are required to uniquely identify an individual target. the strategy is most efficient when each character bisects the targets into two equal groups, i.e. it is bisectionally distributed, and when different characters bisect the targets differently, ideally in a progressively binary way. in theory the minimum number of characters required to distinguish a finite number of targets by this method is defined by the binary logarithm x = log2y, where x is the number of characters and y is the number of targets. for example, ten ideal characters would, in theory, identify each of a set of  <dig> targets, and only  <dig> ideal characters could identify more than a million targets;  <dig> and  <dig> , <dig> fewer tests respectively than using target-specific characters.

using target-specific characters  is the least efficient strategy for identification when efficiency is measured as the number of characters required to identify a target. using combinations of shared bisectionally-distributed characters can be much more efficient. the use of such shared characters is most efficient when they separate the targets in a progressively binary way.

in this paper we report that gene sequences contain sub-sequences that are present in quasi-randomly distributed sets of around half of the sequences, and hence their presence or absence could be used like the questions in a traditional taxonomic key. these sub-sequences could be detected by sets of probes with complementary sequences. a suitable set of such 'combinatorial probes' could be used to uniquely identify different individual dnas as these would give different patterns of hybridisation, 'fingerprints', with different individual dnas sub-sequences that are suitable targets for probe combinations are most commonly 6– <dig> nts long. sub-sequences of such lengths are not unique to the set of target genes, and so the target genes must first be separated from other 'contaminating' dnas. various physical or chemical techniques could be used to isolate the target sequences, but perhaps the most convenient would be by pcr using target region-specific primer mixtures .

attempts have been made to use algorithms based on suffix trees to find sub-sequences that could be used in combinations to distinguish between gene sequences  <cit> , and others have used selection algorithms based on entropy maximisation  <cit>  or on lagrangian relaxation  <cit>  to optimise probe selection. these studies focussed on the algorithmics of probe selection and demonstrated that sets of sub-sequences 5– <dig> nts long could distinguish individual sequences. probes that are only  <dig> to  <dig> nts long are not widely used because they usually require unusual hybridisation conditions. in the work reported here we looked at a range of sub-sequence lengths and used a simple greedy algorithm, where sub-sequences were successively chosen that merely maximised the number of pairs of gene-sequences that were distinguished; the algorithm was based on suffix arrays because they use less computer memory than suffix trees to manipulate as large sets. our study focussed on understanding the effect of gene-sequence diversity on the number and diversity of sub-sequences of different lengths that might be targeted by probes, as these factors will affect their use in practical applications. here we report a study of three published sets of cytochrome oxidase c subunit  <dig>  genes from representative groups of animal species  <cit> . these data were chosen because each set is consistent in length and composition, but differs greatly from the others in phylogenetic range and diversity. we have also studied, in less detail, several sets of sequences of plant and animal viruses and the ribosomal genes of bacteria.

RESULTS
three sets of co <dig> sequences were used; the details of which are available via the internet  <cit> . the "co1-animal" data was from  <dig> species of animals representing the seven dominant phyla of animals, the "co1-insect" data was from  <dig> species of insects representing eight of the largest orders of insects and the "co1-moth" data was from  <dig> species from three superfamilies of moths found near guelph, canada. after being aligned using clustalx  <cit>  with default parameters, the same region was selected from all three datasets for analysis; see methods. the selected regions, the "test-sequences", were  <dig>   <dig> and  <dig> nucleotides long respectively in the three sets. comparable random test-sequence datasets were constructed.

the three sets differed greatly in diversity: the co1-animal set was the most diverse with an average nucleotide difference, ignoring positions that had gaps for alignment, between all pairs of sequences of  <dig> %  with a range from  <dig> % to 57%; the co1-insect set had a mean nucleotide difference of  <dig> %  with a range from  <dig> % to  <dig> %, and the co1-moth set had a mean difference of  <dig> %  with a range from  <dig> % to  <dig> %. random sequence datasets were constructed that matched the length and average nucleotide composition of each test-sequence dataset, and had mean nucleotide differences of  <dig> % to  <dig> % . the co1-animal sequences yielded a pool of  <dig>  sub-sequences  <dig> nts long that included all replicates. pools of sub-sequences up to  <dig> nts long were also produced and these were, of course, a little smaller. the co1-insect sequences produced pools that were almost the same size, whereas those from the larger co1-moth dataset were about twice as large.

distinguishing sub-sequences
it was assumed that two test sequences could be distinguished if one of them contained a sub-sequence and the other did not, even if the second contained a sub-sequence that differed from one in the first at only one position, as hybridisation methods to distinguish such sequences are well established for the assay of single nucleotide polymorphisms  <cit> . to find sub-sequences that could be used like questions in a taxonomic key we searched among those that were shared and bisectionally distributed. we excluded specific sub-sequences, namely sub-sequences that were singletons, and also all sub-sequences found in all the test sequence set. therefore, the search was confined to "distinguishing sub-sequences" , namely those that were present in at least two test-sequences but not present in all the test-sequences.

distinguishing sub-sequences  constituted, at most, 15% of the sub-sequences in the pools from each co <dig> sequence set . almost all nucleotide combinations up to  <dig> nucleotides  long were present in all the sequences and, as they were uninformative and therefore eliminated, the percentage of dsss tended towards zero for lengths less than  <dig> nts. the proportion of dsss increased in pools of longer sub-sequences, but the number of singletons also increased with length, and so as sub-sequence length increased the percentage of dsss in the sub-sequence pool peaked and then decreased. the position of the peak depended on sequence variation; the peak was found at lengths of  <dig> or  <dig> nts in pools from the random sequences, and at  <dig>   <dig> and  <dig> nts in those from the co1-animal, co1-insect and co1-moth sequences respectively. only a few short sub-sequences were repeated within any one sequence and so these had only a minor effect on the size of the dss pool.

plots of the number of dsss in each 'occupancy' category, namely the percentage of test-sequences in which each dss occurred, showed large variations between the datasets , and this mostly reflected the diversity of the sequences. whereas the co1-moth set yielded dsss with 50% occupancy over the complete range of lengths tested, the co1-insect sequences yielded none longer than  <dig> nts, and the co1-animal sequences yielded none longer than  <dig> nts. in general, as the length increased so the number of dsss in each occupancy category declined at approximately a negatively exponential rate, but there were large variations between the datasets. for all pools, most dsss were present in fewer than 10% of the sequences and singletons were most common in pools of the longest dsss, especially from the diverse co1-animal data.

minimum complete sets  of co <dig> sequences
sets of dsss that, in combination, would distinguish between test sequences were selected. a set of dsss that could distinguish all the test-sequences in a dataset, in a manner like a taxonomic key, was considered a "complete set". a minimum complete set  was defined as a set that contained the fewest dss found by a random trajectory method . table  <dig> gives a mc-set for the co1-moth sequences, and table  <dig> gives the 'dss signatures', binary barcodes or 'fingerprints' for some representative moths.

mc-sets obtained from twenty searches each of the co1-animal, co1-insect and co1-moth data consisted of only  <dig>   <dig> and  <dig> sub-sequences respectively . in theory,  <dig> dsss behaving in a perfectly dichotomous way would be required to distinguish all the sequences in the co1-animal and co1-insect data, and the co1-moth data should require  <dig> dsss. thus, the mc-sets of the shortest dsss were close to the theoretically predicted size. however, as dss length and sequence diversity increased, so too did the sizes of the mc-sets. the increase was smoothly curvilinear with the random data, but more variable with real sequences. the more diverse sequences usually required larger mc-sets, although the greater size of the co1-moth dataset also increased the mc-set size.

each of the dss pools was shown to contain several independent equally parsimonious mc-sets by successively excluding mc-sets from the pools and searching the depleted pools for new mc-sets. when this was done using the co1-animal data and dsss  <dig> nts long, the first mc-set was of  <dig> dsss, but it was not until eight mc-sets had been successively removed that the mc-set size increased to  <dig>  during the removal process the average occupancy of the dsss in the mc-sets steadily declined from a mean of  <dig> %  to  <dig> %  when several mc-sets were obtained using the random dss choice method and compared, it was clear that many dsss from different mc-sets were interchangeable.

sub-sequence efficiency
the relative efficiency of each dss within a complete set was assessed by calculating the percentage of sequence pairs it distinguished, from among those remaining to be distinguished when it was chosen. in this way, it was found that relative efficiency depended on whether suitable dsss were available for selection, so whereas the first dss selected from the co1-animal sub-sequences  <dig> nts long was able to distinguish 50% of the sequences, the first dsss that were  <dig> nts and  <dig> nts long only distinguished 41% and 28% of the sequences respectively .

sequence groups
our search method also allows groups of the sequences to be defined, so that the resulting mc-sets only contain dsss that distinguished between members of different groups of sequences, but not necessarily between sequences of the same group. this enabled, for example, the  <dig> different co1-animal sequences to be grouped into seven phyla  but this only decreased the size of the mc-set for dsss six nts long from  <dig> to  <dig> dsss, and for dss  <dig> nts long from  <dig> to  <dig>  however grouping was more valuable for sequence sets containing many nearly identical variant sequences. for example a set of sequences from  <dig> isolates of potyvirus, a genus of plant viruses, gave mc-sets of  <dig>   <dig> and  <dig> dsss with sub-sequences  <dig>   <dig> and  <dig> nts long respectively, but when the sequences were grouped as the  <dig> recognized species the mc-sets were less than half the size; only  <dig>   <dig> and  <dig> dsss respectively.

speed
the search method took  <dig> seconds to select an mc-set of  <dig> dss  <dig> nts long from the  <dig> co1-moth sequences when using one processor on a dual opteron  <dig> processor machine running at  <dig>  ghz. the same system took  <dig> seconds to select an mc-set of  <dig> dsss  <dig> nts long from the  <dig> co1-animal sequences. these tasks took  <dig> minutes  <dig> seconds and  <dig> seconds respectively in a pc with a pentium cpu at  <dig>  ghz. a version of the program is available for use for research purposes over the internet, contact the corresponding author  for details.

discussion
all the studies described above in which the three sets of co <dig> sequences were compared, illustrate the fact that the number of dsss in a set of sequences is mostly determined by its diversity and by the length of the sub-sequences being sought. short sub-sequences for probe targeting could readily be found, but longer sub-sequences that would be more useful for identification in standard hybridisation reactions were less common and more likely to be found among closely related, well conserved, gene sequences. the most useful sub-sequences for identification were, as predicted, those that were present in about half of the targets . most gene sub-sequences less than  <dig> nts long are not unique to particular genes. therefore they can only be used as targets for diagnostic tests when the target nucleic acids that contain them have been preselected in some way. this could be accomplished most conveniently by pcr using region-specific primers or primer mixtures.

one advantage of combining region-specific amplification with identification using combinatorial probes is that related but previously unrecognised or uncharacterised species or subtypes may be found. the chosen region, even from unknown species or subtypes, is likely to be amplified using the region-specific primers or primer mixture, and it is then also likely that the combinatorial probes will hybridise with at least some of the target sub-sequences, but will give dss 'signatures' that have not been seen before. this is because each mc-set that we have found is many-fold redundant, and has the potential to generate many more different signatures than would be generated from the known test-sequences. for example, the mc-sets  <dig> nucleotides long that distinguished the  <dig> co1-moth sequences were of  <dig> dsss. sixteen dsss could, if they behaved in a perfectly dichotomous way, uniquely identify  <dig>  different gene sequences or species . thus the mc-sets we found were  <dig> % redundant, and the combinations of dsss not represented among the target sequences would be available to distinguish previously unknown variants of the selected gene region.

the aim of the work reported in this paper was to investigate the factors that influenced the numbers of sub-sequences that, in combination, could distinguish sequences or groups thereof. we therefore tested our selection algorithm using three published sets of co <dig> sequences that were consistent in length and composition, but differed greatly from one another in phylogenetic range and diversity. we have also examined, but in less detail, a set of ribosomal rna genes from  <dig> bacterial species representing  <dig> genera and also gene sequences from several groups of animal and plant viruses, namely flaviviruses, orthomyxoviruses, potyviruses and tobamoviruses . the results obtained with the bacterial and viral sequences did not differ in any significant way from those obtained with co <dig> sequences, which suggests that there is no a priori reason to believe that dsss for targeting by probe combinations are not present in all genes.

the design of practical diagnostic tests, based on the principles outlined in this paper, would involve several stages. first, known sequences of potential targets would be examined to find regions of convenient length and variability bracketed by conserved sites for pcr primers. the region-specific primers would be tested and optimised using a range of variant sequences. then all known sequences of the region would be used to identify mc-sets of dsss, whose complements could be used as probes in hybridisation-based tests to identify individual variants. however an iterative process will be required to design a working set of combinatorial probes as it is well known that a significant proportion of sub-sequences selected as hybridisation probes fail to behave as expected because of secondary structures in the target nucleic acid or the probe  <cit> . first an initial mc-set would be selected bioinformatically, then tested biochemically, and the probes that performed correctly used as a 'starter set' for further rounds of bioinformatic and biochemical selection, until a working mc-set was obtained. when this dss set is used in practice, variant sequences giving unknown dss signatures are likely to be found. these would then be sequenced and added to the trainer set, and the mc-set might have to be redesigned.

the value of target-specific 'high-density microarrays' of dna probes was most spectacularly demonstrated when the pathogen causing sars was shown to be a coronavirus. it was detected using an array of about  <dig>  different oligonucleotides from some of the most conserved regions of about  <dig>  reference viral genomes  <cit> . however, the microarrays used for sars were not standard diagnostic tools, and high-density microarrays are also not used routinely in infectious disease diagnostics because of their cost and complexity  <cit> . nonetheless multiplexing offers clear benefits  <cit>  as more information is provided by each test.

at present non-multiplexed tests or tests that use just a few specific probes are the standard. these tests are used routinely for screening donor blood for viruses, including human immunodeficiency lentiviruses and hepatitis c hepaciviruses, and as the primary or confirmatory diagnostic tests for sexually transmitted pathogens and pathogens that cause meningitis  <cit> . these nucleic acid probe-based medical diagnostics have a very large market value  <cit> .

probes, which identify by being used in combinations, could be most usefully used in low-density dna microarrays. low-density microarrays typically comprise fewer than  <dig> probes and often fewer than  <dig> probes, and it seems likely that such microarrays could outperform high-density microarrays for routine diagnostic applications because of their reliability, simpler data analysis and much lesser cost  <cit> . different combinatorial probe sets could be combined in each low-density array to achieve greater redundancy and accuracy; they might not merely replicate one another but could optimally target different major organism groups or different epidemiologically important strains with each replicate mc-set  <cit> .

CONCLUSIONS
this paper reports a method that finds sub-sequences which, in combinations, distinguish the individual gene sequences or groups of gene sequences from which they came, and that could be used as targets for dna probes. sequence diversity and sub-sequence length were found to be the major factors influencing the number of sub-sequences available as probe targets.

