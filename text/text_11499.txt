BACKGROUND
high density oligonucleotide microarrays are widely used in many areas of biological research for quantitative, high-throughput measurements of gene expression. although ultra-deep sequencing techniques promise to replace them in the near future  <cit> , it would be a mistake to ignore the biological importance of the massive quantity of data already produced through this platform. publicly available databases alone store a huge  quantity of microarray experiments , comprising hundreds of different species.

among microarrays, the single-channel affymetrix genechip platform  <cit>  is by far the most popular . in this technology each transcript is typically measured by a set of 11- <dig> pairs of  <dig> bases-long probes, collectively referred to as "probeset".

for every "perfect match" probe , affymetrix chips contain a "mismatch" counterpart , with a single nucleotide change in the middle of the pm probe sequence. the role of mm probes, located adjacent to the respective pm, is to measure probe-specific background signal associated to any perfect-match signal intensity.

in general, the process of obtaining a single gene expression value out of raw probe intensity measurements is called "microarray preprocessing". three steps are usually required: background correction, normalization and summarization. many different methods or combinations of methods were proposed over the years  <cit> .

the most popular manufacturer-provided method, mas <dig>  <cit> , uses a scale normalization approach, then corrects the background by subtracting the mean intensity of the lowest 2% spots in every microarray region, and then mm intensities from the respective pm ones. wherever mm intensity is higher than a pm one, in order to avoid negative signal intensities typical of the mas <dig> predecessor, mas <dig>  <cit> , mas <dig> replaces the mm signal with an "idealized mismatch" value  derived from other values in the same probeset. to extract final probeset intensities, mas <dig> calculates a robust average  of all the contained probes.

many alternative techniques have challenged mas <dig> supremacy for preprocessing. being a single-array technique, mas <dig> doesn't model probes' behaviour across different samples, and therefore suffers from high variance and is theoretically less robust than multi-array algorithms  <cit> .

two of the most popular multi-array normalization techniques are rma  <cit>  and gcrma  <cit> . rma doesn't use information contained in mm probes, and calculates background signal by performing a modelled global correction of all pm intensities. then it applies a quantile normalization step and a median polish summarization, which accounts for probe intensities over multiple arrays. gcrma applies the same normalization and summarization steps as rma, but it differs in the background correction method, which is based on the probe sequence. other multi-array methods which don't discard mm intensities exist, one of them being dchip  <cit> . however, in the present paper we will focus on rma, gcrma and mas <dig>  which are possibly the most popular microarray normalization methods  <cit> . their popularity is illustrated by the fact that they are the most popular normalization techniques in online databases  <cit> .

most benchmarks have tried to assess the quality of different preprocessing methods in differential gene expression scenarios, the original purpose for which microarrays were developed  <cit> . to do so, golden set spike-in samples were used, with known concentrations of transcripts  <cit> , or real time pcr measurements were performed for comparison  <cit> . the outcome of these benchmarks has not identified any technique as the top performer, although single-array techniques such as mas <dig> have been outperformed by multi-array ones such as rma  <cit> .

however, many different approaches to biological investigation have relied on microarrays, ranging from gene and sample clustering  <cit>  to gene-gene network reverse-engineering  <cit> , from sample classification  <cit>  to global transcript models  <cit> . the field of microarray data correlation and clustering based on the principle of coexpression has developed at a quite considerable pace  <cit> ; despite this, the effects of preprocessing on coexpression analyses have been generally overlooked, with a few exceptions.  <cit>  used bacterial operons to validate the different normalization techniques for correlation analysis and concluded that a combination of different methods works best. on the other hand,  <cit>  have pointed out how the use of the multi-array techniques rma and gcrma can yield inter-array correlation artifacts and generally lower quality networks than the older mas <dig>  in particular, a specific step in gcrma background correction  has been identified as partially responsible for the spurious correlations generated by gcrma. notably however, the correction of this step is not sufficient to remove all artifact effects, and no explanation was provided for artifacts produced by rma.

in the present paper, we extend the analysis performed by  <cit> , aiming to shed more light on the behaviour of multi-array techniques specifically in the context of inter-array correlation. we will describe the characteristics of probesets which induce these artifacts and provide both a mathematical and a biological explanation for the phenomenon. finally, we introduce a slightly changed version of the rma code which massively reduces inter-array correlation artifacts, while retaining rma features in the context of differential gene expression analysis.

RESULTS
multi-array preprocessing effects
in order to compare the behaviour of three of the most popular microarray preprocessing techniques , lim and colleagues  <cit> , tested these on a single dataset of  <dig> microarrays hybridized with human samples. we extended this analysis on a considerably larger arabidopsis thaliana dataset comprising  <dig> microarrays, selecting different sample sizes , according to the realistic size of a single experiment dataset . first, we calculated inter-array correlations on randomly selected groups of original arrays . the plots show us that many genes' relative expression will remain constant across different treatments and genotypes, indicating a certain robustness of arabidopsis' genetic machinery in varying environmental conditions and other perturbations . the sample size doesn't seem to influence the high correlation between arrays, although some evident oscillations could be detected for rma and gcrma at lower sample sizes. the comparison of the three preprocessing methods shows that rma and gcrma yield somewhat more similar microarray expression values than the affymetrix algorithm mas <dig> 

in order to compare real data with a null dataset, we analyzed the behaviour of the three preprocessing techniques on permutated arrays . since permutated arrays are entirely shuffled and uninformative, we expect them to be, on average, not correlated at all. however as previously reported by lim and colleagues  <cit> , this is not the case for the non-affymetrix techniques we used . rma and gcrma show a high mean inter-array correlation, which is decreasing with the sample size and this correlation is also much higher for odd sample sizes, and reminiscent of the oscillating behaviour in real arrays . average values for figure  <dig> are shown in table  <dig>  in order to assess if these artifacts were due to the choice of correlation coefficient we repeated our analysis using pearson's and lin's correlation, but obtained nearly identical results .

average inter-array correlation coefficients at different sample sizes, using three different normalization procedures.

mas <dig> alone shows the expected no-correlation behaviour. it must be noted that, unlike the other two techniques, mas <dig> uses a single-array summarization technique  which treats each sample separately.

we will focus on the cause of this behaviour observed when using rma and gcrma, trying to understand the mathematical and biological scenarios that could introduce such a massive artificial inter-array correlation for these two methods.

causes of rma and gcrma artifact generation
we have already seen that the introduction of artificial similarities between arrays by rma and gcrma is particularly strong for small and odd sample sizes. in figure  <dig> we show how adding an increasing amount of noise to microarray samples in the arabidopsis dataset  results in the expected loss-of-correlation behaviour for mas <dig>  gcrma and rma for an even sample size . however, for sample size  <dig> , rma and gcrma actually add inter-array correlation as noise is combined with the biological signal. the situation is still atypical for the next odd sample size .

returning to our original arabidopsis dataset, we observed that many probesets seem to yield completely identical values across different samples when processed by rma or gcrma. datasets of three arrays normalized by rma and gcrma show, respectively, around 20% and 12% of the probesets population with identical values across all samples. the effect will decrease with increasing sample size  as previously reported in  <cit> . we therefore measured the tendency to yield identical expression estimates for any particular probeset after rma normalization  and compared it to several probeset characteristics.

the id tendency is inversely correlated  to the probeset internal consistency , which we measured using the fit of the probeset to a linear model that measures concordance between probes.

this phenomenon is also particularly evident for lowly expressed probesets  and those hybridizing to multiple targets , especially if the different targets fall into different biological classes .

in summary, rma and gcrma tend to yield identical values for probesets containing probes that yield grossly different measurements across samples, and therefore are either noise-driven or have multiple independent targets.

as the problem of bad probesets has been discussed before and been tackled by providing updated probeset definitions in the customcdf project  <cit> , we assessed whether the oscillating behaviour for real data was still observable when using such an updated definition. however, qualitatively identical results were still obtained using such an updated probeset annotation . this might be explained by the fact that expression is also inversely correlated to a probesets' tendency to give identical values across arrays.

taken together, these results tell us that rma  introduce artificial correlation across microarrays driven by lowly expressed, internally inconsistent, multi-target and/or multi-function probesets.

median polish inconsistency
rma  <cit>  and the closely related method, gcrma  <cit> , differ only in the initial background correction step. since the same effect is present in both methods , we reasoned that the artifact generation should depend on either the shared normalization step , or on the probe summarization step . we concluded that the effect cannot arise from quantile normalization, since substituting it by scale normalization or removing it completely yields qualitatively identical plots whereas the inclusion of a median polish step always introduced the effect, regardless of background correction and normalization procedures . the shared artifact can therefore only be generated within the median polish summarization step. indeed, substituting the median polish step with any other alternative available in the bioconductor rma implementation eliminates the artificial inter-array correlation effect . as an example of multi-array summarization, we substituted the rma default summarization with the robust least squares linear model summarization, described by  <cit> , and show that this procedure almost completely removes inter-array correlation . on the other hand, as an example of single-array summarization, we used rma with an "average of log" summarization, which simply computes the average of the logarithms of probe intensities for every probeset. this single-array summarization yields a predictable  <dig> correlation among all arrays .

to identify why this artifact arises during the median polish procedure, we investigated the algorithm further. rma and gcrma apply median polish by creating a matrix from the measured values within each probeset, placing probes along each row, and samples along each column. the medians are subtracted from the intensities to cumulate residuals in each step and the grand effect  is subtracted from medians to cumulate probe effects in each step .

this algorithm is more likely to introduce identical values with odd and small sample sizes, like the one depicted in additional file  <dig>  figure s <dig>  in such a case, the row medians will fall on a specific value and be transformed to zero during the first row sweep , this will increase the chance to have a zero as column median during column sweep .

overall, the rma implementation of the median polish algorithm shrinks all values in the probeset matrix to similar or identical values, with a stronger effect for samples, since it starts subtracting probe  medians. in the example of additional file  <dig>  figure s <dig>  the final sample values will be calculated by adding the grand effect to each column effect, and will therefore be equal to  <dig> for all samples.

it could be argued that the median polish summarization step could be helpful in the context of differential gene expression analysis, since it will flatten unclear probeset matrices and therefore highlight strong signals. however, the result of generating completely identical expression values across arrays is not always beneficial. moreover, this effect can be dramatically reduced by swapping the order of row/column median subtraction within median polish, or equivalently, by transposing the matrix created for each probeset, placing samples on rows and probes on columns. this alteration will introduce a presumably harmless similarity between probes within a probeset  while massively reducing the artificial sample identity.

to confirm this, we re-implemented the median polish summarization by inverting the order of the two sweep steps , in what we call "transposed rma" or trma. as shown in figure  <dig>  the inversion of median subtraction steps alone reduces the median polish effect to a very small residual inter-array correlation. this can be explained by the fact that the likelihood for the sample effects to give a zero value in trma is very low during the first iteration, as it would require perfectly identical medians of raw probe values . effectively, trma transfers the artifact of inter-correlation between sample to an inter-correlation between probe  effects, which might be more plausible biologically  and remains contained within the procedure and not yielded as output of the preprocessing method.

the inter-array artificial correlation effect introduced by the median polish step is increased in gcrma . as previously discussed by  <cit> , gcrma contains a potential problem in its background correction step, that adjusts probe intensity values through gene-specific binding. this introduces artificial inter-array correlations between probes with similar binding affinity, and therefore strengthens the effect of the following summarization step. however, substituting the median polish step with our transposed alternative "tgcrma" , massively reduces the inter-array correlation between permutated samples.

comparison between rma and trma in biological contexts
the affycomp open challenge benchmark  <cit>  is a well known tool to evaluate summaries of affymetrix probe level data, based on known concentration of transcripts in the so-called "spike-in" experiments by affymetrix  <cit> . in order to demonstrate that our trma procedure still performs nearly as well as the original rma implementation, we used the latest implementation of the affycomp benchmark  to compare the performance of the original rma with our trma implementation. in table  <dig> we show some of the most relevant scores, as calculated for the hgu <dig> affymetrix spike-in series.

affycompii most indicative results  for mas <dig>  rma and trma, spike-in hgu <dig> dataset. differences between rma and trma are trivial, especially when compared to other methods .

the differences between rma and trma are minor when compared to the results for an independent method : trma shares most of the qualities of rma, without introducing inter-array correlations. it is interesting to highlight the fact that trma yields a higher median standard deviation  between spike-in replicates. this effect can be wrongly interpreted as trma's lower sensitivity; however, we now know that the original rma median polish implementation is introducing identical values across experiments, and therefore artificially reducing the variance between spike-in replicates as well.

since median polish alters inter-array correlation, sample classification is a common analysis that could be affected by this summarization step. thus, we analyzed the atgenexpress stress dataset for arabidopsis  <cit> , and calculated the capability of both preprocessing techniques to separate roots and shoots samples .

as can be seen in figure 5a, trma outperforms rma as it increases the distance between different tissue samples , while keeping similar low distances between samples coming from the same tissue . as variance filtering is a common procedure for microarray clustering, we used only the 50% most varying genes in every subset and obtained similar results . it can be concluded that trma increases the capability to discern different array conditions, when only a small number of microarrays have been used.

in order to compare the relative performance of rma and trma when filtering on differentially expressed genes, we used a dataset that was previously used by  <cit> , to tune classification where the origin of the rna in each sample was known. choosing a sample size of  <dig> where  <dig> pairs of  <dig> samples each came from the same specimen and one sample came from a different specimen, trma yields better classification results for almost all fdr corrected p-value thresholds .

however, when filtering out lowly expressed genes  <cit> , rma performed generally as well as trma when performing sample classification on this dataset . unlike for the tissue sample dataset, rma performed better than trma when filtering based on variance in this use case even when adding random noise to all samples . only when noise was selectively added to non-paired samples did trma outperform rma .

furthermore, rma performs slightly better than trma in  <dig> out of  <dig> of the affycomp tests shown. although objectively minor, these differences point out that trma may not necessarily be an improvement over rma in all types of analyses.

discussion
the use of gcrma and rma preprocessing algorithms for affymetrix genechip technology has received a remarkably broad adoption in the community due to their low computation time and to their superiority with respect to other methods in previous benchmarks.

however, one of the most relevant advantage of rma and gcrma in the affycompii challenge  <cit> , the low variance across replicates, seems to be partially the result of artificial inter-array correlation. extending what was already noted by  <cit> , we show that the artificially high similarity between samples given by rma and gcrma is caused by the shared median polish summarization step. this artificial behaviour is particularly strong in internally inconsistent, noise-driven and multi-hit probesets, and as a consequence identical results across arrays are generated. we analyzed this artifact effect for the arabidopsis thaliana ath <dig> affymetrix genechip, but we found highly similar results in exploratory experiments on other organisms and platforms .

the median polish step doesn't seem to pose a particular problem in differential gene expression analyses, because, on the contrary, it could enhance the differences of changing transcripts by shrinking most unclear probesets to identical values across experiments. in any case, the small underlying change in gene expression of such an unclear probeset would generally be below the cut-off value to be considered an 'interesting' gene. it is interesting to note, however, that median polish has already been shown to work poorly when compared to mas <dig> summarization in correlation between e. coli operon members  <cit> .

however, this artificial correlation can't be ignored in contexts where unbiased measurements are needed, like transcript clustering  <cit> , genetic network reverse-engineering  <cit> , sample classification  <cit>  or global transcript models  <cit> , and we show in the present paper how rma can artificially decrease the gap between samples coming from different tissue types. furthermore, we could show that filtering of differentially expressed genes leads to a worse sample classification performance for small odd sample sizes samples for rma, when compared to trma. nevertheless, depending on the use case, rma performed better when filtering based on variance. thus, our results raise issues, especially when small sample sizes are used, on the validity of many studies obtained on the basis of correlation measures after these normalization procedures were applied.

CONCLUSIONS
we propose a minor change to the median polish algorithm that will almost eliminate the correlation artifacts without significantly affecting any of the positive rma/gcrma qualities. we provide a modified version of rma named trma as a standalone r package . the method contains a modified version of the bioconductor  <cit>  preprocesscore and affy packages that alter the median polish summarization step as described in additional file  <dig>  figure s <dig> . our trma method will offer the possibility to use an unbiased normalization technique both for differential gene expression analyses and for correlative studies based on microarray data.

