BACKGROUND
the classification problem of determining the origin of a given dna sequence  in a given set of target sequences  is common to several fields of computational molecular biology. here, we focus our attention on two applications related to metagenomics and genomics.

in metagenomics, the objective is to study the composition of microbial community in an environmental sample. for example, sequencing of seawater samples has enabled discoveries in microbial diversity in the marine environment  <cit> . similarly, the study of samples from the human body has elucidated the symbiotic relationships between the human microbiome and human health  <cit> . once a metagenomic sample is sequenced, the first task is to determine the identities of the microbial species present in the sample. several tools are available to classify metagenomic reads against known bacterial genomes via alignment  or sequence composition . a recent comparative evaluation of these tools  <cit>  demonstrated that nbc  <cit>  exhibits the highest accuracy and sensitivity at the genus level among  <cit> . this study also showed that nbc and other probabilistic methods  as well blast-based methods  are computationally expensive. recently, new faster methods have been introduced  but their performance still does not meet nbc’s sensitivity. to the best of our knowledge, there is no tool yet that has both a sensitivity comparable to nbc and a speed comparable to kraken. a related group of metagenomic tools, such as metaphlan  <cit>  and wgsquikr  <cit>  addresses the abundance estimation problem, that is, they estimate from the reads the proportion of each organism present in the sample.

the second application is associated with de novo clone-by-clone sequencing and assembly. given a bac clone , an objective of a classification problem sometimes is to determine which chromosome  is the most likely origin of that clone/transcript. the problem assumes that reads for each bac/transcript as well as reads for each chromosome arm are available, but that the fully-assembled reference genome is not. this is the situation in barley, which we have used for this work, and for many other organisms. in the past, the bac/transcript assignment problem had been addressed using general-purpose alignment tools , as in  <cit> .

in both of these applications the computational problem is the same: given a set of dna sequences to be classified  and a set of reference sequences , identify which target is the most likely origin of each object based on sequence similarity. although this problem has been extensively studied, it is still computationally challenging due to the rapid advances in sequencing technologies: cheaper, faster, sequencing instruments can now generate billion of reads in a few days. as the number of objects grows, so does the number of targets, as demonstrated by the exponential growth of genbank  <cit> . given these demands, it is critical for software tools to minimize computational resources  required for analysis.

here we present clark , a new tool that can accurately and efficiently classify objects to targets, based on reduced sets of k-mers . clark is the first method able to perform classification of short metagenomics reads at the genus/species level with a sensitivity comparable to that of nbc, while achieving a comparable speed to kraken. in some situations, clark can be faster and more precise than kraken at the genus/species level. unlike tools like lmat  <cit> , metaphylan, phylopythias  <cit> , metaphyler  <cit> , or nbc, clark produces assignments with confidence scores, which are critical to post-process assignments in downstream analyses. additionally, clark is designed to be user-friendly, self-contained , and multi-core-friendly. clark does not need as much disk space as kraken or phymmbl. finally, a “ram-light” version of clark can be run on a memory-limited architecture .

RESULTS
we briefly review clark’s algorithm before reporting experimental results.

target-specific k-mers and classification
during preprocessing, clark builds a large index containing the k-spectrums of all targets sequences. we recall that a k-mer is a dna word of fixed length k, and that the k-spectrum of a string x is the vector of dimension 4k that collects the number of occurences of all possible k-mers in x. the k-spectrum is a succinct  representation of x, which allows sequence comparison . once all k-spectrums of target sequences have been collected in the index, clark removes any common k-mers between targets .

henceforth, we call the remaining k-mers either target-specific or discriminative, because they represent genomic regions that uniquely characterize each target. finally, an object is assigned to the target with which it shares the highest number of k-mers.

clark offers two modes of execution. the first mode  outputs for each object the number of hits against all the targets and the confidence score of the assignment . the second mode  employs sampling to reduce the number the target-specific k-mers for classification, and outputs assignments without any detailed statistics so that the output size is significantly reduced . the default mode is slightly less accurate, but it is faster.

metagenomics classification
inputs to this classification task are  ncbi/refseq databases of known bacterial genomes  and, either  the set of metagenomic reads used in  <cit>  and the set of simulated long reads from “simhc”  <cit> , or  the set of real metagenomic reads from the human microbiome project . the human microbiome project data are freely accessible  <cit> .

at the time we carried out the experiments the ncbi/refseq database was composed of  <dig>  complete bacterial genomes, distributed into  <dig> distinct genera, or  <dig>  species. the total length of all these bacterial genomes was about  <dig>  gbp. the average size of a genome was about  <dig>  mbp.

in the first experiment, we used three microbial metagenomics datasets called “hiseq”, “miseq” and “simba-5” that were introduced in  <cit> . according to  <cit> , “the hiseq and miseq metagenomes were built using twenty sets of bacterial whole-genome shotgun reads. these reads were found either as part of the gage-b project  <cit>  or in the ncbi sequence read archive. each metagenome contains sequences from ten genomes . for these metagenomes, 10% of their sequences were selected from each of the ten component genome data sets ”. the set “simba-5” included “simulated bacterial and archaeal reads, and was created with an error rate five times higher than” the default . we also analyzed the set “simhc” of synthetic reads  <cit> , which simulates high complexity communities lacking dominant populations. simhc contains  <dig> sets of reads from various microbial genomes. from simhc, we selected arbitrarily twenty distinct genomes, and extracted the first  <dig> reads for each genome to build a total of  <dig>  reads . we called this latter dataset “simhc. <dig> ”.

for the experiments below we used the “hiseq”, “miseq” , “simba-5” from  <cit>  and “simhc. <dig> ” . each of these sets contains  <dig>  reads. the average read length in hiseq was  <dig> bp,  <dig> bp in miseq, and  <dig> bp in simhc. <dig> . in simba- <dig>  all reads are  <dig> bp long.

in the second experiment, we have arbitrarily chosen three metagenomic samples selected from the human microbiome project  <cit> . the three samples we used were srs <dig>  containing  <dig> thousand paired-end reads, srs <dig>  containing  <dig>  million paired-end reads, and srs <dig>  containing  <dig>  million paired-end reads.

hiseq, miseq, simba- <dig> and simhc. <dig> 
we used clark to classify the reads in the four datasets described above and compared its classification results against the state-of-the-art methods, namely nbc  <cit> , which we chose for its high accuracy , and kraken, which we chose due to its high speed  and its high precision at the genus level.

we classified the reads  against  <dig> genus-level targets  and  against  <dig> species-level targets .genus-level classification accuracy and speed of 
clark, kraken
, and 
nbc
 for four simulated metagenomes and several
k
-mer length


k
hiseq
miseq
simba-5
simhc. <dig> 
prec
sens
speed
prec
sens
speed
prec
sens
speed
prec
sens
speed

nbc
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 

 <dig> 
541
 <dig> 
435
591
 <dig> 
 <dig> 
 <dig> 
 <dig> 
122
 <dig> 
 <dig> 
 <dig> 
 <dig> 

kraken
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
237
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 

clark
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
251
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 

 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 

clark-e
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 

clark-l
performance statistics for several choices of the k-mer length for nbc, kraken, clark and their fast variants on the classification of “hiseq”, “miseq”, “simba-5” and “simhc. <dig> ” metagenomic datasets against the  <dig> genus-level targets; precision and sensitivity are expressed as percentages, while speed is expressed in  <dig> reads per minute; kraken-q and clark-e are faster, but less accurate, variants of these tools; clark-l is a less memory-intensive version of clark which runs only for k = 27; experiments were carried out in single-threaded mode; ∗parameter k is referred as n in the nbc manuscript.
species-level classification accuracy and speed of 
clark, kraken
, and 
nbc
 for four simulated metagenomes


hiseq
miseq
simba-5
simhc. <dig> 
prec
sens
speed
prec
sens
speed
prec
sens
speed
prec
sens
speed







precision and sensitivity are expressed as percentages, while speed is expressed in  <dig> reads per minute for nbc, kraken, and clark on the classification of “hiseq”, “miseq”, “simba-5” and “simhc. <dig> ” metagenome datasets against the  <dig> species-level targets, in single-threaded mode.



for a given level in the taxonomy tree , we define precision as the fraction of correct assignments over the total number of assignments, and sensitivity as the ratio between the number of correct assignments and the number of objects to be classified. in order to have a fair comparison against kraken’s assignments, when kraken produces an assignment that is not available at or below the genus or species level, it is then considered as not assigned.


nbc was tested with k= <dig> , <dig>  we observed that k= <dig> produced the highest sensitivity on all datasets. the value k= <dig> is the highest possible value, which is recommended by the authors of  <cit>  for datasets composed of short reads. since nbc produces detailed statistics on the assignments, we executed clark in “full” mode for a fair comparison. using k= <dig> for clark  we obtained a similar sensitivity to nbc . at the same level of sensitivity of nbc, clark achieves a higher precision and it is thousands of times faster.

in the case of kraken, k= <dig> was the value used in  <cit>  for hiseq, miseq and simba- <dig> and it is supposed to achieve the highest precision. nonetheless, we tried to run kraken for other values of k. as expected, table  <dig> shows that k= <dig> produces the best precision for all the datasets. for this comparison, we also ran clark with k= <dig>  observe that clark  is slightly less sensitive than kraken but is more precise and faster. the difference in speed is significant for all datasets of short reads . on simhc. <dig> , kraken and clark achieve the same speed due to the fact that these datasets contain longer reads. finally, clark has better sensitivity than kraken on simhc. <dig> .

the same comparisons were carried out between the two variants of kraken and clark optimized for speed, called kraken-q and clark-e . as indicated in table  <dig>  kraken-q achieves the best precision for all the datasets when k= <dig>  which is consistent with  <cit> . however, when k=31clark-e runs four–five times faster than kraken-q and is also more precise. in addition, observe that as we decrease k, both variants gets faster but clark-e maintains a precision above 90% while kraken-q produces progressively lower precisions.

in the last row of table  <dig>  we report the performance of clark-l, another variant of clark designed for low ram architectures that runs only for k= <dig> . clark-l performs assignments with a lower precision than clark  but can process more than  <dig>  million of reads per minute on hiseq or simba- <dig>  and only uses about 4% of the memory used by clark .

all experimental results reported so far were obtained in single-threaded mode. if a multi-core architecture is available, clark and kraken can take advantage of it. in additional file 1: table s <dig>  we summarize the classification speed of the two tools using  <dig>   <dig>   <dig> or  <dig> threads for k= <dig>  observe that using eight threads, clark achieves a speed-up of  <dig> x compared to one thread, while kraken only achieves a speed-up of  <dig> x. when comparing clark-e to kraken-q, we can make similar observations. in general, note that clark-e is at least five times faster than kraken-q, independently of the number of threads used.

for the analysis at the species level, we repeated the classification of the objects in the four datasets described above against species-level targets. this time we used values of k that allowed best sensitivity for nbc  and best precision for kraken . observe in table  <dig> that nbc achieves the best sensitivity on all datasets. however, when clark is ran in full mode using k= <dig>  it achieves a higher precision than nbc on hiseq, miseq and simhc. <dig> , and is several orders of magnitude faster. in addition, clark in default mode using k= <dig> achieves higher precision than kraken on all datasets  when k= <dig>  clark also outperforms the speed of kraken on hiseq, miseq and simba- <dig>  on simhc. <dig> , since the reads are much longer, the speed of kraken and clark are comparable. but, clark has higher sensitivity than kraken on hiseq, miseq and simhc. <dig> . finally, the fast variant clark-e, as previously observed for the experiments at the genus level, outperforms kraken-q in both speed and precision.

human microbiome samples
in the second experiment, we used clark to classify human microbiome project reads against  <dig> genus-level targets described above. this time, however, the “ground truth” was not available.

using k= <dig>  clark was able to assign  <dig> % of the reads in srs <dig> ,  <dig> % of the reads in srs <dig>  and  <dig> % of the reads in srs <dig> . kraken achieved similar rates of assigned reads using k= <dig>  reducing k would increase the number of assignments, at the cost of increasing the probability of misclassification. we investigated whether we could take advantage of clark’s confidence scores to compensate for a smaller value of k, and improve the fraction of assigned reads.

observe in table  <dig> that the number of high confidence assignments for k= <dig> is significantly higher than for k= <dig>  the relative increase in assignments is about 40% . table  <dig> also reports the most frequent five genera in high confidence assignments. for the saliva sample, the dominance of streptococcus, haemophilus and prevotella is consistent with findings in  <cit>  and  <cit> . study  <cit> , which focused on salivary microbiota of  <dig> inflammatory bowel disease patients, also reports streptococcus, prevotella, neisseria, haemophilus and veillonella as dominant genera. concerning the mid-vagina sample, we have found that lactobacillus is the dominant genus, in agreement with findings reported in  <cit> . the proportion of lactobacillus we have identified  is very close to the reported proportion  in  <cit> . the presence of pseudomonas and gardnerella is expected because some individuals who lack lactobacillus have instead gardnerella or pseudomonas as the predominant bacteria  <cit> . in the nose sample, the high presence of propionibacterium and staphylococcus is consistent with the results in  <cit> .summary of the genus-level classification for three human microbiome project datasets 



srs id
high confidence
low confidence
no assignment
average
most frequent genera 
assignments 

confidence score
confidence assignments)
columns:  short read sample id;  percentage of high confidence assignments;  percentage of low confidence assignments;  percentage of unassigned reads;  average confidence score for all assignments;  five most frequent genera in high confidence assignments . an assignment is high confidence if the confidence score is higher than  <dig> , low confidence otherwise.



classification of barley bacs and unigenes to chromosome arms and centromeres
inputs to this classification task were  barley chromosome arms  and  barley bacs or unigenes . samples of each barley chromosome arm were obtained using flow-sorting  <cit> . the procedure to obtain gene-rich barley bacs was described in  <cit> . sequences for chromosome arms and bacs were generated on an illumina hiseq  <dig> instrument by j. weger at uc riverside.

for the targets, we processed thirteen datasets of shotgun sequenced reads: one for barley chromosome 1h and twelve for barley chromosome arms . after quality-trimming the reads, we had a total of about  <dig> gbp of sequence data. the cumulative size of the assembled barley chromosome arms obtained via soapdenovo  <cit>  resulted in about  <dig> gbp .

the objects were  <dig>  barley unigenes  obtained from  <cit>  for a total of about  <dig>  mbp. additionally, we trimmed short reads for  <dig>  bacs obtained from  <cit> , for a total of about  <dig>  gbp. we also had access to  <dig>  bac assemblies  for a total of about  <dig>  gbp. while the genomic location for the majority of these “objects” was unknown, we had  <dig>  unigenes for which a location was derived from the golden gate oligonucleotide pool assay   <cit> , which allowed us to determine a presumed location of  <dig>  bacs  <cit> . we should point out that although we have used these locations as the “ground truth” to establish the accuracy of the classification, our observations indicate about 5% errors in these opa assignments  <cit> .

as stated above, the most critical parameter in clark is the length of the k-mer used for classification. by assuming that the subset of the unigenes that have a location via opa are correct, we were able to estimate clark’s precision and sensitivity for various choices of k. figure 1e shows these statistics, along with the assignment rate  and the average confidence score for all assignments. observe that as k increases, the number of assignments decreases but the precision/sensitivity increases. based on this analysis we determined that k= <dig> represents a good tradeoff for this dataset.
table  <dig> 
summary of 
clark
’s assignment of  <dig>  unigenes  to barley chromosome arms  and centromeres 



targets
19-mers
discriminative 19-mers
assignments
low confidence
high confidence

total
columns:  barley chromosome 1h, twelve chromosome arms, and six centromeres;  number of distinct k-mers in each target;  number of discriminative k-mers present in target sequences ;  number of assigned objects per target;  number of low confidence assignment per target;  number of high confidence assignment per target;  percentage of low confidence assignment ;  percentage of high confidence assignment .



additional file 1: table s <dig> presents a summary of clark’s assignment of barley bacs  to arms , while table  <dig> refers to the same assignments based on the reads instead of the assemblies . the consistency between these results  demonstrates the robustness of our approach. the agreement with opa-based locations is  <dig> % for r2r assignments, and  <dig> % for a2a assignments. observe that the agreement for bac/arm assignments is lower than unigene/arm assignments .summary of 
clark
’s assignment of  <dig>  bacs  to barley chromosome arms  and centromeres 



targets
19-mers
discriminative 19-mers
assignments
low confidence
high confidence

total
columns:  barley chromosome 1h, twelve chromosome arms, and six centromeres;  number of distinct k-mers in each target;  number of discriminative k-mers present in target sequences ;  number of assigned objects per target;  number of low confidence assignment per target;  number of high confidence assignment per target;  percentage of low confidence assignment ;  percentage of high confidence assignment .



finally, we compared clark against  the blast-based method used in  <cit>  for bac-arm assignment ; and  the assignments provided in  <cit> . for , clark assigned  <dig>  bacs  while the blast-based method assigned  <dig>  bacs . clark’s precision and sensitivity were  <dig> % and  <dig> %, respectively, while blast-based’s precision and sensitivity were  <dig> % and  <dig> %, respectively. blast-based and clark disagreed on  <dig> assignments; within these  <dig> disagreements, clark agreed with the goldengate assays on seven cases, and blast-based agreed on four cases. in , we examined the assignment for the  <dig>  bacs that were sequenced by our group and by leibniz-institut fur pflanzengenetik und kulturpflanzenforschung, gatersleben, germany   <cit>  and we identified only  <dig> disagreements ; among these disagreements,  <dig> had an independent assignment via pop-seq  <cit> . in  <dig> cases out of  <dig>  our assignment agreed with the pop-seq assignment. for the  <dig> disagreements for which there was no pop-seq assignment, we compared the assembled bacs and we discovered  <dig> cases in which the sequences were less than 30% similar, suggesting a naming error. in summary, there were only a handful of cases where the disagreement could not be readily explained.

performance dependency on the k-mer length
to determine the optimal value of k for a particular dataset one can take advantage of prior knowledge, as we did in the case of unigene/bac assignment to chromosomes. in that case, we had  <dig>  unigenes for which the correct bac assignment  was experimentally determined via illumina goldengate assay . given these known assignments, we estimated precision and sensitivity, as well as the average confidence score for all assignments and the assignment rate . observe that k= <dig> maximizes all four measurements. higher precision and average confidence score can be achieved by using higher k but at the cost of decreasing sensitivity and assignment rate.

similar evaluation were carried out on the metagenomic datasets. figure 1a to figure 1d show precision, sensitivity, as well as assignment rate and average confidence score as a function of k. in both cases we observe that as we increase k, precision and the average confidence score are increasing, while the sensitivity is decreasing. we observe that the maximum sensitivity is achieved for k in the range 19– <dig> for all metagenomic datasets, independently of the reads length or complexity.

as a consequence, for high sensitivity  one must choose k between  <dig> and  <dig>  for high precision  one must choose k higher than  <dig>  the current implementation supports k up to  <dig> 

CONCLUSIONS
we have presented clark, a new method for metagenomic sequence classification and chromosome/arm assignments of dna sequences.

experimental results demonstrate that clark has several advantages over alternative methods.  clark is able to classify short metagenomic reads with high accuracy at multiple taxonomic ranks  and its assignments on real metagenomic samples are consistent with findings published in the literature.  clark can achieve the same or better accuracy than the state-of-the-art metagenomic classifiers.  the classification speed of clark, in the context of metagenomics, is unmatched. clark can classify  <dig> million metagenomic short reads per minute, which is five times faster than kraken. in addition, clark “scales” better on a multi-core architectures: the speed-up one can obtain by adding more threads is higher than kraken.  clark is able to output confidence scores, is user-friendly and self-contained .  clark can be executed with relatively small amounts of ram  or disk space . indeed, lmat can use about  <dig> gb of ram, while the maximum amount of ram needed by clark is less than  <dig> gb . phymmbl or kraken require respectively about  <dig> gb and  <dig> gb of disk space to run, while clark requires 40– <dig> gb for classification.  in the context of genomics, clark can classify bacs and transcripts with better accuracy than previously used blast-based method  <cit> , and can infer centromeric regions.

even though in this manuscript we focus the attention on genus and species level classification, clark is expected to work also at higher taxonomic levels such as phylum, family or class. as it is now, however, clark cannot take advantage of taxonomic tree structures. we believe that clark will be useful in a variety of applications in metagenomics and genomics. for instance, we have used clark to identify chimerism and vector contamination in sequenced bacs.

