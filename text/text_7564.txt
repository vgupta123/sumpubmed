BACKGROUND
semrep semantic interpretation
the clustering method used for automatic summarization in this study depends on cliques identified in a graph of semantic predications extracted from pubmed citations with semrep  <cit> , a symbolic rule-based natural language processing system relying heavily on biomedical domain knowledge in the unified medical language system   <cit> . extraction of predications begins with an underspecified syntactic analysis based on the specialist lexicon  <cit>  and medpost part-of-speech tagger  <cit> . metamap  <cit>  maps simple noun phrases from this structure to metathesaurus concepts, and “indicator rules” map syntactic elements to umls semantic network predicates. semrep extracts  <dig> predicate types, in the domains of clinical medicine , substance interactions , etiology , and pharmacogenomics .syntactic processing then identifies arguments  for each predicate. as an example, the predications  below were extracted from the text, patients with single brain lesion received an extra 3 gy x  <dig> radiotherapy.

brain – location_of – single lesion

single lesion – process_of – patients

radiation therapy – administered_to – patients

automatic summarization
automatic summarization condenses source text into an abbreviated version representing salient information. most methods exploit an extractive process that selects informative text strings from the source and concatenates them into a summary. fewer attempts have been made to generate an abstractive summary, which processes the source text and represents it using terms not found in the source. both summarization techniques depend on identification of salient source content, either through informative textual cues, term frequency, or, more recently, graph-based metrics.

identifying salient source content
most frequency-based methods provide extractive summaries composed of source sentences containing frequently occurring content units. nenkova and vanderwende  <cit>  assessed the contribution of frequency of occurrence to summarization, which is considerable. reeve et al.  <cit>  further exploit domain ontologies to identify salient information.

recently, graph structures have been used to represent source content to be summarized. often, terms or sentences are represented as nodes and relations between them as arcs; however, abstractive representations are also used in graph-based analysis. graph theory-based metrics have been proposed to identify salient information. two commonly used metrics are degree centrality and eigenvector centrality, and both are based on connectedness. degree centrality is determined by the connecting arcs a node has, normalized for the size of the graph, while eigenvector centrality is computed based on the connections a node has along with the connectedness of neighboring nodes. several studies  have shown that degree centrality, when compared to other connectedness metrics, performs best for most tasks. lexrank  <cit>  and textrank  <cit>  have applied connectedness metrics to generate multidocument summaries. in lexrank, for example, nodes represent sentences and arcs similarity between them. node connectedness is used to identify prominent sentences as a summary.

in addition to text, biomedical data can also be represented as a graph, with nodes representing biological entities  and edges associations between them. for example, protein-protein interactions can be successfully modeled by a graph. based on the recognition of cohesive subgroups , gene or protein complexes can be extracted to help predict protein interactions or find gene-disease relations  <cit> .

cliques in graph theory
in graph theory, a clique is a subgraph in which every node is connected to every other node in that subgraph. the size of a clique is defined by the number of nodes in it. for example, a 4-clique contains four nodes. figure  <dig> shows five cliques, one 5-clique at the center, two 4-cliques on the left, and two 3-cliques on the right. in figure  <dig>  the four peripheral smaller cliques are included in the 5-clique, which is a maximal clique not included in any other.

identifying cliques can help find cohesive subgroups in a graphical network. usually, each node in a clique is, in some way, highly related to every other node. this characteristic makes clique identification a very important approach to uncover meaningful groups from a network, such as protein-complex discovery from protein-protein interaction networks  <cit> , collaborating groups from co-authorship networks  <cit> , etc. zubcsek et al.  <cit>  clustered cliques to identify information communities with ucinet. taking advantage of node overlap among cliques, ah-pine and colleagues  <cit>  proposed a clique-based clustering method to annotate named entities.

theme identification
identification of various themes contained in the summary can help users locate specific information they are interested in and link to relevant source documents. theme identification, also known as topic identification or topic discovery, is the process of assigning one or more labels to text  <cit> . to discriminate it from the topic of a summary, we refer to this task as “theme identification” in this paper.

theme identification is particularly important in multi-document summarization. to avoid similar information repetitiously appearing in the summary, stein et al.  <cit>  grouped their summaries from single documents into clusters and selected a representative passage from each cluster to construct the final summary. other studies  <cit>  clustered documents before performing summarization in order to help users select clusters of interest.

clustering is a very powerful data mining technique for identifying and labeling themes in a group of documents, and both k-means and hierarchical clustering are used for this task. for each cluster, features, such as keywords, terms, or sentence are chosen as the label . k-means clustering  <cit>  groups documents into predefined n classes. it is often used when the number of classes for the documents is known and serves as a reference standard to evaluate the final clusters generated. in reality, it may be hard to obtain expert-determined classification for thousands of biomedical documents, and hierarchical clustering is often used instead.

hierarchical clustering is an unsupervised method that does not require setting a predefined number of clusters for the documents. when using hierarchical clustering to group documents and generate labels for the clusters, the vector space model is often adopted to produce term or keyword vectors, which help indicate similarity among documents  <cit> . subsequently, documents are clustered into several subgroups, and terms or keywords that are salient for a given cluster are extracted as the theme  for the cluster.

methods
overview
our method for automatic summarization includes two major parts:  applying graphical metrics to help produce a summary and  using a clustering technique as well as semantics to identify themes contained in the summary . in the first part, the citations from a pubmed search are represented as semantic predications with semrep. then predications are converted into a graph with arguments as nodes and predicates as arcs. degree centrality and frequency of occurrence of predications are used to eliminate nonsalient predications from the graph, thus identifying relationships important for the summary. finally, cliques are identified in the summarized graph. in the second part, theme identification, a hierarchical clustering algorithm is applied to cliques to group them into several clusters, and a semantic theme label is assigned to each cluster.

data sets
to test the effectiveness of our method for automatic summarization, several topics, including disorders, substances, and physiological processes, were chosen for training and testing. citations were retrieved from medline with the topic term or phrase as major mesh term, limited to english and with abstracts. to accommodate evaluation, we further limited the number of citations to fewer than  <dig> , by publication date . the topics and the number of the citations for training and testing are shown in table  <dig> 

graphical representation for semantic predications
semrep predications extracted from medline citations to be summarized are first converted to a graph, with nodes representing arguments and arcs predicates. the direction of the arcs is from subject to object. the width of the arcs indicates the number of citations containing a given predications in the entire input set. figure  <dig> shows the graph resulting from processing a sample set of  <dig> distinct predications .

summarization processing
besides frequency of occurrence of predications, we used two graphical constructs, degree centrality and cliques, to condense the graph into a summary of salient predications. both degree centrality and clique detection help identify predications with high connectedness, which, along with frequently occurring arcs in the graph, convey information crucial to the summary. for example, in figure  <dig>  the predication “deep brain stimulation treats parkinson disease” is identified as highly salient because the nodes representing its arguments have more connections than other nodes, and the frequency of occurrence of the arc between them is higher than that of other arcs.

eliminate uninformative predications
before graph theoretic techniques are applied to create a summary, predications with at least one generic argument are eliminated from the graph, which removes uninformative relationships as part of the condensing process of summarization  <cit> . as noted earlier, arguments are metathesaurus concepts, and generic arguments,  are identified as occurring higher than an empirically determined cutoff in the umls hierarchy  <cit> . for example, the predication “pharmaceutical preparations treats parkinson disease” is eliminated from the graph, while “dopamine agonists treats parkinson disease” is kept because “pharmaceutical preparations” in the former is high in the hierarchy, while both arguments in the second predication are lower.

identify highly connected nodes
we assume that central nodes in the predication network are likely to represent important contents in the documents being summarized. in our previous study  <cit> , we found that degree centrality effectively identifies information crucial to summarization for researchers and clinicians. in the current study, we used degree centrality to sort the concepts in the network, and then, based on training data, defined a degree centrality cutoff, which is the mean of the sum of the degree centrality scores plus half of the standard deviation. predications in which both arguments have a degree centrality score above the cutoff are kept, while others are eliminated.

eliminate predications with lower frequency of occurrence
since frequency also plays an important role in automatic summarization, we calculated frequency of occurrence for the rest of the predications. the computation for frequency is based on how many citations a predication appears in  <cit> .  a formula similar to that for degree centrality  was adopted and predications with frequency of occurrence below the cutoff were eliminated from the graph.

identify cliques
after the first three steps, the predications remaining were those with high frequency of occurrence and having highly connected arguments; in the next step, cliques were identified in the graph of these predications. the tool used to identify cliques and cluster them in the next step is ucinet  <dig>  <cit> , a social network analysis package particularly useful for extracting cliques and analyzing overlap  <cit> . there is other research of relevance to our work. boyack et al.  <cit>  compare the effectiveness of several algorithms for clustering large numbers of documents, but they do not address details of the semantic content involved. blondel et al.  <cit>  discuss an efficient algorithm for identifying communities in large networks, but the “content” of these involves only one feature, primary language used in mobile phone networks, rather than the rich expressiveness of semrep semantic predications. since our main concern is exploiting semantic predications for the semantic content of documents, for the purpose of automatic summarization, rather than development of clustering algorithms, ucinet is entirely adequate.

the ucinet algorithm to identify cliques is based on the notion of a maximal clique, one that is not contained in any other. cliques are allowed to overlap, which means that concepts can be members of more than one clique. this feature is important for summarization because it permits certain concepts, which have high degree centrality and are the core of a network  to appear in several cliques of the graph.

theme identification
overview
a summary of a large number of documents usually includes several themes, or points of view. for example, a summary of breast cancer may include information on chemotherapies, procedures, genetic etiology, etc. in exploiting such a summary, a user may want to focus on any one of these themes. the accessibility of a summary is increased if the different themes are discriminated from each other and overtly represented. although cliques correlate somewhat with themes, this is not absolute due to the fact that cliques share nodes.

our approach to identifying themes in a summary exploits clusters of cliques and has two phases. in the first, clustering is based solely on nodes in the clique . in addition to identifying cliques from the predication network, ucinet automatically produces a clique co-membership matrix and a hierarchical clique clustering, which produces several possible solutions, each containing a varying number of clusters.

we then use semantic processing to select the clustering solution that best represents the themes of the summary. the goal is to put cliques with similar themes in the same cluster, while keeping cliques with different themes in separate clusters. the challenge is to determine the best clustering solution by grouping cliques in such a way that the themes of the summary are optimally represented. generally, the best clustering solution is neither too compact  nor too dispersed, as is the case if every cluster is a singleton having only one clique. when this solution has been selected, further processing determines whether some of the clusters should be collapsed  <cit>  based on semantic similarity.

visualizing cluster solutions
the tool we used to find and cluster cliques is ucinet  <cit> , a hierarchical clustering software package originally developed for social network analysis. ucinet produces a clique co-membership matrix in which the th entry of the matrix is the number of shared nodes  in clique i and clique j and the diagonal entries are the size of the cliques. based on this matrix, ucinet produces an icicle plot composed of solutions to the clique clustering. although each clique is assigned to a unique cluster, concepts may be in more than one cluster  <cit> .

these solutions can be visualized as an icicle plot  <cit>  such as that seen in figure  <dig>  in which the numbers on the top of the plot are labels for each clique. each row shows a cluster solution with a different number of clusters. for example, in the bottom row all cliques are included in one cluster, while in the top row there are two multiclique clusters: the first contains cliques  <dig> and  <dig>  while the second contains cliques  <dig> and  <dig>  all other clusters in the top row are singletons containing a single clique. we use an icicle plot to guide the processing for selecting the clustering solution that best represents the themes of a summary our system produces.

semantic processing for labeling clusters
in our method, determining the best clustering solution is based on semantic similarity of the individual clusters, as represented by theme labels. our graphs represent semantic predications, and cliques thus contain the arguments of predications  along with the predicates connecting them. identifying similarity of clusters depends on characteristics of the predications contained in the cliques that constitute the clusters. other approaches have used terms or sentences as theme labels, neither of which provides the greater expressiveness of semantic predications.

metapredications are used to identify and label the theme for each cluster. a metapredication, whose form is similar to a semrep predication, is defined as “<semantic group > <predicate group > <semantic group>”. the scope of the semantic group and predicate group is broader than that of the arguments and predicate of a semrep predication, so a metapredication generalizes the meaning of a cluster of cliques composed of several predications.

the predicate group used in a metapredication was defined for this project as a group of semrep predicates expressing related content. for example, predicate part_of is used with two physical units, in which the first is a component  of the second. predicate location_of is used to indicate the body location  of an entity or the site of a process. since these two predicates both express a relationship between physical entities, they were put into the predicate group physical. the semrep predicates that were assigned to predicate groups are given in table  <dig> 

*compared_with regularly appears along with treats to indicate drug comparisons.

** uses is commonly seen with treats to specify some aspect of the therapy.

the arguments of a metapredication are groups of semantic types suggested by mccray et al., who aggregated  <dig> umls semantic types into  <dig> groups based on six principles   <cit> . for example, the semantic type ‘therapeutic or preventive procedure’ and ‘laboratory procedure’ belong to the semantic group procedures, while ‘disease or syndrome’ and ‘neoplastic process’ are included in disorders. the metapredications used for this project are given in table  <dig> and represent the major semrep semantic predications extracted from medline titles and abstracts.

*the predicate for this metapredication is compared_with.

** the predicate for this metapredication is uses.

*** the predicate for this metapredication is measures.

in theme identification, each semrep predication in a cluster identified in the icicle plot is assigned to a metapredication. for example, the predications “dopamine agonists treats parkinson disease” and “dopamine agonists treats dyskinetic syndrome” are assigned to the metapredication “<chemicals & drugs > <therapy > <disorders>” because the predicate treats belongs to the predicate group < therapy > and the semantic type of the subjects and the objects of these two predications belongs to the semantic group chemicals & drugs and disorders, respectively. metapredications are then counted and sorted in descending order of frequency of occurrence; the most frequent identifies the theme of the cluster and serves as its label.

as an example of assigning a metapredication theme label to a cluster of cliques, the graphical representation of the first cluster in row  <dig> in figure  <dig>  is shown on the left side of figure  <dig>  for this cluster, there are two semantic types, ‘therapeutic or preventive procedure’ and ‘disease or syndrome’, which belong to two semantic groups, procedures and disorders respectively. given that the most frequent predicate in this cluster is treats, the most frequent metapredication is “procedure treatment” , which serves as the theme label for this cluster.

selecting the optimal clustering solution
semantic theme labels form the basis for selecting the best clustering solution to represent themes for the summary generated by the method. as represented in the icicle plot, the several clustering solutions are arranged hierarchically, so that the solution containing the most clusters is at the top of the plot. in each succeeding row, adjacent clusters may be merged , so that the final, bottom row contains fewer clusters than those preceding it. in our method, merging of clusters in succeeding rows is augmented with semantic processing to choose the optimal clustering solution, one in which there are no clusters that could be merged in the succeeding solution  based on shared nodes and which have the same theme label.

after theme labels have been computed for clusters in the icicle plot, each successive row of the icicle plot is processed, starting with the row that is likely to require minimum merging. based on training data, this is the first row from the top that has no more than three singleton clusters . the current row is compared to the immediately succeeding row, and it is noted whether any separate clusters in the current row are merged in the following row, and further, whether those clusters have the same metapredication theme label. if both conditions are satisfied, the succeeding row is considered to be a better solution than the current row, and the former succeeding row becomes the current row. when a row is encountered for which the succeeding row is not a better solution than the current row, the current row is considered the optimal solution.

for example, in figure  <dig>  row  <dig> is the starting line because it has only two singleton clusters. in the succeeding line, row  <dig>  clusters  <dig> and  <dig>  are merged, and they have the same theme label . thus row  <dig> is considered a better solution than row  <dig>  when row  <dig> is compared to row  <dig>  it is seen that clusters  <dig> and 5– <dig> have the same theme label  and that they are merged in row  <dig>  which is thus considered to be a better solution than row  <dig>  when the immediately succeeding row, row  <dig>  is encountered, it is seen that clusters  <dig> and  <dig> are merged. since they do not have the same label theme, the algorithm stops and row  <dig> is selected as the best clustering solution for this summary.

evaluation
in a previous study  <cit> , we evaluated the effectiveness of degree centrality as a condensing mechanism for automatic summarization to answer disease treatment questions in a semantic predication graph. we have also constructed a semantic predication gold standard  <cit>  to support further evaluation. in addition, we have assessed the ability of semantic medline, a semrep-based summarizer, to identify useful drug interventions for evidence-based medical treatment  <cit> . in this paper, we evaluated two aspects of clustering cliques for automatic summarization: the validity of the clusters produced and the quality of the cluster labeling.

validity of the clusters
the validity of the clusters was assessed by measuring cluster cohesion and cluster separation. cohesion measures the purity of the objects within a cluster, i.e. how closely related the objects in a cluster are. separation measures the isolation of the objects in different clusters, i.e. how distinct a cluster is from other clusters. for our clusters, composed of semantic predications, we evaluated how related the semantic predications in a cluster are to its cluster label  and how well-separated semantic predications with different labels are in different clusters.

for example, for a cluster i labeled as “procedure treatment” , if there are x predications included in this metapredication  and y predications not matching , then the cohesion of the cluster i is defined as:

 cohci=x/x+y 

if in addition to cluster i, there are z predications in other clusters that match the label of cluster i, then the separation of cluster i is:

 sepci=x/x+z 

inspired by calculation of f-score for information retrieval task, we defined the overall validity of cluster i as follows:

 overallvalidityci=2cohcisepci/cohci+sepci 

we compared our system output to a baseline whose clique clusters were determined by the silhouette coefficient  <cit> , which is often used to determine the appropriate number of clusters in clustering data mining research. we used a symmetric matrix in which each cell was the number of shared nodes by the corresponding pair of cliques to compute the distance between cliques. then the average silhouette coefficient   was calculated for each clustering solution and the solution with the highest asc served as the baseline. cohesion, separation, and overall validity were also calculated for the baseline.

quality of the cluster labeling
the accuracy of themes annotated by cluster labels is important to the final summary. a cluster with a poor label may be ignored by users even if it links to a group of documents relevant to their information needs. we thus also evaluated the labeling effectiveness of our system. since it is almost impossible for domain experts to produce class labels for the results of clustering tens of thousands articles, we constructed a reference standard for evaluation based on the medical subject heading  descriptors assigned to source citations that produce predications in the summary clusters. this evaluation was done by comparing arguments extracted from the predications in the cluster to mesh indexing terms assigned to the citations from which the predications were extracted.

for each citation in medline, indexers at the national library of medicine assign  <dig> to  <dig> mesh descriptors as well as qualifiers  to cover the topics of the article; they also indicate those mesh descriptors reflecting the major points of the article as major mesh descriptors. since this indexing procedure is performed by human experts, it is deemed that the mesh descriptors, especially the major ones, accurately represent the contents of the article. for example, for a citation entitled “aspirin and antiplatelet agent resistance: implications for prevention of secondary stroke” , the major mesh descriptors are: aspirin/pharmacology; platelet aggregation inhibitors/pharmacology; stroke/prevention & control. in constructing the reference standard, we ignored mesh qualifiers. for example, mesh descriptors “antipsychotic agents/therapeutic use” and “antipsychotic agents/administration & dosage” were counted as one term.

for each cluster in the summary, major mesh descriptors assigned to citations producing predications in the given cluster were extracted and sorted in descending order of frequency of occurrence. the predication arguments in each cluster were compared to an equal number of the ranked mesh descriptors, starting with the most frequent descriptor.

in comparing predication arguments to mesh indexing terms, we exploited metathesaurus synonymy to match concepts in the graph to mesh descriptors. for example, the concept “diabetes mellitus, non-insulin-dependent” was matched to term “diabetes mellitus, type 2” because the concept is a synonym of the term in mesh vocabulary. finally, recall, precision and f-score were calculated.

RESULTS
an example of the final summary
figure  <dig> illustrates the final graphical summary  for the topic schizophrenia, which appears as the central node of the graph. four themes were identified and are highlighted in color. notably in this summary, delusions and hallucinations are seen as comorbidities of schizophrenia, while dopamine, glutamate and neurotransmitters are associated with its etiology. drug treatment constitutes the largest cluster; in addition to representing major drugs for schizophrenia , it shows comparison between two drugs , and some adverse effects resulting from the drugs, such as weight gain and tardive dyskinesia . it should be noted that the characteristics of this graph reflect the condensing aspects of a summary, and do not necessarily accommodate other information management tasks, such as discovery. for an example of processing semantic predications for discovery see  <cit> .

validity of the clusters
table  <dig> shows cohesion, separation and overall validity of both the system summary  clusters and the baseline  for the testing data. out of  <dig> topics, one, interleukin- <dig>  produced only one cluster, so we did not compute cohesion and separation for this topic. results for the other  <dig> topics appear in table  <dig> 

quality of the summary theme labeling
table  <dig> shows the results of comparing predications in the summary to mesh terms. the overall f-score is  <dig> , with recall  <dig>  and precision  <dig> . scores are largely consistent across all eleven topics and are comparable to those obtained with other systems .

discussion
generally, results showed that our method, based on graph theory as well as semantic predications, can produce satisfying summaries of large numbers of biomedical documents. the validity of clusters determined by semantics was better than that determined by the silhouette coefficient, and, further, the summary represented the major salient content of topics. analysis of the overall validity of clusters showed that system output is 10% better than the baseline . although the cohesion of the baseline is slightly higher than that of the system summary, the separation of the system summary is significantly better than that of the baseline. the number of clusters determined by the silhouette coefficient is greater than the number determined by semantic information, which results in a relatively higher cohesion and lower separation in the baseline.

we used metapredications to calculate cohesion and separation; such predications were constructed from semantic information pertinent to the core meaning of the themes. for example, the drug therapy theme  expresses predications asserting specific drug therapies  and comparison of such therapies .

predications that do not belong to these two metapredications are counted as false positives when computing cohesion and separation. a problem arose with the predicate causes, which semrep uses to expresses both side effect of drug  and etiology of disease . we chose not to include causes in this theme, which caused some legitimate side-effect predications to be considered false positives when evaluating this theme. this decreased cohesion and separation, as well as overall validity for clusters containing the drug therapy theme.

false negatives
two issues were encountered in comparing concepts in each cluster to mesh descriptors to evaluate the summary, both of which caused discrepancy between results and actual quality of the summary in expressing the semantic content of input citations. the first issue is due to indexing policy. for example, concepts referring to body part represented the major contents in disease location clusters. however, mesh descriptors in the anatomy category are not normally indexed as major topics. for example, lung  and pancreas , were not indexed as major topics.

a second problem encountered in matching predications to mesh indexing terms involves qualifiers . for example, the concept “toxic effects” in the predication “anti-inflammatory agents, non-steroidal causes toxic effects” was often extracted from citations that had been indexed with the qualifier “toxicity.” since only mesh descriptors were compared in the evaluation, this concept was counted as a false negative.

false positives
false positives were largely caused by infelicitous mapping to metathesaurus concepts. for example, statin has two mapping candidates, “stn gene” and “hydroxymethylglutaryl-coa reductase inhibitors,” in the metathesaurus. for most sentences, such as “… patients prescribed a statin with drugs that may increase the risk of myopathy”, “stn gene” was selected due to incorrect word sense disambiguation.

limitations and future work
although our system can produce useful summaries for large numbers of medline citations and cluster the summary into several groups based on the themes, it has limitations. as mentioned in theme identification section, ucinet uses a hierarchical clustering algorithm to cluster cliques. hierarchical clustering analysis is very practical in detecting topics for documents because it does not require human intervention to assign the number of the clusters in advance, as k-means clustering algorithm does. wartena and colleagues  <cit>  used a k-bisecting clustering algorithm, which is based on the k-mean algorithm, to cluster frequently occurring keywords in  <dig> documents taken from  <dig> wikipedia categories. they clustered these into  <dig> categories, one for each wikipedia category and one additional cluster. while in reality, it is almost impossible to pre-define the number of the clusters for varied topics in biomedical domain, lee and colleagues  <cit>  compared supervised and unsupervised methods to detect topics in biomedical texts and found that the performance of supervised topic spotting methods was better. they also found that unsupervised hierarchical clustering was robust and more readily applicable in real world settings. the clustering algorithm we used is based on the common concepts shared by the cliques. in other words, the clique-clique proximity matrix used for clustering is constructed on the basis of the similarity of predication arguments contained among the cliques. it ignores the similarity of predicates, which may also contribute to the computation of clique similarity. although the effectiveness of clustering algorithms is not the focus of this paper, we will explore different clustering algorithms and consider adding predicates to enhance results in our future work.

another limitation is that the final number of clusters is determined by a fixed threshold, which is widely used to detect the number of clusters in a dendrogram  whose branches are the clusters of interest. a fixed height on the dendrogram is chosen to cut the cluster tree into several groups. the icicle plot we used provides information similar to that in a dendrogram. we used semantic themes contained in each cluster to help find the height at which to cut the icicle plot. as mentioned in how to select the optimal clustering solution, when clusters identified in the icicle plot have different themes, the algorithm ends at that level and the corresponding row is determined to be the optimal clustering solution. but for some topics, the fixed threshold cannot achieve satisfactory results. for example, figure  <dig> shows the icicle plot for clustering the topic tumor necrosis factor.

as shown in figure  <dig>  the system uses a fixed threshold  to group this topic into eight clusters. by considering the semantic information contained in each cluster, we can determine that the themes of cluster one and two are the same , cluster three and four are both about locations of the substances, while clusters five, seven and eight are all about chemicals as the cause of disorders; finally, cluster six is about chemicals treat disorders. it is obvious that repetitive themes are produced.

instead of the fixed threshold, we will explore the use of a dynamic threshold  <cit>  to detect clusters. compared to cutoff based on fixed height, a dynamic threshold, which uses different cut heights on different branches of the cluster tree, makes determining the number of clusters more flexible. for example,  <cit>  and  <cit>  used a dynamic tree cut method on the basis of analyzing the shape of the branches of the dendrogram. in the future, we will consider both the shape of the icicle plot and cluster themes to determine a dynamic threshold, such as cutoff b in figure  <dig>  by considering the themes of clusters  <dig> to  <dig> in figure  <dig>  the dynamic cutoff b chooses different clustering solutions at different cutoff heights, so that clusters having the same cluster labels in the fixed threshold cutting method  are merged together, and three new clusters  are produced. with cutoff b, five clusters  are produced for the topic tnf. compared to cutoff a, dynamic cutoff b increases separation by  <dig>   and overall validity by  <dig>  .

CONCLUSIONS
we exploited graph theoretical methods to summarize biomedical documents; using hierarchical clustering, we then grouped the summary into several themes for a given topic based on the semantics contained in the summary. the system summary was compared to a reference standard produced by selecting the same number of the most frequent major mesh descriptors as the number of concepts in the summary. the result showed that recall, precision and f-score were  <dig> ,  <dig>  and  <dig>  respectively. the validity of the clusters was compared to a baseline computed with the silhouette coefficient method for cohesion, separation and overall validity. the overall validity of the system output clusters was better than that of the silhouette coefficient clusters.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
hz conducted all research, including developing the algorithm and evaluation, and wrote the manuscript. mf provided suggestions to the research. ds implemented the algorithm. bw designed and implemented the algorithm for finding the quality of the cluster labeling . tcr supervised the research and edited the manuscript. all authors read and approved the final manuscript.

