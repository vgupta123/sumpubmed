BACKGROUND
all biological processes at the cellular level are the consequence of a series of chemical-physical reactions at the molecular level that occur within the micro-volume of the cell. the collection of molecular species and the reactions among them is referred to here as a 'biomolecular reaction network'. the complete biomolecular reaction network for a cell includes thousands of molecular components and reactions involved in transcription, translation, molecular self-assembly, metabolic reactions, transport and physical movements. since these reactions occur in an extremely small reaction volume, the number of molecules of any one molecular species that can participate in a given reaction ranges from single copies of genes to several hundred molecules of chemicals at the μm concentration to several hundred thousand molecules of chemicals at the mm concentration. as a consequence of the fact that a subset of all the reactions in the system involve low copy numbers of substrate molecules, the behavior of individual instances of the system cannot be modeled accurately using continuous deterministic  approaches . thus, these natural micro-systems should be modeled and simulated using basic theory of discrete stochastic  chemical kinetics  <cit> .

with the evolution of systems biology in recent years, interest in modeling and simulating the behavior of engineered genetic circuits in bacterial cells has increased  <cit> . in addition to living cells, nano-biotechnology researchers are exploring the possibility of developing and using artificial cellular constructs employing natural and engineered biological processes . in order to predict the behavior of these constructs, modeling and simulation of their biomolecular reaction networks are needed to enable the design and fabrication of both the constructs themselves and physical devices based on these constructs.

using stochastic chemical kinetics for exact simulations of biomolecular reaction networks presents several computational challenges. the ultimate goals of the simulation exercise are to be able to:  model and simulate the behavior of the system using a complete and accurate physical and mathematical description of the system and an exact simulation algorithm,  generate large numbers of simulations, and  analyze the data in a meaningful way. all of these goals should be accomplished in a reasonable amount of computational time. the main factors that determine the computational challenge of a particular simulation activity are the size of the model , the nature of the reactions , the duration of the simulation, the number of simulations required for statistical significance, the data logging requirements, and, data analysis requirements. depending on the computational dimensions of the problem, the ultimate goals of the simulation exercise, as defined above, may be attainable. however, as the computational dimension increases, the ability to meet all of the requirements of the ultimate solution becomes more difficult.

there are two approaches that can be taken to address the more difficult computing problems associated with larger computational dimensions. the first approach is to employ approximations at various levels of the modeling and simulation process. at the conceptual model level, detailed reaction mechanisms consisting of multiple micro-reactions can be replaced with approximate lumped macro-reactions. this has the effect of reducing the number of both molecular species and reactions in the model. at the simulation level, there are approximate stochastic simulation algorithms, such as τ-leaping  <cit> , that can speed-up the simulation time, but at the expense of accuracy. at the statistical level, the accuracy of the statistical properties of the ensemble of system simulations, computed from the simulation data, increases as the number of simulations increases, ultimately approaching the statistical properties of the exact solution in the limit as the number of simulations increases to infinity. thus, truncating the number of simulations to decrease the computational time results in less accurate approximations of the statistical properties of the system. finally, the collection and storage of the raw simulation data will affect the computational time. the maximum information obtainable from a simulation run requires the collection of the time and nature of every reaction event. limiting the amount of data collected will reduce computation time at the expense of the types and accuracy of subsequent data analyses.

the second approach is to run simulations on bigger and more powerful computer hardware using software designed to take advantage of multiprocessors. although the exact stochastic simulation algorithms do not lend themselves to efficient parallelization of the algorithm itself, running multiple simulations on separate processors can reduce the overall time required to generate a statistically adequate ensemble of independent simulations. this approach does not reduce the actual computational time, but, by running multiple simulations in parallel, it does allow one to reduce the clock time required to obtain a sufficient number of simulations for appropriate statistical analysis. in addition, numerical analysis of the large data sets generated by the simulation can be parallelized to speed up this time consuming step. overall, there are a range of trade-offs between simulation strategy, data accuracy and computational time that must be taken into consideration when optimizing the modeling, simulation and analysis of biomolecular reaction networks for particular applications.

in recent years, single cell experiments have become a significant focus of the experimental approach to problems in systems biology. analysis of data derived from such experiments should be interpreted in the context of stochastic systems and we feel that it is of practical value to the broader community of researchers to present concrete examples of these issues using a hypothetical model that is relevance to the fundamental transcription-translation-metabolism scheme. to model and simulate the behavior of these systems, various software packages have been developed and released to the general public . each of these software products has its advantages and disadvantages for different modeling needs. we developed a software package – the biomolecular network simulator  – that is specifically designed to operate on either single or multiple processor hardware  <cit> . the bns software allows one to build a model of a synthetic biomolecular reaction network and to investigate its behavior using several different stochastic algorithms. here we use the bns software to investigate the effects of various external conditions, such as selecting:  the observation interval,  the time-averaging interval, or  the number of simulation, on the observed behavior of a hypothetical, yet relatively complex, biomolecular reaction network involving transcription, translation and metabolism to illustrate some of the unique data analysis issues that arise in stochastic simulations of biomolecular reaction networks. it is hoped that the reader will gain a better intuitive understand of how these factors can influence the interpretation of stochastic reaction systems.

methods
stochastic simulation algorithm
the mathematical description of the behavior of stochastic biomolecular reaction networks is based on markov process theory  <cit> . the system behaves as a multi-variant, discrete state, markov jump process and is governed by the chemical master equation . the solution of the cme is in fact the mathematically exact description of the behavior of the system. for our purposes, we will consider a biomolecular reaction network consisting of ns identifiable molecular species, denoted si . these molecular species can undergo nr fundamental chemical reactions rk  and are confined to a fixed reaction volume, vr. it is assumed that the system is well-mixed  and at constant volume and temperature. let s be an ns-dimensional state vector whose elements si  are the number of molecules in the system of each molecular species si at time t.

the stochastic process that describes the behavior of the biomolecular reaction network is characterized by the state probability density function p. this function gives the probability that the system is in state s at time t, where s can take on any value in the allowable state space. p is the solution of the cme  <cit> :

   

where ak  is the propensity of the kth fundamental reaction at time t and νk is the state change vector, a ns-dimensional vector that specifies the changes in the number of molecules of each state variable when the kth reaction occurs. note, the sum is over all of the nr possible reactions that can occur. further note, the propensity for a given reaction, ak, is computed as the product of the reaction probability constant, ck, and the total number of combinations of possible reacting molecules for that reaction. the reaction probability constant is, in a sense, a measure of the reactivity of the reaction substrates  <cit> .

the specification of the initial condition for the biomolecular reaction network of interest, p <dig> = p, depends on the precision and accuracy of the measurement techniques used to experimentally characterize the system. in theory, the system is in a single well defined state s <dig> at time t <dig>  where the number of molecules of each molecular species is equal to the exact number of molecules of that species contained in the reaction volume vr at time t <dig>  in this case, p <dig> is defined by the kronecker delta function as

   

for our purposes, it will be assumed that the initial condition as defined by equation  will hold and the state density function that is the solution of the cme can be written as the conditional probability density function p.

usually, an analytical solution of the cme is not possible and direct numerical computation of the solution is computationally overwhelming due to the large state space. however, the direct simulation of exact  trajectories in state space is feasible  <cit> . the time evolution of the state vector s for a theoretically possible instance of the system can be calculated using various algorithms proposed for monte carlo simulations of stochastic trajectories. the gillespie direct stochastic algorithm  <cit>  is used in this report to illustrate the stochastic behavior of a gene expression system. the gillespie direct stochastic algorithm theoretically generates exact simulations of system trajectories in state space if and only if all reactions in the biomolecular reaction network are fundamental reactions  <cit> . in the limit of an infinite number of simulations, the statistical properties of the ensemble of exact simulations approaches those of the exact solution of the cme, i.e., for the first moment  of s ⟩) we have

   

where si  is the value of the state vector at time t in the ith simulation run, ⟨s⟩n is the estimate of the mean state vector at time t based on an ensemble of n simulations, the left hand sum is over all possible states in state space and the right-hand sum is over all values of the state vector at time t observed in the n simulation runs. in addition, the second moment of the probability density function for the state vector s is related to the variance by the relationship

   

where the variance of s is

   

and σn  is the estimate of the standard deviation  based on the ensemble of n simulations. thus, computing the mean and sd of the ensemble of simulations at a given time provide an estimate of the first and second moments of the probability density function for the system at that time.

although the basic biochemical reactions in a biomolecular reaction network are treated as discrete, jump markov processes and thus stochastic in nature, if the number of molecules of every species in the system is large then the process can be approximated by a continuous markov process  <cit> . furthermore, if the number of molecules and the volume increase in proportion such that the concentration of each species is constant , then the solution describing the behavior of the state variables can be written as the sum of a single-valued variable that is the solution of the classical rate equations and a variable factor that decreases in magnitude as . thus, for sufficiently large reaction volume, keeping concentrations constant , the first moment of the probability density function of the state variables approaches the classical continuous deterministic solution of the reaction rate odes. however, if there are only a few molecules of any given species, as is often the case in gene expression, this approximation will not accurately describe the instantaneous state of the system. furthermore, the c-d approach will provide no information concerning the temporal fluctuations of state variables of a given system nor the variability between multiple instantiations of the system with identical initial conditions.

biomolecular network simulator software
the biomolecular network simulator software was developed to allow for stochastic simulations on either desktop or multi-processor hardware . the front-end graphical users interface  and the backend data analysis tools are written in matlab. this allows the user to exploit the interactive features and visualization tools of matlab for setting up simulations and analyzing and interpreting the resulting data. the simulation engine itself and the analysis tools are written in the c language to maximize speed for the computationally intensive part of a simulation run and post-simulation data analysis.

the bns software accepts two types of model definitions:  systems biology markup language  format  <cit>  and  bns format where models are defined by a set of matlab m-files. there are two types of output files: snapshot data and event log data. snapshot data files contain the state of the system  and the number of reaction occurrences in each reaction channel since the last snapshot at user specified time intervals. the second type of output files – the event log files – contain the record of every discrete event that occurs during the simulation .

the bns software has a comprehensive set of tools for post-simulation analyses. the most frequently used type of analysis is to plot the number of molecules of a particular molecular species versus time. the number of molecules of a particular molecular species versus time plots can be created with both types of output files, snapshot data or event log data, with the event log data giving an exact description of the behavior of the selected state variable. a time-weighted average analysis provides for the calculations of the average number of molecules of a particular molecular species during a user selected time-interval. the time averaged number of molecules of state variable k over the interval Δt at time ti, ⟨sk⟩Δt, is given by:

   

where

   

ti, j is the jth time subinterval in the interval ti to ti+ Δt and the summation is over , the total number of reaction events in the interval ti to ti+ Δt that affect sk. the computation is accomplished by summing up the products of the time sub-intervals multiplied by the number of molecules present in that sub-interval, thus the average is weighted according to the amount of time the compound exists in each state during the selected time-interval. the averaging analysis can be performed for a single simulation run or for an ensemble of runs. in the latter case, the between run average  and standard deviation are plotted.

when multiple simulations are run, the distribution of state variables for the ensemble of simulations at a given time can be investigated by plotting a discrete histogram. the data to generate these discrete histograms can be extracted from data files saved by the analysis tools in the bns toolbox. the distribution for a particular state variable k at time ti, , is computed by counting the number of times each possible state j for that state variable is occupied at time ti in the ensemble of simulations () and dividing by the total number of simulations .

   

the data are plotted with the y-axis representing the fraction of the simulations that the state variable was in the discrete state indicated on the x-axis. this is an estimate of the probability that the system would be in that particular state at the defined time ti, i.e., the state probability density p defined by equation  <dig> 

complex biomolecular reaction networks that involve gene expression are usually stiff systems, i.e., contain reactions that occur on widely different time scales; some reactions have a low propensity and occur rarely while other reactions have a high propensity and occur frequently. a unique feature of the bns software is that the data stored allows the user to perform various reaction event rate analyses on the simulation data to learn more about the basic nature of the reactions in the system. the time-averaged reaction event rate in reaction channel q  can be calculated for a user-selected time-averaging intervals Δt by:

   

where  is the number of reaction events in the time interval ti to ti+ Δt. these analyses provide important information about the behavior of the system, e.g., relative event rates for important reactions. such event rate data can be used to calculate the rate of substrate utilization in selected reaction channels as a function of the state of the system.

the bns software can be run on high performance computing  hardware. parallelization of the bns code for simulation runs on hpc hardware is accomplished using the message passing interface . in our parallelization scheme, the 'master' processor divides the total number of simulation runs into a set of jobs depending on the number of available processors and sends a job to each of the 'worker' processors. the snapshot data from the workers are sent back to the master processor for the interactive graphics while the event log files are saved directly to the hard drive by the workers. in this approach to parallelization, the power of parallel processing is utilized to run a large number of simulations simultaneously and thus speedup the overall clock time for large batch jobs.

exemplar model
in order to investigate the analysis of a discrete stochastic system, a hypothetical model of a generic two gene, self-assembling catalytic ligation reaction in a cell-free transcription-translation  system is explored. the hypothetical biomolecular reaction network consists of the transcription and translation reactions of two genes in a gene expression system and the subsequent metabolic reactions of the expressed enzymes. the system is assumed to be a closed system contained in a vesicle with a reaction volume of  <dig> × 10- <dig> l corresponding to a spherical vesicle with a diameter of approximately  <dig>  μm. note, in such a vesicle, a molecular species at a concentration of  <dig> μm is equivalent to a total of  <dig> molecules present in the vesicle. the cftt system contains all of the necessary components for transcription and translation of target genes into the expressed proteins.

to formulate a conceptually simple, yet biochemically reasonable, model of the kinetics of the self-assembly of the exemplar biomolecular reaction network and the subsequent metabolic reactions, the high level conceptual system model illustrated in figure  <dig> was proposed. the detailed model of the system consists of  <dig> state variables and  <dig> reactions . in the detailed conceptual diagram of the system, state variables are labeled with names that are descriptive of the molecules that they represent. however, internally in the sbml model code the state variables are labeled s <dig> to s <dig>  wherever there may be confusion in the discussion below, both labels are used for clarity.

transcription of genea and geneb consists of four reactions each. the four reactions are the association and dissociation of the rna polymerase  and the promoter sites for genea  and geneb  to form the promoter-polymerase complexes . the polymerase then translocates from the promoter site to the transcription start site forming the transcription start complex  and the subsequent formation of the mrna . the mrnas can either be degraded by a generic rnase or used as a template for protein synthesis. translation consists of three reactions that include association and dissociation of the small ribosomal unit  with the ribosomal binding site on the mrna to form the ribosomal-mrna complex  and the subsequent translation reaction resulting in the formation of the protein products . key substrates for the translation reaction are the  <dig> charged transfer rnas  which are formed from the appropriate amino acids  and the corresponding transfer rnas  by the associated aminoacyl-transferases . the protein product pro_a is capable of catalyzing the ligation of sub_ <dig>  and sub_ <dig>  to form the metabolic product prod_a  via a series of association, catalytic and dissociation reactions. the protein product pro_b must form a tetramer  to be catalytically active. once formed pro_b_ <dig> catalyzes the ligation of prod_a and sub_ <dig>  to form the final product prod_b  via another series of association, catalytic and dissociation reactions. all proteins can be degraded by a generic protease .

in this biomolecular reaction network, the biomolecular reactions relating to the expression of genea and geneb and subsequent metabolism are treated as stochastic in nature. here we use the gillespie direct stochastic algorithm to obtain sufficient numbers of probabilistically correct state space trajectories, consistent with the cme, for statistical analyses. the simulation data sets obtained through the use of these monte carlo simulations are used to illustrate some of the statistical properties of the stochastic behavior of the exemplar model. note, these simulation data are for a generic model and do not necessarily represent the behavior of any actual system.

RESULTS
simulation of exemplar model using the gillespie direct algorithm
in order to explore the general behavior of the exemplar model, a series of simulations were run using the following conditions:  the gillespie direct stochastic simulation algorithm,  an sbml model definition ,  the stochastic reaction parameters and initial conditions in the sbml model definition, and  the following simulation parameters: number of simulations =  <dig>  duration of simulation =  <dig> sec, snapshot interval  =  <dig> sec , and event log = on. a limited number of simulations  were used to obtain representative results quickly . due to the scale of the model , it is not possible to show the total set of data for all state variables, but a few selected and important state variables are shown in figure  <dig> to illustrate the general behavior of the system. the data presented show the trajectories of the selected state variables for a single representative simulation using the event log data. these data show each and every event that affected the selected state variables and is an exact trajectory in state space. the biomolecular reaction system under investigation is a closed system with a limited supply of energy molecules and reaction substrates. the system self-assembles via transcription and translation of genea and geneb, using the available energy and substrates, to form the metabolic reaction pathway consisting of two tandem ligation reactions that ultimately synthesize the final product, prod_b. when critical substrates are depleted, reactions dependent on these substrates stop. in this particular system, three substrates, gtp , atp  and sub_ <dig>  prove to be critical  and 2) although another substrate, charged trna for glutamine  could be critical under slightly different circumstances ). first, gtp is depleted at about  <dig> sec. since gtp is utilized by both mrna synthesis as a substrate and protein synthesis as an energy source, both transcription of messenger rna and translation of the protein products are simultaneously terminated at the time when gtp is depleted. even if protein synthesis had not terminated at  <dig> sec due to depletion of gtp, it would have terminated soon thereafter due to the depletion of aa_q_trna_aa_q. secondly, atp is not only a substrate for mrna synthesis, but is also an energy source for the ligation reactions and charging of trna with amino acids. therefore, when atp is depleted at about  <dig> sec, both the enzymatic ligation reactions and the trna charging reactions terminate. third, the first metabolic ligation reaction terminated when sub_ <dig> was depleted at about  <dig> sec and subsequently, the second metabolic ligation reaction would have terminated when all of prod_a formed by the first ligation reaction was depleted. these reactions illustrate the general behavior of a closed biomolecular reaction network, reactions that depend on substrates and energetic molecules terminate when these components are depleted while simple binding reactions that operate on thermal energy continue to be executed.

to generate the exact trajectories for state variables, the 'create plots from data' tool in the bns analysis toolbox must parse the event log to obtain the time sequence of each reaction and then create the trajectory of each state variable. for systems that involve many reactions and many state variables, this can be a computationally demanding and thus a time consuming process. to obtain a quicker but lower resolution picture of the general behavior of the system, the bns software computes the state of each state variable at fixed time points determined by the snapshot interval  which is user defined. figure  <dig> shows three of the same trajectories as in figure  <dig> but using the snapshot data with ssi ranging from  <dig> to  <dig> sec. note, these simulations were performed using the same random number seed, thus the event logs are identical for all of these simulation, only the snapshot data files change between simulations. for state variables that are experiencing rapid dynamic fluctuations , and 3), it is obvious that the snapshot plots do not reveal all the details of the behavior of the state variable. for example, the instantaneous values of the free mrnas for genea  blue line) fluctuate rapidly between  <dig> and  <dig> copies when transcription terminates . however, inspection of the snapshot data for ssi =  <dig> sec during the same time interval suggests that the levels only fluctuate between  <dig> and  <dig> copies. as this series of data indicate, the snapshot data approach the exact behavior  as the ssi decreases. for this particular biomolecular reaction network, only a ssi =  <dig> sec gives an adequate approximation to the exact behavior of these rapidly fluctuating state variables. on the other hand, state variables that are only created  or only destroyed  do not fluctuate but merely increase or decrease monotonically ). for these state variables, a ssi =  <dig> sec gives an adequate approximation. for this model, a ssi =  <dig> sec will be adequate to give a general impression of the behavior of most state variables except for those that fluctuate rapidly. however, the ability to observe the actual range of a state variable that fluctuates rapidly will only be possible using the event log data.

each simulation run provides a probabilistically accurate trajectory of the system in state space. figure  <dig> shows the state space trajectories of the number of molecules of several state variables for  <dig> individual simulations. although each of the trajectories shown illustrates the possible behavior of the state variable that is consistent with the physical-chemical nature of the system, the likelihood that the behavior of any actual system would behave in an identical manner to a simulated trajectory is small. thus, comparison of the data for a single simulation run with time-series experimental data from a single biomolecular reaction system would not be particularly useful, except in the sense of general trends. the value of individual simulation runs is to provide some intuitive insight into the possible range of behaviors of the system under investigation. for example, figure  <dig> illustrates the behavior of free genea mrna . in all three simulations, the level of free mrna increases while transcription is active, then levels off when gtp is depleted. in spite of the rapid fluctuations in the level of free mrna, the general trend is similar in all three simulations. in figure  <dig>  the state space trajectories of the number of molecules of the free amino-acyl-transferase for the amino acid glutamine, aa_trans_aa_q , the uncharged trna for glutamine, trna_aa_q , and the charged glutamine trna, aa_q_trna_aa_q  is shown. in each simulation, the level of the charged trna fluctuates about a value of approximately  <dig> while it is feeding the translation reactions and then drops rapidly when glutamine is depleted. however, the timing of the rapid drop in charged trna and the final level of the charged trna varies from run-to-run depending on when gtp is depleted and how many protein molecules were completely synthesized before gtp was totally consumed. in figure  <dig>  the substrates and products of the ligation reactions are shown. in the left-hand panel, the rate of the second ligation reaction was fast relative to the first ligation reaction and all of the intermediate product was converted to final product at the end of the simulation. in the right-hand panel, the opposite was true, and much less intermediate product was converted to final product. the difference in rates can be traced to the amount of pro_a and pro_b formed ). here, the total protein translated is plotted using the fictitious state variable, pro_a*  and pro_b*  that were included in the model code to count every translation event for genea and geneb, respectively. in the left-hand simulation more pro_b than pro_a was formed and vice versa in the right-hand simulation. thus, by inspecting several individual simulations some insight into the possible range of dynamical behavior of the system can be obtained.

as a consequence of the inherent stochastic variability of the behavior of state variables, experimental time-series data obtained from individual biomolecular reaction systems  represent single physical instances of the system under investigation. in general, one would conduct multiple experiments on individual systems and compute the mean and standard deviation of the observed time series . however, if one wished to investigate the behavior of a single experimental time series in relation to the model predictions, the only meaningful comparison is between the experimental data for the selected state variable si and the simulation ensemble mean ± standard deviation for si. this is because the simulation ensemble mean and standard deviation are the best estimates of the mean  and standard deviation  of the state density function p for each selected state variable si . figure  <dig> shows the mean ± the standard deviation of selected state variables using the snapshot data from  <dig> simulations. these plots were created using the 'time-weighted average' tool in the bns toolbox. this tool was set-up to calculate the mean and standard deviation of the number of molecules of the selected state variable for the ensemble of  <dig> simulations at  <dig> sec intervals. these plots are estimates of the temporal behavior of p based on the model. if the model is a reasonable representation of the physical system, two thirds of the time the experimental data for a single vesicle should fall within the envelop of the mean ± the standard deviation. however, significant excursions from the envelop can occur even when the model is a correct representation of the experimental system and thus observing the behavior of a single experimental time series may be misleading. as suggested above, a better comparison between experimental data for single systems and model simulations is between the experimental mean ± standard deviation obtained from multiple  single vesicle observations versus the mean ± the standard deviation of an ensemble of a large number of simulations runs .

as the number of individual experiments on single systems increases, the experimental estimates of the mean and standard deviation of the system state variables improve. however, if experimental data for state variables are only obtained as the mean of a large composite sample of vesicles , then the only meaningful comparison is between this 'macro-sample' mean and the mean of a large number of simulations at corresponding time points. in this case, no data concerning the variability between individual vesicles can be obtained. note, the standard deviation obtained from analyzing multiple macro-samples does not correspond to the fluctuations exhibited in individual model simulations of the system or fluctuations between model simulations, but rather is a measure of experimental uncertainties , which are not taken into consideration by the model simulations. in fact, if there were no experimental uncertainties, then the macro-means of multiple macro-samples taken from ensembles of identical systems would converge to a single value as the number of individual systems collected in the macro-sample increases.

to further investigate the behavior of the system, the event rates of selected reactions were investigated. as the system is treated as a discrete jump markov process, each event occurs instantaneously and the value of associated state variables change discontinuously at the time of the event. consequently, there is no derivative of the state variables that would correspond to the c-d concept of rate of change. hence, for these processes, the 'reaction rate' is defined as the number of events counted during a time-averaging interval  divided by that time interval, giving an estimate of the reaction event rate . these estimates will depend on the tai as illustrated in figure  <dig>  when calculating the reaction event rate in a particular reaction channel, a very small tai relative to the average time between events results in counting individual events, depending on whether an event occurs or not in a particular time averaging interval. subsequently dividing by a small tai results in what appears as an anomalously high reaction event rate and the computed reaction event rate will exhibit large fluctuations between successive sample times depending on whether an event occurred or not. this effect is most obvious in the tai =  <dig> sec panel in figure  <dig>  where the between sample time variability is large fluctuating between  <dig> and  <dig>  note the difference in scales in the tai =  <dig> and  <dig> sec plots compared to the other plots). on the other hand, a large time-averaging interval will reduce the variability thus smoothing the data, but will affect the time resolution and the ability to precisely observe dynamical changes in rates due to the averaging over long intervals. for the results discussed below, a tai of  <dig> sec was selected to maximize time resolution of system dynamics without significant artifacts due to too small a tai.

the total number of reaction events in each reaction channel during the entire simulation run is calculated by the bns software. fin this exemplar model, the total number of reaction events in a given reaction channel ranged from one to several hundred thousand over the  <dig> sec simulation. the specific reaction event rate was computed for selected reactions using a user defined tai of  <dig> sec as discussed above and the results are shown in figure  <dig>  in figures  <dig> through  <dig>  the mean ± one standard deviation for the ensemble of  <dig> simulations are shown. for the selected reactions, the reaction event rates vary during the simulation depending on the availability of substrates . for example, the reaction event rate ranged from  <dig> –  <dig>  reaction events per sec for transcription ),  <dig> –  <dig> reaction events per sec for formation of metabolic products prod_a and prod_b ) and  <dig> –  <dig> reactions events per sec for the association of atp with the amino acyl-transferase for glutamine ). by plotting the event rates for several related reactions on the same graph, it is possible to observe relationships between reactions. for example, figure  <dig> plots the association and dissociation of the rna polymerase  with the promoter for genea  along with the sliding reaction of the bound polymerase to the start site to form the start complex . as long as transcription is proceeding, the association rate  exceeds the dissociation rate  and newly bound polymerase continues to slide to the start site  and transcription of genea_mrna proceeds ). however, when gtp is depleted , transcription cannot proceed and the polymerase stalls at the start site blocking the sliding of new polymerase molecules to the start site . the polymerase sliding reaction ceases and now the association and dissociation reactions are equal resulting in a new quasi-steady state for the rna polymerase ).

a unique feature of stochastic systems is that the timing of specific events varies from one simulation to the next. an example of this effect is seen in table  <dig>  where the time of the last transcription event is displayed for the transcription of genea  and translation of genea_mrna  into pro_a for each of the  <dig> simulation runs. these data were obtained from the parsed event log data files viewed in the matlab workspace. the transcription reaction terminates when the available gtp is depleted and ranges from  <dig> to  <dig> sec with a mean and standard deviation of  <dig> ±  <dig> sec for the transcription of genea. the translation reaction stops when gtp and/or the limiting amino acid charged trna for glutamine  is depleted which occurs over a range of  <dig> to  <dig> sec with a mean and standard deviation of  <dig> ±  <dig> sec for the transcription of genea. thus, the timing of any specific event in a stochastic process will always appear as a distribution rather than a fixed time as would be the case for a c-d process.

for each of the  <dig> simulation runs, the time of the last transcription event for transcription of genea  and translation event for genea  is given. these data were obtained from the parsed event log.

improvement in estimating the mean and standard deviation of s with the number of simulation runs
the mean and standard deviation of the number of molecules for the ensemble of simulation runs at a given time t allow one to estimate the first and second moments of the probability density function, p, for the random variable s as defined by the solution of the cme  – ). as the number of simulations increases, the accuracy of these estimates improve. this can be seen by inspecting the estimated mean ± sd for batch jobs with increasing numbers of simulation runs . figure  <dig> and  <dig> illustrate the behavior of two state variables that can only fluctuate between a limited number of states due to the stoichiometry of the system. figure  <dig> shows the free rna polymerase  where, although the number of total molecules is fairly large , the state variable can only fluctuate between  <dig> and  <dig> molecules corresponding to zero or four polymerase molecules bound to the promoter and start sites of the two genes. the mean and sd for an ensemble of simulation runs fluctuates significantly from one sample time to the next when averaged over a small number of simulation runs – i.e., the mean appears to be noisy when the number of simulations are small , n =  <dig> plot). however, this is merely a consequence of the approximate nature of the statistical estimate of the first and second moments of the solution of the cme using a small number of simulations. in fact, the exact mean, ⟨s⟩, and the sd, ⟨σ⟩, are smooth functions of time as the series of approximations with increasing n in figure  <dig> suggests. only for estimations of the mean with n ≥  <dig> runs does the mean become a relatively smooth function of time. also, the shift in the mean between  <dig> and  <dig> sec becomes well defined with increasing number of simulations. this shift is due to the stalling of two rna polymerase molecules at the start sites of genea and geneb when gtp is depleted resulting in the cessation of mrna synthesis. figure  <dig> shows the behavior of the estimates of the mean and sd of the probability density function for the complex of the rna polymerase and the start site for genea . for this state variable, the only possible states in state space are either  <dig> or  <dig> corresponding to when the start site is unoccupied and when the polymerase is bound at the start site, respectively. thus, the number of molecules of the complex fluctuate over time between  <dig> and  <dig> in any given simulation of the system , n =  <dig> plot). this rapid fluctuation continues until transcription terminates due to the depletion of gtp. the red band in the n =  <dig> plot indicates the mean ± one sd for time when transcription terminated as calculated in table  <dig>  when mrna transcription terminates, a polymerase is locked at the start site and the value of the state variable rnap_genea  becomes a constant. also, these data indicate that at any given time during active transcription, the start site for genea would be occupied by a polymerase in approximately  <dig> percent of the individual systems in an ensemble of a large number of systems.

finally, figure  <dig> shows the time course of the number of proteins translated using the fictitious variables t <dig> and t <dig> to count the number of molecules of pro_a and pro_b synthesized, respectively. for any individual simulation, the translation of genea and geneb can be quite independent within the constraint that the total number of protein molecules synthesized are limited by the availability of energy and substrates ). however, as the number of simulations increases, the ensemble means of pro_a* and pro_b* approach each other demonstrating that the expression of the two genes are controlled in an identical manner. all of these examples emphasize the need to conduct a large number of simulations to obtain accurate estimations of the behavior of the state variables.

the dependency of the accuracy of the estimates of the mean and sd of state variables on the number of simulations is an issue that must be taken into consideration when comparing model predictions with experimental data. if simulations are used to estimate what the model would predict for experimental observations, then the values for state variables predicted by the model will only be exact in the limit of n → ∞ simulations. therefore, if a finite number of simulations are used, there will be some error in the model predictions. there are several situations where this issue becomes particularly important. one example is when one believes that a model is adequate, but there are still minor discrepancies between model predictions and the available experimental data. the usual cause for this situation is that the uncertainty in some model parameters, such as the reaction probability constants, leads to uncertainties in simulations that are greater than the uncertainties in the experimental data. to investigate whether minor adjustments to model parameters will improve the correlation between model predictions and experimental data, various optimization techniques can be employed. to successfully adjust model parameters based on experimental data, it is necessary to compute a large number of simulations to adequately estimate the behavior of the system each time model parameters are variedin the optimization algorithm. if too small a number of simulations are used, the fluctuations in model predictions as the model parameters are varied from one cycle to the next of the optimization process will be so great as to limit the usefulness of the optimization procedure. the larger the number of simulations the better the estimate of the model prediction, thus reducing this additional source of error that is not present when fitting solutions of c-d odes to experimental data.

similar issues arise when investigating reaction event rates. averaging over multiple runs gives a more accurate and consistent estimate of the model predictions of the mean and sd of the reaction event rate as a function to time. it should be noted that the mean and sd for the time-averaged reaction event rate are not directly related to the first and second moments of the state density function p, but are related to the reaction probability constants. the reciprocal of the time-averaged reaction event rate is the mean time between reactions given the current state of the system, which is determined by the propensity. thus, the time-averaged reaction event rate is related to the reaction probability constants through the state dependent propensity. even for reactions that occurs at a significantly greater rate than transcription or translation, e.g., the metabolic formation of products prod_a and prod_b ) with a reaction event rate ranging from  <dig> to  <dig> events per sec, the effect of averaging over multiple simulations is still apparent, particularly for the details of the mean and standard deviation.

when sufficiently large numbers of simulations are performed, it becomes reasonable to generate discrete histograms of the distributions of state variables at defined times. figure  <dig> shows the distribution of several state variables at two time points, one during active transcription and translation  and the other at the end of the simulation . these histograms were generated using  <dig> individual simulation. this is an estimate of the probability that the system would be in that particular state at the defined time t, i.e., the state probability density p. during gene transcription and translation , the free polymerase probability density ) is distributed among the five possible states from no polymerases bound  to four polymerases bound  with two polymerases bound  being the most probable state. at the end of the simulation , the most probable state is with four polymerases bound  and furthermore, the states with zero or one polymerase bound  are not populated . this is due to the fact that when transcription terminates, two polymerases are stalled at the start sites of the two genes. this is seen in figure  <dig>  where before transcription terminates , the start site of gene a is only occupied with a probability of approximately  <dig>  while after transcription terminates it is occupied with a probability of  <dig> . figure  <dig> and  <dig> are the estimates of the state probability density functions for the free gene a mrna  and the total number of protein a molecules synthesized . both of these state variables increase with time while transcription and translation are active. furthermore, the number of possible states available to each state variable increases and is only limited by the total number of molecules of mrna and protein a synthesized. the free genea mrna state variable is influenced by five reactions , its degradation , its association and dissociation with the small ribosomal unit , and its release after translation ), while the fictitious total protein synthesized variable is only a counter for the number of transcription reactions . the variability in pro_a* is a consequence of the stochasticity in the transcription reaction alone, while the variability in genea_mrna is a combination of the variability in the total number of mrna molecules transcribed at a given time and the variability introduced by the other reactions that influence that state variable. discrete histograms of the state variables give a better visualization of the true nature of the state probability density function than just the first and second moments.

comparison between single and multi-processor simulation runs
as is apparent from the discussion above, the ability to accurately estimate the first and second moments of the state density function of the system under investigation using the monte carlo simulation approach increases with increasing numbers of simulations. various analysis techniques, such as optimization  and sensitivity analysis, require repeated batch jobs of large numbers of simulation to obtain statistically valid results. this may not be a problem for a relatively simple biomolecular reaction system, but as the complexity of the system model increases this will increase the computational demand. the need for high performance computing becomes essential.

running a simulation session as a batch job on multi-processor hpc hardware entails a certain amount of overhead, e.g., the time it takes to break up the job into smaller tasks and assign the problem to each processor on the front end and the data collection and storage on the back end. as a result, the speed-up gained by using multi-processor hardware is to a degree dependent on how computationally intensive the problem is. for a relatively simple problem that is not particularly computationally intensive, the majority of the clock time for the simulation session is taken up with overhead. whereas, for a problem that is computationally intensive, the computations involved in the actual simulation are the time consuming component of the simulation process.

to investigate this effect, we ran a batch job with the exemplar model using multi-processor hpc hardware to evaluate the speed-up in clock time with increasing numbers of processors. specifically, we executed  <dig>  simulation runs of the exemplar model as a batch job on an hp xc machine with distributed memory architecture using the gillespie direct stochastic simulation algorithm and various numbers of processors. the speed-up, defined as the clock time for a run with one processor divided by the clock time for the same run on multiple processors, is shown in figure  <dig>  for a simulation of this computational complexity , the speed-up was relatively linear with the number of processors. however, the speedup observed by running the model on  <dig> processors in the batch mode was only  <dig> -fold. this drop-off in performance is due to the computational overhead discussed above, and thus, the performance when using more than  <dig> processors results in diminishing returns

to further explore this effect, we repeated the test with a batch job of significantly less computational complexity. using a one gene model with lumped reactions , the speed-up for a batch job consisting of  <dig>  simulation runs was calculated using up to  <dig> processors. the clock time for a single processor to run the batch job was  <dig>  sec and the speed-up is shown in figure  <dig>  in this case, the computational demand for the actual simulations is relatively small and the overhead becomes a dominant factor. given these conditions, using more than  <dig> processors provides little benefit. the computational complexity of this relatively simple model can be increased by increasing the number of plasmids per reaction network from  <dig> to  <dig> and the number of substrate molecules by a factor of  <dig> . this is equivalent to having  <dig> plasmids containing genea present in the same reaction volume with ten times the number of substrate molecules available. the speed-up results using the 10× model are also given in figure  <dig>  here the value of additional processors is clearly apparent even when  <dig> processors are accessed.

CONCLUSIONS
in this manuscript, we have tried to point out some of the issues that arise in interpreting the results of modeling and simulating discrete stochastic systems. the issues of how the snapshot interval affects the visualization of state variables and how the time-averaging interval affects the estimation of the time-averaged reaction event rates illustrate how simulation and analysis parameters can influence the interpretation of system behavior. probably even more important is how the number of simulations affect the estimation of the mean and sd of state variables. unless sufficient numbers of simulations are conducted, these estimates will not be adequate to:  observe the details of the temporal dynamics of state variables,  accurately estimate the variability between simulations, or  when optimization procedures are being employed, to expect consistent convergence of solutions.

an important point to remember is that the stochastic nature of individual state variables is to some extent model dependent, i.e., will depend on:  the relationships between state variables,  the mathematical forms of the reaction propensities,  the values for reaction probability constants, and  initial conditions for state variables. for example, if the diameter of the vesicle was increased  <dig> times , then the initial numbers of molecules of each state variable would be increased  <dig> times . in this case, the effect of stochastic processes on some state variables, such as the transfer rnas, would be significantly diminished while the effect on others, i.e., transcription, would remain.

in addition, we investigated the generic behavior of a biomolecular reaction network consisting of the expression of two genes in a cell-free transcription-translation system enclosed in a artificial reaction vessel. such a closed system does not reach a steady state and generates a different class of kinetics than is found in systems where it is assumed there is an infinite supply of substrates and energy and all waste products are 'taken care of' by the system. the closed system investigated here simply 'dies out' when critical components are exhausted. the ability to simulate such a system allows one to identify the critical factors that limit the performance of the system. although the model for the system is still relatively crude, it is clear that the availability of limiting amino acids controls the ultimate expression of proteins, the availability of gtp limits transcription of the plasmid genes to form mrna and the availability of substrates  for the catalytic ligation reactions limits the generation of the final products. this quantitative knowledge can be used, for example, to optimize the system to maximize production of products, either proteins or metabolites. as the models for the cftt-vesicle system become more sophisticated, a more detailed understanding of the behavior of these biological constructs will evolve.

availability and requirements
the bns software is available to all researchers through the website below.

project name: biomolecular network simulator

project home page: 

project downloads: 

license: gnu gpl

operating systems: platform independent

programming language: c, matlab

other requirements: matlab  <dig>  or newer; matlabmpi and mpi libraries for multiprocessor execution.

authors' contributions
jmf developed the two gene model, ran simulations, prepared graphics and drafted the manuscript. bf developed the original bns code, developed and evaluated the mathematical analysis tools and helped draft the manuscript. yc modified the original bns code to increase efficiency, ported the software to run on multiprocessor hardware and reviewed the manuscript. all authors approved the final manuscript.

supplementary material
additional file 1
model description. the information provided describes the conceptual structure of the exemplar model and the mathematical description of the model reactions.

click here for file

 additional file 2
sbml model definition. this file contains the sbml model definition code for the exemplar model.

click here for file

 acknowledgements
the work of yaroslav chushak was made possible by a grant from the department of defense high performance computing modernization program office . the work of brent foy was made possible by a grant from the air force office of scientific research  and by the air force summer faculty fellowship program. disclaimer: the opinions and assertions contained herein are the private views of the authors and are not to be construed as official or as reflecting the views of the u.s. army, u.s. air force, or the u.s. department of defense. this paper has been approved for public release with unlimited distribution .
