BACKGROUND
insertional mutations have been playing an important role in biological studies ever since the early development of genetic engineering in the late 1960s . it was first used by bacterial genetics  <cit> . later on, its usage was expanded to other organisms by modification of the bacterial system or the discovery of other appropriate natural insertional agents. it has already been successfully applied to the study of gene functions of a number of model organisms such as yeast  <cit> , fly  <cit> , worm  <cit> , plant  <cit> , fish  <cit> , and mouse  <cit> , and also organisms of economic and/or medical importance such as rice  <cit> , silkworm  <cit> , and mosquito  <cit> . insertional mutagenesis has proven itself to be one of the most efficient means for large-scale functional characterization of a number of genomes, including yeast  <cit> , fly  <cit> , fish  <cit> , plant  <cit> , and mammal  <cit> . when an appropriate insertion vector is used, a large number of mutations can be produced at low cost and with a high speed, and expression patterns of the inserted endogenous genes are readily revealed. for example, new insertional mutations could be produced from mice carrying transposable elements and are capable of transposition in the germ cells. progeny harboring individual transposition events can be subsequently mapped and maintained in the absence of the transposase.

more and more large-scale insertional mutagenesis projects are underway to decode genomes of interest. these projects are producing large quantities of experimental data. simple spreadsheets on personal computers would not meet the demand generated by the current volume of experimental data. large-scale experimental projects are not handled by isolated individuals/groups, but are instead managed with the same flow production commonly used by car manufacturers. in this method, the whole process is divided into multiple interconnected steps with each step under the charge of a specific research group. this kind of management generates two urgent needs: 1) recording data and exchanging information on a daily basis among the collaborating groups, and 2) extracting statistical information in a timely manner for researchers to grasp the current progress of the project. in other words, an efficient way to record and process data is required. a well-designed and implemented management database is the right choice to meet these needs.

recently, two databases have been published to facilitate lab management in large-scale mutagenesis projects: the enu-mutagenesis system for mice  <cit>  and the paclims system used for a rice fungus genome insertional mutagenesis project  <cit> . both have been used in their own projects respectively. however, the enu mutagenesis system does not involve an insertional mutation mapping procedure needed in our project, while the paclims system is only applicable for handling large-scale insertional mutagenesis project carried out in 24- or 96-well plates for cell culture system and microorganisms. in addition, neither satisfies the need of a large-scale project carried out with the flow-control production system.

currently, a genome-wide piggybac  mutagenesis mapping project managed with the flow control system is underway in the institute of developmental biology and molecular medicine  at fudan university in shanghai, china. pb transposon, originally found in the cabbage looper moth trichoplusia ni, is a dna transposon shown to be an important genetic manipulation tool in multiple organisms including mice  <cit> . we have established the pbmice system  for archiving, retrieving, and analyzing the resulting data from this project  <cit> , but the published version did not handle either the raw data or experimental flow. this paper presents the mp-pbmice system , which is developed to meet the demands mentioned above for the efficient management of large-scale projects performed in the flow control fashion: efficient data recording, processing, and exchange. the mp-pbmice system can also be easily adapted to other insertional mutation mapping projects using the flow production mode with large-scale experimental data.

methods
data source
experimental procedure
inverse pcr   <cit>  was chosen in the large-scale pb insertional mutagenesis project. the mapping process of this project runs in the efficient flow-production mode . the whole process is divided into five steps with each step overseen by a designated research group.

mouse tissue and ipcr data
the first step is sampling. in the pb project, mice tissues served as the samples from which the mice genomic dna was generated. mice are taken care of by the animal facility group. this group collects the tips of the tails of mice potentially carrying new pb insertions  in the genome. then the ipcr group performs ipcr experiments using these tail tips to obtain amplified fragments carrying the mouse genomic fragment flanking the pb insertion site. these amplified fragments are sequenced subsequently. in this step, the following data are gathered: sample information, experiment status information , dna electrophoresis gel photos, and the information of the dna fragment to be sequenced.

dna sequence data
the sequencing of the pb flanking genomic dna is performed by the sequencing group. for each dna fragment sequenced, three files are generated to describe the contents and quality of the sequence. these results are passed onto the bioinformatics group to determine the location of the inserts on the chromosomes.

insertional mutation localization data
the insert-flanking genomic sequences are obtained from the reliable sequences and submitted to ensembl and/or ucsc genome browser and/or ncbi for mapping those insertions onto the mouse genome. one example is shown in figure  <dig>  the locations of the inserts on the genome and the genomic features of those locations are obtained. for each insert, a  <dig> kb sequence with the insertion site in the middle is sent to the genotyping  group for experimental gt verification.

verification data
the gt group designs gt primers using the above  <dig> kb sequence as template with the macvector software . suitable primers predicted by the software are submitted to ucsc genome browser to determine its uniqueness in the whole mouse genome. to ensure that there is no accidental sample switch, the animal facility group will collect a piece of the ear for gt verification. the ear tissue comes from the same mouse whose tail tissue was sent for ipcr in the beginning. if the gt verification of one insertion generates a positive result, the mapping process comes to an end for this specific insert. if the experiment fails, new primers will be designed for a new round of gt verification. primer information, experiment status information , and dna electrophoresis gel photos are the three types of data gathered in this step.

design and implementation of the mp-pbmice system
the previously published pbmice collect and disseminate the large quantities of the genetic and phenotypic information from this on-going large-scale pb insertional mutagenesis project  <cit> . it provides a user interface to query and display data related of the published pb insertions in the mouse genome and their characterizations. however, in this published version, neither the raw data nor the experimental flow is touched. in the process of the production of large numbers of insertional mutants and the characterization of their phenotype, large amounts of raw data are produced and recorded daily. there is an urgent need of a mapping system to serve the mutant mapping procedure to ensure detailed and correct data recording and information exchange on a daily basis. we designed and developed the current mp-pbmice system to meet these needs.

database tables
experimental data gathered from every step of the project, including future updates, need to be stored in the database. we employ the relational data schema to model these data. four kinds of tables  are designed in the mp-pbmice to ensure correct daily data recording and exchange.

 <dig>  access-control tables. the function of accessing control in our system is realized through access-control tables including a user table, a role table, a group table, a permission table, and a user-role relation table. the user, role, and group table are used to store the information of every registered user, every defined role, and every designated group respectively. in the permission table we keep the permission status of each data table, such as which table can be read and which table can be updated by a specific role of a specific group. each user can be allocated multiple roles to carry out corresponding tasks. the user-role relation table archives this relationship between each user and the role allocated to the user.

 <dig>  experimental stage tables. data created from one step of the whole procedure are often stored in a single table. data from an earlier stage can be easily accessed in a later stage through foreign keys. for example, if several versions of experimental data of one specific insertion in the same stage are created, foreign keys are able to distinguish the newest version from the old version.

 <dig>  constant tables. certain categories of data are not unique to either each mouse or each insert generated. for example, the coat color of a mouse falls into a few types: black, white, and others. the experimenters only need to fill in the data via a simple pull-down menu to make the right choice. constant tables are applied to store these values instead of fixing these options into codes. this designing strategy allows for easy potential updates by updating the data in corresponding constant tables rather than the need to rebuild the whole system.

 <dig>  status table. in the whole experimental flow, mice and inserts are the key threads. all steps of the experiments are carried out around them and the current status of an insert is critical to the workflow. the status table is designed to record the current experimental stage and the status of each insert in this stage. this strategy smoothens the experimental flow and creates a more efficient query of the stages and statuses.

the model-view-controller pattern
the three-layer architectural pattern model-view-controller  http://heim.ifi.uio.no/~trygver/1979/mvc-2/1979-12-mvc.pdf is the choice for the system design in mp-pbmice. the mvc pattern is widely used in software engineering and often used by applications that deal with multiple views of the same data. the basic idea of this mainstream design pattern is to isolate the business logic from user interface considerations. this results in an application that modifies the visual appearance or the underlying business rules in such a way that they will not affect each other .

in mvc, the model layer stores the data or information on which the application operates, provides application-specific methods to manage the data, and operates all of the business process of an application. it receives and responds to the requests from the controller layer and the view layer.

the view layer is a visual representation of the information contained in the model layer through listening for and reflecting the state updates in the model layer. a view may change when the information in the model layer changes, so there can be more than one view for a model.

the controller layer helps the communication between the model layer and the view layer by listening to the user inputs and translating these inputs into the data changes in the model layer. it also instructs the view layer to make changes in the user interface when the model layer updates.

the struts-spring-hibernate framework
we designed and developed the mp-pbmice system with the lightweight enterprise-level development framework struts-spring-hibernate to implement the mvc pattern  <cit> . this development framework is widely used in commerce and would meet the demands from the large volume of experimental data.

in our implementation, the model layer is also called the data access object  layer, which is formed by the database models generated by middlegen http://boss.bekk.no/boss/middlegen/. these database models are composed of java objects describing the models, operations, and model relationships of the database. dao performs queries on the database models to obtain the information using hibernate query language supported by hibernate   <cit> . this framework controls mapping of every schema  in the database of mp-pbmice to the underlying relational database mysql . every operation on an object will be automatically persisted into the database. as a transparent back-end layer, it is easy to execute data queries and feature extractions.

the controller layer is implemented with spring framework   <cit> , a highly customizable and extensible framework that provides basic infrastructures. this framework is also used by dao to offer the connection pooling and transaction management so that the database connections can be reused by future users. in addition, this framework integrates the service layer containing several services to supply the main functions of the web application developed using eclipse  <dig> . <dig> http://www.eclipse.org, a freely available integrated development environment . the view layer of the application is constructed primarily using a combination of java server pages   and the struts framework   <cit> . tiles  <cit>  is also used in the view layer to create reusable view components. client-side functionality is programmed with javascript.

based on the above architecture, the application was implemented to retrieve, store and operate mice, inserts, data-input, and user-management related information as a set of database models defined by java objects.

RESULTS
the mp-pbmice has been developed and is already used for the mapping of the new insertional mutants produced in the large-scale pb project.

user interfaces
this mp-pbmice system allows users to log in their different roles to carry out corresponding tasks. here we give one example about how this system works. the complete user menu is available with the source code.

the main entry page is the login page . a pull-down menu provides the choice of the roles for the specific user. after the experimenter logs into the system, he/she can fill in his/her own experimental data on the form-filling page . once the experimenter has submitted the data, the group_leader will allocate a different user as the checker for this experimenter to confirm the data . idm internal users are able to perform quick searches to obtain the detailed information of the experimental data related to his/her work easily . the search result will be listed and the detailed information will be retrieved through the "viewdetail" linkage . in the detailed information page , there is a comment box for remarks and opinions and an email message will be sent to the corresponding pi to report any mistake for correction.

main features
strict access control
the mp-pbmice is destined to be a web-based application to meet the needs of concurrent operation of the database by multiple users. an entire strict access control system is introduced into this system to ensure data accuracy. this access control system is divided into three units: 1) user registration, 2) user information management, and 3) user permission management. each user has only one entry in the user information unit, while each user can be allocated multiple roles in the user permission unit after registration . different roles in different groups are allocated different permission to perform designated tasks. in each group, the experimenters perform the allocated experiments, fill in their own data, and submit the data to the database. for each step of the experiment, the checkers validate the data and are allowed to make modifications only once. if anybody finds an error, she or he may report the mistake through the mistake tracking system. only the person with the pi role is able to allocate the wrong experiment record to a specific experimenter to correct the data and/or repeat the experiment. the director role decides to publish the experimental records to the world. all the internet-published data can be accessed without registration. each operation and the time the operation was performed are recorded into the database. every error record is also kept in the database as an old version, rather than being replaced. all of these records can be queried by specific roles to show the rate at which error occurred. the strict division of the work and step-by-step checking may reduce the number of mistakes in experimental data submitted, ensure timely data exchange, and improve the efficiency of the whole process.

this control will be developed further to meet more complicated requirements of each role and will generate new roles needed throughout the progress of the project.

workflow control
mp-pbmice is developed to have a strict control of the experimental procedure. in practice, each step of the experiment carried out would result in various situations, and the mapping process won't be smooth for every new insert from the start to the end. figuring out the complicated branches of the process is the most important part in making the whole project methodically organized. the detailed experimental process and situations that may happen along the way are recorded, discussed, and checked by directors and pis of the project. the purpose of this discrete consideration is to work out an approach that avoids the loss of important data or resources as a result of inattentive operation, as well as minimizing the cost of resources and time. a workflow is designed to deal with all kinds of situations that would happen in the experimental process . in each step, an insert with a specific status defined by the previous experimental result is automatically passed to the corresponding experimental pathway, which notifies the downstream user of his/her coming workloads. automatic workflow control streamlines the experiments and benefits the process of large quantities of batch analysis. this workflow control also allows a timely report generated by the system for users to visualize the progress of each sample once it is in the procedure. this offers project leaders to analyze the quality and quantity of the experiments so as to improve the protocol in time. with the development of experimental research process, we will improve the system to better support researchers to finish tasks intelligently and efficiently. for example, the system will be able to give suggestions or assessments in certain key functions to researchers through a data analysis system.

expandability
the mp-pbmice system is developed to record all kinds of experimental data generated in a large-scale project of mapping insertional mutations onto the mouse genome. initially used for mapping onto the mouse genome, it can easily be used for mapping onto any genome, because the only difference will be in the steps of sampling and blasting. for any other genome, the sample will be the corresponding tissue of the organism of interest, and the genome to be blasted is the genome of interest. either step would generate the same data types as the experimental procedure discussed in this paper. only the title of sample, location of the insert  of the table columns in the database need to be changed for other projects. if the thermal asymmetric interlaced pcr   <cit>  or the ligation-mediated pcr  <cit>  is used for mapping the mutants instead of ipcr, only the titles of the table used to record ipcr results need to be changed to the one in use. in both cases mentioned above, the changes are minimal. the mp-pbmice system is easily modified to archive the information generated from other labs for mapping insertional mutations onto a particular genome of interest.

CONCLUSIONS
the large-scale pb insertional mutagenesis project asks for efficient management of the experimental process and data accumulated. the flow production control is more efficient than the mere collaboration among isolated groups, with each group covering the whole process of new mutant production. a database targeting the lab management specifically for large-scale insertional mutagenesis project with flow production control is the key to meeting the demand. in collaboration among three research groups from fudan university, we constructed the mp-pbmice system to allow researchers to submit data and pass on tasks daily and electronically. the mp-pbmice system was designed and developed with the widely used mpv pattern and lightweight enterprise-level development framework struts-spring-hibernate to ensure the applicability. this system incorporates a strict access-control system and a tight workflow control to ensure the data accuracy and timely information exchange, which are key to the efficiency and success of the project. this system has been in use for five months, and is easily expandable for other large-scale insertional mutation mapping projects.

availability and requirements
the software mp-pbmice is freely available at http://www.idmshanghai.cn/pbmice. for other information, please contact the corresponding author.

competing interests
the authors declare that they have no competing interests.

authors' contributions
wy, jk, and xx designed the architecture of the system. xx, dl, jy and lw designed and implemented the database and all functionalities of the whole system. wy organized the implementation and edited the user guide. yz, ng, and ls directed the project. yz conceived the structure of this paper. ls wrote the paper in collaboration with all of the other authors. all authors read and approved the final manuscript.

note
other papers from the meeting have been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2009: eighth international conference on bioinformatics : bioinformatics, available online at http://www.biomedcentral.com/1471-2105/10?issue=s <dig> 

