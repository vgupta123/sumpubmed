BACKGROUND
clustering is a statistical technique that partitions a large number of objects into a few clusters such that objects within the same cluster are more similar to each other than to the objects in other clusters. clustering is widely used in gene expression data analysis to cluster genes and/or samples  based on their similarity in expression patterns. since gene clusters are often enriched with genes involving in common biological processes, identifying such clusters discloses potential roles of previously un-characterized genes and provides insights into gene regulation. similarly, clustering of samples reveals different stages or subtypes of diseases such as cancer leading to development of customized diagnostic procedures and therapies.

despite the widespread use of clustering algorithms in gene expression data analysis  <cit> , selection of clustering parameters continues to be a challenge. in many cases, the optimal specification of number of clusters, k, is difficult especially if there is inadequate biological understanding of the system  <cit> . a suboptimal specification of number of clusters can generally result in misleading results – either all classes may not be identified or spurious classes may be generated  <cit> . while the correct number of clusters can be identified by visual inspection in some cases, in most gene expression datasets, the data dimensions are too high for effective visualization. hence, methods that find the optimal number of clusters are essential.

several methods have been proposed for finding the number of clusters in data. the popular methods evaluate the partition using a metric and optimize it as a function of number of clusters. comprehensive reviews of these methods are available elsewhere  <cit> . here we briefly describe some recent methods recommended for gene expression data analysis. tibshirani et al.  <cit>  proposed the gap statistic that measures the difference between within-cluster dispersion and its expected value under the null hypothesis. the k that maximizes the difference is selected. since the gap statistic uses within-cluster sum of squares around the cluster means to evaluate the within-cluster dispersion, this method is suitable for compact, well separated clusters. dudoit and fridlyand  <cit>  proposed a prediction based re-sampling method for finding the number of clusters. for each value of k, the original data is randomly divided into training and testing sets. the training data is used to build a predictor for predicting the class labels of the test set. the predicted class labels are compared to that obtained by clustering of test data using a similarity metric. this value is compared to that expected under an appropriate null distribution. the k for which the evidence of significance is the largest is selected. ben-hur et al.  <cit>  proposed a similar re-sampling approach where two random subsets  are selected from the data. the two random subsets are subsequently clustered independently and the similarity between the resulting partitions is measured. the similarity is measured for multiple runs and its distribution is visualized for each k. the optimal number of clusters is selected where transition from high to low similarity occurs in the distribution. the approach of dudoit and fridlyand as well as ben-hur et al. assume that the sample subset can represent the inherent structure in the original data which may not be true for small clusters. furthermore, the user has to manually locate the transition in ben-hur et al. approach.

recently, bolshakova and azuaje  <cit>  employed silhouette  <cit> , generalized dunn's index  <cit> , and davies-bouldin index  <cit>  on gene expression data. these methods use the intra- and inter-clusters distances to identify the best partition. in general, cluster validation is easier when the underlying clusters are well separated. but, most cluster validation methods lead to suboptimal results when inter- and intra-cluster distances vary largely. to illustrate this, consider the artificial dataset in figure  <dig> consisting of  <dig> objects in three clusters . clusters b and c are closer to each other and far from cluster a. figure  <dig> shows the results of silhouette, normalized dunn's and normalized davies-bouldin indices for this dataset. for ease of visualization, all indices have been min-max re-scaled to  <cit> . for a given index value ik, the re-scaled index value is obtained as

  i^k=ik−minmax−min 

silhouette, generalized dunn's index, and davies-bouldin indices incorrectly identified only  <dig> clusters in this dataset. a partition with two clusters {a} and {b ∪ c} is more favorable according to intra- and inter-cluster distance based methods. gene expression data contain clusters of different sizes, shapes, and there exist smaller clusters within the larger well-separated cluster  <cit> . hence, the methods for finding number of clusters based on intra- and inter-cluster distances do not perform well for gene expression data . this finding motivates development of new methods that do not rely on intra- and inter-cluster distances.

in this paper, we propose a new method to find optimal number of clusters in the data. our approach is based on an evolutionary view of the clustering process . we start by considering the whole dataset as a single cluster and notate it as generation  <dig> . in each subsequent generation, the number of clusters, k, is incremented by one and the data re-clustered. a generation with k clusters is notated as gk. the net change in the information content due to the addition of a cluster is measured using net information transfer index . nifti includes two components – direction of information change and magnitude of information change – in its calculation. the direction of change indicates whether information is gained or lost during evolution. the magnitude indicates the extent of change. during evolution, objects from ith cluster, cki, in the current generation, gk, will be distributed across several clusters in the next generation, gk+ <dig>  the clusters in gk+ <dig> that receive objects from cki are called as offspring of parent cluster cki. nifti considers this rearrangement of cluster members when a new cluster is added for calculating the information change. the net information change is the sum of the information change for all parent clusters. information increases if offspring clusters are separable. we use a simple but effective procedure with statistical basis to check the separability of offspring clusters. the magnitude of information change is calculated using information theory. this evolutionary procedure is carried out for a predefined number of generations . the total information content, tic, of a partition is defined as the cumulative information gained till that generation. a partition with the highest tic is selected as the best partition. while testing for separability of clusters, nifti does not give weightage for largely separated clusters or penalize marginally separated clusters, thus eliminates the problems associates with varying inter-cluster distances.

RESULTS
four publicly available microarray datasets are used to illustrate the performance of the proposed approach. the first two datasets are time-course datasets. in time-course datasets, genes are clustered based on their similarity in expression patterns. the other two datasets contain data from different samples.

two different clustering techniques, namely k-means and model-based, are used for generating partition with different number of clusters. the distance metrics used for clustering are the same as those used by the data publishers i.e pearson coefficient for first, third, and fourth case studies and standard correlation coefficient for the second dataset. in all the case studies, the maximum number of generations, gmax is selected as  <cit> :

  gmax≤n 

where n is the number of objects to be clustered.

case study  <dig> : yeast cell-cycle data
the yeast cell-cycle dataset was generated by cho et al.  <cit> . oligonucleotide microarrays were used to monitor the expression levels of all known and predicted yeast genes during two cell-cycles. expression levels were measured at  <dig> time points with a time period of  <dig> min. the aim of this experiment was to identify the cell-cycle controlled genes in yeast. cho et al. visually observed the highly variant genes for consistent periodicity during the cell-cycle and identified  <dig> genes. these  <dig> genes were classified into five classes – early g <dig>  late g <dig>  s, g <dig>  and m phases – based on their peak expression. since the number of clusters is known for this dataset, the  <dig> cell-cycle genes are used to validate the proposed method.

the proposed method, nifti, correctly identifies five clusters in this dataset using k-means method . for comparison, the results for silhouette, dunn's, and davies-bouldin indices are shown in figure  <dig>  all three indices predict  <dig> clusters in this data. the reason is as follows. at k =  <dig>  genes from s and g <dig> phases are combined into one cluster while those from early g <dig>  late g <dig>  and m phases are clustered correctly. these four clusters are well-separated. when the number of clusters is increased to  <dig>  while s and g <dig> clusters are identified correctly, the inter-cluster distance is small. the three methods therefore identify the partition with four clusters as optimal. in contrast to these distance based methods, the proposed method gives no weightage for larger inter-cluster distances and correctly identifies  <dig> clusters.

the five clusters identified by k-means clustering correspond to the five phases of cell-cycle – early g <dig>  late g <dig>  s, g <dig>  and m phases. for example, cluster  <dig> contains the cell-cycle regulated genes including pcl <dig>  sic <dig> and dna replication genes cdc <dig> and cdc <dig> that are classified into early g <dig> by cho et al.  <cit> . the mean expression profile of this cluster shows single peak during the early stage of g <dig> . similarly, other clusters are also enriched with genes that are classified into one of the reported clusters and their mean expression profiles peak during the corresponding stages .

however, some of the genes especially s phase genes are found to be 'mis-classified' by k-means clustering algorithm. to understand the discrepancy, we used principal component analysis and plotted the scores with the first two dominant principal components . from figure  <dig>  it is clear that some of the genes from reported classes, especially s phase genes, are distributed to other classes. the k-means algorithm put those genes in appropriate classes which explains the mismatch between the reported and k-means partitions .

results for this dataset using model-based clustering are shown in figure  <dig>  nifti correctly identifies  <dig> clusters using model-based clustering as well. since the 'true'  partition is available for this dataset, we compare the clustering results using k-means and model-based clustering with reported partition using jaccard coefficient  which measures the similarity between two partitions. let c be the partition from the clustering algorithm and p be the reported solution. the jc measures the extent to which c matches with p

  jc=n11n11+n10+n <dig> 

where n <dig> is the number of pairs of objects that are in the same cluster in both c and p, n <dig> is the number of pairs of objects that are in the same cluster in c but not in p, and n <dig> is the number of pairs of objects that are in the same cluster in p but not in c. jc takes a value between  <dig>  and  <dig> . the better the agreement between identified and the 'true' solution, the higher the value of jc. figure  <dig> shows the jc for yeast cell-cycle five phase criterion data as a function of number of clusters using k-means and model-based algorithm. the jc takes a maximum value of  <dig>  at k =  <dig> indicating that in the given range of k the extracted partition best matches with the reported one. this clearly shows that the  <dig> clusters identified using proposed method are correct.

case study  <dig> : serum data
the serum gene expression dataset is reported by iyer et al.  <cit> . in this study, the response of human fibroblasts to serum was measured using microarrays containing around  <dig> probes. iyer et al. employed filtering techniques and shortlisted  <dig> most variant genes. they used hierarchical clustering and identified  <dig> clusters in this dataset using visualization tools. we use these  <dig> genes in this case study.

nifti identifies  <dig> clusters in this dataset using k-means clustering . this result is supported by an other independent study using a graph-theoretical clustering algorithm  <cit> . the silhouette, dunn's and davies-bouldin indices identify only  <dig> clusters in the dataset . this dataset is more complex than the previous one. it contains two large clusters – one with up-regulated genes and another with down-regulated genes. all the other clusters are embedded in these large clusters. the ratio of difference between the intra- and inter-clusters distances is highest at k =  <dig>  so any distance based method will generally identify only two clusters in this dataset. multiple peaks were observed for nifti index for this dataset with the highest peak at k =  <dig> when model-based clustering is used for generation partitions . however, the jaccard coefficient between the partitions from model-based clustering and the reported partition has the highest value at k =  <dig>  indicating  <dig> clusters in this dataset.

in the next two case studies, the datasets contain gene expression data from different cancer samples. in these datasets, samples are clustered based on their similarity in expression patterns. model-based clustering is not suitable for these datasets as it uses covariance matrix in its computation. the estimation of covariance matrix is inaccurate for sample clustering as the number of samples in each cluster are very small. so results are given for only k-means clustering.

case study  <dig> : lymphoma data
the lymphoma dataset was reported by alizadeh et al.  <cit> . in this experiment, cdna microarrays were used to characterize gene expression patterns in adult lymphoid malignancies. after filtering, the final data contain  <dig> genes whose expression levels were measured using  <dig> arrays. the dataset comprises samples from three prevalent adult lymphoid malignancies – diffuse large b-cell lymphoma , follicular lymphoma , and chronic lymphocytic lymphoma . for comparison, the normal lymphocyte subpopulation under a variety of conditions is also included. the objective of the study was to identify if the presence of malignancy and its type can be identified from gene expression patterns. alizadeh et al. used hierarchical clustering for clustering the samples and identified two distinct subtypes of dlbcl-germinal center b-like dlbcl and activated b-like dlbcl.

nifti finds  <dig> clusters in this dataset using k-means clustering algorithm with pearson correlation as the distance measure . not surprisingly, these four clusters correspond to the four distinct branches of the dendrogram reported in  <cit> . two of these clusters contain the samples from two subtypes of dlbcl namely germinal center b-like dlbcl and activated b-like dlbcl. the third cluster contains all fl and cll samples along with the resting blood samples. most of the cell-cycle control genes, checkpoint genes and dna synthesis genes that are defined as 'proliferation signature' by  <cit>  are under expressed in these samples. this makes these samples distinct from dlbcl samples in which the proliferation signature genes are up-regulated. the fourth cluster comprises the remaining normal lymphocyte subpopulation under different activation conditions. however, the transformed cell line samples which are grouped with other normal sub-populations by  <cit>  are clustered with dlbcl samples by k-means. the over-expression of proliferation signature genes in these samples might be the reason that they appear 'closer' to dlbcl samples to k-means. nevertheless, k-means clustering correctly clustered two out of the three dlbcl samples that were incorrectly clustered by the hierarchical clustering.

the silhouette, dunn's and davies-bouldin indices for this dataset are also shown in figure  <dig>  the silhouette index estimates only  <dig> clusters and dunn's index predicts  <dig>  the lowest value of davies-bouldin index occurred at k =  <dig> in the range of k values tested . however, davies-bouldin index has a local minima at k =  <dig> indicating four clusters in this dataset. at k =  <dig>  all dlbcl samples are grouped into one cluster and all other samples  are lumped into other. at k =  <dig>  the latter is split and normal samples are identified as the third cluster. this indicates that at k =  <dig> and k =  <dig> subclasses of dlbcl cannot be identified. only at k =  <dig>  the two subclasses of dlbcl are identified. this clearly shows the usefulness of proposed method to identify correct number of clusters that aids discovering novel sub-types of diseases.

case study  <dig> : pancreas data
the pancreas dataset used in this study was reported by  <cit> . in this study, cdna microarrays were used to analyze gene expression patterns in  <dig> pancreatic cell lines,  <dig> resected infiltrating pancreatic cancer tissues , and  <dig> normal pancreases. the final filtered dataset consists of  <dig> genes and  <dig> samples.

as shown in figure  <dig>  silhouette, dunn's, and davies-bouldin indices estimate  <dig> clusters for this dataset. a partition with two clusters lumps together the normal and pancreatic cancer tissues into a single cluster. the second cluster contains all the pancreatic cancer cell lines. nifti estimates four clusters in this data. a partition with four clusters describes this data well: all cancer cell line samples are accurately placed in one cluster, all normal samples are grouped together, and two different cancer tissues are well separated into two clusters. only one sample was found to be mis-clustered. this partition with four clusters also exactly matches the dendrogram reported in  <cit> .

discussion and 
CONCLUSIONS
the use of clustering techniques in gene expression data analysis is increasing rapidly. to obtain the best results from these clustering techniques, optimal specification of the number of clusters is essential. hence, methods that automatically identify the number of clusters in high-dimensional gene expression data have been proposed. methods for finding the number of clusters in a dataset can be classified as global or local methods  <cit> . global methods evaluate clustering results by calculating some measure over the entire dataset whereas local methods consider pairs of clusters and test whether they should be amalgamated. the disadvantage of the global methods is that there is no definition for the measure for k =  <dig>  i.e., the global methods do not provide any clue whether the data should be clustered or not. since local methods consider pairs of clusters, they can be used to decide if data should be clustered. the disadvantage of local methods is that they need a threshold value or significance level to decide whether the clusters should be amalgamated. the proposed approach combines both local and global approaches. at the local level, offspring clusters are checked for overlap and this information is converted into a global index.

the well-known methods for finding the number of clusters use within-cluster dispersion and/or inter-cluster distances. these 'distance' based methods are generally suitable when clusters are compact and well-separated but fail when sub-clusters exist. our approach overcomes this limitation by giving no extra weightage for larger inter-cluster distances. in our approach, clusters lose or gain information based on intersection with other clusters. the actual distance between the clusters is not taken into consideration. furthermore, the cumulative way of measuring information content of a partition ensures that information increase as long as a non-intersecting cluster can be identified.

we have compared the performance nifti with four other methods – silhouette, dunn's, davies-bouldin, and gap statistic – in terms of percentage of correct prediction of actual number of clusters in artificial datasets. the synthetic datasets are generated with number of dimensions d =  <dig>   <dig> and  <dig> and number of clusters k =  <dig>   <dig>  and  <dig>  for each combination of d and k,  <dig> artificial datasets are generated and k-means clustering is used for generation of partitions. the results are given in additional file  <dig>  for a given d, the performance of silhouette, dunns and davies-bouldin indices decreased significantly with increasing k. for example, for 2-dimensional datasets, the percentage success of these methods dropped from 70% to 20% as k increased from  <dig> to  <dig>  this is mainly due to decrease in inter-cluster distance with increase in number of clusters. similar trend of decreasing performance is observed with gap statistic as well. also, its performance is very poor  with large number of clusters. in all the case studies, nifti performed better compared to the other methods. the performance of nifti is largely independent of the number of clusters and number of dimensions. this study clearly indicates the efficacy of nifti in predicting the number of clusters in data.

however, the proposed method has a limitation. it models clusters as hyper-spheres. even though modeling clusters as hyper-spheres simplifies the task of finding cluster intersections, it may lead to incorrect results in case the clusters do not have a spherical shape. nevertheless, this procedure consistently identified the 'correct' number of clusters suggesting, in part, the spherical shape of gene clusters. an independent study also reported that normalization techniques used in gene expression data analysis make the clusters spherical  <cit> .

in this paper, the proposed method is evaluated using k-means clustering algorithm with pearson correlation as distance measure for the yeast cell-cycle and lymphoma datasets. the standard correlation coefficient  is used for the serum dataset. these two measures are bounded: the minimum and maximum distances are  <dig> and  <dig> respectively. on the other hand metrics such as euclidian distance and manhattan distance are unbounded. hence, the affect of outliers will be high while estimating the cluster radii. this may lead to incorrect estimation of number of clusters. this can be overcome by suitable normalizing the data or selecting other ways to find cluster radius that are less sensitive to outliers. further study using various distance metrics and clustering techniques is needed to further evaluate the method.

generally computational time is an important issue in determining the number of clusters. in this study, we used  <dig> replicates of k-means algorithm for all datasets. the time required for finding number of clusters is less than  <dig> minutes for all datasets on a pentium  <dig> with  <dig>  ghz processor.

