BACKGROUND
recent advances in high-throughput sequencing technologies have enabled the scientific community to sequence a large number of genomes. currently there are  <dig>  complete genomes  <cit>  annotated in the kegg genome repository and many more are in progress. however, experimental functional characterization of these genes cannot match the data production rate. adding to this, more than 50% of functional annotations are enigmatic  <cit> . even the well studied genomes, such as e. coli and c. elegans, have  <dig> % and  <dig> % ambiguous annotations  respectively  <cit> . to fill the gap between the number of sequences and their  annotations, we need fast, yet accurate automated functional annotation methods. such computational annotation methods are also critical in analyzing, interpreting and characterizing large complex data sets from high-throughput experimental methods, such as protein-protein interactions   <cit>  and gene expression data by clustering similar genes and proteins.

the definition of biological function itself is enigmatic in biology and highly context dependent  <cit> . this is part of the reason why more than 50% of functional annotations are ambiguous. the functional scope of a protein in an organism differs depending on the aspects under consideration. proteins can be annotated based on their mode of action, i.e. enzyme commission  number  <cit>   or their association with a disease . the lack of functional coherence increases the complexity of automated functional annotation. another major barrier is the use of different vocabulary by different annotations. a function can be described differently in different organisms  <cit> . this problem can be solved by using ontologies, which serve as universal functional definitions. enzyme commission   <cit> , mips functional catalogue   <cit>  and gene ontology   <cit>  are such ontologies. with go being the most recently and widely used, many automated annotation methods use go for functional annotation.

protein function assignment methods can be divided into two main categories - structure-based methods and sequence-based methods. a protein's function is highly related to its structure. protein structure tends to be more conserved than the amino acid sequence in the course of evolution  <cit> . thus a variety of structure-based function prediction methods  <cit>  rely on structure similarities. these methods start with a predicted structure of the query protein and search for similar structural motifs in various structural classification databases such as cath  <cit>  and scop  <cit>  for function prediction. structural alignments can reveal the remote homology for 80-90% of the entries in protein data bank  <cit>  even if no significant sequence similarity was found for the two proteins  <cit> . however, these methods are limited by the accuracy of the initial query structure prediction and the availability of the homologous structures in the structural databases. despite of being highly accurate, the big gap between the number of sequences and their solved structures restricts the use of structure-based methods. therefore, sequence-based methods are needed.

the main idea behind sequence-based methods is to compare the query protein to the proteins that are well characterized, and the function of the best hit is directly assigned to the query sequence. go annotations are assigned to the blast search results  <cit>  for the first time by goblet  <cit>  which maps the sequence hits to their go terms. later on the go terms are given weights based on the e-value of the blast search by ontoblast  <cit> . this was further refined in gofigure  <cit>  and gotcha  <cit>  by communicating the scores from one level to the other in the go hierarchy tree. all these methods are based on the blast search results; thus they fail to identify the remote homologues with a higher e-value. this problem is tackled by the protein function prediction  server  <cit> , which replaces the blast with psi-blast  <cit>  and thus can detect remote homologues. the pfp server can predict the generalized function of protein sequences with remote homology, but with a trade-off of low specificity. ffpred  <cit>  is the most recent protein function prediction server that builds support vector machine  classifiers based on the extracted sequence features of the query sequence and thus it does not require prior identification of protein sequence homologues. however the server needs one svm classifier for each go term, which makes it computationally expensive. furthermore, the server only provides classifiers for  <dig> molecular function and  <dig> biological process categories that represent more general annotations, which limits its usage in deciphering specific annotations. the lack of annotation specificity and high complexity of the existing methods advocate the need of improvement in the automated protein function prediction.

here we present a novel automated protein functional assignment method based on the neural response algorithm  <cit> . the algorithm simulates the neuronal behavior of human's image recognition, and has been successfully applied for image classification. the main idea of this algorithm is to define a distance metric that corresponds to the similarity of small patches of the images and reflects how the human brain can distinguish different images. this algorithm uses a multi-layer framework with spatial scale, and size increasing as we move from the one layer to the other in a bottom-up fashion. the bottom layer consists of templates  of the images and the intermediate layers consist of secondary templates formed by the assembly of the templates in the lower layers. the whole image is in the topmost layer. for example consider a three layered architecture of templates  p, q and r , with p ⊂ q ⊂ r as shown in figure  <dig>  let im, im and im be the function spaces corresponding to the similarity of the templates in the layers p, q and r respectively. im gives the similarity between any two patches in the layer x and a mapping set m: that maps the templates from the bottom most layer to the templates in the next layer i.e. mp: p → q, and similarly mq: q → r. having defined the layers  and the initial layers similarity function im, the algorithm builds a derived kernel on the top of layer r in a bottom-up fashion. the process starts with the calculation of initial reproducing kernel kp on the bottom most layer p as the inner product of its functional space im×im. based on the this initial kernel kp, intermediate derived kernel kq is computed on top of the layer q and this in turn is used to compute the final derived kernel kr on the top most layer r, which can help us in the classification of the whole images in layer r. refer to  <cit> , for the detailed mathematical formulation of the initial and the derived kernels. the computation of kernels forms the unsupervised preprocessing component and is key for the superior performance of the neural response algorithm as it can minimize the complexity of the corresponding image classification problem  <cit> .

in the current context of protein functional characterization, the top layer represents the whole protein sequences and the subsequent layers are constituted of sequence motifs. at each layer similarity is computed between the templates of two successive layers, which are referred to as derived kernels by taking the maximum of the previously computed local kernels in a recursive fashion. finally a mapping engine is built on the kernels derived from the neural response algorithm to map the query protein to its most probable go term. a detailed description of the whole methodology is given in the methods section.

RESULTS
we used the go terms with no further children  and their corresponding proteins for the assessment of our method. the rationale for using leaf nodes is that these go terms are functionally more specific than the go terms at the higher levels, i.e. no two go terms should share a common protein and thus can demonstrate the specific function prediction strength of our method. this also addresses the issue of redundancy in the training set. to further fortify our argument we had also addressed the redundancy problem at sequence level by eliminating the redundant sequences that are more than 80% similar in the training set. this was done by using cd-hit  <cit> , a program that removes redundant sequences and generates a database of only the representatives. from the extracted go terms we enumerated all the protein pairs belonging to the same go term and labeled them as positive dataset i.e. we assigned a label y as  <dig> and the protein pairs belonging to different go terms were labeled as negative, y =  <dig>  among such labeled pairs, we randomly selected  <dig> positive pairs and  <dig> negative pairs and used these labeled protein pairs to train and validate our method. after training the final mapping function, f) produced a value between  <dig> and  <dig> corresponding to the similarity between the proteins i and j in the validation set. upon applying the threshold of  <dig> , we predicted the labels y to  <dig>  if f) ≥  <dig> , and predict y to  <dig>  if f) <  <dig> .

cross validation
to evaluate our method we performed 5-fold cross validation i.e. we randomly divided the pool of  <dig> labeled protein pairs into five partitions with an equal number of positive and negative labeled pairs. out of the five partitions, four were used to train the neural response algorithm, and the remaining one partition was used to test the algorithm. this process was repeated for five time , with each of the five partitions used exactly once as the validation data. the idea was to check whether our method can correctly classify the pairs, which were not used for training. the values of average accuracy, area under the curve  and training time of the 5-fold cross validation are reported in table  <dig>  with respect to the template library and the mapping engine used . the difference in the accuracies using the prosite and pfam template libraries is due to the differences in the respective sequence coverage. thus we combined the pfam and prosite templates for a better sequence coverage, and indeed, the accuracy increased . out of the two mapping engines least squares classifier is almost  <dig> folds faster than the svm classifier with almost the same accuracy . therefore we report the accuracy values using the least squares mapping engine.

classification specificity with respect to the go term distance
as described in methods, the derived kernel classifies two proteins to be similar, if the pair is equivalent  to a pair with two known similar proteins. to test the classification specificity of our method, we have selected  <dig> proteins  with the first  <dig> pairs sharing an immediate parent go term ; second  <dig> pairs sharing a common parent separated by an edge distance of  <dig> in the go tree . similarly we have level  <dig> and  <dig> datasets with an edge distance of  <dig> and  <dig> respectively. as the positive pairs in the training set share a common go term, we expect our method to classify the protein pairs as positive whose go terms are the same or the next one in the go hierarchy and as negative if their respective go terms are far away. the number of positively classified  pairs in respective subsets is given the figure  <dig>  we observed that the proportion of positively classified  pairs is 88% in the level  <dig> dataset as they are much closer in the go tree and it gradually dropped to 9% in the level  <dig> dataset as the go distance between them is increased. this suggests that our method is highly specific in classifying the similar proteins with respect to the relative distance between the respective go terms.

comparison of classification accuracy
having shown the predominant classification specificity and the  <dig> fold cross validation results, we further compare the classification accuracy of our method with the pfp and ffpred servers, which are the most sensitive protein function prediction server using go vocabulary  <cit>  to date. we had compiled a test set of  <dig> proteins constituting of  <dig> protein pairs, with  <dig> pairs sharing the same go term  i.e. the edge distance between the go terms of a protein pair is zero and other  <dig> pairs sharing a distant root go term  i.e. the edge distance between the go terms of a protein pair is ≥  <dig>  each of the  <dig> protein pairs were classified as either positive  or negative  by nrprof. since pfp or ffpred server does not have a standalone software version, we had to submit our query directly to the online server manually for each of the  <dig> proteins. the pfp and ffpred servers list the probable go terms for a query protein sequence with a confidence score associated with each of the go terms. a classification is considered to be accurate if the servers predict the same go term  for both the proteins of a pair in the positive test set and different for the negative test set. on the other hand nrprof classification is considered to be accurate if it can classify the positive set as similar and negative set as dissimilar pairs. out of  <dig> predictions, nrprof performed better than pfp and ffpred servers in  <dig> and  <dig> instances respectively. the accuracies are tabulated in table  <dig>  we therefore conclude that nrprof has a better classification accuracy.

go term predictability
next we demonstrate the go term predictability of our method. our method labels a protein pair pi  and pj  as  <dig> if they are similar and thereby assigns the go term of the protein pj to the protein pi based on the threshold applied on the function f). to overcome the threshold dependency and to make the results comparable with the pfp and ffpred servers, we had sorted the proteins in the base dataset in descending order based on their similarity )) to the query protein, and assigned the go term of the corresponding most similar  protein to the query protein. for a better understanding of the methods, we present the stepwise workout of the algorithm for a human protein chromodomain helicase dna binding protein  <dig> . firstly the query sequence chd <dig> was scanned for the potential template hits. we got  <dig> hits in the template library, with no hit occurring more than once thus a neural response vector can be computed with equation  <dig> . the neural response vector computed was < chd <dig> |ps <dig>   <dig>  | ps <dig>   <dig> | ps <dig>   <dig>  | ps <dig>   <dig>  | ps <dig>   <dig>  | ps <dig>   <dig>  | ps <dig>   <dig>  | >. the first element in the vector is the query protein followed by the template id  and its score respectively. however if the query sequence have repeats or if a template t has more than one hit in the query sequence we consider the hit with the maximum score . we then calculated the pair wise neural response n  where p is the query  and qi is the pre-computed neural response of the ith protein sequence from the initial base set. for illustration here we show the calculation of  <dig> pair wise neural response vectors ,  and  in the figure  <dig>  next these pair wise neural response vectors together with the another pair wise neural response vector  were fed to the mapping function using a gaussian kernel  to generate a value ranging from  <dig> to  <dig> corresponding to the similarity between the proteins in the pair wise neural response. then we sorted the proteins in the base dataset in a descending order based on their similarity )) to the query protein. since the f is higher than the other two, we assigned the go term of chd <dig> to chd <dig>  in the go tree, chd <dig> has  <dig> associated go terms. since we considered only leaf go terms for the higher annotation specificity, we assigned the go term go: <dig>  to chd <dig>  however, in addition to the current state of the algorithm if users wish to consider other non-leaf go terms, we suggest the users to use the sequence diversity  in the go terms associated with the most similar protein to the query protein, as a criteria for assigning the go term i.e., the go term with the least sequence diversity is assigned to the query protein. this can be advocated by the fact that the sequence diversity is inversely proportional to the specificity of the go terms. in the current example by either ways our method had assigned the term go: <dig> to the chd <dig> 

comparison with the existing methods
we compared the go term predictions of our method with pfp and ffpred servers, which are the most sensitive function prediction servers to date. pfp and ffpred servers predict the most probable go terms for a query protein with a confidence score associated with each of the go terms. a prediction is considered to be accurate if actual  go term of the query protein is ranked among the top  <dig> probable go terms by the respective methods. lack of standalone versions of pfp and ffpred is a serious limitation on the dataset used for comparison. we compiled a dataset of  <dig> proteins each belonging to the leaf nodes of the go tree. the prediction results from pfp and ffpred were obtained by manual submissions to the respective servers. table  <dig> compares the go terms predicted for the human protein wdr <dig>  pfp could not report the actual leaf go term in its top  <dig> predictions. this is due to trade-off of annotation specificity to weak hits with high e value. ffpred could not predict any go term because it is limited to only  <dig> molecular function and  <dig> biological process categories. whereas nrprof predicted top  <dig> similar proteins with the same go term. the overall accuracy on the set of  <dig> proteins is reported in the table  <dig> 

actual leaf
from table  <dig>  we can infer that our method nrprof performs reasonably better than the pfp server. we have not reported the accuracy of the ffpred, as it is limited to only  <dig> molecular function categories, which makes it suitable for general rather than specific function annotations. there are other methods that use go vocabulary for protein function prediction methods including goblet, gofigure and gotcha. but the pfp server has already been proved to be superior to all the above mentioned methods  <cit> . thus we have compared our method  only with the pfp server.

discussion
mapping function threshold
the mapping function, f) produces a value between  <dig> and  <dig> corresponding to the similarity between the proteins i and j. upon applying the threshold of  <dig> , we assign the labels y to  <dig>  if f) ≥ x, and to  <dig>  if f) < x. we tried different values of x to decide on the best threshold. different threshold values and their corresponding accuracies are plotted in figure  <dig>  it can be observed that the accuracy is high for the threshold values ranging from  <dig>  to  <dig> . thus we selected  <dig>  as the optimal cut-off.

cd-hit threshold
here all our validation and test data sets constitute of human go terms  thus we need to take care of the redundancy. this was implicitly addressed by using go nodes with no children; however we even address this issue at the protein sequence level by using cd-hit with optimal cut-off, to ensure proper training. an optimal threshold should not be too high or too low, if so the predictions will be biased towards highly similar/dissimilar proteins respectively. in order to observe the influence of this cut-off on the accuracy, we compared the accuracy values on a test set of  <dig> protein pairs, with  <dig> positive and  <dig> negative pairs with respect to five different cut-offs and the results are shown in the table  <dig>  we can observe that the accuracies at 60% and 100% cut-offs are less when compared to others. this may be due to the biased training on negative and positive protein pairs respectively. the accuracies at 70% and 80% are almost as good as or higher than the other cut-offs. this supports the use of 80% as the cut-off to eliminate the redundancy. however this cut-off should be changed with the addition of sequences from the other species. thus we advise to choose the cut-off based on the diversity of the dataset.

similarity based on protein pairs
we can simply calculate the similarity between a query protein and a known one to assign the corresponding go term. however with this similarity, we can only use some naive algorithms like k-nearest neighborhood, whose accuracy is not quite satisfactory especially for biological data , which is essentially multi dimensional. in addition to this, we should artificially enforce a similarity cut-off between the query and the known protein to assign the query protein to its associated go category. considering the fact that the intra go term similarity varies from go term to go term it is difficult to set such cut-offs. to conquer this, it is necessary to design a machine learning algorithm that can learn and chose the cut-off based on the similarity between the proteins sharing the same go term i.e. the similarity cut-off should be high if the intra go term similarity is high and vice versa. here, our model assigns the query protein to its associated go category  based on the respective intra go term similarity, given by the similarity between the proteins constituting the 2nd pair, i.e. the 1st pair will be labeled as similar if its similarity is equivalent to the similarity of the 2nd pair  and vice versa. by this we can bypass the cut-off that needs to be enforced on the simple similarity score for assigning go terms.

go term mapping
mapping contains entities from external database system indexed to similar or related go terms. currently these mappings in the gene ontology database are made manually consuming a lot of resources and time. as a spin-off, our methodology can automate the process of mapping between the templates  and the go terms, without compromising much on the accuracy. the neural response of a protein with respect to all the templates computed according to the equations  <dig>  is nothing but the mapping of a protein  to the respective templates . go-motif association scores for the same is given by:

  si=nmi×i 

where nmi is the number of proteins  having a specific motif i associated to a go term  and asi is the alignment strength of the respective motif's. we use the product of nmi and asi to achieve a trade-off between the overrepresentation of a motif to its alignment strength. the detailed calculation is shown in figure  <dig>  the computed go-motif association scores can be used to rank the multiple mappings to a go term.

proteins with multiple leaf go terms
our test set is compiled of leaf go terms and their corresponding proteins with no two go terms sharing a common protein, to demonstrate the specific function prediction strength of our method. however, up on perusal we found that ~25% of the proteins belong to more than one leaf go term under the category of molecular function. to analyse the effect of "not including such proteins" on the accuracy, we have compiled a new test set of the same size . we perceive that considering proteins belonging to more than one leaf go term has no negative effect on the go term predictability. in fact the prediction accuracy is slightly better  <dig> % when compared to  <dig> % on the actual test set.

CONCLUSIONS
here we present a novel protein function prediction method, nrprof, based on the neural response algorithm using the gene ontology vocabulary. the neural response algorithm simulates the neuronal behavior of the visual cortex in the human brain. it defines a distance metric corresponding to the similarity by reflecting how the human brain can distinguish different sequences. it adopts a multi-layer structure, in which each layer can use one or multiple types of sequence/structure patterns.

nrprof is the first instance of neural response being used in the biological domain. it finds the most similar protein to the query protein based on the neural response n between the query and the target sequences; and thereby assigns the go term of the most similar protein to the query protein. this is a profound and composite method with the essence of sequential, structural and evolutionary based methods for protein function prediction. the templates from the prints and pfam database contribute to the functional profiles or signatures . the mismatch and deletion states in the hmm profiles of the pfam templates account to the degeneracy due to evolution and the secondary structural information of the match states in the hhm profiles contribute to the structural part. the use of hmm profiles along with the secondary structure information of prosite and pfam sequence motifs to define the neural response gives our method an edge over other available methods to identify the remote homologues, as profile-profile alignments are superior to psi-blast based methods in detecting the remote homologues. thus nrprof can complement most of the existing methods.

our method is computationally less complex compared with the other methods, as the initial neural response of the proteins in the base dataset with respect to the template library are computed only once and from there the neural response between the query and target is computed with the least computational effort unlike other blast/psi-blast based methods. the simple derived kernel adds to the computational simplicity of our method. we validated our method in a 5-fold cross validation fashion and obtained an accuracy of 82%. considering the criterion that a prediction is valid if and only if the actual go term is top ranked  go term by our method, 82% is quite a good accuracy. the classification accuracy of  <dig> % on a test set of  <dig> proteins suggests that our method is highly specific in classifying the similar proteins with respect to the relative distance between the respective go terms. upon further caparison of our method with the pfp and ffpred servers which are the most sensitive function prediction servers to date, the go term prediction accuracy of  <dig> % evince that our method is more accurate in predicting the specific functions. thus we conclude that our method is computationally simple yet accurate when compared with the other methods. this is achieved by simulating the neuronal behavior of the visual cortex in the human brain in the form of neural response.

