BACKGROUND
gene expression microarrays enable the simultaneous measurement of the expression levels of thousands of genes. supervised classification of gene expression data aims to identify combinations of genes which give the best discrimination of groups of samples specified in advance. for such methods, which are classically used in disease class prediction, the identification of a subset of discriminating genes can be critical  <cit> . indeed, a large proportion of genes are generally non-informative in terms of disease class prediction. a gain in classification and prediction performance can be expected when predictors are built upon a subset of highly discriminating genes  <cit> .

several algorithms capable of selecting a subset of predictive genes were recently proposed  <cit> . these methods include a genetic algorithm  <cit> , maximum difference subset algorithm   <cit> , support vector machines  <cit> , a shrunken centroids technique  <cit>  and several which use of discriminant functions  <cit> .

however, two issues remain: 1) different subsets of genes may provide comparable optimal discriminations  <cit> ; 2) it is generally difficult to determine the optimal number of genes for discrimination  <cit> . this number may vary according to the number of individuals in the training set, the number of groups to discriminate and the method used for classification and prediction. dolédec and chessel  <cit>  developed a supervised classification approach, between group analysis , which was recently applied to microarray data  <cit> . the authors specified several key features of bga that make it a method of choice for sample classification and class prediction. in bga, all genes participate in the discrimination. consequently, no gene selection step is required. on the other hand, bga calculates group means and is therefore sensitive to outliers. our objective was to improve the robustness of bga by optimizing the number of discriminating genes supporting the analysis.

in this study, we propose a new jackknife-based algorithm – optimized between-group classification  – that produces a selection of the most robust discriminating genes in order to improve the accuracy of disease class prediction. the criterion optimized in obc is the percentage of between group inertia . obc is applied to bga but it could also be associated with other supervised methods. we tested the efficiency of obc on four datasets using independent test sets and leave-one-out cross-validation . we compared our approach to different classification methods.

RESULTS
outline of the obc algorithm
obc can be described in three steps . these steps are detailed below. each dataset used in this study was systematically split into a training set and a test set. obc was applied exclusively to the training set.

pre-selection of discriminating genes – step 1
in the first step, pre-selection of a few hundred most discriminating genes is made. this is to reduce the number of calculations and computational resources in step  <dig> . this initial set of discriminating genes is obtained from a bga of the whole training set . genes with the highest scores on bga discriminating axes, those located at extremities of bga axes, are collected. for datasets where samples are grouped into  <dig> categories , we selected an equal amount of genes at each end of the single discriminating bga axis. for datasets with more than two categories, we chose genes projected at the periphery of each pair of discriminating axes using a "peeling" function .

jackknife optimization – step 2
this second step of the algorithm is cpu and time consuming. due to computational limitations, the number of pre-selected genes should be in the order of a few hundreds . strategies to reduce calculation time are discussed below.

classification accuracy by loocv
the performance of the subsets of predictive genes was assessed using loocv. to perform loocv, a sample is removed from the dataset and a bga is performed on the remaining samples. the excluded sample is projected on to the bga and classified. this is iteratively performed until all samples have been subjected to cross-validation. the percentage of samples correctly classified by cross-validation is calculated. this parameter measures the prediction accuracy of the subset of genes.

optimization criterion
the objective of obc is to improve the discrimination efficiency of bga, by excluding genes which contribute least to the % bg inertia of samples. obc uses a jackknife iteration to maximize the between group inertia while minimizing the within group inertia. the inertia decomposition can be described as follow.

let us suppose n the number of samples , dist the squared euclidean distance between two samples xi and xj, k the number of groups  and nk the number of individuals in the kth group. potentially distances other than euclidean could be used. in a preliminary analysis we found that the euclidean distance performs similarly to manhattan distance. therefore, given its relative ease of implementation, we use euclidean distance throughout our analyses. by using a weighted pair-group average calculation, the total inertia can be decomposed into within group inertia  and between group inertia . the algorithm aims to maximize the percentage of between group inertia, i.e. the ratio of the between group inertia to the total inertia .





% bg inertia = bg inertia/     

measurement of the contribution of each individual gene using jackknifing
we assessed sequentially the influence of each gene in the remaining gene subset using a jackknife procedure. in jackknife analysis, we remove a gene, perform a bga on the dataset and calculate the % bg inertia. if we remove a gene which positively contributes to the between group discrimination, the % bg inertia decreases and vice versa. by comparing the % bg inertia before and after removing a given gene, one can assess the influence of this gene. in addition, we assess the stability of the % bg inertia during jackknife .

jackknife approaches have been previously used in the context of gene selection  <cit> . as an example, lyons-weiler et al.   <cit>  used jackknifing to reduce the false positive rate of a gene set. in the present study, we used jackknifing to progressively eliminate the least discriminative genes from a subset of genes.

backward optimization
at each step of the algorithm, the gene that contributes least to the % bg inertia is removed from the dataset. another jackknife procedure is then performed with the remaining genes. this backward optimization algorithm reduces the number of genes from a large subset  to a minimal subset .

stability and robustness of the optimization – variance of % bg inertia and monte-carlo permutation test
the variance of % bg inertia was used as a measure of the stability of the optimization. by jackknifing a subset of n genes, we obtain n values of % bg inertia. the range of variation of these values is the variance of % bg inertia. during backward optimization the number of genes included in the classifier gets smaller, and the effect of the jackknife perturbation measured by the variance of % bg inertia tends to increase. if this variance is high, the robustness and the stability of the prediction model is low. consequently, low variance of % bg inertia is preferable.

throughout the optimization, the statistical significance of bga is evaluated with a monte-carlo permutation test.

identification of the optimal subset of genes for disease class prediction – step 3
the optimal subset of genes are identified with the aid of the summary diagram which summarizes the results of the algorithm. the optimal subset of genes should have both high loocv prediction accuracy and stability . if optimization of these two parameters resulted in a range of near optimal solutions, we chose subsets with fewer genes and higher % bg inertia. importantly, although we calculate prediction accuracy of the independent test set, these results were never taken into account in obc, as this would result in over-training.

application of obc to sarcoidosis data
between group analysis
standard bga was applied to the whole sarcoidosis training data set. the biplot representation shows that bga separated the three phenotypes with no overlap . the first axis separated the healthy controls from the sarcoidosis patients. the second axis separates the two stages of sarcoidosis. the efficiency of classification of new samples was measured using loocv. seventy-five percent of the  <dig> samples were classified correctly. however, we observed discrepancies in classification accuracy between the three phenotypes. all healthy controls,  <dig> out of  <dig> stage i, but none of the stage ii/iii sarcoidosis patients were correctly re-classified. when we tried to predict the classification of a blind test of  <dig> follow-up patients, using this bga of the whole set of genes, only 50% of these test samples were correctly classified. four out of five patients, which recovered  <dig> months after they were diagnosed with a stage i sarcoidosis, were classified in the healthy group. all of the patients still suffering from active sarcoidosis stage ii/iii  were incorrectly classified.

optimized between group classification
we selected the  <dig> most discriminating genes in this initial bga, using the above mentioned peeling procedure . obc was applied on this subset of genes. the least influential genes in terms of % bg inertia were removed one by one.

the subset of genes with the best cross-validation efficiency and least variable % bg inertia was judged to be the optimal subset. therefore, this was a subset of  <dig> genes . the accuracy of loocv obtained using this optimized subset of genes was clearly improved since 96% of samples were correctly classified . figure  <dig>  shows the projection of  <dig> follow-up samples predicted by this subset of classifiers. these predictions were also improved since 2/ <dig> of sarcoidosis stage ii/iii were correctly associated to their group, whereas 4/ <dig> of patients in remission from a stage i sarcoidosis were classified as healthy. patient  <dig>  who was mis-classified, clinically recovered from a sarcoidosis stage i. it is possible that signals of gene activity specific to stage i sarcoidosis be still detectable in this patient.

application of obc to tumour data
between group analysis
bga was applied to the whole tumour training set  <cit> . bga clearly separated the  <dig> different types of tumours with no overlap . based upon the complete set of  <dig> genes, the loocv showed that 93% of the  <dig> samples from the training set were correctly cross-validated and 19/ <dig> of the test sets were correctly predicted. the most discriminating genes associated with the different groups were identified at the periphery of the bga biplot .

optimized between-group classification
from the initial bga, the  <dig> most discriminating genes were selected. we applied the optimization algorithm to this initial subset. we used the optimization diagram to determine the optimal subset of genes. as shown in diagram figure  <dig>  panel b, there was a range of near optimal solutions . we decided to choose an optimal subset of  <dig> genes for which the accuracy, the stability and the % bg inertia were high.

the results of bga using the  <dig> optimal genes are plotted in figure  <dig> . the accuracy of loocv, of bga on the  <dig> training samples using the  <dig> optimal genes, increased to 100%. all 20/ <dig> test sets were correctly classified .

stability of obc and test of significance
the stability of obc was controlled by monitoring the evolution of variance of % bg inertia. this parameter was of great importance as it monitored whether the classification was overly influenced by a few genes.

the monte-carlo permutation test was constantly significant for the different datasets . this result suggests that our method is robust.

sensitivity and specificity
we built confusion matrices from the results obtained from loocv and classification of independent test sets. then, we calculated the sensitivity and specificity of bga and obc for each disease category. sensitivity measures the proportion of individuals correctly classified for a given disease class . specificity measures the proportion of individuals that do not belong to the class and which are not classified in this class . the sensitivities and specificities of obc vs. standard bga are summarized in tables  <dig> and  <dig> 

we observed an improvement in prediction sensitivity and specificity of both the sarcoidosis  and tumour datasets  when obc was applied in loocv and independent test sample cross validation.

comparison with other algorithms
we compared obc with three other recently described gene selection methods: the ga/knn algorithm  <cit> , maximal margin linear programming   <cit>  and nearest shrunken centroid  <cit> . results  show that obc outperforms these approaches in terms of accuracy of loocv and classification of independent test sets. comparisons between bga and other supervised classification methods  <cit>  report that bga outperforms or performs with similar effectiveness.

1threshold of  <dig> 

2threshold of  <dig> 

obc applied to datasets with binary categorization
colon cancer dataset
we assessed the prediction accuracy of obc when applied to the colon cancer data set, which contains two categories of tumor samples. we applied obc optimization to the  <dig> most discriminating genes. results of loocv, show an increase of accuracy from 85% for standard bga to 94% for obc . we investigated the sensitivity and specificity of obc classification prediction when applied to independent test data. we built  <dig> pairs of training sets/test sets by randomly splitting the complete data set of  <dig> samples into training sets of  <dig> samples and test sets of  <dig> samples. obc produced an improvement in both the sensitivity  and specificity  of prediction.

leukemia dataset
we compared the prediction accuracy of bga and obc using loocv of the whole dataset. the percentage of samples correctly predicted in loocv was 90% for bga and 99% for obc . similarly to the colon cancer data analysis, we built  <dig> pairs of training sets/test sets by randomly splitting the whole dataset into  <dig> training and  <dig> test samples. application of obc to the leukemia dataset improved the sensitivity and specificity of test set classification. when obc was applied, the sensitivity of classification was improved for both all  and aml . the specificity of prediction of both all and aml samples was also improved .

discussion
selection of genes that optimize disease class prediction is a significant and difficult challenge in microarray data analysis. most discriminative functions require more cases than variables which is not realistic in the context of microarray experiments. a further challenge is the considerable amount of noise in microarray data. bga can be applied to complete datasets without prior gene selection and performs comparably or outperforms several other approaches  <cit> . we showed that an optimized gene selection considerably improves the predictive power of bga. our jackknife-based algorithm tests the robustness of bga discriminating genes and progressively excludes weaker discriminators. as a consequence, it optimizes the performance of bga and reduces the number of discriminating genes.

the obc algorithm presented here might be time consuming depending on the size of the initial subset of genes. increasing the number of genes in the initial dataset ensures that more potentially discriminative genes are present in the analysis. however, the time required for the optimization process increases significantly. we assessed the percentage of gain in % bg inertia obtained by increasing the number of genes in the initial subset. this number depends on the dataset and in particular the number of groups to discriminate. the optimal number of genes of obc starting genes is around  <dig> for the sarcoidosis data and 150– <dig> in the tumour data .

in obc, the choice of the initial subset of genes from which the algorithm starts remains critical and alternative procedures might be used. for example, the genetic algorithm proposed by li et al.   <cit>  could be associated to obc and might provide some improvements in performance.

different options could be considered to speed up the algorithm. we considered removing more than one least influential gene at a time in the jackknife optimization. the execution time would decrease proportionally to the number of genes removed at each step. for example, if we removed  <dig> % least influential genes from the subset of genes at each step, we could greatly increase the speed of execution of the algorithm. with this, it would be possible to include a few thousands of genes in the initial subset of genes. the decision on how many genes to remove per jackknife cycle is a trade off between testing more combinations of genes  and including more genes in the analysis. on the other hand, the numerous tasks performed during the optimization could be split into several jobs, which could be potentially computed in parallel by a cluster of processors/computers. finally another solution would be to rewrite the computationally demanding parts of the algorithm in a more efficient computer language like c.

we decided to choose a backward optimization procedure as this seemed to be more adapted for taking possible gene-gene interactions into account. the prediction power of a single gene might be negligible in itself while it might be preponderant when associated with one or a few other genes. removing a gene that jointly participates with other genes to the group discrimination will have an impact, which is measurable by a backward approach, whereas no evidence might be found by using a forward optimization.

our results show that an improvement in discriminative and predictive power of bga can be achieved by reducing the number of predictors in the analysis to a small subset of highly discriminative genes. these genes contribute to improve the % bg inertia. in this study, two criteria were used to define the optimal subset of genes: a positive criterion, the percentage of correct classification by loocv and a negative criterion the variance of % bg inertia. when searching for the subset of genes where both criteria were optimized, we generally found a range of near optimal solutions. in the sarcoidosis dataset, the size of the optimal subset of genes was around  <dig>  whereas in the tumour dataset, subsets including around  <dig> genes were found to be optimal. by using a method that associates a genetic algorithm with the k-nearest neighbors technique  on a lymphoma dataset, li et al.   <cit>  concluded that using only a few discriminating genes may not be reliable, whereas using too many genes will add noise to the classification. they suggested 50– <dig> genes would give an optimal result which is in agreement with our study.

CONCLUSIONS
we propose obc, a novel jackknife-based backward optimization algorithm, which improves both the classification and predictive power of bga. our algorithm tended to outperform alternative classification techniques. in the future, obc could be used as a decision making-tool for disease class prediction based on gene expression data in various clinical situation. future developments will include the application of the algorithm to different supervised methods.

