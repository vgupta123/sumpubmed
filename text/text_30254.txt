BACKGROUND
an important problem in computational biology is the detection of remote homologous proteins, that is, proteins that have a common ancestor but that have diverged significantly in their primary sequence in evolutionary history. in practical terms, remote homology detection is the problem of detecting homology in cases of low sequence identity, frequently below 30%. this is an important and hard problem, thus the development of methods to identify homologs between proteins is essential for functional and comparative genomics. in a general way, homology detection methods are today very important to help for sequence annotation and to guide laboratory experiments.

traditional methods, such as blast  <cit> , deal with the homology detection problem by searching for regions of local similarity among pairs of sequences. certainly, the performance of these methods is directly related to sequence identity, and since remote homologous sequences have low identity, those methods fail to give satisfiable answers. an alternative to blast are generative methods. first, they train a model to represent a group of homologous sequences , and then match a query sequence against the model to evaluate the similarity of the query sequence to the group/family. profile hidden markov models   <cit>  and psi-blast are examples of such approaches, also known as family-based or sequence-profile based approaches. psi-blast builds a probabilistic model based on position specific score matrix  from the results of the first blast alignment. next, this pssm is used to further search on the database for new matches, and is updated for subsequent iterations with newly detected sequences. several studies have shown that sequence-profile based approaches perform better than methods based on pairwise comparison only  <cit> , but they still largely fail to detect distant homologous proteins. a significant improvement over those methods were made possible by comparing profile-profile instead of sequence-profile. methods such as prof-sim  <cit> , compass  <cit>  and hhsearch  <cit>  build a profile from the query protein and then compare it against a profile database constructed from the target proteins.

the performance of generative methods degrades as sequence similarity decreases. this limitation has motivated researchers mainly in two directions, i) to combine extra information to previous approaches, such as phylogenetic  <cit>  and protein structure information  <cit> , and ii) to search for new accurate methods. among the new approaches, a family of methods called "discriminative", have been able to attain additional accuracy to remote homology detection by modeling the differences between positive and negative examples. the most popular discriminative method applied to the remote homology detection problem is support vector machine   <cit> . basically, svms learn a classification function, from positive and negative training examples, that optimally separates the unseen data into two categories, for instance, homologous and non-homologous proteins. the kernel function that measures the similarity between a pair of examples has a key role in the svm performance. typical approaches represent each protein sequence as a fixed-length vector, where each vector's item is a protein property, and design a kernel function taking the inner product between these vectors. several feature protein vector representations have been proposed. svm-fisher  <cit>  represents each protein x as a vector of fisher scores. these scores are obtained comparing x to the phmm built from the positive training sequences . svm-pairwise  <cit>  also uses scores to compose its feature vector, those are extracted from pairwise alignments of x and each sequence in the training set. some methods use representations based on primary-sequence motifs, where a sequence x is represented in a vector space indexed by a set of precomputed motifs  <cit> . gpkernel  <cit>  is another method based on motifs, but instead of using precomputed motifs coming from an existing database, it generates motifs from training data. other methods have used structural motifs in place of primary-sequence ones for feature extraction task. the svm-i-sites method  <cit>  constructs the feature vector of a protein x by comparing the x profile  to the i-sites library of local structural motifs. later, this work was improved taking into account the order and relationship of the i-sites motifs  <cit> . a series of works have explored the use of k-mers . mismatch kernel  <cit>  represents a sequence x as a vector of k-mers occurrence, that is, each vector position has a non-zero weight if the k-mer is present in x and zero weight otherwise. a k-mer is said to be present in x if x contains a substring that has at most n mismatches to the k-mer. profile kernel  <cit>  vector representation is similar to mismatch kernel one. however, it considers a k-mer to be present if x contains a substring whose pssm-based ungapped alignment scores with the k-mer is above an user defined threshold. a feature vector representation based on distances between k-mers was introduced in  <cit> . statistical and relevant features have been extracted from all possible k-mers  by using latent semantic analysis  in  <cit> . later, this work was improved by using top-n-grams that are extracted from protein sequence frequency profiles  <cit> .

on the other hand, some approaches have followed a way that is alternative to the feature protein vector representation by pre-computing a kernel matrix where each element is the measure of similarity between a pair of examples. this matrix can be used directly as a kernel function. some new tools have followed this way, such as svm-la  <cit> , which measures the similarity between a pair of sequences by summing up scores obtained from its local alignment, and sw-pssm  <cit> , which uses profiles scoring schemes for measuring the similarity between pairs.

most of svms are family-based, that is, a protein family is required to train them, and the aim is to classify unseen proteins as member or non-member of this family. certainly, these methods are limited to the number of known families. in order to overcome this drawback, a new svm category has been proposed, that is, pairwise svm  <cit> . here, the aim is to rank proteins that are homologs to a given query protein. these methods are an alternative to the most commonly used methods in the biology community, that is: blast and psi-blast.

in fact, in the svm-hustle  <cit>  a training strategy was presented that could convert a family-based svm into a pairwise svm. like psi-blast it iteratively searches for homologs against a database by using blast in the first iteration. next, it trains concurrent svms from positive sequences selected from blast output, and negative sequences selected randomly from the remaining database. then, trained svms scan the database searching for new homologs that are added to the positive set. the algorithm stops when no new sample is classified as positive or when a maximum number of iterations is achieved.

to improve the performance some methods have been applied the semi-supervised training strategy, that is, they combine information from labeled and unlabeled databases in order to recruit more training sequences. this strategy is generally applied when unlabeled data is abundant while labeled data is limited, and this is the actual scenario of protein classification, since there is a large group of still unannotated proteins. however, semi-supervised approaches can become computationally hard when unlabeled large databases are used, such as nrdb <dig>  among methods that employ this strategy are rankprop  <cit> , svm-hustle  <cit> , top-n-gram  <cit>  and sw-pssm  <cit> .

svm methods are among the most effective and accurate methods for solving the remote homology detection problem. they classify query sequences as member or non-member of homologous proteins, but they do not provide any insight to the user concerning the reasons for the separation. moreover, svm is not able to work directly over relational data. however, biological data is naturally relational. for example, a specific amino acid in a protein could belong to an α-helix and at the same time belong to the active site of that protein. therefore, methodologies that explore relational data are expected to be more suitable to deal with biological data. in this vein, we focus our attention on inductive logic programming   <cit> . ilp is a relational data-mining method that uses first-order logic predicates to represent background knowledge, theories and examples . from those an ilp system can learn a hypothetical logic program which entails all the positive and none of the negative examples. this logic program is a comprehensible set of logical rules that can be used to classify unseen examples. moreover, when applied to remote homology detection problem, it can provide insights into conserved features of homologous protein families.

to the best of our knowledge, researchers have developed two approaches for applying ilp to remote homology detection. the first method is known as homology induction  <cit>  and uses ilp to improve on conventional sequence-based homology method. the second method uses a hybrid ilp-propositional machine learning method to predict protein functional classes directly from sequences  <cit> . first, it represents each protein through first-order logic predicates. it creates predicates based on properties extracted directly from sequences, such as frequency distribution of single residues, and on properties predicted from sequences such as secondary structure elements. second, it uses warmr  <cit> , an ilp data-mining program, to identify the most frequent patterns in its knowledge base. third, it converts these frequent patterns into binary attributes to be used in propositional learning. finally, it uses decision trees   <cit>  as propositional machine learning method.

our work is based on the same basic approach  <cit> . however, there are significant differences. first, we have proposed a novel first-order logical representation based on conserved amino acid positions in a multiple sequence alignment . second, we have related the first-order logical representation based on sequence properties, proposed in  <cit> , with our novel representation based on conserved positions for creating a hybrid representation that takes into account conserved physico-chemical positions in a msa. third, we have joined features created by these representations to train propositional models. in a general way, this combination of features has improved the performance of models. fourth, we have proposed to use svm as propositional machine learning method rather than dts. figure  <dig> summarizes the proposed methodology.

we confirmed that building models using only the most frequent patterns is a suitable methodology to the remote homology detection problem. remote homologous proteins seem to share only the essential properties in order to keep their function, and these properties can be represented by first-order logic predicates. for instance, figure  <dig> shows the partial alignment of "glucocorticoid receptor-like " superfamily sequences. the sequence identity of this alignment is smaller than 30%. we can observe that some positions are completely conserved . also, there are positions which are partially conserved . methods that have the ability of exploring only these positions most likely will outperform the methods that consider the whole alignment, since non-conserved positions could add noise to the model.

our intention in this paper was to investigate if the performance of remote homology detection methods could be improved only by exploring the most frequent patterns into homologous sequence groups. therefore, we did not use any extra-information, such as structural properties or phylogenetic trees, contrary to  <cit>  that used structural properties. all training data was extracted from sequences and msas. we carried out experiments on remote homology benchmarks and showed that svm outperforms dts when they are trained by using only the most frequent patterns. also, we have demonstrated that good performance can be achieved when we used first-order logical representations for the protein sequences based on conserved amino acid positions and based on conserved physico-chemical positions in the msa. moreover, we showed that the combination of features created by different first-order logical representations improves the performance of propositional models. finally, we compared the performance of our models with state of the art methods and showed that they are comparable to or better than its competitors, this includes the cases where sequence identity is low . however, the output of our method can be interpreted biologically to provide insights into conserved features of homologous protein families.

RESULTS
in order to assess our methodology, we have trained dts and svms using representations described in methods. we called seq those models that are trained from sequential properties only, and we named alncons those models that are trained from conserved amino acid positions in a msa. we have created a hybrid representation that takes into account conserved physico-chemical positions in a msa , the resulting models were called alnpc, where pc is an abbreviation for physico-chemical properties. additionally, we created models by joining seq, alncons and alnpc features. we named ilp-svm and ilp-dt models trained from our methodology. table  <dig> summarizes results . ilp-dt models did not reach good performance on sfull and s <dig> databases . ilp-svm-seq-alncons-alnpc models outperformed all other ilp methods for both databases.

some logical rules learned from "glucocorticoid receptor-like " sequences and their alignment . they are shown in their original warmr output and their interpretation is given below.

we highlighted that the novel logical representation, based on conserved amino acid positions  and based on conserved physico-chemical positions  in msa, that we propose here, is able to achieve better prediction accuracy than the sequential logical representation commonly used by related works. this result is expected since it is known that msas contain more functional and structural information than properties extracted from unaligned sequences. on the one hand, the combined models  were able to attain better accuracy than single models  for the sfull database. on the other hand, for the s <dig> database, the sequential logical representation does not contribute to improve the model performances. based on the observation that msa information is richer than sequential properties, we tested the hypothesis that below 30% of sequence-identity, msa information is still rich enough to build accurate models and that sequential properties might add noise within combined models. in fact, we observed that ilp-svm-alncons outperformed ilp-svm-seq-alncons, while ilp-svm-seq-alncons-alnpc and ilp-svm-alncons-alnpc achieved a similar perfomance.

when we compare ilp-svm models with ilp-dt models, all ilp-svm models outperformed ilp-dts. in fact, svms are often more accurate than dts. we observed that ilp-dts have produced fewer and simpler rules for both databases and they presented a poorer classification on test examples. in order to provide a comparison with  <cit> , we considered for comparison the ilp-dt-seq model, since it uses all properties handled in  <cit> , except those predicted from sequences, such as secondary structure. our results show that all models proposed here outperformed ilp-dt-seq for both databases.

when we combine the representations the number of features can increase creating sparse data. however, this can be avoided by using a feature selection technique. here, we applied chi-square statistical test to remove class uncorrelated rules. we set δ for  <dig>  and  <dig> , see methods. table  <dig> shows how auc values vary according to and without the chi-square test. we can observe that for most methods the performance was kept with δ =  <dig>  with a significant reduction in the number of features. on the other hand, δ =  <dig>  worsened the performance for all methods. in fact, for some families δ =  <dig>  removed all logical rules.

we compared our best models, that is, those trained from seq-alncons-alnpc features, with two models based on svm , and also with two other widely used methods: hmmer- <dig>   <cit>  and psi-blast  <cit> . we carried out rank-sum tests  <cit>  to compare models listed in figure  <dig>  and we show in table  <dig> statistical measures for this comparison. for both databases, ilp-svm-seq-alncons-alnpc outperformed svm-ngram-lsa, psi-blast and hmmer- <dig> , and achieved comparable performance to svm-la. ilp-dt-seq-alncons-alnpc model achieved better results than hmmer- <dig> , and achieved similar performance to psi-blast. based on ilp-svm-seq-alncons-alnpc performance, we can conclude that the combination of alignment information and sequence properties, and the strategy of selecting only the most important features can yield a more accurate model than those that explore all alignment positions, as hmmer- <dig>  and psi-blast, and those that extract ngram from unaligned sequences, such as svm-ngram-lsa.

we consider a result with p ≤  <dig>  to be significant.

although the results show that ilp-svm-seq-alncons-alnpc outperformed some state-of-art methods, we emphasize that the performance of psi-blast depends on the number of iterations and on the size of the database used to build the profiles. thus, to extract the maximum performance of psi-blast, we adopt the semi-supervised training strategy and we used nrdb <dig> as unlabeled database and set the number of iterations to  <dig>  as done in  <cit> . unsurprisingly, it performed better than our ilp-svm models. for example, psi-blastnr <dig> achieved a auc of  <dig>  for the database sfull and  <dig>  for the database s <dig>  certainly, methods trained from the nrdb <dig> database are expected to build more accurate models and be more effective in annotating remote homologous proteins. however, the computation time of methods that adopt semi-supervised training depends on size of the unlabeled database. therefore, psi-blast run on this configuration is computational time consuming. in conclusion, when supervised training strategy is employed ilp-svm methods obtain better or comparable performance than its competitors.

in order to provide an example of the biological interpretation of the logical rules constructed by warmr, we show in table  <dig> some rules which have been learned on members of the "glucocorticoid receptor-like " superfamily. rules r <dig>  r <dig> and r <dig> were learned from conserved amino acid positions  and r <dig> from conserved physico-chemical positions , see figure  <dig>  while rules r <dig> and r <dig> were learned from sequential properties. these rules represent only the conserved properties of "glucocorticoid receptor-like " superfamily members, that is, these rules catched essential features identifying the superfamily members. this was possible by using first-order logic predicates to represent the properties of each superfamily member, and by applying ilp in order to filter the essential features.

CONCLUSIONS
we have combined ilp and propositional models for improving the accuracy of remote homology detection methods. our approach can be segmented into three parts. first, training sequences are represented through first-order logic predicates. similar to  <cit> , we have used a representation based on sequence properties. additionally, we introduced a novel representation based on conserved amino acid positions in protein alignments. also, we related the logical representation based on sequential properties with our logical representation based on conserved positions creating a new representation for conserved physico-chemical positions in a msa. second, we executed warmr, an ilp system, in order to find only the most frequent patterns in our training set. third, the logical rules learned in the previous stage were converted in binary attributes for training propositional models. here, we applied decision trees and the widely used support vector machine as propositional methods.

our methodology is partly similar to the study developed in  <cit> . however, we proposed a novel logical sequence representation based on conserved positions in msa; we combined this representation with the logical representation based on sequence properties only, proposed in  <cit> ; we applied svms rather than dts. we showed that the prediction performance of our method, that uses logical representation of alignment information, is better than the prediction performance of our models trained only on the sequential representation. also, the combined representations improved the performance of ilp-dt models in any sequence identity range and the performance of ilp-svm for the original database. we carried out comparisons among the models proposed here with models based on svm , a model closer to the model proposed in  <cit> , that is, ilp-svm-seq, hmmer- <dig>  and psi-blast. our experiments showed that for the same data set, ilp-svm models achieves a superior or a comparable performance for any sequence identity range. in particular, our method produces a human-understandable output that can provide insights about conserved features of protein families.

we can conclude that the first-order logic language is suitable to represent conserved protein properties, and that from this representation, an ilp system can learn the essential rules that discriminate between homologous and non-homologous proteins. our methodology supports the intuition that proteins with remote evolutionary relationship have suffered several mutational events, and that only essential amino acids and their physico-chemical properties are kept in evolved sequences. thus, computational methods that explore only the conserved positions are more suitable to the remote homology detection problem than the methods that explore all amino acids within sequences.

we have confirmed through this study that conserved alignment positions play an important role in recognizing remote homologous proteins contrary to sequential properties extracted from unaligned sequences. we highlight that sequential properties can be useful for helping to identify remote homologous proteins, however, when the sequence identity is smaller than 30%, this information might become noise and worsens the performance of methods, as we observed for ilp-svm-seq-alncons.

another advantage of our methodology is the simplicity to include additional sequence properties. for this we can create a new predicate that represents the property and no modification of the algorithm is necessary. in this study, we used only properties that can be extracted directly from sequences or from conserved alignment positions. we considered a limited number of amino acid physico-chemical properties , since our logic sequential representation is based on previous ones  <cit> . however, the amino acid index database  <cit>  has defined amino acid numerical indices for more than  <dig> different kinds of physico-chemical properties. some methods used these indices to train svm and achieved a good performance  <cit> . thus, we intend to create a logic sequential representation that takes into account properties of the acid index database. other points that we would like to explore are: the presence of short hydrophobic blocks in homologous proteins, as well as, structurally conserved amino acids  <cit> , and functional amino acids, that is, active and binding sites. moreover, we would like to replace warmr with mineseqlog  <cit> . mineseqlog is an extension of warmr that works on sequences where each sequence is an ordered list of ground predicates. this approach seems to be more suitable to deal with protein sequences, since the amino acid order is taken into account. psi-blast performs better when run on nrdb <dig> with  <dig> iterations, and the use of psi-blast output, as done in  <cit> , to train our models provides another path to be explored.

