BACKGROUND
deciphering the mechanisms of transcriptional regulation of gene expression is one of
the key problems biologists are facing. it is widely accepted to date that genes
especially, in higher eukaryotes are regulated by a combination of transcription
factors  bound to their cognate dna sites, rather than by a single factor.
therefore, an extensive research is conducted on combinatorial interactions of
protein factors and their dna binding sites  with respect to transcriptional
activity of affected genes. the majority of present methods evaluate the statistical
properties of motif pairs  or multiple combinations of motifs  <cit> . some methods use comparisons with existing examples of
motif combinations as a basis for recognition  <cit> .

the minimal functional unit, which can provide combinatorial regulation, is a
composite element . structurally a ce consists of two closely located bss for
distinct transcription factors . but functionally ces are considered as single
elements, since its regulatory function are qualitatively different from regulation
effects of either individual bss  <cit> . function, structure and primary sequence of ces are
studied in a number of different experiments, in particular, to confirm
protein-protein interactions and cooperative binding to dna, as well as effects on
transcriptional regulation. such data on ces can be found in databases such as
transcompel  <cit> .

the major problem in developing general recognition methods for ces lies in the
extremely limited number of experimentally defined ces. for particular types of ces
some ad hoc methods have been suggested  <cit> . however,
the method, which can identify many types of ces  <cit>  shows relatively poor recognition characteristics.

the basic idea of the current method is to complement existing knowledge on
experimentally identified and functionally described ces by data available for
single bss constituting the ces. we demonstrate that such an integrative approach is
able to model the heterogeneity of ces, which results in good recognition
characteristics of the method. we also show that the existing variety of ces is in
no way a limiting factor to the method applicability. quite the contrary,
matrixcatch with the provided library outperformed all statistical methods, that to
date attract excessive attention of bioinformatics community. elements of
crowdsourcing were implemented in the website to allow further extension the existed
ce library.

methods
matrix model of ce
the idea behind matrixcatch is to complement the lack of knowledge on sequence
variation of each dna bs in ces by recruiting data collected for respective bss
separately from each other. such information is compiled in position weight
matrices . each ce will serve as a template for a model, which consists of
two pwms, as well as their minimal scores, relative orientation and distance.
thus, pwms, which are built using many single bss, define sequence variability
of bss in the ce. minimal scores for pwms, orientation and distance between pwms
are determined by the ce itself.

building the ce model
first, pwms related to the first binding tf are selected from the entire transfac
library . here and further we call the
“first” and “second” bs in a ce model in accordance to
the database annotation. second, pwm scores are calculated for both orientations
at the position of the first annotated bs in ce for all selected pwms. third,
the combination of pwm, its score and its orientation, which delivers the lowest
prediction rate on random sequences, is selected. often, but not always, it is
the pwm with the highest score. this score becomes the minimal required pwm
score sm <dig> in the model for the first bs. after repeating the
same three steps for the second bs, all the parameters of the ce model are
identified: pwm <dig>  pwm <dig>  their
orientations, minimal scores sm <dig>  sm2
and in-between distance dm.

on this basis, we build  <dig> matrix models for all ces collected in the
transcompel database. to search for potential ce, matrixcatch will test these
models on a dna sequence. to be able to reveal “non perfect
matches”, model parameters like pwm scores  and distance 
should be relaxed. to increase the specificity of the search we introduced a
“composite score” . as will be showed later, this composite
score provides higher recognition accuracy in comparison to existing
methods.

dependence between binding sites in ces
it was observed that the combination “one bs with low pwm score –
another with high pwm score” in real ces is more frequent then “low
- low” . pearson correlation coefficient
calculated for pwm scores equals − <dig>  
indicating negative correlation between matrix scores within one ce. to test the
statistical relevance of this observation, we investigated the distribution of
pwm scores  in matrix models
of “random ces”. random sequence ces were obtained from real ces by
reshuffling its dna sequence. matrix models for random ces were constructed
following the same procedure as for real ces. the procedure with random ces was
repeated  <dig> times, generating  <dig> models. pearson correlation in this case was
only − <dig>  .
random ces.  distribution of pwm scores for first and second
bss in real ces  and random sequence ces . scores
sm <dig> and
sm <dig> define the rectangle oabc and
perfectly separate high scoring ces. by reducing the scores , many additional true ces, but also a large number of
random ce are also covered by the rectangle oa′b′c′.
introduction of a sum of scores  greatly improves the
separation between real and random ces .  distribution of distances
between bss and sum of matrix scores in real ces . distance values
were averaged in intervals of score values , ,
,  and  . the trend line reflects
the dependence between pwm scores and distance between bss.

accuracy of the recognition method will obviously benefit when such mutual
dependence of bss is taken into account. from figure 1a it becomes obvious that better separation of real and random ces
cannot be achieved by vertical or horizontal lines but rather by a diagonal. the
diagonal corresponds to the sum of pwm scores, whereas vertical and horizontal
lines are minimal scores for both bss separately. combination of restrictions on
scores of both bss individually  and their sum  is one of the
key points of the method and formally described in equation .

recognition rule
mathematically this approach has to be described as follows. the diagonal or an
absolute value of the composite score is defined by:

  abscs=sm1+sm <dig>  

where sm <dig>  sm <dig> are pwm scores defined by
the ce model.

for the purpose of recognition we will use relative values for the composite
score:

  relcs=sm1−s1sm1+sm2−s1s <dig>  

where s <dig>  are the actual matching scores of pwms on
an investigated dna sequence. it is notable, that relcs may adopt
negative values when one or both bss of potential ce have higher pwm scores than
defined by the model . in such cases we say
that the potential ce matches the model better than it is minimally required.
alternatively, another bs may have lower pwm score than required by the model,
which corresponds to “high-low” phenomena described above.

to account for a relative positioning of bss in ce we add a third term to
:

  cs=sm1−s1sm1+sm2−s2sm2+λdm−d, 

where d is the actual distance between identified bss and
dm - distance defined by ce model.

considering the physics of dna-protein and protein-protein interactions, it can
be suggested that remotely located bss both might have higher affinity to their
tfs compared to closely located ones. despite the fact that dna may form loops
and bss distant by sequence may become close in 3d, we found this suggestion
relevant and subjected it to verification.

using all matrix models of ces the distribution of distances between bss
 and the abscs was calculated
. averaged distance between bss show
that ces that have longer distances between bss have on average a higher
abscs. linear regression coefficient between distance and sum of
scores equals  <dig>  with a 90% confidence interval . t-score of this
regression is  <dig>  with p-value of  <dig> . 90% confidence interval for
the slope value  equals , 95% – .therefore,
our assumption on dependence on distance and quality of bss within a ce can be
regarded as statistically relevant.

to make our method more stringent we considered both positive and negative
fluctuation of distance d around the dm as
unfavorable. coefficient λ in  was set to be equal to the slope
value of the trend line .

finally, a dna sequence is reported as a potential ce, when the following
recognition rule holds true:

  {sm1−s1sm1≤r1sm2−s2sm2≤r2cs≤rcsdm−ddm≤rd, 

where rcs, r <dig> 
r <dig> and rd are the
relaxation parameters for the composite score cs, pwm scores and the
distance respectively. a maximum stringency search is achieved with all these
parameters set to  <dig> 

input and output
to run matrixcatch, the user should supply  dna sequence in embl, fasta or
plain text formats and  should define search stringency. results are ordered
by p-value. threshold for p-value or expected frequency of ces
per 1kb can be optionally supplied. calculation of raw p-values and its
correction for multiple testing can be done using bonferroni , bonferroni
step-down , and benjamini and hochberg  procedures by the formulas:

  p−value=1−1−p⋅qdm−d 

  corrected_p−valueb=p−value⋅sequencelength 

  p−valuebsd=p−value⋅sequencelength−rank_ce 

  p−valueb&h=p−value⋅sequencelength/rank_ce, 

where p  is a frequency of the first  bs of a ce
found on a random sequence with pwm minimal score equals
s <dig> , and
rank_ce is the rank of ce in the output list sorted by
p-values before correction.

all p-value related parameters, namely p-value threshold, type
of p-value correction or frequency of ces per 1kb, can be adjusted
after the search in order to refine the output. matrixcatch produces a list of
potential ces, their positions, scores, p-values and respective links
to the original ces in the database. graphical visualization and machine
readable output is also provided.

in addition to the preloaded library users are encouraged to create, store and
search for their own ce models . to do this a user
should select pwms from the existing library, specify thresholds, orientations,
interspace distance and optionally give a description. such an element of
crowdsourcing allows a quick integration of novel data and its use by the
community. a single composite regulatory element found in a specific experiment
is already sufficient to be submitted into the system and used without a need
for a programming and/or an establishment of a separate website. as a gratitude
for such submissions, users who will use these models in their research are
requested to cite the work of the submitter.

RESULTS
comparison with other ce recognition methods
at first, we compared our method to other available methods for ce prediction.
compelpatternsearch  <cit>  is based on
comparison of an original sequence of ce with an investigated sequence. by
increasing the number of allowed nucleotide mismatches in both motifs and the
distance between them the accuracy of the method can be adjusted. another method
was specifically developed for the recognition of composite element nf-at/ap-1
 <cit>  with a score function based
on weighted logarithms of pwm scores and a fixed length of intermediate sequence
from  <dig> to 11bp. false positive rates were estimated on sequences of second exons
derived from the human genome, since they are supposed to comprise no regulatory
elements. in all tests the elements to be recognized were excluded from the
training data. all three methods were tested on the same dataset by the same
procedure.

receiver operating characteristic  curves of the three methods tested on
recognition of nf-at/ap- <dig> are shown in figure  <dig> 
roc-curves for another two ces  can be found in
additional file 1: figures s <dig> and s <dig>  these tests show
that matrixcatch in general outperforms the simple pattern based search used in
compelpatternsearch. compelpatternsearch performs similarly only when used with
most stringent parameters, i.e. when no mismatches are allowed in both bss and
length variation is not more than just a few nucleotides. relaxing parameters
results in a sharp increase of the false positive rate. already with ≥2
allowed mismatches per bs, compelpatternsearch becomes practically unusable due
to extreme number of predictions . matrixcatch performance is much more tolerant to parameter
relaxation. this also shows that matrixcatch is less subjected to an
over-training effect, since more knowledge is enclosed in ce matrix models
rather than just in the dna sequence of ce.
recognition of ce nfat/ap- <dig> 

unfortunately, many types of ces are represented by a single example. in
practical applications all are used for recognition, but for testing, obviously
at least two known ces of the same class are required. therefore, a
cross-validation for all elements is not feasible. we presented comparisons for
two classes nf-at/ap- <dig> and c/ebp/nfkappab that have the highest number of
examples. however, even for smaller classes the performance of matrixcatch is
evident .

comparisons with statistical methods
first let us define what we call known, novel and de novo regulatory
element. by known regulatory elements  we assume
those verified experimentally. by novel regulatory elements we assume those
identified by any kind of computational comparison but without experimental
verification on functionality. these elements can be found using similarity to
known ones  or solely by statistical
evaluations of motif frequencies in an investigated dataset . so, for example, matrixcatch uses a library of ce
models and hence finds novel composite elements. cma and modulesearcher use a
library for single sites  and find novel single sites but discover pairs
de novo. cismodule discovers single sites and pairs de
novo purely based on statistics. although these methods utilize
different approaches, from practical view one would like to know which method
to apply first to, for example, a set of dna sequences to have the highest
chances of true discovery. in such cases collections of known elements are
commonly used for evaluation of both library based and de novo
methods.

for testing of the performance of matrixcatch we selected well established
benchmark datasets  <cit> , and as a quality
measure, we chose the nucleotide-level correlation coefficient . we
preferred ncc over ppv , since the latter did not
accurately account for situations when, for example, a predicted module only
slightly overlaps with a real one or is much longer then a real one. instead ncc
reflects the sensitivity and specificity of predictions by counting the number
of correctly predicted nucleotides i.e. nucleotides that lie in an overlap of a
predicted and a real module .

the selected benchmark consists of transfac matrices related to the composite
elements to be identified, complemented by a number of “noise”
matrices . noise levels correspond to the number of the
additional matrices in a set. the “noise_99” series comprises all
pwms. matrixcatch was run with its default parameters, the entire library of ce
models and with pwm datasets provided by  <cit>  that correspond to the different noise levels. reduction
in the pwm library automatically directed matrixcatch not to use ce models that
comprise missing pwms. results obtained were submitted for evaluation
.
unfortunately, comotif  <cit>  converged to
equiprobable pwm  on all datasets. other tests showed
that comotif performs better on data consisting from a large number of shorter
sequences .

the results of the comparison are presented in figure  <dig>  it is evident that matrixcatch significantly outperforms all
other methods on all datasets. despite such a good performance, one should note
the different nature of these methods  and the results need to be interpreted adequately.
dataset. nucleotide level correlation scores  on the
transcompel dataset. the graphs show ncc scores at increasing noise
levels. values for cismodule could be calculated only for the
“noise0” dataset. for further details see .

matrixcatch was used with the entire ce library. it identified all ces in each of
the datasets , which would indicate a sensitivity of 100%.
however, we should point out that the identified ces are the same that were used
to build the models and matrixcatch by its definition always identifies the ces
used to construct the models. this is the major difference to comparisons in the
previous section, where respective ce models were removed from the ce library.
thus, comparing the sensitivity parameter is not fully appropriate here.

instead, specificities of the predictions should be compared. ncc score is
calculated upon all reported ces and its higher values in all categories for
matrixcatch indicate higher specificity. this can be interpreted in such a way
that matrixcatch not only identified all true ces in the dataset but also did
not report too many false hits.

however, if we assume that a dataset contains only regulatory elements
principally different from those in the library, priority should be given to
de novo identification methods. the practical application of
matrixcatch presented in the next section shows that the existing variety of
known ces is already sufficient to outperform statistical methods in most of
situations.

investigation of tissue-specific promoters
an experimental study of tissue-specific promoters was recently performed by
 <cit> . the authors investigated
the expression of genes triggered by alternative promoters in different tissues.
they could show that transcription from alternative promoters differs
significantly in most investigated cases. therefore, tissue specific promoters
found in that study represent a competitive example for bioinformatics analysis.
we will search for potential composite regulatory elements similar to known ones
using matrixcatch and novel combinations using other programs. the key question
is which program can identify elements that are most specific to the dataset of
interest.

using the data provided by  <cit> , 11
datasets of positive and negative promoters with a length of 500bp and 1kb that
covered regions − <dig> to + <dig> and − <dig> to + <dig> around the tss,
respectively, were generated . for the discovery of cis-regulatory modules,
methods reviewed by  <cit>  were selected.
out of eight programs, two are not available to date .
cluster-buster and cister could not be applied, since they require a single
sequence as input, but not a set. mcast identified very long modules with many
motifs. for instance, in the 500bp breast dataset mcast reported a module 355bp
long with  <dig> motifs as a top hit. though of very significant e-value,
this result seems to have little practical use. finally, only three programs,
cismodule, modulesearcher and cma in addition to matrixcatch were used for the
analysis.

the goal was to identify such a module that can be found in at least
min+ of positive promoters and in no more than
max– of the negative ones. if we denote
c+ and c–
the normalized number of positive and negative promoters comprising a module,
then the above can be formalized: c+ ≥
min+ and c–
≤ max–. several values for
min+ and
max– were fixed: , , , , .

all programs were run with default parameters except the following. the number of
single pwms in a module was set to  <dig> in cma, modulesearcher and cismodule. in
modulesearcher “number of top scoring modules to return” was set to
 <dig>  cma was set to output  <dig> pairs  and to optimize distance of
a module. both above programs used the transfac library of pwms. cismodule does
not require pwms, since it identifies them during the search. in summary, all
programs were set to find several modules each consisting of a pair of dna
motifs. since modulesearcher and cismodule cannot use negative datasets, the
results of all three programs were additionally optimized in order to maximize
the ratio c+/c–,
provided that the boundary conditions for c+ and
c– hold true. this was done by varying
independently the minimal required scores for both pwms in a module and the one
with the highest
c+/c– is
reported as a hit. matrixcatch was run with entire library of ce models and
relaxation parameters were adjusted for maximum
c+/c–.

we believe that this determination of the method performance is straightforward
and is most indicative in real applications. indeed, no common measures like
false positives, true negatives etc. can be calculated, since
regulatory modules are to be discovered de novo. tests on re-discovery
of known examples are presented above.

results of the application of the four methods are presented in tables  <dig>   <dig> and additional file 1: table s <dig>  as can be seen from table  <dig>  in each specificity group matrixcatch has found modules in more
datasets, compared to the other methods. for example, in a group
 matrixcatch found
ces in breast, heart, kidney and prostate promoters, while cma and
modulesearcher only in prostate promoters.

specificity level 
number of datasets of tissue specific promoters in which the programs
found at least one module with the required level of specificity.
the total number of datasets is  <dig> 

highest values of specificity

shown by the programs in different datasets. none of the programs
found modules in the datasets: cerebellum, liver, spleen and
testis.

out of four methods only matrixcatch was able to identify a regulatory element
with very high specificity . this ce could be recognized in  <dig> out of
 <dig> promoters active in prostate . as was identified in a study of chicken
myeloid cells both motifs of this ce are bound by c/ebp-related proteins
 <cit> . it is very important to
mention that c/ebp transcription factor was later found to upregulate metastatic
gene expression in human prostate cancer cells  <cit> . this demonstrates that
matrixcatch identified highly specific regulatory elements the functionality of
which was confirmed by several independent studies. in comparison, other
programs could identify modules only in  <dig>  or 12
 promoters. none of the methods found an element similar to c/ebp
binding motif. we may speculate that elements reported by statistical methods
may represent some functionality, but no other support than statistical
significance can yet be presented.

to emphasize the importance of the developed approach, we should mention that
this type of ce is represented by a single example. as can be seen from
table  <dig> newly discovered ces in prostate
promoters don’t show many conserved positions in either motif. approaches
based on mere pattern matching of the dna sequence of the ce itself  would
produce a huge number of hits, which renders predictions useless. matching the
motifs independently  will not help to reveal this ce
either, due to the low score of one of the bss. indeed, composite elements in
genes net <dig>  sulf <dig> mad1l <dig>  kiaa <dig>  sdr39u <dig> and col4a <dig> have one c/ebp site
recognized with a very low pwm score .
nevertheless, the second site, recognized with a high pwm score, contributes to
the overall composite score  of the pair. thus, in all of the above-mentioned
genes the composite score entailed specific recognition of the regulatory
element.

name
1
2
s


1


3
s


2


3
cs
p
sequence complementary to the original composite element
composite regulatory element c/ebp / c/ebp recognized in promoters of
genes active in prostate tissue. nucleotides with significant
conservation shown in bold  and italics
.

 <dig> names according to .

 <dig> beginning of the element relative to tss.

3s <dig>  - pwm scores for the
first and second c/ebp motif, cs - composite score.

altogether, using the approach presented here it became possible to build up a
matrix model for a singular example of a c/ebp/ c/ebp composite element and use
this model for recognition of new potential regulatory elements in prostate
promoters with high specificity. therefore, highly reliable experimental
knowledge is not dismissed due to statistical considerations.

we investigated potential composite elements identified with specificities
c+ ≥  <dig> , c– ≤  <dig>   for their biological relevance. ce
nf-kappab/ atf- <dig>  was found specific  to
promoters active in breast tissue and was described as activator of interleukin
 <dig> gene  <cit> . although neither nf-kappab
nor atf- <dig> per se exhibits any specific tissue specificity, the
nf-kappab family has shown to be active in human breast cancers  <cit> . taking into account that composite
elements often have their own transcriptional function  <cit> , this element may represent a promising example for
further investigations. another element c-myb/ets-1
, found in heart specific promoters,
contains ets- <dig> as one of the contributing factors, which has been shown to be
expressed during heart development in mouse  <cit> . the third element hnf-4α/ hnf-4α found in
kidney promoters 
is known to play a role in development of the liver, kidney and intestines.
altogether, these examples show that matrixcatch is able to identify potential
composite elements that are not only specific, but are also biologically
relevant to the investigated datasets. the biological knowledge behind is an
important advantage in comparison to methods based on pure statistics.

an interesting dependence on the input data is shown by the programs cismodule
and modulesearcher. modulesearcher identified regulatory modules substantially
in 1kb promoters, whereas cismodule in 500bp . such a behavior may impede the practical
applications of these methods since there is no agreement on a
“proper” length of a promoter. matrixcatch is more tolerant towards
the input data as well as to the optimization of parameters. results in
additional file 1: table s <dig> show that in general
matrixcatch finds composite modules in many specificity groups. there are just a
few cases when modules that discriminate positive and negative datasets are
found exclusively in one specificity group which corresponds to one specific set
of relaxation parameters. for example, modules found in pancreas and thyroid
promoters are probably false hits, since they can be identified only in the
specificity group , which may represent
an artefact of parameters optimization. as a rule, if matrixcatch identifies a
composite module it can be found in several specificity groups, which proves
greater tolerance to search parameters than in other methods.

discussion
investigation of transcriptional regulation of genes by bioinformatic methods is
widely used in biomedical research and the presented approach contributes to that
topic. the software matrixcatch is supplied with  <dig> matrix models of composite
elements, which represents the most comprehensive collection of known ces available
to date. the program has no restriction on the size of promoters and is suitable for
examination of a single short dna locus of particular interest or big datasets
representing the whole genomes. the search stringency can be easily adjusted via
several parameters. the program was tested for recognition of known composite
elements and compared with other programs on the established datasets. in all cases,
matrixcatch outperformed other methods. in a real study of tissue specific
promoters, matrixcatch identified a candidate composite element that is specific to
promoters active in prostate, which we offer for further investigation. other
methods identified hits with much lower specificity and for many tissues they were
not able to find any.

in the introduction we pointed out that the problem in developing ce recognition
methods lies in the extremely limited number of experimentally characterized and
documented ces. we may speculate that this could be a major reason why there is a
bias towards statistical methods rather then methods based on experimental examples.
in addition, many algorithms for the recognition of particular examples have no
software implementation  <cit>  or the announced
web resource is not maintained anymore  <cit> .
to the best of our knowledge, matrixcatch is the only ready-to-use application
available to date that is designed for recognition of known composite regulatory
elements.

one fundamental question is whether dna motifs constituting a ce and bound by
interacting protein factors are similar to those bound by the same factors
separately. this is an important issue, since it allows a generalization of the
search by recruiting the information available for the single binding motifs.
similar performance of our method and the one described by  <cit>   suggests no or
very minor changes of binding motifs, since the latter method uses exclusively dna
sequences of ces for motif recognition. this method definitely accounts for all
kinds of dependences between motifs - if any. but based on that principle,
recognition methods could be constructed for just a few types of ces, for  <dig> or  <dig> at
best, since statistics become a critical issue. we can speculate that some tf
binding motifs may be different in single sites and within composite elements, where
they are bound by a tf complex. there are cases when subsets of a specific motif of
single sites appear as constituents of ces  <cit> . however, data available to date do not provide sufficient
experimental evidences either to support or reject this. similar results of this and
the previous method  <cit>  suggest that single
binding motifs are at least not strongly changed, which allows to build a method for
recognition of many types of ces.

the presented approach has the advantage that already on the basis of any single
identified ce, a matrix model can be constructed, which will ensure a reliable
recognition. thus, existing limited although valuable knowledge on combinatorial
regulation of transcription can be used for the discovery of similar regulatory
elements in other genes and/or related genes in different organisms. together with
other methods, both statistical and library based, matrixcatch may serve as a basis
for more sophisticated combinatorial analysis of promoters, enhancers or other
regulatory regions, thereby helping to understand complex transcriptional regulation
of genes and reconstruct complete hierarchical regulatory models.

CONCLUSIONS
here, we have presented a novel methodology for the identification of composite
regulatory elements in promoter sequences. the software implementation matrixcatch
is supplied with a library of  <dig> matrix models used for recognition. that
represents the widest scope of known ces available to date. additionally, this
library can be easily extended via user supplied models. investigation of
regularities encoded in known composite elements helped to improve the specificity
of the identification compared to other methods, that is proved on an established
benchmark and real genomic data. another advantage of the approach is that on the
basis of any single newly discovered ce, a matrix model can be constructed and used
for the recognition. a practical advantage of this method compared to statistical
methods is the direct biological interpretation of the identified results.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
ivd: implementation of matrixcatch, construction of matrix models, writing the ms;
ovk: initial data management, expert advice on structure of ce; evd: critical
comments on the program and the ms; aek, ew: conceptual idea for matrixcatch and
writing the ms, sw project coordinator and writing the ms. all authors read and
approved the final manuscript.

supplementary material
additional file 1
supplementary figures and tables.

click here for file

 additional file 2
dataset of tissue specific promoters.

click here for file

 acknowledgements
we thank michael jarek  for the web server installation and andreas
dötsch  for granted computational facilities. the work was partially
supported by the bundesministerium für bildung und forschung . the
work of aek was funded by the federal program “living systems”,
state contract , by fp <dig> project “syscol” and by bmbf
project “gerontoshield”.
