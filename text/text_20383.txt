BACKGROUND
systems biology aims to identify and quantify the molecular components of dynamic biological networks, determining interactions between the various players and integrating the resulting information into system models  <cit> . this research necessitates the use of an ensemble of correlative measurement technologies. ideally, data should be acquired from groups of elementary samples, such as single cells, using high throughput technologies, in order to disentangle biological noise due to the stochastic nature of interaction networks  <cit> . an experimental environment of this type will generate large quantities of heterogeneous but related data. this presents many challenges, including the key problem of tracking and integrating measurements made on a series of related samples across diverse technological platforms.

a number of software tools are available to handle data originating from high throughput experimental set-ups. these are technique specific. examples are, omero for light microscopy  <cit> , leginon for electron microscopy   <cit>  and prism for high-throughput proteomics  <cit> . difficulties arise when several instruments and/or complex  preparation steps are required for the research, as is often the case in a micro-fluidic pipeline. one way to create a multi-instrument solution would be to amalgamate the domain-specific software systems. the disadvantage is that combinatorial problems caused by required interaction between and coordination of the individual software packages, will increase rapidly with the number and complexity of the technologies involved. furthermore, the correlation of individual datasets in relation to space and time will become progressively more difficult.

flexible data management systems such as openbis   <cit>  offer a partial solution, providing scalable data storage and retrieval, metadata integration and searching, and data source tracking. although the platform-independent, web-based graphical user interface  of openbis allows user management, authorization and configurable database browsing, it does not allow in depth data handling and does not support direct instrument control. these shortfalls are overcome by the new software presented in this paper, openbeb .

the requirements to be met become apparent when the following typical example is considered : eukaryotic cells growing in miniaturized petri dishes and are subjected to pulse chase experiments. during the experiment, the cells are observed by time-lapse light microscopy . at specific time points, individual cells are lysed and prepared for further analysis by em. subsequently, specific features of the images, e.g., fluorescence signals detected by lm, are tracked over time. this scenario has three requirements:  data acquisition and instrument control must be tightly integrated.  various data types must be collected and handled, e.g., image data and time-resolved “wave” data.  the individual steps of the experiment must be correlated in space and time, e.g., em data of an individual cell must be assigned and correlated to series of time-lapse lm images. openbeb provides a flexible, data-type agnostic core framework that performs the tedious “house keeping” tasks demanded, such as data management and the creation and maintenance of a unified hierarchical coordinate  system. the latter establishes the relationships between experimental results that have to be retained in multi-scale space and time, a fundamental requirement for any correlative measurement. furthermore, openbeb provides a plug-in manager that supports plug-ins for data-type specific tasks and instrument control. an internal macro system allows the control and coordination of these individual technology-specific modules. furthermore, plug-ins can be used to connect openbeb to databases such as openbis, facilitating data storage and synchronization.

openbeb furnishes the end-user with an environment for instrument control, data acquisition, visual inspection, advanced visualization, annotation, information correlation and metadata management. of advantage for the developer, the software architecture allows the rapid integration of new instrument-specific modules, facilitating the use of correlative methods for systems biology, e.g., complex micro-fluidic set-ups.

implementation
central goals of openbeb are to provide both an environment allowing the fast integration of correlative measurements and a platform allowing the rapid development of control-software. the extensible openbeb framework is implemented in labview using object-oriented “loose coupling” principles. the latter is achieved via a plug-in structure. the programming language, g, makes it possible for researchers with little or no programming experience to develop their own extensions with minimal effort. the extensive libraries of the labview environment for instrument control, data acquisition and signal processing are optimal for the implementation of the automatic data acquisition essential to realize high throughput.

openbeb consists of two parts :  a static core program, responsible for data and metadata handling and the coordination of different modules.  a dynamic plug-in architecture. plug-ins supply the case-specific functionality of openbeb, and are dynamically loaded by the plug-in manager during program start-up. they provide the tools of the browser, such as data-type specific libraries, importers, data visualization modules , instrument controllers as well as database bridges, e.g., for openbis. this modular architecture allows maximum flexibility and scalability.

core program
a queued message state machine drives the core program . the central message queues can receive commands from several sources, such as the gui, the macro-parser or the application server via a tcp based protocol. the latter allows platform-independent communication with other software packages or remote instrument controllers and computers . complex operations can be controlled by text-based macros that are located in the application support folder and can be adjusted by users if needed . the data manager organizes the import and management of data in a data-agnostic manner and can handle arbitrary types of data. the data-types themselves are defined in plug-ins as described below. furthermore, the data manager of the core program maintains one or more local containers for data and metadata called “bundles”. bundles rely on a hierarchical file structure and can be directly accessed by any program without the need of the openbeb software. to avoid conflicts with automated processes, access to bundles or data collections they contain via the gui can be blocked. data-management tasks are performed centrally by the data-manager, which can be reserved by a process, e.g., a macro . the data manager calculates md <dig> checksums during data import as a control measure to check the integrity of the raw data. openbeb never changes the raw data. furthermore, the data manager allows transparent, lossless data compression by the zip algorithm  <cit> . the metadata manager organizes the metadata, which are stored in an xml format. the metadata includes the embedded metadata of the raw data, which can be quite extensive for some data types. in addition, the metadata manager supports pre-defined metadata annotations called “protocols”, based on a controlled vocabulary. these predefined protocols are located in the application support folder. this support folder is automatically updated by the update manager during openbeb start-up, keeping all components, e.g., plug-ins and protocol definition files, up-to-date with a server-side repository. last but not least, a central error handler and logging system monitors all activities of both the openbeb core program and the plug-ins.

macro control and modules
openbeb includes a simple macro interpreter, which also allows unified control of the modules provided by plug-ins. the macro language is primarily an inter-module processing and coordination system. it supports both the use of variables and branching and looping, provides primitives for graphical user interaction , and supports communication between modules. a tcp based application server is integrated to handle applications of greater complexity or to provide an interface to existing software.

importantly, the macro interpreter has an open modular architecture. every plug-in can provide one or several modules that can be addressed by the macro interpreter. every module implicitly consists of a queued state-machine architecture and runs independently; this is particularly important for instrument control. a module is associated with a name and must follow specific rules for command and error handling. furthermore, a minimum set of commands, e.g., for process coordination, must be supported. the coordination of different modules is achieved using synchronization primitives that are available in the macro language.

a macro panel  simplifies the creation and editing of macros as well as task handling; start, execution and scheduling . the debug menu provides information about the last run of the selected macro, such as the variables used. the “cron “ tab entry configures a cron-like server  for the time specific execution of macros. this is useful to trigger macros to prepare instruments ahead of usual working times, e.g., to carry out routine cleaning procedures or to activate temperature controls.

local repository
openbeb maintains a local repository for raw-data, metadata and cache files. this is accessible by standard tools of the operating system. standard formats are used, except for the instrument dependent raw-data and the cache files. the local repository can be browsed by a file-browser, such as the macintosh finder or windows explorer, therefore, the entire contents are accessible to 3rd party software.

openbeb organizes data in “collections”, i.e., containers that can but do not have to host a series of raw datasets and associated metadata files. in the simplest case, a collection only consists of a metadata file. collections can contain other collections, and can thus be organized in a hierarchical structure. the upmost collection, the root of the collection hierarchy, is called a “bundle”. a bundle is a collection associated with a path in a file-system. the structure of the openbeb bundle is outlined in figure  <dig>  several bundles can be attached to and maintained by an openbeb instance.

note, that the collection hierarchy of a bundle does not necessarily reflect the workflow of experiments. however, the workflow is preserved in the database system, e.g., openbis  <cit> . a bundle is a work-snapshot and can combine collections from different spots in the workflow, e.g., a bundle can contain collections of original data obtained by different techniques and collections that amalgamate the results.

annotating metadata, hierarchical coordinate system and graphical annotations
the metadata handling system is an important aspect of openbeb. every collection and dataset contains separate metadata. the xml-based metadata files are organized in several sections :  protocols; provide domain and technique specific information. protocol templates based on a controlled vocabulary are organized centrally in the application support folder and are automatically updated during program start-up.  user descriptions; contain additional user information, such as free text annotations and a rating system.  database id  and coordinates; indicate the relationship between collections and the data sets they contain. the hierarchical coordinate system  defines the physical relationship between different experiments and datasets in space and time .  dataset properties .

in addition, openbeb supports graphical annotations by creating portable network graphics files . this metadata includes representations required for each dataset; both a thumbnail and a preview file are created. further, graphically annotated views can be stored .

metadata entries can be added in various ways, e.g., by using the gui . automatic annotation is of importance for high throughput measurements and can be performed either by directly accessing the xml metadata-files through openbeb, or by writing an attribute file to accompany the raw data. the latter allows the transfer of embedded metadata information from the raw-data file into the explicit metadata of a dataset.

the metadata file also contains a description of the dataset properties. these data properties are very flexible and support an arbitrary number of dimensions. they are designed to describe equally spaced data, but are not limited to this. a dimension contains a name, a type , a unit, a start and spacing  and a length . the data elements themselves are described by the data-type; consisting of a name, unit and type  and a precision that indicates the memory structure of the data, e.g.,  <dig> bit floating point.

the coordinate system is hierarchical  and allows the correlation of different experiments, each measuring a specific property of the same subject. collections or datasets can define the root of a coordinate hierarchy, or can be at a specific point in the coordinate system relative to the parent collection, e.g., using a different scale . note: the coordinate systems are linear and the coordinate vectors are additive . an internal timer that uses an ntp  client for calibration provides a clock for absolute time stamps. as long as the same ntp server is used, this allows the synchronization of measurements made using different instruments.

fields that are not applicable must be described as nan . error estimates can be provided for every parameter.

error handling
openbeb implements centralized, system-wide error handling . a log server maintains a log of all events taking place in all running modules, i.e., in both the core program and the plug-ins. a central error handler reacts to errors. optionally, errors can be reported to an issue tracker and viewed via a gui. different levels of error tolerance can be set to allow automation.

plug-in manager
the experiment-specific functionality of openbeb is provided by plug-ins. a plug-in can provide functionality to the core program in two ways:  by using functions to override standard core routines, e.g., importing a dataset by an importer.  by using so called “modules”, i.e., a queued state machine that can be addressed by the macro interpreter as described above. plug-ins are instantiated during program start-up and destructed when openbeb quits. before loading, a plugin.ini file is read to confirm compatibility and provide plug-in descriptions for the user. the plug-in is then initialized, e.g., standard settings are read from the file-system or plug-in-specific modules are started. note that either plug-ins that function as stand-alone programs or plug-ins that call other 3rd party software can be written for instrument control. the homepage of openbeb provides specific information and tutorials on how to write plug-ins. the available plug-ins are distributed together with their source code and can thus easily be studied or changed locally.

the openbeb plug-ins are organized hierarchically :  viewporttype plug-ins are libraries providing data-type definitions .  library plug-ins do not provide data-type definitions but basic functionalities, such as data-manipulation routines or basic instrument control functionalities. other plug-ins can be dependent on viewporttypes or libraries.  viewports are plug-ins for data visualization. they are always linked to a data-definition library and provide a module called “viewport” which must understand specific commands such as ‘display data’ or ‘unload data’. note that every data-definition library can have several linked viewports allowing the visual representation of different aspects of a data type, e.g., the display of an image in real or fourier space .

the plug-ins are loaded during program start-up, the position in the table indicates the load order. (): optional.

the plug-in manager  displays information about all installed plug-ins and allows them to be activated/deactivated at will . every plug-in also owns a preferences gui that can be accessed by the plug-in manager.

RESULTS
the use of openbeb is first demonstrated for administrators and plug-in developers. a typical scenario describing how openbeb is used to combine live cell microscopy, microfluidic control and a new approach for visual proteomics called “spread and lyse”  <cit> , is then presented.

installation, administration and plug-in development
installation and update
openbeb is installed in two steps: first, a standard installer  installs the runtime library and the core program . second, the core program downloads and installs the application support folder containing the plug-ins, metadata template definitions, macros and libraries. this folder is different for every user and is located in a directory with full user access. during openbeb start-up, the application support folder is updated to the newest version from a server-side repository . this allows the metadata templates and plug-ins to be updated in a centralized way for a workgroup. different repositories can be specified for different work environments. an administration plug-in facilitates the management of the application support folder .

protocol management
protocols are managed by a gui provided by the administration plug-in . protocols are created in two steps: first, a controlled vocabulary library is defined; the same vocabulary is used for all protocols. second, the protocols are assembled from the controlled vocabulary. an entry in a protocol can be modified; the parent title can be changed as well the standard value of the entry. note, that every vocabulary entry is associated with a unique identifier, which allows protocols to be automatically updated if a controlled vocabulary entry is changed.

plug-in development
templates and tutorials are provided on the software homepage http://www.openbeb.org. a helper program called “openbeb devcenter”  that facilitates the batch compilation of plug-ins and editing of the plug-in initialization file, is also downloadable .

to create a plug-in, a labview project is created including the openbeb core and any other openbeb library required. a plug-in must provide a minimal set of override functions, which are called during execution. the specific functions that must be present depends on the type of plug-in .

example: live cell imagining and “lyse and spread” visual proteomics
the use of openbeb together with our recent hardware developments that connect micro-fluidics to em for visual proteomics  <cit>  is reported. in the demonstration experiment adherent eukaryotic cells are cultured, and monitored by time-lapse lm throughout. at specific time points, pulse chase investigations are performed and, after a chase time, individual cells are lysed by electroporation  <cit> . subsequently, the cell lysate is transferred into a microcapillary, prepared for em and imaged for analysis by “lyse and spread visual proteomics”  <cit> . the presentation focuses on the application of openbeb using the gui, and demonstrates some typical aspects of the program.

main window of the openbeb gui
openbeb can be run headless and controlled via the application server, or by a gui . the main window of the gui has three panels namely the viewport , the tools and navigation panel  and the management and metadata panel for core program control .

creating and managing collections, instrument control and data acquisition
bundles and collections are managed using the management panel of the metadata tab control . figure  <dig> depicts the user interface that allows a new collection to be initiated . a typical workflow combining cell culturing, time-lapse lm imaging and visual proteomics by em is shown . the responsible plug-ins are indicated , and the resulting collection hierarchy is depicted . the plug-in controlling live cell imaging and sample preparation for em, is shown as an example .

note, coordination between the different measurement domains is crucial, and is achieved by the hc system: as an example, the cell culture defines a  coordinate system in x and y and the lm images can be calibrated accordingly. subsequently, an individual cell imaged by lm is selected for further experiments, e.g., lysis. the new data is stored in a sub-collection . the data from this analysis define a sub-coordinate system; this sub-coordinate system depends on the root coordinate data of the mother collection . together, this defines a hc system as described above. in other words: to find the soccer stadium, latitude and longitude “gps” coordinates are reasonable, to find a player on the soccer field, a rectangular coordinate system with the origin at a corner is better suited. the two systems define a hc system.

data browsing and visualization
various viewport plug-ins are available for data visualization. the type required depends on the data-type. data types are defined in so-called viewporttype plug-ins .

three viewport plug-ins are currently provided for the visualization of scientific greyscale images . the first visualizes images in real space and allows the addition and adjustment of a look-up table as well as the visualization of the greyscale histogram . the second calculates and displays the power-spectrum of the image data. this is useful to evaluate the contrast-transfer function of the imaging device . the third uses the data values as height information and draws an interactive surface plot representation . note, that viewport data visualization profits from the rich libraries provided by the labview environment, facilitating the development of such plug-ins.

data annotation and metadata management
openbeb includes a comprehensive metadata management tool. metadata can be assigned to collections, datasets and, depending on the data-type, to frames of a dataset stack, e.g., time series. annotations can be created or modified using the gui . individual annotations can be written to collections  and dataset files . if supported by the importer, the metadata embedded in the raw-data file is displayed . furthermore, the data visualization provided by the different viewports can be stored as “views”  that can also be graphically annotated if required . a batch-annotation tool facilitates changes to the metadata of selected data series .

database synchronization with openbis
openbeb supports database synchronization plug-ins; a standard plug-in to synchronize with an openbis database is presented here. this plug-in lets openbeb transparently store a user’s local work on a server, which has several benefits:  it makes the user’s work accessible to other team members or collaborators.  it protects against data loss. having a second copy of the data on a server enables data recovery in the event of hardware failure or loss. the server, which is managed by a system administrator, is typically configured to make a nightly back up.  synchronization with a server ensures that work remains accessible beyond the duration of a phd . storing the data on a server, along with any required contextual metadata, makes it possible for future team members to understand and build upon the results of present or previous team members.  it further increases the scalability of the overall system as only recent data has to be kept locally in openbeb, while older data can be offloaded to openbis.

the data synchronization plug-in for openbis is a standard plug-in supplied with openbeb . the openbis data synchronization plug-in stores the raw-data and the accompanying metadata in openbis. just pushing the data to the server is not sufficient; information about the experiment that produced the data and the biological and technical samples that were measured is required as well. to reinforce this connection, the openbeb synchronization process creates an experiment and sample in openbis. information about the experiment and sample are important for data-provenance tracking.

limitations and comparison to other software
the functionality of openbeb depends on the available plug-ins. currently, two viewporttype families are provided, each defining a data-type; one is for greyscale images , the other is for “wave” data providing support for equally spaced measurements, e.g., a time resolved signal. further, to a certain degree available plug-ins for hardware control are inherently tied to the hardware and communication protocols of a local set-up. accordingly, the instrument and data-acquisition control system presented in figure  <dig> is directly linked to specific hardware developed in-house, and limited to this specific setup. however, the extensive libraries for data acquisition, processing and visualization of labview make it easy to develop new plug-ins, and openbeb hardware integration via library plug-ins allows a high degree of code re-usage. furthermore, the core system of openbeb facilitates the integration of independently developed modules.

to our knowledge, openbeb is the only data-agnostic browser that has both developers and the end-user in mind. it complements “single domain” software solutions  <cit> . use of openbeb can provide the unified control and tight integration essential to maintain the temporospatial relationship of correlated experiments. combining the data-type independent housekeeping tools offered by the openbeb core program with the flexibility of the plug-in system makes this possible.

CONCLUSIONS
openbeb is a tool for correlative experiments in systems biology. it allows instrument control and provides a bridge between biological experiments, annotation and synchronization with databases. the software is  for end-users performing automated  experiments and  for developers requiring a framework to write instrument control and data-registration plug-ins. the latter inherently benefit from the “house-keeping” data-management and annotation tools of the openbeb core program. the plug-in based, loose coupling and the open modular architecture of the macro subsystem make openbeb highly flexible and scalable. further data-type plug-ins will be implemented in the future, e.g., to directly access mass-spectrometry data.

availability and requirements
the openbeb core program has the following requirements and is available as indicated:

project name: openbeb

project home page:http://www.openbeb.org

operating system: mac os x, windows xp, 7; will be compiled on linux

programming language: g , java

other requirements: labview runtime  <dig>  java. minimal screen-size of  <dig> × 720 pixel

license: apache license 

any restrictions to use by non-academics: no restriction, however restrictions may apply for specific plug-ins.

abbreviations
openbis: open biological information system; openbeb: open biological experiment browser; gui: graphical user interface; hc: hierarchical coordinate system; em: electron microscopy; lm: light microscopy; ntp: network time protocol.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
tb developed the software concept and wrote most of the core software and plug-ins; ns developed the instrument plug-in connecting live cell imaging, microfluidic based cell lysis and sample preparation for visual proteomics ; cr, ke and br critically reviewed openbeb progress, developed/maintained openbis and created the openbeb-openbis bridge; ab, sr, pr, kng, hs, sam tested the software and/or provided significant feedback during the software development. all authors were involved in the manuscript preparation. all authors read and approved the final manuscript.

