BACKGROUND
protein structural class prediction problem is defined as categorizing a given protein into one of the four structural classes namely, all-α, all-β, α + β, and α/β  <cit> . knowledge of the structural classes of proteins can also provide important information about their functionalities and overall folding types  <cit> . therefore, protein structural class prediction problem is considered as an important step towards the protein structure prediction problem. despite the importance of this problem, finding a fast and accurate computational approach to solve this problem when the sequence similarity rate is low still remains an unsolved problem for bioinformatics and computational biology.

during the past two decades, a wide range of studies, using machine learning-based methods, have been conducted to solve this problem  <cit> . these studies can be categorized into two groups. the first group consists of studies that have tried to address this problem by proposing novel classification techniques  <cit> . they proposed a wide range of classification techniques based on different learning algorithms such as, bayesian based learners  <cit> , meta-classifiers , support vector machines  , artificial neural network  , and ensemble classifiers . among a wide range of classification techniques used to tackle this problem, svm classifier has attained the best results for this task  <cit> . the second group consists of studies that have mainly focused on proposing novel features that capture local and global discriminatory information to address protein structural class prediction problem such as sequence based information , pseudo amino acid composition , physicochemical-based information , and structural based information . the most important enhancements in protein structural class prediction accuracy have been based on relying on these techniques rather than exploring the impact of classification techniques. these recent enhancements were mainly because of extracting features from position specific scoring matrix  profiles  <cit>  as well as structural information extracted from the predicted secondary structure of proteins  <cit> .

the most significant enhancement by solely relying on the pssm for feature extraction was achieved by  <cit> . they used pssm profiles to extract sequence order information based on the concepts of dipeptide composition, auto covariance and composition of the amino acids. they used entire protein sequence as a general entity to extract these features. hence, the auto covariance and dipeptide composition calculated along an entire protein sequence were used as its local descriptor. further enhancement for protein structural class prediction accuracy has been achieved by including structural information extracted from the predicted secondary structure of the proteins using psipred  <cit> . by adding these features to the extracted features from the pssm, the protein structural class prediction accuracy has been significantly improved especially when the sequence similarity rate was low  <cit> . similar to the features extracted from the pssm, the whole protein as a general entity was used to extract these features as well. despite all the recent efforts on extracting effective features to capture local and global discriminatory information from evolutionary and structural profiles, the protein structural class prediction accuracy have not been improved significantly since the study of mizianty and kurgan in  <dig>  <cit> .

in this study, we propose segmented auto covariance and segmented distribution feature extraction methods to capture more local sequence order information from evolutionary and structural profiles. we also employe the concept of occurrence and composition feature groups to capture global sequence order information based on evolutionary, and structural profiles. first, by solely relying on the pssm profiles for feature extraction, we enhance the protein structural class prediction accuracy by over 15% and 5% for 25pdb and  <dig> benchmarks respectively compared to similar studies  <cit> . these enhancements highlight the potential discriminatory information embedded in the pssm that have not been adequately explored in the literature. then, by exploring our proposed feature extraction techniques to include structural information derived from the predicted secondary structure using spine-x  <cit> , we achieve up to  <dig> % and  <dig> % prediction accuracies respectively for 25pdb and  <dig> benchmarks and enhance the overall protein structural class prediction accuracy even further by  <dig> % and  <dig> % better than previously reported results found in the literature  <cit> .

benchmarks
to evaluate the prediction performance of our proposed approaches, we employe two benchmarks namely 25pdb and  <dig>  these two benchmarks have been widely used for protein structural class prediction problem. the 25pdb was introduced by  <cit>  consisting of  <dig> proteins with less than 25% sequence similarities in average . this benchmark extracted from 25% pdbselected which includes high-resolution non-homologous proteins from the protein data bank   <cit> . therefore, it is considered as an appropriate representative of benchmarks consisting of proteins in twilight zone  for protein structural class prediction problem. hence, in this study, the 25pdb benchmark is used as the main source to investigate the effectiveness of our proposed model.

the other benchmark employed in this study is known as the  <dig> benchmark. the  <dig> benchmark was introduced by  <cit>  consisting of  <dig> proteins with less than 40% sequence similarities. this benchmark was modified in later studies to address further corrections of structural classification of proteins   <cit>  and  <dig> of its proteins were removed  <cit> . therefore, later version of this benchmark consists of  <dig> proteins. sequences in this benchmark have lower resolution than proteins in the 25pdb benchmark. therefore, despite higher sequence similarity in average among proteins in this benchmark compared to 25pdb benchmark, similar  protein structural class prediction accuracies has been reported for  <dig> benchmark compared to 25pdb benchmark  <cit> . since, this benchmark has been widely used to investigate the performance of the methods used for protein structural class prediction problem, it is also adopted here to compare our achieved results directly with previously reported results found in the literature  <cit> . employed benchmarks in this study and the number of proteins belonging to each structural class are shown in table  <dig> table  <dig> the properties of  <dig> and 25pdb benchmarks.

α/β
α + β


feature extraction methods
in this study, we use pssm profiles to extract evolutionary-based information as well as predicted secondary structure using spine-x to extract structural-based information. pssm is calculated by applying the psi-blast  <cit>  in which its cut off value  is set to  <dig>  on our explored benchmarks  protein data base). given a protein sequence, pssm produces the substitution probability of the amino acids along its sequence based on their position with all  <dig> amino acids. pssm consists of two l ×  <dig> matrices . the first matrix is called pssm_cons and gives the log-odd of the substitution probability. the second matrix is called pssm_prob and gives the normalized substitution probability for each amino acid  <cit> .

we also use predicted secondary structure using spine-x which was recently proposed by  <cit>  and attained better results than psipred on predicting protein secondary structure . given a protein sequence, spine-x produces a l ×  <dig> matrix  including the normalized probability of contribution of a given amino acid based on its position along the protein sequence to build one of the three secondary structure elements namely, α-helix, β-strands, and coils. it also return a transformed version of the protein sequence  in which each amino acid along the protein sequence is replaced with h , e , or c  based on its tendency to incorporate in building one of these secondary structure elements. we will refer to this sequence as the structural consensus sequence. it is expected that predicted secondary structure using spine-x provides significant structural information for the protein structural class prediction problem similar to or even better than psipred due to its better performance  <cit> .

consensus sequence-based occurrence
to provide global discriminatory information about the sequence order of the amino acids along a protein sequence, we first extract the occurrence of the amino acids from the evolutionary consensus sequence as well as occurrence of secondary structure elements from the structural consensus sequence. as it was mentioned earlier, the structural consensus sequence is produced as one of the output of spine-x. the evolutionary consensus sequence is calculated based on the pssm as follows. to extract this sequence, we replace a given amino acid along the original protein sequence  with an amino acid with maximum substitution probability in the row corresponding to the location of that amino acid in the pssm . this is done using the following two steps. in the first step, the index is found as:  <dig>  

where pij is the substitution probability of the amino acid at location i with the j-th amino acid in the pssm_cons. in the second step, we replace the amino acid at i-th location of original protein sequence by the j-th amino acid to form the consensus sequence. note that the pssm_cons is used in this study for feature extraction  as it was used in the literature  <cit> .

after calculating evolutionary consensus sequence, we count the occurrence of each amino acid  along this sequence and produce corresponding feature group . similarly, we calculate the occurrence of each secondary structure element  in the structural consensus sequence and produce the corresponding feature group . occurrence feature group as the global descriptor of the proteins is used in this study instead of composition of the amino acids  since it maintains the length information which is disregarded in the composition feature group  <cit> .

semi-composition
in this method, we calculate semi-composition feature group from both pssm and spine-m. it is called semi-composition because instead of using the protein sequence directly to calculate the composition of each amino acid along the protein sequence , we calculate the summation of the substitution probability for each amino acid directly from the pssm  or normalized frequency of each secondary structure element from the spine-m. the semi-composition derived from the pssm  is calculated as follows:  <dig>  

in the similar manner, we calculate the semi-composition of each secondary structure element by adding the normalized frequencies of the corresponding element from the spine-m  as follows:  <dig>  

where sij is the normalized probability of the occurrence of the j-th secondary structure element at location i of the protein sequence in the spine-m. it was shown that using semi-composition method is able to provide more discriminatory information compared to extracting composition of the amino acids feature group from the original protein sequence  <cit> . this feature group is also able to provide important global discriminatory information about the substitution probability of the amino acids as well as normalized frequency of secondary structure elements.

segmented distribution
this method is specifically proposed to add more local sequence order information about how the amino acids based on their substitution probability with each other  as well as their tendency to incorporate in one of the secondary structure elements  are distributed along the protein sequence. we propose this segmentation method in the manner where segments of a protein sequence are of unequal lengths and each segment is represented by a distribution feature which is computed as follows. first, for the pssm, to extract the segmented distribution feature group , we compute the total sum of substitution probability of the j column of the pssm . then, we start from the first row of the pssm and compute the partial sum of the substitution probability of the amino acid amino acid j, for the first i amino acids which is given by . using the distribution factor fp , we find out the maximum value  of index i such that partial sum s <dig> is less than or equal to the fp% of total sum . thus we can say that the first ?6? substitution probabilities contribute to fp% of the total sum . we use ?6? to define the ending location of the first segment, while its beginning point is taken to be  <dig> . the distribution feature of this segment is given by ?6?. in a similar manner, we find out the number of first  amino acids of the protein sequence that contribute to 2fp%, 3fp%, ..., 50% of tj , respectively. indices , are used to define the ending locations of segments  <dig>   <dig>  ..., 50/fp , respectively; while the beginning location of all these segments remains to be  <dig>  hence, the distribution features for these segments are computed as . note that we have thus computed 50/fp distribution features by processing the protein sequence starting from the first row of the pssm in downward direction. we repeat this process starting from the last row of the pssm in upwards direction to get another set of 50/fp features . thus, the total of 2×  = 100/fp distribution features are computed for each column of the pssm.

the distribution factor  is a parameter which is determined here experimentally. for this, three values of fp  are investigated. thus there will be  <dig>   <dig>  and  <dig> features for fp =  <dig>   <dig> and  <dig>  respectively for the j-th column of the pssm. since there are  <dig> amino acids  we produce  <dig> ×  <dig>   <dig> ×  <dig>  and  <dig> ×  <dig> features corresponding to fp =  <dig>   <dig>  and  <dig>  respectively. in the similar manner, we calculate the segmented distribution of the normalized frequency of the secondary structure elements from the spine-m  using fs =  <dig>   <dig>  and  <dig>  and extract  <dig> ×  <dig>   <dig> ×  <dig>  and  <dig> ×  <dig> features in total for all three elements, respectively. this procedure is shown in figure  <dig> figure  <dig> 
feature extraction scheme using the segmented distribution method.



segmented auto covariance
the concept of auto covariance have been widely used in the literature to capture local sequence order information and attained better results compared to similar methods used for this task such as dipeptide composition  <cit> . pseudo amino acid composition based features are good examples of these types of features  <cit> . these features have been computed using the whole protein sequence as a single entity for feature extraction. therefore, they are not able to adequately explore the local sequence order information embedded in the protein sequence  <cit> . in the present study, we extend the concept of segmented distribution features as described in the previous subsection to compute the auto covariance features from the segmented protein sequence. this is done to provide more evolutionary and structural sequence order information both from the pssm and spine-m. first for the pssm, we segment the protein sequence using distribution factor of 25%  until reaching to fp =  <dig> from each side . using a procedure similar to the one described in the previous subsection in which fp =  <dig>  we calculate . these indices are used to divide protein sequence into four segments as follows: from the first amino acid  to ?6?; from the first amino acid  to ; from the last amino acid  to ; and from the last amino acid  to . then we calculate kp  numbers of auto covariance coefficients for each of these segments as follows:  <dig>  

where, pave, j is the average substitution probability for the j-th column in the pssm . note that  <dig> × kp auto covariance coefficients are computed in this manner . we also compute the global auto covariance coefficient  corresponding to the j-th column to provide more information as follows:  <dig>  

thus, we have extracted a total of  auto covariance features in this manner . therefore, for pssm, for all of the amino acids  segmented auto covariance of substitution probability of the amino acids are extracted and combined to build the corresponding feature group  features in total). this procedure is also repeated for spine-m in the similar manner . for all three secondary structure elements we calculate segmented auto covariance of normalized frequency of secondary structure elements as follows:  <dig>  

where, save, j is the average substitution probability for the j-th column in the spine-m. similarly, the global auto covariance corresponding to the j-th column in spine-m is computed and added to this feature group as follows:  <dig>  

combining spine-seg and spine-ac, we build spine-sac feature group consisting of  <dig> × ) features in total .

support vector machine 
svm was introduced by  <cit>  aiming to find the maximal margin hyperplane  based on the concept of the support vector theory to minimize the error. it transforms the input data to higher dimension using the kernel trick to be able to find support vectors . the classification of some known points in input space xi is yi which is defined to be either - <dig> or + <dig>  if x′ is a point in input space with unknown classification then:  <dig>  

where y′ is the predicted class of point x′. the function k() is the kernel function; n is the number of support vectors and ai are adjustable weights and b is the bias. this classier is considered as the state-of-the-art classification techniques in the pattern recognition and attained the best results for the protein structural class prediction problem  <cit> . in this study, svm classifier implemented in the libsvm toolbox using radial base function  as its kernel is used  <cit> . rbf kernel is adopted in our experiments due to its better performance than other kernels functions . rbf kernel is defined as follows:  <dig>  

where γ is the kernel parameter, xi and xj are input feature vectors. in this study, the γ in addition to the cost parameter c  of the svm classifier are optimized using grid search algorithm implemented in the libsvm package. the grid search algorithm tries various pairs of γ and c values and selects the values with the best classification accuracy  <cit>  . the range of gamma and c parameters to be searched in this algorithm are taken to be their default values used in the svmlib toolbox . it is a simple algorithm as it has just two parameters to optimize . despite its simplicity, it has been shown to be an effective method to optimize these parameters  <cit> .

RESULTS
we first investigate the effectiveness of our proposed feature extraction methods to capture local and global discriminatory information from the pssm. we compare their performances with similar studies that relied solely on the pssm for feature extraction  <cit> . in this step, we also explore the effective value for distance factor  in segmented auto covariance feature extraction method as well as segmentation factor  in segmented distribution method. to find the effective value for segmented auto covariance method, we study the kp value between  <dig> and  <dig> . we also study the segmentation factor  in segmentation distribution between three values used in this study . in the second step, we conduct a similar experiments using the spine-x for feature extraction. we investigate the effectiveness of our proposed feature extraction method to extract these features from the spine-m as well as the effective values for ks  and fs  used in this study) in the similar manner. in the final step, we add the structural features extracted from the spine-m using our proposed methods to the extracted features from the pssm and compare our results with the best results found in the literature for the protein structural class prediction problem  <cit> .

to explore the impact of the distance factor on the segmented auto covariance method, 10-fold cross validation is adopted as it was widely used in similar studies  <cit> . in this paper, we have used k-fold cross validation where k =  <dig> to measure the prediction performance. we also provide these performance results using k-fold cross validation as a function of k where k =  <dig>   <dig>   <dig>  ...,  <dig> in additional file  <dig>  in the 10-fold cross validation, the benchmark is divided into ten non-overlapping subsets called fold. then in each iteration, the combination of nine folds is used for training purpose and the remained fold is used for testing purpose. this process repeats for all  <dig> folds to be used as the testing set. we also use jackknife cross validation to report our overall achieved prediction accuracy as well as prediction accuracy achieved for each structural class individually to compare them with previous studies. in this method, in each iteration, all but one sample use as a training purpose while the remained sample is used for testing purpose. this process repeats for all the samples available in the benchmark to be used as the testing sample. jackknife is considered as a computationally expensive approach for evaluation. furthermore, it was shown in  <cit>  that its performance is similar to 10-fold cross validation. since it has been widely used to evaluate protein structural class prediction accuracy, it is also adopted in this study to enable us to directly compare our results with the state of the art results found in the literature  <cit> . we will use the overall prediction accuracy  as the main accuracy measurement to be able to directly compare our achieved results with previously reported results found in the literature which is defined as follows:

  <dig>  

where c is the number of correctly classified test samples and n is the total number of test samples. we will also report the sensitivity, specificity and matthews correlation coefficient  measurements for each structural class to provide more information about the statistical significant of our achieved results  <cit> . sensitivity measures the proportion of correctly classified proteins compared to the whole number of samples which are classified as correct  and is calculated as follows:  <dig>  

where tp is the number of correctly identified  samples, while fn is the number of incorrectly rejected samples . on the other hand, specificity measures the proportion of the number of correctly rejected samples compared to the whole number of rejected samples  and is calculated as follows:  <dig>  

where tn is the number of correctly rejected  samples while fp is the number of incorrectly accepted samples . these two parameters are closely related to the prediction error and a predictor which is 100% sensitive and specific is considered as a perfect predictor . on the other hand, mcc measures the classification correlation and varies between - <dig> and  <dig>  and calculated as follows:  <dig>  

more information about these three measurement for protein structural class prediction problem can be found in  <cit>  and  <cit> . we will report sensitivity as well as specificity and mcc measures for all four structural classes for the best results reported in this study.

exploring the impact of our proposed methods relying only on pssm for feature extraction
in this step, we first extract the feature vector proposed by  <cit>  and reproduce their results with respect to different distance factors . their explored feature vector consists of semi-composition  and global auto covariance  features extracted from the pssm . in continuation, we build a feature vector based on our proposed feature extraction methods in this study relying solely on the pssm for feature extraction. we extract aao ), pssm-aac ), pssm-sac ), and pssm-sd ) feature groups. the combination of these feature groups is referred as pssm-s . the results achieved by reproducing  <cit>  experiment compared to our results with respect to different values of kp  for the 25pdb and  <dig> benchmarks are shown in figure  <dig> and figure  <dig> respectively.figure  <dig> 
the overall accuracies of pssm-s compared to aac-pssm-ac for 25pdb benchmark.
the overall accuracies of pssm-s compared to aac-pssm-ac for  <dig> benchmark.



note that we optimized γ and c for kp =  <dig> and fp =  <dig> using grid algorithms on the  <dig> benchmarks  and used corresponding values for the rest of this study . we determine the parameters used in this study for feature extraction as well as employed classification technique on the  <dig> benchmark while the 25pdb is not used at all and reserved to investigate the generality and effectiveness of our proposed model. however, our experiments have determined that there is no significant difference between the optimized parameters for the 25pdb and  <dig> benchmarks for our extracted features.

as we can see in figure  <dig> and figure  <dig>  our extracted feature vector significantly outperforms the results reported in  <cit>  for all the values used for kp . it shows the effectiveness of the proposed segmentation-based method to explore discriminatory information embedded in the pssm compared to use of whole protein sequence as a general entity. it also shows that by using segmented auto co-variance method, even by using very low values for kp, we can achieve to high prediction accuracy since it is able to explore adequate local sequence order information . we report up to  <dig> % prediction accuracy  by adjusting kp to  <dig>  ×  <dig> +  <dig> =  <dig> features in total) which is  <dig> % better than  <dig> % prediction accuracy achieved by reproducing  <cit>  experiment  for the 25pdb benchmark . similarly, we achieve up to  <dig> % prediction accuracy by adjusting kp to  <dig> which is  <dig> % better than  <dig> % prediction accuracy achieved by reproducing  <cit>  experiment  for the  <dig> benchmark . since the best results for both 25pdb and  <dig> benchmarks are achieved by setting kp to  <dig>  which highlights the effectiveness of segmentation technique rather than the effect of the distance factor  to extract this feature group), it is adopted as a distance factor to extract features for segmented auto covariance from the pssm for the rest of this study.

we also repeat this experiment to explore the impact of segmentation factor fp in segmented distribution feature extraction method. the prediction accuracies achieve by adjusting the segmentation factor to  <dig> and  <dig> are not improved  compared to the achieved results by adjusting this parameter to  <dig>  it highlights the sufficiency and effectiveness of adopting fp =  <dig> as the segmentation factor compare to use of  <dig> and  <dig>  in other word, using four segments is able to effectively provide adequate discriminatory information for this task better than increasing the number of segments to  <dig> or  <dig> 

in table  <dig>  we show the prediction accuracy achieved by adding proposed feature groups  in this study one by one to pssm-aac to build pssm-s . in this manner, we can investigate the effectiveness of each feature group individually on the reported prediction accuracy. as we can see, adding pssm-sac and pssm-sd significantly enhance the protein structural class prediction accuracy which highlights the impact of segmentation approach to provide significant discriminatory information for this task.table  <dig> the impact of the proposed feature extraction groups  proposed in this study to enhance protein structural class prediction accuracy .



exploring the impact of our proposed methods relying only on spine-x for feature extraction
in this step, we investigate the impact of our proposed feature extraction method on the spine-x for feature extraction. we build a feature vector based on our proposed methods in this study relying solely on the spine-m for feature extraction. we extract sseo ), spine-ssec ), spine-sac ), and spine-sd ) feature groups. the combination of these feature groups is referred as spine-s . the protein structural class prediction results are obtained in this subsection using the jack-knife cross validation method.

the results achieved for spine-s with respect to different values of ks  for the 25pdb and the  <dig> benchmarks are shown in figure  <dig>  these results are obtained with distribution factor fs =  <dig>  as we can see in figure  <dig>  these spine-s features give best results for ks≥  <dig>  for ks =  <dig>  these features produce  <dig> % for the 25pdb benchmark and  <dig> % for the  <dig> benchmark. note that these results are comparable to their corresponding pssm results reported in section  <dig> . this shows the effectiveness of the proposed segmentation-based method to explore discriminatory information from the spine-m . for ks =  <dig>  the feature vector has  <dig> features  ×  <dig> +  <dig> = 78). furthermore, we have studied the spine-s features for distribution factor  having values  <dig>   <dig>  and  <dig>  we have found that all the three values of fs gave similar results. therefore, we have reported the results for fs =  <dig> figure  <dig> 
the overall accuracies of spine-s with respect to different values of
k
s
for 25pdb and  <dig> benchmarks .



in table  <dig>  we show the prediction accuracy achieved by adding proposed feature groups  in this study one by one to spine-ssec to build spine-s . in this manner, we can investigate the effectiveness of each feature group individually on the reported prediction accuracy. we can observe from table  <dig> that addition of spine-sac and spine-sd has enhanced the protein structural class prediction accuracy, similar to pssm.table  <dig> the impact of the proposed feature extraction groups proposed in this study to enhance protein structural class prediction accuracy .



exploring the impact of our proposed method using both pssm and spine-x for feature extraction
in continuation we investigate the effectiveness of our proposed feature extraction methods to extract structural information from the spine-x and add these features to evolutionary information extracted from the pssm. we extract sseo , spine-ssec , spine-sac ), and spine-sd . the general architecture of our proposed feature extraction model is shown in figure  <dig>  the combination of the extracted features from the pssm and the spine-m is referred to as pssm-spine-s for the rest of this study .figure  <dig> 
the general architecture of our proposed feature extraction model. the number of features extracted in each feature group is shown in the brackets below the feature groups' names.



in the first step, we set the segmentation factor  to  <dig> and adjust distance factor  between  <dig> and  <dig> and add these features to the extracted features from the pssm . we conduct  <dig> experiments by adjusting ks from  <dig> to  <dig> in this step . the results achieved for both of the 25pdb and  <dig> are shown in figure  <dig>  in this part, for the first time we enhance the protein structural class prediction accuracy to over 90% for 25pdb benchmark and 85% for  <dig> benchmark. by adjusting ks =  <dig>  and segmentation factor fs =  <dig>  we achieve up to  <dig> % and  <dig> % prediction accuracies for both of the 25pdb and  <dig> benchmarks  ×  <dig> +  <dig> +  <dig> +  <dig> +  <dig> × ks  ×  <dig> +  <dig> =  <dig> features in total), up to  <dig> % and  <dig> % better than previously reported results for these two benchmarks using evolutionary and structural features simultaneously  <cit> .figure  <dig> 
the overall accuracies of pssm-spine-s with respect to different values of
k
s
for 25pdb and  <dig> benchmarks .



these enhancements achieved by increasing the prediction accuracy for all of the structural classes monotonically. we achieve to over 90% prediction accuracies  for three structural classes for the 25pdb benchmark . we also report  <dig> % prediction accuracy for α + β structural class, which is considered as a difficult structural class to predict which is  <dig> % over the highest results reported for this structural class  <cit> . despite the results achieved for the  <dig> benchmark have not been as high as the results achieved for the 25pdb benchmark, they still have been significantly better than the reported results for this benchmark . we also report  <dig> %,  <dig> %, and  <dig> % prediction accuracies for all-α, all-β, and α + β structural classes which are respectively  <dig> %,  <dig> % and  <dig> % over the best results reported for these structural classes in the literature  <cit> ). the results achieved  in this study compared to previously reported results for the 25pdb and  <dig> benchmarks are shown in table  <dig> and table  <dig>  respectively.table  <dig> comparison of the results reported for the 25pdb benchmark 

α/β
α + β
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
α/β
α + β
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 


adding structural features to evolutionary features extracted in our experiments enhances the results for up to  <dig> % and  <dig> % better than relying solely on evolutionary features for the 25pdb and  <dig> benchmarks respectively. this emphasis on the impact of structural information extracted from the spine-x in general for the protein structural class prediction problem.

we also provide the specificity and mcc for the best results reported in this study  for the 25pdb and  <dig> benchmarks in table  <dig>  as we can see, high values for specificity  similar to the high sensitivity values in table  <dig> and table  <dig>  as well as mcc values  for our achieved results support the statistical significant of our reported results in this study.table  <dig> the specificity  and mcc measurements for the best results:  for the 25pdb benchmark;  for the  <dig> benchmark

all-
α
all-
β
α
/
β
α
+
β
all-
α
all-
β
α
/
β
α
+
β




CONCLUSIONS
in this study we proposed novel segmented distribution and segmented auto covariance feature extraction methods to capture more local and global discriminatory information from evolutionary profile and predicted secondary structure of proteins. we first extract the corresponding features from the pssm in addition to the occurrence of the amino acids extracted from evolutionary consensus sequence and semi-composition extracted from the pssm. then by applying svm to the extracted features, we enhanced the protein structural class prediction accuracy for low-homology protein sequences  up to  <dig> % for the 25pdb benchmark and  <dig> % for the  <dig> benchmark better than similar studies that relied solely on the pssm for feature extraction  <cit> . our results supported the idea that potential sequence order information embedded in the pssm has not been adequately explored in the literature.

in continuation, we added similar features extracted from the predicted secondary structure using the spine-x  to previously extracted features from the pssm. by incorporating structural information, we achieved up to  <dig> % and  <dig> % for the 25pdb and the  <dig> benchmarks which were respectively up to  <dig> % and  <dig> % better than previously reported results found in the literature for these two benchmarks that have been widely used for the protein structural class prediction problem  <cit> .

future works
we are currently investigating the effectiveness of our proposed techniques in this study to tackle protein fold recognition. we are aiming to develop our protein structural class, and fold prediction server which will be publicly available in the near future. we also aim at exploring the-state-of-the-art feature reduction techniques on our extracted features to investigate the possibility of further feature reduction for these tasks.

declarations
publication of this article funded by griffith university and national ict australia .

electronic supplementary material
additional file 1: results as a function of k in k-fold cross validation the results achieved using svm to the spine-s, pssm-s, and pssm-spine-s feature vectors using  <dig> to  <dig> fold cross validation for 25pdb and  <dig> benchmarks. 

 competing interests

the authors declare that they have no competing interests.

