BACKGROUND
as a groundwork for the mutational study of a protein, many researchers will choose the comparative analysis of the protein homologues. column entropy in the multiple sequence alignment  <cit>  has proven over time as a workhorse of such endeavors, giving an excellent estimate of residue variability, and proving difficult to beat in terms of its prediction power. one of its limitations, which we address in this paper, is its inability to differentiate between amino acid residue types. for example, its straightforward application proves blind to the fact that an isoleucine, a residue of a type that mutates easily, when found conserved over a large evolutionary distance, should appear more conspicuous than a conserved proline. shannon's entropy is unable to distinguish between the two cases, and thus its resolution stops at the level of residues which are completely conserved across the aligned homologue set.

this is illustrated in figure  <dig> where entropy  is compared with a prediction from a detailed simulation of evolutionary events, provided by rate4site program  <cit>  . the most prominent feature of the simulation result is that the simulation can differentiate among the 35% of residues which are invariant in this alignment. this capability can be traced back to the fact that the mutation rates used in the simulation are residue type-dependent – a distinguishing capability that shannon's entropy lacks. this shortcoming makes application of shannon's entropy particularly awkward in the cases where the available homologues are few and closely related to the query.

while the entropy is by no means the only method to estimate residue conservation , and is not suitable for the identification of functional determinants  <cit> , we leave it as a focus of our attention for its central role in the existing research , and its potential as a building block for more elaborate methods  <cit> .

in order to introduce mutational preferences of different residue types into the analysis, we turn to joint entropy with kullback-leibler-like  <cit>  background frequencies. the joint entropy allows consideration of mutational events in terms of residue pairs  , whereas the background frequencies enable the estimate of the statistical probability of an observed mutation occurring at random. the background frequencies, we suggest, are already available in terms of blosum matrices, even though some adjusting is needed to turn them into matrices of transition probabilities. in distinction from earlier works using joint entropy with kullback-leibler background distribution to detect co-evolution across multiple alignment columns , we propose, closer in spirit to blosum itself, considering joint entropy for a single alignment column . to establish the reasonableness of the approach, we first argue that the expression for joint entropy, when applied to a single distribution, has the properties of entropy in the general shannon sense, but at the same time allows introduction of a phenomenological  term describing the difference in residue types and in their mutational preferences. we then turn the raw set of data, from which the blosum matrices were derived, into a mutation probability matrix, and then apply the resulting formula to the detection of a set of protein interfaces. the method shows a significant improvement in the specificity of detection of functional surfaces starting from a small set of close homologues, as illustrated on a test set of  <dig> transiently interacting homodimers.

method
a column in a multiple sequence alignment can be thought of in the following way: if the sequence set were a fair sample of all possible orthologs, and the variability of each residue depended only on its type, the amino acid population in each column would reflect the ease with which they are exchangeable in a general case. setting aside the problem of the fairness of sample, which we do not attempt to address here, the difference from the expected distribution is a result of the particular evolutionary forces on the residue, or the lack thereof.

the shannon entropy of an alignment column – represented by a distribution of residue types x – is evaluated as

 h=−∑xplnp, 

where x is one of  <dig> residue types, and the probability of occurrence of x, p, is estimated by f, the frequency of the appearance of residue type within the alignment column:

 p≈f=nl, 

where n is the number of appearances of residue type x, and l is the length of the column. to find an expression which will incorporate residue mutation propensity, we first look at the expression for joint entropy of two distributions

 h=−∑x∑ypln⁡p, 

and apply it to a single distribution, x:

 h=−∑x1∑x2≤x1pln⁡p. 

p is now estimated by the frequency of residue type pairs which can be formed from the residues in the column:

 p≈nl/ <dig> 

where n is the number of unordered pairs , which can be formed by taking both x <dig> and x <dig> from the distribution x, and l is the column length. the quantity p behaves the same way as the shannon entropy, as illustrated in figure  <dig>  for the case of a set of  <dig> elements of types a and b. this corresponds to a case of a column taken from an alignment of  <dig> sequences, and which happens to contain only two residue types. just as in the case of shannon's entropy , the entropy function defined in eq.  <dig> is zero when the set contains only one type of element , and maximal when the two types are equally represented.

the joint entropy also has the advantage that it allows for easy incorporation of information about mutational preference of amino acids, following the approach of kullback and leibler:

 hbb=−∑x1∑x2≤x1pln⁡pq. 

q here plays the role of the "background" mutation propensity. in particular, p which is greater than q will result in negative hbb, indicating that the residue is more conserved than its average mutation propensity would dictate . the most conserved residue still has the minimal score  which can in this case be less than zero. to estimate q, we take a matrix of raw pair frequencies originally assembled for the calculation of blosum matrices  <cit> . these matrices are not probabilities, but counts of pairs of different amino acid types appearing in the same alignment column. thus, we first normalize each row to unity. the distribution p described in eq.  <dig> and used in eq.  <dig> has no way of distinguishing between the two possible orderings of its arguments; that is, in this model we do not know which residue type was "earlier" and which one was "later" – mutations in both direction are equally probable . therefore, we need the reference distribution q which possesses the same symmetry. the matrix obtained by normalizing the rows in the raw blosum table is no longer symmetrical, so we approximate it with a nearest  symmetric matrix whose rows and columns sum up to  <dig>  to find q we use a monte carlo procedure: starting from  <dig> ×  <dig> identity matrix, we subtract  a small quantity from a randomly chosen off-diagonal element, and add  it from the two corresponding diagonal elements.

the optimized  quantity is root-mean-square distance of matrix elements to the starting  matrix. the q matrix used in this work was derived from the frequencies in 35% clustering blocks, and can be found in additional file  <dig> 

to illustrate the way hbb scores residue columns, we look at two simple examples. first we compare the scoring of two completely conserved columns, one with isoleucines, and one with prolines:

 ipipipip 

since q =  <dig> , and q =  <dig>   is equal to  <dig> for any conserved column), the value of hbb for the first column is - <dig> , and for the second - <dig> . remembering that, just as in the case of shannon column entropy, the lower number indicates higher degree of conservation, the isoleucine column is by this reasoning under higher evolutionary pressure than proline. that is, since isoleucine is quite prone to mutation , we find it as an element of surprise that it is completely conserved, and attribute this to a special role alanine plays at this particular position in the protein.

in a slightly more complex example we compare two columns with two values of amino acid types each:

 iiiiiivp 

perhaps counterintuitively, the second column scores better , largely because of the contribution of q =  <dig>   =  <dig> ). if it is true that in the evolutionary history of our hypothetical protein the isoleucine at this position was replaced by a proline, then this position must be very special, claims this model, perhaps conferring specificity to the proteins function. 

the test set
the test set used here consists of  <dig> transiently interacting heterodimers, a subset of the set originally published by nooren and thornton  <cit> , resulting in  <dig> interfaces. out of  <dig> protomers in this set,  <dig> are classified as all a-helix in the scop  <cit>  scheme,  <dig> as all β-sheet,  <dig> as α/β,  <dig> as α + β, and  <dig> simply as "small proteins" . the interface residues are defined as the set of residues which upon complexation become completely isolated from the water molecules, or can be found in the vicinity of coordinated water molecule. such regions are either in close contact with the interacting partner, enabling short range interactions , or functioning as hydrophobic "suction pumps;" in either case they are expected to be responsible for the interaction strength and specificity, and thus under increased evolutionary pressure.  <cit> 

the hssp  <cit>  alignment was used as the initial alignment in all cases presented. sequences aligning with less than 75% of the query length were removed from the alignment. for each pair of sequences more than 98% identical, the shorter sequence was discarded. if the average identity of any two sequences, measured by an average over all windows  <dig> residues long, was below 50%, the sequence with the smaller percent identity to the query was discarded. in the same way, all sequences were required to have at least 70% identity. these strict requirements were used precisely to illustrate the point that the presented method can extract interesting information even from very closely related sequences.

for comparison, the results are also shown for the same set of proteins, but using a set of more distant homologues for each family – sequences at least 15% identical to the query and among themselves. in some cases  this procedure – using the hssp alignment as a starting point – still resulted in a set of very similar homologues. in these cases we resorted to  <dig> iterations of psiblast  <cit>  search on the ncbi non-redundant database of protein sequences  <cit> , with the cutoff e-value of  <dig> , followed by alignment using muscle  <cit> , and pruning of similar sequences as described above for the hssp case.

RESULTS
figures  <dig> and  <dig> show the performance of hbb  in detecting protein interface, compared with the column entropy  and rate4site . the results are presented in terms of sensitivity versus surface coverage curves. definitions of sensitivity and coverage stem from our use of methods which, in one way or another, rank residues by the evolutionary pressure they experience. coverage in this context refers to the fractional overlap of certain percentage of top ranking residues with the set of surface residues, while sensitivity is the overlap of the same top ranking residues with the target set of interface residues. the question of the optimal choice of coverage  is left open, with the understanding that a higher coverage choice detects a larger number of test residues, but also leads to a larger number of false positives. the quality of any method consists precisely of its ability to maximize this hit-to-miss ratio.

the results in figure  <dig> refer to a hypothetical and especially stringent case, in which only very close homologues  are available for the analysis. for the proteins in our test set this is not necessarily the case, but we limit the sequence selection to close homologues to illustrate our claim that hbb is then still able to extract information beyond the reach of shannon's entropy. as shown in figure 3hbb is capable of detecting parts of the interface down to one percent coverage of the entire surface, even using an evolutionarily narrow selection of sequences. at the same time, the results are quite comparable to the results obtained using a full-blown simulation of evolutionary events . taking the area under the sensitivity vs. coverage curve as an indicator of the prediction quality , in a wilcoxon signed-rank test  <cit> , the areas resulting from the use of hbb are indeed different from those using entropy with the p-value < <dig> × 10- <dig>  using the same test, the quality of the predictions by hbb and rate4site are statistically indistinguishable . rate4site and hbb average the area of  <dig>  and  <dig>  respectively for this selection of sequences, while the entropy averages  <dig> , thus indicating that both hbb and rate4site move the prediction toward more reliable. the last result is the consequence mostly of the inability of the entropy to achieve resolution at small coverage, thus decreasing the area under the curve.

in the following figure, figure  <dig> we note that for a broader evolutionary coverage , entropy becomes competitive again. however, hbb still performs comparably to rate4site, and even somewhat better than the column entropy. the average areas under the sensitivity-coverage curve are  <dig> ,  <dig> , and  <dig>  for hbb, entropy and rate4site respectively. on the wilcoxon test, in this case of a sequence sample with lower homology, the results by hbb are more similar to those produced by column entropy  than by rate4site .

information analogous to figures  <dig> and  <dig>  using matthews correlation coefficient, is presented in additional file 1: the success of the method varies from case to case, but it achieves the values of matthews coefficient of up to  <dig> .

the usefulness of the method is not limited to protein interfaces – it works as well as rate4site, and better than entropy in detection of catalytic sites for enzymes .

the model behind this approach acknowledges that starting from the the alignment column alone it is not possible to establish the residue type in the ancestral allele. instead, the reasoning goes, in the lack of evolutionary pressure, the observed distribution should reflect the statistical propensity of residues to mutate to each other: if a residue type a is just as likely to mutate to type b as not to mutate at all, and vice versa, we expect to find the two types equally represented in a fair sample of existing alleles. a deviation from the uniform distribution, then, points to an external pressure to maintain a particular type, calling attention to the corresponding position in the protein sequence. this interpretation of the model makes its pitfalls obvious: a sequence sample produced automatically from currently available protein sequence databases is highly unlikely to be fair.  also, even though it tolerates small evolutionary breadth, since the method is inherently statistical, it requires a sizable number of sequences, a requirement shared with shannon's entropy, but not with maximum likelihood methods . finally, and this is the problem common to all three methods discussed here, the pressure to conserve a particular physicochemical characteristic  goes undetected by hbb. however, with all of its shortcomings, the model immediately proves to be more useful  than the one oblivious to amino acid type, as indicated in figure  <dig> 

consideration of the inherent problems may yet lead us to an improved approach.

CONCLUSIONS
we have shown that a simple heuristic modification of shannon entropy can match the prediction power of an elaborate evolution simulation. it is worth noting the advantages this brings: hbb is simple, which makes it applicable as a part of a more complex approach  <cit> , and its speed  makes it useful in repetitive tasks, such as optimization schemes  <cit> . in practical applications, the presented method can tackle much larger alignments, in terms of both number of sequences and their length, than an evolutionary simulation; in the opposite extreme , the presented method can extract information from a very narrow evolutionary sample.

the data set used in this work is available at the lichtarge lab website  <cit> .

authors' contributions
im conceived of the study and implemented necessary software. the method was developed and the manuscript written through collaborative work of all authors. all authors read and approved the final manuscript.

supplementary material
additional file 1
background frequencies for residue variability estimates: blosum revisited – supplementary material. the supplement contains the reference distribution q, structural classification of used proteins according to scop, and additional comparative analysis of the method presented here with methods already available in the literature.

click here for file

 acknowledgements
the authors thank tuan a. tran and r. matthew ward for critical reading of the manuscript. support from nih gm <dig>  nih gm <dig>  nsf dbi- <dig>  march of dimes  to ol, as well as partial support to im by biomedical research council of a*star, singapore is gratefully acknowledged.
