BACKGROUND
the correlated mutations  analysis has been used to predict pairs or networks of amino acids that are distant in the primary sequence but form contacts in the native 3d structure  <cit> . the basic presumption is that during evolution, proteins accumulate sequence variability due to spontaneous mutations. however, the variability within a family of proteins should not affect the protein fold and function. thus, amino acid positions that are important for the fold and the function should evolve in an orchestrated manner to conserve both the fold and the function.

the cm method predicts contacting residues by analyzing the correlated variability of the amino acid composition at two or more positions within the multiple sequence alignment. thus, the detection of homologous sequences and the generation of the multiple sequence alignment are crucial for the performance of the method. both tasks require substitution rules and several approaches were explored:  the cm based on amino acid identity  <cit> ;  the cm using substitution matrices  <cit>  and  the cm with statistically delivered pairing potentials  <cit> . the last approach appears very promising; vriend and coworkers  <cit>  achieved 20% mean accuracy on a set of  <dig> non-redundant proteins taken from the hssp database  <cit>  using  <dig> Å distance cut-off. another promising direction of predicting residue contacts is a combination of machine learning and the cm method. in a series of studies casadio and co-workers applied neural networks in conjunction with the cm method to predict disulfide bridges  <cit>  and contacting residues  <cit> . applying their methodology to a set of  <dig> non-homologous proteins resulted in an average accuracy of  <dig>  while automatic predictions on  <dig> targets of casp <dig> with the cornet  <cit>  server resulted in an accuracy of  <dig> . recently, a novel neural network method  <cit>  that utilizes sequence information, secondary structure and solvent accessibility predictions, and the overall properties of the entire protein was developed in the rost lab. on a test set of  <dig> proteins the profcon server  <cit>  achieved an accuracy from  <dig>  to  <dig>  depending on both the number of predicted pairs in respect to the query length and the sequence separation. to the best of our knowledge this is the best result reported yet, however, the method is quite computationally demanding. rather than predicting pairs of contacting residues, the statistical coupling analysis , developed in the ranganathan lab was extensively used to predict networks of interacting residues that mediate allosteric transitions  <cit> , functional specificity  <cit>  or energetic connectivity  <cit> . the predictions were tested against the experiment and a very good agreement was reported  <cit> .

despite the apparent progress made in developing reliable methodology of predicting residues contacts, the accuracy of the current methods is between  <dig>  and  <dig> . at the same time, the cm generates many predictions with relatively good scores and thus provides a large pool of predictions that contains a significant fraction of the true contacts. therefore, the problem lies not in improving the sensitivity of the methodology, but in improving the accuracy, e.g. in reduction of the false positive ratio. the main goal of this study is to suggest possible improvements in the confidence of the predictions and to make the predictions more protein-specific.

as previously mentioned, the correlated mutations method reveals possible residue pairs within a protein family. if the structural region is highly conserved within the family, it is most likely that no variation in the amino acid sequence will occur. in contrast, if the structural region is not well conserved within the family members, then the residue contacts most likely will not be preserved. we wish to elucidate a more specific series of predictions relative to a particular member of a given protein family. therefore, in this study the predictions made for a whole protein family are subjected to a set of pairing rules with respect to the biophysical properties of the amino acid sequence of a protein of interest. to the best of our knowledge this is the first attempt to incorporate biophysically-related knowledge into the statistical methodology of the correlated mutations approach.

implementation
simplified correlated mutations  method 
the correlated mutations and statistical conservation analysis methods have been previously described in detail . our approach differs from the existing implementations of the cm methods, since we do not emphasize the scoring scheme of the algorithm and the details of theoretical formulation. thus, we do not rank the predictions and do not specify how many contacts should be predicted. instead of using the correlation score as usually done in the cm analysis , we define a set of four parameters which are subjects of optimization.

the optimization is done on a set of known high-resolution structures so that the true prediction ratio  is maximized. the sequences of these test pdb files were submitted to the cm methodology to predict contacting residues. the predictions were then verified against the 3d structures. a prediction was considered to be correct  when any two heavy atoms of the side chains of the predicted residues were within  <dig> Å distance  <cit> . predictions of contacts separated by less than six sequence positions  were considered trivial and omitted from the analysis. the optimization was done to maximize the true predictions ratio  by selecting the best values for several parameters  as described below.

purging the initial set of homologous sequences 
each query sequence was subjected to a Ψ-blast search against the database of non-redundant sequences obtained from the national center for biotechnology information. the cut-off e-value remained the default , but the number of output hits was increased to  <dig> to ensure a sufficiently large pool of homologues. the resulting hits were then purged to remove short alignments , very similar hits with sequence identities > 90% and very dissimilar hits with sequence identities < 20%. this approach differs from previous cm approaches because we remove "bad" sequence prior to performing the cm analysis. now, the "bad" sequences will not affect the quality of the multiple sequence alignment which is crucial for the cm performance. the remaining homologous sequences were further purged with cd-hit  <cit>  to remove homologous sequences at certain levels. this is similar to applying a correction coefficient to the correlation formula to downweigh information from very similar sequences  in ref.  <cit> ). the level of cd-hit purging was considered the first parameter of the optimization, with a range variance of 90% to 40%. in addition, the cases that returned less than  <dig> homologues amino acid sequences were regarded as having little information and were subsequently deleted from the protocol.

excluding totally conserved residues 
the purged sequences were further subjected to clustal w  <cit>  to generate multiple sequence alignment. some of the positions of the multiple alignment were totally conserved while others showed little variation. a totally conserved position does not provide information necessary for the cm analysis and thus is deleted in our implementation. however, to reduce the noise from the occasional insertion of sequences dissimilar to the rest of the sequences in the multiple sequence alignment, the definition of "totally conserved position" was slightly relaxed. this second adjustable parameter in our approach was varied from 100% to 80%. figure  <dig> illustrates this parameter on an example of  <dig> sequences where ala residue in the position marked as "parameter 2" is presented in  <dig> sequences. therefore if parameter  <dig> is set to  <dig> % or less, this site will be omitted from the analysis. the fact that the residue is not conserved in the remaining sequence indicates that most likely the 10th sequence is not a member of this particular family.

definition of partially conserved position 
in our implementation of the cm method, we first searched the multiple sequence alignment  for partially conserved positions. the minimum degree of conservation was considered to be the third adjustable parameter in our approach and was varied from 90% to 40%. this position  is then used to extract a sub-multiple sequence alignment , in which this position becomes totally conserved. for instance, as shown in fig.  <dig>  if a position in a multiple sequence alignment has lys residue within  <dig> out of  <dig> sequences, the degree of conservation is 60%  and thus this position will be considered further if the parameter  <dig> is set to 60% or less. removing all sequences not containing lys residue in this position will result in a sub-multiple alignment that is shown separately in figure  <dig>  similar smsa's are constructed for all msa positions that satisfy parameter  <dig> 

finding correlated positions 
we then performed a second search within each smsa  to find partially conserved positions . if in a particular smsa position the given residue has a degree of conservation larger than a certain threshold, this position is considered to be correlated with the position i for which the smsa was constructed. this minimum degree of conservation for the position ii in this second search was considered to be the fourth adjustable parameter in our approach and was varied from 100% to 40%. an example of such position is shown in figure  <dig> as a position with asp residue in  <dig> of the  <dig> smsa sequences resulting to a degree of conservation of 66%.

filters for reduction of the false positive ratio
the predictions made by the cm were subjected to a set of rules  to filter out pairs that do not have complementary physical-chemical properties. the selection rules are introduced using general biophysical considerations and are not related to the pairing frequencies or residue pairing preferences delivered from statistical studies of residue contacts in the existing 3d structures. residue contacts observed in protein structures may not reflect true residue interactions but rather could be caused by other factors. for example, the statistically observed large number of hydrophobic – hydrophilic residues' contacts perhaps reflects the overall protein structure made of a hydrophobic core surrounded by a hydrophilic shell of residues. thus, we believe that using biophysically-based constraints better accounts for the driving mechanism of correlated mutations. in addition, the cm method is family specific, i.e. the predictions are based on the multiple sequence alignment of the entire protein family. thus, it is possible that a prediction made for the entire family may not be suitable for the particular query.

the filters are based on the general considerations of the nature of the interactions between amino acids and thus, strictly speaking, are neither delivered statistically nor analytically, although small corrections in the original assumption were made during the optimization phase against the first set of proteins. four physical-chemical characteristics were applied: hydrophobicity, polarity of the charge, hydrogen donor/acceptor pairing and disulfide bridge formation. thus, two residues are considered to be in energetically favorable contact if they can form:

 a hydrophobic pair, i.e. when both residues in the predicted pair are hydrophobic ones .

 an ion pair, i.e. when the residues within the predicted pair have opposite charges .

 a disulfide bridge .

 a hydrogen bond, i.e. hydrogen donor-acceptor pairs, like asn and gln paired with asp, glu, his, lys and arg.

 pairs, in which donation of a hydrogen bond to a hydrogen acceptor is possible, such as ser, thr or tyr coupled to asp or glu.

thus, if a predicted pair falls within one of the above categories, the pair is accepted, otherwise the prediction is deleted. in addition, during the optimization of the parameters, it was found that gly residue quite often forms contacts with another gly, and therefore gly-gly rule was also included in the list of acceptable pairs. at the same time very few true contacts were observed for trp-phe, phe-ile, trp-leu, trp-pro pro-phe, pro-ile, pro-leu, pro-met and pro-trp pairs and thus those pairs were excluded from the list of acceptable predictions.

it should be emphasized that these selection rules are applied in respect to the query sequence independently of the multiple sequence alignment. thus, the predictions after the filters are query-specific. the selection rules are shown in figure  <dig>  filled squares correspond to acceptable pairs, while empty squares correspond to pairs that are rejected. for convenience we refer to this methodology as correlated mutations with filters .

web server
the recon  web based server is intended to provide the scientific community with a publicly available tool capable of predicting intra-residue contacts by the correlated mutation method as described above. the front page of the server provides the user with options to either upload files with a sequence of interest to the server or to paste a sequence into the input window. although the values of the four parameters are initially set to the optimum values reported in this paper, the user has the option to select other values from the list . selection from the list rather than from the text fields is implemented in the server for convenience , reliability  and security . users can also select whether biophysical constraints will be used during the calculations. help buttons located at each selectable parameter and input field activate pop-up windows with a detailed explanation of the meaning of the corresponding parameters or input fields.

after the "submit query" button is pressed, the home-made cgi perl program controls the correctness of the input sequence. it will either verify that the submitted file is in the fasta format or that the sequence contains the appropriate letters . if mistakes are discovered, a pop-up window appears informing the user of the error. this popup also contains instructions for correcting the mistake made, so the user may resubmit the sequence.

if the submitted input is error-free, the program then displays information on the progress and completion of each calculation step. after simulations are completed, a new window appears containing the submitted sequence and the list of residue pairs predicted to interact. the residues are colored according to their physical-chemical classification . a small embedded visualization script makes it easy to comprehend where in the sequence the predicted residues are located. when a user clicks on the predicted pair it gets highlighted both in the predicted contact list and in the displayed sequence. the program also offers the user an option to download the prediction results in a plain text file format.

pdb files used for testing
the optimization of both cm and cmf protocols was accomplished using a set of high resolution structures. they were chosen using the dunbrack cutting utility  <cit>  applying two selection criteria . these criteria assure that the structures are of high quality and that they provide a diverse set of test cases in terms of their sequences. this selection yielded  <dig> structures . in  <dig> cases, the Ψ-blast search against the non redundant database of sequences revealed less than the required  <dig> homologous sequences. thus, the number of sequences/structures was dropped to  <dig>  it can be argued that a training set of  <dig> structures may be too small to be representative of contact space. however, the set provided  <dig> contacts in total, which is satisfactory from a statistical point of view. we refer to this set as the first dataset.

the second test was performed on a larger set of pdb structures obtained again from the dunbrack server using a resolution criterion of  <dig>  Å. the files from the previous test were excluded. this resulted in  <dig> files. however, not all sequences generated enough homologues in the Ψ-blast search, which reduced the final number of test cases to  <dig>  we refer to this set as the second dataset.

RESULTS
optimizing the parameters
each sequence of the first dataset was subjected to both cm and cmf algorithms. the predictions were made by varying the four adjustable parameters in increments of  <dig> . thus, for each sequence we generated many sets of predictions. the results, shown in figure  <dig>  show the peak of the distribution for both cm and cmf at a true positive ratio  of approximately 10%. two observations can be made from a comparison of the cm and cmf results. the cmf reduces the overall number of predictions by approximately  <dig> times, but keeps the predictions with high tpr . this feature is the core of our approach.

the above results were obtained by varying all four adjustable parameters. since we do not score the predictions, we adopted the following strategy to find the optimal values of the adjustable parameters. each query sequence generated a pool of predictions obtained by varying the adjustable parameters. from this pool we selected ten predictions with the best tpr for each sequence in the first dataset. the selection was done separately for the cm and cmf results. in certain cases, the tprs were very good and were even equal to  <dig>  , but the predicted contacts were very few. to gain some statistical significance we neglected all cases that resulted to less than  <dig> predictions per query sequence. thus, collecting  <dig> best results for all query sequences resulted in a pool of predictions that were used to count the frequencies of the values of the adjustable parameters . the maximal frequency among the best tprs was found to occur at different parameter values for the cm and cmf. in the case of the cm, the optimal values for the four parameters were  <dig> ,  <dig> ,  <dig>  and  <dig> , respectively. in the case of cmf, they were  <dig> ,  <dig> ,  <dig>  and  <dig> , respectively.

benchmarking the first dataset
we again benchmarked the first dataset while keeping the parameters fixed at their optimal values. this resulted in a mean tpr of  <dig>  for the cmf and a mean tpr of  <dig>  for the cm protocols, indicating that the cmf outperformed the cm. the effect of selection rules is illustrated in figure  <dig>  here we show the predicted tprs of the cmf plotted against the tprs of the cm for each sequence in the first dataset. the four parameters were kept fixed at their optimal values for the cmf obtained in the previous section. the results obtained with optimal values of the parameters for the cm are similar and thus are not reported. we applied the same cut-off as before requesting at least  <dig> predictions per query. in cases of less than  <dig> predictions, we performed sequential runs relaxing the fourth parameter until the number of predictions became larger than six. as can be seen, most of the points lie above the diagonal line demonstrating that the selection rules preferentially cut mostly false predictions, which in turn increases tpr. the least-square linear fit of the data points  results to a line slope of  <dig>  indicating improvement of ~50% .

benchmarking the second dataset
the above results are obtained on the same dataset that was used to obtain the optimal values for the four adjustable parameters. therefore these results are considered biased and a further test was performed using the second dataset. using the corresponding optimal values of the parameters for the cm and the cmf, we obtained a mean tpr of  <dig>  for the cmf and a mean tpr of  <dig>  for the cm. though these results are less impressive than the results obtained from the first set, they still clearly indicate the improvement made by the selection rules, which on overall is 30% improvement of the mean value. the effect of the selection rules is demonstrated in figure  <dig>  which compares the tpr values of the cmf versus tpr values of the cm . the vast majority of the points again lie above the diagonal, which confirms that the selection rules selectively reject mostly false positives. the ratio between the tpr values of the cmf and the cm is now  <dig> .

the length of query sequences may be a possible explanation for the less impressive results in the second dataset as compared with the first. the first dataset was generated at a resolution cut-off  <dig>  Å and such high resolution structures are usually obtained for short-sequence proteins. relaxing the resolution criterion to  <dig>  Å, as done in the generation of the second dataset, longer query sequences were included. as repeatedly demonstrated, the cm performance degrades as the length of the protein increases. indeed, analyzing the results obtained from the second dataset showed several outliers  corresponding to very long query sequences . thus, we would not recommend applying our method to predict contacts in sequences longer than  <dig> amino acids.

as it was mentioned in the introduction, the accuracy of the current cm methods varies between  <dig>  and  <dig>  depending on the number of predicted contacts in respect to the query length. our implementation does not rank the predictions and thus it is impossible to control how many predictions will be made per query length. however, a plot of the number of the predictions for each query as a function of the query length  resulted to fitting line with a slope 1/ <dig> for the predictions without filters and to 1/ <dig> for the predictions with filters . thus, on average the cm protocol predicted l/ <dig> pairs, while the cmf protocol made l/ <dig> predictions. we would like to emphasize again that our protocol does not rank the predictions, and thus the reduction of the number of the predictions from an average of l/ <dig> with the cm protocol to l/ <dig> with the cmf protocol does not mean selecting the best l/ <dig> predictions from the pool of l/ <dig> predictions. if the filtering rules were randomly selected one should expect reduction of the number of predictions but no change of the tpr, since true positives and all predictions will be reduced by the same proportion. the selectivity of the filters is illustrated in figure  <dig> where the true and false predictions are plotted for the cmf and the cm protocols, respectively. it can be seen from the slope of the fitting line that the filters reduce the true predictions made by the cm method by a factor of  <dig>  while the false predictions are reduced by a factor of  <dig> 

the main finding of the paper is that the biophysical filters always improve the quality of the predictions. the effect was tested against different versions of the sequence database, using different versions of Ψ-blast and clustal w and the results were found to be consistent . however, the individual predictions per protein were quite sensitive to the above factors. the reason for that is our simplified implementation of the cm analysis that uses cut-offs for the parameters rather than applying a scoring function to rank the predictions.

what could be the reason for the improvement introduced by the physico-chemical filters? perhaps this is the combination of the statistical approach of the cm analysis in conjunction with the filters that makes the difference since the physical-chemical filters alone cannot make predictions. in many cases the cm analysis finds a correlation between two positions in the multiple sequence alignment, but these positions may be far apart in the 3d structure of the representative protein since a reason for the evolutionally related correlation would not necessarily be a physical contact. there could be other reasons of a different nature, for instance, functional cooperativity when the positions could be "connected" through rigid secondary structure elements. thus, the cm predicts a pool of correlated positions such that some of them are contacting while some of them are not. applying filters that require physical-chemical complementarity favors the fraction of the contacting positions and thus improves the tpr .

our method combines statistical and biophysical approaches. the statistical approach  is used to generate the initial predictions and then these predictions are filtered based on biophysical considerations . although these two approaches are applied independently of each other, there certainly is an overlap since the statistics reflect, to some extent, the biophysical interactions between residues . however, since the filters were not statistically delivered, we can not estimate this overlap.

CONCLUSIONS
the main goal of this study was to maximize the confidence of the predictions of contacting residues in the new implementation of the correlated mutations method. the results presented in this paper show that a set of selection criteria based upon the physico-chemical properties of amino acids significantly improves the performance of the cm protocol. the improvement coefficient per protein was found to be  <dig>  and overall improvement for the entire set of  <dig> proteins was 30%. though the absolute value of the accuracy is not impressive , we argue that the filters can be implemented into a more advanced cm method to improve the predictions . the method was implemented into a web server, freely available to the scientific community and which can be used for residue contact predictions needed in users research.

availability and requirements
the recon web server for predicting residue contacts using our implementation of the correlated mutation method is freely available.

project home page: 

operating systems: internet explorer on ms windows and mozilla browser on linux systems.

other requirements: allowing pop-up windows and enabling java in internet browser

license: free

abbreviations
cm – correlated mutations without filters

cmf – correlated mutations with filters

tpr – true positive ratio 

fpr – false positive ratio 

pdb – protein databank

recon – residue contacts

authors' contributions
ea and pk equally contributed in the development of methodology and to writing the manuscript. ea contributed to the development of the fortran code for the correlated mutations and pk contributed to the development of the web server. all authors read and approved the final manuscript.

