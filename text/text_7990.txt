BACKGROUND
protein aggregation has been intensely studied experimentally and computationally because the aggregation of protein drugs is of significant concern. it is encountered routinely during the protein refolding, purification, formulation, storage and shipping processes  <cit> . moreover, it is associated with over  <dig> human diseases, such as alzheimer’s, parkinson, huntington, prion diseases, and type ii diabetes  <cit> . interestingly, recently several functional amyloids have been found that play an important role in cellular biology and caused no measurable cytotoxicity  <cit> . despite extensive research efforts, the underlying mechanisms of protein aggregation are not completely understood  <cit> . many common phenomena related to aggregation, however, have been observed in various experiments  <cit> . for example, a small segment of one protein can be involved in aggregation while the rest retains a native-like structure. some short de novo peptides can also form fibrils that closely resemble those formed by natural amyloid proteins. experiments have confirmed many small peptides with lengths as short as  <dig>  <cit> ,  <dig>  <cit> ,  <dig>  <cit> , and even  <dig>  <cit>  residues can form aggregates. swapping an aggregation prone segment from an amyloidogenic protein to a non-amyloidogenic homolog can trigger amyloid formation  <cit> . these observations suggest that short aggregation prone regions of sequence and structural specificity, rather than full-length sequences, can induce the formation of most if not all aggregates. although in vivo amyloid disease aggregates may show different characteristics from those formed from protein drugs, as the former are well ordered entities containing cross beta structure fibers while the later are frequently amorphous entities, current prevailing theories consider both amyloid fibers and amorphous aggregates are formed from partially-folded intermediates  <cit> . therefore, both amorphous aggregates and fibers may contain similar aggregation prone motifs  <cit> .

a number of computational methods have been developed for predicting peptide aggregation propensities and identifying aggregation prone regions in whole protein sequences  <cit> . notable methods include tango  <cit> , page  <cit> , foldamyloid  <cit> , zyggegator  <cit> , aggrescan  <cit> , and pafig  <cit> . in all of these methods, with the exception of pafig, a small number of physicochemical properties were empirically chosen to develop predictive models. for example, chiti et al.  <cit>  developed an empirical model using hydrophobicity, charge and propensity to predict aggregation rates. the model was later extended to a seven-parameter model designated zyggegator for predicting absolute aggregation rates  <cit> . in both models, parameters were fitted using experimental data. tartaglia et al.  <cit>  instead developed a model using physicochemical properties without any free parameters. page includes more properties such as aromatic residue number, parallel or anti-parallel configuration, and accessible surface area  <cit> . tango is a statistical mechanics algorithm for predicting β-aggregation in peptides and proteins. it is based on the assumption that the core regions of an aggregate are fully buried  <cit> . foldamyloid uses packing density which represents the average number of residues within a contact radius of  <dig>  Å for  <dig> amino acid residues obtained from a database consists of protein with sequence identity less than 25% as well as the probability of hydrogen bond formation  <cit> . it has been demonstrated that regions that possess high packing density can be responsible for amyloidogenic properties. aggrescan is a sequence based aggregation prediction tool based on an aggregation propensity scale for each of the  <dig> amino acids, which is derived from experimental data  <cit> .

while these methods have generally resulted in good prediction accuracies, little systematic research has been done to determine peptide properties relevant to aggregation and their relative importance. although pafig uses machine learning methods to identify features relevant to aggregation, the number of the selected features is very large . therefore it is very difficult to evaluate the biological relevance of each selected feature.

the goal of this study is to use feature selection algorithms to identify a small number of features important to protein aggregation. the removal of irrelevant or redundant features often improves the performance of learning models, providing faster and more cost-effective predictions. more importantly, this procedure may provide a better understanding of properties important to aggregation. therefore, an investigation into physicochemical factors affecting protein aggregation has dual aims, precisely predicting protein aggregation propensities and discovering additional underlying mechanisms governing this important process.

in this study, we initially collect comparatively large training and test datasets from literature. a set of nine classification algorithms are used to test the classifiability of the datasets and define a baseline for performance evaluation of feature selection. we then apply two feature selection methods based on support vector machine   <cit>  and random forest   <cit>  algorithms to rank  <dig> numeric features. svm and rf classifiers, named proa-svm and proa-rf respectively, with selected features are built, cross-validated and compared to five state-of-the-art methods. to test the reliability of selected features and robustness of the learned models, a leave-one-protein-out  cross validation is conducted. finally, we use our predictors to calculate aggregation propensity profiles for some well-studied proteins to identify aggregation prone regions and compare them to experimental results and other predictive methods.

one interesting finding of this study is that aggregation prone peptide sequences share similar properties with signal peptide and signal anchor sequences. this is supported by our finding that this model for aggregation can be used to accurately distinguish signal peptides from non-signal peptides. a possible relationship between aggregation and localization is also discussed.

RESULTS
baseline classification of samples using nine algorithms
we first constructed  <dig> classifiers based on  <dig> commonly used algorithms and then used these classifiers to establish a performance baseline. the performance of the classifiers was evaluated using the standard 10-fold cross validation. the accuracies of the predictions range from  <dig>   to  <dig>   . the results show good classifiability on the dataset ap <dig>  therefore it is feasible to predict peptide propensities using collected features by machine learning methods.

the  <dig> features are selected by svm-rfe and the  <dig> features are selected by rf-is. the  <dig> fold cross validation of each classifier is conducted on dataset ap <dig> 

feature selection
we use two feature selection methods, namely svm-rfe and rf-is, to select features which are important to protein aggregation. the feature selection procedure of both approaches starts with the full set of features and then iteratively eliminates a number or a fraction of the least important features, as determined by the svm-rfe and rf-is algorithms. to determine the optimal set of features, the accuracy of the cross validation in each iteration is calculated and plotted against the number of selected features , leading to a selection of the top  <dig> features by the svm-rfe method and the top  <dig> features by the rf-is method . these numbers are chosen because they both represent the first significant minimums with near-best performance while the numbers of features are significantly smaller than the ones with the best performance. for example, in the rf-is case the best performance is achieved by the model with  <dig> features. it is clear that the performance gain from the  <dig> additional features is insignificant from the one with  <dig> features .

*aaindex database entry numbers.

evaluation of feature selection performance
we constructed a group of  <dig> classifiers using the top  <dig> features selected by the svm-rfe method and another group of  <dig> classifiers with the top  <dig> features selected by rf-is to evaluate the efficacy of feature selection. the results of the cross-validation of all classifiers on the dataset ap <dig> are shown in table  <dig>  it is observed that, 1) the top  <dig> features result in improved performance for all  <dig> tested algorithm; 2) the top  <dig> features produce enhanced performance of  <dig> classifiers , and reduced in the remaining four. overall, the feature selection process is very effective in removing a significant number of features  while improving the performance. in addition, the results imply that selected features are important to the aggregation propensities of those peptides.

we further evaluated the selected  <dig> and  <dig> features using lopo cross-validation. the lopo results show that svm and rf achieve good performance . therefore, we applied svm and rf to build  <dig> predictors for practical uses: proa-svm  and proa-rf .

tp: the number of true positive samples; fn: the number of false negative samples; fp: the number of false positive samples and tp: the number of true positive samples. ac: accuracy. mcc: matthews correlation coefficient.

comparison with other methods
proa-svm and proa-rf were compared on the dataset ap <dig>  with five state-of-the-art sequence-based predictors, namely aggrescan, tango, page, foldamyloid, and zyggregator. to display the outputs of these predictors together, their values are scaled into the numeric range of  <dig> to  <dig> . considering their different predictive thresholds, the roc  curves are used to evaluate the performance of all predictors. figure  <dig> clearly shows that the best performance is achieved by proa-rf with an auc  of  <dig> , followed by proa-svm with  <dig> , zyggregator with  <dig> , aagrescan with  <dig> , foldamyloid with  <dig> , page with  <dig> , and tango with  <dig> . based on the roc curve, if the predictive threshold  is set as  <dig> , the tn, fn, tp and fp are shown in the following table  <dig>  it can be seen that the best performance is achieved by proa-rf with accuracy  <dig> . the followings are proa-svm , zyggregator , aagrescan , foldamyloid , tango  and page . although proa-rf and proa-svm have better or comparable performance to other algorithms, caution should be taken in interpreting the comparison results because of the different data sets and validation strategies used to build these models. the results, nevertheless, clearly demonstrate that the feature selection procedure used in the study is able to identify features important to aggregation.

tp: the number of true positive samples; fn: the number of false negative samples; fp: the number of false positive samples and tp: the number of true positive samples. ac: accuracy.

application to identification of aggregation prone regions
to compare the ability to identify aggregation prone regions on entire sequences with those of other methods, we use proa-svm and proa-rf to generate aggregation propensity profiles of  <dig> proteins using sliding windows of length  <dig>  the models are built using the lopo approach and therefore both predictors scan and predict regions on one protein based on a model built on all other proteins.

in most cases, the predictions of all methods are in good agreement with the experiment data. nevertheless, in some cases the methods developed in this study can identify more true positives and true negatives than other approaches. one example is the aggregation profile of the microtubule-associated protein tau , whose function is involved in promoting microtubule assembly and stability. it has been experimentally validated that tau is involved in alzheimer’s disease  <cit> . figure  <dig> shows the aggregation propensity profiles by  <dig> predictors of the region 244– <dig> in tau. all  <dig> predictors are able to identify a nonamyloidogenic region 253lknvkskigste <dig> and an amyloidogenic region 304gkvqivyk <dig>  nevertheless, our methods correctly predict the nonamyloidogenic regions 244qtapvpmpd <dig> and 339vkse <dig>  which are predicted as amyloidogenic regions by most of other methods.

analysis of selected features
the  <dig> features from the union of top  <dig> and top  <dig> features can be roughly grouped into  <dig> different categories : aggregation propensities , hydrophobicity , propensities of secondary structure or conformation , energy , and accessibility . the index “x15925383” calculated using the zyggregator method  can be decomposed into the properties of hydrophobicity, secondary structure propensities and net charge. thus these results are consistent with previous findings that hydrophobicity, charges, secondary structure propensities of residues play important roles in the aggregation process. a detailed annotation of selected features is provided in additional file  <dig> 

properties relevant to protein aggregation are important to signal peptides
among  <dig> selected features, two are related to protein translocation. “vheg790101” is the free energy of transferring amino acids from aqueous solution to a lipophilic phase  <cit> , and “pram900103” is the statistics of the relative frequency of beta-sheets distributed in signal and nascent peptides  <cit> . there are  <dig> features related to hydrophobic properties such as rosm <dig>  vent <dig>  ponp <dig>  zimj <dig>  casg <dig> and wilm <dig>  it is consistent with previous publications that signal peptide and signal anchor sequences have a distinct hydrophobic region  <cit> .

this observation suggests that peptides with a tendency to aggregate may have similar properties with signal peptides and signal anchors. to test this hypothesis, we downloaded the signalp version  <dig>  dataset  which contains  <dig> groups of signal peptides and signal anchors  <cit>   and tested them by proa-svm and proa-rf . the accuracy of the predictions by proa-svm on the test dataset sp reaches  <dig>  , which is even higher than the accuracy of  <dig>  obtained in the predictions on the training set ap <dig>  the accuracy of the predictions by proa-rf  is also fairly good. therefore models built on ap <dig> with selected features can be used to predict signal peptides and signal anchors, indicating aggregation-prone fragments share similar physicochemical properties with these two types of functional sequences.

tp: the number of true positive samples; fn: the number of false negative samples; fp: the number of false positive samples and tp: the number of true positive samples. ac, accuracy; mcc, matthews correlation coefficient.

while it is interesting that aggregation prone peptides share common properties with signal peptides and signal anchors, the results are not particularly surprising since both aggregation and localization processes are associated with inter-molecular hydrophobic interactions. this observation, nevertheless, raises an interesting question whether aggregation prone regions of a protein determine the deposition site of protein aggregates since it has been observed that protein aggregates are deposited at specific cellular sites  <cit> . we suggest that the quaternary structure of protein aggregates, especially soluble oligomers, may allow the formation of new molecular recognition signals that guide aggregate targeting to specific cellular sites. if this hypothesis is confirmed, it will help us to better understand the molecular basis for protein aggregation and may have significant implications for developing new therapeutic strategies for treating protein aggregation related diseases.

methods
datasets construction
we compiled a set of peptides known to form or not form aggregates determined experimentally from the literature. after removing ambiguous entries, we obtained a set of  <dig> samples  including  <dig> positives and  <dig> negatives.  <dig> samples originated from  <dig> proteins  but  <dig> of them are de novo peptides. the average lengths of positives and negatives are  <dig>  and  <dig>  residues while the corresponding standard deviations are  <dig>  and  <dig> , respectively. considering the confusion of protein names and sequences in the literature, we referred these peptide sequences to the uniprotkb/swiss-prot database and used their uniprotkb/swiss-prot ids as their unique identifiers wherever possible. all entries of aggregation propensity dataset  <dig>  and their original references are provided in additional file  <dig> 

we obtained signal peptide data  from the signalp version  <dig> , which was previously used for identifying prokaryotic and eukaryotic signal peptides and predicting their cleavage sites  <cit> . sp contains  <dig> non-redundant datasets in which signal peptides and signal anchors are designated as positive samples and others as negative samples:

 <dig>  euksig.reduc:  <dig> eukaryotes signal peptides ;

 <dig>  eukanc.reduc:  <dig> eukaryotes signal anchors ;

 <dig>  gram+sig.reduc:  <dig> gram-positive bacteria signal peptides .

 <dig>  gram-sig.reduc:  <dig> gram-negative bacteria signal peptides .

feature extraction and peptide encoding
we compiled a collection of  <dig> features including  <dig> physicochemical properties obtained from aaindex database  <cit>  and  <dig> additional features collected from published literatures . all features were scaled into a range between  <dig> and  <dig>  each peptide is encoded by an array of  <dig> features, each of which is the average of corresponding features of the amino acid residues in the peptide. thus, the ith sample peptide is represented by  <dig> features in a form of x→i=xi <dig> xi <dig> …xij…xi <dig>  if a peptide or a protein contains an amino acid residue with ‘na’ value for a particular physicochemical property in aaindex, this amino acid are not used to calculate the average value for this physicochemical property.

classification algorithms
we use nine different classification algorithms to establish a performance baseline for classification and to test the efficacy of feature selection. these  <dig> algorithms include: svms  <cit> , rf  <cit> , generalized boosted models   <cit> , recursive partitioning and regression trees   <cit> , neural network   <cit> , partial least squares   <cit> , k nearest neighbours   <cit> , naive bayes   <cit> , and ada boost   <cit> . these algorithms are implemented in r using the caret package  <cit>  in this study. the following is a brief description of these algorithms. details can be found in the manual of the caret package and references cited therein. the specific commands including parameter tuning of each method used in the study can be found in the additional file  <dig> 

the svm algorithm is a supervised learning method, which can be used for classification or regression. it derives parameters of the maximum-margin to construct an optimized separating hyperplane by solving the optimization. the fit of svm classifiers includes the selection of kernel, the kernel's parameters, and soft margin parameter c.

the random forest algorithm is an ensemble machine learning method that utilizes many independent decision trees to perform classification or regression. each of the member trees is built on bootstrap samples from the training data by a random subset of available variables. each random forest model built in this study consists of  <dig> decision trees. the number of variable randomly sampled in each tree is , where m is the number of total variables.

gbm integrates the concept of boosting methods with that of classification or regression trees. using gbm for classification is to build a sequence of simple decision trees, where each successive tree is for the prediction residuals of the preceding tree. a learned function must be chosen from a restricted class of functions to most closely approximate the gradient of the loss function.

rpart is a method used to create decision trees and iteratively split the data on each of the nodes using user-specified splitting criteria. the algorithm chooses the split that partitions the data into separate nodes such that it minimizes the sum of the squared deviations of the mean in all of those nodes. the process continues until it satisfies a user-specified stopping criterion.

nnet is a computational model that imitates the structure and function of biological neural networks. it is typically defined by three types of parameters: the interconnection pattern between neurons, the learning process for updating the weights of the interconnections, and the activation function. the nnet used in this study is a feed-forward neural network with single hidden layer.

pls is an extension of the multiple linear regression model, bearing some relation to principal component analysis. a pls model is acquired by projecting the predicted variables and the observable variables into a new space. the pls can be used for classification and regression.

knn is one of the simplest machine learning algorithms. in knn classification, a sample is assigned to the class with most common amongst its k nearest neighbors  by a majority vote of its neighbors. despite its simplicity, knn is often shown good performance comparable to other state-of-the-art algorithms.

nb uses the bayes rule to compute the posterior probability of a categorical class variable, with the conditional independence assumption. one advantage of nb is that the decoupling of the class conditional feature distributions in calculation alleviates the problem known as the “curse of dimensionality.” another advantage is that nb does not need to accurately estimate the absolute accuracy of each class because the classification outcome is determined by the relative probabilities of all classes.

ada is an adaptive algorithm that can be used to build a series of classifiers, where subsequent classifiers are adapted in favor of those instances misclassified by previous classifiers. although ada can be sensitive to noisy data and statistics outliers, it has been found that it is often less susceptible to the overfitting problem than many other learning algorithms.

svm-rfe and rf-is
in this study, feature selection is executed using two state-of-the-art algorithms, svm based recursive feature elimination   <cit>  and a random forest importance spectrum based feature selection algorithm   <cit> . svm-rfe is based on a backward sequential selection, which starts with all the features and removes one feature each time. the removed feature is the one whose removal minimizes the variation of weights. in this work, svm-rfe uses linear kernel and c type svms  <cit> .

rf-is eliminates iteratively a number or a fraction of the least important features. random forest uses two methods to measure the importance, including the mean decrease in accuracy and mean decrease in node impurity measured by the gini index. the second approach is used in this study and 20% fraction of features   <cit>  is removed in each loop. the features are selected in this approach using the command varselrf.

cross validation
we use the standard 10-fold and leave-one-protein-out  cross validation methods to estimate the performance of classifiers. in 10-fold cross validation, we randomly split the ap <dig> into ten equal portions. we use nine portions as the training dataset and the remaining one as the test dataset. all parameters are fitted using an “inner” 10-fold cross validation in order to avoid potential overfitting problem. the procedure is repeated nine more times until each portion is used as the testing dataset once. lopo mimics real-world applications by grouping all of the peptides  according to the proteins to which they belong. we obtain  <dig> protein groups and a non-protein group comprising all de novo peptides. in lopo cross validation, the test dataset consists of samples from one protein or the non-protein group, with all other samples included in the training dataset.

performance comparison to other methods
we compare our methods with five state-of-the-art sequence-based methods including tango  <cit> , page  <cit> , foldamyloid  <cit> , zyggregator  <cit> , and aggrescan  <cit> . to visualize and compare the results of those methods, outputs from these methods are scaled into a range of  <cit> . since different methods may use different classification thresholds, the area under the receiver operator characteristic  curve  is used to evaluate the performances of all methods. auc is considered as a robust metric for classifier evaluation and comparison. an roc curve is generated by varying the output threshold of a classifier and plotting the true positive rate  against the false positive rate  for each threshold value. the roc curve has been widely used in many protein aggregation studies as a standard threshold-independent metric  <cit> . we also provide the matthews correlation coefficient   <cit> for each method:

 mcc=tp×tn-fp×fntp+fptp+fntn+fptn+fn 

where tp is the number of true positives, tn the number of true negatives, fp the number of false positives and fn the number of false negatives. mcc is in the range between − <dig> and + <dig>  a mcc of + <dig> represents a perfect prediction,  <dig> an average random prediction and − <dig> an inverse prediction.

prediction of peptide aggregation propensities and calculation of aggregation propensity profile of the whole sequences
in this study we aim to develop models for predicting aggregation propensity of short peptides  and aggregation propensity profiles of longer peptides  or entire proteins. the overall propensity of longer peptides or whole proteins is less significant since short aggregation prone regions, rather than the full-length sequences, are probably responsible for inducing the formation of most if not all aggregation.

each short peptide is encoded using an input vector composed of selected features. for a longer peptide or complete protein sequence, a sliding symmetrical local window centered at a particular amino acid residue is used to scan the sequence. each local window is also encoded with an input vector. the input vector is then used by the predictive models to calculate the aggregation propensity of the short peptide or local window. the predicted value, scaled to a range from  <dig> to  <dig>  is assigned to the short peptide or the central residue of the window. the predicted values for all of the local windows from the n-terminus to the c-terminus provide an aggregation propensity profile for longer peptides or whole protein sequences. the short peptides or the regions with values above the threshold  are considered as aggregation prone peptides or regions.

for predicting aggregation propensity profiles, we set the default window size to  <dig> amino acid residues. using a shorter window may result in a profile with poor smoothness and a longer window may contain more than  <dig> or more aggregation prone regions  <cit> . in addition, experimental measurements and theoretical calculations have indicated that approximate  <dig> residues are required to span the distance of protofilaments  <cit> . furthermore, the optimal window length in the foldamyloid algorithm was found to be  <dig> amino acid residues  <cit> . based on these considerations, a window size of  <dig> amino acid residues is chosen as the default size.

CONCLUSIONS
in this study,  <dig> physicochemical properties have been identified important to protein aggregation. these findings confirm that hydrophobicity, secondary structure propensities and net charge play important roles in protein aggregation. two sequence-based predictors  are built to predict peptide aggregation propensities based on the svms and rf algorithms. both predictors demonstrate good generalization abilities and can be used to identify aggregation prone regions of proteins. an interesting new finding is that aggregation peptides have similar properties to those of signal peptides and anchors, which indicates that the aggregation prone regions may also determine the deposition location of protein aggregates. we suggest that the quaternary structure of protein aggregates may allow the formation of neo- signals that guide aggregate targeting to specific cellular sites. if this hypothesis is confirmed, it will provide better understanding of the molecular basis for protein aggregation, and may have significant implications for developing new therapeutic strategies for treating protein aggregation related diseases.

abbreviations
proa-svm: protein aggregation svm predictor; proa-rf: protein aggregation rf predictor; svm: support vector machine; rf: random forest; svm-rfe: svm based recursive feature elimination; rf-is: random forest importance spectrum based feature selection; lopo: leave-one-protein-out; gbm: generalized boosted model; rpart: recursive partitioning and regression tree; nnet: neural network; pls: partial least square; knn: k-nearest neighbour; nb: naive bayes; tp: the number of true positive samples; fn: the number of false negatives samples; fp: the number of false positives samples; tn: the number of true negatives samples; ac: accuracy; mcc: matthews correlation coefficient.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
jf conceived the project. sg and yf carried out the study with input from cm and jf. yf, sg, cm and jf drafted the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
selected features and their aaindex records.

click here for file

 additional file 2
the dataset ap <dig> .

click here for file

 additional file 3
 <dig> additional features collected from published literatures.

click here for file

 additional file 4
commands of the classification algorithms used in the study.

click here for file

 acknowledgements
we are indebted to professor amedeo caflisch, professor luis serrano, and their research groups for providing the page and tango programs. we also thank dr. max kuhn for his help in using the caret package, and dr. david volkin for his review of the manuscript. this work was supported in part by the national institutes of health  grant p <dig> ag <dig> .
