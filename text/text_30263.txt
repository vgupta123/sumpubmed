BACKGROUND
recently, microarray technology has provided the means for simultaneous screening and analysis of thousands of genes. although an enormous volume of data is being produced by microarray technologies, the full potential of such technologies cannot be accessed without the ability to sift through the noisy signals to obtain useful information. the large data sets produced by microarray technology have resulted in the need for reliable, accurate, and robust methods for microarray data analysis. a major challenge is to detect genes with differentially expression profile across two experimental conditions. in many studies, the two sample sets are drawn from two types of tissues, tumours or cell lines, or at two time points during the course of a biological processes.

the computationally simple methods used for such analysis, including the methods of identifying genes with fold changes   <cit> , are known to be unreliable due to the fact that in such methods the statistical variability of the data is not properly addressed. while various parametric methods and tests such as two-sample t-test  <cit>  have been applied for microarray data analysis, strong parametric assumptions made in these methods as well as their strong dependency on large sample sets restrict the reliability of such techniques in microarray problems. the nonparametric statistical methods, including the empirical bayes  method  <cit> , the significance analysis specialized for microarray data  and the mixture model method   <cit>  have been specialized and applied for microarray data analysis. it is claimed and argued that the new extensions of the mmm are among the best methods producing biologically-meaningful results  <cit> . in this paper, without ignoring the potential applicability of non-parametric methods in microarray processing applications, due to the claims made in  <cit> , we have restricted the comparison of our methods only to the mmm based methods.

the major disadvantages of the above-mentioned methods, especially the mmm, include the lack of repeatability of the results under different runs of the algorithm, and the sensitivity of the algorithm on parameter initialization. a reliable microarray analysis method must be reproducible and applicable to different data sets under different experimental conditions. more specifically, an accurate microarray processing method is expected to pinpoint, with a relatively high degree of accuracy and robustness, genes with elevated expression levels that are related to the experimental condition in all runs. the main objective of this paper is to design and test an extension of the mmm whose results are reproducible, more biologically meaningful, and significantly less sensitive to the models' parameters.

the paper is organized as follows. in algorithms section, a review of the mmm and its recent extensions, mod2mmm, together with the detailed description of the proposed method are given. in results and discussion section, the k5m algorithm is first applied to the well-studied leukaemia data set  <cit>  that is often treated as a benchmark problem to compare different algorithms with each other. once the desirable performance of the proposed algorithm is verified against the leukaemia data set, the algorithm is applied to a new data set  that deals with the pathogenesis of hypophosphatemia, which is a common x-linked metabolic bone disorder in human and mouse. finally, the conclusion section is in the end.

algorithms
mmm & its recent extensions
we start this section with a brief review of the existing mmm based techniques. consider yij as the expression level of gene in array i , where the first j <dig> and last j <dig> arrays are obtained under two conditions. a general statistical model for the resulting data is:

yij = ai + bixj + εij     

where xj =  <dig> for  <dig> ≤ j ≤ j <dig> and xj =  <dig> for j <dig> +  <dig> ≤ j ≤ j <dig> + j <dig>  in addition, εij is a random error with mean  <dig>  from the above formulation, it can be seen that ai + bi is the mean expression level of the first condition, and ai is the mean expression level of gene i in the second condition. the method requires that both j <dig> and j <dig>  the number of data sets for each experiment condition, be even.

the t-test statistic type scores  and  are calculated on the pre-processed data. here, ai is a random permutation of a column vector that contains j1/ <dig> 1's and j1/ <dig> -1's and bi contains j2/ <dig> 1's and j2/ <dig> -1's.





since the data are not assumed to be normally distributed, the distribution functions f <dig> and f are estimated as in  and , respectively. the null distributions, f <dig> and f, are estimated directly in a nonparametric model for gene expression data.





where φ symbolizes the normal density function with mean μi, variance vi, and the mixing proportions πi define the linear combination of the normal basis function. we use Φg <dig> to represent all unknown parameters {: i =  <dig>  ..., g <dig> } in a g0-component mixture model. the number of normal basis functions, i.e. g <dig> can be estimated by the em algorithm, which maximizes the log-likelihood function of  to obtain the maximum likelihood estimation of .



within k iterations, the em algorithm is expected to find the local maxima for all unknown parameters. it is recommended to run the em algorithm several times with various random starting parameters and choose the final estimate as the one resulting the largest log-likelihood  <cit> . as mentioned above, using random starting points causes the result of the mmm instable and avoids reproducibility of the results. more specifically, in each run the mmm algorithm may give different number of expressed genes, which is not desirable in biological studies. this issue will be addressed in our proposed method.

after finding the optimized  for different g <dig> 's, the algorithm selects the sub-optimal g <dig> corresponding to the first local minimum of bic or aic  <cit> .





where vg <dig> is the number of independent parameters in Φg <dig>  then, the algorithm uses the resulting g <dig> as the number of normal functions to fit f <dig>  the same procedure is performed to estimate the sub-optimal number of normal functions to estimate f. as mentioned above, with the fixed number of normal functions, the parameters of functions f and f <dig> are iteratively updated for a number of iterations. when the iterations are terminated, the likelihood ratio is estimated based on the final estimations of f <dig> and f:

lr = f <dig> / f     

a bisection method  <cit>  with a bonferroni adjustment is used to determine the cut-off points  <cit>  for decision-making. this means that for a threshold value s, if lr <s, then the gene is identified to have significantly altered expression in two experiments. it is possible to determine the rejection region numerically, i.e. for any false positive rate α, the threshold value s = s can be calculated from the following integral:



in literature of microarray processing, α =  <dig>  is often used as the genome wide significant level, so the gene-specific significance level is: α* = α/ recently a new modification of the mmm algorithm, mod2mmm hereafter, was introduced  <cit> . this method points out a problem in constructing the test and null statistics and indicates that the true distribution of z may be different from the null distribution of z, which can lead to invalid inference. the modified algorithm starts with the assumption that j <dig> ≥  <dig> j <dig>  <cit> , and constructs the new z and z as you can follow in appendix <dig> 

for the cases where j <dig> ≥ j <dig> but j <dig> <  <dig> j <dig>  j <dig> observations drawn under condition one are split into two equally-sized parts to calculate , vi and , vi respectively. to calculate  and vi about j1/ <dig> observations are drawn under condition two. while this modification can address the differences in the distributions of f and f <dig>  the stability of the parameter estimation step still remains a major problem.

the main difference between the conventional mmm and its recent extensions are that the conventional mmm disregards the fact that the true distribution of z  may be different from the null distribution of the statistics z . this assumption can potentially lead to invalid inference. a modified version of the mmm , introduced in  <cit> , assumes that the denominator and the numerator of one of t-statistic-type score zi may not be independent. this method addresses the issue by constructing new zi and zi variables as will be discussed later.

a concern over all existing mmm based methods  that greatly affects the results is associated with the way mixed distributions are estimated. in the mmm, expectation maximization  algorithm  <cit>  is often used to optimize the parameters of fitted mixture distribution functions of two t-statistic-type scores related with genes expression level. starting the em algorithm with random values as the parameters of the normal basis functions to estimate distributions makes the results depend highly on the exact initialization, and always makes variations in the results. on the other hand, if all parameters of the normal functions in the mixture model distributions are set without iterative optimization, the set values may never result to an accurate model of the data set in hand. we propose a modified version of mmm to address this problem. our modified mmm  combines k-mean clustering and the em estimation to not only optimize most of the parameters with the em iteratively but also apply k-means to optimize other sensitive parameters to ensure complete reproducibility of the algorithm. the experimental results indicate superior robustness of the proposed algorithm compared to the conventional mmm and other recently introduced extensions of the mmm  <cit> .

proposed method 
in order to address the stability and reproducibility of the mmm, we propose a new modified approach for the mmm that estimates the distribution function of z by using mixture of normal distributions in a stable and reliable way. the following observations made in the experimental study of the mmm for gene expression analysis were the main motivations for the proposed changes to the mmm:

 <dig> the observed variations in the parameter estimation process in some versions of the mmm can be attributed to the algorithm's attempt to iteratively update the means and variances of the normal distributions using often noisy data. in experimental studies, often the direct observation of the data reveals specific points where centers  can be positioned and the scattering patterns that can give reliable estimates on the variance of each cluster. however, the iterative updating of model parameters with noisy data and based on some random starting points often misses the true optimal points and even creates variations and fluctuations in parameter estimation in many runs.

 <dig> even when variations do not occur, two runs of the algorithm can result to significantly different estimations of f and f <dig>  this in turns results to lists of differentially expressed genes in different runs. more specifically, a set of two typical runs of the algorithm on the same data set can result to two lists that are very different both in number of the genes as well as the exact genes picked up by the algorithm. in our study of the conventional mmm and mod2mmm, two runs with the same algorithm  resulted to lists whose size vary between  <dig> and  <dig> 

 <dig> the literature of other areas of research utilizing normal basis function for estimation including neural networks indicates that in order to have more robustness in different runs and have reproducible results, the means and variances of the basis functions must be estimated and fixed during the iteration on the coefficients  <cit> . this is due to the fact that updating means and variances makes the estimation process a nonlinear one that is highly sensitive and very likely to become unstable. however, when updating the values of coefficients only, the problem is reduced to a reliable linear estimation that is much more robust and stable.

 <dig> based on the observations mentioned above, in our proposed method, finding the distribution of z is regarded partially as a clustering problem, i.e. the means and variances of the normal distributions are estimated as the prototypes of a clustering step. specifically, if z is distributed in a one-dimensional space, wherever there is a mass of z, there is a cluster with mean μi and variance vi, which are identified by the members of that cluster.

hence applying a clustering method is capable of estimating the means and variances of each normal distribution. the key is to use a simple clustering technique such as k-mean to estimate the mixture distributions f <dig> and f based on k normal distributions. while the algorithm can use k-means to find the optimal values of means and variances, the coefficients πi 's need to be optimized using an optimization process such as the em.

based on the above discussion, the proposed algorithm can be described in the following two steps:

step 1: using bic, find the sub-optimal number of normal distributions for both f and f <dig> . these optimal numbers are then used as the number of clusters in k-means technique.

step 2: using k-means clustering technique, for both f and f <dig> find the best mean μi and variance vi for all clusters.

step 3: with the obtained values of μi, vi and using the em algorithm, iteratively update the values of the optimized πi for all clusters , i.e.



a reasonable number of clusters is expected to be obtained from the first step of the algorithm, and the estimation results of the two bellow data sets in tables  <dig> and  <dig> show that the used k  is satisfactory. table  <dig> shows the results of the mmm and k5m methods for the run with an unequal variance and four normal distributions for both f and f <dig>  the mmm creates the likelihood ratio  statistics plotted in figure  <dig>  the k5m with k =  <dig> forms the lr statistics plotted in figure  <dig>  and the k5m with k =  <dig> results to the lr plot of figure  <dig> 

it is worth mentioning that due to the random initialization in k-means and the random initialization of the coefficients πi 's, in each run, it is expected that the number of identified differentially expressed genes fluctuate slightly. however, as indicated above, since the k- means clustering algorithm is known to a robust method, and considering the fact that in the em estimation process, only a linear estimation is performed, it is expected that the robustness of the proposed algorithm be much more than the other version of the mmm based algorithms. this observation, as have been shown before, is supported by our experimental results. in addition, our experimental indicate that the most expressed genes are identified in all runs or the algorithm and in each run one or two new genes with less expression ratio are added to this set.

RESULTS
in this section, first the two applications and their corresponding data sets are described and then the results produced by the proposed method  is compared with the other mmm based methods on two data sets. the detailed description of the methods is given in mmm & its recent extensions section.

leukaemia dataset
in this section, we apply the nonparametric mmm method with and without the proposed modifications to the leukaemia data presented in  <cit> . the objective of this application is to identify the most important genes involved in development of different types of leukaemia. the dataset used for this analysis includes  <dig> acute lymphoblastic leukaemia  samples and  <dig> acute myeloid leukaemia  samples for  <dig> genes. the main goal is to find genes with differential expression between all and aml cases. a second goal is to compare the result of mmm and mod2mmm  with k5m and test the robustness of k5m. the genome-wide significance level is chosen α =  <dig>  . each sample in the dataset is pre-processed as in  <cit> , by subtracting its median and dividing the resulting variable by its quartile range .

results of leukaemia study
thomas et al  <cit>  used known biological information to identify the most important genes in leukaemia and provided biological justifications for these identified genes. they introduced  <dig> genes out of the identified genes as the most expressed and related genes to the disease, including  <dig> most expressed genes for aml and  <dig> for all. we treat thomas et al's list as the biology knowledge base and compare the capabilities of the computational techniques to correctly identify the genes discussed in  <cit>  by processing the dataset.

the comparison of the result obtained by the k5m with those of the mmm and the mod2mmm is summarized in table  <dig>  as can be seen in table  <dig>  the mmm has identified  <dig> differentially expressed genes  <cit> , among which the total of  <dig> genes are in the list of genes obtained by thomas et al  <cit> . the mod2mmm method found  <dig> genes of the thomas's list. the k5m algorithm, determines  <dig> genes that are identified in the thomas's list, i.e. the proposed algorithm successfully identifies 90% of biological result. this means that k5m improved the detection of expressed genes 12% compare to the mmm and 30% compare to the mod2mmm for the leukaemia data, i.e. our method identified more genes from the list of the  <dig> truly expressed genes identified by thomas et al  <cit> .

as the bic suggested the optimum number of clusters k =  <dig> for the mmm, the k5m is applied with k =  <dig> also. running k5m with different number of clusters leads to the different but reasonably similar results. as the number of the clusters increase, the number of expressed genes decreases. table  <dig> shows that the k5m with k =  <dig> identifies the total of  <dig> differentially expressed genes, while with k =  <dig> the total of  <dig> genes are identified, however; the  <dig> genes found with k =  <dig> are the most expressed genes among  <dig> genes found by k =  <dig>  this result shows the consistency of the k5m method.

in order to further compare the performance of the mmm and k5m on the leukaemia data, the roc curve is plotted based on false positive rate and true positive rate of the data set calculated as in  <cit> . the area under each curve is the measure of test accuracy. as can be seen in figure  <dig>  the area under the k5m curve is more than the area under the mmm curve, therefore the k5m is providing a more accurate classification than the mmm.

hypophosphatemia dataset
the following study is the main application for which the proposed method was specialized and therefore is described in more details. hypophosphatemia is a common x-linked metabolic bone disorder in human. hypophosphatemia results from phosphate wasting in the renal tubules. phosphate that is normally reabsorbed from the urine is excreted. it appears that elevated levels of fgf- <dig> activate the excretion of phosphorous by the kidneys. previous studies have demonstrated an impairment of the high- affinity, low capacity na+ dependent phosphate co-transport system  <cit> . the main animal model used to study this disease is the hyp mouse. hyp mice have a mutation of the phex gene  <cit> . the disease is characterized by low reabsorption of phosphate, bone disease, and bone abnormalities in the lower extremities. the genes active in the regulation of phosphate re-absorption in the kidney are not well understood. it is also not clear whether mutations of the phex gene block renal adaptation to low phosphate diet. hyp mice have a primary osteoblast defect and defects in vitamin d metabolism. parabiosis experiments on normal and hyp mice have revealed that there is an intrinsic osteoblast defect in hyp mice rather than an intrinsic renal abnormality. hyp kidneys transplanted into normal mice reabsorbed phosphorus at normal levels. kidneys transplanted from normal mice into hyp mice began phosphate wasting in the hyp mice.

the mechanism that leads to the excessive excretion of phosphorous is unknown. on a low phosphate diet a normal mouse will activate systems to conserve phosphate by increasing re-absorption. the genes activated in the normal mouse on the low phosphate diet, and the genes with differential expression between normal and hyp mice should indicate the systems involved in the phosphorus homeostasis. in an attempt to identify these genes, nutritional experiments were performed on normal and hyp mice . normal and hyp mice were placed on low phosphate diets for  <dig> –  <dig> days. tissue samples from the kidneys of test and control mice were collected.  <dig> samples were analyzed using affymetrix genechip mouse u74a arrays-  <dig> samples for each experiment state. the mrna of  <dig>  genes was analyzed. two genechip microarrays were done for each diet for normal mice and three microarrays for each diet for the hyp mice for a total of  <dig> arrays.

to investigate this, 5-week-old normal and hyp were fed a control  or low phosphate  diet for five days. the four group experiments are shown in table  <dig> 

in this study, we consider the gene expression signal less than  <dig> as noise caused by the microarray machine, and in the pre-processing step we ignored the genes whose expression signals in both conditions are less than  <dig>  the following two specific goals are considered in this study:

 <dig>  to identify the genes in whose mrna expressions are altered by low phosphate diet in normal mice.

 <dig>  to determine the effect of hyp mutation on this response, i.e. identifying the genes in hyp condition that are differentially expressed across the normal and low phosphate diet experiments.

results of hypophosphatemia study
the hyp dataset includes five samples for each group. in order to make the number of data samples even, we used four samples of each group. for this data set, since j <dig> = j <dig>  the mod2mmm cannot be applied. in mmm method, five mixture models are used to estimate f <dig> and f  with number of normal basis functions ranging from  <dig> to  <dig>  i.e. the mmm algorithm was run several times and the run with maximum log-likelihood was chosen as the final model. bayesian information criterion   <cit>  was used to determine the number of components. to find the rejection region for a given model, the bisection method is used. in this paper we assume α =  <dig> , and therefore the gene-specific significance level used here is calculated as:

α* =  <dig> / =  <dig> * 10-7

using bisection method  <cit> , as discussed in section  <dig>  the value of s is obtained as s =  <dig> × 10- <dig> . both the mmm and k5m were run  <dig> times. figure  <dig> presents the number of genes expressed in each run of the mmm. the difference between the number of identified differentially expressed genes in two runs with the minimum and the maximum number of genes amounts to  <dig> genes. this clearly indicates the high degree of inconsistency and irreproducibility of the results obtained by the mmm. the number of genes expressed in each run of the k5m indicates that all genes are the same in all runs and therefore indicates 100% repeatability and robustness of the proposed method.

the ten most significant genes expressed by the low phosphate diet in the normal mouse identified by the mmm, and the ten most significant genes provided by k5m are represented in table  <dig>  as can be seen in table  <dig>  the most differentially expressed genes are same for the mmm and k5m. out of these  <dig> genes, six are directly related to the kidney's functions. for this data set, the main advantage of the k5m is its consistency and robustness as discussed above. a similar procedure is conducted to accomplish the second goal of this study, i.e. identifying the role of hyp condition on the most definitely expressed gene in normal and low phosphate diet microarrays. the ten most significant genes that are differentially expressed across the two experimental conditions, i.e. normal low phosphate and hyp low phosphate, are listed in table  <dig>  as shown in the table  <dig>  again eight genes are related directly to the kidney's function. these further witnesses to the capability of the proposed technique to discover the genes that are truly involved in the biological study.

CONCLUSIONS
in this paper, we proposed a technique to improve the repeatability, and robustness of the mixture model method by using the k-mean clustering method in estimating the distributions. our proposed method finds the distribution of the variables partially based on a clustering procedure and an em optimization process. the method is applied to analyze two microarray data sets, leukaemia data set and a data set reflecting the effect of the low phosphate diet on regular and hyp mice  <cit>  data. the experimental results indicate 100% robustness and repeatability of the results in different runs and provide 12% improvement  in detecting the relevant genes in both studies.

authors' contributions
maryam zaheri, and ali a. rad were in charge of writing the codes and programming aspects of the paper.

siamak najarian and javad dargahi's primary role was to perform a literature review on mixture model techniques, identify the aspects of the method that need to be improved, and provide suggestions to address these shortcomings.

kayvan najarian's primary roles were to design improvments to the algoritm , prepare and pre-process the data , partcipate in preperation of the hyp dataset, define the hyp problem interpret the results and finally write and edit the manuscript.

appendix 1
the mod2mmm makes a new z and z based on the following formula:





where:





and:



