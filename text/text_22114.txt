BACKGROUND
computational protein annotation is a major goal of bioinformatics and annotation methods are widely used. a wide variety of annotation methods exist, many of which rely on some kind of scoring. typically, when testing whether a protein should be given a certain annotation, a score threshold is set, and proteins that score higher than the threshold are given the annotation. obviously, some annotation mistakes may occur. such mistakes can be divided into false positives  and false negatives . fps  are annotations that were mistakenly assigned to a protein . fns  are annotations that should have been assigned to a protein but were not . adjustment of score thresholds allows tradeoff between these two types of mistakes. fps annotations are considered to be of graver consequence than fns. this is partially due to the fact that introduction of a false positive annotation into a protein database may cause other proteins to become incorrectly annotated on the basis of sequence similarity  <cit> . a systematic evaluation of the source of false annotations that already contaminated current databases was reported  <cit> . several automatic systems such as pedant  <cit>  and genequiz  <cit>  were introduced with the goal of matching the performance of human experts. still, over interpretation, fn errors, typographic mistakes and the domain-based transitivity pitfall  <cit>  limit the use of such fully automatic systems for inferring protein function.

due to the importance of minimizing the amount of false annotations and maintaining highly reliable protein databases, three methods are generally used to avoid false annotations. the first method is manual validation of the annotation of each protein, which creates a serious bottleneck in the addition of new proteins and annotations to the database. the second method is using high score thresholds, thus lowering the rate of fps but also increasing the rate of fns . the third method is requirement for hits from different detection methods, eliminating advantages that are unique to some methods. thus it would be beneficial to develop means by which fp annotations could be detected automatically, allowing both high throughput and high sensitivity.

here we present such a method that uses clustering of protein functional groups to separate true positives  from fps automatically. our method is based on the following notions:  protein annotations represent biological properties;  protein functional groups share specific combinations of biological properties, essentially constituting "property clusters";  if two proteins have very different combinations of annotations, they are unlikely to share a single functional annotation and therefore there is a high chance that one of them was given that annotation incorrectly. these notions are not obvious, but were shown to correctly indicate false annotations in some individual cases tested manually using the graphical annotation-analysis tool of pandora  <cit> . we aim to generalize these sporadic observations and to address the feasibility of automating the detection of fp.

using these ideas, the method attempts to separate a group of proteins into "property clusters", by introducing a measure that quantifies the similarity between the annotation combinations of two proteins. according to our basic notions, these clusters are likely to be in accordance with false and true hits.

we tested our method on the prosite protein signature database  <cit> . the database consists of  <dig> protein signatures  that were assigned to a protein database. prosite annotation of proteins is manually validated, stating for each protein hit whether the annotation is a tp or a fp. out of this set of  <dig>  signatures, we chose a subset of all signatures that have both true and false hits, and this served as our test set. altogether  <dig> such signatures were collected and tested. for each of the signatures, the method examined the set of proteins that were assigned the signature. we called the separation successful only if at any step of the clustering process all the tps were clustered together without any fps. we applied a stringent scoring, where a partial success is considered failure.

furthermore, we constructed a random fp simulation test in order to provide a more extensive test. in this test, all  <dig>  interpro  <cit>  annotations were considered. for each interpro annotation we selected the set of proteins in swissprot  <cit>  that were assigned that annotation, and added to that set random proteins, simulating proteins that were assigned the annotation by mistake . for each annotation we repeated the test  <dig> times:  <dig> times with  <dig> random protein,  <dig> times with  <dig> random proteins and  <dig> times with  <dig> random proteins. this artificial contamination of the annotation source strives to simulate mistaken annotations that may occur under some automation annotation inference schemes.

RESULTS
property-based clustering
we begin by describing the method of property-based clustering. given a set p of all proteins that were given a certain annotation, and that there are both fps and tps in p, we would like to separate the set into disjoint subsets, so that one of the subsets will include all tps and no fps .

annotation-based clustering is used to detect these subsets. we define an annotation as a binary property assigned to a protein . at the first stage, annotations from go   <cit> , interpro  and swissprot  are gathered for all proteins in p.

the clustering works in the following way: between each two proteins we define a similarity score that tries to quantify how much do the two proteins have in common from a biological perspective. the score between two proteins p <dig> and p <dig> is defined as:



where a <dig> and a <dig> are the set of annotations of proteins p <dig> and p <dig> respectively, i is the current annotation, and f is the frequency of i in the database. this score uses the following logic: if two proteins share an annotation, they are biologically similar in some manner. the more annotations these proteins share, the more cause we have to believe that they are similar biologically. however, two proteins sharing an annotation like "enzyme"  should receive a worse similarity score than two proteins that share a much uncommon annotation like "heat shock protein" . this is taken into account by using log). obviously, one could think of different scoring schemes that would quantify this differently. for a specific example of how the score is calculated see table  <dig> 

the similarity score is calculated between every two proteins in p. next, we define the similarity score between two clusters as the arithmetic average of scores of all inter-cluster protein pairs:



where c <dig> and c <dig> are clusters of proteins. starting with clusters of  <dig> protein each, the method begins by an initial one-step clustering which merges all clusters that have the exact same combination of annotations. following this the primary clustering commences: at each clustering step the two clusters that have the highest similarity score are merged. at each step the contents of the clusters are evaluated, and if all tp proteins appear in one cluster without any fps, we say that the clustering process successfully separated the tps from the fps. note that we do not require all the fps to be grouped into one cluster, due to the fact that they cannot be expected to share biological similarity amongst themselves.

prosite test
out of  <dig> sets of proteins that share a prosite signature, the method showed successful separation  in  <dig> sets, i.e. 69% of the cases. the average size of the protein sets was  <dig>  and the median  <dig>  altogether  <dig>  proteins were used for this test. the average and median fp rates ) of the sets were  <dig>  and  <dig>  respectively. these general statistics about the test set indicate that the sets were large enough and had a high enough amount of tps and fps so that the chance of random success would be minimal.

in order to demonstrate the method's performance in this test, we provide the following example of testing a single protein set. the set presented here is the set of all  <dig> proteins that matched the prosite "serum albumin family" signature. each protein in the set contains an average of  <dig>  annotations . first, the score between every pair of proteins is calculated, based on their mutual annotations. next, the proteins undergo a preliminary clustering step in which all proteins that have the exact same combination of annotations are merged into clusters. following this, the proteins are clustered together based on their mutual similarity score. finally, once the clustering has finished we examine the tree to see if the true positives were separated from the false positives. in the given example, there are  <dig> proteins that were incorrectly assigned the prosite annotation , and in figure  <dig> we see that they are indeed separated from the tp proteins.

random fp simulation test
 <dig>  sets of proteins were tested  <dig> times each and showed successful separation in 74% of the cases. altogether  <dig>  proteins were used for this test. this can be subdivided into 78% success for the sets that had  <dig> random protein added, 74% success for the sets that had  <dig> random proteins added and 68% for the sets that had  <dig> random proteins added. the average set size was  <dig> proteins. the drop in the performance by increasing the level of fps is due to the fact that there is a higher chance that one of the randomly selected proteins will be biologically similar to the tps. since we consider only cases in which all fps are detected, then there would be a higher chance of failure as the number of randomly-generated fps increases.

while the simulation of fp errors randomly provides endless amounts of test sets, which is a clear advantage over the limited test sets provided by a real database such as prosite, the simulation has its own limitations. the hidden assumption made by this approach is that the fp hits are independent of each other. this assumption is not necessarily true: for example, if annotation is done by means of sequence similarity, false hits may be more likely to be biologically similar to each other . in fact, in many cases in the prosite test we find that the correct separation separates the tp proteins into one cluster and the fp into one or two clusters, suggesting that the fps share some degree of biological similarity . this difference in the way that fp annotations are generated may also account for the difference in success rates between the prosite test set and the simulated test set. the way fp annotations are introduced into databases is impossible to model, but the combined success of the method on both a real database test set and on an extensive simulated test set seems promising.

a further issue which concerns the simulation method is determining the amount of fps to add to each set. here we chose to add  <dig>   <dig> or  <dig> proteins to each set. this does not necessarily reflect the amount of fps in real databases. understandably, each database's average fp rate depends on its specific characteristics. however, the prosite database's average fp rate of  <dig>   might give an indication as to what a typical rate is. in comparison, the average fp rate for our random simulation set was  <dig>  , which suggests that our choice was reasonable.

determination of the correct halting step
we call a clustering process successful if it managed at any step to separate the false annotations. however, this step must be somehow determined automatically. there are two approaches to this: one is to use an intrinsic parameter of the clustering process that would indicate where the correct halting step is located; the other is selecting a predetermined step of the process. we chose the similarity score at each merging step as an intrinsic process parameter. when plotting the score against the progression of the clustering , a knee shape in the plot would indicate a point of stability , suggesting it as a potential halting step. analysis of the second derivative of this plot allows finding these knee-shaped stability points automatically. using this method, 56% percent of the correct halting steps in the prosite test were correctly predicted. a different approach was to always choose the last step or the last two steps as the correct halting step. this resulted in 45% and 65% correct prediction, respectively. furthermore, the union of the correct predictions made by both approaches indicates that together they correctly predict the halting step in 79% of the prosite test cases.

discussion
prediction of success
interestingly, we found that with certain sets the method tended to be more successful than with other sets, probably indicating that these sets are more coherent biologically. this might suggest exploring an approach in which for each annotation one could predict the level of success provided by this method. furthermore, we used the interpro categorization of annotations into types in order to check success in specific annotation types. interpro divides its annotations into different categories, such as "domain", "repeat" and "family". understandably, "family" type annotations had a ~30% higher success rate than the other annotation types, primarily due to the fact that the "family" annotations often represent protein sets that are biologically coherent whereas other types such as "repeat" or "domain" annotations are biologically diverse. this result would be expected by a method that performs a clustering based on biological similarity. this indicates that this approach should be aimed primarily at functional family annotations.

however, functional families can be defined at different resolutions: an alcohol dehydrogenase belongs to the enzyme family, the dehydrogenase family and the alcohol dehydrogenase family. the test sets of the prosite and interpro databases mainly represent mid-level and low-level annotations, with a typical size of tens or a few hundreds of proteins . in order to further our understanding of the resolution in which this method is successful, we divided the protein groups into size categories and studied the relative amount of success in every size category. figure  <dig> shows that as the group size increases, the rate of success decreases. assuming larger sets represent the higher level annotations of interpro, this suggests that when the annotations are more general  they have less in common biologically. therefore, we would not expect the method to succeed on very general terms such as "enzyme". sporadic tests of several high level go annotations suggest that this is indeed the case .

annotation source interdependency
because multiple annotation sources were used, concerns arose regarding interdependencies amongst them. for example, interpro is highly dependent on prosite, so proteins that have a prosite annotation will very likely be assigned an interpro annotation as well automatically. in order to minimize this effect, we did not allow the algorithm to use the interpro annotations that matched the prosite annotation which was being tested. furthermore, in order to increase reliability of the random fp simulation test, all known prosite fps were removed from interpro prior to the test. still, there is some concern that the results are partially biased due to annotation source interdependencies. furthermore, it is difficult to determine whether these dependencies represent true biologically dependent properties, or simply a duplication of the same property in different sources. keeping this difficulty in mind, our results which show different levels of success for different types of annotations  indicate that the success of the method is more likely due to biological dependency rather than artificial duplication.

sufficient annotation
it should be stressed that the clustering process is based on sufficient annotation. therefore, it may be difficult to apply this method to proteins that are poorly annotated. still, these cases should be relatively rare: nearly 77% of the ~ <dig> , <dig> proteins in trembl  <cit>  have at least one annotation by interpro, and when considering several annotation sources there are on average ~ <dig> annotations per swissprot protein. note that the amount and richness of annotation is constantly increasing at a fast rate. furthermore, the ability to detect false annotations automatically may allow an increase in the sensitivity of current methods, thereby allowing more extensive annotation of proteins.

it is worthwhile noting that amongst the  <dig>  proteins used in these sets there were  <dig>   proteins annotated by swissprot as "hypothetical proteins". 18% of the sets that were successfully separated contained such hypothetical proteins, with an average of 8% hypothetical proteins for each such set. these results suggest that the method is capable of handling to some extent hypothetical proteins of unknown function.

another helpful approach to the problem of insufficient annotation could be the introduction of quantitative protein properties that are easily determined and show some correlation with function  into this method. preliminary testing showed some positive correlation between protein length and isoelectric point with function in certain cases .

CONCLUSIONS
introduction of fp annotations into protein databases can be harmful. it has been shown that once a mistaken annotation is introduced into a database, it often transfers to other proteins that are sequentially similar causing a propagation of false annotation  <cit> . due to the importance of keeping high-quality databases, either the proteins are manually checked one by one or the annotation detection sensitivity is reduced in order to minimize fps. the error rate and the limited sensitivity of assigning structural annotations using psi-blast  <cit>  or sam-t <dig>  <cit>  and methodologies based on hmms and svms had been reported  <cit> . naturally the process of manual validation of the annotation of protein databases is extremely time-consuming and in many cases is subjective to the expert view. automatic detection of false annotations greatly facilitates the task of manual validation of annotation, and allows using lower thresholds when trying to detect protein signatures, therefore allowing higher method sensitivity.

based on the notion that protein functional groups share specific combinations of annotations, we have introduced a method that by separating a set of proteins into biological "property clusters" shows successful separation of incorrectly annotated proteins from correctly annotated proteins. we test the method both with a manually validated test set and with a randomly constructed test set, and in both cases show a high degree of success. these results suggest that this tendency of certain annotations to appear in groups may be used as a basis of automatic methods that detect fps. naturally, different computer learning methods can be used to take advantage of these interdependencies of biological properties .

