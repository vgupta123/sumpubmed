BACKGROUND
biomedical text mining  has become increasingly popular due to the great need to provide access to the tremendous body of texts available in biomedical sciences. considerable progress has been made in the development of basic resources  and techniques in this area, e.g. in information retrieval   and information extraction  , and research has began to focus on increasingly challenging tasks, e.g. summarization and the discovery of novel information in biomedical literature  <cit> .

the major current challenge is to extend tm techniques with richer and deeper analysis and to apply them to support real-world tasks in biomedicine. in recent past, there has been an increasing trend towards research which is driven by actual user needs rather than by technical developments  <cit> . corpus annotation and classification schemes applicable to a wider variety of biomedical literature have been developed to support biologists with diverse tm needs  <cit> . shared tasks  targeting the actual workflow of biomedical researchers have appeared, along with studies exploring the tm needs of specific tasks   <cit> . several practical tools have been developed for the use of working scientists which can support ir and ie from biomedical literature  <cit> . however, the understanding of user needs is still one of the neglected areas of biomedical tm, and further user-centered evaluations and systems grounded in real-life tasks are required to determine which tools and services are actually useful  <cit> .

in our recent work, we investigated the user needs of a challenging task yet to be tackled by text mining: cancer risk assessment   <cit> . cra is a task which involves examining existing published evidence to determine the relationship between exposure to a chemical and the likelihood of developing cancer from that exposure  <cit> . it has become increasingly important over the past years as the link between environmental chemicals and cancer has become evident and tight legislations governing chemical safety have been introduced worldwide. for example, the recently established european community reach  legislation requires that all the chemicals manufactured or imported in a high quantity must undergo thorough cra   <cit> .

performed manually by experts in health related institutions, cra is a demanding exercise which requires combining scientific knowledge with elaborate literature review. it involves searching, locating and interpreting relevant information in repositories of scientific peer reviewed journal articles - a process which can be extremely time-consuming because the data required for cra of just a single carcinogen may be scattered across thousands of articles. over the recent years, while the need for cra has grown, the task has also turned increasingly complex due to the rapid development of molecular biology techniques, the increased knowledge of mechanisms involved in cancer development, and the exponentially growing volume of cra literature . under these circumstances, cra is getting too challenging to manage via manual means.

to gain an understanding of how tm could best assist cra, we conducted an initial study where we interviewed  <dig> experienced risk assessors working for different national and international cra authorities in sweden <dig>  <cit> . during this study, the risk assessors described the following steps of their work:  identifying the journal articles relevant for cra of the chemical in question,  identifying the scientific evidence in these articles which help to determine whether/how the chemical causes cancer,  classifying and analysing the resulting  evidence to build the toxicological profile for the chemical, and  preparing the risk assessment report. these steps are conducted largely manually, relying on standard literature search engines  and word processors as technical support. cra of a single chemical may take several years when done on a part time basis. the risk assessors were unanimous about the need to increase the productivity of their work to meet the current cra demand. they reported that locating and classifying the scientific evidence in literature is the most time consuming phase of their work and that a tool capable of assisting this phase and ensuring that all the potentially relevant evidence is found would be particularly helpful.

it became clear to us that a prerequisite for the development of such a tool would need to be an extensive specification of the scientific evidence used for cra. this evidence -- which forms the basis of all the subsequent steps of cra -- is described in the guideline documents of major international cra agencies, e.g. european chemicals agency  <cit>  , the united states environmental protection agency  <cit>  , and the international agency for research on cancer   <cit> . the guideline documents describe various human, animal , cellular  and other mechanistic data which provide evidence for both hazard identification  and the assessment of the mode of action  . however, our investigation showed that although these documents constitute the main reference material available for cra, they cover the main types of evidence only, do not specify the evidence at the level of detail required for comprehensive data gathering  and are not updated regularly to include the latest developments in biomedical sciences. for example, the most recent epa cra guideline was published in  <dig> and the data requirements have not been updated since then.

the same guidelines emphasise, however, the importance of investigating all the published scientific data on the chemical in question which might be of potential relevance for cra. for example, according to echa  <cit>  "failure to collect all of the available information on a substance may lead to duplicate work, wasted time, increased costs and potentially unnecessary animal use" . recent research has revealed that conflicting risk assessments of the same chemical are surprisingly common  <cit> . inadequate or imbalanced data may give rise to such problems. extensive data gathering is therefore essential not only for the coverage but also for the accuracy of cra.

where the guidelines fail to provide sufficient information, risk assessors rely on their experience and expert knowledge. this is not ideal since chemical carcinogenesis is such a complex process that even the most experienced risk assessor is incapable of memorizing the wide range of relevant evidence without the support of a thorough specification.

here we report the work we did on obtaining a more adequate specification of the scientific evidence for cra. ideally, a comprehensive knowledge resource is needed which specifies the range of relevant evidence and provides extensive lists of keywords to support the gathering of this evidence in literature. given the dynamic nature of cra data, the best approach long term would be to develop technology for automatic acquisition and updating of such a resource from cra literature  <cit> . however, the very development of such technology requires target specification of the scientific evidence more comprehensive than that currently provided. therefore, in this first work, we opted for expert annotation of biomedical literature according to the evidence it offers for cra.

following the recommended practices of biomedical corpus design by cohen et al.  <cit>  as far as practical, we constructed a representative, balanced cra corpus of  <dig> medline abstracts from a set of journals typically used for cra. a user-friendly annotation tool was designed which experts could use to annotate abstracts  for the relevance for cra and  according to the types of evidence they provide for the task. three experts  agreed on the annotation guidelines and produced a corpus which contains  <dig> abstracts judged as relevant and annotated for  <dig> unique keywords  indicating the evidence they offer for cra. the experts grouped the keywords according to the types of evidence they provide for the task, and organized them into a taxonomy which contains  <dig> distinct classes and covers a variety of data related to carcinogenic activity, moa and toxicokinetics. we measure the inter-annotator agreement of both relevance and keyword annotation tasks. in addition, we report a series of experiments which involve training and testing automatic classifiers to assign pubmed abstracts to taxonomy classes. finally, a simple user test in a near real-world cra scenario is reported. the evaluation we report demonstrates that our taxonomy is highly accurate and can be useful for practical cra. the materials we have produced can thus provide valuable support for manual cra as well as facilitate the development of an approach based on tm. we discuss refining and extending the taxonomy further via manual and machine learning approaches, and the subsequent steps required to develop tm to support the entire cra workflow.

the rest of this paper is organized as follows: the methods section introduces the cra corpus, the annotation tool, the annotation guidelines, the principles of taxonomy construction, and the automatic classification methods. the results section describes first the annotation work and the resulting taxonomy. the results of the inter-annotator agreement tests, the automatic classification experiments and the user-test are then reported. the discussion and conclusion section concludes the paper with comparison to related research and directions for future work.

methods
cancer risk assessment taxonomy
three experienced risk assessors helped to construct the resources described in the following four sections, respectively:  a representative corpus of cra literature for parts of hazard identification ,  a tool for expert annotation of the corpus,  an annotated corpus, and  a taxonomy which classifies and organizes the scientific evidence discovered in the corpus.

cra corpus
most cra literature is now available electronically via online resources such as the national library of medicine's pubmed system  <cit>  and databases such as the integrated risk information system   <cit> , toxicology data network  <cit>  and the organisation for economic co-operation and development  global portal to information on chemical substances  <cit> . as pubmed is by far the most frequently used resource in cra, we selected  <dig> journals available via this system which are used frequently for cra and jointly provide a good coverage of the main types of scientific evidence relevant for the task. from these  <dig> journals , all the abstracts from years  <dig> to  <dig> which include one of eight test chemicals were downloaded for further analysis. the eight chemicals are shown in table  <dig>  they were selected by the experts on the basis that they are  well-researched using a range of scientific tests and  represent the two most common moas - genotoxic and non-genotoxic <dig>  although full articles are known to provide richer data for tm purposes than abstracts,  <cit> , we focussed on abstracts in this work because they are the typical starting point in cra. the literature search was limited to recent  <dig> years. since many of the selected chemicals are well-studied, this yielded a sufficient number of abstracts for annotation. all the retrieved abstracts were included, except for benzopyrene for which only the latest  <dig>  were considered. the resulting corpus of  <dig> abstracts is distributed per chemical as shown in table  <dig> 

annotation tool
risk assessors typically  read each abstract retrieved by pubmed to determine its relevance for cra, and  classify each relevant abstract based on the types of evidence it provides for cra. we designed a tool for expert annotation which imitates this process as closely as possible.

the tool provides two types of functionality. the first enables the experts to classify abstracts using the classical ir concept of document relevance. the judgements are made at the document level. an abstract is marked as relevant or irrelevant if the expert deems after reading the title and the abstract that it is not relevant for cra. an abstract can also be marked as unsure. the second functionality enables the experts to annotate such keywords  in abstracts and their titles which indicate scientific evidence relevant for examining the carcinogenic properties of chemicals. this annotation is grounded in actual pieces of text. initially a very shallow taxonomy  and two types of moa  was integrated inside the tool. as explained below, this was gradually extended as the annotation progressed further. the tool permits annotating any number of relevant keywords in the abstracts, attaching them to any  node in the taxonomy, and classifying the same text in more than one way.

the tool was implemented inside the mozilla firefox browser using its extension facility. the implementation enables pubmed abstracts to be viewed inside a familiar web-browsing environment and also to be classified according to the specialized taxonomy. previous work has observed that integrating custom functions within a familiar document browsing environment greatly encourages user uptake  <cit> . the cra analysed abstracts could then be stored, reviewed by others and edited. in this way, the deployment of the analysis in a genuine cra scenario was able to be quickly tested. a screenshot illustrating the annotation tool is provided in figure  <dig> 

annotation guidelines
the three experts agreed on the guidelines of document relevance and keyword annotation. the guidelines were developed so that one of the experts conducted annotation based on the initial set of principles agreed among the three experts. the other two evaluated the outcome, the disagreement cases were discussed, and the annotation principles were improved where possible. this process  was repeated on a subset of the corpus for several times. the guidelines described below are the final result of this work.

relevance annotation
the aim of the relevance annotation is to classify each abstract in the corpus as relevant, irrelevant or unsure with regard to hazard identification and moa assessment. since current cra guidelines do not provide clear advice for this step, the experts agreed on the annotation principles based on their experience with cra literature. they agreed that the abstracts of articles focussed on initiator/promoter studies or studies on chemoprevention where the chemical in question is used as a model compound should be considered as relevant because they invariably contain data interesting for cra. they also agreed that the abstracts of articles focussed only on exposure assessment should not be included because they are not suitable for hazard identification. any other abstracts should be examined carefully for their relevance for cra using expert judgement.

as a general rule, when an abstract contains evidence relevant for cra, it should be classified as relevant, even when the name of the chemical of interest is missing in the abstract or the title. although some such abstracts may turn out to be irrelevant after reading the full article, experts agreed that since they are potentially relevant, they should be included for further assessment as not to lose data valuable for cra. appendix  <dig> shows sentences from some abstracts judged as relevant where the evidence for relevance is highlighted using bold font.

when the abstract  either contains no evidence for relevance or contains "negative" evidence , it is classified as irrelevant. negative evidence includes, for example, diseases or endpoints unrelated to cancer . appendix  <dig> shows example sentences from irrelevant abstracts with negative evidence highlighted.

not all the abstracts are clearly relevant or irrelevant according to these criteria. some abstracts include only vague evidence for relevance. some contain conflicting  evidence. for example, effects on cell death  may occur in the same abstract with plants . others include evidence whose association with cancer development is currently unclear or evidence which focuses on studies on single chemicals in complex mixtures such as tobacco smoke. the experts decided to deal with such challenging abstracts on case by case basis.

keyword annotation
the aim of the keyword annotation is to highlight such keywords  in abstracts which indicate relevant evidence for hazard identification and moa assessment of chemicals. the experts found keyword annotation easy to understand since they typically look for words and phrases while reading abstracts, and since existing cra guidelines provide some sample keyword lists to support data gathering. it was agreed that the keyword annotation should focus on the following main types of data considered in cra  <cit> :

 <dig>  carcinogenic activity. various types of human, animal , cellular  and other mechanistic data provide evidence for cra. risk assessors pay attention to a variety of keywords indicating different study types in texts when aiming to locate this data. for example, the appearance of the keyword haemoglobin-adduct may indicate that the abstract focuses on a biomarker study, and the appearance of humans in the same abstract may suggest that the biomarker study focuses on humans rather than e.g. animals. it was agreed that the experts would annotate all the keywords which jointly identify the types of scientific data offered by the abstract.

 <dig>  mode of action . a moa is a core concept in cra. it specifies the key events leading to cancer, explaining the genetic and cellular alterations which result in the appearance of the scientific data mentioned above. different chemicals act according to different moas, and risk assessors search evidence for a specific moa type in abstracts. two main types of moa can be distinguished: genotoxic and non-genotoxic . chemicals acting by a genotoxic moa interact with dna, while chemicals acting by a non-genotoxic moa induce cancer without interfering directly with dna. to identify the moa type in question, risk assessors examine scientific data  in conjunction with mutations in genes. a number of genes  are known to be involved in cancer development and are therefore used as evidence. some of these are shown in table  <dig>  together with proteins regulated by them. for example, an abstract which reports mutation in p <dig> gene resulting in decreased expression of its downstream protein p <dig> suggests genotoxic moa while an abstract which describes activation of fasl resulting in caspase- <dig> mediated apoptosis suggests non-genotoxic moa.

 <dig>  toxicokinetics. toxicokinetics describes the process of uptake of chemicals by the body: the metabolism and biotransformation, and the distribution and excretion. accurate moa classification of some chemicals requires evidence for a certain type of toxicokinetics. for example, aflatoxinb <dig> needs to be activated by cyp  <dig> to be able to bind to dna.

many abstracts focus on several chemicals and/or refer to results conducted in previously published experiments. it was agreed that the experts would focus only on the chemical of interest and on new rather than previously published results. for maximum accuracy, the experts were not required to annotate every potentially relevant keyword but only the ones which they perceived as the most important or dominant. where the same keyword appeared several times in the abstract or appeared in different forms  it was annotated at least once.

principles of taxonomy creation
the keyword annotation resulted in lists of words and phrases indicating evidence for cra. the next task was to classify this evidence and organize it into a taxonomy. we mentioned earlier that initially only a very shallow taxonomy was implemented inside the annotation tool. as the keyword annotation progressed, this taxonomy was gradually extended and refined further with novel classes and class members. the resulting taxonomy relies solely on expert knowledge. experts were merely advised on the main principles of taxonomy creation: the classes should be conceptually coherent and their hierarchical organization should be in terms of coherent sub- and superordinate relations.

automatic classification
to find out whether the classification created by experts provides a good representation of the corpus data and is machine learnable, we conducted a series of abstract classification experiments. a number of standard feature extraction, feature selection and machine learning methods were used and compared in these first experiments to identify optimal methodology for our data and task. these are introduced in the subsequent sections.

feature extraction
the first step of our text categorization  approach is to transform documents into a feature vector representation. we experimented with two document representation techniques. the first one is the simple 'bag of words' approach  which considers each word in the abstract as a separate feature. bow was evaluated using three methods which have proved useful in previous tc work:  stemming  which removes affixes from words,  the tfidf weighting  <cit> , and  stop word removal .

the second technique is the recent 'bag of substrings'  method by  <cit>  which considers the whole abstract as a string and which extracts from it all the length p substrings without affix removal. bos has proved promising in recent biomedical tc experiments  <cit>  and unlike a traditional grammatical stemmer, it does not require domain tuning for optimal performance. because it generates substrings with a fixed length p, a word shorter than p -  <dig> can get obscured by its context <dig>  for example, 'mice' could be transformed to ' _mice_a', '_mice_b',..., which is less informative than the original word form. therefore, we enriched the bos features with word forms shorter than p -  <dig> 

feature selection
we employed two feature selection methods for dimensionality reduction. the first is information gain  which has proved useful in tc  <cit> . given a feature's distribution x and class label distribution y, ig = h - h, h is the entropy of x. the second method fscore optimises the number of features . features are first ranked using the simple fscore criterion  <cit> , and n is selected based on the performance of the svm classifier using the n features.

classification
we experimented with three well-known classifiers: naive multinomial bayesian , complement naive bayesian   <cit>  and linear support vector machines   <cit> .

nmb is a simple, widely used classifier in tc  <cit> . it selects the class c with the maximum probability given the document d: argmaxc pr Πw∈ d pr. pr can be estimated from the frequency of documents in c. pr is estimated as the fraction of tokens in documents of class c that contain w.

cnb extends nmb by addressing the problems it has e.g. with imbalanced data and the weight magnitude error. the class c of a document is: .  is the number of times term i occurs in classes other than c. α and αi are the smoothing parameters. p is the prior distribution of class c.

we used weka software environment  <cit>  for the implementation of nmb and cnb.

svms have been reported to outperform other tc methods on many tm tasks and have the benefit that they work well even when the data is sparse. l-svm is the basic type of svm which produces a hyperplane that separates two-class samples with the maximum margin. the method handles high dimensional data efficiently, and has been shown to perform well in tc  <cit> . given the data set x = ,..., yi ∈ {- <dig>  +1}, l-svm requires a solution w to the following unconstrained optimisation problem: . cost parameter c was estimated within range  <dig> ..., <dig> on training data using cross validation. the c of the positive class was weighted by class population ratio . the feature vector was normalized before inputting into l-svm, because the scaling is important for svm  <cit> . liblinear  <cit>  was used for the implementation of l-svm.

RESULTS
the following sections report our results first for the annotation and taxonomy construction tasks, then for the automatic classification experiments, and finally for the user test which involves applying the automatic classification technology to corpus data of unseen chemicals and evaluating the resulting classified data using expert judgment.

annotation tasks
using the annotation tool and the guidelines we have described, the experts annotated each of the  <dig> abstracts for  relevance and  keywords. they classified  <dig> % of the abstracts as relevant,  <dig> % as irrelevant and  <dig> % as unsure. the small proportion of unsure abstracts can be explained by the general cra principle which the risk assessors followed which encourages them to collect all the data of potential relevance for further assessment  <cit> .

we used the widely employed kappa statistics  <cit>  to measure the level of inter-annotator agreement in relevance classification. although not a fully ideal measure , we adopted it for this first annotation effort due to its familiarity. we used the cohen's chance agreement model  <cit>  since eugenio and glass  <cit>  have shown that the model is better than siegel and castellan's model  <cit>  in the studies such as ours where the distribution of categories is not equal between the annotators.

the kappa statistics was calculated on data which two experts annotated independently <dig>   <dig> abstracts per chemical were selected randomly from the  <dig> and  <dig> journals listed in table  <dig> and appendix  <dig>  respectively. the  <dig> journals in appendix  <dig> were selected on the basis of their likely irrelevance for cra. they were included to make the annotation task harder, given the high proportion of relevant abstracts among the  <dig> journals used for corpus creation. the resulting test data contains  <dig> abstracts in total. the test set was kept intentionally small to facilitate thorough error analysis. table  <dig> shows basic statistics with regard to the experiment: the values that the kappa function requires as input. the kappa statistics k is calculated as follows:

   

pa measures the observed level of agreement while pe measures the chance agreement between two annotators.

the maximum value of kappa score occurs when the agreement is one . the minimum value  <dig> indicates that the agreement is by chance . our kappa result is  <dig> . according to the scale of  <cit> , this value indicates substantial agreement between the annotators.

the annotators disagreed on  <dig>  of the abstracts. half of the disagreements  were due to one of the annotators failing to notice keywords in text, and thus erroneously judging abstracts as irrelevant. these disagreements do not warrant improving the annotation guidelines but are likely to decrease when the annotators gain more experience. the other half of the disagreements  were caused by one  of the following problems:

• environmental studies can provide important evidence for cra, but it is unclear what kind of environmental studies should be included in cra .

• conflicting information in abstracts: the abstracts can include both relevant and irrelevant information, making it difficult for the annotators to decide on the relevance.

the keyword annotation was done for the  <dig> abstracts deemed relevant during the relevance annotation. keywords mentioned in existing cra guideline documents were identified along with many novel ones missing in them . a total of  <dig> unique keywords were identified. figure  <dig> shows an example of an annotated abstract where keywords indicating different types of evidence are highlighted in blue, red, and green fonts. since the experts were not required to annotate every single relevant keyword, calculating inter-annotator agreement was not meaningful. however, we evaluated the keyword annotation as part of the taxonomy classification and provide the corresponding inter-annotator agreement scores in the following section.

taxonomy
the keyword annotation of the first two chemicals  resulted in several updates in the classification and considerable extension of the initial taxonomy implemented inside the annotation tool. during the annotation of the subsequent six chemicals, only minor changes were required: some classes were combined, divided or refined following the discussion among the experts. the resulting taxonomy consists of three sub-taxonomies, corresponding to 1) carcinogenic activity, 2) moa and 3) toxicokinetics.

carcinogenic activity
the first sub-taxonomy, shown in figure  <dig>  specifies the types of data which provide evidence for carcinogenic activity. five main classes are included: "human study/epidemiology", "animal study", "cell experiments", "study on micro-organisms", and "subcellular systems". the first three of these divide further into subclasses. for example, "human study/epidemiology" has several sub-classes corresponding to different types of human studies: "polymorphism", "biomarkers", "tumor related effects", "morphological effects on tissues and organs", and "biochemical and cellbiological effects". each class is illustrated in the figure by 2- <dig> example studies, corresponding to individual keywords in the annotated abstracts . most child nodes in this sub-taxonomy have a type of relation with their parent class. for example, "polymorphism" is here a type of "human study". the only exceptions are "study length" and "the type of animals" under "animal studies" class. they provide additional information about animal studies important for cra.

mode of action
the second sub-taxonomy focuses on moa and specifies the types of scientific evidence required for moa classification. shown in figure  <dig>  this sub-taxonomy currently covers the two most frequent moa types. in this taxonomy, the sub-classes of "genotoxic" and "non-genotoxic" specify different types of evidence for the moa type in question. for example, "strand breaks", "adducts", "chromosomal changes" , "mutations" and "other dna modifications" each provide different types of evidence for the genotoxic moa.

toxicokinetics
the third sub-taxonomy focuses on toxicokinetics, shown in figure  <dig>  specifying the different parts of this process. it consists of four main classes: "absorption, uptake, distribution, excretion", "bioaccumulation/lipophility", "metabolism", and "toxicokinetic modelling". for example, the class "metabolism" gives information about the distribution of the chemical in the body, e.g. "biodegradation", "metabolic enzymes", "biotransformation".

the resulting taxonomy, consisting of the three sub-taxonomies, includes  <dig> classes in total. table  <dig> shows the total number of abstracts and annotated keywords belonging to each class. it shows that  <dig> % of the annotated abstracts include keywords belonging to the "carcinogenic activity" sub-taxonomy, and  <dig> % and  <dig> % belonging to the "moa" and "toxicokinetics" sub-taxonomies, respectively. as we go into the deeper levels of the taxonomy, the number of abstracts associated with individual classes gets increasingly small.

the first column shows the name of a class in the taxonomy. the second column shows the total number abstracts classified in the class . the value in brackets is the number of abstracts classified in the class without taking the sub-classes into account. the third column shows the total number of unique keyword annotations for each class. the count does not include the annotations for sub-classes, except for the three top level classes where the number of all keywords  are included.

we conducted an inter-annotator agreement test to measure the agreement with which the experts assigned abstracts to classes via keyword annotation. for each of the eight chemicals ,  <dig> abstracts from  <dig> journals listed in table  <dig> were randomly retrieved from pubmed by using the chemical name as the search term. two experts performed both relevance and keyword annotation using the final taxonomy in the annotation tool, and we investigated the agreement with which they associated the same abstracts with the same classes. we used the kappa measure introduced earlier in section  <dig> . <dig> 

because the classes are hierarchically organized, disagreement on a child class may still mean agreement on the parent class. for example, annotator  <dig>  may select "type of animal" while annotator  <dig>  may select "animal study". although these classes are not identical they are related as "animal study" is the parent class of "type of animal", and therefore there is an implicit agreement on the class "animal study". we calculated the agreement based on both explicit agreement and implicit  agreement. however, the same parent agreement was counted only once for each abstract. for example, if a <dig> selected "animal study" and a <dig> "type of animal" and "study length", the two implicit parent agreements on "animal study" were counted as one agreement only.

the columns a <dig> and a <dig> correspond to the annotators  <dig> and  <dig>  respectively. the values shown are the number of annotations by the annotator. the last two columns show the statistics of agreement and disagreement. rows 2- <dig> show the results for the three sub-taxonomies and the last row indicates the number of irrelevant abstracts among the relevant ones.

the average agreement between the annotators is the highest with "carcinogenic activity" and "moa" at 78%. with "toxicokinetics" it is significantly lower . the overall agreement is 76%. these results are good, particularly considering that the annotation was done using a relatively high number of classes and the chance agreement is low at  <dig> %.

we conducted error analysis of the annotations the annotators disagreed on. the main source of disagreement was the different annotation style of the two annotators. a <dig> annotated as many words as possible, aiming for a maximum number of taxonomy classes per abstract. a <dig> annotated just one or a few words that classify the abstract as precisely as possible. in other words, a <dig> focussed on word-level annotation while a <dig> focussed on document level annotation . both approaches are plausible  and both resulted in annotations useful for cra. the error analysis revealed that some classes are not specific enough to yield unique distinctions and as a consequence, some keywords are even assigned to different sub-taxonomies. for example, a <dig> typically assigned protein changes to "biochemical effects" in the "carcinogenic activity" sub-taxonomy, while a <dig> assigned them to e.g. "post-translational modifications" in the "moa" sub-taxonomy. both annotations are plausible given the current model, but future work should focus on refining the taxonomy further to obtain clearer distinctions.

automatic classification
we evaluated the automatic classification against the expert annotated cra corpus. we used the standard evaluation measures of recall , precision  and f measure  to evaluate the rate with which the classification assigned abstracts to the correct taxonomy classes. these measures are defined as follows:

  

where p+/n: positive/negative population; tp: true positive; fn: false negative, and fp: false positive. our random baseline is .

document preprocessing
we first evaluated the bow preprocessing technique with and without the use of  the porter stemmer  <cit> ,  tfidf,  stop word removal, and  their combinations. the evaluation was done in the context of binary relevance classification of abstracts . only  improved the performance of all the classifiers  and was thus adopted for the main experiments. the poor performance of  demonstrates that a standard stemmer is not optimal for biomedical data. as highlighted by han et al. and wang et al.  <cit> , semantically related biological terms sharing the same stem are not always reducible to the stem form.

feature selection
we evaluated the feature selection methods with two taxonomy classes: the most balanced class 'animal study'  and an imbalanced class 'adducts' . ig was used for the fixed n setting and fscore for the dynamic n setting. each combination of classifiers , document representations  and settings for n  was evaluated. the results showed that the dynamic setting yields consistent improvement for all the setups  and that the optimal n varies by the data and the classifier . thus, we used the dynamic feature selection in the taxonomic classification.

taxonomic classification
we ran two sets of experiments on the corpus, using 1) bow and 2) bos for feature extraction. without feature selection, bow had c.  <dig> features and bos c.  <dig>  features were selected using fscore. for each class with more than  <dig> abstracts  <dig>  three "one against other" classifiers  were trained and tested using a standard 10-fold cross validation.

in sum, these experiments demonstrate that the taxonomy we have created is machine learnable with high accuracy for the classes for which sufficient corpus data is available.

user test
a small user test was finally carried out to investigate the practical usefulness of the automatic classification in a near real-world cra scenario. in this test, the best classifier  trained on the cra corpus  was applied to the pubmed abstract data of five unseen chemicals which represent the same genotoxic  and non-genotoxic  moas . the abstracts were downloaded from the set of  <dig> journals listed in table  <dig>  as with the cra corpus, only abstracts from years 1998- <dig> were included.

the results were displayed to one of our experts in a web interface. the expert was invited to imagine that she had submitted a query to a tm system, the system had classified each abstract of each chemical to relevant taxonomy class, and the task is to judge whether the proposed classification is correct. the top  <dig> bos features per class were shown to the expert to aid the judgement.

the results were evaluated using precision  . table  <dig> shows the average p per each  chemical and  sub-taxonomy. the results are impressive: the only chemical with p lower than  <dig>  is polychlorinated biphenyls . as pcb has a well-known neuro-behavioural effect, the data includes many abstracts irrelevant for cra. the good performance can be observed across the whole taxonomy: tox has the best p , and ca and moa have  <dig>  and  <dig>  p, respectively. most errors are due to the lack of training data for low frequency classes. for example, the cra corpus has only  <dig> abstracts in "dna repair " class, while the data for new chemicals have many.

the expert found this evaluation easy to conduct. she felt that if such an automatic classification system was available to support real-world cra, it could significantly increase the productivity and also lead to more consistent and thorough cra since manual gathering of such a wide range of scientific evidence from abstracts is very difficult. this result is encouraging. larger tests using several experts are required to investigate the full performance of automatic classification on unseen corpus data. we plan to conduct such tests after we have extended the initial taxonomy further to cover additional, finer-grained moa types .

discussion and 
CONCLUSIONS
the results of our inter-annotator agreement tests, automatic classification experiments and the user test all demonstrate that the taxonomy created by risk assessors is accurate, well-defined, and can be useful in practice. this is particularly encouraging considering that the taxonomy is based on expert annotation of biomedical texts.

the annotation of biomedical corpora is a challenging task  <cit> . it is also an important task since most current tm approaches rely on annotated corpora and are therefore dependent on the quality of these resources. various annotation schemes have been proposed which involve either linguistic or expert annotation. as highlighted by kim et al  <cit> , expert annotation is more challenging and more prone to inter-annotator disagreement than better-constrained linguistic annotation. we believe that we obtained promising results regardless of this because our interdisciplinary team included also risk assessors: we developed an annotation approach which imitates their current practices as closely as possible and involves gathering information specifically for their needs. like the recent user-centered annotation scheme of wilbur et al.  <cit>  it can support the classification of biomedical literature along various qualitative dimensions. however, with the focus on cra, our scheme is specifically aimed at classifying cancer related evidence. the latter can be useful for risk assessment and for e.g. researchers working on cancer research. a number of works have been reported on disease- and drug-related tm which have involved similar knowledge acquisition and classification efforts as our work, e.g.  <cit>  among others. although some prior work has been done on cancer-related tm, the work conducted so far has focussed on tasks such as building cancer-related databases , detecting associations between cancer and specific genes or proteins  <cit> , classifying abstracts based on the type of cancer they focus on   <cit> , and mining clinical records for cancer diagnosis  <cit> . no prior work has been done  on specifying such a wide range of cancer-related evidence or developing tm for risk assessment of potentially carcinogenic substances.

the work we have presented in this paper constitutes the first step towards developing tm for cra. the taxonomy we have constructed provides the practical means to identify key evidence in cra literature and to classify this evidence in semantically meaningful classes. the ability to assign journals, abstracts, and experimental results in the taxonomy can help risk assessors to  keep track of the evidence covered/not covered and  detect important statistical tendencies in the cra literature, e.g. that most of the scientific data provides evidence for some specific moa type.

in the future, we plan to develop and extend the taxonomy further. although our results show that the current taxonomy provides a good basis for the classification of cra literature, it is not comprehensive: more data is required especially for low frequency classes, and the taxonomy needs to be adapted and extended to cover more specific moa types  and novel findings.

the taxonomy can be extended using manual annotation, by supplementing it with additional information in knowledge resources and/or using automatic methods. a number of extensive knowledge resources have been built for biomedicine which also enable classifying concepts in biomedical texts in semantically coherent classes. the most prominent of these are widely used to support biomedical text mining tasks, e.g. the medical subject headings  ontology  <cit>  and the unified medical language system  knowledge sources   <cit> . although these general resources lack a number of concepts important for cra , cover a large number of concepts irrelevant for cra, and organize many similar concepts differently , some information provided in them could further support cra and would therefore be worth exploring.

we performed a small experiment to investigate the usefulness of mesh for supplementing our current classification. mesh terms were first retrieved for each abstract using efetch  <cit>  and then appended to the bos feature vector. the best features were selected using fscore and classified using l-svm. the figures included in table  <dig> show that the classification improved significantly for 43% of the classes, the majority of which are low in frequency. although this demonstrates the potential usefulness of additional manually built resources, given the rapidly evolving nature of cra data, the best approach long term is to develop technology for automatic updating of the taxonomy from literature. given the basic resources we have constructed and presented in this paper, the development of such technology is now realistic and can be done using unsupervised or semi-supervised machine learning techniques, e.g.  <cit> .

our simple automatic classification method could be improved in various ways. an obvious way to improve it is to extend the shallow feature set with more sophisticated features extracted using nlp tools that have been tuned for biomedical texts, such as taggers and parsers, e.g.  <cit> , named entity recognizers, e.g.  <cit> , and exploiting lexical resources such as the biolexion  <cit> .

given the basic resources described in this paper and the proposed extensions, our long term goal is to develop a tm tool to support the entire cra workflow. our initial study  revealed that a tool capable of identifying, ranking and classifying articles based on the evidence they contain, displaying the results to experts, and assisting also in the subsequent steps of cra would be welcome. such a tool could significantly increase the productivity and consistency of cra and enable risk assessors to concentrate on what they are best at: the expert judgement. it could also, as a side-effect, keep track of the cra process, providing the practical means to address one of the biggest current problems in cra: the need for improved consistency and transparency of risk assessments  <cit> .

such a tool should be developed in close collaboration with risk assessors. the interface should be easy to use, interactive, support search in a graphical manner, include a helpful statistical summariser, and enable the storage of interesting results in specific collections. it should provide online access to cra guidelines and resources, and be sufficiently flexible to permit specific searchers in selected repositories of literature. ideally, it should be designed in a way that it facilitates also the subsequent steps of cra, e.g. the analysis of the retrieved data, the discussion among the cra team and the subsequent generation of the cra report.

a number of tools have recently been built to assist other critical activities in biomedicine   <cit> . a few of them have also been evaluated for their practical usefulness in a real-world scenario  <cit> . such tools and evaluations act as an important proof of concept for biomedical tm as well as enable improving existing technology according to the needs of practical applications.

appendix
appendix  <dig> sentences from abstracts relevant for cra
keywords representing evidence for relevance are indicated in bold font

although a:t to t:a transversions were the major form of mutation observed following treatment with each of the three stereoisomers , s, s-deb induced higher numbers of g:c to a:t transitions, whereas r, r-deb treatment resulted in a greater frequency of g:c to t:a transversions.

measurements of hprt mutant frequencies  showed that repeated exposures to  <dig> and  <dig> ppm bd-diol were significantly mutagenic in mice and rats.

all three bd exposure indices were associated positively with leukemia.

assays for the n, n- valine  hemoglobin  adduct, which is specific for the highly genotoxic  <dig> , <dig> -diepoxybutane  metabolite of bd, have been conducted on blood samples from all participants in this second czech study.

thus, in terms of mutagenic efficiency, stereochemical configurations of eb and deb are not likely to play a significant role in the mutagenicity and carcinogenicity of bd.

thus, in mouse liver, the trihalomethanes administered by gavage enhanced cell proliferation and decreased the methylation of the c-myc gene, consistent with their carcinogenic activity.

the data support the hypothesis that pb promotes neoplastic development through a reduction in the incidence of cell death.

appendix  <dig> example sentences containing evidence for irrelevance
example sentences containing information  which suggests that the abstract is irrelevant for cra

exposure to  <dig> ppm styrene caused a  <dig> db hearing loss only at the highest test frequency .

asthma symptom severity was regressed on pollutants using generalized estimating equations, and peak expiratory flow  was regressed on pollutants using mixed models.

collectively, our results indicated that chloroform directly and concentration-dependently provoked muscle contraction in swine tracheal smooth muscle.

these results demonstrate that bap/dmba causes a loss of bone mass and bone strength, possibly through an increase in bone turnover.

appendix  <dig> the  <dig> additional journals used for inter-annotator agreement test
journals

journal of biological chemistry

pnas 

pancreas

bone

endocrinology

regulatory toxicology and pharmacology

epidemiology

blood

toxicologic pathology

international journal of toxicology

risk analysis

cell death and differentiation

american journal of epidemiology

american journal of industrial medicine

toxicology

european journal of pharmacology

appendix  <dig> footnotes
 <dig>  institute of environmental medicine at karolinska institutet, swedish chemical inspectorate, scientific committee on occupational exposure limits , swedish criteria group.

 <dig>  chemicals acting by a genotoxic moa interact with dna, while chemicals acting by a non-genotoxic moa induce cancer without interfering directly with dna.

 <dig>  minus  <dig> because of space characters.

 <dig>  since our third expert was not available during the inter-annotator agreement tests, the tests were conducted using two experts only.

 <dig>  the classes with less than  <dig> abstracts may have less than  <dig> positive abstracts in each fold of  <dig> fold cv, which is not representative of the class population.

authors' contributions
all four authors participated equally in the work reported in this paper. ak wrote most of the paper and together with us designed, supervised and coordinated the project. is conducted the annotation work, designed the taxonomies, and conducted the inter-annotator agreement tests and the user test with the assistance of us. ls developed the annotation tool, constructed the cra corpus, implemented the automatic classification approach and performed the evaluation of these resources with the assistance of ak. all authors have read and accepted the final manuscript.

