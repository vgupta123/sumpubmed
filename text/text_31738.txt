BACKGROUND
public databases of microarray gene expression data have been quickly growing as the use of high-throughput techniques has become routine in genome-wide studies. major repositories of microarray data, e.g. gene expression omnibus  <cit> , arrayexpress  <cit> , or stanford microarray database  <cit> , are exceptionally rich mines of genomic information and exploiting their content, through meta-analysis, represents an unprecedented opportunity to improve the interpretation and validation of expression studies. meta-analysis of large microarray expression datasets allows researchers to confirm biological hypotheses, formulated from results of a study, in a relatively inexpensive way, i.e. using data independently obtained in another laboratory, without the need of novel experiments. meta-analysis also offers the opportunity of re-analyzing formerly available data, in combination with new samples and state-of-the-art computational methods, thus increasing the reliability and robustness of results. finally, meta-analysis enhances the capabilities of bioinformatics methods to obtain precise estimates of gene expression differentials and to assess the heterogeneity of overall estimates.

challenges of integrative analysis of expression data
in recent years, different strategies to combine results from independent but related studies have been proposed. the choice of the most effective meta-analysis technique depends on the type of response  and on the objective of the study. meta-analysis strategies can be divided into two broad classes: data integration and data combination. statistical techniques as vote counting  <cit> , p-value or rank combination  <cit>  and effect size estimation  <cit>  have been used for meta-analyses based on data integration. instead, data combination encompasses the direct comparison of different studies, is applicable only when expression profiles have been obtained using the same array technology  and requires an ad-hoc normalization step of the raw data files.

despites numerous efforts, mining and analyzing publicly available microarray data still represents a bioinformatics challenge and the lack of appropriate tools able to overcome critical issues, as annotation, cross-platform comparison and handling of metadata, is still hampering the potentialities of large-scale meta-analyses. performing a meta-analysis of independent microarray studies requires to carefully handle the heterogeneity of array designs, which complicates cross-platform integration, and of sample descriptions, which impact the correct characterization of specimens. at least for the case of affymetrix arrays, cross-platform comparison has partially been solved by the adoption of custom chip definition files  which, relating probe sequences to annotated entities as genes or transcripts, allow matching expression profiles across subsequent generations of microarrays  <cit> . instead, retrieval, organization and utilization of meta-information is still an extremely critical step which impacts the correct match between raw data files and sample ids and the organization of samples into meaningful, homogeneous groups. this task is further complicated by the fact that i) datasets may be incompletely annotated, ii) the relationship between specimen, biological sample, phenotypic characteristics and raw data files, the most granular object in repositories, may be not sufficiently explicit, and iii) the procedures for managing large numbers of data files and related meta-information are tedious and error prone  <cit> .

available tools
different computational tools have been proposed for retrieval and meta-analysis of microarray expression data  <cit> . in particular, geoss  is a web-interfaced system for the storage and local analysis of microarray data  <cit> ; crosschip uses probe by probe sequence comparison to integrate data from different generations of affymetrix arrays  <cit> ; the server version of seqexpress has a geo integration tool which allows for retrieval and analysis of geo data sets and geo series  <cit> ; genepattern contains a module  for importing single geo data sets or series  <cit> ; wgas is a multi-purpose web-based analysis system  <cit> ; geoquery is a bioconductor package for downloading and parsing soft files from geo  <cit> ; ezarray, is an affymetrix-centered analysis system  <cit> ; microarray retriever  allows batch retrieval of microarray data from geo and arrayexpress according to user-defined searching criteria  <cit> ; emaas allows importing and analyzing data from several repositories including geo  <cit> . some of these tools provide a user friendly interface for searching and retrieval of data from geo and arrayexpress, others implement database structures for storing and locally organizing the data and others offer modules for applying well established meta-analysis algorithms and procedures. however, none of them allows altogether i) the batch retrieval and local organization of raw data files and of any related meta-information, ii) the re-annotation of samples to create user-defined batches of data, iii) the integrative analysis of data obtained from different platforms, and iv) the sharing of data, meta-information, analysis flows and results.

a-madman approach
the purpose of this paper is to present a-madman, an open source web application for the meta-analysis of affymetrix data contained in gene expression omnibus . a-madman allows retrieving, annotating, organizing and analyzing gene expression datasets. in particular, a-madman addressees several of previously stated open issues in the meta-analysis of gene expression data allowing the integrative analysis of data obtained from different affymetrix platforms through custom chip definition files and meta-normalization and the sharing of analysis flows and results.

implementation
architecture
a-madman is a web application that allows retrieving gene expression datasets from geo, annotating and locally organizing the downloaded samples, and generating an r object  which contains the integrated expression levels and all available metadata and sample characteristics. the gene expression data are obtained through a meta-analysis approach which includes signal generation, probe re-annotation into gene-centered identifiers, merging of expression levels from different experiments and a normalization step. a-madman generates an expressionset object in which the meta-expression levels from multiple experiments are completed by geo-derived and user-defined metadata. the final expressionset contains all the necessary information to perform, directly in r, any higher level analysis  of all downloaded and integrated data.

a-madman web application comprises a console, a job server and a web-application . the console is needed for the first phases of data retrieval, import and database filling. it performs the automatic download and organization, in a proper and transparent file system hierarchy, of raw data and annotations from gene expression omnibus, starting from a configuration file listing the accession numbers of geo series and/or samples to download. metadata of geo records are automatically imported into a local relational database to assist subsequent manual annotation and selection of samples from the web application. the job server is in charge for asynchronous execution of jobs which, depending on data size and algorithm, can be computationally intensive and take longer than allowed by an http response-request cycle. the core of the framework is the web application, whose user friendly front-end facilitates data organization, annotation and analysis .

technical details
the software, written in python  <cit> , is based on the popular django web framework  <cit>  and uses the r environment for statistical computing as a backend  <cit>  . a-madman supports a collaborative working style for local or geographically dispersed teams through lan or internet deployment options, but can also be installed on a single personal computer with windows operating system through an all-in-one package that bundles all required dependencies except r. the stand-alone package is completed by supporting material  and by a step-by-step tutorial  <cit> .

a-madman natively supports retrieval and analysis of human data, but it can be customized, as explained in the documentation, for analyzing data from other species or to use third party custom cdf sets.

RESULTS
data organization
the user logins into the a-madman web application with a personal account. a user may be part of a group of users sharing the same rights on projects and related resources. a project is a collection of samples, series, tags, baskets and analyses owned by a group. series and samples are the primary data objects imported via the console commands. a sample is a single experiment, each associated to a cel file and to metadata extracted from the geo miniml file. a series is a collection of samples, as defined in geo.

the user can create additional data entities, critical for planning and execution of analyses, and associate them to primary data. in particular, a-madman supports the following entities:

individual: a given biological entity  to which one or many samples refer to;

tag: a free-text, descriptive label assigned to any sample and used for sample selection and grouping. the tags menu allows managing and creating tags to annotate/describe samples, through a labeling system whose complexity depends on the project, on the biological question and on the type of analysis.

basket: a named collection of samples obtained making a logical query on tags.

data annotation
data and metadata of selected series and samples, automatically downloaded from geo, are imported into a-madman and organized in a file system hierarchy. sample characterization can be further enriched by user-defined annotations and tags. the tag based annotation system is central to a-madman meta-analysis philosophy and can be used to:

i) exploit geo metadata information, although incomplete, inaccurate and not conform to a controlled vocabulary. the a-madman tag system allows the user to define his own vocabulary and consistency is enforced by the software itself ;

ii) test new hypotheses not envisioned by the original authors enriching the sample annotations with information derived from bibliographic references or from other sources.

samples can be grouped in user-defined data baskets on the basis of logical queries performed on tag information . a parsing system has been implemented to specifically support this flexible extraction mechanism. the parser exploits a simple, custom query language where standard boolean operators and explicit parenthesis precedence allow the user to populate baskets using a friendly interface and an almost natural language expression. for instance, once collected a muscle-related gene expression database and created a muscle physiology and disease tag system, a query like 'young and male and dystrophy and not ' allows populating a basket with only those samples derived from young, male patients affected by any muscular dystrophy different from the becker's or the erb's ones.

baskets can contain samples from different platforms. gene expression signals generation, platforms integration and normalization are then performed on baskets according to the basic analysis workflow shown in figure  <dig> 

the labeling system allows creating data structures which are tailored to the subsequent meta-analysis. for instance, samples can be tagged to identify differentially expressed genes from two-class or multi-class comparisons or may be labeled to generate a large data matrix, accounting for different biological contests, when the goal is to detect co-expressed genes. practically, the user can create a custom tags system and use it for tagging series/samples. the tag annotation system is based on the conceptual model of bottom-up classification, recently exploited by many social network web sites to organize and search data not amenable to enter a predefined and unambiguous taxonomy. this model enables the user to create a project-tailored, controlled, but unconstrained vocabulary to describe biological or technical characteristics of samples, which may be significant and informative according to the specific scopes of a meta-analysis.

one of the most critical problems in meta-analyses is originated by the inexplicit relationship among individuals/patients and samples. the granularity of affymetrix-based gene expression data in geo is represented by .cel files but, depending on the platform, the rna of a single individual may have been hybridized to more than one array, i.e. may be associated to more than a single .cel file. a typical example of this one-to-many association between individuals and .cel files is represented by the hg-u <dig> and hg-u <dig> sets with up to  <dig> or  <dig> possible raw data files for each biological sample, respectively, and a given .cel file is not directly associated to a patient/sample id. said that, a-madman interface considerably facilitate the matching of individuals to .cel files and metadata, which can be inferred by combining metadata with information available in other formats and repositories, e.g. in a publication, in a supplementary information file, in a study-dedicated web site. a-madman can relate each sample to an individual in two ways, i.e. through an automatic assignment  or using a knowledge-based assignment. in the latter case, the user-friendly interface allows matching samples and individuals according to the information derived from geo or from original references or project websites.

dataset/s extraction
once samples are tagged and assigned to individuals, the user may set up a query, based on a boolean combination of annotation tags, to select and extract samples and put them in a basket. the baskets represent the starting point of the subsequent analysis, i.e. the objects from which expression profiles are generated and information for the supervised comparisons are retrieved. once selected one or more available baskets, all analyses will be conducted automatically, following a workflow selected by the user.

analyses
the action analyses of a-madman allows viewing analyses status, debugging information, logs and results, while the administration action allows the administration of users, groups and projects, according to the allotted permissions. analyses are conducted by the r backend powered by packages of the bioconductor project  <cit> , downloaded and installed automatically the first time they are required.

a-madman contains a standard analysis workflow which may be applied to one or more baskets, but any user can create custom workflows, editing a workflow template, and share them within a group. this feature makes easily customizable and expandable the analysis flow. the basic analysis workflow comprises the following steps:

 <dig>  creation of a work directory named after the current analysis and copy of the selected raw data files to the work directory;

 <dig>  signal reconstruction using rma algorithm  <cit> ;

 <dig>  generation of an expressionset containing expression profiles and metadata;

 <dig>  integration of different chip platforms trough matching of platform-dependent probesets to integrated probesets.

 <dig>  normalization of the final expressionset with quantile distribution transformation  <cit> .

the standard workflow is implemented as a template with three blocks of code that can be modified or replaced by the user, through the web interface, to define custom workflows. specifically, the user can customize the cdf_flavour, i.e. the type of cdf used in the signal reconstruction , the signal_reconstruction, i.e. the algorithm and parameters for signal reconstruction , and the additionalcode block containing code to be run after the platform integration phase . blocks are written mixing r code  <cit>  and some tags of the django templating engine  <cit>  and must conform to some conventions detailed in the a-madman documentation. this type of customization, where the user can directly change the template code, allows a greater flexibility as compared to implementing a web interface with a fixed number of analytical options. the workflow customization is particularly useful in the frame of a collaborative resource, allowing easy sharing of both data and analysis schemas.

signal reconstruction
a-madman supports different affymetrix platforms and the integration of data obtained with subsequent generations of chips is achieved through the annotations of several, gene-centered cdf packages . in a given meta-analysis project, a subset of supported platforms will be represented. the first step of analysis is the platform-specific quantification of expression levels from probes intensities. this can be carried out using rma, probably the most efficient algorithm when dealing with the elevate number of affymetrix arrays of a meta-dataset  <cit> . in this phase microarray probes can be re-organized and annotated using different chip definition files  <cit> . in particular, for human expression data, the user may choose among standard affymetrix cdfs  <cit> , geneannot-based cdfs  <cit>  or entrez-based cdfs  <cit> .

if the data baskets under consideration are composed by samples obtained from more than one platform, rma will be carried out separately for each platform on all those samples which are homogeneous with respect to the selected cdf . gene expression levels and metadata, originating from geo or from user-defined annotations, are then incorporated into an expressionset object, i.e., into the bioconductor class that contains and describes microarray expression level assays.

platforms integration
the annotations of the selected cdfs are used to generate a non-redundant list of gene-centered identifiers, each derived from one or more platform-specific probesets/metaprobesets. this list constitutes the backbone grid of the integrated data matrix whose values will be composed from gene expression signals derived from the various samples. since each platform represented in the baskets will contribute expression data according to a list of platform-cdf dependent probesets , the values of the integrated data matrix will be obtained averaging the expression levels of the various platform-specific probesets/metaprobesets . it's worthwhile noting that if the original affymetrix cdf is chosen, the expression values pertaining to a gene maybe averaged twice, i.e. intra and inter platform, given the probe redundancy inherent in these definition files.

according to the adopted cdf and to the combination of platforms in the basket, a fraction of the gene identifiers in the integrated data matrix may include some <na> values. since expression vectors including some <na> values may represent a problem for the subsequent analyses, the user may choose to fill empty cells using a specific function, e.g. sam imputes missing values via a k-nearest neighbor algorithm. in the case that a given gene is not represented in any platform of the baskets, i.e. if the data matrix has an entire row of <na>, the record will be pruned so that the final integrated expression matrix contains only non-empty expression vectors.

finally, the integrated data matrix is normalized to remove experiment-dependent biases. this normalization procedure is a crucial step to limit misleading outcomes due to the direct integration of different datasets. among the various normalization techniques proposed for microarray meta-analysis, the quantile distribution transformation has been demonstrated to be highly efficient for normalizing data across experiments  <cit> . data transformations based on a reference empirical distribution function, in fact, have been extensively applied on single channel microarray technologies showing their ability to increase inter-studies expression comparability. in this case, the median expression across the experiments with the largest available number of probesets has been used as the reference empirical distribution function in the quantile normalization.

after normalization, the integrated data matrix represents the observed expression levels of the final expressionset object, while geo-derived and user-defined metadata compose the phenodata slot. as such, the expressionset contains all the necessary information to perform any higher level analysis  directly in r.

an example on muscle expression data
as a simple case study, we collected, annotated and analyzed with a-madman a muscle-related gene expression dataset with the following main steps:

 <dig>  data belonging to the geo series gse <dig>  were downloaded and imported in a project called "muscle-survey". the series belongs to the platforms gpl <dig> and glp <dig> , since most muscle biological samples were hybridized to both chips of the set.

 <dig>  metadata and information coming from the original paper  <cit>  were used to:

a) build up a tag system, defining samples characterization ;

b) apply the tags to the samples, obtaining an annotated database.

 <dig>  samples were manually assigned to the corresponding individual ids: some individuals are represented two times in the samples , since the same biological sample was hybridized to both platforms.

 <dig>  the query-based system was used to extract from the database three baskets:

a) a basket of  <dig> normal muscle samples for a total of  <dig> individuals;

b) two baskets of duchenne and becker muscular dystrophy samples containing  <dig> and  <dig> samples respectively for a total of  <dig> individuals.

 <dig>  the default workflow  was applied separately to the basket of normal samples and to the pair of duchenne and becker baskets, thus obtaining two expressionsets representing  <dig>  geneannot genes:

a) an expressionset, collecting gene expression levels in normal muscle tissue, which can be exported and used for a classic co-expression analysis.

b) an expressionset ready for the comparison of duchenne and becker expression profiles, for instance by sam, to find genes differentially expressed in the two forms of the muscular dystrophy.

discussion
in recent years, high-throughput technologies represented a breakthrough for the analysis of gene expression levels and hundreds of microarray-based studies generated an overwhelming mass of potentially valuable data. most of these data are organized in major repositories, are publicly available, and their meta-analysis represents an enormous opportunity for biologists and geneticists. however, the meta-analysis of data, obtained using a plethora of array platforms and experimental protocols in different laboratories, represents also a complex task for bioinformatics. indeed, the integrated analysis of microarray data generated by different research groups on different array platforms requires ad-hoc computational methods to retrieve raw data files and any related meta-information, to fix incomplete, or otherwise inadequate, sample annotations, to integrate multiple data sets obtained using different technologies and to remove center- and platform-specific biases from the final integrated signals.

despite major efforts to provide guidelines, formats, and standards for the annotation of microarray experiments, the identification, collection, and analysis of publicly available data sets still remains a cumbersome and error-prone process, further complicated by the heterogeneity of array designs and of sample characterization. the latter are among the most critical issues hampering meta-analysis approaches, since heterogeneous array designs complicate cross-platform integration and incomplete, or often inadequate, characterizations of specimens limit the robustness of statistical analyses. for the case of affymetrix assays, the cross-platform comparison can partly be solved re-defining the array geometry through custom definition files and re-annotating the probesets in terms of unique entities . an expression profile associated to a unique gene identifier can be more easily matched across subsequent generations of microarrays  <cit>  than a signal generated from a platform-dependent probeset. on the contrary, retrieval, organization and utilization of sample characterizations  are still critical and often severely limit the possibility to organize samples into biologically meaningful and homogeneous groups. indeed, the relationship between specimen, biological sample, phenotypic characteristics and raw data files, the most granular object in repositories, may be not sufficiently explicit or, even worse, may be scattered around the web as supplementary data to a scientific manuscript. as such, procedures for efficiently associating large numbers of data files and their related meta-information may be extremely tedious and error prone  <cit> .

several software and web tools have been proposed for retrieval, organization and meta-analysis of microarray expression data from public repositories  <cit> . however, none of them offers the possibility to retrieve and organize both data and meta-information, to use the latter to re-annotate samples, and integrate data obtained from different platforms.

a-madman is a novel tool for meta-analysis of affymetrix data contained in gene expression omnibus, which allows retrieving, annotating, organizing and analyzing gene expression datasets. in particular, a-madman addressees i) the batch retrieval from gene expression omnibus and the local organization of raw data files and of any related meta-information, ii) the re-annotation of samples, iii) the creation of user-defined batches of data through queries performed on sample labels, and iii) the integrative analysis of data obtained from different platforms through custom chip definition files and meta-normalization.

the batch retrieval of gene expression data from both geo and array express can be carried out using wgas  <cit> , mare  <cit>  and emaas  <cit>  while ezarray  <cit> , the geoquery package of bioconductor  <cit> , the server version of seqexpress  <cit>  and the geoimporter module of genepattern  <cit>  are limited to data deposited in geo. in particular, the geoimporter module of genepattern allows retrieving only a single series at once and does not permit to perform sub-selections of samples. mare, emaas and wgas can retrieve multiple series/datasets. however, mare is limited to the simple search and retrieval of data , while the web centralization of wgas poses serious operative limitations with very large datasets. a-madman, once downloaded raw files and meta-information, locally organizes and displays the data through a user-friendly interface. moreover, once data and metadata are retrieved, organized and annotated by a-madman, they constitute a stable dataset which, being available through a web application, can be used to define and analyze different subsets of samples for answering different biological questions. the possibility of re-annotating samples, through user-defined assignments, is a peculiar feature of a-madman and an improvement over all other available tools for meta-analysis. indeed, a flexible assignment of .cel files to specimens and a proper tracking of this association are necessary steps to efficiently exploit the mass of available data. however, handling multiple sample labeling and creating sub-classes of data may be so laborious and error-prone to discourage any meta-analysis diverse from the simple reproduction of the original experimental design. in a-madman, samples are annotated using not only the original metadata but also a proprietary, controlled, but unconstrained vocabulary of descriptive terms. this project-tailored vocabulary allows adding biological, clinical, technical descriptions to the original sample annotations, thus widening the scopes of a meta-analysis. the annotation of samples through tags allows the definition and the extraction of any subset of data and, in principle, the meta-analysis of any user-defined experimental design. specifically, one or multiple baskets of samples can be defined and extracted from the whole database simply using boolean queries on the available tags and then used to construct any custom data matrix.

the platform integration step is not clearly addressed by most of the available tools. indeed, the expressionfilecreator module of genepattern, although allowing the use of custom cdf, cannot consider more than one platform at the time. similarly, ezarray and emaas permit the analysis of only one type of affymetrix platform in a given project. crosschip  <cit> , instead, uses probe by probe sequence comparison to integrate data from different generations of affymetrix arrays. in crosschip, when comparing affymetrix platforms, only probes that have a certain amount of overlap in their nucleotide sequences in both arrays are retained in a mask file, which is later applied to the original .cel files to generate new .cel files. the new .cel can be then be processed using any signal quantification algorithm. the major limitation of crosschip is that only two platforms at the time can be compared. differently, a-madman can handle and integrate data generated by any type of affymetrix arrays. specifically, considering a set of samples obtained from more than one platform, expression signals are quantified separately for each platform on all those samples which are platform-homogeneous . gene expression levels and metadata are incorporated into as many expressionset objects as the different platforms represented in the baskets. the expression data of the various expressionset  are then integrated into a unique data matrix using a non-redundant list of gene-centered identifiers each derived from one or more platform-specific probesets/meta-probesets, using standard or custom cdfs. each platform represented in the baskets contributes expression data according to a list of platform-cdf dependent probesets  and the values of the integrated data matrix are obtained averaging the expression levels of the various platform-specific probesets/metaprobesets . the final step of the integration is inter-platform quantile normalization, i.e. a data transformation using, as reference empirical distribution function, the median expression across the experiments with the largest available number of probesets.

a-madman outputs an expressionset object, which contains all the necessary information to perform any higher level analysis, i.e., the integrated data matrix of normalized expression levels and the geo/user-defined metadata.

CONCLUSIONS
we developed a-madman a novel software which allows the retrieval, organization and meta-analysis of microarray expression data from public repositories. a-madman presents several features not available in any current tool and specifically designed to plan and conduct meta-analyses of microarray expression data: i) perform the batch retrieval and local organization of raw data files and of any related meta-information, ii) re-annotate samples using meta-information, iii) create user-defined batches of specimens, and iv) integrate data obtained from different platforms through custom chip definition files and meta-normalization.

availability and requirements
• project name: a-madman

• project home page: 

• operating systems: posix compliant and win <dig> 

• programming languages: python, r

• other requirements: gnu r >=  <dig> 

• license: gnu gpl v <dig> or any later version

list of abbreviations
geo: gene expression omnibus; cdf: chip definition file; http: hypertext transfer protocol; soft: simple omnibus format in text; sam: significance analysis of microarrays; na: not available; miniml: miame notation in markup language; miame: minimum information about a microarray experiment; rma: robust multi-chip analysis.

authors' contributions
ab planned, wrote and tested most of the software. ac contributed user interface code and participated to code review and quality control. ff participated to code review and algorithm planning, specifically for platforms integration. dr developed the inter-datasets normalization routine. sbo, cr, and sbi provided guidance during all phases of planning and implementing the software. ab, sbo and sbi wrote and revised the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
a-madman  <dig>  source code. version  <dig>  of a-madman source code.

click here for file

 additional file 2
supplementary figure  <dig>  the role of raw data-to-individuals assignment in the process of platforms integration.

click here for file

 acknowledgements
this work was supported by university of padova ; italian ministry of instruction, university and research ; fondazione cassa di risparmio di padova e rovigo  and fondazione cassa di risparmio di modena .
