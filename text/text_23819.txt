BACKGROUND
"without some assessment of reliability, a phylogeny has limited value"  – an examination of the recent phylogenetic literature shows there is a general agreement on this fact, and only few molecular phylogenetic studies of the past  <dig> years exist in which no estimate of confidence is provided. in the context of cladistic  analyses, two basic types are most common: resampling plans , and those based on the length difference of trees .

bootstrap and jackknife in parsimony analyses
bootstrap and jackknife are computer intensive statistical methods for error estimation  <cit> . with regard to their applicability in phylogenetics  <cit> , elaborate discussions exist in the literature  <cit> . the fact that fundamental statistical assumptions may not be met in the phylogenetic context  could not prevent the bootstrap from becoming the most popular method for reliability assessment, in particular since many researchers consider bootstrap and jackknife merely as indications of relative support, not in a hypothesis-testing framework. felsenstein  <cit>  provides an easy-to-read but detailed description of resampling plans in phylogenetics and addresses solutions to circumvent some of these more fundamental problems.

aside from that, the majority of applied phylogenetic studies hitherto do not provide a justification for using a certain number of replicates or a particular search strategy during each bootstrap  replicate. unfortunately, often the parameter settings that are employed are not those that appear recommendable in view of the existing theoretical and empirical work that provides a guideline for the number of replicates  or search strategies  <cit>  to be used. phylogenetic trees are tools for understanding biological processes and gain more and more importance far outside the field of pure phylogenetics. ideally, biological conclusions based on a given node in the tree should take into account the level of confidence one can have in the existence of the node. therefore, it appears necessary to more efficiently spread the existing knowledge on the performance and interpretability of the bootstrap and jackknife under different circumstances, but also to address those questions that still remain open.

the number of replicates
hedges argued that at least  <dig> replicates are needed if one wants to attain ±1% accuracy for bootstrap proportions of 95% or higher  <cit> . the underlying considerations are based on the binomial distribution, which has the favorable characteristic of a variance σ <dig> that equals np. in the context of resampling plans, n is the number of replicates and p is the bootstrap or jackknife support value  expressed as a fraction of  <dig>  i.e., the proportion of replicates that yielded a tree containing a particular phylogenetic group. therefore, the n needed to attain ±a accuracy  at a support level p can readily be calculated as

n = p  <dig>      

hedges  based the determination of the confidence interval upon an approximation of the binomial distribution by the normal distribution. however, when np ≤  <dig> and n ≤  <dig> , much precision is gained when standard errors are based on the binomial distribution. this condition is easily fulfilled at high probabilities. here, the confidence intervals become asymmetric.

let y be the number of successes  out of n trials , and p the success probability of each trial. the lower endpoint of the 100%-confidence interval around the estimated p  is given by the pl such that



similarly, the upper endpoint is defined by finding the pu such that





rather than odd numbers such as "1825", researchers currently use "500", "1000", etc. replicates, and the question arises, what the confidence interval for a given p may be when these number of replicates are used. this is easily derived from eq.  or  from eqs. -, and fig.  <dig> graphs these intervals for support levels of ≥ <dig> and common replicate numbers. with help of this graph, the frequent issue whether two apparently different support values really differ can relatively easily be addressed visually. the decrease of bs/js  standard deviations with an increase of the number of replicates , which theoretically follows from the above equations, was confirmed in detailed empirical studies on the topic using real datasets of saxifragaceae  <cit>  and orchidaceae  <cit> .

search extensiveness
from a theoretical point of view, the question of the optimal number of bootstrap replicates is easier to solve than that of the optimal heuristic search strategy to be applied during bootstrap replicates of cladistic analyses. farris et al.  <cit>  initially argued that thorough swapping during replicates is unnecessary. the whole point of using resampling is "to avoid drawing poorly-supported conclusions"  and identifying those groups that are strongly supported by the data. the most strongly supported groups are certainly easily identified via bootstrapping or jackknifing when no swapping is performed, but at the expense of risking that some nodes are ignored that could gain significant support .  <dig> - s is conventionally interpreted as type i error  in hypothesis tests where a group of taxa will be considered monophyletic if bs > s . thus, bs/js that is systematically too low at least does not entail an increased danger of mistakenly inferring monophyly. it does, however, lead to rejecting monophyly incorrectly too often, which is not desirable, either. nonetheless, one of farris & al.'s main points was to contrast the speed of their jackknifing approach with the slower neighbor-joining bootstrap and extensive heuristic parsimony searches to identify mp trees ; branch swapping during each replicate would have strongly lowered the performance contrast. therefore, the first version of farris' jackknifing application, 'jac', did not perform branch swapping at all.

a number of studies provided practical evidence from real datasets that the non-branch swapping approaches  yield significantly lower support estimates than analyses performing some kind of branch swapping  <cit> . accordingly, branch swapping was later added in the upgrade 'xac'. in line with farris & al.'s basic assumptions, however, it was concluded that swapping on more than  <dig> to  <dig> trees per iteration does not change support significantly  <cit> . this implied that the increased computational effort connected with more extensive searches per replicate does not necessarily translate into more accurate estimates. note that these examinations used the random addition search strategy available in paup*  <cit> , which is known to relatively soon fail to find shortest trees as the number of terminal sampled increases . this is why cladistic analyses of datasets approaching or exceeding  <dig> to  <dig> taxa  usually make use of the parsimony ratchet  <cit>  or other fast cladistic algorithms, available through a number of software tools  <cit> .

these results raise the question in how far bootstrap percentages are affected by trees found in each bootstrap replicate being far from most parsimonious. the above-cited increase in search exhaustiveness, namely moving from non-branch swapping via nni and spr to tbr, yielded a considerable increase in support  <cit> . swapping on more trees  apparently did not increase, but sometimes even lessened the average support  <cit> . these investigations, however, were conducted on datasets for which it was quite likely that shortest trees could be encountered without much search effort per iteration because size and homoplasy still allowed that shortest trees could be found with intermediate effort without algorithms designed for particularly large datasets.

if the standard error of the bs/js value itself is neglected , a dataset-dependent graph can be imagined in which the bootstrap is a function of the exhaustiveness of the search. if we further ignore for a moment the effect of how many trees per replicate are actually used in the majority rule consensus  <cit> , and whether tree weighting is employed for these, this graph will asymptotically approach a "bs/js level of saturation" at which further increase in exhaustiveness does not increase bs/js. as a rough guideline we expect that the more taxa, the later this level of saturation will be reached. certainly other factors such as homoplasy and phylogenetic signal inherent to characters play a significant role, but the mere fact that the number of possible tree topologies soon reaches astronomical dimensions  <cit>  provides the most severe limitations to search algorithms. somehow a point has now to be chosen at which one decides that the increase in support is not worth the additional search effort. a statistic could be chosen that describes the support level for each discrete level of exhaustiveness and subjected to hierarchical significance tests.

without the unrealistic assumption of an infinitely narrow confidence interval around each support level, things become more complicated. the size of the  confidence interval depends on the support level one looks at, less dramatically so when the number of replicates becomes very large . thus, to a considerable extend, drawing conclusions on the relative merits of certain search strategies has to take into account the support levels of interest. commonly, these will fall in the interval , but less likely only in the standard interval  due to the frequently cited conservativeness of the nonparametric bootstrap  <cit> .

the relationship between the number of trees per replicate fed into the consensus calculation and the bs/js is still less straightforward. the more conservative approach of using strict consensus trees of each replicate for the final consensus tree , referred to as "strict-consensus approach"  by davis et al.  <cit> , can be expected to always result in equal or lower support than the standard approach in paup*, for which the term "frequency-within-replicates approach"  has been coined  <cit> . the latter employs tree weights that maintain information on nodes that other trees found in the same replicate lack. this theoretical expectation was empirically corroborated very recently using a 218-terminal dataset  <cit> . the sc approach  <cit>  may more closely reflect the use of the bootstrap outside the field of phylogenetics, but is only rarely pursued in published analyses . restricting the discussion to the tree-weighting approach in paup*, it is hard to predict whether additional trees saved per replicate will decrease resolution of the final majority rule consensus, because these additional trees are usually also swapped upon and thus enhance the probability of finding trees closer to the optimal score of the current replicate. the latter effect is counter to the first, and which effect will be stronger depends on a whole array of parameters, probably above all on the sampling size and thoroughness of the search. using a  <dig> taxa data set with  <dig> parsimony informative characters, freudenstein et al. found that beyond  <dig> trees, saving more trees considerably decreases overall support, if these trees are from the same ras  iteration and not obtained via additional ras replications . the authors, however, did not test the effect of increasing search extensiveness beyond  <dig> ras replicates per jackknife replicate.

jackknifing versus bootstrapping
principally, all considerations below apply equally to the bootstrap and jackknife. farris et al. argue that, in order to directly compare jackknife frequencies with bootstrap frequencies, the probability that a character appears in the resampled matrix has to be set to 1-1/e  <cit>  . this was recently emphasized again by freudenstein et al.  <cit> . felsenstein disagrees with that view, demonstrating that at least sometimes a 50%-deletion-jackknife more closely reflects bootstrap proportions  <cit> . in any case, when comparing the behavior of bootstrap and jackknife, differences in the support levels are also a function of the probability that a character appears in the resampled matrix and, thus, the amount of data used for tree inference in the pseudoreplicates.

the bremer support
the bremer support , a synonym of "decay index"  <cit> , "length difference"  <cit> , or "support index" , is a completely different measure of branch support and has been addressed in detail recently  <cit> . for intermediate to large datasets, the calculation of brs can be problematic, because support values can turn out to be severe overestimations of support  <cit>  unless relatively thorough search strategies are invoked to assess support of each branch. it has been demonstrated that using the parsimony ratchet during bremer support analysis is highly advantageous in such cases  <cit> . however, the data-dependent optimal compromise between ratchet search time and improved support accuracy has not been addressed so far and therefore will be briefly dealt with below.

RESULTS
bootstrapping and jackknifing
empirical studies on four different molecular datasets  of  <dig>   <dig>   <dig>  and  <dig> taxa, respectively, yielded the following results. using  <dig> or  <dig> parsimony ratchet cycles per jackknife replicate instead of one simple addition search with one saved tree yielded no enhanced support for the  <dig> and  <dig> taxa datasets . this confirms conclusions from ras searches on data sets of similar dimension  or twice as big . for the considerably larger  <dig> and  <dig> taxa datasets,  <dig> ratchet cycles could not enhance support significantly, either . moreover, the effect of saving more than one shortest tree per jackknife iteration and using a strict consensus tree of these for the final jackknife consensus tree became obvious. this is detailed in table  <dig> for the  <dig> taxa tree: computing a strict consensus of the n shortest trees found during  <dig> ratchet iterations  provides less support than saving only one out of these shortest trees . the same effect was previously observed in a  <dig> taxa dataset  <cit>  when  <dig> trees were saved : support decreased compared to the outcome of the same analysis saving only one tree . consequently, for larger data matrices, reduced search effort  yields rather slightly overestimated support compared to the support found with higher effort. while it has been shown that not applying tbr can severely underestimate support  <cit> , using still more thorough search approaches  does not significantly raise or even lowers support.

in all, extending the search extensiveness beyond the rather moderate effort of tbr and saving one tree per replicate does not translate into significantly increased support. compared to bremer support, theoretical considerations show that there is a lower risk of significantly overestimating support by using less thorough searches . the lack of inflated estimates caused by less extensive searches was corroborated using real datasets  <cit>  and simulation studies  <cit> . these studies, however, compared searches without branch swapping or less effective swapping with searches that include tbr, while not addressing the factor of the number of trees saved and used in the bootstrap/jackknife consensus. the investigation of freudenstein et al.  <cit>  with  <dig> saved trees already indicated that support might well drop with more conflicting topologies taken into account per jackknife replicate. in their experiment, however, the option of saving   <dig> trees also enhanced the likelihood of finding still shorter trees per replicate. in the present study, the pure effect of ignoring all but one of the topologies with the best score per jackknife replicate becomes evident: support is significantly higher than in a jackknife consensus tree based on all shortest trees found. thus, for very large trees, there appears to be a small risk of overestimating support. however, this risk probably cannot be judged problematic, in particular not in view of the general conservativeness of nonparametric jackknife and bootstrap estimates in phylogenies  <cit> , which in general should more than counterbalance this slight effect; at least it does so for the dataset analyzed here. as a response to this general conservativeness, α-levels have been raised far above the common 1% – 10% in empirical phylogenetic studies, leading to the acceptance of the presence of nodes with <<90% bs, or at least to referring to such nodes as "highly supported" . one could easily recommend reducing this small risk of overestimating support by representing each bootstrap replicate by a consensus tree derived from multiple searches, but this probably suffers from a too high cost-benefit ratio to be practical in most analyses:  <dig> ratchet iterations require roughly a 20-fold search time compared to a simple search.

on the other hand, even for large trees, there appears to be no severe risk to underestimate support, as long as one simple-addition tree is swapped using tbr. in contrast, using random addition or random trees as starting trees during each replicate leads to highly significantly underestimated support .

note that the above considerations aim at contrasting search strategies and do not extend to fundamental statistical bias existing in bootstrap and jackknife proportions  <cit>  that may deteriorate with increased taxon sampling  <cit>  but improves with increased character sampling. for datasets with many taxa, computational limitations of search strategies become confounded with this bias. therefore, sanderson and wojciechowski  <cit>  could not preclude that part of the decline in bs they observed when increasing sampling size  was due to the failure of the simple addition search  to find shortest trees. in view of the results presented here, this effect was probably negligible compared to the statistical bias from random homoplasy distributed among taxa . to reduce this bias and achieve more accurate confidence limits, much more computer-intensive, iterated bootstrap methods have to be taken , frequently thought to be too time-consuming to be practical for large amounts of data. sanderson and wojciechowski argue that relying on search algorithms with only little branch swapping may circumvent this computational limitation, allowing multiple rounds of bootstrapping by saving time during each individual bootstrap . the outcome, they say, may still be somewhat too conservative because of the failure of these algorithms to find mp trees, but would still be more indicative of true support than conventional bs/js. in light of the performance of varyingly extensive search strategies on datasets even larger than that in ref.  <cit> , it appears that iterated bootstrap methods are not as impractical as previously thought and should more frequently be considered.

finally, as shown in fig.  <dig>  the higher the number of replicates, the lower the error margin for the bs/js support. to evaluate differences in support for a particular clade, confidence intervals have to be kept in mind to arrive at a statement on the significance of differences. the number of replicates needed to narrow down the confidence intervals to a desired level is a function of the bs/js. if, for example, one restricts conclusions from a tree topology to nodes > <dig> and is happy with knowing  that a "91" cannot equally likely be a "89" , more replicates than  <dig> are not needed.

bremer support
fig.  <dig> shows how the bremer support develops at the  <dig> randomly selected nodes with increasing search extensiveness. values obtained by a simple search with tbr branch swapping  are compared with those obtained with  <dig> –  <dig> parsimony ratchet iterations. vertical lines mark the average number of iterations at which 90% of the final support difference  are exceeded first. in the smallest dataset  this is the case at the 12th ratchet iteration. for the slightly larger  <dig> taxa dataset, less iterations are needed until support values become comparably saturated. this dataset, however, displays much less homoplasy than the first and, thus, is easier searchable. consequently, less effort is needed here to arrive at a similar result. the  <dig> taxa dataset is comparable to the  <dig> taxa set in terms of homoplasy but is much larger. unsurprisingly, the bremer support settles later here. the same reasoning applies to the largest,  <dig> taxa dataset, for which the 90%-level is reached only after  <dig> iterations. in view of the range of different taxon and character sampling covered by these four analyses, saturation appears to happen at quite similar times. obviously, the 90%-level is an arbitrary measure, and one might want to extend analyses until an average 95% of the final bremer support differences are reached. this, however, would not change much the relative times at which that is achieved. as a rule of thumb it appears that not much is gained relative to the additional effort when searches are extended beyond  <dig> iterations, at least not for datasets that fall within the size range observable in current publications. for datasets with a still smaller taxon sampling and still less homoplasy, for which using the ratchet principally does not save time, a single simple addition search  may already yield bremer support values close enough to the "true" values . as soon as the size and structure of a dataset entails that shortest trees are principally only encountered when at least a random addition search is performed, using the ratchet and the 90%-levels found here as a guideline seems a reasonable strategy.

CONCLUSIONS
one consequence of the above findings is that calculating bootstrap- or jackknife proportions with narrow confidence intervals can be achieved with less expense than often thought, even for very large datasets. in turn, this means that iterated bootstrap methods that aim at reducing statistical bias inherent to bootstrap proportions are more feasible, since the individual bootstrap searches may be performed using less time-intensive heuristic searches during each replicate.

as a further consequence of these reflections, finding bootstrap or jackknife proportions with reasonable confidence can be achieved with much less costs than trying to find the correct bremer support for large datasets. bootstrap or jackknife values saturate immediately after one simple addition search, while finding satisfyingly accurate bremer support may require  <dig> or more iterations, much depending on what one subjectively accepts as "satisfyingly accurate" . if we take the  <dig> taxa dataset as an example, bootstrap support with 1% accurateness at ≥95% could be gained by  <dig> simple searches , while bremer support would require n* such searches, where n is the number of nodes to test . if we approximate that tbr swapping on one tree takes roughly equally long irrespective of the particular resampled matrix or the particular constraints in effect at a given node, calculating bremer support for the  <dig> nodes resolved in the strict consensus  <cit>  takes five times longer than bootstrapping or jackknifing .

the relative speed of both methods strongly varies with the accurateness aimed at, but even calculating  <dig> jackknife iterations needed for  <dig> % accurateness at nodes with ≥85%  is faster than obtaining bremer support with the precision outlined above, which may only be the case beyond an equivalent of 339*) =  <dig> such jackknife iterations. the relatively higher performance of jackknifing and bootstrapping further increases with the taxon sampling size. strictly speaking, a comparison of the speed at which both support types are computable makes not much sense, due to the fundamental differences of both. on the other hand, along with considerations on the interpretability of bremer support compared to the bootstrap and jackknife  <cit> , such practical considerations may assist in choosing which support type to report when the time available for analyses is limited.

