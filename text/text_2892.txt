BACKGROUND
hydrogen-deuterium exchange mass spectrometry  is a powerful method for relaying information on protein dynamics and protein-ligand interactions. in h/dx-ms, proteins are deuterium-labeled by simple incubation of the protein or protein mixture with d2o, which exchanges labile hydrogen with deuterium. the degree of labeling is determined by the rate of exchange, which in turn is determined by the structure and dynamics of the protein. these exchange rates are influenced by the binding interactions of the protein. if exchangeable hydrogens are involved in the ligand binding site, these will be 'less available' for exchange and will exchange at a lower rate than in the absence of the ligand  <cit> . while n-terminal and most side-chain hydrogens exchange very quickly and escape detection, amide hydrogens exchange in a time scale supporting measurement at a temporal resolution approaching a few milliseconds  <cit> . the overall workflow for typical bottom-up h/dx-ms experiments has been reviewed .

the readout for h/dx-ms is the mass spectrum. in a bottom-up h/dx-ms approach, h/d exchange is monitored at the peptide level and the deuterium-labeled peptide generates an isotopic envelope which is well modeled by binomial expansion of the underlying unlabeled counterpart  <cit> . extraction of deuterium levels typically requires extraction of the envelope for each peptide of each raw data file. h/dx-ms studies can consist of a set of experiments that monitor tens to hundreds of peptides. often two or more states of a protein require comparison . proteins may be labeled for durations of msec's to days in order to generate kinetic data  <cit> . varying the concentration of d2o used in the labeling reaction may also be required  <cit> . thus, while individual h/dx-ms experiments can be completed rather quickly, thorough protein analysis usually involves numerous runs with the attendant requirement for replicates for each run. this creates a burden in data analysis, where tens to hundreds of lc-ms files require inspection. a set of experiments for small proteins can take several weeks to analyze, if processed manually.

several tools have been developed to address ms-level data processing needs. hx-express is a semi-automated excel-based application that extracts average deuterium incorporation levels from the user-supplied experimental and theoretical isotopic distributions. calcdeut  <cit>  and dex  <cit>  are software packages that extract deuterium incorporation distributions from user-provided mass spectra, through a command-line approach. these tools require manual processing of extracted ion chromatograms  and mass spectra and do not attempt to provide a means of grouping raw data inputs or organizing and aggregating data outputs on a project-wide scale. this is also the case for autohd, an earlier approach to deuterium incorporation measurement  <cit> .

two packages are available that operate on a project-wide scale. the deuterator  <cit> , is a freely available web-based tool that organizes the raw data files according to experimental conditions, and effectively completes all the tasks in the ms-based workflow shown in fig.  <dig>  as with autohd, it uses a 'theoretical fit method' to measure deuterium incorporation, in which the theoretical isotopic profile for varying degrees of deuterium labeling is fit to the experimental isotopic profile. deuterium incorporation values can be outputted and further data handling is left to the researcher. a newer version, 'hd desktop'  <cit> , provides additional data handling capabilities. 'tof2h' is a second package  <cit> . this is a recently published excel-based application geared toward processing and viewing ms-level maldi-tof data from the ab  <dig> tof-tof instrument. tof2h organizes raw files, and iterates through the typical processing workflow shown on the left-hand side of fig.  <dig>  other packages have been described in the literature, but are not as readily available  <cit> .

though the deuterator and tof2h greatly advance an automated approach to h/dx-ms data processing, they do not meet several of our data analysis requirements. we required a customizable data analysis workflow in order to evaluate novel h/dx-ms procedures such as the one we recently reported, involving restraints on the peak envelope width  <cit> . this demanded an architecture supporting easy adaptation. we were also interested in automating deuterium distribution calculations, methods that were described by several groups including ours  <cit>  but not incorporated into a project-wide scale with a convenient graphical interface. further, as our group conducts large scale studies on large multiprotein systems, retaining file size efficiency was an important operational requirement. most of our experiments are conducted on qstar instruments thus we needed a utility for processing analyst qs .wiff files. avoiding a file conversion process has advantages in time savings. while .wiff files could be converted to mzxml for use in the deuterator, the conversion greatly increases file sizes and these projects would require uploading to the deuterator ftp site, which could be cumbersome for large projects. we recognize that retaining platform independence is a useful attribute, thus the software also required a means of processing mzxml files efficiently.

most importantly, we required an automated approach to the extraction of deuteration data from ms/ms spectra on a large scale, such as might be generated in a proteomics-style approach to h/dx experiments. although extracting deuteration data from ms/ms spectra is not yet common, two recent observations argue for its routine implementation. first, we have demonstrated that deuterium scrambling, common in collisionally-induced dissociation  of peptides, enables robust measurements of deuteration reflective of the precursor ion . second, recent studies have highlighted that alternative fragmentation processes such as electron capture dissociation may suppress scrambling and support higher resolution localization of deuteration  <cit> . both will require new software for automated processing of data. the right-side of fig.  <dig> highlights the additional considerations that such a software package needs to address, for data collected in a conventional proteomics fashion . this article will describe how hydra meets each of these new requirements, in addition to providing features available in other h/dx-ms data processing packages.

implementation
hydra was written in c# . a stand-alone executable setup file facilitates installation on the target computer. hydra allows processing of ab/sciex qstar data  directly, which requires a local installation of analyst qs  <dig>  . an alternative version processes mzxml files after a file conversion step, and does not require analyst qs.

generation of extracted ion chromatograms  and ms spectra from analyst qs files uses libraries available within this software package. hydra leverages several additional publicly available class libraries. all graphing controls are from zedgraph version  <dig> . <dig>  <cit> . for platform independent mzxml files, xic's and ms spectra were generated using class libraries from proteowizard  <cit>  and decon2ls  <cit>  was used for peak detection and savitzky-golay smoothing. for both versions of hydra, lutz roeder's c# library 'mapack'  <cit>  was used for performing linear least squares operations for the extraction of deuterium incorporation distributions. numbers generated by this library were tested for agreement with values generated from the command-line program 'calcdist.py,' as described in chik et. al  <cit> . molecular weight calculations and theoretical isotopic distributions were calculated using the class library 'mwtwindll.dll'  provided as part of source code for pacific northwest national laboratory's molecular weight calculator  <cit> . calculation of student's t-values and p-values were carried out using c# source code from the alglib project  <cit> . all the class libraries listed above are included in the setup file for hydra.

unit testing using nunit  <cit>  was performed throughout hydra to ensure well-functioning source code and algorithms that return appropriate values.

RESULTS
an overview of hydra is provided in fig.  <dig>  the main outputs include 1) deuteration values at both the ms and ms/ms level 2) data visualization for manual assessment and validation and 3) distributions of deuterium incorporation. these are described in detail below. one of the key design features of hydra relates to the configurability of the workflow. this will be described in conjunction with the automated processing capabilities of hydra.

automated extraction of deuteration values and flexible workflows
hydra focuses on bottom-up h/dx-ms experiments and therefore examines deuteration incorporation at the peptide level. minimally the researcher must supply the sequence, m/z, expected retention time, and charge state for each peptide. this can be accomplished within hydra by parsing the comma separated values  output of a mascot search result, for example, allowing a quick way to import peptide data from a common database search program; a screenshot of this tool is shown in fig.  <dig>  alternatively, the peptide data may be entered manually within hydra or from a user-generated .csv format  from the selected protein are imported into hydra.

on a basic level, several steps are required prior to extraction of the deuteration data. the first is extraction of peptide ion chromatograms . this reveals the liquid chromatographic elution profiles for the peptides. in a typical experiment, several peptides may share the same m/z as the target peptides, thus the xic's often contain several peaks. a peak is usually selected based on the expected retention time for the peptide within a given tolerance or via a specified time-range. integration over the xic peak or specified range generates the mass spectrum. the mass spectrum contains many peaks and the isotopic profile for the target peptide must then be located. the deuteration level can then be calculated in a number of ways. the most common approach is the 'centroid method' in which the average mass of the isotopic profile is calculated, either using isotopic peak intensities and m/z values, or all m/z and intensity data points within a defined m/z range. deuterium incorporation can be calculated by a simple formula  using the experimental centroided mass and the theoretical centroided mass, which may be calculated from the theoretical isotopic profile of an unlabeled peptide. this 'centroid method' is highlighted in fig.  <dig>  showing that the intensities of the individual isotopic peaks are required for such measurements. other methods of calculating deuterium incorporation are discussed later in the text. hydra provides a tool for global adjustment of most peptide data fields. this is useful for quickly adjusting fields that are often the same for each peptide .

fig.  <dig> summarizes the three basic inputs into hydra for automation of data extraction for multiple datasets: 1) a project tree, which functions to associate raw data files with experimental conditions; 2) the peptide set and 3) the data analysis workflow. the project tree is a means of organizing all the raw data files within a confined set of experiments. as an example, we have studied the calcium-free  vs. the calcium-loaded  forms of the protein calmodulin under six different d2o concentrations , with the labeling time held at two minutes. we generated six replicates for each concentration. additional file  <dig> shows hydra's project setup interface that was used in defining this project. in this example, the project tree was populated with the raw data files according to the two 'protein states' – apo and holo – and the six labeling conditions with replicates. currently, hydra allows processing of both ab/sciex .wiff files and generic mzxml files. future versions of hydra will implement new generation mzml files.

once the peptide set and the project tree have been defined, the data processing workflow must be established. rather than force a given workflow on the process, we have enabled easy customization and configuration of data analysis to facilitate the addition of new processing algorithms into the software code base . fig.  <dig> shows a screenshot of the workflow configuration window. the available algorithms  are displayed on the right-hand side. these are 'dragged-and-dropped' into the data analysis workflow and can be clicked to reveal underlying customizations. the left-side of fig.  <dig> shows a typical h/dx-ms workflow that firsts extracts an ion chromatogram, provides smoothing, selects the appropriate peak, integrates over the peak to give the mass spectrum, provides smoothing and peak detection, locates the isotopic profile, and finally calculates the deuteration level.

the modular nature of the workflow set-up allows flexibility in the tasks that are selected, how they are implemented, and in what order they are performed. at the software level, this is made possible through the dynamic loading of algorithm assemblies that implement a plugin interface defined by hydra. each algorithm is derived from an abstract 'task' that simply requires one input  and has one function . each task is executed and thus populates the result object. configurations are embedded within each task and the workflow is saved as part of the entire hydra project, allowing easy retrieval of previous workflow settings. the modular nature of the workflow allows a great deal of freedom in defining workflows. for example, in this first release of hydra, we provide two alternatives for calculating average deuteration levels. one provides the conventional method of measuring the centroid mass of the isotopic distribution, while the other extracts the underlying deuterium distribution and uses this data to calculate the labeling level  <cit>  .

although the current algorithm toolbox  limits the user to one or two choices per algorithm, we envision the addition of algorithms previously described by others, especially in the area of peak detection, isotopic profile isolation, and label amount calculation. openms has recently been released and offers robust ms feature detection  <cit>  and if implemented into hydra, will provide a strong peak-finding alternative. in hydra, we use a simple algorithm for locating an isotopic profile, resembling that described by pascal et al.  <cit> . in the hydra algorithm, the monoisotopic peak is first located; then other members of the isotopic profile are populated by searching within a m/z window for peaks that match the expected m/z and charge state of the peptide. while this simple algorithm has been used successfully by our lab for over two years, we recognize that it is less successful with convoluted mass spectra. use of more complex algorithms such as thrash  <cit>  or nitpik  <cit>  will be extremely beneficial for teasing apart overlapping peptides. as noted above, hydra provides two alternatives for deuterium incorporation calculation. using a isotopic distribution fitting algorithm to calculate label incorporation such as the method used by the deuterator  <cit>  or most recently described by sperling et al.  <cit>  will be useful additions. hydra's framework should speed the implementation of these and other algorithms. we note here that hydra was primarily designed for high resolution ms data, where baseline resolution of isotopic peaks within an envelope promotes greater accuracy and precision in deuterium level calculations.

the most obvious benefit to automatic h/dx-ms data processing is speed of analysis. to examine this, the workflow shown in fig.  <dig> was applied to a set of experiments involving tubulin conformation analysis, first using the analyst-based version of hydra. tubulin is a relatively large dimeric protein  that yields a complex mixture of peptides challenging to many facets of h/dx-ms data processing, validation, and visualization. we have identified over  <dig> peptic peptides, about  <dig> of which we monitor during data analysis. since the peptide mixture is complex, xic's of the target m/z values often feature several elution peaks and mass spectra are frequently convoluted with overlapping peptides. in this test project we compared two biochemical states of tubulin, each state consisting of  <dig> labeling condition , with a total of  <dig> raw data files. deuterium incorporation data was extracted for  <dig> tubulin peptides from analyst™ qs  <dig>  '.wiff' files. data processing in this project required the evaluation of  <dig> mass spectra; table  <dig> displays the analysis times. to test the processing of mzxml files using the analyst-based version, mzxml files were generated from '.wiff' files using seattle proteome center's mzwiff.exe command-line application  <cit> . as table  <dig> shows, processing raw data was nearly twice as fast as processing mzxml files, demonstrating the efficiency of direct file access. the time difference is tolerable in most situations, since a first-pass extraction of the data is normally performed once. clearly, processing mzxml files using the analyst-based version of hydra is awkward when using data from other instruments, as a license for analyst is required. thus we developed an analyst-free version where analyst algorithms were replaced with publicly available libraries. this version offers a comparable efficiency to the analyst version for processing mzxml files .

* refers to tasks listed in fig.  <dig> 

** processing time for entire project/processing time per peptide

once processing is complete, the project can be saved in a binary format and can be reloaded at a later time. hydra allows some control as to what data is saved. for most projects it is convenient to save all chromatograms, mass spectra and deuterium incorporation data for all peptides. for the tubulin test project, the hydra file size for both the analyst-based and mzxml-based projects was around  <dig> mb. to avoid extremely large file sizes for even larger protein systems, the user can remove the 'data saver' task from the workflow. in this case, the individual chromatograms and/or mass spectra will not be saved, although this will come at the cost of slower re-processing.

viewing, validating, and re-processing tools
fig.  <dig> shows the primary layout of hydra as it is used in viewing the processed data. the screen is divided into three sections. the left-most section is used for navigating through the project tree, including protein states, labeling conditions and individual peptides. the center area displays graphs and tables of data and the right-most section presents context-sensitive properties of the selected feature of the project tree. the primary means of viewing deuterium incorporation data is through the summary table, shown in the center section of fig.  <dig>  this table reports the averaged deuterium incorporation values and their standard deviations for the replicates for each peptide of each protein state. in the sample table of fig.  <dig>  we compare the apo versus holo forms of calmodulin. comparative statistics are shown in the right-most columns of the table. these include the deuteration ratio and its standard deviation, a student's t-test and p-value for detecting differences between the two protein states. right-clicking on the table allows the user to control the selection of protein states being compared. a graphical view of the data is also shown in the screenshot overlaying the table.

graphical tools are also available for viewing the data as a function of labeling time or labeling percent. in a sample project we examined apo and holo-calmodulin over a range of d2o concentrations . the center pane of screenshot in fig.  <dig> shows the deuteration incorporation measurements for the two protein states for peptide e84-f <dig>  as a function of labeling percent. other peptides can be viewed by selection in the left-most pane, and details of the selected peptide can be seen in the right pane.

hydra also provides a means for 'drilling down' to allow visual assessment, manual validation and reprocessing of individual replicates. fig.  <dig> shows a screenshot of the 'manual assessment and validation' form, whose arrangement resembles that of hydra's main display: the left-side for navigation, the center for xic and ms graphs. the right-side contains controls for adjusting the individual replicates . there are three viewing modes: 'quick view' for viewing single replicates; 'replicate view' for vertically displaying all replicates of a given protein state/labeling condition/peptide/fragment ; and 'protein state compare view' for vertically comparing data across protein states.

the replicate viewing mode is heavily used during manual validation and adjustment of the data and is a key time-saving aspect of hydra. vertical alignment of the xics and mass spectra for all replicates is quick way of visually spotting problems and rejecting spectra . the most common problem we encounter in processing ms-level data is in the correct selection of the xic peak from "busy" chromatograms. global performance was evaluated using the tubulin test project, in which we used hydra to automatically process the data and manually validate and adjust the results. fig.  <dig> shows a screenshot of the 'project-comparer tool' that was used to follow the run-by-run number of adjustments that were required for optimum extraction of data from the tubulin test. comparing the pre- and post- adjustment phase projects showed that adjustments were required for an average of  <dig>  of  <dig> peptides per run, giving a success rate of 94% for automated extraction. the 'project comparer tool' also reports adjustments on a per peptide level, and helps reveal 'problem peptides.' hydra's visual alignment of all replicates contributed to the speed of adjustments, which required approximately one hour for the entire project set.

adjustments of the individual peptide results can be easily made to the xic peak retention time, the xic integration window , and the number of peaks from the isotopic envelope to be used in the deuteration amount calculation. when an adjustment is made, the individual result is re-processed according to the workflow that was initially defined in the project. reprocessing is executed only using the tasks necessary. this is done real-time and is nearly instantaneous. for example, in the workflow described above featuring  <dig> tasks , an adjustment of xic peak selection  only requires reprocessing using tasks  <dig>  through  <dig> . this adjustment required about  <dig>  seconds per peptide.

deuterium distribution tools
multiple algorithms have been described that extract the deuterium distribution of an isotopic profile  <cit> , but none of these have been incorporated on a project-wide scale into a convenient user interface to support rapid visualization of deconvolved isotopic distributions. in hydra, we implement the method described by chik et al.  <cit> , which uses a linear-least squares approach to fit the deuterium distribution. this can be included as a task within the data processing workflow, and can be further examined in the manual assessment and validation tool, as shown in fig.  <dig> 

in this deuterium distribution method, the measured isotopic envelope is truncated by excluding peaks whose normalized intensities fall below a user-defined threshold, and the measured isotopic profile is 'padded' with a user-defined number of zero-intensity peaks. in hydra, deuterium distribution values can be overlaid on the actual mass spectrum  and the two parameters – threshold and padding – can be adjusted with live-updating. enabling visualization of the deuterium distribution in this way helps to detect departures from "normal" labeling conditions well modeled by a single binomial distribution. for example, transition from an ex <dig> to an ex <dig> exchange phenomenon would be revealed in a departure from a simple binomial distribution of states  <cit> . it may also support new validation strategies. for example, the deuterium distribution can visually show anomalies in the isotopic envelope that may be missed by visual inspection of the mass spectrum . detection of these problematic spectra through the use of deuterium distribution analysis provides a useful means of automating validation, which remains the bottleneck in data analysis.

mining the ms/ms regime
the ms/ms regime in bottom-up h/dx studies is a largely untapped data reserve. two reasons likely contribute to the underutilization of ms/ms data – one is the perception that cid-based ms/ms data is of little value because of deuterium scrambling. another is the lack of software to automatically extract deuterium incorporation values from lc-ms/ms spectra, precluding the large-scale analysis of many fragment ions from many peptides. we have demonstrated the analytical utility of the ms/ms domain for deuteration measurements  and recent studies have shown the potential for ecd fragmentation to preserve deuterium location  <cit> . thus we developed hydra to accommodate ms/ms data. here, we describe the implementation of ms/ms data processing and present some preliminary results. the full evaluation of the ms/ms domain for h/dx-ms studies will be presented elsewhere.

hydra provides two tasks that enable ms/ms data processing. the 'ms/ms generator' works on both raw analyst™ qs data and mzxml data to extract the ms/ms spectrum for each peptide precursor ion. this data can be extracted from conventional data-dependent acquisition runs, with or without extensive "inclusion lists". user-controlled parameters define the acceptable m/z mass tolerance and the width of a eluted chromatographic peak. these parameters guide the merging of multiple ms/ms spectra that may have been acquired as part of an automated data-dependent ms workflow. the 'ms/ms fragment analyzer' is comprised of two tasks – an isotopic profile finder, and the label amount calculator. this fragment analyzer takes the ms/ms spectrum, loops over the list of user-provided fragment ions for each peptide analyzed and extracts the deuterium incorporation amount for each fragment ion. smoothing tasks can be inserted into the data processing workflow as desired.

multiple workflows can be executed to extract both ms-level and ms/ms-level deuteration incorporation values on the same project. as an example, we examined the deuteration incorporation for the precursor ions and for all singly and double charged b- and y product ions, for  <dig> calmodulin peptides representing apo and holo calmodulin under five labeling conditions , with up to six replicates for each condition. this required data extraction from  <dig> precursor ions and  <dig> fragment ions from  <dig> raw data files. table  <dig> summarizes the statistics and time required for extraction of ms- and ms/ms-level deuterium incorporation values for this project. ms-level processing of all peptides in all raw data files required  <dig>  minutes or  <dig>  seconds per peptide. this is about  <dig> times faster than the tubulin project described above, primarily because this experiment consisted of both ms- and ms/ms-level spectra whereas the tubulin test project contained only ms-level data. consequently, generating ms-based xics for the calmodulin test data set was much quicker than for the tubulin test data since the chromatograms have a reduced sampling rate to accommodate ms/ms spectral acquisition. indeed, we have found that xic generation is the most time-intensive task within our typical data processing workflows.

the same project file was re-processed using a ms/ms workflow. in this 'shotgun' data extraction approach, we attempted to extract data for all singly and doubly charged y- and b- fragment ions for all peptides, as well as the precursor ion in the ms/ms spectrum, which amounted to a total of  <dig> fragment ions. total time for executing the ms/ms workflow was  <dig>  minutes or  <dig>  seconds per fragment ion. both ms- and ms/ms data can be assessed and evaluated using the assessment and validation tool described above. additional file  <dig> displays the 'proteinstate_compare view' for assessing ms/ms spectra. the saved project file was approximately  <dig> mb in size. while extracting as much fragment ion data as possible is used here to demonstrate the capability of hydra to extract large quantities of ms/ms-level values, alternative data analysis strategies could include selective fragment monitoring.

CONCLUSIONS
hydra accommodates an efficient yet tailored approach to automation of deuteration data from complex sets of bottom-up h/dx-ms experiments. such automated extraction permits a high success rate when applied to larger protein systems, where a streamlined manual validation utility supports rapid identification and correction of instances where accurate data extraction fails. this automation extends to the deconvolution of the underlying distribution of deuteration states, a powerful tool for studying the underlying exchange process on a global level and supporting a semi-automated error-checking capacity. the design strategy applied to the development of hydra promotes easy incorporation of additional algorithms to improve facets of the workflow  or to simply adopt alternative strategies. finally, enabling the extraction of deuteration data from ms/ms spectra collected in a conventional data-dependent fashion will open up a proteomics-style approach to the collection of such data, which is expected to increase the range of application for this technique.

availability and requirements
project name: hydra

project home page: 

operating system: windows xp with sp <dig> or sp3; vista is not supported by analyst™ qs  <dig> . the analyst-free version is functional on vista.

programming language: microsoft c#.net

other requirements: microsoft .net framework  <dig> ;

license: free software

any restrictions to use by non-academics: none

abbreviations
ms: mass spectrometry; ms/ms: tandem mass spectrometry; m/z: mass-to-charge ratio; h/dx-ms: hydrogen/deuterium exchange mass spectrometry; xic: extracted ion chromatogram; cid: collisionally-induced dissociation; csv: comma separated values

competing interests
the authors declare that they have no competing interests.

authors' contributions
gs provided requirements, developed algorithms and some of the user interface, performed unit testing and wrote the manuscript. cjb led the project, designed the software architecture, designed and developed the user interfaces and edited the manuscript. bb and ad designed the software architecture and developed core software framework. ajp and mb collected data in support of this project and tested the software. ds initiated and directed the project, provided requirements, tested the software, edited and finalized the manuscript.

supplementary material
additional file 1
this section contains additional screenshots of various aspects of hydra functionality, including project setup, deuterium distribution detection and ms/ms-based data extraction.

click here for file

 acknowledgements
financial support for this study was provided by grants from the natural sciences and engineering research council  of canada. dcs gratefully acknowledges the support of the canada research chair program and the alberta heritage foundation for medical research .
