BACKGROUND
prior to cluster analysis or genetic network analysis it is customary, after initial quality screening, to remove genes considered to be substantively irrelevant from the set of genes to be analyzed. typically genes which are informally judged to exhibit insufficient variation across samples are deleted. one obvious advantage of this is dimension reduction; clustering algorithms run faster and genetic network analysis may be simplified if there are fewer genes than samples. another obvious advantage is clarity of interpretation: the biological meaning of a cluster or gene pathway is more easily discerned if the results of an analysis do not include irrelevant and distracting genes. we will demonstrate another ill effect of not filtering prior to analysis – bias in a cluster analysis of the data.

the accuracy and usefulness of a cluster analysis is strongly affected by the subset of genes to be analyzed, as determined by filtering the genes prior to the analysis. however, although much recent work has been devoted to the development of clustering methods, relatively little attention has been directed to the filtering step. this paper explores filtering in some depth and presents some new approaches. we establish the feasibility of data-based selection of genes, and its superiority to arbitrary thresholds.

RESULTS
the model
to investigate filtering we focus on the covariance structure of the data. cluster and genetic network analysis focuses on the relatedness of the expression patterns of the genes being studied. we represent this by the covariance matrix of the gene expressions, and assume that there are groups of genes that are correlated among themselves while being uncorrelated with the other groups. there is a final set of genes d whose members are uncorrelated with each other and all other genes. it is this group of genes that we term irrelevant and wish to remove from the analysis.

this model implies a block structure for the appropriately ordered covariance matrix Σ. suppose that n genes belong in the analysis and d genes are unrelated and should be deleted. then

   

where Σjj is a nj × nj within cluster covariance matrix, Δ is a d × d diagonal covariance matrix for the set d of irrelevant genes, and .

this model is an example of modularity, where a module is a part of an organism that is integrated with respect to a certain kind of process and relatively autonomous with respects to other parts of the organism. the modularity concept has gained popularity more-or-less simultaneously in molecular biology and systems biology, developmental biology and evolutionary biology, and cognitive psychology  <cit> . we assume that the within cluster covariance matrix Σjj arises from an independent module which is a biological gene network. we consider two simple network architectures as examples in this paper.

sims
a sim  consists of a set genes that are controlled by a single transcription factor  <cit> . there is considerable experimental evidence that sims occur frequently  <cit> . for example, consider a sim represented by the linear model for gene expression

   

   

where β >  <dig> and the ϵi are independent errors with mean  <dig> and variance  <dig>  the covariance of all pairs of genes in this system is nonzero. the covariation among the n <dig> network genes is driven by the hub y <dig> which codes the transcription factor. we assume that genes not included in the sim follow the model

   

where ϵj is an independent error with mean  <dig> and variance  <dig>  this will yield a covariance matrix of the form  with m =  <dig>  the correlation of two non-hub genes is β2/, and correlations with the hub are .

a causal chain
another simple network architecture we consider is a causal chain of genes specified by the first-order autoregressive process

   

we assume that the process is stationary, whence

   

the correlation of expression between adjacent genes in the chain is β. we can regard y <dig> as coding the transcription factor which initiates the chain. the expression of genes outside the causal chain is distributed jointly as iid n.

the need for filtering
to investigate the necessity of filtering prior to cluster analysis, suppose that the set d of irrelevant genes is known. we will compare two strategies: 1) preselection: filter out the set d and do a cluster analysis and 2) postselection: do the cluster analysis and then delete the set d from the clusters. the final set of genes is the same, but the second method includes the irrelevant genes in the analysis phase. a data set of  <dig> arrays was generated using a multivariate normal distribution with five gene clusters each consisting of  <dig> genes. within-cluster correlations of  <dig> , between cluster correlation of zero, and variances of  <dig> defined the covariance matrix. the set d consisted of  <dig> genes each of which was independent of all others. we did a k-means cluster analysis  of the genes for each of strategies 1) and 2) and compared the agreement of the respective gene clusters with the true grouping using the adjusted rand index  <cit> , which is a traditional criterion for assessment and comparison of different results provided by clustering algorithms. it is able to measure the quality of different partitions of a data set from a classification perspective, including partitions with different numbers of classes or clusters. the adjusted rand index can range from  <dig> to  <dig>  with  <dig> being perfect agreement. the data set was simulated  <dig> times and the average adjusted rand index computed.

the means of the adjusted rand index for strategy  <dig>  and for strategy  <dig>  were 90% and 76%, respectively. not deleting the irrelevant genes prior to cluster analysis introduces considerable bias. thus even if an astute biologist has no trouble discarding irrelevant genes when presented with the results of an unfiltered cluster analysis, the validity of the results will be compromised. if we specify a sixth cluster when analyzing the larger set of genes, in the hope of isolating the irrelevant genes, the mean adjusted rand index for strategy  <dig> rises to only 83%. thus even if we knew the true number of clusters and added an "over flow" cluster to the analysis, postselection is inferior and the analysis is biased.

the same picture emerges if we are clustering arrays. a data set was generated using  <dig> arrays divided into  <dig> groups of  <dig>   <dig> genes had mean  <dig>  for the first group of  <dig> arrays and mean  <dig> for the other arrays. another  <dig> genes had mean  <dig>  for the second group of  <dig> arrays and mean  <dig> for the other arrays, and so on for a total of  <dig> genes. thus each group of arrays has a unique gene expression profile. another set of  <dig> irrelevant genes was included which had mean zero for all the arrays. the genes had a multivariate normal distribution with the specified mean and the identity covariance matrix. we did a k-means cluster analysis of the arrays for each of strategies  <dig> and  <dig> and compared the agreement of the respective array clusters with the true grouping using the adjusted rand index. this was replicated  <dig> times and the average adjusted rand index computed.

the means of the adjusted rand index for strategy  <dig> and for strategy  <dig> were 79% and 62%, respectively. again, not deleting the irrelevant genes prior to cluster analysis of the arrays introduces considerable bias. extraneous genes can also degrade more exploratory methods. a common exploratory method is to portray the arrays in two dimensions by projecting them onto the first two principal components. figure  <dig> shows the principal component plots for arrays generated according to the preselection and postselection strategies already described. there were three groups of  <dig> arrays, each defined by a unique set of  <dig> genes over-expressed in that cluster. group  <dig> was over-expressed for  <dig> genes and mean  <dig> otherwise. group  <dig> was over-expressed for a different  <dig> genes and mean  <dig> otherwise, and likewise for group  <dig>  another  <dig> extraneous genes had mean  <dig> over all the arrays. for postselection the principal components were computed using all genes and then the irrelevant genes were deleted from the principal components plot. the preselection strategy computed the principal components using only the relevant genes. figure  <dig> gives the principal component plots.

filtering improves the informativeness of the principal component plot dramatically. the existence of bias in sample principal components in the presence of noise variables has been shown theoretically by  <cit> . the preceding has demonstrated that filtering irrelevant genes before analysis is desirable. we next investigate how this can be done.

motivation for proposed filtering methods
it is common to filter genes with small variance prior to clustering. the rationale is that genes which do not vary across samples contribute little information or may not be expressed, and genes which do not vary cannot covary. in this section we show that the pattern of covariance can be much more informative for filtering irrelevant genes. we will also demonstrate this later by simulation.

consider the hub model given by equations  – . the variances of the genes in this network are

  

note that the hub gene y <dig> which drives the underlying gene network has variance σ <dig>  the same as the irrelevant genes . clearly y <dig> should be included with the network genes in a cluster or inferred gene network, but filtering by a variance criterion would lump y <dig> with the irrelevant genes.

now suppose that instead of filtering based on only the diagonal element of the covariance matrix, we associate with gene i the sum of the absolute values of the elements in row i of Σ, i.e. the summed absolute covariance with itself and the other genes. this measure is

  

clearly the summed absolute covariance has more potential for filtering in the context of this network architecture. the measure differs more for the network versus non-network genes, and the hub y <dig> is now distinguished. we will refer to filtering based on the absolute row sums as covariance-based, and describe filtering based on small gene variance as variance-based.

to compare the two approaches, we generated data from a sim of  <dig> genes, along with another  <dig> genes which were dormant in the process being studied. the regression coefficient was chosen so that the genes in the network had a correlation of . <dig> with the hub. there were  <dig> arrays. the left panel of figure  <dig> shows the variances of the genes and the right panel shows the sum of absolute covariances. the dark points are the network genes. we observe that the network genes are more clearly distinguished using the absolute covariances.

next we consider the causal chain architecture given by  and . for this stationary first-order autoregressive model each network variable has variance 1/ >  <dig> and the extraneous variables have variance  <dig>  so the variance distinguishes the network genes. the sum of the absolute covariances for the ith network gene is

  

so this measure distinguishes the network genes more clearly that the variance.

the preceding results lead us to consider new filtering criteria which include off-diagonal elements of the covariance or correlation matrix.

filtering criteria
the first two new criteria we define are based on the covariance or the correlation.

• 

• 

where ∑ = {σij} and r = {rij} are the covariance and correlation matrices, respectively.

the other two measures are motivated by the structure displayed in . the elements in a row of ∑ corresponding to a network variable are mixture of mean zero and mean nonzero random variables, indicating more variability than found in a row of non-network variables. we thus define two measures which exploit this property.

• varcovi = var{|σij|; j ≠ i}

• varcori = var{|rij|; j ≠ i}

where for a vector x, var{x} is the sample variance of the sample x.

we will refer to filtering using only the variance as var.

to use the filtering criteria to identify the relevant genes, in this paper we use k-means clustering with k =  <dig>  <cit>  to form two groups of genes based on their measured criterion value. the cluster of genes with the highest average criterion value are then taken to be relevant for cluster of network analysis.

simulations
to compare the filtering criteria, we simulated expression data using two models. both models consisted of  <dig> independent equally-sized modules and a set of extraneous genes. there were  <dig> genes in total, and we varied the percentage of extraneous genes from  <dig> per cent to  <dig> per cent, in increments of  <dig> per cent. for example, with  <dig> per cent extraneous genes,  <dig> genes were extraneous and there were  <dig> modules consisting of  <dig> genes each. for  <dig> per cent, there were  <dig> extraneous genes and each module consisted of  <dig> genes.

model  <dig> – sims: the modules are sims. within a sim, the correlation between non-hub genes was . <dig> 

model  <dig> – causal chains: the modules are causal chains. the correlation between adjacent genes in the chain was . <dig>  so that a gene accounted for 49% of the variance of its successor in the chain.

each model was generated  <dig> times, and the sensitivity and the positive predictive value was averaged over the  <dig> simulations for each of the criteria – variance, sumcov, sumcor, varcov, and varcor. the maximum possible standard deviation for any of the estimates was . <dig> 

for the model  <dig> simulation of sims, figure  <dig> shows the average sensitivity and average positive predictive value for each of the  <dig> criteria.

sumcor is the most sensitive measure when the percentage of noise genes is 80% or less, but is dominated by sumcov for higher percentages, and drops precipitously at 95% to be the worst of the measures. sumcov is more sensitive than varcor, varcov, var, with the marginal exception of varcov at 95%. in particular it is more sensitive than var throughout the range of percentages. the positive predictive value of all the methods deteriorates for high noise proportions, but var is the worst. the ranking of the methods with respect to positive predictive value is varcor, varcov, sumcov, sumcor, var. we conclude that var is not very informative for the sim model, and sumcov and sumcor are good overall choices.

as expected, var does very poorly at finding hub genes. the other methods are ranked as sumcor and varcor, varcov, sumcov, var. both sumcov and varcov include aspects of var which is uninformative about hubs, and so probably pay a penalty for that reason.

for the model  <dig> simulation of causal chains, figure  <dig> shows the average sensitivity and average positive predictive value for each of the  <dig> criteria.

var does better for causal chains than for sims. this is because the off-diagonal covariances decay rapidly with increasing distance from the diagonal and have relatively little impact, so var captures most of the information. sumcov and varcov incorporate aspects of var, and have much better sensitivity and positive predictive value than sumcor and varcor which ignore the diagonal elements of the covariance matrix. considering both sensitivity and positive predictive value, sumcov and varcov are competitive with var. sumcov has the advantage of also doing well for sims.

in practice, in the absence of knowledge of the underlying network architecture sumcov is a good overall choice, and is preferred to var since it captures additional structure. sumcor will perform well when var performs poorly. for example, when disparity of gene variances largely reflects experimental inconsistencies sumcor will benefit from not being a function of the variance , while sumcov will be degraded. when the variance is informative, sumcov will include that information and also capture block structure, so it performs well for both sims and causal chains.

a graphical method
as an alternative to the partitioning of the filtering criterion by k-means partitioning, we propose a graphical method. this is a q-q plot of the observed filtering criterion versus the criterion values for a null matrix of independent n random variables. we average  <dig> simulated null matrices to get a stable estimated of the null distribution. to use the plot we inspect it for a point of inflection corresponding to a slope change, and take that point as the threshold for the filtering criterion.

to demonstrate this we simulated a data set generated according to the sim model used in the previous section.  <dig> of the  <dig> genes were network genes. figure  <dig> shows the q-q plots for the criterions var, sumcov, and sumcor.

the data for figure  <dig> is similarly generated, using the causal chain model described in the previous section. the height of the plot is the value of the criterion, specified by the left vertical axis. the right vertical axis gives the number of genes with values greater than the corresponding height of the left axis. thus one can read a cutoff value from the left axis and the consequent number of genes obtained on the right axis. in figure  <dig> sumcov and sumcor show a clear inflection in their q-q plots. in both cases  <dig> network genes is plausible from the plot. 2-means partitioning estimates  <dig> network genes based on sumcov and  <dig> genes based on sumcor. the plot for var shows only a mild bend and offers little information as to a plausible cutoff. this is in agreement with the simulation results shown in figure  <dig>  where var did not do well for sims. 2-means partitioning of var suggests  <dig> network genes.

in figure  <dig> both the var and sumcov show a clear inflection in their q-q plots. in both cases  <dig> network genes is plausible from the plot. 2-means partitioning estimates  <dig> network genes based on sumcov and  <dig> genes based on var. the plot for sumcor is straight and offers no information as to a plausible cutoff. this is in agreement with the simulation results shown in figure  <dig>  where sumcor performed poorly for the causal chain model. 2-means partitioning of sumcor suggests  <dig> network genes.

analysis of e. coli and s. cerevisiae regulatory network data
the modular network models we have simulated certainly do not match the complexity of real microarray data. however, with real data the true underlying model is unknown so it is impossible to know which genes selected are true positives or misclassified irrelevant genes. to satisfy the criteria of realism and known properties, we generated datasets using syntren  <cit> , a generator of synthetic gene expression data. this approach allows a quantitative assessment of the accuracy of the methods applied. the syntren generator generates a network topology by selecting subnetworks from the well characterized e. coli or s. cerevisiae regulatory networks. then transition functions and their parameters are assigned to the edges in the network. eventually, mrna expression levels for the genes in the network are obtained by simulating equations based on michaelis-menten and hill kinetics under different conditions. after the addition of noise, microarray gene expression measurements are produced.

we produced two synthetic expression datasets, one corresponding to the e. coli network topology and one for s. cerevisiae. in each dataset there were  <dig> network genes and  <dig> background genes. the  <dig> background genes have an underlying network structure, but are not perturbed and so propagate only error. this is a more realistic model for inactive genes than we simulated previously. we used the cluster addition option of syntren and set all parameters to their default values. we normalized the expression data produced using vsn  <cit> .

sumcov partitioned well for both analyses, and had the most interpretable q-q plot with a clear inflection in the vicinity of the correct number of genes. var partitioned well for s. cerevisiae, suggesting that the connectivity may be less than for e. coli. the q-q plots for var were not very useful, which is a serious disadvantage for this metric. sumcor did not partition well for either dataset, but the q-q plots for this metric were very informative.

CONCLUSIONS
this paper presents objective methods for evaluating and choosing metrics and thresholds for filtering genes prior to cluster and network analysis. we introduced a model for genetic data with modular network structure and a substantial proportion of irrelevant "noise" genes. we considered two variations, sims and causal chains. the examination of these models shows that the common practice of filtering out genes with low variance can be justified for some models, and introduces alternatives which are superior for other models and conditions.

real biological phenomena are certainly more complex than the simple models we considered, and probably represent a mixture of complex architectures. we have shown that using var can miss hubs, so that metric may be considered to be biased against hubs. variables with higher connectivity will be more easily detected using sumcov and sumcor. sims have a stronger block-diagonal structure, but the connectivity is still rather limited and more complex structures may be expected to have larger off-diagonal entries. in general, variables with higher connectivity will be more easily selected by the new metrics sumcov and sumcor. an advantage of sumcov is the incorporation of both diagonal and off-diagonal elements of the covariance matrix. however, if the diagonal elements reflect experimental inconsistency this becomes a disadvantage. we advocate using our graphical approach to chose the most informative measure.

we adopted 2-group clustering algorithms to classify genes because these are familiar methods for identifying the components of a mixture of two distributions. however, we don't claim any inherent advantage for this approach. further investigation of mixture methods in the context of varying types of data could be done, but the intent of this paper is to point out the feasibility of data-based selection of genes, and its superiority to arbitrary thresholds. the analysis of the e. coli and s. cerevisiae shows that in a realistic setting robustness is an important consideration when selecting a partitioning method.

although we have restricted our discussion to measures based on the covariance matrix, the ideas are much more general. the covariance could be replaced by any similarity measure and analogous measures computed. self-similarity would be substituted for var, row sums of the similarity matrix for sumcov, and row sums of the off-diagonal similarities  for sumcor. the q-q plot could again be used to judge relative efficacy.

methods have been developed recently which simultaneously cluster and perform variable selection  <cit> . these methods are restricted to model-based clustering and will not apply to other clustering algorithms, varied definitions of gene similarity, or other network inference methods. an advantage of our method is that it is model-free and can be used in conjunction with any clustering algorithm or similarity matrix. we recommend that other information relevant to filtering be employed before focusing on the covariance matrix. for example, conventionally genes considered to be unexpressed based on the small magnitude of their gene expression measurements are deleted, and such screening should be performed prior to applying the methods of this paper.

authors' contributions
dt, ep and jb contributed equally to methods development. ep and dt performed the computer simulations. dt analyzed the example data sets. all authors read and approved the final manuscript.

