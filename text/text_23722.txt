BACKGROUND
the process of linking genes to disease phenotypes is rapidly gaining momentum since the first disease-causing gene was identified  <dig> years ago  <cit> . alternative approaches adopted in the past to identify disease genes are the candidate gene approach, where likely suspects are prioritised and screened on a genome-wide basis; and linkage analysis where specific loci are determined systematically using family studies. the two approaches have been synthesized into a pipeline by completion of the human genome project; and further enabled by the increased availability of high-throughput experimental data and the development of sophisticated bioinformatics tools. in addition there have been efforts in the bioinformatics community to systematize and automate candidate gene prediction. automated prediction systems provide geneticists with a reduced list of genes estimated to have a high probability of involvement in the disease phenotype by sifting through hundreds to thousands of genes. ultimately, these tools aim to give the researcher the best possible guidance in honing in on the gene culprits for further biological confirmation. since their introduction in the early 2000s, the predictive powers of automated candidate gene prediction systems have improved, largely due to increases in biological systems knowledge and more effective algorithms.

candidate gene prediction systems vary in their approach and the data sources they draw on in generating predictions. these are summarised in figure  <dig> and table  <dig>  comparing the performance of these systems can be difficult because of the use of custom benchmark test sets by individual groups. typically, benchmarking data is derived from genotype-phenotype information from the online mendelian inheritance in man  database  <cit> , but groups have used varying subsets of diseases. several groups have tried to use standard benchmark sets  <cit> , but these efforts have been limited. in addition, it is difficult to predict whether benchmarks which predominately contain data on well characterised diseases with mendelian transmission patterns  resulting from mutations in single genes  <cit>  will be effective in predicting genes involved in less well characterised diseases, or in complex diseases.

♠ assessed here, ◇ webserver.

a recent effort by tiffin and colleagues  <cit>  to identify candidate disease genes for the complex disease type ii diabetes  and the related obesity trait predicted  <dig> genes in previously implicated chromosomal regions. the study also allowed a limited comparison of seven candidate gene prediction systems. since that time two genome-wide association studies  on t2d undertaken by the wellcome trust case control consortium  and the genetics replication and meta-analysis consortium  have been published  <cit> . gwas are a powerful tool for identifying genetic variants linked to complex diseases because they are more sensitive than linkage studies to small to moderate effect size contributions from polygenic and oligogenic diseases. the data from these gwas allow the assessment of the predictions made by tiffin et al., as well as evaluation of the effectiveness of predictions made by the individual automated candidate gene prediction systems used in their study and our system, gentrepid  <cit> . we assessed the candidate gene predictions systems' ability to select robustly supported genes from the gwas and used them to filter noisy data from statistically less well supported genes to select favoured candidates.

RESULTS
predictions
all methods were given the starting set of  <dig> genes mapped to chromosomal intervals implicated in t2d as assessed by tiffin et al., except for pocus which was run against a search space of  <dig> genes. the pocus method was confined to the smaller search space because "poorly defined susceptibility regions or regions with questionable association with the disease are obscured by background noise"  <cit> . the number of candidate gene predictions made by the eight methods varied from two to  <dig>  pocus generated the smallest number of candidates but neither of the two predictions matched genes in either the highly significant  or medium-to-highly significant  data sets. other candidate gene prediction methods made considerably more predictions. the largest numbers of predictions were made by g2d  and evoc . these comprise almost one third and one quarter of the search space respectively. thus neither of these methods prune the search space particularly well. excluding pocus, the least number of predictions was made by gentrepid comprising  <dig> genes in known-disease-gene mode.

accuracy of predictions
to assess the accuracy of the predictions, all eight systems were compared with genes found in previously-implicated intervals strongly linked to t2d by the gwas. figure  <dig> shows the comparative performance of seven of these methods in selecting the  <dig> genes in the hs gwa data set. several metrics were calculated to assess accuracy. no metrics were calculated for pocus as neither of its two predictions matched genes in either the hs or mhwd data sets.

the enrichment ratio is a general measure of the system's ability to accurately prune the search space. enrichment ratios ranged from  <dig> to  <dig> for the seven remaining prediction systems. the highest enrichments ratios were obtained by gentrepid and geneseeker. these results were robust when the upper and lower  95% confidence interval limits were taken into account. the lowest enrichment ratios were associated with the machine learning methods. this is not surprising, as the classifiers are trained to distinguish "disease genes" from "non-disease genes" and are ignorant of any concept of phenotype. the specificity of a system measures its ability to reject genes not associated with the phenotype. specificity scores among all seven methods ranged from  <dig>  to  <dig> , with a median of  <dig> . as a group, the machine learning methods were poorer at rejection. g2d also performed poorly on this metric, but this result is slightly misleading because it does not take into account g2d's prioritization method which will be discussed later.

the sensitivity is a measure of a system's ability to find the disease genes in the search space. a caveat here is not all of the gwa predictions are currently confirmed. g2d is by far the standout performer in sensitivity, with evoc ranked second. however, as can be seen from the other metrics, this result is obtained at the expense of specificity for both systems. gentrepid's sensitivity is on par with most of the machine learning methods but with higher specificity. the high specificity reflects the high quality of the data in the underlying databases. the lower sensitivity is due to incompleteness of these databases with respect to all human genes.

the results shown for gentrepid in figure  <dig> are for the known-disease-gene mode. in ab initio mode, gentrepid's cps method identified  <dig> pathways containing a total of  <dig> candidate gene predictions. this resulted in enrichment ratios of  <dig>  and  <dig>  when the hs and mhwd full gene sets were considered .

abbreviations in table: er – enrichment ratio, l95% – lower 95% confidence limit, u95% – upper 95% confidence limit, s – sensitivity

in ab initio mode, the cmp method generated  <dig> predictions by limiting the selection to the top 10% most probable genes. this resulted in correct prediction of one gene from the hs set and five from the mhwd set, yielding a enrichment ratio of  <dig>  when applied to the hs and  <dig>  for the mhwd gene data sets. 

it is also interesting to note the effect of lack of annotation on these results. only five of  <dig> genes in the hs dataset, and  <dig> of  <dig> genes in the mhwd set contained kegg or biocarta pathway annotations.when we included only genes containing pathway information from the gene datasets  we observed enrichment ratios of  <dig>  against the hs and  <dig>  against the mhwd pathway-annotated sets. sensitivities also improved by a factor of  <dig> for the hs dataset. by extrapolation, if all genes were pathway annotated, we could expect approximately two- to three-fold improvement in enrichment and sensitivity scores.

prioritization
although the metrics discussed provide useful measures of a candidate gene prediction system's performance, another criterion of importance to geneticists is the system's ability to prioritize predictions. although several methods claim the ability to prioritize , only g2d provided prioritized predictions in tiffin et al.  <cit> . hence only g2d and gentrepid will be discussed here. because gentrepid only made  <dig> predictions in toto, we took the top  <dig> predictions made by g2d and recalculated the enrichment ratio, sensitivity and specificity for this restricted set of favoured predictions. er and specificity significantly improved to  <dig>  and  <dig>  such that g2d surpassed gentrepid's gross er and almost equalled gentrepid in specificity. the improvement in these two metrics came at the expense of sensitivity which was reduced to  <dig> , but the g2d system still managed to maintain its lead on this metric.

in g2d's prioritization system, a go-metric is calculated for each gene in the search space based on how well its go profile fits the go profile of the disease genes inferred from mesh terms. an r-score is calculated for each gene by normalizing against the number of genes in the genome with better go-metrics for the phenotype. genes with r-scores closer to zero are better fits to the phenotype.

gentrepid cps ranks genes by the number of loci in the search space involved in a particular pathway. in ab initio mode, of the  <dig> intervals searched, the top pathway, focal adhesion, was represented in  <dig> of these. all five of the hs dataset genes were represented by pathways found in at least eight intervals. pathways implicated in at least eight intervals constituted the top 40% of the  <dig> pathways containing  <dig> candidates. in these pathways, gentrepid identified all five pathway annotated genes from the hs dataset, and  <dig> of the  <dig> pathway annotated genes from the mhwd gene data set. other figures for cmp are given in table  <dig> 

cmp ab initio looks for protein domains enriched in the search space compared to the genome by taking a census of domains in the search space and the genome. two expectation values are calculated to estimate the frequency of occurrence of genes with domains of interest based on a random combination of these domains ea and the rarest domain eb  <cit> . figure  <dig> shows the data ranked on a χ <dig> test based on ea was most effective in prioritizing the hs data. this reflects our experience of phenotypes with genotypes encoded by multi-domain proteins, as would be expected for diseases associated with signaling. for metabolic diseases associated with single-domain proteins, eb may be a better measure.

although the g2d prioritization system appears more sensitive than the coarse-grained prioritization of gentrepid, the performance of both systems was roughly equivalent against the hs set. both systems were moderately successful in prioritizing the hs data. for example, of the seven genes in the hs dataset predicted by g2d, four were ranked in the top 15% by g2d's prioritization method . significant work needs to be done to improve the prioritization schemes of both g2d and gentrepid. 

finally, we used the candidate gene predictions systems to filter the less statistically-well-supported mhwd data set : effectively adding more power to the gwa study. prioritized predictions are the unbolded genes in figure  <dig>  additional unprioritized predictions made for the mhwd dataset using the other candidate predictions systems are given as supplementary data in additional file  <dig> 

discussion
candidate disease gene prediction is a rapidly moving area of bioinformatics research with the potential to deliver great benefits to human health. by assisting geneticists to use existing biological information to investigate disease loci obtained by linkage analysis and association studies, disease genes can be identified more rapidly. the need for good applications in the area of candidate gene prediction is becoming increasing important as the proliferation of snp-based association studies produces valuable genetic information in need of analysis.

the biggest problem facing candidate gene prediction today is the accuracy and completeness of the underlying databases. failure to make a prediction is mostly due to incomplete data coverage. for example, 65% of human proteins have go terms but only 25% of these are manually annotated. systems drawing on go terms like g2d are potentially able to make predictions for 65% of genes but only around one third of these are likely to be accurate. systems biology methods like gentrepid cps are reliant on pathway and protein-protein interaction data. one of the databases cps draws on is ophid  <cit> , one of the most complete protein-protein interaction datasets, containing over  <dig>  <dig> interactions. however these  <dig>  interactions are estimated to be only 13% of the complete human interactome  <cit> . completeness of the underlying data clearly impacts the sensitivity of the gentrepid cps method. as time goes on this constraint will ease as these databases are further populated. in the meantime, we have shown that the use of independent biological data to make complementary candidate gene predictions is one way to ameliorate the problem of incomplete data coverage   <cit> .

in addition to the predictions made by the individual candidate gene prediction systems in tiffin et al., a set of nine "winners" were chosen using a consensus approach  <cit> . these nine candidate genes were independently predicted by six of the seven prediction systems studied. a larger consensus set, chosen by five of the seven methods, contained  <dig> genes  <cit> . none of the genes in either of these consensus lists matched any of the genes in the hs and mhwd gene sets. even if we compile a third tier of consensus genes from any four of the seven methods  only one gene  fell within the hs data set and only three genes  matched the mhwd data set. clearly the consensus approach is not working and it is easy to see why when the underlying databases are considered . candidate gene prediction systems that use an independent data set, not drawn upon by most of the other methods, will be penalized. possibly the only benefit of a consensus approach is to give the user a false sense of accuracy when confronted with noisy data.

clearly much work still remains to improve the sensitivity and specificity of candidate gene prediction methods but some general conclusions are possible. machine learning methods were not as effective as other methods. most of the machine learning approaches do not use phenotype information and are based on the concept that the genome consists of a bipartite distribution of genes: those which cause diseases, and those that do not. the evidence supporting this assumption is limited  <cit> . we believe the concept that there is a difference between "disease genes" and "nondisease genes" is intrinsically flawed and no such boolean classification exists. we hypothesize that the ability of these methods to predict disease genes in test sets is based on selection effects in the data: possibly rare, highly penetrant monogenic diseases, such as those involved in metabolic syndromes, are over-represented among known disease genes because they have been easier targets to identify. although these systems were not as effective as the other candidate gene prediction systems, their performance was not greatly different. however, we believe that unlike systems which attempt to map genotype to phenotype, machine learning systems based on the disease gene/non-disease gene concept will not improve as more biological data becomes available.

CONCLUSIONS
candidate gene prediction systems have typically been benchmarked on well characterized oligogenic phenotypes. geneseeker  <cit>  produced a 10-fold enrichment using a data set consisting of eight diseases. gentrepid's combined methods  <cit>  produced an enrichment ratio of  <dig> when  <dig> diseases with a total of  <dig> known disease genes were used. for  <dig> diseases with  <dig> genes, pocus  <cit>  reported enrichment ratios between  <dig> to 42-fold, depending on the size of the intervals in the search space. the prioritizer  <cit>  method yielded a  <dig> -fold enrichment using a data set consisting of  <dig> heritable disorders. in summary, enrichment ratios of  <dig> to  <dig> have been reported in benchmarks, but a substantial part of the data used for these studies has been limited to oligogenic phenotypes, where several different genes may cause the disease, but a single mutation in each case or family has a large effect.

some doubts have been raised about the ability of systems to predict candidates for complex polygenic diseases such as t2d where multiple genes interact to create a permissive gene pool for disease genesis. the candidate gene prediction systems did prune the genome in favour of moderately to highly significant snps identified by the gwas under semi-blind testing on a complex polygenic disease. enrichment ratios calculated in this study suggest that most of the oligogenic benchmarks have been reasonably good predictors of system performance.

