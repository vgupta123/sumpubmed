BACKGROUND
reconstruction of biological networks from data has become important in modern analysis of large data sets in genomics or proteomics. the aim is to infer pairwise regulations or influences of network nodes, such as genes or proteins, describing the system as a graph structure. with this graphical representation, the functional characteristics of a biological system can be visualised in a comprehensive and informative way. for this purpose, many approaches have been suggested in the past, including boolean or probabilistic boolean networks, bayesian or dynamic bayesian networks  or learning with differential equation systems and many more  <cit> . these methods rely on the measurement of network components, either under several experimental conditions or at different time points. the simultaneous measurement of time courses combined with different experimental conditions or even directed perturbation of components becomes an increasingly important way of characterising biological systems  <cit> . corresponding modelling approaches try to describe the responses of model systems after external perturbation  <cit> . recently, we proposed a framework that searches for optimal network structures by modelling the signal flow in a cell from an external stimulus to the downstream components and we showed how parts of a literature based reference network could be reconstructed  <cit> . the method is now implemented in the r-package 'ddepn' which is available in the 'comprehensive r archive network' .

the purpose of this document is to give a comprehensive description of the package and its capabilities. besides the original approach for network inference, three components are added to the package. first, as alternative to the genetic algorithm  presented in our previous work, a metropolis hastings markov chain monte carlo  sampling scheme is set up. this approach is based on a publication of werhli et al.  <cit> , but extended by the possibility to sample two types of edges directly . hence, the package contains an optimisation algorithm  that is designed for converging to an optimal network, as well as the mcmc algorithm for true sampling of the space of possible network structures. second, a prior probability model for the network structure is adapted from fröhlich et al.  <cit> , that can penalise differences of inferred edges to prior confidences of these edges. again, we extended the previous model to include the possibility to model different edge types. third, an alternative prior model is provided that models the scale-free characteristics of inferred networks, i.e. it tries to reconstruct networks with node degrees that follow a power law distribution. this approach was introduced before  <cit> . we describe how prior parameters can be adjusted to guide the reconstruction to be more or less close to the given reference and how reconstruction performance is affected by the prior parameter settings. finally, advantages and disadvantages of both the ga and mcmc methods are discussed and a real data example is given that highlights how the prior knowledge inclusion is improving the outcome of the inference process.

implementation
the following sections provide a description of the different methods included in the package. the first section 'network inference types' describes the network inference approaches. a short overview on the original method based on a ga is given in the first subsection 'genetic algorithm'. in section 'inhibmcmc' we present our novel approach for markov chain monte carlo sampling of network structures. the next section 'prior knowledge incorporation' includes the two prior models for the inference. subsection 'laplace prior' introduces our extension to the prior model of fröhlich et al.  <cit> , subsection 'scale-free prior' describes the implementation of the alternative prior model of kamimura et al.  <cit> .

in general, the networks to be inferred are encoded as directed  graphs. let v = {vi : i ∈  <dig> ... n} be the set of nodes representing the network components  and Φ = v × v → { <dig>   <dig>  -1} an adjacency matrix defining a network. each edge in Φ is defined as pair of nodes {ϕij : i, j ∈  <dig> ... n }, where  <dig> means no edge,  <dig> activation and - <dig> inhibition between two nodes. the networks are inferred using a data matrix d = {ditr : i ∈  <dig> .. n, t ∈  <dig> ... t, r ∈  <dig> ... r} holding the time-resolved data of n proteins in t time points, measured in r replicates each.

network inference types
genetic algorithm
in principle, a population of candidate networks is 'evolved' over a large number of iterations, starting with either a population of randomly drawn networks or by providing an initial population of networks. one can thus extract networks based on biological prior knowledge and feed them into the algorithm as a starting point for the network search. in each iteration of the algorithm, first up to a fraction  <dig> - q ∈  of all candidate networks is selected that has a score larger than a given quantile of the scores of all current networks . this is done to keep the best scoring networks in the population. second, crossover is performed between pairs within a fraction q of the networks to allow exchange of parts of the networks. third, mutation of a fraction of m ∈  edges in each network is performed, changing an edge to one of the remaining states, e.g. if an activation edge is present, it can change to an inhibition or to no edge at the current position. this increases the chances to evade local optima and explore different parts of the search space, even if the local move is reducing the score. the details of the methods are described in our previous publication  <cit> . for our purposes, we set the parameters to q =  <dig>  and m =  <dig>  and recommend to use a population size of at least  <dig> networks to ensure broad sampling of the network search space.

inhibmcmc: markov chain monte carlo for two edge types
as an alternative to the ga, an mcmc structure learning approach to sample the space of possible networks is included. the sampler is based on a previous approach by werhli et al.  <cit> . because we allow to include two edge types for activation and inhibition in our networks, we change the mcmc sampler in the following way. adding an edge is replaced by two moves, one for adding an activation and one for adding an inhibition. further, we include a move for switching the edge type from activation to inhibition  as well as one type to simultaneously revert and change the type of an edge. this leaves us with six move types: add activation, add inhibition, delete, revert, switch type and revswitch. inclusion of the novel move types is done to ensure that any edge can be changed to any other edge  in exactly one step. using these move operations, for any given network structure all other structures can be constructed in a finite series of moves. consider table  <dig> for an illustration of the edge transitions.

possible edge transitions and the corresponding move to perform the transition. an edge is changed from the type shown in the first column to the type shown in the first row by the move shown in the corresponding table field. the following moves are possible: adda: add activation, addi: add inhibition, del: delete, rev: revert, st: switch type, rst: revert and switch type. the symbols for the edges are →: activation, ⊣: inhibition, ∅: no edge.

now the essential relationships for the mcmc sampling procedure are repeated . the proposal probability of any network Φk+ <dig> that differs from a network Φk by only one edge is:   

where n is the neighbourhood of a network k, i.e. all network structures that can be reached by a single edge operation. a move is accepted with acceptance probability      

where the posterior distribution is   

 is a constant normalising factor that can be neglected for model comparison purposes. p represents the prior probability distribution for a network structure Φk, which is described in the next section. the posterior p is the product of the prior p and the likelihood of the data given the network, defined in bender et. al.  <cit>  as:   

where d is the n × t × r data-matrix and  the optimized system state matrix, holding the active and passive states for each protein at each time. , ∀i ∈  <dig> ... n is the parameter matrix obtained during the hmm procedure from bender et. al.  <cit> , containing the parameter estimates for the gaussian distributions for the active  and passive states . details on parameter estimation as well as the system state matrix computation can be found in our previous publication  <cit> .

we end this section by describing the determination of the neighbourhood  of a network. there are three cases to be considered to determine the cardinality of the neighbourhood of a network Φk:

i) addactivation/addinhibition  

ii) deletion/switchtype  

iii) revert/revswitch  

depending on the type of the move, the corresponding proposal probabilities q can be calculated. note that for metropolis-hastings mcmc structure sampling described here, the proposal distribution q can be non-symmetric, i.e. q ≢ q is allowed for any pair of networks Φk and Φk+ <dig>  to show that q is not symmetric, we describe a counterexample for two simple networks with two nodes a and b :  

Φ <dig> is reached by adding the edge a → b, and going back from Φ <dig> to Φ <dig> is done by deleting this edge. the number of neighbours of the first network is calculated as follows. according to i),  <dig> neighbouring networks can be reached by adding a single activation edge, as well as  <dig> networks by adding a single inhibition. following ii) and iii), there are no edges that could be deleted, reverted or whose type could be switched. in total, there are  <dig> neighbouring networks to Φ <dig>  analogous to that, for the second network there is one reachable neighbour by adding an activation and one by adding an inhibition, one edge can be deleted, and one reverted, and for one edge a type switch as well as a reverse-type-switch is possible, totalling in a neighbourhood of  <dig> networks for network Φ <dig>  thus, the proposal distribution is not symmetric for all possible networks.

prior knowledge incorporation
laplace prior
based on the structure prior of fröhlich et al.  <cit> , a prior model is proposed that also incorporates different types of edges and a more fine-grained control of the prior influence. networks are encoded as mentioned above. we need a matrix b = v × v →  containing prior confidences for each edge, which can be obtained in various ways. here, one example is given how to derive b using the kegg database  <cit> . the approach is similar to the one described by werhli et al.  <cit> , but preserves the information on the type of the edges.

first, we download the signalling and disease related networks from kegg . the number of occurrences of each node pair vi and vj in all pathways is counted and recorded in a matrix m = v × v → ℕ. further, it is counted how often each node pair is connected via an activation or inhibition edge in all reference networks and the corresponding numbers are recorded in two matrices mact and minh, both with the same dimensions as m. note that for pairs of nodes that do not occur in any reference network , we set the confidence score to  <dig>  the prior confidence matrix b is thus defined as:  

assuming that the type of each edge is consistent in all reference networks. this leaves positive confidences for activation edges and negative confidences for inhibiting edges. the larger the absolute value of the confidence score, the stronger is the belief in the presence of this edge.

no matter how b was derived, to calculate the prior belief for a network structure Φ we assume all edge probabilities to be independent:   

we calculate the difference between an edge in the inferred network Φ and the prior b and include a weight exponent γ ∈ ℝ+to obtain the weighted difference term:   

the prior belief for an edge in the network is then modelled as   

which penalises large differences from the network structure Φ to the prior belief b.

now we derive upper and lower bounds for the prior influence, in the general case for two edge types. let λ, γ ∈ ℝ+. if the edge type information is used, all differences Δij lie in the interval , because ϕij ∈ { <dig> , -1} and bij ∈ . without edge type information, we ignore the signs in both Φ and b, leading to Δij ∈ , because ϕij ∈ { <dig>  1} and bij ∈ . because the bounds for p  will not change in either case, only the case for including edge type information is shown in the following.

for the moment, let γ =  <dig> and consider the limits of the exponential term in equation 8:  

this means that   

since Δij ≥  <dig>  ∀γ ∈ ℝ+, the bounds are valid for γ ∈ ℝ+, too. figure  <dig> shows on the left side the prior curve for equation  <dig> when λ ∈ { <dig> ,  <dig> , 1} and γ =  <dig>  as it can be seen there, with increasing λ the  prior probability curve flattens out, giving unbiased probabilities for each value of Δij. the maximum value is bounded by . on the right side of figure  <dig> we set λ =  <dig>  and increase γ ∈ { <dig> ,  <dig>   <dig>   <dig>  50}. this results in a broader prior probability plateau at the upper bound for small differences Δij, suggesting that γ can be used to control how strong small differences of inferred edges to their prior confidence should be penalised. extending the plateau of high prior probability will lead to high prior weights for edges with absolute confidence values not equal to  <dig>  and additionally will leave a strong penalisation of larger differences.

the prior parameter λ should be adjusted in a way that it exceeds the changes introduced by the likelihood, if strong bias towards prior knowledge is desired during inference. for inhibmcmc, we suggest to inspect the likelihood and prior ratios for various settings of λ and choose λ in a way that both ratios are approximately equal . to do this, transform equation  <dig> to log scale:  

now consider the prior and likelihood ratios on log scale, i.e. the differences of the log priors and log likelihoods. to make the prior capable of having substantial influence on the inference, the log prior differences should be on similar scale as the log likelihood differences. for instance, if the log likelihood differences are on the scale of  <dig>  set λ = 10- <dig> and γ =  <dig>  such that  will be in the range of the thousands. the first part of the prior  - log) cancels out in the difference and does not have an influence. this means, that the prior influence is controlled over the second part, which is zero for no difference to the prior and and can become very large for differences > <dig>  hence, edge mismatches between the reference and the inferred net guide the structure search and the strength of the influence can be controlled using different settings of λ.

for the ga, adjusting λ is slightly different. instead of tracking the log likelihood and log prior differences between subsequent networks in the markov chain, the unlogged likelihood and prior differences  for each changed individual to a given population quantile  have to be recorded. in the first iterations of the ga, the individuals in the population will be widely spread around the network structure search space and changes in the likelihoods and priors will be rather large. once the population approximates an optimum, the changes will become smaller and be centred around zero. a strong prior will assure faster convergence to an optimum that is close to the reference. however, giving a guideline on how to set λ for the ga is difficult, because already rather 'weak' prior strength  seems to have a substantial influence  and the true impact of the prior might vary in different data sets. it seems reasonable to find some λ that gives average prior differences slightly above zero, which means that the final score, i.e. posterior, is biased towards the prior confidences on average. in general, finding the right choice for the prior parameters is not trivial. we suggest to use the above rationale to find an initial estimate and to iteratively update and improve the settings. this requires evaluation of the results obtained using a specific setting for the prior involving expert knowledge on the field studied. depending on that, subsequent modifications to the initial guesses might be necessary and the reconstruction has to be repeated.

scale-free prior
a different way of specifying a prior model was introduced by kamimura et al.  <cit> , as well as by sheridan et. al.  <cit> . it is assumed that the networks have a scale-free architecture and that the degree of a node follows a power-law p ∝ d-γ, where d is the number of edges adjacent to a node. for any graph structure Φ with fixed number of nodes n, a prior probability can be calculated as follows. first, assign a probability pi to each node i ∈  <dig> .. n:  

this probability decreases when i gets large, and all pi sum up to  <dig>  i.e. . μ is in the range  <dig> < μ < <dig> and defined as , γ ∈ [2; ∞[.

assuming independent node selection proportional to pi, and introducing a parameter k that controls the mean number of edges, the probability of two nodes not being connected is defined as  

the probability of any structure Φσ =  of node set v, edge set e and a permutation σ = {σ <dig>  ..., σn} of all nodes in Φ is then  

a number of b permutations σ are generated, resulting in one graph Φσ for each permutation. the final probability of Φ is averaged over the prior probabilities of all permutations networks:  

for a detailed description of the model we refer to the previous publications  <cit> . the scale-free prior can be used in cases where no information on edge confidences is available. during inference with the scale-free prior model, sparse network structures will be preferred, because high node degrees are penalised by the prior model. in our implementation the scale-free model can be selected by passing the argument priortype="scalefree" to the function call ddepn. further the arguments gam, it and k have to be provided. kamimura et al. give hints on the proper setting of the arguments. in the following sections, we assume that prior edge confidences are present and suggest the use of the laplace prior. however, the scale-free prior might be a reasonable substitute for modelling more general characteristics of network structures and thus interesting for further analyses.

RESULTS
testing the laplace prior influence
for both the ga and inhibmcmc sampler several tests were performed. the aim was to show that the inference could be influenced in a way that on the one hand the result was close to a given reference network and on the other hand allowed to confute the prior, when evidence from the data got strong enough. the following rationale was applied for these tests. first, we assumed that our prior information was true. to ensure this, a network with n =  <dig> nodes was sampled, data was generated depending on this network structure and the original sampled network was used as laplace prior matrix b. sampling of the network and data were described previously . both the prior confidences and inferred edges only take on values ∈ { <dig>   <dig>  -1}, so the absolute differences were either  <dig>   <dig> or  <dig>  all differences larger than  <dig> should have been strongly penalised, so we set γ =  <dig>  leading to a sharp decrease of the prior density  for Δij > <dig>  each mismatch in an inferred edge to the prior was thus given a weight close to  <dig> . we performed tests of the reconstruction performance for the following cases:

ga, bic score optimisation  <dig> iterations, p =  <dig>  q =  <dig> , m =  <dig>  no prior

ga, laplace prior  <dig> iterations, p =  <dig>  q =  <dig> , m =  <dig> , γ =  <dig>  λ ∈ { <dig>   <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig> }

inhibmcmc, laplace prior  <dig> iterations, burn-in  <dig> iterations, γ =  <dig>  λ ∈ { <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig> },

we performed n =  <dig> independent reconstructions on the same original network and data for both the ga and inhibmcmc samplers and calculated the area under curve  of the receiver operator characteristic  curves for each sampling run to measure the quality of the inference. aucs were calculated as follows. for inhibmcmc,  <dig> iterations were performed in each run with a burn-in phase of  <dig> iterations. final networks were generated by including an edge into the network that was present in at least a given proportion th ∈  of the  <dig> non burn-in networks. by varying th between  <dig> and  <dig>  for each setting of th the number of true positive, false positive, true negative and false negative edges of the final network compared to the original network could be counted. roc curves were set up and the aucs calculated as area under the roc curves.

on the right hand side of figure  <dig>  the likelihood and prior differences are shown. as stated in section 'laplace prior', λ should be set such that the prior differences are slightly above zero. as depicted in figure  <dig>  setting λ =  <dig>  lead to prior differences of around  <dig> and already had a strong influence on the reconstruction performance and could be used as appropriate setting for λ. nevertheless, it remains difficult to find the proper λ, and it is ongoing work to find reasonable ways of identifying 'good' parameter settings for both inhibmcmc and the ga.

note on the choice of the algorithm
the question, of course, arises, which algorithm to choose. one should be aware, that the purpose of both approaches differs. the ga is used for performing optimisation of the network structure, while inhibmcmc explicitly samples the space of networks. however, both methods can be used to generate final estimates of the network structure and provide the user with a confidence of each edge in the final inferred network. the influence of the prior seems to be less controllable in the case of the ga, since rather 'weak' prior settings  already had a strong impact, but increasing the prior strength always left some errors in the reconstructed networks. however, a clear dependency on the prior strength could be observed in both cases and a rough guideline for finding a suitable setting for the prior hyperparameters could be given. in general, finding the trade-off between strength of the prior and the influence of the data is of central importance. too strong prior influence will only reproduce the prior knowledge and not allow for novel insights from the data. if the prior is too weak, the inference might not be able to identify the underlying network structure, due to e.g. too wide time intervals during the measurements, noise in the data, or nodes that were not measured at all.

as a last point, we consider the computational demands of both approaches. clearly, the ga is much more expensive in terms of computation time. as an example, consider reconstruction of networks with the following settings : population size p =  <dig>  iterations =  <dig>  q =  <dig> , m =  <dig> . in each iteration q * p =  <dig> individuals are processed in the crossover step and m * p =  <dig> individuals are processed during the mutation step. for each of these  <dig> +  <dig> =  <dig> operations, the time limiting step is the viterbi training algorithm including hidden markov model  computations. in our experience, for networks of size around n =  <dig>  viterbi training is computed in less than one second, leading to an estimate of total computation time of  seconds, corresponding to ~  <dig> days. for inhibmcmc, we usually use  <dig> iterations for one sampling run, which means  <dig> times the viterbi training in each sampling. this corresponds to approximately half a day for one network reconstruction, meaning that more than  <dig> independent samplings can be performed in the same time as needed for one reconstruction with a ga. if parallel computing architecture is available, the ga computation time can be reduced to a few days, but also the independent inhibmcmc runs can be distributed on different computing cores or nodes, making multiple parallel network reconstructions possible in about half a day. so due to the computational burden of the ga and the improved control of the prior strength in inhibmcmc, it is suggested to prefer inhibmcmc over the ga.

rppa data from breast cancer cell line hcc1954
to demonstrate how the prior knowledge inclusion improves reconstruction results from real data, we show an inference performed on a series of protein phosphorylation measurements for proteins selected from the erbb signalling network. measurements were generated on reverse phase protein arrays  from hcc <dig> cells after ligand stimulation with egf, hrg and the combination of both. the data set is attached to our r-package as dataset hcc <dig> and described in our previous publication  <cit> . prior edge confidences were generated as described in section 'laplace prior', and a final reference network was assembled as follows. edges with confidence ≥  <dig>  were included in the prior network, while the edge type information was preserved. this threshold fits best our expectations on the prior network. additionally, several edges were included manually, that were described in current literature resources. the prior network is shown in figure  <dig> 

using this prior network, we applied inhibmcmc inference with  <dig> iterations, where the first  <dig> iterations were regarded as burn-in and discarded. the following parameters were chosen: λ =  <dig> , γ =  <dig>  to assess convergence and ensure robustness of the results,  <dig> independent inhibmcmc chains were run in parallel, each starting at a randomly sampled initial network structure. figure  <dig> shows the posterior traces of the  <dig> mcmc chains. it can be seen that the posterior probabilities converge to a stationary distribution after several thousand iterations. comparing the number of activation and inhibition edges sampled in each of the  <dig> runs , it can be seen that similar numbers are found, hinting at good mixing properties of the sampler . note that each chain might visit distinct networks with similar posterior during the inference. according to the posterior probability, the chains seem to be converged, but there might be still substantial differences in the high scoring networks, reflected in increased variation in the numbers of edges. for instance, panel mtor, column csrc in supplementary figure s <dig>  shows rather high variation in the number of activating and inhibiting edges. nevertheless, the shift in the number of sampled edges  reflects stronger support for the inhibition in the data and might be of interest for further investigation of this particular edge. it is difficult to overcome this problem, but we think that using a suitable summarisation method to identify edges  can help to identify true consensus networks described in the different inhibmcmc chains. however, the user should be aware of this issue and take precaution to avoid misleading inference results. we also refer to cowles and carlin  <cit>  for a good review on convergence in mcmc methods.

for each run, a summarised network was generated by including a particular edge, if it occurred in at least a fraction th ∈  of the  <dig> non burn-in networks. this left us with  <dig> summarised networks, that were merged into a consensus network. for this, we counted, how often each edge was an activation, inhibition or empty edge in all of the  <dig> summarised networks. a simple majority rule decided on the final type of the edge. in the case of ties, the edge type was chosen that had the larger posterior probability average over all summary networks with the same edge type.

the following rationale was applied for inferring a network from the hcc1954-data using our assembled prior network. because the erbb network has already been extensively studied, we assume that much of this information is true. we intended to include a strict bias towards the a priori known edges, guaranteed by the prior hyperparameter λ set to  <dig> . by this, the general erbb scaffold is retained unless there is strong support included in the data that contradicts the prior knowledge. the question is how to set the inclusion threshold used to determine the edges that are contained in the final network. under our settings, for values th ∈ , the inferred network equals the prior network, and no new information can be gained. for higher inclusion thresholds th > <dig> , edges are disappearing subsequently. this is expected because in the sampling procedure it is unlikely that an edge is contained in very high proportions of all sampled networks. indeed, in our samplings at th =  <dig> , no edges remain in the final networks. therefore we decided to decrease the inclusion threshold until differences to the prior were observed. this was the case at th =  <dig> . the inferred network using prior knowledge for this setting of th is shown in figure  <dig> on the right side. the left side of figure  <dig> displays the inferred network, when the ga and bic score optimisation was used. it is apparent that the inference was improved using the prior knowledge when looking at the structure of known signalling cascades. for example, the mapk kinase cascade egf → erbb <dig> → mek <dig> → erk <dig> → p70s6k or the cascade hrg → erbb <dig> → pdk <dig> → akt were inferred, which could be expected, because these are major signalling cascades that are ubiquitously present in biological systems. using this prior setting, the inferred network is strongly biased towards the reference network, and only two new edges could be seen in figure  <dig> : erk <dig> → p <dig> and pkc ⊣ akt. to allow more differences in the network structure, the parameter λ can be increased. the purpose here is to pinpoint the way of how bias towards the reference can be controlled using the λ parameter. for a detailed analysis of networks, e.g. under different experimental conditions, a suitable λ should be identified first by comparing inference results to the expectations on the network structures. once a setting for λ is determined, the resulting network structures and inferred model parameters  can be further investigated.

CONCLUSIONS
we present our r-package 'ddepn' for inference of signalling networks from longitudinal high-throughput data. the method is able to model the effects of external perturbation, as it might be introduced by external stimulations or inhibitions. two different network structure search algorithms are available in the package, a ga performing network structure optimisation and a metropolis hastings mcmc approach that samples the space of possible networks. we extend mcmc structure sampling by the ability to sample two edge types, one for activation and one for inhibition. further, two models for the inclusion of prior knowledge are included in the package. the first uses a reference network as guidance for the inference , the second uses a general property of biological networks, namely that node degrees follow a power law and high node degrees are penalised . we also give a guideline on how to adjust parameters for the laplace prior model, such that precise control on how close the reconstruction will be to the prior knowledge is possible. we show the dependence of the reconstruction performance on the prior parameter setting and give an assessment of both methods and their usage. finally, for a data set measuring phosphorylation of proteins related to the erbb signalling network, it is described, how inclusion of the prior is improving the outcome of the network reconstruction.

availability and requirements
project home page http://ddepn.r-forge.r-project.org

operating systems linux, windows

programming language r

other requirements graphviz

licence gnu gpl

list of abbreviations
auc: area under curve; cran: comprehensive r archive network; ga: genetic algorithm; hmm: hidden markov model; mcmc: markov chain monte carlo; roc: receiver operator characteristic; rppa: reverse phase protein array.

authors' contributions
concept and computations, as well as writing the manuscript were done by cb. svdh ran several ga reconstructions. fh performed the rppa experiments, and together with uk helped with the design of the prior network. tb gave advice on experiment design and writing the manuscript. sw proofread the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
edge confidences across  <dig> mcmc runs. shows the confidences for each edge obtained in multiple inhibmcmc runs.

click here for file

 additional file 2
model parameters for gaussian distributions. shows the gaussian model parameters for active/passive states of each protein.

click here for file

 acknowledgements
we thank anika joecker and alexander kerner for proofreading the manuscript, as well as stephan gade, maria fälth and marc johannes for helpful discussions. we also thank dirk ledwinka for technical support.

funding: this project was supported through the helmholtz alliance on systems biology network sb-cancer and through the german federal ministry of education and science  project breastsys in the platform medical systems biology.
