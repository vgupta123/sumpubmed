BACKGROUND
vertebrate genomes are now recognized as containing a huge number of non-coding functional regions, a large fraction of which is likely to be involved in regulating the various steps of gene expression  <cit> . while most of the attention has been centered on understanding the regulation of transcription, post-transcriptional regulatory mechanisms now appear to be more important than originally thought. cis-regulation of pre-mrna splicing is believed to be operated by splicing factors binding intronic and exonic splicing enhancers and helping to include or exclude specific exons from the transcript  <cit> . post-splicing, parts of the mature mrna often folds into some rna secondary structure that determines the level of mrna degradation  <cit>  as well as mrna localization  <cit> . translational efficiency and accuracy have been shown to be largely determined by the choice of synonymous codon, thus imposing some selective pressure on the codons of certain genes  <cit> . translation is also known to be affected by certain secondary structure elements in the mrna  <cit> . while most of the known examples of formation of functional secondary structure are restricted to the 5' and 3' utrs, the coding portion of the mrna has also been shown to form functional structures  <cit> . finally, there are also examples of transcription factor binding sites located in coding exons . the method presented here should allow the detection of many of these functional elements, which we call coding regions under non-coding selection . to this point, the computational methods that have proven the most valuable for identifying non-coding functional regions are based on comparative genomics. the guiding principle of this family of approaches is that functional features of a dna sequence tend to evolve slower than non-functional ones, because of selective pressure. this simple idea is at the core of phylogenetic footprinting, a method that compares orthologous regulatory dna regions to identify short conserved motifs likely to be transcription factor binding sites  <cit> . the key here is that most of the dna in promoter regions is non-functional, with the exception of the regulatory elements we are interested in. the same reasoning applies to the detection of intronic splicing enhancers  <cit> . with the ongoing sequencing of a large number of vertebrate genomes  <cit> , the power of these methods is quickly improving and, coupled with algorithmic improvements  <cit> , they are now able to detect very short regions under selection, or regions under weak selection.

the search for cruncs is more challenging. although the same "conservation implies function" principle applies in this case, it needs to be used more cautiously. indeed, cruncs are not located in non-functional sequences as are, for example, most known transcription factors binding sites, but rather in coding regions. this means that the sequence conservation observed in exons may be the result of two types of selective pressures. the first one is the pressure to maintain the function of the protein encoded by the gene, which probably explains most of the sequence conservation observed in coding regions. the second type of selective pressure applies only to cruncs, which are required to maintain their regulatory role. to apply phylogenetic footprinting to the detection of cruncs, one needs to determine which type of selective pressure is responsible for the sequence conservation observed.

the method suggested here takes a conservative approach to the problem. given a set of aligned orthologous coding sequences, we first evaluate the degree of conservation of each column of the alignment, using either a parsimony score or an entropy score. we then put the burden of explaining the conservation observed as much as possible on the shoulders of the selective pressure on the protein product. because most amino acids are encoded by many synonymous codons, amino acid selective pressure leaves room for some sequence variation. a region of the sequence will be predicted to be an cruncs only if the conservation observed cannot be explained solely by the need for conservation of the encoded amino acids. the method introduced here build a mixture model of codon evolution, and then uses it as a null model to assess the significance of the observed degree of conservation. we illustrate our approach on two sets of orthologous vertebrate genes  and compare it to a related approach by blanchette  <cit> .

RESULTS
given a multiple alignment of orthologous mrna sequences, our goal is to identify alignment columns that are conserved beyond what would be expected by chance if the corresponding sites were evolving only under the selective pressure on the amino acid they contribute to encode. such sites are likely to be under non-coding selective pressure. this section, which constitutes the main contribution of this paper, is structured as follows. first, we define two commonly used sequence conservation scoring methods: the entropy, and the parsimony score. we then describe a methods for assigning a p-value to a given entropy or parsimony score, under null models of evolution of codons that are only under coding selective pressure. under this method, we model codon evolution as a mixture of codon substitution models and use these models to assign a posterior p-value to a given conservation score.

two measures of sequence conservation
a number of methods have been proposed to measure the degree of conservation of a set of orthologous sequences and to identify regions under selective pressure . in this paper, we consider two such methods, the entropy score and the parsimony score, and later show how to assess the statistical significance of these scores in the context of coding regions.

entropy
in the area of transcription factor binding sites detection, a popular method for evaluating sequence conservation is the entropy . given a set of orthologous nucleotides x <dig>  x <dig>  ...,xn from n different species, the entropy measures the distance between the observed frequency of a, c, g, and t's at that site and the uniform distribution: entropy  = -∑α∈{a,c,g,t} fα log <dig>  where fα is the relative frequency of nucleotide α. perfectly conserved sites have an entropy of zero, while the worst levels of conservation obtain a score of  <dig> 

parsimony score
a major drawback of the entropy score is that it does not take into consideration the phylogenetic relationships among the sequences being compared, and indeed the method is mostly used for motif discovery within a single species. an alternative to the entropy score is the parsimony score  <cit> . given a set of orthologous nucleotides x <dig>  x <dig>  ..., xn and a phylogenetic tree t whose leaves are labeled with these nucleotides, the parsimony score is defined as the minimum number of substitutions, performed along the branches of the tree t, that can explain the set of nucleotides observed at the leaves. it is thus a lower bound on the actual number of substitutions at that site, and, in cases where this number is not too large compared to the number of branches in the tree, it is a fairly good estimate of the actual number of substitutions that occurred at that site. the parsimony score of a set of n nucleotides can be computed in time o using sankoff's algorithm  <cit>  or fitch's algorithm  <cit> . figure  <dig> gives an example of orthologous nucleotides whose conservation is well characterized by either the entropy or the parsimony scores. entropy and parsimony scores attempt to measure the total selective pressure on a given site. while, for non-coding regions, this selective pressure can be assumed to come completely from the presence of non-coding functional elements, this is not the case in coding regions. the rest of this paper describes how to measure the statistical significance of a certain conservation  score when the site under study lies within a coding region.

conservation p-values under a mixture of codon models
in this section, we introduce a null model of coding sequence evolution that consists of a mixture of codon substitution models representing the evolution of codons that are under different types of purely coding selective pressure. we then show how to compute posterior p-values for the entropy and parsimony scores of orthologous sequences evolving under those models.

mixture models for codon evolution
different positions in a protein sequence are usually subject to different types of coding selective pressures. some are constrained to have a specific amino acid , while others are free to have any residues with some particular chemical properties , and still others are under little or no selective pressure at all. selective pressure on amino acids translates into selective pressure on codons, which explains part of the sequence conservation observed at the mrna level in coding exons. we describe a mixture model of amino acid evolution, and the corresponding mixture model of codon evolution. we derive a set of  <dig> amino acid substitution rate matrices , ..., , together with codon rate matrices ,..., , describing the substitution rates for as many classes of selective pressures on amino acids. the choice of modeling codon evolution with only  <dig> classes is a compromise between an highly accurate modeling of codon evolution  and constraints on computing time. tests carried out with  <dig> classes instead of  <dig> resulted in very similar results .

we learn amino acid functional categories using the pfam database of amino acid sequence alignments of protein domains  <cit> . we start by learning the amino acid stationary distribution of each rate category. we then use these distributions to classify the pfam alignment columns, and use this classification to estimate the amino acid and codon substitution rate matrices for each class.

the stationary amino acid distributions π <dig>  π <dig>  ..., π <dig> and class prior probability distribution τ are estimated using an unsupervised expectation-maximization algorithm  in order to fit the pfam alignments as closely as possible. figure  <dig>  shows the amino acid distribution obtained for each of the  <dig> classes . we observe that most of the expected functional classes are present among our  <dig> classes. first, for each amino acid, there is at least one category where that amino acid has a probability at least  <dig> . these correspond to positions that tolerate little variation outside of that particular amino acid. less constrained categories include several combinations of residues with similar properties: hydrophobic residues , small neutral residues , aromatic residues , positively charged residues , etc. the class of negatively charged amino acids  is surprisingly not directly represented, although these two amino acids show up together in several more weakly defined classes. various categories correspond to positions under little selective pressure. many of our classes are similar to those reported by sjolander et al.  <cit>  using a related procedure.

amino acid and codon substitution rate matrices
for each of the  <dig> classes above, an amino acid substitution rate matrix and a codon substitution rate matrix are derived. we first compute the probability of each pfam alignment column to belong to each of the classes, and use these to estimate the probability of amino acid and codon transitions between human and mouse sequences. rate matrices are then derived from these empirically estimated transition probabilities matrices. the detailed procedure is described in methods.

distribution of conservation scores
we now return to the problem of identifying regions under non-coding selective pressure in a multiple alignment of orthologous coding mrna sequences  = x <dig> ... xm, where xi is the triplet of alignment columns corresponding to the i-th codon in the alignment. let xi be the codon observed in species j ∈ { <dig> ..s}, where s is the number of column triplets in the alignment, and let xi,p be the nucleotide at position p  in that codon. given a column of orthologous codons xi, we want to assess whether the conservation observed at position p of the codon is unexpected. to this end, we compute the posterior p-value of the observed conservation score  of that codon position, under the null hypothesis that the columns are only under coding selective pressure.

to describe more formally our null model of sequence evolution, we need to introduce some notation. let t =  be a binary phylogenetic tree with vertices v, edges e, root r, and with leaves numbered  <dig> ,...,n. let λ be the length of the branch going from node u to node v, let a be the amino acid encoded by codon c, and let q be some codon substitution rate matrix. the codon transition probability matrix for a branch  is given by p = eλq  <cit> . let b be the background probability of codon c, which is assumed to be the stationary distribution of q. these three parameters  describe a process that generates random but related codons at the leaves of the tree t, by drawing a codon from the stationary distribution of q at the root of t and letting it mutate along the branches of the tree using the appropriate transition probability matrices. let c be the random variable representing the codon that has been generated by this process at node u of the tree.

we are interested in computing the distribution of the conservation score of a given position p of a set of random orthologous codons generated at the leaves of the tree. we start by showing how to compute this distribution for the entropy score entropy,cp, ..., cp), and later show the modifications required to do the same for the parsimony score. for a fixed codon position p ∈ { <dig> ,3}, and for any node u ∈ v, let yu = , yu, yu, yu) be a random multivariable where yu is the number of nucleotides of type a at position p of the codons at the leaves of the subtree rooted at u. notice that yu is only a function of the codons at the leaves of subtree, and not of those at the internal nodes of subtree. the p-value of a certain entropy score e for position p is obtained by summing the probabilities of all values of yr that yield an entropy score e or better:



we will show how to compute pr, for every node u and all choices of ya, yc, yg, yt and k, using a dynamic programming algorithm visiting the nodes of t in post-order. when u is a leaf, we have



define  ⊕  : = . now, let u be an internal node with children v and w. notice that yu = yv ⊕ yw. we compute the desired conditional probabilities at node u based on those at nodes v and w:



implementation optimizations and computational complexity analysis are given in methods.

distribution of parsimony scores
the method described in the previous section can be surprisingly easily modified to compute the conditional p-value of parsimony scores instead of that of the entropy score. we need to redefine the random variable yu =  so that yα is now the parsimony score obtained for the nucleotides at position p of codons at the leaves of the subtree rooted at u, assuming that the nucleotide at the ancestral node u is required to be a. note that this set of four numbers per node is exactly that computed by the sankoff algorithm for computing parsimony scores  <cit> . we also redefine the ⊕ operator as

 ⊕  = ,

min,

min,

min)

where  = minj≠iyj. notice that this is again in direct analogy to sankoff's algorithm. again, yu = yv ⊕ yw and we get parsimony , ,..., cp) = min. with these redefinitions, equation  <dig> holds without any modifications needed. we get



posterior distributions of conservation scores
having shown how to compute the p-value of a given entropy or parsimony score under a fixed codon rate matrix, it is simple to compute posterior p-values for the case where the functional class is not known in advance. consider a given set of aligned codons xi = , ..., xi) encoding the set of amino acids ai = , ..., ai). define the unobserved variables zi,k =  <dig> if the site i belongs to functional class k, and zero otherwise. we first compute the posterior probability of each zi,k, given the observed amino acids at site i:



where pr is computed using felsenstein's algorithm  <cit> , with rate matrix . finally, we obtain the posterior estimate pvpost for the p-value of the entropy score e observed at position p of codon i, by summing over all classes:



and similarly for parsimony scores p-values.

conditional p-values
an alternative to trying to guess the type of selective pressure under which a given codon evolves is to use a single codon rate matrix but subject to the constraint that the random codon generated at each leaf has to encode the amino acid that was actually observed at that leaf. this approach was originally proposed by blanchette  <cit> . this model does not rely on amino acid classifications and in fact allows sites to change function during their evolution. by conditioning on the observed amino acids at the leaves of the tree, we ask: given that in species j, the codon had to encode amino acid a), for each leaf j ∈ { <dig>  ..., n}, is the conservation observed in xi surprising? notice how, compared to the mixture model approach, this model transfers the responsibility of sequence conservation even more onto the shoulders of coding selection. see figure  <dig> for an example. mathematical details are provided in methods.

a sliding window approach
until now, we have shown two ways to compute p-values for individual alignment columns. since most non-coding functional elements are expected to span several consecutive positions , we can improve the sensitivity of the method by using a simple sliding window approach. for each position i, let pv be the p-value obtained for the i-th column of the alignment , and let w be the width of the sliding window . we compute si = ∏j = i- ⌊w/2⌋...i + ⌊w/2⌋ pv. if we assume that, under the null model, pv is approximately uniformly distributed, a compounded p-value can be assigned to si: cpv = pr = sij/j!). this is the type of p-value being reported in the applications section. it should however be noted that although the uniformity assumption holds quite well for the third codon positions, the first two codon positions are often completely determined by the codon they encode, so the range of possible p-values they can take is quite small. this results in the compounded p-values being quite conservative.

implementation
the algorithms were implemented in c++ and the program is available upon request. a number of optimizations described in  <cit>  have also been implemented and make the program relatively fast. in particular, a caching mechanism allows to re-use the results of computations done on previous columns. this allows the program to handle very long sequences quickly. all analyses reported here have been obtained in less two hours of computation on a desktop machine.

analysis of simulated data
we first verify that the p-values computed by our approach have the basic properties we would expect of them. to start, we confirm that sequences evolving under the null model obtain p-values that are approximately uniformly distributed. this would be a trivial statement if the functional category of each site was known, but in the absence of such prior knowledge, the uniformity of p-values under the null model is less obvious. to this end, we simulated the evolution of a  <dig> kb region of dna, with each codon belonging to one of the  <dig> rate categories described above. sequences were evolved along the branches of the 69-leaf phylogenetic tree derived from the gh <dig> data set described below. figure  <dig> shows the distribution of posterior p-values obtained at each of the three codon positions. as desired, the distribution is nearly uniform. however, we observe a depletion of columns with low p-values , in particular for codon positions  <dig> and  <dig>  this is due to the fact that, at these positions, a column that is perfectly conserved is not particularly surprising, and obtains a p-value around  <dig> – <dig> . to obtain a p-value distribution that is closer to uniform, one would need to use a tree with much larger total branch length. second, we study the power of our method to detect selection on sets of aligned codons that are perfectly conserved. as expected, the power of our method to detect cruncs depend on the amino acid encoded by the codon. perfectly conserved codons encoding amino acid w cannot be detected by our approach. on the other hand, codon conservation is easiest to detect among four-fold and six-fold degenerate amino acids. among those, codons encoding amino acids p and g, both of which have chemical properties making them more difficult to exchange for other amino acids, obtain higher p-values, because their conservation can be explained to a larger extent by the amino acid encoded.

analysis biological data
we illustrate our approach on two sets of orthologous mrna sequences: a set of  <dig> vertebrate growth hormone  <dig>  sequences, and a set of  <dig> vertebrate cortbp <dig>  sequences .

gh <dig> was one of the first gene shown to harbor an exonic splicing enhancer, in cow  <cit> . the availability of a large number of orthologous sequences makes it ideal for our study. figure  <dig> shows the compounded p-values obtained from the mixture-based method, for the parsimony score, using a sliding window with w =  <dig>  the human region orthologous to a known exonic splicing enhancer in the cow, located around position  <dig>  <cit> , is clearly identified, obtaining a compounded p-value of about  <dig> × 10- <dig>  although this region could have been identified on the basis of parsimony scores alone , it is highlighted much more clearly by the posterior p-values.

finally, the analysis of the cortbp <dig> transcript is particularly intriguing. little is known about the post-transcriptional regulation of this gene. we find that its mrna contains a very large region , which obtain fairly low p-values. this region is much too large to be a binding site, and we conjecture that it may form some large rna secondary structure affecting the pre-mrna splicing or the mrna stability, localization or translation. notice that in this case, a simple parsimony score is not sufficient for identifying the region, as many other regions of the transcript are well equally well conserved.

CONCLUSIONS
with the many genome sequencing projects rapidly producing vertebrate genomic data, comparative genomic approaches are becoming increasingly powerful. in the case of cruncs, additional data is often available in the form of ests and cdnas. we believe that within one year or two, there will be sufficient data for accurate detection of cruncs in vertebrate genes, using methods like those described here. once many cruncs will have been detected, the next step will of course be to assign functions to these elements. although the last word will remain with experimentalists, we have good hopes that more advanced bioinformatics approaches will yield insights into these questions.

finally, we expect that organisms that are under severe genome size constraints, in particular bacteria and viruses, will more often use cruncs. we believe that our approaches will prove particularly fruitful to analyze these genomes.

