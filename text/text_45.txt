BACKGROUND
knowledge engineering in the life sciences is challenged by the combination of high specificity and high heterogeneity of the data needed to represent and understand biology's systemic puzzles. despite the deluge of data that has invaded life sciences in the past decade  <cit> , data-driven discovery in biology is hindered by a lack of enough interlinked information to allow statistical algorithms to find the patterns that inform hypothesis-driven research  <cit> . life sciences research relies heavily on bioinformatics integration tools like ensembl  <cit> , the ucsc genome browser  <cit> , entrez gene  <cit>  or the gene ontology  <cit>  because these offer researchers portals to a wealth of interlinked biological annotations within the context of their experimentally derived results, thus playing a lead role in advancing scientific discovery. the amount of time and effort required to develop and maintain such tools has prompted linked data approaches for data integration to become increasingly relevant in health care and life sciences  domains  <cit> . briefly stated, linked data can be described as a bottom-up solution for data integration: its focus is on creating a global web of data where typed links between data sources provide rich context and expressive reusable queries over aggregated and distributed heterogeneous datasets  <cit> . the architecture of that web is expected by its original architects  <cit>  to require a representation of usage contexts that can be applied in the collaboration and controlled sharing of data. when this functionality is supported, as that report anticipates, "social machines" will be able to manage the simultaneous and conflicting views of data that fuel scientific debate. the s3db knowledge organization system was designed to provide baseline support for that bottom-up process by addressing a recurrent need for controlled sharing of hcls datasets  <cit> . this report describes a convention, the s3ql language, to query and manipulate it. it will also be demonstrated that s3ql provides a convenient mechanism to engage linked data in general.

 <dig>  linked data best practices
linked data best practices set the stage for an interlingua of relational data and logic in the web  <cit>  by the definition of core principles that can be summarized as: 1) information resources should be identified with http universal resource identifiers ; 2) information should be served against a uri in a standard semantic web format such as the resource description framework  and 3) links should be established to information resources elsewhere  <cit> . for large datasets, it is also convenient that a web service supporting sparql, the protocol and rdf query language, is also deployed  <cit> . aggregation of data sources is available either by accessing metadata about the datasets as rdf  <cit> , or through direct aggregation of rdf assertions in a single knowledgebase  <cit> . to ensure contextual consistency and reusability across datasets, data elements and descriptors are mapped using standard vocabularies, namespaces and ontologies  <cit> .

 <dig>  challenges involved in publishing primary experimental life sciences datasets as linked data
the value of linked data for life scientists lies primarily in the possibility to quickly discover information about proteins or genes of interest derived, for example, from a microarray or protein array experiment  <cit> . life scientists involved in primary research still face significant challenges in harnessing the power of linked data to improve biological discovery. part of the difficulty lies in the lack of adequate and user-friendly mechanisms to publish biological results as linked data prior to publication in scientific articles. efforts in linking life sciences data typically focus on datasets which are already available in structured and annotated formats, i.e. after the researchers have analysed, correlated and manually annotated their results by browsing the literature or submitting their data to multiple web-based interfaces  <cit> . current research  <cit>  and our own experience in developing content management systems for health care and life sciences  <cit> , has identified the need to go beyond those data sets by creating mechanisms for contextualizing linked life sciences data with attribution and version before it can be shared with a stable annotation. advances have been made in that direction by other research efforts such as the recent publication of void as a w3c note  <cit> .

the technological advancements that will make primary life sciences experimental results an integral part of the web of data are also thwarted by challenges which go beyond infrastructure and standards  <cit> . in particular, hcls datasets often include data elements, such as those that could be used to identify individual patients, with stringent requirements for privacy and protection  <cit> . the typical approach to privatizing data has been to make it the responsibility of the data providers. although this may provide a temporary solution for a small number of self-contained datasets, it quickly becomes unmanageable when datasets aggregate both public and sensitive data from multiple sources, each with its own requirements for privacy and access control  <cit> .

one final common concern in life sciences is the need to enable data experts to edit and augment the data representation models; failure to support this flexibility has lead in the past to misinterpretation of primary experimental data due to absence of critical contextual information  <cit> .

 <dig>  knowledge organization systems for linked data
in order to address the information management needs of life scientists, the practice of linked data standards must be coupled with the implementation of knowledge organization systems , a view also espoused by the w3c, where the simple knowledge organization system  has been recently proposed as a standard  <cit> . in previous work we proposed the design principles of a kos, the simple sloppy semantic database   <cit> . the s3db core model is, much like skos, task-independent and light-weight. implementation of the s3db core model and operators resulted in a prototype that has been validated and tested by life scientists to address pressing data management needs or, in particular, as a controlled read-write linked data system  <cit> . s3db was shown to include the minimum set of features required to support the management of experimental and analytic results by life sciences experts while making use of linked data best practices such as http uri, subject-predicate-object triples represented using rdf schema, links to widely used ontologies suggested by ncbo ontology widgets  <cit>  or new owl classes created by the users and a sparql endpoint  <cit> . although complying with these practices is enough to cover the immediate query or "read" requirements of a linked data kos, we found that efficient data management or "write" operations, such as inserting, updating and deprecating data instances within a kos could be more efficiently addressed with the identification of the s3db query language , a domain specific language  devised to abstract most of the details involved in managing interlinked, contextualized, rdf statements.

s3ql is not meant as an alternative to sparql but rather as a complement: data management operations enabled by s3ql can also be formalized in sparql. however, the availability of a data management dsl that can be serialized to sparql provides an abstraction layer that can be intuitively used by domain experts. as such, dsls can provide a solution for bridging the gap between the formalisms required by linked data best practices such as sparql and rdfs, and the basic controlled read/write management requirements of hcls experts  <cit> . dsls optimize beyond general purpose languages in the identification of the domain in which a task belongs, drastically reducing the development time  <cit> . the task of adding a graph to a triple store is supported by most graph stores by means of the sparql  <dig> . update language  <cit> . to enable controlled "write" operations targeting the dataset, it would be useful to annotate, for example, the creator of a named graph, under which circumstances it was created and who has permission to modify it. similarly, upon changes to the dataset, annotation of the modifier and a comment describing the change would be in the interest of the communities using the data. many triple stores are in fact quad stores to enable partial support of that requirement for contextual representation. the most common approach is to use a named graph, a set of triples identified by a uri  <cit>  that indicates the source of a graph. the s3db query language  presented in this report was devised with the intent of automating linked data management by creating those contextual descriptors in a single s3ql transaction, including author, creation date and description of the data.

by making use of those contextual descriptors, we propose a method for fine grained permission control in s3ql that relies on s3db:operators  <cit> , a class of functions, with states, that may be used as the predicate of an rdf triple between a user and a dataset with privacy requirements. these operators, described in  <cit>  and made available for experimentation at  <cit> , operate on the adjacency matrix defined by the nodes and edges of an rdf graph. they can be applied in a variety of scenarios such as optimizing queries or, as is the case with s3ql, to propagate permission assignments. in the latter case, an adjacency matrix includes both the edges between instances of s3db entities and the transitions of permission on s3db entities such as, e.g. the assertion that a user's permission on a project propagates to its entities. accordingly, by defining user permissions as states of s3db:operators, the core model's adjacency matrix is used to propagate the ability to control, view and modify s3db entities.

we have found the target audience for s3ql to be both life sciences application developers, who use it through a restful application programming interface , and life sciences researchers who use it through user interfaces for weaving the ontologies that best represent the critical contextual information in their experimental results. the applicability of s3ql to other linked data koss such as the simple knowledge organization system   <cit>  is explored with an example and the advantages of the solution proposed are discussed in three biomedical datasets with very different requirements for controlled operations: gastrointestinal clinical trials  <cit> , cancer genomic characterization  <cit>  and molecular epidemiology  <cit> .

methods
this section overviews the core model for s3db, including the set of operators that enable fine grained permission control and the distributed infrastructure supporting s3ql. the principles defined here are implemented as a prototypical application available at http://s3db.org.

the s3db knowledge organization model
s3ql is a dsl to programmatically manipulate data as instances of entities defined in a kos. one of the key features of the kos defined using the s3db core model  <cit>  is the use of typed named graphs to separate the identification of the domain, the metadata describing the data, from its observational instantiation - the data itself. we have previously shown that this approach to representing rdf greatly facilitates the assembly of sparql and lowers the entry barrier for biomedical researchers interested in using semantic web technologies to address their data management needs  <cit> . that separation is achieved by using the representation of domain as triples that are themselves the predicates of the statements that instantiate that domain . for example, the triple , identified as :r <dig> through a named graph of type s3db:rule, describes the domain while the triple , identified by a named graph of type s3db:statement, instantiates that domain. through the logic encoded in the rdf schema definition of domain  and range , the assertion that "john" is of type "person" and that "26" is an "age" is enabled in the s3db kos. s3db's use of named graphs to describe the domain enables updates to the domain without affecting the consistency of its instantiation - in the example above, modifying "hasage" with "hasageinyears" will not affect queries that have already been assembled using that property.

in the s3db core  <cit> , a meta-model for this data is also created with the specific objective of enabling propagation of operations, such as permission assignments, between the domain description and the data itself, described in the following section . in the example above, the two triples are respectively assigned to entities of type s3db:rule and s3db:statement where indexes "person" is identified by a named graph of type s3db:collection and "john" is identified by a named graph of type s3db:item. the s3db core specifies three other entities which are specifically devised to enable knowledge organization and operator propagation: s3db:project entails a list of s3db:rule and s3db:collection and are typically applied in domain contextualization; s3db:deployment corresponds to the physical location of an s3db system  and s3db:user is the subject of permission assignment operations. it is worth noting that, by making use of s3db entities, blank nodes are avoided by assigning a unique alphanumeric identifier to every instance of an s3db entity. the s3db entities can also be identified using the first letter of their names, d, p, r, c, i, s or u, which will be used in subsequent examples to indicate, respectively, s3db:deployment, s3db:project, s3db:rule, s3db:collection, s3db:item, s3db:statement or s3db:user.

operators for permission control
the second key feature that makes s3db appropriate for controlled management operations is support for permission control embedded in its core model. as described above and in  <cit> , the hierarchy of permissions to view/edit entities in s3db is modelled by an adjacency matrix, which is used as a transition matrix in the propagation of permission states. for a walkthrough of the propagation mechanism, see additional file  <dig>  the s3db:operator states applied to the s3db transition matrix modulate propagation by three core functions - merge, migrate and percolate. this behaviour for propagation of permission is described in detail in equation  <dig> of  <cit>  and is reproduced here in equation  <dig>  the s3db transition matrix  is defined by  <dig> s3db:relationships describing dependencies and inference rules between entities of the s3db core model. the operator state vector  is used as the predicate of a triple established between an s3db:user and an entity of the s3db core model. the javascript application at  <cit>  can also be used to attempt this set of propagation behaviours for s3db:operators both on the s3db transition matrix or with alternative adjacency matrixes.   

the s3db:operators  <cit>  have a scope and applicability in linked data beyond permission management. in s3ql we define three operator types for controlled management operations: for each of the rights to view, change/edit or use instances of s3db entities. the format used to assign permission was defined as a three character string, where each operator occupies respectively the first, second or third positions and may assume value n, s or y according to the level of permission intended: no permission , permission limited to the creator of the resource  or full permission . for example, the permission assignment "ysn" specifies complete permission to view  the subject entity, partial permission to change it  and no permission to use it . states may be defined as dominant, by use of uppercase  or recessive, by use of lowercase characters . dominant and recessive permissions are used to decide on the outcome of multiple permissions converging on the same entity . missing permission states, indicated by the dash character '-'  are also allowed, as well as a mechanism to succinctly specify transitions with variable memory length . the propagation of permissions in the s3db core model ensures that for every entity and every user, two types of permission are defined: the assigned permission, or the permission state assigned directly to a user in an entity, and the effective permission, which is the result of the propagation of s3db:operators.

components of a distributed system
one of the requirements for rdf-based knowledge management ecosystems is the availability of queries spanning across multiple sparql endpoints. automation of distributed queries in systems supporting permission control, such as s3db, is challenged by user authentication. in s3ql, we propose addressing this through delegation to authentication authorities. as a result, a user , can be identified by a uri that is independent of the authorities that validate it. whenever possible, it is recommended that authentication credentials be protected by use of oauth  <cit> .

use of uris and internationalized resource identifiers  to identify data elements is one of the core principles of linked data. however, many programming environments cannot easily handle uris as element identifiers. problems range from decreased processing speed to a need for encoding the uris in web service exchanges. as an anticipation for that class of problems, the uris for entities in s3db are interchangeable with alphanumeric identifiers formulated as the concatenation of one of d, u, p, c, r, i or s  identifying the entity and a unique number. as an example, for a deployment located at url http://q.s3db.org/demo, the alphanumeric p <dig> is resolvable to an entity of type project with uri http://q.s3db.org/s3dbdemo/p <dig>  to facilitate exchange of uri in distinct deployments, the uri above could also be specified as d282:p <dig>  where "d282" is the alphanumeric identifier of the s3db deployment located at url http://q.s3db.org/demo. every s3db:deployment is identified by a named graph in the form d; for completeness, metadata pertaining to each s3db:deployment, such as the corresponding url, is described using the vocabulary of interlinked datasets   <cit>  and shared through a root location.

availability and documentation
the specification of the s3ql language has been made available at http://link.s3db.org/specs and one example of the output rdf is available at http://link.s3db.org/example. s3ql has been implemented through a rest application programming interface  for the s3db prototype, which is publicly available at http://s3db.org. both the prototype and its api were developed in php with mysql or postgresql for data storage. documentation about the s3db implementation of s3ql as an api can be found at http://link.s3db.org/docs. s3ql queries may be tested at the demo implementation at http://link.s3db.org/s3qldemo and a translator for the compact notation is available at http://link.s3db.org/translate.

RESULTS
s3ql syntax
s3ql is a domain specific language devised for facilitating management operations such as "insert", "update" or "delete" using entities of a linked data kos such as the s3db core model described above. its syntax, however, is loosely tied to the s3db core model, and can easily be applied to a set of kos' core models in which s3db is included. the complete syntax of s3ql in its xml  flavour is represented in the railroad diagram of figure  <dig>  the s3ql syntax includes three elements: the description of the operation, the target entity and the input parameters. four basic operation descriptions were deemed necessary to fully support read/write operations: select, insert, update and delete. the action of these operations mimic those of the structured query language  and target instances of entities  defined in the core model. input parameters include the set of attributes defined for each of the entities either in the alphanumeric form associated with entity instances  or in the form of entityattributevalue . the values for e.a are determined upon choice of e - for an example using s3db entities and attributes see figure 2: e may be replaced with any of the entities defined in the s3db core model ; upon choice of e, valid forms of e.a include any of the attributes defined for e . a table summarizing all available operations, targets and input parameters is made available at http://link.s3db.org/specs. the formal s3ql syntax is completed by enclosing the outcome of one of the diagrams on figure  <dig> with the <s3ql> tag. for example, the following xml structure is a valid s3ql query for an operation of type insert where the target is the s3db entity project and the input parameter, formulated as entityatributevalue is "label = test":

<s3ql>

  <insert>project</insert>

  <where>

   <label>test</label>

  </where>

</s3ql>

the set of  <dig> s3db:relationships  in the s3db model determine the organizational dependencies of s3db entities. for example s3db:pc is the s3db:relationship that specifies a dependency between an instance of a collection  and an instance of a project  . the s3ql syntax fulfils this constraint by assigning project_id  as an attribute of a collection. in this description of attributes associated with the s3db core model we make use of the assumption, as in other koss and in the linked data in general, that there is no restriction to adding relationships beyond those described here. s3ql was identified as the minimal representation to interoperate with the s3db core model and therefore only those relationships are explored in this report.

the syntax diagram in figure  <dig> generates xml, a standard widely used in web service implementations. that alternative often results in verbose queries that could easily be assembled from more compact notations. one example to consider is the form: action . here the symbol '|' should be interpreted, as in bayesian inference, as a condition and be read "given that". the letter "e" corresponds to the first letter of any s3db entity  and e.a is any of its attributes as described in figure  <dig>  in this example, the query insert is equivalent to the example query above. that particular variant is also accepted by the s3db prototype and a converter for this syntax into complete s3ql/xml syntax was made available at http://link.s3db.org/translate. for further compactness of this alternative formulation, entity identifiers used as parameters may be replaced with its corresponding alphanumeric identifiers - for example project_id =  <dig> may be replaced with p <dig>  this alternative notation will be used in the subsequent examples.

s3ql permission control
permission states are assigned using an s3ql query such as insert, which includes the action insert, the target entity user and three input parameters: identifier of the user , identifier of the entity  and permission assignment . effectively, this will result in the creation of the triple , where the subject is of type s3db:user, the predicate is of type s3db:operator and the object is of type s3db:project. the inclusion of this triple in a dataset will modulate the type of management operation that a user may perform. as described in the methods section, each position in the permission assignment operator  encodes, respectively, for permission to "view", "change" or "use" the object entity. values y, s and n indicate, respectively, that the user has full permission to view it , permission to change its metadata only if he was the creator of the entity  and no permission to insert  child entities. each s3ql operation is therefore tightly woven to each of the three operators: select is controlled by "view"; update and delete are controlled by "change" and insert is controlled by "use" . the 'use' operator encodes for the ability of a user to create new relationships with the target entity, which is defined separately from the right to "change" it. for example, in the case of a user  being granted "y" as the effective permission to "change" an s3db:rule, then the metadata describing it may be altered. if, however, that same user is granted permission "n" to 'use' that same rule, she is prevented from creating statements using that rule. although "use" may be interpreted as being equivalent to "insert" or "append" in other systems, we have chosen to separate the terms describing the operator "use" from the s3ql action "insert". the permission assigned at the dataset level will then propagate in the s3db transition matrix following the behaviour formalized in equation  <dig>  therefore avoiding the need to assign permission to every user on every entity. it is worth noting that the dsl presented here is extensible beyond the  <dig> management actions  described. the s3db:operators that control permission on these actions are also extensible beyond "view", "change" and "use" and different implementations may support alternative states.

the permission control behaviour for s3ql operations can be illustrated through the use of the quadratus, an application available at http://q.s3db.org/quadratus that can be pointed at any s3db deployment to assign permission states on s3db entities to different users . other use case scenarios are also explored in the s3ql specification at http://link.s3db.org/specs.

global dereferencing for distributed queries
a simple dereferencing system was devised for s3db identifiers that relies on the identification of root deployments, i.e. s3db systems where alphanumeric identifiers for s3db deployments can be dereferenced to url. this simple mechanism enables complex transactions of controlled data. for an example of this behaviour see figure  <dig>  where the s3db uid d327:r <dig>  identifying an entity of type rule  available in deployment d <dig> is being request by a user registered in deployment d <dig>  in order to retrieve the requested data, the url of deployment d <dig> must first be resolved at a root deployment such as, for example, http://root.s3db.org.

the dereferencing mechanism is also applicable in more complex cases where the root of two deployments sharing data is not the same. prepending the deployment identifier of the root to the uids such as, for example, d1016666:d327:r <dig>  where d <dig> identifies the root deployment, would result in recursive url resolution steps such as select prior to step  <dig> in figure  <dig>  this mechanism avoids broken links when s3db deployments are moved to different urls by enabling deployment metadata to be updated securely at the root using a public/private key encryption system.

implementation and benchmarking
in the current prototype implementation, s3ql is submitted to s3db deployments using either a get or post request and may include an optional authentication token . the rest specification  <cit>  suggest separate http methods according to the intention of the operation: often, "get" is used to retrieve data, "put" is used to submit data, "post" is used to update data and "delete" is used to remove data. there are, however, many programming environments that implement only the rest "get" method, including many popular computational statistics programming frameworks such as r and matlab. therefore, in order to fully explore the integrative potential of this read/write semantic web service, and to support operations beyond the  <dig> implemented, the s3db prototype implementation of s3ql supports the "get" method for all s3ql operations, with the parameters of the s3ql call appended to the url. one drawback of relying on get is the limits imposed by the browser on url length. to address this potential problem, the s3db prototype also supports the use of "post" for s3ql calls.

two further challenges needed to be addressed in the prototypical implementation of s3ql: 1) the need for a centralized root location to support dereferencing of deployment uri when the condensed version is used  and 2) distributed queries on rest systems required users to authenticate in multiple koss. the first challenge was addressed by configuring an s3db deployment as the root location, available at http://root.s3db.org. deployment metadata is submitted to this root deployment at configuration time using s3ql; data pertaining to each deployment can therefore be dereferenced to a url using http://root.s3db.org/d. the option to refer to another root deployment than the default is possible during installation. to avoid overloading these root deployments with too many requests, a local  <dig> hour cache of all accessed deployments is kept in each s3db deployment using the same strategy; if the url is cached, it will not be requested from the root deployment. to address the second challenge, each s3db:deployment can store any number of authentication services supporting http, ftp or ldap protocols. once the user is authenticated, temporary surrogate tokens are issued with each query. when coupled with the user identifier in the format of a uri, these tokens effectively identify the user performing the query regardless of the s3db deployment where the query is requested.

screencasts illustrating processing time of data manipulation using s3ql are available at http://www.youtube.com/watch?v=2kzc6ki609s and http://www.youtube.com/watch?v=fjsylcwbapi.

discussion
one of the major concerns in making use of linked data to improve health care and life sciences research is the need to ensure both the availability of contextual information about experimental datasets and the ability to protect the privacy of certain data elements which may identify an individual patient. domain specific languages  can ease the task of managing the contextual descriptors that would be necessary to implement permission control in rdf and, by doing so, could greatly accelerate the rate of adoption of linked data formalisms in the life sciences communities to improve scientific discovery. we have described s3ql, a dsl to perform read/write operations on entities of the s3db core model. s3ql attempts to address the requirements in linking life sciences datasets including both publishable and un-publishable data elements by 1) including contextual descriptors for every submitted data element and 2) making use of those descriptors to ensure permission control managed by the data experts themselves. this avoids the need to break a consolidated dataset into its public and private parts when the results are acceptable for publication.

applying s3ql to the s3db core model in a prototypical application benefited from the definition of loosely defined boundaries for rdf data that enabled propagation of permission while avoiding the need to document a relationship for each data instance, individually, and for each user. the assembly of sparql queries is also facilitated by the identification of domain triples using named graphs, from the data itself  <cit>  and can be illustrated in the application at  <cit> , where a subset of s3ql can be readily converted into the w3c standard sparql. although the prototypical implementation of s3ql fits the definition of an api for s3db systems, it is immediately apparent that the same notation could be easily and intuitively extended to other kos' core models. for example, pointing the tool at http://q.s3db.org/translate to a javascript object notation  representation of the skos core model  instead of the default s3db core model  results in a valid s3ql syntax that could easily be applied as an api for skos based systems, as illustrated by applying the example query "select" using http://link.s3db.org/translate?core=skos.js&query=select to retrieve skos concepts labelled "animal". the progress of adoption for life sciences application developers can be further smoothed by complete reliance on the rest protocol for data exchange and the availability of widely used formats such as json, xml or rdf/turtle.

the applicability of s3ql to life sciences domains is illustrated here with three case studies: 1) in the domain of clinical trials, a project  <cit>  that requires collaboration between departments with different interests; 2) in the domain of the cancer genome atlas  project, a multi-institutional effort that requires multiple authentication mechanism and sharing of data among multiple institutions  <cit>  and 3) in the domain of molecular epidemiology, a project where non-public data stored in an s3db deployment needs to be statistically integrated with data from a public repository. all described use cases shared one considerable requirement - the ability to include, in the same dataset, both published and unpublished results. as such, they required both the annotation of contextual descriptors of the data, enabled by s3ql, and the availability of controlled permission propagation, enabled by the s3db model transition matrix. future work in this effort may include the application of s3ql in a knowledge organization system based on skos terminology and the definition of a transition matrix for skos to enable controlled permission propagation.

gastro-intestinal clinical trials use case
as part of collaboration with the department of gastrointestinal medical oncology at the university of texas m.d. anderson cancer center, an s3db deployment was configured to host data from gastro-intestinal  clinical trials. a schema was developed using s3db collections and rules and s3ql insert queries were used to submit data elements as items and statements . two permission propagation examples are illustrated, one of a restrictive nature and the other permissive, which can also be explored at http://q.s3db.org/quadratus . in this example, the simple mechanisms of propagation defined for s3ql support the complex social interaction that requires a fraction of the dataset to be shared with certain users but not with others. contextual usage is therefore a function of the attributes of the data itself  and the user identification token that is submitted with every read/write operation.

the cancer genome atlas use case
the cancer genome atlas  is a pilot project to characterize several types of cancer by sequencing and genetically characterizing tumours for over  <dig> patients throughout multiple institutions. s3ql was used in this case study to produce an infrastructure that exposes the public portion of the tcga datasets as a sparql endpoint  <cit> . this was possible because sparql is entailed by s3ql but not the opposite. specifically, sparql queries can be serialized to s3ql but the opposite is not always possible, particularly as regards write and access control operations. the structure of the s3db core model which explicitly distinguishes domain from instantiation enables sparql query patterns, such as ?patient: r <dig> ?cancertype to be readily serialized into its s3ql equivalent select. although this will not be further explored in this discussion, it is worth noting that the availability of this serialization allows for an intuitive syntax of sparql queries by patterning them on the description of the user-defined domain rule, such as, "patient hascancertype cancertype".

a molecular epidemiology use case
in this example, sparql was serialized to s3ql to support a computational statistics application. as a first step, an s3db data store was deployed using s3ql to manage molecular epidemiology data related to strains of staphylococcus aureus bacteria collected at the instituto de tecnologia química e biológica , in portugal. specifically, the itqb staphylococcus reference database was devised with a purpose of managing multilocus sequence typing  data, a typing method used to track the molecular epidemiology of infectious bacteria  <cit> . as a second step, we downloaded the public staphylococcus aureus mlst profiles database at http://www.mlst.net and made it available through a sparql endpoint at http://q.s3db.org/mlst_sparql/endpoint.php. the process of integration of mlst profiles from the itqb staphylococcus database with the publicly available mlst profiles is illustrated in figure  <dig>  in this example, a federated sparql query is assembled to access both mlst sources; data stored in the s3db deployment is retrieved by serializing the sparql query into s3ql and providing an authentication token to identify the user, as described in figure  <dig>  the assembled graph resulting from the federated sparql query , can be imported into a statistical computing environment such as matlab . using this methodology, it was possible to cluster strains from two different data sources with very different authentication requirements. the observation that some portuguese strains  that are not publicly shared cluster together with a group of public uk strains  and therefore may share a common ancestor is an observation enabled by the data integrated through s3ql.

CONCLUSIONS
life sciences applications are set to greatly benefit from coupling semantic web linked data standards and koss. in the current report we illustrate data models from life sciences domains weaved using the s3db knowledge organization system. in line with the requirements for the emergence of evolvable "social machines", different perspectives on the data are made possible by a permission propagation mechanism controlled by contextual attributes of data elements such as its creator. the operation of the s3db kos is mediated by the s3ql protocol described in this report, which exposes its application programming interface for viewing, inserting, updating and removing data elements. because s3ql is implemented with a distributed architecture where uris can be dereferenced into multiple s3db deployments, domain experts can share data on their own deployments with users of other systems, without the need for local accounts. therefore, s3ql's fine grained permission control defined as instances of s3db:operators enables domain experts to clearly specify the degree of permission that a user should have on a resource and how that permission should propagate in a distributed infrastructure. this is in contrast to the conventional approach of delegating permission management to the point of access. in the current sparql specification extension various data sources can be queried simultaneously or sequentially. there is still no accepted convention for tying a query pattern to an authenticated user, probably because sparql engines would have no use for that information as most have been created in a context of linked open data efforts. the critical limitation in applying this solution for health care and life sciences is the ability to make use of contextual information to determine both the level of trust on the data and to enable controlled access to elements in a dataset without breaking it and storing it in multiple systems. to address this requirement, s3ql was fitted with distributed control operational features that follow design criteria found desirable for biomedical applications. s3ql is not unique in its class, for example the linked data api, which is being used by data.gov.uk is an alternative dsl to manage linked data  <cit> . however, we believe that s3ql is closer to the technologies currently used by application developers and therefore may provide a more suitable middle layer between linked data formalisms and application development. it is argued that these features may assist, and anticipate, future extensions of semantic web provenance control formalisms.

competing interests
the authors declare that they have no competing interests.

authors' contributions
hfd developed the s3ql domain specific language, implemented it in the s3db prototype, validated it with examples and wrote the manuscript. mcc, rs, mm, hl, rf, wm and jsa tested and validated the language with examples and made suggestions which lead to its improvement. all authors read and approved the final manuscript.

supplementary material
additional file 1
walkthrough of s3db's permission propagation: merge, migrate and percolate.

click here for file

 additional file 2
matrix of mlst profiles in portugal and the united kingdom.

click here for file

 acknowledgements and funding
this work was supported in part by the center for clinical and translational sciences of the university of alabama at birmingham under contract no. 5ul <dig> rr025777- <dig> from nih national center for research resources, by the national cancer institute grant 1u24ca143883- <dig>  by the european union fp <dig> pneumopath project award and by the portuguese science and technology foundation under contracts ptdc/eia-eia/105245/ <dig> and ptdc/eea-acr/69530/ <dig>  hfd also thankfully acknowledges phd fellowship from the same foundation, award sfrh/bd/45963/ <dig> and the science foundation ireland project lion under grant no. sfi/02/ce1/i <dig>  the authors would also like to thank three anonymous reviewers whose comments and advice were extremely valuable for improving the manuscript.
