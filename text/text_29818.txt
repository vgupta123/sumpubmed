BACKGROUND
microarray time-course experiments allow researchers to explore the temporal expression profiles for thousands of genes simultaneously. the premise for pattern analysis is that genes sharing similar expression profiles might be functionally related or co-regulated  <cit> . due to the large number of genes involved and the complexity of gene regulatory networks, clustering analyses are popular for analyzing microarray time-course data. heuristic-based cluster analyses group genes based on distance measures; the most commonly used methods include hierarchical clustering  <cit> , k-means clustering  <cit> , self-organizing maps  <cit> , and support vector machines  <cit> . due to the lack of statistical properties of these heuristic-based clustering methods, statistical models, especially analysis of variance  models and mixed models are often implemented as a precursor to clustering to ensure the genes used for clustering are statistically meaningful  <cit> . only genes identified to be significantly regulated by statistical models are used for further clustering. fitting statistical models prior to clustering usually dramatically reduces the number of genes used for clustering, which in general will improve the performance of the clustering method. an alternative way of clustering is statistical model-based clustering methods, which assume that the data is from a mixture of probability distributions such as multivariate normal distributions and describe each cluster using a probabilistic model  <cit> .

in microarray time-course studies, time dependency of gene expression levels is usually of primary interest. since time can affect the gene expression levels, it is important to preserve time information in time-course data analysis. however, most methods for analyzing microarray time-course data treat time as a nominal variable rather than a continuous variable, and thus ignore the actual times at which these points were sampled. peddada et al.  proposed a method for gene selection and clustering using order-restricted inference, which preserves the ordering of time but treats time as nominal  <cit> . recently, a number of algorithms treating time as a continuous variable have been introduced. xu et al.  applied a piecewise regression model to identify differentially expressed genes  <cit> . both luan and li  and bar-joseph et al  proposed b-splines based approaches  <cit> , which are appropriate for microarray data with relatively long time-course, but their application to short time-course data is questionable. new methods for analyzing short time-course microarray data are needed  <cit> .

in this paper, we propose a model-based approach, step down quadratic regression, for gene identification and pattern recognition in non-cyclic short time-course microarray data. this approach takes into account time information because time is treated as a continuous variable. it is performed by initially fitting a quadratic regression model to each gene; a linear regression model will be fit to the gene if the quadratic term is determined to have no statistically significant relationship with time. significance of gene differential expression and classification of gene expression patterns can be determined based on relevant f-statistics and least squares estimates. major advantages of our approach are that it not only preserves the ordering of time but also utilizes the actual times at which they were sampled; it identifies differentially expressed genes and classifies these genes based on their temporal expression profiles; and the temporal expression patterns discovered are readily understandable and biologically meaningful. a free excel macro for applying this method is available at  <cit> . the proposed quadratic regression method is applied to a microarray time-course study of olfactory receptor neurons  <cit> . biologically meaningful temporal expression patterns have been obtained and shown to be more effective classifications than anova-protected k-means clusters. comparison with peddada et al.'s order-restricted inference method  <cit>  showed that our method provides a different and interesting insight into the temporal gene profiles. reliabilities of the results from all  <dig> methods were assessed using a bootstrap method  <cit>  and regression patterns were shown to have the highest reliabilities.

RESULTS
step-down quadratic regression
we propose a step-down quadratic regression method for gene discovery and pattern recognition for non-cyclic short time-course microarray experiment. the first step is to fit the following quadratic regression model to the jth gene:

yij = β0j + β1jx + β2jx <dig> + εij     

where yij denotes the expression of the jth gene at the ith replication, x denotes time, β0j is the mean expression of the jth gene at x =  <dig>  β1j is the linear effect parameter of the jth gene, β2j is the quadratic effect parameter of the jth gene, and, εij is the random error associated with the expression of the jth gene at the ith replication and is assumed to be independently distributed normal with mean  <dig> and variance . two levels of significance, α <dig> and α <dig>  need to be pre-specified, where α <dig> to is recommended to be small to reduce the false positive rate in the gene discovery and α <dig> less stringent to control pattern classification. α <dig> could be chosen using various multiple testing p-value adjustment procedures, for example, false discovery rate   <cit> . the temporal gene expression patterns can be determined as follows:

 <dig>  if overall model  p-value >α <dig>  the jth gene is considered to have no significant differential expression over time. the expression pattern of the gene is "flat".

 <dig>  if overall model  p-value ≤ α <dig>  the jth gene will be considered to have significant differential expression over time. the patterns are then determined based on the p-values obtained from f tests .

a. if both p-value of quadratic effect ≤ α <dig> and p-value of linear effect ≤ α <dig>  the jth gene is considered to be significant in both the quadratic and linear terms. the expression pattern of the gene is "quadratic-linear".

b. if p-value of quadratic effect ≤ α <dig> and p-value of linear effect >α <dig>  the jth gene is considered to be significant only in the quadratic term. the expression pattern of the gene is "quadratic".

c. if p-value of quadratic effect >α <dig>  the jth gene is considered to be non-significant in the quadratic term. the quadratic term will be dropped and a linear regression model will be fitted to the gene:

yij = β0j + β1jx + εij     

from fitting model ,

• if p-value of linear effect ≤ α <dig>  the jth gene is considered to be significant in the linear term. the expression pattern of the gene is "linear".

• if p-value of linear effect >α <dig>  the jth gene is considered to be non-significant in the linear term. the expression pattern of the gene is "flat".

the four expression patterns described above can be furthered classified into  <dig> patterns according to the up/down regulation of the gene expression based on the least-squares estimates  and  and the predicted signals . a flow chart for the above procedure is shown in figure  <dig>  this procedure can be easily applied using the excel macro available at  <cit> .

application of the quadratic regression method
normality test based on shapiro-wilk statistics  <cit>  suggested that most of the  <dig> present genes in the olfactory receptor neuron data do not have a significant departure from the normal distribution . therefore the quadratic regression method with normality assumption was applied to the data of  <dig> present genes , where α <dig> was chosen to be  <dig>  and α <dig> to be  <dig> .  <dig> genes were determined to have significant differential expression over time at level  <dig> . examples of  <dig> regression patterns are shown in figure  <dig> 

comparison with peddada et al.'s method
peddada et al.'s method  <cit>  was applied to the expression data of  <dig> present genes with  <dig> pre-specified profiles: monotone increasing ; monotone decreasing ;  <dig> up-down profiles with maximum at the second, third, forth time point ; and  <dig> down-up profiles with maximum at the second, third, forth time point . based on  <dig> bootstrap,  <dig> genes were classified into one of the  <dig> pre-specified profiles at significance level  <dig> . this indicates that peddada et al.'s method might be relatively more conservative than regression method by selecting much fewer genes at significance level  <dig> . comparisons of peddada et al.'s profiles and regression patterns are listed in table  <dig>  we observe that the majority of genes in mi are in lu, similarly for md and ld, ud <dig> and qlcd, and du <dig> and qlvu. however, each of the peddada et al.'s profiles contains a mixture of regression patterns, and vice versa. this is reasonable because even though both methods perform gene selection and classification, they are aimed at different aspects of the temporal profiles. for example, peddada et al.'s mi profile contains regression patterns lu, qlcu and qlvu. although the gene expression level is increasing monotonically over time, the regression method gives more information on how it is increased: constantly , increases faster then slower , or increases slower then faster . peddada et al.'s ud <dig> profile contains genes that are first up-regulated then down-regulated with maximum at the second time points, which could be classified as regression pattern qlcd in general , but it could also be classified as ld if the expression levels of all time points are close to a line ; or classified as qc if the expression profile is close to quadratic ; or classified as qlcu if the expression levels of last  <dig> time points are much closer than those of the first time point. similarly, peddada et al.'s ud <dig> profile could be classified as regression patterns qc, qlcu, and qlcd .

comparison with anova-protected k-means clustering
anova-protected k-means clustering was applied to the expression signals of  <dig> present genes. out of  <dig> present genes,  <dig> were identified to be differentially expressed over time by one way anova . these  <dig> genes were used for classification by k-means clustering with k =  <dig> and the distance measure being pearson correlation coefficient .

in order to make the regression patterns comparable with the k-means clusters, the quadratic regression method was applied to the  <dig> anova significant genes. table  <dig> shows the number of genes in common when comparing each regression pattern with each k-means cluster. an example of a good match between regression patterns and k-means clusters is the qlcd regression pattern and k-means cluster k <dig>  however, in most cases, k-means clusters contain a mixture of regression patterns and the regression patterns are separated into different k-means clusters. for example, genes that have the lu regression pattern are split into  <dig> k-means clusters . the similarity of the temporal expression profiles in figure  <dig> indicates that it might be more appropriate to classify these genes into the same group, which occurs using the proposed regression method. examples in figure  <dig> show that some k-means clusters are also mixtures of expression profiles in terms of the mean signals . for example, a down-up-down-up pattern  appeared in both k-means clusters k <dig> and k <dig> , but are identified to have qlvu regression pattern ; similarly see figure 7a and 7b . once again, the regression method provides better classification. figure  <dig> is an example of genes with similar expression patterns but different initial starting time of the differential expression . adora2b clearly starts differential expression later than psmb <dig> . after the initial starting point , these two genes show similar upward regulation. these two genes were classified into the same regression group, but in different k-means clusters. based on the above analysis, our regression method is demonstrated to be more appropriate for the classification of temporal gene expression profiles than k-means method.

ease functional analysis on regression patterns and k-means clusters
to further explore the effectiveness of the regression method on gene classification, ease  software was used to examine the potential relationship between the biological functions of the genes and their expression patterns  <cit> . ease calculates ease scores  to identify over-represented gene categories within lists of genes. ease analysis was applied to each of the  <dig> regression patterns and  <dig> k-means clusters that were obtained from the classification of  <dig> anova significant genes . the results are summarized , with part of the information shown in tables  <dig> and  <dig>  the ease analysis demonstrates that the proposed regression method is more effective for gene classification than the k-means clustering method. almost all of the regression patterns contain genes mainly from one biological process. for example, lu has  <dig> over-represented gene categories,  <dig> of which are involved in immune regulation . the majority of the lu and qlvu gene categories are in the immune regulation category. this suggests that there exist multiple regulatory mechanisms within the immune regulation. the immune regulation in qlvu appears to be a more complex regulatory mechanism for the initial up-regulation of these genes due to the slow upward regulation at early time points of this regression pattern . the ease results for the k-means clusters shows that the over-represented gene categories of most k-means clusters are involved in more than one biological process, for example, k-means cluster k <dig> contains  <dig> over-represented gene categories,  <dig> involved in immune regulation,  <dig> involved in cell death, etc. notice that the immune regulation category is represented in  <dig> k-means clusters, which suggests that the immune regulation category is more consolidated in regression patterns than in k-means clusters . also, by comparing ease scores in tables  <dig> and  <dig>  one can see that the over-represented gene categories in the regression patterns have, in general, smaller ease scores than those in the k-means clusters, which further indicates the greater effectiveness of the regression method in pattern classification.

reliability analysis
kerr and churchill  introduced a bootstrap technique to assess the stability of clustering results  <cit> . we applied the same idea here to assess the reliability of regression patterns, peddada et al.'s profiles, and k-means clusters. all  <dig> pattern classification methods were performed on the expression data of  <dig> anova significant genes to make the results comparable. the reliability curves show that regression patterns have the highest reliability, and k-means clusters have the lowest reliability . this suggests that the regression method provides relatively more stable pattern classifications.

simulation study
we investigated the false positive rate  of our method via a simulation study. the data were generated randomly from n, containing expression signals of  <dig> "null" genes , with  <dig> time points and  <dig> replications per time point per gene.  <dig> of such data were generated. the regression approach was applied to each gene in each simulated data at α <dig> =  <dig>  and the numbers of significant genes in each of the  <dig> data were obtained. the average proportion of significance  is  <dig> % with standard deviation  <dig> %. this demonstrates that the false positive rate of the regression method is accurate because 1% of  <dig> genes would be expected to be significant at  <dig>  level by chance. the false positive rates of the regression patterns lu, ld, qc, qv are all approximately equal to 1/ <dig> of the average false positives, and those of qlcu, qlcd, qlvu, and qlvd are all approximately equal to 1/ <dig> of the average false positives.

discussion
the proposed step-down quadratic regression method is an effective statistical approach for gene discovery and pattern recognition. it utilizes the actual time information, and provides biologically meaningful classification of temporal gene expression profiles. furthermore, it does not require replication at each time point, which anova-type methods do require. also, this method can identify genes with subtle changes over time and therefore discover genes that might be undetectable by other methods, eg, anova-type methods. however, there are several limitations to this method. firstly, it is designed to fit time-course data with a small number of time points. we recommend this method when there are  <dig> to  <dig> time points in the data. for an experiment with more time points, spline-type methods  <cit>  could be a possible choice; for an experiment with  <dig> or  <dig> time points, anova-type method is recommended. secondly, the  <dig> regression patterns are rather limited considering the complexity of gene regulatory networks. for example, certain proportion of genes show cubic, "m", and "w" shaped patterns in  <dig> regression flat genes which are anova significant . these patterns could be caused by random chance, but they could also be real patterns. fitting a higher order polynomial regression model may discover these types of genes profiles. theoretically, one could fit a 4th-order polynomial regression model to this data . the model with 4th-order polynomial will work similarly to connecting the mean at each time point, therefore will provide a good fit to the data with smallest r <dig> and minimum mean squared error, compared with lower-order polynomials. however, the purpose of pattern analysis is to cluster the data instead of fitting models, so the quadratic fit is useful even though the goodness of fit may not be great. also, the use of high-order polynomials  should be avoided if possible  <cit> , particularly in cases such as this where the regression coefficients are used primarily for classification. another issue is the transformation of the experimental time. transformation should be considered when the sampling time is unequally spaced. the choice for the type of transformation  is not critical because the resulting pattern classification will in general not be impacted.

in the reliability curves, at 95% reliability, regression patterns, peddada et al.'s profiles, and k-means clusters have 33%, 12%, and 0% of genes, respectively; and at 80% reliability, the percentage of genes are 55%, 32%, and 0%, respectively . even though the regression patterns have the highest reliability, only 33% of genes have 95% reliabilities. we examined the overall model  p-values of  <dig> genes by the regression method and found that genes that have the smallest overall model  p-values all have 95% reliabilities. this suggests that we could reduce the level of significance α <dig> to increase the stability of regression patterns. α <dig> could be reduced using various multiple testing p-value adjustment procedures, for example, westfall and young's step down method  <cit> , and false discovery rate   <cit> . application of the fdr method can be done as follows : let p <p < … <p be the ordered overall model  p-values, start from the largest p-value p, compare each p with α *i/m; let k be the largest i that p ≤ α *k/m, conclude p, …, p to be significant.

both our quadratic regression method and peddada et al.'s method serve the same overall goal: gene selection and classification. peddada et al.'s method provides more choices of temporal profiles than our method. while our regression method offers less choice of patterns, it may provide deeper insight into the gene expression profiles than peddada et al.'s method. our method distinguishes patterns with different rates of change and provides more information on the relative relationship among the expression levels of all time points. for example, specifying a profile of up-down with maximum at one time point does not provide much information on the relative relationships among other time points . a further refinement of peddada et al.'s method may provide such information about the relationship of other time points besides the maximum/minimum. however, it is less likely to separate the patterns in figure 5a, b, and 5c by their method. another fact is that peddada et al.'s method provides exactly the location of the maximum/minimum, whereas our method provides the neighborhood of the location of the maximum/minimum. furthermore, their method is based on bootstrap, which is computationally intensive. the result of their method, for example, the reliability curves, might be improved by applying more bootstrap, which is  <dig> in this paper due to the computational difficulties and time constraints. moreover, their method depends on the ordering of time but not the actual time at which the samples were taken, whereas the regression method accounts for both.

k-means is an iterative clustering algorithm  <cit> . the first step of this method is to randomly assign the data points to the k clusters. next, the distance to the center of each cluster is calculated for each data point, and the data point is moved into the closest cluster. this step will be repeated until no data point is moving from one cluster to another. in k-means, the number of clusters, k, needs to be pre-specified. researchers usually choose several different k and find the one which has the most biologically meaningful clusters. there are methods of finding the "optimal" k, for example, bayesian information criterion  <cit> . in this paper, k was arbitrarily chosen to be  <dig>  since the k-means clustering does not perform well , we investigated different choice of k based on the bayesian information criterion and identified that the "optimal" k is  <dig>  however, as we examined these  <dig> k-means clusters, the pattern classification does not seem to be improved, the same problem exists as with k =  <dig>  for example, prom <dig>  clu, and d17h6s56e- <dig>  all have similar temporal profiles and are all classified to be qlvu, but they were separated into  <dig> of the  <dig> k-means clusters. this could be related to the distance measure used . as we discovered, genes in the same cluster do not necessarily have higher correlation than genes in different clusters. for example, sfpi <dig> and anxa <dig>  are highly correlated  and their expression patterns are similar, but they are in different k-means clusters. a possible reason might be that the time-course in olfactory receptor neuron data is too short for correlation to perform well. even though there are a total of  <dig> observations for each gene, correlation calculations are based on the  <dig> mean signals, which could be too few to describe the relationship between temporal profiles. there is also concern about using correlation as the distance measure. a large correlation coefficient does not necessarily indicate two similarly shaped profiles, nor does a small correlation coefficient necessarily indicate differently shaped profiles  <cit> .

a number of regression algorithms have been proposed recently, which treat time as a continuous variable. several of them are based on cubic b-splines  <cit> . b-splines are defined as a linear combination of a set of basis polynomials. in order to fit cubic b-splines to time-course data, the entire duration of experimental time needs to be divided into several segments by "knots" , and each segment will be fit by cubic polynomial. the successful application of these methods to microarray time-course data depends heavily on having a relatively large numbers of time points. the b-spline based methods will not be effective when there are a small number of time points in the time-course experiment  <cit> . for a data with  <dig> time points, cubic b-spline type methods would not be appropriate because it is recommended that there should be at least  <dig> or  <dig> experimental time points in each segment  <cit> . xu et al used a piecewise quadratic regression model to identify differentially expressed genes  <cit> . in their approach, expression levels at  <dig> hour and  <dig> hours after treatment are fit differently from the rest of time points after treatment. although appropriate for their data, their method cannot be applied to the dataset used in this paper.

the quadratic regression method that we applied to the olfactory receptor neuron data relies on the normality assumption. this is supported by the result of the shapiro-wilk normality test, which indicates that most of the genes used for the analysis follow a normal distribution. this might be due to the fact that we removed genes that are called "a"  by affymetrix across all chips. "a" calls are often assigned to low expression signals, which tend to be non-normal in general. therefore removing genes with a high proportion of "a" calls may reduce the possibility of violation of the normality assumption, which will then make the test based on distributional assumption more likely to be valid, and thus avoid computational intensive resampling procedures, for example, bootstrap and permutation. if desired, experimenters could also try various types of data transformation to make their data closer to normal when the data are shown to have large departure from normality. however, the log transformation performed on the olfactory receptor neuron data was not to reduce the possible non-normality, but solely to make a fair comparison of our regression method and k-means method because it is the default transformation in genespring. when the normality assumption ) does not hold, the bootstrap method  <cit>  can be used to avoid the distributional assumption. for an experiment with m genes, t time points, and r replications per time point, the bootstrap procedure can be performed in the following way: form the data into a matrix of m × rt, each column in the matrix contains expressions of m genes in one chip and each row contains rt expressions of one gene; randomly draw rt columns with replacement to form a bootstrap sample; apply step-down quadratic regression procedure to the bootstrap sample to obtain f statistics from f tests; repeat the above steps  <dig> times to form a bootstrap f distribution for each gene; claim a gene to be significance at level of α if its observed f statistics is greater than the upper thpercentile or less than the lower th percentile of its bootstrap f distribution. one concern about using bootstrap here is that the bootstrap f distribution might be too discrete due to the small number of time points. however, the fact that we are bootstrapping both the explanatory and response variables mitigates this issue by using all the data points, not just the time points. additionally, in a small simulation study, we observed that the bootstrap f distribution is rather smooth .

CONCLUSIONS
the proposed step-down quadratic regression approach is shown to be effective for gene discovery and pattern recognition for non-cyclic short time-course microarray experiment. major advantages of this method are that it preserves the actual time information, and provides a useful tool for gene identification and pattern recognition. the nine regression patterns, obtained when applied to the olfactory receptor neuron data, are shown to be more reasonable classifications compared to anova-protected k-means clustering method. ease analysis further showed that our regression patterns are more biologically meaningful than the k-means clusters. comparison with peddada et al.'s method showed that our method provides a different perspective on the temporal gene profiles. reliability study indicates that regression patterns are most reliable. in conclusion, this method should improve gene discovery and pattern recognition for microarray time-course data. with the freely accessible excel macro, investigators can readily apply this method to their research data.

