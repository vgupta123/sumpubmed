BACKGROUND
the presence of a wide array of organelles enables eukaryotic cells to perform multiple and even competing biological processes in parallel. the cellular distribution of these organelles, and in particular the proteins and other molecules associated with them, remains of intense interest to the scientific community. indeed the identification and understanding of the localization of all the proteins encoded by the genome can be considered as a first critical step towards assigning function  <cit> . following the completion of various genome-sequencing projects many labs have been highly active in developing methodologies and tools to systematically assess the localization of the proteins encoded. imaging-based technologies are particularly relevant to this task as they not only provide spatial information in a cellular context, but when applied in living cells can also provide information about protein dynamics over time. the first genome-wide assessment of protein localization was carried out in the yeast saccharomyces cerevisiae, using a green fluorescent protein -tagging approach  <cit> . similar systematic approaches to reveal the localization of the human proteome have also been described  <cit> , however this task remains to be completed. apart from the sheer complexity of mammalian genomes and their extensive transcriptional products, systematic analysis of protein localization in higher eukaryotes is also hampered by a lack of software tools to aid in automated determination of localization. some tools to automatically annotate localization have been reported  <cit> , however due to the highly diverse morphology of the same organelles between different cells this approach remains challenging. one potential solution to this problem is to combine different fluorescently-labeled proteins  in the same cells. quantification of the abundance of a molecule, and its relative distribution compared to known organelle markers , would provide a more accurate description of localization, and potentially could be applied on a genome-wide scale.

co-localization, representing the co-compartmentalization of specific molecules, can be defined as the existence of spatial overlap between two molecules. the existence of overlap can be most simply determined by visual inspection of merged channels . a second possibility is the use of a scatter plot - a 2d histogram representing the pixel intensities across two colour channels from a merged image. the component along the diagonal of this plot represents co-localized regions. this plot however assumes that the intensities across the two images are similar, which is not often the case, and therefore can produce aberrant results. a linear least-square fit of intensities of the two channels can be used to normalize for the differences, but this is not easily applicable to large numbers of diverse images.

the pearson's correlation  coefficient was the first described quantitative measurement approach for comparing dual channel images. this method gives one number that represents the overall correlation of intensities between two channels. the pearson's correlation coefficient between two channels a and b is represented as follows:

 pc=∑iai-aavg*∑iai-aavg2* <dig> 

in this equation ai and bi are the intensities of pixel i, and aavg and bavg are the average intensities of channels a and b respectively. although pc is used widely by the microscopy community to assess co-localization, the pc value generated is highly sensitive to the intensity in each channel. in microscopy images, the intensity values acquired from two channels can be highly different as a result of many factors, including nature of the organelle or protein under investigation, the brightness of the fluorophores, and the manner in which the images were generated. the high sensitivity of pc to channel intensities can therefore cause skewed results, and so awareness of this is vital.

a modification to address this deficiency in the original pc equation was formulated  <cit> . in this modified equation the intensity values in each pixel, without subtracting the average intensities in each channel, are applied. this new coefficient  is now expressed as:

 r=∑iai*∑iai2*∑i <dig> 

in this formula ai and bi are the intensities of pixel i in channels a and b respectively. manders and colleagues suggested dividing the coefficient into two components in order to cancel out the bias coming from the number of objects in each channel  <cit> . the overlap coefficients k <dig> and k <dig> provide a measurement of overlap between one channel and another, and are represented as:

 k1=∑iai*bi∑iai2;k2=∑iai*bi∑ibi <dig> 

manders went on to propose a new measure for co-localization based on the proportion of signal overlap, independent of the influence of pixel intensities. these coefficients, m <dig> and m <dig> are represented as:

 m1∑iai,coloc∑iai;m2∑ibi,coloc∑ibi 

in this formula ai, coloc = ai if bi >  <dig> and bi, coloc = bi if ai >  <dig>  one limitation of these co-localization equations is that thresholds first need to be manually identified in order to eliminate background and/or noise, and therefore this process can introduce bias. in this regard, costes et al. demonstrated the importance of threshold for more accurate quantitative co-localization, and proposed an automated thresholding algorithm to define independent thresholds for each of the channels by pixel intensity correlations between the two channels  <cit> . to obtain the thresholds, each pixel in both the channels is represented as two components; a co-localized component and a random component . a stoichiometry constant α is introduced in the second channel of the co-localized component to account for the variability in co-localization ratio . the thresholds for the two channels a and b are then set to t and a*t+b where a corresponds to the stoichiometry constant α, and b represents the mean random overlap difference between a and b after correction for the variability α. the thresholds are determined simultaneously for both channels by setting the thresholds at the highest intensity values and decreasing the thresholds t and a*t+b simultaneously on both channels until the pc of the remaining pixels below the thresholds is  <dig>  the co-localization coefficients are represented as:

 m1c≅∑i>tai∑iai∀ai>a*t+b 

 m2c≅∑i>at+bbi∑ibi∀bi>t 

one of the main drawbacks is the overestimation of co-localization quantified in these methods. in each of these cases, the contribution of a pixel to quantification of co-localization is binary, by classifying them as either 100% co-localized or 0% co-localized. in calculating the percentage of co-localization of the first channel with the second channel, while weighting is given to the intensity values in that first channel , the intensity value of the corresponding pixel position in the second channel  is completely ignored. however, the intensity of the corresponding pixel position in the other channel indicates the relative abundance of the molecule of interest in that channel and therefore this should be accounted for. differences in pixel intensities across the two channels render it difficult to combine these values and hence the classification is binary.

while pc estimates the overall correlation of intensities within a particular region of interest, it does not discriminate overlapping pixels from non-overlapping pixels. if the relative number of non-overlapping pixels is larger than the number of overlapping pixels, the correlation can be skewed by the intensity variation in the non-overlapping pixels. the manders' coefficient is insensitive to intensity correlation and therefore the co-localization is quantified as a ratio of overlapping pixels to the total number of pixels. in order to address these deficiencies in the currently available co-localization algorithms, we have devised a new algorithm that not only takes account of correlating pixels between two channels, but also considers their relative intensities. we propose that this 'dual channel rank-based intensity weighting coefficient'  provides the most accurate measurement to date of co-localization between two image channels.

RESULTS
rank-based intensity weighting
we propose a new weighting measure that overcomes the drawbacks described above, by weighting each pixel position in each channel based on the relative strength of intensities between the two channels. the uneven distribution of intensities between two channels warrants the use of a non-parametric approach for integrating these values. the weighting of co-localized pixels thus discriminates pixel positions with a similar intensity from those having extreme values. this ensures that co-localized pixel positions, where the two markers under investigation also have a high correlation of intensity, contribute more to the coefficient compared to poorly correlated positions. the new coefficients for each of the channels can be represented as rank-weighted co-localization coefficients rwc <dig>  and rwc <dig>  as follows:

 rwc1≅∑i=1nai,coloc*wi∑i=1nai∀ai>athr 

 rwc2≅∑i=1nbi,coloc*wi∑i=1nbi∀bi>bthr 

in this formula weight wi=rn-dirn, ai, coloc = ai if bi > bthr ,  <dig> otherwise, and bi, coloc = bi if ai > athr ,  <dig> otherwise. rn is the maximum of ranks of channel a and b, whichever is the largest, and d is the absolute difference between the ranks of channel a and channel b for each pixel position i given by di = | - rank|. parameters athr and bthr are threshold values for channels a and b, respectively. the provision of defined threshold values is not necessary in this formula, as the ranking of pixels already discriminates low intensity pixels from high intensity pixels. however, by including these threshold parameters in the formula, users can still control the minimum pixel intensity above which co-localization quantification should be performed. furthermore, it also allows easy comparison with other co-localization methods that require threshold information to be manually entered. if no manual intervention is required, the threshold values athr and bthr are set to zero.

the ranking of pixels is made in each channel by giving the pixel with the highest intensity a rank of  <dig> and assigning the next highest intensity pixel a rank of  <dig>  and so on. pixels having the same intensities are assigned the same rank. the number of ranks in each channel depends on the number of grey levels in that channel. this method of ordinal ranking of pixels normalizes for the intensity values without altering the image. each pixel in each channel gets a rank based on its intensity relative to the highest intensity in its channel. for an n-bit image, the ranks in each channel can range from  <dig>  to 2n . the number of ranks in each of the channels is determined, and 'rn' is assigned to the largest of these values.

the weighting for each pixel position is derived from the following expression, rn-dirn. if a pixel position in each of the channels has the same rank, the expression will tend to  <dig>  thereby the weight has minimal contribution to the co-localization coefficient. the further apart the ranks of the pixel position, the more the weight will tend to 1rn, and for extreme rank differences of which the maximum di can be rn- <dig>  the weight will be 1rn. the weight can range from 1rn to  <dig> corresponding to the maximum rank difference to the same rank, respectively. for an n-bit image, the maximum possible range is when all the grey levels are present in one of the two channels and this will range from 12n to  <dig>  the greater the number of grey levels present, the higher is the sensitivity and resolution of weighting. the sensitivity of weight depends on rn and the sensitivity can be reduced by modifying the weight to rn′-dirn′ where rn' is a linear algebra equation derived from rn such that rn' = rn + k*rn, and k can take values from  <dig> to  <dig> and correspond to weights ranging from 1rn to  <dig> for k =  <dig> and  <dig>  to  <dig> for k =  <dig>  the absolute difference between ranks ensures that the same weighting can be used for co-localizing pixel positions in both the channels and the weighting depends only on the difference of ranks. we envisage that this ranking approach could also be used for segmentation, for example to identify particular objects within an image based on a reference channel.

the weight represents the relative amount of co-localization and this can then be used for each pixel position to determine the degree of co-localization. rank-based weighting addresses the critical issues of difference in channel illumination, dual channel directional illumination, and uniform noise and gradient correlation, as the ranks are preserved even though the actual intensities might suffer degradation in all of these cases. this method demonstrates a statistically efficient meta-analysis approach of combining both pixel co-occurrence and intensity correlation to improve co-localization analysis.

synthetic data sets
in order to test our algorithm we first designed a series of synthetic data sets. a pair of 256* <dig> 8-bit images with pixel-sized objects was synthesized, having gaussian distributions with a mean value of  <dig> and a standard deviation of  <dig>  the correlation of the intensities of the overlapping pixels was then modified to generate a set of images having correlations ranging from r =  <dig> to r = + <dig>  this set of images, containing both varying levels of co-occurrence and correlation, were tested with manders, pearson and rwc co-localization algorithms. as shown in figure 1a, the manders' coefficient was insensitive to the correlation of the pixel intensities. similarly, as shown in figure 1b, the pearson correlation measurement was insensitive to co-occurring pixels and the response was skewed as a result of correlation seen in the non-co-occurring pixels. by contrast, the rwc approach was able to combine both co-occurrence and correlation information, thereby producing sensitive and meaningful co-localization coefficient .

in order to further validate the robustness of our algorithm we modified the synthetic data used in figure  <dig> to include random noise, having a normal distribution with standard deviation of  <dig>  we first compared the response of manders' and rwc coefficients in the presence of this noise . strikingly, when the images were not subjected to thresholding  the noise had a much greater effect on the manders' coefficients  compared to the rwc coefficients . although the dynamic range of the rwc coefficients was reduced, the coefficients observed still showed a linear response to varying degrees of co-occurrence. we next introduced a threshold  in order to potentially suppress the effect of the noise. these experiments revealed that the response curves of both the manders' and rwc co-localization coefficients returned to similar profiles to those shown in figure  <dig> , with the exception that at lower levels of correlation  the noise effect was still visible.

we next determined the influence of non-co-occurring  pixels on co-localization. as shown in figure  <dig>  the overall correlation can be negatively influenced by the presence of uncorrelated non-co-occurring pixels. using a scenario in which only 20% of the pixels co-occur , and where the correlation of the co-occurring pixels is 100% , the overall correlation  was found to be very low . although increasing the amount of co-occurring pixels to 40% and 60%  improves the overall correlation scores , the uncorrelated non-co-occurring pixels still severely distort the overall correlation value. for this reason, it is important to consider the correlation of only co-occurring pixels in isolation. indeed, when only co-occurring pixels were considered, the correlation was correctly determined  . it is also for this reason that a non-linear response was seen in figure 1b and 1c.

a second set of 512* <dig> 8-bit images  was next synthesized, with each image composed of a  <dig> segment sub-grid  each of different intensity . in these images black pixels were assigned a grey value of  <dig>  and white pixels a value of  <dig>  the first  segment in each image was assigned an intensity value of  <dig>  the next segment a value of  <dig>  progressively adding  <dig> grey levels to each segment such that the final  segment had an intensity of  <dig>  the original image was designated as 'channel a', and the rotation of this image sequentially by  <dig>   <dig> and  <dig> degrees was used to form the images for 'channel b'. using these data, four co-localization experiments were performed, allowing us to analyze the effect of pixel intensity distribution across pairs of images with respect to co-localization. the third column shows the costes' mask generated, based on the threshold set by costes' automated threshold algorithm  <cit> . in the mask, co-localized pixels above threshold are shown in white , and other pixels are shown as a merge of their corresponding lut, assigning channels a to red and b to green. the costes' automated thresholding was performed using the jacop plugin within imagej  <cit> .

applying the costes' mask to the data in figure  <dig> allowed us to determine that the proportion of pixels above the threshold was  <dig> %,  <dig> %, 0% and  <dig> % respectively in each of the co-localization experiments . we first analyzed the co-localization experiment in which the two channels were identical . as expected, applying costes' automated threshold resulted in  <dig> % of the pixels being discarded from the mask, however because the images were perfectly correlating, the co-localization coefficients  were correctly calculated at  <dig>  . by contrast, in co-localization experiments in which the intensities did not correlate , the majority of the pixels were discarded from the mask leading to incorrect co-localization coefficients. this was particularly striking in cases where there were pixels co-occurring in both channels, but anti-correlation of the intensities resulted in failure of the automated thresholding, in turn producing co-localization coefficients  of zero . this scenario is especially relevant in biological samples where two molecules could have anti-correlating intensities, despite co-occurring. applying the rwc algorithm to the synthetic data set in figure  <dig> produced more realistic co-localization coefficients. this was because the algorithm considers both co-occurrence  and correlation. even in the example of anti-correlating pixels, the rwc approach produces co-localization coefficients  of  <dig> , which are more representative of the intensity distribution . next we examined this synthetic data set without applying a threshold. strikingly, in all the four cases, the manders' algorithm always reported a co-localization coefficient of  <dig> , whereas rwc produced similar values to those observed when the images had been thresholded. this highlights that the application of the manders' algorithm always requires the application of careful thresholding, but that rwc is not sensitive to this requirement as it produces meaningful co-localization coefficients in the absence of thresholding. use of the rwc methodology therefore eliminates the need for thresholding, which can be a source of significant bias when analyzing image data.

as a final test of the algorithm we subjected this synthetic data set to varying degrees of random noise, with standard deviations of  <dig>   <dig> and  <dig> . although rwc takes account of pixel intensity, we observed that even in the presence of very high levels of noise , the effects on the co-localization coefficients were negligible when appropriately thresholded , except in the specific case of 100% co-occurrence and 100% correlation, where the coefficients became mildly distorted . this shows that rwc is comparable to existing co-localization methods in terms of its response to image noise.

biological data sets
we next tested our co-localization algorithm on biological data. in the cellular context it is essential that we are able to discriminate the localization of proteins between different cellular components. this is particularly important with respect to membrane-bounded compartments, which occupy a significant volume within cells, can be very closely opposed to one another, but which carry out very different functions. in order to test the sensitivity of our algorithm we first probed cultured hela cells with a primary antibody directed against the mitochondrial chaperone hsp <dig>  we then used a cocktail of two fluorescently labeled  secondary antibodies to detect the primary antibody, and thereby produce a two channel image in which the same subcellular structures were labeled with two different fluorophores. confocal imaging of these immunostained cells revealed, as expected, a very high degree of apparent co-localization between the two colour channels . on application of the manders' and costes' algorithms we determined that the co-localization coefficients were on average  <dig>  and  <dig> , respectively. by contrast, analysis of the same image set using the rwc algorithm revealed a lower average co-localization coefficient of  <dig> . closer examination of the images revealed that the two secondary antibodies did not in fact evenly decorate the primary antibody, and it was possible to discern specific membrane elements that were more strongly labeled with either the alexa <dig> or alexa <dig> antibodies . these results indicate that as a consequence of the rwc algorithm considering the pixel intensity at each position within an image, it is able to discriminate very subtle differences between localization profiles.

we next performed a co-localization experiment with two different primary antibodies that recognize different membranes within the cell, specifically the chaperone hsp <dig> representing the mitochondria, and the putative cargo receptor tgn <dig> that has a steady-state localization at the trans-golgi network   <cit> . confocal microscopy analysis revealed that both the manders' and rwc algorithms could accurately discriminate these different membranes and produce low co-localization coefficients . by contrast the co-localization coefficient determined by the costes' algorithm performed very poorly, most likely as a result of the way it determines thresholds based on intensity correlations.

rather than considering individual pixel intensities within an image, an alternative method of probing co-localization is to use object-based analysis  <cit> . this approach relies on the ability to discriminate and segment defined objects . typically the centroid of each object is used as a reference point for comparison between the channels, and the number of co-localizing objects, as a fraction of the total number of objects detected, defines the degree of co-localization. we applied such a method to our hsp60-tgn <dig> biological data  using the jacop plugin within imagej  <cit> . applying the same thresholds as used previously, this analysis revealed vastly differing co-localization values for the same set of images, depending on the minimum pixel size used to determine objects. for example, at a minimum value of  <dig> pixels,  <dig> tgn <dig> objects were identified, of which only  <dig> co-localized with hsp <dig> . however, increasing the minimum pixel size to  <dig> pixels, resulted in the detection of only  <dig> discrete objects, of which only  <dig> co-localized with hsp <dig>  the consequence of this large discrepancy in the numbers of objects identified resulted in an overall change in object-based co-localization co-efficient from  <dig>  to  <dig>  for the test set of images analyzed. this indicates that while object-based co-localization methods can produce coefficients similar to co-occurrence methods, they are wholly dependent on the object segmentation and identification parameters given by the user. moreover, the pixel intensity information is only used in the segmentation process rather than for quantification of co-localization, meaning that this valuable information is effectively discarded.

finally we sought to test our algorithm in the context of a well established cellular assay that traditionally has required a biochemical approach for evaluation. within cells the secretory pathway serves to transport proteins and lipids from their site of synthesis in the endoplasmic reticulum , through the golgi complex, ultimately out to the endosomal/lysosomal system or the cell surface. characterization of the initial steps in this pathway  has largely been studied by following the change in glycosylation pattern of a temperature-sensitive viral glycoprotein   <cit>  as it tracks through these compartments  <cit> . imaging approaches to follow this model cargo molecule in living cells were first described in the late 1990s  <cit> , however to date no quantitative co-localization-based approach to follow ts045g through the early secretory pathway has been reported. we therefore transfected hela cells with plasmids encoding a fusion of ts045g with the cyan fluorescent protein , and accumulated this cargo in the er before releasing a wave of it into the secretory pathway. we then fixed cells at various time points after er release, and carried out immunostainings with antibodies targeting the cis-golgi marker gm <dig> or the tgn marker p <dig>  confocal images from each time point of the assay were acquired , and rwc analysis was applied to determine the co-localization profile of ts045g with the cis- and trans-golgi markers . rwc co-localization analysis revealed a peak in co-localization of ts045g with the cis-marker after  <dig> minutes, followed by a peak with the trans-marker after  <dig> minutes . visual inspection of the images also revealed that the majority of ts045g had exited the golgi complex after  <dig> minutes, and this was in good agreement with the low rwc coefficient determined at this time point. overall, the kinetics of ts045g transit through the early secretory pathway, as measured by co-localization analysis, was extremely similar to that determined by biochemical techniques. the results from this assay clearly demonstrate the sensitivity of the rwc algorithm, as it was successfully able to discriminate co-localization at the entry and exit faces of a single organelle. of particular interest are the time points  <dig> minutes and  <dig> minutes after ts045g release from the er. at  <dig> minutes the majority of ts045g had arrived at the cis-face of the golgi complex , but after this time the rwc algorithm was able to detect loss of the cargo from this side of the golgi complex and accumulation at the trans-face of the organelle . these measurements clearly demonstrate that this algorithm has the capacity to detect relatively small spatial changes in the distribution of proteins across a compact structure such as the golgi complex. furthermore, a co-localization-based approach not only has the advantage of being easier to perform than the equivalent biochemical technique, but also it provides quantitative data at a single cell level, therefore potentially making it suitable for high-throughput approaches.

CONCLUSIONS
in this work we present a novel tool to precisely quantify co-localization between structures within biological images. although a number of co-localization algorithms have been described previously, this is the first example of such a tool that takes account of both co-occurrence and correlation of pixels, combining them efficiently to produce a meaningful coefficient value. we demonstrate in this work, using both synthetic and biological data sets, that this algorithm is a robust tool that works effectively across a very wide range of situations, and that it eliminates the need for manual thresholding of images, which is a well established cause of error in co-localization analyses. we envisage that this tool will facilitate the quantitative analysis of a wide range of biological data sets, including high resolution confocal images, live cell time-lapse recordings, and high-throughput screening data sets.

