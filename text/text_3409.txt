BACKGROUND
microarrays are one of the latest breakthroughs in experimental molecular biology. they allow to simultaneously monitoring the expression level of tens of thousands of genes. arrays coupled with pattern recognition methods have been applied to studies in gene expression, genome mapping, transcription factor activity, toxicity, pathogen identification, and many other applications  <cit> 

however, although in standard classification problems one has to classify a sample and assign it to one of a set of known classes, in a clinical diagnostics setup in which some classes  may be known but novel unknown classes  may appear as well, one must be able to reject those samples that do not fit the trained model.

in this paper, we present a set of empirical decision rules designed to implement a rejection option in a set of multi-class classifiers widely used for the analysis of gene expression profiles. in particular, we will focus on the r language and environment for statistical computing   <cit> .

the problem of implementing a rejection option in a multi-class classifier has not been widely addressed in the statistical literature with the exception of a few publications  <cit> . chow  <cit>  put forth the decision theoretic framework to rejection in pattern recognition. the overall idea is to estimate the class conditional probabilities for a sample and to reject it if the maximum probability is below a given threshold. this simple rejection rule is optimal when the class conditional probabilities can be estimated without errors, which is in contrast with several real setups  <cit> . gene expression profiles suffer from the curse of dimensionality problem  <cit>  that negatively reflects on the reliability of probability estimators. the number of available classes and the correct setup of the threshold are additional constraints that limit the reliability of this approach. an attempt to setup per-class thresholds has been proposed by fumera et al.  <cit>  to mitigate errors in probability estimation. however, the computational effort and the complexity of tuning the resulting classification system increases, limiting a widespread application in laboratory setups. recently, one-class classifiers gained attention in the implementation of rejection systems in gene expression profiles  <cit> . these algorithms base the prediction model on the concept of distance among samples rather than on the estimation of class conditional probabilities. they therefore overcome the limited reliability of available class probability estimators. however, increased number of classes, high dimensionality feature spaces such as the one of microarray datasets, noisy features, and quite often not enough samples, still limit their accuracy.

in this paper we will build a set of rejection rules able to work with the very simple and often unreliable class probability estimators provided with the multi-class classifiers implemented in r . the main contribution of the proposed rules is their simplicity. it makes possible an easy integration with available data analysis environments while maintaining, at the same time, good classification performance. since in the definition of a rejection model tuning of the involved parameters is often a complex and delicate task, in this paper we exploit an evolutionary strategy to automate this process. this allows the final user to maximize the rejection accuracy with minimum manual intervention.

a complete experimental setup is presented to validate the proposed model on a challenging data-set of blood diseases. a set of three multi-class classifiers widely adopted in the analysis of gene expression profiles which are also available in r has been considered. results are compared to those obtained building rejection options based on one-class classifiers  <cit> . results show that the proposed decision rules can be efficiently used as a powerful rejection method, outperforming most of the considered one-class classifiers.

RESULTS
experimental setup
the results of this paper have been validated on a dataset of gene expression profiles from complementary dna  microarrays related to very similar phenotypes. only a reduced subset of genes allows for discrimination . this peculiarity increases the complexity of the classification allowing us to better validate the proposed method. it is worth mentioning here that, in all experiments, the training-set does not include any sample from the test-set. this is a given requirement to avoid overoptimistic results and therefore to honestly evaluate the classifiers performances.

the table reports the acronym of each phenotype and the related number of samples.

the data-set includes a total of  <dig> phenotypes. samples have been downloaded from the cdna stanford microarray database  <cit> . all genes without a valid unigeneid have been discarded. the expression level of each gene is measured as the log-ratio between the cy <dig> and the cy <dig> channel of the array: .

four sets of samples have been downloaded from a large set of experiments aiming at performing lym-phoma classification  <cit> :

• diffuse large b-cell lymphoma : a non-hodgkin lymphoma disease,

• b-cell chronic lymphocytic leukemia wait&watch ,

• b-cell chronic lymphocytic leukemia , and

• follicular lymphoma : independent lymphonode samples on lymphochip microarrays  <cit> .

the remaining three phenotypes in the data-set are:

• acute lymphoblastic leukemia ,

• core binding factor acute myeloid leukemia : subgroups characterized by shorter overall survival  <cit> ,

• acute myeloid leukemia  <dig> data-set : peripheral-blood samples or bone marrow samples of intermediate-risk aml with a normal karyotype.

three multi-class classifiers often used in gene expression profile analysis have been considered in this study: k–nearest neighbors , feed-forward neural network with a single hidden layer , and random forests . all algorithms are available in r. a detailed description of how data have been processed and how the prediction models for the different classifiers have been trained is available in the methods section.

class probability estimates analysis and decision rules
the process of detecting samples to reject in a multi-class classification system can be modeled as a binary classification test discriminating between samples that belong to one of the known classes  and samples that do not belong to any of them . the outcome of the test is measured in terms of:

• true positives : target samples correctly accepted,

• true negatives : reject samples correctly rejected,

• false positives : reject samples erroneously accepted, and

• false negatives : target samples erroneously rejected.

the number of tp, tn, fp, and fn adds up to 100% of the data-set. the accuracy in which target samples are assigned to the corresponding class is out of the scope of this work and depends on the accuracy of the selected multi-class classifier.

the multi-class classifiers considered in this paper  do not natively implement a rejection option. discarding reject samples by setting a single threshold on the class probability estimates is inaccurate since class probability estimates show small differences between target and reject samples . however, this information can still be used for discrimination if coupled with well tuned decision rules.

in order to perform a preliminary qualitative analysis of how class probability estimates change between target and reject samples, we performed a set of multi-class classification experiments generating different splits of the considered data-set . for each split, the multi-class classifiers have been trained on a subset of the considered phenotypes, using the remaining data as a set of samples to reject. figure  <dig> reports, for each classifier, two density plots that show how the value of class probability estimates of target and reject samples distribute in the performed experiments. in the max plot the considered random variable is the highest class probability estimate of each classified sample, split into target samples  and reject samples ; in the diff plot the considered random variable is the difference between the two highest probability estimates of each sample, again considering target and reject samples. the density functions have been estimated from the experimental data by performing a gaussian kernel density estimation using the density() command of r.

although the plots of figure  <dig> may seem to suggest a strong overlap between the distributions of target samples  and reject samples , a certain amount of separation is still visible. this is particularly evident in the case of rf, that shows a quite visible distinction both in the max and in the diff plots. in particular, in the diff plot of rf, target samples  have a max around  <dig> , far from the max of reject samples  that falls around  <dig> . this means that, for a target sample, the difference between the two top rated classes is very high . instead, reject samples show a very low difference between probability estimates of the two top ranked classes, revealing the inability of the classifier to clearly select a target class. k-nn and n-net show smaller separation; however, experimental results will show that a partial discrimination is still possible.

from this preliminary analysis, it seems reasonable that, for the three considered classifiers, the class probability estimates provided by r could potentially be used for detecting reject samples. the idea exploited in this paper to design a set of decision rules for detecting reject samples is to split the max plot into three distinct areas:  max area,  decision area, and  reject area, delimited by two rejection thresholds tmax and trej , as shown in figure  <dig> for rf.

if the highest class probability estimate  is lower than trej, then the sample falls in the reject area and is rejected to maximize the number of tn . similarly, if max <dig> is higher than tmax, the sample falls in the max area and can be accepted to maximize the number of tp. the class with probability estimate equal to max <dig> is predicted . the first part of this decision process is very similar to the single threshold method proposed in  <cit> .

whenever neither r <dig> or r <dig> are satisfied, i.e., max <dig> falls between trej and tmax  there are two possible conditions based on the analysis of the difference between max <dig> and max <dig> :

 <dig>  if max <dig> – max <dig> >tdiff, the sample can be accepted and the class with probability estimate equal to max <dig> is predicted . tdiff is the minimum difference between the probability estimates of the two top ranked classes that allows us to use max <dig> to perform a reliable classification;

 <dig>  if max <dig> – max <dig> <tdiff , the value of max <dig> is considered. two cases are possible:

• if max <dig> is higher than trej, i.e., both max <dig> and max <dig> fall in the decision area, the prediction is considered uncertain . in this case the classifier does not produce any classification result. this rule prevents from providing a result when the distinction between two classes is not sufficient to correctly discriminate. in alternative, multiple classification results can be provided to alert the user that the confidence in the prediction is low;

• if max <dig> is lower than trej, the sample is rejected . this rule mitigates the noise in those samples that fall at the border of the reject area.

the three rejection thresholds  can be empirically chosen analyzing the density plots of figure 2:

• if the max plot shows a clear separation between target and reject samples, tmax can be placed in such a way to maximize the number of tp immediately detected by rule r2;

• similarly to tmax, trej can be placed to maximize the number of tn detected by rule r1;

• the definition of tdiff is performed looking at the diff plot. a good heuristic is to consider the point where the two curves intersect.

manually setting the three thresholds is very complex and may easily lead to a high error rate. when the plots do not show a clear separation between target and reject samples, the choice of the thresholds involves a trade-off between increasing the sensitivity, and lowering the specificity of the classifier. this is a complex optimization task.

all thresholds must be setup only considering information extracted from the considered training data. to tackle the complexity of this process, and to allow the automatic tuning of all rejection parameters, a threshold setup algorithm based on a covariance matrix adaptation evolutionary strategy  has been developed. the full description of this algorithm is available in the methods section.

architecture of the multi-class classifier with rejection option
the proposed decision rules can be easily integrated within the multi-class classification flow provided by r or other similar computational environments. figure  <dig> shows the computational flow of the resulting system. as usual when working with classification algorithms, a training set containing known samples is used to train the prediction model then used to classify a set of test  samples.

compared to a traditional multi-class classification flow, the proposed system includes two additional modules required to: 1) setup the rejection thresholds, and 2) apply the decision rules.

setting up the rejection thresholds requires collecting a statistically significant set of class probability estimates for both target and reject samples on which to compute the density plots of figure  <dig>  at this stage, in which the model is trained and real reject samples are not available, this information can only be collected starting from samples in the training set by setting up several cross-validation experiments on different folds of these training data. figure  <dig> outlines the way this module operates. let us denote with t the full training set and with ti a portion of it including only those samples related to a specific phenotype. if k classes are included in t, k subsets of experiments are generated by iteratively excluding one of the classes ti from t to form a new target class t′. the removed samples are used as a set of reject samples denoted with r .

for each subset , m folds are generated by removing x samples from each subclass contained in t′, and x samples from r. each fold will therefore generate a test-set  of x ·  target samples , and x reject samples. to avoid overoptimistic results, target samples of the test-set are removed from t′ forming a new training set train* . each fold is then used for an independent multi-class classification experiment to obtain the class probability estimates of each test sample in test*. after running all k · m experiments, the cma-es analyzes the collected probability estimates and provides a set of optimal thresholds .

validation and discussion
the proposed rejection rules have been tested on different groups of experiments based on different configurations of the considered data-set in terms of target and reject samples. the rejection accuracy has been compared with the one of a set of selected one-class classifiers. five one-class classification algorithms have been considered in this comparison:

• parzen one-class classifier ,

• k-nn one-class classifier ,

• k-means one-class classifier ,

• principal component analysis  one-class classifier , and

• svdd, a svm based one-class classifier .

all one-class classifiers have been implemented and optimized using matlab’s dd_tools  <cit> , a standard implementation used in several publications on microarray analysis  <cit> .

two methods of using one-class classifiers have been considered. let us suppose to have a target class including k different subclasses . the one-class classification problem can be solved by training either k different one-class classifiers  with samples rejected if rejected by all classifiers, or a single one-class classifier trained with samples of all k subclasses. the first approach will be referred to as multi one-class with voting  while the second approach will be referred to as single one-class with multiple targets .

four groups of experiments each denoted as gk  have been generated. in the group gk the target class includes k out of the  <dig> available phenotypes. samples in the remaining  <dig> – k classes must be rejected. for each group different random combinations of the k classes included in the target profile are considered and for each combination several random splits of data into test- and training-set are generated for a total amount of  <dig> experiments for each group. for all experiments, the test-set includes a balanced number of target and reject samples.

for each experiment data are classified with mocv, socmt, and the three considered multi-class classifiers paired with the decision rules presented in this paper. rejection thresholds have been automatically computed according to the process described in figure  <dig> 

for each group of experiments results are provided in terms of average sensitivity  and specificity  with the related confidence intervals . confidence intervals are computed with 95% loc.

results are provided in terms of improvement of the accuracy of multi-class classifiers with decision rules versus one-class classifiers.

a final confirmation of the improvement introduced by the presented approach can be appreciated in the receiver operating characteristic  curves of figure  <dig>  for each group of experiments the related roc curve compares the average performance of the three multi-class classifiers coupled with the decision rules and the two best one-class classifiers . in the case of multi-class classifiers the roc curve is plotted by changing the value of the three rejection thresholds in order to explore as much as possible the space of possible solutions, while, in the case of one-class classifiers, it is obtained by changing the considered rejection rate. in all experiments rf improves the accuracy of the one-class classifiers while k-nn and n-net provide an accuracy that is comparable to those of one-class classifiers. this result is obtained using a very simple computational model compared to the one required to setup a one-class classification model.

all proposed results have been obtained by computing the rejection thresholds using the cma-es with the ss <dig> objective function . the diagram of figure  <dig> shows the average accuracy obtained during the cross-validation experiment used to setup the rejection thresholds. proposed results are for rf coupled with the rejection rules considering the different cma-es objective functions. the dashed diagonal lines represent iso-accuracy lines, with accuracy that decreases from the top-left corner to the bottom-right corner. the graph shows that the three functions ss, ss <dig>  and ss <dig> provide the better accuracy with ss <dig> providing the best results.

the value of the objective function associated with the thresholds computed by the cma-es can be used as an indicator of the reliability of the trained model. whenever an objective function is equal to  <dig>  it means perfect discrimination among target samples and reject samples. values greater than  <dig> indicate reduced accuracy. this is confirmed by the results of table  <dig>  it reports for each classifier and for each group of experiments the average accuracy and the average value of the ss <dig> objective function associated with the computed thresholds. the numbers clearly show how rf, that is the one with better accuracy, has a lower value of the objective function compared k-nn and n-net, thus suggesting a more reliable model.

the value of the objective function is used as an indicator of the reliability of the trained model.

CONCLUSIONS
life sciences are undergoing a true revolution as a result of the emergence and growing impact of a series of new disciplines/tools including genomics, transcriptomics, proteomics and metabolomics. these new disciplines are devoted to the examination of the entire systems of genes, transcripts, proteins and metabolites present in a given cell or tissue type. new technologies allow now to collect huge amounts of data dramatically modifying the way scientific research is carried out. the focus is shifting from the study of ”isolated realities” to the understanding of whole biological systems and the interactions between the huge number of their individual components. from the beginning of this revolution, machine learning immediately appeared as a natural tool for sorting, analyzing, and extracting useful information from these large amounts of data. unfortunately, some peculiar characteristics of biological data, such as the large number of variables and the low number of samples, challenged even the most robust machine learning algorithms, especially when considering their use in a real clinical setup. this paper shows how the use of simple decision rules can be used to add to state-of-the-art multi-class classifiers a rejection option able to discard samples that do not belong to any of the trained classes. traditionally, this operation is performed by other rejection methods, like one-class classifiers, which do not perform very well on microarray data. the proposed solution has several advantages:

• it can be easily plugged into an environment widely spread in several research groups;

• it is simple and does not require high computational resources;

• in general it performs better than other available solutions such as those based on one-class classifiers;

• it automatically tunes all parameters for the rejection model, requiring minimum intervention from the user.

