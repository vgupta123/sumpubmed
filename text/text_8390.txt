BACKGROUND
genomic dna copy number is often variable. some of this variability, commonly referred as copy number variations or cnvs, is naturally present in the germ line and thus heritable  <cit> , whereas somatic, large-scale alterations that often characterize tumor cells are called copy number alterations or copy number aberrations   <cit> . these cnas are often longer than cnvs and have been linked to other diseases in addition to cancer, such as hiv acquisition and progression, autoimmune diseases, and alzheimer and parkinson's disease  <cit> . the most popular current approaches for the identification of dna copy number differences are chip- or array-based. these include snp arrays  <cit>  and array-based comparative genomic hybridization . acgh is a broad term that encompasses oligonucleotide acgh , bac and, less frequently nowadays, roma and cdna arrays  <cit> . in addition to the array-based technologies, sequencing-based approaches  <cit>  are also used to study cnas. . location of cnas in individual samples, however, is only the initial step in the search for "interesting genes". the regions more likely to harbor disease-critical genes are those that show alterations that are recurrent among diseased individuals  <cit> . in this context, we can define a recurrent cna region as a set of contiguous genes  that shows a high enough probability  of being altered  in at least some samples or arrays. unfortunately, although many methods exist for analyzing a single array , few papers deal with the problem of integrating several samples and finding cna regions that are common over sets of samples. thus, merging data from several samples to find recurrent cna regions remains a challenge  <cit> , both methodologically and conceptually.

two recent reviews  <cit>  highlight the main features and difficulties of existing methods. most methods  <cit>  try to find recurrent cna regions using, as starting point, the discrete output from an acgh segmentation algorithm in the form of the classification of every probe into gained, normal or lost. because these methods use discretized output, they discard any available estimate of the uncertainty of these estimates; as a consequence, a gain for which there is strong evidence will have the same weight in subsequent calculations as another gain for which there is less certainty. moreover, the majority of these methods ignore within- and among-array variability in acgh ratios as they use a common threshold for all probes and arrays. a few other methods perform the segmentation and search for recurrent cna regions in the same step  <cit> . the method in  <cit> , which does not use nor returns probabilities, employs elaborate and heuristic approaches to search over possible thresholds and adjustments for multiple testing. another two methods,  <cit> , intertwine, in a complex way, biological assumptions and statistical procedures, leading to convoluted, heuristically based methods, with critical assumptions and parameters of difficult interpretation and assessment . in  <cit>  copy numbers of contiguous probes as treated as independent, which is clearly biologically unrealistic. hidden markov models are used by  <cit> , but this method seems to locate recurrent probes, not recurrent regions, and the number of states is restricted to four; therefore, all the gains are grouped into a single state with a common mean, which is biologically unreasonable, and makes it impossible to differentiate between samples with moderate amplitude changes and large-amplitude changes.

in addition to the above difficulties, one the most serious problems of existing methods is the inability to find common regions over subset of samples. the majority of approaches  <cit>  try to find regions that are common to all the arrays in the sample. thus, these methods presuppose that a disease is homogeneous with respect to the pattern of cnas. it is known, however, that for many complex diseases, such as cancer or autism  <cit> , molecular subphenotypes are common. it follows that heterogeneity should be appropriately addressed  <cit>  in studies of recurrent cna regions. two methods  <cit>   try to find recurrent regions defined over a subset of the samples but, in addition to not using probabilities, they depend on a resolution  parameter that controls the number of probes considered within region, so that, given this parameter, the method, by construction, will regard either all or none of the probes as jointly altered. but the point of searching for regions is, precisely, to identify regions for which we do not know in advance location, number of subjects, or length. moreover, there are concerns  <cit>  about the permutation strategy used by the above two methods to assess the statistical significance of the patterns found, as it precludes locating large aberrations. therefore, there are currently no satisfactory approaches for addressing among-sample heterogeneity.

to further clarify and understand this problem, we can differentiate between two different scenarios. in one scenario, we consider all the samples  in the study as a homogeneous set of individuals, so we want to focus on the major, salient, patterns in the data and thus we will try to locate regions of the genome that present a constant alteration over all  the samples. this is what most existing methods for the study of recurrent cna regions try to do. in a second scenario, we suspect that the subjects are a heterogeneous group. what we really want here is to identify clusters or subgroups of samples that share regions of the genome that present a constant alteration. in other words, we want to detect recurrent alterations in subtypes of samples when we do not know in advance which are these recurrent alterations nor the subtypes of samples. this second scenario is arguably much more common than the first one in many of the diseases where cna studies are being conducted. in this second scenario, using an algorithm appropriate for the first scenario  is clearly inappropriate: it does not answer the underlying biological question, risks missing relevant signals, and leads to conceptual confusion.

existing methods, therefore, have serious limitations and it is necessary to develop new approaches that fulfill the following three major requirements. first, we want to explicitly differentiate between the two scenarios in the last paragraph. as a consequence, we want to be able to locate either regions common to most of the arrays or regions common to only a subset of the arrays. second, we want to preserve the uncertainty in the state of a probe , and we want to return probabilities, as a probability is the single most direct answer to the question "is this region altered over this set of arrays?" . third, we want that the biological meaning of the regions found be immediate, which we can try to achieve by using methods that depend on few parameters of straightforward interpretation. we have developed two approaches that fulfill these criteria.

RESULTS
two different approaches for finding recurrent cna regions
here we provide an intuitive understanding of our two different approaches. further details are provided below.

our first method, prec-a , finds those regions that, over the complete set of arrays, show an average  probability of being altered that is above a predefined threshold. when using prec-a we only need to provide one threshold, pa, the minimal probability of alteration of a region over a set of arrays. pa is chosen by the researcher, but generally cannot be too stringent  because even with a large number of arrays, only a few arrays without that alteration will prevent finding the region .

our second method, prec-s , identifies all common regions over subsets of arrays; alternatively, we can think of this algorithm as identifying subsets of arrays that share regions of alteration. the regions of alteration found might not be common to most arrays, but within each array in the identified subset, the regions of alteration will have a probability of being altered above a threshold . when using prec-s, therefore, the user needs to provide two thresholds, pw, the minimal probability of alteration of a region in every array in the selected subset, and freq.array, the smallest number of arrays  that share a common region. here we will often use more stringent thresholds for probability , because those high probabilities might be attained over a highly homogeneous and small subset of arrays. we can use the output of prec-s as the basis for clustering and to display patterns of groupings of arrays; an example is shown below .

for both methods, we will use probabilities of alteration as returned, for example, by rjacgh  <cit> . rjacgh is a hidden markov model-based approach that returns probabilities of alteration of probes and segments; no hard thresholds are imposed, and thus the user decides what constituted sufficient evidence  to call a probe gained . we have shown  <cit>  that rjacgh performs as well as, or better than, competing methods in terms of calling gains and losses, and the relative advantage of the method increases as the variability in distance between probes increases. it is essential to understand that the probabilities that we use are not the marginal probabilities of alteration but the joint probabilities of alteration of a region of probes . our approach incorporates both within-and among-array variability : we use the information on the certainty of each call of gain/loss  in all computations of recurrent cna regions. therefore, our approach is qualitatively different from using the same threshold over all probes and arrays. see further details below. moreover, using probabilities of alteration , in addition to differentiating between evidence of alteration and estimated fold change, prevents inter-array differences in range of log <dig> ratios and tissue mixture to get confounded with evidence of alteration. finally, note that we use at most two parameters and that their biological meaning is immediate: probability of alteration, and number of samples that share an alteration .

algorithms
before we can develop algorithms for the two approaches, prec-a and prec-s, we will need to develop methodology that will allow us to: 1) compute the joint probability of alteration of an arbitrary sequence of probes; 2) combine that probability over arrays. the first two parts of this section detail this machinery before showing the details of the algorithms. for the rest of this section, please bear in mind that we are always referring to probabilities of alteration, and never to p-values. we are working on a bayesian framework and are estimating posterior probabilities; we are not conducting hypothesis tests.

computation of the joint probability of an arbitrary sequence of probes in an array
to find altered regions, that is, sets of contiguous probes, we have to compute the joint probability of alteration for a sequence of probes. in other words, we need to compute, for each array i =  <dig> ... r, the probability that a subset of consecutive probes is, for example, gained . that is, if we denote as si the state of probe i and with  <dig> the state 'gain', we are interested in p for a subset of contiguous p probes.  also for the case of non-contiguous probes, but this scenario is unlikely to be of any interest in the search for recurrent cna regions.)

using rjacgh  we can compute the probability for every probe to belong to any of the states of gain and to any of the states of loss. the problem of these probabilities is that they are marginal probabilities: they are the probability of the event of an alteration of a probe without considering the alteration of other probes, in particular of neighboring probes. but the states of the probes are not independent  <cit> , and thus the probability of alteration of a region  can not be computed simply as the product of the probability of the individual probes.

with hmm it is customary to obtain the most likely path of hidden states using the viterbi algorithm which returns the maximum a posteriori sequence . the viterbi algorithm, however, does not return any distributional statements about the states of the path  <cit> . it is straightforward, however, to compute the marginal probabilities of the state of a probe or the joint probabilities of an arbitrary sequence of probes, because the sequence of hidden states conditioned on the parameters of the hmm is a markov chain  <cit> . for instance, we could compute the probability that the first three probes are jointly gained: p using straightforward conditional probabilities as ppp, and these conditional probabilities can be computed by backward-smoothing. the problem is that the classification of probes or regions into states given by these two approaches  does not always coincide, leading to inconsistencies. for example, we might obtain a sequence of hidden states with maximum marginal probabilities that is not the same as we obtain with viterbi; that sequence might even contain two consecutive altered probes that can not be jointly altered  <cit> . this is a common problem that can arise when using maximum likelihood approaches to hmm.

to avoid these problems, we can use, as rjacgh does, markov chain monte carlo  instead of maximum likelihood . with mcmc, however, we can not average the conditional probabilities obtained through the mcmc iterations, because that would break the markovian property  <cit> , as we are averaging over different runs with  different values for the model parameters . for instance, suppose we want to compute the probability that the first three probes are jointly gained: p. we cannot compute ppp, with those conditional probabilities obtained by averaging over the multiple mcmc runs. what we can do, instead, is compute the probability of an alteration for any arbitrary sequence as the frequency of that sequence being altered in the maps from each of the mcmc draws. for the previous example, we would count in how many maps  we found s <dig> = s <dig> = s <dig> =  <dig>  we must note that, in this case, we are not obtaining the real distribution of the hidden states per se, but the distribution of the hidden states as members of the maximum a posteriori hidden sequence  <cit> . that is, we do not sample from the distribution of the hidden states, but from the distribution of the map. this is coherent with the classification method used with just one array, as every sequence is only accounted for if it has been part of the map sequence, and thus this is a stronger requirement as the regions obtained have always been part of the map.

finally, the above scheme can be applied both to models that assign to hidden states probabilities of being altered of either  <dig> or  <dig>  and to models that assign to hidden states probabilities of being altered between  <dig> and  <dig> 

combining regions over arrays
once we have computed the probability that the above region is altered, for our first algorithm, prec-a, we need to know how to average over the arrays to get a probability of alteration for that region over a set of arrays. many hmm models  will model each array with a different hmm, to reflect the fact that they can have different characteristics, such as dispersion. thus, for each array, we have a  stochastic process for the log-ratios. once the data are summarized as states , however, they are comparable across arrays as we are using the same approach to label probes as gained/lost/not-changed. in other words, a value of sj =  <dig> has the same meaning regardless of the array. thus, we can average directly all the probabilities for every array . therefore, the probability that a given region of the genome is altered over a set of arrays is computed as:

   

where different p allow us to use different weights for different arrays  are scaled, if needed, so that ∑j p = 1).

for notational convenience, when there is only one probe, we define

   

prec-a: finding regions with a probability of alteration of at least pa
the following algorithm  finds all the regions with an average  probability of alteration of at least pa. this algorithm is the one that is most similar to other existing approaches in objective. notice, however, the simplicity of our algorithm, and the straightforward interpretation of its parameters. a detailed explanation of each line of the algorithm and its logic is provided in the additional file  <dig> 

prec-s: finding all the regions shared by at least freq.array arrays where each region in each array has a probability of at least pw
in this algorithm  we are imposing two thresholds: 1) pw, the minimum joint probability, within array, for each region; 2) freq.arrays, the minimum number of arrays that share the alteration. notice that pw in this algorithm is different from pa in the previous algorithm . this algorithm has no equivalent in alternative methods. a detailed explanation of each line of the algorithm and its logic is provided in the additional file  <dig> 

simple numerical example: prec-a
suppose we have fit a model to six probes and four arrays and, after using rjacgh's model averaging, we have obtained the marginal probabilities of gain shown in table  <dig>  we want to use prec-a with pa =  <dig> . first, we average the probability for probe  <dig> for the four arrays:

marginal probabilities of being gained.

  

as it does not reach the threshold of  <dig> , s <dig> can not belong to a region. we do the same for s <dig>  obtaining  <dig> . for s <dig> the averaged probability is  <dig> , so the first region will include this probe. to see if we can extend this region to the next probe, we compute for every array the joint probability of probes  <dig> to  <dig> to be gained. this probability is not shown in the table above  but is obtained as explained above : the relative frequency of a sequence in the maps from all the mcmc samples.

  

as it is over the threshold, we join s <dig> to the region.

now we check if s <dig> can be joined too. we compute the joint probability of gain for the probes  <dig> to  <dig> :

  

as it does not reach  <dig> , s <dig> will not be part of the region, so we get:

region 1: {}.

now we keep on searching from probe  <dig>  s <dig> does not have a marginal probability higher than the threshold, so it will not form any region. but s <dig> will:

  

so it will form its own region. as there are no more probes, the regions found are {, }.

boundaries of regions are forced to be common over all arrays: the algorithm finds the common regions. for instance, the left boundary of the first region of gain of sample a <dig> is located in probes s <dig>  whereas the boundary for all the other three samples is located in s <dig>  thus, s <dig> is excluded from the first common region: a region that spanned {} would not reach, over all four arrays, the required pa =  <dig> .

simple numerical example: prec-s
we use the same data as above. we want to find all regions where at least two arrays have a joint probability of gain of at least  <dig>  . in other words, we are using prec-s with freq.arrays =  <dig> and pw =  <dig> . line numbers below refer to the lines in the algorithm.

we start on s <dig>  but there is no array that reaches the threshold of  <dig>  for that probe . we iterate  to the next probe, s <dig>  but the threshold is reached only in array  <dig>  and we imposed that there should be at least  <dig> arrays. thus, condition in line  <dig> is not met. we iterate to the next probe, s <dig>  here, when we iterate over all the arrays  we find all of the arrays reach the threshold, so in line  <dig> we end up with setarrays_a = . as the condition in line  <dig> is fulfilled we try to increase the region by one probe: we set end to s <dig>  and enter the "while" loop  as we are not yet at the end of the total number of probes.

after looping over all four arrays  we find that line  <dig> is only fulfilled for arrays  <dig>   <dig> and 4:

  

note that the last expression is obvious since p =  <dig> .

therefore  we have setarrays_b = . we still fulfill the condition about freq.arrays in line  <dig>  but the new set of arrays contains fewer than before  which means that in the step before a region was found. we call updateregions so that the region , ) is stored, and we set setarrays_a =  . we increase end to s <dig> , and consider it as the end of the new possible region. iterating again  we find

  

as above, this means that in the previous step we found a region . therefore, we call updateregions to store the region from the previous step: , ). we increase end to s <dig> and find

   

now, the condition in line  <dig> is true, because only one array satisfies being over pw. we break out of the while loop  and we updateregions in line  <dig>  so we store the region from the previous step:, ).

we continue iterating over start , so now start = s <dig>  repeating the steps above we would find a first region , ), and a second region , ). however, when executing updateregions, we would find each of these regions is a subset of a previously found region , ) of , ); , ) of , )).

when we iterate over start to start = s <dig>  we find only the region , ) which is again a subset of a previously found region.

finally, we set start = s <dig>  we find  that pw is satisfied by arrays a <dig>  a <dig>  a <dig>  so we end up with setarrays_a = . we fullfill the requirement about freq.arrays, but in line  <dig>  however, we find we are at the end of the total number of probes, so we do not enter that loop . we therefore call updateregions, and add the region , ). . therefore, we end up with the regions:

regions = {, ), , ), , ), , )}

we can see the regions obtained in figure  <dig>  in contrast to prec-a, boundaries need not be common over arrays; with prec-s differences in boundaries will lead to different subsets and different regions  includes only samples a <dig>  a <dig>  a <dig>  but not a3).

we can also use the output of this algorithm as the basis for clustering and to display patterns of groupings of arrays. we can measure similarity between two arrays as the number of common probes in recurrent cna regions between those two arrays or, alternatively, as the number of common regions  between two arrays. once similarity is measured, we can immediately apply any clustering method of our choice. an example is show in figure  <dig>  at this stage, clustering is mainly a device for representing patterns of similarity, since the grouping of arrays with respect to recurrent cnvs is the very output of the prec-s algorithm.

implementation and testing
the algorithms above are part of the freely available and open-source rjacgh r package , which uses r and c . for storage and efficiency reasons, we do not save directly all of the viterbi paths  but only the jumps in paths and the counts of different paths. this requires less storage, allows for faster access to the information and computation of the joint sequence, and of course permits reconstructing all of the sequences. the viterbi paths are obtained as part of the regular execution of the c code for rjacgh, saved in r as gzipped files, and read back by the c functions for prec-a and prec-s only once.

execution time in all the examples of the paper is negligible: all the examples of prec-a execute in less than  <dig> seconds. execution time for prec-s goes up to  <dig> seconds for the examples from  <cit>  but less than  <dig> seconds for the remaining examples. .

testing was carried out by comparing the output from the algorithms with manually computed examples. code for the examples and comparisons is included in the repository for the package .

examples with real data and comparison to other approaches
all the examples below were analysed with rjacgh, which provided the probabilities of alteration. our examples use acgh arrays because these are three "classic" sets of data that have been analyzed before with other approaches. our methods, however, can also be applied to other platforms, including custom and commercial oligonucleotide arrays and snp arrays  or any other platform for which we can obtain joint probabilities of alteration. the main objective of these examples is to illustrate the range of analysis that can be performed.

colorectal cancer example : direct application of prec-a
nakao et al.  <cit>  analyze  <dig> colorectal tumors. they apply a segmentation method based on a threshold and then find common regions of alteration studying the frequency of alterations. rouveirol et al.  <cit>  apply both of their algorithms for minimal common regions to the same data. as shown in the additional file  <dig>  using prec-a with a threshold of  <dig> , we find basically the same regions of alteration, and most of the reported differences come from regions with a probability  in the limit of 35%. the only remarkable case is the gain in 11q which has a much lower probability in our analysis, probably because that alteration is based on a single bac and the segmentation analysis used in  <cit>  is based on a threshold and therefore is more likely to be affected by outliers.

colorectal cancer example : comparing probability of alterations between groups using prec-a
prec-a can also be used to compare the probability of alteration between groups of samples. douglas et al.  <cit>  present data from  <dig> primary cancers. seven show microsatellity instability  and  <dig> show chromosomal instabillity . . they call alterations using a threshold-based method and compare their frequency between the two types using a chi-square statistic. van de wiel and van wieringen  <cit>  analize the same data using a dimension reduction technique  after segmenting the data with dnacopy  <cit> . they then use a wilcoxon test with fdr correction for the difference between the two levels.

we have used a threshold of pa =  <dig>  to find the common regions of gain/loss and have then compared the probability of alteration in those regions for the two groups of samples. we have obtained a total of  <dig> regions of gain and  <dig> of loss, shown in additional file  <dig> - figure s <dig>  next, for every region found above we computed the joint probability of alteration for each of the  <dig> arrays of class cin and the seven arrays of class msi and, by region, we calculated the absolute value of the difference in mean probability between the msi and cin groups. to assess the significance of this statistic, we used a permutation test  to obtain a two-sided p-value. then, we applied the fdr method  <cit>  for multiple testing correction . the regions found significantly different  between groups are listed in additional file  <dig> - table s <dig>  where we also provide further details about the differences with the results in  <cit>  and  <cit> . our results are largely coincident with those in  <cit>  and  <cit> . some regions mentioned in  <cit>   are not detected by us as these are regions with probability of alteration just below  <dig> . there are differences with the method of  <cit> , cghregions, in the location of the breakpoints: cghregions is a dimension reduction method that simplifies the complexity of the sample profiles, which probably leads to a larger imprecision in the location of region boundaries.

breast cancer example : prec-s and homogeneity index
pollack et al.  <cit>  analyze data from  <dig> breast tumors and  <dig> cancer cell lines. they search for common regions of alteration and then compare the frequency of aberrations in each arm of every chromosome as a function of other variables such as tumor grade, estrogen receptor  and tp <dig> mutations. rouveirol et al.  <cit>  also analyze these data. we have applied our second method, prec-s, to the  <dig> tumors to examine if there is any similarity in the alterations shared by the groups of arrays defined by those variables. we have computed common regions of at least  <dig>  probability of alteration  shared by at least two arrays .

to compare our approach with the results of  <cit> , and to gain more insight on the patterns of recurrent cna regions and their relationship to the other three variables , we have defined a simple statistic to measure within-group homogeneity of recurrent cna regions. let yij be the number of probes that array i and array j have altered in common, k a group of arrays , nk the number of different pairs of arrays in a given group k and n_k the number of different pairs formed by arrays in group k and arrays in a different group. let us define

  

that is,  is the average number of common altered probes between two arrays of group k, and  is the average number of common altered probes between one array of group k and other in a different group. we define the proportion of common alterations shared by the group k as /. this index measures the homogeneity of the genomic alterations within a subset of arrays compared to the alterations shared with arrays of other group. if this index is greater than  <dig>  the arrays of this group share more alterations between themselves than arrays of different groups do. if this index is  <dig>  no alterations are shared between any two arrays in the group. a value of  <dig> means that no alteration is shared between arrays of this group and others. we can compute this index for the groups defined by the three variables tumor grade, er, and tp <dig> mutations; this is shown in the additional file  <dig> - tables s <dig> to s6). those tables allow us to easily discern chromosomes that are very homogeneous with respect to shared alterations; for instance, gains in chromosomes  <dig> and  <dig> and losses in chromosome  <dig> are very homogeneous in the estrogen receptor negative samples . we can display the patterns of similarity graphically, as is done in figure  <dig>  where we have ordered the arrays by tumor grade and show the number of common alterations for chromosome  <dig>  our results are not easy to compare with  <cit> , because they define the regions and compare subgroups at chromosome arm resolution, while our method works at probe resolution.

furthermore  <cit>  consider every chromosome arm as altered or not without taking into account the number of altered probes in it.

to further understand the pattern of similarities, instead of comparing subgroups according to the number of alterations, we can analyze how homogeneous each group is over the whole genome . this is shown in table  <dig>  when we divide arrays according to tumor grade, grade i and grade iii show high homogeneity within groups, meaning that the alterations are consistent in arrays within those grades. arrays of grade ii, however, show much more heterogeneity, sharing many aberrations with arrays of grade i and/or grade iii. this is an indication that arrays of grade ii can be classified in one of the other two groups according to the pattern of alterations. figure  <dig> provides a graphical illustration: four arrays of grade ii are very similar to the arrays of grade iii.

the homogeneity index, , is computed over the whole genome, not chromosome by chromosome, as done in previous tables.

discussion
we have developed two very different approaches for finding regions of recurrent, or common, copy number alteration. the lack of gold standards and the current non-existence of an unambiguous definition of what a region of recurrent cna is  <cit> , as well as the unique and qualitatively different nature of our methods from previous ones, make it difficult to compare performance, but at the same time highlight the relevance of our methods for current and future studies of cna, their relation to phenotypic variation, and their usage for subject clustering.

the two methods we have developed share that they use as input probabilities of alteration and return probabilities. regardless of whether the input probabilities are obtained from our rjacgh method  <cit>  or some other approach, it can be argued that probabilities are much better suited to the task at hand than p-values or discrete classifications into "gained", "lost", "not changed". by using probabilities as input, we incorporate uncertainty in the estimates of copy number states. by returning probabilites and using probabilities throughout all the analysis, the user can decide the appropriate thresholds  and define distances between arrays that incorporate the strength of evidence in favor of alteration. precisely because of the conceptual simplicity of using probabilities, we can approach within a unified framework both questions related to "unsupervised problems"  and to "supervised problems" . this unified approach is unique to our methods, and not shared by any others.

our first method, prec-a, searches for general, broad patterns of common gains  over all the samples in the study. this is the approach which is most similar to previous ones. this method is well suited to comparing pre-defined groups of samples. by its very nature  this method can only detect regions for which there is at least moderate evidence  of alteration over almost all samples, or very strong evidence  of alteration over an important fraction of the samples. thus, it is easy to miss regions that are present with very high probability in a small subset of the samples. as well, mixing in the same sample very heterogenous groups will tend to smooth out the evidence of alteration, so that few common regions will be found. alternatively, if there are very different sample sizes  in the different heterogenous groups, the detected common regions will often be a subset of the common regions among the most abundant group. these features can be controlled to answer the specific study questions. first, as equation  <dig> shows, it is easy to weight different arrays differently, so as to increase the influence of some arrays in the final analysis. moreover, if we know in advance that there are different subgroups of samples, we can use prec-a independently in the different subgroups; for instance, when we have already subdivided the subjects in the study into homogeneous groups with respect to disease , and want to locate recurrent cna regions common to most samples within a subgroup and possibly different from other subgroups. finally, as our last example with the data of  <cit>  shows, a user that understands these features of prec-a can employ this algorithm to highlight the differences between subgroups and how these change as we modify the minimum required threshold for the probability of alteration. in particular, note the easy formulation of a permutation-based test for identifying the differences in the probabilities of alteration of regions between subgroups. this type of approach might be even more useful when two or more suspected subgroups are compared against a larger, reference group. the main advantages of this algorithm are that it is most similar to previous approaches, has a simple interpretation in terms of global patterns across most of the samples, and requires the specification of only one parameter. thus, prec-a will often be the method of choice if we are trying to relate major, global, recurrent patterns of cna to variations in phenotype or to differentiate between subroups of samples. in contrast to prec-a, the second method, prec-s, can detect small subgroups of samples with respect to common alterations, without being adversely affected by averages over arrays or differences in number of samples in different subgroups. moreover, different subgroups can be detected with respect to different alterations. prec-s, therefore, addresses a common and distinct need that arises in any study of cna with heterogeneous samples.

as seen in the results, this second algorithm allows us to elegantly approach some of the questions in the second example . first, the derivation of a specially tailored statistic, , to answer the relevant questions in this study is straightforward. more importantly, the second algorithm finds homogeneous subgroups, with respect to alterations, and these differences are associated with differences in three other markers . in other words, prec-s finds cnv that differentiate between groups. it must be emphasized that prec-s has been applied to the complete set of data after specifying that the within-array probability of alteration be larger than  <dig>   and that these regions be shared among, at least, two arrays , but the algorithm is blind to the "labels" of the arrays regarding the other markers . therefore, prec-s allows us to find cnvs that differentiate between known groups , but its systematic usage also opens the door to finding patterns of cna that might differentiate between previously unknown groups. moreover, there is no need for the association recurrent cna regions-marker to be similar among different markers, specially since, as explained above, different subgroups of arrays can be detected with respect to different cna recurrence patterns. these are features unique and characteristic of prec-s, compared to all the alternative available methods.

we suggest that prec-s is the method of choice when there is unknown heterogeneity among arrays in cnas, and when we want to relate possibly non-identical subsets of samples, defined in terms of recurrent patterns of cna, to phenotypic variation. moreover, routine use of prec-s even with apparently homogeneous groups of samples might help discover possible subtypes of diseases that might generate novel hypothesis or uncover previously unknown heterogeneities.

prec-s is also a key method for clustering. integrative studies that combine cnv data with other data  often use clustering of subjects based upon the cna data . the problem of most of these approaches is that, when clustering based upon the cna data , the measure of distance or similarity used ignores that some of the data show strong serial dependence  whereas some of the data  are independent. thus, in most cases the distance computed is likely to introduce serious distortions in the true distances among subjects . this problem is in addition to the aforementioned issues of not integrating variability and uncertainty in the gain/loss calls or smoothed means. in contrast, by using a biologically motivated and probabilistically based approach to cna common regions, such as prec-s, it will be possible to construct distance metrics and, therefore, clustering approaches, that make full usage of cna data when searching for groups of subjects. fully developing a method for clustering based upon cna data is outside the scope of this paper, but we have presented a simple example to motivate further work.

moreover, an additional distinct feature of our methods is that both prec-s and prec-a have at most two parameters of straightforward biological interpretation . an added advantage of the type of input and output used by our methods is that probabilities allow researchers to modify thresholds as needed, and to easily  examine the sensitivity of results to changes in thresholds.

furthermore, as both methods are based on a hidden markov model  with no restrictions on the number of states  <cit> , we can use models involving an arbitrary number of states of gain and loss. the hmm  assigns probes to hidden states, but it is up to subsequent analysis to assign those states to specific or interesting "copy number states". this allows us to keep the two different concepts of "amplitude  of change" and "evidence of alteration" separate. moreover, it is also immediate to restrict finding common regions to alterations above a certain threshold of amplitude or that belong only to a subset of states so that we can focus only on alterations of a certain type .

finally, note that the problem we have been addressing is the location, de novo, of recurrent cna regions. a different set of problems is using pre-existing information about regions that show copy number polymorphism to inform the search for rare copy number variants  <cit> . likewise, another very different set of problems is the usage of previously identified variable regions in tests of association between copy number variation and disease  <cit> . these are, however, sufficiently related objectives, and methodological and conceptual advances in any one set of approaches could be highly beneficial for the other two sets of problems.

CONCLUSIONS
we have developed methods for finding regions of copy number alteration  common or recurrent over several arrays. our methods have an immediate and intuitive biological interpretation, and incorporate both within- and among-array variability. reanalysis of several data sets in the literature show that our methods can indeed recover patterns previously found but can also uncover additional patterns. moreover, probabilities allow researchers to modify thresholds as needed, and to easily examine the sensitivity of results to changes in thresholds. in addition, the examples show how it is straightforward to derive tailored statistics and summary measures to answer specific research questions. the development of these two distinct algorithms highlights a key idea that has often been neglected: recurrent or common cnas can refer to very distinct patterns in a group of samples, specially concerning heterogeneity among arrays and probability of alteration. we expect that these two algorithms will help advance efforts to standardize definitions of recurrent or common cna regions, and ultimately the search for genomic regions harboring disease-critical genes.

authors' contributions
omr developed the statistical model, participated in the programming and conducted all of the analysis. rd-u conceived the original hmm model and participated in model development and programming. both authors wrote, read, and approved the final manuscript.

supplementary material
additional file 1
supplementary material for "detection of recurrent copy number alterations in the genome: taking among-subject heterogeneity seriously". a pdf file with further details on the algorithms and tables and comments on the examples.

click here for file

 acknowledgements
c. lázaro-perea, j. poyatos, and four anonymous reviewers for comments on the ms. funding provided by fundación de investigación médica mutua madrileña. publication charges covered by projects consolider: csd2007- <dig> of the spanish ministry of science and innovation and by rtic combiomed rd07/0067/ <dig> of the spanish health ministry.
