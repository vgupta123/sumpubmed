BACKGROUND
bacteria and archaea have an adaptive heritable immune system against viruses, plasmids and other mobile genetic elements  <cit> . this locus, crispr , consists of an array of repeats and unique spacers. the repeats are of length 21- <dig> nucleotides depending on crispr type and species. the spacer sequences are 26- <dig> nucleotides in length, where the variance of spacer length within one array is small. the spacer sequences were found to be of extrachromosomal origin  <cit>  and are involved in immunity  <cit> . cas  genes adjacent to the crispr arrays are necessary for the biogenesis of the crispr rna, for the interference with the target nucleic acid and for the acquisition of new spacer sequences  <cit> . different types of crispr/cas systems exist based on the set of cas genes present  <cit> .

comparisons of the crispr array of closely related strains showed that the crispr array undergoes a rapid evolution that is mainly determined by the gain and loss of the whole system or of individual spacers  <cit> . in most cases, spacer addition was observed at the beginning, the ‘leader’ end, of the array  <cit>  and the pattern in metagenomic samples suggest that deletion of consecutive repeat-spacer units occurs  <cit> . bacterial genomes can have multiple crispr arrays that differ in their dynamics  <cit> . it was observed that closely related strains can differ in their spacer content, thus the crispr array is used as a tool for strain typing .

the targeting of extrachromosomal elements by the crispr/cas system was discovered recently  <cit>  and many questions regarding the functions, mechanisms and evolution of this locus are still open. this is complicated by the fact that different crispr/cas systems have different mechanisms and may have different function  <cit> . thus computational methods that make predictions are important to narrow the space of hypotheses that need to be tested experimentally. for example, self-targeting spacers are not conserved between species and crispr arrays with self-targeting spacers may get inactivated. these observations exclude the hypothesis of gene regulation by crispr  <cit> .

using model simulations can provide insights into the parameters allowing crispr existence and into the details of crispr dynamics. one result using population genetics models is that crispr is maintained if it provides immunity to viruses or plasmids even when there is a cost of having crispr  <cit> . simulating a spatial model of virus and host population showed that coexistence is possible with a crispr-based immune system  <cit> . furthermore, a spatially structured environment can lead to intermediate array lengths, i.e., the number of spacers has an optimum between  <dig> and the number of viruses excluding the extreme values. then the lengths are determined by the spacer insertion rate and by the cost for having spacers not by the total number of phages in the environment  <cit> . modeling coevolution of hosts and viruses results in the observation that spacers at the leader-distal end tend to be more conserved, due to selective sweeps, and that immunity to contemporary viruses is mainly determined by the most recently acquired spacers  <cit> . in addition, simulations can find parameter regimes that are important for the existence of crispr like a threshold on the viral mutation rate  <cit> .

our approach differs from the population genetics models described since it estimates parameters directly from the array data. we describe the dynamics of the crispr locus over time in diverging populations related by a phylogeny. this is the phylogeny of the crispr/cas locus. since the locus can be transferred horizontally  <cit> , the crispr/cas phylogeny does not need to be identical to the strain phylogeny. there are a few instances of recombination inside cas genes  <cit> , but in our model, we exclude recombination in the spacer arrays. the evolutionary events we model are spacer insertion and deletion. by using only strains harboring the locus, we ignore the loss or gain of the whole crispr/cas system.

 mutations inside the crispr locus are also not included in the model, but in data analyses multiple spacers with sequence similarities can be subsumed into one identity.

even before the function of the crispr/cas system was clear, pourcel et al.  <cit>  formulated three observations for crispr evolution by comparing yersinia pestis arrays: random deletions of one or more spacers and repeats; polarized addition of new spacers; and identical spacers reflect shared ancestry not independent events. we also assume that the crispr arrays analyzed are homologous and that each spacer was only inserted once, i.e., all spacers with identical sequence are identical by descent. thus we present three models: an unordered model , an ordered model  and a fragment loss model .

another class of models that take order relationships into account are gene order models, i.e., they model the order of genes in the genome over time. most methods for evaluating the distance between two gene orders find the minimum number of rearrangement events between these genomes. this approach can also be combined with insertions and segment deletions  <cit> . probabilistic methods of rearrangement only model inversions  <cit>  or inversions and transpositions  <cit> . multi-gene events are considered in one model of gene innovation, duplication and deletion, but ignoring the order of genes on the genome  <cit> .

our ordered and fragment loss models are thus different from the probabilistic models for gene order since they capture the properties specific for crispr spacer evolution. we describe our method and investigate its properties by simulation and application to real world yersinia pestis data sets  <cit> .

methods
models
we describe different models for estimating insertion and deletion rates from crispr arrays. we ignore repeats and only use the spacer information and their order encoded in an array. the leader end is displayed on the left . in our models, these arrays evolve by insertion and deletion events. an overview of the types of insertions and deletions allowed in the different models can be found in table  <dig>  in all models, the waiting time for insertion events is exponentially distributed with rate λ . one spacer is inserted for each insertion event.

in the independent loss model only single spacers can get lost. for each spacer, the waiting time to get lost is exponentially distributed with rate

μ. all deletions are independent of each other. the corresponding length model describes the length of the array by a markov process . in contrast, the full model takes spacer identities into account. in the independent loss model, a loss means a transition to length - <dig> and a gain a transition to length + <dig>  we analyze two sub-models of the independent loss model: the unordered model, where there is no position information; and the ordered model, where insertion occurs in a polarized way, i.e., at the end adjacent to the leader. for simplicity, we refer to this end as the beginning of the array. the latter model is motivated by the observation that spacers are usually inserted at the leader end of the array .

in the fragment loss model the position is informative since insertion occurs in the beginning and subsequent spacers can get lost together. this model is motivated by the pattern in metagenomic samples that shows deletion of consecutive repeat-spacer units  <cit> . each possible non-empty substring of the array is a fragment. thus fragments can be overlapping and one spacer inside an array is then part of different fragments. for example, the array 3-2- <dig>  consists of the fragments  <dig>   <dig>   <dig>  2- <dig>  3- <dig> and 3-2- <dig>  the fragment 3- <dig> overlaps with the fragment 2- <dig> in the spacer  <dig>  and the spacer  <dig> occurs in  <dig> fragments:  <dig>  2- <dig>  3- <dig> and 3-2- <dig>  for each possible fragment, the waiting time to get lost is exponentially distributed with rate μ, independent of the number of spacers a fragment contains. in the length model, all lengths smaller than the current length are accessible in a single step .

since μ has a different meaning in both models, we emphasize this by using μf for the fragment loss model , and μi for the independent loss model . the rates are always rescaled such that one event  is expected in time t =  <dig>  this allows for estimating times, but only the ratio ρ=λμ can be estimated. again, we distinguish the two models by using ρf=λμf and ρi=λμi. subscripts are omitted when the underlying model is clearly stated.

now, we present the stationary distribution of the length models and the transition probabilities of the full model necessary to formulate an estimation approach under each of these models. afterwards details of the estimation approaches are described.

independent loss models
length model
the independent loss length model is a markov process known as an m / m / ∞ queuing model  <cit>  . in this queuing model, customers  arrive according to a poisson process with rate λ. they are immediately served and exit after an exponential waiting time with rate μ. the stationary distribution of the number of busy servers , is a poisson distribution with rate ρ: 

  p=e-ρρnn!,wherenis the array length. 

transition probabilities
given an ancestor s <dig> and a descendent s <dig>  m spacers are shared, d spacers are unique to s <dig> and j spacers are unique to s <dig>  the transition probabilities of changing from s <dig> to s <dig> use the property that inserted, preserved and deleted elements are independent of each other:

  t=mdiwhere the probability of preservingmspacers in timetism=e-mμt,the probability of loosingdspacers in timetisd=d,the probability of insertingjspacers in timetisi=e-ρ1-e-μtρ1-e-μtjj!. 

m and d follow directly from the exponential model. i is known from queuing theory  <cit> . the probability of inserting j spacers is the probability of observing j spacers after time t when there were  <dig> spacers at time  <dig>  that is the integration over all possible paths leading to j, including paths where spacers were inserted and lost and thus never observed.

fragment loss models
length model
the stationary distribution of the length model  is given by

  p=2ρ∏i=0n2ρ+1). 

equation  can be solved from the conditions that in stationarity the flow into a state equals the flow out of that state and that the probabilities of such events necessarily sum to  <dig> .

for each ρf there is a correspondingρi that has the same expected length. we find that for corresponding ρs the fragment loss model has a higher variance of the length distribution than the independent loss model .

transition probabilities
given an ancestor s <dig> and a descendent s <dig>  we segment them into independent pairs . note that this segmentation is different from the fragments described above. fragments are all possible substrings of one array, but segments are calculated using two arrays. each segment is either an inserted, deleted or preserved segment. segments are of maximal length, i.e., two consecutive segments are of different type. see figure  <dig> for an example of segments resulting from a pair of arrays. in contrast to the independent loss model, this segmentation is an approximation since it ignores the probability of deletion events spanning multiple segments. the segmentation is, however, necessary to factorize the transition probabilities. the transition probability is then the product over the segment probabilities.

preserving a fragment of length m has probability

 m=e-m2μt. 

 deleting a fragment of any length has probability

 d=1-e-μt. 

inserting i spacers has probability

  i=2i+1e-λtρi×∑k=1i+1k-1k2!!×e-k2μt1--k2ρ1+k2ρ)+2ρ∏k=0i2ρ+ <dig>  

as before, the probability of inserting i spacers includes unobserved spacers that were inserted and lost again. these equations were found by integration over all possible paths in mathematica  <dig>   <cit> .

for example, in figure  <dig> the transition probability is i × m × d × m.

estimation
maximum likelihood function
we describe a maximum likelihood approach to estimate rates and times of spacer insertions and deletions, given a set of ordered spacer arrays from different strains. since we do not have phylogenetic information, we consider each pair of arrays and their possible common ancestors.

formally, the maximum likelihood estimate for a spacer set s with k = |s| is 

  =argmaxlwithl=∏i= <dig> …,k2l, 

where s is the list of all different pairs of s and t is the corresponding list of pairs of times.

the likelihood of a pair of spacer arrays  with times  is then 

  l=∑ancestorsaqt×t, 

where λ and μ are computed from ρ given the constraints λμ=ρ and the expected number of insertions and deletions in time  <dig> is  <dig>  then, q is the probability of observing a, t is the transition probability of changing from a to b in time t given insertion rate λ and deletion rate μ.

if the pair has no overlap, i.e., no common spacers, we assume that the time from the common ancestor is long enough such that the transition probabilities approach the stationary probabilities. then the likelihood function can be simplified by using the fact that the probability of the whole ancestor space is  <dig>  we find that only the lengths are informative for estimating ρ: 

  l=∑ancestorsaqpp=pp,withn1=|s1|andn2=|s2|. 

note that q and p are different but related by the following constraints: the sum of all q with |a| = n is p and q = q if |a| = |b|.

optimization
we are interested in both the estimate of ρ, ρ^, and the estimation of the divergence times. for a pair, we denote the estimated time between two arrays as τ^=t^1+t^ <dig>  τ for a phylogeny or for a collection of pairs denotes the average of τ over all pairs.

overview of the estimation approach: 

 <dig>  estimate a starting ρ from the length model by maximum likelihood. the likelihood function is lstart=∑arrayssp, where |s| is the length of s and p is the stationary distribution of the length model.

 <dig>  for each pair of spacers with overlap, generate the possible ancestors: ancestral arrays can be arbitrarily large, but the probability of observing a certain length is given by p. for practical reasons we do not consider ancestors whose length is outside the central 99% of the stationary distribution given by ρ estimated in step  <dig>  since they would have a negligible contribution to the likelihood. in detail, the length l <dig> where the cumulative distribution exceeds  <dig>  is the minimum ancestor length and the length l <dig> where the cumulative distribution exceeds  <dig>  is the maximum ancestor length. then the possible ancestor lengths n are between l <dig> and l2: l1 ≤ n ≤ l <dig> 

 <dig>  

 for all pairs with overlap, estimate the times with fixed ρ. it is possible to iterate through the pairs and estimate their times independently of the other pairs. the estimation of both times is iterated alternatingly until the likelihood has converged.

 estimate ρ with fixed times using l.

 check if the log-likelihood of the estimated parameters has converged, then return the estimated parameters, else repeat step  with the new parameters.

all three models are analyzed in this computational framework. all optimization steps only optimize one parameter and use powell’s method from the python package scipy <cit> . the python package mpmath is used for high-precision computing  <cit>  that is necessary to compute the probability functions accurately.

ancestors
here, we describe for each of the models how we generate the ancestors in step  <dig> above. thereby we must account for unobserved spacers, that are not present in the data but in ancestral lineages. we overcome the problem of the infinite state space by ignoring the identity of unobserved spacers. for example, there may be four unobserved spacers, each of them gets a new unique name, but then no other four unobserved spacers with other names or an other order are considered.

unordered model
given a pair of arrays s <dig> and s <dig>  they have c spacers in common, d <dig> are unique to s <dig> and d <dig> are unique to s <dig>  then all n between min and l <dig> are generated. when length n is generated, enumerate all i, j, u such that c + i + j + u = n, i ≤ d <dig> and j ≤ d <dig>  then for ancestor a, there are c common spacers, i only occur in s <dig>  j only occur in s <dig> and u are unobserved . since this ancestor comprises multiple spacer identities, we assign a weight to it, w=d1i×d2j. the weights for each n are rescaled such that they sum to  <dig>  i.e., the rescaled weight ws is ws=w∑b,|b|=|a|w. then q = wsp.

ordered model
given a pair of arrays s <dig> and s <dig>  find the first shared spacer. the ancestor must contain this spacer and all subsequent spacers from both arrays, these are c spacers in total. there are d <dig> and d <dig> spacers before the first shared spacer in s <dig> and s <dig>  respectively. with these new definitions of c, d <dig> and d <dig>  the method from the unordered model is applied.

fragment loss model
for the fragment loss model, the ancestors must fulfil several constraints given by the order in the observed arrays. since all shared ancestors are identical by descent and insertions occurs only in the beginning, all spacers from the first shared spacer on must be present in the ancestor. thereby the order of spacers must be preserved. enumerating the ancestors is best explained with an example. consider the arrays s1 = 8-7-6-4-3-2- <dig>  s2 = 11-10-9-7-6-5- <dig>  

•  <dig> is the first shared spacer.

• the set of spacers necessarily present in the ancestor is the union of all spacers after the first shared spacer: { <dig> , <dig> , <dig> ,7}. 

– possible orders of these spacers: 7-6-5-4-3-2- <dig>  7-6-4-5-3-2- <dig>  or 7-6-4-3-5-2-1

• the set of spacers possibly present in the ancestor is the union of all spacers before the first shared spacer: { <dig> , <dig> }. 

– order constraints for these spacers:  <dig> before  <dig> before  <dig> before 7

• unobserved spacers  may have occurred at all possible positions.

since a lot of possible arrays are generated by this approach, heuristics are used to reduce their number: 

• shared fragments cannot be interrupted by an unobserved spacer. 

in the example, there is no unobserved spacer between  <dig> and  <dig> 

• unique fragments in the beginning are not mixed. 

– in the example,  <dig> and 11-10- <dig> are in the beginning and then the following ancestral fragments are not allowed: 11-8- <dig> and 10-8- <dig> 

• deleted pairs are also not mixed. 

– in the example 4- <dig> and  <dig> are deleted and the ancestral fragment 4-5- <dig> is ignored.

• the number of positions with unobserved spacers is maximal four. that means there can still be a lot of unobserved spacers but they occur only in maximal four stretches.

this reduction is only for computational reasons, and may result in the true/simulated ancestor not being included in the set of possible ancestors. for small simulations it was shown that the results are very similar  and that the ancestors generated contain enough information for the likelihood function.

loss time
two arrays do not contain information about the divergence time if they have no overlap. to include them in the analysis, we are interested in the time passed until an array lost all spacers present in the ancestor.

the lineage loss time distribution for a given ρ is the following distribution of times: given an array in stationarity, when does the last spacer from the ancestral array gets lost? the expected lineage loss time is the expectation of this distribution. analogously, we define the pairwise loss time distribution as the distribution of times when two independently evolving lineages lost their last common spacer. in detail, we simulate two lineages starting from a common ancestor and track changes in both lineages simultaneously. t is the time when the deletion in one lineage results in the loss of all spacers that are present at that time in the other lineage. the pairwise loss time simulated is then 2t since there were two lineages. the distribution is always approximated using  <dig>  simulated pairs.

the expectations of these distributions is denoted by αl , αp , and analogously with subscript f for the fragment loss model. in case the underlying ρ is clear, the argument is omitted. the expected lineage and pairwise loss times are lower for the fragment loss model . in the estimation, we set τ^=αp for a pair without overlap. note that this is an underestimate of the time between two arrays since the loss time is an estimate of the minimum, i.e., the first time when two arrays lost common spacers.

simulation
simulation under each model is implemented in a python program. input is a phylogeny with branch lengths, ρ and the type of the model. an ancestor length is drawn at the root of the phylogeny from the stationary distribution of the length model. spacers are labelled arbitrarily. then the tree is traversed in preorder and the descendent of each branch given its ancestor and branch length t is simulated as follows.

start with the ancestor s, n = |s|, current time tc =  <dig>  

 <dig>  determine the time until the next event of each type: 

 draw a waiting time until the next insertion event from an exponential distribution with rate λ.

 draw the waiting times until the next deletion for each spacer or fragment.

 if the independent loss model is simulated, draw n exponential waiting times, each with rate μ.

 if the fragment loss model is simulated, draw n <dig> exponential waiting times with rate μ, one for each fragment.

 <dig>  find the minimal time tmin over all times generated in step  <dig> 

 <dig>  tc = tc + tmin.

 <dig>  if tc > t, return s as the sequence at the descendent node.

 <dig>  else the event that corresponds to tmin is realized, the other events are discarded. if tmin corresponds to an insertion, one spacer with a new name is inserted. in case of the unordered model, the spacer is inserted at a random position, in the other cases it is always inserted in the beginning of s. if tmin corresponds to a deletion, modify s by deleting the corresponding fragment or spacer.

 <dig>  continue at step  <dig> with the modified s.

phylogeny computation using crispr distances
the sum of the estimated times given two strains, τ, can be interpreted as the distance between these two strains. these distances can be used to compute a distance-based phylogeny using neighbor joining  <cit>  as was presented by huson and steel  <cit> . for the non-reversible models, however, there is more information available, since there is an estimate for the distance of the last common ancestor to each of the two strains. we use a modified neighbor joining method to utilize this information and refer to it as rooted neighbor joining. we describe the algorithm with an example.

input: for k taxa, all k <dig> pairs with rooted time estimates, that is dx, y for the distance to taxon x from the ancestor of the pair .

output: a rooted phylogenetic tree with times t.

algorithm
 <dig>  compute the weights for all pairs : 

 wx,y=∑z≠x,y=+∑z≠x,y 

 <dig>  choose the pair with maximal weight wx,y. create a new node r that is the ancestor of  with tr,x = dx,y and tr,y = dy,x.

 <dig>  compute the distances between all other nodes z and r: 

 dr,z= <dig> dz,r= <dig> 

 <dig>  if only one node is left, return it as the root, else continue with step  <dig> 

by construction, the method results in the correct rooted tree if the distances were extracted from a rooted tree. we show this for three taxa.

for three taxa, there is only one clade, we choose  to be the correct clade. then the branch lengths are given in figure 

iteration 1:   

weights: w <dig>  = - + d <dig>  + d <dig>  = - + a + c + b + c = 2c, w <dig>  = - + a + d = -c, w <dig>  = - + b + d = -c. thus for all possible a, b, c, d, w <dig>  = argmaxi,jwi,j and the correct grouping is chosen by the algorithm.

create node  <dig> with t <dig>  = d <dig>  = a and t <dig>  = d <dig>  = b. the tree is now  <dig> 

iteration 2:  

there is only one pair, create node  <dig> with t <dig>  = d <dig>  = d and t <dig>  = d <dig>  = c. the resulting tree is 4:c,t3:d) <dig>  apart from the internal labels, this tree is identical to the original one .

we abbreviate the method rooted neighbor joining with times from the fragment loss model by rnjf, analogously for nj and subscript o for the ordered model and subscript u for the unordered model.

yersinia pestis data set
we downloaded available yersinia pestis genomes . unfinished strains were included if open reading frames have been annotated. cas genes are detected using hmmer  <cit>  and the profiles defined previously for the ypest type . unfinished strains were excluded if cas genes were detected on different contigs. in these cases, not all cas genes were available.

spacers are grouped and assigned a unique number for each array if they show >90% sequence similarity. different variants are marked by superscript and ignored in the analysis. the leader-proximal end is displayed on the left. spacer sequences can be found in additional file  <dig> for yp <dig>  in additional file  <dig> for yp <dig> and in additional file  <dig> for yp <dig> 

 the whole locus was extracted, i.e., the sequence from the start of cas <dig> until the end of csy <dig>  nucleotide sequences from the resulting  <dig> strains were aligned using clustalw  <cit>  into an alignment of  <dig> sites that is subsequently used for phylogeny estimation with iqpnni  <cit> .

putative crispr arrays for the  <dig> strains are extracted using crisprfinder  <cit> . true crispr elements are found by comparing the repeat sequence to the known yersinia pestis repeat. the three types of crispr arrays are distinguished by their last degenerated repeat  <cit> . in total, four crispr arrays are missing from the crisprfinder results. in these cases, we located the respective leader in the genome and extracted repeats and spacers manually. these arrays harbor none or one spacer. for each data set, spacers were assigned the same identity if they show more than 90% sequence similarity. this is a natural cutoff to choose since there was no pair of spacers with similarity between 65% and 90%. spacer sequences can be found in additional file  <dig> for yp <dig>  in additional file  <dig> for yp <dig> and in additional file  <dig> for yp <dig> 

RESULTS
parameter estimation for simulated pairs
in the first simulation setting, we present basic simulations with clocklike two-taxon trees. a tree height of  <dig>   <dig> and  <dig> is investigated, resulting in τ =  <dig>   <dig>   <dig>  and different possible values for ρ: ρ =  <dig>   <dig>   <dig> for the fragment loss model and ρ =  <dig> ,  <dig> ,  <dig>  for the independent loss model. these values were chosen because they are corresponding ρs .

first, we compare the simulated ρ with its estimation. ρ is estimated based on the start likelihood using the stationary distribution or on the full likelihood summing over all pairs. note that the start likelihood functions are equal for both independent loss models. the estimates based on the start likelihood and on the full likelihood are very similar for the independent loss models . for the fragment loss model, ρf tends to be underestimated for the full likelihood but not for the start likelihood . the segmentation of ancestors and descendants into independent pairs may cause this bias. this segmentation ignores the probability of deletion events spanning multiple segments and can result in an overestimation of μf and thus in an underestimation of the ratio ρf = λ / μf.

we also compare the estimation using the full likelihood with the ancestor fixed to the true ancestor and using the full likelihood with summing over possible ancestors. the estimated values of ρ are very similar, which leads to the conclusion that the ancestor enumeration works appropriately.

next, we use the same simulated data sets, but investigate the results when using an incorrect model for the estimation. we only compare the models with single deletions among each other and the models with polarized insertions among each other . the independent loss models differ only in their insertions. when using the incorrect insertion model, ρ^i is very similar . these models are also very similar in their construction. they are the same if after the first shared spacer there are no spacers unique to one strain. when using the incorrect deletion model, the corresponding ρ tends to be estimated . in detail, the ρi that is estimated under the ordered model from the data generated under the fragment loss model is on average the ρi corresponding to ρf used for the simulations . the underestimation of ρf is even present to a larger extent when ρf is estimated from data generated under the ordered model compared to the estimation under the true model.

times can only be estimated for pairs with overlap. the quality of the time’s estimation depends on the simulated ρ since the loss times depend on ρ. for larger ρ, the pairwise loss time is larger, thus it is possible to estimate larger times. when only pairs with overlap are considered, the times tend to be underestimated when the true time exceeds the expected pairwise loss time . we use the expected pairwise loss time as an approximation of the times for the empty pairs. thus for these pairs, τ^=αp. using τ^ from all pairs instead

from the pairs with overlap only, decreases the average time estimated, if there are many empty pairs . this can be explained by two effects. first, the loss time is a minimum, i.e., the first time when two arrays lost common spacers. second, shorter arrays occur more often among the pairs without overlap. that means, ρ^ is smaller for these pairs and thus their loss time is smaller as well .

estimation with two arrays under the correct model, same data as figures  <dig> and  <dig>  no - number of pairs with overlap,ρ^o - median ofρ estimates of pairs with overlap only,ρ^e - median of ρ estimates of pairs without overlap only.

using the true model, we find that times are well estimated until a threshold depending on the simulated ρ. for example, for the independent loss model, for ρ =  <dig> , only τ =  <dig> is well estimated, but for ρ =  <dig> , τ =  <dig> and τ =  <dig> are well estimated. this threshold is below the expected pairwise loss time. time estimation for the fragment loss model is more noisy and a slight overestimation can occur for intermediate times that may be related to the underestimation of ρ for these parameter settings .

time estimates for the incorrect independent loss model are very similar . in general, the ordered model results in slightly lower time estimates. small and intermediate times are overestimated when the ordered model is applied to data generated under the fragment loss model , possibly because more events are necessary to explain this data. applying the fragment loss model to ordered independent loss data also results in an overestimation for intermediate times .

parameter estimation for simulated phylogenies
next we apply the estimation to data sets simulated on a phylogeny. the same values of ρ as in the previous simulations were used. phylogenies of  <dig> taxa are generated under a yule process and rescaled to a specific tree height .

these results generally confirm the results for pairs of arrays, but resulting distributions ofρ^ andτ^ have a lower

 variance. the variance in the estimates is higher for the fragment loss model compared to the independent loss models. for the independent loss model, the mean of theρ^-values is usually close toρ . under the fragment loss model, ρ for the intermediate times are underestimated . times are again well estimated until a threshold depending on the simulated ρ . for the fragment loss model, times are overestimated for intermediate tree heights .

yersinia pestis analysis
yersinia pestis genomes generally harbor three crispr arrays types, called yp <dig>  yp <dig>  and yp <dig>  all three array types have the same repeat sequence and only one set of cas genes of the ypest type is present in the genome. we demonstrate the methods using three yersinia pestis data sets . one data set was assembled from  <dig> sequenced genomes . pourcel et al.  <cit>  investigate  <dig> strains but yp <dig> is only present in  <dig> of them. they sequence yp <dig> in  <dig> of them but give no detailed information about yp <dig>  thus it was not included. cui et al.  <cit>  investigate  <dig> strains, including published genomes and yersinia pestis isolates from asia. the three arrays are present in all of them but sequence information for yp <dig> and yp <dig> is missing in  <dig> and  <dig> strains, respectively.

the average overlap is computed as the mean of the overlap over all pairs. the overlap of a pair is the number of equal spacers divided by the mean length of both arrays.

data set  <dig> consists of on average shorter arrays than the published data sets. this results in lower estimates of ρ for this data set . for data sets  <dig> and  <dig>  ρ estimates between the data sets for the same crispr array type are largely congruent. comparing average times between arrays with different ρ is problematic, since larger ρ can resolve larger times. thus we compare average diversity between data sets. diversity for a pair is computed as the

 time between the arrays divided by the pairwise loss time, where maximum diversity is  <dig>  yp <dig> has the lowest diversity for each data set it is present. however, the results for the other array types differ. pourcel et al.  <cit>  argued that yp <dig> is the most dynamic crispr locus. based on the data of pourcel et al. , diversity is similar in yp <dig> and yp <dig> under the independent loss model, and diversity is lower in yp <dig> than in yp <dig> under the fragment loss model. this discrepancy is resolved when comparing the average times. the average time is larger in yp <dig> than in yp <dig> for each model. thus there are more events present in yp <dig> compared to yp <dig>  when considering that the longer arrays in yp <dig> could resolve larger times, the diversity results in a similar value. data set  <dig>  <cit>  shows higher diversity in yp <dig> compared to yp <dig> under all three models. diversity in yp <dig> is also higher in data set  <dig> compared to data set  <dig>  data set  <dig> thus captures a larger fraction of the diversity in crispr spacer content present in yersinia pestis.

cas sequence data is only present for data set  <dig>  the respective cas phylogeny contains few substitutions . the spacer distances are also displayed in a tree structure using the unrooted and rooted neighbor joining method . these trees contain substantially more changes than the cas gene phylogeny and there are also few incongruencies. the group  present in the cas phylogeny is not present in any crispr tree, but is compatible with the trees from yp <dig> and yp <dig>  the group  is contradicted in all trees. the rooted method tends to connect strains with few spacers directly to the root, for yp <dig> this is nepal <dig>  and for yp <dig> and yp <dig> this is angola . note that the angola strain was indeed described to be a deep-rooting yersinia pestis strain  <cit> . for the slowly evolving locus yp <dig>  the clusters displayed by nju and rnjf are equal, only the branch lengths differ and the clusters display the relationships well. in detail, there is a cluster for all strains having spacer  <dig>  for all strains having spacer  <dig>  and for all strains having spacer  <dig>  the terminal branch leading to angola is much longer for nju, since multiple deletions are needed that can be explained by only one event under the fragment loss model. on the other hand, the branches leading to pestoidesf have about the same length since there are only two observed insertions. for the other more diverse loci, trees display which strains are more divergent and which ones are more similar. for example,rnjf for yp <dig> shows that angola, pestoidesf, antiqua and pestoidesa are more divergent, whereas the other strains are more similar to each other. indeed, to convert between two of the other strains at most one event is needed, wheres to convert one of the four strains mentioned into any other one at least two events are necessary.


discussion
we present a new method for analyzing crispr spacer data from microbial populations. the evolution of crispr is mainly driven by the insertion of new spacers during infection with foreign dna and by the presumably random deletion of successive spacers. we try to meet these biological characteristics in the models presented here. estimating insertion and deletion rates and time in number of expected events in one lineage allows for comparisons of empirical data sets that could lead to relevant conclusions. first, bacterial groups in different environments can be compared in terms of crispr dynamics to assess the relative importance of crispr in

 these environments. different crispr array types might show different dynamics and thus have different utility for strain typing. an observed switch in spacer dynamics on a phylogeny might suggest a change in crispr cost or environment.

the three models presented here capture different mechanisms of crispr evolution, namely polarized addition of spacers and deletion of multiple successive spacers . the crispr spacer arrays used for the analysis are assumed to be homologous. crispr homology can be determined by synteny in genomic positions and by repeat and leader similarities.

models are necessarily a simplification of the past biological process. in our model, we ignore population dynamics. our insertion and deletion rates are, as the substitution rates in phylogenetics, a compound parameter including the process of random changes and selection. the model is based on a time-homogenous markov process and the dynamics are assumed to be in stationarity. since an analysis is based on one species and one crispr type, it is reasonable to assume that the mechanistic insertion and deletion rates are homogeneous across the set of strains analyzed. we can not exclude, however, that subsets of strains experienced a different environment and thus different selection pressure on their spacer content. simulations showed that the number of spacers in an array is determined mainly by internal parameters, like spacer insertion rate and cost of having spacers, not by external parameters, like the number of viruses in an environment  <cit> .

we are not aware of previous publications estimating parameters under the ordered or the fragment loss model. the length model of the independent loss model corresponds to an m / m / ∞ queuing model  <cit> . the unordered model corresponds to the gene content model for the maximum-likelihood distance estimation in  <cit> .

 in the context of birth and death processes it is known as the simple death-and-immigration process .

the times estimated under these models also allow a comparison to substitution rates if sequence data is available. this analysis is however complicated by several facts. first, microbial genomes often harbor multiple crispr arrays. as a consequence, it is not clear how to combine these estimates to make a comparison possible. second, spacer content might be different for very closely related strains. then only a few polymorphisms are available and the substitution rate cannot be estimated reliably. finally, frequent horizontal gene transfer of the crispr/cas system has been suggested , and thus crispr rates can only be compared to substitution rates of cas genes.

the parameter estimation as presented here does not use an explicit phylogeny. this is advantageous since no search through tree space is necessary or no precomputed phylogeny needs to be given. the latter may

 not be possible since no external information might resolve the crispr relationships. on the other hand, only a distance-based approach is available to display the crispr relationships. we can use the rooted distance from non-reversible models to compute rooted non-clocklike distance-based trees.

we find that estimation of the rate parameter performs well on average, but the estimates under the independent loss models show a lower variance. the fragment loss model tends to an underestimation and may be affected by the factorization of the likelihood function. the time estimates are most accurate for shorter times. for longer times, the absence of overlap complicates an accurate time estimation. in the analyses presented here, the different models result in similar estimates. if the incorrect loss model is applied, the corresponding ρ tends to be estimated fairly accurately. there is also no clear bias that affects the time estimation under an incorrect model. note that there is a wide range of possible models accounting for fragment deletions. we chose one with the same instantaneous rate for each possible fragment, i.e., ignoring fragment length. this simplification is mainly for computational reasons. future work on other fragment loss models, including lengths of fragments, might lead to a better fit for crispr spacer data.

we compare the estimations between data sets and between different crispr arrays present in a genome. three yersinia pestis data sets were chosen since they harbor three crispr array types and thus this data sets allows for comparison between data sets and between crispr array types evolving with different dynamics. using this data set, we find ρ estimates to be similar using two published data sets but lower in a data set assembled from published genomes. time and diversity estimates differ between data sets thus the presented methods allow comparisons of the diversity of crispr loci sampled from different populations.

for the yersinia pestis data from published genomes, we observe only few differences in the cas gene sequences but a high diversity at the spacer level. thus substitution

 rates cannot be compared with reliability, but nucleotide and crispr spacer data provide phylogenetic information at very different time scales. it is possible to compute cas gene phylogenies on the species level . in contrast, spacer information could be utilized for closely related strains that have only few differences in the other nucleotide sequences, which has already been done in using crispr in strain typing . the method presented here can be used to define groups based on the clustering or to find relationships between groups.

a steadily growing literature suggests many other possible mechanisms of crispr evolution apart from polarized addition and fragment deletion. spacer insertion can happen together with an internal deletion  <cit> , or at an internal repeat  <cit> . spacers or whole fragments may be duplicated  <cit> . and present spacers can guide the acquisition of new spacers from the same dna molecule  <cit> . note that these results affect only the insertion step of the crispr evolution process. but the fragment deletion model as it is presented here is based on the polarized insertion assumption. combining an unordered insertion with a fragment deletion process is currently infeasible. given these studies and the fact that the models presented here do not give substantially different results, the unordered model may be a robust choice for estimating rate and time parameters from crispr array data. note that several simplifications are possible for the likelihood computation under this model. first, for the start likelihood, the estimate of the poisson parameter is well known to be the mean of the data values. second, it is reversible, thus only the time between two arrays can be estimated and the ancestor generation can be omitted. third, the loss time can be calculated analytically and does not need to be acquired using simulations. to make the model comparisons fair, the same computational approach is used for all models in this paper. but it is possible to implement a more efficient approach for the unordered model. under this model, an algorithm for the likelihood computation on a phylogeny is also potentially feasible.

CONCLUSIONS
we present different models specific for crispr spacer content evolution. the three models differ in two aspects. first, fragment loss models differ from the independent loss models since they allow the loss of a succession of spacers in one event. second, the unordered independent loss model differs from the others since spacers can be incorporated throughout the array, not only on one end. a probabilistic model for each of these three models is presented here. we developed an approach derived from a well behaved stationary distribution, to establish the bounds on the state space that is a priori infinite. we find that the simpler model, without fragment deletions, is more robust. distance-based phylogenies can be calculated from the time estimates, but the rapid change of spacer content restricts this method to closely related strains with similar spacer content.

in summary, the models facilitate quantitative statements about the spacer dynamics of microbial communities. thus comparisons are possible, for example, between strain collections from one species at different locations or between different homologous crispr arrays in the same set of species.

competing interests
both authors declare that they have no competing interests.

authors’ contributions
jpb and ak designed the project. ak implemented the methods, carried out simulations and estimations and wrote the manuscript. both authors discussed the results and the manuscript. both authors read and approved the final manuscript.

supplementary material
additional file 1
proof of equation .

click here for file

 additional file 2
yersinia pestis spacer sequences for data set  <dig> yp <dig> in fasta format.

click here for file

 additional file 3
yersinia pestis spacer sequences for data set  <dig> yp <dig> in fasta format.

click here for file

 additional file 4
yersinia pestis spacer sequences for data set  <dig> yp <dig> in fasta format.

click here for file

 acknowledgements
the authors would like to thank christoph lampert, sebastian matuszewski and rodrigo a.f. redondo for productive discussions and helpful comments on the manuscript, and two anonymous reviewers for valuable comments improving the manuscript.
