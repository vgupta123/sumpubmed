BACKGROUND
blood oxygen level dependent  fmri  <cit>  has been widely used to detect brain activity. recently, brain activation patterns detected by fmri technology have been used as biomarkers to detect deception   <cit> . currently, the existing rule-based classification methods for deception detection have already achieved excellent performance  <cit> . in these studies, regions of interest were first identified through performing conventional group-wise statistical comparisons of brain activation patterns obtained during lying and truth-telling sessions. then, the activation patterns within the regions were used as input features to derive various classification rules. machine learning algorithms have also been applied to perform deception detection based on fmri data  <cit> . the task is commonly cast as a classification problem, in which pre-processed bold signals in the voxels of fmri images are treated as input features and each input image is associated with a class label. using fmri image data as input for classification poses a major challenge due to the high dimensionality of fmri images. the images usually consist of hundreds of thousands of voxels that causes most of the contemporary classification algorithms to suffer from overfitting – a phenomenon whereby a classifier performs well on training data but fails on new data. in this study, we investigated the utility of different dimension reduction and feature selection procedures in fmri-based deception detection. while this study concentrates on employing fmri-based biomarkers for deception detection, the principle developed in this study can be applied to other fmri-based biomarker for translational research, e.g., psychiatric disease diagnosis and prognosis.

RESULTS
classification without feature selection
when dealing with high dimensional data, two types of methods can be applied: dimensional reduction and feature selection. we first investigated a few models that perform high dimensional classification without selecting features. contemporary state-of-the-art classifiers, particularly partial least square   <cit> , random forest   <cit>  and support vector machine , have achieved excellent performance in various high-dimensional classification tasks, e.g., text categorization  <cit>  and microarray-based disease classification  <cit> . the pls algorithm deals with high dimensional data by reducing the dimensionality of the data through a linear project of data from a high dimensional space to a low dimensional principal component space, with a constraint of maintaining the class separation in the low dimensional space. rf handles high dimensionality by averaging the output from a large number of classification trees trained with relatively small number of features. svm employs kernel methods to project training data into a high dimensional space to make the data points separable and reduces overfitting through maximizing the margin that separates the data from different classes. since each classification task is unique, we first investigated how well these classifiers handled the high dimensional data and if they performed well over the fmri-based deception detection. the pls and rf classifiers ran extremely slowly on the data with  <dig>  features, which would render them impractical in the real world application. we then tested the methods on the data consisting of  <dig>  voxels selected in our previous study  <cit>  as features. we applied leave-one-out cross validation to estimate the accuracy, sensitivity and specificity. briefly, the performances of the above classifiers were not satisfactory in terms of overall accuracy. in pls classification, models with different number of principal components, from  <dig> to  <dig> and  <dig>  were trained. all models showed accuracy less than 60%. in the case of the rf classifier, models were trained with  <dig>  trees and the number of features for each tree varied from  <dig> to  <dig>   <dig>  and  <dig>  the accuracies for all trained models were smaller than 60%, which were deemed to be non-satisfactory. lastly, the accuracy of svm with the leave-one-out evaluation was  <dig> %. the above results indicate that the fmri-based classification is a unique task, in which directly applying conventional classification algorithms in an out of box manner does not perform well. the results also indicate that dimension reduction using pls and rf failed to provide practically acceptable performances.

another approach to reduce the dimensionality of the fmri data is to sample the bold signals using a large voxel size. in a recent report on fmri-based deception detection by davatzikos et al  <cit> , the dimensionality of the fmri image was reduced by sampling the bold signals using  <dig> large voxels, which are of the size  <dig> ×  <dig> ×  <dig> mm instead of the commonly used voxel size of  <dig> ×  <dig> ×  <dig> mm. then, the bold signal was modeled using a general linear model to produce a β-value for each voxel . using values from the voxels as input features, their in-house-developed svm model achieved an outstanding accuracy in the study. adopting a similar strategy, we tested the performance of svm on the re-sampled bold signals from the subjects of this study, and the overall svm classification accuracy was less than 60%. the discrepancy between our results and those from davatzikos et al. can be possibly explained by the differences in the subject populations and parameterization of svm models. while the resampling approach alleviates the difficulty of high dimensionality, large voxels  may potentially result in the loss of information regarding the anatomic structure involved in the cognitive process of deception. this prompted us in the direction of identifying the most discriminative features through feature selection, instead of through the dimension reduction approach.

classification with feature selection
methods for feature selection are mainly grouped into two categories: the filter approach; and the wrapper approach  <cit> . in the filter approach, feature selection is only based on predefined relevance measures and is independent of classification performance of specific classifiers. we investigated five feature selection approaches, including two filter methods, fisher criterion score   <cit>  and relief-f  <cit> , two wrapper methods, gar2w <dig> and gajh  <cit> , and an ensemble method. both wrapper methods use svm as the classifier and the genetic algorithm   <cit>  to search for the 'fittest' feature subset. the ensemble method is designed based on fcs, relief-f, gar2w <dig> and gajh . we applied these five methods on the data with  <dig>  features to identify the discriminative features.

to a varying degree, selection of features is a greedy process for all above methods. as such, the results will be biased by the samples used for training, especially when the number of training cases is small. in order to address this problem, we performed a ten-fold feature selection to identify the features that consistently performed well. the data set was divided into  <dig> folds. during each iteration, we held one fold, put the other  <dig> folds of data together and selected a set of  <dig> features based on these  <dig> folds. we repeated the process  <dig> times, which led to  <dig> sets of features for each approach: fcs, relief-f, gar2w <dig> and gajh. to evaluate the consistency of each of these four methods, we identified the features that were shared by  <dig> sets up to  <dig> sets. furthermore, we also identified the common features from all sets derived using the above four methods, which can be referred to as an ensemble method for feature selection. the number of the identified common features is plotted against the number of sets sharing them in figure  <dig>  comparing the within-methods consistencies of the two filter methods, we found that the fcs method returned no features that were share by more than  <dig> fold sets, while the relief-f method returned more features shared by more sets. the results indicated that feature selection according to fcs tended to be more easily biased by training data than relief-f. with respect to the between-methods-consistencies, the features returned by the two methods are largely disjointed: only  <dig> common features were shared in both sets of  <dig> features  and  <dig> features , which indicates that different criteria return different features. similar analysis on the features returned by wrapper methods showed that the number of common features was relatively small for the two ga-based methods. this reflects the nature of ga in that selection is stochastic and a large number of combination of features can have a similar fitness, due to the fact that ga does not select individual features based on their ranking. instead, it attempts to identify the best combination of features for classification. however, out of the  <dig> and  <dig> features returned by gar2w <dig> and gajh, respectively,  <dig> features were returned by both methods – a significant intersection. thus, although fewer common features were identified by each of the methods, the two wrapper methods using different criteria were capable of identifying the same features that were deemed discriminative. the figure also shows that, as expected, more selected features were shared in 4– <dig> fold sets when the ensemble of  <dig> sets was pooled. there were  <dig> common features shared in  <dig> fold sets using the ensemble method, which were later mapped back to the brain volume to identify regional brain activation patterns associated with deception activities.

to evaluate the impact of feature selection on classification performance, we used the common features identified in the above steps from each method to train svm and evaluated the performance with the leave-one-out procedure. the classification performance was measured in terms of accuracy, sensitivity, specificity and positive predictive value , and is shown in figure 2a–d. although each of the filter methods identified more common features, they were not necessarily discriminative. the performance using the features returned by both fcs and relief-f was worse than those using the wrapper methods. although fewer shared features were returned by the wrapper methods in comparison to filter methods, these features overall performed better than those derived from the filter methods in terms of accuracy and sensitivity. the observed superiority may be attributed to the consistency of the feature selection and the relevance of the features because a classifier and its theoretical error bounds were involved in feature selection. overall, the feature sets returned by the ensemble feature selection method outperformed those from each individual method. there are two potential advantages of the ensemble feature selection method. first, it combines the features selected according to different selection criteria, and thus covers different aspects of discrimination between classes. we noted that in panel c of figure  <dig>  the sensitivity of classification for the ensemble method shows a "bell-shaped" curve, in which the set of  <dig> features  provides the most discriminative power. from the ensemble method, the numbers of features shared by 4– <dig> candidate sets are greater than those from the individual feature selection methods. the additional features potentially make the classifier more resistant to variances in the signals associated with each feature. however, this does not indicate that more features result in better performance.

anatomic locations of the selected features
we mapped the  <dig> selected features from the ensemble method back to the brain volume and inspected the feature locations, which are shown in figure  <dig>  panel a of the figure shows the localization of the voxels selected as discriminative features and panel b shows the overlapping of the features selected in our previous and this study. interestingly, although the features are far apart in the input feature vector for classifiers, they tend to form clusters in the brain regions . the corresponding brain regions, reported for clusters of at least  <dig> contiguous voxels, were bilateral supplementary motor area , right medial superior frontal cortex , right middle frontal gyrus , left rolandic operculum , right putamen and pallidum, right inferior orbitofrontal cortex , and left cerebellum. supplementary motor area  is one of the most frequently reported areas across studies of deception  <cit> . there is general correspondence  between brain regions identified in the present analysis and brain regions previously reported to have predictive value in detecting deception, such as supplementary motor areas , right inferior orbitofrontal cortex , and right middle frontal gyrus   <cit> .

the anatomic overlapping of the selected features with the brain regions from the previous studies indicates that the feature selection procedure provides another means to identify the brain regions that may be involved in the psychological process of deception. however, it should be noted the method in this study for identifying the brain regions is significantly different from the previous ones. in the previous analysis  <cit> , all fmri images associated with one type of event, e.g., truth or lie, were pooled from all subjects, followed by group-wise comparison to identify the regions with differential brain activities. therefore, the procedure was not classification oriented, and the features from this procedure resulted in a relatively poor classification performance using our methods. on the other hand, the feature selection approach from this study combines the procedure of using t-maps to remove background noise and selecting features that are relevant to the classification. therefore, it is not surprising that the features from this task-oriented procedure significantly enhanced classification performance.

CONCLUSIONS
in this study, we investigated the utility of feature selection in fmri-based detection of deception. the high dimensionality of fmri data makes it a difficult task to directly utilize the original data as input for classification algorithms. our results indicate that feature selection not only enhances classification accuracy in fmri-based detection of deception when compared to the models that rely on dimension reduction, but also provides support for the biological hypothesis that brain activities in certain regions of brain are important for the discrimination of deception. while these conclusions were obtained in the setting of detection of deception, the general approach of feature selection is applicable to the identification of other fmri-based biomarkers.

