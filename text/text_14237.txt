BACKGROUND
dissociation of neural activity related to processing objects belonging to different semantic categories has been demonstrated in several neuropsychological and functional neuroimaging studies . for example, tranel et al.  <cit>  demonstrated that word retrieval in response to visually presented concrete entities engages neural systems in the left temporal lobe and that the precise pattern of activation in the temporal lobe depends in part on the conceptual category to which the entity belongs. for instance, they found that patients with defective retrieval of concepts for persons had brain lesions that extended to the right temporal polar region, patients with defective retrieval of concepts for animals frequently had lesions in right mesial occipital and mesial ventral temporal regions, and patients with abnormal retrieval of concepts for tools had lesions that were localized to the left lateral occipital-temporal-parietal junction. according to the authors, their findings support the hypothesis that normal retrieval of semantic information about concrete entities from different conceptual domains depends on partially segregated neural systems.

warrington and colleagues <cit>  proposed a model of representation for conceptual knowledge called modality-specific semantic memory that explains why damage to a particular modality-specific semantic system results in a specific impairment for a given semantic category, such as animals or persons. according to the model, dissociation of different semantic domains occurs because of the different types of perceptual and sensorimotor information that are associated with entities of different semantic categories. thus, the representation of artifacts is more strongly associated with functional and action-related features, whereas the representation of natural objects is more strongly associated with sensory and perceptual features. the results of several functional neuroimaging and electrophysiological studies support the modality-specific semantic memory model  <cit> . for example, it has been observed that the lateral posterior fusiform gyrus responds more robustly to animate than inanimate objects, suggesting that there may be specific brain regions devoted to encoding visual properties of animate objects  <cit> . other studies have shown bilateral activation of inferior occipital-temporal cortex for natural objects, as opposed to a left hemispheric activation for artifacts  <cit> .

in addition to the literature on perceptual processing, neuroimaging and erp studies on language processing provide evidence of category-specific functional dissociations. for example, left frontal anterior regions are active during processing of function words  <cit> , temporal-parietal areas are active during processing of nouns  <cit> , and abstract words were more likely than concrete words to activate anterior brain areas  <cit> . verbs are more likely than nouns to activate anterior brain regions, including motor and premotor areas  <cit>  and other left frontal areas  <cit> , thus supporting the hypothesis.

according to caramazza and coworkers  <cit> , who proposed the domain-specific model of representation of conceptual knowledge, neural circuits dedicated to processing particular semantic categories are neuroanatomically and functionally segregated. these category-specific semantic systems may have originally evolved because rapid and efficient identification of objects from particular categories had survival advantages, and reflect an innate categorical organization of the brain. the model proposes that domain-specific representation systems, which are accessed by verbal and non-verbal stimuli, store conceptual information related to one particular category. according to this view, damage to one semantic system impairs all semantic information pertaining to one category . on the other hand, tyler and moss  <cit>  proposed a model in which semantic categories  and domain  are not explicitly represented but are emergent properties of the structure and content of semantic representation, and categorical dissociations would depend on the specific patterns of brain activation in response to stimuli characterized by specific perceptual and functional features. for instance, distinctive or shared features of stimuli determine the degree of segregation or overlap in the locus of brain activation. therefore, the sites of activation in response to "lion" and "canary" would be similar not because the words belong to the same domain , but because they share domain-relevant perceptual properties . the authors are very critical about the theory postulating a clear neuroanatomical segregation of neural circuits devoted to processing of distinct semantic categories, and base their claim on the many inconsistencies present in the neuropsychological and neuroimaging literature failing to provide clear dissociations, especially for processing of living vs. non-living things. therefore, according to these and other authors  <cit>  conceptual knowledge would be represented within a unitary distributed system without clear functional and neuroanatomical boundaries.

in this regard, gerlach et al.  <cit>  performed a positron emission tomography  study in which they compared regional cerebral blood flow  in two different conditions. the first condition was a categorization task in which subjects decided whether pictures represented artifacts or natural objects, and the other was a decision task in which subjects decided whether pictures represented real objects or non-objects. the categorization task was associated with activation in the left inferior temporal gyrus. the object decision task was associated with bilateral activation of the fusiform gyrus. the results suggest that the fusiform gyrus may be involved in first-pass processing of structural object properties, and the left inferior temporal gyrus may be involved in the analysis of functional and semantic object properties. however artifacts and natural objects often caused activation in the same regions within tasks. therefore, the authors concluded that categorization and object recognition are not totally segregated processes. similarly, results of other studies support the hypothesis of a distributed representation of visual objects in the ventral temporal cortex  <cit> .

in summary there isn't a general agreement on the way conceptual knowledge is represented in our brain. as for the time course of neural processing related to object categorization several electrophysiological studies have examined the timing of brain evoked responses to determine when semantic knowledge is segregated in the human brain  <cit> . ji and colleagues  <cit>  found a specific involvement of right frontal cortex  during categorization of vegetable/fruits which was absent in the topographic distribuition of animal-elicited erps, in a match/non-match s1–s <dig> paradigm. however a difference in familiarity or perceptual complexity of vegetable with respect to the animal exemplars  was not considered in this study. the authors also found a greater posterior n <dig> to animals than vegetable/fruits. on the contrary, sitnikova and colleagues  <cit>  recorded erps in response to pictures of animal and tools and found an increase in negative potentials associated with tools compared to animals at left posterior and anterior areas in response to animals 200– <dig> ms after stimulus onset. they did not find an early  effect of stimulus category in response to animate and inanimate objects. similarly, sim and kiefer  <cit>  presented  <dig> pairs of names of common objects, half of which were artifacts  and half of which were natural  in a feature verification task with verbal stimuli. word pairs were formed such that objects were visually and/or functionally similar. in the first phase, the task was to decide whether the two objects belonged to the same category . erps showed that natural objects elicited a larger positive potential than artifacts over occipital-parietal areas in the n <dig> and late positive  time windows, particularly over the right hemisphere. in the second phase, half of the subjects had to decide whether objects had similar shapes . the remaining subjects had to decide whether the function of objects was similar or dissimilar . erps were more positive to words that represented natural objects compared to those representing artifacts over the right occipito-parietal area, but only during the visual judgment task. the results suggest that the processing of natural categories depend relatively stronger on the activation of posterior brain areas, thus supporting the notion of a modality specific semantic system.

in a previous erp study, kiefer  <cit>  investigated category-specific categorization mechanisms by comparing visual and verbal modalities with pictures and words referring to natural and artifactual categories. first a category probe was shown which was followed by a target stimulus. the task was to decide whether the target object was a member of the previously presented category. for example. probe = "animal", target = "cat". in the perceptual condition  primers and targets were images of animals and tools. in the verbal condition, targets were written names of objects. interestingly, there was an early inferior temporal n <dig> response that was greater to natural objects than artifacts, but only in response to images, not written words. the authors concluded that 1) there was greater activation in response to natural objects due to simultaneous activation of multiple competing exemplars, 2) perceptual information  was more relevant than linguistic information  for natural entities, and 3) the greater relevance of perceptual information for natural objects was due to high within-category similarities.

in order to further investigate the neural mechanisms that support processing of objects belonging to different domains we used a perceptual categorization task without involving linguistic functions. at this purpose no verbal stimuli were used but only drawings of man-made objects and animals. erps to pairs of objects and animals  were recorded while participants performed a super-ordinate categorization task. different stimuli to be compared by viewers were not similar in shape. in order to be correctly recognized as belonging to the one or the other category their perceptual or functional properties were to be accessed as quickly and accurate as possible to perform a speeded response. the goal of the study was to investigate 1) if any difference in brain activation was observed as a function of stimulus semantic category , 2) more importantly, when exactly in time this difference was observable. in this regard, the event-related potentials technique is a very powerful tool for investigating the time course of information processing because of its capacity to record brain activity generated in different cortical and sub-cortical regions with a very high temporal resolution .

while the majority of studies on the representation of conceptual knowledge in the brain involves linguistic coding, our intent was to investigate the emergence of semantic categorization in visual processing by means of a purely perceptual task. we predicted that if the observed differences consisted, for instance, in a greater response of visual areas for animals and of anterior and motor areas for man-made usable tools, within the first  <dig> ms of processing, this would suggest an early semantic catogorization emerging from the specific patterns of brain activation, and thus supporting a modality-specific representation of conceptual knowledge.

in this study subjects were asked to make a categorization judgement based on the semantic distinction between animate and inanimate stimuli based on image-specific structural and functional information. the task consisted in paying attention and responding to homogeneous pairs of animals  presented in a given field, while ignoring mixed configurations or location irrelevant stimuli. in this paper we report patterns of brain activity related to processing of animals vs. artifacts but independent of attentional factor .

RESULTS
behavioral data
an analysis of variance  demonstrated a significant effect of category on response latency . subjects responded much faster to animals  than objects . neither visual field nor response hand affected reaction time . an analysis of false alarms showed a significant effect of category , with a higher percentage of errors made for artifacts  compared to animals .

electrophysiological data
the latency and amplitude of the early sensory c <dig> component  and the p <dig> component  were not affected by stimulus semantic category, indicating that stimuli were balanced in terms of luminance and spatial frequency .

the analysis of n <dig> peak amplitude revealed an effect of stimulus category with larger n <dig> responses to animals  than artifacts . post-hoc analysis of the significant category × hemisphere interaction suggested that, at this latency, the right hemisphere was significantly more sensitive than the left to stimulus category, with a greater difference in the response to animals than objects , as shown in fig.  <dig> 

temporal series of scalp current density  difference maps were computed between 120– <dig> ms with a pass of  <dig> ms. differences were obtained by subtracting scd maps for artifacts from those for animals. the earlier involvement of right posterior temporal cortex in the discrimination between the two shape categories is evident in fig.  <dig> 

an anova of the n <dig> latency showed a significant interaction of category × visual field × electrode. post-hoc comparisons indicated that the n <dig> component had a shorter latency at lateral occipital and posterior temporal sites in response to animals  compared to artifacts  that were presented in the left visual field .

the amplitude of the n <dig> component, larger at mesial occipital sites, was affected by stimulus category, in interaction with hemisphere. again, the right hemisphere was more sensitive to semantic category: images of objects that were presented in the left visual field elicited a larger negative  potential than images of animals  over the right hemisphere, as demonstrated by a significant category × visual field × hemisphere interaction and post-hoc analysis .

the anterior n <dig>  larger at central sites, showed a similar amplitude in response to contralateral and ipsilateral stimuli in the rh and a much larger response to contralateral stimuli at left sites, where it reached its maximum amplitude, as shown by hemisphere × visual field interaction. it was strongly affected by stimulus category, being much larger in response to artifacts  than to animals , as shown in fig  <dig>  this effect showed an anatomic specificity  with a significant animal/object difference at anterior  but not than temporal sites, as shown by post-hoc comparisons .

anteriorly, the n <dig> component  was larger at temporal sites and exhibited a marked left hemispheric asymmetry as also visible in maps of fig.  <dig>  overall n <dig> was sensitive to stimulus category being larger in response to artifacts  than to animals . the category dissociation was bilateral at frontal/central sites, and strongly lateralized toward the left hemisphere at temporal sites. indeed n <dig> showed its maximum amplitude in response to artifacts  than animals  at left temporal site, as shown by significant category × electrode and category × electrode × hemisphere interactions 

the anova performed on latency values of parietal p <dig>  which was earlier in the left than right hemisphere, demonstrated a significant category × hemisphere interaction, with earlier p <dig> peaks in response to artifacts  compared to animals  at left sites .

p <dig>  which reached its maximum amplitude at parietal sites, was strongly affected by stimulus being larger to animals than artifacts . in contrast to the p <dig> component, the n <dig> response at central-parietal sites was greater to artifacts  than animals , as shown by a significant effect of category. fig.  <dig> shows a time series of difference maps computed in the n <dig> latency range  that were obtained by subtracting the scalp voltage distribution of erps to animal stimuli from those to artifact stimuli and showing the distribution of negative potentials that were larger in response to artifacts. in the following interval , the lp component, showing a midline distribution, was very sensitive to stimulus category, being it larger in response to animals  than artifacts .

in this study subjects were required to press a button in response to target pairs of animals or artifacts without directly accessing or providing verbal or conceptual representation of the items. their complexity and familiarity was rated post-hoc according to the instructions of snodgrass and vanderwart  <cit> . our results demonstrated that stimuli for both categories were at an identical level of complexity , with a slightly greater level of familiarity for artifacts  than for animals . response latencies were not affected by stimulus complexity or familiarity. rts were faster to equally complex but less familiar objects .

early perceptual effects
our data showed an early effect  in right posterior visual areas. indeed, the right occipital-temporal cortex was significantly more sensitive than the left to stimulus category in the 120– <dig> ms interval. a similar increase in the early negative response to natural but not artifactual stimuli was observed by kiefer  who reported larger n <dig> potentials over inferior temporal-occipital regions in response to images of animals compared to images of tools. the topography of the category-related erp effect is also consistent with results of neuroimaging studies, which suggest that processing natural stimuli is more dependent on the visual association cortex in occipital-temporal areas than is processing artifactual stimuli  <cit> . there is also evidence that the right occipital-temporal cortex, and to a lesser extent its contralateral counterpart, is involved in the representation of natural categories . in addition, the greater activation in right visual cortex in response to animals compared to artifacts may be related to specific activation of the visual face area, a region in the central occipital-temporal cortex that includes the fusiform gyrus  and has been shown to respond more robustly to faces than to other objects, such as houses, tools, and inverted faces. activation of this area has been identified in the posterior n <dig> component  <cit> .

on the other hand, the larger frontal/central n <dig>   in response to artifacts than animals is consistent with the data by antal and colleagues  <cit>  who found a greater n <dig> to non-animals  than animals at frontal sites  in a visual categorization task.

it is also consistent with the literature supporting the notion of an anterior brain activation for accessing knowledge related to actions and motoric patterns such as verbs as opposed to nouns  <cit> , manipulable tools as opposed to animals  <cit>  or manipulable objects in natural as opposed to awkward grips  <cit> .

the differences we observed in early brain activation during stimulus processing and recognition are likely due to structural differences in animals and artifacts that might have a strong effect on sensory and perceptual processing. animals are more homomorphic  than artifacts  <cit> . conversely, inanimate objects share fewer characteristics and may belong to an infinite set of specimens. therefore, object processing appears to be performed by a set of multi-processes that analyze physical and functional properties of an object. on the other hand, recognizing animals might involve only sensory identification of physical features  <cit>  such as faces, eyes, and legs. interestingly, it was suggested that processing stimuli belonging to a specific semantic category reflects processing demands that are jointly determined by representational structure and the particular task being performed  <cit> .

later erp effects
processing images of animals was associated with faster rts, larger occipital-temporal n <dig> components and larger parietal p <dig> and lp components. these results suggest that animal recognition was less demanding than object recognition. the much larger parieto/occipital activation related to animal than artifacts at p <dig> level  displayed in maps of fig.  <dig>  might be interpreted also as greater involvement of visual sensory areas in the processing of associate semantic features. on the other hand, processing images of artifacts was associated with slower rts and larger posterior n <dig>  frontal/central n <dig>  anterior temporal n <dig> and centro-parietal n <dig> responses. these effects were probably linked to the larger positive potentials elicited by animal images. they are consistent with those described by kiefer  <cit>  for the perceptual study , showing shorter rts and smaller central-parietal n <dig> responses to natural compared to artifactual stimuli . on the other hand, they do not agree with the findings of sitnikova et al.  <cit> , who reported larger negative components 200– <dig> ms after presentation of animals compared to tools and no differences in rts or accuracy for stimuli from different categories. the authors interpreted their results in terms of quick, direct access to functional semantic representation for tools compared to animals.

one might hypothesize that the larger n <dig> response to artifacts compared to animals is related to differential inter-category stimulus familiarity. indeed, the right central-parietal linguistic n <dig> component, which shared topographic distribution and functional properties with the image-evoked n <dig> in the present study, is described in the literature as having greater amplitude to low compared to high frequency items and to pseudo-words compared to words. that is, the n <dig> potential is larger in response to unfamiliar compared to familiar items  <cit> . kiefer  <cit>  reported a smaller negative potential over the right parietal region in response to natural objects compared to artifacts, with stimuli that had been rated as equally typical but not equally familiar or complex. in that study, stimulus complexity and familiarity was rated post-hoc according to the instructions of snodgrass and vanderwart  <cit> . results showed that artifacts were rated as slightly more complex  and less familiar  than animals. in that case, the n <dig> effect might have hardly been interpreted as an index of increased response to less familiar pictures. furthermore, in our study, animals and artifacts were judged as equally complex in perceptual structure, and artifacts were judged as only slightly more familiar than animals . therefore, late category effects on the n <dig>  which in the kiefer's study  <cit>  were observed independent of input modality , cannot be accounted for by factors like visual complexity or familiarity and according to kiefer might reflect modality-specific feature-representation within the semantic system. in other words, it might reflect a stronger access to visual semantic features stored in posterior brain regions for animals than artifacts.

the n <dig> component is believed to index semantic integration processes and the difficulty with which new information is processed and integrated with previously stored information, including semantic and world knowledge  <cit> . accordingly, a larger n <dig> in the right central-parietal area that is clearly visible in fig.  <dig> might also reflect a difference in semantic categorization processes. indeed, our behavioral data, showing slower rts and more frequent categorization errors for artifacts compared to animals, support this interpretation. decision-making processes are likely to be more difficult for less homogeneous items than items that share more perceptual  and semantic  properties. and indeed recently, paz-caballero and colleagues  <cit>  provided evidence of a dissociation between difference in semantic domains for natural vs. artifactual entities, and difference in task difficulty. in their study categorization of natural stimuli was associated with faster rts and larger late positivity , and was interpreted with the notion that natural stimuli are easier to correctly categorize than artifactual stimuli, due to greater perceptual similarity, and as supported by available literature  <cit> . artifactual objects may be even slightly more familiar than objects if presented singularly  but difficult to discriminate if presented randomly mixed.

general discussion
our data provide evidence of differential brain activation during visual categorization of items belonging to animal and artifact categories. at early latency stages  the right occipital-temporal cortex exhibited larger potentials to familiar, homomorphic, visually salient objects with faces  compared to artifacts. on the other hand, rts were slower, p <dig> was smaller, frontal/central n <dig> and anterior temporal n <dig> and n <dig> potentials were larger to equally complex and familiar artifacts, especially usable man-made objects. these data are consistent with literature that supports the idea that activation of anterior brain regions is greater during perception of manipulable tools compared to non-usable objects  <cit> . for example, a recent fmri study  <cit>  demonstrated that viewing graspable tools, but not shapes, activated motor-related regions of cortex . the authors concluded that the functional identity of graspable objects influences the extent to which they are associated with motor representations.

CONCLUSIONS
overall, our data are compatible with a model in which sensory and action-related semantic features of objects are represented in modality-specific brain areas. according to this model, category-specific differences in the type and distribution of neural response depend on several factors, including object imageability; motor association  <cit> ; abstractness  <cit> ; content of sensory information  <cit> ; complexity; familiarity ; the presence of learning-independent cues, such as eyes, faces, and hands ; learning ; homomorphism  <cit> ; content of acoustic or phonetic information  <cit> ; content of spatial information ; complexity of spatio-temporal mnestic coordinates ; and not necessarily semantic domain.

however, the present data are not inconsistent with the view that there may be some overlapping in the way objects belonging to different semantic domains are represented in the brain, in line with other neuroimaging data. for example, haxby and colleagues  <cit>  showed that, while it is possible to identify specific regions of ventral temporal cortex responding maximally to a specific object category , patterns of response that discriminate among all categories are found even within cortical regions that respond preferentially to one category.

