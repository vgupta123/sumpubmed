BACKGROUND
our understanding of molecular basis of complex diseases is being dramatically changed by systems investigation supported by the most advanced tools and techniques developed by the scientific community. in particular, cancer investigation has greatly benefited by systems level approaches since tumor development and progression are believed to be among those system trajectories that arise from abnormal working states. the work by hornberg and colleagues  <cit>  pointed out the relevance of systems biology approaches in the study of dynamics leading to cancer. epidermal growth factor receptor  pathway is one of those biochemical reaction networks believed to play a central role in cancer development. as a matter of fact egfr and receptors in the same family  mediate cell to cell interactions both in organogenesis and in adult tissues  <cit> . the 40-year long study of this pathway led to associate overexpression of the egfr family members to several types of cancer  <cit> . because of the high clinical relevance, several efforts have been spent in the last decades in unravelling the complex dynamics of this biochemical network, as well as in finding potential targets of therapeutic intervention  <cit> . although global models of egfr pathway exist  <cit> , many questions still remain open both in terms of model accuracy  <cit> , parameter identifiability  <cit>  and driving input design  <cit> . in this context we put the pioneering works by arkin and colleagues  <cit> , van oudenaarden and colleagues  <cit>  and steuer and colleagues  <cit> . other recent works have focused on the connections between optimal experimental design strategies and structural and experimental identifiability analysis of biochemical pathways; this is the case of  <cit> .

structural identifiability refers to the possibility of finding the mathematical model of the true system , after having applied a specific search strategy in the space of the solutions.

experimental identifiability  <cit> , on the other hand, is related to the possibility of finding the mathematical representation of the true model given a predetermined set of observations. this is a central aspect of this class of identifiability problems since it is more focused on the available data and, in particular, on information content. this aspect establishes an interesting bridge between system identification theory and experimental design. the design of experiments  is a well developed methodology in statistics  <cit>  focusing on the design of all information-gathering exercises where variation is present, the main objective of the whole task being the maximisation of the information obtained from experiment and the minimisation of the number of experiments. this specific task is commonly referred to as 'optimal experimental design' . this discipline quickly gained a significant interest among researchers mostly in natural and social sciences but became an active research field in engineering only with the pioneering work by lennart ljung and his standard model for dynamical system identification oriented experiments  <cit> . this model has been recently modified by phair et al.  <cit>  and cho et al.  <cit> .

nevertheless the main idea behind system identification in systems biology remained unchanged  <cit> . in line with fisher's criteria, ljung's scheme  <cit>  suggests to define a detailed plan of the experiments to be carried out before starting to collect input-output data from the system to be modeled. specifications like data sampling strategies and driving inputs should be fixed in order to optimise the information yield of each experiment and to address the cost minimisation task oed is aimed at. these issues gain an even stronger relevance, if we consider the so-called 'data rich-data poor paradox'  <cit>  resulting from the difficulties and costs involved in systems biology related assays. for these reasons and in order to develop a comprehensive framework for system identification in systems biology, we will describe how a specific issue of oed, namely optimal input design , can be addressed using optimality criteria and microfluidics-based experiments. as a matter of fact, microfluidic platforms have been shown to provide a powerful tool for the development of data-rich experimental strategies able to fill the gap of the previously cited paradox. signals obtained in this stage are used as templates for the development of a microfluidic device for a flexible and automated platform for affordable single-cell experiments in systems biology.

in the following paragraphs, we go through a brief introduction of the egfr model then we analyse oed and oid criteria. we review current approaches to cell stimulation in the 'methods' section and compare them with optimality criteria derived ones. an analysis of the experimental results follows in 'results', where we introduce a feasible design of the microfluidic device thought to speed up the process of data collection in systems biology by lowering the costs associated to experiments. a discussion of the results presented herein and final cues for further research are given in the last paragraph.

RESULTS
in order to model and understand the functionality of the egfr signaling cascade a quantitative description of the signal dynamics is of major relevance. for this reason, we discuss the computational results obtained from in-silico simulations carried out using potterswheel <cit> . potterwheel is a multi-experimental fitting matlab package intended to allow researchers to ease model analysis and experimental setup steps. in particular, this package is one of the few in systems biology providing a simple interface to external input based simulation of biological pathways behavior.

to estimate the effects of different inputs on parameters estimates uncertainties, we carried out  <dig> identification experiments for each of the three classes of stimuli, namely: a step input, a persistently exciting input and the time profile of the stimulation obtained from the optimisation task. therefore we plotted a bivariate distribution of both the vmax and km of the first michaelis-menten based reaction  in kholodenko's model accounting for the dephosphorylation of the egf-egfr dimer. it should be noted that parameter correlation can greatly affect our ability to successfully recover real parameters. this is one of the main issues arising in the field of parameter idenfitiability. in particular parameters that are structurally correlated cannot be uniquely identified from experiments. in order to investigate such peculiarities of our dynamical model we carried out an identifiability analysis based on the 'alternating conditional expectation' algorithm  method described in  <cit>  and implemented in the mean optimal transformation approach  package. we present herein the computational results so as to provide a tool for comparing the different approaches to oed in systems biology.

identifiability analysis
the statistical investigation of the properties of oed should be a primary goal when the time profile of the input is computed. previous works in this field have focused on the comparison among alternative designs on the fim cost values and confidence intervals  <cit> . nevertheless it has been noticed that the fim is derived from a linearisations of the least squares thus it may be unreliable in cases of considerably extended non linearities. the non identifiability of one of the parameters directly implies the functional relationships among at least two of them  <cit> . this phenomenon can be easily observed by plotting the joint probability distribution of each of them which will show statistically significant differences if compared with the expected multivariate normal one. from an algebraic point of view this results in the loss of rank of the covariance matrix of the multivariate distribution or, alternatively, a condition number of the same matrix asymtotically tending to infinity. then, in order to cope with identifiability issues that may arise in identification tasks, we propose to investigate this property by using the ace method proposed by hengl and colleagues  <cit> . mota package is included in potterswheel toolbox and is applied together with a linear fit sequence analysis. mota detects groups of two or more linearly or non-linearly related parameters. it revealed some major non-identifiabilities in the parameter space  whose nature should be certainly investigated in order to understand their causes and possible solutions. we should remark that an integrated approach using monte-carlo methods for both experimental design otpimisation and parameter correlation investigation can be a feasible choice. however, we should consider that this would imply a major rise in computational costs of the approach resulting fom the high number of parameter estimation tasks to be accomplished. not to mention the issues arising from large scale models, noise and potential multimodality that would certainly imply using a robust global optimisation algorithm.

monte-carlo based analysis
several alternative choices to dynamic optimisation methods have been used in the context of oed, the most widely employed are direct methods such like complete parameterisation, control vector parameterisation and multiple shooting approach  <cit> . these methods are based on the transformation of the original infinite dimension optimisation problem into a non linear programming problem through the discretisation of the state and the stimuli or only the stimuli and the approximation of the time dependencies using locally defined function. in this work, we employed a slightly different approach with similar discretisation strategies but based on an genetic algorithm ; for this purpose we used the implementation provided by matlab through the ga routine. it should be noted that no formal proof of the convergence of gas can be derived for the problem at hand. however, some property of this kind of approaches, just like computational complexity and efficiency can be studied in a more formal context  <cit> . we set the population to be composed by  <dig> individuals and we used the tournament system as selection criterion; crossover and mutation operators were set to 'uniform' and 'heuristic' respectively. all the other options were left at the default values while constraints on signal amplitude reflecting technological limitations were coded in the appropriate arrays . as previously outlined the fitness function of this ga encodes for the fim associated to the specific experimental design under investigation. in order to investigate if any statistically significant difference existed between parametric uncertainties estimated from classical and oed based experiments, we developed a monte-carlo based analysis with n =  <dig> repetitions. we collected parameter estimates for each identification experiment. at this stage we carried out an intermediate analysis to find the parameters with the highest relative uncertainty; we selected the highest two, namely v <dig> and k <dig>  a χ2goodness-of-fit test confirmed that the probability density function for these parameters can be well approximated by a normal curve. in order to compare the three experimental design selected we performed a gaussian mixture model  fitting of the identified parameters starting from a bivariate distribution arising from k <dig> and v <dig> variables. estimates were normalised and then plotted. figure  <dig> shows the distribution of parameters estimates couples from sustained input experiments; fig.  <dig> and  <dig> show the same plot for persistently exciting and oid based esperiments, respectively. the plots show the 95% confidence interval of each distribution computed as the ellipsoid centered in the mean of the bivariate distribution and having:

• major semiaxis equal to λmax

• minor semiaxis equal to λmin

• rotational offset with respect to the the x axis equal to 

where cov is the covariance matrix estimated from gmm fitting and λmax/λmin its max and min eigenvalues respectively, while yeigv and xeigv are the y and x component of the eigenvectors of cov matrix. figure  <dig> shows the 95% ellipsoids of the three experimental designs compared. it is evident that the volume of the uncertainty ellipsoids gets minimised by more appropriate designs. moreover the oid based strategy proves to be the one providing the best experimental conditions for accurate parameter estimation and system identification. in order to obtain a more quantitative estimation of the information gain provided by oed based experiments we performed an ansari-bradley test  <cit>  on the estimated parameter values; the ansari-bradley test checks the hypothesis that two independent samples come from the same distribution, against the alternative that they come from distributions that have the same median and shape but different variances. pairwise tests carried out on oid vs pe and oid vs step experiments returned p-values smaller than  <dig>  thus supporting the rejection of the null hypothesis and then suggesting evidence of statistically meaningful advantages of oed based experiments over both pe and step input based ones.

CONCLUSIONS
the intrisic quantitative nature of systems biology poses new issues in everyday laboratory practice. modelling, in this context, has long suffered from data shortage; the 'data rich-data poor' paradox greatly influenced the pace towards a comprehensive understanding of molecular mechanisms governing biological systems. nevertheless the potential of novel experimental techniques seems to promise new groundbreaking innovations thus increasing the versatility of new laboratory protocols and keeping experiment-associated costs low. among these major limitations we should certainly mention the ability to stimulate cells in chemostats with input having very limited harmonic content. microfluidic technology currently allows us to go beyond step like stimulation and to generate complex time-varying signals whose modulation can be achieved using control engineering strategies  <cit> . the availability of such tools and devices will allow us overcome the limits of indicial response for highly complex and fed-back dynamical systems identification as outlined in  <cit> . in this framework, the ability to optimally control and take advantage of the new methods and devices will be a major focus of the scientific community. this contribution presents, then, a mathematical formulation of the problem of optimal experimental design in systems biology by considering a case study of one of the most relevant biological pathways for cancer development. formal derivation of problem definition results and heuristic solutions to a highly non-linear optimisation problem have been both provided. in particular we formulated the problem of oed in systems biology as a non-linear optimisation task in which the amount of information per experiment, quantified in the fisher information matrix, is optimised by varying the stimulus time profile here representing the concentration of extracellular egf ligand. we set up an evolutionary optimisation task aimed at finding the time sequence of the input signal that maximises the amount of information associated to the experiment. moreover we proposed a statistical framework based on monte-carlo estimates for the computation of the uncertainty regions for the parameter values; identifiability analysis, on the other hand, has been carried out using the ace approach integrated in potterswheel package. the results shown clearly indicate that dynamic experiments outperform canonical experiments based on sustained or persistently exciting inputs. nonetheless we should consider that the approach presented herein depends on the starting model; a sequential experimental design should be investigated in order to overcome this issue. moreover we should consider that all the simulations reported should be validated in a series of experiments. for this reason, we proposed the microfluidic device described in the 'methods' section. 'labrys' goes beyond the specific context of egfr and, associated to a hardware abstraction layer like biosteram  <cit> , is thought to provide researchers with a fully automated platform for complex experiment development and implementation. future work in this field will certainly require a more tight collaboration among the different competences in the field of systems biology aimed at the full integration of both hardware and software findings for the development of a common, powerful and versatile platform for systems oriented experiments.

