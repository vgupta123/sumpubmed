BACKGROUND
cancer is driven by genomic alterations. recent advances in high-throughput sequencing technologies allow identification of somatic alterations at an unprecedented resolution
 <cit> . in particular, numerous large-scale cancer projects scan for somatic mutations in various tumor types, prior to conducting downstream analyses such as detecting significantly mutated genes or pathways
 <cit> , inferring clonal history
 <cit> , and characterizing the landscape of the somatic mutations
 <cit> .

nonetheless, accurate somatic mutation-calling using high-throughput sequence data remains one of the major challenges in cancer genomics. for somatic mutation-calling, one looks for a site in which a variant allele exists in the tumor sample but not in the normal sample. even with the sequence data from a normal sample, variant calling in high-throughput sequencing data is challenging due to various sources of errors such as artifacts occurring during pcr amplification or targeted capture , machine sequencing errors, incorrect local alignments of reads
 <cit> . tumor heterogeneity and normal contamination add additional challenges for the tumor samples.

understanding mutation-calling errors is constrained by the availability of the validation data. false positives can be learned by validating every called site, but experimentally validating all such sites across a whole exome or genome is laborious and expensive. learning about false negatives can be even more difficult. even independent sequencing at a much higher sequencing depth or using a different sequencing technology does not guarantee the finding of all true mutations. comparing outputs from multiple callers and learning from their discrepancies, however, can be a fast and practical solution to study calling errors to some extent. false negatives from one caller could be revealed by mutations detected by other callers. calls that are uniquely detected by a certain caller are likely to reveal at least a partial set of false positives from that caller.

one such comparison example is the the cancer genome atlas mutation-calling benchmark study in which several major analysis centers called mutations on a set of selected samples. a venn diagram summarization of the outputs immediately revealed substantial discrepancies among the calls from different centers, but a more thorough analysis was necessary for better characterization and assessments of the callers. similar exercises can be easily conceived by anyone who is interested in performing mutation analysis, since mutation-calling is a rapidly growing field and there is unlikely to be a single “best” caller.

to provide guidelines for more illuminating analyses in comparing multiple callers beyond venn diagrams, we present how we have analyzed two datasets generated for tcga benchmark studies. one dataset was generated by applying four mutation-callers to illumina exome-seq pairs from  <dig> lung squamous cell carcinoma  patients. the other dataset was generated by applying three callers to solid exome-seq pairs from  <dig> rectum adenocarcinoma  patients. for each dataset, partial validation data exists. for the lusc dataset,  <dig> genes were independently sequenced at a higher coverage by the illumina technology, allowing in-depth investigation of called sites within the  <dig> genes. for the read dataset, validation information based on the  <dig> sequencing technology was available for  <dig> sites.

we characterized the discrepancies in the two datasets in various ways. furthermore, based on the insights gained by analyzing these data, we introduced four approaches to comparing the relative performances of multiple callers. the first is using independent dna-sequencing data, available for  <dig> genes for lusc patients, to validate detected mutations. the second utilizes the tumor rna-seq data to validate variants in the tumor samples. the third method uses the variant quality scores obtained by running a publicly available variant caller, the gatk unifiedgenotyper <cit> , on the original exome-seq data, to define pseudo-positives  and pseudo-negatives. the last approach estimates the sensitivity and the specificity of each caller from the observed counts of mutations classified by the detection status of the multiple callers, using the statistical method called latent class models
 <cit> .

RESULTS
tcga benchmark studies generated mutation-calling outputs by applying multiple callers on the same sequence alignments  for a selected list of samples. we have analyzed two datasets, one based on lung squamous cell carcinoma  samples and the other based on rectum adenocarcinoma  samples. the callers used and the types of available sequence data are described below as well as summarized in additional file
1: table s <dig> 

note that all the mutation-calling outputs were generated before july  <dig>  and no current mutation-caller will be the same as those used in this study, which is a part of the reason for using anonymized callers. even though indels and other structural variants are important kinds of somatic variants, in this paper we focus on comparing single nucleotide variant  type somatic mutations, which comprise the majority of somatic variants.

lusc dataset mutation calling was done by four callers  using illumina exome-seq tumor-normal pairs from  <dig> lusc patients. two kinds of additional data exist for the same patients. one is illumina rna-seq data available for the  <dig> tumor samples. second is high-coverage illumina sequencing data  available for tumor-normal pairs on a pre-selected set of  <dig> genes .

read dataset mutation calling was done by three callers  using solid exome-seq tumor-normal pairs from  <dig> read patients. three kinds of additional data exist. one is illumina rna-sequence data available for the  <dig> tumor samples. a second is illumina exome-seq tumor-normal pairs for all  <dig> patients. the last one is information available for  <dig> sites, for which validation was done using the  <dig> sequencing technology.

in an effort to create comparable calling outputs, all four centers agreed on one annotation representing exome regions and generated calls only within those regions. outputs were provided in a modified variant call format , which reports the genomic position, somatic status, filter status, sequence information from each tumor and normal sample. the filter status indicates whether the variant  passes all the filters implemented by each caller or not. the full details of all filters were not given in the vcf files though, partly because the modified vcf format was under active development.

detecting a variant in an aligned sequence  is looking for the existence of a variant allele that is different from the reference allele. in principle, the more reads carrying the variant allele, the stronger the evidence for it being a true variant. thus, the fraction of reads carrying the variant allele  is frequently used in variant calling analyses. for somatic mutation-calling, the tumor and its matched normal sample are considered together. therefore, a variant is determined by the joint status in tumor-normal sequence pairs: ‘somatic’ , ‘germline’ , and ‘wildtype’ . in our manuscript, a mutation or variant ‘site’ refers to a position only for the particular patient carrying the variant.

discrepancies observed in the benchmark data
lusc dataset from each caller’s raw mutation-calling output , we extracted a final set of somatic mutations. to have a broad picture, we gathered all such mutations from all  <dig> lusc patients. an immediate venn diagram summary reveals substantial discrepancies among the mutations from the four callers . for example,  <dig> and  <dig> mutations were detected by caller a only and caller d only, while  <dig>  mutations were discovered by all four callers. there are many mutations that were missed by a single caller. for example,  <dig> mutations were detected by all but caller b, and  <dig> were detected by all but caller c. we also categorized mutations based on the degree of agreement . in total,  <dig>  mutations were called by one or more callers, and 31%, 28%, 16%, and 25% of those were detected by all, three, two, and a single caller. a similar categorization of the mutations detected by each caller suggests that caller b is stringent, since it detected a relatively small number of mutations, most of which were detected by the other callers. callers a, c, and d reported a similar number of mutations, a good proportion of which are caller-specific.

we attempted to further characterize the discrepancies among the callers using those mutations called by a single caller only  or missed by a single caller only . to a large extent, discrepancies occurred due to different variant call status on the tumor sample. variant calling in the normal sample seems to be highly accurate, as potential mis-classification between somatic mutations and germline mutations explain relatively small fraction of the discrepancies . the distribution of the coverages and the variant allele fractions in the tumor exome-seqs vary significantly across the mutation sets defined based on the detection status of the four callers . for example, the set of mutations detected by caller a only is somewhat enriched for positions of medium- to low-sequencing depth , while the set detected by caller d only has many sites with very high depth  but have very low vaf . the characteristics of mutations that were missed by a single center are different. a large fraction of mutations that were missed by caller b only have tumor vaf <20%. almost all the mutations detected by all but caller d have very high depth , and most of them have vaf > 20%. the mutations missed by caller a only have medium-to-high coverage  and medium-to-high vaf > 20%. the number of mutations that were missed by caller c is significantly lower than those missed by other callers only. overall, many of the mutations detected by a single caller only and those missed by caller b only have relatively low sequencing depth or low vaf, which presumably poses difficulty in detecting existence of alternative allele in the tumor sample, while mutations missed by caller a, c, or d only tend to have high sequencing depth and show good support of the existence of a variant allele. thus, for these mutations, it’s likely that the single caller employed a certain filter that was different from the others.

to better understand the sources of discrepancies, we examined all variants in the vcf files.  the classes of variants and the number of variants reported in the vcf files differ significantly among the callers . caller d reported only somatic variants. caller a, b, and c reported both somatic and germline variants but the numbers vary. our main interest is in the somatic variants that successfully pass all the filters implemented by each caller, which comprise the final set of mutations. nonetheless, information of the somatic variants that did not pass filters can be used for comparison purposes. for example, for each caller, we screen the corresponding vcf file to check whether the mutations missed by the caller only are reported in the file, and then find the reasons for them being filtered out. around 60% of mutations that were missed by caller b only are not reported in the vcf file from caller b , suggesting that initial requirement to be scanned by caller b might be more stringent than others. the scale of mutation quality scores reported in the vcf varies across the callers as well . mutations that were detected by all callers tend to have high quality and those that were detected by a single caller tend to have low mutation quality. nevertheless, pairwise comparison of mutation quality scores between callers shows some but not a very high level of agreement . furthermore, such scores from all callers are available only for a limited subset of mutations. thus ranking all mutations detected by any caller is not feasible based on these mutation quality scores.

read dataset from the mutation-calling outputs  of the three callers , we extracted the final set of somatic mutations. the mutations detected by each caller are stratified by the number of callers detecting those mutations . caller i tends to be stringent, in that it calls a small number of mutations but most of those are shared by the other two callers. notably, among the mutations that were detected by one or more callers, a very large fraction  were detected by a single caller, especially by caller h or caller j only. the relative numbers of mutations called by each caller varies across the  <dig> read patients. specifically, for read- <dig>  read- <dig>  and read- <dig>  caller h and j detected a similar number of mutations. for read- <dig> and read- <dig>  caller h detected around three times as many calls as caller j. read- <dig> is unique in the sense that caller i and j detected relatively many more mutations compared to other cases.

since many mutations were detected by a single caller only, we explored such mutations further. first, we checked whether each mutation detected by a single caller was reported in the vcf files of other callers. additional file
1: figure s <dig> shows that it is the case for majority of the mutations. that says, those mutations were initially considered for variant detection by at least one more caller but filtered out. unfortunately, as mentioned earlier, the full details of all filters were not available for further exploration. we also examined the coverage and the vaf of the tumor sample of such mutations. almost all calls detected by caller j only have very low vaf, less than 10%. the tumor vaf of the mutations detected by caller h only covers the whole spectrum of allele fractions, and more than 80% of those are larger than 10% .

analysis of validation data
lusc dataset deep-sequencing data was available for  <dig> genes for all lusc patients. we used it to determine the validation status of any variant in the vcf files that are within the  <dig> genes. a variant is called ‘somatic’ if the tumor vaf in the deep-seq data is > 10% and the normal vaf in the deep-seq data is < 2%, otherwise, ‘non-somatic’. . the validation results are summarized by each mutation set, defined based on the detection status by the four callers . notice that mutations that were detected by two or more callers tend to have a high accuracy. for example, all the  <dig> mutations detected by all but caller a, or all the  <dig> mutations detected by caller a and c are validated as ‘somatic’. mutations that were called by a single caller tend to be enriched for false positives but some of those turned out to be false negatives for the other three callers, suggesting that a non-negligible number of sites posed difficulties in mutation-calling. for example, among the  <dig> mutations that were called by caller d only, five of them are validated as ‘somatic’, i.e., caller a, b, and c failed to detect these mutations.

the variants included in any mutation output  file were divided into mutation sets based on the detection status of the four callers . for each variant, validation status  was determined as ‘somatic’ if the deep-sequencing data shows the signature of a somatic mutation: the vaf in the tumor sample is > 10% and the vaf in the normal sample is < 2%; otherwise, it is as ‘non-somatic’. variants that have less than  <dig> reads in the original exome-seq data were discarded. one mutation was such a case.

the individual validation status of all the  <dig> mutations is shown in figure
 <dig>  mutations are marked as ‘strand bias’ if more than 95% or less than 5% of the reads carrying the variant allele are on the forward strand. out of  <dig> such mutations,  <dig> overlap with those mutations that were detected by a single caller or missed by a single caller. not surprisingly, many of the mutations validated as ‘non-somatic’ have low tumor vaf . manual examination of the five mutations validated as ‘non-somatic’ but having tumor vaf > 20% suggested that four of them are likely to be ‘germline’ mutations. mutations in each mutation set  tend to scatter around across a large range of tumor vafs. one exception is the set ‘detected by all but caller b’, for which many of them are clustered by having a low vaf.
 <dig>  a mutation is marked as ‘strand bias’  when more than 95% or less than 5% of the reads carrying the variant allele are on the forward strand in the tumor exome-seq data. mutations that were detected by a single caller only  or missed by a single caller only  are indicated with upside down triangle or filled diamond, respectively.

we further interrogated false positive and false negative sites by exploring alignment of nearby regions, distribution of base scores of the variant and the reference allele, coverage, and variant allele fraction. some of such details for each mutation are summarized in additional file
 <dig>  each discrepancy has a very specific reason but broadly, there are two explanations accounting for the false positives and false negatives. one is when a mutation has low-quality information . the other is when different pre- and post-filtering criteria were applied to high or intermediate-quality mutations, i.e., mutations showing clear signs of the existence of the variant allele, but may show strand bias, repeatedly appear in the first or last few bases of the reads, etc. nonetheless, detailed characterization couldn’t be performed, since full details of the filters were not available.

read dataset among the mutations called for the  <dig> read patients, we obtained the validation status of  <dig> sites that were validated by the  <dig> technology. we first classified each mutation found in any vcf file into five validation groups. it is ‘nonmaf’ if the mutation was found in the benchmark data but did not appear in the tcga colon working group maf  file as of nov  <dig>   <dig> nor validated by the  <dig> technology. otherwise, it was classified as ‘unknown’ , ‘wildtype’ , ‘germline’ , and ‘somatic’ . we didn’t have information about how sites were chosen for validation. however, classification of the mutations by the detection status of the three callers and by the validation group suggests that only the variants initially called by caller j were considered for validation, except for a few variants in read- <dig> . it is important to be aware of such ascertainment. otherwise, one may mistakenly compute the false positive and the false negative rates of caller h or caller i using the validated mutations, and may make unfair comparison with the rates of caller j. note that in the set of validated mutations, if a mutation is called by caller h, then it implicitly implies that the mutation is called by both caller h and caller j due to the ascertainment.

validation results for the mutations that were called by caller j are shown in additional file
1: figure s <dig>  most of the calls detected by caller j only were not considered for validation nor included in the maf file , except for the calls from patient read- <dig> and read- <dig>  for the two patients, numerous mutations were considered for validation and validated as wildtype. mutations that were detected by all callers have high validation rate for most of the patients, except read- <dig>  for read- <dig>  around half of the mutations were validated as wildtype. the validation results of the mutations that were detected by caller j and another caller also suggest somewhat unusual validation accuracy for the mutations from two patients, read- <dig> and read- <dig>  it is plausible that the quality of samples or the experimental procedure for these patients provided a challenge to all three mutation callers.

our earlier work suggested that for illumina sequencing data, the variant quality scores computed by the gatk unifiedgenotyper <cit>  could be effectively used for visualizing overall and individual mutation qualities. therefore, we first compiled the variants in any vcf output, which was produced based on  <dig> solid exome-seq pairs. then for each such variant, we obtained the signed gatk variant call quality scores using the corresponding illumina exome-seq pairs . the signed gatk qualities are shown for two patients in figure
 <dig>  and for all  <dig> patients in additional file
1: figure s <dig>  we expect a somatic mutation to have a large positive signed gatk quality score in the tumor sample  and a large negative signed gatk quality score in the normal sample . indeed, most of mutations validated as ‘somatic’ show such characteristics. for read- <dig>  read- <dig>  read- <dig> and read- <dig>  the overall distribution of the gatk quality scores suggests good dna sample quality. in this case, wildtypes, germlines, and somatic mutations are well distinguished. however, for read- <dig> and read- <dig>  the distribution of the gatk quality score seems much noisier , suggesting poor dna sample quality. numerous wildtypes show expected characteristics for somatic mutations, and that is likely to be the reason for the relatively poor validation rates for these two patients in additional file
1: figure s <dig>  note that mutation-calling is done based on solid sequences, but the signed gatk quality scores are computed based on the illumina sequences. therefore, the difficulty is not likely due to the sequencing technology but due to sample quality. we suspect that the poor quality dna sample induces many artifactual variants causing high false positive rates, since those artifactual variants do not exist in the rna-seq tumor sample . notice that all the mutations validated as wildtypes have zero vaf in the rna-seq data.

analysis of the deep-sequencing data for construction of an evaluation dataset
for method development, we constructed an evaluation dataset by compiling a set of candidate somatic variants detected based on the exome-seq data and determining their validation status based on the deep-sequencing data. our evaluation dataset consists of the  <dig>  variant sites that were detected within the  <dig> genes using the gatk unifiedgenotyper from  <dig> lusc tumor exome-seq data . to determine the validation status of these sites, we first examined the distribution of variant allele fractions in the deep-seq tumor-normal pairs . the scatter plot shows good separation between somatic mutations from other types of variants. a somatic mutation is characterized by having a variant allele in the tumor sample but not in the normal sample. on the left boundary of the plot, there are many points for which the tumor vaf is reasonably large  but the normal vaf is almost zero . these points are well separated from the other points, especially when the normal vaf is larger than zero . the distribution of the vafs in the normal samples clearly has three modes , corresponding to genotypes with zero, one, and two variant alleles. presumably, the alignment bias preferring the reference allele resulted in the centre mode around 45% rather than 50%. when the normal vaf is near the centre mode , the tumor vafs are vertically spread around, suggesting that varying degrees of normal contamination exist in the tumor samples and the loss of heterozygosity regions. interestingly, there are numerous variants for which the normal vaf departs from the three modes but the correspondence between the tumor vaf and the normal vaf is very high. in particular, most of these variants have the normal vaf less than half. since these variants have both the tumor and normal vafs in the range suggesting for the existence of a variant allele, we name these as ‘germline-like’ variants. alignment biases are not likely to explain numerous occurrence of these ‘germline-like’ variants fully. we suspect that a large fraction of these variants appeared due to artifactual variant alleles that were caused by sequencing technology, since a substantial number of the variants exhibit extreme levels of strand bias . specifically, among the  <dig> germline-like variants for which the normal vaf is between 5% and 35%, around 50% variants exhibit very strong strand bias in the tumor sequence data . in contrast, among the  <dig>  variants for which the normal vaf is in a more expected range  for heterozygous genotype for the normal sample, only  <dig> % exhibit such extreme strand bias. below, we further discuss that base mis-calling can cause numerous artifactual variant alleles that are characterized by extreme strand bias, in contrast to the reference alleles.

we also examined the gatk variant quality scores . such scores indirectly combine the vaf with sequence depth for each sample. since we flipped the sign when no alternative allele is found by the gatk, the points on the left boundary with positive values for the tumor sample and negative values for the normal sample are strongly supported to be somatic mutations. those points are reasonably well separated from other points in the diagonal. after further examination of the distribution of the vafs as well as the signed gatk quality scores, we determined the validation status for each of the  <dig>  sites based on the deep-seq pairs . a variant is called ‘somatic’  if the tumor vaf is > 10% and the normal vaf is < 2%, otherwise, ‘non-somatic’. an alternative criterion for a ‘somatic’ mutation is that the signed gatk quality scores for the tumor sample and for the normal sample are >  <dig> and < - <dig>  respectively. the two criteria mismatch only for  <dig> sites. rather than making subjective judgement for these sites, we have exclude these  <dig> ambiguous sites from our final evaluation set.

reasons for artifactual variants
in the evaluation dataset, we validated the variants found in the exome-seq data using the deep-sequencing data. among the variants validated as ‘non-somatic’, there are numerous cases for which both the tumor and the normal vafs are very low  in the deep-sequencing data. we classified these as ‘wildtypes’  and visualized for comparison with somatic ones and investigated the reasons for mis-calling. notice that many of these wildtypes look like germline variants in the original exome-seq data . these artifactual variants also exist in the tumor rna-seq data . our exploration reveals a remarkable difference in the strand bias pattern between the somatic mutations and the wildetypes in the tumor samples .  for somatic mutations, the fraction of reads on the forward strand is very similar between the variant allele and the reference allele. for wildtypes, the strand bias of the variant allele is extreme in that almost all the reads carrying the variant allele are either on the forward strand or the reverse strand. although weaker than the tumor exome-seq, the rna-seq data exhibits a similar behavior. thus, the sources causing these wildtypes are not the characteristics of the protocol used for exome-sequencing or rna-sequencing, but rather are likely to be consequences of the illumina sequencing technology. even for the deep-sequencing data, numerous false variants seem to occur due to strand bias. the ‘germline-like’ variants based on the deep-seq pairs show a very different strand bias pattern compared to the somatic ones . to a large extent, we believe that such false variants occur due to base-calling errors in the raw sequencing reads
 <cit> . some sequence contexts are more prone to base-calling errors than others, and these errors may occur in only one direction
 <cit> . indeed, the direction of the strand bias is the same across the different sequenced samples such as tumor exome-seq and the normal exome-seq .

pseudo- and rna-seq validation methods
pseudo-validation method in the absence of a gold standard data, direct comparison among calls from different mutation callers is difficult. each caller reports information for a subset of genomic positions, and these sets do not entirely overlap. to overcome this difficulty, i.e., to provide reasonable and consistent measure of mutation quality across all positions that are reported by any mutation caller, we used a publicly available variant caller, gatk unifiedgenotyper, to build our own pseudo-caller. specifically, for each variant of interest, we computed the signed gatk variant quality score for each tumor and normal sample . with a given threshold qt for the tumor sample, and qn for the normal sample, we define pseudo-positives as variants for which the signed gatk quality from the tumor is >qt and the signed gatk from the normal is <qn. note that the pseudo-caller is for comparison purposes only, and is not to be treated as an independent mutation caller.

rna-seq validation method rna-sequencing is often done for tumor samples, since the expression pattern of the tumor sample is of great interest in many cancer projects. if such tumor rna-seq data is available as well as the original exome-seq pairs used for mutation calling, it can be used as partial validation data. due to the variation in the expression levels across the genes, rna-seq generally shows a significantly larger variation than dna-seq data in the number of reads carrying the variant allele.

to construct a validation dataset using the rna-seq data for the tumor sample, we examined the variant allele fraction  in the rna-seq data together with the vaf in the normal exome-seq data. we restricted our analysis to those variants that have rna-seq depth >10x.  then, with a given threshold for tumor and the normal, ft and fn, respectively, we define positives as such variants for which the tumor rna-seq vaf exceeds ft and the normal exome-seq vaf is less than fn.

evaluation of pseudo- and rna-seq validation methods
to assess the performance of the pseudo-validation method, we ranked the variants in the evaluation set using the gatk quality score obtained from the tumor exome-seq, given that the signed gatk quality score from the normal sample is less than - <dig>  we mostly used only the tumor sample for ranking, since most of difficulties in calling somatic mutations seem to occur due to heterogeneous aspects of the tumor sample. for the normal sample, it suffices to set a threshold to exclude any sites with a variant in the germline. we also attempted to filter out artifactual variant alleles by introducing a criterion based on the strand bias pattern in the tumor exome-seqs. if the variant allele shows much more extreme strand bias compared to the reference allele, specifically, more than 95% or less than 5% of the variant alleles are on the forward strand, while less than 70% or larger than 30% of the reference alleles are on the forward strand, then we filtered out the mutation sites.

the performance of the rna-seq validation method was assessed using the  <dig>  variants  in the evaluation dataset that have the rna-seq depth ≥ 10x. we used the tumor vaf to rank the variants, given that the normal vaf in the exome-seq is less than 2%. to filter out artifactual variant alleles, we filtered out a mutation site if both the tumor exome-seq and the tumor rna-seq showed strong strand bias  for the variant allele. the reason that we applied different filtering criterion is because for the rna-seq data, the correspondence of the strand bias between the variant allele and the reference allele is much weaker even for the “true” variants  but existing exome-seq data can help for filtering out artifactual variants.

the performances of the two methods were summarized by roc-like curves, showing the true positive rate at each false discovery rate .  instead of the false positive rate since the evaluation dataset consists of the ascertained variants obtained using the gatk unifiedgenotyper. thus, only relative false positive rates are meaningful. instead, we chose to use fdr here since it has very intuitive scale and it won’t change the conclusion. note that we examined the full spectrum of stringency levels by varying cut-offs for the gatk quality scores and for the tumor vaf in the rna-seq data.) as expected, both validation approaches show improved performances with the strand bias filters. for the pseudo-validation method, for example, the signed gatk quality score in the tumor sample exceeds  <dig> for  <dig> sites. among these,  <dig> sites are validated as ‘true’ somatic mutations  detecting 80% of the  <dig> somatic mutations. the remaining  <dig> sites are false positives, but with the strand bias filter,  <dig> of them are removed, dropping the false discovery rate from 8% to  <dig> %. for the rna-seq validation method, the vaf in the rna-seq is larger than 10% for  <dig> sites. among these,  <dig> sites are validated as ‘true’ somatic mutations detecting 88% of the  <dig> somatic mutations with the rna-seq depth > 10x. the remaining  <dig> sites are false positives. nine of those were discarded using the strand bias filter, dropping the false discovery rate from 15% to  <dig> %. note that we conceived the strand bias filter based on the insights learned from the strand bias pattern in the exome-seq and the rna-seq data in the evaluation dataset. therefore, re-applying the strand bias filter to the same data will obviously improve the performances. nonetheless, we keep this strand bias filter for the evaluation of the two validation methods using the benchmark data, since a similar strand bias pattern is likely to be observed using only the data from the additional  <dig> lusc patients that were not used for the benchmark study. notice that for the rna-seq validation method, the true positive rate is only 90% even with the 1% threshold for the rna-seq vaf. it is because some of the true variants that existed in the dna exome-seq data did not appear in the rna-seq due to the variation in the expression level as well as the sequencing depth.

comparing the performances of callers in the benchmark data using the pseudo- and rna-seq validation methods, and latent class models
we applied the pseudo- and the rna-seq validation methods to the whole exome benchmark data from  <dig> lusc patients. for each validation method, we picked a specific cut-off for convenience and illustration purposes, but across a range of reasonable cut-offs, the qualitative conclusions were similar. for the pseudo-method, we validated mutations as somatic if the signed gatk quality scores for the tumor sample and for the normal sample are >  <dig> and <- <dig>  respectively. for the rna-seq method, for the mutations with the rna-seq depth ≥10x , we validated them as somatic if the vaf in the rna-seq >10% and the vaf in the normal exome-seq <2%. the chosen cut-offs for each validation method roughly correspond to a false discovery rate less than 3% and the true positive rate larger than 80% based on the analyses of the evaluation dataset constructed using data from  <dig> lusc patients. however, the absolute values should not be emphasized since the features of the whole exome benchmark data are likely different from the sites within the  <dig> genes for which the evaluation dataset was constructed. for the two validation methods, we attempted to remove the artifactual variants by applying the strand bias filters.

when submitted to the pseudo-validation method, around 75% of the mutations called by a single caller only  were validated as false positives. notice that majority of the mutations in the upper row in figure
 <dig> have disappeared from additional file
1: figure s <dig>  while around 85% of the mutations that were detected by three callers  have been retained. when submitted to the rna-seq validation method, a similar observation is made . nonetheless, among the  <dig>  sites that were called by one or more callers and validated by both the pseudo- and the rna-seq methods,  <dig> sites  have different validation status, implying that validation can be quite challenging. a part of these differences  occurred for the sites that were detected by all callers.

for the mutations within the targeted regions of deep-sequencing data , validation status based on a gold-standard data is available. thus, for those mutations, we compared the gold-standard  validation status with the status based on the pseudo- or the rna-seq validation method. out of  <dig> sites,  <dig> sites are validated as somatic by the gs method but not by the pseudo method, and vice versa for  <dig> sites. almost all of the  <dig> former sites have low vaf  in tumor exome-sequence data, and that may explain why missed by the pseudo method. out of  <dig> mutations where rna-seq validation can be applied ,  <dig> sites are validated as somatic by the gs method but not by the rna-seq method, and vice versa for  <dig> sites. the former  <dig> sites tend to have low-to-medium rna-seq coverage, mostly less than 30x, and this might be the reason for losing the true variant allele. two out of the latter  <dig> sites have very low vaf  for both tumor deep-seq and the exome-seq data. finally, when the pseudo-validation status was compared with the rna-seq validation status,  <dig> out of  <dig> mutations  show different status. it is difficult to know what are the genuinely correct status for all these discrepancies, but these observations illustrate the challenges in mutation-calling.

we also employed latent class models, which have been repeatedly used to compare multiple diagnostic tests in medical studies when there is no gold standard data
 <cit> . in the benchmark study, multiple mutation callers were applied to the same tumor-normal paired sequence alignments, and the decision was made on whether each position in the alignments is a somatic mutation or not. in the absence of gold standard validation data, latent class models offer a convenient statistical framework within which the false positive and the false negative rates are estimated by treating the true mutation status as a latent variable . we fitted the latent class model using the set of mutations within the  <dig> genes, and the set consisting the whole exome data. for the set using the  <dig> genes, the model assuming conditional independence among the callers fits the data pretty well . for the whole exome data, the conditional independence model does not fit the data as well, but the latent class model with random effects having an additional parameter improves the fit significantly . note that our model is equivalent to the 2lcr <dig> model in qu et al.
 <cit> , except that we let the variance component be shared between ‘somatic’ and ‘non-somatic’ sites. we decided to use this model for the exome data, since more general models do not improve the fit much nor change qualitative conclusions. the observed and the fitted counts using the latent class models are summarized in additional file
1: table s <dig> 

in figure
 <dig>  we summarized the false positive  and the false negative  rates estimated using two datasets  by four validation methods: gold-standard method using the deep-sequencing data, pseudo-method using the gatk quality scores, rna-seq validation method utilizing the variant allele fraction in rna-seq, and the latent-class models. note that the gold-standard validation is not applicable to the whole exome-data. for the pseudo- and the rna-seq methods, the thresholds controlling the performance were picked by us for convenience. the latent class models directly estimate the false positive and false negative rates based on a statistical model. since absolute values of fp rates are less emphasized for our dataset, for an easier comparison, we re-scaled the fp rates across the four validation methods. within the  <dig> genes, around 3% of the all variants compiled from vcf files were validated as ‘somatic’ by the gs method. we assume that the same portion of the evaluated sites are ‘somatic’ in other datasets, and re-scaled the fp rates accordingly.

overall, relative performances of the four callers were similar across the different datasets and methods. caller b is stringent and other three callers show few distinctive characteristics. there is one exception. when the mutations within the  <dig> genes are validated by the rna-seq method, caller b shows an unusually high false positive rate. our manual examination suggests that the unusually high false positive rate of the caller b is likely due to the few sites for which the rna-seq missed the variant allele presented in low fraction  in both the deep-seq and the exome-seq data. therefore, one needs to be cautious when utilizing rna-seq for validation of a small dataset. often, caller c performs slightly better than caller a and d by having a lower false positive rate as well as a lower false negative rate, i.e., located in a lower left part compared to caller a and d in additional file
1: figure s <dig>  in particular, the latent class models clearly prefer caller c, implying that high fraction of the calls detected by caller c is shared with other callers. however, systematic comparison of the performances was not feasible, since we were not able to explore the full spectrum of the performances of each caller due to limited information.

discussion
we observed a number of sites exhibiting artifactual variant alleles while we were constructing the evaluation dataset using the deep-sequencing and the rna-seq data in addition to the original exome-seq data. most of the artifactual variants show an extreme level of strand bias for the variant allele, regardless of the corresponding level in the reference allele. such artifactual variants are present not only in the tumor sample but also in the normal sample. in particular, on many occasions, the artifactual variants occur simultaneously in both tumor and normal samples, creating ‘germline-like’ variants, based on the exome-seq data. moreover, a substantial fraction of such variants are also present in the tumor rna-seq data. the accumulation of such errors repeatedly at the same genome location across different biological samples suggests that those artifactual variants are likely to occur due to the errors in the sequencing technologies, cf. meacham et al.
 <cit> . the ‘germline-like’ variants based on the deep-sequencing data also exhibit a strand bias pattern similar to the artifactual variants found in the exome-seq data.

for somatic mutation-calling, the joint occurrence of the artifactual variants in both tumor and normal samples could be useful for filtering out ‘non-somatic’ mutations. any position exhibiting the presence of a variant allele in the normal sample will be discarded, and thus the artifactual variant in the tumor sample when the normal sample also carries it. for a similar reason, many of artifactual variants in the tumor rna-seq data were filtered out by our rna-seq validation method. interestingly, substituting the normal exome-seq data by the normal deep-seq data hurts the performance of the rna validation method. the deep-sequencing data seems to have a higher quality and thus contains many fewer artifactual variants, and thus filtering out artifactual variants in the tumor rna-seq data was less effective. a better characterization of artifactual variants remains as our future work.

in this study, we introduced two validation approaches, the pseudo- and the rna-seq validation methods. the two approaches, however, should not be considered as alternative mutation-calling methods. our validation methods were developed to overcome the challenge of comparison, rather than for correcting all the biases or errors affecting mutation-calling. in particular, the performance of the pseudo-validation method depends on how effectively the gatk unifiedgenotyper calls a variant in the tumor and the normal samples. even though we observed that on many occasions it proved its usefulness in somatic-mutation analyses, gatk was developed for normal samples not for tumor samples. furthermore, some of the mutation-callers used for the benchmark study may share with the gatk the underlying statistical models or methods, which could result in biased inferences. however, our small exercise in replacing gatk unifiedgenotyper with samtools mpileup suggests this was not the case.

CONCLUSIONS
tcga conducted benchmark studies comparing multiple mutation-callers on the same sequence pairs . our work attempted to characterize the discrepancies among the callers in two benchmark datasets, and provide guidelines for the analysis of such comparative data. to assess the performances of mutation callers, we have introduced four approaches estimating the sensitivity and the specificity of each caller.

our analyses revealed that the discrepancies among the callers not only occur at sites with low-information , but also at sites with intermediate or high-quality information. specifically, a large fraction of calls missed by a single caller in the lusc benchmark dataset exhibit strong evidence for the existence of a variant allele. investigation of raw mutation-outputs  suggested that the uniquely missing caller initially included such calls as candidate somatic mutations but implemented a filter removing those. the details of these filters were not available in the vcf files for this benchmark study, but this recognition emphasizes the value of full details for a comprehensive analysis. in addition to that, a more comprehensive analysis can be performed if somatic mutation qualities are included in the vcf files, allowing ranking of mutations within each caller and thus varying the stringency level of the caller by changing the false positive rate. then the full roc curve showing the performance of each caller can be examined.

strand bias is one of well-known features producing artifactual variants in high-throughput sequencing data, and we presume at least some of the callers used for the benchmark study have implemented filters for strand bias. nevertheless, our analysis of the validation data for the lusc samples suggests that the specifications of such filters are likely to vary considerably across the callers. when we marked the mutations that have an extreme level of strand bias for the variant allele in the tumor exome-seq sample, most of them accounted for the discrepancies.

our work calls for extra caution in comparing the performances of multiple callers based on an ascertained validation data, since ‘not attempted to be validated’ mutations should be distinguished from ‘attempted to be validated’ mutations. for the read dataset, validation information for  <dig> sites was available, but not the information about the ascertainment, i.e., how those sites were chosen for validation. by classifying the mutations based on the detection status of the three callers and the validation status, we learned that almost all of those  <dig> sites were initially called by one particular caller. presumably, the experimental validation of those sites was performed for evaluation of that particular caller’s performance, and not for comparison of multiple callers. such validation information can be used for learning about individual errors of other callers but should not be used for evaluating the performance of other callers.

somatic mutation-calling based on the high-throughput sequencing data is a rapidly evolving field. currently, a limited number of somatic mutation-callers are publicly available
 <cit> , but many more are likely to appear in the near future. our paper focused on understanding the discrepancies and highlighting the challenges in comparing multiple callers. with more details in the mutation outputs, such as mutation quality scores and the details of filters, another interesting question to address is how to combine the calls across multiple callers. a recent study by lower et al.
 <cit>  tackled a similar problem by assigning an fdr confidence score for each call from multiple callers, but their method requires replicate sequencing of at least one of the tumor or the normal sample. when only a pair of tumor-normal sequence data are available for mutation-calling, combining the calls incorporating the information in the outputs from multiple callers is another upcoming problem.

