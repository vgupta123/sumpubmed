BACKGROUND
many common disorders have genetic components which convey increased susceptibility. while linkage and association analyses have been quite successful in identifying rare variants with high penetrance, such as in huntington's disease  <cit>  and some forms of cancer  <cit> , the ability of these approaches to detect common variants with more modest effects  is limited. frequent alleles with modest genetic effects play important roles in the susceptibility to most diseases. for example, most autoimmune disorders involve multiple alleles of different genes with individual low penetrance which also interact with environmental factors to produce the final disease phenotype. dissecting the disease phenotype into the individual genes and associated alleles that are responsible is crucial for understanding the mechanism of the disease and ultimately developing treatment modalities  <cit> .

to this end, many researchers have been using genome-wide approaches to locate single nucleotide polymorphisms  that are in disequilibrium with a disease-causing allele, or associated with a disease phenotype  <cit> . unfortunately, the requirement to completely scan the entire genome with sufficient snp coverage required to achieve an appropriate study-wide power as well as the concomitant increase in number of subjects required to overcome the multiple-testing effect makes this type of study prohibitively expensive. indeed, many association studies are under-powered, which leads to low reproducibility, compounded additionally by publication bias  <cit> .

there are two general methods to reduce the number of snps tested in a search for variants which convey susceptibility. the first is to reduce the number of snps necessary to cover the entire genome by maximizing the information conveyed by each individual snp. this process involves the elimination of redundant snps whose state is already determined with high probability by other snps in the study  <cit> . the second method is to use prior available information to select genes and genomic regions likely to be involved in a disease and testing the most likely genes and regions in preference to the least likely. while this approach does have advantages over a whole-genome study, specifically in financial cost, time required and a smaller number of subjects needed to assure reasonable power, it does have disadvantages in that it does not select candidate genes which are not associated with biological functions or genomic regions currently thought to be related or linked to a disease.

in order to determine which genes or genomic regions are likely to be associated with the disease, it is necessary to connect genes and genomic areas with available literature on the disease and disease-associated pathways. the implementation we present here relies on experts to build a list of keywords and genomic areas from the available literature and expert knowledge coupled with publicly available databases to connect keywords and genomic areas to specific genes. an alternative using automated information extraction techniques which do not rely on expert knowledge is presented in the discussion. this experimental design, where the genes  are selected using prior available information allows for the determination of the prior probability that a particular gene is associated with a disease.

once specific genes have been selected, the snps used in the study need to be selected. a popular class of methods is the tagsnp methods, which attempt to reduce the number of snps while maximizing the information that each snp represents by grouping snps that are in linkage disequilibrium with each other and in the same phase . the genes suggested by our program and its associated method do not necessarily require such powerful techniques, but discarding redundant snps will be useful in maximizing power while reducing cost. beyond discarding non-informative snps, special importance should be placed on functional snps as they are more likely to actually represent the disease allele in question.

the method presented here uses a combination of automated and manual approaches to maximize the power of a study using snps. the method has the following steps:

 <dig>  use expert knowledge and literature to identify a set of keywords  which have high prior probability of being associated with the disease.

 <dig>  use publicly available databases to select genes that reference the set of keywords.

 <dig>  rank the identified genes based on their prior probability of association using the selection results and expert knowledge.

 <dig>  choose an appropriate number of genes for snp selection and association studies based on the number of cases available, monetary, and time constraints of the study while maintaining acceptable study-wide power.

 <dig>  conduct study.

 <dig>  analyze results, optionally using the prior probability of association obtained during genetic selection.

implementation
the application is separated into a series of separate scripts, each of which has a specific function, and operate in a specific order .

once a set of keywords  has been identified by expert knowledge of the disease in question, publicly available databases  are queried in series with delays between each query as appropriate for each database to avoid overloading them. because there is no well documented common interchange format for these databases, the get_series of scripts download the html  which the search requests generate and save it. to avoid putting unreasonable demands on the databases, the get_scripts limits the number of requests they make per minute.

after all of the html  has been retrieved, the next series of scripts  are run which use the html::parse  module to extract the gene name, accession number for the reference sequence, genomic location, alias, function, and description.

these files are then combined into a single file by combine_results that tracks what database and keyword resulted in which genes. the aliases from all databases are joined. gene descriptions are retrieved from each database; the longest description is retained in the final list. for example, harvester, when queried with "adhesion", returns vcam <dig> . harvester also returns vcam <dig> when queried with "inflammation". genecards also returns vcam <dig> for these two queries. combine_results would then indicate that genecards returned vcam <dig> twice, harvester returned vcam <dig> twice, and it was returned for "adhesion" and "inflammation". at the same time three separate weighting procedures are applied to order the genes. first, a simple approach, dubbed "rzscore", simply counts the number of times that a gene was returned by unique search terms, and orders the results from most number of term matches to least. the second, allows user-specified weights to be applied to each keyword, and orders the results by the sum of the weights of the corresponding keywords which returned a result. the third method automatically weights the keywords to avoid over-counting keywords which are entirely subsets of other keywords. it does this by dividing the number of results returned by a keyword by the sum of the number of results returned by that keyword and any other keyword, including itself.

to facilitate easier use of this collection of meta-search utilities, a script which binds them all together has also been provided, called function2gene, which takes a set of keywords, an optional set of databases to query, and returns the complete tabulated results to the specified directory.

by using perl and existing modules  the actual number of lines  of the codebase is greatly reduced, as custom code to deal with form submission as well as html and xml parsing did not need to be written. this approach also allows the scripts to be slightly less dependent on the exact output format of the sites which are searched. splitting the retrieval and parse stages also allows for extracting additional information from the search results by modifying the parser and reparsing the results without waiting to retrieve results from the remote databases again.

RESULTS
the system described above was utilized to generate a list of genes which were then used to select snps in a study of childhood-onset systemic lupus erythematosus . sle is a debilitating multi-system autoimmune disorder affecting ≈  <dig> % of the north american population. an initial search using a set of  <dig> keywords  selected by expert knowledge returned  <dig> genes with various contributions from the three databases used . it is important to note that the results obtained are temporally-sensitive; as databases are updated different sets of genes will be returned. in every case a single database did not retrieve all the genes found by other databases, demonstrating the need to query multiple databases. the substantial contribution made by each database in identifying the candidate genes demonstrates that each of the databases is required to maximize the number of candidate genes discovered, though there are likely results which are still not captured by the set of databases queried. as new databases come into prominence, function2gene can be extended to query them as well. the top  <dig> genes  were used to select  <dig> snps. the number of genes to select was dictated by the capacity of the chip , and a decision to have approximately ten snps per gene on average. the choice of snps to genotype within the selected genes was based on available information from databases including the human haplotype mapping project  with priority given to snps with high heterozygosity in two or more relevant ethnicities and to snps representing amino acid coding variants. the selected snps were then cross-checked against the accumulated snp validation test results available at our industrial collaborator , an active participant of the international hapmap project.

number of genes returned for a subset of the keywords used in the example study  <cit>  for each database . the genes returned by a specific keyword and only this database are in parenthesis. the total unique column gives the total number of unique genes for each keyword with unique genes returned only by this keyword in parenthesis. the total unique row gives the total number of unique genes for each database with genes returned only by this database in parenthesis. the intersection of the total unique row and the total unique column gives total number of unique genes with genes returned by only one database, and the number in parenthesis gives the number of genes returned by only one database and only one keyword. - indicates that a keyword was not used with a database. as some composite keywords used in the study  <cit>  were omitted for clarity, the totals in this table reflect the total number of genes retrieved, not the sums of the columns.

using the selected snps,  <dig> nuclear families consisting of both parents and the affected child  were genotyped. the analysis of the genotypes of the  <dig> trios using transmission disequilibrium test  followed by false discovery rate  multi-test correction yielded  <dig> noteworthy genes, that are associated with sle with fdr less than  <dig> ; two of these genes were highly significant, with fdr less than  <dig>   <cit> .

using bayesian methodologies, the impact of pre-existing knowledge of a disease on the discovery of genes associated with the disease can be increased, as the posterior probability of association with the disease can be modified in accordance with its prior probability as reported by function2gene. the false positive report probability  measure is one such method which uses the prior probability of association, which can be calculated from the results of the keyword-based gene selection, to modify the posterior probability of association. using bayes' theorem =ppp), fprp determines the probability of the null hypothesis  being true given a test statistic greater than zα , knowing power , the prior probability of association , and the probability of the measured data given that the null hypothesis is true   <cit> :

 fprp=p=pp+π 

one method of calculating prior probability based on the keyword based gene selection is to order the snps according to number of times they were returned by different keywords, taking into account the biological relevance of the snp, and then apply a continuous function such that the higher ranked snps have a greater prior probability of association than the lower ranked snps, and the sum of the probability of association is the prior estimate of the total number of snps in the search believed to be associated with the disease. an alternative method is to order the snps in the same manner, and then place them in to different groups, assigning the same prior probabilities to each snp in a group while controlling the sum of the prior probabilities assigned. for example, assuming  <dig>  snps,  <dig> of which are believed to be associated, assign priors of π =  <dig>  for the top 1%,  <dig>  × 10- <dig> to the next top 4%,  <dig>  × 10- <dig> to the next top 20%, and  <dig>  × 10- <dig> to the remaining 75%. in this manner the multiple testing effect is controlled while maximizing the effect of the prior available information. applying fprp  <cit>  to the results of the tdt test with a prior assumption of  <dig> associated snps yielded  <dig> noteworthy genes, including all  <dig> obtained with the fdr corrections, and the same two significant genes  <cit> .

an existing web-based program which is functionally similar to the methodology presented here is the disease candidate gene search of snps3d. using the keywords chosen by snps3d for three diseases, diabetes, pancreatic cancer, and alzheimer disease, we have compared the results obtained by snps3d and function2gene in table  <dig>  the majority of high ranking genes returned by snps3d are also returned by function2gene, but function2gene returns a far greater number of genes.

comparison of the number of genes returned by function2gene and snps3d for three diseases, showing the number of genes returned only by a function2gene or snps3d, and the number of genes returned by both search methodologies.

future advancements of the approach presented here could be made by the use of more powerful literature mining techniques which would reduce  the need for expert information on the nature, pathology, and biology of the disease to generate a list of keywords and discard spurious results. such approaches would also reduce the reliance of this approach on the contents of stewarded fields in the databases, enabling novel associations as well as incorrect associations to be discerned. for example, named entity recognition  and relationship extraction  could be used in tandem to elucidate connections between diseases and genes directly. ner identifies biologically-relevant entities  from literature using techniques such as hidden markov models and dictionaries. once entities have been identified, re can identify the relationship and/or connection between entities using the proximity of entities , along with rule base systems and full predicate/subject grammars  <cit> . it would then be possible to walk the relationship tree, using the probabilities between each node of the tree connecting specific genes and a disease , and then ordering the resultant genes by the probability of their connection which should be directly proportional to the prior probability of association.

CONCLUSIONS
the use of available prior information to decrease the size of the problem space for gene identification in complex polygenic disorders is an as yet underutilized technique. the methodology and the programs presented here use data mining techniques to retrieve from a few databases a number of genes with high prior probability of being associated with the disease. the program also allows to order genes by relevance, thereby allowing the problem space to be greatly reduced, increasing the power of the study and thus increasing the likelihood of successfully finding associated genes.

availability and requirements
• project name: function2gene

• project homepage: 

• operating system: platform independent

• programming language: perl

• license: gnu gpl v <dig> or later at your option

abbreviations
fdr: false discovery rate; fprp: false positive report probability; ner: named entity recognition; re: relationship extraction; sle: systemic lupus erythematosus; snp: single nucleotide polymorphism; tdt: transmission disequilibrium test.

authors' contributions
dla wrote the software described herein as well as the text of this article; coj and rz contributed to design of the software and the text of this article. all authors read and approved the final manuscript.
