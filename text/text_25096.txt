BACKGROUND
in this section, we provide the definitions and the terminology needed to describe our method . we then summarize the key literature tackling similar problems to the one considered in this paper .

definitions and notation
we represent a given biological network using a graph denoted with g=. here, the set of nodes v denotes the set of interacting molecules, and the set of edges e denotes the interactions among them. in the rest of this paper, we use the term graph to denote a biological network. here, we focus on undirected graphs. figure 1
a represents a graph that contains seven nodes and eight edges.
fig.  <dig> 
a a graph g that contain seven nodes {a, b, c, d, e, f, g} and eight edges {, , , , , , , }. b a pattern with two embeddings in g, {, , } and {, , }. c a pattern with three embeddings in g, {, , , }, {, , , }, and {, , , }. d a pattern that has one copy in g, {, , , , }




we say that a graph is connected if there is a path between all pairs of its nodes. we say that a graph s= is a subgraph of g if v
s⊆v and e
s⊆e. in the rest of this paper, we only consider connected subgraphs. thus, to simplify our terminology, we use the term subgraph instead of connected subgraph. notice that a subgraph of a given graph can be uniquely determined by the set of edges e
s of that subgraph as all of its nodes are connected.

we say that two subgraphs s1= and s2= of g are identical if they have the same set of edges. a less constrained association between two subgraphs is isomorphism. two subgraphs s
 <dig> and s
 <dig> are isomorphic if the following condition holds: there exists a bijection f:vs1→vs <dig> such that ∀∈es <dig> ⇔,f)∈es <dig> 

we say that two subgraphs s
 <dig> and s
2
overlap if they share at least one edge . in fig. 1
a, consider the four subgraphs s
 <dig>  s
 <dig>  s
 <dig>  and s
 <dig> defined by the set of edges {, , , }, {, , , }, {, , , }, and {, , , } respectively. s
 <dig> and s
 <dig> are disjoint as they do not share any edges. s
 <dig> and s
 <dig> overlap as they share the edge . similarly s
 <dig> and s
 <dig> overlap. all three subgraphs s
 <dig>  s
 <dig>  and s
 <dig> are isomorphic as they have the same topology. s
 <dig> and s
 <dig> are non-isomorphic as they do not satisfy the bijection function defined above.

notice that isomorphism is a transitive relation. thus, for a given subgraph s of g, the set of all subgraphs of g which are isomorphic to s defines an equivalence class. we represent the subgraphs in each equivalence class with a graph isomorphic to those in that equivalence class and call it a pattern. figure 1
c shows the pattern that represents the equivalence class { s
 <dig>  s
 <dig>  s
3}.

there are alternative definitions of the frequency of a pattern in a given graph. the classical frequency definition is the number of all subgraphs of the target graph which are isomorphic to the given pattern. this definition, also known as the f <dig> measure  <cit> , counts all the subgraphs regardless of whether they overlap with each other or not. there are two other frequency definitions which avoid overlaps between different subgraphs. f <dig> measure counts the largest subset of subgraphs in a given equivalence class which do not share any edges with the rest of the subgraphs in that subset. it however allows them to share nodes. f <dig> measure is more stringent as it requires that no two subgraphs can share a node. consider the pattern in fig. 1
c and the target graph in fig. 1
a. the frequency of this pattern in the target graph according to the f <dig> measure is three as it has three embeddings . on the other hand f <dig> is two { s
 <dig>  s
2}, and f <dig> is one . from here on, we denote the f <dig>  f <dig>  and f <dig> counts of a motif m in graph g using the notations f1g, f2g, and f3g respectively.

the downward closure property states that the frequency of a pattern should monotonically decrease as this pattern grows . more specifically, consider a function f() that operates on a pattern and returns a real number. let us denote two patterns with p
 <dig> and p
 <dig>  we say that the function f() has downward closure property if and only if f≤f for all  pairs where p
 <dig> is a subgraph of p
 <dig> 

under the light of these definitions, next we show that f <dig> measure is not downward closed. consider the pattern p
 <dig> in fig. 1
b. the frequency of p
 <dig> is two in the target graph in fig. 1
a. now consider the pattern p
 <dig> in fig. 1
c which contains p
 <dig>  although p
 <dig> is a subgraph of p
 <dig>  the frequency of p
 <dig> is three in the same graph . next, consider the pattern p
 <dig> in fig. 1
d. p
 <dig> contains p
 <dig>  and its frequency is only one . this example demonstrates that the f <dig> measure not only fails to monotonically decrease, but it also fluctuates  as we grow the pattern .

unlike the f <dig> measure, f <dig> is downward closed. in the following, we formally prove this.

theorem  <dig> 
assume that we are given a graph g. given two patterns m and m¯ where m
⊂m¯, we have f2g≥f2g.

proof
to prove this, we consider the placement of each embedding of m¯ in g according to f <dig> measure . notice that each embedding of m¯ contains m as m
⊂m¯. from each of these embeddings, we remove the edges that are in m¯−m. this leads to one embedding of m for each embedding of m¯. thus, the number of non-overlapping embeddings of m in g is at least as much as that of m¯ in g. therefore, f2g≥f2g. □

similarly, we say that f <dig> measure which also counts non-overlapping embeddings, is also downward closed.

failure to satisfy the downward closure property has major implications on the correctness of motif identification. traditional motif identification algorithms often grow a motif starting from an initial motif of a small number of edges . should they employ the f <dig> measure, these algorithms cannot have an early stopping criteria as they grow motifs. this is because the frequency can go up as we grow motif even when the current motif frequency is low. next, we formally define the problem considered in this paper.


problem definition given an input graph g=, the number of nodes in the target motif μ, and frequency threshold α, we aim to find all patterns of μ nodes which have frequency at least α in g under the frequency measure f <dig>  the method we develop in this paper can however be easily extended to f <dig> as well .

summary of existing methods
we classify the literature on motif identification and counting, based on the underlying frequency measure. this is because the frequency measure dramatically changes the cost of counting motifs as well as how we can interpret the frequency of the underlying pattern. most of the existing studies use f <dig> frequency measure to count the embeddings of a pattern in a given graph . these methods carry the drawbacks inherent in the f <dig> measure. first, f <dig> ignores the fact that different copies of the same motif can overlap due to the nodes and the edges they share. this can lead to artificially massive number of motif embeddings as the same node or edge can participate in multiple embeddings. to understand this better, consider the pattern and the graph in figs. 1
c and 1
a respectively. f <dig> counts three copies of the pattern . different nodes and edges however contribute to this count at different numbers. the edge  appears only in s
 <dig> while  appears in both s
 <dig> and s
 <dig> 

second and more importantly, the f <dig> measure is not downward closed. this is because as we grow a pattern by including new edges or nodes, its count as computed by f <dig> is not monotonic; it may decrease, stay the same, or increase. lack of downward closure property makes it nearly impossible to decide if the motif found is the largest one in size while growing a pattern. thus, using f <dig> is essential for the tractability of identifying frequent patterns. we use the f <dig> measure in this paper. thus, the studies limited to the f <dig> measure are out of the scope of this paper.

several algorithms tackle the problem of finding frequent patterns in multiple graphs. fsg  <cit>  is one of the key methods in this class. these methods, however, do not count the number of occurrences of a pattern in each graph. they rather check if the given pattern appears at least once in each graph. vanetik et al.  <cit>  also addressed the same problem.

finding frequent patterns or counting them without overlaps  have received little attention in the literature. one of the existing algorithms in this category is subdue  <cit> . flexible pattern finder algorithm   <cit>  detects frequent patterns using both f <dig> and f <dig>  two algorithms were proposed by kuramochi and karypis  <cit> , named hsigram, vsigram. however, these algorithms are computationally expensive and do not scale to large graphs or motifs. we evaluate subdue and fsg experimentally in section “results and discussion”.

methods
in this section we describe our method. section “algorithm overview” presents an overview of our algorithm. section “joining patterns to find larger patterns” explains the mechanism we use to grow motifs by joining smaller motifs. section “finding mis: going from f <dig> to f2” describes how we count disjoint motif instances. section “accelerating our algorithm through efficient filters” presents filtering techniques we implement to avoid costly isomorphism tests. section “complexity analysis” discusses the complexity analysis of our method.

algorithm overview
in this section, we provide an overview of our method for discovering motifs. at the heart of our method lie four unique graph patterns. we call them the basic building patterns for we use them as guide to construct larger motifs of arbitrary sizes and topologies. figure  <dig> presents these basic building patterns. we explain why we use these four specific patterns in section “joining patterns to find larger patterns” in detail.
fig.  <dig> the four basic patterns used by our algorithm which represent all patterns of two  or three undirected edges 




algorithm  <dig> presents the pseudo-code of our method. we elaborate on each key step of our method in subsequent sections. the algorithm takes a graph g, the number of nodes of the target motif μ, and the minimum acceptable motif frequency as input α. for each of the four basic building patterns, it first locates all subgraphs in g that are isomorphic to that pattern . let us denote the set of instances of the ith pattern  with s
i. in each set s
i, it is possible to have overlapping subgraps. it then extracts the maximum set of edge-disjoint subgraphs in each set s
i  . let us denote the resulting set with s
i′ for the ith pattern. notice that the cardinalities of the sets s
i and s
i′ are the f
 <dig> and f
 <dig> measures of the ith pattern respectively. the union of all the sets s
i′ constitutes the current motif instances as well as the basic building pattern instances at this point . the algorithm then iteratively grows the current motif set. at each iteration, it joins the current motif set with the basic building pattern set . more specifically, a motif instance and a basic building pattern join if they share at least one edge. joining two such subgraphs either creates a pattern which already exists in the current set  or a new pattern . at each iteration, after growing the current set, it filters the overlapping subgraphs to identify mis for each pattern . the algorithm removes all patterns with frequency lower than the user supplied cutoff . it reports the frequent subgraphs that have as many edges as the target motif size . the algorithm terminates when the current set can not be grown to have any other patterns which satisfy the target motif .





joining patterns to find larger patterns
here, we describe one join iteration of our method; the process of joining the subgraphs of current set of patterns with the subgraphs of the basic building patterns to construct larger patterns. at the end of the iteration, the resulting set of subgraphs becomes the current set of subgraphs for the next join iteration.

recall that we join two subgraphs only if they share at least one edge. joining two such subgraphs either yields a pattern that is isomorphic to one of the existing patterns or a new one. in the former case, we consider the set of subgraphs s isomorphic to that pattern. we check if the new subgraph is already in s. if it is in s, we discard it. otherwise, we store it in s. in the latter case , we save this as a new pattern and also keep the corresponding subgraph.

notice that, although the subgraphs in s do not overlap prior to join, this may no longer hold after new subgraphs are inserted into s. at the end of each join iteration, we select the mis for each pattern. we defer the discussion on how we do this to section “finding mis: going from f <dig> to f2”. we then remove the patterns with f <dig> values below the user supplied frequency threshold, α. this eliminates non-promising patterns, and thus, reduces the number of candidate patterns for the next join iteration. using the f <dig> measure ensures that patterns maintain downward closure property. thus, non-frequent patterns will never grow to yield frequent patterns.


why do we need different equivalence classes? if the motif frequency is measured using f <dig>  it is sufficient to join the subgraphs belonging to existing patterns with only those which belong to the same equivalence class of the simple pattern with two edges  to construct any larger pattern. this however is not true when f <dig>  is used to count the motif frequency. to understand the rationale behind this, recall that each equivalence class represents a set of disjoint isomorphic subgraphs. as a result, no two subgraphs from the same equivalence class join for they do not share any edges. therefore we need more than one equivalence class to construct new and larger patterns.

given that we need multiple patterns, next, we seek the answer to the following question: what is the smallest set of patterns which can be used to produce arbitrary large topologies by joining them? here we outline the key steps of the proof that the four basic building patterns, presented in fig.  <dig>  suffice to construct any larger pattern. that said, we do not guarantee to find all copies of such patterns in the target network.

before we discuss our induction steps, we explain our strategy on a specific motif size of four to improve the clarity of the discussion on induction. figure  <dig> shows all the possible patterns which can be constructed with undirected four edges. a careful inspection shows that each one is an overlapping combination of two of the basic building patterns. for instance, the pattern in fig. 3
a can result from joining the basic pattern in fig. 2
a with the basic pattern in fig. 2
c. it is worth noting that we can construct some of the patterns in fig.  <dig> by joining two different pairs of basic building patterns. this redundancy ensures we can still locate a specific pattern even if one of those pairs does not exist. therefore, our method can construct any pattern with four edges from patterns with three or two edges.
fig.  <dig> all patterns which can be constructed with four undirected edges. a, b, and d represent patterns with  <dig> edges and  <dig> nodes while b represents pattern with four nodes and four edges




we conduct our proof for the arbitrary pattern size by induction.


basis the four basic patterns in fig.  <dig> constitute all possible graph topologies with two or three edges.


induction step we assume that our method can construct any pattern with up to k edges . we next show that any pattern with k+ <dig> edges can be constructed by joining a pattern with k edges with one of the basic building patterns.

recall that the downward closure property states that those smaller patterns have at least as much frequency as the larger one according to f <dig> . this means that if a pattern with k+ <dig> edges is frequent, then so is any of the k edge patterns obtained by removing an edge from that pattern.

consider a graph g and a copy of a pattern p <dig> of size k edges in g, s
 <dig>  also, consider a copy of a pattern p <dig> with k+ <dig> edges such that p <dig> contains p <dig> and one additional edge. let us denote this additional edge with . we need to show that p <dig> can be obtained from p <dig> by joining it with at least one of the basic patterns.

since both p <dig> and p <dig> are connected graphs, at least one of the two nodes a and b has an edge in p <dig>  without violating the generality of the proof, let us assume that b has an edge  in p <dig>  figure 4
a illustrates the two edges  and .
fig.  <dig> 
a a subgraph s
 <dig> in a hypothetical graph g. s
 <dig> is isomorphic to a pattern p <dig> of size k+ <dig> edges. if we remove the additional edge  we obtain s
 <dig> which is isomorphic to p
 <dig> where p
1⊂p
 <dig>  notice that s
 <dig> could have arbitrary k− <dig> edges rather than . here we obtain s
 <dig> as a result of joining s
 <dig> with the subgraph {,} which belongs to m <dig> equivalence class . b failure to accomplish the join in , we seek to inspect d
e
g and d
e
g in s
 <dig>  the first possibility is that d
e
g> <dig>  this means that the subgraph {,} exists. we then can join s
 <dig> with the subgraph {,,} which belongs to m <dig> equivalence class  to obtain s
 <dig> which is isomorphic to a pattern p <dig> of size k+ <dig> edges. c the second possibility is that d
e
g> <dig>  this means that the subgraph {,} exists. we then can join s
 <dig> with the subgraph {,,} which belongs to m <dig> equivalence class  to obtain s
2





first, we consider using the basic pattern m <dig> in fig. 2
a in the join operation. in this case, a copy of m <dig>  {,} will join with s
 <dig> having a common edge  which will result in the pattern p <dig> with k+ <dig> edges. this join however occurs only if the subgraph {,} is included in the f <dig> counts of m <dig> .

if this condition fails, we consider the degrees of the two nodes b and c in pattern p <dig>  we start with node c. let us denote the degree of a node with function d
e
g()  is the degree of node c in pattern p1).

if d
e
g> <dig>  then c has at least one more edge on top of . let us denote this edge with  . in this scenario, we join a copy of the motif m <dig> , {,,}  to obtain p <dig> 

finally, if d
e
g= <dig>  it is guaranteed that d
e
g> <dig>  this is because if both nodes b and c have degree one, s <dig> cannot be a connected subgraph. let us denote one of the additional edges of b with  . in this case, we join the subgraph that isomorphic to the pattern m <dig>  {,,}, with s
 <dig> to obtain p <dig>  we can do this if this copy exists in the f <dig> count of m <dig> 

in summary, we conclude that any pattern p <dig> with k+ <dig> edges can be constructed by joining a pattern p <dig> with k edges  and one of the basic building patterns to obtain the additional edge  if at least one of the many possible scenarios hold. we however cannot guarantee that the joins will find all of the instances of the k+ <dig> edge pattern on the target graph.

recall that as we aim to calculate the frequency of a given motif using f <dig>  there is no self join of any pattern. thus, the basic building patterns set is the smallest set of patterns as we can not construct one of those four patterns using the three other patterns. more specifically, this means that we can not use only one of those four basic building patterns to construct larger patterns by joining pairs of subgraphs belong to that pattern’s equivalence class. this is because if we join the embeddings of a single motif topology  we cannot get any larger pattern as they do not share any edge.

finding mis: going from f <dig> to f2
here, we explain how we compute the f <dig> frequency for a given pattern. we use two algorithms for this purpose. we explain why we have two separate algorithms later in this section after describing the two algorithms. the first one is a heuristic used in the literature  <cit> . this algorithm constructs a new graph, called the overlap graph for each pattern as follows. each node in the overlap graph of a pattern denotes an embedding of that pattern in the target graph. we add an edge between two nodes of the overlap graph if the corresponding embeddings represented by those nodes overlap in the original graph. once the overlap graph is constructed, the algorithm starts by selecting the node with the minimum degree  in the overlap graph. we include the subgraph represented by this node in the edge-disjoint set. we then delete that node along with all of its neighboring nodes in the overlap graph. we update the degree of the neighbors of the deleted nodes. we repeat this process of picking the smallest degree node and shrinking the overlap graph until the overlap graph is empty.

the algorithm described above works well for patterns with small number of embeddings. it however becomes computationally impractical as the number of embeddings of the underlying pattern gets large. this is because both constructing the overlap graph  and updating it are computationally expensive tasks. therefore, we use this algorithm for all patterns except for the basic building patterns .

the second algorithm addresses the scalability issue of the the first one. this scalability issue is imposed by the expensive task of calculating the degree of each node in the overlap graph . recall from the previous algorithm that this number is considered as a loss value when selecting the node  with minimum degree  to include in the final mis of the pattern under consideration. briefly, the second algorithm we introduce here avoids the expensive task of calculating number of overlaps for each embedding. the algorithm performs this by algebraically computing such numbers instead of performing actual overlapping tests. once we compute node degrees of the overlap graph, this algorithm selects the disjoint embeddings the same way as the former algorithm described before. more specifically, the algorithm selects the node with the minimum degree and includes its corresponding embedding in the final mis. it then removes neighboring nodes to that node from the overlap graph. it repeats this process until the overlap graph is empty. next, we explain how we compute the degree of a node in the overlap graph for the pattern m <dig> in fig. 2
a. our computation is similar for the other three basic building patterns, yet tailored towards their specific topologies . figure  <dig> shows a hypothetical subgraph s
1={ , } in the input graph g which is isomorphic to m <dig>  this subgraph is represented by a node in the overlap graph of m1’s embeddings. let us denote the degree of a node in the original graph g with function d()  is the degree of node v
i). another embedding of m <dig> in g overlaps with s
 <dig> only if it contains the edge , or . any edge in g connected to the middle node c forms two overlapping embeddings, one with the subgraph that has edge the  and the other with the subgraph that has the edge . we exclude the edges belong to s
 <dig>  itself from the potential edges of g that considered in the overlapping embeddings with s
 <dig>  thus, by excluding the two edges  and  from c’s degree, node c yields  <dig> ×  - 2) overlaps. in addition, any edge that belongs to node a forms an embedding when combined with the edge . excluding the edge , node a yields d -  <dig> overlaps. similarly, node b produces d -  <dig> overlaps. thus, the total number of overlaps for the embedding s
 <dig> = { , } combined from edges of its three nodes { } is 
 2−2)+d−1+d−1=2d+d+d− <dig> 
fig.  <dig> 
a one of the basic building patterns. b a hypothetical graph that contains subgraphs isomorphic to the pattern m <dig> in 




notice that unlike the first algorithm, the second one requires a unique derivation for each pattern. thus, we apply it only to the basic building patterns, for their topologies do not depend on the input graph. also, it is worth noting that typically the basic building blocks have much larger number of embeddings as compared to the patterns derived by joining them. thus, the efficiency of the second algorithm is needed for them more than the patterns obtained in subsequent iterations .

to adapt our method to count non-overlapping embeddings of each pattern according to f <dig> instead of f <dig>  we only need to change how we calculate the mis of this pattern. more specifically, we change the criteria which states that “two subgraphs overlap if they share at least one edge” to “two subgraphs overlap if they share at least one node” . this will result in changing the overlap graph constructed using the first method we explain in this section. in addition, it will also have slight change in calculating the total number of overlap of each embedding using the second method we discuss in this section. practically, we expect the overlap graph to be denser when we use the f <dig> measure as compared to that for the f <dig> measure. to illustrate this, consider the graph g in fig. 1
a and the pattern in fig. 1
c. this patter have  <dig> embeddings in g which are s
 <dig>  s
 <dig>  and s
 <dig> defined by the set of edges {, , , }, {, , , }, {, , , } respectively. figure 6
a and fig. 6
b represent the overlap graph of this pattern based on f <dig> and f <dig> measures respectively.
fig.  <dig> 
a the overlap graph of the pattern in fig. 1
c based on f
 <dig> measure of this pattern in the graph in fig. 1
a. b the overlap graph of the same pattern based on f
 <dig> measure




accelerating our algorithm through efficient filters
recall that at each iteration, our algorithm generates new subgraphs. for each of these subgraphs, it checks if this subgraph is isomorphic to one of the patterns constructed till that iteration. isomorphism test is a computationally expensive task. next, we describe how we avoid a large fraction of these tests.

we develop two canonical labeling strategies for patterns. canonical labeling assigns unique labels to the nodes of a given pattern  <cit> . if two patterns are isomorphic, then they have the same canonical labeling. the inverse is however not true. unlike isomorphism test, comparing the canonical labeling is a trivial task. following from this observation, when we construct a new subgraph, we first compare its canonical labeling to those of existing patterns. we then limit the costly isomorphism test to only those patterns which have the same canonical labeling as the new subgraph.

the first canonical labeling counts the degree  of each node in the given pattern. it then sorts those degrees and keeps them as a vector we call the degree vector. if two patterns have different degree vectors, then they are guaranteed to have different topologies. despite its simplicity, this labeling filters out a large fraction of patterns. to test its efficiency, we have tested it on random graphs generated using barabási −albert model  <cit> . we generate  <dig> pairs of graphs where each pair is non-isomorphic and have the same number of nodes and edges. the degree vector successfully filters  <dig> % of the  <dig> experiments.

the second canonical labeling extends on the first one. it was first introduced by  <cit> . consider a pattern p=. let us define the distance between two nodes v
i, v
j∈v as the number of edges on the shortest path that connects v
i and v
j and denote it with x
ij. let us define the diameter of p as the maximum distance between any two nodes, and denote it with x. using this notation, we assign label to node v
i as: ∑jj∈v2x−xij−d. once we compute the labels of all the nodes in the given pattern, we sort them. we call the resulting vector the nodes vector. similar to the first labeling above, two isomorphic graphs are guaranteed to yield the same labeling. we compute and compare the nodes vector with only the patterns which cannot be eliminated using the first canonical labeling. we then consider the patterns with identical canonical labels for graph isomorphism.

complexity analysis
here we analyze the complexity of our method. we refer to algorithm  <dig> as we discuss the steps of our method. for each steep, we explain its complexity. we then summarize the complexity of all steps to denote the overall complexity of our method. these steps are 

find all subgraphs isomorphic to each of the four basic patterns : in this step, we analyze each of the four basic patterns separately since they have different topologies. for the pattern m <dig> in fig. 2
a, to get all subgraphs isomorphic to this pattern, we consider all edges connected to each node in the underlying network. we select any two edges combination connected to every node. here, we denote the degree of a node with function d()  is the degree of node v
i). thus, the complexity of collecting subgraphs that are isomorphic to m <dig> is ∑vi∈vd <dig>  similarly, for the pattern m <dig> in fig. 2
c, we select any three edges combination connected to each node in g. thus, the complexity of constructing subgraphs which are isomorphic to m <dig> is ∑vi∈vd <dig>  for the pattern m <dig> in fig. 2
b, we consider each edge e
ij in g with two nodes v
i and v
j. we collect edges of both nodes. we then select one edge connected to v
i and one edge connected to v
j  along with e
ij to form a subgraph isomorphic with m <dig>  thus, the complexity of constructing subgraphs that are isomorphic to m <dig> is ∑eij∈edd. similarly to m <dig>  we perform the same operation to get isomorphic subgraphs to the pattern m <dig> in fig. 2
d. only this time we make sure that the two edges belong to v
i and v
j are not connected with each other from the other end. thus, the complexity of constructing subgraphs that are isomorphic to m <dig> is ∑eij∈edd. collectively, the complexity of performing this step is o3+∑eij∈edd). notice that, theoretically, the worst case scenario happens when d=o. in this scenario, the complexity of this step becomes o.


extract maximum disjoint set for basic patterns : in this step, we use the algebraic algorithm described in section “finding mis: going from f <dig> to f2”  to calculate the number of overlaps of each subgraph belonging to each pattern equivalence class. this process takes constant time. we calculate this algebraic equations as we construct subgraphs in the previous step. we then sort those subgraphs within each equivalence class in decreasing order of their number of overlaps. this process has complexity equal to o) where m is the number of subgraphs in each equivalence class. recall from previous step that this number is o∑vi∈vd3+∑eij∈edd. thus, the complexity of this step is o∑vi∈vd3
log∑vi∈vd3+∑eij∈edd
log∑eij∈edd.


join iterations : in this step, we analyze the complexity of one join iteration. we then summarize the complexity of all join iterations. let us denote the number of current patterns in iteration i with x
i. notice that, for the first iteration x
i= <dig>  recall that in each join iteration, we increase the size of each of the current patterns with one or two edges. in addition, the patterns of the first join iteration are at least of size  <dig>  thus, the size  of each of the current patterns in iteration i is at least i+ <dig>  the number of subgraphs isomorphic to each of the current patterns is at most |e|i+ <dig> since they are non-overlapping subgraphs. recall that the subgraphs of the basic patterns are non-overlapping within each pattern. thus, the number of subgraphs of the patterns m <dig>  m <dig>  m <dig>  and m <dig> are |e| <dig>  |e| <dig>  |e| <dig>  and |e| <dig> respectively. collectively, the number of subgraphs of the basic patterns is o.

in the join iteration, we start by joining subgraphs of current patterns with the subgraphs of the basic patterns . thus, the total number of joins we perform at iteration i is o|e||e|i+2xi. for each join, we compare the resulting subgraph against all patterns . recall that, we use filters to avoid this costly isomorphism check . thus, the complexity of this operation is o. if this subgraph is isomorphic to one on the current patterns, we check whether this subgraph is a duplicate of one of the subgraphs which already exists in this equivalence class . we search an indexed list of those subgraphs in olog|e|i+ <dig>  collectively, we obtain the complexity of performing all joins at iteration i by multiplying the three complexities above and get |e||e|i+2xixilog|e|i+ <dig> whichequalsoxi2|e|2i+2log|e|i+ <dig> 

upon completing all join operations, our algorithm extracts the mis for each pattern  using the overlap graph algorithm described in section “finding mis: going from f <dig> to f2” . notice that we perform this operation for the new set of patterns, x
i+ <dig>  for which the number of patterns is at most |e|i+ <dig> . for each pattern, we collect the overlapped subgraphs of each subgraph in o|e|i+ <dig>  we then sort the subgraphs in decreasing order of their number of overlaps in o|e|i+3log|e|i+ <dig> time. thus we extract the mis for all patterns in oxi+1|e|i+33log|e|i+ <dig> 

finally, we check each resulting pattern  and delete it if its frequency is less than the threshold α. we perform this step in o time.

recall that in each join iteration, we increase the size of each of the current patterns with one or two edges. also recall that we start the with patterns of at least of size  <dig>  thus, total number of join iterations we perform until we reach to all patterns are at least of the target motif size is μ− <dig>  thus, the complexity of all join iterations is o∑i=1μ−2xi2|e|2i+2log|e|i+2+xi+1|e|i+33log|e|i+3+xi+1orsimplyo∑i=1μ−2xi|e|2ilog|e|i+2xi+|e|i2+xi+1





in summary, the complexity of our method considering all the previous steps is 
 o∑vi∈vd31+log∑vi∈vd3+∑eij∈edd1+log∑eij∈edd+∑i=1μ−2xi|e|2ilog|e|i+2xi+|e|i2+xi+ <dig> 


notice that x
i here depends significantly on the topology and the density of the given network g. to the best of our knowledge, there is no closed formula that calculates x
i .

RESULTS
in this section, we experimentally evaluate the performance of our motif discovery algorithm on synthetic and real graphs . we measure the running time and accuracy of our algorithm. we compare our algorithm to two state of the art algorithms, fsg  <cit>  and subdue  <cit>  . we evaluate the statistical significance of the most abundant motif in each of the real graph . we present a case study of the motifs identified by our method on human herpesvirus ppi network . in all of our experiments, we report the motif frequency using the f <dig> measure.


data set we use real and synthetic datasets in our experiments. the real graphs are the ppi networks of seven organisms taken from the mint database  <cit>  . we first remove the nodes and edges of these graphs which are guaranteed to not be a part of the motif to be found. to do that, we filter a subset of the nodes of each network as follows. we first identify connected subgraphs of each graph. let us denote the size of the motif we aim to find with μ. we remove the connected subgraphs with less than μ nodes. table  <dig> lists these networks and their sizes after filtering them for μ= <dig> .



in addition to the real dataset, we construct synthetic graphs. the purpose of having synthetic dataset is to systematically evaluate our method by varying network characteristics  in a controlled environment. we build this dataset using the barabási −albert model  <cit>  for it captures the connectivity patterns of real networks . moreover, this model has been frequently used in the literature to simulate real networks.


implementation and environment we implement our algorithm in c++ and perform experiments on a computer equipped with amd opteron processor  <dig>  ghz cpu,  <dig> gbs of main memory running linux operating system.

evaluation of running time
in this experiment, we evaluate the running time of our motif discovery algorithm. our goal here is to observe the effect of varying parameters; graph size, graph density, and motif size on the running time of our algorithm.

effect of graph and motif size
we evaluate the running time of our method under varying graph and motif sizes using both synthetic and real datasets.

results on synthetic graphs
we generate synthetic graphs of varying size  from  <dig> to  <dig> at increments of  <dig>  we fix the graph density to two edges per node on the average . we set the minimum desired motif frequency, α=  <dig>  we run experiments for motif sizes μ=  <dig>   <dig>  and  <dig> and report the running time. figure  <dig> presents the results.
fig.  <dig> the total running time of our method for varying graph size and motif sizes . motif size varies from  <dig> to  <dig>  the x-axis shows the input graph sizes varying from  <dig> to  <dig>  the y-axis shows the total running time in seconds




the results demonstrate that our method scales well with growing graph and motif sizes. the running time grows with increasing graph and motif sizes, yet it remains practical for very large graphs. for motif sizes of  <dig> and  <dig>  it runs in only several minutes even for the largest input graph. as the motif size grows, the cost increases. however, our method can identify very large motifs in a little over a day for massive networks. we observe that the motif size has more influence on the performance of our method than the input graph size. this is because the number of alternative motif topologies grow exponentially with the motif size. this is an inherent characteristic of the underlying computational problem. however, even when the motif size is  <dig> our method remains to have a practical running time.

results on real graphs
next, we test our method on real dataset. we set the minimum desired motif frequency, α=  <dig>  we run experiments for motif sizes μ=  <dig>   <dig>  and  <dig> and report the running time. figure  <dig> presents the results. similar to the synthetic dataset results, our method scales to large graph and motif sizes on the real dataset. note that the number of alternative motif topologies grows exponentially with the motif size. furthermore, the cost of subgraph isomorphiosm also grows exponentially with the motif size. despite these two major complicating factors, the running time of our method increases only by about an order of magnitude when we increase the motif size by five. finally, the parallel between these results and those in fig.  <dig> suggests that synthetic graphs generated by barabási −albert model have similar structural properties as the real ppi graphs.
fig.  <dig> the total running time of our method for the real ppi networks. network numbers  <dig> to  <dig> on the x-axis correspond to hhv- <dig>  cje, tpa, rno, hpy, eco, and pfa ppi networks respectively. the positions of the ppi networks on the x-axis indicate the sizes of the input graphs . the y-axis shows the running time in seconds




effect of graph size and density
here, we evaluate the effect of varying input graph size and density on the running time of our algorithm. we use synthetic dataset in order to control the graph density in this experiment. we generate synthetic graphs varying network size from  <dig> to  <dig> at increments of  <dig>  we set the desired motif frequency α=  <dig> and the motif size μ=  <dig>  we vary graph density from one to four which covers broad range of biological networks  <cit> . for each input graph and density value, we report the total running time. figure  <dig> presents the results.
fig.  <dig> the total running time of our method for the synthetic graphs with different graph sizes  and varying graph densities from  <dig> to  <dig>  the x-axis shows the input graph sizes. the y-axis shows the total running time in seconds




we observe that the running time increases with growing graph density. as the graph density increases, the number of alternative embeddings of a given motif grows as well. this also increases the number of overlapping subgraph pairs, which in turn increases the cost of finding mis for each pattern to calculate its f <dig> frequency . despite these major complications inherent in the nature of the motif counting problem, our method remains scalable with respect to growing density. these results suggest that our method is reliable and computationally feasible for a broad range of networks with different sizes and densities.

comparison with existing methods
here, we compare our method against two methods in the literature which are tailored towards a problem similar to the one considered in this paper, namely subdue and fsg. we measure the running time and accuracy. we compute accuracy in terms of three parameters, the number of unique motifs found, the average frequency per motif in the target graph, and the frequency of the most abundant motif.

of these two methods, for subdue, we only report the accuracy of the result as we observe that for most datasets and motif sizes, subdue fails to identify motifs . for fsg, we only report the running time. this is because fsg finds motifs in multiple graphs, limited to at most one embedding per graph. in other words, it cannot find multiple embeddings of the same motif in a single graph. therefore, fsg would yield very low accuracy when applied to a single graph. in the rest of the paper, we will refer to our method as md  for simplicity.

comparison with subdue
in this experiment, we analyze the effect of varying input graph and motif sizes on the accuracy of our method as compared to that of subdue. we use real dataset in this experiment . subdue does not allow the user to set a minimum allowable motif frequency parameter. it finds all subgraph topologies of a given size even for those subgraphs that appear only once. due to this limitation of subdue, to have a fair comparison, we set α=  <dig> for our method as well. we follow our earlier definition , and use motif size μ to denote the number of nodes in the given motif topology. we run both methods on each input graph using motif sizes μ=  <dig>   <dig>  and  <dig>  we report the accuracy of our method as well as subdue. figures  <dig>   <dig>  and  <dig> present the results of μ=  <dig>   <dig>  and  <dig> respectively.
fig.  <dig> the accuracy of our method  and subdue in terms of three measures a the number of unique motif topologies found, b the average frequency per motif in the target graph, and c the frequency of the most abundant motif. results are for the motif size μ=  <dig> on the real dataset 


fig.  <dig> the accuracy of our method  and subdue in terms of three measures a the number of unique motif topologies found, b the average frequency per motif in the target graph, and c the frequency of the most abundant motif. results are for the motif size μ=  <dig> on the real dataset 


fig.  <dig> the accuracy of our method  and subdue in terms of three measures a the number of unique motif topologies found, b the average frequency per motif in the target graph, and c the frequency of the most abundant motif. results are for the motif size μ=  <dig> on the real dataset 




our results for μ=  <dig>  demonstrate that both methods identify similar number of unique motifs, yet our method outperforms subdue significantly in terms of the average frequency per motif in all cases . when we focus on the most abundant topology of each method, we observe a similar pattern; our method always finds patterns with much higher frequency than subdue in all the experiments . it is worth nothing that motif discovery problem gets exponentially harder with growing motif size. as a result, we expect most algorithms tailored for motif identification to perform well for small motif sizes such as μ=  <dig>  next, we observe how our method and subdue perform for large values of μ.

as we grow the motif size to μ=  <dig> , the results suggest that the gap between our method and subdue grows rapidly in terms all three accuracy measures. more importantly, the results also show that in half of the cases, particularity where the input graph size is large, subdue could not find any motifs while our method continue to locate patterns with high frequency. for example, our method was capable of finding motif topologies with frequency over  <dig> while subdue could not locate any motif .

for few cases , , the average frequency per motif of subdue is slightly higher than that of our method. this is because, we set the minimum frequency α=  <dig>  our method locates many topologies which exist only once while subdue fails to locate them. for example, our algorithm finds thousands of unique motif topologies while subdue outputs only  <dig> motif topologies for the hhv- <dig> organism . as a result, these unique topologies pull the average frequency down. that said, fig. 11
c confirms that our method can identify motifs which are more frequent than those found by subdue even for those organisms.

as we further increase the motif size to μ=  <dig> , the significance of our method becomes more prevalent. we observe that subdue could not find any motifs in any of the graphs accept for tpa’s ppi network. on the other hand, our algorithm not only identifies a massive number of patterns , but also some of these patterns have very large frequencies .

in summary, the results demonstrate that our method scales to large input graph and motif sizes and continue to locate patterns with high frequency for a broad range of motif and input graph sizes while subdue fails to do so.

comparison with fsg
in this experiment, we compare the effect of different input graph and motif sizes to the running time of our algorithm and that of fsg. we use real dataset in this experiment . fsg method requires multiple graphs as input. it defines the frequency of the motif topology as number of different graphs that this motif appears within. since our method operate on one input graph, we set the desired motif frequency α=  <dig> to be consistent with fsg. fsg defines motif size as the number of edges in the given motif. to be consistent with fsg, we use μ to denote the number of edges in the motif in this experiment. we run both methods on each input graph using motif sizes μ=  <dig>   <dig>  and  <dig>  we report the running time of our method  as well as fsg. we do not run experiments for μ>  <dig> as fsg fails to scale to large motif sizes unlike our method. figure  <dig> presents the results.
fig.  <dig> the total running time of our method  and fsg for the real ppi networks . the y-axis shows the running time in seconds for three motif sizes; a. motif size =  <dig>  b. motif size = <dig>  and c. motif size =9




we observe that our method  is orders of magnitude faster than fsg, particularly in large motif sizes. the running time of our method increases slowly with both motif size and the graph size. on the other hand, the running time of fsg increases slowly with the input graph size, but very rapidly with the motif size. only for a few cases of small motif sizes  fsg performs better than our method. this is due the overhead of calculating f <dig> for the basic building patterns where number of overlapped embeddings is huge. that said, the running time difference in those cases are negligible. these results suggest that our method outperforms fsg in terms of running time for a broad range of input real biological networks with different sizes. this performance advantage is further magnified by the fact that our method can find multiple embeddings of each motif while fsg finds only one. the two main reasons behind the fact that our method is significantly faster than fsg is that our method  does not calculate the frequency of the each new pattern by locating the copies of this pattern in the network using subgraph isomorphism as fsg does, and  it ensures that every generated pattern exists at least once in the underlying graph.

evaluation of statistical significance
in this experiment, we evaluate the statistical significance of the most abundant motif identified by our method in each of the six ppi networks . we compute the statistical significance of the abundance of the most frequent motif of a given size in two alternative approaches. each of these two approaches measures a different aspect of the significance. 
the first approach measures the statistical significance of the frequency of most abundant motif with respect to the abundances of all motifs with the same size in the same graph. more specifically, given a target graph g= and motif size μ, we first find all motifs of size μ in g. assume that there are totally m such motifs. let us denote the frequency of these motifs with x
 <dig>  x
 <dig>  …, x
m, with x
 <dig> being the largest among all. let us denote the mean and standard deviation of these m frequency values with x¯ and σ. we report the z-score of the frequency of the most abundant motif as x1−x¯σ.

the second approach measures the statistical significance of the frequency of the most abundant motif in the original graph with respect to those in the random ensemble of graphs of the same size and degree distributions. more specifically, given a target graph g= and motif size μ, let us denote the frequency of the most abundant motif of this size in g with x. we construct a set of n random networks from g through degree preserved edge shuffling  <cit> . note that degree preserved edge shuffling is an iterative technique, which is often used in the literature to construct random network topologies with same size and degrees as a given target graph g=. at each iteration of this technique, we randomly pick two edges from e. let us denote these edges with  and , where v
 <dig>  v
 <dig>  u
 <dig>  u
2∈v. we remove these two edges from e and insert two new edges  and . this way as the network topology evolves randomly, we ensure that the degrees of all the nodes remain unchanged. we repeat these iterations large number of times  to randomize the entire network. using the strategy above, we generate  <dig> random graphs, denoted with g
 <dig>  g
 <dig>  …, g
 <dig>  for each random graph g
i, we measure the frequency of the most abundant motif of size μ. let us denote this number as x
i. let us denote the mean and standard deviation of these  <dig> frequency values with x¯ and σ. we report the z-score of the frequency of the most abundant motif as x−x¯σ.




for both of the approaches above, we assume that a z-score above  <dig> or below - <dig> implies high statistical significance . the larger the magnitude of z-score is, the more significant the result is. tables  <dig> and  <dig> present the z-score for each of the six ppi network and three motif size  combinations using the first and the second approach described above respectively.




case study on human herpesvirus
here we briefly analyze the motifs identified by our method on the hhv- <dig> ppi network which causes kaposi’s sarcoma disease. we choose this organism in our case study as it has the smallest ppi network among the organisms in our database . notice from fig. 11
c that despite its small size , hhv- <dig> has four disjoint embeddings of a very large motif with  <dig> nodes, covering a significant fraction of its ppi network. this begs the question whether there is a fundamental recurring function that hhv- <dig> serves and is covered through evolutionary process with high redundancy. figure  <dig> presents the structure of those four embeddings. each row of table  <dig> lists the uniprot ids of the ten proteins that contribute to each of those embeddings. analysis of these proteins in the gene ontology database  <cit>  reveals that three of those four embeddings, each contains two proteins one responsible for viral dna packaging  and one responsible for virion assembly . without either process, no infectious progeny virus could be formed  <cit> . several studies use these two processes as targets to identify effective inhibitors. the existence of these two process in each of the three instances reflects the functional importance of the motif topology found. these results suggest that our algorithm can find significant and valuable motifs which can be use to detect key functions governed by the network processes.
fig.  <dig> the organization of the four isomorphic subgraphs of  <dig> nodes in the hhv- <dig> ppi network. each supgraph has different color and pattern





CONCLUSIONS
in this paper, we developed a scalable method to solve the motif identification problem given an input graph, desired motif size μ, and minimum frequency of desired motif α. we proposed a set of small patterns, we call basic building patterns each containing two or three edges. we proved that any motif with four or more edges can be constructed as a join of these patterns. our method first locates instances of the basic building patterns. it then iteratively grows known motifs at that iteration by joining them with the instances of these patterns. we developed efficient mechanisms to avoid a significant fraction of the costly isomorphism tests. we also introduced a new and efficient strategy for solve the mis extraction problem. we analyzed the time complexity of our method based on the number of nodes and edges in the target network and the number of frequent motifs at each iteration. our experiments on ppi networks from mint comprehensively demonstrated that our method is significantly faster and more accurate than the existing methods. furthermore, we observed using synthetic networks that the running time of our algorithm is reasonable with growing the size of the target network and network density. we also showed using ppi networks that the increase in the running time of our algorithm is dramatically less than that of the competing methods as the motif size grows. we evaluated the statistical significant of the most abundant motif of ppi networks resulting from our algorithm.

additional file

additional file  <dig> appendix  <dig>  this appendix shows the algebraic derivation of number of embeddings for each three of the four basic building blocks . in addition, the appendix lists further experimental analysis. appendix file is attached as pdf file. 




abbreviations
fbfflexible pattern finder

mismaximum independent set

ppiprotein-protein interaction

not applicable.

funding
this work has been supported partially by the us national science foundation under grant dbi- <dig> 

availability of data and materials
the real dataset supporting the conclusions of this article is publicly available at http://bioinformatics.cise.ufl.edu/code/nm-data.zip.

authors’ contributions
both authors participated in the design, and evaluation of the method described in this paper. re implemented the methods and gathered experimental results. both authors wrote and approved the final manuscript.

authors’ information
we have no additional information about the authors.

competing interests
the authors declare that they have no competing interests.

consent for publication
not applicable.

ethics approval and consent to participate
not applicable.
