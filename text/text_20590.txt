BACKGROUND
an extremely broad variety of phenomena in physics, biology, and the social sphere is described by power law distributions. the power laws apply to the distribution of the number of links between documents in the internet, the population of towns, the number of species that become extinct within a year, the number of sexual and other contacts between people, and numerous other quantities  <cit> . in the field of genomics, the "dominance by a selected few"  <cit>  encapsulated in the power laws applies to the distribution of the number of transcripts per gene, the number of interactions per protein, the number of genes in coexpressed gene sets, the number of genes or pseudogenes in paralogous families, the number of connections per node in metabolic networks, and other quantities that can be obtained by genome analysis  <cit> .

mathematically, these distributions are described by the formula: p ≈ ci-γ where p is the frequency of nodes with exactly i connections or sets with exactly i members, γ is a parameter which typically assumes values between  <dig> and  <dig>  and c is a normalization constant. obviously, in double-logarithmic coordinates, the plot of p as a function of i is close to a straight line with a negative slope. recently, it has been shown that the distributions of several genome-related quantities are best described by the so-called generalized pareto function: p = c-γ where γ >  <dig>  a are parameters  <cit> . at large i , this distribution is indistinguishable from a power law, but at small i, it deviates substantially, with the magnitude of the deviation depending on a.

power law distributions and the associated scale-free networks are compatible with the intuitively plausible mechanism of evolution by preferential attachment although other modes of evolution are also possible  <cit> . under preferential attachment, a network or a mathematically analogous object, such as an ensemble of gene families, grows via attachment of new nodes to the pre-existing ones with a probability that is proportional to the degree  of the latter.

however, preferential attachment or other general evolutionary principles associated with power law type distributions and scale-free phenomena do not actually explain the emergence of these phenomena in biologically meaningful terms. a biological explanation involves, at a minimum, identifying the elementary events underlying the evolutionary process and the simplest models of evolution that include these events and are compatible with the observations. under this logic, families of paralogous genes represent a perfect object for evolutionary modeling. indeed, for these families, elementary evolutionary processes are defined naturally. by definition, paralogous families evolve by gene duplication. it has been long suspected and, with the advent of genomics, established beyond reasonable doubt that genome evolution proceeds largely by duplication of genes or portions thereof, and even long genomic segments or entire genomes  <cit> . all sequenced genomes contain numerous paralogous genes, and in more complex genomes, the majority of genes have at least one paralog  <cit> . duplication is followed by mutational diversification and gradually leads to functional differentiation of the paralogs. it is thought that such differentiation occurs via the routes of neofunctionalization   <cit>  and, probably most often, subfunctionalization, i.e., partitioning of subfunctions of the ancestral gene among the paralogs  <cit> . hence, duplication obviously is the first elementary process of genome evolution. genomes and gene families not only grow but often shrink or, probably most of the time, persist in equilibrium. therefore, duplication must be counter-balanced by the opposite elementary process, gene loss. again, comparative genomics has shown that gene loss occurs in all species and seems to be extensive in certain lineages, particularly in parasites  <cit> . finally, genes new to a given lineage may emerge either as a result of a dramatic change after duplication obliterating all "memories" of a gene's origin, or via horizontal gene transfer, or by evolution of a protein-coding gene from a non-coding sequence . collectively, the contribution of these processes to genome evolution may be termed innovation. gene duplication, gene loss, and innovation seem to comprise a reasonable minimal set of elementary events for modeling genome evolution. the only potential major addition could be rearrangement of the gene structure whereby genes accrete or lose domains. however, at least for first approximation modeling, these changes could be covered either by duplication, if they do not yield new genes without detectable relationships to pre-existing families, or by innovation if they do. we should further note that evolutionary analysis of paralogous gene families can be reasonably viewed as a study of the evolution of genomes themselves if all genes are viewed as members of paralogous families, ranging in size  from  <dig> to n . of course, one must keep in mind that describing genome evolution in terms of gene duplication, loss, and innovation represents a high level of abstraction, whereby a gene is considered an atomic unit of evolution, and mutation processes occurring within a gene are ignored. however, numerous comparative-genomic studies have shown the utility of the gene-level abstraction both for systematic prediction of the functions of uncharacterized genes using the patterns of their distribution in diverse genomes  <cit>  and for understanding general evolutionary trends. a striking recent example of the latter type of achievement is the demonstration that different functional categories of genes scale differently with genome size, with the steepest ascent of regulatory genes offering a plausible explanation for the observed limits of genome size in prokaryotes  <cit> .

a natural framework for modeling evolution of gene families is a birth-and-death process, a concept well explored in many physical and chemical contexts  <cit> . duplication constitutes a gene birth, and gene loss is a death event; innovation also can be readily incorporated in this context. the birth-and-death approach has been applied to modeling the evolution of paralogous genome family sizes  <cit> , the distribution of folds and families in the entire protein universe  <cit> , and protein-protein interaction networks  <cit> . for over a century since the publication of darwin's seminal work  <cit> , biologists believed that evolution at all levels is largely driven by natural selection  <cit> . however, the advent of molecular evolution shifted the perspective by demonstrating, largely through the work of kimura and his school, that many, if not most, of the fixed nucleotide substitutions are effectively neutral  <cit> . recent comparative analyses of gene expression led to the expansion of the neutral evolution concept beyond the genome sequence, at least to the level of the transcriptome  <cit> . perhaps the principal importance of the neutral theory is that it leads to a change of the prevailing null hypothesis of evolutionary biology: neutrality should be taken as the null hypothesis, and selection should be invoked only when this hypothesis can be rejected. birth and death models naturally fit this paradigm because they do not include the notion of selection . it is therefore of considerable interest to determine whether or not simple models of this class can be rejected as the explanation for various observed features of genomes.

in the previous work  <cit> , we examined in detail simple deterministic models of genome evolution, which we dubbed bdims, after birth , death , and innovation  models. we showed that the power law asymptotic of the size distribution of gene families appears if, and only if, birth and death rates of domains in families of sufficiently large size are balanced  and that any power asymptotic with γ ≠  <dig> appears only if the per gene birth/death rates depend on the size of the gene family. we showed that the simplest model that adequately approximates the empirical data on gene  family size distributions is the linear 2nd order balanced bdim.

subsequently, we expanded the bdim framework by introducing stochastic bdims, which account not only for the stationary state of the gene ensemble but also for the characteristics of evolution of the system, such as the probability of the formation of a family of the given size before extinction and the mean times of formation and extinction of a family of a given size  <cit> . we first investigated these issues for the linear 2nd order balanced stochastic bdim. given the published estimates of the rates of gene duplication and loss  <cit> , we found that this version of bdim, which gives a good approximation of the stationary distributions of family sizes for different genomes, predicts completely unrealistic mean times for reaching the observed sizes of the largest domain families. in computer simulations with a large ensemble of genes, even the minimum time required for the formation of the largest family was shown to be unrealistically long. thus, the linear bdim is incompatible with the estimates of the rate of genome size growth derived from the empirical data. therefore we performed a preliminary examination of non-linear, higher degree bdims and showed that the rate of genome size growth increases with the degree of the model, rendering non-linear bdims more realistic models of genome evolution  <cit> .

here, we present a detailed analysis of the properties of different non-linear stochastic bdims, including polynomial, rational, and logistic ones, which were obtained by the appropriate transformations of the original linear model. these models generated the same stationary family size distribution, but the stochastic properties of the higher order models were dramatically different from those of the linear bdim. the mean number of elementary events, duplications and deletions, which are required for the formation of the largest family, decrease monotonically with the increase of the model degree. by contrast, the mean time of formation of a gene family of the given size under a fixed average duplication rate went through a minimum depending on the model degree; typically, the model degree corresponding to this minimum was between  <dig> and  <dig>  however, even with this optimal degree, the mean times of formation of the largest families in different genomes were unrealistically long.

the times of formation and extinction of gene families are random variables with unknown distributions. therefore it was important to determine the variance of these times and the number of elementary events preceding the formation and extinction of the largest families. we found that the coefficients of variation were very large such that the extreme values of the formation times for the largest family could differ from the mean time by at least two orders of magnitude. thus, for assessing the feasibility of the formation of the largest families under a given model, the relevant value is not the mean but the minimal time of family formation over the entire ensemble of genes. using monte carlo simulations, we show that the minimal time required for the formation of families of the expected size under bdims of the orders between 2– <dig> is compatible with the timescale of genome evolution.

RESULTS
 <dig>  definitions and empirical data
the basic bdim definitions and assumptions
we treat a genome as a "bag" of genes  encoding protein domains . domains are treated as independent evolving units disregarding co-occurrence of domains in multidomain proteins. each domain is considered to be a member of a family, which may have one or more members. in this work, we interchangeably refer to domain families or gene families. three types of elementary events are postulated: i) birth, which yields a new member in the same domain family as a result of gene duplication, ii) death, i.e., inactivation and/or deletion of a domain, and iii) innovation, which generates a new, single-member family. innovation may occur via domain evolution from a non-coding sequence or a non-globular protein sequence, via horizontal gene transfer from another species, or via radical change of a domain after duplication. the rates of elementary events are defined as the probabilities of the respective events during an infinitesimally short time interval  <cit>  and is postulated to be independent of time  and of the structure, biological function, and other features of individual domain families. clearly, these assumptions are simplifications made in order to avoid prohibitively complex models; the justification is that, over large  ensembles of families and long time intervals, the existing non-homogeneities are likely to cancel out, making homogeneous models realistic. it may be useful to emphasize that homogeneity of the models does not imply constancy of the number of events during any finite time interval, which is a random variable.

the data on the size of domain families in sequenced genomes were obtained as described previously  <cit> . briefly, the domains were identified by comparing the cdd library of position-specific scoring matrices  for domains extracted from the pfam and smart databases, to the protein sequences from completely sequenced eukaryotic and prokaryotic genomes  using the rps-blast program  <cit> .

in a finite genome, the maximum number of domains in a family cannot exceed the total number of domains and, in reality, is probably much smaller. let n be the maximum possible number of domain family members . we also consider virtual, "empty" families that consist of  <dig> domains. in the stochastic bdims, newborn domains are extracted from this class and dead domains return to it. originally, we examined exclusively the deterministic version of the bdims  <cit> . introduction of the  <dig> class "closes" the model and allows us to transform it into a markov process, which provides for the possibility to explore the stochastic properties of the system  <cit> . in these stochastic models, innovation was not introduced explicitly as it was in the deterministic models, but was implied in the emergence of domains from the  <dig> class.

let pi be the frequency of a domain family of size i. then pi satisfy a system of forward kolmogorov equations for birth-and-death process :

dp0/dt = -λ0p <dig> + δ1p <dig> 

dpi/dt = λi-1pi- <dig> - pi + δi+1pi+ <dig> for  <dig> <i <n,     

dpn/dt = λn-1pn- <dig> - δnpn.

mathematically,  defines the state probabilities of a birth-and-death process with the finite number of states { <dig> ,...n} and reflecting boundaries in  <dig> and n. the evolution of individual trajectories of the birth-and-death process x, whose state probabilities satisfy the system , can be described as follows. at the starting time, the system is situated in some initial state x <dig>  the time axis {t ≥ 0} can be divided into intervals [ <dig> τ1), [τ <dig>  τ2), [τ <dig>  τ3) ... such that x is a constant on each interval. if, at the moment τn, the system was situated in the point xn = i, then, in the moment τn+ <dig>  the system moves either into the state i+ <dig> with the probability βi = λi/ or into the state i- <dig> with the probability μi = δi/. the sojourn time ti = τn+ <dig> - τn between the arrival at the point xn = i and the exit from this point is a random variable independent of the previous history of the system and is distributed exponentially: p{ti ≥ x} = expx). note that the random variables ti are independent, and the mean sojourn time, e, in the state i is e = 1/.

process  has a unique stationary ergodic distribution p <dig> ...,pn defined by the equalities dpi/dt =  <dig> for  <dig> ≤ i ≤ n. let j = δipi - λi-1pi- <dig> be the current through the state i in t time moment, j = δipi - λi-1pi- <dig> be the current in the stationary state. then the equation for the stationary distribution can be written as j - j =  <dig>  as the system is closed, j =  <dig> and hence j =  <dig> for all i, such that

pi / pi- <dig> = λi-1/δi.





we will consider also the variant of this model with states { <dig> ...n} and reflecting boundaries in states  <dig> and n:

dp1/dt = -λ1p <dig> + δ2p <dig> 

dpi/dt = λi-1pi- <dig> - pi + δi+1pi+ <dig> for  <dig> <i <n,     

dpn/dt = λn-1pn- <dig> - δnpn.

this model describes the evolution of the size of a domain family that includes an indispensable  gene and is not allowed to go extinct. similarly, for model , the ergodic distribution is:





the ergodic distribution   is globally stable and is approached exponentially with respect to time from any initial state. the asymptotic of the ergodic distribution is completely defined by the asymptotic behavior of the function χ ≡ λi-1/δi. let us suppose that, for large i, the following expansion is valid:

χ ≡ λi-1/δi = is θ )     

then, the asymptotical behavior of the stationary distribution of model  is completely defined by three parameters: s, θ and γ . in particular, if the birth-and-death process is the 1st order balanced, i.e. if, by definition, s =  <dig> in , then, asymptotically, pi ~ θii-γ . if the process is 2nd order balanced, i.e. s =  <dig> and θ =  <dig>  then pi ~ i-γ.

the complete description of all possible asymptotics of the ergodic distributions of model  under condition  is given in mathematical appendix, theorem  <dig>  refer to the corresponding formula in the mathematical appendix ). it asserts that a large class of models, namely the second order balanced bdims, provide any given power asymptotic of the stationary frequency distributions of family sizes.

 <dig>  classification of bdims
linear bdim
the simplest model that shows the generalized pareto distribution is the linear bdim with

λi = λ, δi = δ for i >  <dig>  λ, δ, a and b are constants.     

the equilibrium distribution of domain family sizes is defined by:



so, if λ = δ , the resulting 2nd order balanced linear bdim has a power asymptotics with γ =  <dig> + b - a.

polynomial bdim
informally, polynomial bdims can be introduced as follows. under the linear bdim, the dependence of the birth and death rates on family size is very weak; although each gene "senses" the size of the family , this dependence cannot be interpreted as a specific form of interaction between family members. if such interactions are postulated, λi ~ pn and/or δi ~ qm, where pn, qm are polynomials on i of the n-th and m-th degrees. the ergodic distribution of the stochastic polynomial bdim of the form  and  is asymptotically the same as that of the originally described deterministic polynomial bdim  <cit> , see appendix ,   and proposition  <dig> for details. we show here that non-linear polynomial 2nd order balanced bdim predict evolution rates that are dramatically greater than those for the linear bdim.

as an example, let us consider the quadratic bdim in more detail. it takes into account the simplest, pairwise interaction between family members, which leads to λi ~ i <dig> and/or δi ~ i <dig>  i.e., one or both rates are polynomials on i of the second degree. if the polynomial degrees of the birth and death rates are different , the corresponding bdim is non-balanced, and equilibrium frequencies have no power asymptotics. thus, let

λi = λ , δi = δ,     

where λ, δ, rk, qk, k =  <dig>  are constants ; equivalently,

λi = λ , δi = δ .

then, r <dig> = a + a <dig>  q <dig> = b + b <dig>  and

χ = λi-1/δi = θ /i + o), where θ = λ/δ.

the quadratic bdim has equilibrium sizes of domain families 

pi ≈ c2p <dig> λ0/λθiiρ-2

where ρ = r <dig> - q <dig>  c <dig> = p <dig>  / , and



thus, if the quadratic bdim is 2nd order balanced, then pi ~ iρ- <dig>  note that the asymptotic behavior frequencies pi do not depend on free coefficients r <dig> and q <dig> in , but only on θ and r <dig> - q <dig>  although the constant c <dig> could depend on the free coefficients r <dig>  q <dig> 

rational bdim
rational models comprise a rather general class of bdims, for which the asymptotic behavior of the equilibrium frequencies and equilibrium sizes of domain families are fully tractable. the ergodic distribution of the stochastic rational bdim is asymptotically the same as that of the deterministic rational bdim  <cit> . in particular, if the model is 2nd order balanced, then pi ~ i-γ, .

the rational bdims can describe a substantially wider class of birth and death rates compared to polynomial models. in particular, birth rate can have a maximum at some specific value of family size and then decrease with further growth of the size, e.g., as shown in fig.  <dig>  this dependence of rates on family size can be described by the rational model with λi = λ/ <dig>  δi = δ/ <dig> 

logistic bdim
evidently, the number of size classes of protein families, n, should be finite, although intrinsic features that could determine the value of n so far have not been considered . under the bdims described above, birth rate grows monotonically as the family size increases from  <dig> to n and then abruptly drops to  <dig> . however, this behavior is an arbitrary simplification of the model and hardly can reflect the actual process of genome evolution.

in population dynamics models, the finiteness of a population size typically results from the "saturation type" of growth: the growth rate tends to  <dig> as the population size tends to the maximal possible value . it seems likely that, during genome evolution, gene duplication  rate also tends to  <dig> as duplications leading to increase in gene number become deleterious when the size of some paralogous families becomes prohibitively large. the simplest formalism, which yields this type of population growth, is the logistic form of the birth rate. logistic-like stochastic models have been investigated in various applications , which considered a birth-and-death process with the rates

λ  = c <dig>  δ = c3i, ck >  <dig>  k =  <dig> , <dig>  c <dig> >n.

this model produces log-normal and log-series distributions; with the appropriate values of parameters, power low distributions of frequencies also appear, but only for intermediate values of i, namely,  <dig> <<i <<n and n >>  <dig> 

non-linear transformation of bdim
we have shown previously  <cit>  that the following modification of any form of bdim:

λ*i = λig, δ*i = δig     

where g, i =  <dig> ...n, is a positive function, g =  <dig>  results in a bdim with the same ergodic distribution of the family sizes as the original one. in particular, modifications of a linear bdim with g = d- <dig> or g = d-1) define, respectively, wide classes of rational or logistic bdims with the same stationary distribution as the original linear bdim, but with manifestly different dynamic properties.

 <dig>  probability of formation of a family of the given size before extinction and mean and variance of extinction time
in is known  <cit>  that the probability for the birth-and-death process to reach state n before reaching state  <dig> from an initial state i>  <dig> is given by formula . in terms of bdim , this means that the probability of formation of a family of size n starting from a family of size i before getting to extinction is given by .

the random birth-and-death process  certainly visits state  <dig> in the course of time; this means that any domain family will eventually get extinct . below we compute the mean time to extinction of a family of the given size for different versions of bdim; the mean time to extinction of the largest family in the given genome is of particular interest.

let us denote s=inf{t:x = 0|x=n} the time to the first passage of state  <dig> from the initial state n; s is a random variable for each n. the mean time to extinction of the family of initial size n, e), is given by the general formula a. <dig> .

linear bdim
we have shown previously that, for the linear 2nd order balanced bdim, the probability that a singleton expands to a family of size n before dying, p has the power asymptotics for large n . the values of probabilities p for different species are shown in table 1; these probabilities are no greater than ~10- <dig> - 10- <dig>  the mean time to extinction, e), can be calculated using the relation e) = 1/λen, where en, the mean time to extinction expressed in the 1/λ time units, is given by formula a. <dig>  .

for the linear bdim  and for the largest family of size n in each genome, the table shows the probability of formation p, mean number of events before extinction of the largest family en; mean number of events before formation of the largest family from a singleton, fn; mean times of formation mn and extinction en ; the value of coefficient cdu = rdu/λ; mean times of formation tn in ga  under rdu =  <dig> × 10- <dig>  the model parameters were genome-specific as determined previously  <cit> . and were the same for all model degrees according to . species abbreviations: sce, saccharomyces cerevisiae, dme, drosophila melanogaster, cel, caenorhabditis elegans, ath, arabidopsis thaliana, hsa, homo sapiens, tma, thermotoga maritima, mth, methanothermobacter thermoautotrophicum, sso, sulfolobus solfataricus, bsu, bacillus subtilis, eco, escherichia coli.

the variance of extinction time var) for the linear 2nd order balanced bdim is var) = 1/λ2wn, where wn can be calculated using the formula . the plot of the coefficient of variation sn = n)1/2/en versus n for different species is shown in fig.  <dig> . clearly, the extinction time can vary within an extremely broad range of values. 

non-linear polynomial and rational bdim
the stochastic behavior of the system and its characteristics also can be investigated within the broader framework of rational bdims. we will examine models represented as transformed linear bdim , with

λi = λd- <dig>  δi = λid- <dig>      

where d ≥  <dig> is the model degree. let us recall that theorem  <dig>  shows that the highest degrees and the corresponding coefficients of the birth and death rates at id must be equal to provide for the power asymptotics of the stationary distribution, p ~ i-γ. the power γ of this distribution is completely determined by the degree d and the coefficients at id- <dig>  thus, the model ,  is representative of all rational bdims of the degree d with a given power asymptotic  of the stationary distribution. besides, according to proposition  <dig>  this distribution for model  is exactly the same as for the corresponding linear model with λi = λ , δi = λ , which was studied in detail in  <cit> .

we applied formula  



with g = d- <dig>  to calculate the probability of formation of a family of the given size from a singleton before getting to extinction for the bdim of degree d, p. for example, the probabilities p and p for the quadratic and cubic bdims, respectively, are given by this formula with g = i +  <dig> and g =  <dig>  respectively. figures  <dig> and  <dig> show the dependence of the probabilities p and p on the family size n for different species. the dependence of the probability p of the formation of the largest family on the model degree is shown in fig.  <dig> 

the mean time to extinction for the rational bdim ,  with a fixed d is calculated using the formula   where 



here e*n is the mean time to extinction in the 1/λ time units. figures  <dig> and  <dig> show the dependence of en and en on n for the quadratic and cubic bdims, respectively. fig.  <dig> shows the mean times of extinction of the largest family, en, for different species, depending on the model degree d. some numerical values of the mean time to extinction for quadratic and cubic bdims and different species are given in tables  <dig> and  <dig>  the variance of the extinction time of a family of size n, var)= 1/λ2w, d =  <dig>   <dig> for the quadratic and cubic bdims, and the coefficient of variation sn = n)1/2/en are calculated using the formulas . the results are shown in figs.  <dig> and  <dig>  some numerical values of the coefficient of variation of the extinction time for different species are given in table  <dig> 

for the quadratic bdim  and for the largest family of size n in each genome, the table shows the probability of formation p, mean number of events before extinction of the largest family en; mean number of events before formation of the largest family from a singleton,fn; mean times of formation mn and extinction en ; the value of coefficient cdu = rduvλ; mean times of formation tn in ga  under rdu =  <dig> × 10- <dig>  the model parameters were the same as for the linear model according to . species abbreviations: sce, saccharomyces cerevisiae, dme, drosophila melanogaster, cel, caenorhabditis elegans, ath, arabidopsis thaliana, hsa, homo sapiens, tma, thermotoga maritima, mth, methanothermobacter thermoautotrophicum, sso, sulfolobus solfataricus, bsu, bacillus subtilis, eco, escherichia coli.

for the cubic bdim  and for the largest family of size n in each genome, the table shows the probability of formation p, mean number of events before extinction of the largest family en; mean number of events before formation of the largest family from a singleton, fn; mean times of formation mn and extinction en ; the value of coefficient cdu = rduvλ; mean times of formation tn in ga  under rdu =  <dig> × 10- <dig>  the model parameters were the same as for the linear model according to . species abbreviations: sce, saccharomyces cerevisiae, dme, drosophila melanogaster, cel, caenorhabditis elegans, ath, arabidopsis thaliana, hsa, homo sapiens, tma, thermotoga maritima, mth, methanothermobacter thermoautotrophicum, sso, sulfolobus solfataricus, bsu, bacillus subtilis, eco, escherichia coli.

the table shows coefficient of variation sn of extinction time for the largest family; coefficient of variation σn of formation time for the largest family; d =  <dig> , <dig> for the linear, quadratic and cubic bdim, respectively. species abbreviations: dme, drosophila melanogaster, cel, caenorhabditis elegans, ath, arabidopsis thaliana, hsa, homo sapiens.

logistic bdim
let us consider the logistic modification of the rational bdim; specifically, we will examine models with the birth and death rates of the form

λi = λd-1), δi = δ id-1/).     

we will refer to the parameter c as saturation boundary. the shape of λi essentially depends on the value of c .

the logistic model ,  is a transformation  of the linear bdim using the function:

g = d- <dig>  c = const ≥  <dig>      

the stationary distribution of family size frequencies for the logistic model ,  is exactly the same as that for corresponding linear bdim but the stochastic properties are different and close to the rational models, and essentially depend on the boundary c. with a large c, the model is very close to the corresponding rational model with λi = λd- <dig>  δi = δ id- <dig>  but with small c, we can observe some new effects when the family size approaches n.

the probability of formation of a family of a given size from a singleton before getting to extinction for the logistic bdim is calculated using the general formula  where the function g is given by . the dependence of this probability on the model degree d under a fixed large value of the boundary c~n is similar to that for the corresponding rational models but differs under a small c; fig.  <dig> shows this dependence for c =  <dig> 

the mean times of extinction for the logistic bdims are calculated using formula . fig.  <dig> shows the mean times of extinction of the largest family, en, depending on the model degree d for different values of saturation boundary c. fig.  <dig> shows the dependence of en on the saturation boundary c for different values of d.

 <dig>  mean and variance of formation time for a family of the given size
let us denote t = inf{t: x = n|x = j} the time to the first passage of state n from the initial state j; t is a random variable for each j, n. the mean time to the first passage for bdim , m = e), can be calculated using the formula m = m <dig> + m <dig>  here the term m <dig> is the mean time elapsed before the system leaves the  <dig> state for the last time, and the term m <dig> is the mean time of formation of a family of size n from a singleton after its last "resurrection"  for details). below we examine only the mean family formation time from an essential singleton ).

linear bdim
previously, we determined the mean time of formation of a family of size n from a singleton for different species  <cit> . for the linear bdim, the value of the mean formation time from an essential singleton is given by formula m = 1/λ mn, where mn, the mean formation time in 1/λ units is calculated using the formula 



the transition from the 1/λ time units to years is considered in s. <dig> of the mathematical appendix [see additional file 1
]. the mean formation time e) in years is calculated using the formula  and the current empirical estimates of the gene duplication rate  <cit> . plots of e) for different species are shown in fig.  <dig> 

once we computed the mean time of formation of a family of size n for different species, the question arises how accurately is the time t of the first random passage through the threshold n predicted by the mean value. to address this problem, we estimated the variance of the time of family formation, var) using the general formulas  for model  and  for model , respectively. for the linear bdim, the variance of the formation time for a family of size n from an essential singleton, vn, is given by the formula . a more important and informative characteristic, which is independent on the model parameter λ, is the coefficient of variation, which is equal to . the coefficient of variation of the formation time of a family of size n from a singleton, σn = n)1/2/m for the bdim of degree d is the most relevant value. the plots of σn versus n for the linear model and for different species are shown in fig.  <dig> 

the coefficients of variation were very large for all species . to summarize the results obtained for the stochastic characteristics of the linear bdim, we found that: i) under this model, the mean time to extinction of the largest families in most genomes was much shorter than the mean time of formation of these families, and ii) using the current estimates of duplication rates in eukaryotic genomes  to express the mean family formation times in real time units instead of the dimensionless 1/λ units, we obtain m ~  <dig> -  <dig> yrs, a completely unrealistic time estimate. the mean family formation times given by the linear bdim would become realistic only if the recent analyses underestimated the gene duplication rate by a factor of ~ <dig>  which does not seem plausible. thus, the linear bdim cannot provide an adequate description of genome evolution, at least when only the mean time of family formation is considered. the variance of the family formation time is extremely large , and, accordingly, large deviations from the mean time, more to two orders of magnitude, are possible. however, even taking this into account, the family formation times predicted by the linear bdim are far longer than the time allotted for life's evolution of earth. in the next section, we consider non-linear, higher order models that have the potential to yield shorter mean times of family formation.

polynomial bdims
the mean time of formation of families from an essential singleton  depending on the family size n for the polynomial bdims is e) = 1/λ m*n where m*n, the mean time of formation in 1/λ units can be calculated using the formulas 



fig.  <dig> shows the dependence of the mean time of family formation on the family size for the quadratic bdim in years, calculated using the formula . the values of mean times of formation for this bdim are given in table  <dig> 

the variance of formation time of a family of the size n can be calculated using the formula , with g=j+ <dig> for the quadratic bdim and g =  <dig> for the cubic bdim, respectively. the dependence of the coefficient of variation σn = )1/2/m on the family size for the quadratic bdim is shown in fig.  <dig>  and some numerical data are given in table  <dig> 

although the variance of family formation times for the quadratic bdim is approximately  <dig> orders of magnitude less than that for the linear bdim, the values of the coefficient of variation for quadratic bdim are about  <dig> – <dig>  times greater than those for the linear bdim. thus, the actual formation time for the largest family could differ from the mean value by several orders of magnitude with a high probability. figures  <dig> and  <dig> show the dependence of the mean and the coefficients of variation of family formation time on family size for the cubic bdim.

we have shown previously that the cubic model shows extremely high evolution rate comparatively with the linear and even quadratic models under the same value of the parameter λ  <cit> . on the contrary, the mean formation times in years for the quadratic and cubic models are of the same order . the polynomial models bring the mean time required for the formation of families of the observed size closer to realistic values but these times still remain far too long. specifically, with the empirical estimates of the duplication rates used above for the linear bdim, the quadratic model gives the mean family formation times ~ <dig> yrs. this value is close to the minimum possible time of family formation that can be calculated using the duplication rate estimates of lynch and conery  <cit>  and non-linear rational bdims.

non-linear rational bdims
let us investigate the dependence of the dynamics of the mean time of family formation on the model degree and the family size. the mean time of formation of a family of size n from a singleton under a fixed model degree d, m, for the rational bdim ,, is calculated using the formula . a comparison of the mean time of formation and extinction for rational bdims reveals an interesting property of non-linear bdims: for any given family size n, there exists such a model degree that the times of family formation and extinction are equal . accordingly, at higher model degrees, the mean time of formation becomes shorter than the mean time to extinction. the model degree that corresponds to the point of intersection in fig.  <dig> obviously depends on the size of the considered family. tables  <dig> and  <dig> show that the mean time of formation is about  <dig> times more than the mean time to extinction for the largest families of different species for the quadratic bdim and only about  <dig> times more for the cubic model.

as shown previously, increasing the degree  d results in indefinite decrease of the family formation time expressed in 1/λ time units . however, we have also shown that this effect is offset by the rapid increase of the average duplication rate in the model. assuming the gene duplication rate of ~2*10- <dig> year- <dig>  <cit> , the evolution time in years, calculated according to the formula , does not decrease indefinitely, but has a minimum at the model degree between  <dig> and  <dig> . even the minimum mean time of the largest family formation achievable with the rational bdims is on the order of  <dig> years , which is incompatible with the age of life on earth  <cit> . thus, a rational bdim of any degree cannot provide an adequate description of genome evolution, at least when only the mean time of family formation is considered. accordingly, for assessing the feasibility of the formation of the largest families under a given model, the variance of the formation time should be investigated.

for each genome, d is the value of the model degree d, which results in the minimum of the mean time of formation of the largest family, tn = r/rdu  are shown. species abbreviations: sce, saccharomyces cerevisiae, dme, drosophila melanogaster, cel, caenorhabditis elegans, ath, arabidopsis thaliana, hsa, homo sapiens, tma, thermotoga maritima, mth, methanothermobacter thermoautotrophicum, sso, sulfolobus solfataricus, bsu, bacillus subtilis, eco, escherichia coli.

generally, the variance of the formation time of the family of the given size is given by the formulas  and . although the variance of formation times for the quadratic and, especially, for the cubic bdim is several orders of magnitude less than that for the linear bdim, the coefficients of variation for both formation and extinction time increase with the model degree . these coefficients are so large that the actual formation time of the largest family could differ from its mean value by several orders of magnitude with a high probability.

logistic bdim
the mean time of formation  of a family of size n from an essential singleton for the logistic bdim ,  under fixed d is calculated using formula . fig.  <dig> shows the dependence of mean times of family formation, m, on the family size n for different model degrees d under the fixed saturation boundary c =  <dig>  and fig.  <dig> shows the dependence of mean times of family formation on the boundary value . similarly to the rational bdim, increasing the degree  of the logistic model results in faster family evolution under a fixed value of the parameter λ. however, when this inner model parameter is excluded and the mean time of family formation is expressed in years according to formula , then we again face a restriction that does not allow indefinite shortening of the family formation time, tn. specifically, tn for the logistic model with a fixed n has a minimum over d. we identified the model degrees yielding the minimum mean time of formation of the largest family for the logistic-rational bdim. fig.  <dig> and table  <dig> show the dependence of tn on d for the logistic model with fixed saturation boundary.

model parameters are for d. melanogaster.

model parameters are for d. melanogaster.

for each genome, d is the value of model degree d, which results in the minimum of the mean time of formation of the largest family, tn = r/rdu , is indicated. species abbreviations: dme, drosophila melanogaster, cel, caenorhabditis elegans, ath, arabidopsis thaliana, hsa, homo sapiens.

thus, as in the case of rational bdims, increase of the degree of logistic bdims under a fixed value of average duplication rate rdu cannot yield mean family formation times <  <dig> years. furthermore, the "saturation effect" seen in the logistic models increases the mean time of family formation compared to the corresponding rational models .

coefficient of variation Σn of the number of events before formation of the largest family; d =  <dig> for the linear bdim, d =  <dig> for the quadratic bdim, d =  <dig> for the cubic bdim. species abbreviations: dme, drosophila melanogaster, cel, caenorhabditis elegans, ath, arabidopsis thaliana, hsa, homo sapiens.

 <dig>  the mean number of elementary events before family extinction and formation
comparing the mean family formation and extinction times predicted by bdims with the actual evolutionary timescale allow us to choose the most appropriate version from the examined class of models. the number of elementary evolutionary events namely, duplication and deletion of domains, predicted by these models is of potential interest in itself as an approximation of an important characteristic of genome evolution.

to calculate the mean number of elementary events during evolution of gene families, we employed the so-called embedding chains {y} instead of the original bdim. the embedding chain {yn} for a particular bdim is a random walk with discrete time on the same set of states and transition probabilities pi,i+ <dig> = βi = λi/, pi,i- <dig> = μi = δi/ and pij =  <dig> for all other cases .

the transition from the state i to the state i+ <dig>  corresponds to the duplication  of a domain in a family of size i. the only difference between the original birth-and-death process and the embedding chain is that the sojourn time for the embedding chain is equal to  <dig> for any state i instead of 1/. the ratio βi/μi  characterizes the trend of family evolution from the state i, i.e., is the family more likely to grow or to shrink; for a symmetric random walk, βi/μi =  <dig> for all i. the dependence of the ratio βi/μi on i for different rational and logistic embedded chains is shown in figures  <dig> and  <dig>  for the rational models, βi/μi ≈  <dig> for large i; for the logistic models, βi/μi ≈  <dig> for  <dig> <<i <<n . thus, the behavior of the embedding chain is similar to the behavior of the symmetric random walk in the corresponding subsets of states. informally, the plots in figures  <dig> and  <dig> indicate that small families may preferentially grow  or shrink  whereas the evolution of large families tends to a symmetrical random walk.

the mean number of elementary events before the formation of a family of the given size, fn, is computed using formulas -. the plots in figures  <dig> and  <dig> show the dependence of fn on the family size for different species for the linear and quadratic models, respectively. the mean number of elementary events before the extinction of a family of the given size, en, is computed using formulas - and figures  <dig> and  <dig> show the corresponding dependences for family extinction. some numerical data for the mean number of elementary events for polynomial bdims are shown in tables  <dig> , <dig> and, for coefficients of variation, in table  <dig>  given that all the analyzed bdims are balanced, i.e., the birth and death rates are asymptotically equal, it was not unexpected that the mean number of events required for the formation of a large family  was orders of magnitude greater than the size of the family. this suggests a highly dynamic picture of genome evolution whereby numerous duplications counterbalanced by gene losses are typically involved in the evolution of large families. however, the number of events required for the formation of a family of the given size quickly drops with the increase of a model degree , which may be construed as reflection of positive selection leading to amplification of family members.

 <dig>  monte carlo simulation of evolution of gene family ensembles under bdims of different degrees
as noticed previously  <cit> , it is the minimum rather than the mean evolution time that is important for modeling the dynamics of evolution of genomes consisting of many gene families. due to the large variance of the family formation time estimates , this value is likely to be much less than the mean. although an analytical solution to this problem is hard to obtain, it can be examined in detail by monte carlo simulation analysis. as described previously  <cit> , we employed for this analysis model parameters estimated for the human proteome. the simulated evolution started from  <dig> families of size one  and continued until the largest family reached  <dig> members ; the simulation was run from  <dig> to several hundred times depending on the model degree . in the course of the simulation, the number of families fluctuated due to stochastic births, deaths, and innovations of genes but, generally, tended toward the equilibrium number of ~ <dig>  which is close to the empirically determined number of families in the human genome and is pre-determined by the choice of model parameters . the time scale was adjusted such that rdu =  <dig> × 10- <dig> duplications/gene/year  <cit> . a series of simulations was performed for non-linear rational bdims with different degrees d.

as shown in fig.  <dig>  the time at which the family size of  <dig> members is reached for the first time depends on d in a similar fashion as the mean time for a single family, i.e., there is clear minimum at a particular value of d. at the optimal value of d ≈  <dig> , the model reaches this family size in  <dig>  ±  <dig>  ga, which is comparable to the time of evolution of eukaryotes. compared to the minimal evolution time predicted by bdims of different degrees for a single family, the genome-size ensemble of gene families reached the threshold size much faster , and the optimum values of d was lower by ~ <dig>  . the much faster formation of large families from an ensemble of singletons was predictable due to the large variation coefficient of the family formation and extinction times, but the simulation was necessary in the absence of knowledge of the exact distribution of these values.

 <dig>  general discussion
here and in the previous publications  <cit> , we describe a general class of models, which are based on the classical concept of a birth-and-death process and seem to naturally apply to the genome evolution process. similar, although not identical and apparently less general, modeling approaches have been considered by others  <cit> . even earlier, evolution of gene families has been modeled within the distinct mathematical framework of multiplicative processes  <cit> . the utility of birth-and-death type models in evolutionary genomics in itself is not a trivial matter but rather stems from fundamental features of genome evolution. as captured in the title of ohno's famous book  <cit> , although foreseen even in the early days of genetics  <cit> , gene duplication probably is the principal mechanism of genome evolution. of course, genomes cannot grow ad infinitum and, through most of the evolutionary history, the number of genes within a given phylogenetic lineage probably remains roughly constant. hence duplication is intrinsically coupled to gene loss. the results of comparative genomics further show that many genes in each lineage cannot be obviously linked to other genes through duplication. without necessarily specifying the biological mechanisms , it is reasonable to view these unique genes as resulting from innovation. for genomes to maintain equilibrium, the combined rates of duplication and innovation over the entire ensemble of gene families should equal the rate of gene loss, at least when averaged over long time spans. the observed distribution of family sizes, which asymptotically tends to a power law, dictates a much more specific connection between the gene birth and death rates, namely, the second order balance. it should be noted that this form of balance does not amount to particularly fine tuning of the gene birth and death rates. the only requirement is that these rates tend to the same value when the family size tends to infinity according to the condition . in contrast, for small families, the rates may substantially differ, without significantly changing the shape of equilibrium distribution.

the incentive to examine bdims in detail stems from at least two fundamental questions: i) are the above elementary evolutionary mechanisms sufficient to account for the empirically observed characteristics of genomes, ii) what is the contribution of natural selection to the general, quantifiable features of genomes, such as the size distribution of gene families. the analysis of bdims starts to provide some answers, albeit preliminary ones. the critical observation made in the course of bdim analysis was that different versions of these models could be readily distinguished on the basis of goodness of fit to the empirical data. this being the case, we found that the simplest possible model, in which all paralogs are considered independent, is incompatible with the data. thus, turning to the first of the above questions, we had to conclude that, in addition to the three elementary processes, "something else" was required to model genome evolution. this "something" is the dependence or "interaction" between gene family members which results in self-accelerating family growth. in order to account for the observed stationary distribution of family sizes, it is sufficient to introduce a very weak dependence as embodied in the linear bdim. however, when we switched from the deterministic to the stochastic version of bdims, which provide for the possibility of analysis of the dynamics of the systems evolution, we found that evolution under the linear bdim was much too slow to account for the emergence of the large families of paralogs found in all genomes during the time of life's evolution. only higher order bdims, with degrees between  <dig> and  <dig>  i.e., with "strong interactions" between family members were found to provide for sufficiently fast evolution to be compatible with the real biological timescale.

obviously, these findings beg the question: what is the nature of the mysterious "interactions" between paralogs? although, on some occasions, paralogous protein do form physical complexes or interact functionally, the situation when such interaction does not exist is much more common. therefore, the "interactions" in our models should not be perceived literally. this brings us to the second of the above major problems. bdims do not explicitly include the notion of selection. however, the simplest interpretation of the virtual interactions implied by the higher order bdims seems to be that these reflect differential tendencies of genes to form paralogous families of different sizes depending on the intensity of selection. recent studies have shown that evolutionary fixation of gene duplications is linked to the evolutionary rates of genes. specifically, duplications of slowly evolving genes, i.e., those that are subject to stronger purifying selection, are fixed more often  <cit> . the strong dependence of per gene duplication rates on family size in higher order bdims could be an abstraction of this trend. should that be the case, we are justified to conclude that very weak selection would suffice to explain the stationary distribution of family sizes, but much stronger selective pressure is needed to account for the dynamics of genome evolution. however, the interpretation of bdim degree as a manifestation of selection is, at this point, no more than a guess. one of the further developments of genome evolution modeling involves introducing selection explicitly and determining whether the resulting more sophisticated models will be equivalent to the higher order bdims explored here.

CONCLUSIONS
in this work, we extended our analysis of stochastic birth, death and innovation models  of gene family evolution and showed that:

• the behavior of logistic bdims models, in which birth/death rates are limited for the largest families, is essentially the same as that of previously investigated bdims that included no such limitation

• the mean time required for the growth of large families is limited by the overall number of duplications and does not increase indefinitely with the increase of the model degree but instead passes through a minimum; even under the best-case scenario, which corresponds to a non-linear rational bdim with d ≈  <dig> , the mean time of the largest family formation is orders of magnitude greater than any realistic estimates based on the timescale of life's evolution;

• using the embedding chains technique, we estimated the expected number of elementary evolutionary events  preceding the formation of gene families of the observed size; the mean number of events exceeds the family size by orders of magnitude, suggesting a highly dynamic process of genome evolution;

• the variance of the time required for the formation of the largest families is large , which means that some families might grow much faster than the mean rate; thus, the minimal time required for family formation is more relevant for a realistic representation of genome evolution than the mean time;

• monte carlo simulations of family growth from an ensemble of simultaneously evolving singletons show that the time elapsed before the formation of the largest family was much shorter than the estimated mean time and approached realistic values .

contributions of individual authors
gpk developed most of the mathematical formalism and wrote the draft of the mathematical part of the manuscript; yiw performed the imitation modeling and wrote the draft of the corresponding part of the manuscript; fsb derived some of the mathematical statements; evk contributed to the inception of the work and the formulation of the models, gave the biological interpretation of the results, wrote the background and discussion sections and extensively edited the entire manuscript.

supplementary material
additional file 1
this additional file includes proofs of some of the mathematical statements contained in the main text as well as accessory mathematical formulations.

click here for file

 acknowledgements
the authors thank b.shraiman and other members of the computational biology program at the kavli institute for theoretical physics, university of california, santa barbara, for helpful discussions. the work of f. berezovskaya was supported by nsf grant # <dig> 
