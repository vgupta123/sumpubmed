BACKGROUND
the choice of interface becomes a critical factor in many large community databases such as genbank, ucsc genome browser, and flybase, as well as many smaller individual databases, used by researchers across the globe. applications in life sciences domain are often designed using specific analysis or query need in mind. these applications widely use graphical interface technologies for access to the underlying database and to capture query semantics. these query driven graphical user interfaces do not allow free form and arbitrary querying, thereby limiting the use of the underlying database content. since these interfaces must necessarily be built for each query need, cost acts as a significant prohibitive factor. as a result of adopting pre-fabricated web interfaces for access, the wealth of these repositories remain poorly used. to compensate for the perceived lack of use and to serve users who desire to exploit the content in ways other than originally anticipated, database contents are often made available for copying and differential use. this materialized view  <cit>  based alternative has been proven to be expensive and complicated, principally because indiscriminate copying introduces version maintenance problem, making it difficult to correct obsolete information in the copied version when the main copy is corrected. end users in general, and biologists in particular, prefer to use graphical interfaces to access databases mainly because query language based interfaces demand considerable familiarity with the underlying database schema and expertise in framing semantically meaningful queries. while sql or xquery type query languages allow ad hoc and arbitrary querying, and potentially eliminate the bottleneck imposed by pre-fabricated graphical interfaces, biologists are resistant to adopting such an archaic interface. to exacerbate this situation, databases are slowly but certainly adopting more complex xml type representations for the purpose of information interchange and data integration, making it even harder for biologists to accept textual query interfaces because xquery type languages are considerably more complex than sql.

regardless of the query platform used, in works such as biobike  <cit> , it was argued that for several decades biologists have voted overwhelmingly not to embrace computer programming as a basic tool through which to look at their world. biobike tries to simulate a natural language like interface using graphical interactions as a means to support access to database content. the idea is based on the premise that the limitations imposed by graphical interfaces and the complexity inherent in query languages such as sql and xquery can be bypassed if access to information is facilitated using natural language queries. natural language processing  based query answering systems enjoy the benefit of user's natural ability to frame queries at a conceptual level she is comfortable with. the real issue is how abstract such queries can be so that the user need not worry about the technicality involved in framing the query for the database query engine to understand and execute the intended query. the higher the abstraction level, the harder usually it is to parse and map the query on the underlying database schema. such a high level interface still remains illusive mostly because of the representation hurdles, highly interpretive nature of life sciences data , translation from natural language to database queries, and the inherent difficulty in processing nlp queries. a practical approach, we argue, is providing a flat universal relational view of data so that users can comprehend and query the information repositories at their disposal. once chosen, the question remains, how do we facilitate comprehension of a natural language query in a given context, device a strategy to compute its response, and implement the strategy as a traditional query over structured relations stored in local or remote information repositories.

our goal in this paper is to develop a semantic "plug-in" in the form of a common knowledge ontology to describe the intended semantics of the underlying database, still at a conceptual level. we use this common knowledge ontology to bridge the semantic gap between the database schema and the nlp parsing engine so that meaningful connections between the natural language queries and database can be established. we present a method to map conceptual queries to database schema and show that a natural language parser now has a better chance to generate meaningful sql queries, especially for short natural language queries. we also show that the use of the plug-in makes it possible for the parsing systems to be unaware of low level schema details.

related research
while systems such as toorjah  <cit>  and coin  <cit>  attempt to improve the usability repertoire of databases, they still do not support unrestricted use as they remain committed to pre-fabricated query interfaces. in this paper, we argue that universal and ad hoc access to community biological databases can be facilitated through natural language interfaces to counter interface constraints. we envision database independent natural language interfaces which will intelligently map english sentences to sql like structured queries to return a response. in such an environment, we also expect the system to tolerate discrepancies in users' knowledge of the database scheme and to allow flexibility by not demanding strict schema adherence in user queries.

in natural language processing community, stanford parser  <cit>  and minipar  <cit>  are two leading tools that perform fairly well in recognizing acceptable english sentences. the success of nlp systems such as these are encouraging database interface development in english to facilitate access to databases using text querying  <cit>  with limited scope. while nlp interfaces for traditional databases has been extensively studied in the literature , several recent proposals toward mapping nl queries to sql  <cit>  are of significant interest. however, most of these interfaces work well for a limited class of queries, and for a specific database schema. in other words, changes in application objectives or underlying databases are extremely difficult to accommodate in these approaches. an important limitation is that these systems are unable to incorporate arbitrary rules that drive computational tools to make inferences, a feature that biologists need. our contention is that although there have been many attempts in other domains, natural language interfaces for biological databases remain an emerging area of research. the few that are prominent , are extremely rigid and difficult to replicate.

an illustrative example
consider the biological database shown in figure  <dig> consisting of relationships among genes and organisms, and a set of computational tools to analyze its contents. the database has the following tables with the primary keys underlined - gene , protein , equivalentgenes , and geneproteinencoding capturing all proteins encoded by a gene.

the database may also include computational tools such as david  <cit>  and genecards  <cit>  for id mapping, and blast  <cit>  for sequence homology analysis. these tools are used to analyze the contents in more sophisticated ways using generalized knowledge such as the ones below.

 <dig>  function of gene a is equivalent to function of gene b if a and b are equivalent.

 <dig>  two object ids are equivalent if they are aliases, orthologs, or homologs.

 <dig>  two sequences are homologs if blast returns true .

 <dig>  two ids are homologs if their corresponding sequences are so.

 <dig>  two ids are equivalent if david or genecards returns one for the other.

 <dig>  two ids a and b are equivalent if a gene  encodes a protein .

these rules can be used to derive the function of gene loc <dig> in chimpanzees  even though there is no record of this gene in the database. this is because loc <dig> is an ortholog of the gene uqcc in humans, and either genecards will successfully establish the correspondence , or blast will . users traditionally write queries and apply similar functions to draw conclusions. the question that we are trying to address is: is it possible for a natural language interface to hide the complex computational view of the database and respond to queries from a more conceptual level for example, could we develop a system to answer natural language query such as  "what is the function of gene loc <dig> " or  "which gene in chimpanzees is responsible for growth control " our focus in this paper is to propose a practical method to map such queries to semantically equivalent database specific sql queries.

we also envision that a generalization of the above mechanism will significantly enhance the query answering capability of a database when augmented with appropriate deductive capabilities and machineries to compose scripts for executing computational pipelines. for example, the query  above cannot be directly computed from the example database in figure  <dig>  to compute this query, we must first find out the complete set of chimpanzee genes and apply the six rules above to infer possible responses. if, in addition to the above six rules, we also know that the homologene database  <cit>  can be queried to get a list of organism genes, we can then construct a pipeline to compute a possible response and find that chimpanzee gene loc <dig> is a growth control gene. alternately, we can find the growth control genes of all organisms, and find out from genecards if there is a chimpanzee ortholog for any of these genes. in the remainder of this paper, we discuss a general approach toward constructing a computational strategy to respond to a natural language query. our focus is mainly on strategy construction and query translation by exploiting the strengths of minipar  <cit> , or other similar tools for parsing, and dependency assignments of query sentences. accordingly, we discuss the following components needed for the construction of our interpreter.

 <dig>  a model for an ontology with deduction rules is proposed. such an ontology helps bridge the semantic gap between the decoupled user view and the database view. earlier research have already exploited similar adoption to facilitate natural language interfacing  <cit> .

 <dig>  the concept of a schema graph to merge the ontology and the database scheme as an interface between the user view of the database and the database instance. similar tools, e.g., structured object model  <cit> , for bridging user view and the database have been previously investigated and exploited.

 <dig>  we adopt a deductive query processing model to support intensional query processing. but we do so using sql since the vast majority of biological databases use a relational platform. we, however, derive the computational strategy intensionally entailed by the query using deductive rules in the ontology. a similar approach, though in significantly limited form, has been exploited in biobike  <cit> .

 <dig>  we support querying online resources to access tools and databases needed to process user queries and modeled as functions in the ontology. we exploit the notions of remote user defined functions  <cit>  and biological workflows  <cit>  we proposed earlier to facilitate such integration in a user transparent way.

in the next few sections, our plan is to explain these components using the query "list all growth control genes in dogs that function similar to human genes ." for simplicity, we first consider the query without the parenthesized part, and then consider the full query to see how more complex queries can be constructed. we discuss the construction of structured queries in the context of the database in figure  <dig> 

methods
structure of a natural language interpretable database
the overall approach is to view the base database as a collection of entity and relationship sets in the sense of er model  <cit> , and preserve this conceptual view across different levels of abstractions we use to facilitate mapping of natural language queries to sql queries. accordingly, the base database Δ is a set of 3rd normal form classical relations r over schemes r with attributes a <dig>  . . ., an with corresponding domains d <dig>  . . ., dn. the database Δ in figure  <dig> contains four such relations wherein the primary key of each relation is underlined. although not readily apparent, the relations equivalentgenes and geneproteinencoding are relationship sets in the sense of er model while the remaining two are entity sets. for this fact to be available to the natural language interpreter and to exploit this structural information toward query construction, we complement the database with the following machineries.

common knowledge ontology
an ontology o  in our system is a set of basic concepts  c, a set of base relationships  r among the concepts, a set of derived relationships as inference rules  i involving ontological concepts in  c, and a type hierarchy  t involving the concepts in  c. inference rules thus define more concepts in the form of relationships involving the concepts. in figure  <dig>  we show such an ontology for our database Δ. in this figure, genes, functions and organisms are concepts, and so are molecular functions and plant. partof and has are relationships. in this system, concepts are distinct from instances or objects, and instances are not part of the ontology although we show a few instances  for expository purposes, e.g., human is an instance of a concept. for every concept and relationship in the ontology, we expect to find a representation of each as an entity or relationship set, or as their attribute in the underlying database. the converse need not be true, i.e., we may have attributes and relations in the database that are not represented in the ontology.

the knowledge similar to the six rules embedded in the database Δ can be represented in terms of the concepts in the ontology  o as the following set of rules. in this ontology language, all predicates are either unary, or binary. the object  of a concept is represented in the form of concept where concept is the concept name, and x is either a variable or a concrete object  that uniquely identifies an object in the database. similarly, a relationship between two concepts is represented as a binary predicate of the form relationship as all relationships in our ontology are binary in nature.

 <dig>  function ← alias, has.

 <dig>  alias ← homolog.

alias ← ortholog.

alias ← gene, encode.

note that the concepts homolog and ortholog in the rules above are not represented in figure  <dig>  yet they are part of this vocabulary. concepts not part of the ontology description are expected to be computed or represented in the database as properties of entities or relationships. all unary undefined concepts are considered entity properties while binary concepts are considered relationship properties. finally, observe that not all six rules are captured in the ontology as some of them are more database and operation specific. our goal is to cover this gap using a reduction function, defined next.

ontology augmented schema graph
the ontological characterization of a database is at the highest level of conceptual relationship among the database objects. it is defined independent of the database schema and structure so that it reflects a commonsense and general view of the information content. this view is expected to be close to the natural language queries we anticipate. to bridge this high level view with the underlying database, we create a schema graph that merges the ontology with the database scheme to capture the semantic relationships the database objects share through their attributes to facilitate natural language query to sql translation. before presenting the process of conversion from ontology to schema graph, we present the idea on intuitive grounds. given the database scheme ∑ = ⋃r∈Δr, the schema graph for the database Δ in figure  <dig> with respect to the ontology  o in figure  <dig> is shown in figure  <dig> 

in the schema graph,  a rectangle represents the concept in the ontology,  a solid ellipse represents a database attribute in which the annotation above the middle line is the relation name and the one below is the attribute name,  a solid line between an ellipse and rectangle represents the attribute's classification in  t,  a solid named double ended arrow between two ellipses represents an association in  o, and  a dashed unnamed double ended arrow represents a property of an object. a value concept is represented in two ways -  as an extension in a database column , or  as an intension modeled as a function that returns a value in a database column .

the schema graph emphasizes the concepts, and groups database attributes according to them. the relationships  are captured using attribute relationships. additional database attributes not present in the ontology are also included as properties of a concept represented as keys. finally, user defined database functions are included to complete artifacts needed for querying the database. essentially, a schema graph represents reachability structure among the database concepts, using which we plan to construct sql queries from natural language sentences.

procedure for generating the schema graph
in the spirit of  <cit> , we make no distinction between objects represented as values, attributes or classes, and adopt the view that ontological concepts not only relate class objects, but also value objects. for example, gene represents the object  <dig> in the table gene in figure  <dig> as the class object gene in ontology  o. however, the fact that uqcc is an ortholog of loc <dig> is not captured as a relationship in table equivalentgenes. it is however captured as an attribute value of the relationship. to accommodate such relationships, we adopt a priority scheme for mapping concepts to underlying database in which we prefer to map them first to the database scheme, and then we map only those concepts to instances for which we fail to find a schema level mapping. we explain the process below the result of which is the schema graph shown in figure  <dig> on database Δ and ontology  o.

mapping ontology to schema graph
we define two functions μ and φ to map respectively the concepts and associations in the ontology to an underlying database. let ℜ and  a correspondingly be finite sets of relation and attribute names in database Δ where each attribute name in  a is made unique by prefixing the relation name to which it belongs, i.e., for relation r ∈ ℜ and a ∈ r, there is r.a∈a. then, μ:c→2a, such that for ∀c∀c′∀s∀t∧t∈μ∧s=t⇒c=c′). in other words, all concept to attribute mappings are unique. for example, μ = {gene.geneid, equivalentgene.object <dig>  geneproteinencoding.gene}, and that gene.geneid ∈ μ and gene.geneid ∈ μ is not simultaneously possible. also, whenever ∃s, s = r.a ∈ μ, and a → r holds, concept c is said to have an entity mapping c ⇀ r. the set of all concepts having entity mapping is denoted by  e, and nothing else is in  e. in the gene database, μ has an entity mapping since geneid in gene is a primary key. the mappings that are not in  e, i.e., mappings ∀c∈o, μ ≠ ∅ but c∉e, are called property mapping. generally, all mappings in μ are denoted as c ↠ r.a.

for every association a∈r involving concepts c,c′∈c, if  {c,c′}⊆e  and r.a ∈ μ ^ r.b ∈ μ and r.a and r.b are prime attributes  of r, or  c = r. a∈e, c' = r'. b∉e and r = r', then a has a relationship mapping a ⇁ 〈r.a, r.b〉. the set of all associations having relationship mapping is denoted by  s. for example, in the first category, for the associations alias and encode respectively, alias ⇁ 〈equivalentgenes.object <dig>  equivalentgenes.object2〉 and encode ⇁ 〈geneproteinencoding.gene, geneproteinencoding.protein〉 hold. in the second category, for the associations partof and function partof ⇁ 〈gene.geneid, gene.organism〉 function ⇁ 〈protein.proteinid, protein.function〉 hold.

to facilitate mapping of concepts that are captured as values at the database level, we use a second function φ. therefore for every concept c∈c such that μ = ∅, φ maps c to a set of instance values in relations, i.e., φ:c→2v, where  v is a set of unique values of the form r.a.v in which r is the relation name, and v is a value in column a of r , i.e., → σa = c) ≠ ∅. since value concept may be part of an entity set as well as a relationship set, it is denoted as a polymorphic relation c ↣ 〈r.a, r.b〉 whenever ∃a, a ⇀ 〈r.a〉 and r.b.v ∈ φ, or c ↣ 〈r.a, r.b, r.c〉 whenever ∃a, a ⇁ 〈r.a, r.b 〉 and r.c.v ∈ φ.

the predicate representation of value concepts is identical to class concepts, i.e., gene, function or ortholog. in this database, the class concept gene is represented as a table ), whereas the class concept function is represented as an attribute of the table protein. in both representations, x is the primary key of the tables gene and protein, respectively. for example, for gene,  <dig> is a primary key, and for ortholog, both uqcc and loc <dig> are in the primary key of equivalentgenes table. the set of all such mappings are denoted by  p.

concept and association mapping functions
implementation of the concept mapping function μ, and value mapping function φ is quite straight forward and intuitive. for the function μ, first, we use a subset of the gene ontology  <cit>  and adopt the ontology as our type hierarchy  t. we use a simple syntactic scheme for typing attribute values. for example, uqcc will be typed as a gene name, while  <dig> will be recognized as a gene. we inspect and select a representative set of values per column of each table in the database, using a statistical sampling technique. the type of the attribute is then taken as the least upper bound of all the types of sampled values in each column in the type hierarchy  t. the value concept mapping function φ is implemented as σa = c) for each attribute a of each relation r in Δ. with the help of these two functions, we classify each attribute of each relation as a type/class concept in  t, and capture the value concepts in  o, i.e., concepts that do not have an attribute level correspondence, as associations. for example, ortholog can be viewed as a relationship between two gene products x and y , whereas growth control may be viewed as a unary relationship with a protein x, a property.

database to schema graph mapping
since users view of the database is somewhat unrestricted and independent of any database schema, or the assumed ontology, queries may involve concepts and relationships that are represented in the database even though they are not present in the ontology. therefore, the ontology to schema graph mapping described in the previous section will miss them. to fill this gap, we also define a backward mapping from the database to schema graph as follows.

let r be a relation with primary key k such that k is mapped to concept c, i.e., r.k ∈ μ. if c∈o, r.k will be connected to a concept c in schema graph as described with a solid line although it may not have any relationship with any other concept. however, if r.k ∈ μ but c∉o, we create a new concept c in the schema graph and represent it. for both cases, i.e., c∈o and c∉o, every attribute a ∈ {r - k} that is not in  o but r.a ∈ μ for some c, we create a concept c and associate r.a with c, and connect r.a as an unnamed property of r.k . in the schema graph in figure  <dig>  genename and proteinname are of concept type name , and dnasequence is of concept type sequence . these are called database concepts and always connect to the concept, representing the key of the relation they belong to.

for every database function f, we add an intensional value concept  that accepts a set of concepts and returns a concept in the schema graph. for example, genemapper and idmapper are two such functions. since these database functions produce value concepts, value concepts in o can be mapped to these functions as well. for example, idmapper is an implementation of the value concepts in column relationship, i.e., given two gene products, it returns the nature of their relationship.

query transformation
while natural language interfaces are powerful, intuitive and desired, it is well established that current technology does not make it possible for us to support unrestricted querying on all databases accurately  <cit> . it is thus often suggested  <cit>  that limiting the type of queries supported on a specific database may help alleviate the problem and improve the usability of such interfaces over generic databases. accordingly, our goal in this paper is to allow three types of queries - interrogative, imperative and declarative. while all three types of sentences are basically queries, an interrogative sentence poses a question specifically using a structure such as "does", "is", "why", "how", "what", and so on. while "does" and "is" types of questions mainly pose existential or verification type queries and can be computed using selection operation in relational algebra, "why" and "how" types of questions often imply deductions and require significant reasoning to answer. imperative questions, and often declarative questions, generally use structures such as "list", "print", and "return" that is a selection query in its simplest form. the real complexity though lies in the way such questions are formed.

semantic roles of objects in queries
since our main interest is in mapping natural language queries to structured queries, and not in developing parsing technologies, we exploit systems such as minipar  <cit>  or stanford dependence parser  <cit>  that are widely respected for their accuracy in parsing query sentences and computing dependence graphs and semantic roles. we accept the semantic roles generated by minipar in conjunction with data dictionaries such as wordnet  <cit> . the overall translation process is shown in figure  <dig> in which we introduce three components - term analyzer, semantic graph matcher, and query generator.

the term analyzer generates the semantic role of the query sentence in the form of a dependence graph as closely as possible, using the concepts and terms in the schema graph, synonyms and other equivalence relations in wordnet and the type hierarchy  t. intuitively, the term analyzer transforms the query sentence using terms in the schema graph concepts. the dependence graph is analyzed to identify the subgraphs in the schema graph that match. if the match results in a connected graph, it is accepted as a logical query graph and sent to query generator. the query generator then generates the sql query by properly sequencing the joins, plugging selection conditions, and substituting function calls when needed. let us revisit the query we introduced in section, " that function similar to human genes ." and discuss it in the context of the machineries we have introduced so far, and see how we can formulate a structured query to respond to it, and how the nature of the query changes as we modify it slightly. in this query, we have separated four segments  that changes the nature of the query when added successively. the query "list all growth control genes" is a simple imperative query that can be answered with a simple selection query as follows:

select geneid

from gene g, protein p

where g.uniprotid = p.proteinid and p.function = "growth control"

this query can be generated based on dependence parse tree of the query sentence and by establishing the semantic roles of the sentence. for example, minipar will generate the terms {} where "growth control" is treated as a modifier of the head noun gene. we then match the head noun with the concept gene, and "growth control" to the concept function using type hierarchy  t. the relationship between these two terms are then generated as the graph in figure  <dig> from the schema graph, called the logical graph , since this is the shortest path to connect them . semantically this subgraph means every gene has a uniprot protein id for which a function is available. in terms of the database Δ, this graph also entails the sql query above. while this query is somewhat straightforward, the query "list all growth control genes in dogs" is not simple to generate, and will require substantial machineries described next. the query "list all growth control genes in dogs that function similar to human genes" will require even more.

correspondence between english sentence structures and concepts
once the sentence is parsed and terms are generated by minipar, the query is decomposed into semantic roles and verbs. each semantic role is comprised of a head noun and a set of modifiers. in the query, "list all growth control genes", growth control  are modifiers of the head noun gene. the verbs are the terms that relate the semantic roles we generate. once the semantic roles for the english sentence has been established, and the dependence graph has been generated by the term analyzer, we use table  <dig> as a guide toward establishing correspondence between the terms and the concepts in the schema graph.

a generalized mapping procedure
the sql query that our system would ordinarily generate  to compute the query "list all growth control genes in dogs" is as follows.

select geneid

from gene g, protein p

where g.uniprotid = p.proteinid and g.organism = "dog" and p.function = "growth control"

given the database instance Δ, this query will produce the response loc <dig>  in the event the third row in table gene is missing, our hope is that we still will be able to compute this response because we know  q9nva <dig> is a growth control protein encoded by gene uqcc which is an ortholog of loc <dig>  since we would not know to which organism loc <dig> belongs, we could invoke a function, say organismmapper, that maps a gene id to an organism, and see if loc <dig> belonged to dog. if such a function existed in the database, the query generator would also return the following sql query segment that we would union with the one above to generate all possible responses.

select geneid

from gene g, protein p, equivelantgenes e

where g.uniprotid = p.proteinid and g.geneid = e.object <dig> and p.function = "growth control" and organismmapper = "dog"

in  <cit> , we introduced an sql construct using which external web form based, or desktop based, functions may be conveniently used as tables to maintain compatibility with sql. this mechanism allows the capability to exploit arbitrary external resources to enhance computing capabilities. for example, consider now the query "list all growth control genes in dogs that function similar to human genes". this query is more complex and requires more analysis because a direct conclusion is not possible from the database instance. a possible approach is as follows. first, find the growth control gene loc <dig> in dog. then, find all the orthologs of this gene in human. check to see if they control growth. else, find all genes in human and find dna similarity, and infer functional similarity using tools. return response found. clearly, the complexity has increased, but if the knowledge to carry out the process is included in the ontology, constructing the required query is possible.

RESULTS
at this point, it is only instructive to mention that the entire query "list all growth control genes in dogs that function similar to human genes but are absent in fruit files" though feasible, is likely to be very complex if effective semantic role of the sentence can be computed. our attempt to compute a dependence graph for this sentence using cmu link parser  <cit>  is shown in figure  <dig>  cmu link parser has similar functionality as stanford parser and minipar but generates a visualization of the parse graph. the graph for this query is shown in figure  <dig>  it is apparent that for complex queries such as this, the dependence graph generation is a challenge. the figure shows broken links for many of the query terms. for less complex queries such as "list all growth control genes in dogs that function similar to human genes", the parsers work reasonably well as shown in figure  <dig>  so the choice of the parsing and semantic link generation tool becomes exceedingly crucial. however, this choice often forces changes in our system as well as significant interfacing effort. in our current prototype, we remain uncommitted to a specific parser as we investigate several parsers and their suitability for such complex queries.

we believe the novelty of our plug-in is in its ability to bridge the semantic gap between a database schema and engine that maps nlp queries into queries in sql or other declarative languages by leveraging the parsing effectiveness of short nlp queries by stanford parser or minipar. to accurately map each nlp query to an equivalent sql query, we leverage a high level conceptual description of an application in the context of which all nlp queries are interpreted. the dynamic nature of the plug-in allows updates in the knowledge base to refine application semantics to improve the quality of the query response. such flexibility is desirable in databases needing to change the underlying database schema, or the guiding rules for query response. the separation of layers in our system also allow for accommodating changes at any level without disturbing the other layers, thus facilitating the portability of our approach to other applications.

CONCLUSIONS
our goal in this paper was to explore the outline of a smarter and cooperative natural language interface for biological database where the semantics of a query usually have many interpretations. we have demonstrated that in such databases, even though an answer is available, traditional systems will usually fail to respond due to the conventional query processing model. the novelty of our approach is in the generation procedure of the schema graph that embodies the semantic relationship in a conceptual ontology in terms of an arbitrary database scheme in a user transparent way. the process ensures that all the information content of a database is matched to the conceptual view to the maximum possible extent. the inclusion of conceptual rules enhances the querying capability of the system and allows deductive queries involving complex rules and external functions, even over-the-internet queries. this feature now allows users to plug in generic hypotheses and enrich the query capability of the engine, modifying as needed. our contention is that the idea of an automatically generated schema graph allows us to map natural language queries to sql queries over arbitrary database scheme. the requirement that we include an ontology and a type hierarchy is far less restrictive and non-technical than the requirements imposed by contemporary systems . these two requirements can be readily met by many domain ontologies being proposed and developed by the community, one of which is gene ontology. from the standpoint of community knowledge sharing, this is a significant strength of our system.

this paper also raises an interesting question - is it possible to transform an sql query to respond in a way similar to how it would respond to a natural language query. for example, is it possible to transform the sql query discussed earlier that one would traditionally issue to compute the query "list all growth control genes in dogs". we assert that it is easier to provide a smarter response when a natural language query is asked because such queries offer the semantic richness to explore logical alternatives, that is seemingly difficult at the sql level. however, this is one of the issues we would like to explore in the future.

competing interests
the author declares that they have no competing interests.

authors' contributions
hmj is the sole contributor of this paper.

