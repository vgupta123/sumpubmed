BACKGROUND
conventions
throughout the paper we use the terms “name”, “scientific name”, and “name-string” in particular ways. “name” refers to one or several words that act as a label for a taxon. a “scientific name” is a name formed in compliance with a nomenclatural code  or, if beyond the scope of the codes, is consistent with the expectations of a code. the term “name-string” is the sequence of characters  that forms the name. a name can be expressed in the form of many name-strings . there are about two and a half million currently accepted names for extinct and extant species. there are approximately ten million of legitimately formed scientific names and hundreds of millions of possible name-strings for them. we use the term “elements” for the components of a name-string. traditionally, in biological literature, scientific names for genera and taxa below genus are presented in italics. in this paper, where we wish to emphasize examples of name-strings, we use bold font.
fig.  <dig> some legitimate versions of the scientific name for the ‘northern bulrush’ or ‘singlespike sedge’. the genus , species , and subspecies  may be annotated  or include or omit the name of the original authority for the infraspecies , or for the species , or for the current infraspecific combination . the name of the authority is sometimes abbreviated, sometimes differently spelled, and may be with or without initials and dates. this list is not complete. image courtesy of  <cit> 




introduction
biology is entering a “big data” age, where global and fast access to all knowledge is envisaged. progress towards this vision is still limited in scope. one impediment, especially for the long tail of smaller sources , is the absence of devices to inter-connect distributed data. the names of organisms are invaluable in “big data” biology because they can be treated as metadata and as such can be used to discover, index, organize, and interconnect distributed information about species and other taxa  <cit> . the use of names for informatics purposes is not straightforward because, for example, there may be many legitimate spellings for a name . a cyberinfrastructure that uses names to manage information about organisms must determine which name-strings are variant forms of the same scientific name.

carex scirpoidea var. convoluta description by kükenthal



carex scirpoidea subsp. convoluta rank determination by dunlop.




in the past, the need to parse scientific names to form normalized names has mostly been achieved manually. a person familiar with rules of botanical nomenclature would be able to analyse the  <dig> name-strings in this example with relative ease, but not thousands or millions of name-strings - especially if they include scientific names to which more than one nomenclatural code may be applied. the manual splitting of names into even only two parts — the latinized elements of taxon names that make up the canonical form and the authorship — is slow and therefore expensive. to scale this exercise up requires an algorithmic solution, a scientific name parser!

the strategy of the algorithmic approach is to identify which combinations of the most atomic parts of a name-string  represent words  or dates. an early algorithmic approach to parsing scientific names was with “regular language” implemented as regular expression  <cit> . a regular expression is a sequence of characters that describes a search pattern  <cit> . for example, a regular expression “{2}” recognizes a word that starts from a capital letter followed by two small letters . scientific names almost universally follow patterns that are influenced by the codes of nomenclature: such as the use of spaces to separate words, capitalization of generic names and authors, or the inclusion of four digit dates between the middle of the 18th century and the present. this makes most names amenable to parsing by regular expressions. current examples of scientific name parsers based on regular expressions are gbif’s name-parser  <cit> , and yasmeen  <cit> .

while regular expression is a powerful approach to string parsing, it has limitations. it cannot elegantly deal with name-strings where an authorship element is present in the middle of the name  d.a.dunlop). indeed, regular expressions are not well suited to any targets with recursive  elements  <cit> , such as hybrid formulae  dc. convar. fruticosa  alef. × b. oleracea l. subsp. capitata  var. costata dc.). name parsing built on regular expressions is impractical for complex name-strings.

another limitation with most regular expression software tools is that they are “black boxes” that allow developers very limited interaction with the parsing process. they do not reveal much information about the parsing context and developers cannot call a procedure during a parsing event. as a result, complex regular expression-based parsers are difficult to implement and maintain, and functions such as error recovery, detailed warnings, descriptions of errors are missing.

we wanted to deal with scientific names across a very broad range of complexity and to give more flexibility than can be achieved with a regular expression approach. we believe that a scientific name parser should satisfy the following requirements. 

high quality. a parser should be able to break names into their semantic elements to the same standards that can be achieved by a trained nomenclaturalist or better. this will give users confidence in the automated process and allow them to set aside tedious and expensive manual parsing.


global scope. a parser should be able to parse all types of scientific names, inclusive of the most complex name-strings such as hybrid formulae, multi-infraspecific names, names with multilevel authorships and so on. no name-strings should be left unparsed, otherwise biological information attached to them may remain undiscoverable.


parsing completeness. all information included in a name-string is important, not just the canonical form of the scientific name. authorship, year, rank information allow us to distinguish homonyms, similar names, synonyms, spelling mistakes, or chresonyms. access to such information improves the performance of subsequent reconciliation .


speed. users, especially large-scale aggregators of biodiversity data, are more satisfied with speedy processing of data as it allows them to move forward to more purposeful value-adding tasks. speed reduces the purchasing/operating costs of the hardware used for production parsing.


accessibility. to be available to the widest possible audience, a parser should be released as a stand-alone program, have good documentation, be able to work as a library, to function as a command line tool, as a tool within a graphical interface, to run as a socket or as restful services.




these requirements became our design goals. based on our experience with prototype systems, we chose to use parsing expression grammar and scala language.

adoption of parsing expression grammar
parsing expression grammar   <cit>  have been introduced for parsing strings. peg allows developers to define the rules  that describe the general structure of target strings. such rules can be used to deconstruct scientific names. the rules are built from the ground up, starting from the simplest — such as a combination of “characters” separated by “spaces”. that ‘rule’ identifies most “words”. digits and other characters make dates identifiable. further rules can be applied, such as a “genus” rule can describe a part of a polynomial name-string in which the first word begins with combination of a “capital_character” followed by several “lower_case_characters” that fall within a relatively small spectrum of allowed characters; “authorship” would consist of one or more capitalized words and followed perhaps by a “year”. within some instances of authorship, authors may be grouped to form “author-teams”. peg rules are designed to be recursive. they can be expanded to deal with increasingly complex name-strings, or address errors such as absent or extra spaces, or ocr errors. each rule can have programmatic logic attached, making the peg approach very flexible. we believe that peg suits our goals better than regular expressions for the following reasons: 
peg is better suited than regular expressions for strings with a recursive structure;

the syntax of scientific names is formal enough to be closer to an algebraic structure rather than to a natural language. inconsistencies and ambiguities in scientific name-strings are relatively rare because they usually comply with the requirements and conventions of nomenclatural codes;

scientific name-strings are short enough to avoid problems with computational complexity and memory consumption;

programming a parser with peg can describe parsing rules in a domain-specific language;

domain-specific languages offer great flexibility for logic within the rules, for example to report errors in name-strings.




the global names project created a specialized parsing library biodiversity in  <dig>  <cit> . it was written in ruby and based on peg. it uses the treetop ruby library  <cit>  as the underlying peg implementation.

the peg approach allowed us to deal with complex scientific names gracefully. it gave us flexibility to incorporate edge cases and to detect common mistakes during the parsing process. the biodiversity library has enjoyed considerable popularity. at the time of writing, it had been downloaded more than  <dig>  times  <cit> , it is used by many taxon name resolution projects   <cit> , the iplant tnrs  <cit> , and world registry of marine species   <cit> . according to statistics compiled by bioruby, biodiversity, at the time of writing, has been the most popular bio-library in the ruby language  <cit> .

we were pleased with peg approach for parsing scientific names, but regard the biodiversity parser library as a working prototype. it has allowed us to make further improvements and deliver a better, faster production-grade parser.

other approaches
there is a growing number of algorithms and tools in machine learning and natural language processing that aim to recognize parts of texts. they include statistical parsing  <cit> , context-free grammars  <cit> , fuzzy context-free grammars  <cit> , and named entity recognition  <cit> . unsupervised deep learning  <cit>  increases the quality of entity recognition without extensive curation and programming efforts by people. we chose not to use these approaches for the following reasons. 
the limited scope of a parser. a parser of scientific names very rarely needs to work with name-strings of more than  <dig> words.

there is no need for recognition. a scientific name-string parser is usually applied to preexisting lists of scientific names. there is no requirement to recognize scientific names in larger bodies of text. other scientific name recognition and discovery tools are available.

formal grammar. scientific names are formed in compliance with well-defined and formal codes of nomenclature. they have predictable structures making the requirements for a scientific name-string parser to be more similar to parsers of programming languages than to tools designed to work with natural languages.

scale and throughput. we created the parser to serve the needs of biodiversity aggregators. a core design requirement was to develop a lightweight library for inputs of millions of scientific name-strings per second, and to be processed locally.

stand-alone approach. we did not wish the parser to rely on local or remote previously known information of genera, species, author names, or other scientific names. gnparser relies instead on morphological features of scientific name-strings.

determinism. biologists know that there is only a single correct parsed version of a scientific name. a scientific names parser must produce a single “correct” result for each input string. a parser should provide meta information on every part of the string.




adoption of scala
the pre-existing biodiversity package is not speedy and cannot scale because it uses ruby as its programming language. ruby is one of the best languages for rapid prototyping, but it is an interpreted dynamic language with, originally, a single-threaded runtime during execution. this makes it slow and inappropriate for “big data” tasks. we concluded that we needed a replacement language environment with the following properties: 
a mature technology;

multithreaded, with high performance and scalability;

an active support community with an open source friendly culture;

a wide range of libraries: utilities, web frameworks, etc.;

a powerful development environment with ides, testing frameworks, debuggers, profilers and the like;

mature libraries for search and cluster computations;

interoperable with languages popular in scientific community ;

natural support of domain specific languages embedded in the hosted language.




while many of the properties are true for ruby, other properties, such as high performance, scalability and interoperability, are not. to meet all requirements, and exploiting what we had learned from biodiversity, we rewrote the code using scala , and the open source parboiled <dig> library  <cit>  which we improved  <cit> . the parboiled <dig> library implements peg in scala. an alternative to parboiled <dig> is the scala combinators library  <cit> . we did not use it because it is slow and has memory consumption problems.

the functional programming features of scala allowed us to build a domain specific language that describes the grammar’s rules to parse scientific names. this produces a parsing expression grammar with considerably more flexibility than external lexers such as bison or yacc. as this domain specific language is within parboiled <dig>  it can take advantage of the macro capacity of scala  <cit>  to optimize the compilation of the code and the subsequent running of the program. as a result, the software performs with high efficiency. the resulting gnparser library is faster, more scalable and more flexible than its predecessor.

we limited this version to work with scientific names that comply with the botanical, zoological, and prokaryotic codes of nomenclature, but not with names of viruses because they are formed in different ways  <cit>  and need a different peg. we intend to add this later.

implementation
the gnparser project is entirely written in scala. it supports two major scala versions:  <dig> .6+ and  <dig> .x. the code is organized into four modules: 
“parser” is the core module used by all other modules. it parses scientific names from the most atomic components of a name-string to semantically-defined terms. it includes the parsing grammar, an abstract syntax tree  composed of the elements of scientific names, warning and error facilities. when the parsing is complete and semantic elements of name-strings have been assigned to ast nodes, the elements can be recombined and formatted to meet further needs. for example: 
 
normalizer converts input name-strings into a consistent style;

 
canonizer creates canonical forms of the latinized elements of names;

 
json renderer, the parsing result is converted to json  <cit>  to allow developers to work with the output using other languages. the output  has the following information: ’details’ contains the json-representation of a parsed scientific name; ’quality_warnings’ describes potential problems if names are not well-formed; ’quality’ depicts a quality level of the parsed name; and ’positions’ maps the positions of every element in a parsed name to the semantic meaning of the element. full and formal explanation of all parser fields is given as a json schema and can be found online  <cit>  .
fig.  <dig> web graphical user interface  <cit> . in this example a user entered a name-string of a hybrid name consisted of  <dig> elements. the “results and discussion” section contains detailed parsed output using compact json format







the “spark-python” module contains facilities to use “gnparser” with apache spark scripts written in python. apache spark is a highly distributive and scalable development environment for processing massive sets of data. spark is written in scala, but can also be used with python, r and java languages. spark programs written in java and scala are able to run “parser” in a distributed fashion natively.

the “examples” module contains examples to assist developers in adding “parser” functionality into other popular programming languages such as java, scala, jython, jruby, and r.

the “runner” module contains the code that allows users to run “parser” from a command line as a standalone tool or to run it as a tcp/ip socket or http web server. it depends on the “parser” module. the core part is the launch script “gnparse”  that creates a jvm instance and runs “parser” on multiple threads against the input provided via a socket or file. this module also contains a web application and a restful interface to offer simpler ways to access “parser”. “web” achieves interactions with “parser” via http protocol. it works both with simple web  and rest api interfaces. figure  <dig> illustrates a parsing example using the web-interface. socket and rest services use akka framework which makes them highly concurrent and scalable.




“parser“ and “examples“ can run in jvm  <dig> +. “runner” requires jvm  <dig> +. documentation is available in a readme file .

parsing rules

gnparser v <dig> . <dig> contains  <dig> peg rules. in turn, these rules make use of more elementary rules provided by the parboiled <dig> library. the rules are domain-specific based on hours of conversations with leading taxonomists, study of nomenclatural codes, and feedback of the users.

as an example, the yearnumber rule is given below. it detects the year in which a name was published. rule is a type of the returning value of the rule. using domain-specific language and elementary rules of parboiled <dig> we capture the start and the end positions of a year substring . this matches a substring that represents a year in scientific name-strings. a publication year is usually a number between  <dig>  <cit>  and the present. a year substring might have one or two digits substituted with question marks if the exact year of a publication is unknown. the capture is then passed as a parameter to a parser action . parser action, a scala function, might produce warnings or a class instance of defined type .





we then assemble more complex inter-dependent rules , and finally combine all of them into the rule year on line # <dig> that consists of prioritized alternatives of all previously defined rules.





this enables the incorporation of the year rule into all cases where it might be needed. for example on line # <dig> we indicate that year must be present in the matcher for the authorsyear rule.





installation
“gnparser” is available for launch in three bundles. 
a parser artifact is provided via the maven central repository of java code  <cit> . physically it is a relatively small jar file without embedded external dependencies. the artifact can be accessed in custom projects by a build system such as maven, gradle, or sbt. the build system identifies and provides access to all dependent jars.

a zip-archived “fat jar” is located at the project’s github repository. the jar contains the compiled files of gnparser along with all necessary dependencies to launch it within jvm. the archive is also bundled with a launch script  that can run a command line interface to gnparser.

the project’s docker container image is located at docker hub  <cit> . docker provides an additional layer of abstraction and automation of operating-system-level virtualization on linux. it can be thought of as a lightweight virtualization technology within a linux os host. when it is setup properly, everything — starting from jvm and ending with scala and sbt — can be run with simple commands that will, for example, pull the gnparser’s docker image from the dockerhub, and run the socket or web server on an appropriate port.




testing methods
data for our tests were sets of  <dig> and  <dig>  name-strings randomly chosen from  <dig> million unique name-strings of the global names index   <cit> . the name-strings in gni are collected from a large variety of biodiversity data sources and are pre-identified as scientific names. while gni contains some incorrectly classified strings, it is the largest compilation of name-strings representing scientific names. it is not biased towards any particular taxon or particular variant of name, and so the extracted datasets are believed to represent naturally occurring data quite well. the datasets are randomly chosen and are therefore mixtures of well-formed names, lexical variants of names, names with formatting and spelling mistakes, and name-strings that were misrepresented as names. name-strings in the sets are independent of each other. an evaluation dataset with  <dig> names is included as additional file  <dig> 

we compared the performance of gnparser with two other projects: biodiversity parser  <cit>  , and the gbif name-parser  <cit> . the following versions were used: gnparser v.  <dig> . <dig>  gbif name-parser v.  <dig> . <dig>  biodiversity v.  <dig> . <dig>  to make comparisons, we calculated precision, recall and accuracy  using a dataset consisting of  <dig> name-strings. we also tested the yasmeen parser from imarine  <cit> . with our dataset, yasmeen generated many more mistakes than other parsers , and was unable to finish a full dataset without crashing. we excluded it from further tests.

to estimate the quality of the parsers, we relied on their performance in representing canonical forms and terminal authorships. a canonical form represents the latinized elements of taxon names, while the terminal authorship refers to the author of the lowest subtaxon found in the scientific name. for example, with oriastrum lycopodioides wedd. var. glabriusculum reiche, the canonical form is oriastrum lycopodioides glabriusculum and the terminal authorship is reiche, not wedd.

when both the canonical form and the terminal authorship were determined correctly we marked the result as true positive . if one or both of them were determined incorrectly, the result was marked as a false positive . name-strings correctly discarded from parsing were marked as true negatives . false negatives  were name-strings which should have been parsed, but were not. the results of the tests are summarized in table 1:

true positive

true negative

false positive

false positive

precision

recall

f1

accuracy




accuracy — the proportion of all results that were correct. it is calculated as: 
 accuracy=ntp+ntnntp+ntn+nfp+nfn 



precision — the proportion of name-strings parsed correctly compared to all detected name-strings. it is calculated as: 
 precision=ntpntp+nfp 



recall — the proportion of correctly detected name-strings relative to all parseable name-strings and is calculated as: 
 recall=ntpntp+nfn 


the f1−measure is a balanced harmonic mean . when precision and recall differ, f1−measure allows results to be compared. it is calculated as 
 f1=2×precision×recallprecision+recall 


some names in the dataset were not well-formed. if a human could extract the canonical form and the terminal authorship from them, we included them in our assessment. examples of such name-strings are “hieracium nobile subsp. perclusum  o. bolòs & vigo” , “campylium gollanii c. m?ller ex vohra  <dig>  <cit> ” , “myosorex muricauda .” .

parsers analyze the structure of name-strings, but they cannot determine if a string is a “real” name. for example, in the case of a name-string that has the same form as a subspecies such as “example name word var. something capitalized words, 1900”. in such a case, the identification of a canonical form as “example name something” and terminal authorship as “capitalized words, 1900” would be considered a true positive. clearly, it will be important for name-management services to distinguish between name-strings of scientific names, names of viruses, surrogate names, and non-names. to find out how well parsers distinguished strings which are not scientific names, we calculated accuracy for discarded/non-parsed strings. if the parser worked well, non-parsed strings would include only names of viruses and terms that do not comply with the codes of zoological, prokaryotic, and botanical nomenclature.

we processed  <dig>  name-strings with each parser. each parser discarded close to  <dig>  name-strings as non-parseable. accuracy, in this case, provided the percentage of correctly discarded names out of all discarded by the parser names. we do not know recall, as it was not reasonable to manually determine this for  <dig>  names. to get a sense of names which should be discarded but were parsed instead, we analysed intersections and differences of the results between the three parsers as shown in table  <dig> 

true discarded

correctly discarded

incorrectly discarded

accuracy



to establish the throughput of parsing we used a computer with an intel i7-4930k cpu , 64gb of memory, and 250gb samsung  <dig> evo ssd, running ubuntu version  <dig> . throughput was determined by processing  <dig> , <dig> random name-strings from global names database.

to study the effects of parallel execution on throughput we used the parallelparser class from biodiversity parser. we used ‘gnparse file –simple’  for gnparser. for gbif name-parser, we created a thin wrapper with multithreaded capabilities  <cit> . the following versions had been used for throughput benchmarks: gnparser v.  <dig> . <dig>  gbif name-parser v.  <dig> . <dig>  biodiversity v.  <dig> . <dig> 

RESULTS
we discuss and compare gnparser, gbif name-parser and biodiversity parser in the context of our requirements for quality, global scope, parsing completeness, speed, and accessibility.

high quality parsing
quality is the most important of the  <dig> requirements. gbif name-parser uses regular expressions approach, while gnparser and biodiversity parsers use the peg approach. results for quality measurements are shown in tables  <dig> and  <dig>  we include the  <dig>  tested names as additional file  <dig> 

if test data contain a large proportion of true negatives  accuracy will not be a good measure as it favors algorithms that distinguish negative results rather than finding positive ones. we manually checked our test datasets and established that ≈1% were not scientific names. given that true negatives are rare, they will have very limited influence on accuracy. recall for all parsers was high, hence false negatives are not important.


accuracy is probably the best measure for our tests. all  <dig> parsers performed very well, with accuracy values higher than 95%. both gnparser and biodiversity parser approached the 99% mark which we regard as the metric for production quality. most of the false positives came from name-strings with mistakes. for example, out of  <dig> false positives  that gnparser found in the  <dig> name-string test data set, only  <dig>  were well-formed names. 

eucalyptus subser. regulares brooker



jacquemontia spiciflora  hall. fil.



acanthocephala declivis variety guianensis osborn, 1904



atysa  frontalis



bumetopia  quadripunctata breuning, 1950



cyclotella kã
1
/
4
tzingiana thwaites



elaphidion  tæniatum leconte, 1873



hieracium nobile subsp. perclusum  o. bolòs & vigo



leptomitus vitreus  agardh?



myosorex muricauda .



papillaria amblyacis  a.jaeger





we do expect a parser to deal with names that are not well-formed. that means overcoming problems such as aberrant characters which might arise from unicode character miscodings, inappropriate annotations, or other mistakes. to alert users, gnparser generates a warning when it identifies a problem in a name-string. the other parsers do not have this feature.

when parsers reach ≈80%
accuracy, they hit a “long tail” of problems where each particular type of a problem is rare. every new manual check of additional test sets of  <dig> – <dig>  name-strings reveals new issues. examples of these challenges are given elsewhere  <cit> . for all three parsers, developers have to perform the meticulous task of adding new rules to address each rare case. that is, parsers need to be subject to continuous improvement. the problems found during preparation of this paper are being addressed in the next version of gnparser. as the parsing rules improve, we believe that gnparser can reach > <dig> %
accuracy without diminishing recall.

as we incorporate new rules to increase recall, we have to consider the risks of reducing precision by introducing new false positives. for example, the gbif name-parser allows the genus element of a name-string to start with a lowercase character. as a result the name-strings below were parsed as if they were scientific names, while the other parsers ignored them: 

acid mine drainage metagenome



agricultural soil bacterium crs5639t18-1



agricultural soil bacterium sc-i-8



algal symbiont of cladonia variegata mn075



alpha proteobacterium ap-24



anaerobic bacterium ana no.5



anoxygenic photosynthetic bacterium g16



archaeon enrichment culture clone aom-sr-a23



bacterium endosymbiont of plateumaris fulvipes



bacterium enrichment culture dgge band 61_3_fg_l



barley rhizosphere bacterium jj-220



bovine rumen bacterium niuo17





strategies like these may increase recall with certain low-quality datasets, but they decrease precision. many “dirty” datasets contain recurring problems. as an example, dryad contains many name-strings in which elements of scientific names are concatenated with an interpolated character such as ‘_’   <cit> . for them, our solution was to include a “preparser” script which “normalizes” known problems that are inherent within particular datasets and then apply a high quality parser to the result.

our testing also revealed differences between regular expressions and peg approaches. both can achieve high quality results with canonical forms of scientific names, but the regular expressions are less suitable for more complex name-strings. the recursive or nested nature of some scientific names can cause problems which become insurmountable for regular expressions.

global scope
if we want to connect biological data using scientific names, no name-strings should be missed or rejected, no matter how complex they are. during our testing we found that accuracy of gbif’s name-parser was depressed because, in part,the parser did not recognize hybrid formulae and infrasubspecific names with more then one infraspecific epithet. this case underscores the limitations of the regular expression approach. as examples, the following were not parsed by the gbif name-parser:


erigeron peregrinus ssp.callianthemus var. eucallianthemus 


polyporus varius var. nummularius f. undulatus  domanski, orlos & skirg. 


salvelinus fontinalis x salmo gairdneri 


echinocereus fasciculatus var. bonkerae × e. fasciculatus var. fasciculatus 

the peg approach supports nested parsing rules to create progressively more complex rules that manage such cases. the capacity to address recursion allows gnparser to handle the full spectrum of scientific names that we have presented to it.





parsing completeness
the extraction of canonical forms from name-strings representing scientific names is the most beneficial and widely used parsing goal. sometimes, however, this may not be sufficient because the canonical form does not always distinguish a name completely.

in the example in fig. 1
carex scirpoidea convoluta is a canonical form for carex scirpoidea var. convoluta kükenthal and carex scirpoidea ssp. convoluta  dunlop. the first non-parsed name-string refers to the variety convoluta of carex scirpoidea that had been described by kükenthal. the second captures dunlop’s reclassification of convoluta as a subspecies. we are not able to distinguish between these two different names without knowing the rank and/or the corresponding authorship. furthermore, it is useful to see in the second example that  was the original author and dunlop was the author of the new combination. also, canonical forms do not distinguish between homonyms. the heather, pieris japonica  d. don ex g. don and the butterfly, pieris japonica shirôzu,  <dig> have the same canonical form pieris japonica.

after matching by canonical form, rank, authors, and “types” of authorship allow us to distinguish name-strings with similar or identical canonical elements. the name-string carex scirpoidea michx. var. convoluta kükenth. adds the information that the species carex scirpoidea was described by michx but is not evident in the examples in the paragraph above.

another area in which parsers with limited abilities can give misleading results is with negated names  <cit> . in these cases, the name-string includes some annotation or marks to indicate that the information associated with the name does not refer to the taxon with the scientific name that is included. examples include gambierodiscus aff toxicus or russula xerampelina-like sp.

all components of a name may be important and need to be parsed and categorized. with gnparser, we describe the meaning of every element in the parsed name-string and present the results in json format. parsing of carex scirpoidea michx. subsp. convoluta  d.a. dunlop gives the following json output

the output includes the semantic meaning of all parsed elements in a name-string, indicates if the name-string was parsed successfully, if it is a virus name, a hybrid, or a surrogate. surrogates are name-strings that are alternatives to names  and they may or may not include part of a scientific or colloquial name . the output also includes a statement of the position of each element in the name-string. last, but not least, the json output contains uuid version  <dig> calculated from the verbatim name-string. this uuid is guaranteed to be the same for the same name-string, promoting its use to globally connect information and annotations.

the output usually covers every semantic element in the name-string. the fields in the output illustrated above have the following meanings. 

name_string_id: uuid v <dig> identifier;


parsed: whether a name-string was successfully parsed ;


quality: how well-formed a name-string is ;


parser_version: version of a parser used;


verbatim: name-string as was submitted to gnparser;


normalized: name-string modified by the parser to give a normalized style;


canonical_name: a special form of normalization that includes only the scientific elements of the name, this form is contained within most name-strings relating to scientific names;


hybrid: whether the name-string refers to a hybrid ;


surrogate: whether a name-string is a surrogate name ;


details: describes the semantic elements within the name-string inclusive of the following;


genus: reports the genus part of the name ;


specific epithet: reports the species epithet ;


authorship: reports the authorship of the combination ;


basionym authorship: reports the authorship of the basionym 


infraspecific epithets: reports the infraspecies name if present  with rank 


authorship: reports the authors of the infraspecies name  d. a. dunlop)


basionym authorship: reports the author of the basionym of infraspecies name element ;


combination authorship: reports the author of the infraspecies name combination ; and


positions: identifies each name element and where it starts and ends.




the complete list of fields for the gnparser’s output exists as a json schema file  <cit>  .

parsing speed
in the areas of performance discussed above, there is little difference between biodiversity parser and gnparser. there is, however, a dramatic difference in their parsing speed and ability to scale. parsing tasks that took  <dig> hours with earlier biodiversity parsers can now be completed in a few minutes on a multithreaded computer. parsing is a key to other services such as name-reconciliation and subsequent resolution. improvements to the speed of the parser will increase user satisfaction elsewhere.

results on the speed performance are given in fig.  <dig>  the performance depends on the number of cpu threads used. on  <dig> thread gnparser was  <dig> times faster than biodiversity,  <dig> times faster on  <dig> threads, and  <dig> times faster on  <dig> threads.
fig.  <dig> names parsed per second by gn, gbif and biodiversity parsers 





gnparser displays functionality not presented in the gbif name-parser as described in previous sections. in spite of this additional functionality gnparser outperformed other tested parsers.

accessibility
by ‘accessibility’ we refer to the ability of the software code to be used by a wide audience. for open source projects, accessibility is very important. if more people use a software, the more cost-effective is its development.

parsing scientific names is essential for organizing biodiversity data. many biodiversity database environments and projects include a parsing algorithm. examples are ubio  <cit> , the botanical society of britain and ireland  <cit> , fat  <cit> , netineti  <cit> , and taxonome  <cit> . a modular approach offers an option of re-use and avoids replication of effort. biodiversity was the first biodiversity parser to be released as a stand-alone package that could be used as a module — as it was with the iplant project  <cit> . the same approach has now been adopted with the gbif name-parser  <cit> , yasmeen  <cit> , and gnparser.

we designed gnparser with accessibility in mind from the outset. scala language allows the use of gnparser as a library in scala, java, jython, jruby and a variety of other languages based on java virtual machine it can also be used natively in r and python via jvm-binding libraries. apache spark, a “big data” framework, is also supported. the following example illustrates how a client written in jython can access the gnparser functionality.


from org.globalnames.parser import



scientificnameparser



snp = scientificnameparser.instance()



result = snp.fromstring.rendercompactjson()



print result


if programmers want to use gnparser in some jvm-incompatible language they can connect to the parser via a socket server interface. there is also a command line tool, a web interface, and a restful api. in  <dig>  encyclopedia of life started to parse name-strings using gnparser socket server.

we pay close attention to documentation, trying to keep it detailed, clear, and up to date. we have an extensive test suite  that describes the parser’s behavior and contains examples of gnparser functionality and output format.

this commitment to accessibility creates a larger potential audience for the parser, and will help many researchers and programmers deal with the problems that arise from variant forms of scientific names.

CONCLUSIONS
the performance of the scientific names parsers is summarised in table  <dig>  the two peg-based parsers — biodiversity and gnparser are similar. they are based on the same algorithmic approach and follow similar design goals. while we had the option of modifying the rules for biodiversity to improve accuracy, we preferred to create a new tool from scratch to overcome limitations in speed, scalability and accessibility. we needed to address speed at global names because existing software took too long to parse or reparse  <dig> million name-strings. gnparser can be used natively by larger variety of programming languages than biodiversity, because jvm-based languages and tools are so widely used. our first goal for gnparser was complete coverage of the biodiversity’s test suite. we continue to improve gnparser while biodiversity entered maintenance mode. that explains a slight difference in accuracy by these two parsers.

accuracy

hybrid formulas support

infrasubspecies support

throughput 

parsing details

library for the same languages

library for other languages

command line tool

socket server

web interface

restful service




gbif-parser is a high quality product. however, its regular expressions-based algorithm limits its usability. the recursive nature of some scientific names creates significant obstacles for intrinsically non-recursive algorithms such as regular expressions. coverage of multi-infraspecific names and hybrids, both with recursive patterns, is prohibitively expensive for such an approach.

in conclusion, this paper describes gnparser, a powerful tool for working with biodiversity information. it transforms names of taxa into their semantic elements. this allows standardization of names by, for example, representing them as canonical forms. this step dramatically improves name matching within and among data sources, and this increases the amount of data on a single taxon that can be integrated. parsing can be used to improve the discovery of names in sources, and creating a common taxonomic index to multiple sources. parsing allows users to extract, compare and analyse metadata within the name-strings, and allowing comparisons of the efforts of individuals or to map trends over time. the gnparser tool is released under mit open source license, contains command line executable, socket, web, and rest services, and is optimized for use as a library in languages like scala, java, r, jython, jruby.

availability and requirements

project name: gnparser


project home page:
https://github.com/globalnamesarchitecture/gnparser



operating system: any platform able to run jvm  <dig> 


programming language: scala


license: the mit license


other requirements: docker 


any restrictions to use by non-academic: no restriction

the data supporting the conclusions of this article are available in the repository https://github.com/globalnamesarchitecture/gnparser-paper under the data directory.

additional files

additional file  <dig> includes a full and formal explanation of all parser fields as a json schema. 

 



additional file  <dig> readme.rst file that is converted to html format. it is also available at project home page  <cit> . 

 



additional file  <dig>  <dig>  name-strings randomly selected from gni and used to determine accuracy, precision and recall data . 

 



additional file  <dig> extensive test suite that describes the parser’s behavior. it is also a source of examples of parser functionality and output format. test suite consists of a pipe delimited input  and parsed output in json format. 

 


abbreviations
aamalexander a. myltsev

apiapplication program interface

astabstract syntax tree

bhlbiodiversity heritage library

djpdavid j. patterson

dymdmitry y. mozzherin

gbifglobal biodiversity information facility

gnaglobal names architecture

gniglobal names index

jsonjavascript object notation

jvmjava virtual machine

pegparsing expression grammar

restrepresentational state transfer

electronic supplementary material

the online version of this article  contains supplementary material, which is available to authorized users.

