BACKGROUND
in living cells, proteins interact with other proteins in order to perform specific biological functions, such as signal transduction or immunological recognition, dna replication and gene translation, as well as protein synthesis  <cit> . these interactions are localized to the so-called "interaction sites" or "interface residues".

identification of these residues will allow us to understand how proteins recognize other molecules and to gain clues into their possible functions at the level of the cell and at the organism. it can also improve our understanding on disease mechanisms and further advance pharmaceutical design  <cit> . 3d  structures of proteins are the basis for the identification. however, resolving 3d protein structures by experimental methods, such as x-ray crystallography and nuclear magnetic resonance, is much more time-consuming than sequencing proteins. this is the reason why less than  <dig> protein structures are available in pdb databank  <cit>  while more than ten million proteins are sequenced in the uniprotkb/trembl database  <cit> , as of jan.  <dig>  to narrow the huge gap, various computational methods have been developed to predict protein structures, assisted by the abundance of protein information deposited in various biological databases. among them, methods to identify protein-protein interface residues have attracted research attention for a long time.

the pioneering work by kini and evans addressed the issue of protein interaction site prediction by a unique predictive method based on the observation that "proline" is the most common residue found in the flanking segments of interaction sites  <cit> . jones and thornton were aimed to analyze  <cit>  and predict  <cit>  surface patches that overlap with interfaces by computing a combined score that gives the probability of a surface patch forming protein-protein interactions. other works have addressed various aspects of protein structure and behavior, such as detecting patch analysis  <cit> , solvent-accessible surface area buried upon association  <cit> , free energy changes upon alanine-scanning mutations  <cit> , in silico two hybrid systems  <cit> , sequence or structure conservation information  <cit> , and sequence hydrophobicity distribution  <cit> .

among them, many machine learning methods have been developed or adopted, such as those using support vector machine   <cit> , neural network  <cit> , genetic algorithm  <cit> , hidden markov models  <cit> , bayesian networks  <cit> , random forests  <cit> , and so on.

numerous properties were used in previous work to identify protein-protein interactions. they can be roughly divided into two categories: sequence-based properties and structure-based properties. sequence-based properties include residue composition and propensity  <cit> , hydrophobic scale  <cit> , predicted structural features such as predicted secondary structures  <cit> , features from multiple sequence alignments  <cit> , and so on  <cit> . on the other hand structure-based properties were also widely utilized, such as the size of interfaces  <cit> , shape of interfaces  <cit> , clustering of interface atoms  <cit> , b-factor  <cit> , electrostatic potential  <cit> , spatial distribution of interface residues  <cit> , and others  <cit> . the existing methods using these properties showed good performance in the prediction of protein-protein interactions. however, those properties that are specifically significant for particular protein complexes have not been fully assessed. furthermore, a large set of properties do not always perform well.

since the amount of protein structures is significantly smaller than those of protein sequences determined by large-scale dna sequencing methods, it is important to identify protein-protein interaction sites from amino acid sequences alone. it is also valuable to use sequence-based features without experimental 3d structure information. actually, predicted structure features such as secondary structure can still be helpful to the identification of interaction sites  <cit> . however, sequence based approaches to identify protein interaction sites are still more difficult to those based on structure information. the reasons are in that:  the relationship between sequence-based features and protein-protein interactions are not fully understood;  how to represent each residue in a protein by a series of sequence-based features is difficult;  the unbalanced data between interaction samples and non-interaction samples may worsen the interface identification  <cit> .

this work addresses these issues by integrative features and by adopting an svm ensemble method based on balanced training datasets. since identification of interaction sites in hetero-complexes are much more difficult and more interesting than that in homo-complexes, in this work we focus on hetero-complexes. we first design a schema to represent each residue that integrates hydrophobic and evolutionary information of the residue in a complex. then an ensemble of svms is developed, where svms train on different pairs of positive  and negative  subsets. the subsets having roughly the same sizes are grouped in the order of accessible surface area change  before and after complexation. a self-organizing map  technique  <cit>  is applied to group similar training samples. this is aimed to make more accurate the identification of interface residues. an ensemble of ten-svms achieves an mcc improvement by around 8% and f <dig> improvement by around 9%, compared to those by three-svms. we also found that the svms ensemble always performs better than individual svms. moreover, using som technique achieves an increase of mcc by  <dig>  and an increase of f <dig> by 2%.

RESULTS
we calculated amino acid composition in our dataset to show the propensity information of the  <dig> amino acid types between interface and non-interface regions. the propensities for the  <dig> amino acid types in a logarithm  scale are shown in additional file  <dig>  results show that amino acids with smaller propensity values, such as 'a', 'g', and 'v', representing hydrophobicity, are always involved in non-interface regions. conversely, hydrophilic amino acids 'r', 'y', 'w', and 'h' often present in interface regions. some of these discoveries are consistent with other literature  <cit> . interestingly, arginine is the most frequently occurring residue in interface regions while cysteine and alanine appear in non-interface regions mostly.

determination of the sliding window length
a sliding window technique is used to represent each target residue in this study, where the most challenging issue is to represent each residue by a feature vector and further to construct a predictor. our first step is the determination of a good sliding window length since prediction performance is usually varied with window length l. the tradeoff between prediction performance and the algorithm complexity is also concerned. in this work three individual svms were selected from the ten-svms without som and therefore  <dig> possible combinations were obtained. the average performance of those svms was used to determine the window length. here five levels of window length,  <dig>   <dig>   <dig>   <dig>  and  <dig> were attempted. results show that a sliding window with  <dig> residues is sufficient to train and test our model, although the model with a window length  <dig> performed a little better than that with a window length  <dig>  however, the model performed faster than that with the window length  <dig>  the comparison of sensitivity-precision under different window lengthes is illustrated in additional file  <dig>  note that using a window length  <dig> leads to the worst performance. if not otherwise stated in this work, we adopt the window length  <dig> to evaluate our model and identify protein-protein interface residues.

prediction performance without som
additional file  <dig> shows the performance comparison among the combined svms as discussed above with three thresholds. because none of single measures can fully evaluate prediction performance, we just show all the evaluations on our predictor under six measurements. in this work, mcc and f <dig> are used as the main measures to evaluate our method. actually using mcc as a benchmark measurement may lead to cover less positive samples, while using f <dig> to achieve balanced performance between sensitivity and precision measures may lead to truly identify less positive samples. from this figure, svm with threshold  <dig> performs better than those with thresholds  <dig> and  <dig>  and achieves a sensitivity of  <dig> %, precision of  <dig> %, specificity of  <dig> %, accuracy of  <dig> %, and f <dig> of  <dig> % when reaching the largest mcc of  <dig> . in the case of benchmark measurement of f <dig>  additionally, our model with threshold  <dig> achieve s a sensitivity of  <dig> %, precision of  <dig> %, specificity of  <dig> %, accuracy of  <dig> %, mcc of  <dig> , when reaching the largest f <dig> of  <dig> %.

to fully understand the power of our method, we investigate the combination of all the ten-svms. figure  <dig> shows the performance comparison of the ten combined svms with different thresholds. the two types of performance curves illustrate the performance of sensitivity-precision and that of sensitivity-mcc, respectively. results from figure  <dig> show that the 5-th combined svm outperforms models with other thresholds. furthermore, combined svms with thresholds from  <dig> to  <dig> perform better than those with thresholds from  <dig> to  <dig> , while individual combined svm within the former or the latter groups yields similar prediction performance. however, combined svms yield similar precisions but different mccs when achieving sensitivities of more than 55%. table  <dig> shows performance comparison of the ten-svms before and after the combination. as for the ten-svms before combination, the first five svms perform better than the latter five ones probably because the differences of the average Δasas between training positive samples and negative samples for the former ones  are larger than those for the latter ones . it probably suggests that the larger the difference of the average Δasas between training positive samples and negative samples, the better prediction the model yields. in this case, our method also achieves a good prediction. the best mcc among the ten-svms is  <dig>  . statistically, the model with threshold  <dig> makes a good prediction and obtains the highest mcc of  <dig>   after combining the ten-svms, comparatively, the 4-th combined svm achieves the best f <dig> of  <dig> % .

*the subtraction between average Δasa for positive samples and that for negative samples.

**the above ten numbers from  <dig> to  <dig> stand for the ten-svms.

***the following ten ones stand for the combined svms with thresholds from  <dig> to  <dig> 

it is interesting to note that all models perform similarly if the training positive and negative subsets are respectively constructed by random selection without overlap. the details are shown in table  <dig> which lists the performance comparison of the ten-svms before and after the combination. in this case, the differences of the performance before combining the ten-svms are rather small probably due to containing similar average Δasas between training positive and negative subsets. comparison of such performance is meaningless but just listing them here not for ranking. actually these models also yield good predictions before combining them. in the case of random sample selection, the best mcc among the ten-svms is  <dig>  . after combining the ten-svms, the model with threshold  <dig> performs better than other models and obtains an mcc of  <dig>  , comparatively, the 4-th combined svm achieves the best f <dig> of  <dig> % . comparison between table  <dig> and table  <dig> shows that the model with sample selection in the order of Δasa and that with random sample selection perform similarly after the combination. moreover, when combining the svms, the model performs better and better with threshold from  <dig> to  <dig> and, becomes worse and worse with threshold from  <dig> to  <dig> as shown in both table  <dig> and table  <dig> 

*the above ten ones are for the ten individual svms.

**the following ten ones stand for the combined svms with thresholds from  <dig> to  <dig> 

however, another issue we would like to address is that why the models with random sample selection perform better than those with Δasas-sorted sample selection before the combination of classifiers and, surprisingly, why they perform similarly after the combination of classifiers. the reason is probably in that models have been trained efficiently with feasible Δasas distribution of training data compared to that of test data. furthermore, our results suggest that if the Δasas distribution of the training data is consistent with that of test data, a good prediction can be yielded.

in addition, the performance comparison under three levels of combined svms is listed in table  <dig>  among them, the model of combining ten svms outperforms that of combining three-svms and achieves improvement of mcc by  <dig> % and f <dig> by  <dig> %, while the best individual svm performs the worst among the three cases. it can be concluded that combining outputs of a number of independent classifiers can indeed improve classification rate since the errors made by a classifier can be corrected by the others. however, the best threshold needs to be thoroughly investigated and can be changed in different cases. in this study, the best threshold for 3-combined model is  <dig> and, 10-combined model with threshold  <dig> performs the best, when using mcc as a benchmark measurement.

*the best svm among the ten individual svms.

**average performance when combining three-svms selected from the ten-svms.

prediction performance with the use of som
due to the limitation of residue amount in proteins, adopting more neurons in som is not always a good idea to cluster the similar input vectors for residues. therefore in this work three kinds of soms,  <dig> ×  <dig>   <dig> ×  <dig>  and  <dig> ×  <dig> soms, were investigated. handling by the two modifications, the relatively less important neurons associated with a small number of samples and those neurons with relatively larger entropies were removed.

in the experiments by using the  <dig> ×  <dig> som and the combination svm classifiers, we constructed the same  <dig> ×  <dig> svm ensembles, trained and tested our model as above. we obtained  <dig> clusters in total. clusters from  <dig> to  <dig> and clusters from  <dig> to  <dig> were retained. performance by averaging the retained clusters is shown in figure  <dig>  results show that the model with threshold  <dig> outperforms others and achieves the largest mcc of  <dig>  and f <dig> of  <dig> %. furthermore, it can be found that the 5-th combined svm performs the best when precision is larger than 50% and, the model with threshold  <dig> makes the best prediction when sensitivity is larger than 50%. the tendencies of sensitivity-mcc curves are almost the same as those of sensitivity-precision curves.

the model with the  <dig> ×  <dig> som were also constructed and evaluated on the same dataset. a very small improvement was achieved in comparison to the model with the use of  <dig> ×  <dig> som. table  <dig> demonstrates the performance comparison among the combined svms by the use of the three kinds of soms. the model with  <dig> ×  <dig> som outperforms others. it should be noted that the model without som also makes a good interface prediction and yields the largest mcc of  <dig>  and f <dig> of  <dig> % as illustrated in figure  <dig>  additionally, the case of  <dig> ×  <dig> som by combining three-svms is also shown in table  <dig>  where clusters  <dig>   <dig>   <dig>  and  <dig> with small number of vectors and clusters  <dig> and  <dig> with larger entropies were removed. in this case, the model with threshold  <dig> performs better than that of combining three-svms without som and makes a small improvement of f <dig> by 1%, however, it performs much worse  than the models with the same som by combining the ten-svms.

*evaluation by combining three-svms.

improvement by using evolutionary context of residues with respect to hydrophobicity
kauzmann  <cit>  first pointed out that hydrophobic effect is the most significant property of protein folding and stability. as for the interface prediction, it is often a major contributor to stabilize protein complexes  <cit> . gallet et al. proposed a fast method to predict protein interaction sites by analyzing hydrophobicity distribution  <cit> . this work suggested that interface residues can be identified by using the mean hydrophobicity and the mean hydrophobic moment. however, it appears that the hydrophobic effect alone is insufficient to the protein interface prediction  <cit>  or does not appear to be useful for the interface prediction.

in this work, we used two feature profiles, sequence profile and hydropathy scale. the former was extracted from the hssp database  <cit> , where each amino acid is represented by elements whose values are based on multiple alignments of protein sequences and their potential structural homologs. the latter was adopted from kyte-doolittle's measurement  <cit> . despite the two profiles have been used before in interface prediction, the novel integrative technique here can discover the residue's evolutionary context with respect to hydrophobicity in protein-protein interacting sites. it can thus be helpful to improve the interface prediction.

the difference between the integrative profile and each individual profile is that in equation  <dig>  one profile term would be removed for the model keeping only one profile left. the three pictures in figure  <dig> illustrate the interaction identification results by the use of the three profiles: hydrophobic scale, sequence profile, and the integrative profile. from the figure  <dig>  results show that the model with the integrative profile outperformed the other two, and predicted interface sites more accurately. in addition, the model with sequence profile alone performed better than that with hydropathy scale alone.

to demonstrate the power of the integrative technique, performance for the models with the three profiles are also calculated as discussed above. table  <dig> presents the performance comparison for combined svms with threshold  <dig>  it can be found that svm ensembles, whose feature vectors integrate residue sequence profile with hydropathy scale, outperforms the model based on hydropathy scale or sequence profile alone . moreover, the model with hydropathy scale performs the worst and therefore it cannot be applied to distinguish protein interface residues alone. the performance improvements here indicate that the information contained within the residue sequence profile and the hydropathy scale may be complementary, and that exploiting the complementarity is helpful for predicting protein interface residues.

a biological case of improvement by classifier ensemble
classifier ensemble might perform well in many classifications. combining the outputs of a number of independent classifiers can improve classification rate since the errors made by a classifier may be corrected by the others  <cit> . hansen and salamon  <cit>  denoted that better performance can be achieved by using the optimizational parameters and training different classifiers on different portion of the dataset. in this work, we applied the classifier ensemble technique to combine the outputs from the ten independent svm classifiers whose training datasets are non-overlapped and thus independent to each other.

discussion
comparison with other methods
due to different datasets and definitions on interface residues adopted by existing methods, it is very hard to compare prediction performance among different methods. to compare with the current state of the art of protein-protein interaction prediction, we tested on the same dataset and adopted the same definition of interface residues as literature  <cit> , where the dataset was from literature  <cit> . this dataset consists of  <dig> chains in  <dig> complexes. figure  <dig> shows the comparison of sensitivity-precision performance between our model and the sikic's method based on sequence alone  <cit> . additionally, the performance of a random predictor is also affiliated in figure  <dig> as reference. in the case of precisions above 90%, our model achieves sensitivities slightly below 30% while sikic's method achieved sensitivities around only 5%. in the case of precisions from 70% to 80%, sikic's method achieved a sensitivity level of about 25% while our model reaches sensitivities near to 45%. in these cases our model performs better than sikic's method based on sequence alone and even better than its prediction based on both sequence and 3d structure . for precisions from 30% to 70%, our model also outperforms sikic's method based on sequence alone and makes a little worse prediction than that based on both sequence and 3d structure.

actually, using true secondary structure information and other real 3d structure information in sikic's method may lead to overestimate the interface predictions, although it obtained a little higher precision than our model with sensitivities from 50% to 90%. therefore, we just show the performance curve of sikic's method based on both sequence and real 3d structure, with no purpose of comparison. however, as discussed in figure  <dig>  our model with threshold  <dig> performs similar to sikic's structure-based model when achieving sensitivities from 50% to 90%. it should be noted that our model and sikic's method share the same definition of interface residues and therefore obtains approximately the same ratio of interface residues to total residues,  <dig> % in our dataset and  <dig> % in sikic's method. as a result, our method outperforms sikic's method based on sequence information. furthermore, our method based on sequence alone performs similarly to sikic's method based on both sequence and 3d structure.

next we discuss the comparison results with other methods whose datasets have different interface fractions, defined as percentages of the total number of protein residues. table  <dig> shows the performance comparison of these methods on hetero-complex datasets with sequence alone. in recent years, random forests made a good performance in protein structure prediction, especially in the protein-protein interaction prediction, which is an ensemble method that combines individual classification trees from several bootstrap samples. chen and jeong applied random forests in interface prediction and obtained a good f <dig> of 49%  <cit> , while sikic et al. used random forests and achieved an f <dig> of  <dig> % based on sequence alone and achieved an f <dig> of 52% based on both sequence and 3d structure information  <cit> . our previous work also achieved a good prediction of protein-protein interface residues based on  <dig> proteins by the use of svm and evolutionary rates of residues  <cit> . note that the comparison aims to demonstrate the development of the protein interaction prediction tools, with no purpose to rank them since predictors were developed based on different datasets, different definitions of interface residues, and different evaluation measurements. although it is extraordinarily difficult to compare among related methods, our method outperforms others as shown in table  <dig>  as a result the model by the integrative profile is a very promising approach to predict interface sites.

*based on homo-hetero mixed complexes dataset.

**the ratio of interface residues to surface residues.

***estimated.

****random forests.

*****neural network.

blind test
to show the potential of our model to practical problem, a ccd-ibd complex  was taken as a test case. again the evaluation of this blind test is based solely on sequence information without knowing 3d structure of the complex and the true interacting residues.

the asymmetric unit of the complex pdb:2bgn contains two molecules, a dimer of integrase  catalytic core domains   and a pair of human lens epithelium-derived growth factor  in-binding domain  molecules   <cit> . ledgf binds hiv- <dig> in via the small ibd within its c-terminal region. previous results showed that the ibd is both necessary and sufficient for the interaction with hiv- <dig> in  <cit> . there are several key intermolecular contacts at the ccd-ibd interface. residues ile <dig>  asp <dig>  and phe <dig> play critical roles in hiv- <dig> in recognition as hotspot residues which are located at the interhelical loops within ibd molecules . the water molecule hydrogen-bonds link to the main-chain carbonyl group of ledgf residue ile <dig> and in residue thr <dig>  we correctly predict the hotspot residues ile <dig> and asp <dig>  overall, our method achieves a good prediction performance with a sensitivity of  <dig> %, precision of  <dig> %, specificity of  <dig> %, accuracy of  <dig> %, and f <dig> of  <dig> % when achieving the largest mcc of  <dig> . in order for more correct predicted interface residues, our model can obtain a precision of  <dig> % with a sensitivity of  <dig> %, specificity of  <dig> %, accuracy of  <dig> %, f <dig> of  <dig> %, and mcc of  <dig> . in this case the hotspot residues ile <dig> and asp <dig> are also predicted correctly.

CONCLUSIONS
this paper addresses the problem of identifying interface residues in hetero-complexes by using an integrative profiling. this novel profile combines residue sequence profile with hydropathy scale and, therefore obtains standard deviation value for each residue in proteins. the deviation value may reveal the evolutionary relationship of a residue in proteins and hydrophobicity in water surroundings. the novel residue profile and an ensemble of svms together achieves a good prediction in protein-protein interactions with a sensitivity of  <dig> %, precision of  <dig> %, specificity of  <dig> %, accuracy of  <dig> %, and f <dig> of  <dig> % when achieving the largest mcc of  <dig> . in addition, som technique is adopted to investigate the interacting relationship of residues. when the som technique is used, the prediction performance increases to a sensitivity of  <dig> %, precision of  <dig> %, specificity of  <dig> %, accuracy of  <dig> %, and f <dig> of  <dig> % when achieving the largest mcc of  <dig> .

moreover a residue in our work was represented as a 1-by- <dig> vector by using the sliding window with length  <dig>  the scale is much smaller than most other methods. the input vector for representing a residue used in sikic et al.'s method contained  <dig> ×  <dig> =  <dig> elements and,  <dig> features were used as input vector in chen and jeong's method. therefore our model is very fast and simple. more importantly, a larger number of features in input vectors does not necessarily lead to a better performance. as pointed out by previous work, a machine learning algorithm adopting a simple representation of a sequence space could be much more powerful and useful than using the original data containing all details  <cit> . actually biological properties which may be responsible for protein-protein interactions are not fully understood. therefore how to apply feasible features or feature transformations in protein interaction prediction remains an open problem. additionally imbalanced data of interface residues and non-interface residues is a very challenging issue, which always causes classifier over-fitting. the ensemble of classifiers may be a feasible pathway to balance training data.

finally, residue's evolutionary context with respect to hydrophobicity plays an important role in the interface prediction. above discussion appears to suggest that integrating residue's evolutionary context with other properties of residues, such as residue volume or free energy solution in water, is a plausible way to discover the protein-protein interactions. in our future work, we will investigate the inner relationships of interacting residues, and make use of them for a more accurate prediction.

