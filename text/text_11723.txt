BACKGROUND
the last decade has witnessed a rapid development in dna sequencing by the introduction of next generation high-throughput dna sequencing  <cit>  technologies. the equipment based on that new technology produces billions of reads in a single day per machine  <cit> . the most important two problems regarding the dna sequencing are alignment and assembly  <cit> . if the target specie has not been sequenced before, a de novo dna assembly  <cit> , which requires concatenation of the reads in an optimum way, has to be performed. otherwise, reads are mapped against a reference genome that is the result of a previous sequencing effort of the same specie. with the advent of the next-generation sequencing, various short read aligners such as bowtie  <cit> , perm  <cit> , soap  <cit> , mrs-fast  <cit> , and many others have been proposed in the last three years. in a recent study, li and homer  <cit>  surveyed short read aligners in general.

many strategies have been applied to perform the alignment process fast and accurately. while some of the aligners index the reference genome, some others rely on hash tables based on q-grams or spaced seeds to perform a quick scan. although hash-based solutions are more flexible in detecting approximate matches, indexing solutions are faster. the dominant solution in genome indexing is the burrows-wheeler transform   <cit>  of the reference sequence , in which the reads are searched with the backwards search algorithm introduced in fm-index of ferragina and manzini  <cit> .

we concentrate on indexing the genome via sparse suffix arrays . lexicographic ordering of all the suffixes of the text forms the suffix array  <cit> , which is a well-studied data structure initially proposed to lower the space requirement of the suffix tree. although suffix arrays are much more space-preserving than suffix trees, they still require large memory space for indexing massive data such as the whole genome of a human. the space consumption of an ordinary suffix array for a given text of n characters is o. the occurrences of a pattern of length m characters can be found in o time by searching the pattern on the suffix array by binary search procedure. this bound can further be improved to o time by using auxiliary data structures  <cit> .

it was long believed that compressing a suffix array is not feasible since it is mainly a permutation of the numbers from  <dig> to n. grossi and vitter  <cit>  refuted that belief and showed that suffix arrays are compressible. following that work, compressed data structures in text indexing gained greater focus within the community  <cit> . these efforts resulted in showing that an index for a text can occupy space proportional to the compressed size of the text itself. however, if it is not possible to significantly compress the input data, as is the case for dna sequences, these methods do not provide a considerable advantage.

recently, chien et al. <cit>  proposed sparsíficatíon of the suffix array as an alternative method to compress it. the key idea is that instead of sorting all the suffixes beginning from each position  <dig> to n of the text, a sorted list is created of the suffixes that begin at positions p, such that p mod d =  <dig>  for all  <dig> ≤ p ≤ n, where d denotes the sparsification factor. as a result, we have a list of n/d numbers in the sparse suffix array rather than n numbers in the original suffix array. we interpret the text with a new alphabet by combining each d contiguous original characters into a meta-character. the length of the text is now n/d meta-characters. thus, the space consumption decreases to o log).

the main two drawbacks of the sparse suffix arrays are i) the necessity to run the search procedure d times, and ii) a complicated search procedure when the queried pattern length is less than d. the necessity to run the search procedure d times comes from the fact that the queried pattern may begin at some position s, where the value s mod d can be any one of d different values. thus, d appropriate alignment positions should be checked one by one .

when the pattern length is shorter than the sparsification factor d, then the meta-characters, which are d ordinary characters in length and may include the queried pattern, must be investigated first. specified meta-characters should then be located on the text to finalize the actual search , which is not so elegant.

on the other hand, we have two advantages to overcome these drawbacks, in particular for the short read alignment problem. first, today's multicore processor architecture enables parallelism more than ever. we can benefit from multicore architectures to decrease the overhead in repeating the search procedure d times. second, next-generation sequencing machines have a lower bound on the length of the reads. short reads are in range from  <dig> to  <dig> base pairs , and it is foreseen that lengths will be longer in a couple of years. thus, if we choose the sparsification factor d less than the minimum possible length of the input reads, we do not need to deal with short pattern case anymore.

recently, khan et al. <cit>  proposed using sparse suffix arrays for finding maximal matches in large sequence data along with an application on short read alignment. their study considers only exact matching of the reads. although it is argued in some studies  <cit>  that exact matching would be enough for short read alignment, an approximate alignment of a queried pattern would help on reducing the total number of required reads  for whole sequencing. that is because the percentage of aligned reads will be lower if we neglect approximate matches.

based on the fact that errors are more probable towards the end of the reads, we extend exact matching with sparse suffix arrays to include any number of mismatches by defining the rightmost mismatch criteria. we prioritize the errors on the right-hand side of the reads, and detect the k-mismatch alignments sorted according to their rightmost occurrences in an elegant way. when equipped with mismatch detection capability, sparse suffix arrays serve as a good alternative to bwt-type genome indexing, as shown by experimentally comparing the proposed sparse suffix arrays against bwt-type genome indexing.

methods
aligning with exact matches
let g = g0g1g <dig> … gn–1$ be an n-base-long dna sequence, where each base gi is from alphabet Σ = {a, c, g, t} and the end of the sequence is marked with a special character $ that is lexicographically smaller than all the characters in Σ. if we denote the n suffixes of such a given sequence by s <dig> to sn– <dig>  then the ith suffix si will correspond to si = gigi+1…gn–1$. the lexicographical sorting of those suffixes creates the suffix array a = a0a1…an– <dig> such that ai is the beginning position of the ith smallest suffix of g, for  <dig> ≤ i <n.

the sparse suffix array  of g includes only those ai numbers in suffix array a that are multiples of a specific number d; that is ai mod d =  <dig>  in other words, rather than sorting all the suffixes of g, we sort only those suffixes si, where i mod d =  <dig> and keep their starting positions divided by d in ssa. we refer to d as the sparsification factor. figure  <dig> depicts the suffix array and the sparse suffix array of an example sequence aggtcgattcgggacc. the first element of the suffix array is a <dig> =  <dig> as s <dig> = acg$ is the smallest among all suffixes of g. when we want to sparsify that suffix array with a factor of d =  <dig>  we take only those points from a where ai mod  <dig> =  <dig>  we preserve their order of appearance in the original suffix array. thus, the sparse suffix array of the given g is ssa = { <dig> , <dig> }.

the space required by a sparse suffix array of a sequence of length n characters is o log). when d =  <dig>  this complexity converges to that of the ordinary suffix array. the decrease in the size of the index comes with a cost in the search complexity.

the time complexity to locate all possible occurrences of queried pattern p on a sequence of length n using the ordinary suffix array is o. when we use the sparse suffix array, however, the same procedure only lets us detect those occurrences starting at positions that are multiples of d because ssa includes the sorted list of the suffixes beginning only on those locations. we also need to consider the cases where p starts at positions that are not divisible by d.

given a pattern p = p0p1…pm– <dig>  where d ≤ m ≤ n, let  denote the initial i characters and  show the rest. if we search  on g via the ssa for each  <dig> ≤ i <d, and then verify whether g has the corresponding  preceding the positions where  appears, we can locate all possible occurrences. algorithm  <dig> describes this procedure.

the time complexity of exact match via ssa is o +  log + o <dig> ·  <dig> +  log + o <dig> ·  <dig> + … +  log + od– <dig> · ), where oi is the number of occurrences of  on g. the terms beginning with oi in the summation correspond to the verification cost. thus, total time may be approximated as o+ verification). note that increasing sparsification factor d decreases the space complexity while increasing the time complexity. this gives us the flexibility to tune d according to the available processors and memory.

aligning with mismatches
reads may contain some errors. although today's sequencing machines produce quality values that represent the confidence of the individual bases in each read, these values vary greatly and require a fine-tuning step to be integrated into the alignment process. using these quality values also decreases the speed of the alignment  <cit> . in general, the errors are more probable towards the end of the reads; hence, we define the rightmost criteria to prioritize these positions and find the k-mismatch approximate matchings of a given pattern.    

let a given pattern p = p0p1…pm– <dig> be aligned with the text segment gigi+1…gi+m– <dig>  for some i,  <dig> ≤ i ≤ , and b = b0b1…bm– <dig> be a binary number of m bits such that, for all j,  <dig> ≤ j <m, if pj = gi+j, then bj =  <dig>  else bj =  <dig>  the total number of 0-bits in b is the total number of mismatches between p and g. among the possible -mismatch alignments of p onto text g, the ones having the highest b numbers are defined as the rightmost k-mismatch alignments of p. figure  <dig> depicts this definition.

when we search a pattern by using the suffix array, the process returns a range r =  that means p starts at text positions ga, ga, …, ga. if there are no occurrences of p on g, then ep is one less than sp . in that case, either the g,…, a + m – 1] or g,…, a + m – 1] have the longest match with p. that is because the suffix array is a sorted list of the suffixes, and since we are running a binary search on the suffix array, the final position is the closest point to the pattern, if not itself exactly. we compare p against both and find for each the number of matching nucleotides from the left side until we encounter the first mismatch. we denote the maximum of these two numbers as l, meaning the length of the longest matching prefix of p. that indicates p does not occur in the text for all j ≥ l, while the prefixes p exist for all i <l.

for example, let's assume sample pattern aggtcgattcgggacc does not occur in the reference genome, and we detect that the length of the longest matching prefix is l =  <dig>  which indicates the prefix aggtcgattc exists in the text, but the longer prefixes aggtcgattcg, aggtcgattcgg, …, aggtcgattcgggacc do not. if we attempt to alter the sample pattern's last base c to any of the a, g, or t, none of them will report a match since we know the nonexistence of its prefix aggtcgattcgggac. similarly, changing the previous base c also does not make sense as aggtcgattcggga is absent in the reference. the first base that has a chance to match when altered is p <dig> = g preceded by the prefix aggtcgattc that occurs in the text. thus, when looking for the 1-mismatch alignment of the sample read, we don't need to spend time to check possible alternatives of the last five bases.

remembering the fact that k-mismatch alignments are 1-mismatch apart from the -mismatch alignments, we can generate the 2-mismatch patterns from the 1-mismatch cases, and keep going up to k-mismatch alignments. this procedure ensures the rightmost mismatch criteria.

algorithm  <dig> depicts the k-mismatch idea in pseudocode. we keep possible alterations of original p in a list  consisting of three attributes. the first one is the altered pattern. the second attribute is the list of the altered positions that are used in sorting the alterations according to rightmost mismatch criteria. note that this inner list contains k numbers for k-mismatch alterations because a k-mismatch occurrence requires changing k positions. the third one is the offset indicating the length of the head of p as it is required in the sparse suffix search process. after initializing the α-list for the 1-mismatch case within the first for loop, we generate the possible k-mismatch alterations of p sorted according to the rightmost mismatch criteria by the second for loop, and then search the exact occurrences of those altered patterns on g by using the proposed ssa index.

aligning in parallel
indexing via ssas gives users the opportunity to decrease the size of the index according to the preferred sparsification factor d. however, the search process should consider the possible d offset alignments of the queried pattern as described earlier in the proposed method, which causes an increase in the time complexity with a factor of d. the procedure to check each offset-i, for  <dig> ≤ i <d, is independent from each other and, hence, can be executed concurrently in a multiprocessor environment. assuming a system with p processors, if the sparsification factor is chosen to be d ≤ p and each offset-i search is run separately in the dedicated processor, then the increase in the time complexity can be reduced significantly in practice.

it is noteworthy that data level parallelism is always possible by distributing the number of entities among available processors. such a multi-thread execution is nearly supported by all aligners. on the other side, algorithmic level parallelism is not that simple to achieve. by algorithmic parallelism we mean the case that even a single query is to be executed in parallel. the search mechanism of ssas serves as a good basis for algorithmic level parallelism due to its structure partitioning the search process into d number of offset-i investigations. thus, it is possible to parallelize even a single search query by dedicating an individual processor to each offset-i search. however, when the number of patterns is large, as is the case in a dna alignment problem, it might be more advantageous to prefer data-level parallelism and simply partition the patterns among processors. in a scenario where a server is answering pattern matching queries arriving sequentially, algorithmic level parallelism will be more appropriate.

implementation
we have implemented Ψ-ra in c++ language based on the proposed method and used gnu compiler g++ with all optimization flags turned on. the index of a reference genome in Ψ-ra has two parts. one is the sequence itself coded in 2-bit format; the other is the sparse suffix array of the sequence with a given spar-sification factor. we use yuta mori's implementation  of the sais  <cit>  algorithm for constructing the sparse suffix array. initially we run sais on the 2-bit coded sequence that actually produces sparse suffix array with d =  <dig> as each byte is composed of  <dig> bases. according to the input d parameter, we extract the required ssa from the one with d =  <dig>  the input d parameter should be a multiple of  <dig> in the current implementation.

as an example, the size of the whole human genome, which has approximately three billion bases, is about 700mb in 2-bit format. if d =  <dig>  ssa requires storing one-eighth of the three billion positions, which is roughly 325k numbers. since we store each number as a 32-bit integer, ssa for d =  <dig> needs approximately  <dig> gb of memory. thus, the total size of the index becomes  <dig> gb including the original sequence.

the backbone of Ψ-ra is the binary search over the ssa. we use a trick to speed up the search process on the suffix array. we partition the suffix array according to an initial k =  <dig> bases. that is, we store the range of each 8-gram on the ssa as a separate table that has  <dig> = 64k rows, where each row includes the starting and ending positions of the corresponding item on the ssa. when we search the pattern acgttgcaggtca on the ssa, as an example, we first fetch the range of the first eight bases acgttgca from the table and then run the ordinary binary search on that interval instead of the whole array. this trick decreases the time complexity o of binary search to o) along with the additional cost of storing the table of size o.

Ψ-ra supports k-mismatch search for any k value, but having larger k values requires longer times, as in other aligners. the difference is Ψ-ra returns the queried number of alignments sorted in rightmost mismatch criteria and guarantees to find them, as opposed to some aligners sacrificing accuracy for speed. the implementation of the k-mismatch search is an optimized version of the algorithm depicted in algorithm  <dig>  Ψ-ra software can be downloaded from http://www.busillis.com/o_kulekci/psira.zip for academic or noncommercial purposes.

RESULTS
the reads used in all experiments were collected from the srr <dig> experiment that is available from the sequence read archive at http://www.ncbi.nlm.nih.gov/sra. we mapped randomly selected 100k reads of various lengths from srr <dig> onto the complete human genome grch <dig> that is available at the site of genome reference consortium . all experiments were executed in a multiprocessor system of eight intel xeon  <dig>  ghz processors having a shared 32gb memory. the operating system was gentoo running the linux kernel  <dig> . <dig> 

we created the sparse suffix array-based indexes of the reference genome with sparsification factors of  <dig>   <dig>   <dig>  and  <dig> according to the proposed methodology. the index sizes of Ψ-ra, Ψ-ra, Ψ-ra, and Ψ-ra, where Ψ-ra refers to Ψ-ra with a sparsification factor of d, are  <dig> gb,  <dig> gb,  <dig> gb, and  <dig> gb respectively. note that these values all include the 700mb complete human genome in 2-bit format.

ssas give us the opportunity to tune the size of the index according to available memory by defining the sparsification factor d. a larger d value results in a smaller index size, but the computation cost increases as we need to consider offsets from  <dig> to d –  <dig>  figure  <dig> exhibits this trade off. the same queries were executed both with a single thread and with eight threads. it is observed that the gain in space is directly reflected in increased computation time, as expected. the increase in time can be compensated for with parallel execution of the software. since today's processors in general have multiple cores, we can work with smaller-sized indexes and receive the same performance as if using a larger one. sparse suffix arrays with larger sparsification factors match the performance of the smaller ones by benefiting from multicore architecture. for example on all cases, eight-core running of Ψ-ra is faster than single processor running of Ψ-ra index.

two widely used techniques in genome indexing are burrows-wheeler transform and seed-based hash tables. we compared Ψ-ra with bowtie  <cit>  and soap <dig>  <cit> , as the two successful representatives of bwt genre, and with perm  <cit>  and mrsfast  <cit> , which are based on spaced seeds and ordinary q-grams respectively. the index sizes of those aligners are  <dig> gb ,  <dig> gb ,  <dig> gb , and  <dig> gb . the exact matching performances of the tested aligners on mapping 100k reads against complete human genome are shown in figure  <dig>  the speed of the mrsfast was not competitive with the other aligners and hence it is not plotted.

short read aligners have different strategies and hence different parameters to perform matching. although it is very difficult to make a fair benchmark, we compare the speed of Ψ-ra against bowtie  <cit> , which is one of the fastest aligners, to provide a comparison on the exact and also approximate matching performance. figure  <dig> shows the results of the comparison. on exact matching and 3-mismatch, Ψ-ra represents a better performance, where bowtie is faster on 1- and 2-mismatch cases. we should note that although bowtie does not guarantee the results for the 2- and 3-mismatch cases, Ψ-ra finds all occurrences.

CONCLUSIONS
indexing dna sequences requires much memory. it is not possible to benefit much from the compressed indexes because of the random structure of the dna sequences. as an alternative method of generating small size indexes of biological data, we focused on sparse suffix arrays and developed an aligner named Ψ-ra.

Ψ-ra is very fast on exact matching because of its cache-friendly structure. in addition to the speed caught in exact matching, we also integrated an elegant k-mismatch alignment capability by defining the rightmost mismatch criteria. the k-mismatch alignments of a queried read are reported according to the position of the mismatches, where being on the right is prioritized because the sequencing machines tend to generate erroneous bases particularly toward the end of the reads.

the size of a sparse suffix array changes with the chosen sparsification factor d, such that larger values result in smaller sized indexes. on the other hand, large sparsification factors worsen the time complexity of the processing. we showed experimentally that by applying parallelism in contemporary processor architectures, small-size indexes having large d match the performance of the large size indexes that have smaller d values. Ψ-ra gives users the flexibility to tune the size of the index according to the available resources. the index will fit in the main memory at the cost of increased computation time. that increase can be avoided up to some level in practice by benefiting from multicore processors.

authors contributions
drs. m. oğuzhan külekci and bojian xu drafted the manuscript. the implementation and experiments were done by dr. m. oğuzhan külekci. all authors contributed to the technical content of the study, including the algorithms for exact matching. drs. jeffrey scott vitter, m. oğuzhan külekci, and bojian xu worked on approximate matching. all authors read and approved the final manuscript.

competing interests
the authors declare no competing interests.

acknowledgments
thanks to the authors of bowtie, soap <dig>  perm, and mrsfast for providing the source code or executables of their softwares. part of this work was done while drs. külekci, vitter, and xu were at texas a&m university. support for dr. m. oğuzhan külekci was provided in part by u.s. national science foundation research grant ccf- <dig> and the turkey tubitak-bideb  <dig> programme. support for dr. wing-kai hon was provided in part by taiwan nsc grant 99-2221-e-007- <dig>  support for drs. rahul shah, jeffrey vitter, and bojian xu was provided in part by u.s. national science foundation research grants ccf- <dig> and ccf- <dig>  the preliminary version of this article has been published in the proceedings of the ieee international conference on bioinformatics & biomedicine, hong kong, china,  <dig> 

this article has been published as part of bmc genomics volume  <dig> supplement  <dig>  2011: selected articles from the ieee international conference on bioinformatics and biomedicine  <dig>  the full contents of the supplement are available online at http://www.biomedcentral.com/1471-2164/12?issue=s <dig> 
