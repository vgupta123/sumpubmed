BACKGROUND
in the uk in  <dig>  97% of farmers reported lame sheep in their flock with an average within flock prevalence of 10%  <cit> . footrot is the main cause of lameness and foot lesions in sheep in the uk  <cit> . dichelobacter nodosus is the essential organism for causing footrot, other organisms especially fusobacterium necrophorum are thought to play an important role in the pathogenesis of footrot  <cit> . the clinical presentation of footrot is highly variable and ranges from mild interdigital inflammation  to under-running of horn with a characteristic smell . long term disease with footrot  <cit>  and poor foot trimming  <cit>  can alter foot integrity.

a diagnosis of footrot can be made using culture or pcr from swabs taken from the hoof horn junction  <cit> . however, these laboratory methods are not completely reliable. d. nodosus requires complex media for culture with strict anaerobic conditions  <cit> , and while 16s rrna pcr is more rapid and sensitive than culture it is still far from 100% sensitive  <cit> . as a consequence, diagnosis using visual observation of the foot without further laboratory tests is commonly used by researchers and clinicians once d. nodosus is endemic in a flock. visual diagnosis may include a system to score the severity of the footrot lesion. a commonly used system to score footrot is an australian system with five ordinal scores  <cit>  . in the uk, in addition to scoring footrot, a  <dig> point ordinal scoring method to score foot integrity has been used  <cit> . these scoring systems have been used by researchers  <cit>  to study the epidemiology, pathogenesis, treatment, control and economic losses attributable to footrot. however, the between and within observer reliability of a scoring method for foot integrity has not been formally tested. one study  <cit>  investigated agreement of a footrot scoring system between two trained observers and reported a high level of agreement, but the study had 85% of lesion score  <dig>  out of  <dig> sheep. the study provided no information on when the observers disagreed or where  the disagreement lay.

the reliability of a numeric scoring system is the generalizability  of the results across scoring situations and judges  <cit> . to evaluate this, reproducibility  and repeatability  are estimated  <cit> . in both the medical and veterinary fields, an ordinal score is often used to evaluate the severity of a disease  <cit> . the observer agreement for such ordinal data is commonly provided by a single measure of agreement e.g. weighted kappa coefficients  <cit>  or kendall’s coefficient of concordance  <cit> . these do not provide information on components of disagreement such as observer bias  or differences in thresholds and therefore category widths for the ordinal scale. there is one study by thomsen et al.  <cit>  that tested whether the category widths used by observers for an ordinal scale were equidistant by calculating a polychoric correlation. but this approach only compared two observers and did not provide an estimate for observer bias.

modeling techniques have been described to evaluate observer agreement for ordinal scores. these include log linear models  <cit> , association models  <cit>  and latent trait and latent class models  <cit> . both log linear and association models have been designed to compare only two observers and there are issues with interpretation of relative magnitude of some of the parameters used  <cit> . latent trait and latent class models have been designed for multiple observers and have been used in the medical field  <cit>  to quantify agreement with multiple observers. these models explore agreement by testing whether there is observer bias and give a visual representation of the observers’ perceived impressions of the scores on a continuum, thus indicating the threshold and width of score categories, for example, for a  <dig> to  <dig> category scale, the first threshold is the point from which an observer applies score  <dig> and below that would be score  <dig>  the second threshold the point from which an observer applies score  <dig> and so on. to our knowledge such modeling approaches have not been used to evaluate observer agreement for ordinal categories in the veterinary field. in the current paper, observer agreement of scoring systems for footrot  and foot integrity  in sheep is evaluated and explored using two approaches, weighted kappa and located latent class modeling.

methods
scoring systems
we used a five point ordinal the scoring system  proposed by egerton and roberts  <cit>   to score photographs and videos of footrot and a four point ordinal scale to score foot integrity proposed by kaler et al.  <cit>  .

study design
videos and photographs of footrot lesions
 <dig> video clips of sheep feet with footrot scores ranging from 0– <dig>  were made on farms with informed consent from farmers in the uk, sardinia and india. videos were recorded using a jvc  or a sony camcorder  and edited using movie maker . eighty videos clips were selected that included the range of scores . eighty photographs were made from snapshots of footrot lesions from the video clips. the identification number for the video and picture of the same footrot lesion were different.

feet with different foot integrities
a total of  <dig> sheep feet were collected from an abattoir over two weeks. feet were washed and then stored at −20°c. a total of  <dig> feet with the range of integrity scores were selected. feet were removed from the freezer and left overnight to thaw before being scored.

data collection
three observers with some previous experience of scoring feet were selected. observers were trained for one hour before they were tested. they scored footrot  from the  <dig> photographs and videos which were given to them on two cds. each photograph was shown for five seconds with a four second lag between each photograph and each video lasted 20–25 sec with four seconds lag between each video clip. on day  <dig>  the photographs were scored twice  by observers with a gap of  <dig> hours between the two scorings sessions. on day  <dig>  observers scored videos twice with a gap of  <dig> hours between the scoring sessions.

observers scored the integrity of the soles and walls  of the  <dig> digits in a preparation room. they had  <dig> seconds to examine and score each digit. they repeated the scoring after an interval of  <dig> hours. observers did not discuss their observations with each other.

statistical analysis
data were entered in microsoft excel  and analysed using stata  <dig>   and llca  <cit> .

weighted kappa
the weighted kappa  was calculated within observers and between pairs of observers. the kw values were interpreted according to landis and koch  <cit> , 0 = poor,  <dig> – <dig>  = slight,  <dig> – <dig>  = fair,  <dig> – <dig>  = moderate,  <dig> – <dig>  = substantial and  <dig> –1 = almost perfect.

located latent class analysis
to investigate components of disagreement a located latent class analysis as described by uebersax  <cit>  was performed. the located latent class model works on the theoretical principle that there is a unidimensional continuum of a latent trait θ that is a basis for ratings which is assumed to range from -∞ to ∞. the latent trait in the current study was the ordinal scoring scale. different ordinal categories  of the scoring scale were represented as latent classes  which presented themselves as discrete locations on this continuum and were assumed to correspond to the true latent trait level . each observer  had i- <dig> ordered thresholds  on this continuum which was the observer’s perceived impression  of an ordinal category. for the  <dig> to  <dig> category scale, there are three thresholds 0– <dig>  1– <dig> and 2– <dig> and similarly for the  <dig> –  <dig> ordinal scale there are four thresholds. due to measurement error α , the apparent trait levels of latent class c varied from βc. the model took the form:

  φcr={1+exp[− <dig> αr is the logistic cumulative density function of the apparent trait level of latent class c for observer r. the model was run in llca fortan  <cit>  and maximum likelihood was used to quantify observer bias  and category widths . two sub-models were created by adding constraints to the basic model  to test whether there was significant observer bias and significant differences in ordinal category widths for between and within observers. sub-models were defined:

  tir=Δr+δir 

where Δr was the mean threshold of observer r and δir was the deviation of threshold tir from Δr. in the first sub-model , to test observer difference in category widths, a constraint was applied by restricting δi1=⋯δir so that category widths were the same across the observers and observers differed by an overall bias. this was nested in the basic model  and compared. for the second sub-model  Δ1=⋯Δr,  was restricted and this model was nested in the simple bias model and compared. a likelihood ratio chi-square test was used to compare both sub-models; p-values < <dig>  were considered significant. estimated threshold locations with bias parameters and confidence intervals were compared. further details of the methodology of llca are presented in ubersax  <cit> . for between observer agreement, observers 1st scores were used.

the verification of the model assumption of unidimensional latent trait was done by confirming a single high eigen value of polychoric correlation between pair of observers  <cit> .

RESULTS
the distributions of scores between and within observers for photographs and videos of footrot lesions and foot integrity scoring scales are presented in figure  <dig> 

footrot scoring scale
a) weighted kappathe weighted kappa values between observer pairs for footrot ranged from moderate to substantial;  <dig>  to  <dig>  for photographs and  <dig>  to  <dig>  for videos. the within observer weighted kappa values were higher and ranged from substantial to almost perfect:  <dig>  to  <dig>  for pictures and  <dig>  to  <dig>  for videos .

b) located latent class modelthe observer thresholds for lesion scores using photographs and videos at their first and second scoring sessions are presented in figure  <dig>  for photographs, all the observers had similar threshold locations for score  <dig> and score  <dig> and for videos, the threshold location for score  <dig> was similar between observers but varied for other scores.

category widths
the category widths  for the lesion scale varied significantly between observers with both photographs and videos. observer  <dig> had significantly narrower widths for scores  <dig> and  <dig> for photographs and score  <dig> for videos compared with the other two observers . category widths for the scores did not vary significantly within observers for photographs or videos.

observer bias
there was evidence of significant between observer bias when scoring lesions from photographs; observer  <dig> had a significantly lower mean threshold  compared with observers  <dig>  and  <dig>  . similarly, there was significant bias between observers in their scores for videos; observer  <dig>  had a higher mean threshold compared with the other two observers ;− <dig>  ) with observer  <dig> having a comparatively higher threshold than observer  <dig>  there was no evidence of bias within observers when scoring photographs. however, when scoring videos, observers  <dig>  and  <dig>  had significantly higher mean thresholds at the second scoring session compared with the first session .

foot integrity scale
a) weighted kappabetween observer weighted kappa values ranged from moderate to substantial;  <dig>  to  <dig>  for soles and  <dig>  to  <dig>  for walls. within observer weighted kappa values were higher than between observer with substantial to almost perfect agreement and ranged between  <dig>  to  <dig>  for soles and  <dig>  to  <dig>  for walls .

b) located latent class modelthe observer threshold locations for foot integrity scores of soles and walls at the first and second scoring sessions are presented in figure  <dig> 

category widths
there were significant differences in the category widths of scores between observers for soles and walls. scoring soles, observer  <dig> had a wide category for score 3; observer  <dig> had a wide score  <dig> category and a narrow score  <dig> category compared with the other two observers. scoring walls, observer  <dig> had smaller category width for score  <dig> compared with the other two observers. sole category widths did not differ significantly within observers, however, within observer  <dig> there were different category widths for the middle scores for wall integrity .

observer bias
there was significant bias between observers for scoring foot integrity of soles and walls . observer  <dig>  had a significantly higher  mean threshold for scoring soles compared with observers  <dig>  and  <dig>  with observer  <dig> having higher mean threshold than observer  <dig>  observer  <dig> had a lower  mean threshold for scoring walls compared with the other two observers ;  <dig>  ).

there was no bias within observers for scores of sole integrity; however, there was significant bias within all observers for scores of wall integrity. observers  <dig> and  <dig> had a lower mean threshold value and observer  <dig> had a higher mean threshold value at their second scoring session compared with their first session .

discussion
this paper explores components of disagreement between and within observer scoring for two visual ordinal scales. for both photographs and videos of footrot and foot integrity, the within observer agreement was higher than the between observer agreement suggesting that these scoring systems are most reliable when used by the same person. this is evident from both the weighted kappa values  and the llca  where the threshold locations for ordinal scores were very different between observers but less so within observers.

the high within observer agreement could have occurred because there was a gap of only two hours between the two scoring sessions and observers remembered their scores which reduced the within observer variability, however, there were  <dig> items  to score and they were re-ordered between sessions so this seems unlikely. another possible explanation for high within observer reliability is that the within observer agreement is less likely to be affected by some additional sources of variation that exist between observers e.g. different experiences and different inherent score definition among different observers which reduce reliability. these sources of variation could have resulted in differences in the score thresholds and bias between observers and the poor between observer reliability as seen in this study. knowledge of where the disagreement lies between observers by getting information on their thresholds for each score is useful to identify particular scores where observers have most disagreement. for example, scoring photographs and videos of footrot this was for scores  <dig> and  <dig> . visual representation of thresholds, and where a discrepancy lay could help train observers and reduce between observer differences and so improve reliability. it could also be used to make improvements in particular score definitions for an existing scoring system and also could be used during development and training of a new scoring system.

unlike footrot where there are more clear signs that differentiate a diseased foot from normal, there was more within observer subjectivity in categorising the wall of the foot as mildly misshapen or normal. the overall observer agreement for walls was lower than that for soles this could be because the smaller surface area and relatively flat anatomical presentation of the soles, of the foot, in comparison to walls, makes scoring easier and more consistent.

the observers’ reproducibility and repeatability for scoring video clips and feet  were both lower than scoring from photographs. there was a difference in the length of time for which feet, videos and photographs were shown which might account for this difference but it might also be that a still 2d image of the foot was easier to score consistently than all-around video footage or a 3d digit where observers had several views and so could make several interpretations. in reality, it is quite possible that feet and videos clips although less reliably scored are more similar to real life than a photograph.

we considered the use of live sheep for this study, however, the possible change in footrot lesions over time  <cit> ,  and the difficulty in restraining live sheep to allow controlled observation of the feet for a specified time period would have introduced unnecessary error into the study. in addition, it is unlikely we would have been able to represent the whole range of scores in sufficient number in a flock of sheep at one point in time  and to run the study over time would again have introduced error. for these same reasons other studies have used videos or photographs to test observer agreement in scoring locomotion or injuries in different species such as horses  <cit>  cows  <cit> , sheep  <cit>  and dogs  <cit> . in addition, such an approach is a refinement on the use of animals in research; all the sheep that were videoed in this study were being examined as part of normal farming practice and those with lesions were treated immediately. a future study with  <dig> observers simultaneously scoring footrot lesions on live sheep to test between observer bias when observing live sheep would be useful, but carries the provisos of numbers of sheep with each score as above  <cit> .

there is a growing literature on the drawbacks of using kappa values to assess observer agreement. weighted kappa values influence the prevalence of each score, the marginal distributions of scores given by observers  <cit>  and the chosen weights in an ordinal scale  <cit> . as also evident from the current study, weighted kappa values provide no information on sources and types of disagreement  <cit> . in contrast, the located latent class analysis presented here is a very useful method to investigate agreement in ordinal scales and gain a visual insight into the various sources of disagreement. it could be particularly useful when developing and piloting a scoring system to identify sources of disagreement and make improvements to the score definitions.

CONCLUSIONS
located latent class analysis is a useful technique to unravel sources of disagreement between observers. in the current study, although both the footrot and foot integrity scoring scales had moderate to high between observer agreement there was observer bias and differences in category widths between observers. the difference in category widths between observers occurred mainly in the middle categories  for footrot scores when scored using photographs and videos and for all categories for foot integrity scores. this indicates that improvements in the scoring systems are required. currently, given that the within observer agreement was almost perfect and category widths were consistent these scales are most reliable when scored by the same person.

competing interests
authors declare that they have no competing interests.

authors’ contributions
jk participated in the design of the study, data collection, performed the statistical modeling and drafted the manuscript. af participated in the study design, data collection, performed weighted kappa analysis and contributed to a first draft of the manuscript. leg participated in the study design, discussion on analysis and in the preparation of the final manuscript. sam contributed to the statistical programming. all authors read and approved the final manuscript.

