BACKGROUND
protein localization is a general a term that refers to the study of where proteins are located within the cell. in many cases, proteins cannot perform their designated function until they are transported to the proper location at the appropriate time. improper localization of proteins can exert a significant impact on cellular processes or on the entire organism. therefore, a central issue for biologists is to predict the cellular localization of proteins <cit> , which has implications for the functions and interactions <cit>  of proteins.

with the development of new approaches in computer science, coupled with an improved dataset of proteins with known localization, computational tools can now provide fast and accurate localization predictions for many organisms as an alternative to laboratory-based methods. therefore, many studies have begun to address this issue. to predict the cellular localization of proteins, soon after their proposal of a probabilistic classification system to identify  <dig> e.coli proteins and the  <dig> yeast proteins  <cit> , paul horton and kenta nakai  <cit>  also compared their specifically designed probabilistic model with three other classifiers on the same datasets: the k-nearest-neighbor  classifier, the binary decision tree classifier, and the naive bayes classifier. the resulting accuracy using stratified cross-validation showed that the knn classifier performed better than the other methods, with an accuracy of approximately 60% for  <dig> yeast classes and 86% for  <dig> e. coli classes.

feng  <cit>  presented an overview about the prediction of protein subcellular localization, and in  <dig>  donnes and hoglund  <cit>  introduced past and current work on this type of prediction as well as a guideline for future studies. chou and shen  <cit>  summarized the more recent advances in the prediction of protein subcellular localization up to  <dig>  a variety of artificial intelligence technologies  <cit>  have now been developed, including neural networks, the covariant discriminate algorithm, hidden markov models , decision tree and support vector machines . among these methods, the svms are always considered as a powerful algorithm for supervised learning.

besides, there are other methods proposed too, like the yloc tool implemented by briesemeister et al.  <cit>  and the prolocalizer  <cit>  which integrated web service to aid the prediction. recently, the random-walk-on-graph technique  <cit>  has been applied to biological questions such as the classification of proteins into functional and structural classes based on their amino acid sequences. weston et al. presented a random-walk kernel based on psi-blast e-values  <cit>  for protein remote homology detection. min et al.  <cit>  applied the convex combination algorithm to approximate the random-walk kernel with optimal random steps and applied this approach to classify protein sequence. freschi et al.  <cit>  proposed a random walk ranking algorithm to predict protein functions from interaction networks. random walks are closely linked to markov chains, which inspired yuan  <cit>  to apply a first-order markov chain and extend the residue pair probability to higher-order models to predict protein subcellular locations. garagea et al.  <cit>  also presented a semi-supervised method for prediction using abstraction augmented markov models.

this study introduces a novel random walk method for protein subcellular localization based on amino acid composition. by mapping the protein data into a weighted and partially labeled graph where each node represents a protein sequence, we implemented a random walk classification model to predict labels of unlabeled nodes based on our previous theoretical work  <cit> . we present an intuitive interpretation of the graph representation, label propagation and model formulation. we additionally analyzed the performance of the method in predicting the cellular localization of proteins. this method produced results that were both competitive and promising when compared to the state-of-the-art svm classifier.

RESULTS
our random walk classifier  was coded in matlab. given the training data and their classes, we computed the state matrix y and weight matrix w. in our experiment, the similarity or weight between two nodes was given according to the radius basis function 

 sim=e-γxi-xj2=e-xi-xj22σ <dig> 

to prove the effective classification performance of our method, we compared our classifier with rbf-svm by implementing libsvm  <cit> , and the γ = 1/2σ <dig> of our rawa and rbf-svm was optimized over the interval {2- <dig>  2- <dig>  ...,  <dig>  211}. in this study, we adopted an n-fold cross-validation measurement to produce the highest predication accuracy, which was computed by dividing the number of correctly classified data points by the size of the entire unlabeled dataset.

predicting the cellular localization of proteins
since our classifier involved two parameters, the laziness parameter α for constructing transition matrix and the random walk step t, we first tested the performance of our classifier on different combinations of α and t. then, under the optimized parameter settings, we compared our approach with various measurements to the svm classifier.

influence of α and t
we investigated a maximum walk of  <dig> steps and five parameters:  <dig> ,  <dig> ,  <dig> ,  <dig>  and  <dig> . figure  <dig> and figure  <dig> depict the predictive accuracy curves of our random walk classifier on yeast and gneg datasets, respectively. each figure contains five lines that correspond to each α and depicts the trend of accuracy ratios with increasing t. the test results were obtained from 10-fold cross validation.

we found that a large number of steps were unnecessary for the rawa classifier to achieve the best results. first, the complete graph offers each label a chance to reach the unlabeled node in at least one step. second, both figures show that good accuracy was always obtained when the value of t was low. in contrast, the accuracy gradually declines after the peak value of t. this decline may probably due to the fact that with the increasing of t, pt will become trivial and in turn mislead the classification. this situation is quite apparent in figure  <dig>  in addition, szummer and jaakola  <cit>  found that small constant values of t  were effective on a dataset with several thousand examples.

since the labeled training data is often deterministic, the transition matrix built over the labeled data is commonly treated as a unit matrix in semi-supervised random walk methods. however, the best result for the yeast data was achieved when α =  <dig> . this value gave the labeled nodes more freedom to move to each other, whereas the best result for the gneg data was achieved when α =  <dig> . consequently, it is necessary to import the laziness parameter when the training data is not fully reliable; α can usually be set above  <dig> .

comparisons with svm
according to the above results, our method achieved a total prediction accuracy of 61% for yeast data, and >93% accuracy for gneg data. furthermore, to quantify the performance of our proposed algorithm, we employed svms and compared the two methods by computing the widely used measures of specificity and sensitivity. table  <dig> compares the ability of the two methods to classify yeast data into  <dig> classes, while table  <dig> shows the comparison for the gneg data with  <dig> classes. we also compared the total accuracy of both classifiers; these data are presented in the final row of the table.

each classifier was able to produce results with high sensitivity and specificity, but neither could identify the proteins that localized to the vac site. the rawa performs slightly better since it could predict the proteins that localized to pox and erl, whereas the svm could not. as illustrated in table  <dig>  both classifiers produced high sensitivities and specificities on the  <dig> locations, but according to the total accuracy listed in the last row, our classifier outperformed the svm by 1%.

we further compared the two classifiers using receiver operating characteristic curves . figure  <dig> and figure  <dig> depict the results for yeast and geng, respectively, and each figure contains the roc curve for the rawa method on the left and the roc curve for the svm method on the right. these figures together offer an intuitive comparison and show that our rawa classifier is effective and that the results are comparable to those derived from a svm-based method.

discussion
herein, we propose a novel classification model for label propagation through random walks on graphs. we first initialized an undirected complete graph over the labeled data whose data points act as the nodes and pairwise distances act as the weights. then, labels and weights are employed to construct the state matrix and state transition matrix so that any node can start a random walk and propagate its label to any unlabeled data point after several steps. this model is also optimized by a kernel method and regularization so as to provide flexible control over the transition matrix.

one interesting possibility for future work is to develop algorithms for a clever selection of the labeled dataset and the kernel based on the data. in this study, we used the very simple gaussian kernel with the identity covariance matrix, which likely does not exploit the similarity information conveyed in the data points.

CONCLUSIONS
protein cellular and subcellular localization has been an important facet of research because of its role in characterizing protein functions and protein-protein interactions. in this study, we developed a novel approach based on a random walk technique to predict protein localization. we demonstrated that this approach improves the accuracy of predicting protein cellular localization and is easy to train. when compared to the svm classifier, our results are both competitive and promising.

