BACKGROUND
fluorescent microscopy datasets composed of nuclear and membrane  channels pose problems to automated image analysis algorithms, as seen in the examples in fig.  <dig>  to address these challenges we propose an interactive segmentation and analysis tool that guides the user to quickly correct potential errors and adaptively propagate these corrections through the entire dataset, thus providing a robust framework for further quantitative image analysis and results validation.fig.  <dig> image segmentation challenges. a reconstructed cross-section of a spim light sheet microscopy volume of the ascidian p. mammillata showing an artifact in which as many as five nuclei appear connected. this makes it difficult for existing nuclei detection methods to properly segment. b weak signal in the membrane channel in lower z slices of a confocal microscopy image. c inconsistent signal strength in the cell wall channel of a z slice through a confocal microscopy image of arabidopsis thaliana . d cells with interrupted membrane which share cytoplasm, as in this example of the caenorhabditis elegans gonad cells  <cit> . watershed segmentation methods will have difficulty segmenting such structures due to leakage. e sperm cells appear in the nuclei channel resulting in false positives for a nuclei detector  <cit> . f dividing p. mammillata cell spim images that show up as large nuclei



interactive segmentation has gained significant interest in the bio-imaging community in recent years. for example,  <cit>  proposes an interactive learning approach for segmentation of histological images. ilastik is a widely used interactive segmentation and classification tool  <cit> . other tools are specifically targeted to, for example electron microscopy images  <cit>  or for segmentation of clusters of cells such as  <cit>  which classifies pixels based on the geodesic commute distance and spectral graph theory. the user-guided segmentation algorithm in  <cit>  is aimed at 3d nuclei segmentation and integrates multiple nuclei models simultaneously. the software introduced in  <cit>  offers interactive visualization and analysis tools which enable users to create a processing pipeline for microscopy applications, from image filtering to segmentation and analysis. the work of  <cit>  uses an active contour approach based on parametrized b-splines for interactive 3d segmentation. a conditional random field whose underlying graph is a watershed merging tree is trained in the interactive segmentation approach of  <cit>  and is applied to segmentation of neuronal structures in electron microscopy data.

here we introduce an interactive cell analysis application called cellect , which consists of a segmentation component and an analysis component. the user can modify a label map that is obtained using seeded watershed  <cit> , by adding, removing or modifying segments. the algorithm aims at obtaining correct segmentation with minimum user interaction. we define an adaptive metric we call cellness which is trained to highlight the regions where the segmentation is likely to be incorrect and may require the user’s attention. additionally, the algorithm can offer specific suggestions. segmentation results can then be propagated to other time points in the 3d+t dataset. furthermore, cellect provides an analysis component which summarizes the changes in various cell measurements over the time sequence. a user-friendly interface allows for easy workspace management, including the import of 3d or 3d+t tiff stacks with any additional information , opening an existing workspace for continuing work, or appending two existing workspaces to concatenate time points from separate tiff files.fig.  <dig> cellect software screenshots. cellect enables the interactive segmentation and analysis of 3d+t microscopy membrane  volumes. screenshots of cellect’s main interface , the interactive segmentation tool , and analysis module  are shown above



the primary contributions include:  an interactive segmentation tool that manages user guidance markers in the geodesic image space,  an adaptive cellness metric that learns from user-feedback and computes/maintains a probabilistic belief about the quality of a cell’s segmentation and a method to make suggestions to the user,  the ability to propagate user corrections to other time points, and  an analysis component which facilitates quantitative observation about the organism’s development changes over a time sequence. these algorithms and features are packaged into an open source software application. we utilize this software for the analysis of a 3d+t confocal microscopy dataset of the ascidian p. mammillata consisting of  <dig> time point, a 3d+t spim dataset of p. mammillata consisting of  <dig> time points, and a dataset of eight 2d confocal microscopy slices of a. thaliana consisting of  <dig> pavement cells.

methods
cellect overview
cellect is an application for interactive segmentation and analysis of 3d+t microscopy datasets containing cell boundary information . its features include:

workspace management:cellect allows users to import a dataset in tiff format along with other optional information such as image metadata, seed points  obtained with an external tool , or sample orientation . cellect then creates a workspace consisting of individual time points and channels.

users may choose to append existing workspaces to the current one in order to concatenate additional time points. this facilitates the construction of time sequences from otherwise independent image stacks, and is especially useful when working with large time sequences.

input seeds: input seeds for the segmentation algorithm may be loaded if available, or they can be added by the user when working on the segmentation. furthermore, if the dataset represents a time sequence, such input seeds can be propagated from neighboring time points.

interactive segmentation: interactions include modifying, deleting, and adding segments. we introduce a cellness confidence measure that models the segmented cells’ features and reas of uncertainty for the user’s attention. additionally, the interactive segmentation tool suggests corrections for the user to accept or reject.

high-throughput analysis:cellect provides the option of running the segmentation tool in a non-interactive mode on multiple time points. this option is useful for high-throughput analyses where results are needed quickly with little human intervention. further, an option to propagate the segmentation to neighboring time points is available. this transfers seed points from one time point to the next as well as propagates a bias for segment shapes. the user has the option to correct the segmentation results in the interactive mode.

analysis tool:cellect provides an analysis module which runs on a selected subset of time points for which segmentation is available. changes in local and global statistics of various cell measurements over time are tracked. the user has the ability to select regions of interest in order to observe cell behavior. furthermore, automated clustering can be performed to categorize similar cells.

exporting results: the segmentation results are available in various formats: slice by slice tiff files, mat-file format, and polygon contours in xml files. the analysis and measurements computed for each segmented cell are available in xml format.

interactive segmentation
the method starts out with the membrane/cell wall channel of the original microscopy volume, vt, at a given time point t, and a point cloud of initialization seeds  associated with this volume, . these points, if available, may be imported from an external nuclei detector such as described by  <cit> , or randomly distributed throughout the volume, or propagated from the segmentation available at a neighboring time point.

in this section, we limit the discussion to the interactive segmentation, analysis and confidence evaluation of a single volume at a given time t and use the simplified notation of v and  for vt and  respectively. though this is not a limitation on the overall methodology, the notation in the analysis that follows refers to a single time point t.

at each iteration the user contributes a set of guidance marker points, pi, where each marker point xp is described by its spatial coordinates within the given volume: xp=. the initial input seed points, , along with guidance marker points resulting from subsequent user interaction are maintained in a graph gi=vi,ei, where i is the user interaction iteration index, and . each seed xp∈vi is associated with a segment in the final segmentation, and each segment is described by at least one seed. the index of the segment associated with a seed is given by seg=k. there exists an edge in the graph epq∈ei if seg=seg. in summary, the nodes in the graph represent seed points, and the edges in the graph model the membership of seeds to disjoint subsets . each disjoint subset contains the seeds  associated with one segment.

user interactions model such actions as “merge two segments”, “modify a segment”, “delete a segment”, and “add a new segment”, by manipulating the graph of input markers gi. for example, to modify a segment additional guidance markers  can be provided and associated with the given segment. to delete a segment, the seeds associated with it are eliminated. the seeds  and their subset membership are efficiently maintained as a disjoint set data structure  <cit> , permitting find and union operations with computational complexity o and constant amortized complexity. the graph which is actually is actually a forest of tree graphs, is implemented internally using two arrays.

at each iteration i, a seeded watershed segmentation method  <cit>  takes as input a membrane  volume v and a spatial arrangement of seed markers along with their subset membership relationship as modeled by the configuration of graph gi. this results in a segmentation label map, si, in which every pixel is assigned a label corresponding to a segmented cell or the image background.

the segmentation label map si is evaluated by computing the cellness metric of each segment . the cellness metric uses segment measurements to return a confidence value which models the likelihood that the segment correctly represents a segmented cell. the cellness metric is used to highlight regions of uncertainty for the user’s attention.

once the segmentation label map and the cellness metric evaluation of each segment are computed, the user may once again modify the segmentation. the process repeats until the user is satisfied with the results.

watershed markers
user guidance seeds play a vital role in initializing the seeded watershed segmentation algorithm. the watershed algorithm is a segmentation algorithm which flood fills the image space starting from input markers, interpreting the image as a topological relief, where pixel intensity is analogous to altitude. the input markers may be a single point per segment or a series of strokes through the segment volume. cellect enables users to interact with the watershed segmentation algorithm by manipulating the input markers through guidance seeds.

each input seed point, whether detected using a nuclei detector or manually marked, translates to one input marker for the segmentation algorithm, which flood fills its neighborhood to form a segment. in order to modify a segment, the user places additional guidance seeds at each iteration i, which are maintained in the graph gi.

when multiple guidance seeds are provided for the same segment, cellect combines them to form stroke markers in the 3d space. this is done by computing the geodesic shortest path in the image space between one central seed and all other seeds describing the same segment k. the central seed, given by image space coordinates xkc, is picked to minimize the euclidean distance to the mean location x¯ of all the seeds x∈vki describing a segment k:   xkc=argminx∈vki||x−x¯|| 

the geodesic shortest path between the seed xkc and the other seeds pertaining to segment k, vki∖xkc, connects all seeds describing to segment k. the shortest path is computed using gradient descent over the distance function d. d can be obtained by solving the eikonal eq.  <dig> using the fast marching algorithm introduced in  <cit> .   |grad|=p 

where p is the speed of the propagating front, embedded in a higher dimensional level set function. if the speed p is constant, the resulting distance function d can be seen as the distance function to the starting point, xkc. gradient descent on this distance function returns the shortest path in geodesic image space from each point in vki∖{xkc} to the starting point xkc.

the resulting shortest paths connecting the guidance markers for each segment together with the point cloud of input seeds are given as input markers to the watershed algorithm. figure  <dig> shows an example of such input guidance markers, the resulting segmentation and the original image. guidance markers pertaining to the same cell must be connected to each other in order to prevent the segmentation of one to result in disjoint fragments. the geodesic shortest path connects seeds through curved paths without crossing cell boundaries.fig.  <dig> user markers. a seeds , and the shortest path through the geodesic image space between identically-labelled seeds. these seeds and paths are given as initialization points or strokes to a seeded watershed algorithm. b an x−y and an x−z plane through the resulting segmentation. c the corresponding planes through the original image



segment features
once the segmentation is computed using the input markers described in section “watershed markers”, several properties are calculated for each segment at every iteration. these features are further used in calculating the cellness metric  to guide user interactions and for computing cell statistics .

segment border features
capture the implicit assumption that the membrane or cell wall channels are expected to have higher intensity signal than the cell interiors.

1) border to interior intensity ratio is given by ℬk¯sk¯, where ℬk¯ represents the average intensity along the border of segment k and sk¯ represents the average signal intensity within segment k.

2) distance between border and interior intensity histograms. this is computed using the earth mover’s distance  <cit>  and evaluates whether there is any membrane signal present in the segment interior.

position properties
describe the segment’s position in the image space and relative to the specimen’s coordinate system, as explained below.

3) segment centroid. the centroid coordinates are given with respect to the image origin, rescaled according to the image resolution in each dimension, and is equivalent to the center of mass of the segment.

4) centroid distance from specimen surface. the minimum euclidean distance of each segment’s centroid to the specimen’s outer boundary, scaled by the image resolution, is computed. this is given by dℬkℬ, where ℬ is the boundary  of the specimen in the microscopy volume, ℬk is the boundary of segment k, and the distance transform in eq.  <dig> denotes the minimum distance of every point x in set a to the points in set b.   dab=minp∈bd|x∈a 

5) best fit line. a line is fit through the voxel coordinates of segment k using the algorithm of  <cit> , which is based on the m-estimator technique that iteratively fits the line using the weighted least-squares algorithm. the resulting feature consists of a 6-element vector containing a normalized unit vector collinear to the line and a point on the line, in the image coordinate system.

6) segment position along the anterior-posterior  axis. the ap axis is a set of points sap obtained by interpolating a list of consecutive marker points in the image space given by the user, which traverses the specimen from the anterior end to the posterior end. the projection of the centroid of segment k, ck is given by the point on the ap axis with the smallest euclidean distance to ck. this is given by eq.  <dig>  next, the position along the ap axis is calculated as the percentage along the axis starting from the first anterior point to the last posterior point.   ckap=argminx∈sap||x−ck|| 

7) segment angle with the ap axis. for every segment k, the unit tangent to the ap axis at the projection point ckap is used to compute the smallest angle with the best fit line unit vector.

8) segment distance to ap axis. this is given by ||ckap−ck||.

shape and size properties
characterize the 3-d shape of each segment.

9) segment volume: is given by the voxel count of the segment scaled by the image resolution, vk=|sk|·μxμyμz, where |sk| is the cardinality of the set of voxels occupied by segment k, and μx, μy and μz represent the image resolution scale factor in each dimension.

10) distance of segment border to segment centroid: this feature computes the histogram of the set of distances between the voxels on the segment border and the segment centroid, dkc={||x−ck||·μ|x∈ℬk}, where d is the distance function defined in eq.  <dig>  here, μ=1maxx∈ℬk||x−ck|| is a scale factor such that the maximum element in the set is  <dig> 

11) sphericity: the radius of a sphere with the same volume as segment k is given by rk=3·|ℬk|4·π <dig>  the ratio of the surface area of this sphere to the surface area ℬk of segment k is stored as a feature and indicates how much the segment shape deviates from a sphere, and is given by |sk|4π·rk <dig> 

12) squareness: is given by the ratio of the segment volume and the volume of the minimum enclosing bounding box: vkvkbox. the minimum oriented bounding box is obtained from the projection extremities of each segment along each of the three principal axes.

13) cylindricity: this metric evaluates the segment’s deviation from a cylinder. the volume vkcyl of the minimum enclosing cylinder oriented along the principal axes of segment k. the lowest vkvkcyl ratio of the three enclosing cylinders represents the cylindricity score.

14) convexity: the deviation of the segment shape from a convex form is measured as the ratio of the segment volume to the convex hull volume: vkvkhull.

15) entropy: is a measure of compactness and is calculated using the eigen values obtained from principal component analysis, as in  <cit> .

16) elongation: similar to  <cit> , the elongation is given by the ratio of the largest eigenvalue to the midium eigenvalue: λmaxλmed.

17) flatness: similar to  <cit> , the elongation is given by the ratio of the medium eigenvalue to the smallest eigenvalue: λmedλmin.

learning a cellness metric
a novel cellect feature is its ability to highlight uncertain segmentation results to the user. a confidence metric, called cellness, is constructed for each dataset based on a continuous learning framework that models various cell features described above. the model is continuously updated based on user interactions.

expected segment characteristics


learning region characteristics from positive user examples
user feedback is of two types: a problematic segment may be corrected, or a segment may be marked as correct. segments marked as correct provide information about the expected segment measurements in their neighborhood. segments in the neighborhood of positive user feedback are compared against the user examples under the spatial homogeneity assumption and scored accordingly.

each segment is modeled as a node in a graph and edges are introduced between nodes representing neighboring cells. given a set of segments marked by the user as correct, the task is to disseminate this confidence credit to other segments in the graph, based on their similarity to and distance from the correct segments, as shown in fig. 5a-b. we consider the simplified problem of disseminating the credit from each correct segment to every node in the graph along the optimal path.fig.  <dig> 
a segments represented as nodes in a graph. edges connect neighboring segment. two segments  marked by the user as correct. b disseminate credit from the correct segments to other segments in the graph, based on similarity within the neighborhood. c confidence credit disseminated from segment p
 <dig> to all other segments along the path of highest similarity. d credit disseminated from p
2




the optimal path from a segment k to a segment p labeled as correct is the path which maximizes the probability that every segment along the path is correct. this can be written as in eq.  <dig>  in which a path through the graph between nodes  k and p is defined by the set of vertexes pkp=v <dig> v <dig> ..vn, where v1=p, vn=k and p= <dig>    p=maxpkppp==maxpkpppp…pp 

we model the probability p as the pairwise similarity between the two neighboring nodes vi and vi+ <dig>  which is independent of v <dig>  this can be expressed as p=p=di,i+ <dig>  the similarity measure di,i+ <dig> is given by 1−||fi−fi+1||·c, where fi and fi+ <dig> are the feature vectors defined earlier and c is the scaling factor in eq. . therefore, the goal is to obtain the path that maximizes the pairwise similarity between segment k and the correctly labeled segment p, i.e., apkp=∏i=1ndi,i+ <dig> 

to find the above optimal path, we note that:   pkp∗=argmaxpkp=v <dig> ..vn∏i=1ndi,i+1=argminpkp=v <dig> ..vn∑i=1n−logdi,i+ <dig> 

where wij=− logdij are non-negative weights. therefore, the method described by  <cit>  can be used to obtain the shortest path from a correct node p to every node in the graph, as shown in fig. 5c-d. finally, the confidence credit obtained by a segment k from a set of correctly labeled segments p is given by:   sk5=maxpp=maxpexp−apkp∗ 

hence, sk <dig> quantifies the confidence that segment k is correct assuming the user input and the knowledge about its neighborhood, in terms of similarity metrics.

an example of the effects of this metric are shown in fig. 6b.fig.  <dig> 
cellness metric example. a slice through the original confocal microscopy image. b propagation of confidence from segments marked as correct  to similar neighbors. c color coded cellness metric. d reconstructed cross section in the x−z plane of the cell with low cellness metric indicated by arrow in panel. this segment appears correct in the view from panel c however it has a low cellness score. e error in the segmentation, indicated by arrow, observable in the cross section . the cellness metric helped identify this error in segmentation



metric learning from positive and negative user examples
the cellness metric adapts to user feedback. segments which are marked as correct are used as positive examples, while segments that are corrected through user interactions are used as negative examples. we use the semi-supervised learning approach of  <cit>  which is designed to work well if given a very small number of labeled samples, together with a large number of unlabeled samples. the feature space consists of sk <dig> sk <dig> sk <dig> sk <dig> tuples, and two class labels are considered: correct segment and incorrect segments. the output of the classifier is the probability that each sample belongs to the correct class, which we denote sk <dig> 

a correct segment will obtain high values for metrics sk <dig> through sk <dig> and, if the classifier is trained well, the segment will obtain a high value for sk <dig>  the cellness metric combines sk <dig> through sk <dig>  giving more weight to either the mean of sk <dig> through sk <dig> or to the result of sk <dig>  according to eq.  <dig>  the average of sk <dig> through sk <dig> gives equal weight to each of the five sub-metrics. the output of the classifier produces a more complex decision boundary tailored to the dataset. this score is reliable if a balanced number of positive and negative training samples are available, and sufficient training examples are available. thus, the weight factor ν ranges between  <dig> and  <dig> and evaluates to a higher values for a larger number of training examples and a balanced number of positive and negative samples.   cellness=·∑p∈{1…5}15skp+ν·sk <dig> 

cellect recommendations, segment propagation and cell analysis
in this section we discuss several features in cellect, such as correction recommendations for the user, segmentation propagation to neighboring time points, and analysis tools for segmented volumes.

recommendations
cellect identifies problematic segments for the users to validate. examples of such segments include spurious boundaries due to weak signal to noise ratio or dividing cells for which a nuclei detector may have discovered more than one nucleus. the mean intensity on the common boundary ℬkj of segment k and its neighbor j is given by ℬkj¯. a merging score given by ℬkj¯·|ℬkj||ℬk| is computed for every pair of neighboring segments. pairs of segments are suggested to the user for merging or deletion in the increasing order of their scores.

segment propagation
in order to facilitate high-throughput analysis cellect allows users to propagate the segmentation results from one time point to the next. a simple approach is to transfer the background location and an interior point of each segment as seed points to the next  consecutive time point.

the segment inner point is given by the maximum of the distance transform  from the segment boundary applied in the interior of the segment. thus, the segment inner point is given by argmaxx∈skdxℬk, where sk denotes the interior of segment k and ℬk denotes the border of segment k.

the new seeds will serve as input seeds to the new segmentation. in the event of errors in the resulting segmentation, the user can correct the segmentation by placing additional guidance seeds. segmentations may be propagated using the interactive segmentation tool, or using the segmentation tool in non-interactive mode analysing a batch of time points together.

cell analysis
cellect includes an analysis tool, applicable to the multiple time-point segmentation results computed in the fashion described earlier. this tool can compute multiple local/global statistics as well as keep track of their changes over a subset of time points. regions of interest may be selected for analysis by constraining position coordinates relative to the specimen.

additionally, cellect has a clustering module which implements k-means clustering algorithm. this module enables the user to cluster cells in a given volume based on similarity in a user-defined feature space. the user can select one or more features  and specify the number of desired clusters for grouping cells. these parameters can be adapted to the data, and the resulting clusters can be visualized in the segmented volume. a number of group statistics  are computed per volume over the time-series.

RESULTS
ascidians are used in the study of animal morphogenesis due to their small size, simple and compact embryo, and its similarity in early development to vertebrates. the smith lab at ucsb uses microscopy volumes of ascidians for quantitative analysis in morphogenesis research  <cit> .

two 3d+t datasets of the ascidian p. mammalitta are analyzed using cellect. the first dataset, ascidian- <dig>  is a confocal microscopy time series which consists of  <dig> time points , from stage  <dig> to stage  <dig>  <cit>  with membrane and nuclei channels. this dataset starts out with approximately  <dig> cells which develop into  <dig> cells. the second dataset, ascidian- <dig>  is a spim time series which consists of  <dig> time points , from stage  <dig> to stage  <dig>  also with membrane and nuclei channels. this dataset starts out with  <dig> cells which develop into almost  <dig> cells.

additionally, a third case study from a different application is considered: the leaf and cotyledon epidermal cells of dicot plants are highly interdigitated with a jigsaw-puzzle piece shape. using arabisopsis as a model, it has been shown that the growth properties of the epidermis influence the size and shape of the organ  <cit> . therefore, understanding how the growth properties of the cell relate to organ form is an important biological question. historically, measurements of these cells have been done by manually segmenting each cell , a highly time-consuming procedure, but recently there has been a push for a more automated approach  <cit> . the a. thaliana dataset consists of  <dig> individual cells from 2d confocal microscopy slices which were segmented using cellect.

ascidian p. mammalitta - 18
the method in  <cit>  is used to detect nuclei. segmentation results corresponding to the first and last time points are presented in fig. 7a-d. cellect’s analysis module is used to isolate several regions of interest and observe changes over the development of the embryo. this datasets captures the development of the embryo up to tailbud stage  <dig>  <cit> . the following regions of interest are relevant at the tailbud stage: the notochord tissue forms in the posterior half of the embryo along the ap axis; muscle cells develop surrounding the notochord tissue; the epidermis develops at the surface of the embryo; finally, the cells in the dorsal half of the embryo, below the epidermis, represent the neural tube. these four regions of interest are marked by restricting the spatial properties computed in section “segment features”. figure 7f-g shows the spatial arrangement of the cell nuclei color coded by their membership to one of these regions of interest.fig.  <dig> 
ascidian- <dig> dataset: a–d original slice and respective segmentation for t= <dig>  and t= <dig>   clustering of cells with similar properties identifies tissues f – g nuclei at t= <dig> and t= <dig> in each of the four regions of interest: notochord , muscle , endoderm and neural tube , epidermis . h–i average cell measurments over time per region of interest: h volume i flatness



statistics over various cell measurements in each of these regions of interest are computed. for example, fig. 7h-i shows the average volume and cell flatness over the  <dig> time points in each region. as expected from the known development of the ascidian tailbud, notochord cells become mostly flat, followed by muscle cells. also, as a result of cell divisions the average volume over time decreases, while muscle cells and endodermal cells maintain the highest volume. these measurements confirm the expected developmental behavior, suggesting that the segmentation label maps resulting from cellect are accurate.

additionally, segments are clustered in feature space in order to group similar cells using k-means clustering algorithm  <cit> . the inter-cluster distance was computed for every time point, and an increasing trend was observed . this is due to the fact that cells specialize as they form tissues. these measurements meet the expected behavior, suggesting that the segmentation label maps resulting from cellect are reliable. an example of such clustering is shown in fig. 7e, where the color coding marks each of the four clusters.

ascidian p. mammalitta - 192
the nuclei detector of  <cit>  did not perform well on this dataset due to artifacts such as those in fig. 1a, f. only about  <dig> out of the approximately  <dig> cells in the last time point were detected. cellect’s interactive segmentation tool is used to correct and propagate the segmentation results. the interactive recommendation feature in the segmentation module was used to quickly identify the dividing cells. figure 8a-d shows a slice through the first and the last time points of the dataset and their respective segmentation.fig.  <dig> 
ascidian- <dig> dataset: a–d original slice and respective segmentation for t= <dig>  and t= <dig>  e–g: superimposed histograms of segment measurments, color coded by time point : e volume, b sphericity, c entropy



this dataset starts out with  <dig> cells in the first time point and ends with approximately  <dig> cells in the last time point. using cellect analysis module various measurements are computed over the time sequence. figure 8e-g shows three of these measurments over time: the histogram of volume of cells at each time point, the histogram of sphericity values over time and the histogram of entropy values over time. each histogram is color coded by the time point it represents. as expected, cells exhibit lower surface area in the later time points. this is a result of cell division resulting in many more cells occupying approximately the same total volume as the early time points. similarly, cells in later time points exhibit lower entropy, suggesting that cell shape become more compact over time.

arabidopsis pavement cells
images were collected using a scanning confocal microscope with a 40x-oil immersion objective  <cit> . this dataset lacks a nuclear marker to automatically identify each cell. cell identification is assigned manually and segmentation is based on fluorescent signal of the lipophilic dye fm4- <dig> which labels cell periphery. cell segmentation is restricted to pavement cells that are completely contained within the image field. the same cells are also segmented manually and morphometric measures  are obtained on both sets. these measures are compared against each other to determine the quality of the segmentation in section “quantitative evaluation of segmentation quality using a. thaliana slices”. small symmetrical cells associated with the stomatal lineage are also accurately segmented using cellect, but are not included in the morphometric analyses.

cellect reduced the necessary time for cell segmentation by a factor of ten when compared to manual methods. two examples of confocal slices and the respective segmentations are shown in fig.  <dig> fig.  <dig> 
a. thaliana pavement cells: left column: original slices, middle: segmentations overlaid on original slices, right: segmentation label maps



analysis
next, we evaluate the quality of the segmentations obtained using cellect and the efficiency in using the cellness metric.

quantitative evaluation of segmentation quality using a. thaliana slices
the segmentations obtained in section “arabidopsis pavement cells” are compared against manually obtained segmentations in order to evaluate the segmentation quality. xy-coordinates were extracted from cellect’s results and imported as a roi into the scientific image viewing software, imagej  <cit> . manual segmentation was conducted on the same cells segmented by cellect using the polygon selection tool in imagej with the spline function active.

a total of  <dig> pavement cells were segmented from three different plants all taken at the same developmental stage. the majority of the cells in the field were accurately segmented, and an average of  <dig> pavement cells from  <dig> day after germination  cotyledons were obtained from an image field of  <dig> ×  <dig> μm. measurements of cell area, perimeter, and circularity , which are commonly used for pavement cell analyses, were taken from cell outlines that were manually segmented and those obtained using cellect. cell population from each image field were tested for normal distribution and analyzed using either student’s t-test for populations with normal distribution or mann-whitney test for populations with non-normal distributions. a p-value less than  <dig>  indicates a statistical significant difference between parameter outputs from cellect and manual segmentation table  <dig> table  <dig> 
a. thaliana pavement cells analysis: p-value for student’s t-test analysis between cellect and manual segmentation


*mann-whitney test performed



quantitative evaluation of segmentation quality and cellect’s segmentation propagation feature using the ascidian- <dig> dataset
in this section we compare the segmentations obtained using cellect’s workflow against manually generated 3d ground truth for a subset of cells. we compare different approaches in order to determine the benefits of the interactive segmentation feature.

to demonstrate the utility of propagation over consecutive time points, a set of fifty cells spanning over five consecutive time points was manually traced in 3d. ten cells per time point were selected for the last five time points of the ascidian- <dig> dataset and ground truth segmentation was generated. this set contains cells from different tissues, as well as special cases such as dividing cells. the metric used for comparison is the f-measure which is a volume based error metric defined as   f=2·p·rp+r 

where p and r are the precision and recall of the corresponding ground truth volume.

in order to evaluate the utility of the segmentation tool, four different segmentation approaches were compared, and the f-measure was evaluated for every cell for which ground truth is available. the f-measure corresponding to the fifty segmented cells is shown in fig. 10a, where the x-axis corresponds to the index of the fifty cells. cells 1– <dig>  11– <dig>  21– <dig>  31– <dig> and 41– <dig> correspond to time points  <dig>   <dig>   <dig>   <dig> and  <dig>  respectively. four different approaches to the segmentation of these five consecutive volumes were explored: first, the volumes were segmented by initializing the algorithm with the output of the nuclei detector of  <cit> . this dataset is particularly challenging for a nuclei detection algorithm as shown in fig. 1a and fig. 1f. as seen in fig. 10a this initialization results in the incorrect segmentation of several cells. using the interactive segmentation tool, the initialization errors can be corrected and subsequently propagated to neighboring time points, which in turn may be corrected in the event of any additional mistakes. these workflows are explored next.fig.  <dig> quantitative evaluation of the segmentation: a
f-measure for the segmentation of fifty randomly selected cells from the last five time points of the ascidian- <dig> dataset. four segmentation results are compared:  nuclei detector initialization,  propagation of corrected volumes,  chain propagation without corrections,  propagated and corrected volumes. b
f-measure for four approaches to the segmentation of time points 188– <dig> from the ascidian- <dig> dataset



the second approach consists of correcting the last time point  and propagating this corrected segmentation to the previous four time points . thus a chain of propagated segmentations is obtained without any user intervention, except for the last time point.

the third approach measures the quality in segmentation when every propagated volume is corrected for potential errors. this approach evaluated the quality of a segmentation propagated from a corrected result and before any additional human interaction.

finally, the fourth approach measures the quality of segmentation when propagating from a corrected volume and after correcting any resulting errors.



as seen in fig. 10a, there are little differences in the scores of the three propagation approaches and they compare favorably to the results without any human intervention. therefore, propagating a corrected volume reduces the need for human intervention. the average f-measure for each of the approaches is listed in table  <dig>  in conclusion, the interactive segmentation tool coupled with the propagation feature enables segmentation with reduced human interaction of large time sequences for which automated methods often have difficulty. for example, in fig. 10a, several cells obtained scores as low as  <dig> % with automated nuclei detection, but instead, using cellect’s features, a correct segmentation can be propagated to subsequent time points. as a result, f-scores above  <dig> % can be obtained without any additional user interaction.table  <dig> average f-measure for four approaches to the segmentation of time points 188– <dig> from the ascidian- <dig> dataset



next, we use  <dig> cells from the first time point of the ascidian- <dig> dataset for which manually traced 3d ground truth is provided. we observe improvements in segmentation over multiple user feedback iterations using the f-measure for each cell. as seen in fig. 10b the problematic cells are corrected and a satisfactory segmentation is obtained in four iterations. the average f-measure at each iteration is listed in table  <dig>  where the first iteration starts out with the output from the nuclei detection algorithm. the most significant corrections are made in the early iterations.table  <dig> average f-measure over four iterations for the segmentation of the first time point of the ascidian- <dig> dataset



quantitative evaluation of cellness metric performance using ascidian- <dig> dataset
in this section we investigate if the cellness metric can effectively identify incorrect segments. the following experiments are performed using segmentations from the ascidian- <dig> dataset. in the first experiment we compare the cellness metric score for two sets of cells which are manually annotated into one of two classes: “correct” and “incorrect”. an effective cellness metric is expected to show a distinct separation between the two classes. this experiment is performed on five time points of the dataset, where approximately 15– <dig> cells of each class are selected at each time point. in a second experiment, ten “correct” and ten “incorrect” cells are selected from the final time point, for which each component of the cellness score is observed.

in the first experiment, we manually identify 15– <dig> correctly segmented cells from each of the time points t= <dig> , <dig> , <dig>  similarly 15– <dig> incorrectly segmented cells are manually selected from each of these five time points. the cellness metric for the cells in these two categories is plotted in sorted order in fig.  <dig>  the two categories of cells separate well for every time point. the average cellness metric for the “correct” and “incorrect” groups for these time points is listed in table  <dig>  as expected, “correct” cells consistently obtain a higher cellness metric than the set of “incorrect” cells in each time point.fig.  <dig> cellness metric for correct and incorrect cells. cellness metric in sorted order for hand picked cells in two categories, “correct” and “incorrect”, over five time points  of the ascidian- <dig> dataset. the two classes of cells separate well for the different time points



next, in the second experiment, we examine the contribution of each component of the cellness metric. ten “correct” cells and ten “incorrect” cells are selected from the last time point of the dataset. fig.  <dig> shows the contribution of each cellness score for every cell of the “correct” and “incorrect” categories: sk <dig>  sk <dig>  sk <dig>  sk <dig> and sk <dig> and cellness described in section “learning a cellness metric”. in addition, fig.  <dig> and table  <dig> show the average score for each cellness component over the ten cells of each category. this experiment demonstrates that the cellness metric effectively captures cues which indicate the quality of the segmentation.fig.  <dig> cellness metric components. score of each cellness metric component over ten “correct” and ten “incorrect” cells from t= <dig> of the ascidian- <dig> dataset, and the combined cellness score

fig.  <dig> average cellness metric components. average scores over the ten cells in each class for each cellness metric component, the average of all components, and the combined score . “correct” cells obtain a higher cellness score than “incorrect” cells



CONCLUSIONS
we introduced a software for the interactive segmentation and analysis of 3d+t membrane or cell wall image datasets. cellect enables users to create and interact with the segmentation of images containing cell boundary information by adding, deleting, or modifying segments. an adaptive confidence metric  helps identify areas of uncertain segmentation. the algorithm is able to identify spurious boundaries and suggest corrections. segmentation results can be propagated to neighboring time points. once segmentation is obtained for multiple consecutive time points the analysis tool displays statistics over time and allows the user to focus on regions of interest.

we demonstrated to utility of this framework by quantitatively evaluating the quality of segmentations and the efficiency of the cellness metric. case study analysis was performed on three datasets: a time series of  <dig> volumes of the of the ascidian p. mammillata, a time series of  <dig> volumes of the same species, and a set of  <dig> cells from  <dig> confocal slices of a. thaliana pavement cells. cells from different time points of the two p. mammillata datasets were compared against manually segmented cells. additionally, the efficiency of cellect’s segmentation propagation feature and the utility of the cellness metric were demonstrated in quantitative analysis. in the case of the a. thaliana, cellect reduced the segmentation time by a factor of  <dig> when compared to manual methods without reducing the quality of segmentations. no statistical significant differences were found between cellect coordinates and manually extracted cells in the parameters of area, perimeter, and circularity.

future work aims at developing a cell lineage reconstruction module. an integrated framework which jointly detects nuclei, computes cell segmentation and reconstructs lineage over the time series in a continuously adaptive feedback loop is desired. additional future plans include the integration with bisque, introduced in  <cit> , an online web-based bio-image analysis system which facilitates collaboration among biologists.

availability of supporting data
cellect is an open source project available at http://bioimage.ucsb.edu/. supplementary material is available such as demo video , detailed results  and animations .

additional files
additional file  <dig> 
cellect
 demo. video demonstrating the utility of cellect. 



additional file  <dig> 
additional analysis. additional plots and measurements obtained on ascidian- <dig> and ascidian- <dig> datasets. 



additional file  <dig> 
ascidian- <dig> middle slice first to last time point. animation showing the middle slice of the ascidian- <dig> dataset from the first to the last time point. 



additional file  <dig> 
ascidian- <dig> middle slice first to last time point. animation showing the middle slice of the segmentation of the ascidian- <dig> dataset from the first to the last time point. 



additional file  <dig> 
ascidian- <dig> first time point. animation showing the first time point of the ascidian- <dig> dataset. 



additional file  <dig> 
ascidian- <dig> first time point segmented. animation showing the segmentation of the first time point of the ascidian- <dig> dataset. 



additional file  <dig> 
ascidian- <dig> last time point. animation showing the last time point of the ascidian- <dig> dataset. 



additional file  <dig> 
ascidian- <dig> last time point segmented. animation showing the segmentation of the last time point of the ascidian- <dig> dataset. 



additional file  <dig> 
cells clustered by features. animation showing cells clustered by features in the last time point of the ascidian- <dig> dataset. 



competing interests

the authors declare that they have no competing interests.

authors’ contributions

dld designed and carried out research, implemented software and user interface, obtained segmentation on ascidian- <dig> and ascidian- <dig> datasets and drafted the manuscript. ug obtained cluster analysis results. jk obtained segmentation on ascidian- <dig> dataset. mk and ens collected microscopy data. ws coordinated design requirements for biological applications and reviewed the manuscript. sb obtained a. thaliana image datasets, manually segmented, analyzed its measurements and helped prepared the manuscript. dbs helped to analyze the data and prepare the manuscript. bsm coordinated the overall design, development and evaluations of the image processing methods and helped in preparing the manuscript for publication. all authors read and approved the final manuscript.

