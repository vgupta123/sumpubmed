BACKGROUND
tiling arrays have recently become widely used to investigate thousands of biochemical reactions in a parallel fashion. in oligonucleotide microarrays the probes are designed to match parts of the known genomic sequence. genome tiling arrays include overlapping oligonucleotides designed to cover an entire genomic region of interest. these arrays are able to simultaneously monitor the expression of thousands of genes  <cit>  as well as to identify the transcription factor binding sites  <cit> . transcription factors are regulatory proteins which bind to dna and control the gene transcription or biochemical activity of other regulatory proteins. the experimental technique to identify these regions of activity of the regulatory proteins on dna involves the hybridization of immunoprecipitated dna on a tiling microarray  <cit> . in this paper we examine data from two chip-chip experiments in order to identify regions of activity.

one common feature of all microarray experiments is that the signal of interest due to biochemical reactions is contaminated by noise. this noise can be mainly attributed to non-specific cross-hybridization. in the ideal case the oligonucleotides on the microarray only bind targets with exactly the right complementary sequences. in reality, however, lower affinity binding with other, imperfect sequences  also occurs. in order to correct for this non-specific binding two samples labeled with red and green fluorescent dyes  are hybridized on the same tiling array simultaneously. one sample, labeled with red dye, contains dna immunoprecipitated with antibodies against the transcription factor of interest. another sample, labeled with green dye, is derived from non-immunoprecipitated, genomic dna and is used as a negative control.

several statistical techniques have been developed for microarray data analysis  <cit> . experimental data coming from the pol ii and histone modification chip-chip data show a broad distribution of the lengths of biochemically-active regions. the signal-of-interest on the tiling microarray exhibits triangle-like peaks of different widths  <cit> . there is both a scale and intensity separation between the useful signal and the noise in chip-chip experiments. most of the existing chip-chip data analysis methods do not explicitly exploit this feature.

signal decomposition using basis functions  that resemble peaks makes this separation more apparent. numerical implementation of the wavelet transformation is called discrete wavelet transform . computational cost of dwt scales linearly with the number of input data points ). the same is also true for the computation cost of the moving window averaging. one of the major advantages of the dwt over the moving average window method is that dwt gives explicit representation of the signal at different lengthscales and the possibility to choose the type of wavelets for the dwt closely resembling the shape of the peaks we are trying to identify. one of the existing chip-chip data analysis methods  <cit>  uses wavelets only as a denoising tool by thresholding the wavelet decomposition at a fixed level.

the peaks were detected not from the wavelet decomposition, but by applying laplacian of a gaussian  edge detector. we describe a method which is capable of delineating peaks of different sizes from the wavelet decomposition coefficients at different levels, and the range of sizes is determined by the algorithm parameters. our method does not require any data pre-processing. statistical analysis of the wavelet coefficients produces the probability density function of the signal intensity due to the non-specific hybridization and makes it possible to conduct an unbiased identification of protein binding site locations. below we describe how to employ a wavelet algorithm to analyze the experimental data.

methods
mathematical formalism
in this section we will provide an overview of wavelet decomposition. the term "wavelets" is used to refer to a set of localized basis functions which posses a special structure. wavelets are defined by two mutually orthogonal functions: scaling function ϕ and mother wavelet ψ. the rest of the basis functions can be obtained by performing dilation and translation operations with the scaling function and the mother wavelet. the fundamental idea behind wavelet analysis is that one can separate data based upon its scale. a very comprehensive review of wavelets can be found in  <cit> .

in this work we use the discrete wavelet transform  algorithm proposed by mallat  <cit> . this algorithm uses scales and positions based on powers of two . mallat's algorithm takes the discrete input signal a of length 2n and decomposes it into two signals: a and d, each of length n. the results of this process are called approximation coefficients and detail coefficients. for chip-chip data, the approximation coefficients represent a relevant signal, whereas the detail coefficients represent noise. the approximation coefficients at scale  can be obtained from the approximation coefficients at the finer resolution scale  as follows  <cit> :

  an=12∑kcka2n+k 

where ck, k =  <dig> ..,  <dig> are the decomposition low-pass filter coefficients. for the coif <dig> wavelet the numerical values are  <cit> :

c <dig> = - <dig> , c <dig> = - <dig> , c <dig> =  <dig> , c <dig> =  <dig> , c <dig> =  <dig> , c <dig> = - <dig> .

similarly the detail coefficients at scale  can be obtained from the approximation coefficients at scale  as follows:

  dn=12∑kbka2n+k 

where bk, k =  <dig> ..,  <dig> are the decomposition high-pass filter coefficients. for the coif <dig> wavelet the numerical values of the coefficients are:

b <dig> =  <dig> , b <dig> =  <dig> , b <dig> = - <dig> , b <dig> =  <dig> , b <dig> =  <dig> , b <dig> = - <dig> .

a schematic view of the decomposition process is shown in figure  <dig> 

equations  and  perform low-pass and high-pass filtering of the input signal. approximation coefficients retain a low-frequency, smoothed version of the signal; whereas the detail coefficients capture the low-scale, high frequency component of the signal. procedures  and  can be performed recursively using a as the input signal. in practice, the discrete input signal is treated as the set of approximation coefficients at scale m =  <dig>  and multilevel wavelet decomposition is performed using formulas  and . the decomposition - is reversible. approximation coefficients at scale  can be reconstructed from the approximation and detail coefficients at scale :

  an=12∑kfn−2kak+12∑kgn−2kdk 

for the coif <dig> wavelet, the low-pass filter coefficients f and high-pass filter coefficients g are  <cit> :

 f1=− <dig> ,f2= <dig> ,f3= <dig> ,f4= <dig> ,f5=− <dig> ,f6=− <dig> ,g1=− <dig> ,g2= <dig> ,g3= <dig> ,g4=− <dig> ,g5= <dig> ,g6= <dig>  

the pyramidal structure of the algorithm makes signal decomposition - and signal reconstruction  computationally very efficient  <cit> . additional file  <dig> figure s <dig> shows the high-pass and low-pass filter coefficients for the decomposition and reconstruction procedures.

specific datasets used for the analysis
all the analysis was performed using data from nimblegen's encode tiling arrays. the goal of the encode  project  <cit>  is to identify functional elements from a representative 1% of the human genome. this part of the human genome is represented on the nimblegen encode tiling array. the single array contains more than  <dig>  unique 50-mer probes selected from  <dig> megabases of human sequence data specified by the encode project consortium  <cit> . these probes are spaced apart every  <dig> bases on the average, thus creating a 12-base overlap between probes. no probes were included for interspersed repetitive dna, thus there are gaps in genome tiling paths on the array. the pol ii  and h3k36me <dig> histone modification data were obtained from  <cit> . it is interesting to use these datasets to test our algorithm because they have broad peaks.

RESULTS
in the current work we propose a new computational approach to analyze chip-chip data using wavelet decomposition. a schematic view of the decomposition process is shown in figure  <dig> 

we use coiflets  as basis functions for the wavelet decomposition  <cit> , as coiflets have a nearly symmetrical, peak-like form of the mother wavelet. this shape resembles the tiling array signal profile at the transcription factor binding sites observed in chip-chip experiments . we chose coiflets for the wavelet decomposition due to their properties of having the maximum number of zero moments while also having small widths , ensuring a fast convergence rate  <cit> .

we applied a thresholding procedure to the wavelet coefficients at different resolutions in order to delineate the regions of biochemical activity of interest at the same confidence level for all relevant length-scales.

application of wavelet analysis to pol ii and histone modification data
our goal is to expand both signals in red and green channels using a wavelet basis.

the input signal for the wavelet decomposition is derived as follows. we define the signal as a function of the genomic coordinate to be equal to the measured intensity of this probe for the genomic coordinates inside of the non-overlapping part of the probe, as well as for half of the part which overlaps with the nearest-neighbor probe along the genomic coordinate. each overlapping region is divided equally between two nearest- probes along the genomic coordinates. the signal is assumed to be zero for the missing data  in the genomic regions lacking probes on the tiling array. an example of the input signal for the wavelet decomposition algorithm is shown in figure  <dig> . in this figure, the signal of biochemical activity  contained in the red channel is located between genomic coordinates  <dig> and  <dig> and also between  <dig> and  <dig> 

it is important to mention that almost all the wavelet coefficients are greater than one  > 1). as a result it is possible to log transform them. wavelet coefficients corresponding only to the missing data points  next to the tiled regions can take small values values  < 1) and even can become negative. we filter out those coefficients while retaining the rest, including those corresponding to peaks. wavelet coefficients a >  <dig> are log-transformed for further analysis.

the level of wavelet decomposition to be used is defined by the typical length-scale of the signal variation we wish to analyze. this length-scale  is in the range of 200- <dig> base pairs in the chip-chip experiments for pol ii data and in the range of 200- <dig> base pairs for the histone modification data. the width of the wavelet at the composition level m is approximately 2m. hence, we used wavelet decomposition levels m =  <dig>   <dig>   <dig>   <dig> for the pol ii data  and m =  <dig>   <dig>   <dig>   <dig>   <dig> for the histone modification data  to resolve the signal variation length-scales of interest.

choice of the wavelet decomposition levels
approximation coefficients for the wavelet decomposition at levels m =  <dig> through m =  <dig> should capture the signal on the tiling array due to biochemical activity. the presence of this activity is indicated by the enrichment of the red channel signal relative to the green channel signal. if there is no enrichment of the signal in the red channel relative to the signal in the green channel, we expect the wavelet coefficients for the red and green channels to grow proportionally to each other as a function of the average intensity. wavelet coefficients corresponding to the regions of the enrichment of the red signal relative to the green signal will exhibit deviation from this main trend. the approximation coefficients a of the input signal for the decomposition levels m =  <dig>   <dig>  and  <dig> are shown on the second, third, and fourth graphs from the top in figure  <dig>  the region of biochemical activity between genomic coordinates  <dig> and  <dig> is captured by one wavelet approximation coefficient at decomposition level m =  <dig>  three wavelet approximation coefficients at decomposition level m =  <dig> and five wavelet approximation coefficients at decomposition level m =  <dig>  broader peaks require higher order wavelet decomposition.

wavelet coefficients ared vs. agreen  for the signal on the entire array are plotted in figure  <dig> . each point on the graph corresponds to the pair of the wavelet coefficients of the signals of the red and green channels on the tiling array. as can be seen from the graph, the majority of the points are located inside of the triangle-like area bounded by two lines coming from the origin of the coordinates. plotting the same data using logarithmic coordinates log vs. log, we see that all points lay inside of the stripe-shaped region and that the width of this region is roughly independent of the average intensity of the signal ). figure  <dig>  shows the histograms of the distribution function for the log. peaks on the histograms for log at the resolution levels m =  <dig> , <dig> indicate that the scale of the wavelet at those resolution levels is smaller than the size of many contiguously tiled regions on the encode array. many data points inside the red box in figure  <dig>  correspond to the peaks inside the contiguously tiled regions whose size is larger than the size of the wavelet used for the signal decomposition. we can only identify parts of the broad peaks by going back to the original input signal and selecting the regions corresponding to those wavelet coefficients. in order to identify all the broad peaks in their entirety we should combine the information provided by the wavelet coefficients up to the resolution level m =  <dig>  as can be seen on figure  <dig>  the histogram for a <dig> becomes flat compared to the histograms for a <dig>  a <dig> and a <dig> . this is an indication that there is a lack of contiguously tiled regions on the encode tiling array with a size greater than the size of the wavelet at the resolution level m =  <dig>  wavelet coefficients for the decomposition levels m >  <dig> contain the information from the missing data regions where the signal is zero. consequently, it makes it impractical to use the decomposition levels m >  <dig> 

the probability density function of log is very close to normal at the resolution levels m =  <dig> ..., 11; as can be seen in figure  <dig>  the deviation from the normal distribution is due to the regions of high enrichment attributable to the specific hybridization. for each resolution level m we can compute the standard deviation σm of log and threshold the wavelet coefficients relative to σm, allowing us to obtain regions of biochemical activity of interest at the same confidence level for all relevant length-scales. for every wavelet coefficient above the threshold we can go back to the original signal and identify the region of the biochemical activity. the size of each region is related to the resolution level of the corresponding wavelet. at the end, all the detected regions are combined together.

the log-normal distribution is the characteristic feature of multiplicative random processes  <cit> . one explanation for the appearance of the log-normal distribution in the data is that the measurement process of the fluorescent signal of the tiling array involves multiplicative random factors. these factors can include the collection efficiency of the light during array scanning and the variation of the quantum efficiency of the pixels in the ccd camera. the log-normal distribution was previously observed in the fluorescence microscopy signal  <cit> .

furthermore, the log-normal distribution of the data could be attributed to the kinetics of the hybridization process on the array.

consistency property of the wavelet coefficients corresponding to the locations of the peaks
a very interesting feature can be observed from figure 5: approximation coefficients for the red channel are consistently above the approximation coefficients for the green channel over the region of the biochemical activity across several wavelet decomposition levels. we use this characteristic to decrease the number of false-positive calls. we describe the numerical procedure ensuring the consistency property of the wavelet coefficients below.

according to  the approximation coefficients anat scale  can be obtained from six approximation coefficients at the finer resolution scale :

 an=12∑kcka2n+k 

where ck, k =  <dig> ..,  <dig> are the decomposition low-pass filter coefficients of coif1: c <dig> = - <dig> , c <dig> = - <dig> , c <dig> =  <dig> , c <dig> =  <dig> , c <dig> =  <dig> , c <dig> = - <dig> .

three of the six approximation coefficients at the resolution level m: a2n- <dig>  a2n- <dig> and a2n- <dig> contribute the most to an. repeating the same argument for the decomposition level m we find nine approximation coefficients at the resolution level m- <dig> contributing mostly to the numerical values of three approximation coefficients at the resolution level m. for the wavelet decomposition using coif <dig> there are nine approximation coefficients at the resolution level m- <dig> and three approximation coefficients at the resolution level m that greatly influence the numerical value of the approximation coefficient an.

description of the numerical algorithm
our algorithm performs wavelet decomposition of the signals in red and green channels, computes the standard deviations of the distribution functions of the log-ratios of of the wavelet coefficients, thresholds the log-ratios, checks the thresholded wavelet coefficients for consistency, generates hit regions from the wavelet coefficients selected by the algorithm and estimates the fpr  for the chosen threshold.

here are the steps of our algorithm:

1) depending on the range of peaks we are looking for, we choose the range of wavelet decomposition levels: m <dig> ≤ m ≤ m <dig>  the width of the wavelet at the decomposition level m is approximately 2m. hence, we use wavelet decomposition levels m <dig> ≤ m ≤ m <dig> to look for the peaks of width l: 2m1≤l≤2m <dig>  for example, we use m <dig> =  <dig>  m <dig> =  <dig> for pol ii data and m <dig> =  <dig>  m <dig> =  <dig> for the histone modification data. we compute the wavelet decomposition of the signal at levels m <dig> -  <dig> ≤ m ≤ m <dig> .

2) for every decomposition level m, the probability density function of logn red)n green)) is approximated by a gaussian and the standard deviation σm is computed.

3) we call a region corresponding to the approximation coefficient an a hit only if:

a) logn red)n green))>ασm, where α is the numerical value of the threshold. the threshold value is the same for all m <dig> -  <dig> ≤ m ≤ m <dig>  the thresholding allows us to select peaks of different sizes with the same confidence level.

b) the same as in 1) is true for the log ratios of at least three approximation coefficients at the resolution levels m- <dig> and m- <dig> contributing greatly to an. requirements a) and b) impose consistency constraints on the wavelet coefficients across three resolution levels which help to reduce the number of false positives. each time we find a hit we go from an, to a2n- <dig>  a2n- <dig>  and a2n-3; until we reach the original input signal to identify the region of biochemical activity.

4) we combine together each overlapping group of hits into one big hit region. we call n the total number of final hit regions.

we can estimate the false positive rate  corresponding to the chosen value of threshold α. signal of the red channel is randomly shuffled between the probes. we repeat the same scoring procedure for the shuffled signal keeping m <dig>  m <dig> and α the same.

the obtained hits are false hits which allow us to estimate the false positive rate : fpr=nshuffn, where n is the total number of hits without random shuffling and nshuff is the total number of hits after the random shuffling of the red signal probes. one can choose the α according to the corresponding fpr.

comparison with other methods
in order to test the performance of our method with the consistency constraint previously described, we applied our algorithm to the spike-in data from the encode nimblegen tiling array. mixtures of human genomic dna and  <dig> human sequences at various concentrations were hybridized on the array  <cit> . spike-in data was obtained from human sequences of approximately the same size, which were generated in the laboratory. spike-in data allows for an objective estimation of the performance of our method and a comparison with other methods.

we used model parameters: m <dig> =  <dig>  m <dig> =  <dig>  and varying α to obtain roc-type curve. we choice of the model parameters was based on our observation that the size of the wavelets should be comparable to the size of the peaks to identify. roc-type curves were generated by plotting the sensitivity  vs. the false positives ratio . the optimal roc-type curve is the one closest to the left upper corner.

we compared our method with other methods described in  <cit> : ma2c, splitter, permu, acme, tamalg, and tamals. ma2c   <cit>  is a normalization method based on the gc content of the probes. it compensates each probe's log ratio for the gc bias and weights each probe, taking into account the signal variance of the gc group to which the probe belongs. a sliding window consisting of  <dig> bp was used, and windows with high median values were identified as hits. the splitter algorithm  <cit>  incrementally changes the cutoff value of the signal and compares the total number of hits before and after the change. if the ratio of the number of hits before and after the cutoff change is smaller than a pre-defined value, the algorithm stops and hits before the last cutoff change are reported as final hits. clusters of probes located closer than a "maxgap" parameter were merged together. clusters of probes containing the number of probes smaller than a "minrun" parameter were discarded. permu  <cit>  identifies the peaks within the sliding window based on iterative thresholding procedure. fpr  is assigned to each peak using the randomized data. tamalg and tamalc are two versions of the same peak-finding algorithm  <cit>  that use different stringency levels.

our method demonstrated excellent performance compared to other methods as can be seen from the roc-type curve in figure  <dig>  the intuitive reason behind of such a good performance of our method is that the shape of the wavelets we use is very similar to the shape of peaks of the signal. another reason of a good performance is the use of consistency constraint which reduces the number of false positives.

we also tested our method using stat <dig> data from encode nimblegen arrays in  <cit> . we use the following parameters for our model: m <dig> =  <dig>  m <dig> =  <dig> and the threshold α corresponding to the estimated false positive rate fpr = 5%. most of the hits  obtained by our method overlap with hits reported in  <cit> .

CONCLUSIONS
we analyzed tiling array data using wavelet transformations, and from the resulting wavelet coefficients we obtained clear intensity and length-scale separation between the background signal and the signal coming from the regions of biochemical activity. a thresholding procedure was applied to the wavelet coefficients at different resolution levels with the consistency constraint in order to delineate the regions of biochemical activity of interest at the same confidence level for all the relevant length-scales. this method was successfully applied to several chip-chip data sets, including pol ii and histone modification experiments. our method demonstrated excellent performance using spike-in data from the nimblegen tiling array.

authors' contributions
ak designed the algorithm, coded it and wrote the manuscript. jr provided crucial help in improving the data analysis. mg provided general advice and guidance in drawing necessary conclusions and results. all the authors read and approved the final manuscript.

supplementary material
additional file 1
figure s <dig> - high-pass and low-pass decomposition and reconstruction filters for coif <dig>  low-pass decomposition filter c has a triangular-like shape that resembles the shape of the signal over binding sites observed in chip-chip experiments.

click here for file

 acknowledgements
the authors would like to acknowledge raymond auerbach, sudhakar chelikani, lukas habegger, alex urban and sherman weissman for useful discussions.
