BACKGROUND
the polymerase chain reaction   <cit>  is one of the most widely used techniques in biological laboratories today. it allows for isolating and exponentially amplifying fragments from a dna sequence. two short oligonucleotides  are synthesized so that they can bind correctly at the 5' and 3' ends of the dna region of interest. the pcr usually consists of a series of cycles  and is essentially carried out in three steps:  the denaturation step melts the double stranded dna  into two separate strands.  during the annealing step the primers bind to the single-stranded template. here, the temperature depends on the melting temperature of the primers.  in the extension step, a dna polymerase synthesizes new dna strands complementary to the single-stranded templates. this procedure is then repeated, doubling at each step the number of copies of the desired dna segment. through such repetitive cycles it is possible to obtain millions of copies of the desired dna segment within a short period of time.

pcr primer design with genefisher
before each pcr experiment, specific primers have to be designed according to a number of criteria. based on the assumption that genes with related function from different organisms show high sequence similarity, degenerate primers can be designed from sequences of homologous genes. genefisher  <cit>  is a sophisticated interactive program for designing degenerate primers. the procedure leads to isolation of genes in a target organism using multiple alignments of related genes from different organisms. the term “gene fishing” refers to the technique where pcr is used to isolate a postulated but unknown target sequence from a pool of dna .

for that purpose, genefisher selects pcr primers with certain criteria such as: melting temperature tm, gc content, primer length, 3' clamp gc content and degeneration, hairpin loop structure detection, primer-primer dimers detection, primer degeneration, amplified region length, and primer uniqueness. genefisher gives biologists the possibility of adjusting these parameters meeting the conditions of the pcr experiment.

genefisher accepts single or multiple dna and protein sequences as input . as primers are calculated for a single dna sequence, multiple input sequences are aligned using alignment programs such as clustalw  <cit>  or dca  <cit> . from the alignment, a consensus sequences is derived and used as input for the primer calculation step. if protein sequences have been submitted, a backtranslation step is necessary, where amino acid sequences are translated to a hypothetical nucleotide sequence using either maximum redundancy methods or the codon usage of a given organism.

genefisher implementation
the original genefisher implementation is a successful  but aged monolithic web application. it reveals a number of shortcomings, especially regarding user-friendliness and process monitoring/guidance. for instance, pauses in the workflow occur after requests to the server, and users have to check the state of their server requests and trigger the continuation of the application's execution manually. the monolithic nature of the code is a clear limitation.

genefisher2
genefisher <dig>  <cit>  is a recent reimplementation of the original genefisher application which recreates the overall functionality of its predecessor while enhancing usability and user experience. this new version accesses basically the same underlying tools, now turned into components, via a web application, and conducts the whole application from a web gui by means of ajax  technology . genefisher <dig> uses this technology to connect to services hosted on the bielefeld university bioinformatics server   <cit> .

bibiserv currently offers a variety of about  <dig> different software tools, spanning a wide area of applications such as genome comparison, alignment methods , structure analysis , mirna target prediction  and pcr primer design . the tools are usually offered  as soap web services, allowing their usage as independent components in different scenarios. genefisher <dig> utilizes this component potential to create a much more flexible implementation of the general genefisher methodology.

the web service versions of the tools involved  are combined on the client-side, additionally employing the biodom web service  <cit>  and hobit xml data formats  <cit>  for data conversion and validation. due to this new program structure, several parts of the process can be modified and improved without breaking the whole system. it is, e.g., possible to use different alignment tools in the process by just adding the respective web services to the client-side javascript code, using the biodom web service to maintain consistency of input- and output data formats.

using ajax technology makes the genefisher <dig> web interface much more responsive than the old implementation. the integration of web services allows the usage of already implemented tools on the local or a remote server. but still, primer design remains a highly interactive process in genefisher <dig> and designing tens or hundreds of primers cannot be automated this way.

genefisher-p
a new approach to provide genefisher's functionality in a convenient way is its transformation into a complex service that orchestrates the basic services and introduces a dedicated layer for processes.

genefisher-p puts the processes in the foreground. following the design principles described in  <cit> , it makes genefisher2's internally hidden processes explicit and accessible to the user. these processes are expressed in terms of a complex, reconfigurable business logic that uses  an extensible collection of heterogeneous basic services. as shown in figure  <dig> , it separates the process modeling layer from the basic service layer and the gui layer, in order to support process-oriented application repurposing, along the lines sketched in  <cit> .

in particular, in genefisher <dig>  a completely predefined application, the workflow is hidden from the end user, who can only interact with it through the web gui. genefisher-p exposes the internal processes and the underlying services and components to the end user, who is now able to intervene and change or integrate them with others at ease.

in the following, we show how to turn a component-based application like genefisher <dig> into a collection of orchestrated composite services that implement sophisticated processes. to this aim, we first show how to integrate genefisher2's components into the java application building center  as basic services, then we remodel the original genefisher <dig> workflow as orchestrated process, show an execution example, and finally we discuss variations of genefisher-p, i.e., how to flexibly vary and extend the process into a family of task-specific processes by modifying the control structure or adding heterogeneous functionality to the process at the process model level.

RESULTS
the models of the genefisher-p process and its variations in bio-jeti are realized as service logic graphs in the jabc modeling framework. the jabc  <cit>  is a general-purpose modeling framework which has already been successfully used to model and implement bioinformatics workflows  <cit> . in particular, it is a mature service engineering environment  <cit>  that follows the aggressive model-driven development  paradigm  <cit> . in contrast to the data-flow approach taken by many popular bioinformatics workflow systems like taverna  <cit> , models in the jabc are directed graphs that express the control-flow of a process. currently, we are extending and improving our previous experience in the bioinformatics application domain in order to set up a comprehensive web-based service provisioning platform called bio-jeti  <cit> .

basic services are called sibs  in the jabc. sibs use java to encapsulate the functionalities from which whole processes can be composed at the process level. the process layer of an application thus becomes a true service orchestration or choreography, depending on whether the basic services are provided locally or in a distributed fashion. access to local services is possible just as well as to remote tools, e.g. bioinformatics web services.

integrating genefisher2's components
according to genefisher2's internal logical workflow , genefisher <dig> uses tools for input validation, multiple alignment, backtranslation, consensus calculation and primer calculation. tools for these tasks are already available at bibiserv  <cit> ), where the original genefisher is provided as well. we need to make these tools available to jabc process modellers as libraries of basic services. in other words, sibs are needed which provide access to these tools via the internet. depending on the nature of these tools , different technologies are used.

we discuss now how to deal with each of the three kinds of components: web services, legacy tools, and local components.

web services
some resources used by genefisher already offer web service interfaces and can thus be accessed via soap calls as customary:

• clustalw  <cit>  computes multiple alignments for dna or protein sequences. the result is a biologically meaningful alignment of divergent sequences.

• dca <cit>  stands for divide-and-conquer multiple sequence alignment. this program is very fast and produces high quality multiple sequence alignments of protein, rna, or dna sequences.

in the genefisher web applications, the user can choose between these two tools for the multiple alignment. as we will show later, in the process-oriented approach such alignment components can be easily exchanged.

furthermore, as in genefisher <dig>  we use the biodom web service for the input validation: input sequences for the web services at bibiserv can be in plain text or, preferentially, in sequenceml  <cit>  format. starting with fasta sequences , these are converted into sequenceml via the sequencemlfromfasta operation of the biodom web service  <cit> .

if the conversion succeeds, the input fulfills the fasta format specification and can be processed further, otherwise the process is aborted. additionally, the types and numbers of sequences have to be figured out. in this version of the process we let the user provide this information, but the use of appropriate services would also be possible.

we use the biodom web service again when converting the xml-based sequence formats back to plain fasta, the required input format for the legacy tools described next.

legacy programs
some of the required tools are already available from the original genefisher project, but are not directly accessible via the internet:

• batcons performs the backtranslation  and the consensus calculation .

• gf_ <dig> is responsible for the actual primer design. the input has to be a single nucleotide sequence.

these legacy programs are written in c, compiled for and thus dependent on a particular cpu type.

they are integrated into the jabc as remote sibs with the aid of the java electronic tool integration platform  <cit> . to this aim, a jeti toolserver is installed on the server machine. on the one side, the jeti toolserver can access batcons and gf_ <dig> via command line, on the other side it provides an interface to the internet. at runtime, it will accept service requests for these tools from the web and forward them to the actual tools, then collect the results and build adequate response messages. the actual call used by the jeti server to execute the tool and relevant request parameters are defined via the jeti tool configurator . with this configuration information, sibs can be automatically generated, downloaded, and then directly be used as representatives for the remote services in the jabc process models.

local activities
in order to define the control flow and to achieve user interaction, we use some native jabc sibs encapsulating local functionalities. for the control flow, these are mainly sibs declaring variables or checking conditions, as well as for steering the flow of control in dependence of intermediate results. user interaction refers, e.g., to sibs for file management and display of  results. these functions are provided in the jabc environment as libraries of helper-sibs, and are thus directly part of bio-jeti.

modeling the genefisher process
the basic services introduced in the previous section, embodying local and remote functionalities, are sufficient to build a process model that reproduces genefisher's functionality. based on sibs encapsulating these services, we easily compose a process model that corresponds to the abstract workflow of figure  <dig> but provides much more information and is immediately executable.

we follow the main process, reported in figure  <dig>  together with some of its subprocesses.

• the process starts with the input validation, which has been encapsulated into a separate subprocess  for means of clarity. the jabc therefor offers full hierarchical modeling where subprocesses can be abstracted into so-called graphsibs, that enable viewing the process model at different levels of abstraction. here the input file is read, checked by using the biodom web service as discussed earlier, and the number and type of the sequence is entered by the user.

• when the input and its classifications are available, the necessary steps preceding the actual primer design are derived from this information by appropriate if-clauses. the sibs if multiple sequences and if protein evaluate the variables mentioned before and this way steer the control flow according to the different preprocessing steps that are required for different inputs:

– single nucleotide sequences  need no further processing before primer design.

– single protein sequences  have to be translated back into nucleic acids. they therefore go through the backtranslation subprocess, not shown here in detail.

– multiple sequences have to be aligned first . subsequently,

* for multiple nucleotide sequences  a consensus sequence has to be computed from the alignment in order to obtain a single sequence again.

* multiple protein sequences  have to translated back into nucleic acids before the consensus calculation .

• the multiple sequence alignment  is done asynchronously with the clustalw web service here . the required operations are request and response. correspondingly the sib clustalw_request submits the sequences and initiates the alignment computation, and clustalw_response is checked within a loop on the basis of the jobid that is available in the context after the initiation. while the job is running, the response will be a corresponding status, when it's finished, it contains the actual alignment.

• the backtranslations and consensus calculations are performed by a jeti-sib that invokes the remote batcons service.

• finally, the single nucleotide sequence available at this point is submitted to the gf_ <dig> program via the appropriate jeti-sib, which returns a set of possible primers. the results are then displayed by an appropriate local sib.

given the interactive nature of the genefisher web application, intermediate results are displayed to the user and may be accepted or rejected on demand. for example, the sib sequence ok? in the input validation subprocess asks the user if the data about to be submitted is what he intended to submit, and alignment ok? asks if the alignment that is going to be used for the consensus calculation is satisfactory. in case of rejection, the process leads the control-flow back to a previous process step, typically to the sib where the appropriate data or parameters can be modified before part of the process is executed again.

if errors occur during any task, an error message is written into the process context  and can be displayed by the errormessage sib. this sib is included at those points in the process where it is reasonable to provide a detailed error description, for example at the execution of remote services.

enacting the process: an execution example
jabc process models are immediately executable by the appropriate interpreter, the tracer plugin, which is at the same time an execution environment. the tracer allows for the stepwise or complete execution of the process, with additional capabilities characteristic of debugging tools for distributed executions, like using breakpoints, jumping into subprocesses or executing them atomically in one step, or following and advancing single threads singularly.

dealing with process extensions and variations
once the processes are available as executable models, they can be reconfigured and extended very easily, at the level of the service orchestration graphs, without need of programming.

as soon as the explicit formulation of the basic process models was available, we immediately had two proposals for variations, concerning an extended data retrieval feature and the use of an alternative sequence alignment service based on ebi services, which are external to bibiserv.

the ebi provides, in fact, various web services, for example for database access and sequence analyses  <cit> . meanwhile, sibs are already available for accessing most of them from previous projects, and others can be automatically imported via the wsdl2sib plugin also available in bio-jeti.

thus it is possible to extend the previously presented workflow by automated data retrieval, or vary it using alternative tools for the multiple alignment  completely at the process level, inside the jabc.

data retrieval with ebi's wsdbfetch
the wsdbfetch web service  <cit>  allows for the retrieval of entries from various biological databases, such as embl for nucleotide sequences or uniprot for protein sequences. the sequences are identified by their ids or accession numbers and can be retrieved in different formats, for instance fasta. with the operation fetchbatch the web service provides the means for fetching a set of entries from a database by specifying their ids.

accordingly, we can start the process with the sib wsdbfetch_fetchbatch before entering the bare genefisher workflow from figure  <dig>  in order to retrieve a set of data from a database rather than using data from the local file system.

multiple alignment with ebi's wsclustalw
similar to bibiserv, the ebi provides several web services for multiple sequence alignment. like all analysis web services at the ebi, they provide distinct basic operations for running the application, checking the status and obtaining the results. thus, sibs are available for each of these operations and can be assembled in an own small process in order to create a correct asynchronous remote execution.

in case of wsclustalw  <cit> , the required operations are runclustalw, checkstatus, and poll. correspondingly, as shown in figure  <dig> , the sib wsclustalw_runclustalw submits the sequences and initiates the alignment computation, wsclustalw_checkstatus is checked within a loop on the basis of the jobid that is available in the context after the initiation. when the job is finished, wsclustal_wpoll retrieves the actual alignment.

further possible variations
the previous examples described how the process can be varied by carrying out particular execution steps by alternative tools. even more sophisticated adaptions can be realized just as easy. for instance, it is possible to reduce the level of interactivity and run the primer design process in a loop in order to design large numbers of primers. it has been mentioned before that this is not feasible when carried out completely interactive. in bio-jeti the model parts realizing any kind of interactivity can be excluded by simply directing the branches defining the control flow around them. for the repetition of the primer design process, the whole model can be transferred into a loop by adding a backward branch and a sib working off a whole collection of inputs.

classifying and browsing the service libraries
using the taxonomyeditor plugin we can easily produce special-purpose classifications of the service libraries, called taxonomies, that support specific classification criteria or viewpoints. taxonomies group services, and can be seen as very simple forms of ontologies, namely with a built-in is-a relation . in absence of any taxonomy, the jabc presents the available services in terms of the sibs, and sorts them according to their location  in the filesystem. with the taxonomyeditor users can arrange them according to any useful criteria, such as function , origin , technology  or input/output behaviour .

for the above mentioned groups of service we set up two taxonomies: by their provider , and by their functionality . thus, when we intend to modify genefisher, but remain close to the original process, we can use the provider-based taxonomy in order to easily get the bibiserv's services. conversely, when we intend to replace certain components by equivalent ones , the functionality-based taxonomy should be used.

workflow verification and code generation
the pure modeling could have been likely carried out in a different flavour also in other workflow tools, like kepler and taverna, but other functionality that bio-jeti inherits from the underlying jabc framework add value to the pure modeling and execution.

verification
during the model development process itself, different kinds of verification support can be used. the localchecker provides means to specify properties, preconditions, and environment conditions at the single component level. examples of local check properties are the correct setting of parameters, the well-formedness of some inputs, the correct and complete connection of a sib in the surrounding model  which would hamper the correct execution of the control flow.

more interestingly, we can also check global properties of a process. this is done with the gear model checker, a jabc plugin, which enables the model-wide verification of modal and temporal specifications expressed in ctl  or the μ-calculus  <cit> . examples of such properties are

the input is not submitted to any remote service before it has been checked

or properties that describe what is legal for good runs, e.g. inside control loops, like

it is possible to select a new input.

it is possible to re-do the alignment, the backtranslation, the consensus calculation, the primer design.

the central issue here is that these are not local properties of a single service or processor, but properties of the process runs. they can be checked at process modeling time, without execution of the process. therefore they offer a clear advantage over usual debugging methods.

code generation
with the genesys code generation plugin users can automatically compile the whole process model into a single application, for example in java. the generated application is a standard java program or a servlet, which can be deployed on any platform for which a java virtual machine is available .

the process execution is this way completely independent of bio-jeti and of the jabc. this solves in particular also potential performance problems: the interpretation overhead is eliminated.

the genesys code generator can also produce c/c++, bpel, and lejos  code, and it is currently being extended to cover other target languages .

discussion
several workflow environments are already available for bioinformatics applications, with different characteristics. a popular platform is the taverna workbench  <cit> , which can integrate bioinformatics web services and some other kinds of remotely available tools. other examples are the biospice dashboard  <cit> , now discontinued as project, which integrates bioinformatics tools from different sources, or the weblab  <cit> , an internet platform providing web access to popular bioinformatics service programs.

in contrast to these frameworks, the bio-jeti platform is based on the sound service engineering techniques of the underlying the domain-independent jabc modeling framework. the full power of model-driven design is maintained when adapting the framework for the biology domain.

comparing bio-jeti to taverna, the basic difference is that taverna's workflows describe the data-flow, while models in the jabc define the control-flow of a process. both approaches are usually considered to be capable of expressing the same processes, but in fact there are limitations with respect to the inclusion of elaborate control structures when using the data-flow approach: the taverna workbench offers control links in addition to the basic data links, but these are merely sufficient to express simple dependencies.

in the jabc a set of different common control structures is already available and shared among its different application domains. they allow for the modeling of sophisticated processes, for instance with different execution traces depending on the kind of input data, as shown above, or with iterations or recursions over sets of data. the data itself is managed within an execution context of the model, and identifiers similar to variables can be used to refer to particular data items.

both bio-jeti and taverna support graphical modeling: they provide distinct canvas for the palette of available components , the configuration of the components and the whole model, and for the display of the model itself. however, while in taverna the design is entirely done via context menus, and from this information a read-only graphical representation of the workflow is generated, in bio-jeti the model is constructed in a convenient and intuitive way by dragging and dropping and configuring the selected components on the canvas.

both frameworks provide means for the direct enactment of the model and for the integration of web services on the basis of their wsdl descriptions. taverna even performs an automated service discovery at startup. while taverna can additionally invoke soaplab and talisman services, bio-jeti integrates almost arbitrary tools via the eti technology: command-line, wsdl, corba idl and rest imports are already provided with the platform.

the additional benefits offered by the jabc plugins for verification and code generation are so far unique to bio-jeti.

CONCLUSIONS
we have proved in practice on a well known tool  that remodeling its processes in bio-jeti is a swift and easy business, and that making those processes explicit and first-class citizens of a distinct architectural layer pays off in terms of enhanced flexibility and ease of modification and variation. our view of basic services, the sibs, provides a uniform interface to heterogeneous sources and can be assembled and exchanged easily, this way achieving at the same time a high level of modeling flexibility and executability of the modeled processes.

the additional capabilities to verify the conformance of the designed processes with respect to desirable properties and the code generation offered by bio-jeti are object of ongoing work.

list of abbreviations used
ajax: asynchronous java and xml

amdd: aggressive model-driven design

bibiserv: bielefeld university bioinformatics server

bpel: business process execution language

corba: common object request broker architecture

cpu: central processing unit

ctl: computation tree logic

dca: divide-and-conquer alignment

dna: deoxyribonucleic acid

dom: document object model

ebi: european bioinformatics institute

gear: game-based easy and reverse model-checking tool

gui: graphical user interface

hobit: helmholtz open bioinformatics technology

idl: interface description language

jabc: java application building center

jeti: java electronic tool integration platform

pcr: polymerase chain reaction

rest: representational state transfer

rna: ribonucleic acid

sequenceml: sequence markup language

sib: service-independent building block

wsdl: web service description language

xml: extensible markup language

competing interests
the authors declare that they have no competing interests.

authors' contributions
al implemented or generated the basic services from the existing deployed components and tools, built the models and drafted the manuscript. tm and bs have been developing the concept of the jeti platform since  <dig>  first in the area of formal verification tools, then in the area of semantic web services. they lead the development of the bioinformatics application of the jabc. they have revised and edited the manuscript. sh, as and rg provide and maintain the bibiserv infrastructure, conceived genefisher <dig> and edited the part of the manuscript describing the traditional genefisher approach and tool. all authors read and approved the final manuscript.

