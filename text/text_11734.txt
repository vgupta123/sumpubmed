BACKGROUND
during the past decade the databases of protein sequences have grown exponentially reaching several millions entries while 3d protein structures databases grew quadratically so as to reach, regarding the protein data bank 
 <cit> ,∼ <dig> non redundant structures sharing less than 90% sequence identity. in order to assign a structure and then a function to as many new sequences as possible, there are various methods. when a sequence is similar enough to the sequence of one or more known 3d structures, methods based on homology modeling give satisfying results. when sequence similarity fall in the “twilight zone” - i.e. under 30% of sequence identity - one has to resort to other methods. among those, threading methods take advantage of available 3d structures to infer a 3d structure from a new sequence. using statistical filters parametrized on a library of structural cores -i.e. a bank of invariant structural motifs of protein families -, they correlate 1d  and 3d information. in such context, the predictive ability of the threading method directly depends on the representativeness and exhaustivity of the core library. such a library can be built upon a set of representative structures taken from expert structural classifications
 <cit>  as scop
 <cit>  and cath
 <cit> . however, due to the necessary careful manual inspection of the data, these expert classifications face difficulties in coping with the growing number of newly determined protein structures. for instance, since the last version of scop , there has been a growth of about 21%  of the total number of non-redundant protein chain in the pdb . hence automatic and fast clustering approaches become necessary.

over the past decade there have been many attempts aiming at developing automatic classification procedures, mainly applying supervised classification methods using as labels of know 3d structures part of a reference classification. jain and hirst
 <cit>  proposed such a supervised machine learning  algorithm based on random forest to learn how to classify a new 3d structure in a scop family. thus a 3d structure is described using a set of global structural descriptors composed from four to six secondary structural elements  for protein domains. however, supervised classification methods heavily depends on the reference classification, whose labels are fixed, and therefore only partially address the problem of automatic classification of 3d structures.

røgen and fain
 <cit>  suggested an unsupervised approach using a description of protein structures derived from knot theory in order to describe the compared structures globally. zemla et al <cit>  proposed a similarity scoring function that aims at automatically identifying local and global structurally conserved regions in order to drive a clustering algorithm. sam et al.
 <cit>  investigated varieties of tree-cutting strategies and found some irreducible differences between the best possible automatic partitions and scop classifications. these results have been confirmed by the work of pascual-garcia et al.
 <cit> . they have investigated the non-transitivity of objective structural similarity measures: a protein a can be found similar to an other protein b, the protein b can be found similar to a third protein ok and still proteins a and c may share no similarity. they have shown that non transitivity, that does occur at low similarity levels, leads to non unicity of the partition resulting from the clustering process. for fine granularity -i.e. high similarity levels- structural transitivity is satisfied with few violations within a given cluster and different classification procedures converge to the same partition. for coarser granularities -i.e. lower similarity levels- as the similarity measures are computed on distorted and divergent 3d motifs, requiring to partition the set of structures implies choices for deciding which transitivity violations should be ignored. depending on these choices classifications may differ significantly.

furthermore, such similarity based classification procedures of 3d structures only consider a single overall pairwise similarity measure or score, that is derived from local similarities, and do not make use of the detailed mapping of similar parts computed during the alignment process. as a consequence, these procedures, ignoring the mapping information, may lead to cluster proteins that do not all share a common motif. this point will be further illustrated using a simple case studies section. then, prior to running a graph based clustering process, we propose to make use of the mapping information in ternary similarity constraints applied on triples of structures. our experiments will compare the agreement between automatic classifications, obtained with and without that preliminary processing, and the scop reference classification.

first we need to use the similarity degree between two protein structures in order to build a graph of similarities whose vertices are protein structures and edges correspond to similarities exceeding a given threshold. such a graph can be directly given as an input to a graph based clustering process. however, our proposal is to use the mapping information for defining similarities between protein alignment as follows. let us define an alignment between  <dig> proteins a and b as a one to one mapping of parts of a onto parts of b. a similarity between two alignments is thus defined if the two alignments share a common sequence. more precisely, the alignment between protein a and protein b and the alignment between protein b and protein c are stated as similar if the parts of b implied in both alignments constitute a significant part of at least one of the two alignments. in other words, we consider a ternary similarity between a, b and c, centered on b, and that such a ternary similarity is stronger if the regions of b implied in its similarity with a are also implied in its similarity with c. the aim of the preprocessing step is then to consider that whenever there is an edge between proteins a and b and an edge between proteins b and c, then the ternary similarity centered in b, quantifying the common part shared by the three proteins, should be high enough. in that case we will state that the ternary constraints are satisfied. the preprocessing step will then consist in reducing the original graph to a graph satisfying the ternary constraints.

to summarize it, the method, shortly introduced in
 <cit>  starts with building a graph of 3d structures whose edges represent pairwise similarities. that graph is first transformed into its line graph that represents the adjacencies between the graph edges. applying the ternary constraints results in eliminating some vertices of the line graph. a maximal line graph is then extracted from the resulting graph. the graph of 3d structures corresponding to this maximal line graph now satisfies the ternary constraints: every triple of linked proteins corresponds to a significant structural motif. in our experiments, mcl
 <cit> , a graph clustering algorithm previously applied with success to the clustering of protein sequences in families on a large scale
 <cit>  is used for achieving the final classification. that classification is then compared to the expert classification scop at the finest granularity -ie the scop “family level”-. we also experiment a standard clustering method, suited for applications involving a large and unknown number of clusters, the preprocessing step being also applied in these experiments.

definitions
in this work as in
 <cit>  a protein structure is identified to an item o. each item is defined as a set of parts o={pi}. here each part pi will represent a structural unit defined by a sequence of one or more amino-acids. we first define the similarity of two parts by comparing their distance to a threshold.

items and similarities
definition  <dig> 
let piand
pi′ be parts of two different items,
d be a distance between parts, and tpa distance threshold defined on the distance range. we define
simp, the similarity of items parts piand
pi′, as follows: 

•
simp is true iff
d≤tp.

we also suppose that we have a mapping function m that maps subsets of items parts into a one-to-one correspondence. for protein sequences such a function is an alignment algorithm. two items are then considered as similar if they have enough parts in common.

definition  <dig> 
let o be a set of items and a mapping function m. let  be two items, and m be the set of pairs of parts of o and o′in one-to-one correspondence, then, the symmetric similaritysimo between items o and
o′ is defined as follows: 

• simo iff card)≥to, where tois a given threshold.

elements of m are denoted as mapped pairs. we now define a ternary similarity relation over triples of items.

definition  <dig> 
let  be three items such that simo and simo are true, and po′,o′ be the subset of parts of o related to both
o′ and o′′, i.e., such that
po′,o′={p|∈m and ∈m}. then sim <dig>  the ternary similarity centered around o, is defined as follows: 

sim <dig> iff card)≥t×min),card)),where the ternary similarity threshold t lies in the range 0− <dig> 

we note and exemplify hereunder that the notion of ternary similarity should not be confused with the notion of transitivity, which only depends on the graph of similarities, i.e. on binary relations. as an example, we consider the case of three items, pairwise linked, i.e. forming a clique, and highlight a case in which none of the three centered ternary similarities exceeds the ternary similarity threshold.

property  <dig> 
here is a counterexample. let  such that m=pi, m=pjand m=pk. assuming that to= <dig> we obtain that {o,o′,o′′} is a 3-clique, and therefore similarity is transitive. nevertheless sim <dig> is false, sim <dig> is false and sim <dig> is false for any threshold t> <dig>  and therefore all ternary constraints are violated.

graph model
similarities between items are encoded as edges in an undirected graph g whose vertices are identified to items, and whose edges represent similarities between pairs of items. conventional notations are those of
 <cit> .

definition  <dig> 
the graph g of item similarities with respect to the above notions of pairwise similarities on a set of o items is defined as follows: 

• g= where v=oand e=e={∈o2| simo is true}.

definition  <dig> 
a connected component of g is a subgraph of g in which any pair of vertices is connected through a path. correlatively independent connected components, named iccs, are two subgraphs of g for which there is no path between any node of one component to any node of the other component.

now we introduce a useful equivalent representation of g as a line graph whose definition is recalled here.

definition  <dig> 
let g= be a graph. its line graph is defined as l= where f={∈e2| ei adjacent to ej in g)}.

the line graph transformation is bijective if nodes labels are known and has the following property:

property 2
the connected components of g and of l are in a one-to-one correspondence.

indeed, given giand gjtwo iccs of g, according to definition  <dig> there is no edge linking a node of gi with a node of gj. consequently, by construction, there cannot be adjacency between any edge of gi and any edge of gj. then, according to definition  <dig> there is no edge between l and l. the reciprocal can easily be inferred.

our purpose is to modify l in order to satisfy the constraints derived from centered ternary similarities. such modification relies on the following properties:

property 3
line-graph

 <dig>  a vertex of l is an edge of g,

 <dig>  two connected vertices of l correspond to two adjacent edges of g: let two edges of g be  and , the corresponding edge of l is −.

 <dig>  removing a vertex in a line-graph l leads to the line-graph of the subgraph of g obtained by removing the corresponding edge from g.

from property  <dig> and definition  <dig>  the centered ternary similarity can be checked on every l edge as such an edge links two vertices representing two similarities sharing a common item.

measures
in order to compare two classifications we use standard comparison measures of classification similarity. more precisely, let p={p <dig> p <dig> …,pn} be a partition of the set of items o, two items ok∈piand ol∈pj are said co-classified iff pi=pj.

let p be a reference partition and p′be an other partition of the same set of items o obtained by a classification procedure. we denote as tp the number of pairs of items co-classified in cpand in
cp′, as fn the number of pairs of items co-classified in the reference partition p but not in p′, and as fp the number of pairs of items co-classified in the partition p′but not in p.

the precision and recall of the partition p′with respect to the reference partition p are defined as follows: 

recallp=tptp+fn,

precisionp=tptp+fp.

recallp measures the ability of the classification procedure for co-classifying item pairs when a pair is co-classified in the reference partition p . precisionp measures the accuracy of the classification procedure to co-classify correctly item pairs according to the reference classification p .

the jaccard similarity coefficient
 <cit>  is defined as follows: 

jaccard=tptp+fn+fp

it is a measure of concordance between two partitions of a same set of items very similar to the f-measure. when negatives are much more numerous than positives, this measure has the advantage - over measures such as mcc  and plain accuracy - of not taking into account over-represented true negatives. as a result, variations of concordance are easier to detect.

simple case studies
as previously mentioned
 <cit> , similarity relations between proteins structures belonging to the same class show high values and are considered almost to be transitive, i.e. whenever o1o2o <dig> belongs to a given class, we should have that simo∧simo∧simo = true. according to our graph formalism, these three items are represented by a 3-clique in g . clustering strategies such as search of max-cliques should allow identifying classes of proteins sharing a similar set of structural motifs, which is not the case.

for the sake of clarity the definition of items similarity for the two first case studies is simpler than definitions  <dig> and 2: two items are stated as similar when they share at least one identical common part.

case 1: non transitive graph g and no common sub parts
in figure
2-a, considering items o1={p1}, o5={p <dig> p2} and o8={p2}, we have: simo by parts{p1} and simo by parts{p2}. an item such as o <dig> made of two subparts  is denoted as a modular item. though o5similarities such as  and  are adjacent in g  they represent different local similarities: edge  represents part p <dig> and  represents p <dig>  a modular item can be considered as a linker between two or more classes: it is similar, and then connected to any item member of the class  <dig> of items comprising part p1) and to any member of the class  <dig> of items comprising part p2). consequently its degree is higher than those of its neighbors that are only linked to members of a single class. due to their higher degree, modular items will act as kind of “attractors” during clustering processes. consequently immediate neighbors of different classes will tend to form around the modular item a unique class, grouping together items having nothing in common . thus, in such a context, direct search of the most connected components from g does not seem appropriate.
ft¯ not fulfilling the constraint of ternary similarity represented in dashed gray,  the graph pt−et=l, with vertices etremoved during the heuristic ℋ and their removed incident edges represented in dashed gray,  the graph gtfulfilling the ternary similarity.

case 2: transitive graph g and no common sub parts
in figure
1-b, considering items o1={p <dig> p3}, o2={p <dig> p2} and o3={p <dig> p3}, we have simo due to part{p1}, simo due to part{p2} and simo due to part{p3}. here transitivity exists at the similarity graph level: o <dig>  o <dig> and o3constitute a clique. nevertheless considering similarities at the local level of shared sub parts, there is no transitivity as no sub part is shared by all of the three items, which case shows that even if transitivity is assumed at the graph level for a set of items, nothing ensures the occurrence of a set of subparts common to all items. therefore direct search for max-cliques components from g does not seem appropriate.

case 3: non transitive graph g and common sub parts
similarity measures used for comparing modular and fuzzy motifs must be tolerant to take into account the flexibility and the divergence of the compared items as in yakusa
 <cit> , the algorithm used here for identifying, selecting and mapping similar 3d protein structures. as shown in figure
1-c, with such a measure some similarities stated as not significant by use of user defined selection threshold may be rejected even when a sub-part is found similar. again, for the sake of clarity the definition of items similarity in the following case study is simplified. two items are considered as similar if at least 50% of the parts of the shortest item are mapped to sub-parts of the second item. considering items o1={p1p2p3}, o2={p1p2p3p4} and o3={p3p4}, we have simo and simo but not simo, which corresponds to a non-transitive case at the graph level with the occurrence of a sub-part p <dig> common to all items o <dig>  o <dig> and o <dig>  in such a case, the search for max-clique is not well suited.

method
use of ternary similarities
these case studies emphasize some difficulties encountered by classical graph clustering approaches in grouping together modular items in classes where all items share a common set of parts. searching max-clique - sets of items with transitive relations in graph g - does not seem adequate  as transitive relations in the graph may occur between items sharing no common subparts, and not be necessary  as items whose relations are not transitive in the graph may share a common set of sub-parts. searching for the most connected components  in considering all links of the initial graph g is not appropriate either as some highly connected items may force the union of two significantly different classes.

these drawbacks could be corrected by searching a maximal subgraph gt of g in which the ternary similarity constraint is verified, before applying any classical connectivity-based clustering approaches. indeed, as depicted later, application of ternary similarity constraint will tend to reduce the connectivity between items not sharing a same set of subparts  and preserve links of interest  increasing their relative connectivity in the context of the modified graph gt.

applying ternary similarity constraint
let l= be the line graph of g=. from property  <dig> each edge of l,) links two similarities having one item in common and can be submitted to the ternary similarity test. the edges of l are then divided into the subset ftof f whose elements satisfy the ternary constraints and the subset
ft¯ whose elements will be marked: 

• ft={,)∈f | sim <dig> is true}

•
ft¯∪ft=f,

the graph of pairsptis obtained by deleting marked edges from l: 

•pt=, i.e.pt=l−ft¯.

the modified graph ptis no more homomorphic to a line graph, i.e. there is usually no graph g′ such that pt=l. the bijection established by the line graph transformation between l and g is broken by the introduction of the ternary similarity constraints. we will search now for a maximal line graph l that is a subgraph of pt. as the edges of l are also edges of pt, the ternary relations for the corresponding items  will necessarily hold in gt. for that purpose a greedy heuristic ℋ eliminates vertices of l until it finds a subgraph, with no marked edges, corresponding to a line graph l of some subgraph gt of g .

heuristic for selecting a subgraph of l homomorphic to a line graph with no marked edges
let nt be the marked subgraph of l, i.e.nt=l−pt and
e=ft¯. let us recall that l−e′ where e′⊆e is the subgraph of l induced by e′−e′ contains all edges of l that join two vertices in e′). we will search for some - minimal - subset etof nt vertices such that l−etcontains no marked edges, and therefore, following property  <dig> , corresponds to the line-graph of some - maximal - subgraph gt of g.

removing first the vertices of ntshowing the maximal degree maximizes the ratio of the number of deleted vertices over the number of edges taking away the graph from a line graph. as minimizing etis equivalent to maximizing l it is also equivalent to maximizing gt. this subgraph of g both fulfills the ternary similarity constraint and tends to be maximal. 

 1/ n←nt//initializes n as the set of marked edges of l //

 2/ et←∅// initializes the set of vertices to be removed //

 3/ whilee≠∅: // still some marked edges //

// identification ofntvertices of maximal degree//

 4/ Δ← the maximal degree among n vertices,

 5/ ed←{e | e∈etand deg=Δ}

 6/ n←n−ed

 7/ et←et∪ed// iterative definition ofetvertices set//

material
scop database is an expert classification of structures of protein domains. it is used as a source of data for our clustering studies and as reference classification to which classes formed by clustering procedure are compared to.

scop offers a hierarchical classification organized as a 6-levels tree. protein domains are successively divided into “classes”, “folds”, “superfamilies” and “families”. the leaves of the tree are the protein domains. in this study automated classifications will be compared to the finest grained scop level, a group of protein domains belonging to the same scop family are then considered as a scop cluster.

the set of items is taken from 3d protein structure of domains of scop database
 <cit> . over the  <dig>  available domain structures we restrict our search to a non-redundant subset made of the  <dig>  scop domain representatives exhibiting less than 40% sequence identity - i.e. the astral_ <dig> data set 
 <cit> .

the mapping function of two objects is performed by the yakusa software
 <cit> . the program searches for the longest common similar substructures, between the query structure and every structure in the structural database. such common substructures consist of amino-acids of proteins o and o′ and are represented by the mapped parts m.

the set of protein pairs showing a yakusa z-score over or equal to to= <dig>  defines the edges e of our graph g.

before applying the graph modification method we remove all the isolated proteins , i.e. we remove all objects o such that deg =  <dig>  we obtain then the graph g representing the pairwise similarities between  <dig> items  encoded in  <dig> edges . items are grouped into  <dig> connected components with a large component containing  <dig> items , achieving a initial coarse grained clustering.

RESULTS
clustering effect of the modification graph process
in order to experiment the method, g was submitted to the modification process using different values of the ternary similarity threshold t ranging from t= <dig>  to t= <dig>  by step of  <dig> .

the heuristic ℋ selecting vertices et to be removed from pt can potentially select any vertex . if  is the only vertex where item oi appears, deletion of  leads to removal of item oi. as gtis built from the inverse line-graph transformation , item oi is absent from gtvertices.

by construction, our modification graph process implies a reduction of g connectivity. this results from removal of marked edges −ft¯) and then of vertices of pt that kept the graph away from a line graph =pt−et). removal of vertices from pt corresponds to the removing of edges from g to gt. as expected, this loss of connectivity is directly correlated to the value of threshold t. higher values of t lead to a more stringent constraint of ternary similarity, and finally to a less connected graph .

moreover, icc’s formed in the building of ptare transferred to l and from property  <dig> to gt. as shown in figure
3-bottom and
 <dig> this leads to a pre-partition of the objects. more stringent constraint of ternary similarity leads to more icc’s of lower sizes facilitating the work of the clustering algorithm.

pre-clustering effect of ternary similarity constraints
our modification graph process implies two edge deletion steps. first step is the suppression of l edges failing at the centered ternary similarity test. second step is the removal of l nodes through application of the heuristic ℋ. according to property  <dig>  node removal from l is equivalent to edge removal from g.

in the second step, edge deletion can potentially split an icc of g into one or more icc’s in gt. for a similarity threshold of t= <dig> , nine icc’s are split into two or three icc’s. as shown in figure
 <dig>  in eight cases, the deleted edge isolates a group of items of the same scop family from items classified differently, showing that application of ternary similarity constraint tends to separate items that are to be found in different scop families.

one can notice in this figure that protein domains from different scop classes are linked in g. this is due to the flexibility of the yakusa similarity measure. hopefully, the ternary constraint identify some of these issues, and do remove such links.

ternary similarity threshold and 3d structural comparisons
picked-up from one of the nine splits presented in figure
 <dig>  figure
 <dig> illustrates the way the fractional ternary similarity threshold identifies the candidate edges to be deleted in the context of the ternary relation. considering the three domains d1w0pa <dig>  d1uaia_ and d1j1ta_, pairwise similarities are significant:  <dig> amino acids are mapped in the alignment  and  <dig> amino acids are mapped in the alignment . but considering the ternary relation, one considers the overlap of mapped part on the common domain d1uaia_, and finds only 48%  of the amino acids common to both alignments. therefore, with a threshold t= <dig> =65%, the ternary similarity is considered to be not significant  and one of the two edges of the ternary relation  has to be deleted. there, the heuristic selects the edge  splitting the iccs into two components according to scop classification.

classifications granularities
application of ternary similarity constraints has a clustering effect taking into account shared similarities. it bears an incidence on the classes formed by mcl, the main clustering algorithm of our procedure. granularity of the clustering has been studied for varying thresholds of ternary similarity t and inflation parameter i .

the inflation parameter i is the main mcl parameter that rules the clustering granularity. lower values of i lead to coarser clustering. different values of i were tested .

as expected, large icc’s are rapidly split into small clusters when inflation parameter increases as shown in figure
7-top. the size of the largest clusters formed for low inflation parameters  <dig> <i≤ <dig>   depends directly on the ternary similarity threshold used which rules the granularity of the pre-clustering process. for higher inflation parameters  the sizes of the largest clusters appear to be almost independent from t, and the cluster mean size  is also independent from t.

thus, if the reduction of g to gtchanges the clustering of items, the granularity is not significantly affected.

comparison of the mcl classes to standard expert classifications
we compare the mcl classifications obtained with or without the application of ternary similarity constraints to the reference classification scop. this is done by mean of precision/recall  curves rather than by roc curves because i) the information contained in both curves are quite equivalent
 <cit>  and ii) pr curves are usually preferred in a context where the number of negative examples greatly exceeds the number of positives examples, which is the case here.

as shown in figure
8-left, increasing values of mcl inflation parameter i-i.e. making smaller clusters-, in- crease  the ability to provide a correct prediction when co-classifying two items , and decreases  the ability to retrieve all the positives. as ex- pected, the recall decreases when the precision increases.

differently, for increasing values of threshold t , precision increases, but surprisingly, this gain in precision is not correlated to a loss of recall. indeed, for t in range  <dig> - <dig> , the recall remains stable up to high values of t= <dig>  . as a consequence, ternary constraints allow increasing the precision while preserving the recall. as shown in figure
8-right, we can consider the use of ternary similarity as an improvement of the classification .

choice of the final clustering algorithm
in order to evaluate the real impact of the ternary similarity constraint independently from the choice of the final clustering algorithm, we compared classifications obtained with mcl to those obtained with a standard approach. we used a normalized spectral clustering algorithm
 <cit>  with a final k-means clustering initialized with centroids
 <cit>  computed from a hierarchical clustering of our data
 <cit> .

both mcl and spectral methods do not tend to form clusters with only one member. as shown in figure
 <dig>  for a number of clusters between  <dig> and  <dig> - close to the number of clusters found in scop at the “family level” and having more than one member  - mcl and spectral clustering algorithms give very similar results, applying or not the ternary constraint. for a number of clusters closest to the real number of represented scop families , mcl algorithm gives better results and appears to be more robust.

whatever the final clustering algorithm, figure
 <dig> highlights the enhancement of the quality of the automated classification procedure  introduced by the ternary similarity constraint.

discussion and 
CONCLUSIONS
classification of objects such as protein structures based on pairwise similarity relations is a classical problem. we have shown the advantages of applying ternary similarity constraints in the clustering process.

the method proposed here is in line with many constrained clustering methods as recently investigated
 <cit> . however in most of these methods, only pairwise constraints are considered: a must-link  constraint states that two objects should be placed in the same cluster while a cannot-link  constraint states that two objects should not be placed in the same cluster. constraints acting on groups of objects have also been considered, as ε-constraints and δ-constraints. however both can be represented as conjunction or disjunction of pairwise constraints. indeed it should be clear that the method proposed here deals with ternary constraints that cannot be represented as any combination of pairwise constraints. besides the ternary constraints introduced here concern the initial graph representation of data: they are not constraints for which satisfaction is required  in the clustering result. as a matter of fact, the initial graph representation, by directly linking only nodes that are similar enough, exerts some pairwise constraints on clustering: obviously two nodes belonging to two different connected components are submitted to a clconstraint. this is true for any graph based clustering approach. in such approaches, the similarity  matrix defines the initial weighted graph, and edges are then removed until the graph is partitioned. for instance in
 <cit>  a minimum spanning tree  is computed, and then using some similarity threshold, a forest is obtained. however, for large datasets, starting from a sparse graph by first applying some simple neighborhood criteria, as we do here, is a much more efficient procedure . it would be interesting to investigate the use of our ternary constraints on various graph-based clustering schemes, as long as objects are modular. in biology, beyond protein structures, adding ternary constraints would also be relevant for clustering protein sequences using graph based methods
 <cit> .

competing interests
the authors declare that they have no competing interests.

author’s contributions
j p, hs and gs conceived the graph based algorithm. gs implemented the algorithm and carried the experiments. all authors read and approved the final manuscript.

