BACKGROUND
motivation
rna, once considered a passive carrier of genetic information, is now known to play a more active role in nature. many recently discovered rnas are catalytic, for example rnase p which is involved in trna maturation and the self-splicing introns involved in mrna maturation  <cit> . in addition, there is evidence that rna based organisms were an essential step in the evolution of modern dna-protein based organisms  <cit> . the number of non-coding rnas  in humans remains a mystery, but progress in this direction suggests the number of ncrnas produced is comparable to the number of proteins  <cit> . surprisingly, the number of protein coding genes does not correlate with our concept of "organism complexity", hence it has been hypothesised that control of gene expression via a combination of alternative splicing and non-coding rnas are responsible for this, implying that the "central dogma"  at least in higher eukaryotes is woefully inadequate  <cit> .

a fundamental tenet of biology is that a stable tertiary structure is essential for biological function. in the case of rna the secondary structure  provides a scaffold for the tertiary structure  <cit> . yet, the experimental determination of rna structure remains difficult  <cit> ; researchers increasingly turn to computational methods. to date the most popular structure prediction algorithm is the minimum free energy  method for folding a single sequence, this has been implemented by two packages: mfold  <cit>  and rnafold  <cit> . however, there are several independent reasons why the accuracy of mfe structure prediction is limited in practise . generally the best accuracy can be achieved by employing comparative methods  <cit> . this paper explores the extent to which this statement is true, given the current state of the art, for automated methods. there are currently three approaches to automated comparative rna sequence analysis where the comparative study is supported by available algorithms . a researcher following plan a may align sequences using standard multiple sequence alignment tools , then use signals provided by structure neutral mutations for the inference of a consensus structure. frequently the mutual-information measure is used for this  <cit> . recently tools have been developed that use a combination of mfe and a covariation-score  <cit>  or probabilistic models compiled from large reference data-sets  <cit> . however, a multiple-sequence-alignment step assumes a well conserved sequence. this is often not so with swiftly evolving ncrna sequences, in this case incorrect sequence alignments can destroy any covariation signal.

this has motivated plan b, the use of the "sankoff-algorithm", an algorithm designed for the simultaneous alignment, folding and inference of a protosequence for a set of homologous structural rna sequences  <cit> . the recurrences combine sequence alignment and nussinov  folding  <cit> . the algorithm requires extreme computational resources  in time, and o in space, where n is the sequence length and m is the number of sequences). current implementations, foldalign  <cit> , dynalign  <cit>  and pmcomp  <cit> , are restricted implementations of the sankoff-algorithm which impose pragmatic limits on the size or shape of substructures.

the final approach  applies when no helpful level of sequence conservation is observed. we may exclude the sequence alignment step, predict secondary structures for each sequence  separately, and directly align the structures. because of the nested branching nature of rna structures, these are adequately represented as trees. the concept of a similarity measurement via edit operations, a standard procedure for string comparisons, has been generalised to trees  <cit> . tree comparison and tree alignment models have been proposed  <cit>  and implemented  <cit> . the crucial point in plan c is the question whether the initial independent folding produces at least some structures that align well and hence give clues as to the underlying consensus structure – when one exists. an increasing number of researchers have recently released novel rna structure analysis and prediction algorithms  <cit> . yet few algorithms are tested upon standardised example data-sets, and often they are not compared with algorithms of the same pedigree. algorithm evaluation is a regular event for protein structure prediction groups  <cit> , gene-prediction  <cit>  and multiple sequence alignments  <cit> . based on reliable data-sets, we evaluate:

• the viability of plan a, b, or c given tools available today, and

• the relative performance of the tools used within each plan.

we shall explicitly not evaluate computational efficiency, which  differs widely between the tools. we also do not evaluate user friendliness  except for some remarks in the discussion section. data-sets, documentation and relevant scripts are freely available from .

structural alignments and consensus structures
rna secondary structure inference is the prediction of base-pairs which form the in vivo structure, given only the sequence of bases. three general considerations apply:  the in vivo structure is not only predetermined by the primary structure, but also by cellular components such as chaperones, base modifications, and even by the transcriptional process itself. there are currently no computational tools available that assess these effects.  there are 'ribo-switches', whereby two or more functional structures exist for a given sequence  <cit> . such cases will fool all the tools studied here, because asking for a single consensus structure is simply the wrong question. on the other hand, the potential of conformational switching can be reliably detected  <cit> .  structures may contain pseudo-knots, which are ignored by most current tools due to reasons of computational complexity and scarcity of these motifs. we do not consider pseudoknots here. however, several comparative approaches that include pseudoknots are currently under development, and certainly merit a comparative study of their own. note that in an application scenario, we often do not know whether the considerations  apply.

the comparative approach to structure inference is initiated from a set of homologous rna sequences. attempts are made to infer the in-vivo structure for each of them, as well as a consensus structure that captures the common, relevant structural aspects. the consensus structure per se does not exist in vivo, and so some mathematical rigour should be applied when working with this notion.

an rna sequence is a string over the rna alphabet {a, c, g, u}. an rna sequence b = b <dig> ...,bn contains n bases, but no structural information. for comparative analysis, we are given the rna sequences b <dig> ...,bk. a secondary structure can be associated with each sequence b as a string s over the alphabet {""}, where parentheses in s must be properly nested, and b and s must be compatible: if  are matching parentheses, then  must be a legal base-pair. a base-pair is also denoted as bi·bj, si·sj, or simply i·j when the sequence is clear from the context. both sequences and structures may be padded with a gap symbol "-", in order to align sequences and structures of different lengths. for compatibility of padded sequences and structures, we require that bi = "-" iff si = "-".

a multiple structural alignment is a multiple sequence alignment of the  <dig> * k sequences, b <dig>  s <dig> ..., bk, sk, such that bi is compatible with si, and the following consistency criterion is satisfied: for any si and sj and any base-pair , we have  ≠ ")" and  ≠ "", then . this means that if one partner of a base-pair in sj is aligned to one partner in si, their partners must also be aligned to each other .

a consensus structure c for a multiple structural alignment can be determined by a majority rule approach using a threshold p with  <dig>  <p ≤  <dig>  we define ck = x if  = x for at least  sequences si, and ck = ".", otherwise. the latter definition is somewhat arbitrary; when relating the consensus structure to a particular sequence b in the alignment, we quietly turn those dots into gaps that align with gaps in b. for p =  <dig>  we speak of a strict consensus, and the base-pair set in c is the intersection of the base-pairs in all si.

a consensus structure exhibits base-pairs shared by the majority of structures under consideration, but has no sequence information associated with it. each individual structure for a concrete sequence typically has additional base-pairs which are properly nested between those that constitute the consensus. given a consensus structure c and a sequence b compatible with it, we can obtain a structure refold which is the best thermodynamic folding for b that exhibits the base-pairs specified by c, plus additional ones that do not conflict with the former. refolding can be achieved by rnafold with option -c . if b and s contain gaps, we remove them before refolding and reintroduce them in the same positions afterwards.

given a consistent structural alignment, it is easy to derive a consensus structure, as we can count majorities at individual positions. if the 5' partner of a base-pair passes the majority threshold, consistency implies that its 3' partner also makes it into the consensus.

given a consensus structure and a sequence alignment without structural information, we can approximate a structural alignment by computing si = refold. we call this structural alignment reconstruction. while all si will be consistent with c, and with each other as far as the base-pairs of c are concerned, they may be inconsistent for the base-pairs introduced in refolding. this is tolerable, since if we trust the consensus to capture the relevant common structural features, there is no need to require that all members of a family agree upon extra-consensus features.

we note in passing that it seems worthwhile to study the conditions under which consensus derivation and structural alignment reconstruction are mutually inverse operations, but such theoretical issues are outside our present scope.

interpreting database information
while the plans a, b and c we are about to evaluate strive to find a good consensus structure from sequence data, the "truth" available to us comes in a different form. structural databases only convey a consensus by example: they provide a reference sequence, say b <dig>  with an experimentally proved structure s <dig>  and provide a multiple sequence alignment of b <dig>  s <dig> and additional sequences b <dig> ..., bn in the family under consideration. the sequence alignment is chosen to exhibit structural similarities between the reference structure and the other family members, but in general, we do not know the precise model of achieving similarity, nor do we know whether this model has been solved to optimality.

one consequence of this situation would be to conclude that the reference structure is the only reliable anchor point available to us for evaluation. comparative analysis tools would then be evaluated by the capacity to predict this particular structure by using family information. this would be a meaningful way to proceed, however, the effect of structural homogeneity within a sequence family would go unmeasured, and so would the difficulty or success of exploiting it. we therefore proceed in a different way which we call consensus reconstruction.

the reference structure s <dig> need not be compatible with any bi except for i =  <dig>  however, we can still compute si := refold by treating bases as unpaired where they violate compatibility.  what we obtain in this way is a reconstructed structural alignment, which will be consistent to the extent that the reference structure indeed describes the common structural features, and to the extent that the database sequence alignment reflects these. in all our test cases, this alignment was overall consistent, an indicator that the families and their structural features are in fact well defined. from this alignment, we derive a consensus structure as explained above using a threshold p =  <dig> , which will serve as the standard of truth in our evaluation.

one may argue that our approach to reconstruct the truth is somewhat ad-hoc and should be replaced by a more systematic method. however, this is what the tools we evaluate try to achieve, and we should not add one of our own as the standard of truth. hence, our consensus reconstruction is designed to stay as close as possible to the database information.

caveats
results of observations based on the above measures must be interpreted with care. we list a number of caveats that must be kept in mind when proceeding to the subsequent sections.

use of defaults
in all tests, one could possibly obtain better predictions by tuning the program's parameters. we felt that it would be inappropriate to do so, since in the evaluation, we know the correct result and could use this knowledge in the tuning, whereas in a true application context, one does not have such guidance. hence we used the recommended defaults in all cases.

tool abuse
in some cases we apply a tool to data where we know that the model structure has features not recognised by the tool. an example is a structure with multiloops or pseudoknots, searched for with a tool that explicitly excludes such structures. we permit such cases, because again, in a true application context one does not know whether the tool is appropriate or not, and it is still of interest to see how close to the correct structure one can get.

standard of truth
we take for granted the correctness of structural alignments taken from the literature, and the consensus reconstructed thereof. should one of the tested algorithms produce a result that is actually better , it may be penalised. also, we do not consider a large number of data-sets here, it is possible that performance of some algorithms improves on a different selection of data-sets.

tools improve
our data reflect the state of the art in  <dig>  most of the tools tested are very recent, and their authors are still improving them. hence, not all observations will remain reproducible. in fact, we hope this study helps to obtain better results in the future.

methods
we have compiled rna sequence alignments consisting of up to  <dig> sequences derived from reliable sources . these have been used to test several rna analysis packages. each alignment contains at least one reference sequence b <dig> with  an experimentally verified secondary structure s <dig>  experimental verification of a structure may be from a variety of sources: x-ray crystallography, nmr, enzymatic structure probing or phylogenetic inference. a comparison of phylogenetic with x-ray crystallographic structures has shown the phylogenetic predictions of rrna to be very reliable   <cit> . this data specifies a "consensus by example", as explained above, to which our consensus reconstruction was applied to obtain the "true" consensus.

to avoid results bias, we constructed test alignments, with corresponding phylogenies that, wherever possible, were free of highly similar clades. in addition, we endeavoured to ensure that the reference sequence was central to the phylogeny, or more specifically, not an out group. to meet these requirements, sequences from large data-sets were sorted into high-similarity and medium-similarity groups , from which maximum-likelihood phylogenies  <cit>  were constructed. these were pruned until the desired size and topology was achieved. for each data-set two sequence alignments were constructed, one of high sequence identity  and the other more diverse data-set of medium sequence identity .

our data-sets are quite diverse and must for the purposes of this study be considered difficult to analyse in structural terms. the shape of ribosomal rna is believed to be influenced by interaction with ribosomal proteins. the shape of rnase p shows relatively little sequence and structure conservation, and furthermore, it contains pseudoknots which are generally excluded by prediction algorithms. transfer rnas are known to be a hard case for thermodynamic folding, primarily due to the propensity of modified bases which influence structure formation. all tools tested may perform better upon less complex data-sets, but the purpose of this study is not to show how good the algorithms are but to compare relative performance when prediction is difficult.

performance measures
sensitivity  and selectivity  are common measures for determining the accuracy of prediction methods  <cit> . selectivity is also known as the "specificity"  <cit>  and "positive predictive value"  <cit> . we use slightly modify versions of the standard definitions of x and y for examining rna secondary structure prediction:



where tp is the number of "true positives" , fn is the number of "false negatives"  and fp is the number of "false positives" . however, not all fp base-pairs are equally false! we classify fp base-pairs as either inconsistent, contradicting or compatible. predicted base-pairs which conflict with a base-pair in the reference structure are labelled inconsistent ). predicted base-pairs  which are non-nested with respect to the reference structure are labelled contradicting . note that some base-pairs may both contradict and be inconsistent with the reference structure. predicted base-pairs which are neither true positive, contradicting or inconsistent are labelled compatible and can be considered neutral with respect to algorithm accuracy. hence these are subtracted in the selectivity evaluation, their number is ξ in the above equation. it is of interest to note that the base-pair metric  <cit>  between the reference and predicted structures dbp is the sum of fn and fp, and hence is different from the measure used here.

a measure combining both selectivity and sensitivity is useful for ranking algorithms. for this we employ the matthews correlation coefficient  <cit>  defined below:



mcc ranges from - <dig> for extremely inaccurate  to  <dig> for very accurate predictions . when comparing rna structures tn =  <dig> occurs only in extreme examples, hence mcc generally ranges from  <dig> to  <dig>  furthermore, for the specific case of rna structure comparisons, mcc can be approximated by the arithmetic-mean or geometric-mean of x and y  <cit> .

RESULTS
single sequence methods
the accuracy of the mfe single sequence method has been evaluated elsewhere and was found to have an accuracy of 73% when averaged over many different rnas and "base-pair slippage" was tolerated in the evaluation  <cit> . a recent and more stringent work found mfe predictions had a sensitivity of 56% and selectivity of 46% for rnase p, srp and tmrna structures  <cit> . similar values are also reported by the "gutell lab" for trna and rrna structures  <cit> . we need to clarify the accuracy of this method on the particular data-sets we employ here for comparison with the multi-sequence methods. after all, if mfe folding worked perfectly for our given data-sets, there would be no need to resort to comparative methods.

mfold & rnafold
mfold  <cit>  and rnafold  <cit>  both implement the zuker-stiegler algorithm for computing minimal free energy  structures assuming a "nearest neighbour model" and using empirical estimates of thermodynamic parameters for neighbouring interactions and loop entropies to score structures. the algorithm is o in time and o in memory where n is the sequence length. both employ the same thermodynamic parameters  <cit> . hence, differences in the predictions are generally minor and are the result of slightly different implementations. there appears to be no significant differences in terms of algorithm accuracy.

the sensitivity, selectivity and correlation of mfe methods  ranged from 22–63%, 20–60% and  <dig> – <dig>  respectively . the low accuracies  are due to an alternative long-stem conformation of s. cerevisiae trna-phe which the free energy methods favour. mfold infers 'suboptimal' structures by calculating minimum free energy structures with the restriction that every possible base-pair is forced in a one-by-one fashion. unique structures are then ranked by energy. investigating the top two suboptimal structures from mfold resulted in an overall increase in the range of sensitivity, selectivity and correlation, 22–69%, 20–67% and  <dig> – <dig>  respectively. the predictions shown here are used to illustrate the potential advantages of using comparative analyses over single sequence methods.

sfold
sfold  <cit>  represents another energy-based single-sequence folding algorithm. for a given rna, sfold stochastically samples all possible structures in the boltzmann ensemble of secondary structures using conditional probabilities which are computed with the partition function  <cit> . clustering techniques could then be used to obtain representative ' likely ' structures. instead, the current implementation samples  <dig> structures, sorts these by energy, the minimum and maximum energy structures are computed and the energy range divided into  <dig> equally sized energy blocks. the minimum energy structure from each block is returned with ranking  <dig> to  <dig>  we consider the top  <dig> structures labelled 'sfold '. in terms of accuracy, the results are very similar to those of the zuker-stiegler single sequence methods, although with a slightly higher variance .

intrinsic limits of single sequence methods
there are systematic limits to the accuracy of single sequence prediction methods. the thermodynamics may not be accurate, as some parameters are extrapolated and parameter measuring conditions in vitro are different from in vivo conditions. indeed the thermodynamic model itself is an estimate of the real physics of rna folding. also, many bases of structural rnas are chemically modified by sugar methylation, pseudo-uridine, dihydrouracil, etc, these are generally ignored by these methods. kinetics of folding are also ignored. given only a single sequence, we have no way to distinguish base-pairs and structure elements important for the consensus from those that are peculiar for the given sequence. finally, some functional rnas have bistable structures, while in others, the structure is irrelevant, hence not conserved, and the optimal mfe structure is biologically meaningless. this is some justification of why researchers proceed to comparative methods.

comparative method: alignment folding 
to simulate realistic rna folding studies we use clustalw  <cit>  to re-align each of our test data-sets, then folded these using each of the methods mentioned below. the resultant predicted structures were then compared to our reconstructed consensus structures.

rnaalifold
rnaalifold  <cit>  implements an extension of the zuker-stiegler algorithm for computing a consensus structure from rna alignments. the algorithm computes an averaged energy matrix   and a covariation score matrix, augmented with penalties for inconsistent sequences, bij. a standard trace-back procedure is performed to recover a consensus structure with the optimal sum-of-average-energy-and-covariation-score . the algorithm is remarkably efficient o in time and o in memory.

the sensitivity, selectivity and correlation of the rnaalifold predictions ranged from 57–91%, 57–100% and  <dig> – <dig>  respectively, showing a significant increase in the accuracy measures when compared to the mfe-methods.

pfold
pfold implements a "stochastic context free grammar"  designed to produce a "prior probability distribution of rna structures" for an rna alignment input  <cit> . a maximum-likelihood phylogeny is used to weight posterior probabilities computed from large reference data-sets.

the algorithm is generally accurate and efficient. hence, the over-all sensitivity, selectivity and correlation of the pfold predictions ranged from 0–100%, 0–100% and  <dig> – <dig> , respectively. but removing those points where pfold predictions were empty structures  and ssu rrna , see figure 3), the prediction accuracies ranged from 66–100%, 89–100% and  <dig> – <dig> , respectively. the zeros are due to 'under-flow errors', a solution is presently under construction by the authors .

ilm
ilm  is one of the few comparative rna folding algorithms which can return pseudo-knotted structures  <cit> . it uses a combination of thermodynamic and mutual information content scores  <cit>  to produce a secondary structure. all possible stems  are generated and ranked according to a combination of thermodynamic and mutual-information scores. the stem with maximal score is selected, scores are updated and stems conflicting the selection removed, then the next highest scoring stem is selected. this algorithm is iterated until no stems remain. ilm generally ranked low in terms of selectivity and was not as sensitive as either rnaalifold or pfold on the high similarity data, but did improve on the medium similarity data-sets . the over-all sensitivity, selectivity and correlation of ilm predictions ranged from 44–100%, 37–75% and  <dig> – <dig> , respectively. to ensure the low selectivity values weren't due to the reference-structure being pseudo-knot free we re-evaluated ilm with reference-structures replete with pseudo-knots. the new sensitivity, selectivity and correlation values ranged from 31–100%, 26–75% and  <dig> – <dig> , in fact evaluating with pseudo-knotted structures did little to increase ilm selectivity. but, keep in mind that the sensitivity of the other  methods must decrease when a significant proportion of the true base-pairs are engaged in pseudo-knots.

the inclusion of pseudo-knots prediction vastly increases the number of possible secondary structures, this is why they are generally excluded from exhaustive folding algorithms. in addition, there is a general lack of experimentally derived thermodynamic parameters which include pseudo-knots. ilm is a method still under development, hence the performance may improve once pseudo-knots can be more accurately modelled.

comparative method: simultaneous sequence alignment and folding 
sankoff
the sankoff algorithm is a dynamic programming approach to obtain a common base-pair list with maximal sum of base-pair weights. basically, this is a merger of sequence alignment and nussinov  <cit>   folding dynamic programming methods  <cit> . sankoff's algorithm can be used to obtain both an alignment and consensus structure. full implementations of the "sankoff algorithm" for the solution of simultaneous rna folding, alignment and protosequence problems have proven too computationally taxing  in time, and o in space for sequence length n and m sequences) to be practical  <cit> . hence, three restricted versions of this algorithm have been implemented. these are foldalign  <cit> , dynalign  <cit>  and recently pmcomp has also been published  <cit> . carnac  <cit>  is another recent innovation designed to detect conserved stems in unaligned sequences, we include it here as a relative of the sankoff approach.

foldalign
foldalign  <cit>  can be interpreted as "a mixture of local alignment and maximum number of base-pairs algorithm"  <cit> . a combination of "clustal"  <cit>  and "consensus"  <cit>  heuristics are used to build multiple sequence alignments from pair-wise comparisons. restricting maximum motif size  and forbidding bifurcating structures  reduces the time complexity to o in time . a simple match-based scoring scheme is used to rank putative conserved structure elements.

the tool abuse caveat generally applies to the tool foldalign as all of our data-sets contain multi-loops. the use of foldalign for the prediction of global, multi-looped secondary structures is not recommended-as foldalign is specifically designed for the location of short regulatory motifs such as ires  <cit>  where the motifs are only related at the level of  structure and not at the level of sequence. hence the relatively poor sensitivity, selectivity and correlation, which ranged from 5–24%, 23–36% and  <dig> – <dig>  respectively, for our test data-sets.

dynalign
dynalign  <cit>  is a pairwise implementation of the sankoff algorithm, which uses a "full energy model" to locate a common low energy structure  and align two structural rnas. the computational complexity of the full sankoff is reduced by restricting the difference in the indices i and j of aligned nucleotides  to be less than m. in addition, dynalign uses the same method employed by mfold to reduce the conformation space, by limiting the size of internal loops  <cit> . the complexity is thus reduced to o.

the current dynalign implementation is restricted to pair-wise sequence comparisons. rather than compute all  pairwise foldings we compared all sequences with the reference structure. due to the computational expense of this algorithm it could only be used to predict trna and rnase p structures. dynalign performed well on the trna, medium sequence homology data-set . with this one high-scoring point removed, averaged sensitivity, selectivity and correlation values ranged from 32–54%, 33–54% and  <dig> – <dig>  respectively. comparing the performances of mfold and dynalign showed that mfold performance was always superior on the rnase p data-set, dynalign however did much better on the shorter and more diverse trna sequences. performance gains could be made by investing more computer time and refolding rnase p with larger ' maximum insert size', which was set to  <dig> during this study. the use of dynalign on the rnase p data-sets in this study is therefore a case of tool-abuse, as the parameters recommended by the authors of dynalign were not used .

carnac
the carnac algorithm, as mentioned previously, is not strictly an implementation of the sankoff algorithm. a set of filters are employed through which sets of sequences are passed in a pair-wise fashion  <cit> . sequences are scanned for stems and "high similarity" regions of sequences  are identified, a dynamic program is used to select conserved stems using anchor point and covariation information.

the carnac algorithm was remarkably selective at base-pair predictions. however, the sensitivity of the algorithm was generally low, although when evaluated with the correlation coefficient it is comparable to rnaalifold and pfold. sensitivity, selectivity and correlation values for carnac predictions ranged from 45–71%, 92–100% and  <dig> – <dig>  respectively. the sensitivity of carnac can be increased by constraining a minimum free energy fold  with the carnac predicted structure, but this cost in terms of selectivity. on average this increased the sensitivity by  <dig> , decreased the selectivity by  <dig>  and slightly increased the correlation by  <dig> .

alignment of predicted structures 
rna forester
rnaforester  <cit>  implements the tree alignment model. in contrast to approaches that produce only a similarity value, but no underlying alignment, it computes pairwise alignments of two input structures. rnaforester can produce either global or local alignments; we used the global mode. a structure alignment is itself a branching  structure; the set of matched base-pairs can be derived from it and evaluated as with the other approaches.

we used the trna and rnase p data-sets and generated structure single sequence predictions with rnafold. all predicted structures were aligned pairwise and a neighbour-joining approach used to cluster and align high similarity sequences and structure profiles. the highest scoring alignment was used to derive a predicted consensus that was evaluated against the consensus trna model structures. sensitivity, selectivity and correlation ranges of consensus structures computed from the highest scoring rnaforester alignments were 29–67%, 27–67% and  <dig> – <dig>  respectively. it seems likely that much of the inaccuracy of this approach is due to mfe structure prediction, however the structure-clustering approach frequently separates mis-folded mfe predictions from the accurate folds.

marna
the marna algorithm  <cit>  proceeds by constructing edge weights between nucleotides in a pairwise fashion. weights are structure-enhanced-sequence-similarities transformed from edit distances proposed by zhang  <cit> . phase two pipes the set of alignment edges into t-coffee  <cit>  for multiple alignment production. the resultant alignments are not strictly structural alignments in the sense defined above. rather, these are sequence alignments influenced by structure.

sensitivity, selectivity and correlation values of consensus structures computed from marna alignments of mfe structures ranged from 29–52%, 32–84% and  <dig> – <dig>  respectively. we also tried trimming high entropy base-pairs from the mfe predictions using the bound qij >  <dig>  where , , and pij are pair-probabilities computed using mccaskilps partition function  <cit> . the new accuracy ranges were 29–71%, 92–100% and  <dig> – <dig> . a related approach for trimming of low probability was recently shown to improve the selectivity of mfe predictions  <cit> . marna is generally less dependant upon the accuracy of the input structures hence performs slightly better with the poorly predicted trna structures than rnaforester.

discussion
we have evaluated three different strategies for comparative structure prediction, and altogether eight tools . the results of which are summarised in figures  <dig> & <dig>  a surprising discovery given that the test data-sets are so diverse is that algorithm specific clusters formed in sensitivity versus selectivity scatter plots, indicating algorithm-specific eccentricities. a number of algorithms which might have been evaluated here have been excluded, primarily due to the heavy computational costs of the various implementations on our longer data-sets. we favoured recent algorithms which could be compiled on modern computers and those with input and output which could be simply dealt with  representations favoured by a minority of researchers).

practical recommendations
for well aligned short sequences, both pfold and rnaalifold generally perform well, pfold performed marginally better than rnaalifold. it is likely that some moderate refinements to rnaalifold would improve accuracy without altering the efficiency, for example, if gaps were not penalised in the free-energy evaluation and a more sophisticated model for scoring mutations was employed, perhaps ribosum matrices  <cit>  could be used to weight base-pair bonuses and penalties. for well aligned, long sequences the performance and speed of rnaalifold was excellent. for data-sets consisting of short  and diverse sequences dynalign might do well, as it does not require sequence similarity – in fact the scoring function does not include sequence comparison. otherwise, one might choose to use a mixture of rnaalifold and/or pfold to fold similar clades and rnaforester and/or marna to align folded clades. advocates of plan a should note that many multiple sequence alignment algorithms generally do not favour transitions over transversions or employ ad hoc 2-parameter methods to model these . structural rna sequences however evolve rapidly via structure neutral mutations which are frequently transitions and rarely transversions  <cit> . multiple sequence algorithms which employ more complex yet more accurate models of sequence evolution will undoubtedly produce "better" alignments for folding.

carnac produced highly selective structures for all the test data-sets, which if used to constrain a free energy fold produced sensitive predictions with a cost to selectivity. the consistency of carnac performance is remarkable, for all the data-sets considered here this heuristic approach performed well. it is however unclear how carnac will perform on highly diverse data-sets.

for advocates of plan c, we have an encouraging message: both marna and rnaforester perform better on the medium similarity data than on high similarity data. this seems paradoxical at first glance, but one must understand that for an approach purely based on predicted structures, high sequence similarity can be a curse rather than a blessing: if sequences are very similar, they may jointly fold into the wrong mfe structure. with more sequence variation, it becomes more likely that at least some family members have good predictions, which by their mutual similarity can be picked out from the rest. this means that especially in the case of low sequence similarity, where nothing else works, plan c, currently the least explored strategy of all, has a certain promise.

CONCLUSIONS
finally, let us outline some directions for future research.

an implementation of the single sequence pseudoknot algorithms  <cit>  employing similar strategies to rnaalifold  <cit>  for alignment folding would be most useful. based upon the rnaalifold results this approach would dramatically increase the accuracy of these algorithms upon certain data-sets. also, an extension of these allowing constrained foldings to incorporate prior knowledge would be of assistance, this has proved extremely useful for mfe predictions. sampling structures from reference alignments is also likely to prove beneficial. the implementation of fast and accurate variants of the sankoff algorithm remains an open problem.

again allowing constrained foldings and alignments would be useful. the further development of "blast-like" folding heuristics for this should be a priority, obviously carnac is a good start. the marna approach for producing structurally enhanced multiple alignments produced rather selective results after trimming high-entropy base-pairs from mfe predictions. this suggests that weighting edit-distances with partition-function derived probabilities or entropies will produce reasonable rna alignments. a consensus structure could then be derived from mfe-structures or from pfold or rnaalifold predictions on the resultant alignment. this approach would effectively decouple the sankoff algorithm into manageable structure-enhanced-alignment and folding stages.

note added in proof
two further developments are likely to increase the power of plan c. pure multiple structure alignment  presented in  <cit>  may leave out some misfolded structures from a progressively constructed profile aligment. a small but representative set of near-optimal structures can now be derived by abstract shape analysis  <cit> . combining both approaches, one could consider a progressive multiple alignment approach where these representative, near-optimal structures are included for each sequence.

more training data is essential for this field to progress, for this homology search tools are essential. infernal  <cit>  used to construct the rfam database  <cit>  is an excellent approach but sensitivity might be increased with a phylogenetic approach and rna-specific sequence search tools. the implementation of methods combining energetics, covariation  <cit>  and co-transcriptional folding  <cit>  in a statistically reasonable manner is also a potentially fruitful direction for development.

authors' contributions
ppg carried out the experiments, the analysis and drafted the manuscript. rg suggested comparing comparative structure prediction methods and assisted in the manuscript preparation. all authors read and approved the final manuscript.

