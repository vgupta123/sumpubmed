BACKGROUND
in microarray data analysis, the process of converting probe-level flourescent intensities from a scanner to gene-level expression estimates is commonly referred to as preprocessing. the vast majority of preprocessing algorithms require multiple arrays to be analyzed simultaneously, and in general such multi-array preprocessing algorithms outperform single-array algorithms  <cit> . therefore, it is not surprising that four of the most widely used preprocessing algorithms - rma  <cit> , gcrma  <cit> , mbei  <cit> , and plier  <cit>  - are multi-array.

however, multi-array preprocessing algorithms restrict scientific inquiry because it is necessary to analyze all arrays simultaneously. because data preprocessed separately cannot be combined without introducing artifacts  <cit> , the total number of arrays one can compare is limited by computer memory, restricting large meta-analyses; furthermore, datasets that grow incrementally need to be preprocessed each time an array is added. lastly, for microarrays to aid in clinical diagnosis and treatment, one needs to obtain information based on a single sample hybridized to a single microarray.

recent work by mccall et al.  provided a method of single-array preprocessing, frozen robust multiarray analysis , that retains the advantages of multi-array preprocessing. the fundamental idea behind frma is a simple but powerful one - parameter estimates are precomputed based on a large biologically diverse database of microarrays and then frozen. these frozen parameter estimates can then be used to preprocess new array. in addition to allowing arrays to be preprocessed individually or in small batches and combined for subsequent analysis, frma resulted in improved performance when analyzing microarray data in the typical multi-array setting, especially when the new data consisted of arrays from different batches  <cit> .

it should be noted that frma allows the user to easily combine affymetrix microarrays from different batches; however, these arrays must all be from the same platform. for example, frma cannot be used to preprocess affymetrix human genome u133a and u <dig> plus  <dig>  arrays together. to combine different platforms, one would need to first preprocess the data from each platform separately using frma and then combine the data using an additional batch correction algorithm such as combat  <cit>  or surrogate variable analysis   <cit> .

the primary limitation of frma is that it requires a curated database of microarrays to generate the frozen parameter vectors. as such, frma has currently been implemented for only the three most widely used affymetrix microarray platforms - human genome u <dig> plus  <dig> , human genome u133a, and mouse genome  <dig>  <dig> . efforts are underway to implement frma on two more platforms - arabidopsis ath <dig> genome and rat genome  <dig>  <dig> .

to address this limitation, we have created an r package, frmatools, designed to allow the user to easily create the frozen parameter vectors necessary to run frma. by decentralizing frma implementation, each group can contribute a database and parameter estimates specific to their area of research. we begin by describing the frmatools package itself and how it interfaces with the standard frma package. next we examine the size and scope of data necessary for a platform-wide implementation of frma. we then turn our attention to situations in which one might want to generate custom parameter vectors for a specific experiment.

 <dig> implementation
the computational tools described here are written in the open-source statistical language r and are available as part of the bioconductor project  <cit> , a collaborative effort to produce computational tools for biological data. as previously described in  <cit> , we have implemented the primary tools necessary to preprocess and analyzed data from a single microarray hybridization in the r package, frma. this package provides the fundamental framework for single array preprocessing and analysis; however, it requires precomputed frozen parameter vectors. for platforms on which frma has been already implemented these frozen parameter vectors are contained in bioconductor data packages of the form <platform>frmavecs and are automatically used by frma. to extend the frma algorithm to a new platform, one need only create a data package or supply ones own frozen parameter vectors directly to frma.

to preprocess single arrays using frma, one needs  <dig> frozen parameter vectors:  the reference normalization distribution,  the probe effect estimates,  the within batch residual variance,  the between batch residual variance, and  the within probeset average standard deviation. optionally, a sixth vector of median standard errors is necessary to compute a measure of array quality. by default, the frma function attempts to load the appropriate data package for the affybatch object given as input. however, it is possible for the user to supply some or all of the frozen parameter vectors allowing the user to preprocess data using their own frma implementation.

the frmatools package was developed to allow users to easily create their own frozen parameter vectors for use with frma. it contains two primary functions - makevectorsaffybatch and makevectorpackage. the former is used to create the frozen parameter vectors used by frma; the latter both creates the vectors and builds a r data package for them. by creating a data package, one can share frozen parameter vectors with other researchers and track changes over time. the interface between the affy, frma, and frmatools packages can best be understood by examining a typical workflow .

 <dig> 
RESULTS
 <dig>  training data
the frozen parameter vectors used in the frma algorithm are generated using a training dataset comprised of a balanced sample from multiple batches. for example, in the three current implementations of frma,  <dig> arrays from each of  <dig> different batches are used. in this case, batch is defined as a unique combination of tissue type and experiment id . here the between batch variability in probe effects captures all the potential differences between experiments - different labs, different technicians, different environmental conditions, etc. - as well as differences due to the hybridized tissue type.

one of the fundamental assumptions underlying frma is that the training data is both large enough and diverse enough that the vast majority of probes that differ in performance across batches can be detected as such in the training data. some probes may only perform poorly in a small handful of tissues or laboratory conditions, so it is advantageous to include as many different tissues and experiments as possible to maximize our chance of detecting unreliable probes. when implementing frma on widely used platforms for which there is a plethora of publicly available data, it is advisable to use as many arrays as possible. this allows one to obtain the most information about the behavoir of probes across a wide variety of tissues and experiments. in these situations, the size of the training dataset should only be constrained by computer memory.

for a fixed amount of memory corresponding to a fixed number of arrays in the training dataset, the primary question is whether it is better to include a greater number of batches  or a greater number of arrays per batch . to address this question, we examined a variety of training datasets of varying number of batches and batch size. for each combination we repeated the random sampling used to select the training arrays  <dig> times. for each set of parameter vectors, we preprocessed a single average-quality array  and computed the median absolute deviation  across the  <dig> replicates for each probeset. to assess the consistency of frma for a variety of training datasets, we report the median and inter-quartile range  of the within-gene mads .

median and iqr of the across-replicate median absolute deviations  for different batch sizes  and number of batches  used to train the frma algorithm. the median provides an estimate of the typical mad; the iqr provides an estimate of the variability seen in mads across replicates.

as one would expect, increasing the number of batches while holding batch size constent, typically improves the consistency of the results. however, increasing batch size while holding the number of batches constant appears to result in increased consistency in general, but this increase is far less reliable than increasing the number of batches. specifically, increasing the batch size from  <dig> to  <dig> is just as likely to decrease consistency as increase it. however, increasing batch size from  <dig> to  <dig> or  <dig> to  <dig> yields increased consistency more often than not, and increasing batch size from  <dig> to  <dig>  results in increased consistency for all batch sizes examined. this suggests that consistency is driven primarily by the ability to detect probes whose behavior differs between batches rather than detection of probes that are highly variable within batches and that detection of highly variable probes within batches requires a sizable investment in terms of the number of arrays per batch. finally, the improvements in consistency due to adding additional batches, seem to diminish as the number of batches increases. taken together these findings suggest that, one should first seek to increase the number of batches and then the number of samples per batch.

however, for future frma implementations, computer memory may not be the limiting factor. for newer microarray platforms, it is often the case that a relatively small number of labs have conducted one or more large experiments possibly involving a wide variety of tissues. as table  <dig> suggests, this is not the ideal situation and training frma on such data may not capture the behavior of a number of probes. in such a situation, it may be more appropriate to consider a custom frma implementation for either a single large dataset or a single lab. such an implementation will be described in section  <dig> .

 <dig>  alternative cdf
affymetrix microarray platforms by default use probe target definitions based on the knowledge available when they were created. since then, our understanding of the human and mouse transcriptomes has greatly improved. multiple studies have demonstrated that using updated probe annotations can significantly improve gene expression estimates and detection of differential expression  <cit> .

while the original implementation of frma was based on the default affymetrix probe annotation, the latest version of the frma package gives one the option to use the version  <dig> entrez gene probe annotation  <cit> . however, there are numerous other probe annotations that might be of interest . the frmatools package allows one to choose any of the alternative annotations to create one's own frma implementation.

 <dig>  new platform
although we strive to implement frma on all affymetrix microarray platforms for which there is a sufficient amount of publicly available data, frma may not currently be implemented on a platform of interest. if there is enough data publicly available, one has the option of creating one's own implementation by following the recommendations outlined in section  <dig>  and using the frmatools package described in section  <dig>  however, for a relatively new microarray platform, there may not be enough publicly available data. in this case, one might consider creating a custom frma implementation. we describe this option in the following section.

 <dig>  custom implementations of frma
the frma preprocessing algorithm typically requires a large diverse dataset to estimate the frozen parameters. the dataset is required to span a large number of batches in order to capture the variability in probe behavior, so that when preprocessing a new array, one can appropriately down-weight probes known to have either large between- or within-batch variance. while it is always possible that a probe that appears reliable in the training data performs poorly on a new array, the chance of this occurring can be minimized by training on a large diverse dataset.

however, a large diverse dataset is not always available either because the microarray platform is relatively new or because the data being analyzed differs from the publicly available data in some fundamental manner . in these cases, one might consider creating one's own custom frma implementation that is specific to a certain dataset, lab, or experiment.

 <dig> . <dig> rma-like implementation
if it is infeasible  or undesireable  to use a standard frma implementation to analyze one's data, it could be beneficial to implement frma in a manner that mimics rma. while the primary advantage of frma over rma is the ability to preprocess a single microarray, the frma algorithm also improved the rma model by recognizing that some probes within a probe set were more variable than others and down-weighting such probes  <cit> . for this reason, one might be interested in applying frma within a large dataset in the same manner one would apply rma.

such an implementation can easily be accomplished using the frmatools package. to illustrate the ability of frma to mimic rma when analyzing a single dataset, we compared the expression values generated by rma to those generated by  <dig> different frma implementations:

 <dig>  the default frma implementation trained on a large diverse sample of arrays,

 <dig>  frma trained on a balanced random sample from the experiment being analyzed,

 <dig>  same as  but using all the arrays to form the reference normalization distribution.

as one would expect, the differences in expression values are much greater between the default frma implementation and rma than between the two custom frma implementations and rma . it is important to assess whether the observed differences between the custom frma implementation and rma are due differences in performance. to assess this, we used a large pseudo-simulated spike-in dataset generated by extending the affymetrix human genome u133a spike-in dataset. specifically, we replicated each of the original arrays  <dig> times to create  <dig> batches of  <dig> arrays, each with a latin square spike-in design. we then added both random noise and random batch effects to each probe based on that probe's observed behavior in a large biologically diverse dataset. this resulted in a dataset with probe-specific noise and batch effects comparable to a typical large dataset.

we used this extended spike-in dataset to assess the performance of rma and frma trained on only these data. specifically, we assessed the accuracy, precision, and overall performance of both methods in three expression strata using the methodology proposed in  <cit> . we assessed accuracy by computing the signal detection slope, the slope from regressing observed expression on nominal concentration in the log <dig> scale. the signal detect slope is the expected difference in observed expression when the true difference is a fold change of  <dig>  with the optimal result being a slope of one. we assessed precision by computing the standard deviation and  <dig> th percentile of the null log-ratios, log-ratios from transcripts which were not spiked in and therefore should not be differentially expressed. the standard deviation is an estimate of the variability in log-ratios for non-differentially expressed genes; the  <dig> th percentile assesses outliers -  <dig> % of non-differentially expressed genes are expected to exceed this value. finally, we report the signal-to-noise ratio  and the probability of a gene with a true log <dig> fold change of  <dig> being in a list of the  <dig> genes with the highest fold change .

in all three strata, frma outperformed rma with regard to precision and overall performance . in the low and medium strata, frma also had better accuracy than rma; however, in the high strata, rma and frma had comparable accuracy with rma performing slightly better. the primary difference between the two preprocessing methods is that frma does not treat all probes as equally reliable - it down-weights probes that have high within- or between-batch variance. these results suggest that when preprocessing a fairly large dataset, it is potentially beneficial to use a custom frma implementation if a standard frma implementation is not available.

comparison of rma and frma trained on the modified spike-in data. for three intensity strata, we report assessments of accuracy , precision , and overall performance .

 <dig> . <dig> incrementally growing, large dataset
another reason one might wish to create a custom frma implementation is to analyze a dataset in which samples are added in small batches over a period of time and intermediate analysis would be beneficial. for example, suppose researchers are interested in investigating a gene signature for breast cancer prognosis when treated with a novel chemotheraputic drug. at the start of treatment, a biopsy of each patient's breast tumor is hybridized to a single microarray. as the results begin to trickle in, the researchers are able to train the frma model based on the currently available data and use that model to predict the response of patients currently undergoing treatment.

in contrast, most multi-array preprocessing methods would require the entire dataset to be preprocessed each time a new array was added. this poses several potential problems. first, although preprocessing hundreds of arrays with rma requires relatively little computational time, other multi-array preprocessing methods take significantly longer. second, while rma requires little computational time, it does require large amounts of memory - preprocessing  <dig> arrays requires over 11gb of ram; for  <dig> arrays, this increases to over 30gb. third, once an array has been preprocessed with frma, it's gene expression estimates will remain the same regardless of any additional arrays that are added to the data. the same cannot be said of multi-array preprocessing methods, which would provide different expression estimates for a given array each time an additional array is added and the data are preprocessed again.

to assess the applicability of the frma algorithm in such a situation, we consider a dataset of  <dig> breast tumor samples  collected from patients over  <dig> days from jan 29th,  <dig> to march 20th,  <dig>  the arrays were grouped in  <dig> batches by the date on which the array was scanned. we defined a batch as consecutive dates over which at least  <dig> arrays were hybridized. only  <dig> out of the  <dig> arrays did not fall into a batch.

first, we trained the frma algorithm using  <dig> arrays randomly selected from each of the  <dig> batches and stored the resulting parameter vectors. we then trained the frma algorithm using only the first n batches where we let n vary from  <dig> to  <dig>  we then used each of these sets of parameter vectors to preprocess all  <dig> arrays. finally, we subtracted the expression estimates based on all  <dig> batches from the expression estimates based on each of the other subsets. as one would expect, the distributions of these differences are centered close to zero and their spread decreases as the number of training batches increases . the bias, deviation of the center of the distribution from zero, can be explained primarily by the quantile normalization reference distribution. in fact, if we quantile normalize to a fixed reference distribution, all of the distributions are centered roughly at zero . on the other hand, the spread of the distribution is primarily due to the summarization step, in particular, the probe effect estimation. from this example, we can also gain insight into the number of batches one should include in the training data for a custom frma implementation. while training on the first  <dig> batches produced expression estimates that differed the most from training on the full dataset, the differences were actually remarkably small -  <dig> % of the absolute differences exceeded  <dig>  and  <dig> % exceeded  <dig> , with the median absolute difference equal to  <dig> . if instead one were to train on roughly the first half of the data , only  <dig> % of the absolute differences exceeded  <dig>  and 2% exceeded  <dig> , with the median absolute difference equal to  <dig> . this suggests that training on just the first  <dig> batches would allow one to detect moderate to large changes in gene expression and that training on the first half of the data, perhaps from an initial pilot study, would be enough to detect relatively small changes in gene expression.

 <dig> . <dig> a different definition of batch
in the current implementations of frma, batch is defined as the combination of tissue and experiment. however, there are certainly batch effects present within many experiments  <cit> ; therefore, it could be advantageous to define batch in a different way. for example, in section  <dig> . <dig> we defined batch based on the date on which an array was scanned. there are many other potential sources of variation in an experiment any of which could be used to investigate batch effects. the frmatools package allows the user the flexibility to define batch in any way he or she desires.

in fact, even if the user eventually plans to use a preprocessing method other than frma, examining the frozen parameter vectors generated by frmatools may provide insights in to batch effects present in the data that need to be addressed in some manner. specifically, we can compute an f-statistic for each probe, defined as the ratio of between-batch and within-batch variance, to assess whether that probe displays a batch effect in a given data set. to illustrate this, we computed these ratios for the data presented in section  <dig> . <dig> and the data presented in section  <dig> . <dig>  in the former case,  <dig> % of probes show a statistically significant batch effect, while in the latter case, only  <dig> % of probes show a batch effect. thus by simply comparing the within- and between-batch probe variances produced by frmatools, we can assess the extent of batch effects within a given dataset.

 <dig> 
CONCLUSIONS
we have described a novel r package, frmatools, that allows the user to easily create his or her own frma implementation. we have described how this new package fits into a standard analysis workflow and the size and scope of data necessary to make use of it. this package will allow researchers to use frma on a much wider range of datasets and annotations. furthermore, we have described several situations in which a dataset-specific custom frma implementation might be advantageous. the frmatools package makes such custom implemenations straightforward. the frmatools package is freely available as part of the bioconductor project and as additional file  <dig> 

competing interests
the authors declare that they have no competing interests.

availability and requirements
• project name: frmatools

• project home page: http://www.bioconductor.org/packages/release/bioc/html/frmatools.html

• operating system: platform independent

• programming language: r

• other requirements: r >=  <dig> 

• license: gnu gpl

• any restrictions to use by non-academics: none

authors' contributions
mnm conceived the study, created the r package, and wrote the manuscript. rai conceived the study and edited the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
frmatools package. the r/bioconductor package frmatools , providing tools for advanced use of the frma package.

click here for file

 acknowledgements and funding
we thank the maintainers of geo and arrayexpress for making the data publicly available. we thank marvin newhouse, harris jaffe, and jiong yang for helping manage the data. the work of mnm was partially funded by national institutes of health . the work of rai was partially funded by national institutes of health .
