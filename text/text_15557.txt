BACKGROUND
a major goal of this paper is to describe an ongoing research effort to ascertain the most important lesion features that change over time as rendered on computed tomography , as well as other imaging modalities, using statistical learning theory  and complex adaptive system  paradigms, to reliably and reproducibly predict patient outcomes in response to targeted therapies for metastatic colorectal carcinoma. there is currently a great deal of interest in the establishment of radiologic imaging as a valid biomarker for assessing the response of cancer to a variety of treatments  <cit> . imaging holds the promise of serving as an earlier, more accurate predictor of patient outcomes than serologic or clinical parameters  <cit> . ct is the most widely used imaging modality to assess the change in patient tumor burden using quantitative measures of tumor lesion volume such as the two dimensional who  <cit>  or one dimensional criteria response evaluation criteria in solid tumors   <cit>  used to measure patient response.

little work has been done in validating imaging as a surrogate endpoint for patient overall survival in response to the many new therapies that are being developed to treat advanced cancer in patients on defined protocols or for the vastly larger pool of patients having imaging used to assess their likely outcome in response to established therapies. to date there has been no mechanism to have radiologists consistently use reproducible metrics of tumor response validated by a high level of performance in predicting patient outcome at individual sites or collaborating sites regionally or nationally. difficulties arise in the logistics of having radiologists reproducibly use similar terms and methods of measuring lesion change  <cit> , and in relating imaging findings to patient outcome  <cit> . most prior work has been directed at measuring lesion size on ct with recist and who  measurements  <cit> , and more recently with 3-d volumetric analyses  <cit>  without considering how change in size relates to outcome. other information contained on ct and magnetic resonance imaging  scans regarding lesion appearance  has not been addressed adequately  <cit> .

recist  <dig> , the current standard  <cit>  used to evaluate treatment response for patients on new protocols for cancer, is a semi-quantitative scoring system which considers only existing lesion size change measurements and interval development of new lesions in placing patients into different response categories. recently positron emission tomography  and pet fused with ct  have been used to assess cancer response, but the same issues of reproducibly relating and validating imaging findings with regard to patient outcome are present.

we have chosen to study patients with metastatic colorectal carcinoma for this pilot project to learn whether statistical learning theory can improve the performance of radiologists using ct in predicting patient treatment response to therapy compared with the more traditional recist standard. ct is currently the most commonly used imaging modality to evaluate response to treatment of a variety of solid tumors including colorectal carcinoma. colorectal carcinoma arises from the epithelial lining cells of the large intestine. systemic chemotherapy, with or without surgery and radiation becomes the treatment of choice for patients with metastatic disease. survival in these patients is usually short, but therefore readily measurable as a marker for the success or failure of different treatments. various new therapies are being developed to improve survival, which have assorted mechanisms of action including angiogenesis modulators and epidermal growth factor inhibitors, which can be evaluated by imaging biomarkers. more accurately predicting patient outcome in patients early in the course of therapy has the potential to accelerate drug development in phase ii and phase iii trials, improve patient survival, and avoid prolonged potentially toxic therapies in patients unlikely to do well. this research project considers ct and colon cancer but our methods of analyzing imaging results is readily applied to other modalities  and other types of malignancies.

recist   <cit>  and its predecessors, primarily the who method  <cit> , define standard measurement methods for converting visual image observations into a quantitative and statistically tractable framework for measuring tumor size response to therapy. the recist criteria were modified in  <dig>  <cit>  to make measurement practices procedurally more consistent across multiple trials and accommodate improvements in ct and mri scanners. each method uses a pragmatically simplistic technique, which is dependent on observer judgment, to determine lesion boundaries. who defines its tumor measurement by summing a group of individual masses, each of which is assessed by the cross product of its greatest diameter and largest perpendicular diameter. recist uses a linear measure. recist was designed to be sufficiently aligned with past who practices such that no major discrepancy would occur in the partial response between the old and new guidelines, while specifying procedures on such items as the maximum number of solid tumor lesions that should be measured  <cit>  and the maximum number of lesions measured in any one organ  <cit> . recist target lesions have to be acquired with image slice thicknesses no larger than one half the diameter of the measured lesion, which results in recommending that 10-mm objects be imaged with 5-mm image slice thicknesses, while limiting measurable target lesions to no smaller than 10mm except under special circumstances. after target lesions are measured using either single linear summation  or the bilinear product approach , the results are subsequently assigned to response-defined categories of complete response , partial response , stable disease , and progressive disease . by an apparently subjective criteria, recist defined pr as a more than 30% linear decrease of the linear sums of the target lesions  and pd as a more than 20% increase . this contrasts with who criteria, in which those boundaries were set volumetrically at 65% and 40%, respectively  <cit> .

because recist was framed in the context of individual slices  the research community is currently re-exploring the obvious gaps in both recist and who criteria, which are constrained by the limits of earlier technology. little attention has been paid to acknowledging inter and intra observer variability. that is, the reader makes his/her measurements unassisted by anything other than the most rudimentary form of image-processing technology , resulting in significant differences among readers and within single readers over time. aside from suggesting the value of multiple independent observers, current approaches are hardly likely to improve decision making consistency on fuzzily bounded objects. neither recist nor who provide especially rigorous guidance on the subject of observer variability aside from recommending review panels and independent observers. disagreement among observers  <cit>  has been noted to be as high as 15% to 40% in these contexts and may not be ideally remedied by consensus or tie preventing arrangements. in fact, there is little scientific literature that resolves the question of what would constitute a sufficient number of observers  <cit> . to minimize reader variation, three observers have generally been employed. this odd-numbered arrangement offers a pragmatic means of averaging data and avoiding a tie, but has no theoretical basis. larger numbers of readers may permit some greater level of certainty but is impractical or unaffordable in a real-world context. furthermore, providing only nominal guidance on slice thickness, recist does not address at any length image acquisition components that inevitably result in significant lesion contrast differences within and between studies.

however, recist has served a useful historic purpose in grouping image data into the four response classifications . since diameter measurements are best determined on smoothly shaped, distinct tumor boundaries—an ideal circumstance encountered infrequently—measurement variability inherent in such judgments is not adequately reflected in the recorded data and is therefore a confounder that cannot be corrected systematically. tumors with irregular or diffuse boundaries pose the most significant challenge to data extraction and are highly observer dependent.


               despite these recognized limitations, studies continue to be directed towards refining the recist paradigm by minor, incremental modifications. this is a major reason for proposing this new slt technology, which can take advantage of the new feature vector components resulting from these newer imaging modalities, such as ct and mri.
            feature vector components are the elements of the input vector used by the statistical learning theory algorithms in arriving at an intelligent decision.

finally, the national cancer institute  cancer treatment evaluation program in its review of proposed trials acknowledges both who criteria and recist as useful for estimating tumor size response to therapies, but neither mandates nor requires either for use in its sponsored clinical trials.

consequently, we propose to use complex adaptive systems  and slt to develop and test intelligent post processing software to address these problems. this software is designed, in part, to identify false positive  and false negative  errors. patients that fall into the fn error group should have been treated but were not while the patients that fall into the fp error category needlessly suffer the morbidity of treatment as well as generating significant, unnecessary treatment cost. consequently, both type i  and type ii  errors are significant and should be minimized, which is possible with the proposed stl algorithms that adapt to the environment by using a feedback mechanism to develop intelligent emergent interpretation behavior by radiologists.

RESULTS
recist, who individually and with additional information
eight experiments were designed to measure the individual performance slt accuracy of recist and who as well as recist and who slt improved performance with additional information. these experiments use the “one hold out” cross-validation technique because the validation sets for 5-fold cross-validation did not contain enough samples for statistically valid conclusions. two slt paradigms were used: a non-linear support vector machine  that employed a sigmoid mapping kernel, and a linear logistics regression  approach.

the svms were manually trained by an iterative process rather than using an evolutionary programming  approach, which if implemented may have resulted in an improved svm system performance. the authors have developed and ep / evolutionary strategies  svm hybrid  that efficiently ascertains, by an optimal search mechanism, the optimal mapping kernel parameters used in mapping the feature data from the non-linear input space to the linear feature space. this hybrid was not used in this analysis because the software package used to configure the dataset for experiments, perform the svm and lr techniques, and then run the receiver operator characteristic  analysis did not contain the ability to use these advanced ep/es-svm theories. rather, an iterative process of manually changing the svm parameters in small steps was employed. orange, the software package used, acts as a wrapper for the well known lib svm libraries, but does not offer any optimization algorithms. this software package requires the user to ascertain, by experiment, the mapping kernel parameters which result in the best possible performance.

the group evaluated included  <dig> patients with metastatic colon cancer treated with a last line therapy , who had a median survival of  <dig> months. survival was used as the gold standard diagnosis for measures of performance . a good response was considered survival beyond  <dig> months  and a poor response was considered death at or prior to  <dig> months . the experiments had either  <dig>   <dig>  or  <dig> samples, which were representative of the  <dig> lesions,  <dig> patients who had at least one lesion, and  <dig> patients who had multiple lesions. when only one or two lesions per patient are used, lesions were selected at random. the total feature vector length contained  <dig> components, where each experiment utilized subset elements of this feature vector. table  <dig> depicts the information content for these eight experiments: four for recist and four for who, and delineates the number and type of feature used as well as the sample size.

experimental designs to ascertain performance accuracy for recist and who

area under the roc curve  performance results for the four recist only and the four who only experiments are depicted in figure  <dig>  figure  <dig> contains  <dig> curves. curves  <dig> and  <dig> are auc svm and lr values for recist only, while curves  <dig> and  <dig> are the svm and lr results for who only. in general, this set of studies showed the following:

• svm performance for both recist and who are better than the lr performance for all experiments . this is an expected result because the svm paradigm captures predictive and discriminating information “hidden” in the non-linear regions of the input space, where the lr paradigm, because of its linear processing only, cannot “see” this discriminating information.

• recist performed slightly better than who for experiments  <dig>   <dig> and  <dig>  but out performed who in experiment  <dig>  when using svm processing . {note: remember that two sets of  <dig> experiments were performed:  <dig> for recist and  <dig> for who}.this means that including more patients  with only one lesion has more predictive power than including less patients with  <dig> or more lesions, at least for this population. this preliminary result may disagree with intuition, which says that more lesions/patient provides more information. however, with these non-linear algorithms perhaps the manner in which the feature vector components interact and their information diversity may be more significant than the number of lesions/patient processed. this is an area for further research study using experimental sensitivities.

• both recist and who alone performed equally, but with a fair to poor auc of  <dig>  using the non-linear kernelized svm paradigm. .

• logistics regression  performed worse, especially with recist, when using  <dig> lesions per patient compared to using just  <dig> lesion. this may be because more patients complicated the structure of the input space, thereby making it more non-linear because of coupling effects. consequently, the linear recist measures cannot capture the information in these non-linear regions, but who can with a higher resultant auc of ~ <dig> . this may be because who defines its tumor measurement by summing a group of individual masses; each lesion is assessed by the cross product of its greatest diameter and its largest perpendicular bisector, a mathematical operation that contains a non-linear component. this is also a topic for further investigation.

• experiment  <dig>  where all lesions are processed independent of patient, provides the least improvement between lr and svm processing when compared to the baseline experiment  <dig> , as well as when using additional information . that is, svm processing for experiment  <dig> increased the auc for both recist and who performance from ~ <dig>  to ~ <dig>  . however, the svm processing for experiments  <dig> and  <dig> increased performance, when compared to recist and who alone, by an average of ~25%  for experiment  <dig> and an average improvement of ~23%  for experiment  <dig>  this is also a topic for further research.

• note the negatively correlated lr values for experiment  <dig>  this result occurred for both recist and who, and is again a reflection of the fact that linear processing techniques cannot capture information “hiding” in the non-linear region of the solution space. note that the non-linear processing provided by the svm for both recist and who using only these feature inputs resulted in a ~ <dig>  auc. this result says that, when compared to experiments  <dig> through  <dig>  both the basic recist and who benefited from additional information added in the input feature vector. this result implies adding imaging components to the feature vector should also increase performance and we will quantify this measured improvement.

• because of the marginal svm and lr results from experiment  <dig>  we are actively investigating  other mops which might be more sensitive to recist and who measurements, when supplemented with additional information, as was done in experiments  <dig> and  <dig>  this is an ongoing research effort.

• we have the capability to evaluate the efficacy of drug treatment related to vascularity and lesion enhancement. however, initial lesion enhancement experiments did not improve performance for the cases studied.

• in summary, we suggest that this preliminary research study has demonstrated that these slt algorithms, properly designed, tested, evaluated and properly used with a computer in a clinical setting, has the potential to address those questions discussed in section  <dig>  as well as those problems delineated in section  <dig>  . we also suggest that tumor heterogeneity and shape, etc, obtained from ct and/or mri scans, be added to the feature vector for processing. this will be a simple process when the data is available.

observer variability
we have previously discussed , lack of rigorous guidance for recist and who regarding observer variability except from recommending panels and independent observers. we hypothesize that both slt and cas can help in reducing observer interpretive variability by:  using automated intelligent computer processing, and  training observers using slt paradigm outputs. that is, cas and slt do not make subjective judgments: they adapt to the environment by developing emergent behavior using only factual information contained in the feature vector and will adapt differently when this information content is altered in some way. they also recognize and better adapt to the more accurate information content contained in the feature vector. this is illustrated by the three experiments described in table  <dig>  whose content is similar to that described in table  <dig> 

experimental design to ascertain observer variability

finally, this set of observer variability experiments shows that experiment  <dig> provides the most accurate results, which is consistent with the auc results found in the previous set of experiments.

CONCLUSIONS
eight experiments were designed to measure the individual performance slt accuracy of recist and who as well as recist and who slt improved performance with additional information. these experiments used the “one hold out” cross-validation technique because the validation sets for 5-fold cross-validation did not contain enough samples for statistically valid conclusions. two slt paradigms were used: a non-linear support vector machine  that employed a sigmoid mapping kernel and a linear logistics regression  approach. the group evaluated included  <dig> patients with metastatic colon cancer treated with a last line therapy , who had a median survival of  <dig> months. survival was used as the gold standard diagnosis for mop. a good response was considered survival beyond  <dig> months  and a poor response was considered death at or prior to  <dig> months . the experiments performed resulted in the following general behavior:

• svm performance for both recist and who are better than the lr performance for all experiments. this is an expected result because the svm paradigm captures predictive and discriminating information “hidden” in the non-linear regions of the input space, where the lr paradigm, because of its linear processing only, cannot “see” this discriminating information.

• we suggest that this preliminary research study has demonstrated that these slt algorithms, properly designed, tested, evaluated and properly used with a computer in a clinical setting, has the potential to address those questions discussed in section  <dig>  as well as those problems delineated in section  <dig>  . we also suggest that tumor heterogeneity and shape, etc, obtained from ct and/or mri scans, be added to the feature vector for processing.

• two results for the observer variability experiments were immediately clear:  observer  <dig> has the best mops for predicting patient survival as expected being the more experience observer , and  svm processing provided more accurate auc results than lr, which is an expected result. however, another observation is that the svm  results can possibly be used to improve observer 1’s performance by designing a set of sensitivity experiments to establish which inaccurately “read” feature values are most significantly contributing to performance denegation, and train observer  <dig> using this information.

• finally, we have the capability to evaluate the efficacy of drug treatment related to vascularity and lesion enhancement. however, initial lesion enhancement experiments did not improve performance for the cases studied.

