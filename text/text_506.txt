BACKGROUND
the genome scale metabolic network of small molecule reactions for cells  is sufficiently complex that it is hard to visualize, let alone interpret. using conventional biochemical pathways is a bottom-up approach that helps to bridge the complexity gap between individual reactions and the complete network. but this still leaves scope for an intermediate level of granularity, namely subnets. a subnet allows the study of the interplay between pathways and reactions in a broader context, while still focussing attention on a limited biological functionality of interest.

this line of thought has been pursued by many authors in the recent literature, together with algorithms that use a top-down approach utilising the inherent structure of the complete network to determine its natural subdivision points. in addition to the conceptual argument, there are also practical considerations that motivate this endeavour in particular contexts. the use of structural analysis tools such as elementary modes and extreme pathways  <cit> , suffers from the problem of a combinatorial explosion  <cit>  of the number of such modes in a complex network. in essence the problem is that if two small networks are joined together sequentially, each pathway in one can be joined to each pathway in the other. so reversing this and partitioning a large network into subnets is a useful strategy to keep mode numbers manageable. alternatively, significant advances have also been made in large scale mode calculations in genome scale networks  <cit>  and analyzing the results by sorting  <cit>  or pattern matching  <cit>  techniques. whether such methods or partitioning is preferable depends on the goals of a particular project.

another significant context is flux balance analysis . there, knowledge of at least some measured fluxes is needed in order to calculate others by applying stoichiometric and other constraints. current technology allows simultaneous measurement of about a dozen flux values or several hundred metabolite concentrations  <cit> . optimization of an objective function such as biomass production has been used successfully to supplement the constraints for metabolic modelling of unicellular organisms, but the choice of objective for multicellular organisms is problematic and even for unicellular systems, maximising biomass is not always appropriate  <cit> . so in a study that focuses on a particular aspect of metabolism, it would be helpful if a way can be found to limit the fba calculation to a "relevant" section of the network and avoid needing boundary conditions that only affect other metabolic aspects.

depending on the priority allocated to these three sets of considerations, different approaches have been advocated, and a recent review including the application of more general network theory approaches to biological networks, can be found in a recent article by nayak and de  <cit> .

the conceptual network simplification problem is typically addressed by clustering- or community finding algorithms. a typical example is the markov clustering  algorithm <cit> . there, the focus is on identifying groups of nodes that are closely connected to each other, while intergroup connections are weaker by comparison. a clustering method somewhat similar to mcl has also been applied to metabolic networks  <cit> . this approach uses simulated annealing to process connectivity information to find modules with high connectivity within and minimal links between modules, but takes no account of mass balance constraints.

however, clustering of this kind is not really appropriate for metabolic subnetworks. the most highly connected metabolites are commodity or currency compounds such as h2o and nadh, but generally  they are of least interest in terms of function. conversely, the conventional pathways of biochemistry that should form the core of a functionally oriented partitioning are typically linear or circular and only weakly connected in terms of graph structure.

an alternative approach to the conceptual clarification of biochemical network structure is as hierarchy trees, an approach advocated in the work of holme, huss and jeong  <cit>  and of gagneur, jackson and casari  <cit> . however, such hierarchies are not very amenable to isolating a particular subnetwork for fba or mode analysis.

an approach that prioritises the appropriateness of a biochemical subnet for use in practical applications, was demonstrated by schuster et al  <cit> . the approach is based on the observation that metabolite nodes in a biochemical network are of two distinct types: internal nodes that have associated stoichiometric mass balance constraints, and external nodes that represent metabolite inflows and outflows from the environment and have no associated mass conservation. the external nodes define the periphery of the network, and so a new boundary that separates a subset of nodes from the rest can be created by reclassifying some of the internal nodes as external. changing the status of a node from internal to external, can in a graphical network representation be seen as splitting it into two: one copy becomes a sink in one subnet, and the other a source in another subnet. this demonstrates another difference from clustering, where networks are usually partitioned by deleting links rather than splitting nodes. the selection criterion used  <cit> , is that all internal metabolites that participate in more reactions than a chosen threshold value are made external. one rationale behind this criterion is that the many reactions that contribute to mass balance of such a highly connected metabolite are reasonably represented by considering it as buffered, in a subnet not containing all those reactions. another is that this choice is particularly effective at avoiding the combinatorial explosion problem. and finally, for a high enough threshold, mainly carrier and commodity metabolites are selected that are not the focus of interest in a typical subnet.

using a threshold connectivity of  <dig>  the metabolic network of mycoplasma pneumoniae was found  <cit>  to divide into  <dig> subnetworks, with identifiable biological functions. similarly the human redox metabolism was found  <cit>  to split into  <dig> subnetworks for the threshold value of  <dig>  although successful in these relatively small metabolic networks, a criticism expressed by several authors  <cit>  is that it relies totally on a local property, the degree of node connectivity, and takes no account of the global network structure. compared to their method that uses the global "bow-tie" structure, ma et al  <cit>  found that while both methods classify most currency metabolites similarly, there are examples in their method of both internal metabolites with high connection degree and external metabolites with a low degree. it was also acknowledged in the original article  <cit>  that the fully automated selection on connection degree alone can be improved by minor editing based on biochemical knowledge. despite these reservations, connectivity selection is still implemented in the current version of the network analysis software application yanasquare  <cit> .

the network splitting procedure presented in this article aims to incorporate the insights outlined above. in addition it provides flexibility to interactively guide how the splitting proceeds, based on the purpose and biochemical knowledge of the user, within the limits set by the inherent network structure.

the formulation adopts internal/external reassignment as the splitting paradigm, but only uses the connectivity degree as a preliminary coarse filter to identify the most obvious external metabolites. this is optionally supplemented or refined by an explicit listing of metabolites that are/are not taken as external. the main algorithm uses random walks to explore long range network structure, in a similar way as mcl clustering  <cit> . however instead of the rigid automated cluster delineation produced by the "inflation" step of the mcl, the results are displayed to the user as a matrix that summarises network structure even for large networks in a powerful visual form. at the heart of the visualisation is a blocking transformation designed to express subtleties of the status of each node in relation to an underlying hierarchical clustering, in a way that resembles fuzzy clustering algorithms. optimisation using linear programming delivers a small set of candidate externals, which the user can accept or reject and this process is repeated until acceptably small subnets are produced. in a final postprocessing step, externals that are not essential for the partitioning achieved, are reincorporated to ensure that the inevitable loss of mass balance information is kept to a minimum. the procedure described here has been implemented in a software application called netsplitter, and is subsequently referred to as the "netsplitter algorithm".

methods
general overview
processing of a metabolic network consisting of an unordered list of chemical reactions specified in the standard way by a matrix of stoichiometric coefficients, proceeds through four computational stages:

 <dig>  generating a matrix representation of the network connectivity structure from random walks, which expresses each internal metabolite as a distinct source or sink node in an associated directed acyclic graph .

 <dig>  using hierarchical clustering and a blocking transformation to rearrange the dag matrix into latent blocks that express the underlying partially separated subnets.

 <dig>  proposing prospective separator nodes for approval to the user, implementing the decision and recalculating the dag with improved blocking, leading to the next round of separator selection.

 <dig>  post-processing to consolidate subnets by reincorporating superfluous externals and to reconstitute a stoichiometry matrix specification of each subnet from the dag matrix blocks.

each of these stages is described in more detail in the following subsections, followed by introduction of a quantitative measure of effectiveness. fuller justifications for some of the steps are supplied in a separate subsection at the end of methods.

matrix representation of biochemical networks
random walks and probability matrices
the procedure is based on representing the network as a matrix of probabilities that reflect random walks on a simple graph, similar to that used in the well-known markov clustering  algorithm  <cit> . however, since a metabolic network contains nodes of two distinct types , the first task is to reduce the stoichiometry matrix  used conventionally to specify a metabolic network, to a probability matrix for a simple graph containing metabolite nodes only. for this step it suffices to treat the metabolic network as a bipartite graph, although it has been pointed out that metabolic networks are best considered hypergraphs  <cit> .

for a simple graph, one starts from a probability matrix p <dig> where the elements in row i are the probabilities that a random walk starting from node i in the network will reach node j in a single step. for simplicity, equal probabilities are assigned to all links emanating from a particular node. to achieve this, one merely needs to normalise each row of the adjacency matrix c of the graph, by dividing each element by the sum of all elements in the row. the probability matrix pn for a random walk of n steps, is calculated by raising p <dig> to the n-th power. walks of n ≤ n steps, will be included in this provided that there is a non-zero probability for a random walk step to "stay put" on a node; in other words self-loops are included in the adjacency matrix, or in matrix terms a multiple of the identity matrix is added before the row normalisation is carried out.

if we start from a state where there is a single "random walker" on each node of the network at step  <dig>  the probability associated with each walker has the value  <dig> for being localised on its starting node. then p <dig> represents propagation of this probability to nearest neighbour nodes in step  <dig>  and generally the potentiating of the matrix can be visualised as the flow of probability through the network after increasing numbers of steps. this is expressed in mcl terminology by referring to potentiating as the "expansion" operation.

as constructed, the matrix p <dig> has non-negative elements with a row sum =  <dig>  which makes it an example of a right stochastic matrix. from the theory of stochastic matrices  <cit> , it is known that raising a matrix of this type to consecutive powers converges to a matrix denoted as p∞. in practice, for metabolic networks numerical convergence to an approximation of p∞ is obtained for values of n in the low tens. a typical feature of this matrix is that many of its columns are zero vectors, implying that after a sufficient number of steps, the probability of finding a random walker on the node corresponding to that column approaches zero, regardless of the node from which the walker started at step  <dig>  such nodes therefore act as sources, while the remainder with non-zero columns are sink nodes. in a thought experiment with one walker starting from each node of the network at time  <dig>  all walkers will congregate on the sink nodes after the number of steps needed for convergence. a binary version of p∞ , obtained by replacing all non-zero elements by  <dig>  can be interpreted as the adjacency matrix of a new graph, containing the same nodes as the original network, but in which all links connect sources directly to sinks in a star-like configuration. this is formally described as a directed acyclic graph, and is directed irrespective of whether any links in the original network were directed. in what follows, either p∞ or its binary version is referred to as the dag-matrix. qualitatively the features described above are quite similar to those in the mcl, but note that in mcl terminology only the "expansion" operation  is applied while the "inflation" operation that is key to the mcl, is not used. consequently the dag obtained here does not usually separate into disconnected clusters, and needs to be further manipulated by the algorithm to extract subnetworks.

the generalisation of the procedure outlined above to the bipartite metabolic network case, starts by defining two separate adjacency matrices cr and rc. for a network of m reactions and n metabolites, the s-matrix is  with rows representing metabolites and columns reactions. cr is similarly  and each row contains the adjacencies of a metabolite node that act as a substrate to each reaction column, while rc is  and gives the adjacencies of reaction products but with the roles of rows and columns reversed. formally, these are constructed from s by the relations

  cr=12|−sign) ; rc=12transpose|+sign) 

here the sign function takes the values - <dig>   <dig> or  <dig> and serves to ensure that cr and rc are nonnegative binary matrices. from these the probability matrix for the reduced metabolites-only network is calculated by

  p1=rownorm•rownorm+ <dig>  i) 

here the function rownorm normalises each matrix row by a simple row sum, and converts the adjacency matrices to probability matrices. the summation implied in the matrix multiplication accumulates the probabilities for a random walk jump from metabolite node i to metabolite node j, over all reactions that connect them. note that links in the metabolites-only network are directed in accordance with underlying reaction directions, whether these are reversible or not. in the added term, i represents an  identity matrix to account for selfloops, and its coefficient is chosen to scale their probabilities in accordance with typical values in a sparse network. the results for the dag are found to be insensitive to the actual coefficient value. unlike for a simple graph, the selfloops could not be introduced into the adjacency matrices because they are non-square and even if not, it would have destroyed the bipartite nature.

calculation of the dag matrix proceeds by straightforward iterative potentiation of p <dig>  using convergence of the frobenius norm of the matrix to within an absolute value of 10- <dig> as the criterion.

matrix implementation of partitioning
reclassifying an internal node as external to produce network partitioning, is implemented by deleting the corresponding row from cr and column from rc. this implies that at any stage the dag matrix only represents internal metabolites, and as this changes during the course of the partitioning the dag is regularly updated. a detailed account of this implementation is given in the justifications section further below.

preprocessing the dag matrix
the first step in processing the dag matrix is to sort its columns so all non-zero columns are collected on the left and rows sorted in the same order, then deleting the zero columns. in this way, by definition only sink nodes remain in the column sequence and rows are sorted with all sinks appearing first, followed by all source nodes.

to demonstrate the method, an example network consisting of  <dig> metabolites and  <dig> reactions is used in what follows. this network happens to be a subnet for flavonoid metabolism in arabidopsis thaliana extracted from the aracyc  <cit>  database, but serves here merely as a realistic example of a small metabolic network. the specification of this network in sbml format is available as additional file  <dig> 

the top square  <dig> ×  <dig> submatrix is seen to be  diagonal. for the majority of single diagonal elements, this merely indicates the finite probability that a random walk starting from a sink node will end there as a result of a selfloop, while it will not terminate at any other sink. there are also a few small blocks; they represent small clusters of nodes that are fully connected and hence jointly act as a "supersink". this top square does not reflect much of the overall network structure and further manipulation centers on the lower part, i.e. the dag matrix is further truncated to contain just the  lower left submatrix of the original.

inspection of the lower  <dig> ×  <dig> submatrix in figure  <dig> shows very little internal structure on which to base network partitioning; almost all source nodes are connected to almost all sinks. the reason is that in a metabolic network there are typically a small number of ubiquitous metabolites such as carrier molecules that participate in many reactions. sacrificing mass balance for these, is arguably not a serious loss of information, as an excess or lack of the molecule in the subnet can be assumed to be made up by other subnets. the common convention of presenting metabolic pathways as a backbone structure while suppressing secondary metabolites, is an implicit recognition that such crosslinking tends to obscure the underlying connectivity structure that is important to understand functional units in a metabolic network.

reclassifying just the four highest connectivity internal metabolites  in the demonstration network produces the drastic change shown by figure  <dig>  the truncated dag now exhibits clear structure, creating scope for further manipulation as described in the next section.

a useful strategy to determine such a set of a priori ubiquitous metabolites is to simply choose a fixed threshold value and reclassify all internal metabolites with connectivities higher than the threshold, in order to reveal the connection structure. a threshold of  <dig> was found to work well for networks over a wide range of sizes, from about  <dig> metabolites upwards. manual adjustment of the threshold can also be done as its effect is easily monitored by visual inspection of the truncated dag as in figure  <dig> 

alternatively, an explicit list of commonly occurring ubiquitous metabolites can be used instead of a threshold, to avoid inadvertent reclassifications. the most efficient strategy was found to be a combination, using a threshold to automatically reclassify the most "obvious" carrier metabolites automatically, and supplementing this with an explicit list of less obvious ones.

rearranging the dag matrix to identify subnets
subnetworks and matrix blocks
the key insight needed to use the mathematical infrastructure described so far for network partitioning, is that separated subnets can be made to appear in the truncated dag matrix as non-overlapping blocks.

a block is defined as a rectangular submatrix, formed by the intersection of a horizontal band of rows and a vertical band of columns, and where any non-zero matrix elements in either band occur only inside the intersection . it follows that the row and column ranges of a block does not overlap with those of any other block. so if it exhibits a non-trivial block structure, the full set of rows in the truncated dag matrix will be partitioned with no overlap into two or more bands, and similarly the columns into the same number of bands. this definition does not require that blocks are arranged diagonally.

the connection with disjoint subnets is established by noting that a non-zero element  in a particular block of the truncated dag means that there is a finite probability, and hence a path through the network from source node i to sink node j in the same block. conversely, the zero elements in the bands belonging to a particular block but outside that block, means that probability does not flow from source nodes in one block, to nodes in any other block; nor are sink nodes in one block fed by sources in any other block. so the collection of sources and sinks of each block, specifies the internal nodes of an isolated subnet.

the truncated dag as constructed so far will not show such block structure, but two operations are available to produce the block structure:

• rows and columns may be reordered. there is no penalty to this, as the ordering of internal metabolites inherited from the s-matrix is arbitrary.

• internal metabolites may be reclassified as external and deleted from the adjacency matrices. this carries a penalty, as information is lost - the mass balance of the metabolite is not enforced any more. the dag matrix needs to be recalculated in this case and usually has a different allocation of sinks and sources.

rearrangement of rows and columns
the first step is to rearrange rows and columns so that metabolites belonging to a block are grouped together. for computational efficiency, operations described here are performed on a binary version of the truncated dag matrix, on the grounds that it is the connectivity of the network that is relevant rather than detailed probabilities from the random walk. in a binary matrix with simple rectangular blocks, all rows/columns in a particular block are identical but are orthogonal to those in any other block. however, the definition of a block given previously allows zero elements inside a block as well, so this is relaxed to say that rows/columns belonging to a block needs to be similar to each other but dissimilar from those in other blocks - i.e., it reduces to a vector clustering problem. the sokal-sneath vector dissimilarity is used to quantify this, as discussed in more detail in the justifications section.

using this measure the rearrangement problem reduces to one of finding row and column sequences that give optimal clustering. of various standard clustering methods that were considered the hierarchical clustering method  <cit>  was found to be most suitable.

hierarchical clustering, as expressed in a dendrogram representation, has the advantage that - unlike most other clustering methods - it gives a definite sequence  while not committing to a fixed number or size of clusters. these can be subsequently determined by choosing a cutoff level in the dendrogram, a property exploited in the next stage of the procedure.

blocking transformation
the next challenge is to identify latent blocks that can be separated in further processing. a crucial decision to be made is the optimal number, size and shape of blocks. reordering alone as in figure  <dig>  does not give any obvious clues to whether many small blocks or fewer large ones will best represent the network.

the decision is facilitated by introducing a blocking transformation that expresses the extent to which the hierarchical clusters succeed in defining blocks. the transformation proceeds in five steps:

 <dig>  truncating the column dendrogram at a particular chosen level, defines a collection of consecutive column clusters such as c = . in the matrix, these clusters define vertical bands. in row i of the rearranged, truncated dag matrix with elements pij, we make the replacement

  pij→rij=∑j∈cjbij∑jbij 

here bij are the binary matrix elements and cj is the column cluster to which column j belongs.

in the case of a perfectly blocked matrix, all non-zero elements in a row will belong to the same unique cluster and their values are left unchanged at  <dig>  any zero element in the same cluster is replaced by  <dig>  i.e. any gaps inside the cluster are filled in. all row elements in the remaining clusters will be, and remain, zero.

however, for an imperfectly blocked matrix, any non-zero element outside the range of a particular cluster will serve to dilute the common value of elements inside the cluster to a fractional value. hence in a gray-scale representation the row appears as a sequence of bands in different shades of grey; the darkest grey identifies the cluster containing the largest fraction of non-zero elements.

applying this transformation to all rows of the matrix in figure  <dig> produces the row blocking matrix shown in figure  <dig>  analogously, columns are blocked next:

 <dig>  truncating the row dendrogram at a particular chosen level, defines a collection of consecutive row clusters ci. in column j of the rearranged, truncated dag matrix, we make the replacement

  pij→cij=∑i∈cibij∑ibij 

application of this transformation to all columns similarly gives the column blocking matrix shown in figure  <dig> 

in a perfectly blocked matrix, blocks based on grouping rows or columns are identical, but the demonstration example shows that for imperfect blocking the row and column blocking matrices are similar but not identical. the next step superimposes the information from the two separate hierarchies.

 <dig>  combine row and column blocking matrices by elementwise averaging:

  sij= <dig> 

the combined blocking matrix obtained in this way is shown in figure  <dig>  in this matrix, grey shades again indicate deviations from perfect blocking - whether by leakage of amplitude from hierarchical clusters or by discrepancies between row and column blocking. black areas, on the other hand, identify areas where all evidence from the grouping procedures agrees and that can plausibly be taken as cores for blocks still to be further delineated. moreover, the gap filling effect mentioned above serves to highlight the intrinsically rectangular shape of blocks.

an important aspect of the algorithm has been glossed over above. the dendrograms used in steps  <dig> and  <dig> define hierarchical lists of distances between subclusters. it is by choice of a particular cutoff value in each list  that one can choose between many smaller clusters or fewer larger ones.

to exploit that, a quantitative criterion q for the optimal blocking has been defined as detailed in the justifications section, leading to the next step:

 <dig>  calculate q from equation  after repeating steps 1- <dig> for each of the trial list of cutoff values, and select the one that maximises q.

the blocking matrices shown in figure 3- are those that maximise q for the demonstration network and represent the visual structure of figure  <dig> quite well.

however, there is still one noticeable deficiency in figure  <dig>  some blocks appear split - for example, there are two medium grey horizontal lines in the lower half of figure  <dig> that each clearly belongs with the large dark areas directly above it. the reason for this is a conflict between similarity at the fine-grained  level used when grouping, and the coarse-grained  level that applies after blocking. this is rectified by the final step of the blocking transformation.

 <dig>  consolidate blocks by reordering rows and columns according to hierarchical clustering now applied to the combined blocking matrix.

as figure  <dig> shows, the final result of the blocking transformation gives a succinct and visually appealing overview of the size, shape and location of blocks, as well as indicating areas that produce block overlap.

finally, in order to computationally process individual subnets, automated recognition of separated blocks is required. this is a fairly straightforward image processing problem, and a heuristic procedure based on the block definition given above is described in additional file  <dig>  a side effect of the heuristic is that matrix rows and columns are rearranged once more, aligning recognised blocks along the matrix diagonal.

selection of separation nodes
having prepared the dag matrix to express any underlying partial block structure, the procedure now enters an iterative loop in which in each round, a small number of nodes are identified that when "cut" , will lead to separation into subnets. the goal is to keep this set of separation nodes as small as possible, both to minimise the loss of mass balance information and to preserve as far as possible the local structure of the full network.

for example, applying block recognition scanning to the matrix of figure  <dig>  recognises only the full matrix as a single block. that is also visually apparent - there are four or more latent blocks highlighted in black, but none are fully separated as signified by grey areas.

for a number of reasons, it is postulated that the lighter grey cells in the figure are the most promising candidates for removal to induce separation. one rationale is that by construction they reflect a status as exceptions while the majority of cells in their row or column belong to the same group and end up as dark grey. also, they tend to result from cases where there is already separation from the perspective of the row grouping and only weak overlap from the column grouping, or vice versa. middle grey, on the other hand reflects either strong evidence from one of the groupings, or moderate consensus that may solidify once the weakest overlaps are removed. also, there is some analogy to the effects of the "inflation" step of the mcl. in that method, "inflation" is produced by taking the hadamard power of a probability matrix; that tends to suppress low probabilities and leads to the "weakest" links between node clusters to be removed first. these arguments can be made more elaborate, but in the final analysis the justification lies in the result obtained. as detailed in the justifications section, linear programming is used to select a small number of metabolites that optimally cover the lighter grey cells in the blocking matrix and propose these to the user as candidate externals.

an example is illustrated in figure  <dig> where this is applied to the case of the consolidated blocking matrix in figure  <dig>  the picture shows that two columns, i.e. metabolites that produce block overlaps , are identified by solving equation . these metabolites are made external, i.e. they are deleted from the adjacency matrices rc and cr, the dag matrix recalculated and the blocking transformation repeated to identify further candidates in a second round, and this iteration is continued until either sufficiently fine-grained splitting has been achieved, or no more separation nodes are found.

another case of such irreducible blocks that is usually encountered, is the appearance in the dag matrix of isolated sinks or "orphans". these appear as entries in the top, diagonal section of the dag matrix with no accompanying source node entries in the corresponding column of the truncated matrix used for blocking. such an orphan metabolite node signifies the simplest possible subnet, with only a single internal metabolite, and typically containing only two reactions. as these can obviously not be further split and the presence of an empty column complicates block recognition, they are best eliminated in each round from the adjacency matrices along with single row/column irreducible blocks.

postprocessing and reconstruction of subnetworks
once the iterative process of progressively selecting separation nodes has terminated, the main outcome is a list of internal metabolites, partitioned into disjoint subsets that belong to each block. the remaining metabolites constitute a list of external metabolites. this list may contain entries that are not, in fact, essential for block separation. for example, a metabolite may have been made external during initialisation on the grounds that it participates in a large number of reactions, but if all of those reactions belong to the same subnet it should be reinstated as an internal metabolite in this subnet. also, it can happen that the effects of a metabolite selected early on in the progressive selection process, are superseded by one selected later. in the interests of maintaining maximal network integrity compatible with the separation, all such superfluous externals need to be reincorporated before finalising the subnets.

this is done in a loop that inspects the stoichiometry matrix for each external metabolite on the list, to determine all internal metabolites to which it connects by reaction links in either direction in the bipartite representation. if all those belong to a single block, the external metabolite is reincorporated into that block. if they belong to a single block, except for a connection to one or more orphan metabolite nodes, those orphan nodes are also reincorporated into the block as detailed below. as this reincorporation loop changes the composition of the lists of internal and external metabolites, the loop is repeated iteratively until there is no further change in the composition of the lists.

the approach that was chosen to select separation nodes progressively, a few at a time, has the advantage that it allows the user to steer the network splitting by accepting or rejecting proposed separation nodes and terminating the process at the desired level of granularity. however, a disadvantage is that the results may become dependent on the order in which separation nodes are identified. that is counteracted by performing a one-off blocking step in which the full list of external metabolites are applied simultaneously. this step is performed as part of the post-processing done after the selection process is finished; but the question arises whether it should be done before or after the reincorporation step. each choice has some advantages, and the most robust result is in fact achieved by repeating the reincorporation step. so the full post-processing procedure consists of the 3-step sequence: a first reincorporation step, then the one-off blocking, followed by a second reincorporation. figure  <dig> shows the effects of the reincorporation for the demonstration network.

once the partitioned list of internal metabolites is finalised by this post-processing, the individual subnets can be reconstructed in a straightforward way from the original stoichiometry matrix s. for each subnet, all reactions in which its internal metabolites participate are extracted from s and allocated to this subnet. all metabolites that participate in these reactions are collected; those not appearing on the list of internals for the subnet, are by definition the external metabolites of the subnet. the submatrix of s pertaining to the reactions and metabolites so identified is extracted and saved in appropriate format as a full specification of the subnetwork, which can be further analysed by standard network analysis or fba software tools.

by construction, the internal metabolites of different subnets are mutually exclusive sets. external metabolites, on the other hand, are often shared between subnets. in the vast majority of cases, there is also no overlap between external metabolites of any subnet and the internals of any other.

there are, however, rare exceptions where an external of one subnet is in fact an internal of another. this phenomenon can be considered an artefact of the way that the algorithm mainly operates on a reduced metabolites-only simple graph. at this level where the blocking procedure is carried out, there is a strict distinction between internal and external metabolites; they form non-overlapping sets. however, when translated back to the underlying bipartite graph representation, cutting all metabolite nodes that were identified as external, can sometimes still leave subnets connected by a shared reaction node.

a typical case is shown in figure  <dig>  where subnets a and b are connected by reaction node r <dig> which has input reactants a and b respectively from each subnet. figure  <dig> shows the metabolites-only representation, where splitting node c by making metabolite c external will separate the subnets. but then, after the blocking procedure, the external metabolites of each subnet are found by collecting metabolites that participate in all the reactions in which each internal metabolite is involved. in the case of subnet a, both nodes b and c are connected to its internal node a by reaction r <dig> and will be added to its list of externals; and conversely, for subnet b, metabolite b is internal while a and c become externals.

the existence of this kind of limited overlap between two subnets does not compromise the integrity of either as a coherent subnet: it remains true that for all internal metabolites in a subnet, all reactions in which they participate are included in the subnet, and so the mass conservation constraints of all internal metabolites are identical in the subnet and in the full network. however, it does uniquely create the complication that the same reaction is present in both subnets, which can lead to conflicting values for the flux through this reaction in separate fba calculations for each subnet. to avoid that, it may be preferred to merge the two subnets into a larger one when this exceptional case arises.

it should also be noted that for a similar reason the reincorporation of orphan metabolite nodes is slightly more complicated than outlined above. by definition, an orphan node is isolated from all other internal nodes in terms of probability flow, but it could still be connected by a unidirectional link towards the orphan. consequently, incorporation of an orphan takes place in two steps. when an external connected to an orphan metabolite node is incorporated into a block, the orphan is first promoted to an external of that block. in the next round of the incorporation loop, it is then tested for links to internals of other blocks and only incorporated as an internal if no such links in either direction is found.

detailed justifications
internal and external metabolites and network partitioning
conventionally, external nodes are placed on the periphery when drawing a network to indicate that they form the interface between the metabolic system that the network represents and its environment. however, the distinction between nodes that are associated with mass balance constraints , and those that are not  is not apparent when the network topology is simply specified as a list of reactions. most external metabolites can be recognised computationally by the fact that an external metabolite is either taken up or delivered to the environment so that all network links impinging on an external node are directed away from or towards the node; but in cases where the metabolite is exchanged with the environment that distinction is lost.

a convention commonly used in fba of metabolic networks  <cit>  to keep track of externals, is to order the rows of the s-matrix so that internal metabolites appear first and externals last. then the lack of stoichiometry constraints for externals is easily implemented by using only the top  section of the matrix for fba calculations.

another feature of representing a chemical network by a bipartite graph, is that as reaction nodes represent a chemical transformation of one or more reactants, reaction nodes can never be external.

these issues become relevant for partitioning a network, because in isolating a subnetwork a new periphery is created for it. severing the connection between the subnet and the rest of the network, some metabolites are received from or/and delivered to the rest of the network. their mass balance can no longer be guaranteed by the subnet alone; in other words, the status of these metabolites is changed from internal to external. from a graph theory perspective, partitioning corresponds most naturally to deleting a link of a graph. however, that will not do for the biochemical network; in the bipartite representation, that would make a reaction node external, and it makes even less sense in the metabolites-only simple graph representation where a link represents a sum over several reactions. in clustering methods such as mcl, each node is allocated to a particular cluster, but that would not make sense here either as a metabolite that is made external by partitioning belongs to both subnets - as a product of one, and substrate of the other subnet. clearly the appropriate way to represent partitioning is to split the metabolite node into two, each becoming an external node in either subnet. this leaves all reaction nodes as internal and uniquely assigned to a subnet. the effect of splitting a node is to stop probability flow through the node, and the simplest way to implement that in the matrix representation, is to delete the corresponding row from p <dig> and hence ultimately from the dag.

the problem of partitioning the network hence reduces to finding a suitable  subset of internal metabolites such that when deleted, the network divides into self-contained subnets with no probability flow between them.

recognising that the algorithmically found externals are due to be deleted in this way, it follows that metabolites that are already external in the full network should similarly be deleted from p <dig> even before the partitioning starts. this step in fact corresponds to the restriction of fba calculations to the internal rows of the s-matrix as mentioned before. however, in the procedure presented here rows are deleted from the adjacency matrices cr and rc while s is left intact, so that the reaction stoichiometries can be used to restore the externals to each subnet once partitioning is complete.

vector clustering
a quantitative measure of dissimilarity d for binary vectors can be based on the formula

  d=n10+n01n10+n01+a n11+b n <dig> 

here, corresponding elements in two equal length binary vectors are paired, and nij is the number of pairs with value . commonly used such measures are known as matching , jaccard , sokal-sneath , rogers-tanimoto  and dice  dissimilarities. experimentation with all of these in the present context has shown that matching and rogers-tanimoto give low contrast. dice, jaccard and sokal-sneath are similar but the best contrast and hence block identification is obtained with sokal-sneath dissimilarity.

hierarchical clustering in addition needs a measure for the distance between clusters , and again several common measures were tried: single linkage , complete , average dissimilarity, dissimilarity of cluster centroids or medians, and finally the ward minimum variance criterion. single linkage was found to be both fast to calculate and gives good contrast; average, centroid and median are slower but give similar results, while complete and ward lead to excessive fragmentation of the network.

clustering of the combined blocking matrix in step  <dig> of the blocking transformation is performed broadly as described for the dag. however since the combined blocking matrix can contain fractional values, the binary dissimilarity measure described by equation  is replaced by a generalisation of the dice dissimilarity to real values and known as the bray-curtis distance between vectors a and b:

  d=∑|ai−bi|∑|ai+bi| 

blocking quality
experimentation with various possibilities yielded the following scoring formula for the blocking quality q of an  combined blocking matrix:

  q=2wi j 

here, w is the total number of zero  elements in the matrix. the two factors in this formula express distinct features that seem qualitatively reasonable to judge the quality of the blocking matrix. the first, squared, factor would be  <dig> if all non-zero elements are  <dig>  and decreases when there are more and lighter grey cells; so it is a measure of "how black" the block parts of the matrix is. on its own, however, maximising this tends to favour a small number of large blocks because that makes it easier to capture all the non-zero values inside blocks. to counteract that, the second factor represents the fraction of cells that are white, so this tends to be maximised by keeping blocks as compact as possible. it clear that for a perfectly blocked matrix, a maximum q value qmax <  <dig> will be achieved if the cutoff produces clustering that coincides exactly with the blocks.

in an imperfectly blocked matrix, adjusting the dendrogram cutoff gives unpredictable fluctuations in the q value and so a search method is necessary to maximise q. three strategies are employed to keep this manageable. first, as the number of recognised clusters only changes when the cutoff rises above an actual intercluster distance value in the dendrogram, the search space is restricted to a trial list of discrete cutoffs falling midway between values in the ordered intercluster distance list. second, the same cutoff value is applied to both the row and column dendrograms. although it constrains the flexibility of the search, this helps to avoid large disparities in the number of clusters for rows and columns  despite the fact that the truncated dag matrix generally has far more rows than columns. to implement that, the intercluster distance lists for rows and columns are merged before selecting midpoints. finally, bearing in mind that distance values from equation  fall between  <dig> and  <dig>  the discrete list of trial cutoffs is truncated to values in the range . this avoids either very few or very many blocks that would not be desirable for subnet partitioning and rarely produce high q scores anyway.

optimal selection of separator nodes
to implement the recognition of light grey cells in the blocking matrix as most promising for eliminating block overlap while keeping the metabolites taken as external to a minimum, the strategy is to select the smallest set of rows and columns that together cover all matrix cells with values below a chosen threshold. the threshold is determined as the value that selects a total number of light grey cells, no more than a low multiple of the column dimension of the matrix. this gives a flexible threshold value adapted to the size and nature of the matrix, which will lead to only a few metabolites eliminated at a time before checking for adequate subnet separation.

as any light grey cell could be eliminated by taking either its row or column metabolite external, the optimal selection from both sets is determined by reformulating this as an integer linear programming  problem. to set that up mathematically, introduce a binary column vector x of dimension = number of internal metabolites. each vector element is  <dig> or  <dig> according to whether the corresponding metabolite is selected. the total number selected is obtained by premultiplying x with a row vector b of the same dimension with all elements equal to  <dig>  the constraints are that for each light grey element sij included, either its row or column or both needs to be present in x. that is codified by a constraints matrix a in which each row corresponds to a light grey cell, and in such a row the only non-zero elements are 1's for the columns corresponding to i and j. then the ilp problem is:

  minimize b⋅x subject to a⋅x≥b 

this problem is to be solved in the domain of binary vectors, and is guaranteed to be feasible, since all constraints are satisfied by x = b. solution by standard methods typically yields small sets of selected metabolites.

a quantitative measure of overall splitting effectiveness
the goal of subnet splitting is to reduce the complexity of interpretation  by reducing the size of networks that need to be considered. it is shown here that a robust quantitative measure of how effective a particular splitting procedure is in achieving this goal can be developed under quite general assumptions.

the original network constitutes the obvious lower limit of simplification. in the opposite extreme where the network is fragmented into subnets consisting of a single node each, no overall simplification has been achieved either: while the subnets are simple, their interconnections reconstitute exactly the original network. this suggests that to judge overall effectiveness, the subnets should be considered together with a "metanetwork" which is derived from the original network by contracting the internal nodes of each subnetwork to a single meta-node. it should then be possible to construct a measure that evaluates to zero at the two extremes, and reaches at least one maximum at a suitable intermediate network partitioning.

to quantify the concept of simplification, it useful to introduce a monotonically increasing function f that represents the effort to interpret a network with n internal nodes. having split a network with n internal nodes into k subnets, each with ni internal nodes, the metanet has k nodes and the total effort f to interpret the metanetwork and all the subnets is then given by

  f=f+w∑i=1k f 

and this is subject to the constraint ∑ni=n. with a weight w =  <dig>  equation  represents the effort to interpret the metanet and all subnets; choosing w = 1/k is relevant to the case where a single subnet and its interconnections to other subnets are of interest. the latter case is algebraically simplest so is considered first.

the term "effort" is used to emphasize that this is not about network complexity as such. many sophisticated measures of network or graph complexity have been defined by various authors, and network size usually does not play an important part in this - for example, both a square lattice and a fully connected network are conceptually simple, irrespective of size. also, biochemical networks are known to be scale-free  and so complexity measures should give a similar value when applied to the full network and its subnetworks.

for a given k, it follows by straightforward differentiation of equation  that the constrained minimisation of f is achieved by choosing all subnets of equal size, i.e. ni = n/k , provided that f is concave up, i.e. increases monotonically faster than n. this is quite reasonable, considering that the number of reaction links in a metabolic network rises approximately quadratically with the number of internal metabolites and the number of pathways to be interpreted much faster than that.

moreover, setting ni = n/k into  shows that the minimum is achieved at the optimal number of subnets k = n, irrespective of the functional form of f. this result makes intuitive sense, as it implies that all subnets and the metanet have the same number ni = n of internal nodes, so the interpretative effort is spread equally across them all. the value of f at its minimum is given by the simple formula

  fl=2f 

when n is not integer, this minimum cannot actually be reached, but it still serves as a lower limit to the range of f, while the upper limit is obviously fu = f. in these terms the goal of partitioning can be formulated as finding a vector n→= that comes as close as possible to fl, having started from fu. this leads to defining a performance measure  as

  e=100log−loglog−log 

this may be interpreted as the percentage of the distance between the upper and lower limits that has been achieved by a given partitioning, as measured on a logarithmic plot. use of logarithmic scaling is not conceptually essential but helps to smooth the distribution of efficacy values when f is a fast-rising function.

it is easily checked that e evaluates to zero for the original network and could even reach a slightly negative value for the case of complete fragmentation, while it gives 100% if the optimum k = ni = n is reached.

to get concrete values, a power law assumption produces the required concave up behaviour while still allowing the actual rate of increase to be adjusted:

  f=αnp ; p> <dig> 

a value p =  <dig> to reflect the size of the adjacency matrix that fully specifies the network seems reasonable, but the choice is left open for now. the proportionality constant α cancels out in constructing  so is suppressed in what follows.

the efficacy curves calculated from equations  and  for equal-sized subnets, at subnet counts k ranging from  <dig> to n, are shown in figure  <dig> for p =  <dig>  and p =  <dig>  with a smooth variation and quite a steep gradient, in particular near the optimal subnet count, e gives a sensitive measure of how well a particular network split performs in terms of its subnet count. the figure also shows that this behaviour is almost independent of the p-value, with higher values merely sharpening the maximum slightly.

the main significance of the p-value is in determining the discrimination between partitionings with the same k, but homogeneous versus distributed subnet sizes. raising the power value increases the dominance of larger subnets over smaller ones in the summation term of equation , which tends to lower the efficacy value for a split with a large spectrum of subnet sizes.. experimenting with various networks has shown that for large networks p values in the range  <dig> to  <dig> are required to adequately discriminate between network splits that are dominated by large subnets, and those with more even size distributions. for small networks the available range of subnet sizes is correspondingly small and the value of p less important. the best results are obtained by adjusting p to the network size, and the following empirical formula performs this adequately:

  p= <dig> n 

this formula is merely a calibration of the efficacy scale and has no fundamental significance. the results below illustrate its effects.

it is finally noted that the efficacy measure is constructed quite independently of the netsplitter method; as its only required input is a list of subnet sizes, it can equally well be applied to diverse partitioning algorithms.

RESULTS
the results obtained from the netsplitter procedure are illustrated by considering the problem of investigating the flavonoid metabolism of the model plant arabidopsis thaliana. the complete network was obtained by extracting all stoichiometrically balanced reactions from the aracyc  <dig>  database as curated by the arabidopsis information resource   <cit>  and contains  <dig> reactions and  <dig> metabolites. reaction directions and reversibilities were assigned in accordance with the pathways and enzymes tables of the database. it is not intended as a definitive metabolic network for the organism  but for the demonstration purpose it is considered adequately representative of genome scale metabolic networks. the specification of this network in sbml format is available as additional file  <dig> 

for comparison, figure  <dig> first shows the performance of the simple connection degree partitioning  <cit>  for various threshold values. visual representation of the dag matrix is as in figure  <dig>  but elaborated here by the addition of a blue background that displays automatically recognised block limits.

for a large threshold value of  <dig>  figure  <dig> shows that only a few small blocks are split off from the main block that still contains more than 90% of all internal metabolites. as observed in the demonstration example, internal structure in this large block is not resolved. reducing the cutoff threshold to a value of  <dig> used in previous work  <cit> , the internal structure is well resolved but the main block still contains 20% of all metabolites. reducing the threshold still further to  <dig> finally avoids the domination of a single large block, but at the cost of fragmenting the network into  <dig> very small blocks containing only  <dig> internal metabolites on average.

the reincorporation step is important to keep the number of externals as low as possible. for example, in the full arabidopsis network,  <dig> of the  <dig> high connectivity externals and  <dig> of the  <dig> orphan metabolite nodes created by taking a connectivity degree threshold of  <dig>  can be reincorporated without disturbing the block structure in figure  <dig>  when the netsplitter algorithm is subsequently applied, these numbers are reduced because of the increased partitioning achieved, but in turn  <dig> of the  <dig> externals proposed during the course of externals selection rounds are in fact reincorporated in the final stage. even in the case of the small flavonoid network where only a single separation round is needed producing  <dig> proposed externals,  <dig> of these get reincorporated leaving only two separation nodes. the overall effect is that in both cases less than 5% of the significant mass balance constraints in the full network are sacrificed to decompose it into subnetworks.

it is also instructive to see the action of the netsplitter procedure in an explicit network diagram. the actual layout of the flavonoid demonstration network, for which stages in the procedure were traced out in matrix form in figure  <dig> to  <dig>  is shown in figure  <dig>  a larger version of this figure identifying the metabolites is available as additional file  <dig> 

the algorithm identifies two separation nodes in this case - the metabolites trans-cinnamate and coumaroyl-coa ; cutting these, the network falls apart into four natural subnets, plus two small fragments or "orphans". by inspection of the metabolite names  the subnets can be identified as synthesis of flavonoids , lignin precursors , benzenoids  and coumarin . while in this relatively small network it may have been possible  to identify these separators by inspection, it should be borne in mind that much of the work to group nodes coherently has already been done in the manual construction of the two-dimensional layout displayed. in a realistic example, the input to the algorithm is merely arbitrarily ordered lists of metabolites and reactions, making the task much harder.

to place the results in a more general perspective, table  <dig> compares efficacy values for various cutoff values in simple connectivity-based partitioning  <cit> , with netsplitter results applied to four different networks of increasing size. in addition to the flavonoid demonstration network and the genome scale model plant arabidopsis discussed in detail above, genome scale networks for a simple bacterial species and a mammal are included. the first of these is a metabolic model for m. pneumoniae recently published by yus et al  <cit> . details of the application of netsplitter to this model has been published elsewhere  <cit>  and is shown there to give a partitioning that is virtually identical to the assignment by yus et al of pathways to functional blocks, based on biochemical knowledge. the second is a model for mus musculus validated by fba  <cit> .

values are shown as percentages, and peak values highlighted in bold. the p-value increases with network size as described in the text.

considering first the connectivity based splitting, table  <dig> illustrates that as expected, lower efficacies are calculated for large connectivity cutoffs where a large part of the network remains undivided, and also for small cutoffs where the network is fragmented. this produces an intermediate maximal efficacy, at cutoff values close to  <dig>  in accordance with the values chosen empirically  <cit>  on similar small networks. the p-values assigned by equation  fall well within the range between the curves in figure  <dig> in all cases.

in judging efficacy percentages, its increased sensitivity near the optimum as illustrated in figure  <dig> should be borne in mind - e.g., a partitioning with an efficacy e = 80% is about six times closer to the optimal subnet size than one with e = 40%.

while a single numerical score can hardly be expected to capture all the varied considerations  of what constitutes the best partitioning, the more detailed graphical representation in figure  <dig> of the most interesting cases, suggests that e as calculated here does give a good overall quality indication.

in that figure, each bar segment corresponds to a subnet and the total height of each bar represents the total number of internal metabolites for that partitioning. thus the height difference from the reference bar on the right, indicates the total number of internal metabolite mass balance constraints that have been sacrificed to achieve a particular split. the reference bar also shows the theoretical maximal efficacy n size partitioning of the original network. as this totally ignores the network topology, no actual partitioning can be expected to achieve that. but a reasonable aim would be for subnets to have this size on average without too large deviations on either side.

in the case of arabidopsis, the c =  <dig> value that maximises e gives a couple of rather large blocks and many small ones, including fragments too small to be resolved graphically and appearing as black or grey areas at the bottom. decreasing the cutoff to  <dig> worsens the fragmentation, and this is reflected in the e-values of 54% and 43% respectively. it is again visually obvious that the netsplitter result improves on both of these by spanning the reference subnet size more effectively, and has a moderately high score of e = 70%. it has less fragmentation than either of the cutoff results, and it also retains more constraints than either.

a rather similar situation is shown in figure  <dig> for the case of m. musculus, the best cutoff value increases slightly to c =  <dig> for this larger network, but already shows large fragmentation reflected in e = 41% and again this worsens both visually and in terms of the calculated efficacy to e = 33% if c is reduced to  <dig>  visually, the netsplitter result has a slightly better spread of sizes at the top and somewhat better but still significant fragmentation at the bottom, giving an only moderately improved efficacy score of 48%.

in all cases, the efficacy score based on equation  accords quite well with observations from the more detailed graphical display.

the analysis above of the performance of the netsplitter algorithm for the larger networks, shows that there is a decline with size but that this is not due to its efficiency in splitting, but rather that fragmentation becomes an increasing problem as networks grow. a direct approach to solve that is to introduce controlled merging of subnets and this will be further explored in a subsequent article.

discussion
previous work  <cit>  has shown that graph theory algorithms to trace pathways through a network can give results in conflict with stoichiometric constraints. netsplitter is not of this kind; graph analysis is merely used to identify a list of external metabolites, but network splitting is done directly on the stoichiometry matrix and  all the constraints that it expresses are maintained intact. nevertheless, the concern may exist that e.g. elementary modes may be lost through the partitioning.

a general counterargument is that removal of constraints cannot reduce the number of solutions to a problem. more specifically, consider for example a single mode that in the full network traverses two of the subsequent subnets. when the subnets are separated by reclassifying the metabolite node on their interface as external, the mode is correspondingly split into two parts. since the original mode satisfied all constraints set by mass balances of internal compounds along its path, the two parts must separately continue to be viable. one part will now belong to the first subnet and terminate at the boundary node, which has become an unconstrained external sink and cannot affect its viability. the other will start at the corresponding unconstrained boundary source node in the second subnet and similarly remain viable because by construction the network context of internal metabolites nodes in each subnet is identical to that in the full network.

a direct demonstration of this is obtained from a comparison of the null space of the internal stoichiometry matrix in the full network and in the subnetworks. as the flux vector of a mode lies in the null space, a reaction can only be active  if there is a non-zero entry in at least one basis vector of the null space. for example, in the flavonoid demonstration network shown in figure  <dig>  there are  <dig> reactions, and calculation of the null space basis shows that  <dig> of those are active. repeating this calculation for the internal stoichiometry matrix of each of the six subnets gives  active reactions respectively in each subnet. as reactions are uniquely allocated to subnets in this case, the counts can be added to give a total of  <dig> reactions that are active collectively in the subnets. that leaves a discrepancy of one reaction, the one indicated by an "x" at the top of figure  <dig>  this reaction becomes excluded from the flux space because reclassification of the separator metabolite trans-cinnamate  implies that after partitioning the reaction becomes irrelevant as it then only involves external metabolites. the single inactive reaction in the full network, ends up in subnet  <dig> and remains inactive there.

performing this null space analysis for genome scale networks such as those shown in figure  <dig> reveals the same behaviour in all cases. reclassification can result in some reactions involving only external metabolites and consequent reduction of the flux space; but in the remainder, all reactions that are active in the full network remain active in the subnets, and inactive ones remain inactive in subnets as well. this confirms that subnets collectively support the same set of modes as the full network.

the reduction of the flux space is another perspective on the desirability of keeping the set of external metabolites as small as possible, as is implemented in netsplitter. nevertheless, it is observed that the reactions eliminated are  mostly those at the periphery that only involve a single internal metabolite in the full network, and that their removal has a minimal effect on the structure of modes.

computing efficiency has been taken into account in several aspects of the netsplitter procedure. performing the main computation on a metabolites only simple graph rather than the bipartite representation, reduces matrix dimensions roughly by a factor of two, since the numbers of metabolites and reactions are usually similar. as about half of the metabolites are typically external, including only internals gives a further dimension reduction by a factor of about two. focussing on the  submatrix of the dag gives a further reduction by a similar factor, enhanced also by using binary representations for clustering. bearing in mind that matrix manipulations usually scale quadratically or worse, the overall reduction in complexity could approach two orders of magnitude.

this is borne out by moderate computing times. the total running time observed for the demonstration network of  <dig> reactions ×  <dig> metabolites is  <dig>  seconds, while for a genome scale network of  <dig> reactions and  <dig> metabolites this increased to  <dig> seconds, on a core  <dig> duo pc with  <dig> gb of memory running at  <dig>  ghz. these values appear quite acceptable and indicate that the algorithm scales better than quadratic with network dimension. it may be possible to achieve better performance by rewriting the code in a compiled language, but as extensive use is made of sophisticated graph theory and user interface functions built into mathematica, this would be a major undertaking. experimentation with mathematica options to compile the most computing-intensive sections of the code did not produce significant performance improvements, suggesting that the coding of these functions is already quite efficient.

the procedure as presented is quite elaborate and requires considerable programming for its implementation. to facilitate its practical use, a software application "netsplitter" has been developed as a mathematica  <cit>  notebook which is available for download  <cit> . this application provides an interactive interface that displays the progress of the subnet separation in the way illustrated by figure  <dig>  and offers additional facilities not discussed here such as the merging of selected subnets and display of subnet layouts. a more complete description of the software aspects and illustrations of its application to large scale networks, will be presented in a subsequent article.

an intriguing observation made in applying netsplitter, is the radical change in resolving network structure that results from excluding high connectivity metabolites. an example is seen by comparing figure  <dig> and  <dig> 

it is surmised that the reason for this behaviour can be understood from percolation theory  <cit> . in networks where only a random subset of the potential links in an infinite regular lattice are occupied , it is found that there is a critical occupancy of potential links, termed the percolation threshold pc. long range paths that penetrate the entire network only exist for occupancies greater than pc . values  <cit>  of pc for a variety of lattices have been derived mathematically or numerically; for a simple infinite 2-dimensional square lattice this is  <dig>  and typical values range between  <dig>  and  <dig> , including some non-regular or randomized lattices, while lower values are obtained in higher dimensions. the values also depend strongly on the coordination number z . while a metabolic network is not a regular lattice nor necessarily 2-dimensional, a rough estimate of the occupancy can be made from the adjacency matrices by the formula

  p=∑cr⋅rc z n 

where a simple sum over all matrix elements is taken, and n is the total number of nodes. applying this to the example network, it is found that the removal of the four high connectivity metabolites produces a sharp drop in the value of the occupancy from a value of  <dig>  for the network in figure  <dig> to  <dig>  for figure  <dig>  this is consistent with the interpretation that the disappearance of long-range connectivity displayed by the figure, is caused by a drop of the occupancy number below an unknown percolation threshold. the same phenomenon has been observed in several other networks including those of genome-scale size discussed above.

based on this understanding, an automated strategy could be pursued to progressively reclassify the highest connectivity internal metabolites as external until there is a sharp drop in the p value calculated from equation . in practice, however, it works equally well to simply choose a fixed threshold value and reclassify all internal metabolites with connectivities higher than the threshold.

regarding the proposed efficacy measure, it was indicated above that it relies mainly on a general framework and even where a particular functional form such as the power law in equations  and  was postulated, its parameters merely readjust relative sensitivities to detailed features of the partitioning. this was further tested by experimenting with different functional forms such as an exponential dependence instead of a power law, taking w =  <dig> as might seem more plausible in equation , and even replacing the arithmetic mean term in that equation by a geometric mean expression. these changes were found to have marked effects on the complexity of the analysis, some of which could as a result only be done numerically. in the end the results were quite similar  and the simple option presented is deemed adequate.

the efficacy score measures the degree of simplification achieved by a given network partitioning. as shown in its derivation this is mathematically maximised for equal sized subnets. that does not mean that equal sized subnets is the ideal partitioning outcome; simplification is not the only criterion by which to judge success. clearly there would be no special functional or biological relevance to an equal sized partitioning. on the other hand the low efficacy opposite extreme  of a large monolithic block and small fragments, or even complete fragmentation, is also functionally meaningless. as the m. pneumoniae example illustrates, good agreement with conventional pathway assignments accompanies a moderately high efficacy value. in this sense, despite the inherent limitations of a single number score to represent varied considerations for judging the success of splitting a network for a particular purpose, efficacy values are useful as an overall guideline. it is noted that the efficacy measure is only used after the fact, optimising it does not form any part of the netsplitter algorithm.

CONCLUSIONS
the modularization of a large, complex biochemical network into subnets that can be associated with recognisable biological functions, can be helpful both in the conceptual understanding and interpretation of the network, and to reduce practical problems that arise in the application of analysis methods such as constraint-based modelling. the challenge in constructing an algorithm for this task is to accommodate both the objective structural properties of the network, and more subjective requirements such as the desire for a manageable number of subnets of roughly similar sizes. also, while it is inevitable that some information will be lost when a subnet is isolated from its larger context, it is desirable to restrict this loss to information that is not subjectively relevant for a particular study.

in the procedure proposed here, dealing with the information aspect is facilitated by selecting metabolite node cutting as the partitioning operation, since this pinpoints the nature of the information loss as removal of a mass balance constraint. then the subjective requirements are met by allowing the flexibility to veto the selection of particular nodes to be cut, or to terminate partitioning at a suitable subnet size. both local and long range network structure is taken into account by the use of random walks and clustering strategies, and finally information loss is minimised by using optimisation techniques in selecting candidate separation nodes and by explicit reincorporation of nodes not essential for the separation.

the combination of these strategies succeeds in moderating the extremes of the subnet size distribution that results from partitioning based simply on connectivity degree.

this point is illustrated by considering figure  <dig> and  <dig> as alternative outcomes for somewhat similar levels of intervention with figure  <dig> as a common starting point. figure  <dig> shows how simply decreasing the connection degree threshold from  <dig> to  <dig>  introduces  <dig> new externals and increases the block count by  <dig>  but most of these are very small and a large block encompassing 20% of the network remains. in figure  <dig> the netsplitter algorithm incurs a similar but smaller information loss of  <dig> new externals, but only forms  <dig> additional blocks and encapsulates 66% of the network in  <dig> medium sized blocks. this is clearly a much better cost:benefit ratio, although it is recognised that parts of the network are still dispersed into small fragments leaving room for future improvements.

the efficacy measure e that was introduced encapsulates these considerations into a single quantitative quality score.

at present, it seems that the most promising applications of subnet splitting would be to studies and interpretation of network structure, such as those based on elementary mode analysis, rather than for the more quantitative fba. in this context, subnetworks can play an important role in reducing the often very large number of elementary modes in a large network. the use of subnets for fba would similarly simplify the problem and allow the elimination of extraneous detail not relevant for study of a particular aspect of metabolism. however, the obstacle that arises is that it would usually be more difficult to fix the boundary conditions  for a subnet than for the full network. at least for a single cell organism, full network boundary fluxes reflect overall nutrient uptake or waste elimination rates that are relatively easy to measure. externals of a subnet are likely to include metabolites shared with another subnet and measuring the associated fluxes may require much more detailed metabolic measurements. in special cases, such as when the subnet is spatially localised e.g. to a particular cellular organelle, this might present less of a problem.

a by-product of the matrix oriented approach used by the netsplitter algorithm, is the visually powerful display of network structure. even for large networks for which a network layout diagram is totally unintelligible, features of network connectivity can be recognised at a glance from the colourscale plot of the truncated dag matrix.

even more striking is the characterisation of fully and partially resolved subnetworks afforded by grayscale plots of the blocking matrices. the blocking transformation that was introduced as the basis for computational recognition and optimisation of blocks and their overlaps, serves this second purpose to visualise rather subtle structural network properties. quite apart from the purpose to separate subnets, this visualisation should be a useful tool e.g. to explore the structure of large networks or to compare how related networks differ from one another.

competing interests
the author declares that they have no competing interests.

supplementary material
additional file 1
demonstration model. specification of the network model used for demonstration in the methods section, as an sbml file.

click here for file

 additional file 2
heuristic for block recognition. a description of the heuristic employed by netsplitter for automated recognition of non-overlapping matrix blocks as defined in the text.

click here for file

 additional file 3
genome scale arabidopsis model. specification of the network model extracted from aracyc  <dig>  and used for demonstration in the methods section, as an sbml file.

click here for file

 additional file 4
external metabolites. listing of default external metabolites, specified as biocyc compound id's.

click here for file

 additional file 5
demonstration network layout. the network layout shown in figure  <dig>  with all metabolite and reaction nodes labelled with their biocyc id's and names.

click here for file

 acknowledgements
the author gratefully acknowledges the hospitality of the university of queensland, brisbane where part of this work was completed.
