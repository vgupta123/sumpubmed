BACKGROUND
repetitive elements abound in the genomes of higher organisms. tandem repeats, simple sequence repeats, long terminal repeats , segmental duplications, and transposable elements  are among those types commonly found in eukaryotic species. the biological role of these entities in genome evolution has been documented  <cit> , but from a computational standpoint, the frequency with which repetitive elements occur may confound gene finding and the alignment of homologous sequences.

for anticipated plant genome projects and those currently underway, effective and rapid annotation of their many repeats has acquired a new urgency. for example, the maize genome is estimated to be 60–70% repetitive, mainly in the form of retrotransposons that proliferated in the last  <dig> to  <dig> million years  <cit> . extensive repeats in maize has required a bac-by-bac sequencing approach with finishing primarily focused on the unique space. in this context, computational methods designed to annotate unique sequences have become indispensable.

repeat identification strategies fall under two broad categories: de novo detection and similarity-based detection. repeatmasker  <cit> , one of the most widely used computational tools in repeat analysis, employs the latter method and is therefore reliant on precompiled repeat databases specific to the genome in question. repeatmasker is an essential annotation tool for organisms whose repeat content has been well characterized. however, for many novel genomes a specific repeat library is either nonexistent or insufficient.

de novo methods address many of these concerns. recon  <cit>  currently the dominant tool for de novo repeat detection, builds a set of repeat families through pairwise similarity, clustering and boundary calling. recon and other de novo detection programs like reputer  <cit> , vmatch  <cit> , repeatfinder  <cit> , repeatgluer  <cit> , and piler  <cit> , are designed to generate a repeat library rather than to use one. but to define repeat families, these self-alignment approaches are best suited to genomes that have been assembled into sizable scaffolds. if sequence is not available at that depth or with that contiguity, de novo methods may prove inaccurate especially with respect to repeat boundaries.

other more recent programs like reas  <cit>  and repeatscout  <cit>  attempt to build repeat families around frequent k-mers. k-mer frequency based methods were originally used in whole genome shotgun assemblers  <cit>  that omit reads containing frequent k-mers for the purposes of assembly. programs like reas operate in an inverse fashion, using only high copy reads to seed a sophisticated repeat finding strategy. but these methods, like genome assemblers, require significant sequence depth to assure adequate coverage over repeat families. though we propose a similar strategy, our goal is not to identify repeat families. we have found that even if available sequences cover only a fraction of the genome, k-mer frequencies alone capture rich statistical information on the repeat profiles of plant genomes.

like other k-mer frequency approaches  <cit>  our method does not require a precompiled repeat library. rather than simple hashing methods , we employ enhanced suffix arrays  <cit>  to compute occurrence counts and construct an index  from which we can efficiently retrieve the frequency of each stored k-mer. this strategy allows us to process very large datasets for a wide variety of values of k, and to assign frequency annotations with unprecedented speed. we developed this method in the context of the maize genome sequencing project where rapid genome-scale frequency annotation is integral to genome finishing. the project employs a traditional bac-by-bac sequencing strategy, but directed sequence finishing will proceed only in those regions designated as unique with respect to a  <dig>  × wgs data set generated by the joint genome institute . during development of this novel finishing strategy we expanded k-mer frequencies into a powerful comparative genomics tool, highlighting the differences in complexity and overall repetitiveness in several grass genomes.

methods
sequence data sets
this study used publicly available datasets, including expressed sequence tags , gene-enriched genome fractions, representative whole genome sequences, and repeat libraries, as summarized in table  <dig>  in addition, we sequenced and assembled four bac clones from maize  chromosome  <dig>  which map to fingerprint contig ctg <dig> of the agi agarose fpc map  <cit> . sublibrary construction, sequencing on abi  <dig> machines, and assembly were essentially as described in  <cit> . clone names and their genbank accession numbers are as follows: zmmbbb0483g <dig> , zmmbbb0284n <dig> , zmmbbb0614j <dig> , and zmmbbb0448f <dig> . a polymerase chain reaction was used on template zmmbbb0382k <dig> to give a unique  <dig> bp sequence  that served to fill a physical gap between zmmbbb0483g <dig> and zmmbbb0284n <dig>  overlap between clone sequences allowed assembly of a complete supercontig of  <dig>  bp.

wgs stands for survey of 'whole genome sequences'. ge stands for 'gene enrichment'. ga stands for 'genome assemblies'. the sequence sizes are given in million base pairs.

maize wgs data set
whole-genome shotgun reads for maize , generated by the joint genome institute were downloaded from the ncbi trace archive on february  <dig>   <dig> and clipped to remove vector sequences using cross match  <cit>  and the ncbi univec database  <cit> . the resulting dataset, called maize  <dig>  × wgs, included  <dig> , <dig> reads and  <dig> , <dig>  nucleotides.

gene annotation
ab initio gene prediction was conducted using fge-nesh  on non-masked bac sequences. resulting predictions were subjected to blastp against the ncbi non-redundant gen-pept database with the low-complexity filter turned on, and presumptive genes were identified as having an e-value ≤ 1e- <dig>  transposable elements were screened out by matching their hits against a manually curated list of  <dig> transposable element genes.

annotation of transposable elements
transposable elements were identified using repeat-masker  <cit>  and mips repeat element database  and catalog   <cit> . this database provides a hierarchical classification of plant transposable elements and other repeat types. before use, the database was screened for non-te related sequences and the following identifiers were removed: 'bsr1' , 'k_1' , and 'magellan_cone' .

receiver operating characteristic  curves were compared by the method of  <cit> , as implemented in the medcalc® statistical software package.

basic notions for sequence processing
we consider sequences over the dna alphabet {a, c, g, t, n}, where n denotes an undetermined base . for fixed length k >  <dig>  a k-mer is a sequence of length k, only containing the characters a, c, g, and t. let v be some sequence. merk denotes the set of all different k-mers in v. for any set m, |m| denotes the number of elements in m. so |merk| is the number of different k-mers in v. for any sequence w of length k, let occ be the number of positions in v where w occurs. for a set s of sequences we define merk = ∪v∈s merk and occ = ∑v∈s occ. that is, merk is the set of different k-mers in all sequences from s and occ is the number of positions in any sequence from s where w occurs.

occurrence ratios
for integers q, q',  <dig> ≤ q ≤ q', the k-mer occurrence ratio of s is defined by

 ρs,k=|{w∈merk|q≤occ≤q′}||merk| 

that is, ρs, k is the ratio of k-mers occurring between q and q' times in s. ρs, k is the k-mer uniqueness ratio of s, i.e. the ratio of k-mers occurring exactly once in s. we define the multiple occurrence ratio by

 ρs,k∗=∑w is k−mer,q≤occ≤q′occ∑w is k−merocc. 

note that the denominator in this fraction equals the number of all positions in s where a k-mer occurs. the nominator restricts this count to positions where the corresponding k-mer occurs between q and q' times. while the occurrence ratio only considers the number of different k-mers, the multiple occurrence ratio takes the number of occurrences of a k-mer into account. we want to compute ρs, k and ρs,k∗ for a range of values of k and for any pair of values q, q'. we will later see how to do this efficiently.

average k-mer frequencies
the average frequency of v with respect to s, denoted by λ, is defined by

 λ=log⁡10c+1|merk| 

where

 c=∑w∈merkocc. 

that is, c is the sum of the frequencies of all k-mers in v with respect to s. note that λ is large if the k-mers in v occur many times in s. it is small if the k-mers in v rarely occur in s. thus the average frequency measures how often the k-mers of some sequence v occur on average in some reference sequence set. if v is of length k, then it contains exactly one k-mer, namely v, which implies λ = log <dig> + 1).

distribution ratios
now consider a set ℳs of sequence sets . we want to compare the sequence data sets in ℳs according to the distribution of the average k-mer frequencies of the sequences they contain. the average k-mer frequencies are determined relative to some reference sequence set s . to facilitate the comparison, we define non-overlapping subintervals of similar average k-mer frequency and calculate the fraction of sequences that belong to that subinterval . as the sequence sets considerably differ in their size, we make these distributions comparable by computing ratios. to be precise, let

 λmin⁡=min⁡{λ|m∈ℳs,v∈m} 

and

 λmax⁡=max⁡{λ|m∈ℳs,v∈m} 

be the minimum and maximum possible λ-values for all sequences in the different sequence sets. we divide the interval  into equal sized non-overlapping subintervals at some suitable distance Δ. we obtain the intervals

 ,,..., ,  

such that λmin = -mΔ and Δ ≤ λmax <nΔ. then for each integer j ∈  we compute

 Ωk,m=|{v∈m|jΔ≤λ<Δ}||m| 

where λ = jΔ. that is, Ωk, m is the fraction of sequences in m falling into the jth subinterval. Ωk, m is called λ-distribution ratio for m.

efficient computation of occurrence ratios
note that the occurrence ratios only depend on the k-mers in s. that is, it is derived from the distribution of occ for all k-mers w in s. now let δs, k be a table such that for all i ≥  <dig>  δs, k is the number of different k-mers occurring exactly i times in s. for example, δs, k <cit>  is the number of unique k-mers in s, i.e. the number of k-mers occurring exactly once in s. then the following equations hold:

 ρs,k=∑i=qq′δs,k∑i> <dig> δs,k>0δs,kρs,k∗=∑i=qq′i⋅δs,k∑i> <dig> δs,k>0i⋅δs,k 

according to these equations we can efficiently compute ρs, k and ρs,k∗ from table δs, k. to compute this, one needs to enumerate each k-mer with its occurrence count, thereby updating counters that were initialized to zero. that is, if a k-mer w with occurrence count occ is enumerated, then one increments δs, k by one.

traditionally, occurrence counts for k-mers are computed by hashing methods. however, these only work, if the number 4k of possible k-mers is considerably smaller than n. this does not hold for our application, where k ranges from  <dig> to  <dig>  we have developed a different approach based on enhanced suffix arrays  <cit> . the space requirement and running time of our approach does not depend on the number of possible k-mers, but only on the total length of the sequences in s. moreover, we can simultaneously compute δs, k for a range of values of k. this is useful when determining the optimal value for k.

to explain our approach we begin with the concept of enhanced suffix arrays, as introduced in  <cit> .

enhanced suffix arrays
suppose s consists of r sequences. to process s we concatenate all sequences in s into a long string denoted s¯ with unique separator symbols $ <dig> ...,$r- <dig> between the r sequences. additionally we add a sentinel character $r following the last sequence in the concatenation. obviously, s¯ contains exactly the same k-mers as s. that is, we can compute k-mer counts based on s¯.

suppose that s¯ is of length n +  <dig>  s¯ denotes the character at position i in s¯, for  <dig> ≤ i ≤ n -  <dig>  for i ≤ j, s¯ denotes the substring of s starting with the character at position i and ending with the character at position j. for i > j, s¯ denotes the empty string. a substring of s¯ beginning at the first position of s¯ is a prefix of s¯ and a substring ending at the last position of s¯ is a suffix of s¯. for each h,  <dig> ≤ h ≤ n, s¯h = s¯ denotes the h-th non-empty suffix of s¯, i.e. the suffix beginning at position h in s¯.

the key to our method is to lexicographically sort the suffixes of s¯. suppose that the characters are ordered such that a < c < g < t < n < $ <dig> < ... <$r. this character order induces an order on all nonempty suffixes of s¯, which is captured in the suffix array. the suffix array suf of s¯ is an array of integers in the range  <dig> to n, specifying the lexicographic order of the n +  <dig> non-empty suffixes of s¯. in other words, s¯suf <cit> ,s¯suf <cit> ,...s¯suf is the sequence of suffixes of s¯ in ascending lexicographic order.

the lcp-table lcp is an array of integers in the range  <dig> to n. for each h,  <dig> ≤ h ≤ n, lcp is the length of the longest common prefix of s¯suf and s¯suf. since = $r is the largest suffix in the lexicographic order, s¯suf = $r. hence we always have lcp =  <dig>  in the following, the combination of the suffix array and the lcp-table is called enhanced suffix array.

the notion of lcp-intervals, introduced in  <cit>  is central for the computation of the occurrence frequencies for the k-mers. an interval ,  <dig> ≤ i <j ≤ n, is an lcp-interval of lcp-value ℓ if

 <dig>  lcp < ℓ,

 <dig>  lcp ≥ ℓ for all h, i +  <dig> ≤ h ≤ j,

 <dig>  h =  <dig> or lcp = ℓ for at least one h satisfying i +  <dig> ≤ h ≤ j,

 <dig>  j = n or lcp < ℓ.

we will also use the shorthand ℓ-interval for an lcp-interval  of lcp-value ℓ. we say that an ℓ-interval  represents the substring s¯..suf + ℓ - 1] of s¯ of length ℓ.

an interval ,  <dig> ≤ i ≤ n is a singleton interval. we say that a singleton interval  represents the suffix s¯..n - 1] of s¯. an m-interval  is said to be embedded in an ℓ-interval  if it is a subinterval of   and m > ℓ. note that we cannot have both i = l and r = j because m > ℓ. a singleton interval  is said to be embedded in an ℓ-interval , if i ≤ l ≤ j. if an interval  is embedded in , then  is the interval enclosing . if  encloses  and there is no interval embedded in  that also encloses , then  is called a child interval of .

enumerating k-mers and their occurrence counts
the parent-child relationship of the intervals constitutes a conceptual  tree which we call the lcp-interval tree of the suffix array. the leaves of the tree are the singleton intervals and the internal nodes of the tree are the lcp-intervals. in particular, the root of this tree is the 0-interval . an important property of the lcp-interval tree is the fact that it implicitly stores the number of occurrences of all substrings of s¯. in particular, an interval  represents a string occurring j - i +  <dig> times in s¯. the idea is to read these occurrence counts from the lcp-interval tree. this works as follows: we use an algorithm described in  <cit>  to enumerate the nodes of the lcp-interval tree. this algorithm has some important features:

 the nodes of the lcp-interval tree are enumerated in bottom-up order, i.e. a node, say α, is enumerated only after all nodes in the subtree below α have been enumerated.

 the children with the same parent node are enumerated according to the lexicographic order of the strings they represent.

 whenever we process the children of a node, we have access to the lcp-value of the parent node.

 the values in tables suf and lcp are accessed in sequential order from left to right.

due to property , the k-mers occurring in s¯ are enumerated in lexicographic order. it now remains to show how to compute table δs, k for a range of values k between user defined limits kmin and kmax.

suppose that all values incremented below are initialized to zero.

• we process a singleton interval  as follows: let d be the lcp-value of the parent node of . then s¯..suf + k - 1] is a k-mer occurring exactly once in s¯ if and only if the following holds:

 <dig>  d <k,

 <dig>  suf + k ≤ n,

 <dig>  s¯+d..suf + k - 1] does not contain the symbol n.

as a consequence, for all k, max{d +  <dig>  kmin} ≤ k ≤ min{k' -  <dig>  kmax}, we increment δs, k <cit>  by one, where k' is the minimum value greater than d such that either suf + k' = n or s¯ + k'] = n.

• we process an ℓ-interval  different from  as follows: let d be the lcp-value of the parent of . then s¯..suf + k - 1] is a k-mer occurring j - i +  <dig> times in s¯, if and only if d <k ≤ ℓ. as a consequence, for all k, max{d +  <dig>  kmin} ≤ k ≤ min{ℓ, kmax}, we increment δs, k by one.

analysis of time and space requirement
the suffix array can be computed in linear time and space . the same holds for the lcp-table, see  <cit> .

the algorithm to enumerate the lcp-intervals and singleton intervals, given the enhanced suffix array, runs in linear time, see  <cit>  for details. whenever one visits a node, say α, one keeps track of all nodes on the path from the root to α. these are maintained on a stack, using constant time and space per node. in our specific application, we store the lcp-value and the left interval boundary of each node on the stack. since one has access to the lcp-value of the parent node ), one can process each lcp-interval in constant time. for the singleton intervals we need to verify that s¯ + d..suf + k - 1] does not contain the symbol n. rather than checking this condition character by character, we use information about ranges of ns, preprocessed from the input sequence. that is, we store, in sorted order, the first position of each run of consecutive ns in s¯. then for each position i,  <dig> ≤ i ≤ n -  <dig>  s¯ ≠ n, we can determine the smallest position i' > i such that i' = n or s¯ = n using a binary search. let q be the number of these runs. then this method takes on the order of log2q time and requires extra space proportional to q.

due to property , the enhanced suffix array does not need to be represented in main memory. at any time, we only need to store two consecutive entries of table suf and lcp. hence the space requirement is dominated by the stack needed for the bottom-up traversal of the  lcp-interval tree. our specific application only requires to store nodes representing strings of length shorter than kmax occurring more than once as substrings in s¯. hence the stack size can be limited to kmax, which results in a space requirement proportional to kmax.

besides random access to the sequence, we also need random access to a data structure for accumulating the occurrence counts. let τ be the number of values i satisfying δs, k >  <dig> for some k ∈ . then this data structure  requires space proportional to τ ≤ n.

the overall space requirement of the algorithm is proportional to n + kmax + q and the running time is proportional to n log2q. while the running time does not depend on kmax, the space requirement is linearly dependent on kmax. since kmax and q are both much smaller than n, they can be neglected. as a result, we obtain an algorithm that is linear in running time and space requirement. in contrast, the hashing methods run in time proportional to n + 4k time and space proportional to 4k for some fixed value of k. that is, their running time and space requirement grows exponentially with k. as a consequence, these methods can only be applied for small values of k. these values are fixed, in contrast to our method which allows the computation for a range of values of k.

dividing and merging the datasets
the analysis above shows that the running time and space requirement of our algorithm for computing k-mer counts  is dominated by the suffix array construction. this is especially true for the space requirement. to get an idea of whether our method can be applied to large sequence sets, we have to consider the space requirement of the suffix array constructions in more detail. the most space efficient suffix array construction requires / <dig> bytes per input symbol plus 2n/ <dig> bytes for representing the sequence. given a 32-bit computer with  <dig> gigabytes  of main memory, n has to satisfy the inequality / <dig> ≤  <dig> -  <dig>  that is, the sequence length is limited to  <dig> gigabyte. since we want to process considerably larger sequences, we developed a divide-and-conquer approach. this cuts the sequence s¯ into sufficiently small non-overlapping sections, such that for each section we can compute the corresponding enhanced suffix array on a 32-bit computer .

processing each section by the algorithm described above results in occurrence counts for each section. more precisely, for each section we enumerate pairs  where pos is a position in the corresponding section and occ is the number of occurrences of s¯  in this section. thus each pair encodes a k-mer, and the pairs are stored on a file in the order they are delivered by the algorithm, namely in lexicographic order with respect to the k-mer. this property allows to combine the appropriate values in a merging process, which works as follows: suppose we are given, say m, files storing the occurrence counts for the m sections of s¯. these files are merged in m -  <dig> pairwise merge-operations. the merging steps only require to have the entire sequence s¯ represented in main memory. since we restrict to dna sequences and, by construction, do not process any substrings of s¯ containing the character n, we can store each nucleotide in  <dig> bits, i.e. n/ <dig> bytes suffices for representing the sequence. that is, the merging procedure allows to process sequences of length up to  <dig> gigabytes on a 32-bit computer.

efficient computation of distribution ratios
in contrast to the occurrence ratios, the average frequency λ of a sequence v is determined relative to the k-mer content of s. since we want to compute λ for a fixed set s and many different sequences v, it makes sense to preprocess s into a k-mer frequency index i storing all k-mers occurring between occmin and occmax times in s. here occmin and occmax are user defined positive numbers. constraining the indexed k-mers by user specified values occmin and occmax is relevant in applications where we are interested in k-mers occurring rarely  or frequently . given the index i, we want to solve the following tasks:

 for each possible sequence w of length k, determine if it occurs in the index.

 for each k-mer occurring in the index, determine the number of its occurrences in the index.

in the previous section we have shown how to compute occurrence ratios by enumerating k-mers. instead of deriving occurrence ratios by incrementing some table δs, k, the same enumeration process can determine the k-mers w satisfying the constraint occmin ≤ occ ≤ occmax. if this is satisfied, the k-mer is stored on a file. as the k-mers are enumerated in lexicographic order, the index i is simply a sequence of lexico-graphically ordered k-mers stored on a file. whenever this is needed it can be mapped into main memory.

to implement i, we directly store each k-mer together with the occurrence count, if this is required. as a k-mer is a string over an alphabet of size  <dig>  it can be stored in k log <dig>  <dig> = 2k bits. this, of course restricts the choice of k to small values. but since the optimal values for k are rather small , this is not a restriction in practice.

let r be the number of indexed k-mers. since the stored k-mers are lexicographically ordered, for each possible k-mer, task  and  can be solved by a binary search over the index. each step of the binary search requires to compare 2k bits. as these are represented by integers of the machine word size ω, a single comparison takes time proportional to ⌈2kω⌉. there are at most log <dig> r comparisons to determine if a k-mer occurs in the index. if it occurs, then the occurrence count can be determined in constant time by a single table lookup. altogether, the search for a k-mer takes time proportional to ⌈2kω⌉ log <dig> r. for example, on a 32-bit computer, it takes on the order of  <dig> log <dig> r steps to perform the binary search when k =  <dig> 

to put it together, our index differs in several aspects from other indexing approaches employed in sequence analysis :

• first, we do not store information about where the k-mers occur in s. this fact leads to some simplifications for the implementation of the index and allows faster querying time. moreover, it means that the size of the index is not dependent on the size of s. it rather depends on the choice of values occmin and occmax. for large sequence sets and larger values of k, the number of different k-mers becomes very large. when computing occurrence ratios, this is not a problem, as only k-mer counts are accumulated. however, when constructing the k-mer index, occmin and occmax should be chosen carefully. if these values are not restrictive enough, then there may be too many k-mers to be indexed. that is, the input sequence representation and the k-mer index may not fit into memory any more.

• second, we directly store each k-mer as a bit string together with the occurrence count in the index. that is, the information about the indexed k-mer is not distributed over different memory locations, as in other indexing approaches . as a consequence, the querying times for our index are extremely short.

the tallymer software  <cit>  provides programs for computing occurrence ratios , for generating a k-mer index , and for searching a k-mer index . the software-distribution is complemented by a program to construct enhanced suffix arrays. the 32-bit version of this program can handle sequences of size about  <dig> million bp per gigabytes of main memory. for example, to handle the  <dig>  × wgs data set  in this amount of main memory, we have to split it into eight sections each of approximately  <dig> million bp. the program tallymer-occratio provides flexible options to specify the range of k-mer sizes considered and to tailor the values output. for example, one can specify that values are output as ratios instead of absolute counts. comparison of k-mer frequencies of two sequence sets is not directly supported by the software, but can easily be done as follows: create an index of the first sequence set and query it with the second, and vice versa.

the program tallymer-search takes multiple fasta files as input. it generates all k-mers not containing any n from the given files, and matches them against the index in forward and/or reverse direction. currently only exact matches are supported. an extension to degenerate matches would require a combination of index traversal and dynamic programming techniques, as, for example, implemented in vmatch  <cit>  for the case that the index is an enhanced suffix array.

RESULTS
selection of k-mer size for use in maize
because our method allows us to compute k-mer frequencies for large values of k, we have a wide latitude for selection of a k-mer size. figure  <dig> plots the k-mer uniqueness ratio for the  <dig>  × wgs for k in the range  <dig> to  <dig>  as k approaches  <dig>  the curve reaches unity. the information content of the k-mer set increases at a very fast rate from k =  <dig> to k =  <dig>  beyond this point, increasing k does not significantly increase the number of unique k-mers, but does decrease the overall resolution of the k-mer set. the inflection point on this curve is likely to change for other genomes and other sources of survey sequence, but for our wgs reference, k =  <dig> is optimal.

validation of the 20-mer frequency index for the wgs set
the use of k-mer frequencies is premised on the availability of an unbiased sequence set reflecting the overall repeat character of the genome in question. to test whether the  <dig>  × wgs meets this criterion, we computed the corresponding 20-mer frequency index, i.e. s is the  <dig>  × wgs set and k =  <dig>  it contains  <dig> , <dig> different 20-mers. there are  <dig> , <dig>  positions at which a 20-mer occurs. we screened seven publicly available maize sequence sets , against s. that is, we evaluated Ωk, m for m ∈ {bac, bes, repi, repii, est, azm <dig> hc, azm <dig> mf}.

the public maize sequence sets fall into three classes:  maize whole genome sequences,  maize repeats, and  maize gene enrichment sequences. the seven sequence sets are known to have differing degrees of repetitiveness and should therefore provide a means to verify our method. for example, we expect gene enriched sequence to be less repetitive than repii sequences , and repii sequences to be less repetitive than repi sequences .

the results of this analysis are shown in figure  <dig>  panel a confirms that the two maize whole genome sequence sets have similar frequency distributions, providing an overall, unbiased repeat profile for the maize genome. the λ-distribution ratios of repi, repii, and bac sequence is shown in panel b. repi repeats exhibit high average frequency, many of which exceed  <dig> copies in the  <dig>  × wgs set, while the repii repeats, enriched in low-copy elements, are far less repetitive. notably, the λ-distribution ratios for both repeat classes are bimodal. the more repetitive peak for repi corresponds to an enrichment of ty3/gypsy repeat elements, while the less repetitive reflects enrichment in ty1/copia ). though the λ-distribution for repii also appears to be bimodal, we were unable to find significantly different repeat populations among the dna transposon derivatives and superfamilies.

the three sequence sets delivered by gene enrichment methods shown in figure 2c peak around an average frequency of  <dig> in the wgs set. the relative uniqueness of these reads justifies the attribute 'gene-enriched', but their apparent efficacy varies significantly. the high-c0t method succeeds in concentrating unique sequence without much leakage of the highly repetitive content evident to some extent in the ests, and to a far greater extent in the methyl-filtered library. this difference observed between the high-c0t and methyl-filtered libraries was previously observed in  <cit> .

genome annotation using k-mer frequencies
we used a previously published set of  <dig> maize bac sequences that had been chosen at random to be representative of the whole genome  <cit> . a position, say i, in a bac was masked if the logarithm of the absolute frequency of the 20-mer starting at position i achieves some threshold. figure 3a shows that, summing over all bacs, 50% of nucleotides were masked at an absolute frequency threshold of  <dig>  or greater, corresponding to at least  <dig> occurrences in the wgs index. coverage of individual bacs at this threshold ranged from  <dig> % to  <dig> %. reducing the threshold resulted in greater coverage. at the lowest threshold of  <dig>  , total coverage reached  <dig> % .

we compared these results to masking based on the curated mips recat repeat library. this library includes repeats from many sources including annotated tes from the bacs used in this analysis. thus application of this library can be regarded as a 'gold-standard' for detection of tes within these bacs. indeed, masking using the mips recat library, resulted in a total repeat coverage of  <dig> % . this exceeds the masking rate of 67% originally reported for this set  <cit> , suggesting that the mips recat library has been updated with new repeat sequences after its publication in  <dig>  figure 3b shows the extent of overlap between masked positions using these two methods. overlap of positions masked by our method with curated tes in recat exceeded 93% at lowest absolute frequency threshold and reached a maximum of  <dig> % over the most repetitive regions . overlap was  <dig> % at an absolute frequency threshold of  <dig> . these results indicate that the mips recat library is on the whole inclusive of moderately and highly repetitive regions in these bacs.

in contrast, 81% of the mips recat-masked positions are also masked by our method. this was achieved at the absolute frequency threshold of  <dig>  . at the absolute frequency threshold of  <dig> , only  <dig> % of positions masked by mips recat were also masked by our method.

we next compared the two repeat detection methods for their ability to discriminate tes at the level of predicted genes. the set of  <dig> bacs were annotated using fgenesh and resulting predictions were classified as presumptive genes or as tes using a similarity-based search . of the  <dig> predicted genes,  <dig>  were screened out as showing no evidence of homology to ncbi genpept peptides. of the remainder,  <dig>  were classified as te while the remaining  <dig>  were classified as presumptive genes. for these latter two classes the percent of coding sequence masked was calculated based on either repeatmasker data or on constituent 20-mer frequencies at various thresholds. for each method of masking, receiver operating characteristic  curves were used to define a threshold of masking that best discriminated tes from presumptive genes. area under the curve , sensitivity, and specificity were used to compare efficacies  <cit> .

because percent masking using k-mers depends on which absolute frequency threshold is used, we first optimized the threshold by comparing all roc curves for absolute frequency thresholds between  <dig> and  <dig>  at  <dig>  increments. the threshold of  <dig>  gave the maximum area under the curve , with a value of  <dig>  . for masking using recat the auc was only slightly higher,  <dig>  . comparison of these two roc curves, shown in figure  <dig>  revealed that this difference in auc was not significant .

ab initio gene prediction was carried out on  <dig> non-masked bac sequences using fgenesh, and resulting models were classified as te  or as presumed genes  based on a blastp similarity search. roc analysis was used to determine the optimum criterion  that would maximize detection of tes while minimizing false positives .

while both repeatmasker and our method masked the majority of repi retroelements, some low copy tes escaped masking under our method based on average frequencies. as shown in our analysis of the  <dig> pilot bacs, low-copy dna transposons, may be annotated as such by curated repeat databases, but missed by the counting approach used here. in the context of directed sequence finishing, low-copy repeats are often as in need of characterization as protein coding genes. leaving them unmasked in maize is actually in the best interests of the project. but the average frequency threshold must be chosen carefully: more permissive thresholds will lead to finishing te-like elements, and more strict thresholds may mask high-copy gene families. to use this method optimally, a balance must be struck with respect to the genome in question, and the thresholds need to be adjusted according to the annotation requirements.

the validated wgs index can be used to annotate any portion of the genome with respect to its component k-mer frequencies. in another set of experiments, we analyzed a  <dig> kb portion of maize chromosome  <dig>  and display a portion of its annotation from position  <dig>  to  <dig>  in figure  <dig>  the first two tracks show the locations of fgenesh ab initio gene predictions classified as either putative protein-coding genes  or transposable elements . the global k-mer frequency  track visualizes the absolute frequency across the region. frequencies in this histogram were generated by querying each overlapping 20-mer in a 5' to 3' direction against the wgs index. note that some regions contain k-mers occurring on the order of  <dig> times in the maize wgs set. in the gkf track, te-like genes often correspond to regions of high absolute frequency, while genes similar to known proteins reside in regions of smaller absolute frequencies.

if the scope of the experiment is narrowed, however, and the k-mer frequencies are computed with respect to the region itself, independent of the wgs index, a significantly different picture emerges. the local k-mer frequency  track represents a self-analysis: the frequencies of overlapping 20-mers in the query are determined relative to the  <dig> kb region alone. even in a local context many tes are present at high copy number . but the lkf highlights local features in a way gkf cannot. this region contains four locally duplicated genes related to selenium-binding proteins. figure  <dig> shows that these genes have a higher lkf than surrounding genes that are present at single copy. such peaks are not evident in the gkf track indicating that these genes have low overall copy number within the genome. this analysis could be employed to identify local expansions of paralogous genes commonly found in plant genomes  <cit> .

comparative genomics
beyond employing k-mer frequencies to annotate sequence with copy-number information, we have found that the frequency information contained therein are themselves biologically informative, illuminating cross species differences in repetitive content. for example, figure  <dig> compares whole genome shotgun sets acquired from three distinct sequencing projects: rice  <cit> , sorghum  <cit> , and the  <dig>  × maize set  employed throughout this analysis. using randomly selected reads to simulate  <dig>  × coverage in each species given their predicted genome sizes  <cit> , we computed  occurrence ratios, i.e. percentage values 100·ρs,k∗ and 100·ρs,k∗  and 100·ρs, k, 100·ρs, k, 100·ρs, k, 100·ρs, k, 100·ρs, k , where k =  <dig> and s is the respective sequence set. recall that the occurrence ratio ρs, k is the ratio of k-mers occurring between q and q' times in s. the multiple occurrence ratio ρs,k∗ is similarly defined, but takes the number of occurrences of a k-mer into account. see section "methods" for details.

for example, in the case of maize, there are  <dig> , <dig>  positions at which a  <dig> mer occurs. there are  <dig> , <dig> different 20-mers of which  <dig> , <dig> are found only once, while the most highly represented sequences exists  <dig>  times.

the multiple occurrence ratios represented in figure 6a show that maize contains the most repetitive sequence, followed by sorghum, and rice. nearly 25% of maize 20-mers occur more than  <dig> times while only 14% of sorghum and 13% of rice 20-mers exhibit this frequency. this finding was expected. when only considering the number of different 20-mers in figure 6b, we find that a mere 1% of all 20-mers occurs more than  <dig> times, i.e. accounts for the repetitive fractions. this is a remarkable equivalence in complexity across the three organisms. low complexity is consistent with relatively recent proliferation of a small number of originating te's resulting in limited divergence of k-mers. maize demonstrates the most substantial growth in repetitive content, a finding attributable to its known te expansion  <cit> . thus, the k-mer frequency method provides a novel way of quantifying this important evolutionary event.

read lengths in whole genome shotgun sequencing projects limit this sort of analysis. since sanger reads average around  <dig> base pairs in length, most repetitive elements will be truncated at the 5' and 3' ends, making experiments with k-mer sizes greater than  <dig> base pairs impractical. however, genome assemblies obviously do not suffer from these read length restrictions. currently, there are very few plant assemblies. though a number of projects are underway, only four genomes have been published: arabidopsis  <cit> , rice  <cit> , poplar  <cit> , and grapevine  <cit> . in figure  <dig> we plot the k-mer uniqueness ratio for these genomes, as a function of k. we tested k-mer sizes from k =  <dig> to k =  <dig>  with k approaching  <dig>  the uniqueness ratio converges to  <dig>  more repetitive genomes such as rice and poplar converge at a much slower rate than arabidopsis.

we performed a number of experiments demonstrating that k-mer frequencies cannot be used to annotate repeats across species  owing to divergent te families. but within a species, our method seems to work across cultivars regardless of which subtype is considered. for maize, our standard  <dig>  × wgs sequence set is derived from b <dig>  the cultivar currently being sequenced. figure  <dig> shows that using this index, one can successfully mask the tes of two sister cultivars, mcc and mo <dig>  in the well-characterized bronze- <dig> locus  <cit> . while the transposition histories of the three cultivars differ markedly, the k-mers in these tes have undergone little divergence.

CONCLUSIONS
we have described a method based on k-mer frequencies allowing for annotating large repetitive plant genomes. as we have demonstrated, our method is useful as an alternative or supplementary form of repeat annotation in novel genomes. the novelty of genomes being sequenced is precisely the reason why this approach has value. by definition, new genomes lack comprehensive repeat libraries, and the construction of de novo libraries is often hampered by the paucity of sequence available at a project's outset. in the absence of such libraries, survey sequences in the form of sanger wgs,  <dig>  <cit> , solexa  <cit> , or solid  <cit>  reads can be used to create cheap, abbreviated k-mer frequency indices for use across multiple subtypes.

in designing the k-mer frequency approach to be completely independent of any manual annotation, we apply a binary decision framework: given a numerical threshold, sequence is designated as either repeat or non-repeat. though binary designations are sufficient for sequence masking, we believe that the k-mer frequencies  are best used in combination with other methods designed for careful repeat annotation as demonstrated in the accompanying publication  <cit> .

to apply our methods to large sequence sets, we have developed fast and memory efficient algorithms to compute occurrence ratios, to index k-mers, and to retrieve their occurrence counts from the index. the algorithms are implemented in the tallymer software. a distribution of the software and the perl-scripts post processing the output is available from the tallymer website  <cit> .

authors' contributions
sk developed the algorithms and implemented the tallymer software. an analyzed sequence data sets with respect to tallymer output. js performed annotation of maize bacs, their visualization, and roc analysis. dw conceived this study. all authors contributed to writing the article.

