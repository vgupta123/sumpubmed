BACKGROUND
the number of genotyped individuals is growing rapidly in both human and livestock populations due to the availability of affordable high density genotyping services. as a result, genomic information has grown in importance. among genomic applications in livestock, especially in dairy cattle, genomic selection
 <cit>  can substantially increase response to selection per unit of time compared to traditional selection
 <cit> . genomic selection has already been successfully adopted in the dairy cattle industry and has potential benefits for other livestock species e.g.
 <cit> . however, genomic selection requires the routine genotyping of large number of young selection candidates, which can be expensive. to reduce genotyping costs, one option is to genotype young candidates with a cheaper lower density panel , which covers the genome uniformly, and to impute the genotype of untyped loci using information from a reference population genotyped with a higher density panel 
 <cit> . sharing of genomic data in both human and livestock populations is of great advantage in order to increase reliability of predictions
 <cit> . imputation is also a powerful tool when combining data sets genotyped with different panels, provided enough overlap exists between panels. sporadically missing genotypes can also be imputed in order to improve the genotype call rate
 <cit> .

phasing and imputation methods can be broadly divided into family-based methods, which use linkage information from close relatives, and population-based methods, which use population linkage disequilibrium information
 <cit> . methods that rely on family information are mainly rule-based methods e.g.,
 <cit> . they are reasonably accurate, especially if the ldp is sparse. methods that use population information are usually probabilistic or model-based and exploit linkage disequilibrium between close snp by modeling haplotype frequencies. their accuracy depends mainly on panel density and reference size
 <cit> . population imputation methods assume that individuals are unrelated. they do not make use of close relationships directly. however, they can still capture close relationships between individuals by finding long shared haplotypes
 <cit> . population-based methods are highly accurate, if both number of markers and number of reference individuals are high enough, but they are computationally intensive.

kong et al.
 <cit>  presented a method to phase and impute long haplotype blocks. they used a group of surrogate parents  instead of true parents. in long range phasing, surrogate parents play a very important role when the true parents are not known/genotyped. this method was extended to use true parents when available
 <cit> . meuwissen and goddard
 <cit>  proposed a combined family and population phasing and imputation method. first, family information is taken into account by an iterative peeling algorithm. in the second step, population information is used by approximating identical by descent probabilities.

genealogy plays a very important role in phasing and imputation
 <cit> . real data usually shows a wide range of relationships between individuals from parent-progeny to individuals that are separated by many generations. at the haplotype level, close relatives share longer haplotypes that have lower frequency in the population. distant relatives share shorter haplotypes which usually have higher frequency. imputation and phasing are more accurate when using information from close relatives  than when using information from distant relatives. therefore, one effective phasing or imputation strategy is to exploit the genealogy or relationships between individuals by searching for haplotypes from the longest to the shortest. this idea is a key aspect of the proposed method.

accurate imputation of rare alleles is a challenging task. rare alleles could contribute substantially to what is commonly called “missing heritability”, i.e. they could account for a substantial part of the genetic variance
 <cit> , although this is currently being debated. in addition, as minor allele frequency  decreases, association methods become more sensitive to genotyping errors. therefore, accurate imputation of variants with low maf is of importance and interest. most rare variants  tend to be recent and are associated with longer haplotypes
 <cit> . therefore the use of information from close relatives is helpful for the imputation of rare variants.

in this paper a novel rule-based method for imputation is presented. the method relies on exploiting relationships between individuals assuming that close relatives share longer haplotypes while distant relatives share shorter haplotypes. the method has been successfully programmed in fimpute software. the performance of this method in terms of overall accuracy, accuracy of rare variants and computing requirements was investigated and compared to that of beagle and impute <dig> 

RESULTS
the proposed method firstly uses the available pedigree information for accurate phasing and imputation, using an iterative approach. after family imputation, the remaining missing genotypes are imputed by an overlapping sliding window  approach, assuming that all individuals are related to some degree. with osw approach, first more accurate information from close relatives is captured by moving long windows over a chromosome. information from more distant relatives is then taken into account by making the window size shorter and shorter in each chromosomal sweep. for each window a haplotype library is built which is used for phasing and imputation within the window. the proposed method was compared to beagle and impute <dig> software on a large dairy cattle data set. the effect of genotyping close relatives  with hdp, different densities, and utilization of pedigree information was investigated .table  <dig> 
scenarios used for the reference group to assess imputation accuracy



3 k/6 k to 50 k

50 k to 300 k


because of its deterministic nature, the new imputation method was expected to be computationally faster than the hidden markov methods  used by software such as beagle and impute <dig>  however, the first challenge for any imputation method is accuracy. therefore, results of accuracy of imputation, as well as some other important aspects, such as the accuracy of imputation of rare variants, will be first presented followed by the computational efficiency.

overall imputation accuracy
allelic r <dig> for different scenarios and methods are presented in figure 
 <dig>  allelic r <dig> is a measure of imputation accuracy that depends less on snp allele frequency than concordance rate and it is calculated as the squared correlation between imputed and true genotypes
 <cit> . in general, as expected, imputation was more accurate when the ldp was denser, the reference group was larger or when close relatives were included in the reference group.figure  <dig> 
overall allelic r <dig> for fimpute, beagle and impute <dig> across different imputation scenarios. there were  <dig> and  <dig> young target individuals for imputation from 3 k/6 k to 50 k and from 50 k to 300 k, respectively. in scenarios a and f, reference groups with different sizes were randomly chosen after excluding parents and grandparents. the reference group in scenarios b and c included only parents and grandparents, in scenarios d and e it included all genotyped males and in scenarios g and h it included all genotyped individuals. pedigree information was considered in scenarios c, e and h and was disregarded in scenarios b, c and g.



in scenarios a and f, the goal was to assess the performance of fimpute with different reference sizes, and when target individuals were not closely related to those in the reference group. for these scenarios, parents and grandparents were excluded to reduce the chance of observing very long haplotype sharing between target and reference groups. fimpute achieved very high imputation accuracy for 6 k to 50 k and 50 k to 300 k. allelic r <dig> for 3 k to 50 k was relatively high, but not as high as those achieved by beagle and impute <dig>  fimpute performed much better for denser panels, because it could find shared haplotypes between distant relatives with greater precision. for 50 k to 300 k, the allelic r <dig> attained with fimpute and impute <dig> were similar across different reference sizes and were higher than those attained with beagle. allelic r <dig> was higher with a larger reference size and the gain in accuracy for fimpute and, especially, beagle was larger than for impute <dig>  this might be due to the fact that impute <dig> samples a fixed number of haplotypes  from approximated surrogate family members, regardless of the number of haplotypes in the reference group
 <cit> . as can be seen from figure 
 <dig>  one can expect that beagle will be similar in performance to impute <dig> if the reference size is big enough.

for 3 k/6 k to 50 k cases, all target individuals had genotyped parents and grandparents, therefore scenarios b without pedigree information and c with pedigree information were designed to investigate the impact of close reference relatives on allelic r <dig> and efficiency of fimpute for this situation. only parents and grandparents were included in the reference group. inclusion of very close relative in the reference group substantially increased the imputation accuracy especially when pedigree information was taken into account . browning and browning
 <cit>  also found that when parents were included in the reference group, phasing accuracy using population haplotype frequency information was substantially higher. the increase in imputation accuracy was more evident for 3 k to 50 k. however, as the panel becomes denser the importance of having reference individuals with close relationships to the target animals decreased. in scenario b, fimpute always gave higher allelic r <dig> compared to beagle and impute <dig>  this indicates that fimpute can better capture information from close relatives even without a known pedigree. impute <dig> performed better than beagle in scenario b.

for imputation from 50 k to 300 k, most parents and grandparents of the target group were not genotyped with the 777 k panel, therefore, it was not possible to try scenarios similar to b or c. instead, all animals including genotyped parents and grandparents of those in the target group were included in the reference group, and imputation was carried out with and without pedigree information . the gain in accuracy due to adding close relatives in the reference group was small . the use of pedigree information had a slightly detrimental effect on the allelic r <dig> . this slight decrease in accuracy when pedigree information was used could be due to errors in the pedigree. such errors cannot be identified for ungenotyped individuals. this result, however, indicates that the osw approach is more robust than family imputation for high density imputation. with a reference group that includes genotyped parents and grandparents, fimpute showed slightly more gain in allelic r <dig> than beagle and impute <dig> 

in cattle, males tend to contribute more genetically to the population than females. semen samples are usually available for older males and can be used for genotyping while the genetic material of older females is most often not available. scenarios d and e were designed to investigate imputation based on a male-only reference group. the reference for imputation from 3 k/6 k to 50 k consisted of all 50 k genotyped males including sires and grand sires. the size of this reference group was  <dig>  males. imputation with beagle and impute <dig> was not feasible for this scenario due to their high computational demand. the allelic r <dig> for fimpute in scenario d  was  <dig>  for 3 k to 50 k and  <dig>  for 6 k to 50 k. these values were higher than those of scenario a with  <dig>  reference individuals. the higher accuracies for scenarios d and e were mainly due to the larger reference population size and the presence of sires and grand sires in the reference group. one conclusion from comparing scenarios b and c to scenarios d and e is that for low density imputation , the genotypes of female ancestors and the availability of pedigree information are very important in order to achieve optimal imputation accuracy.

imputation accuracy of rare variants
accurate imputation of snp with rare alleles  is important since rare alleles may account for a large portion of the genetic variation that is not explained by common alleles
 <cit> . the relationship between allelic r <dig> and maf in the target group is illustrated in figure 
 <dig> for different scenarios. in general, allelic r <dig> increased as maf increased for all methods. the gain in the imputation accuracy of rare variants increased with reference population size and panel density. from figure 
 <dig> the imputation of rare alleles is more sensitive to the size of the reference group compared to the imputation of common alleles. the larger the reference group size, the more accurate the imputed genotypes for snp with low maf . for scenarios a and f, where close relatives were excluded from the reference group, fimpute was able to call snp with low maf with higher accuracy. because most rare variants are recent and located on long haplotypes, this shows that fimpute can exploit longer haplotypes  quite efficiently. accuracy of imputation for snps with low maf was consistently higher for fimpute than for impute <dig> in all scenarios. accuracy was also higher than for beagle for 6 k to 50 k and for 50 k to 300 k. for the imputation of rare variants, impute <dig> was always inferior to fimpute and to beagle despite the fact that impute <dig> gave very high overall accuracy for scenarios a and f. impute <dig> would need a much larger reference group to achieve the same level of accuracy as fimpute or beagle. one could potentially try to increase the number of sampled haplotypes for impute <dig>  but this would require increased computing time.figure  <dig> 
rare allele imputation: allelic r <dig> in different maf bins for fimpute, beagle and impute <dig>  there were  <dig> and  <dig> young target individuals for imputation from 3 k/6 k to 50 k and from 50 k to 300 k, respectively. in scenarios a and f, reference groups with different sizes were randomly chosen after excluding parents and grandparents. the reference group in scenarios b and c included only parents and grandparents, in scenarios d and e it included all genotyped males and in scenarios g and h it included all genotyped individuals. pedigree information was considered in scenarios c, e and h and was discarded in scenarios b, c and g.



in scenario b, when only parents and grandparents were allowed in the reference group with no pedigree information, the accuracy of fimpute for rare variants increased considerably. similar to overall allelic r <dig>  the most gain in accuracy was observed for a sparse panel , showing the importance of close relatives or longer haplotypes for imputation of sparse panels. under scenario b, allelic r <dig> of rare variants from impute <dig> and beagle also increased but they did not reach the level obtained by fimpute. however, impute <dig> exploited the close relationships better than beagle did. when, in addition to the use of parents and grandparents in the reference population, pedigree information was used for imputation , fimpute reached very high accuracy  for rare alleles. when the reference group consisted of all males, including sires and grandsires , rare variants were imputed with high accuracy from 6 k to 50 k. the accuracy of rare variant imputation from 3 k to 50 k was moderate, but still higher than in scenario a with  <dig>  reference individuals.

for imputation from 50 k to 300 k, adding genotyped parents and grandparents into the reference group with or without pedigree information  did not result in a substantial gain in accuracy of imputation of rare alleles. this is because with a high density panel, shared haplotypes between distant relatives can be found more easily and accurately. therefore, for imputation of high density panels, as long as the reference group is large enough and moderately related to the target group, immediate relatives play much less of a role in imputation.

computational performance
figure 
 <dig> illustrates the cpu time for imputation of chromosome  <dig> for each of the three methods. chromosome  <dig> has an average length for an autosome . fimpute was considerably faster than the two other methods for all scenarios. for example, for  <dig>  target and  <dig>  reference individuals and for imputation from 6 k to 50 k, fimpute took 3 minutes to completion while beagle took more than 15 hours and impute <dig> more than 12 hours. computing time of all three methods increased as the reference size increased. for fimpute and beagle, computing time increased linearly with increasing reference size, , but the increase was more rapid for impute <dig>  however, while fimpute and impute <dig> became slower with denser panels, beagle became faster as the density of the ldp increased.figure  <dig> 
cpu time for beagle, impute <dig> and fimpute over different reference sizes. no pedigree information was used and genotyped parents and grandparents were excluded.



with rapid advances in cpu technologies, multi-core cpus are becoming standard. parallel processing on a multi-core system can make the imputation process substantially faster. existing imputation software  could be modified to take full advantage of multi-core processing. the current version of fimpute is able to parallelize chromosomes on multi-core systems.

discussion
a new method for genotype imputation was presented in this paper. the method is deterministic, and essentially searches for long to short haplotypes, which represent close to far relationships, respectively. pedigree information is taken into account if known. the method makes no specific assumption about the degree of relationship between individuals. similar to the long-range phasing algorithm
 <cit> , the new method initially identifies long shared chromosomal segments. however, the method is fundamentally different from that of kong et al.
 <cit> , because it is not iterative, does not create surrogate family members, works with haplotypes instead of genotypes, and searches for short shared haplotypes as well as long ones. one key task in the new method is finding the beginning and the end of shared haplotypes between individuals. to do so, a chromosome is swept with sliding windows of different sizes starting with a long window and gradually shrinking it. sliding windows are overlapped in order to facilitate the search for the beginning and end of shared haplotypes. the imputation accuracy of the new method was very high despite the fact that no posterior distribution is sampled. this was primarily due to the availability of high density panels with high genotype quality, which together allow for accurate haplotype matching. the current genotyping technologies such as illumina infinium are very accurate, with a reproducibility greater than  <dig> %
 <cit> .

the existence of family information, especially knowledge of the sire and dam, is very important for low density phasing, shown here for imputation from 3 k to 50 k. as expected, imputation from denser snp panels leads to higher accuracy because the osw approach can find shorter haplotypes from distant relatives with higher precision. as a result, it is less dependent on the availability of close family information. for imputation from 50 k to 300 k, there is a slight decrease in allelic r <dig> when the pedigree information is used  compared to a situation with no pedigree information . this decrease can be attributed to pedigree errors for ungenotyped animals. when the pedigree is not traced for ungenotyped animals, the level of imputation accuracy is the same for scenarios g and h. with a dense marker panel, family phasing and imputation do not provide much gain over the osw approach alone. for imputation from 50 k to 300 k, having close relatives in the reference group could lead to a higher gain in imputation accuracy than that observed in scenario g, when the reference and target groups are distantly related, as might occur in the study of some human populations. in all cases, family information remains important for the correction of genotyping errors.

a software program, fimpute, was developed based on this new method, and the results compared to two well established imputation methods in human genetics, beagle and impute <dig>  fimpute was not compared to other methods since other studies have already shown the superiority of fimpute, beagle and impute2
 <cit> . beagle and impute <dig> assume that individuals are unrelated. they model haplotype frequency and use the hidden markov model to calculate a posterior distribution. the relationship between reference and target groups significantly influences phasing and imputation performance
 <cit> . results in this paper show that the osw approach is able to exploit close relationships more efficiently than beagle and impute <dig> in all scenarios, especially when the ldp was the sparsest . this is because fimpute starts with highly accurate haplotype matches, corresponding to the long haplotypes of close relatives. the first window covers the whole genome so only parent-progeny matches are found. impute <dig> was superior to beagle in this regard, likely due to the selection of surrogate family members, which carry long shared haplotypes, for haplotype sampling
 <cit> .

for imputation from 3 k to 50 k, imputation accuracy was moderate. however, the size of the reference group was more important. in contrast to population model-based methods, fimpute can handle a very large reference size. therefore, an additional scenario with  <dig>  reference individuals  and no pedigree information was considered. the allelic r <dig> from fimpute was  <dig>  for  <dig> autosomes and the required computation time was 53 minutes for chromosome  <dig>  handling such large reference groups is not possible within a reasonable time limit for beagle and impute <dig>  therefore a comparison was not attempted.

one of the most challenging tasks is the imputation of rare variants. accurate imputation of snp with rare alleles  is important especially when the imputed genotypes are to be used in association studies. fimpute imputes rare alleles with high accuracy because it is efficient at finding the long haplotype matches on which rare alleles are most likely located
 <cit> . impute <dig> and beagle impute rare variants with lower accuracy, except for population imputation from 3 k to 50 k with beagle. in an independent study, fimpute had higher allelic r <dig> for rare variants than beagle and impute2
 <cit> . in our study, except for very small reference groups, beagle performed better than did impute <dig> for rare variants. this finding was in contrast with that of howie et al.
 <cit> .the difference might be due to: 1) improvements in beagle's methodology since  <dig>  2) different population structures, 3) different snp density and 4) the fact that impute <dig> restricts phasing and imputation updates to  <dig> template haplotypes , which could reduce sampling space if haplotype diversity is high. on the other hand, impute <dig> tends to impute common variants with slightly better accuracy than beagle and fimpute.comparing scenarios a, b, c, d and e against each other  suggests that the genotypes of both parents are very helpful for obtaining high imputation accuracy, especially for rare variants, and that the direct use of pedigree information is beneficial. the gain in accuracy of rare variants was more pronounced with sparser panels. in livestock populations, only elite dams are genotyped with a hdp, and most other dams and young females are genotyped with a ldp, for economic reasons. to investigate the benefit of obtaining low density genotypes on dams versus not genotyping them, two additional scenarios similar to scenario c were considered, where all the dams and grand-dams were either ungenotyped or genotyped with the 3 k panel, and where the reference group included only  <dig> sires and grandsires. despite the small reference group size, overall allelic r <dig> for these two scenarios were  <dig>  and  <dig> , showing the importance of genotyping dams with a ldp to increase accuracy in this situation. however, the accuracy of imputation of snp with rare alleles was low for both scenarios, mainly due to the small reference size. for example, for the snp group with maf between  <dig>  and  <dig> , allelic r <dig> was  <dig>  with ungenotyped dams and  <dig>  with 3 k dams. the gain in accuracy of snp with rare alleles  ranged from  <dig>  to  <dig> . therefore, when the ldp is sparse, it is important to include dams with low density genotypes in the target group.

in dairy cattle selection schemes, selection intensity is high and usually only a few top sires are used to produce the next generation. this intense selection over the past decades has resulted in a lower effective population size and consequently in a high level of ld in dairy cattle breeds
 <cit> . fimpute is well suited to such situations, because it assumes that individuals are related and exploits relatives’ information from the closest to the farthest. the presented method has not been tested on human population, where the effective population size is larger and reference individuals are usually genetically more distant from the target group. a separate study is needed to assess the performance of fimpute on human data.

another notable feature of fimpute is low computational requirements. current routine imputation in dairy cattle in north america includes close to  <dig>  animals with  <dig> different ldps and a very large reference size of close to  <dig>  parents genotyped with 50 k. these numbers are expected to grow fairly rapidly over time. beagle or impute <dig> cannot handle this situation in a reasonable time frame, while fimpute can do it in less than 3 hours. an alternative combined family and population imputation method, which can quickly perform large-scale imputation, is findhap
 <cit> . however, it was shown that, compared to fimpute, findhap yields lower imputation accuracy when close relatives are not genotyped with hdp
 <cit> . another computationally fast method for large-scale imputation is pedimpute
 <cit> . however, the underlying methodology in pedimpute is similar to findhap
 <cit> , so they can be seen as one method with different implementations. pre-phasing has been suggested to speed up the imputation process
 <cit> . to this end, haplotypes are constructed once and stored so they can be used for subsequent imputations. while this strategy might work for human genomic studies due to denser snp panels and sparser relationships between individuals, it is not well suited to livestock applications where ldps are sparse and the genotypes of parents of young animals are continually added to the reference group. in such a case, the use of pre-phased haplotypes will not lead to optimal imputation accuracy for the target group. generally, pre-phasing can only be effectively implemented in situations where individuals newly genotyped with the hdp are not closely related to the target individuals. fimpute has the capability to use pre-constructed haplotypes. however, for livestock populations, the use of pre-phased haplotypes for imputation is only recommended when the ldp has a high density. even then, in livestock species, reducing the reference population to a group of animals that have high genomic relationships with the target individuals might be a better strategy than using pre-constructed haplotypes, and is an approach that warrants further investigation.

CONCLUSIONS
in this study an accurate and fast imputation method was presented. the method is based on the concept that close relatives share long haplotypes, while distant relatives share short haplotypes. because there are more markers on longer haplotypes, accuracy of imputation from long haplotypes is higher compared to short haplotypes. therefore, to achieve high accuracy, imputation is carried out using overlapping sliding windows starting with long haplotypes and moving towards short haoplotypes. the results indicated that the presented method is competitive with existing well-established imputation methods in terms of overall accuracy and yet it is computationally very efficient and can handle very large data sets, which are encountered in livestock species.

