BACKGROUND
the major histocompatibility complex  is a multigene family responsible for the adaptive immune response in vertebrate hosts  <cit>  and has become the most preferred marker to study patterns of adaptive genetic variation related to health issues and life history decisions  <cit> . a hallmark of mhc genes is the high level of polymorphism observed in most natural populations caused by positive selection, gene duplication, recombination and gene conversion  <cit> . the variability in the mhc is represented by the number of alleles present both at the individual and population level, the excess of heterozygosity, the sequence divergence between alleles, as well as the number of locus duplications  <cit> . the number of mhc genes can differ greatly within and between species, especially in the classical mhc genes, such as class i and class ii loci, probably due to their functional importance in pathogen recognition  <cit> .

the correct assessment of the individual allelic diversity pattern and the underlying structural sequence variation is the basic requirement to understand the functional importance of mhc variability  <cit> . multilocus mhc genes, however, pose great methodological challenges as inter-locus sequence similarity usually prevents the development of locus-specific primers. thus, simultaneous amplification and genotyping of multilocus amplification products is often necessary e.g.  <cit> .

until recently, mhc genotyping was mainly done by cloning/sanger sequencing or in species with low copy numbers by dna-based methods using a gel matrix for allele separation, such as single strand conformation polymorphism , denaturing gradient gel electrophoresis  or reference strand-mediated conformational analysis  combined with pcr reamplification of the separated bands  and sanger sequencing. pcr amplification of multi-allelic templates and molecular cloning, however, have the disadvantage of a large error rate due to the formation of chimeras, i.e. amplicons that contain sequence motifs from two or more different alleles, and the formation of heteroduplexes, which become mosaic sequences through the dna mismatch repair system during cloning  <cit> . as a consequence, gold standard rules to ascertain the assessment of correct levels of individual diversity have been progressively developed. these include simple modifications of pcr conditions, use of replicates, i.e. several independent pcr amplifications per individual, and sequencing of a large number of clones to reach allele saturation  <cit> .

with the advent of next-generation sequencing  technologies, such as  <dig> gs flx titanium pyrosequencing , it becomes now feasible to infer individual mhc allelic diversity with reasonable time as well as cost balance for larger sample sizes. the new approach has recently been applied to different non-model bird and mammal species with high copy number variation  <cit> . however, artefacts are still expected to be frequent. first of all, the error rate of  <dig> is not negligible, especially if the target sequence contains homopolymers  <cit> , which can lead to repetitive errors. moreover, since the sequencing of the targeted loci is still based on pcr amplification, some of the errors will be similar to those found in the traditional cloning/sanger sequencing and can originate during the first target-specific pcr or the  <dig> sequencing procedures due to polymerase nucleotide misincorporation, chimera formation, or both. in particular, artefacts originating early in the process may be amplified across pcr cycles and therefore sequenced in multiple copies, which makes them difficult to identify. chimeras may also be present in multiple copies, as they could be formed independently many times from the same sources during pcr cycles and resemble true alleles originating in vivo through recombination  <cit> .

unnoticed artefacts can lead to overestimation of individual allele numbers and overall diversity, crucial parameters for subsequent analyses on the functional importance of mhc diversity and the underlying selection processes. even though including replicates in the  <dig> study design has been acknowledged as the most important source for detecting analytical errors, the percentage of implemented replicates in previous studies is null or rather low e.g.  <cit> . gold standard rules are still in the developmental process for ngs data. therefore, a rigorous  <dig> quality control is essential and strict approaches for data validation and allele calling are required to distinguish true alleles from artefacts  <cit> .

recently published studies e.g.  <cit>  using  <dig> pyrosequencing data followed and modified the quality control and data validation protocols for mhc genotyping developed by babik et al.  <cit> , galan et al.  <cit>  and zagalska-neubauer et al.  <cit> . babik et al.  <cit>  validated variants on the basis of their frequency within individuals and considered variants with an observed frequency lower than a case-specific threshold as artefacts. they also validated variants based on their dissimilarity with the four most commonly found variants in a given sample and considered more distinct variants as more likely to be true alleles. their approach paid no attention to the chimera problem, which are very dissimilar to both parent variants and might occur at a non-negligible frequency within individuals  <cit> . galan et al.  <cit>  developed a probabilistic model for determining the read coverage threshold t <dig>  for validating individual genotypes at a given confidence level. furthermore, galan et al.  <cit>  used a second threshold t <dig>  for the minimum coverage required to define a variant as a true allele. galan’s approach also considered the chimera problem and these artefacts were discarded after sequence alignment and blast procedures. zagalska-neubauer et al.  <cit>  procedures included t <dig> as described in galan et al.  <cit> , but did not establish a second threshold for separating true alleles from artefacts. instead, variants were accepted if they were present in at least two amplicons with a minimum of three reads  and were further checked for the possibility of representing artificial chimeras. overall, the three analytical methods described above have several differences in their allele calling approaches but share at least two general assumptions: artificial sequences should be less frequent than true alleles; and artefacts should have their sources in the true alleles . they also mentioned that primers might have different specificity to different variants, but their analyses did not take differences in pcr amplification efficiency into account, i.e. differences in the probability that an allele is amplified due to primer mismatches. ignoring differences in allele amplification efficiencies might have a significant effect on the read coverage required for reliable genotyping that is crucial for all subsequent downstream analyses and might cause an allelic dropout. allelic dropout, i.e. alleles that are not detected in all individuals that biologically possess these alleles, might cause an artificial increase in the homozygosity values. wrong genotypes and inflated homozygosities can bias the analysis of selection mechanisms in host-pathogen interactions and life history decisions such as mate choice, phenotype-genotype associations, recombination level, intra and inter-population differentiation, and associated conservation management decisions e.g.  <cit> .

here, we used  <dig> gs flx titanium pyrosequencing data from a wild rodent with high copy number variation in the mhc class ii drb locus to develop an allele calling workflow that can be transferred to any other non-model organism. furthermore, we compared the results obtained by high-throughput pyrosequencing with the standard cloning/sanger sequencing in all of our samples. our workflow builds up on previous data processing and validation procedures  <cit> , but has been considerably improved to identify mismatches occurring during the first pcr, the presence of chimeras, and the possibility of allelic dropout. it requires two amplicon replicates for all individuals, which allows the beginning of the classification procedure to be performed for each individual independently. our approach presents two major differences to the three mentioned previous studies  <cit> . first, our method evaluates and classifies independently each single variant as either allele or artefact. moreover, even though we also assume that artefacts are in general less frequent than true alleles, we do not rely on an arbitrary threshold to separate alleles from artefacts, in contrast to babik et al.  <cit>  and galan et al.  <cit> . unlike zagalska-neubauer et al.  <cit> , we also do not make the strong assumption that identical variants should have one single classification. the second major difference to previous approaches is our a-posteriori analysis. we studied how differential allele amplification efficiencies influence the confidence level of genotypes and proposed, accordingly, a new way of estimating the minimum number of sequences per individual required for reliable genotyping. moreover, we developed a method to assess the confidence level of genotyping a-posteriori per genotype, which helps to decide which alleles and individuals should be included in any further downstream analyses.

RESULTS
analysis of putative alleles and artefacts within the  <dig> dataset
we included all  <dig> individuals subjected to cloning/sanger sequencing in duplicates  in one region  of a  <dig> flx titanium picotiter plate. all  <dig> amplicons were barcoded . all terms used to describe the subsequent results are outlined in table  <dig>  we obtained  <dig>  sequence reads passing the filters of the gs run processor .  <dig>  reads had the correct length with recognizable f-and r-mids, from which read numbers per amplicon ranged from  <dig> to  <dig>  and from  <dig> to  <dig> per individual . a total of  <dig>   reads passed the initial filtering steps by showing the expected read length, complete primer sequences, high quality and no frameshifts .

we obtained reliable data for  <dig> out of the  <dig> individuals with  <dig> sequencing. incongruencies between the two intra-individual amplicon replicates were detected for three individuals, probably due to either dna cross-contamination or unnoticed exchange of barcodes before the first amplification. a fourth individual presented too few reads for one of the amplicons , even though we had targeted a very high number of reads per amplicon . we removed these four individuals from subsequent analysis. for the remaining  <dig> individuals the number of reads after applying our initial data filtering  had an average per amplicon of 768 ±  <dig>  ranging from  <dig> to  <dig> reads per amplicon and from  <dig> to  <dig> per individual.

the subsequent workflow  allowed us to distinguish most of the filtered reads  into ‘putative artefacts’  or ‘putative alleles’ . the remaining  <dig> reads were marked as ‘unclassified variants’, as they did not fulfil all assumptions to be called a ‘putative allele’ but could not be classified as ‘putative artefacts’. we checked the classification of each ‘unclassified variant’ among amplicons and detected three variants classified in at least one amplicon as a ‘putative allele’, but that were more often defined as ‘unclassified variant’ because of either lower frequency compared to ‘putative artefacts’ or absence in one individual’s amplicon replicate. the frequency inconsistencies of the latter variants suggest lower amplification efficiency when compared to other alleles. the presence of all three variants could be confirmed by sanger sequencing after designing new allele-specific primers. we accepted those three variants as true alleles, but labelled them as ‘putative low efficiency alleles’. those three alleles corresponded to two additional amino acid sequences . we found a total of  <dig> unique nucleotide true mhc variants, which translated into  <dig> putative mhc alleles on the amino acid level . the ‘putative alleles’ were called mhc alleles for simplicity even though it was not possible to assign them to a particular locus. the alleles were denominated as desu-drb*x, where x corresponds to an allele number between  <dig> and  <dig>  according to the nomenclature . without ‘putative low efficiency alleles’ between two and nine  alleles were detected per individual, suggesting at least  <dig> copies of drb in delomys sublineatus. if the ‘putative low efficiency alleles’ are taken into account, the range of alleles detected by  <dig> pyrosequencing increases to 3- <dig> per individual .

the variant frequencies within each amplicon  were analysed based on their classification categories of figure  <dig>  figure  <dig> shows the prevalence of artefacts over alleles in the total number of clusters . although we confirmed only between 2- <dig>  alleles per individual , the number of variants varied between  <dig> and  <dig>  per amplicon. the intra-amplicon classification for ‘putative artefacts’ was clearly dominated by 'chimeras'  followed by ‘1-2 bp diff'  and ' > 2 bp diff’  . the most frequent variant classified as ‘putative artefact’ represented  <dig> % of an amplicon and the least frequent variant among the ‘putative alleles’ represented only  <dig> % of the total amount of reads within an amplicon .

comparison of individual mhc variability detected by  <dig> pyrosequencing to cloning/sanger sequencing
in the  <dig> individuals investigated by both genotyping approaches, we detected  <dig> mhc alleles on the nucleotide level by conventional cloning/sanger sequencing which could be considered as true mhc alleles according to the widely accepted standards in the literature. they corresponded to  <dig> unique amino acid sequences . the average number of alleles per individual was  <dig>  ±  <dig> , and ranged from two to eight, corresponding to at least four drb loci.

all alleles detected by cloning/sanger sequencing were also detected by  <dig> pyrosequencing  and showed a similar sequence variability pattern between the two methodologies, both at the nucleotide and amino acid levels . on the other hand, the ngs technology identified a further  <dig> alleles, and extended the genotypes of  <dig> out of the  <dig> individuals when compared to cloning results . in addition, on the intra-individual level,  <dig> results indicate a significantly higher number of alleles than conventional cloning/sanger sequencing , even though the number of alleles obtained by  <dig> pyrosequencing was significantly correlated to the ones obtained by cloning/sanger sequencing .

allele amplification efficiencies
we used a maximum likelihood approach to estimate the amplification efficiency of each allele  and found that there is a substantial variation in the amplification efficiency among alleles . the lowest amplification efficiency was reached for the allele desu-drb* <dig>  which presented an amplification efficiency of  <dig> , i.e. more than five times lower than the allele desu-drb* <dig> used as a reference  . maximum amplification efficiency was reached for the allele desu-drb* <dig>  which with an efficiency of  <dig>  is more than  <dig> times more efficient than desu-drb* <dig>  no other allele presented an amplification efficiency close or equal to two, suggesting that desu-drb* <dig> was the only one corresponding to either a duplicated allele in different loci or a homozygous locus. this allele was present in four individuals always as the most frequent one  , and the ratio in frequency compared to the second most frequent cluster  ranged in average from  <dig>  to  <dig>  fold for these individuals, reinforcing the hypothesis that this allele is always present in duplicate. even when omitting desu-drb* <dig>  the span in efficiency between alleles represented an 8-fold increase between the least and the most efficient alleles.

effect of variation in amplification efficiency on threshold t1
the threshold t <dig> suggested by galan et al.  <cit>   aims to estimate the minimum number of reads necessary to obtain a reliable genotyping. since galan et al.  <cit>  assumed that all alleles have the same amplification efficiency, we studied how t <dig> would be affected when taking variation in amplification efficiencies into account. to do so, we first developed a simulation procedure  less computationally intensive but still highly comparable to t1galan negmult. t1galan simul estimations and t1galan negmult differed by less than one read on average and the biggest departure observed was three reads in the case where the presence of nine alleles was considered, which represents a relative error of only 3% . the gain in computing time was substantial. for example, our simulation approach allowed us to obtain an accurate estimate of t1galan simul for the case of nine alleles in less than three minutes using the easy but slow programming language r, while the efficient implementation programmed by galan et al.  <cit>  in the much faster language c++ requires several hours to provide a similar value.

the threshold t <dig> defined as the minimum number of sequences per individual required for reliable genotyping was computed by galan et al.  <cit>  using a negative multinomial distribution . we approximated the threshold by a much less computationally intensive simulation approach . t1galan negmult und t1galan simul do not take differences in allele amplification efficiencies into account. we used a simulation approach to investigate the effect of variation in amplification efficiency between alleles on the minimum number of reads required to achieve a reliable genotyping . assuming that we oversampled each amplicon, we estimated what would have been the minimum number of reads that would have given us the same genotypes as obtained with our  <dig> data for the two amplicon replicates per individual by resampling .

the new t <dig> values obtained assuming different amplification efficiencies  showed that taking variation in amplification efficiency into account leads to an increase of t <dig> by  <dig>  to  <dig>  fold  in order to maintain the same confidence level of genotyping. the highest sensitivity to the assumption of equal amplification efficiency concerned the genotype of individual go <dig>  which consists of five alleles: the t <dig> value shifts from  <dig> to  <dig> when galan’s assumption of equal amplification efficiency was relaxed. interestingly, this genotype includes the allele desu-drb* <dig>  which is the one with the lowest estimated amplification efficiency .

subsequently, we further relaxed the assumption that amplification efficiency is fixed for each allele, by allowing each allele to have different amplification efficiencies in any given amplicon. under these circumstances, t <dig> values , were between  <dig>  and  <dig>  fold  higher than t1galan simul and between  <dig>  and  <dig>  fold  higher than t1simul varampleff . t1resampled increased with the number of alleles observed, as predicted by galan et al. for t1galan negmult. nonetheless, knowing only the number of alleles seems not to be sufficient to predict t <dig> accurately . figure 6b shows however that with the knowledge of the lowest observed read frequency present in a genotype, one could almost predict t1resampled to perfection . interestingly, the lowest read frequency can be predicted accurately  from the ratio between the lowest allele amplification efficiency and the sum of amplification efficiency across all alleles constituting one genotype. thus, we found that in our system t1resampled values can be predicted accurately from the lowest efficiency within a genotype .

therefore, we performed simulations to estimate t <dig> according to different values of the minimum amplification efficiency across all alleles . additional file 1: figures s <dig> and s <dig> show that t1min amp eff increases linearly with the number of alleles for a given value of minimum amplification efficiency considered. the results hold for t1galan negmult , as well as for any other value of minimum efficiency.

discussion
although benefits of using ngs technologies in sequencing multilocus and highly variable regions such as the mhc are undeniable, these novel approaches are not exempt from biases and errors. while the recent literature puts emphasis on mistakes that can occur during the sequencing process, it is important to realize that long lasting limitations concerning genotyping can also occur because, similarly to the traditional cloning/sanger sequencing procedure, ngs genotyping approaches are still based on amplification of the targeted locus via pcr. we showed that the diversity of artefacts emerging during the pcr step can largely outnumber variants corresponding to true alleles , and that the total number of sequence reads originating from artefacts can be higher than for true alleles. in addition, we demonstrated that pcr may be also responsible for allelic dropout caused by differential amplification efficiency between alleles. these two pcr-related side effects can lead to important mistakes at the level of allele calling and/or genotyping and therefore significantly alter downstream analyses relying on heterozygosity, allelic diversity, and genotype composition. the limitations caused both by pcr biases and errors and sequencing imply two main new challenges for ngs-based analyses: 1) the separation of true alleles from artefacts and 2) the correct evaluation of the reliability of genotypes obtained after allele calling, which should in addition to artefacts consider the possibility of allelic dropout. the methodology introduced in this study was specifically designed to address these problems.

separation of true alleles from artefacts
as shown in other mhc genotyping studies using  <dig> pyrosequencing e.g.  <cit> , many of the variants obtained originate from artefacts. artefacts may be produced by  <dig> pyrosequencing methodology during four different stages: the initial specific pcr, the empcr, the sequencing reaction and signal processing. although the use of an initial data quality check and reads filtering step  eliminates a great amount of them, a potentially large number of artefacts is still expected to remain, including many present in multiple copies within amplicons .

our workflow was specifically designed to deal with the different kinds of artefacts potentially present. homopolymer-associated errors along with other causes of insertion and deletion errors  are the most common errors associated with  <dig> pyrosequencing base calling . this type of error is identified and removed during our initial filtering steps, which eliminate reads with shifts in the reading frame. chimeras caused by pcr artefact formation are the most frequent kind of artefact among the filtered reads and may be hard to detect because they usually resemble true recombining alleles  <cit> . however, we eliminated them by assuming that artefactual chimeras will be always present together with their sources  and in lower frequency. the basis for such assumption lies on the fact that chimera formation is thought to occur mainly on the last cycles of a pcr programme and would therefore be amplified less often than true alleles  <cit> . artefacts can also originate from mismatches caused by polymerase errors during empcr, which are eliminated to a large extent by deleting all singletons within amplicons. this kind of artefact usually corresponds to singletons because the probability that the same mismatch occurs independently in different reads should be extremely low  <cit> , especially before position 400 bp of a 454-generated sequence  <cit> . importantly, our workflow also allows the identification of mismatches caused by polymerase errors produced during library preparation  because individual amplicons were done in independent duplicates. while the probability of the same error occurring more than once during the initial specific pcr remains very low, implemented errors can be highly amplified when they occur in early pcr cycles  <cit>  and the same amplified mistake can potentially be observed in multiple copies per amplicon. therefore only the comparison of amplicon replicates allows the detection of polymerase errors.

the comparison of variants classification by our workflow to the ones obtained with alternative methods demonstrates that our method increases both the power  and the robustness  of allelic assignments, as exemplified below. first, if we used the threshold t <dig> proposed by galan et al.  <cit>  to separate putative alleles from putative artefacts, all the different putative alleles defined by our allele and artefact identification workflow would still be recognized, but not for all individuals that carry them . precisely, we would use a t <dig> of  <dig> %, which corresponds to the upper end of the artefact cluster frequency distribution within amplicons . the use of t <dig> would change the genotype composition for  <dig> individuals, with a total of  <dig> variants that would fail to be called ‘putative alleles’. in addition, ‘low efficiency putative alleles’ would be accepted for only two out of the  <dig> individuals we detected carrying this kind of allele.

second, using the procedure suggested by zagalska-neubauer et al.  <cit> , who accepted variants if they were present in at least two amplicons with a minimum of three reads , we would recognize all ‘putative alleles’ as well as our ‘low frequency putative alleles’ for all individuals, but their method would lead to erroneously consider as new ‘putative alleles’ two ‘putative artefacts’ and three ‘unclassified variants’ according to our classification . in addition, their method would fail to distinguish two ‘putative artefacts’ and two ‘unclassified variants’ that have identical sequences to true alleles in other individuals. we trust our classification because those specific variants were found either in low frequencies and/or were present in only one of an individual replicates. finally, if we used a single amplicon for each individual like in their original approach, we would have immediately discarded  <dig> alleles that we detected in a single individual only.

overall, distinguishing between true alleles and artefacts has been possible because our workflow combines several key features: first, using amplicon replicates for each individual facilitates variant classification and helps to recognize mistakes during laboratory procedures, which are more likely to occur with increasing numbers of multiplexed samples. moreover, amplicon replicates help with the identification of alleles that are inconsistently amplified  by a given primer pair. second, our workflow does not rely on pre-defined thresholds based on intra-amplicon variant frequencies for identification of true alleles , which could create a bias in allele calling by not detecting alleles with low or inconsistent intra-amplicon frequencies. third, our workflow allows the identification of alleles with low amplification efficiency, indicating whether primers should be re-designed in order to cover these alleles/loci. finally, our reads filtering pathway  and our allele and artefact identification workflow  can be adjusted to different needs in forthcoming mhc studies .

comparison of individual mhc variability detected by  <dig> with cloning/sanger sequencing
ngs technologies are likely to replace cloning and sanger sequencing for mhc genotyping to a great extent in the near future. nevertheless, traditional mhc genotyping approaches may remain an alternative to consider when a limited amount of samples is to be genotyped, as ngs is still expensive and many research groups do not have direct access to these technologies. few studies compared the performance of one of the traditional methods with the outcome using a  <dig> approach using identical individuals  <cit> . however, this knowledge is essential to calibrate past and future findings. our study has shown that results of  <dig> pyrosequencing and traditional cloning/sanger sequencing are highly comparable at the qualitative level, but the ngs allowed us to detect a higher number of ‘putative alleles’. additional comparative studies will shed light on whether this discrepancy between ngs and traditional methods is general or species-specific, and whether it is more pronounced in species with high copy numbers or not. we believe the higher allele detection probability of ngs builds on the higher sequencing depth that users are able to choose, rather than a real limitation of the traditional method. consequently, cloning/sanger sequencing could be used to supplement ngs studies, as long as the same t <dig> and allele calling workflow are used for both methods.

importance of allelic dropout: amplification efficiencies and confidence level of genotyping
allelic dropout is an important source of bias and errors in allele calling or genotyping. the analysis of the relationship between allele amplification efficiency and the confidence level of genotyping  suggests that allelic dropout is a consequence of the low efficiency of certain alleles. our workflow allowed us to identify three alleles  very likely to undergo allelic dropout. indeed, these alleles did not show a consistent frequency among the amplicons in all individuals that seem to carry these variants, were generally associated with low number of reads, and for a number of individuals these alleles were completely absent in one of the amplicon replicates.

we showed that low amplification efficiency does not only concern few alleles, but that many have amplification efficiencies lower than optimal. by assuming all alleles to have the same efficiency, the effective genotyping coverage obtained when following galan et al.’s t <dig> recommendation becomes insufficient. although we targeted an unusually high coverage and obtained numbers of reads much higher than galan et al.’s recommendations, one ‘putative allele’ was still likely to be involved in allelic dropout. this allele was easily identified using our resampling-based method . as we showed that the confidence level of genotyping was mainly constrained by the lowest read frequency among the alleles constituting the genotype of an individual, the problematic allele was logically the allele with the lowest amplification efficiency among all ‘putative alleles’ . consequently, this allele should not be included in the genotypes for downstream analysis because it is likely to suffer from allelic dropout in some individuals. capturing the second least efficient allele  instead requires a number of reads that we obtained for all but two amplicon replicates. nonetheless, these two problematic amplicons were associated with replicates that did reach the adequate t <dig> threshold value and did not include allele desu-drb* <dig>  therefore eliminating chances of allelic dropout. consequently, this second least efficient allele was reliably covered and could be included in further analysis using these individuals’ genotypes, as well as all alleles with a greater amplification efficiency value.

overall, while our methodology successfully revealed instances of allelic dropout, differences in the expected number of loci found among individuals , suggests that other instances of allelic dropout have remained unnoticed. therefore, it is likely that other alleles were completely missed during the first amplification unless this is explained by a variable number of mhc drb loci within the same population  <cit> .

a guideline to plan future experiments can be derived from the expected maximum number of alleles and the minimum amplification efficiency one could accept . from these two numbers, information provided by additional file 1: figures s <dig> and s <dig> and additional file 2: tables s <dig> and s <dig> allow one to directly obtain the number of reads per amplicon required to reach  <dig> % confidence level of genotyping. note that because of the linearity of the relationship between t <dig> and the number of alleles , one can derive graphically guidelines for higher number of alleles without any computational work. importantly, the required number of reads per amplicon suggested by this method only provides guidance, but does not replace the coverage analysis based on resampling that has to be performed a-posteriori. this is because during the a-priori planning of a ngs project it is not possible to know the amplification efficiency across all alleles and we therefore assumed amplification efficiency to be optimal for all but the least efficient allele. strong departure from this assumption may happen in certain system. besides, the number of reads estimated to reach a certain confidence level of genotyping refers to reads that represent ‘putative alleles’ at the end of our workflow . in this study, we originally obtained  <dig>  high quality reads from 1/8th of a  <dig> picotiter plate, and our final numbers after the initial filtering steps and having excluded artefacts included  <dig>  reads which represented alleles, i.e. around one third of the initial reads. estimating the required sequencing coverage per amplicon a-priori should probably consider similar high percentages of low quality reads and artefacts, or the possibility of increasing the coverage whenever necessary, and the coverage analysis based on resampling has to be performed a-posteriori after collecting the data in any case.

CONCLUSIONS
genotyping studies of multilocus mhc genes using ngs are prone to inaccurate allele-calling caused by both artefacts and unnoticed allelic dropout, especially due to the lack of matured approaches to deal with large amounts of data with an unknown level of complexity. at the same time, the correct assessment of an individual’s mhc constitution is the most fundamental pre-requirement to address the functional importance of mhc allelic diversity in evolutionary ecology, pathogen resistance and conservation. our work, which builds on previous studies such as babik et al.  <cit> , galan et al.  <cit>  and zagalska-neubauer et al.  <cit> , allows an efficient and robust evaluation of the allelic and genotyping coverage associated with a given set of primers. one of the crucial steps in our proposed workflow is the amplification of independent replicates for each individual, which overcomes some flaws from previous approaches, such as the misidentification of artificial sequences as true alleles, and the non-identification of allelic dropout and alleles with amplification deficiencies. another crucial feature of our methodology is the consideration of allelic dropout via the measurement of the allele amplification efficiency. by ignoring variation in allele amplification efficiency, previous methodologies overestimated the confidence level of genotyping. in addition, we showed that amplification efficiencies can be used to estimate the minimum number of reads required for genotyping. allelic dropout cannot be avoided easily but it does not represent a major problem as long as alleles/loci that might be affected by this phenomenon are identified and removed from the downstream analysis whenever appropriate. combining our workflow with the study of the impact of differences in amplification efficiency offers the chance for researchers to evaluate and understand data generated by ngs in great detail, improving confidence over the approach as well as the follow-up analyses and subsequent applications.

