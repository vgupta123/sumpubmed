BACKGROUND
personalised medicine provides patients with treatments that are specific to their genetic profiles. the aim is to offer the safest and most effective therapeutic strategy based on the gene variations of each subject. to that end, it is necessary to interact across a variety of scientific disciplines, such as molecular biology, pathology, radiology and clinical practice. disparate data types from these domains need to be shared and integrated efficiently.

in particular, this is appropriate to oncology, where knowledge about genetic mutations has already led to new therapies. current molecular biology techniques  enable better characterisation of cancer tumours. the vast amounts of data produced coupled with the use of different terms in each discipline - referred to as semantic heterogeneity- make the retrieval and integration of information difficult.

the uk national cancer research institute  and the us national cancer institute  have implemented programmes focusing on building and deploying software infrastructures to manage and analyse data generated from heterogenous data sources. these are the ncri informatics initiative   <cit>  and the cancer biomedical informatics grid®   <cit>  programme. the ncri ii has developed the oncology information exchange  portal, enabling the discovery and searching of biomedical resources. the cabig® programme has developed the cagrid  <cit>  computing infrastructure, and associated tools, supporting a collaborative information network for sharing cancer research data. cagrid deals with syntactic and semantic interoperability of the data resources in a service-oriented model-driven architecture. each data source is represented as an information model  <cit>  in the unified modeling language   <cit> , and it is exposed as a data service. semantic interoperability is achieved by using a metadata registry, which maintains the information models annotated with concepts from a domain ontology, namely the nci thesaurus   <cit> . the data services also expose a common query interface based on the cagrid query language . cql enables to query the data services relying on their individual information models, i.e. the uml models. the query functionality provided in cagrid does not, however, take into account the existing semantic annotations based on ncit. while the domain ontology is used as a global schema for the specification of data sources, the queries are not written in terms of the global schema but rather on the structure of the shared data resources.

in this paper, we provide an analysis of cagrid's support for data integration and its querying capabilities. we extend cagrid with additional services to support ontology-based queries over the cancer research data resources, taking advantage of the existing semantic annotations. the biomedical researchers, as the end-users of our system, can query the distributed data resources using queries based on the domain knowledge . thus, it is not a requirement to know the underlying models as for cql, and the queries are reusable across resources.

our approach assumes that all data sources have a corresponding information model with semantic annotations, where each element in the model  is associated with one or more concepts from a domain ontology. these concepts provide unambiguous meaning to the model's elements and could potentially belong to several ontologies. we assume there are service-oriented interfaces to access to the metadata registry, which stores the models and annotations, and the data sources. while any ontology could be use for the annotations, ncit is the primary ontology in cagrid and all the information models are annotated with it  <cit> . thus, for our implementation we consider ncit exclusively. our evaluation is based on data services from cagrid: we use data schemas and annotations available in the cagrid metadata registry.

our system provides a customised transformation from the annotated information models to an ontological representation using the web ontology language version  <dig>   <cit> . owl is a recommendation from the world wide web consortium . based on the ontological representations of the data resources, we have designed and developed a query reformulation approach that converts concept-based queries into cql, the query language supported by the cagrid infrastructure. this approach is general and could be used to support other target query languages, as the only step dependent on cagrid is the final one. this paper presents significant improvements over our previous work  <cit> . we have extended our earlier work to support federated queries over the cagrid infrastructure, where the selection of join conditions is provided by a semantic analysis of the distributed resources. we present an exhaustive performance evaluation of the query reformulation for single data resources. we also present a graphical user interface: the cancer ontology querying system . conquest offers an ontology-based view of the cagrid data resources, allowing resource-browsing as well as identifying the concepts used therein. it also supports a query wizard to build ontology-based queries, allowing the user selection of the relevant data sources with respect to the concepts used in those queries.

data integration systems
data integration refers to merging data from independent sources and providing access to them through a unified view  <cit> . there exist two common approaches for the integration of data: the data-warehouse approach and the federated database approach  <cit> .

the warehouse approach collates the data from several resources, translates them and combines them into a single repository. queries are executed over the aggregated data, rather than the distributed sources of data. hence, distribution problems are avoided such as network bottlenecks, the unavailability of sources or slow response times, are avoided. moreover, the execution of queries is very efficient and it is possible to apply optimisations over the aggregated data. having the data in a single repository also permits added value in terms of validation and annotation. on the other hand, the data may become stale when the content or structure of data sources change  <cit> . addition of new data sources requires an expensive process of translating its content into the repository  <cit> .

the federated databases approach is composed of a mediator: a run-time component that reformulates queries written in a global-schema  to queries on local schemas for each distributed data source. in contrast to the warehouse approach, federation ensures that the latest version of the data and structures is considered. additionally, new databases can be added easily. the distributed nature of the infrastructure, however, compromises query performance  <cit> .

in the federated approach, there are several ways to represent the mapping between the global schema and the set of local schemas for the data sources  <cit> . each mapping associates a query written over the global schema with a query written over the local schema. these queries could be written in distinct languages. the two main methods are called global-as-view  and local-as-view   <cit> . in gav, each element in the global-schema is associated with a query over a local data source - i.e., each element in the global schema is characterised as a view over the data source. on the other hand, in lav the global-schema is specified independently from the sources and each element of the data source is associated with a query over the global-schema, meaning that the local sources are characterised as a view over the global-schema.

halevy  <cit>  compares the two approaches from the point of view of query processing. in summary, query processing in gav systems is generally based on a simple unfolding strategy, as the mappings identify the sources queries corresponding to elements in the global-schema  <cit> . but for lav systems, query processing is more complex; it is not straightforward to determine how to use the sources to answer a query over the global-schema, as each source maintains only a partial view of the data  <cit> .

cabig® semantic infrastructure
cagrid, the computing middleware in cabig®, is a grid  <cit>  extended to support data modelling and semantics  <cit> . it follows a service-oriented, model-driven architecture, with a number of core services and corresponding application programming interfaces . in this section, we present the cabig® semantic infrastructure as an analogy with the metadata hierarchy in  <cit>  and analyse the infrastructure in terms of its capabilities as a data integration system.

cagrid follows a federated database approach, where each data source is autonomous and its owner is responsible for providing information about the resource. each data source is exposed as a data service, using common interfaces and metadata at increasing levels of abstraction, including syntactic, structural, reference and domain metadata  <cit>  . each data service is an object-oriented virtualisation of the underlying data  <cit> . the data types of the data source are available as extensible markup language  schemas, managed by the global model exchange  service  <cit> . these schemas conform the syntactic metadata. the object-oriented representation of the data source is given as uml models, offering structural metadata about the data source. each uml model is associated with semantic metadata, which indicates the meaning of the objects and associations between them. the semantic annotations come mainly from the ncit ontology  <cit> , which can be accessed via the lexevs api  <cit> . ncit is the primary terminology used in cabig® , but other well-structured ontologies should be suitable for the annotations. the nci enterprise vocabulary services  team reviews and approves suitable terminology for use in cagrid.

the ontology-based annotations relate the domain concepts with the structural information of each data source, and constitute the domain metadata. the cancer data standards repository, or cadsr, is a metadata registry based on the iso/iec  <dig> standard  <cit> . cadsr manages common data elements  and exposes them through the cadsr api. the cdes provide the mappings between the ontology concepts  and the uml models for each available data service . a cde is composed of an object class that relates to a uml class, a property corresponding to a uml attribute, and a value domain corresponding to the data type of the attribute. the lower part of figure  <dig> shows the different levels of metadata available in the cabig® semantic infrastructure. in cadsr, models are annotated with ncit and we consider it as the only domain ontology for our implementation. as a data integration system, cagrid follows a federated approach with local-as-view mappings, where the ncit ontology offers a unified view of the resources. each element of the data source  is related with a query  over the global-schema . in this way, the local sources are characterised as a view over the ontology. as seen before, cdes offer these mappings and are maintained in cadsr.

as mentioned above, the data services expose access to the underlying data with a common interface based on the object-oriented  model of the resource. this common interface also exposes a query processor based on the cagrid or common query language  defined for cagrid. cql is an object-oriented query language reflecting the underlying object model of the data resource while abstracting the physical representation of the data  <cit> . cql allows the definition of one target object, representing the result of the query. additionally, it is possible to add restrictions on associations or attributes for the classes intervening in the query. in this way, cql is a navigational query language: it allows the navigation of the uml model through associations and the specification of conditions over the attributes of the classes traversed during that path navigation.

cagrid also supports basic distributed aggregations and joins of queries over multiple data services by means of the cagrid federated query infrastructure  <cit> . the distributed queries are expressed in the distributed extension of cql, called dcql  <cit> , which is translated into single resource queries in cql. the service responsible for translating dcql queries into cql queries for the specific resources is the federated query processor . both cql and dcql are structural query languages, and require the user to know about the underlying object-oriented models of the resources.

the basic constructs for dcql coincide with those of cql, also permitting the navigation of the uml models through paths of uml associations and the specification of conditions on the uml attributes across the path. in addition, aggregated queries allow the same query to be run over more than one target service and return the combined results. distributed joins, on the other hand, allow the definition of foreign associations. a foreign association element contains a join condition element and a foreign object element. the join condition element describes the logic for associating instances of the enclosing class with instances of the class in the remote data service that is described by the foreign object element.

to sum up, the cagrid infrastructure follows a lav federated approach and maintains rich semantic metadata in cadsr. ncit is the primary ontology in use, offering a unified view of the exposed data sources. however, the querying capabilities are not based in this global schema but on the object-oriented representation.

semantic web/linked data approach for querying and data integration
the semantic web was proposed as the method to solve the problem of semantic heterogeneity in the world wide web  <cit> . the proposal relies on extending the web with a semantic layer that makes data not only human processable but also machine processable  <cit> . this approach allows the sharing and re-use of data on the web, and it is sometimes called the linked data approach  <cit> .

the semantic web methodologies, representation mechanisms and logics are largely based on database theory and practice  <cit> . however, there are important differences between database technologies and the semantic web - for example, databases are closed in nature  and their objects must be uniquely identified, while the semantic web assumes that information is incomplete and it recovers the notion of unique identifiers through unique resource identifiers   <cit> .

the semantic web relies on a hierarchy of languages of increasing level of expressivity  <cit> . the web ontology language  allows for the representation of classes and relations among them, which are organised in graph structures called ontologies. each node represents a concept or class, and links codify logical relationships between the two concepts involved  <cit> .

as discussed above, data integration depends on the mappings between component data schemas, or models, to a common schema. the semantic web supports the use of an ontology to integrate different databases  <cit> . in contrast to data models, ontologies encapsulate generic knowledge about a domain that can be reused across applications  <cit> .

object-based queries
the concept of model-driven architectures   <cit> , which was developed by the object management group   <cit> , is based on platform-independent models and their transformations. the models document business functionality and behaviour of an application and are usually represented in uml. the models decouple the specification from the implementation that realises them, allowing for the independent evolution of the two. the models follow an object-oriented approach to software development, where the objects represent the entities in the system.

when database capabilities are combined with object-based virtualisation of software systems, the result is an object-oriented database management system. these systems offer query languages supporting the retrieval of objects stored in the system. the omg proposed the object query language , which is modelled after sql, as a standard for object-oriented databases. as seen above, the cagrid infrastructure has developed its own object query language , based on the navigation of uml models  <cit> . while object-oriented databases provide powerful data abstractions, they generally lack a formal framework for query processing and query optimisation  <cit> . fegaras and maier  <cit>  proposed the monoid comprehension calculus  as such formal framework. it is a calculus based on monoids and the homomorphisms between them. we use mcc for the query reformulation process described in the methods section.

RESULTS
cql and dcql analysis
a cql query is defined by an xml document, which must comply to a given xml schema  <cit> . the schema indicates that a cql query must specify a 〈target〉 element, which is the data type of the query result. optionally, an 〈attribute〉 element might indicate a predicate over an attribute of the object with a 〈target〉 type and an 〈association〉 may specify a link with a related object. next, we show how a cql query is built recursively presenting it as a context-free grammar, where 〈cqlquery〉 is the start symbol, ϵ is the empty string, 〈xsd:string〉 and 〈xsd:boolean〉 are the non-terminal variables representing the xsd:string and xsd:string data types, respectively. the cql query context-free grammar is:

〈cqlquery〉 → 〈target〉 |

                         〈target〉 〈 querymodifier〉

〈target〉 → 〈cqlobject〉

〈cqlobject〉 → 〈name〉 |

                      〈name〉 〈attribute〉 |

                      〈name〉 〈association〉 |

                      〈name〉 〈group〉

〈attribute〉 → 〈name〉 〈predicate〉 〈value〉

〈group〉 → 〈logicalop〉 〈attribute〉 〈group1〉 |

                 〈logicalop〉 → 〈association〉 〈group1〉

〈group1〉 → 〈attribute〉 〈groupϵ〉 |

                   〈association〉 〈groupeϵ〉 |

                   〈group〉 〈groupeϵ〉

〈groupe〉 → 〈group〉|ϵ

〈name〉 → 〈xsd:string〉

〈rolename〉 → 〈xsd:string〉

〈logicalop〉 → and |or

〈predicate〉 → equal_to |not_equal_to |

                      like |is_null|

                      is_not_null|less_than |

                      less_than_equal_to |

                      greater_than |

                      greater_than_equal_to

〈association〉 → 〈rolename〉 〈cqlobject〉

〈value〉 → 〈xsd:string〉

〈querymodifier〉 → 〈countonly〉 〈distinctattribute〉|

                             〈countonly〉 〈distinctattribute〉 〈attributenames〉

〈countonly〉 → 〈xsd:boolean〉

so, cql traverses the uml class diagram graph, where the 〈target〉 is the initial class, the 〈association〉 conditions allow for path navigation by traversing sequences of consecutive classes and 〈attribute〉 conditions apply locally to individual classes. the terminal symbols 〈group〉 and 〈group1〉 represent the combination of two or more constraints over a particular node in the uml class graph.

now, we present an example from cabio, where the cqlquery encodes the traversal of the path from nucleicacidsequence to protein .

〈cqlquery〉 → 〈target〉

                     → 〈qlobject〉

                     → 〈name〉 〈association〉

                     → 〈name〉 〈rolename〉 〈cqlobject〉

                     → 〈name〉 〈rolename〉 〈name〉 〈association〉

                     → 〈name〉 〈rolename〉 〈name〉 〈rolename〉 〈name〉

                     → nucleicacidsequence genecollection gene proteincollection protein

dcql  <cit>  is an extension of cql to traverse two or more uml class graphs. the graphs are connected by the definition of join conditions, which determine how to associate instances of the enclosing class with instances of the class in the remote data service. dcql specifies the service to which the query is sent to. this is a context-free grammar representing dcql:

〈dcqlquery〉 → 〈targetobject) 〈targetserviceurl1〉

〈targetserviceurl1〉 → 〈targetserviceurl〉 |

                                    〈targetserviceurl〉 〈targetserviceurl1〉

〈targetserviceurl〉 → 〈xsd:string〉

〈targetobject) → 〈dcqlobject〉

〈dcqlobject〉 → 〈name〉

                        〈name〉 〈attribute〉 |

                        〈name〉 〈dcqlassociation〉 |

                        〈name〉 〈foreignassociation〉 |

                        〈name〉 〈dcqlgroup〉 |

〈dcqlassociation〉 → 〈rolename〉 〈dcqlobject〉

〈dcqlgroup〉 → 〈logicalop〉 〈attribute) 〈dcqlgroup1〉 |

                        〈logicalop〉 〈association〉 〈dcqlgroup1〉

〈dcqlgroup1〉 → 〈attribute〉 〈dcqlgroupe〉 |

                          〈association〉 〈dcqlgroupe〉 |

                          〈foreignassociation〉 〈dcqlgroupe〉 |

                          〈dcqlgroup〉 〈dcqlgroupe〉

〈dcqlgroupe〉 → 〈dcqlgroup〉 | ϵ

〈foreignassociation〉 → 〈joincondition〉 〈foreignobject〉 〈targetserviceurl〉

〈joincondition〉 → 〈foreignpredicate〉 〈localattributename〉 〈foreignattributename〉

〈foreignpredicate〉 → equal_to |not_equal_to |

                                  less_than |

                                  less_than_equal_to |

                                  greater_than |

                                  greater_than_equal_to

〈localattributename〉 → 〈xsd:string〉

〈foreignattributename〉 → 〈xsd:string〉

both cql and dcql are declarative, non-procedural languages.

ontology-based queries
we propose to exploit the cabig® semantic infrastructure as a data integration system following the lav approach. this means that the nci thesaurus ontology is considered as the global-schema and queries over the global-schema are reformulated as a set of queries over the data sources  <cit> .

as a consequence, our system extends the cagrid querying functionality, which currently relies on the structure of the underlying data resources, i.e. their uml models. in cagrid, a biomedical researcher interested in retrieving data about, for example, a particular gene of interest needs to explore the uml model of each relevant data service and build a query considering the specific attributes and associations of the class maintaining the gene objects. the queries can be built programmatically or also through the cagrid portal  <cit> , which supports the exploration of the uml models and provides a query builder based on these models. the queries are specific for a data source and cannot be re-used.

on the other hand, users of our system can concentrate on the concepts from the domain, as represented by the ncit ontology on cancer, and build the ontology-based queries which are high-level and descriptive. by a high-level query, we mean a query that can be written without specific details about the structure of the target resource. by a descriptive query, we refer to queries that provide the criteria for the desired data rather than the procedure to find the data. thus, the ontology-based queries can be applicable to any of the underlying data resources, and our system reformulates them according to the specific uml models. the process is semi-automatic, in some cases requiring input from the users to select appropriate paths on the rewriting or join conditions, as will be explained in detail below.

apart from the cancer concepts found in ncit, the queries combine elements from an ontology we have built with metadata on uml models, namely the uml model ontology, and the list ontology  <cit> , used to represent combinations of concepts that annotate elements from the data sources. the uml model ontology contains owl classes to represent uml classes and attributes , owl object properties to represent uml associations and the relationship between a uml class and its attributes  and a data property to represent the values of attributes . the upper part of figure  <dig> shows the ontologies built in our system in order to support ontology-based queries over the cabig® semantic infrastructure.

the navigational characteristics of the target object-query languages  are represented at the ontology level by the hasassociation object property. given two uml classes, they may have a direct uml association, or the association may arise by traversing an association path from the first class to the second one. in order for our system to deal with those paths of associations, without the user requiring knowledge of the specific underlying uml model, we define the hasassociation property as transitive and use reasoning to determine the paths.

in the case of distributed queries, the semantic annotations of the models are leveraged to find the possible join conditions automatically. the join conditions are presented to the user, so that they can select the more biologically-relevant one, depending on the specific query.

use cases
in this section, we present two simple but illustrative use cases, presenting a query for a single resource and a second query that requires the use of two resources to provide a result. the first use case will show how our system exploits the knowledge about the uml semantics. the second use case is based on the query presented in cabig® to demonstrate the federated query capability  <cit> . we will show the steps of our query reformulation process in the methods section, giving examples based on these use cases. more than a thousand genetic mutations of the brca <dig> gene have been identified with increased risk of breast cancer in women . the gene belongs to a class of genes identified as tumour suppressors, i.e. the protein that they produce helps prevent cells from growing and dividing too rapidly or in an uncontrolled way. the brca <dig> gene gives instructions for producing a protein that is directly involved in repairing damaged dna. additionally, the brca <dig> protein interacts with many other proteins, including other tumour suppressors and proteins that regulate cell division.

some mutations on the brca <dig> gene can lead to the production of abnormally short versions of the brca <dig> protein. other mutations may even prevent the protein being produced. other mutations modify single amino acids in the resulting protein, or delete large segments of dna from the brca <dig> gene.

as these mutations alter the normal function of the brca <dig> gene, their accummulatation can provoke uncontrolled cell division and growth, causing a tumour.

taking into account this knowledge about the brca <dig> gene and knowing that its molecular location is at chromosome  <dig>  a biomedical researcher investigating it will be interested in dealing with the results of the following queries:

query 1

find single nucleotide polymorphisms associated with the chromosome whose name is  <dig> 

query 2

find nucleotide sequences associated with the gene whose symbol is bcra <dig> and whose organism's scientific name is homo sapiens.

using our system, these queries can be written using concepts from the nci thesaurus ontology, whose correspondence with the above natural language phrases is straightforward. our graphical user interface provides a query builder facilitating the query construction using concepts from ncit. once these queries are expressed with concepts, the internal representation is as follows :

concept-based query 1

single_nucleotide_polymorphisms and hasassociation some ).

concept-based query 2

nucleotide_sequences and hasassociation some ) and hasassociation some ).

in order to answer these concept-based queries in the cabig® infrastructure, the researcher is able to find out through our interface about these two relevant data services:

• the cancer bioinformatics infrastructure objects   <cit>  data service: a robust resource for accessing molecular annotations from a variety of curated data sources, including cgap, unigene, the cancer gene index  project ands the pathway interaction database ;

• the protein information resource  data service  <cit> : a data resource for genomic and proteomic information, which contains rich and high-quality annotated data on all protein sequences and is supported by the uniprot knowledgebase  and other relevant protein databases.

for the first query, the user chooses a single data resource as target, namely cabio, as it contains data about single nucleotide polymorphisms and chromosomes. figure  <dig> shows a section of the cabio uml model corresponding to a possible path between the snp class, corresponding to the concept single_nucleotide_polymorphism, and the chromosome class, corresponding to the homonym concept. we note that our system is able to reason about the structure of the data resource. then, it automatically infers, based on the data service ontology, that the path between the two classes arises by considering the hierarchy of location classes  and that uml associations  are inherited by the sub-classes. the interpretations of the uml semantics are left to the user in the current cabig® infrastructure. consequently, in cabig® there is the assumption that the user will be highly technologically knowledgeable.

for the second query, the user chooses the two data services as target, cabio and pir, in order to build a distributed query. while cabio has data about nucleotide sequences and genes, pir has information about organisms. figure  <dig> shows sections of the two services' uml models, which refer to the classes annotated with concepts included in the concept-based query. using our system, the researcher is presented with the possible join conditions for the distributed query. a join condition is composed of a pair of uml classes and a pair of uml attributes, corresponding to each of the classes. for the query to make sense, the join condition must contain semantically equivalent  classes and attributes. two uml classes  are semantically equivalent if and only if they are annotated with the same concepts. by using a merged ontology combining the two data service ontologies, our system determines the list of possible join conditions. in this case, the join conditions include the pair of classes  and . each pair of classes are annotated by the same concept, ncit:gene and ncit:protein. in turn, the semantically equivalent attributes for the pairs of classes are:  and . while the gene names  are not unique, as there are several synonyms for each of the existing genes, the protein codes assigned by the uniprot knowledge base are unique. thus, the biomedical researcher selects the protein classes and codes from uniprot as a suitable join condition.

software architecture
the semantic services are:

owl generation service. this service generates ncit modules for each of the available cagrid data services. the metadata is retrieved either from the cadsr service or directly from the individual data service. additionally, this service generates owl ontologies from the information models, i.e. the annotated uml models. the ontologies import the specific ncit ontology module as well as the list ontology and the uml model ontology. the generated ontologies contain concepts and relationships but no data instances .

semantic query service. this service is responsible for rewriting, translating and processing semantic queries at different levels of abstraction, from ontology-based queries to a chosen target language. in the case of the cabig® infrastructure, the target languages are cql or dcql, depending on whether the query is applied to a single or multiple data sources, respectively. the approach utilises the monoid comprehension calculus as an intermediate language, allowing the translation to different target languages for other infrastructures.

more details about these services are given in the methods section.

implementation
we have implemented two modules, with the functionalities described above. the implementation was done in java and uses cagrid version  <dig>   <cit> , the owlapi version  <dig> . <dig>  <cit>  , and relies on the reasoners pellet  <dig> . <dig>  <cit>  and hermit  <dig> . <dig>  <cit> .

owlgen cagrid analytical service
for the first module, we also produced a cagrid analytical service called the owlgenservice  <cit>  and it is accessible through the cagrid portal  <cit> .

the service provides a simple api allowing for:

• extraction of modules from ncit

• data service ontology generation

both methods accept a project short name and version from the cadsr service or the url of the data service of interest.

conquest graphical user interface
in order to demonstrate the functionality of the query rewriting process, we have developed a web-based interface, which we call conquest - cancer ontology querying system, that affords the user several key abilities;

browser  the user can browse the projects available in cadsr and investigate the ncit concepts in each project. we provide information such as definitions and links to the ncim  <cit> .

search tool  the user can search for ncit concepts, either by matching patterns or exact searches, returning metadata about the concepts and the projects that contain those concepts.

query builder  we provide a custom query-building interface that demands no prior knowledge of description logics or owl class expressions. the query builder uses a point-and-click interface with auto-suggestion concept boxes that force the user to create syntactically valid, description-logic based queries.

query rewriting users can interact with the query-rewriting process, choosing from the available uml extractions and selecting the appropriate paths during the path-finding stage. the user is prompted for a choice when required, the ultimate result of which is a cql query that the user can inspect visually to verify the semantic correctness.

query execution  users can run the rewritten query against the service of their choice and retrieve and save their results in a variety of formats.

the interface has been developed using the google web toolkit  with a mysql database backend. client-server communications employ the java rpc implementation <dig> 

performance evaluation
for an evaluation of the query reformulation process, our experimental analysis covers the following:

 <dig>  we present some metrics to assess the owl representation of the information models. in particular, since an important step in the rewriting process is the property path finder, we examine the sequences of concepts linked by object properties .

 <dig>  we provide results of the generation times for the module extraction, the ontology generation and the inference of the ontologies using both the pellet and hermit reasoners. these results show that the generation of the ontologies, which enable our approach, can be done in a performant manner.

 <dig>  we perform an evaluation of the query rewriting process, showing a breakdown of the constituent parts of the rewriting algorithm.

 <dig>  we compare explanation generation times, simulating the request of 1- <dig> explanations, demonstrating the effects on the rewriting process.

the tests were run on a red hat enterprise linux server release  <dig>   and  <dig> mb of ram. the output files corresponding to the performance evaluation are available at  <cit> .

analysis of the owl representation of the information models
throughout this section, we group cagrid projects into three distinct subsets: projects available from the cadsr service, data services that are registered with the cagrid default index service  <cit> , and information models . it should be noted that not all cadsr projects are included in the metrics; some contained errors  and some models are targeted for data modelling, rather than specifically holding data, making them unrepresentative for our system. out of the  <dig> projects in cadsr,  <dig> were excluded from the analysis for these reasons. however, none of the excluded projects had an associated service. additionally, the cagrid subset has  <dig> services and infomodels has  <dig> projects. the groups cagrid and infomodels are the more relevant for our system, as it is only possible to execute cql queries against projects that have an associated cagrid service. while infomodels include a single project from cadsr for a set of deployed services corresponding to that project, cagrid may include the results for several services that correspond to a single model. thus, the cagrid results will be skewed according to the relative weight of services as opposed to models.

there are several tools for establishing ontological metrics including ontometric, ontoqa and protégè as the main available proposals  <cit> . ontometric  <cit>  is a framework that allows users to measure the suitability of a particular ontology with respect to the requirements of their system. ontometric provides a taxonomy of characteristics for each ontology, from which the user can choose a selection to compare against another ontology. while proteégè is primarily a tool for creating and modifying ontologies, it does provide a limited selection of metrics for an ontology, but they are not semantic metrics. there are other ontology metrics that focus on cohesion, most of which focus on mining inconsistencies in the ontology  <cit> . while ontology metrics have been defined in several of these tools  <cit> , these have focused on basic metrics  or semantic-based metrics  that allow for the comparison and quality evaluation of the ontologies. therefore, we will focus on the presentation of some bespoke metrics we developed to measure the proliferation and complexity of paths within the ontologies, as these will ensure the viability of our approach.

our rewriting process seeks to remove the upper-level and transitive object property hasassociation and express the query using only non-transitive properties, which correspond to the uml associations in the models. in order to achieve this, we consider the paths between pairs of concepts from the query connected through the hasassociation property. the calculation of these paths is not trivial; there may be many intermediate nodes and there may be more than one path for a given pair of concepts. we define a journey as a traversal from one concept to another. a journey may have one or many paths, which represent the possible routes that the traversal can take. thus, it is important to evaluate these aspects of the ontologies in order to assess the viability of our rewriting tool.

we propose the following metrics as a measure of complexity in this respect. the longest path is the maximum path length that may be computed within a given ontology. each node in the path can be visited at most once so as to avoid looping. the longest path length provides an indication of the worse case for path calculation times. the average paths per journey reflects the degree of path expansion within the rewriting algorithm, as each journey  may have many different paths. the rewriting algorithm should be capable of returning all possible paths as each path may refer to a different expression of the query. when we consider that a single query may include multiple independent journeys, the possible query rewritings can become very large. the average nodes per path is the average number of nodes that must be visited in order to return a single path. these metrics can affect the path calculation time as well as the complexity of the resulting query.

ontology generation, module extraction and classification
in order to isolate any overhead caused by variations in network performance, we extracted the xml corresponding to each project  in cadsr. this is a preliminary step so that the performance evaluation can be run locally, and we do not include any data or results of the performance of this stage. we generate four ontologies for each project: the ncit module ontology , the annotated uml ontology  and two inferred versions of the uml ontology. we generate the inferred ontologies by classifying the generated ontologies using both the hermit and pellet reasoners. we recorded the time for each generation and figure  <dig> illustrates the times for the four ontologies of the each project grouped by subset. the times are presented in a logarithmic scale to enhance readability. we can see that the vast majority  of ncit modules take less than  <dig> seconds to generate and even less time for ontology generation. the classification of the generated ontologies is also timely, with the average inference of the pellet and hermit reasoners never longer than  <dig> milliseconds. we conclude that the generation and inference of the ontologies used in our approach does not present a barrier to the timely execution of the rewriting process.

query rewriting evaluation
we have developed a test suite of over one hundred queries of varying complexity in order to evaluate the query rewriting. more details on the performance evaluation can be found in the conquest website  <cit> . these queries are run over several services, which are publicly available from cagrid. the test suite currently queries the following models : cabio  <dig> , caarray  <dig> , catissue  <dig>  and pir  <dig> . the results are presented in figure  <dig>  which shows the times of each stage of the query reformulation process. these correspond to each stage of query rewriting: parsing, uml extraction, path finding, mcc conversion and cql conversion. we grouped the test queries by query path length and these are presented in figure  <dig>  the path length refers to the number of intermediate nodes in the rewritten query. we can see from figure  <dig> that, while the path length has an effect on the time taken at the path finding stage, the other stages of implementation remain largely unaffected. we therefore maintain that, given our analysis of paths within our target ontologies described above, we can provide query reformulation in a timely and efficient manner.

there are two principal factors that affect the performance of the path-finding stage of the query rewriting process; the length  of the returned path and the number of explanations requested to describe that path. the length of the returned path is the length  of the path that is found between two nodes. we have shown in figure  <dig> that there is a correlation between the length of the resulting path and the time taken in generation, although we accept that the overall effect is minimal. the path-finding stage makes use of an explanation generator  <cit>  in order to find paths through the ontologies. we can ask for a number of explanations for one particular journey but we have no control over the order in which they are returned and we can make no inferences of how long each explanation took. due to the black-box nature of the explanation generator, it is difficult to make any further assumptions of the internal processes at this stage. rather, we endeavour to present a thorough evaluation of the performance of this stage to ensure the suitability of the method. during the rewriting evaluation described above, the path-finder was configured to return only a single explanation and, therefore, a single path for each query. the explanations returned during the path-finding process, while technically correct according to the ontology, are not necessarily desirable or biologically relevant. it is, therefore, sometimes necessary to request multiple explanations in order for the user to choose the desired path. the number of explanations requested has a marked influence of the time taken to return the paths.

CONCLUSIONS
the realisation of personalised medicine requires the integration of data from a variety of scientific disciplines, such as molecular biology, pathology, radiology and clinical practice. software infrastructures have been developed to facilitate the discovery and management of these types of data in oncology, including the ncri onix system and the nci cabig® infrastructure.

the cabig® infrastructure is based on the cagrid service-oriented middleware, which follows a federated local-as-view approach to data integration by defining mappings from distributed data sources to a global-schema. the global-schema is realised by the nci thesaurus ontology describing the cancer domain. the nci thesaurus ontology is used to provide unambiguous meaning to the data sources. however, it is not currently used to provide a unified view for querying the data sources. current querying capabilities in cagrid rely on the structure of the data sources.

this paper has presented an ontology-based querying system, which works over service-oriented and model-driven infrastructures for sharing cancer data. the design relied on generating ontologies from existing information models and reformulating ontology queries into resources' queries. the implementation was based on the cagrid infrastructure, but the approach could be used over similar model-driven software infrastructures. this work has extended our previous results  <cit>  with the theory and implementation to handle federated queries, a more extensive evaluation of the query reformulation process, and the development of a graphical user interface aimed at cancer researchers. this paper has described the entire approach in detail, presenting:

a) the generation of customised owl <dig> ontologies from annotated uml models, based on the iso <dig> standard for metadata registries. this differs from traditional uml-to-owl conversions and it supports annotations with primary concept and qualifiers;

b) an analysis of the generated ontologies by determining several relevant ontology metrics, existing and new metrics that justify the viability of our rewriting technique;

c) an extended version of the query reformulation stages  to transform a domain ontology-based query into queries for a single resource or multiple resources; the latter involves the definition of join conditions, which can be found automatically by capitalising on the semantic annotations of the data sources; two simple use cases to illustrate the reformulation stages;

d) a cagrid analytical service implementing the owl generation facility;

e) an analysis of the capabilities of the cagrid query languages, both cql and dcql;

f) an extensive performance evaluation of the owl generation, module extraction, querying rewriting and translation process.

