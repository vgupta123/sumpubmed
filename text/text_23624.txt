BACKGROUND
biological data are likely to contain random noise. it may be possible to statistically identify and reduce such random noise, especially in large data sets. principal component analysis , also known as singular value decomposition, has been used for the purpose of statistical reduction of random noise  <cit> . small variances associated with higher-order principal components  are nullified as random noise. pca has been used for analysis of large biological data sets, such as expression profile data  <cit> . although pca is useful for capturing major trends in data, it could result in loss of important information. a typical form of expression profile data is a matrix with thousands of rows  and tens or hundreds of columns . large biological data sets usually have many small features as well as large ones. small features consisting of small numbers of rows and columns do not contribute much to the overall variance of the data. therefore, pcs associated with small features are among the high order pcs. consequently, small but biologically important features may be removed as noise. it is inevitable that severe dimensionality reduction in a global space, such as that often applied using pca, will result in loss of signal from truly high-dimensional data in which many dimensions are represented by small features.

here we present a robust unsupervised method for reduction of random noise in large data sets, which we call row-specific, sorted principal component-guided noise reduction . we applied the method to arabidopsis affymetrix microarray expression profile data collected in multiple experiments. the correlations between expression profiles of gene pairs that share gene ontology  biological process and cellular component terms were significantly increased while those of gene pairs that do not share go terms were decreased. rspr-nr clearly exceeded the performance of pca in this test using a real data set. thus, rspr-nr can facilitate gene discovery by reducing random noise while retaining small features in expression profile data.

RESULTS
rspr-nr algorithm
this noise reduction procedure can be applied to an m rows × n columns  data matrix, d, in which the random noise is assumed to be normally distributed with a mean of zero. in general, we expect m and n to be in the range of thousands and 30– <dig>  respectively. rspr-nr was coded in r   <cit> . the r script for rspr-nr is freely available for non-commercial use at .

the core rspr-nr procedure is as follows.

 pca without centering or scaling was applied to d using the columns as the coordinates, to obtain the pc-coordinated data matrix p. the values in each row of p are called the pc-coordinates of the data point .

 in each ith row of p, the pc-coordinates were squared and sorted in descending order, yielding the sorted squared pc-coordinate matrix, s.

 for each element sij in the ith row and the jth column in s, the probability pij = p, for which sij is derived from the normal noise model, was determined using the jth order distribution of the squared random noise. the squared values of random values sampled from the standard normal distribution n assume the χ2-distribution with one degree of freedom. c and c denote the probability density function and the cumulative distribution function of the χ2-distribution with one degree of freedom, respectively. when n values sampled from c are put in decreasing order, the value in the jth rank is drawn from a distribution with probability density function

 fj=n!!!cn−j)j−1c, 

and cumulative distribution function

 fj = b; n - j +  <dig>  j), 

where b is the cumulative distribution function of the beta distribution with parameters u and w  <cit> .

to calculate pij, the scaling factor ai for the ith row was determined as

 ai=median|k= <dig> ,…,n)median 

this scaling was based on the assumption that the median and the higher ranked columns in the ith row of s contain no signals but noise. then

 pij =  <dig> - fj. 

for practical efficiency, only pij for j≤⌈n2⌉ were calculated because of this assumption. these pij were corrected for benjamini-hochberg false discovery rate   <cit>  to obtain qij. the remaining qij for j>⌈n2⌉ were set to  <dig> 

 noise-reduced data was generated. the elements in the pc-coordinate data matrix p corresponding to the qij that were larger than the preset fdr were nullified as random noise to obtain a noise reduced matrix, pnr. note that the column positions of the corresponding elements in p were the positions before the sorting procedure in step . pnr was transformed back to the original coordinate system by the inverse of the rotation transformation used in the pca to obtain the noise reduced data matrix dnr.

the core rspr-nr procedure was applied to subsets composed of a relatively small number of rows randomly sampled from the large data set. the standard conditions were: the number of rows in a subset was approximately  <dig>  times the number of columns in the data matrix, and the number of times each row was sampled was  <dig>  this was done by sampling each row  <dig> times in different subsets, each of which was subjected to the core rspr-nr procedure. the results of the core rspr-nr corresponding to each row of the original data set from  <dig> subsets were averaged to yield the final rspr-nr output values.

the core idea underlying rspr-nr
selection of only low ranked pcs in pca results in loss of small features. nevertheless, a small number of pc-coordinates may be sufficient to capture even small features, provided that they are properly chosen for each row from all the pc-coordinates. this is because variances from even small features can affect determination of high ranked pcs. if this is the case, a relatively small number of pc coordinates selected for each row could capture features of various sizes quite well. this idea was explored using an arabidopsis gene expression data set.

we used log-transformed expression level ratio data because rspr-nr assumes that the mean of the random noise distribution in each row of the data matrix is zero. in the data set used, each of the  <dig>  rows corresponds to one probe set of the affymetrix genechip® and each of the  <dig> columns corresponds to one biological sample. see methods for details of the data set. the columns of the data set were transformed to the pc-coordinates. the squared pc-coordinate values vary greatly from probe set to probe set . for example, probe set 249054_at  appears to have significant coordinates in some of the high ranked pcs, suggesting it may be part of a pattern not captured by the top few pcs. in step  of the core rspr-nr procedure, the squared pc-coordinates were sorted in descending order for each probe set.

in step , the squared and ordered pc-coordinates were compared with the order distributions of squared and ordered random numbers sampled from the standard normal distribution. the latter is the random noise model. for this comparison, the squared pc-coordinates in each row were scaled so that the median value of the squared pc-coordinates in the row became equal to the median of the  <dig> percentile values in all the ranks of the ordered noise distributions. this scaling is based on the assumption that the squared and ordered pc-coordinates in the median and higher ranks contain only noise. in figures 1b and 1c, the squared, ordered, and scaled pc-coordinates for four probe sets are shown as colored solid curves, and the  <dig> percentile values in the ordered noise distributions are shown as black dashed curves. the black dotted curves represent the p-value of  <dig>   across the ranks. the squared, ordered, and scaled pc-coordinates that are larger than the dotted black curve correspond to the p-values smaller than  <dig>  and are significant at the threshold p-value of  <dig> . note that in the actual rspr-nr core procedure, the fdr-corrected p-value was used for the statistical test . however, in this section, the fixed p-value of  <dig>  was used as a threshold for the demonstration purpose because the fdr-corrected p-value depends on the p-value distribution and is difficult to visualize in this figure format. using this statistical test,  <dig>   <dig>  and  <dig> significant pc-coordinates were identified for the example probe sets 265244_at , 249123_at , and 252618_at , respectively . the probe set 249054_at  did not have any significant coordinates despite the impression given by figure 1a. the actual pc-coordinates selected as significant ones for 265244_at were in pcs  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>  and  <dig>  those for 249123_at were in pcs  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>  and  <dig>  and those for 252618_at were in pcs  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>  and  <dig>  the orders of the listed pcs are the decreasing order of the squared pc-coordinates. the selections and orders of the listed pcs illustrate that the contributions of the pcs to the signal in different rows of the data set vary to a large extent. this observation of highly variable contributions of the pcs strongly suggests that the statistical test applied to each element of the pc-coordinated data matrix help retain small features and justifies building a noise reduction method, rspr-nr, based on this idea.

in step  of the core rspr-nr procedure, the pc-coordinates for which the corresponding squared pc-coordinates are tested insignificant in the statistical test are nullified, and the remaining pc-coordinates are transformed back to the original coordinate system to yield a noise-reduced data set.

simulations for optimization and evaluation
it is impossible to accurately estimate the amounts of random noise and signal in real data. therefore, for the purpose of parameter optimization and performance evaluation, we used simulated data sets in  <dig>  rows ×  <dig> columns matrices, in which we could know the exact amounts of signal and noise for each element of the data matrices. figure  <dig> illustrates the steps of the simulation. first, predetermined numbers of large and small blocks were generated to mimic large and small signal features in data . this is a simulated signal matrix. second, normally distributed random noise of a predetermined variance was added to the simulated signal matrix to obtain a simulated data matrix . the simulated data matrix was subjected to a treatment, rspr-nr  or pca . any values in a treated matrix that differed from the original signal matrix were defined as noise. the performance of a treatment was measured by the ratio of the root mean square  of noise after the treatment to that before the treatment . details of the simulation procedure are provided in methods.

it is clear that rspr-nr retained small features very well while reducing the overall noise level . the noise rms ratio for rspr-nr was  <dig> . to compare the performance of rspr-nr with that of pca, the number of top pcs that should be kept was explored. figure 3a shows the percentage of the total variance of the simulated data matrix that can be explained by each pc. since there were clear drops in the relative variance right after pc <dig> and pc <dig>  two options, keeping the top three pcs  and keeping the top nine pcs , were investigated. unlike rspr-nr, pcs1- <dig> clearly could not handle the complexity of the simulated signals . most small features were lost or widened, and large features caused shadows of non-random noise. this tendency was still evident even with pcs1- <dig> . the noise rms ratio for pcs1- <dig> and pcs1- <dig> were  <dig>  and  <dig> , respectively, which indicate that these treatments increase noise instead of decreasing it. since it was not evident how many top pcs should be kept to obtain the best noise rms ratio, we calculated the noise rms ratio for all the possible numbers of top pcs . when the number of top pcs kept was lower than  <dig>  pca actually increased the noise as the noise rms ratio is higher than  <dig>  when the top  <dig> pcs were kept , the noise rms ratio reached a minimum at  <dig> , which is still larger than that of rspr-nr,  <dig> . in the visualized data matrix resulting from pcs1- <dig> , small features were retained well, however, the remaining noise is higher compared with rspr-nr . thus, using the simulated data set, rspr-nr outperformed pca even when the optimum number of top pcs were kept.

sampling multiple subsets for each row from a large data set
the sensitivity of pcs for capturing small features is higher when the number of rows is limited , as the variances of small features relative to that of random noise become larger. so, we decided to randomly sample rows and make subsets with a smaller row number before applying the core rspr-nr procedure. the number of rows in each subset needs to be at least as large as the number of columns to have the number of pcs at least as large as the number of columns. on the other hand, a number of rows per subset that is too low would allow large peaks of random noise to significantly influence determination of pcs. if pcs are influenced by peaks of noise so that noise is no longer random in the pc-coordinate system, such noise will not be removed in step  of the core procedure. one way to reduce such an effect of noise peaks on the final output data set is to sample each row of the original data set multiple times in different subsets, and then average the results corresponding to each row of the data set from different subsets to yield a final output value for the row. based on these considerations, we used simulation to explore two parameters: the number of rows per subset , and the number of times each row is sampled , to empirically determine the parameter values for good noise reduction performance.

for the sake of simplicity, only one signal block condition of  <dig> large and  <dig> small blocks, one noise variance ratio of  <dig> , and one fdr of  <dig>  were used in the simulation. figure 4a shows the noise rms ratio distributions in  <dig> simulations for different subset row numbers with the repeat number fixed at  <dig>  note that the subset row number of  <dig>  means that no subset sampling was performed as  <dig>  is the number of rows in the complete data matrix. the best result was obtained using a subset row number of  <dig>  which yielded a median rms ratio of  <dig> . however, among subset row numbers ranging from  <dig> to  <dig> , the difference in performance was relatively small. thus, rspr-nr performance is relatively insensitive to the subset row number, and the choice of the subset row number is not very critical. hereafter, a subset row number of  <dig>   <dig>  times the number of columns in the data matrix, was used unless otherwise specified. for data sets not exactly divisible by the subset row number, the actual subset numbers were adjusted with small values to equalize the sampling numbers of each row.

a similar simulation was performed with different repeat numbers. figure 4b shows that the higher the repeat number, the lower the noise rms ratio, as expected. however, the level of noise rms ratio improvement decreases as the repeat number becomes larger. a higher repeat number leads to a longer computing time. we decided that the repeat number of  <dig> yields satisfactory performance. the repeat number of  <dig> was chosen for the standard setting and used hereafter unless otherwise specified.

robust performance of rspr-nr
in the last section, only one condition of signal block numbers and one condition of noise variance ratio were used in the simulation. however, real data sets have wide ranges of signal and noise conditions, and it is generally impossible to know such conditions in real data sets. an unsupervised noise reduction method must perform well under wide ranges of conditions. we performed simulations under wide ranges of signal and noise conditions.

the simulations with various signal complexities and noise levels demonstrated that rspr-nr performs well within the tested ranges, and its performance is relatively insensitive to the fdr level. this robust noise reduction performance of rspr-nr makes it suitable for unsupervised noise reduction. in contrast, the optimum number of top pcs kept in pca varies over a wide range dependent on the complexity of signal and the noise level. we could determine the optimum number of top pcs for pca in the analyses shown in figures  <dig> and  <dig> because we knew the exact signal in the simulation. in real data, we cannot determine the optimum number of top pcs in this way. the optimum number of top pcs for the best noise rms ratio performance is much higher than the number that can be estimated by a conventional method based on the variance associated with each pc . a severe underestimate of the number of top pcs kept in pca results in an unsatisfactory noise reduction performance – it could even increase the noise rms . therefore, pca is not as good an unsupervised noise reduction method as rspr-nr.

noise reduction with actual data
whereas simulations allow exact quantitation of noise in a data set before and after a treatment, block signals used in the simulations may not be good approximations of signals in actual expression profile data sets. therefore, it is important to demonstrate that rspr-nr provides a benefit in analysis of a real expression profile data set. it is challenging to identify reasonable metrics to evaluate usefulness of rspr-nr using a real data set. we chose to use the gene ontology  term conservation in evaluation of rspr-nr performance. the go terms comprise a controlled vocabulary to describe gene and gene product attributes in three categories of molecular function, biological process, and cellular component  <cit> . it has been reported that genes involved in related biological processes tend to have similar expression profiles  <cit> . if this is true, we can expect reduction of random noise to result in statistical enrichment of similarly-regulated genes among genes that share go terms.

among the three categories of go terms, we chose to use the biological process and the cellular component categories because the other category, molecular function, does not imply similarity in expression profiles. for example, different genes with a molecular function of "transcription factor activity" can be regulated very differently. we defined go term relatedness as follows. to conclude that members of a gene pair share go terms, we required the jaccard similarity, which is the ratio of the element numbers between the intersection and the union of the go term sets for the two genes, to be equal to or greater than  <dig> . to conclude that members of a gene pair do not share go terms, we required that they not share any go process and component terms, and have at least  <dig> terms in union, thereby restricting gene pairs to very well annotated ones.

the arabidopsis expression profile data set introduced above was used. as the total number of gene pairs in the data set exceeds  <dig>  ×  <dig>  for practicality  <dig>  gene pairs were randomly sampled and analyzed. first, overall trends of changes in the angles between pairs of gene vectors  were visualized along the angle before rspr-nr treatment . in general, rspr-nr improves correlations between gene pairs . this was expected as rspr-nr is a type of dimensionality reduction method. the question is whether the gene pairs that share go terms tend to have a higher level of correlation improvement than the gene pairs that do not. to enable a comparison of such relative angle changes, we used loess  <cit>  to define the normalization curve along the "angle before" axis . the gene pair data were normalized by subtracting the loess fitted values from the "angle change" values . in this relative angle change plot, the data points for the gene pairs that share or do not share go terms were identified . the gene pairs that only had small correlation before rspr-nr  were excluded from this analysis because it is likely that many of these gene pairs truly do not have significant correlations. the mean values of the relative angle change for the gene pairs sharing go terms were - <dig>  π and  <dig> π for "angle before" <  <dig>  π and "angle before" >  <dig> π, respectively. this result indicates that the correlations between the gene pairs sharing go terms were statistically increased. the mean values of the relative angle change for the gene pairs not sharing go terms were  <dig>  π and - <dig>  π for "angle before" <  <dig>  π and "angle before" >  <dig>  π, respectively. this result indicates that the correlations between the gene pairs not sharing go terms were statistically reduced.

to test the significance of these observations, nine more randomly sampled sets of  <dig>  gene pairs were analyzed . the means of the mean relative angle changes for the total of  <dig> samples were - <dig>  π,  <dig>  π,  <dig>  π, and - <dig>  π for sharing go terms, "angle before" <  <dig>  π and >  <dig>  π, and not sharing go terms, angle before" <  <dig>  π and >  <dig>  π, respectively. all these sample means were significant as the probabilities of any of them being zero or having the opposite sign were < 10- <dig> . these relative angle change values may seem small. however, the mean and sem of the means of the absolute values of the relative angle changes of all the sampled gene pairs across ten sampled sets were  <dig>  π ±  <dig>  π. so, - <dig>  π, the mean relative angle change difference between gene pairs sharing and not sharing go terms  in the range of "angle before" <  <dig>  π, represents -46% of the mean of the absolute values of the relative angle change , a substantial change in correlation.

1) a summary of the results from  <dig> sets of  <dig>  randomly selected gene pairs. 2) go biological process and cellular compartment terms; see fig.  <dig> for the exact rules for shared and not shared. 3) the probability of the mean relative angle change being zero or having the opposite sign by one-sample, one-sided t-test. 4) the ratio in percents of the mean of the mean relative angle changes of the selected gene pairs to the mean of the absolute values of the relative angle changes of all the sampled gene pairs.

the relative angle change differences and the % angle change differences, separately for the ranges of "angle before" <  <dig>  π and "angle before" >  <dig>  π, were also determined with the results from pca. the relative variance explained by each pc did not provide a clear idea for a possible optimum number of top pcs to keep . therefore, the relative angle change differences and in the % angle change differences were measured for numbers of top pcs kept ranging from  <dig> to  <dig> in ten  <dig>  gene pair sets, and the distributions of the difference values are shown in box plots for each number of top pcs kept . for comparison, the distributions of the difference values in ten  <dig>  gene pair sets resulting from rspr-nr are also shown on the right of each panel. figures 8a and 8b show the distributions of the mean relative change differences between the gene pairs sharing and not sharing go terms, in the ranges of "angle before" <  <dig>  π and "angle before" >  <dig>  π, respectively, for each number of top pcs kept in pca. in the range of "angle before" <  <dig>  π, when pcs1- <dig> were kept, the median of the relative angle change difference was minimum at - <dig>  π, which means that on average the gene pairs sharing go terms had the correlation improved by the amount corresponding to  <dig>  π, compared to the gene pairs not sharing go terms . in the range of "angle before" >  <dig>  π, in which the correlations between the gene pairs were negative before pca, when pcs1- <dig> were kept, the median of the relative angle change difference was maximum at  <dig>  π . this means that on average the gene pairs sharing go terms had the correlation improved  by the amount corresponding to  <dig>  π, compared to the gene pairs not sharing go terms. since the medians of the relative angle change differences resulting from rspr-nr were - <dig>  π and  <dig>  π, in the ranges of "angle before" <  <dig>  π and "angle before" >  <dig>  π, respectively , the improvements of the correlations between gene pairs were better than or comparable to the best cases of pca.

when the % angle change differences were determined with the results from pca, the optimum numbers of top pcs kept were very different from those with the relative angle change differences. in the range of "angle before" <  <dig>  π , when pcs1- <dig> were kept, the median of the % angle change differences was minimum at -47%. in the range of "angle before" >  <dig>  π, when pcs1- <dig> were kept, the median of the % angle change differences was maximum at 40% . the corresponding difference median values with rspr-nr were -45% and 44%, respectively. therefore, the performance of rspr-nr in the % angle change difference was comparable to that of the best cases of pca.

when pcs1- <dig> were kept, resulting in the best relative angle change differences, the improvements in the % angle change differences were small . this indicates that when a small number of top pcs are kept, such as pcs1- <dig>  on average the correlations between gene pairs increase substantially due to severe dimensionality reduction, regardless of whether or not go terms are shared. therefore, the selectivity in favoring the gene pairs sharing go terms for correlation increase is low. thus, with pca it is impossible to optimize both the relative angle change difference and the % angle change difference at the same time. in contrast, rspr-nr can achieve performance comparable to the best cases of pca in both the relative angle change difference and the % angle change difference.

discussion
using simulated data sets, we demonstrated that the noise reduction performance of rspr-nr is robust over wide ranges of signal complexity and noise level in data sets, and the fdr used in the procedure . this robustness is important for applying rspr-nr to real data sets. using real data, it is usually impossible to know the exact signal complexity, especially concerning small signal features, and levels of random noise. therefore, it is impossible to select parameters for the best results. rspr-nr can produce nearly optimal results over wide ranges of signal complexity and noise variance ratio, without adjusting the fdr parameter. in contrast, pca could easily result in poor performance with real data because there is no definitive way to optimize the number of pcs kept for noise reduction performance using particular real data sets. to obtain an idea about noise reduction performance with a real data set, we used selective improvements of the correlation between gene pairs sharing go terms over gene pairs not sharing go terms. based on this test, it became clear that in pca, it is impossible to simultaneously optimize the number of top pcs kept for both the relative angle change difference and the % angle change difference. in contrast, rspr-nr can achieve relative angle change difference and % angle change difference values that are comparable to or better than the values optimized separately in pca, without parameter adjustment. so for real data sets rspr-nr is superior to pca for reduction of random noise.

how does rspr-nr achieve the robust noise reduction? one mechanism is that the statistical test used in the core rspr-nr procedure  automatically adjusts the threshold level for significant signals. if the random noise level is higher, the deviation of the squared, sorted, and scaled pc-coordinates from the  <dig> percentile value in each rank of the noise distribution smaller because it gets a smaller scaling factor . consequently, a smaller number of pc-coordinates will be selected as significant. if signals are more complex, the statistical test results in the opposite effect: a larger deviation of sorted squared pc-coordinates from the  <dig> percentile value in each rank of the noise distribution due to a larger scaling factor and a larger number of significant pc-coordinates . a second mechanism is application of the core procedure to one subset at a time with each subset having a relatively small row number . this increases the probability that a small number of pcs adequately capture small features and allows rspr-nr to accommodate complex data sets. the third mechanism is sampling of each row in multiple different subsets, and averaging of the results of the core procedure for each subset . this procedure reduces the likelihood that large peaks of noise remain in the final output data set and improves performance under a high noise condition.

it is worth emphasizing that all these mechanisms could be implemented because rspr-nr makes a decision about a significant signal in each element of the pc-coordinated data matrix. this clearly differentiates rspr-nr from pca as a statistical noise reduction method. for the element-by-element decision making, the scaling factor to compare with the noise distribution is determined for each row of the pc-coordinated data matrix. this row-by-row scaling design of rspr-nr could provide another advantage. although we applied random noise with the same variance to the entire data matrix in the simulation, it is conceivable that the noise variance may vary in different rows, that is, there may be gene-specific variation in the random noise level in expression profile data. with this row-by-row scaling design, rspr-nr is capable of handling such row-specific noise levels.

we applied rspr-nr to arabidopsis expression profile data, and the results were evaluated using an assumption of a correlation between go term conservation and expression profile similarity among gene pairs. we demonstrated that statistically, the gene pairs that share go process and component terms have their correlations increased while the gene pairs that do not share go terms have their correlations decreased by both rspr-nr and pca . this strongly suggests that rspr-nr and pca reduced noise from the actual expression profile data set and that this test may be generally applicable to examine the performance of a noise reduction method in expression profile data sets. however, this test method is not perfect. it is possible that the fundamental assumption of a correlation between the go term conservation and expression profile similarity may not always apply well, and it could depend on data sets. the expression profiles used in this study were collected from experiments related to arabidopsis responses to pathogen attack. if expression profile data collected under more diverse experimental conditions were used, the correlation between gene pairs sharing go terms might be higher. in addition, not all go terms used appear to be useful for this purpose. for example, the go process terms include "developmental processes". it is easy to imagine that genes with this term have diverse expression patterns according to the specific developmental process these genes are involved in. more intensive studies with various expression profile data sets are needed to better evaluate performance of rspr-nr with real data sets.

CONCLUSIONS
rspr-nr is a truly unsupervised method for reduction of random noise in a large data matrix and is highly robust against variation in the signal complexity and the noise level in data. in this work, we have applied the following concepts for noise reduction: interpretation of the pcs as a mere signal-rich coordinate system; sorting the pc coordinates in the order of contribution; applying a statistical test using the noise distribution to each element of the pc-coordinated data matrix; applying the above core procedure to subsets with relatively small row numbers; averaging the results from multiple subsets for each row. all these contribute to robust performance of rspr-nr. with more and more large and complex data sets becoming available in biology, rspr-nr, an unsupervised statistical noise reduction method, will be a useful tool for improving data quality.

