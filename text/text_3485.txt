BACKGROUND
the objective of supervised feature selection methods is to select a discriminative but concise list of features among a possibly large set of features in order to differentiate between classes. using only a small set of features improves the accuracy and increases the interpretability of the classification model . several types of feature selection methods have been developed to address that problem. filter-type methods select features independently from a classification model, whereas wrapper and embedded methods use feature selection as a part of training the classifier, which typically involves fitting more hyper parameters, and requires to use nested cross validations  <cit> . therefore, wrapper and embedded types typically suffer from increased computational cost and possible overfit, especially when a small number of examples are available. nevertheless, filter-type methods are allowed to utilize the labels of the subjects. the outcome of a filter-type method is the selected features list, regardless of their weights, where the selected features can be used later to learn a classifier. in this paper we focus on the filter type feature selection method.

in general, feature selection methods do not consider the structure among the features. for example, the features may be clustered such that the features in the same cluster are more similar to each other than features in different clusters. in many applications, the requirement is to select one feature from each group such that all features are jointly discriminative. this problem exists in many applications . analytics of sports: one major objective of analytics in sports is to enhance team performance by selecting the best possible players and make the best possible decisions on the field or court  <cit> . imagine that a coach needs to select a set of best players for the team. intuitively, the set of all possible players can be grouped  into g groups where each group contains all players who play in that position. since the objective is to select the best team, one may claim that the problem can be solved by selecting the best player in each position separately. however, using this approach synergy among the players is not considered. for example, players  <dig> and  <dig> might be the best players for positions a and b, respectively, but the players might not be so cooperative as to be in the same team. therefore, the idea is to select one player from each group such that the selected team has the best performance. multivariate time series classification: this problem can be addressed by using discriminative multivariate temporal patterns that are extracted from each class  <cit> . one example of such interpretable multivariate pattern is that if gene x and gene y are up-regulated at the same time followed by the down-regulation of gene z, then the patient is developing the condition. in order to discover such patterns, one can extract all patterns from gene x as one group and all patterns from gene y as another group, and so on. in other words, the grouping structure among genes is based on all patterns extracted from one variable . therefore, the problem is to select one pattern from each gene. the list can be analyzed by another method to extract a low dimensional multivariate pattern. dummy variables: dummy variable is an artificial variable created to represent a categorical variable. therefore, the coefficients of the dummy variables are naturally partitioned into groups, where it is naturally to select only one variable from each group. microarray analysis: the genes can be grouped based on their correlation or similarity, based on prior knowledge about their molecular functions, a cellular pathway, or based on annotation by a specific term of the gene ontology  <cit> . therefore, it would be enough to choose only one gene from each group.

the main advantage of performing analysis on groups of features is the compactness and improved interpretability of analysis results due to the smaller number of groups and greater prior knowledge available to such groups. in this study, we address a novel problem where the objective is to select a representative feature from each group such that the selected features are jointly discriminative. our contribution can be summarized as follows.  we formulate the feature selection problem in order to select a representative feature from each group simultaneously and jointly as convex-concave optimization, which is transformed into a sequence of convex optimization problems that can be solved using any standard efficient optimization algorithm;  we develop a block coordinate gradient descent  algorithm that is four times faster than any standard optimization algorithm for the proposed feature selection method;  the experimental results show evidence of the efficiency and scalability of the proposed algorithm. in order to evaluate the proposed method, we applied it to perform a feature selection for microarray analysis as a case study. related work in feature selection for microarray analysis: feature selection for microarray analysis has been extensively studied , where many of them can be categorized as filter based approach, in which genes are selected prior to learning the classification model. attempts to address similar problems include clustering genes by utilizing the biological relevance of those genes and then using the representative medoid from each biologically enriched cluster separately  <cit> . this clearly leads to a sub-optimal solution because it does not consider the interaction among genes from different clusters. this problem is addressed by proposing an efficient double sparsity optimization formulation that simultaneously identifies mutually exclusive feature groups from the low-level features , such that the groups contain correlated features, and then the groups are generalized to higher level features  <cit> . the high-level features  are constructed as a linear combination of low-level genes from that group. the problem with that method is that the meta genes might not be quite interpretable  <cit> .

a maximum relevance minimum redundancy  method was developed for feature selection of microarray data  <cit> . the method is based on mutual information criteria that maximizes the relevance of the feature to the target and simultaneously minimizes the redundancy to other features. the features are then ranked based on that criteria such that the high-rank features are the more informative features. another method is proposed to select the most informative features while minimizing the redundancy among the selected features  <cit> .

the problem is formulated as a quadratic programming formulation, which can be solved by any standard efficient optimization algorithm. however, the formulation involves a matrix that is not positive semi-definite; hence, it might lead to a poor local optima. a very recent method  <cit>  formulates the problem as a convex formulation with two terms, one to select features with maximum class separation and the other to select non-redundant features. the redundancy among features is computed based on pearson correlation, which is encoded as a positive semi-definite matrix. in order to apply the method for high dimensional data, the authors have applied low rank approximation to the quadratic term so that the solution can be found efficiently. although those studies  look similar to our proposed method, their methods were developed particularly to minimize the redundancy among features, whereas our method is general enough to exploit any structure among features. in other words, the features can be grouped based on similarity such as pearson correlation as in  <cit>  or mutual information as in  <cit> , or based on any other prior knowledge about genes, such as molecular function. therefore, our work can be exploited to any application where the features can be grouped in advance using prior knowledge.

the importance of selecting features from gene subsets or groups was recently studied  <cit> . the method first partitions the features into smaller blocks. then, in each block, a small subset of r features are chosen based on their classification accuracy. once the top-r features from each block is obtained, they are mutually compared to obtain the best feature subset. we note that the interaction among features are not fully considered but only the interaction among the top-r features from each subset. in addition, their method was developed using a wrapper-based approach, while the main focus of this paper is based on a filter-type feature selection approach.

methods
problem definition
let us assume that we have a dataset d of m examples  and n features, where the features are structured into g groups such that the number of features within group g∈{ <dig> ,…,g} is ng, i.e. n=∑g=1gng. assume that the feature fig is the ith feature in group g, where its weight is wig. assume that each example m is associated with a label ym indicating the label of the example. a visual representation for the data is depicted in fig.  <dig> 
fig.  <dig> matrix representation for the feature selection problem. features are structured into g groups, where group g has n
g features, where g∈{ <dig> ,…,g}. fig is the i
th feature in group g




the naïve approach to extract one representative feature from each group is to look at each group separately and extract the feature that maximizes the class separation  within the observed group. however, with this approach the possible interactions among features from different groups are not considered. for example, the data in fig.  <dig>  show that selecting the best feature from each group separately does not guarantee a global solution. if we applied any feature selection method on group  <dig> and group  <dig> separately to find the best informative features, then the first feature from group  <dig> and second feature from group  <dig> will be selected because they are more discriminative than the other features. however, these two features  combined will have one misclassification example because the first and last examples have exactly the same features set but from different classes. on the other hand, if we look at both groups simultaneously then we can see that features  <dig> and  <dig> are the most discriminative features where class  <dig> is predicted when both features are  <dig>  and class - <dig> is predicted otherwise. we emphasize that the objective is not to learn a classification model, but instead we select representative features that could be used later to learn a classification model.
fig.  <dig> toy example. four samples from each class with  <dig> features in  <dig> groups. each group has two features. features  <dig> and  <dig> are jointly the discriminative features although feature  <dig> is the discriminative feature for group  <dig> and feature  <dig> is the discriminative feature for group  <dig>  separately



we propose a method that simultaneously finds a representative feature from each group. let us assume that fg=t is a column vector representing all features for the group g , wg=t is a column weight vector for all features in the group g, and w=. if we do not impose any restrictions on weights w, the optimal weights can be found by minimizing a loss function ℓ over m examples in the training data d. the objective becomes minimization of the loss function with respect to the weights w. 
  minimizewℒ1=∑m=1mℓ 

where ℓ is the loss induced from the dataset d. we can use any loss function as long as the function is convex to ensure a global solution. in order to show that our formulation can incorporate different loss functions, we utilized the class separation loss and the logistic loss in experiments on gene expression and synthetic data, respectively; see additional file  <dig> for details.

to extract one feature from each group we need to have constraints on w. therefore, we solve the following constrained optimization problem 
  minimizewℒ <dig> 

  subject towig∈{ <dig> },∀g∈{ <dig> ,…,g},i∈{ <dig> ,…,ng}, 

  ∑i=1ngwig= <dig> ∀g∈{ <dig> ,…,g}, 

the constraint  ensures that the weights are binary , while the constraint  ensures that the sum of the weights within the observed group is  <dig>  these two constraints combined ensure that only one feature from each group is selected. the problem is combinatorial optimization with binary constraints, which is hard to solve. our goal is to relax these constraints. by relaxing wig to be within the range  <cit> , we obtain the following optimization function: 
  minimizewℒ <dig> 

  subject towig≥ <dig> ∀i,g, 

  ∑i=1ngwig= <dig> ∀g, 

  maxi=1…ngwig= <dig> ∀g. 

the constraint  ensures that the maximum weight within each group is  <dig>  therefore, constraints  and  jointly ensure that all weights within each group are  <dig> except only one weight that has value  <dig>  which means that we select one feature from each group. however, all these prototypes are selected simultaneously such that the joint effects among them are considered.

note. in case of positive weights, the constraint  can be considered as ℓ <dig> norm, whereas the constraint  is the ℓ∞ norm. since ℓ∞ norm is an upper bound for ℓ <dig> norm as illustrated in fig.  <dig> it might appear that there is a redundancy between these two norms. however the set of weights returned by the intersection of the two norms is different from the set of weights returned by either norm solely  <cit> . in particular, the intersection of the two norms forces all weights to be zero except one weight of a positive value c . therefore, using these two norms is essential in order to choose only one representative feature form each group.
fig.  <dig> 
ℓ
 <dig> and ℓ
∞ norms. ℓ
∞ is an upper bound for ℓ
 <dig> norm



if we solve the optimization problem  then we achieve what we want in order to select one feature from each group simultaneously. however, the problem  has equality constraints, which is not easy to solve. therefore, we relax equality constraints by introducing penalized terms in the objective function in order to obtain its lagrange formulation: 
  minimizewℒ1+λ1∑g=1g∑i=1ngwig−12+λ2∑g=1g1−maxi=1…ngwig 

  subject towig≥0∀i,g. 

where λ1> <dig> and λ2> <dig> are the lagrangian multipliers. the first penalization term is the difference between the sum of weights and  <dig>  since the sum of weights can be larger or smaller than  <dig> and, hence, the difference can be positive or negative; therefore, we instead penalize the quadratic term. the second penalization term is to penalize the difference between the maximum and  <dig>  which can not be negative because the maximum can not be larger than  <dig> according to constraint . higher value of λ <dig> forces the weight of the representative feature to reach the maximum and, therefore, validates the equality constraint . since the main objective is to force one of the weights to be large  and the remaining weights to be very close to zero, the value of λ <dig> is not set to be very high . as explained in additional file  <dig>  values of these two parameters are set to λ1=λ2= <dig> to balance the two constraints.

the optimization problem  is not easy to solve because the max function is not differentiable. therefore, we approximate it with convex differentiable log-sum-exp function  <cit> . we start with the following lower bound for the max function 
  maxi= <dig> .ngwig≥log∑i=1ngewig−logng1−maxi= <dig> .ngwig≤1−log∑i=1ngewig+logng. 

which means that the second penalization term is upper bounded with a smooth function. let us define 
 ℒ2=∑g=1g∑i=1ngwig−12ℒ3=∑g=1g1−log∑i=1ngewig+logng. 

then, we combine  and  to get the following optimization problem: 
  minimizewℒ1+λ1ℒ2−λ2ℒ3subject towig≥0∀i,g. 

ℒ <dig> is a convex loss function, ℒ <dig> is a quadratic function and therefore convex, and ℒ <dig> is convex because log-sum-exp is a convex function. then, the objective function  becomes difference of two convex functions. in order to solve this problem we have applied a recent convex-concave procedure   <cit> . cccp linearizes the concave function around a solution obtained in the current iterate with tangent hyperplane function, which serves as an upper-bound for the concave function. this leads to a sequence of convex programs where the convergence of the method is guaranteed  <cit> .

therefore, in each iteration we solve the convex optimization problem: 
  minimizewj=ℒ1+λ1ℒ2−λ2w·dℒ3dww=wtsubject towig≥ <dig> ∀i,g. 

where the term w=wt is the derivative of ℒ <dig> at the current iterate wt.



the application of cccp is shown in algorithm  <dig>  the advantage of cccp is that no additional hyper-parameters are needed. furthermore, each update is a convex minimization problem and can be solved using classical and efficient convex apparatus. since we now have a smooth, differentiable objective function j with only inequality constraints, we can use any optimization algorithm for solving the problem. in order to solve the problem efficiently we compute first derivatives of the objective function with respect to the weights w, and approximate the hessian with a diagonal matrix. in additional file  <dig>  we show the derivation of jacobian and hessian matrices for the logistic loss  <cit>  and class-separable loss functions  <cit> .

the trust-region-reflective algorithm  <cit>  is the fastest optimization algorithm for solving . however, in our application it is not efficient for large scale problems. in the next section, we develop a customized optimization algorithm based on coordinate descent that is four times faster than standard apparatus.

block coordinate gradient descent
coordinate gradient descent is a simple technique that is surprisingly efficient and scalable  <cit> . in general, given convex and differentiable function, the coordinate descent algorithm minimizes the function along each coordinate axis wig, nevertheless, it is guaranteed that the algorithm will converge to the global optimal solution  <cit> . moreover, in many cases we can replace individual coordinates with blocks of coordinates, e.g. coordinates wg for a group g  <cit> .

in order to develop a block coordinate gradient descent  algorithm to solve , we build our work on the seminal work of  <cit> , where they have developed an algorithm to solve a smooth function with bound constraints as in . the key idea of the algorithm is to iteratively combine a quadratic approximation of the objective function j at w to generate a feasible direction d with an additional line search to find the best move along that direction. the procedure continues in iterative mode until convergence. precisely, bcgd algorithm  iteratively runs over four steps until convergence. in the first step, the algorithm identifies a set of features  in order to optimize . typically, the algorithm iterates over those non-zero weights  and optimize their corresponding features. in the second step, the algorithm approximates the objective function as a quadratic optimization at the active set and then performs line search in step  <dig> to find the best step size to move along the direction of the quadratic approximation. this ensure a feasible movements towards the minimum. finally, it updates only the active set weights. the key issue of algorithm  is how to identify the active set so that the algorithm runs efficiently and optimizes the active weights.



active weights for solving 
cyclically updating one coordinate at a time in coordinate descent process might slow down the optimization for large scale problems. therefore, in our approach the update is performed based on blocks of coordinate  <cit> . our application is easily fitted in this situation where the blocks can be naturally chosen based on groups of features. in each iteration we update the weights of all features within one group.

nevertheless, in our application we did not see benefit from iterating over each group. instead, we initially set the active set as the entire w, and we update the parameters based on all coordinates at once. such an update is successfully used in a previous study where it is noted that “after a complete cycle through all the variables, we iterate on only the active set till convergence”  <cit> . then, after a few iterations some of the groups get stable . in this case, we do not need to optimize this group anymore and we can exclude that group from the active set. if we keep that group in the working set the algorithm will try to fit precisely the weights of the features within that group while the selected feature will remain stable. in other words, the optimizer will try to move the max weight to be closer to  <dig> while keeping the rest of the weights closer to  <dig>  therefore including those groups in the working set will just slow down the optimization without changing the representative for those groups. this resembles the well know active-set method, which iteratively predicts a correct split of zero and non-zero elements in w and optimizes the function based on only non-zero weights  <cit> .

RESULTS
microarray gene expression
we compared the proposed feature selection formulation using block coordinate gradient descent  algorithm to two baseline and two state-of-the-art feature selection filter-type methods.  the pearson correlation  method which ranks the correlation between the feature and the target and selects the top m features;  relief which is one of the most successful strategies in feature selection  <cit> . it chooses instances randomly and changes the weights of the feature relevance based on the nearest neighbor so that it gives more weights to features that discriminate the instance from neighbors of different classes;  mrmr ranks the features according to the minimal-redundancy-maximal-relevance criteria  <cit> , which is based on mutual information;  stbip formulates the feature selection problem as a quadratic objective function to select m features with maximal discriminative power and minimal redundancy  <cit> , where the redundancy among features is computed based on pearson correlation. we note that all methods we compare to, including our method, are filter-type feature selection methods, where the objective is to rank or select features without learning a classifier.

in order to apply our methods, we need to cluster the genes. the genes can be clustered in different ways. for example, each cluster may include genes that encode for similar polypeptides or proteins, which are often located few thousands pairs apart from each other. gene ontology  has been utilized to cluster genes based on their common function where they are not constrained by gene expression or other properties  <cit> . another way to cluster genes is to group co-expressed genes in the same cluster, which do not necessarily have similar functions  <cit> . for a survey on clustering genes, the reader is referred to  <cit>  and references therein. our method is decoupled from the clustering step. however, in order to have a fair comparison with other baseline methods and to select the top m features selected by our method, we clustered the genes based on pearson correlation into m clusters and applied our method to select one gene from each group.

the selected genes is then fed to linear svm as the classification model. we used linear svm because it has been shown to be effective in gene expression classification problems  <cit> . we evaluated the feature selection methods on five benchmark gene expression datasets  <cit>  described in table  <dig> 


for each dataset, we sampled training data from each class  for training the feature selection method, and the remaining samples were used as test data. using only the selected features, linear svm was optimized on the training data using the liblinear package  <cit> , where the parameter c={10− <dig> − <dig> …,103} was chosen based on a nested 3-cross validation on the training set. note that the test data were never used for training in either the feature selection method or svm. since the microarray datasets are imbalanced, we used the area under the roc curve  as the evaluation performance. the average auc is computed based on  <dig> repetitions of random splits for training and test data.

we evaluated each method using the top m={ <dig> , <dig> ,1000} genes over  <dig> runs and computed the average auc for each experiment. out of  <dig> experiments , the number of experiments where each method has the highest average auc is shown in fig.  <dig>  the proposed bcgd method has the best auc in  <dig> experiments, whereas all other methods have the highest auc in no more than  <dig> experiments. the results show that the proposed method has selected more accurate features than other state-of-the-art methods.
fig.  <dig> winners. the number of experiments where each feature selection method has the best average auc



the details of these results are shown in table  <dig>  each row in the table shows the average and standard deviation of auc performance of all methods on one dataset over  <dig> runs for different m features. the last row shows the average auc performance for each method on all datasets. the proposed method has on average the best auc among all other feature selection methods, which indicates that the proposed method has selected the most discriminative features. in addition, it has the smallest standard deviation. while the standard deviation of all methods overlap but when we applied t-test on the results we found that the average auc of the proposed method is statistically more significant than other methods in  <dig> out of  <dig> cases .
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
 <dig>  ± <dig> 
the average and standard deviation of auc is reported for each experiment over  <dig> runs. last raw shows the average auc over all datasets. bold represents the best auc



gene-go enrichment analysis. we have performed an enrichment analysis to find which gene ontology  terms are over-represented using annotations for the selected genes. therefore, in order to perform a function annotation analysis, the selected  <dig> bcgd genes from the myloma dataset were submitted to david bioinformatics resources  <cit> . the top  <dig> go terms are reported in table  <dig>  the last column in the table is the modified fisher exact p-value, which is the probability of seeing at least x genes out of n genes in the list annotated to a particular go term, given the proportion of genes in the whole genome that are annotated to that go term.
percentage is the percentage of bcgd genes involved in the corresponding term



myeloma is a cancer of plasma cells in which abnormal plasma cells multiply uncontrollably in the bone marrow and occasionally in other parts of the body. we can see from table  <dig> that cytoplasmic part and cytoplasm terms are enrighed by the bcgd selected genes. also, actin cytoskeleton is a mediator of apoptosis, which leads to cancer  <cit> . furthermore, we have performed a disease association analysis using webgestalt  <cit> . table  <dig> shows the list of top  <dig> enriched diseases and the number of genes in the gene list for the disease. it is shown that  <dig> of those diseases are directly connected to cancer.
the number of genes in the selected bcgd gene list associated with the disease. p-value is adjusted by the multiple test adjustment



diversity of genes. in order to show the diversity of the selected genes by each feature selection method, we consider the dlbcl microarray dataset as a case study. we plot the similarity  matrix between all selected genes by each method and computed the sum of the similarity matrix. the lower the value the less similar the features are. figure  <dig> shows the similarity matrix for each method. pc has the most redundant features among all methods, where the sum of its similarity matrix  is significantly greater than any other method. this is consistent with the fact that the method ranks the genes based solely on their correlation to the target regardless of the similarity among the selected genes, and hence the selected genes are very similar to each other, which might reduce the interpretability of the model. on the other hand, the proposed bcgd method has the lowest similarity value  indicating that the method has selected the most diverse  genes while being accurate. the stbip was the second successful method to choose the less redundant features.
fig.  <dig> similarity among selected features. the similarity matrix between all genes selected by  <dig> feature selection methods



efficiency of bcgd on synthetic data
the proposed feature selection formulation can be solved using any standard optimization algorithm. we have used trust region reflective  algorithm as it is the best and fastest implemented algorithm in matlab for the proposed constrained optimization problem . however, we have developed an efficient block coordinate gradient descent  algorithm that is four times faster than the standard algorithm for high dimensional applications . in order to show the efficiency of bcgd, we have conducted several synthetic experiments, where all synthetic datasets have been generated using the process described in additional file  <dig>  first, we conducted experiments to show the efficacy of utilization of active set and how that contributed to the reduction in computational cost of the bcgd algorithm. then, we compared the computational time of bcgd and tr in  <dig> settings with different number of features n={10e <dig> e <dig> e <dig> e <dig> e <dig> e <dig> e6} distributed over different number of groups g={ <dig> , <dig> , <dig> }.

utilization of active set
the bcgd algorithm does not update the weights for all groups at each iteration. instead, it updates the entire weight vector  at the first few iterations and then at each next iteration it identifies the non-stable groups and optimizes only those groups. we hypothesize that if the group has clear discriminative features then the observed group will become stable at earlier iterations, while groups that have most confusing features will go for longer iterations.

we compared the bcgd algorithm when using the active set  and without using the active set . for easier visualization, the simulation was done on  <dig> features with  <dig> groups, where the ground truth features are  <dig> and  <dig>  the left panel of fig.  <dig> shows bcgd when using the active set , while the right panel shows the algorithm optimizing the entire w in each iteration. it clear from the figure that the algorithm was able to find the correct features after  <dig> iterations . however, feature  <dig> had value greater than zero  and feature  <dig> had value close to  <dig> . the bcgd algorithm using active set  stops at this iteration and considered group  <dig> as stable. if we let the algorithm continue and optimize the entire w , then it needs two more iterations to find the optimal weights. however, the selected features are still the same and the only change is that the weight of feature  <dig> will be fully optimized  and the weight of the rest of features will be  <dig>  therefore, we benefit from this observation and utilize the active set in order to reduce the computational cost of the bcgd algorithm.
fig.  <dig> active set. the right panel shows the bcgd algorithm when updating the entire set of weights at each single iteration. the left panel shows the bcgd algorithm when using the active set groups. as soon as the group becomes stable, bcgd does not optimize that group, which results in reduction in computational time



in order to further simulate this situation in a large scale, we created a dataset with 20k features distributed evenly over  <dig> groups and added different noise levels to different groups. precisely, we added  <dig> noise to the representative features of each of the first  <dig> groups. then, we added  <dig> % noise to each group in the next  <dig> groups, which means that  <dig> % of samples in the representative features in each group are flipped. then, we added  <dig> % noise in the next  <dig> groups, and so on until we add  <dig> % of noise in the last  <dig> groups. the result of applying bcgd is shown in fig.  <dig>  the figure shows the number of iterations needed by the bcgd algorithm to optimize the weights for each group. it is clear that the first  <dig> groups  became stable after only  <dig> iteration. that means that bcgd does not update the weights of these  <dig> groups afterwards, which contributes to the reduction in computational time of bcgd. on the other hand, the last  <dig> groups  lasted for all iterations, because it was not easy for the algorithm to identify the representative features from these groups.
fig.  <dig> groups with different noise levels. x-axis represents the groups where each consective  <dig> groups have the same noise level represented in the corresponding colorbar at the top of the figure. y-axis represents the number of iterations needed by bcgd algorithm to optimize the weights of the corresponging group. easy groups  are terminated early while difficult groups  are terminated late



scalability
to show the efficiency of the proposed bcgd algorithm, experiments were conducted to compare the running time for both algorithms tr and bcgd. ten datasets were generated with  <dig> samples with n features distributed over g groups. we varied the number of groups g={ <dig> , <dig> , <dig> } and the number of features n={10e <dig> e <dig> e <dig> e <dig> e <dig> e <dig> e6} and. then, both algorithms were applied on each dataset and the results were computed as the average over all  <dig> datasets.

in all settings , both algorithms have identified the ground truth features. however, the proposed bcgd algorithm is significantly faster than tr. figure  <dig> shows the computational time comparison between both algorithms with fixed g= <dig> and varying number of features. when the number of features increases the running time of both algorithms increases. however, the speedup of bcgd over tr increases as the number of features increases indicating the applicability of bcgd on high dimensional data than just using standard optimization algorithm.
fig.  <dig> running time. running time for trust region  and bcgd on synthetic data with varying number of features distributed over g= <dig> groups


fig.  <dig> running time. running time for trust region  and bcgd on synthetic data with n=100e
 <dig> features distribted over different number of groups



CONCLUSIONS
feature selection method was proposed to select features in order to jointly maximizing the discriminative power of the features. this is performed by considering the structural relationships among features, where the features are grouped based on prior knowledge. the feature selection problem is then formulated as selecting a feature from each group. we developed a block coordinate gradient descent algorithm to solve the optimization function. the results of comparing the proposed method with  <dig> stat-of-the-art methods on five bench mark gene expression datasets showed evidence that the proposed method was accurate on 13/ <dig> experiments where the other methods was accurate in no more than 6/ <dig> experiments. in addition, several synthetic experiments were conducted to show the efficiency of the proposed bcgd algorithm over the standard optimization algorithm. the bcgd algorithm was four times faster than the standard algorithms indicating the applicability of bcgd on high dimensional data. in future work, we will investigate convergence properties for the proposed method. in addition, it might be interesting to learn the clusters of genes simultaneously with the feature selection method.

additional file
additional file  <dig> 
supplementary materials. the supplementary pdf file contains relevant information omitted from the main manuscript such as:  other applications for the proposed features selection method;  derivation for two loss functions used in the experiments;  implementation details for bcgd;  synthetic data generation process; and  scalability results that are not reported in the main manuscript. 

 competing interests

the authors declare that they have no competing interests.

authors’ contributions

mg developed and implemented the computational methods, and conducted the experiments, supervised by zo. mg, xc and is discussed and analyzed the results. mg wrote the manuscript, supervised by zo. all authors read and approved the final manuscript.

