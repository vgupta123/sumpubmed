BACKGROUND
in order to model and dissect the complexity underlying physiological processes, including diseases, developmental programs, and responses to pharmacological treatments, systematic approaches based on genome-wide data are imperative. expression profiling technologies, such as microarray  <cit>  and rna-seq platforms  <cit> , provide quantification of mrna levels on a genome-wide scale, prompting computational methods aimed at learning a more holistic perspective of cellular processes. parallel advancements in the area of genotypic profiling, including high-throughput sequencing and snp detection, offer information complementary to that of expression data. these concurrent developments pave the way for genetical genomic studies, which provide the joint space of expression and genotypic data corresponding to offspring that arise from a segregating population  <cit> . to date, eqtl datasets have been published for several organisms  <cit> , providing ample opportunity to develop novel computational methodologies. the tandem existence of expression and genotypic data is especially powerful in that it allows one to reconcile changes in expression programs in the context of the specific genetic combinations represented by the offspring. since natural genetic variation is the sole source of perturbation, it is logical to view genomic loci as epicenters of phenotypic variation in eqtl-derived causal networks. consequently, modeling eqtl datasets enables one to hypothesize on how genotypic variation results in phenotypic changes.

already several studies have provided methodologies aimed at exploiting the genotypic component of eqtl data to improve causal modeling in gene networks  <cit> . bing et al. introduced methodology to build directed networks starting from a set of candidate cis-genes for each locus  <cit> , establishing directed edges from candidate cis-genes to distally-located genes. this approach yields local regulatory models for individual loci, and the authors also present an innovative approach based on partial correlations to identify models where two regulators play complementary roles in controlling a common set of genes. the methodology of bing et al. was later applied to an eqtl dataset representing arabidopsis by keurentjes et al., who also incorporated information regarding dna sequence to improve the estimation of cis-genes  <cit> . while this application was successful in providing hypotheses regarding local regulatory models, it does not resolve causal orderings amongst distally located transcripts. furthermore, modeling local regulatory programs with respect to individual loci leaves room for improvement in the sense that each of the respective models are disjoint. a worthwhile goal is to produce more holistic and systematic methodologies capable of modeling the complex interdependencies between multiple loci and transcripts. indeed, it has been estimated that the genetic basis of many transcripts is extensively complex, with upwards of 50% of transcripts being linked to five or more loci  <cit> . the need for a comprehensive and systematic approach was addressed by schadt and colleagues, who developed a novel method to augment bayesian networks with probabilistic measures to direct causal orderings of gene pairs with respect to genomic loci  <cit> . their method, which is based on a conditional bivariate normal model, determines if two transcripts linked to a common locus are best modeled as causal or independent  <cit> . ultimately, the information generated by their method is incorporated as a prior for bayesian network structure learning  <cit> . this approach has yielded promising results when applied to yeast  <cit>  and mouse  <cit> , providing hypotheses regarding the architecture of eqtl networks. furthermore, the authors published a study on synthetic networks to quantify the performance gains associated with their method  <cit>  as compared to standard bayesian network structure learning. while their method proved efficacious at resolving causal orientations between correlated transcripts in the context of a global network, the scope is generally limited to the upper echelons of the causal hierarchy, an attribute that stems from their reliance on using genomic loci as causal anchors. ideally, one could commence at the genomic loci, learn the causal orderings of the most proximal transcripts, then advance down the causal hierarchy propagating the structural information gleaned from the upper levels of the network. the probabilistic method presented herein realizes this concept by stochastically reconstructing the causal hierarchy, which is subsequently incorporated as a prior into bayesian network structure learning.

a distinct but related problem to gene network reconstruction  is expression quantitative trait loci  mapping. while these two tasks have to date been addressed independently, they are likely to become more intertwined as eqtl-related computational methodologies advance. this corollary follows from the fact that accurately-modeled networks should inform on transcript-locus associations by virtue of the implied causal pathways. traditional univariate methods, which involve an exhaustive search between all transcripts and loci, typically entail the use of linear regression, anova, or the t-test  <cit> , where the chosen statistic assesses the extent to which a trait  is linked to a locus. while straightforward, this approach results in a considerable loss in statistical power due to the need to correct for multiple hypothesis testing. the issue of multiple testing is compounded when transcripts are tested for simultaneous linkage to two loci, where an exhaustive search across all loci results in complexity that is quadratic in the number of loci. addressing this limitation, storey et al. developed a stepwise mapping procedure  <cit>  whereby testing linkage to a secondary locus involves conditioning on the primary locus, reducing the complexity to 2l -  <dig> tests, where l is the number of loci. this approach, which controls for confounding linkages and tests for epistasis, was later generalized for multiple interval mapping by zou et al.  <cit> . while stepwise mapping techniques produce notable improvements over exhaustive searches, they do not take advantage of the fact that many transcripts sharing linkages to common loci exhibit strong correlation structure. suitably, recent methods have focused on mapping multiple  traits simultaneously to genomic loci  <cit> . pan et al.  <cit> , litvin et al.  <cit>  and lee et al.  <cit>  developed methods based on penalized regression frameworks to discover modules that can be explained by common expression programs. similarly, zhang et al. developed a bayesian partition method to learn modules of transcripts sharing linkage to common genomic loci  <cit> . these clustering based methods offer the distinct advantage of using fewer parameters while detecting eqtl linkages, however, they do not attempt to reconstruct the causal hierarchy and are therefore limited in the biological hypotheses that they offer.

our goal is to reconstruct causal networks with high-fidelity at all levels of the network. consequently, by improving the accuracy of the reconstructed network, we show that our method can provide biological hypotheses as well as enable greater accuracy in eqtl mapping.

RESULTS
we assess the performance of our method for the tasks of gene network reconstruction  and expression quantitative trait-loci  mapping. for gnr, we compare our methodology to standard unaugmented bayesian network structure learning, herein referred to as "basic," and the leading lcms methodology of schadt and colleagues  <cit> , herein referred to as "lcms." we refer to our stochastic causal tree method as "sct." for eqtl mapping, we compare our method to traditional univariate mapping. several statistical methods exist that are suitable for implementing univariate mapping, including regression, anova and the t-test  <cit> . since our study involves data that are generated from gaussian functions, we utilize the t-test in lieu of non-parametric alternatives such as the wilcoxon rank-sum test. we generated a synthetic network according to the protocol outlined in a previous eqtl study  <cit>  . the synthetic network is composed of  <dig>   <dig> transcripts and  <dig> loci, connected by  <dig>   <dig> edges. a total of six datasets are generated from the network adjacency matrix by regression models with noise . the first three eqtl datasets consist of  <dig>   <dig>  and  <dig> samples, respectively, and are characterized by relatively strong correlation structure. we herein refer to these as "strongly correlated networks" or "datasets composed of stronger correlation structure." the three strongly correlated networks feature a mean correlation between parent and child of  <dig> . however, it is possible that modeling techniques are biased in discovering stronger links, and weaker interactions may be more prevalent than can be detected, a point that has been made in previous studies  <cit> . in consideration of this possibility, we simulated three parallel datasets consisting of  <dig>   <dig>  and  <dig> samples with weaker correlation structure. the three datasets with weaker correlation structure possess a mean correlation between parent and child of  <dig> . table  <dig> in the methods section provides a summary of the statistics characterizing the datasets and the parameters used to generate the data. our goal was to assess performance on datasets representing what we feel is a reasonable estimate of lower and upper ranges of interaction strengths in gene networks.

precision and recall of network edges
we first assess the performance of gene network reconstruction. figures  <dig>   <dig> and  <dig> refer to the networks composed of stronger correlation structure, and show that our method provides appreciable performance gains in terms of precision and recall. for the dataset with  <dig> experiments, our method achieves a recall of  <dig>  at a precision of  <dig> . comparatively, the lcms method achieves a recall of  <dig>  at the same level of precision. for the dataset with  <dig> experiments, our method achieves a recall of  <dig>  at a precision of  <dig> , whereas the lcms method yields a recall of  <dig>  at the same level of precision. finally, for  <dig> experiments, the precision level of  <dig>  corresponds to recall levels of  <dig>  and  <dig>  for the sct and lcms methods, respectively. our method, when applied to  <dig> experiments, outperforms unaugmented bayesian network structure learning when applied to  <dig> experiments.

figures  <dig>   <dig> and  <dig> provide a performance comparison for eqtl datasets with weaker correlation structure. the results are consistent with those corresponding to the strongly correlated datasets. sct-augmented structure learning yields improvements in recall over unaugmented structure learning for a broad range of precision levels, particularly between  <dig>  and  <dig> .

we note that the performance gains of lcms-augmented structure learning over unaugmented structure learning reported by zhu et al.  <cit>  are recapitulated in our experiments, though the margin of improvement is slightly lower in our study. this is due to the fact that we explicitly model genomic loci as head nodes, which equates to the authors' logic whereby transcripts with cis-linkages are required to be head nodes. consequently, the performances of the baseline "basic" bayesian networks are higher in our study as compared to zhu et al.  <cit> . in experiments not published herein, we estimate that the performance margins between the basic and lcms-augmented methods are generally at least twice as large when this logic is not included into the unaugmented bayesian network structure learning procedure, indicating that performance gains are realized by simply establishing the head nodes as such.

precision and recall of transcript-locus associations
next, we sought to assess the potential of using the learned networks for the purpose of expression quantitative trait loci  mapping. in order to establish a transcript-locus linkage, for each head node  in the bayesian network, we run a depth-first search down the respective branches. all reachable transcripts from the source locus are associated with that locus. starting with a set of sampled networks, we apply this procedure on each of the individual networks, each yielding a set of transcript-loci linkages. precision-recall curves were generated from the totality of the individual networks . we compare this approach to traditional univariate mapping utilizing a t-test. we note that while there are several recent clustering-based methodologies related to eqtl mapping  <cit> , they do not attempt to reconstruct gene networks. since gnr is our primary goal, we restrict our analysis to the three versions of bayesian networks and traditional univariate mapping.

figures  <dig>   <dig>  and  <dig> depict the performance enhancements associated with bayesian networks as compared to traditional univariate mapping for the datasets with stronger correlation structure and containing  <dig>   <dig>  and  <dig> samples. all three methods utilizing bayesian networks resulted in performance gains over traditional univariate mapping. however, the performance gains associated with the sct-augmented bayesian networks were greater, providing 10-fold gains in recall in the precision range of  <dig>  to  <dig> . performance gains for datasets with weaker correlation structure  are largely consistent with those obtained on datasets composed of stronger correlation structure, though the performance on the dataset composed of  <dig> samples  only provides a roughly 3-fold gain over traditional univariate mapping.

robustness of network reconstruction
as outlined in the methods section, we assess convergence and reconstruct consensus networks from two independent mcmc runs, each consisting of  <dig> million iterations. however, an additional test for robustness involves assessing the stability of edge frequencies across multiple mcmc runs. we follow the protocol outlined by zhu et al.  <cit> , whereby all edges above a predefined frequency threshold are extracted for five individual mcmc runs. additional file  <dig> figures s1a-s1c provide the network reconstruction stabilities for datasets of weaker correlation structure and  <dig> samples, presented for each of the three methods:  unaugmented,  lcms-augmented, and  sct-augmented bayesian networks. we adjusted the frequency threshold that determines the consensus network; the values are:  <dig> ,  <dig> , and  <dig> . for each method and for a given threshold, we first quantify the number of edges that occur in at least one of the five runs, denoted as t. t is the cardinality of the superset of consensus edges derived from the union of the individual sets corresponding to the five runs. we plot count/t for values of x = { <dig>   <dig>   <dig>   <dig>  5}, where count indicates that an edge is present in the consensus networks in each of the  <dig> mcmc runs. at the highest threshold of  <dig> , each of the three methods showed robustness to where at least 80% of the total edges are present in the consensus networks for all  <dig> mcmc runs. these findings are consistent with those of zhu et al.  <cit> . finally, additional file  <dig> figure s1d depicts the number of edges that are recalled in all five mcmc runs at the three thresholds. the results suggest that our method offers relatively higher consistency across sampled networks.

possible explanations for increased performance
there are two likely reasons for the enhanced performance associated with our sct method. the first and most obvious reason is the increased coverage associated with the sct method. the second reason is attributable to better resolution of ordered triplets. for example, consider the hypothetical sequential triplet influenced by a single locus: l <dig> → ti → tj → tk. the lcms procedure will generally establish the following relationships: ti → tj, ti → tk and tj → tk. one practical limitation of this approach is that it does not usually prefer the motif tj → tk over ti → tk. that is, both pairwise orderings are likely with respect to the locus l <dig>  in contrast, our method does not rely on a fixed anchor , and is capable of discriminating between potentially confounding motifs of this nature. this is due to the fact that, while both transitions of ti → tj and ti → tk are likely for our sct method, the best scoring alignment corresponds to the true configuration, which will often be realized as the average configuration over multiple runs. in general, finding the optimal configuration will be self-perpetuating when various ordered triplets are interconnected, as the learning of causal relationships at lower rungs is clearly dependent on correct alignments in the upper levels.

discussion
we presented methodology aimed at utilizing genotypic data for the task of gene network reconstruction on eqtl datasets. our method is motivated by previous studies focused on the same goal, however, we are able to provide improvements in coverage and resolution. furthermore, with enhanced network reconstruction accuracy, we show that sampling a set of networks is efficacious at eqtl mapping. although we followed established protocols for simulating eqtl data, it's inevitable that the simulated data does not perfectly model natural eqtl data. for example, our model omits feedback loops, though such motifs are common in real gene networks. furthermore, we clearly are unable to model cases where genetic variations are associated with amino acid substitutions without corresponding expression changes. other situations that we are unable to model include post-translational modifications, such as protein-phosphorylations and other mechanisms affecting protein concentrations. it is worth noting that, since our model is generally more complicated than univariate mapping techniques, it stands to reason that univariate mapping might be less sensitive to discrepancies between the model used in our study and real eqtl networks.

future work involves applying our methodology to datasets that incorporate macroscopic phenotypes, including medical conditions and responses to pharmacological treatments  <cit> . reconciling variations in macroscopic phenotypes with genotypic and expression variations is an emerging problem that is poised to yield great insights into the molecular bases of complex phenotypes. already methods exist that focus on predicting the outcome of pharmacological treatments in the yeast eqtl dataset  <cit> . while the prediction of such outcomes are useful, we posit that accurate classification of an outcome is better viewed as a constraint within the general problem of learning a causal network. this formulation is more holistic and requires that learned networks agree with the classification of the macroscopic phenotype. given that complex macroscopic phenotypes are often connected to several loci at relatively weak levels, our sct method offers potential for this class of problems due to its ability to causally connect distal nodes in a network. other possible applications include association studies, which carry an added degree of difficulty due to the genotypic heterogeneity associated with population-wide samples.

there are several possible ways in which our approach can be optimized. for example, we plan to investigate the use of iterative procedures, where information from prior runs is incorporated into subsequent runs to improve accuracy. with respect to the general area of bayesian network structure learning, it would be interesting to consider integrating the causal ordering information from our method with other sources of prior biological information, such as protein-protein interactions or gene ontology  annotation  <cit> . such lines of inquiry should be feasible in light of the recent development of principled ways of incorporating prior information  <cit> . finally, we note that our method utilizes parameters that are optimized a priori to structure learning. while this straightforward approach is able to provide appreciable performance improvements, further benefits might be realized by optimizing the parameterization of our method jointly with the beta parameter in the structure learning procedure; methodology addressing joint optimization problems in the context of bayesian network structure learning was recently presented by werhli et al.  <cit> .

CONCLUSIONS
we developed a probabilistic method based on stochastic causal trees to learn the causal relationships between gene transcripts in genetical genomics studies. incorporating the information from our method as a prior into bayesian network structure learning increases the performance of network reconstruction and eqtl mapping.

