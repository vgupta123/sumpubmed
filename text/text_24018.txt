BACKGROUND
high-dimensional genomic data are becoming increasingly available to assist in the identification of genetic factors for complex diseases such as lung cancer. in particular, genome-wide association studies  have implicated a variety of genetic variants in many diseases, while only a small fraction of phenotypic variation was explained by those. this suggests that multi-locus gene-gene or gene-environment interactions must be considered  <cit> .

gene-gene interactions could be detected using a variety of methods  <cit> . for example, multifactor dimensionality reduction  is a non-parametric and model-free method that does not require any assumption of genetic mode of inheritance. however, mdr is inefficient in handling large scale genetic datasets  <cit> . penalized regression methods such as least absolute shrinkage and selection operator   <cit>  and smoothly clipped absolute deviation   <cit>  are also widely used for high-dimensional data. lasso is a useful tool for detecting gene-gene interactions with a broad range of simulations  <cit> . scad penalty has an oracle property, and thus it is more consistent with the actual effects than lasso  <cit> . the cross-validation is usually used for the choice of the amount of regularization in penalized regression methods , but it often includes too many noise variables. in an attempt to minimize such a problem, a modified lasso penalized method, stability lasso , has been proposed to unify optimal shrinkage and variable selection in gwas . stability selection controls false discovery rate and renders cross-validation practically unnecessary. alexander and lange  claimed that slasso could accurately identify the most important regions of gwas, but in a simulation study slasso offers less power than the simpler and less computationally intensive methods of marginal association testing  <cit> .

it has been shown that the lasso penalty could produce a bias even in the simple regression setting due to its linear increase of penalty on regression coefficients. to remedy this bias issue, a non-concave penalty such as scad penalty was proposed. scad has the so-called oracle property, meaning that, in the asymptotic sense, it performs as effectively as if an analyst had known in advance which coefficients were zero and which ones were nonzero  <cit> . scad is capable of achieving the sparse estimator in combination with smaller biases in linear regression than lasso. here, we propose a new stability selection procedure in combination with scad penalization . the new method was compared to slasso using systematic simulations and a published gwas study.

methods
ethics statement
this collaborative study was approved by the institutional review boards of china medical university, tongji medical college, fudan university, nanjing medical university, and guangzhou medical college with written informed consent from all participants.

penalized logistic regression for case-control gwas
let yi denote the disease status of the individual i :  <dig> for case and  <dig> for control. the snp of individual i, xij, is formatted as the count of a particular allele  where j =  <dig> …,m. the logistic model below includes snp-snp interaction terms:

  yi∼binominal <dig> πi,logπi1-πi=β0+∑j=1mβjxij+∑j<kξjkxijxik,i= <dig> ⋯n, 

where xij and xijxik are main effect and interaction features, respectively.

penalized likelihood method makes the fitting of a logistic model with small-n-large-p computationally feasible. it also provides a mechanism for feature selection. l denotes the likelihood function of the above logistic model , where θ consists of those β and ξ. the penalized log-likelihood function takes the form

  lpθ=-2loglθ+∑jpλθj, 

where pλ is the penalty function characterized by a tuning parameter λ. the following penalty functions are used in lasso and scad, respectively:

 lassopenalty:pλθj=λ|θj|,scadpenalty:pλ'θ=λ1|θ|≤λ+aλ-|θ|+a-1λ1|θ|>λ, 

where a is a fixed constant larger than  <dig>  the notation + stands for the positive part, and  <dig> denotes the indicator function.

when the penalized logistic regression model is fitted, a predetermined number of the components of θ can be forced to zero by tuning λ to a certain value. for a specific variable, estimation of the coefficient is non-zero if the coefficient exceeds the threshold or equals to zero. thus the selection of tuning parameter is a crucial step at the application of penalized likelihood. this is usually accomplished with cross validation. we used cross validation predictive area under the roc curve to choose the appropriate tuning parameter.

lasso and scad with cross-validated tuning parameter selection often lead to the inclusion of too many noise variables for high-dimensional data  <cit> . for variable selection in small-n-large-p genomic data, choosing the amount of regularization is more challenging than predicting where a cross-validation scheme can be used. a false variable in variable selection may lead to apparent association with a disease phenotype either through chance or correlation with the true variables. studies using high-dimensional data often need to be validated due to false variables. another practical issue here is reducing false variables while maintaining the power to detect relevant variables. to address this problem, meinshausen and bülmann  <cit>  proposed a stability selection procedure that is relatively insensitive to the choice of tuning parameter  <cit> .

in the current study, scad was used in variable selection in each sub-sample, and then stability selection was used to identify consensus ensemble of solutions.

stability selection procedure
a) meinshausen and bülmann  stability selection methodology

stability selection seeks to identify the non-zero entries s = {k:θk ≠ 0} of a sparse parameter vector in above penalized logistic regression model . assuming that the set i is a uniform random sub-sample of the index set { <dig> …,n}, the index set was used to subsample from the data to yield a subset z. for the subset and a given regularization parameter λ ∈ Λ, penalized regression procedure was used to yield an estimate of θk, i.e., θ^kλi. selection variable set was denoted as

 s^λi=k:θ^kλ≠ <dig>  

the conditional selection probability of the k-th covariate was defined as

  Π^kλ=pk∈s^λi|x,y. 

the selection probabilities were naturally estimated by monte carlo method averaging over b times independent sub-sampling. variables with high selection probabilities were retained, while those with low selection probabilities were discarded. for a cut-off πthr with 0 < πthr <  <dig> and a set of regularization parameters Λ, the stable selection variables set was defined as

  s^stable=k:maxλ∈ΛΠ^kλ≥πthr. 

the basic idea of the stability selection is to repeat the feature selection process in many randomly perturbed subsamples , and to include features that are relevant to majority of the subsamples. the baseline of the stability selection procedure is explained below:  

given a cut-off, compute the stable selection variables set s^stable=k:maxλ∈ΛΠ^kλ≥πthr.

the threshold value πthr is a tuning parameter whose influence is very small. in principle, the tuning parameter of mb is based on the following theorem  <dig> of meinshausen and bülmann.

theorem  <dig> . assuming that the distribution of 1k∈s^λ,k∈n is exchangeable for λ ∈ Λ, and the original procedure is not worse than random guessing. let qΛ be the average number of selected variables, qΛ=e|∪λ∈Λs^λi|, the expected number v of falsely selected variables is then bounded for πthr ∈  ev≤12πthr-1qΛ2p. 

b) improvements of the mb stability selection

in the current study , the primary goal was controlling the false discovery rate :

  fdr=ev/s^stable≈ev/qΛ≤12πthr‒1qΛp=12πthr‒1qΛm+mm‒1/ <dig>  

an advantage of the stability selection is that the choice of the regularization parameters Λ does not have strong influence on the results, as long as λ is varied within a reasonable range  <cit> . to control fdr, we first chose a fixed regularization region Λ, and then chose the selective probability threshold πthr according to the above inequality .

we set a fixed regularization region as Λ = , which was decided by the number of selected variables q as follow: λmax corresponded to the variable that first entered the regularization path and λmin was chosen such that the first q variables that appeared in the regularization path, mathematically, λmin was chosen such that ∪λmin≤λ≤λmaxs^λ≤q. the value of q was chosen a priori to yield a non-trivial bound , i.e. q=o2πthr-1p). the choice of q in stability selection does not have a strong impact on the fdr <cit> . we used a conservative estimate of q  in the discovery stage.

for the fixed regularization region, we applied the scad procedure to every subsample. qΛ=e|∪λ∈Λs^λi| was estimated via the monte carlo simulation averaging over b times independent sub-sampling. the threshold value πthr was solved while maintaining fdr ≤ α according to the expression  as

  πthr=1+qΛpα/ <dig> ifqΛ≤pα. 

unfortunately, given the nature of genetic data, the exact hypotheses required by the theorem of meinshausen and bülmann are unlikely to hold  <cit> . in particular, the exchangeability assumption of theorem  <dig> about the indicator random variables 1k∈s^λ,k∈n is questionable due to the correlations among the markers induced by linkage disequilibrium. we worried that the false positives of stability selection might be grossly wrong in our genetic data. so we adopted the method described in alexander and lange  <cit>  to make a rough check on the false discovery rate of stability selection. we randomly permuted the phenotype vector y for all participants, firstly. we then performed the stability selection procedure on the permutation sample and obtained the selection probability of the variable corresponding to the maximum test statistic in the association analysis, and finally compared the selection probability with the cut-off calculated from the theorem of meinshausen and bülmann.

data simulation
sscad selection procedure was compared with lasso, scad, and slasso under a variety of interaction models.

genotype simulation
hapgen  program  <cit>  was used to simulate genotype information. the simulation parameters for snp frequencies and variance structure were extracted from hapmap <dig> jpt + chb that includes snps located within ±20-kb of abcc <dig>  at 13q <dig>  the legend file for the snp markers, and the fine scale recombination rate were downloaded from the hapmap website . after quality control,  <dig> common snps remained . the linkage disequilibrium  pattern is shown in figure  <dig> 

phenotype simulations
genetic interaction model was applied for case/control phenotypes simulations. during the phenotype simulation, we took m = <dig>  and randomly selected causal snps from different haplotype blocks. the blocks were computed through haploview v <dig>  by standard expectation-maximization algorithm  <cit> , which partitioned the region into segments of strong linkage disequilibrium . a total of  <dig> blocks were generated with a minimum size of  <dig> markers and a maximum size of  <dig> markers. all the causal snps and snp-snp interactions were assumed to improve the risk ; wherein we let yi denote the phenotype value of subject i, which is obtained according to the logistic regression model .

we conducted simulations to evaluate selection performance of the lasso, scad, slasso and sscad procedures under the following scenarios:

. the interactive snps have no main effects:

βj =  <dig> for all j, and ξjk ≠  <dig> for some randomly chosen j, k.

. only one snp in the snp-snp interaction pair has a main effect:

ξjk ≠  <dig> and βj ≠  <dig> for some randomly chosen j, k.

. both interactive snps have main effects:

ξjk ≠  <dig>  βj ≠  <dig> and βk ≠  <dig> for some randomly chosen j, k.

the odds ratio parameters are shown in table  <dig>  since there are only a few etiological loci - only a few of the coefficients in the model are nonzero - the phenomenon is referred to as being sparse.

abbreviations: abcc <dig> atp-binding cassette sub-family c member  <dig>  or odds ratio, snp single nucleotide polymorphisms.

for every simulation scenario of phenotype in table  <dig>  the phenotype yi was generated based on the simulated snps by hapgen  <dig> using the above-mentioned logistic regression model . we simulated the population with an equal number of cases and controls  with  <dig> replicate data sets, and then  <dig>  cases and  <dig>  controls were randomly sampled from the population to form one sample set. next, we performed different variable selection methods for each sample set.

simulated data analysis
r software  was used to perform the simulation. the package “glmnet” and modified package “ncvreg” were used for lasso and scad analysis, respectively. for stability selection, we chose b =  <dig> times independent sub-samples with a size of  <dig> cases and  <dig> controls from each 1000- <dig> cases-controls sample set.

application
the study subjects were from an ongoing two-center  gwas of lung cancer in china. at recruitment, written informed consent was obtained from each subject. the study was approved by the institutional review boards of each participating institution. the details of population and other related information were described previously  <cit> . a systematic quality control procedure was applied for both snps and individuals. snps were excluded if they did not map on autosomal chromosomes, with minor allele frequency <  <dig> , with call rate < 95%, with p < 1 × 10- <dig> for hardy-weinberg equilibrium in combined samples of two studies or p < 1 × 10- <dig> in either the nanjing or beijing study samples. we removed samples with a call rate of < 95%, ambiguous gender, familial relationships, extreme heterozygosity rate, and outliers. briefly, there were  <dig>  cases and  <dig>  controls in the nanjing center,  <dig> cases and  <dig>  controls in the beijing center after quality control.

a multi-stage strategy is often used for detecting interactions on a genome-wide scale. the method proposed in the current study could not be directly applied to genome-wide scale snps data since it is too computationally intensive to exhaustively search for all snp pairs. a filtering method could be helpful, as explained below using the achpathway pathway . this pathway is one of the top pathways associated with lung cancer risk in the han chinese population. several studies have shown that the nicotinic acetylcholine receptors can induce cell proliferation as well as angiogenesis  <cit> . the achpathway pathway includes the genes pik3r <dig>  ptk2b, ptk <dig>  akt <dig>  pik3cg, faslg, musk, chrng, rapsn, bad, foxo <dig>  tert, chrnb <dig>  pik3ca, src and ywhah. all snps are mapped into genes within 20 kb downstream or upstream. all together, there are  <dig> common snps. we conducted an exhaustive search  of two-way interaction in the pathway. covariates including age, gender, pack-year of smoking, and the first two principal components, which have been proposed to sufficiently adjust for population stratification derived from eigenstrat  <dig>   <cit> , were adjusted in the stability selection procedure  <cit> .

to increase confidence in the selection of significant interactions from tens of thousands of snp pairs, interactions findings often need to be replicated in independent studies. we adopted a two-stage strategy in the current study. in the initial discovery stage, we used slasso and sscad to select significant snp-snp interactions using the data from the nanjing center. in the replication stage, the findings in the initial step were validated using the data from the beijing center with slasso and sscad. a slight variation was made to calibrate the significant threshold for the replication phase .

the snp pairs were selected using the following criteria:  the interaction had the selection probability πl ≥ πthr <dig> in the nanjing study, while in the beijing study the selection probability was πl ≥ πthr <dig> ;  the nanjing and beijing centers both demonstrated identical direction of odds ratios for the two snps, with their interaction derived from penalized logistic regression.

RESULTS
result of simulation
we evaluated the performance of different variable selection procedures using four established statistical indexes, including the true positive rate :

 tpr=tptp+fn, 

the mathhews correlation coefficient   <cit> :

 mcc=tp×tn-fp×fntp+fptp+fntn+fptn+fn, 

the estimated area under the roc curves   <cit> :

 auc=1t0p-t0∑u=1t0∑v=t0+1pip^u>p^v+12ip^u=p^v, 

and the estimated false discovery rate :

 fdr=fpfp+tp, 

where tp and tn stand for true positives and true negatives, fp and fn stand for false positives and false negatives, respectively. p^u is the selection probability of the u-th predictor and the first t <dig> variables are assumed to be true signals. the index tpr is known as sensitivity, whereas mcc is generally regarded as a balanced measure for both sensitivity and specificity, auc summarizes overall prediction performance, and fdr is a criterion to measure and control the number of false positives for the class-skewed high-throughput data  <cit> . the indexes tpr, mcc and auc are used to measure the power of detecting interactions, while fdr is primarily used to assess false positives of detection.

the simulation results of different procedures for the three kinds of scenarios are summarized in tables  <dig>   <dig> and  <dig>  all indexes are presented as average and standard error using  <dig> replications. the simulation results based on the tables  <dig>   <dig> and  <dig> are described from the following two perspectives.

abbreviations: tpr true positive rate, mcc matthews correlation coefficient, auc area under the roc curve, fdr false discovery rate.

numbers in each cell represent mean  by  <dig> times simulation.

abbreviations: tpr true positive rate, mcc matthews correlation coefficient, auc area under the roc curve, fdr false discovery rate.

numbers in each cell represent mean  by  <dig> times simulation.

abbreviations: tpr true positive rate, mcc matthews correlation coefficient, auc area under the roc curve, fdr false discovery rate.

numbers in each cell represent mean  by  <dig> times simulation.

. slasso/sscad has lower false discovery rate than lasso/scad while possessing similar auc
it appears that slasso and sscad have lower fdr⌢ for identifying interactions in comparison to lasso or scad. contrary to lasso and scad which generated unacceptably high fdr⌢ in all scenarios, both slasso and sscad controlled fdr⌢ at an acceptable level. in regards to predictive auc, there was no difference in stability selection procedures that being its inclusion or exclusion. in other words, slasso or sscad achieved a higher specificity than other procedures despite the similar diagnostic accuracy of auc.

. sscad has more robust power against slasso among different interaction models
given an acceptable fdr⌢ level, we compared sscad with the slasso procedure in the detection of snp-snp interactions. slasso lost its ability to rapidly detect interactions as the reduction of the main effects from the scenarios c1/c2/c <dig> to scenarios b1/b2/b <dig> and a1/a2/a <dig>  sscad, on the other hand, possessed robust detecting power under all scenarios. for the scenario a1/a2/a <dig>  in which the model only included the snp-snp interaction without any main effects of snps, sscad was more powerful than slasso. an exemplification of this can be seen in scenario a <dig>  in which the criteria of measuring the power of variable selection procedures echoed the trend: therein the tpr of sscad was  <dig> %, while the one of slasso was only roughly  <dig> %. likewise, mcc and auc were also both higher with sscad than with slasso.

the underlying interactions were better detected with slasso in the scenario c <dig> where the corresponding main effects were not too small . slasso possessed slightly higher tpr, mcc and auc than sscad in the scenario c <dig>  sscad was more powerful than slasso in the scenario c2/c <dig> where the corresponding main effects ranged from small to moderate .

generally speaking, the scad penalty has an edge over lasso in selection features, namely those where the selective features are more consistent with their actual effects. the lasso penalty may introduce more false interactions than the scad in the sparse high-dimensional models. thus, slasso loses more true positives than sscad when controlling fdr estimation of stability selection at the desired level.

overall, since the underlying interaction model is generally unknown, and a wide range of interaction models without marginal effects do exist  <cit> , sscad is a valuable tool for discovering interactions without main effects and complement slasso in gwas.

result of application
two snp-snp interactions were significant in both the discovery and replication phases by slasso , and four snp-snp interactions were significant in both phases of sscad selection. sscad contained all significant interactions identified by slasso. when using sscad, the two pairs  were shown to have significant interactions in both the discovery and replication populations. in contrast, neither of two pairs was validated as significant in the replication phase with slasso.
s
lasso and 
s
scad under subsampling


a


Π
b
Π
Π

s
s
s
s
s
s
aΠ represents the empirical selection probability of snp pairs under subsampling.

bp stands for the trend test p-value for simple marginal logistic regression.

cthe significant snp pairs under stability selection are coded by  to indicate its selection probability being higher than the threshold value .

for the slasso procedure, there were ten significant  two-way snp-snp interactions in the nanjing discovery study . among these ten snp pairs, two were selected  in the replication phase . both snp-snp interactions  were verified in the replication phase. in an overall analysis that included discovery and replication datasets , the empirical selection probabilities of rs7839119-rs <dig> and rs3781626-rs <dig> interactions were  <dig>  and  <dig> , respectively; thus, indicating little statistical significance .
s
lasso

a

Π
nanjing study 
s
aΠ represents a predictor’s empirical probability of model inclusion under  <dig> times subsampling.
s
lasso

a

Π
beijing study 
s
aΠ represents a predictor’s empirical probability of model inclusion under  <dig> times subsampling.

under the sscad procedure, all four significant snp-snp interactions  were successfully replicated . the empirical selection probabilities of rs7839119-rs <dig>  rs3781626-rs <dig>  rs7839119-rs <dig> and rs2736100-rs <dig> interactions in the overall analysis, which included all  <dig>  subjects, were  <dig> ,  <dig> ,  <dig>  and  <dig> , respectively. in turn, these results indicate statistical significance .
s
scad

a

Π
nanjing study 
s
aΠ represents a predictor’s empirical probability of model inclusion under  <dig> times subsampling.
s
scad

a

Π
beijing study
s
aΠ represents a predictor’s empirical probability of model inclusion under  <dig> times subsampling.

we also included the result of one permuted data set from the total  <dig>  subjects combined. the selection probabilities of the slasso and sscad were  <dig>  and  <dig> , respectively. this corresponds to the maximum value of the test statistic for the permutation set. the cutoffs obtained from above inequality  for slasso and sscad with the significance  were  <dig>  and  <dig> , respectively; thus, suggesting that the fdr calculated from the meinshausen and bülmann theorem is conservative. there appears to be little danger of selecting grossly inaccurate fdr when applying the meinshausen and bülmann theory.

discussion
identifying interactions among multiple snps is both statistically and computationally challenging in large-scale association studies. the challenges include high-dimensional problems, computational capability, multiple testing problems, and genetic heterogeneity  <cit> . many stochastic and heuristic detecting epistasis methods  <cit>  could be used to analyze gwas dataset. wang et al. used antepiseeker, a two-stage ant colony optimization algorithm , to identify epistasis  <cit> . wan et al. proposed snpruler  <cit>  based on both predictive rule inference, and two-stage design. boolean operation-based screening and testing   <cit>  involves only boolean values, and allows the use of fast logic operations to obtain contingency tables. team  <cit>  exploits properties of test statistics to mitigate multiple testing problems. to date, there appears to be no one method free from model sensitivity.

in addition to non-parametric and model-free methods, many lasso-based penalized parametric methods provide the estimation of parameter as the dimensionality increases, even if the number of variables is greater than the sample size. the coefficients of those none disease-associated snps will be zero in the penalized multivariate regression model. thus, detecting interactions is equivalent with the variable selection problem under the framework of regression analysis. a broad range of simulations has demonstrated that the penalized regression method is a useful tool for detecting gene-gene interactions. however, the regularization choice in penalized regression is usually made by cross-validation that maximizes predictive accuracy in finite samples; although it does not necessarily induce the correct sparseness pattern for variable selection  <cit> . in our simulations, cross-validation often leads to the inclusion of too many noise variables, and induces instability of variable selection for the ordinary penalized regression method, such as lasso or scad. a major hurdle for studying interactions in gwas is the lack of efficient algorithms that can map different forms of interactions while keeping fdr under control  <cit> . slasso introduces stability selection into traditional lasso. the stability selection procedure combines selection algorithms for high dimensional problems by sub-sampling. slasso dramatically reduces the number of false discovery rate, and could accurately identify crucial regions of gwas; however, it is overly conservative, and may miss some important regions.

sscad procedure increases the power of detecting the interactions while controlling fdr. it attempts to provide more true interactions, but less noise terms than slasso. the above advantage could be attributed to the fact that running the lasso-penalized procedure within stability selection results in more false positives than scad for each random sub-sample. thus, the interactions causing noise as well as true interactions in the region both satisfy the threshold condition πthr for selection. to control the number of falsely selected variables, the threshold must be very stringent. as a result, the slasso selection suffers a loss of power.

we analyzed a previously reported lung cancer dataset in han chinese, and confirmed significant interactions in the achpathway pathway, which supported the appropriate use of the proposed method. the observation of interactions between two closely located snp pairs supports the hypothesis that some genetic variation in complex traits may hide in interactions between linked snps  <cit> .

application of the proposed procedure to gwas data may ensure that the power of detection is reduced when over-stringent threshold πthr conditions exist for the much increased ratio of snps to samples. a good alternative to derive genome-wide significant threshold is permutation. unfortunately, genome-wide permutation in real gwas of interactions is computationally prohibitive for the sscad selection. partial search strategies based on biological knowledge  <cit>  or the filtering of unimportant snps prior to analysis  <cit>  could be adopted to reduce excessive computing burdens in early stage of genome-wide scale. these strategies are also necessary for the proposed method.

under our current approach, high-dimensional data were primarily managed with sparse models. high correlations  >  <dig> with other markers) were excluded. the chip data were pruned, and then analyzed with regression model method using a sparse constraint. many common diseases may be associated with many snps with small to moderate effects. in this situation, we are considering group penalized methods in another paper.

CONCLUSIONS
we developed a variable selection procedure . this procedure could control the fdr while maintaining the power to detect snp-snp interactions in association studies. in the pure interaction model, this procedure seems to overcome the conservativeness of slasso. the end result is that sscad, as a new technique in detecting interactions, can benefit the selection of slasso.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
jg performed the simulations, participated in the data analysis, and prepared for the manuscript. yz participated in the design of simulations, and helped to draft the manuscript. yw helped to perform the simulations. rz, yq and pz participated in the data analysis. cw, tw,dy,wt, zh, dl and hs acquired the data. fc conceptualized the study. all authors read and approved the final manuscript.

acknowledgments
the authors thank all of the study participants and research staff for their contributions and commitment to this study. this work was founded by the national natural science foundation of china , key grant of natural science foundation of the jiangsu higher education institutions of china , the priority academic program development of jiangsu higher education institutions , and the research and the innovation project for college graduates of jiangsu province . we also appreciate the editor and two anonymous reviewers for their valuable suggestions.
