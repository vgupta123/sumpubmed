BACKGROUND
during the last decade microarray technology has become an increasingly popular tool for gene expression profiling. microarrays have been used in numerous biological contexts from studies of differentially expressed genes in tumours  <cit>  to identification of cell cycle regulated genes in yeast  <cit> . a theme in microarray investigations is that they generate large amounts of data, and computer-based visualization and analysis tools must be used in experiment analysis. tools such as hierarchical clustering  <cit> , multidimensional scaling  <cit> , and principal component analysis  <cit>  are frequently used to visualize data. machine learning methods like support vector machines  <cit>  and artificial neural networks  <cit>  have been used successfully to classify tumor samples. common for these methods is that they in their standard versions assume complete data sets.

however, data is usually not complete. data values may be missing due to poor printing of the arrays and consequently marked as missing during image analysis, but more common is that values are marked to be missing in a quality filtering pre-processing step. common filter criteria are to mark spots with small area, spots with noisy background, spots with low intensity, or combinations of these  <cit> . one strategy to keep data complete is to remove reporters having missing values, but this may lead to an unnecessarily large loss of data. in particular when working with large data sets, reporters rarely have a complete set of values over all experiments. another strategy is to keep reporters with not too many missing values and modify the subsequent analysis to handle incomplete data. however, it may not be feasible to modify the analysis tool, and therefore a popular approach is to impute the missing data in an intermediate step before analysis.

a common method to impute missing values is to replace missing values with the reporter average, i.e., the average for the particular reporter over all experiments. troyanskaya et al. showed that this method is not sufficient as it neglects correlations in data  <cit> . they also suggested a method knnimpute, that was shown to reconstruct missing values well. in knnimpute, for each reporter the most similar reporters are found and the weighted average of these reporters is used as the imputation value. other imputation methods have been suggested  <cit>  using the same basic idea that the imputation value is taken as an average over the neighbouring reporters.

as far as we know, all suggested imputation methods are binary in the sense that each spot is considered either missing or present. hence they depend on a cutoff, e.g., in intensity, separating poor spots from good spots. tuning this cutoff is a balance act – a too liberal cutoff means noisy spots are kept in data, which may complicate subsequent analysis. on the other hand being too strict means spots containing information are marked as missing values and information is thrown away.

we suggest a more balanced approach, in which a spot quality weight is built into the imputation methods: good quality spots have more impact on the imputation of other spots, and are themselves subject to less imputation than spots with poorer quality. to examine the effects of this approach we extended two widely used methods, average imputation and knnimpute  <cit> , to handle continuous weights. we applied the two resulting methods to three data sets containing replicate measurements and found that weighted methods perform better that non-weighted.

RESULTS
as outlined in the methods section, we devised two imputation methods using spot quality weights. these methods are generalizations of two non-weight based methods and we evaluated the methods with replicate data sets. we used the mean squared deviation  to compare the performance of the two suggested methods, their non-weighted counterparts, and lsimpute  <cit> . we did the comparisons varying the spot quality threshold for missing values for the non-weight based methods. correspondingly, for the weighted methods we varied the weight tuning parameter β in the calculations of the weights .

in figure  <dig> we present how the performance varied with a changing β in the three data sets. the plots show that wenni has the lowest msd for all three data sets, the weighted methods outperform their non-weighted counterparts, and the minimum msd is within the β range  <dig> – <dig> for all methods.

the overall msd is larger for the melanoma data set compared to the two other data sets, which may be due to that the melanoma data was generated a few years earlier than the other data.

an interesting finding was that weighted reporter average outperformed knnimpute and lsimpute in the breast cancer and melanoma data sets. this result was unexpected since the weighted reporter average method neglects correlations between reporters. moreover, the assumption for using reporter average is in general problematic, since the expression of a reporter in one experimental condition does not always reflect the expression of the reporter in another condition. for the mycorrhiza data used here the situation is even worse, since the cyclic experimental design  <cit>  makes the expression value in one experiment auti-correlated to the reporter's average over the other experiments. for the nearest neighbours imputation methods however this problem does not arise because imputations are calculated as an average over the same experiment. these results imply one should consider the experimental design and choose imputation method carefully.

for small β all methods showed approximately equal performance. this result was expected, because for small β most weights are close to unity. in consequence, only a small fraction of the spots are imputed and make a minor contribution to the msd. moreover, the weights are effectively binary for small β, and the weighted methods become identical to their non-weighted counterparts.

to examine the difference between the weighted methods and their non-weighted counterparts, we plotted msd as a function of snr . as expected, spots with small snr contributed most to msd. the discrepancy between mycorrhiza data and the other two data sets also showed up here – the breakdown of the reporter average methods in the mycorrhiza data is very prominent . the melanoma and breast cancer data showed very similar patterns for the different methods and the weighted methods performed better than their counterparts for all snr. in some ranges of snr, weighted reporter average even surpassed wenni, but overall wenni imputed the values most accurately.

in figure  <dig>  we demonstrate the effect of varying β for wenni and knnimpute using the breast cancer data. in knnimpute, only spots with smaller snr than the cutoff β are imputed, and consequently the performance for snr larger than β follows the no impute curve. for knnimpute a choice of β =  <dig>  was close to optimal. using a smaller β deteriorated the imputation in two ways. spots with snr between the used β and the optimal value  <dig>  were not imputed. in the plot we can see that the quality of these spots is so bad that preferably they should be imputed. more importantly, since these spots were not considered missing they were used in the imputation of values with very small snr, which made the imputation less accurate. moreover, when we used a too large β, the spots with snr in the range  <dig> – <dig> were imputed and their deviation from the replicate became larger than if they were not imputed. also, the imputation of the spots with very small snr became worse, since less information was used in the imputation. choosing β corresponds to setting a cutoff in quality control criteria, and figure  <dig> illustrates how a suboptimal cutoff level will lead to less reliable data. for wenni the cutoff is smoothened by the usage of continuous weights, and consequently wenni is more robust with respect to β.

in figure  <dig>  we illustrate how the performance of wenni and knnimpute depends on the number of neighbours, k, used in the imputation. we notice that both methods are insensitive to changing k. for a small number of neighbours, both methods are insufficient. troyanskaya et al. suggested k to be in the range between  <dig> and  <dig> neighbours for knnimpute  <cit> . our results agree with this finding and also show that the imputation of our data sets was accurate for a larger number of nearest neighbours.

when comparing non-weighted imputation methods, it is natural to calculate the comparison measure over imputed values only. including non-imputed values in the evaluation makes no sense, as these values are not modified and thus independent of the imputation method. this is also the way imputation methods are compared in the literature  <cit> . however, for a weighted method every expression value is modified, and it is sensible to include all values in the calculation of msd. in table  <dig> we compare lsimpute.

knnimpute, and wenni using both msd and msd_imputed. msd_imputed is calculated as msd but over imputed values  only. we note that msd_imputed is larger than msd for all methods and data sets, which is expected because msd_imputed is calculated over poor spots only and poor spots are expected to deviate more from their duplicates. moreover, for msd_imputed the difference between the methods is more apparent, which is a consequence from comparing poor spots only. in msd all spots are included in the comparison and as good quality spots are modified to lesser degree, the difference between the methods looks smaller. we note that wenni is the most accurate method also using msd_impute, in other words. wenni has the best performance even when values not imputed by non-weighted methods are excluded from the comparison.

for the largest data set, breast cancer data with approximately  <dig> spots, a typical wenni run takes approximately  <dig> cpu minutes on a off-the-shelf computer , whereas knni is twice as fast. these two algorithms are implemented in the same c++ code base and differs only in the calculation of the imputation values. a comparison with lsimpute is not fair since lsimpute is an adaptive algorithm and is implemented in java.

spot quality weights and expression value imputation
the starting point for imputing expression values in this report is that the weight of a spot should depend on its quality, as best estimated from data. here, we used a straight forward snr based weight as it was not our aim to study quality of spots. the snr based quality weights were introduced in  <cit> , and many different studies of quality measures have been described  <cit> . these papers concentrate on studying how the quality of spots should be defined.

analyses in microarray projects are commonly based on spot intensities, and for that reason we examined if using intensities instead of snr changes the findings in this paper. we found that using this simpler quality weight , the performance was almost as good as when using the snr based weights . the fact that the imputed expression value on average gets closer to its pristine replicate value, indicates that the snr based weight may be a slightly better estimate of the spot quality.

in imputation of expression values, as in any transformation of data , one must be careful to not destroy the biological signal in the data. in our three data sets, we noticed that when wenni is used, the deviation from the pristine replicate is on average smaller than when not doing the transformation, in other world, on average an expression value is closer to its replicate after the transformation. the effect is measurable even for the naïve weight used here.

the goal of a weight is to catch the "true" quality of the spot, and as such it is important to define spot quality weight calculation to suit the data at hand, prior knowledge, and expertise. one important aspect of applying prior knowledge into weight calculation is that initial pre-screening of array data should still be done before imputation, or any subsequent analysis. in this screening step bad spots are removed, and known malfunction in data  should be communicated with zero weights.

CONCLUSIONS
virtually every analysis of microarray data is preceded by a filtering step, in which each spot is required to fulfil certain quality control criteria. if the spot fails to meet the quality requirements it is marked as a missing value. this is equivalent to accompanying each expression value with a binary weight, and enforces an abrupt cutoff in quality control criteria. we have generalised two widely used imputation methods to use continuous weights. our finding that the weighted imputation methods outperformed their non-weighted counterparts, suggests that using continuous weights is superior to using binary weights. our suggested improvement – to use continuous weights – is generic in the sense that most imputation methods can be generalised to use continuous weights.

the weighted nearest neighbours imputation method presented in this paper. wenni, outperformed all other tested methods for the three different data sets used in this study. wenni performs accurate imputation of expression values and is insensitive to the parameter values used, i.e., the number of nearest neighbours and β. an increasing β corresponds to having a more strict spot quality control criteria. for a non-weighted method it means that more values are considered missing and consequently imputed. our results suggest that the usage of a continuous weight makes the imputation less sensitive to the choice of β. the findings in this manuscript are based on comparisons of replicate data, however replicate data may not be available in every experimental setting and the scientific investigator cannot evaluate the impact of different parameter values. the results in this study show that the choice of parameters is not crucial, and suggest a value around  <dig> for nearest, neighbours and a β in the range  <dig> – <dig> 

