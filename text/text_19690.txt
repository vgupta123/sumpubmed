BACKGROUND
the challenges facing molecular systems biologists include the development of accurate mathematical models of complex biological processes  <cit> , the elucidation of design principles that control biological behavior  <cit> , and the generation of new insights into biology that are not apparent solely from experimental studies  <cit> . a common mathematical method to address these challenges is dynamical systems theory  <cit> , the use of nonlinear ordinary differential equations  to describe the way networks of biochemical reactions change in time. by comparing the temporal development of the model under conditions that simulate a variety of experimental protocols with the observed behavior of the biological system under the same conditions, one can evaluate how well or poorly the mathematical model performs.

our focus in this study is parameter estimation of a nonlinear and high-dimensional ode model  that is constrained by a large number of dissimilar experimental observations. the non-differentiable nature of our objective function  led to our choice of a stochastic global optimization approach  <cit>  that relies on an evolutionary search, namely differential evolution   <cit> , starting from a diverse population of parameter vectors scattered over a feasible region of parameter space. de is a popular global optimization method due to its efficiency and simplicity. however, we should mention that a recent novel  algorithm outperformed de in multiple optimization tasks with large scale systems biology models due to extensive local search capability  <cit>  that is lacking in the simplest form of de. for a recent comprehensive review regarding the application of de and other metaheuristic optimization techniques in systems biology, we refer the reader to  <cit> .

parameter estimation is not only about finding an “optimal” set of parameter values for fitting a collection of experimental observations. during the course of the global optimization procedure, we expect to find many different parameter vectors that do equally well  as the best one. working with this sample of “quite good” sets of parameter values, we can quantify how well the experimental data constrain individual parameter values. we can distinguish critical parameters  from irrelevant parameters   <cit> . we can distinguish those experimental results that provide the most information about the underlying model from those that provide the least, and we can design new experiments that will provide the most new information about the underlying molecular regulatory system  <cit> . all these types of information can be very useful in refining and extending the model  <cit> .

our research group has been interested for many years in the molecular mechanisms controlling the cell division cycle of budding yeast. the main events of the cell cycle  are controlled in budding yeast, and indeed in all eukaryotic cells, by a family of protein kinases called cyclin-dependent kinases   <cit> . we have built comprehensive and accurate models of the periodic activation of cdks, based on nonlinear odes describing the underlying biochemical reaction network  <cit> . the models are used to understand how cdks control cell cycle progression in normal  yeast cells, and also how cell cycle progression is altered in yeast strains harboring mutations in genes of the cdk control system. each mutant strain is characterized as “viable” or “inviable”. a viable mutant cell is able to grow and divide despite its altered control system, whereas an inviable mutant cell is blocked at some stage of the cell cycle and eventually dies. the wild type strain is, of course, viable.

in this study, we present an optimization procedure to maximize the number of strains for which the model correctly captures viability or inviability . our approach applies quite generally to exploring the parameter space of a high-dimensional ode model in order to maximize how well the model accounts for a large collection of experimental data, particularly in cases where the objective function may not depend smoothly on parameter values. we start with an initial region of parameter space  where we think a reasonable solution must lie. we use latin hypercube  sampling to provide a starting sample of parameter vectors, widely distributed over the initial hypercube  <cit> , that are consistent with “wild type”  viability. next, we use de that starts from this population of wt parameter vectors and searches for new combinations of parameter values that satisfy an ever larger number of experimental constraints . our approach not only produces a sample of parameter assignments that provide good fits to the collection of mutant phenotypes but it also provides insights about how the model can be reduced without compromising its ability to explain the experimental data. model reduction, parameter identifiability, and parameter sensitivity are critical, related concepts for the analysis and construction of models. relevant recent work regarding identifiability and model reduction in systems biology includes implementations of singular value decomposition to reduce models where parameter estimation is posed as a linear regression problem  <cit> , computation of confidence intervals by extensive parameter sampling to detect non–identifiable parameters  <cit> , and ranking of parameters by means of sensitivities  <cit> . recent reviews on identifiability of systems biology models can be found in  <cit> . our main contribution is a new methodology for model reduction in the absence of a continuous objective function, unlike the aforementioned works that use a continuous objective based on time-series data. we also propose a novel way to quantify the competition between individual experimental constraints and reduce their number to speed up the optimization process in the context of a discontinuous objective function.

methods
problem formulation
in this paper, we focus on biochemical reaction networks modeled by nonlinear odes. typical models of these networks that are considered high dimensional, at the present time, consist of 10– <dig> odes defined in terms of ∼ <dig>  rate constants and other numerical parameters. the models are developed in light of and the parameters are constrained on the basis of large collections of experimental data, which characterize the behavior of cells under a wide variety of experimental conditions. the data are rarely replicate measurements of time courses of biochemical variables; the sort of ideal data assumed in many optimization methods. rather, the data are often a disparate collection of quantitative measurements and qualitative observations on a number of different mutant strains under a wide variety of conditions. in this context, a data-fitting algorithm must be able to search a high-dimensional parameter space for parameter vectors that are consistent with as much of the data as possible. in our case, we characterize the data as a set of n constraints. for a specific parameter vector, the model either satisfies the ith constraint  or not , and the total objective function that we seek to maximize is o=∑i=1noi. the discontinuous, stepwise nature of this objective function prohibits the use of any gradient-based optimization method, even if multiple starting points are used. therefore, in looking for optimal behavior of the model, we search a region of parameter space stochastically and keep track of all parameter vectors encountered during this search.

using this collection of optimal  parameter vectors, our second aim is to characterize the roles of specific parameters and specific experiments in the data-fitting exercise. looking at the sensitivity of experimental constraints with respect to parameter variations, we distinguish “critical” parameters, which have strong effects on the total objective function, from “dispensable” parameters, which have little or no effect on the total objective function. we also distinguish “fragile” phenotypes, which are most often broken  under parameter variations, from “robust” phenotypes, which are correctly simulated even when parameter values are widely perturbed. these distinctions provide insights into the relationships between the model and the data, and they also allow us to reduce the complexity of the model  and the computational demands of the algorithm. finally, we look at competition  between experimental constraints . if two phenotypes compete with each other, then it is difficult for the model to account simultaneously for both. the list of most competitive phenotypes suggests places where the structure of the model may be incorrect or the experimental observations may be suspect.

a mathematical model of the budding yeast cell cycle
the cell cycle is the sequence of events by which a growing cell replicates all its components and divides them more-or-less equally between two daughter cells, so that the daughters inherit all the machinery and information necessary to repeat the process  <cit> . the most important components that need to be accurately replicated in the mother cell and precisely partitioned to the progeny cells are the dna molecules of the cell’s genome. new dna molecules are synthesized during s phase and distributed to progeny nuclei during m phase . s and m phases are separated by two gaps: g <dig>  and g <dig> . the ordered sequence of cell cycle phases, g1-s-g2-m, is governed by the periodic activation of cdks. activity of cdks depend on cyclins, which are regulatory proteins that are needed to form active cyclin-cdk complexes. in budding yeast, the earliest cdks to be activated are cln1- and cln2-dependent kinases, which promote the appearance of later cyclins as well as initiating bud emergence. clb5- and clb6-dependent kinases are essential for timely dna synthesis, and somewhat later, clb1- and clb2-dependent kinases arise to drive the cell into mitosis. to exit from mitosis and return to g <dig>  all the clb-cyclins must be cleared from the cell, which is the job of the apc  in conjunction with its partners, cdc <dig> and cdh <dig>  some other important components of the control system are: sic <dig> , cdc <dig> , net <dig> , sbf , mcm <dig> , and swi <dig> . all these molecules  are involved in a complex biochemical reaction network that controls the periodic activation and inactivation of the cdks  and cdc14-cdc20-cdh1-sic <dig> .

a mathematical model of this reaction network was developed by chen et al.  <cit> . this model consists of  <dig> ordinary differential equations  and reproduces the biological properties of ∼ <dig> mutant strains of budding yeast. the “properties” include not only viability-inviability of the strains but also average size of cells at division, relative timing of bud emergence, dna synthesis and mitosis, and the precise phase of arrest of inviable mutants. the chen- <dig> model evolved over the course of about  <dig> years, as the experimental basis of the model was being discovered by molecular geneticists and as the molecular interactions were translated into differential equations by the mathematical modelers. the parameter values “evolved” along with the model, so that at no time were the modelers faced with the daunting task of fitting a 135-parameter model to a 125-component objective function. in this study, we focus on a new formulation of the chen- <dig> model. this model  uses a simpler mathematical framework, requiring fewer odes  and kinetic parameters , while improving on the model’s representation of the g1/s transition and exit from mitosis. the starting set of parameter values for the optimization, produced by manual tuning, captured the basic cell cycle characteristics of wild type cells as well as the phenotypes  of ∼60%  of the genetic strains. our goal was to develop an automatic method for finding parameter values that capture nearly all the mutant phenotypes when starting from an educated “initial guess” of parameter values.

we provide descriptions of the  <dig> model parameters and  <dig> model variables  along with the numerical values of these parameters from the “initial guess” . we also provide a c++ subroutine that implements the model along with a matlab script , taking as input values the  <dig> parameters and  <dig> initial conditions for the model, and giving as output the phenotypes  of  <dig> budding yeast strains: wt growing in glucose + wt growing in galactose +  <dig> cell-cycle mutants growing in glucose or galactose. all  <dig> strains are listed in additional file 1: table s <dig> along with the parameter changes for each strain with respect to wt conditions. the c code solves the odes using euler’s method with a fixed step size of  <dig>  minutes. while there are certainly more sophisticated ode solvers, this solver was chosen because it easily handles both deterministic and stochastic cases, and also allows direct comparison with previous work on this model  <cit> . the code first simulates wt cells growing in glucose, using the  <dig> initial conditions provided on input , for a total of  <dig> min. if at any time during this simulation cell size  exceeds  <dig> units, the cell is considered inviable. otherwise, the program asks: is cell size at the last division is within 5% of the cell sizes at the two previous divisions? if “yes”, then the cell is considered as“viable”.  if the wt cell  is viable, then we record the initial values of all variables just after the last division of the wt cell. these values  are used for the simulations of all other  <dig> strains. each strain simulation is classified as viable or inviable by the same rules applied to the wt simulation. to calculate the value of the objective function for the given set of parameter values and input-ics, we then sum up  <dig> values of an indicator function that is  <dig> if the phenotype  of the simulated strain is the same as the observed phenotype, and is  <dig> if the phenotypes are different. the objective function is an integer-valued function that varies from  <dig> to  <dig>   finally, we introduce here the nomenclature of budding yeast genes and mutant alleles. proteins, such as cln <dig>  cdc <dig> and sic <dig>  are encoded by wild type genes: cln <dig>  cdc <dig> and sic <dig>  mutant alleles are indicated by lower case, italicized names: cln <dig>  cdc <dig>  sic <dig>  the notation sic <dig> Δ means the wild type sic <dig> gene has been deleted from the genome, and the notation gal-sic <dig> means that the wt sic <dig> gene is being expressed continuously at high level from a galactose-inducible promoter. the meaning of other gene notations used later in this paper can be found in chen et al.  <cit>  or on our budding yeast web page  <cit> .

the parameter estimation algorithm
we start our search of parameter space from a point supplied by the modeler . we assume that the starting point is a reasonable  estimate of the parameters. that is, the starting parameter values are consistent with some but not all experimental constraints, and we expect that a much better parameter vector is in the neighborhood. in our case, the initial guess is consistent with 60% of the mutant phenotypes, and we plan to search in a hypercube  around the starting point. first, we explore this domain by latin hypercube  sampling, as described in detail in the additional file  <dig>  . to obtain a “population” of prospective parameter vectors for the next phase of the search, we select from the lh samples only parameter vectors that are consistent with viability of wt cells growing on glucose.

for the second phase of the search, we use differential evolution  to improve the performance of the lh-derived population of parameter vectors  <cit> . the basic idea behind de is to allow a population of parameter vectors to evolve over many generations of reproduction and selection. during the reproduction step, each “parental” parameter vector generates an “offspring” parameter vector, which differs from the parent by a process of “diversification”. then, the parent and its offspring compete with each other: the better vector  goes on to the next generation, the less good vector is set aside.

to be precise, let x be a vector of parameter values, with components xi, i =  <dig> ,…,d, where d is the dimension of the parameter space. . as described in the previous section, the objective function o is an integer-valued function that counts the number of phenotypes that are correctly captured by the model given the parameter values in the vector x. .

during de, parameter vectors are propagated from generation to generation by processes of diversification and selection. each generation  consists of n parameter vectors xj, j =  <dig> …,n. hence, the real number xi,j is the value of the ith parameter in the jth parent in the tth generation. let uj be the parameter vector for the single offspring of the jth parent in the tth generation. the components of this vector, ui,j for i= <dig> …,d are constructed in two steps . then, given the two parameter vectors xj and uj, a decision is made as to which one is propagated to generation t+ <dig> 

the specific rules are: 

 <dig>  mutation: first, we create a “mutant” vector vj by perturbing a parental parameter vector xj: 

 vj=xj+f·dj. 

by analogy to biological evolution, we might let the components of dj be random perturbations of the parental parameter values. however, we use the strategy of de, letting the perturbation vector be the difference between the parameter vectors of two additional parents, j′ and j′′, chosen at random from the t-th generation of parents. . in this case, the “mutant vector” is defined by 

 vj=xj+f·−xj′′), 

 where  <dig> <f < <dig>  . with this definition, perturbations can be large at first, when the population of parental parameter vectors is diverse in terms of individual parameter values, but the size of perturbations will decrease in later generations as the population converges on a nearly common set of parameter values.

 <dig>  crossover: next we allow for crossover between the parental parameter vector xj and the mutant parameter vector vj. component-wise, the offspring vector uj receives a parameter value from the mutant vector with probability c  or from the parent vector with probability 1−c: 

 ui,j=vi,jif rand≤cxi,jotherwise 

 i= <dig> ,…,dandj= <dig> ,…,n, 

 where rand  is a random number chosen uniformly from the interval  <cit> . we choose c= <dig>  so that neither parental values nor mutant values are given an advantage during the crossover step.

 <dig>  selection: the objective function determines whether, xj or uj, passes on to the next generation. there are two possibilities here. the “greedy” algorithm says that the offspring replaces its parent if it is superior: 

 xj=ujifo)>o),xjotherwise. 

with the “non-greedy” version, the selection condition is o) ≥ o).

in a few hundred generations, de produces an elite set of parameter vectors that reproduce the behavior of nearly all the experimental constraints despite the suboptimal performance of the starting point of the optimization.

all computations were performed in the advanced research computing lab at virginia tech. the computational time was ∼ <dig> minutes for a single generation of de  and ∼ <dig> minutes for  <dig> lh samples . computation time could be significantly reduced by parallel computing, e.g.,  <dig> generations of de, which took ∼ <dig> hours in our code, could be completed in ∼ <dig> hour by using  <dig> processors in parallel. such a reduction may be important in the future when we impose additional constraints on the model.

in concluding this section we note that, in addition to varying the values of c and f, there are other diversification and selection strategies that could be implemented in de  <cit> . in this study we are served well by the most basic mutation and crossover strategies, with conservative values of c and f. investigation of the effects of varying c, f, and mutation and crossover strategies is beyond the scope of this paper.

RESULTS
rapid evolution to high-scoring parameter vectors
we performed lh sampling around the starting point  in a hypercube formed by ±40% perturbations on each parameter value. to create  <dig> sample points inside this hypercube, each parameter range is divided into  <dig> subintervals . of the  <dig> samples,  <dig> reproduced wt viability in glucose . these  <dig> parameter vectors were used as the starting population, xj,j =  <dig> …, <dig>  for the de algorithm . we use a greedy selection algorithm at first and see a steady increase in the objective function  during the evolution process, . here, the starting parameter vector gets  <dig> hits , and the best score among the original  <dig> parameter vectors generated by lh sampling was  <dig> hits. during de, the objective function increases by ∼50% to  <dig> hits. an independent de run  with the same initial population of parameter vectors, but a different sequence of random numbers used in mutation and crossover operations, reached  <dig> hits. this variability of success comes, presumably, from the stochastic nature of de and the highly nonlinear structure of our model.

varying the settings of the optimization procedure
the initial phase of lh sampling can be quite variable in its outcome. for example, when we resampled the ±40% hypercube around the initial guess with  <dig> lh samples, we found n= <dig> parameter vectors consistent with wild type viability in glucose. nonetheless, running de on this larger starting population did not make a significant difference in the final value of the objective function , see figure  <dig>  furthermore, when we generated  <dig> lh samples  without regard to wt viability, the de algorithm reached a maximum of  <dig> hits, indicating that the algorithm’s success is not highly dependent on the initial population’s ability to capture wild type viability in glucose. however, we should note that the center of the lh  is known to be a reasonably good starting point . hence, we can expect that there are good solutions to the optimization problem within the lh even if none of the initial  <dig> parameter vectors are particularly good. in fact, we formed four independent sets of  <dig> parameter vectors from the  <dig> vectors  that failed to reproduce wild type viability. for these four starting populations, de converged to  <dig>   <dig>   <dig>  and  <dig> hits in  <dig> generations.

we also investigated how the size of the lh affects the performance of de, by starting with hypercubes generated by ±20%, ±40% and ±90% perturbations around the initial guess. in each case, we started the de with a population of  <dig> parameter vectors generated by lh sampling without enforcing the viability of wild type cells in glucose. as illustrated in figure  <dig>  40% and 90% perturbations gave similar results after three de runs . on the other hand, 20% perturbations gave lower performance . in fact,  <dig> independent de runs  with 20% perturbations showed a similar trend , whereas 40% perturbations performed best . these results indicate that if there is not enough variability in the lh samples used to initiate de , then de performs suboptimally.

another variation in the algorithm is the criterion we use for deciding when a trial parameter vector can replace a parent. as shown in figure  <dig>  compared to the greedy selection criterion we have been using, non-greedy selection gives faster convergence to good solutions, although the final success of the two strategies is about the same. defining convergence as the first generation in a run when the algorithm reaches  <dig> hits, we find that greedy runs converge in ∼ <dig> generations  whereas non-greedy runs reach  <dig> hits in ∼ <dig> generations .

we also investigated the effect of the starting point on the performance of our optimization procedure. starting from the initial guess, we ran de for  <dig> generations without enforcing any improvement  and randomly picked a parameter vector from the last generation as a potential starting point. repeating this process two more times gave us three new starting points for optimization with  <dig>   <dig> and  <dig> hits. these new starting points differed from the initial guess by ∼25% across all parameter values. starting from these three points, we used both 40% and 90% lh sampling, followed by de with non-greedy selection. the success rates of these runs  indicate that the performance of our optimization procedure is not highly dependent on the quality of the starting point.

optimization results with different initial search points used in lh sampling.

a further variation of our parameter estimation study involved stopping de at a particular generation, grabbing the best population member, resampling around it with the lh approach and continuing de. here, we focused on the ten worst performing runs in additional file 4: figure s <dig>  the average number of hits among these runs was  <dig> , four less than the average of the  <dig> runs. when we performed lh sampling around the best performing population member within each run  at generation  <dig> and continued de for an additional  <dig> generations, the average number of hits increased to  <dig> . in comparison, continuing de for the same number of generations without any resampling led to an average of  <dig> . using the lh resampling approach after  <dig> generations  and continuing de for  <dig> generations carried the average number of hits from  <dig>  to  <dig> , which is approximately equal to the average from the  <dig> runs in additional file 4: figure s <dig>  on the other hand, continuing de for  <dig> generations without resampling resulted in an average of  <dig>  hits. from these results, we conclude that this resampling strategy is useful to improve suboptimal runs.

robustness of the model
as an indicator of the model’s robustness with respect to the phenotype of a particular yeast strain we introduce the “acceptance ratio” for an experimental constraint, which is simply the fraction of sample parameter vectors that are consistent with an observed phenotype  <cit> . for example, consider the  <dig> lh samples in figure  <dig>  the acceptance ratio of “wt viability in glucose” is 19%. that is, the model is not particularly robust at accounting for the viability of wt yeast cells if parameter values are chosen more-or-less randomly in a hypercube of parameter space, even if this box is known to contain quite good parameter vectors. since the acceptance ratio for wt viability among a small number of lh samples is known to be highly variable, we generated a set of  <dig>  lh samples in the ±40% hypercube. within this collection, “wt viability in glucose” has a 25% acceptance ratio.

by comparison, if we optimize overall success rate, then we find that wt viability is an extremely robust property of the model. for example, we maximize the total number of hits on a population of  <dig> parameter vectors over  <dig> generations, without enforcing wt viability in the lh and de stages. in the collection of  <dig>  samples , the acceptance ratio for “wt viability in glucose” was  <dig> .

for these three sample sets  we computed the acceptance ratios of all  <dig> experimental strains and sorted them in ascending order, as shown in figure  <dig>  comparing lh performance to de, we see the power of de to find regions of high overall model performance in parameter space. the set of  <dig>  trial parameter vectors generated during de is quite robust in accounting for most phenotypes . by contrast, for  <dig>  lh samples without any selection, only ∼ <dig> strains have an acceptance ratio greater than  <dig> . despite the inability of lh sampling to find very successful parameter vectors, the lh sampling step is essential to provide de with an initially diverse population that is able to evolve to high scoring parameter vectors. it is also apparent from figure  <dig> that most of the difficulties encountered by de are the consequence of eight strains with very low acceptance ratio . apparently it is very difficult to parametrize the model to fit any of these eight strains without disturbing the fit to many other strains, suggesting that there may be some missing interactions in the model, or there may be some mistaken phenotypes reported in the literature, or both.

competition between the experimental constraints
given the high dimensionality of the model, one may think that it is relatively easy to capture the biological behavior of the majority of the mutants  <cit> . however, that is not the case when mutant phenotypes compete against each other to be correctly simulated by the model, as suggested by the existence of eight “low acceptance” phenotypes in figure  <dig> . to quantify this competition, we keep track of the performance of the parameter vectors generated during the lh and de phases of the optimization procedure. with m as the total number of parameter vectors and n as the total number of phenotypes, we define the m×n acceptance matrix: 

 a=a <dig> a <dig> ⋯a <dig> na <dig> a <dig> ⋯a <dig> n⋮⋮⋱⋮am,1am,2⋯am,n, 

 where ai,j= <dig> if parameter vector i captures phenotype j, otherwise ai,j= <dig>  then, we compute the n×n matrix of correlation coefficients: 

 rk,l=ck,lck,kcl,l, 

 where ck,l is the covariance of the acceptance values of phenotypes k and l: 

 ck,l=1m−1∑i=1m. 

 here, a¯l is the acceptance ratio of phenotype l among m parameter vectors. rk,l quantifies the correlation between the kth and lth phenotypes. for each phenotype, we compute an overall correlation value r^k=∑l= <dig> k≠lnrk,l , that quantifies the strength of the competition faced by the kth phenotype during the optimization against the remaining phenotypes.

next, we identify the strongly anticorrelated mutants and explain how they influence the search for model parameters while we maximize the fraction of the phenotypes that are captured. our focus is on the de run that resulted in  <dig> phenotypes being captured . in addition, we analyze the lh run with  <dig> samples. additional file 1: tables s <dig> and s <dig> show the most competitive phenotype pairs in the lh and de samples. we see that, in all cases, an experimentally viable phenotype is paired with an inviable one. among lh samples, the majority of competitive phenotype pairs have common mutations. however, this is not the case among de samples, which suggests that non–intuitive competitions arise when we maximize the number of captured phenotypes in the de phase.

among the  <dig> top-performing parameter vectors in the de run with  <dig> hits, there is a common set of eight phenotypes that are not captured. seven of these missed phenotypes  have reasonably high acceptance ratios  among the  <dig> lh samples, but each one is strongly anticorrelated with the remaining phenotypes. to demonstrate this fact, we sorted the  <dig> r^ values in ascending order from most competitive  to least competitive . the seven phenotypes under consideration are in the top  <dig> most competitive phenotypes in the  <dig> lh samples, as listed in additional file 1: table s <dig>  furthermore, based on their r^ values, these seven phenotypes are in the top eight most competitive phenotypes in the  <dig>  de sample set. despite their reasonably high overall acceptance ratios in the lh samples, they experienced a large drop in acceptance ratio during de due to their strong competition with other phenotypes .

the eighth missed phenotype  has very low acceptance ratio in both  <dig>  de samples  and  <dig> lh samples . despite the ability of de to increase the acceptance ratios of most phenotypes , this phenotype’s acceptance stays low as a result of its competition with the remaining  <dig> phenotypes during de. the r^ value of this phenotype is the 6th most competitive in the  <dig>  de samples. on the other hand, within the  <dig> lh samples, strain  <dig> is non-competitive, as illustrated in additional file 1: table s <dig> . additional file 4: figure s <dig> shows a comparison of pairwise correlations  of phenotype  <dig> in  <dig> lh samples versus  <dig>  de samples. there are  <dig> r values above  <dig>  in the lh phase, whereas this number drops to zero in the de phase as majority of phenotypes become competitors of phenotype  <dig>  r^ of phenotype  <dig> drops from − <dig>  to − <dig>  as a consequence of this transition. from these observations, we conclude that phenotype  <dig> is not captured due to its extremely low acceptance ratio among lh samples and also during optimization.

some of the eight non-captured phenotypes considered here are also among the “most troublesome” strains identified by us during trial-and-error parameter estimation. for example, it is difficult to explain the inviability of strains  <dig>  and  <dig>  because the single mutants  are viable and it is unclear why deletion of clb <dig> from either single mutant should make the strains inviable. we also observed that capturing the viability of very large cells of strain  <dig>  jeopardizes the simulations of many other mutants, as confirmed in additional file 4: figure s2-b.

some of the other non-captured phenotypes point out limitations of our model and/or objective function. strain  <dig>  is inviable because excess cdc <dig> overwhelms the mitotic checkpoint mechanism and drives cells into premature anaphase, but our model does not capture this effect, probably because we do not overexpress cdc <dig> to a sufficiently high level. strains  <dig>  and  <dig>  are viable by our criteria, but they exit mitosis with an excess of clb5-dependent kinase activity and cannot relicense dna molecules for the next round of dna synthesis, so they should be classified as inviable.

using phenotype competitiveness to accelerate the evolutionary algorithm
by ignoring non-competitive phenotypes we can reduce the number of phenotypes that need to be simulated during optimization. to illustrate, we identified the  <dig> least competitive phenotypes from the r^ values computed from a small set of  <dig> lh samples. we then generated five subsets of phenotypes to be used in the selection process by eliminating from the full set of  <dig> phenotypes the  <dig> least competitive phenotypes, the  <dig> least competitive phenotypes,..., the  <dig> least competitive phenotypes. next, for each subset we performed four independent runs of de optimization, using always the same initial population of  <dig> parameter vectors and varying the random numbers used in mutation and crossover operations. lastly, after  <dig> generations of de, we used the final  <dig> parameter vectors to see how many of the full group of  <dig> phenotypes are correctly simulated. the results, given in table  <dig>  show that by simulating only  <dig> phenotypes, we find parameter vectors that correctly simulate 102– <dig> of the full set of  <dig> phenotypes. this success rate is comparable to the results obtained by simulating all  <dig> phenotypes in every generation of de. hence, by ignoring the least competitive phenotypes we can reduce the computational load of the de algorithm by about 25% in each generation, without losing the ability of the optimization procedure to find sets of parameter values that give the best possible account of all  <dig> phenotypes. apparently, we get these  <dig> least competitive phenotypes for free during the optimization procedure. they are listed in additional file 1: table s <dig> 

optimization results  with reduced sets of phenotypes.

of five individual non–greedy de runs , we found that they all captured  <dig> of the  <dig> phenotypes. of the  <dig> phenotypes that were missed by at least one of the five de runs, none were among the  <dig> least competitive phenotypes identified by the  <dig> lh samples. furthermore, three phenotypes , all among the four most competitive phenotypes  as identified by  <dig> lh samples, were consistently missed by the top performing parameter vectors in all five de runs. these results show that, with a small number of lh samples, we can get an idea of how de will perform over thousands of samples before convergence. nonetheless, de is still necessary to approach an optimal number of hits, since  <dig> lh samples, in three independent runs, can get at most ∼ <dig> hits. even with  <dig>  lh samples, the maximum number of hits is  <dig>  whereas de reaches this many hits in ∼ <dig> generations , indicating that random sampling of parameter space is outperformed by a combination of random sampling  with evolutionary search .

order of events
during de we have applied only the most basic phenotypic constraint on the simulated strains, namely viability or inviability. in our simulations, viability means that cells divide periodically and that cell mass at division converges to a specific value . inviability means that the cell mass exceeds  <dig>  which only happens when the cell becomes arrested in the cell cycle, never dividing but continuing to grow. .

additional constraints could be introduced. for example, for a cell to be viable, not only must it divide periodically at a characteristic size, but also it should execute cell cycle events  in the correct order. and inviable cells should be checked to see that they have arrested in the observed phase of the cell cycle. in addition, we could check other commonly measured cell cycle properties of mutants: for example, cell size at division, and duration of the unbudded phase of the cell cycle. although we intend to examine these additional constraints in later studies, in this study we have checked the order of events in all  <dig> strains produced by the optimum parameter vectors. these parameter vectors reproduced the five events for all experimentally viable mutants in the correct order with the following exceptions: 

 <dig>  in three viable strains that had no copy of pds <dig> , esp <dig> was always active , and the model would ideally show that esp <dig> degrades cohesins and initiates anaphase separation of sister chromatids before all replicated chromosomes are aligned on the mitotic spindle . that such catastrophes are not observed in cells lacking pds <dig>  indicates that the model is missing an important control on cohesin degradation. in this case, it is believed that polo kinase must phosphorylate cohesins before they can be degraded by esp <dig>  and this effect is not included in the present version of the model. in these pds <dig> Δ mutants, all events other than esp <dig> activation took place in the right order; hence, we are justified in considering these mutant strains to be viable.

 <dig>  in simulations of three other “viable strains”  some events did not happen in the right order . on the other hand, there are two experimentally inviable phenotypes  for which our parameter vectors exhibit “viability” but the events do not happen in the right order. hence, these two strains should be correctly classified as inviable.

as a result, even with the event-order constraints, our number of hits is only reduced from  <dig> to  <dig>  hence, it appears that by selecting according to our simple definition of viability/inviability, the model  automatically reproduces the correct sequence of events in mutant strains. this property of the model is an indication that it is correctly representing the sequence of dependencies in the molecular mechanism underlying cell cycle progression in budding yeast.

sensitivity analysis of the model
sensitivity analysis is widely applied to study biological systems in order to quantify the robustness of biological behavior to changes in model parameters, to determine the most sensitive model parameters and experimental constraints, and to guide further experimental work and model refinement  <cit> . our approach to sensitivity analysis, described below, is similar to past studies by bentele et al.  <cit> .

fragile and robust phenotypes
our objective function is the number of phenotypes successfully simulated by the model for a particular set of parameter values. in this section, we identify the effects of single parameter perturbations on this function in order to identify those parameters to which the model is most sensitive. when perturbed, these “critical” parameters cause the loss of already captured phenotypes more frequently than non-critical parameters. in addition, because the objective function encompasses all experimental constraints, we can look for links between individual parameters and individual genetic strains. for large and complex networks, such as the budding yeast cell cycle, the identification of such input-output relationships can be challenging and counterintuitive  <cit> . nonetheless, we seek such relationships because they can suggest how a control system might be perturbed experimentally in order to achieve particular desired outcomes.

our approach to sensitivity analysis is to produce a large sample of perturbations away from the best parameter vectors identified by de. we then ask of this sample which parameters—when perturbed—cause the most drastic loss of correctly simulated phenotypes; these are the critical parameters. the phenotypes most often incorrectly simulated are the fragile phenotypes. to generate the sample of parameter vector perturbations, we must first choose a representative collection of parameter vectors that are most successful in capturing phenotypes. the most successful de run  captured  <dig> of  <dig> phenotypes. of the  <dig>  parameter vectors investigated in this run,  <dig> defined models that reproduced  <dig> phenotypes, and of these successful sets we chose  <dig> at random. next, we introduce perturbations to each parameter in each of these  <dig> vectors. in general, each parameter is perturbed ±20%, ±40%, ±60%, ±80%  from its nominal value and in addition each parameter is set to zero .

recall that each parameter vector consists of  <dig> kinetic constants  plus  <dig> initial conditions . of the  <dig> kinetic constants, two were not perturbed: mass doubling time  and fraction of daughter mass acquired from the mother . in addition, the cln <dig> basal expression rate was fixed at zero, since even tiny values of this parameter consistently caused cln <dig> Δ bck <dig> Δ and cln <dig> Δ bck <dig> Δ sic Δ strains to be viable, contrary to experimental observations. also, there were  <dig> mutant-parameter combinations where setting the parameter to zero did not make sense. for example, for cki overexpression with a gal promoter, it is not sensible to have a zero setting for the synthesis rate of cki protein. similarly, for each phenotype, setting the initial cell size to zero is not possible.

starting from each of the  <dig> successful parameter vectors chosen from the de run, we introduced one of the parameter perturbations to create a “new” parameter vector. we then simulated wt cells in glucose . next, we simulated each of the  <dig> other strains by adjusting the parameter values in the “new” parameter vector according to the rules that mimicked these strains. in total, from the  <dig> initial parameter vectors we created  <dig> new parameter vectors  and ran  <dig> simulations per vector. out of these  <dig> , <dig> simulations, we discarded the ones where setting a parameter to zero was not sensible, leaving us with  <dig> , <dig> to assess model robustness. the total number of hits among the  <dig> parameter vectors generated after perturbations in individual parameters ranged from  <dig> to  <dig>  although some of the eight phenotypes that were missed by optimization were captured by some of these perturbations, the overall number of hits never exceeded  <dig>  these eight phenotypes  were not taken into account in the sensitivity analysis, since our reference point was the outcome of the optimization.

we computed the number of times each of the  <dig> captured phenotypes was lost after a parameter perturbation, and then we ranked the  <dig> phenotypes according to their frequency of loss . the  <dig> most fragile phenotypes  accounted for 46% of the total number of losses, and each contributed at least  <dig> % to this total. only four of these phenotypes are experimentally inviable, which indicates that viability is more vulnerable to parametric perturbations. on the other hand, out of the  <dig> single-mutation phenotypes captured before perturbations, only four of them are among the most fragile  <dig> phenotypes. this prediction aligns with the increasing fragility observed in biological systems with increasing number of structural changes   <cit> . table  <dig> shows the  <dig> most fragile phenotypes. mutations connected to the start cyclins  and the g1-stabilizers  are common features of these phenotypes.

cln <dig> Δ cln <dig> Δ cdh <dig> Δ
cdc <dig> Δ net1-ts cdh <dig> Δ
gal-clb <dig> cdh <dig> Δ
apc-a sic <dig> Δ
clb5-db Δ pds <dig> Δ
cdh <dig> Δ
cln <dig> Δ cln <dig> Δ cln <dig> Δ sic Δ
bck <dig> Δ
gall-cdc <dig> sic <dig> Δ cdh <dig> Δ
clb <dig> Δ clb <dig> Δ cdc <dig> Δ pds <dig> Δ
cln <dig> Δ bck <dig> Δ sic Δ
cln <dig> Δ cln <dig> Δ
apc-a sic <dig> Δ cdc <dig> Δ2-49
these are the phenotypes that are most often lost  when perturbations are applied to individual model parameters. fragility decreases from top to bottom.

the  <dig> most robust phenotypes are all inviable. the first viable phenotype that is also robust is ranked 34th on the list, and there are nine other robust viable phenotypes among the top  <dig> robust phenotypes . the wild type phenotype  is among the most robust viable phenotypes as expected, since the high number of hits during optimization is strongly dependent on the model’s ability to capture wild type viability. the most common feature of robust-viable genetic strains is the presence of mutations in the exit module , as compared to the relative fragility of strains with mutations in the start module.

these are the viable phenotypes that are least often lost  when perturbations are applied to individual model parameters. robustness decreases from top to bottom. tab6- <dig> has lowered efficiency of cdc14-net <dig> complex  formation compared to wt efficiency.

critical and dispensable parameters
we used the same data set to analyze model robustness with respect to parameters. for each model parameter, we counted the number of times a perturbation caused the loss of a phenotype, and ranked parameters according to their ability to affect our objective function . “critical” parameters are parameters that when perturbed cause frequent losses of phenotypes. on the other hand, parameters that can be perturbed with little or no change in our objective function are clearly “dispensable” parameters to the optimization process considered here. the  <dig> most critical parameters, which account for 44% of the total losses, are listed in table  <dig>  the most critical parameter in our analysis is the total amount of cdc <dig>  which accords nicely with the experimental result that, among  <dig> cell cycle genes studied by moriya et al.  <cit> , the cell cycle was least tolerant to overexpression of cdc <dig> 

most critical model parameters that had the largest effects on the objective function upon perturbations. criticality decreases from top to bottom.

twelve of the  <dig> most critical parameters are involved in the exit module. whereas exit module parameters are critical in terms of capturing phenotypes, viable strains with mutations in exit module genes are highly robust to perturbations when the effects are summed over all parameters in the model. these contrasting results underscore the difference between critical parameters and robust strains. the evaluation of model parameters and phenotypes is performed by looking into different sets of outputs. a robust strain  is identified by taking perturbations in all parameters into account. on the other hand, a critical parameter  is identified by taking all phenotypes into account.

we also identified the  <dig> least critical model parameters, i.e., those parameters with little or no effect on the objective function. to determine if some of these parameters are dispensable as far as our optimization problem is concerned, we constructed a series of “reduced models” by setting more and more of these least-critical parameters to zero. the results, presented in table  <dig>  demonstrate that we can eliminate the  <dig> least critical parameters  without seriously degrading the ability of the model to capture at least  <dig> of the  <dig> strain phenotypes.

optimization results with the full model and the reduced models . the least sensitive  <dig> parameters are set to zero in reduced model  <dig>  whereas the least sensitive  <dig> and  <dig> parameters are set to zero in reduced models  <dig> and  <dig>  respectively.

in an independent repeat of this sensitivity analysis,  <dig> of the top  <dig> least critical parameters were the same, and in another repeat after an independent de run that produced  <dig> parameter vectors with  <dig> hits,  <dig> of the  <dig> were the same. it is noteworthy that  <dig> initial conditions  and  <dig> bud related parameters always formed the least critical  <dig> parameters. in hindsight, this is not surprising, because the initial conditions are used only to start up the simulation of a wt cell in glucose. if the wt cell is viable, we replace the “initial” ics by the values of all variables in a newborn wt cell for all further strain simulations. so the “initial” ics have no bearing on the calculation of the objective function. initial mass plays a different role, because if it is too large or too small, then the wt cell may not be correctly simulated. regarding bud-related parameters, the bud variable is part of the model in order to time the appearance of the bud in relation to the onset of dna synthesis , but the bud variable has no effect on further progress through the cell cycle. hence, the bud-related parameters have no effect on the viability or inviability of simulated strains. in future versions of the model, where the timing of budding events will enter into the objective function, the bud-related parameters will no longer be dispensable. of the remaining  <dig> least critical parameters , many are “basal” rates of synthesis or degradation and “basal” rates of activation or inactivation. most of these basal rate constants can be set to zero without seriously degrading the success of the model in capturing viability or inviability of the mutant strains.

strongly connected phenotype-parameter pairs
we also computed the number of times a model parameter, upon perturbation, caused the loss of a specific captured phenotype. the ten most strongly connected mutant-parameter pairs are listed in table  <dig>  each of these parameters has changed the phenotype of the corresponding strain for at least  <dig> of the  <dig> perturbations . all of these strains carry multiple mutations, a characteristic of fragile phenotypes. the fragility of these strains is, for the most part, connected to perturbations in mitotic exit parameters. the highly affected strains also tend to carry multiple copies of a wild type gene, suggesting that de has delicately balanced model parameters to reproduce the viability of these strains.

cdc <dig> Δ net1-ts cdh <dig> Δ
cdc <dig> Δ net1-ts cdh <dig> Δ
cdc <dig> Δ net1-ts cdh <dig> Δ
gall-cdc <dig> sic <dig> Δ cdh <dig> Δ
upon a perturbation, with at least  <dig>  probability, these parameters caused the loss of the corresponding phenotype .

novel phenotypes predicted by the elimination of phosphorylation/dephosphorylation reactions
it is interesting to note that there are only two phosphorylation/dephosphorylation rates among the  <dig> most critical parameters in table  <dig>  despite the presence of several more such rates in the model equations. this motivated us to look more carefully into sensitivity analysis results, specifically the perturbations by which parameter values were set to zero. we focused on nine phosphorylation/dephosphorylation rates  that cause inviability in otherwise viable genetic strains as shown in table  <dig> . in other words, sensitivity analysis gave us novel phenotypes that highlighted the importance of this class of reactions only under specific mutant backgrounds. for a similar past experimental study that identified sic <dig> phosphorylation to be lethal only when one of the clb-cyclins is deleted, see  <cit> .

upon setting phosphorylation/dephosphorylation rate constants to zero , viability is lost in several single mutation strains .

the three genetic strains that are most commonly affected by elimination of these nine specific phosphorylation/dephosphorylation reactions are apc-a, bck <dig> Δ , and cdh <dig> Δ . apc phosphorylation  by clb <dig> is set to zero in apc-a and this inhibits the degradation of clb <dig> and clb <dig>  clb <dig> phosphorylates whi <dig> and cki, and clb <dig> phosphorylates sbf and cki. hence, increased levels of clb <dig> and clb <dig> in apc-a combined with the elimination of phosphorylation/dephosphorylation reactions upset the net phosphorylation of cki, whi <dig> and sbf that is required for viability. likewise, bck <dig> inhibits cki and whi <dig>  and its deletion or overexpression combined with these parametric perturbations cause imbalances between phosphorylation and dephosphorylation rates, leading to inviability. in cdh <dig> Δ background, clb <dig> is in excess  since cdh <dig> degrades clb <dig>  therefore, sbf and cki phosphorylation is affected the same way as described above for apc-a. on the other hand, excess clb <dig> in cdh <dig> Δ background leads to higher levels of phosphorylated  net <dig>  thereby reducing net1’s ability to trap cdc <dig> in cdc14-net <dig> complex resulting in excess free cdc <dig> that impacts net whi <dig> phosphorylation. we would like to note that only  <dig> single mutation strain–parameter pairs,  <dig> % of all possible  <dig> mutant–parameter pairs , are affected by the nine phosphorylation/dephosphorylation rates . these rare fragilities are identified automatically by the sensitivity analysis, which actually generates hundreds of novel phenotypes starting from the  <dig> phenotypes we used in optimizing model parameters. identification of these rare parameter–mutant combinations in such a large input–output space is potentially beneficial to biologists, who are typically faced with the daunting task of performing genetic screens in complex biological networks. our approach provides an experimental design path to follow with a mathematically simple sampling and optimization framework in the absence of time–series data, but only a set of qualitative observations  available to train the model.

CONCLUSIONS
the physiological characteristics of a living cell—for example, how it progresses through the cell division cycle, or how it responds to external stimuli, or how it develops within a specialized tissue—depend ultimately on the dynamical properties of macromolecular regulatory networks. the dynamics of these networks can be described accurately by systems of differential equations  or sets of reaction probabilities . in principle these systems of equations can be simulated numerically and the results compared to the behavior of living cells under a variety of experimental conditions. unfortunately this vision of a grand theory of molecular cell biology is subverted by the “curse of parameter space”. any realistic model of a functional cellular control system will contain dozens of interacting genes, proteins and metabolites and many dozens of rate constants , which are generally unknown. a major part of the challenge of model building in molecular systems biology is to estimate the system parameters from the available experimental data and, in the process, to assess how well the data constrains the model and how well the parameterized model accounts for the data and makes reliable predictions of future experiments. it is in this context that systems biologists need practical approaches to parameter estimation. brute force exploration of parameter space is not an option. for a model with  <dig> parameters, even to evaluate parameter vectors at each corner of a hypercube bounding a feasible region of parameter space would take approximately  <dig> evaluations, a number well beyond foreseeable computational power. in light of this fact, any optimization procedure must propose ways to trade off wider exploration of parameter space for denser sampling of more promising regions found by previous sampling.

furthermore, the optimization problem is itself a moving target. new experimental observations are continuously being reported, forcing the model to adapt and change. there is no point in employing a heavy duty optimization procedure that provides a single “optimal” solution  for a problem that may be outdated tomorrow. what modelers need are computationally light optimization approaches that can help them make quick and flexible progress. the approach we are proposing, based on latin hypercube sampling and differential evolution, appears well suited to the task. in addition, our approach can be of great use to modelers by highlighting parts of the model where the structure may be insufficient  to explain the observed data.

we believe that our approach is a practical and informative strategy for studying how the assignment of parameter values affects the ability of a complex reaction network to account for extensive data sets. of course, other approaches are possible, and it is difficult to compare the relative merits and liabilities of various approaches. the only study directly comparable to ours, in the sense of estimating a large number of cell cycle parameters based on mutant phenotype data, is a paper by panning et al.  <cit>  on global parameter estimation for the chen- <dig> model  <cit>  with a data set consisting of phenotypic characterizations of  <dig> budding yeast strains. these authors used a combination of two deterministic optimization algorithms: direct  and mads . they started with a very good set of parameter values  and looked for the global optimum. direct alone improved this result to  <dig> of  <dig> phenotypes after  <dig>  evaluations of the objective function, most of which were to confirm that the global optimum point did not lie elsewhere. mads improved the result to  <dig> very quickly . at this point, we are not able to provide a direct comparison of our approach with panning et al., since the two studies used different models and optimized with respect to different phenotypic constraints. however, we plan to include a direct comparison of these two optimization approaches in a later publication.

in conclusion, we have presented a parameter estimation approach for high dimensional ode models with a large number of experimental constraints. our approach, which makes use of established parameter sampling and optimization tools, is quite successful in locating points in the parameter space with high model performance, even when the starting point of the search is quite “suboptimal”. sensitivity analysis of the objective function provides additional information on “critical” and “dispensable” parameters and on fragile and robust phenotypes; information that suggests directions for model refinement. we also used random sampling to measure “competition” between experimental constraints, information that is useful to streamline the number of simulations needed for parameter estimation and to assess trade-offs in a model’s ability to reproduce a given set of experimental observations. finally, we identified rare parameter–mutant combinations to highlight particular fragilities in the system to illustrate usefulness of our approach to predict novel phenotypes and design new experiments. to conclude, we demonstrated that these methods of parameter estimation and analysis can be a powerful tool to propel systems biology research forward.

abbreviations
apc: anaphase promoting complex; cdk: cyclin-dependent kinase; de: differential evolution; ic: initial conditions; lh: latin hypercube; ode: ordinary differential equation.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
conceived and designed the model: co, tl, kcc, wtb, jjt. performed the optimization, model reduction and analysis: co. wrote the paper: co, wtb, ltw, jjt. all authors read and approved the final manuscript.

supplementary material
additional file 1
supplementary tables. this pdf file includes the supplementary tables referred to in the main text.

click here for file

 additional file 2
viarray.txt, integrate.cpp, runoptimal.m, runtl.m, integrate.mexw <dig>  optimal.txt and tlset.txt. “viarray.txt” holds the viability array of the  <dig> strains , “integrate.cpp” is the c subroutine for the odes and, integrate.mexw <dig> is the mex file that allows matlab to use the c subroutine for solving the odes. altogether, these files reproduce the number of hits with the parameter values from the best performing de run  and the initial parameter values  before the optimization . in order to reproduce these results, matlab files “runoptimal.m” and “runtl.m” need to be executed, respectively.

click here for file

 additional file 3
supplementary text. this pdf file includes a detailed description of latin hypercube sampling.

click here for file

 additional file 4
supplementary figures. this pdf file includes two additional figures.

click here for file

 acknowledgements
this work was supported by an nih grant  to jjt and wtb. we are grateful to the advanced research computing lab at virginia tech for computing resources. we also thank tyson lab members, especially dr. alida palmisano and dr. janani ravi for useful discussions. finally, we thank the anonymous reviewers for their comments that improved the manuscript. the funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.
