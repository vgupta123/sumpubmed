BACKGROUND
rapid improvement of high-throughput sequencing technologies allows for much deeper exploitation of microbial communities, including bacteria, archaea and microeukaryotes. while only a small fraction of the microbial phylogenetic diversity is represented by cultivated organisms  <cit> , metagenomics  allows reconstruction of microbial genomes  directly from environmental samples without cultivation. however, the binning of assembled metagenomic contigs into individual genomes still remains a significant challenge.

the combination of tetra-nucleotide frequencies  with contigs’ differential abundance spectra  has resulted recently in the development of multiple  automated contig binning approaches . even though fully automated genome binning allows the processing of large amounts of sequencing data, the different binning algorithms often result in redundant or overlapping genome bins. moreover, depending on the chosen parameters, even an individual binning algorithm may provide different binning results. this makes it difficult for a user to determine which configuration produces the best results. alternatively, one might want to combine bin assignments from different tools  in order to get the “consensus” set of bins, similarly to a recently proposed merged assembly concept  <cit> .

therefore, further verification of bin completeness and contamination  as well as subsequent bin refinement are necessary. the first task has been recently addressed by the development of checkm  <cit> , an automated tool that estimates the completeness and contamination of draft genomes  using a set of marker genes that are specific to a genome’s inferred lineage. the second issue concerning the refinement of genomic bins would ideally require an interactive framework allowing for visualizing several automated binning outputs in order to perform further supervised binning. to our knowledge, anvi’o  <cit>  is the only interactive tool that enables for such visualization and for subsequent human-assisted improvement of automatically generated genome bins resulting from multiple binning algorithms. even though, the anvi’o metagenomic workflow enables the user to interactively work with the data and to perform a supervised binning using a real-time display of bin completeness and contamination estimates, its main limitation is a low number  of contigs  that can be clustered for human-guided binning. visualization of larger datasets decreases the responsiveness of its interactive interface.

here, we introduce icover, the interactive contig-bin verification and refinement visualization tool, which allows user-guided refinement of automatically generated contig bins. the software provides a visual interface that allows for comparing different binning results and their further supervised refinement. its visualization window is composed of two connected and interactive main views:  a parallel coordinates view in which gc content, gene length, contig abundance spectra across different samples, binning results and tnfs values are displayed, and  a dimensionality reduction plot in which projections of the tnfs and contigs are shown . to demonstrate icover’s utility we used it to refine automated binning results for a dataset representing the microbiome of an anaerobic digester . we show that it improved the completeness and reduced the contamination of genome bins initially generated with metabat  <cit> , concoct  <cit> , and mycc  <cit> . moreover, we further used icover to refine genome bins for an infant gut metagenome  <cit> , previously validated with concoct  <cit> , groopm  <cit> , maxbin <dig>  <cit> , metabat  <cit>  and mycc  <cit> .fig.  <dig> static image from the icover interactive display of the ad microbiome dataset. icover-refined genome bins  <dig> and  <dig> are shown as examples




implementation
overview of icover software
icover was designed as a visualization and refinement interface and not as primary binning software. it consists of data management and analytical functionality in the back end, and interactive visualization functionality in the front end. data management and analytical functions of icover are implemented in r, thus the software is easily deployable on any system for which r is available. the front end of the application was developed using web technologies. the interface between the r code and the web front end leverages opencpu  <cit> , which provides an http/rest api reflecting the functionality exported by the r package. the analytical functionality in the back end is added to drive the refinement process through the visual interface of icover. it is used to help focusing on relevant parts of the data, and to guide the decision making with respect to adding or removing contigs from a particular bin. currently, it involves classic clustering and dimensionality reduction techniques, including the k-means  <cit>  and correlation-based clustering. correlation-based clustering is similar to the canopy clustering proposed by nielsen et al.  <cit> . as opposed to the latter approach, the data items subject to clustering in our application are contigs rather than called genes. here, the correlation clustering algorithm depends on two criteria:  the correlation threshold, which determines whether a contig is added to a bin with a given seed contig, and  the minimal cluster size, which determines the minimum number of contigs before a bin is considered a single cluster. the r hmisc::rcorr function used for calculating the correlation-based clustering requires at least five variables . in the case where a lower number of samples is available for the analysis, the user may choose to rely on the automated binning results only. additionally, the user can extend the clustering of contigs abundances over samples to other variables, including the gc content or a selection of tnfs, or alternatively penta-nucleotide frequencies . in addition to the clusterings, two dimensionality reduction techniques are provided, including correspondence analysis  and principal component analysis . both techniques are used to extract important information from a multivariate dataset in order to interactively select a subset of the potentially most interesting variables  and individuals . the level of “interestingness” refers to variables  that differ from the majority and thus may include patterns that may be important in driving differences between the individuals . while both pca and ca result in orthogonal components, the former applies better to continuous numeric data , while the latter applies to categorical data . as such, they represent straightforward methods for selecting a possibly interesting subset of variables to be visualized.

as a pre-requisite for icover, a user must provide:  a co-assembly file  containing all co-assembled contig sequences for all the metagenomic samples to be analyzed;  a contig coverage  file in the csv format calculated for each metagenomic sample separately;  an escgs file in the csv format containing all the predicted escgs for all co-assembled contigs; and  a clustering file in the csv format  with binning results from one or more automated binning tools that the user wants to refine. although, the implemented k-means and correlation-based clusterings can perform an initial contig binning, it is highly recommended to start with dedicated automated binning software prior data visualization and refinement processes. a detailed installation guide is provided online
https://git.list.lu/escience/icover/wikis/home/. once the package is installed it allows the software to be run in two different ways. either the r opencpu package is used to start opencpu from an interactive r session, or a dedicated opencpu installation is used. the first option allows individual users to get started more quickly. the latter version scales better and allows for handling simultaneous requests.

ad microbiome sequencing, co-assembly and data preparation
an anaerobic, mesophilic pilot-scale continuously stirred tank reactor  of 100 l reaction capacity was inoculated and operated as previously described  <cit> . seven samples  were selected for metagenomic analysis and the total genomic dna was extracted with a powersoil dna isolation kit , according to the manufacturer instructions. sequencing libraries were prepared using a nextera xtdna library prep kit , and were pair-end sequenced  in a single run on an illumina miseq using a miseq reagent kit v2- <dig>  raw sequence data was deposited in the sequence read archives  under the project accession number prjna <dig>  the resulting  <dig> , <dig> metagenomic reads with average read length of  <dig>  nt were imported to clc genomics workbench v <dig>  , and trimmed using a phred quality score of  <dig> , minimum length of  <dig>  and allowing no ambiguous nucleotides. a total number of  <dig> , <dig> reads were completely removed after trimming. the seven metagenomes were assembled together using the clc’s de novo assembly algorithm in mapping mode, using the following settings: word size of  <dig>  automated bubble size, minimum contig length of  <dig>  mismatch cost of  <dig>  insertion cost of  <dig>  deletion cost of  <dig>  length fraction of  <dig> , and similarity fraction of  <dig> . assembly of over  <dig> million  reads  led to  <dig>  contigs  with n <dig> of 3489 nt, and the longest contig of  <dig>  nt. to determine the average coverage of contigs for each metagenome sample, reads were de-replicated and mapped back to the de novo assembled contigs using the rna-seq analysis mode, with a minimum similarity of  <dig>  over  <dig>  of the read length, and using the ‘count paired-reads as two’ mode. in total,  <dig> % of reads mapped back to the assembled contigs. the average abundance was calculated as dna-rpkms  and exported in bam and csv formats. tnfs and the gc content of the resulting contigs were calculated using functionality provided by the biostrings package . open reading frames  on the resulting co-assembled contigs were first predicted with metaprodigal  <cit> , and subsequently escgs were identified as previously described  <cit> . they are specific to the domain bacteria.

ad microbiome automated binning with metabat, concoct and mycc
the ad microbiome dataset was initially binned using the fully automated metabat, concoct and mycc binning software. to that purpose, respective bam files were generated with clc genomics workbench after mapping the quality trimmed reads to the resulting contigs, as described above. to generate genome bins metabat was run using three different modes including ‘ sensitive’, ‘specific’ and ‘superspecific’. the lowest possible cut-off of  <dig> for ‘mincontig’ was used to valorize multiple short contigs. in addition the ad microbiome dataset was binned with concoct using a cluster number set to  <dig>  this number of clusters was chosen based on the estimated number of at least 30% complete draft genomes  able to be recovered for the cstr metagenome dataset. mycc was run using the default parameters  and including the calculated contigs abundance information for the seven metagenomes. the binning results were further combined in a single csv file and visualized with icover for further human-assisted bin refinement. genome bins completeness and the level of contamination with foreign dna were assessed with checkm. an f <dig> score was used to weigh precision and recall of genome binning, and was calculated as previously described by  <cit> . due to the lack of reference genomes, the checkm calculated bin completeness was used as a recall value. the precision value was calculated as a difference of 100% minus the checkm calculated bin contamination. for contamination values exceeding 100%, the precision value was set to zero. paired-end connections for the different contigs grouping into the resulting genome bins were visualized with circos  <cit> , using the pipeline described in  <cit> .

sharon’s dataset
a human infant gut microbiome  <cit>  was used to further validate icover. the metagenome assembly along with the depth files  and binning information for concoct  <cit> , groopm  <cit> , maxbin <dig>  <cit> , metabat  <cit>  and mycc  <cit>  were downloaded from http://sourceforge.net/projects/sb2nhri/files/mycc/data/sharon.zip and https://sourceforge.net/projects/sb2nhri/files/mycc/data/benchmark/sharon.zip/download. these files were previously prepared as described in  <cit> . only contigs above 1000 bp were considered . the checkm calculated bin completeness and contamination for concoct, groopm, maxbin <dig>  metabat and mycc bin assignements were taken from  <cit> , . for the icover-refined genome bins, bin completeness, contamination and f <dig> scores were calculated as explained above for the ad microbiome dataset.

RESULTS
icover implementation
icover provides an interactive visualization and refinement interface for the refinement of metagenomic contig bins resulting from multiple automated binning algorithms. two clustering algorithms running in its back end work on rows that contain a variety of contig properties. while the widely used k-means clustering algorithm  <cit>  is not suitable on its own to cluster full metagenomic datasets, we found it useful to enlarge or narrow down the selection of contigs during the refinement process. the correlation-based clustering is similar to the canopy concept previously proposed  <cit> , however it allows the user to extend the contig coverages-based clustering to other variables such as gc content or a selection of tnfs, alternatively pnfs. this concept is similar to e.g. concoct  <cit> , which uses gaussian mixture models to cluster contigs into population-level genomes based on sequence composition and coverage across multiple samples. moreover, it allows a level of freedom that exceeds even the approach implemented in anvi’o  <cit> , where the clustering profiles are currently limited either to coverage information, tnfs or the combination of both.

in addition to these two clustering algorithms, dimensionality reduction techniques are provided in icover for selecting variables and contigs of interest. ca is applied to tnfs  and pnfs, while pca is useful to optionally select the most important samples  in case of large dataset composed of hundreds of samples, prior their visualization in the parallel coordinates view. unlike other dimensionality reduction methods, e.g. modified t-sne referred to as bh-sne, initially implemented in vizbin  <cit>  and more recently in mycc  <cit> , ca might not always capture the structure of the data in the most optimal way. however, by applying ca we can visualize not only the final projections but also the calculated contributions of the variables and individual contigs . these in turn allow for more informative views which provide a wide range of interaction opportunities to drive the refinement process.

the front end of icover is a web application with two main views, including a parallel coordinates view  <cit>  and a dimensionality reduction plot . both views are linked to each other and are highly interactive to support a real-time refinement process. the parallel coordinates view displays a vertical axis for each variable of the input dataset that is selected for visualization. each contig is represented by a piecewise linear curve, which crosses each of these axes. the point at which a line crosses an axis represents the value of the corresponding contig for the variable represented by the axis. lines in this view can be colored in different ways to ease the pattern discovery. by default, lines are colored based on gc content, but the user can choose any variable to color the lines by, or use a manual color mode where a color of choice can be assigned to a selection of contigs. the user can specify contigs of interest by making selections on one or several axes. contigs which are selected are highlighted in the window. next, the pane can be simplified by choosing either to keep the selected contigs or to remove them. the interactive ca dimensionality reduction plot shows the 2d projections of tnfs  and/or pnfs  and the contigs. by default the threshold is set to display up to  <dig> contigs in the dimensionality reduction plot. this plot focuses on refining individual clusters. as such this threshold reflects a trade-off between functionality and performance. besides both projections, the dimensionality reduction plot shows additional extracted metrics to aid in assessing the importance of the projections as well as informing about the variables which are the most discriminative. by interacting with this widget, users can select variables of interest and look for structure in different projection planes. to help the interactive refinement process, ca is performed automatically on the tnfs data. this projection is updated automatically each time the contigs or bins are filtered. selecting contigs in the contig projection view will highlight them in the parallel coordinates view and vice-versa. selecting variables in the variable projection view will add them as axes to the parallel coordinates window. thus, only variables capturing the structure which may render the refinement process more efficient can be selected. for an efficient visualization and refinement of more complex datasets, with a higher number of bins, a fish-eye zoom option was added to enable the selection of bins of interest from the parallel coordinates view  <cit> . even on a modestly-sized desktop monitor  up to  <dig> bins can be easily handled without using the zoom.

even though, most of the metagenomic datasets contain only a few samples, the accuracy of binning has been shown to improve as the number of samples  increase  <cit> . displaying too many samples in the parallel coordinates view without prior reduction can result in overcrowding and visual clutter. automatically assessing the relative value of each variable could be used to rank these variables and present the user with the most informative ones only  <cit> . in icover, pca can optionally be performed on all  samples and the user can chose to display in the parallel coordinates view only the samples that explain the largest amounts of variation in the data . the same pre-selected samples can be further used for additional contig clustering.

the two main icover views are surrounded by additional features to support the verification and refinement process. there is a contig highlighter which allows highlighting a contig of interest. furthermore, the interface provides a data counter which helps to keep a sense of how many contigs are in the current view. a tagging feature is provided to keep track of the refined bins. finally, the escgs view shows in real-time the statistics for the current selection of contigs, based on the set of  <dig> escgs. it displays the information on how many of the expected genes are in the current selection as well as how many genes have two or more occurrences. this supports quick verification of completeness and contamination for the current selection of contigs.

automated bins assignment for ad microbiome
the ad microbiome dataset was selected to evaluate icover, since it represents a microbial  community of low to medium complexity that can be easily visualized and the generated genome bins can be easily refined in a reasonable period of time. based on the previous results of the 16s rrna gene amplicon sequencing, the cstr metagenome was mainly comprised of members of bacteroidetes, cloacimonetes and firmicutes  <cit> . the calculated indices of bacterial richness varied between  <dig> and  <dig> for the different samples. however, the  <dig> top dominant bacterial operational taxonomic units  accounted for  <dig> % ± <dig>  of the whole bacterial community. accordingly, using the determined number of  <dig> escg sets  <cit> , the predicted number of at least 30% complete microbial genomes that should be recovered from this metagenome assembly was estimated at  <dig>  around  <dig> genomes should be at least 50% complete .

the ad metagenome was initially binned with metabat, concoct and mycc, leading to disparate genome bins . even though, these three different algorithms can combine sequence composition and contigs coverage information across multiple samples, the underlying algorithms are quite different. nevertheless, our focus here was not on comparing the accuracy of the existing binning algorithms on the ad microbiome dataset, but on generating consensus-based genome bins from the disparate bins obtained with automated binning software and refined with icover. binning with metabat led to  <dig> bins assignments using the ‘sensitive’ or ‘specific' modes, and to  <dig> bins assignments using the ‘superspecific’ mode. both ‘sensitive’ and ‘specific’ modes resulted in identical genome bins, while the ‘superspecific’ mode resulted in different bin assignments, which were in most cases more complete but contained a higher level of contamination . regardless of the binning mode used, short contigs  were not incorporated to the bins, even when the limit was set to  <dig> nucleotides. on the other hand,  <dig> concoct-generated bin assignments were obtained. however, for the main part they were contaminated, as further determined by checkm ; most probably due to the loss of precision related to the low number of samples used for the ad microbiome assembly . indeed, the overall accuracy of concoct starts to decrease below  <dig> samples  <cit> . mycc has been recently identified as the most suitable binning and visualization tool when applied to small sample sizes  <cit> . here, automated binning with mycc resulted in  <dig> bins,  <dig> of which were around 50% complete microbial genomes with low  and medium  level of contamination .table  <dig> summary of genome bins for ad microbiome dataset reconstructed with different binning algorithms

icovera
31
11
8
10
2
30
1
0
0
metabat_ <dig> - ‘sensitive/specific’ mode

metabat_ <dig> - ‘superspecific’ mode


afor icover ,  <dig> pre-selected and the most complete genome bins  were refined

completeness and contamination were calculated with checkm. for concoct the maximum number of clusters was setup to  <dig>  the draft genome quality classification scheme is as proposed by  <cit> 


bina
 <dig> 
0
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
0
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
29d
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
metabat_ <dig> - ‘sensitive/specific’ mode

metabat_ <dig> - ‘superspecific’ mode


anumber corresponds to the icover-refined bin 


bmarker lineage was defined by checkm


cmetagenomic abundance corresponds to the % of reads mapping to the contigs binned inside each bin


dbased on the wide range in the gc content, the pattern of contigs abundances across the multiple samples and the level of contamination, we judged this bin to be a mixture of several low abundant organisms. therefore, the icover-refined genome bin was less complete than the corresponding mycc and concoct genome bins

completeness and contamination were calculated with checkm . nb – no genome bin assigned


concocta

icover
 <dig> 
 <dig> 
 <dig> 

athe relatively lower performance of concoct on the ad microbiome dataset may be attributed to the loss of precision due to insufficient number of samples analysed . results for icover are highlighted in bold font




visualization and refinement of ad microbiome bins with icover
although visualization with icover facilitates whole community analysis, for some datasets of high microbial complexity, the refinement process of all generated genome bins might be time-consuming. here, we used checkm to estimate the completeness and contamination of the resulting metabat, concoct and mycc genome bins in order to prioritize most complete genome bins for further refinement with icover . in total, we selected  <dig> genome bins with around 50% of completeness, based on the checkm results for the different automated binning algorithms . a step-by-step description on how to load the data and refine contig bins is provided online for a few icover-refined genome bins .

none of the automated binning algorithms produced a single set of genome bins with highest completeness and lowest contamination . data visualization with icover helped to improve the completeness and to reduce the contamination for  <dig> out of  <dig> refined genome bins. average completeness of icover-refined genome bins equaled  <dig> % and contamination  <dig> %. even though the genome bins generated with concoct and mycc were in general more complete than the icover-refined bins, they both had higher levels of contamination . among the different binning algorithms, an average f <dig> score was the highest for icover-refined genome bins. except for one genome bin, none of the icover-refined bins was characterized with the contamination exceeding 5%. further tracking and visualization of pair-end reads mapping to assembled contigs, showed that out of nearly  <dig>  good end connections, only  <dig> % were between the contigs assigned to the different icover-refined genome bins . this relatively low number of displayed inter-bin pair-end read connections confirms the overall low checkm estimates of icover-refined bins contaminations . on the other hand, this information could be integrated to the future release of icover to further improve the refinement process.fig.  <dig> visual representation of the paired-end connections for contigs grouping into the resulting genome bins for the ad microbiome dataset. intra-  and inter-bin  paired-end contig connections are displayed as grey and red lines, respectively




metagenomic abundance of the refined genome bins was in a range from  <dig> %  to  <dig> % . their size varied from  <dig>  mb  to  <dig>  mb . the gc content ranged from  <dig> %  to  <dig> % . except for bin  <dig> that was assigned to euryarchaeota, all other refined genome bins were of bacterial origin. further biological interpretation of the obtained results is outside of the scope of the present paper and will be discussed elsewhere .

refinement of genome bins with icover for a previously validated sharon’s dataset
recovering genome bins from mock communities  was previously shown to yield very high precision  and recall  for the tested automated binning algorithms . contigs derived from the same genome should ideally show similar abundance profiles across the different samples. in case of simulated datasets, the sequence coverage is nearly identical, what is reflected by 90–100% precision and recall of such contigs bins. however, due to the biases resulting from the available sequencing technologies, contigs coverages may vary quite significantly within and between the different samples in the case of real datasets  <cit> . additional biological factors e.g. recombination and/or horizontal gene transfer may render the accurate calculation of contigs abundances even more challenging. therefore, to further demonstrate the effectiveness of icover we executed it on a previously validated sharon’s dataset  <cit> . genome bins of different completeness and contamination  <cit> , formerly assigned by concoct , groopm , maxbin <dig> , metabat  and mycc , were visualized with icover . based on the checkm calculated completeness and contamination, we prioritized nine most complete bins for icover refinement. as a result, we obtained seven high-quality genome bins with completeness above 95% and contamination below 5% . by contrast, only five and four genome bins meeting the same criteria were generated with maxbin <dig>  mycc and concoct, metabat, groopm, respectively. accordingly, the demonstrated advantage of combined bin refinement with icover against metagenomic binning results produced by separate binning tools was further supported by the superior average bin completeness, contamination and f <dig> scores .table  <dig> completeness and contamination for nine icover-refined genome bins for sharon’s dataset

bina
 <dig> 
0
 <dig> 
0
 <dig> 
0
 <dig> 
 <dig> 
 <dig> 
0
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
0
 <dig> 
 <dig> 

anumber corresponds to the icover-refined bin 


bmarker lineage was defined by checkm. completeness and contamination were calculated with checkm 


cbin assignments for maxbin <dig>  mycc, concoct, metabat and groopm were downloaded from https://sourceforge.net/projects/sb2nhri/files/mycc/data/benchmark/sharon.zip/download



 <dig> 
 <dig> 
 <dig> 
completeness and contamination were calculated with checkm. bin assignments for maxbin <dig>  mycc, concoct, metabat and groopm were downloaded from https://sourceforge.net/projects/sb2nhri/files/mycc/data/benchmark/sharon.zip/download.. results for icover are highlighted in bold font




current and future perspectives on genome bins visualization and refinement with icover
even though most of the different automated binning algorithms that have emerged in the last couple of years combine both the tnfs alternatively pnfs information and the contigs co-abundances, their different underlying algorithms lead to disparate genome bins. currently, there is no single, perfect tool for contig binning, however the binning variations could be further explored by refining the results of different binning tools. visualization of multiple genome bins and further interactive refinement has been addressed previously by developing anvi’o  <cit> , and currently icover. the principles behind the two tools are similar. anvi’o in addition to its metagenomic workflow can perform further analysis of combined omics data, thus offering a dynamic work environment for comprehensive data exploitation. however, with respect to its application in refining the different automated binning results, the major drawback of anvi’o is the limited number of contigs  that can be simultaneously displayed  and refined. here, we initially tested icover using a relatively small ad microbiome dataset , which was already too big to be entirely refined by anvi’o. a larger dataset  was also successfully displayed with icover and the complete set of files ready to be refined is available online for prospective users . another advantage of icover in terms of big datasets is the very large number of samples  that can be used for analysis, while only the samples capturing the contig co-abundance profiles which may render the refinement process more efficient can be selected to be displayed in the parallel coordinates view.

while icover currently allows users to include the output of different automated binning algorithms, one potential avenue for future work is to allow for algorithms such as concoct, mycc or metabat to be configured and run as part of the icover workflow. however, currently this will require significant effort in terms of updating the application interface and architecture and would limit its usage to the linux systems only. thus, it would offer little benefit compared to including the results of these algorithms in the input data.

quality of the recovered draft genome is crucial for determining its suitability for further analyses. currently, the state-of-the-art estimation of the accuracy of generated genome bins relies on the presence or absence of escgs in contigs that form the specific bin  <cit> . in icover to reinforce the selection of contigs we rely on a selection of bacterial domain-specific  <dig> escgs  <cit> . future implementation of a real-time display of the microbial lineage-specific information of completeness and contamination for a selection of contigs, would likely improve the quality of recovered genomes. currently, this is determined by checkm as a post-binning evaluation procedure  <cit> . in addition to escgs estimates, to facilitate the accuracy of the bin refinement process, information of linkage between contigs provided by the paired-end reads could be incorporated. this information has currently been explored in the recently published cocacola software , where it was shown to improve the overall binning performance, especially when the number of samples is small  <cit> .

the interactive visualization approaches allow the user to leverage their human-vision abilities to detect patterns, which a priori is subjective and may differ from one person to another. even though the visualization-based metagenomic bin refinement process is supported by the escgs estimates, patterns of tnfs and/or contigs abundance spectra, etc., it largely depends on a human-vision ability for pattern recognition. for this reason, it is difficult to accurately compare the outputs of the visualization-based tools using simulated or even previously published metagenomic datasets. indeed, computational applications that are exploratory in nature, such as data visualization, involve many trial-and-error steps. accurate reproduction of such analytical sessions would require the system to record the trail of user decisions and interactions in order to reproduce them at a later time. this concern about the provenance of insights and the reproducibility of findings using visual analytics tools has recently been an active research topic. future use of an open source systems similar to e.g. vistrails could capture the actual changes to data together with a detailed information on how these changes came about  <cit> .

additionally, to improve the visualization-based bin refinement process and to render it more reproducible, an algorithmic approach that combines bin predictions of several automatic binning tools into single, merged clustering should be envisaged. recently, a method to merge suboptimal assemblies of the high-throughput sequencing reads was shown to successfully improve multiple assemblies of metagenomic samples, regardless of the data type, assembler used or parameter variation  <cit> . such an automated approach applied to merge disparate genome bins would be highly interesting, and would potentially make full use of the available data for bin reconstruction, regardless of the algorithm settings.

CONCLUSIONS
we present icover, a new interactive visualization interface for contig-bin verification and refinement. the software can visualize bin assignments from automated binning approaches, as well as perform further contig clustering using both contig co-abundances across multiple samples and their tnfs/pnfs features. icover has an open design that allows adding new algorithms and solutions that could further contribute to a better and faster genome bins refinement. we demonstrated the utility of icover by refining mycc, metabat and concoct bin assignments for ad microbiome dataset. in addition, we applied icover to further refine genome bins for a previously validated sharon’s dataset, formerly binned with concoct, groopm, maxbin <dig>  metabat and mycc. as a result, combining the strength of several binning algorithms led in many cases to nearly complete draft microbial genomes for both analyzed datasets. we also point to several improvements that would further render the bin refinement process faster and more replicable; such as an implementation of systematic mechanisms to capture the provenance of changes derived in the course of an exploratory task and an algorithmic approach to combine the different binning results into a single set of merged and improved genome bins before their visualization.

additional files

additional file 1: table s <dig>  list of contigs and their bin assignments for the automated binning tools used in this study and for the subset of icover-refined genome bins for ad microbiome dataset. 

 
additional file 2: table s <dig>  checkm results for the genome bins generated with the automated binning tools used in this study and for the subset of icover-refined genome bins for ad microbiome dataset. 

 
additional file 3: table s <dig>  checkm results for icover-refined genome bins for sharon’s dataset. 

 


abbreviations
adanaerobic digestion

cacorrespondence analysis

cstrcontinuously/completely stirred tank reactor

escgsessential single copy genes

orfopen reading frame

otuoperational taxonomic unit

pcaprincipal coordinates analysis

pnfspenta-nucleotide frequencies

srasequence read archives

tnfstetra-nucleotide frequencies

