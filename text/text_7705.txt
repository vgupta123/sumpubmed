BACKGROUND
microarrays are rapidly becoming a standard tool for molecular biologists. the technology can reveal a multitude of information from even the simplest biological experiment. the technique is primarily used by scientists to generate ideas in experiments colloquially referred to as "fishing expeditions". however, the result of even simple experiments is hundreds to thousands of gene expression changes. because of this the cost of validation is prohibitive. the microarray technology itself is expensive and this often prevents replication. furthermore, the preliminary experiments are usually composed of the minimum number of samples absolutely necessary to address the question. this minimalistic approach is also used for other common microarray experiments. rather than replicate an experiment or increase the size of a study, it is increasingly common for researchers to turn to other published microarray experiments to attempt to verify or expand their findings. early attempts at cross-platform verification of microarray experiments utilized data generated in other laboratories from independent experiments  <cit> . these attempts produced limited success and undoubtedly many more studies went unpublished because of the difficulty in reproducing the results of one assay in a second platform.

however, recent studies have shed a more positive light on cross-platform comparisons. several studies have now shown that the probes used to detect transcripts are the root cause of differences between platforms  <cit> . the probes on some arrays do not detect the transcripts attributed to them  <cit> . this is especially a concern for cdna-based arrays  <cit> . many commercial platforms are utilizing oligonucleotide-based probes. however, commercial array producers do not always accurately identify the targets of their probes  <cit> . there are also limitations to our understanding of the transcriptome and therefore two different probes that, theoretically, detect the same transcript may produce different measurements in microarray experiments because of cross-hybridization from unknown splice variants, gene families, and transcribed pseudogenes. nonetheless, the correlation between different arrays is quite good if one restricts the analysis to sequence matched probes  <cit> .

oligonucleotide based arrays appear to have higher resolution and lower variability than cdna based arrays  <cit> . they are also easier to compare across-platforms because the sequences can be easily cross-matched. comparison is even easier when the exact same sequence is used on two different arrays. the most recent affymetrix genechips contain probes that were previously available on earlier arrays. therefore the sequences are identical and would be expected to produce similar measurements from the exact same samples. we tested this assumption and found that identical probes on the two arrays can produce different measurements.

RESULTS
the stratagene universal human reference rna standard is frequently used in microarray experiments to provide a standard reference for comparison purposes. we previously processed this rna standard several times for microarray experiments using the u133a and u133b arrays from affymetrix. when the newer u <dig> plus  <dig>   arrays were introduced we also processed this universal reference rna on the new array. the u <dig> plus arrays contain  <dig>  probesets. this includes  <dig>  probesets with identical probes to those used on the u133a arrays,  <dig>  probesets from the u133b arrays, and an additional  <dig> newly designed probesets. after processing the first few reference rna samples on the u <dig> plus arrays we evaluated the similarity of these measurements to those acquired with the corresponding probesets on the u133a arrays. we directly compared the values obtained from  <dig> u <dig> plus arrays to those obtained from  <dig> u133a arrays. we extracted the data from the probesets found on both array types and performed invariant set normalization to place these sets of data on the same scale  <cit> . following this normalization we compared the u133a array values to the u <dig> plus array values for each common probeset. we were surprised to find that  <dig>  probesets gave a different value on the plus chip than on the u133a chip . this is nearly half of the probesets shared by both arrays. overall, the array data from any of the u <dig> plus arrays looks very similar to array data from any of the u133a arrays . the correlation between any two samples was very high . yet, for individual probesets, the values appeared to fall into either a group comprised of u133a array values or a group comprised of u <dig> plus array values. scatterplots and correlation coefficients are frequently used to demonstrate the reproducibility of microarray data. however, this data demonstrates how misleading these and other gross measures of similarity can be for evaluating how different two sets of microarray data can be. the overall correlation was greater than . <dig> across  <dig>  probesets and yet nearly half of these probesets yielded measurable differences between the a chip relative to the plus chip.

controlled hybridization experiment
we decided to investigate this phenomenon further to be certain that the differences were not due to unknown bias introduced during processing of the samples. to minimize the possible sources of bias, we processed  <dig> aliquots of the reference rna in parallel using the same reagents. following the production of labeled rna we prepared enough hybridization mixture from each preparation to hybridize both a u133a array and a u <dig> plus array at the same time. we further processed the samples in parallel to minimize staining and scanning issues. following this carefully controlled experiment we examined the u133a probeset values relative to the same probesets on the u <dig> plus arrays. this time the t-test indicated that more than  <dig> probesets were yielding different values on the two array types . nearly 10% of the evaluated probesets were strongly separated into distinct groups . there were  <dig> probesets in which every recorded measurement from the a chip was larger than every recorded measurement from the plus chip. there were  <dig> probesets in which every recorded measurement from the plus chip was larger than every recorded measurement from the a chip. by chance alone we would only expect  <dig> such occurrences.

although most microarray laboratories cannot mix array types for batch methods such as rma or mbei, we were able to generate artificial a cel files from the appropriate probe values on the u <dig> plus cel files. this allowed us to perform rma on the  <dig> arrays. following quantile normalization and the model-based signal estimation of rma more than  <dig> probesets produced different values indicating that the array specific differences are not a consequence of a specific method of normalization or signal estimation. in addition, the a array files fabricated from the plus array data allowed us to perform several types of normalization at the probe or probeset level similar to the detailed analysis of choe et al. . none of the standard methods used for normalizing microarray data or calculating the probeset values reduced the number of differences between the two array formats to a level expected by chance .

across array type versus within array type comparisons
we evaluated reference rna samples hybridized to only the u <dig> plus arrays. the  <dig> arrays hybridized above, coupled with the previous  <dig> arrays, yields a pool of  <dig> arrays. when we compared any random group of  <dig> arrays from this pool to a second random group of  <dig> arrays, we found ~ <dig> probesets appeared to be different on average . this is less than would be expected by chance if all the probes were producing random measurements. this is not surprising. rna in the hybridized samples should bind to the appropriate probes providing directed signal. this reduces the number of probes producing random signal and therefore reduces the number of probesets producing divergent measurements when two groups of  <dig> are compared. this phenomenon occurs at all p-values . the observed frequency of differential measurements is lower than the expected frequency when replicate arrays were taken from the same array type. in contrast, when the reference rna was hybridized to different arrays types, more probesets showed differential expression than expected . the number of differential measurements is much greater than expected by chance and far greater than expected for arrays hybridized with the exact same sample. this illustrates the prominent effect of array type on the measured value.

when arrays of the same type were compared the probesets that appeared to be differentially measured were probably all due to random noise. approximately  <dig> probesets appeared to have group specific values in any  <dig> array to  <dig> array comparison  within the same array type. a different  <dig> array by  <dig> array comparison yielded a different group of  <dig> probesets. less than 2% of the probesets were in common between any two gene lists produced by such  <dig> by  <dig> comparisons. this illustrates that the apparent differences were nothing more than random variation that happened to fall into distinct distributions when the groups were formed. in contrast, the probesets found to be different when comparisons were made across the array types were more consistent. approximately  <dig> differences were observed at a p-value <  <dig>  when  <dig> u <dig> plus arrays were compared to a group of  <dig> u133a arrays. there was  <dig> to 85% overlap between any two lists generated by comparisons across array types. this suggests that the same probesets were being identified no matter which set of samples were chosen for comparison. this is strong evidence that the differences are real and not chance events.

we ended up with a total of  <dig> replicate measures of the universal reference rna, including  <dig> for each chip type. a comparison of the entire group of u133a arrays to the entire group of  <dig> u <dig> plus arrays yielded more than  <dig>  probesets with differential expression values specific to the array type. therefore, as more data is added to the analysis the number of differential probesets increases rather than decreases, further suggesting that this is a function of the array and not due to chance. there were  <dig> probesets for which all  <dig> measurements for one array type were higher than all  <dig> measurements for the other array type. by chance this would be expected to occur only once in ~ <dig>  experiments of this type. we show  <dig> instances of this occurrence in figure  <dig>  this figure shows that sometimes the a chip-values were higher and sometimes the plus chip-values were higher. it further illustrates that the affected probesets cover a range of hybridization values. all of the probesets depicted are well above the expression intensity observed for absent or weakly expressed transcripts. more than 2/ <dig> of the probesets identified were not considered absent, by either signal values thresholds or mas  <dig>  absent/present calls. to further demonstrate that this phenomenon is observed at all levels we plotted the average signal intensity of the u133a arrays against the average signal intensity obtained from the u <dig> plus array for the probesets that showed a distinct distribution . this plot best illustrates that the phenomenon cannot be a consequence of normalization as one cannot correct a portion of these probesets without increasing the difference of another group.

latin square hybridization control
we have demonstrated that the measurements produced by the u133a arrays are different than the measurements from the u <dig> plus arrays. at the same time the measurements are so similar that the correlation between array types is around 96%. in order to develop a frame of reference for the differences reported here we re-examined the latin-square data produced by affymetrix scientists. this data set was produced from  <dig> hybridizations in which known quantities of rna were added to a hybridization mixture containing labeled crna from hela cells. if we remove from consideration those probesets affected by the supplemented rna, the rest of the data consists of  <dig> replicate measurements of the exact same hybridization mix. this is analogous to the experiment we performed by hybridizing the same cocktail to both a u133a chip and a u <dig> plus chip. as a measure of variation we looked for probeset measurements that deviated more than 2-fold from the mean value of all the measurements. in both the latin square experiment and our experiments the probesets should have yielded the same value on all arrays as the same sample was measured. it is well known that the highest variation occurs for probesets with the lowest measurements. therefore, we sliced the full data into three groups representing the highest expression values, the middle range, and the lowest measurements from the chips. table  <dig> illustrates that hybridization, staining, and scanning related effects introduce some variation to the measurements obtained in a microarray experiment . more variation is observed if you also add the initial processing of the samples . in our experiments, where the same sample was hybridized to both array types, only the hybridization and post-hybridization steps were sources of variability. but rather than producing a similar degree of variation as the latin square data, more overall variation was observed than caused by the entire microarray process. 

evaluation of individual probes and probesets
the measurement differences between the a chip and the plus chip are probeset specific but not transcript specific. this is illustrated by the results presented in table  <dig>  the genes listed in table  <dig> are detected by more than one probeset on the arrays  <cit> . the first probeset of each group was identified because they produced extremely different distributions in the two chip types. the last column lists the p-value of the t-test as an indicator of the differences in the observed measurements. the preceding four columns list the maximum and minimum values recorded on the a chips and the maximum and minimum for the plus chips. these columns provide a second view of how distinct the ranges can be and when they might overlap. the r value for the associated probesets is a measure of the correlation between the values obtained for that probeset and the first probeset of the group across  <dig> u133a arrays representing more than  <dig> different cell or tissue types. this is provided for reference to show that these probesets have a high degree of correlation with their cognate partners when only the u133a environment is considered. yet their behavior across the array formats is distinctly different in many cases. for example, dimethyarginine dimethylaminohydrolase  <dig> and u <dig> small nuclear rna auxiliary factor1-like  <dig> each have two probesets on the arrays that detects the same transcripts with similar intensity, but for one probeset the different arrays produce different values and for one probeset the two arrays produce overlapping values. polyglutamine binding protein  <dig> and putative prostate cancer tumor suppressor also have two probesets detecting the same transcript, but in these cases one of the probesets generates higher values on the a chip and the other generates higher values on the plus chip. several other patterns are shown in table  <dig>  adducin  <dig> is detected by  <dig> probesets, each producing a different pattern when the a chip-values are compared to the plus chip-values. these results further indicate that these differences are not the result of any bias introduced during processing or normalization, but must reside in individual probes on each respective array.

the transcript for kiaa <dig> is detected by  <dig> different probesets. three of these probesets behave very similarly on the two array types. the fourth probeset behaves in the opposite manner . the individual probes in each probeset, and their locations on the two arrays, are shown in table  <dig>  the probesets that show the same behavior are nearly identical while the divergent probeset is distinctly different from the other three. on average,  <dig> of the  <dig> individual probes are identical for the  <dig> similarly acting probesets. the identically designed probes are also located side-by-side on the respective arrays. therefore, these three probesets are virtually identical in both sequence and location on the arrays and identical in the bias seen between the array types. this fact was also true of several other parallel probesets we examined .

we looked at the measurements recorded for the individual probes that comprise these probesets. we found that  <dig> of the  <dig> probes produced higher values on the u133a arrays than on the u <dig> plus arrays for probesets 206431_x_at, 215994_x_at, and 212054_x_at. conversely, the probeset 212052_s_at, which behaved in the opposite manner, had more individual probes yielding a higher value on the u <dig> plus arrays. therefore bias at the probe level appears to generate the bias observed for the full probeset. we looked at all the individual perfect match probes for the probesets that produced different measurements on the two array types. when the probeset produced a larger value in the u133a arrays an average of  <dig>  individual probes  were higher in the a arrays than in the u <dig> plus arrays. conversely, when the plus chip produced a higher value, an average of  <dig>  probes from these probesets were higher in the u <dig> plus environment.

we suspected that this bias might be due to a little bleed over from the surrounding probes on the array. we examined a number of individual probes. in many cases brighter probes surrounded the probes producing the higher values; however this was not universally true. more consistently, it appeared that the probes yielding higher values were just a little brighter on the arrays with the higher measurements. this suggested a possible manufacturing difference as the underlying cause rather than bleed over from neighboring probesets.

discussion
one of the most important considerations in performing a microarray experiment is that the data obtained at the end is an accurate representation of the rna present in the biomaterial used to start the process. bias can lead to erroneous conclusions if the bias happens to track with the experimental condition evaluated or obscures the differences because the bias is larger than the biological effect. bias can come from many sources  <cit> . when properly identified, bias can be corrected and a proper analysis can proceed. our data demonstrates that the array itself can contribute bias to gene expression measurements. it is quite understandable how different probe sequences could lead to different measurements in gene expression arrays. however, our data shows that even identical probe sequences can yield slightly different measurements of gene expression.

the impact of probe level variation depends on the nature of the question addressed in a microarray experiment. for a simple experiment performed in either platform the observed performance of a gene should be substantially reproduced by the alternative platform. however, if clinical samples are being accumulated for a disease state, the differences between platforms might prevent the pooling of samples processed in both platforms. this depends on the differences one finds in the experimental system. small differences might be obscured while large differences would still be observable. we observed that many of the probesets with target genes present in the universal reference rna showed differences greater than 2-fold. this bias could compromise experiments where the number of samples evaluated might otherwise allow one to detect differences less than 2-fold.

our data shows that microarray data can be very consistent at the same time as it shows a bias. overall, any two arrays produced with the universal reference rna yielded fairly consistent microarray results. the final measurements form a tight cluster of values for most probesets and the overall correlation was  <dig>  for any two arrays. however, a significant number of probesets produced two distinctly different or partially overlapping distributions when the array formats were viewed separately . therefore the bias due to the array is clearly evident even though the overall correlation was very high. sometimes a measurement was higher on the u133a arrays and sometimes it was higher in the u <dig> plus arrays. this could even be true for the same transcript, as one probeset yielded higher values and another probeset, detecting the same transcript, yielded lower values than the alternative platform. this shows that the bias was not due to processing, hybridization, or normalization artifacts. this observation has larger implications. it illustrates that it may not be possible to have all probes on an array performing exactly the same way so that all transcripts could be measured on equivalent scales.

the trend in microarray research is towards generating larger sets of data for analyzing complex biological problems and diseases. institutions are pooling resources to attain the large datasets required for analysis. several groups have already evaluated the comparability of data produced at distant sites  <cit> . there are also attempts to directly compare gene expression data from quite dissimilar microarray platforms as well as serial analysis of gene expression  and rt-pcr  <cit> . this push towards the direct comparison of microarray data from distant sites and dissimilar platforms is likely to continue. it is important to consider the differences in measurement observed on different array types.

since their introduction, microarrays have been forecast for clinical use. many people believe that patterns of gene expression will be used to identify disease states. diagnosis, prognosis, and treatment options are all believed to lie in patterns of gene expression. while some people begin the search for these patterns, the microarray community has also been working towards improving the technology to produce more reliable results. some sources of bias can be minimized or corrected. others will simply be accepted as part of the process. classifiers developed to interpret microarray data must allow for any variation that occurs in the measurement of individual probes. it remains to be determined whether the variation caused by the type of array will interfere with the performance or development of classifiers. for the present time it seems wise to use a single array type for the evaluation of microarray data. if the classification of samples relies on small gene expression differences, the classification may be microarray format specific. however, large differences will probably still be observed despite the small differences reported here between the u133a arrays and the u <dig> plus arrays.

CONCLUSIONS
microarray data is often useful beyond the intentions of the original experiment. the microarray community is continuously developing standards for microarray processing and data management that allows scientists to utilize microarray data held in repositories. much like sequence data, this stored gene expression information can be used in a multitude of creative ways. the comparison of microarray data between two formats, or even between two laboratories using the same format, requires knowledge about the sources of error that can arise in a microarray experiment. we have demonstrated that the same sequence can provide slightly different measurements of gene expression in different array formats. this implies that the comparison of microarray data between formats may require an additional, array specific, correction factor for each probe. the larger implication is that it may not be possible to establish equivalent correlations between the measured value in an array and the absolute value in a biological sample for every gene on an array. if sequence, as well as sequence context, introduces subtle adjustments to the final measured value of a transcript, then it may not be possible to know which measurement is the most accurate measurement of transcript abundance. therefore attempts to perform cross-platform verification either have to use gene specific correction factors or be satisfied with similarity rather than exact replication.

