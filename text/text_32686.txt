BACKGROUND
highly polymorphic genes constitute a major component of the functional genetics of biota. they are involved in many crucial functions including the regulation of self incompatibility in plants  <cit> , fungi  <cit>  and marine invertebrates  <cit> , immunity in vertebrates  <cit>  or insects  <cit> , sex-determination in insects  <cit>  and disease resistance in plants  <cit> . by definition, such genes display a very high number of alleles/variants within a single population or a single species, and many individuals are heterozygous for these genes. for instance, exon  <dig> of the mhc class ii gene drb has  <dig> variants in humans and displays an excess of heterozygotes within populations imgt/hla database, <cit> . another feature is their mode of evolution, promoting interspecific polymorphism mhc,  <cit> . this makes them particularly interesting in the study of community genetics e.g.  <cit> . furthermore, the potential involvement of highly polymorphic genes in inter-specific interactions outcomes may promote the emergence/persistence of biodiversity through speciation or diversifying selection processes  <cit> .

despite their important roles in genetics and evolution, in the context of medicine or agronomy, highly polymorphic genes are seldom studied within population and community genetics. in non-model organisms, one major limitation is the difficulty of genotyping high numbers of individuals. highly polymorphic genes are, by definition, prone to display numerous, extremely diverse variants as well as many heterozygotes within populations, which can hardly be genotyped using direct sequencing. the direct sequencing of amplicons would often result in the superposition of two very different sequences, giving mostly unreadable electropherograms. sequencing must therefore be preceded by the separation of the two copies  of the gene. for the classical sanger method, a previous step of cloning is necessary, which is expensive and time consuming. alternative methods rely on the indirect characterisation of sequence variability and involve capillary electrophoresis single-strand conformation polymorphism , denaturing gradient gel electrophoresis , high resolution melting curve analysis , pcr using sequence-specific primers , oligonucleotide chips or other related techniques see e.g.  <cit> . however, these indirect methods are not fully informative because of the non-negligible rates of homoplasy, i.e. preventing different variants from being distinguished based on sequence conformation e.g.  <cit> . moreover, they do not provide the nucleotide sequences, thus precluding many analyses in evolutionary and functional genetics. cloning the target sequences into bacteria and sequencing different clones using the sanger approach, so as to recover the different variants, may be required to further analyze relationships between migration patterns and sequences e.g.  <cit> . such approaches are expensive and time consuming and require many clones to be sequenced for each sample in order to guarantee a high probability of including all variants e.g.  <cit> . cloning-sequencing is often unaffordable for population and community studies, which require several hundreds of individuals to be genotyped.

over the last five years, the development of high-throughput genomic sequencing technologies has opened up new and exciting perspectives in evolutionary studies, biomedicine and agronomy  <cit> . the  <dig> gs flx  platform, for instance, allows the reading of  <dig> bp- to  <dig> bp-fragments. unlike the classical sanger method, the  <dig> technology includes an emulsion polymerisation chain reaction  before the pyrosequencing step  <cit> . this stage allows the isolation of each dna strand before sequencing, just as in the cloning-sequencing approach. this feature is of particular interest in the characterization of genetic variability of single highly polymorphic and multi-copy genes, for which many very different variants may co-occur within individuals. the main limitation of the  <dig> methods remains the high cost of each run . this cost is, however, compensated by the high number of reads produced in one run . it is thus theoretically possible to genotype a high number of individuals. such large-scale pyrosequencing of genes has been applied to detect snps and small deletions and insertions: for example those potentially involved in hereditary diseases and cancers  <cit> . however, the genetic variation observed in the mentioned study was not reattributed to original samples. large-scale pyrosequencing is thus a promising approach, provided that each read produced may be reliably attributed to its original sample. in this way, babik et al.  <cit>  have applied the  <dig> technology to genotype  <dig> individuals at the mhc class ii drb gene. different solutions have been proposed recently to allow a posteriori attribution of the sequences produced. one straightforward way to recover the original sample of a given sequence is to use nucleotide barcodes. they consist in short nucleotide sequences called 'tags' fixed at the extremity of dna strands. these tags must produce a unique barcode for each sample. those are either ligated to dna fragments to be sequenced  <cit> , or are included directly in the 5' end of the primers for sequencing amplicons . for both approaches, the number of different tags to be synthesized is equal to the number of samples to be genotyped. by contrast, the method designed by bierne et al.  <cit>  for cloning-sequencing studies is based on the combination of tags in the forward and reverse primers. only n sets of primers are thus required for the coding of n <dig> samples. this approach has recently been applied to  <dig> sequencing system  <cit> .

here we describe a  <dig> approach that shows similarities with the one developed by babik et al.  <cit> , but that is optimized for the analysis of thousands of individuals in a single region of a  <dig> plate. using one half of a  <dig> run, we were able to barcode pcr amplicons from  <dig> samples of rodents, corresponding to  <dig> species. we used combinations of tagged primers, for a nuclear gene that is known to be highly polymorphic in mammals, the mhc class ii drb gene for a review see  <cit> . amplicons were multiplexed for the empcr to produce a high number of reads in a single run. the tagged primers also allowed a posteriori attribution of most reads to their sample of origin. we then proposed a stepwise procedure for data analysis and variant validation. sequences containing errors have previously been shown to occur in some reads during  <dig> sequencing  <cit> . those needed to be distinguished from correct sequences. we developed a probabilistic model to provide a confidence level for each genotype observed. this model will also be useful for optimizing the number of samples to be multiplexed in one  <dig> run.

methods
samples and dna extractions
the experiment was based on  <dig> rodent tissue samples  collected between  <dig> and  <dig> in europe, southeast asia and caribbean islands. these samples corresponded to  <dig> individual rodents belonging to  <dig> different species and  <dig> genera. reproducibility of the genotyping was estimated for  <dig> samples that had been randomly chosen from the dataset and processed twice for the entire procedure.

dna was extracted from the  <dig> samples using  <dig> plates of the dneasy tissue kit  following the manufacturer's recommendations. various steps of the experiment were carried out using rigorous laboratory protocols to prevent contamination by alien dna and amplicons. pcr plates were prepared in a dna-free room and under a sterile hood. we systematically used filter tips for the different steps of dna extraction and pcr. the absence of contamination was checked at this stage and along the whole laboratory procedure using three negative controls per extraction plate. they corresponded to one extraction blank , one pcr blank  and one aerosol blank .

the total dna set was then divided into two sets of  <dig> dna samples, referred to as pool a and pool b. these pools were independently analyzed using the same combination of barcodes. this allowed the relative efficiency of the different barcodes to be determined.

tagged primer design, pcrs and sequencing
we used the target-specific primers developed by schad et al.  <cit>  to analyze exon  <dig> of the drb gene in rodents. these primers are js <dig>  and js <dig> . they amplify a  <dig> bp fragment  of exon  <dig> from the drb gene in several mammal species  <cit> . one or several copies can be amplified with this set of primers depending on the rodent species considered . there was no prior knowledge on drb variability and duplication for all species studied except m. glareolus and apodemus sp. in our experiment. these primers were modified by adding a short  <dig> bp sequence  and  <dig> bp adaptors to the 5' ends of js <dig>  and js <dig> . these adaptors were required for the empcr and  <dig> pyrosequencing . the key sequence tcag at the 3' ends of both adaptors a and b, which were used during the basecall step as a quality control  measure to validate the reads. primers were synthesized by eurogentec and purified using the standard selective precipitation optimized process .

we designed  <dig> different tags for the forward primers, and  <dig> different tags for the reverse primers . this leads to  <dig> potential unique combinations of forward and reverse tags. samples were individually barcoded during the preparation of the pcr plates. thirty-six forward primers were dispensed into the plates 'vertically', so that each row contained a different forward primer, while the  <dig> reverse primers were dispensed 'horizontally', with wells in each column containing a different reverse primer . thus, each well harboured a single, unique 6-bp barcode through the combination of forward and reverse tags.

pcrs were carried out in a  <dig> μl reaction volumes containing  <dig> mm mgcl <dig>   <dig> μm dntps,  <dig>  μm of each primer and  <dig>  u amplitaq gold®  in the appropriate 1× pcr buffer ii and de-ionized dna- and rna-free water. dna samples were added to this reaction mix in a separate room to avoid dna contamination. dna  was added to each well. the pcr was optimized through touchdown protocol. samples were subjected to initial denaturation at 95°c for  <dig> min, followed by  <dig> cycles of denaturation at 94°c for  <dig> s, annealing with touchdown at 65°c to 55°c  for  <dig> s and extension at 72°c for  <dig> s, followed by  <dig> cycles of denaturation at 94°c for  <dig> s, annealing at 55°c for  <dig> s and extension at 72°c for  <dig> s, with a final extension phase at 72°c for  <dig> min. pcr products  were checked on a  <dig> % agarose gel. the remaining pcr products were sent to cogenics™ genome express where pyrosequencing was carried out using a  <dig> gs flx system .

all pcr products were analyzed using the labchip®  <dig> system and dna chip  <dig> k from caliper life science. this microfluidic electrophoresis allows fragment size and individual amplicon concentration, excluding primer and dntp residues, to be determined. as described above, two equimolar pools  of amplicons were produced. to eliminate unspecific products, the two pools were run on an agarose gel and purified by gel excision of fragments of  <dig> bp ±  <dig> bp. the quality of the pools were checked by size range analysis using a dna  <dig> assay on the  <dig> bioanalyzer  and quantified by fluorescent measurement using the quant-it™ picogreen® dna assay .

the empcr, corresponding to clonal amplification of the purified amplicon pool, was carried out using the gs empcr kit ii . briefly, amplicons were immobilized onto dna capture beads. the amplicon-beads obtained were added to a mixture of amplification mix and oil and vigorously shaken on a tissue lyser  to create "micro-reactors" containing both amplification mix and a single bead. emulsion was dispensed into a 96-well plate and the pcr amplification program was run according to the manufacturer's recommendations. following amplification, the emulsion was chemically broken and the beads carrying the amplified dna library were recovered and washed by filtration. positive beads were purified using the biotinylated primer a , which binds to streptavidin-coated magnetic beads. the dna library beads were then separated from the magnetic beads by melting the double-stranded amplification products, leaving a population of bead-bound single-stranded template dna fragments. the sequencing primer was then annealed to the amplified single-stranded dna. lastly, beads carrying amplified single-stranded dna were counted with a z2™ cell counter .

pools a and b were simultaneously processed in one gs flx run using one half of a  <dig> ×  <dig> mm pico-titer plate device  and one gs lr- <dig> sequencing kit . briefly, the  <dig> ×  <dig> mm pico-titer plate was divided in four sections  using the medium regions bead loading gasket . according to the manufacturer's recommendations for amplicon sequencing,  <dig>  dna beads were loaded for each pool mixed with an appropriate volume of packing beads and enzyme beads. after the pre-wash run, the sequencing run was started with the "full analysis for amplicon" parameter set.

bioinformatics and data processing
a non-negligible number of errors are generated during pcr  <cit>  and pyrosequencing  <cit> . non-specific amplification may also occur. we thus developed a stepwise data processing procedure aimed at detecting and discarding most of the reads that exhibit sequencing errors or that correspond to genes other than the targeted gene . this procedure relied on three assumptions. first, reads with errors were expected to appear at lower frequencies than reads without errors in the whole dataset and for each individual sample. this assumption was validated using a probabilistic approach. considering the probability of substitution errors, the probability of artifactual variants  occurring in our dataset was ≈  <dig> , and the probability of observing three times the same artifactual variant is very low, p <dig> ≈ 10- <dig> . second, reads exhibiting indels with lengths that are not multiples of three base pairs were considered as artifacts because they would induce shifts in the reading frame. third, the reliability of the genotype obtained for a given individual sample should depends mainly on the number of sequences obtained for this sample and on the number of copies of the gene in the species studied.

see text for the definitions of assumptions and thresholds.

our validation procedure involved four consecutive steps . briefly, the first cleaning step allowed removal of most imperfect reads from the dataset . the next two steps were based on thresholds under which the number or frequency of sequences obtained per sample was insufficient to provide reliable genotypes. rationales and procedures for establishing these thresholds are described below. the last step involved the alignment of remaining sequences using mega  <dig>   <cit> . this step allowed the detection and elimination of sequences that corresponded to pseudogenes, paralogs and recombinant chimeric sequences originating from a mixture of sequences of two different variants e.g. for chimeric sequences produced during pcr see  <cit> . paralogs and pseudogenes were then identified using nucleotide blast against all sequencing data available in genbank .

basic statistics and genetic diversity
we calculated simple statistics for the whole dataset and independently for pools a and b. statistical parameters took into account the total number of reads , the total number of sequences , the total number of variants  and the number of sequences obtained for each variant j . these same statistical principles were applied for each individual sample i as the total number of sequences , the number of variants , the number of sequences for each variant j  and the frequency of each variant , corresponding to nij/ni.

thresholds for genotype and variant validation
we then determined a confidence level for each genotype. the rationales for this was that  a minimal number of sequences are required for reliable genotyping; and  true variants must be sequenced several times within the same sample in order to be validated and distinguished from artifactual variants . we first defined the threshold t <dig>  corresponding to the minimal number of sequences required per individual to determine its complete genotype, with a low probability of missing variants. we computed the probability of amplifying at least r times all the variants of the gene studied for a given sample. this probability was based on n, the total number of true sequences obtained for the sample, and m, the maximal number of variants for the gene within a sample. the value m depends on the number of gene copies and on the degree of ploïdy of the studied organism. for instance, m =  <dig> for a single copy of a nuclear gene within a diploid genome, and m =  <dig> for a duplicated nuclear gene within a diploid genome, or for a single-copy nuclear gene in a tetraploïd genome, and so on. a program is now freely available on the web http://www.lirmm.fr/~caraux/bioinformatics/negativemultinomial/ to calculate the probability f of having at least r sequences of each of the m variants potentially observed within the n sequences of a given sample. here, we considered and discussed different values for r  and for m .

we then defined a second threshold, t <dig>  to eliminate artifactual variants that arose from substitution errors. based on our initial assumptions and in accordance with the results of our probabilistic calculations , artifactual variants should occur at much lower frequencies than true variants. we therefore analyzed the distribution of variant frequencies calculated individually for each sample . we expected multinomial-shaped distributions with one peak at very low frequency values corresponding to artifactual variants and several peaks at medium-high frequency values corresponding to true variants. these peaks should include a very high frequency peak , corresponding to homozygous samples, and one or more peaks of medium frequency values , corresponding to heterozygous samples. ideally, the threshold value t <dig> should be chosen to discard most of the artifactual variants and none  of the true variants.

validation and efficiency of the method
we analyzed the efficiency of barcoding by comparing the number of sequences obtained for each tag between pools a and b. we used a one way anova with the number of sequences as an independent variable, and the reverse tag, the forward tag and the pool as dependent qualitative variables. all two-way interactions were tested and removed when not significant. this analysis was performed on the dataset obtained after the first step of the data processing. the number of sequences was log-transformed to normalize its distribution. post-hoc pairwise comparisons were performed with the tukey-kramer method. we then compared the genotypes obtained for the  <dig> replicated samples to investigate the reproducibility of the genotyping. finally, we examined the distribution of the frequency of true and artifactual variants within samples . all analyses were performed using genstat  <dig>  .

RESULTS
none of the  <dig> blanks were found to be positive after pcr amplification. we obtained  <dig>  quality control  reads overall , with ra =  <dig>  for pool a and rb =  <dig>  for pool b. this difference between pools was probably attributed to the difference in dna concentration between pool purifications, which was  <dig>  and  <dig>  ng/μl for pools a and b, respectively.

data processing
step 1
the first step was the detection and suppression of most of the imperfect reads . we had some difficulties in determining sequence using reverse tags starting with base g. these tags formed a homopolymer gg with the "key" sequence . in this case it appears that the g of the tag was removed altogether with the key sequence during the data processing with the gs-flx data analysis software, creating a shift of one base in tag and sequence reading. this problem was encountered for eight reverse tags . we performed an ad hoc analysis, focusing on the two last bases of the tags, allowing sequence information to be recovered for six of the eight tags. after the elimination of imperfect reads, the number of sequences per variant displayed an l-shaped distribution . the number of reads that could be assigned to variants in each pool were  <dig>  and  <dig> , corresponding to  <dig>  and  <dig>  variants, in pools a and b, respectively. we found  <dig>  variants  and  <dig>  variants  to occur only once in datasets a and b, respectively. the minimum and maximum numbers of sequences assigned per variant were  <dig> and  <dig>  sequence per variant in pool a, and  <dig> and  <dig>  in pool b. variants occurring only once and variants containing indels were then removed from both datasets. this considerably reduced the datasets and facilitated further bioinformatic manipulations.

at the end of the first step, we had na =  <dig>  and nb =  <dig>  sequences, corresponding to aa =  <dig>  and ab =  <dig>  variants for pools a and b, respectively. altogether, about 33% of the reads were eliminated in the first step. over the  <dig> samples studied in each pool, we succeeded in assigning sequences for  <dig> of them in pool a and  <dig> in pool b. the number of sequences obtained for each sample strongly depended on the sample considered . averages of sequences per sample were respectively nai =  <dig>   and nbi =  <dig>   for pools a and b. overall we did not obtain any sequence for  <dig> samples. this was explained for  <dig> samples by low amplicon concentrations observed before pooling  and probably resulting from poor dna conservation. for the  <dig> other samples, the reverse tag sequence could not be recovered because of the formation of a homopolymer with the sequencing key .

step 2
the aim of the second step was to provide a confidence level for each genotype produced. we estimated the probability of amplifying at least r times all the different variants of the gene studied for a given sample. this probability depended on n, the total number of true sequences obtained for the sample, and m, the maximal number of variants for the gene within a sample . we then plotted the probability f against the number of sequences n for different values of r and m . as expected, we observed that for a given probability, n must be increased when r and m values increase. that means that to achieve a given confidence level, more sequences per sample  are required when the number of copies amplified of the gene under study  increases, or when the number of sequences required for validating an variant as true  increases. to further analyze our results, we fixed the r-value to three. this value was based on statistical considerations. actually, we showed that the probability of observing three times the same artifactual sequence was very low, p <dig> ≈ 10- <dig> . moreover it also corresponded to the standard procedure in mhc gene studies where three independent observations of the same sequence are recommended to validate a variant that has been identified through a cloning-sequencing approach see  <cit> . furthermore, our approach allows choosing any other value of r and x, depending on particular characteristics  in other experiments.

the threshold t <dig>  was then calculated for r =  <dig>  giving a confidence level of 10- <dig> . simulations showed the threshold value t <dig> ranged from t <dig> =  <dig> for a single copy gene in diploid species to t <dig> =  <dig> for an octaploid species, or for a quadruplicated gene in a diploid species. in a similar way, t <dig> =  <dig> for a single copy gene in tetraploid species or for a duplicated gene in a diploid species. samples with a number of sequences n <t <dig> were then removed from the dataset, as their genotypes were not considered to be reliable. at this stage,  <dig> samples were removed from the dataset, corresponding to 5% of the samples.

step 3
the third step involved separating true from artifactual variants within each sample, based on the frequency of variants within samples . we plotted the distribution of fij after grouping data based either on the number of copies of the drb gene  or on taxonomy . all distributions obtained displayed the expected multimodal shape, with three peaks corresponding to frequencies of 1-4%, 30-60% and 80-100%. a few exceptions were detected, however. maxomys, in which the drb gene is quadruplicated, showed no variants in the 80-100% range, consistent with the absence of homozygotes. by contrast, niviventer showed a low occurrence of variants in the 30-60% range, associated with a high occurrence of homozygotes. for the other species, we fixed the threshold t <dig> value to 4%. all variants with fij <t <dig> in a given sample i were removed from the sample i, being considered as artifactual within the particular sample. by the end of this step,  <dig>  sequences, corresponding to  <dig> variants, were conserved for pool a and  <dig>  sequences, corresponding to  <dig> variants, were conserved for pool b. this step allowed the mean number of variants per sample to be reduced from  <dig> to  <dig> , suggesting that most of the artifactual variants had been removed from the dataset.

step 4
the sequences of the remaining variants were aligned separately for each sample, and analyzed by eye . we detected pseudogenes that were orthologous to the rt1-hb gene of the laboratory rat rattus norvegicus. we also found variants that were orthologous to the dqb gene, a paralog of the drb gene, belonging to the same mhc class ii multigenic family. recombinant chimeric sequences were quite common in the dataset, occurring at high frequencies  in some samples. they were easily detected in alignments because their sequences originated from a mixture of the sequences of two different, true variants occurring in the same sample. after removing those non-specific variants from the data set, the number of sequences became lower than t <dig>  for  <dig> samples. those samples were then eliminated, as their genotypes were not considered to be reliable.

at the end of our data processing procedure,  <dig> samples were reliably genotyped  over the  <dig> initially processed . moreover,  <dig>  sequences and  <dig> variants had been retained in pool a, as where  <dig>  sequences and  <dig> variants in pool b. overall,  <dig> different variants were characterized and sequenced, with an average of  <dig> sequences per variant . of the  <dig> variants finally validated by our data processing for exon  <dig> of the drb gene,  <dig> had been previously reported in genbank .

barcode bias
the anova conducted on the numbers of sequences remaining after step  <dig>  was significant . the interaction between the two factors, "forward tags" and "reverse tags", could not be statistically tested in the anova. the analysis showed significant differences between pools  and between forward tags . the use of forward tags cac and cgc resulted in lower numbers of sequences, whereas tca, tct and tgt led to higher numbers of sequences . interactions between pools and tags were significant and showed that differences between tags were not consistent between pools . the lower numbers of sequences obtained for the forward tags cac and cgc were only significant in pool b. among reverse tags, gct was associated with the lowest number of sequences in pool a, whereas cac had the lowest number of sequences of all the other tags in pool b. thus, despite finding some significant differences, no systematic bias could be related to tag sequences.

genotype reliability
among the  <dig> replicated samples, only  <dig> were successfully genotyped twice by the end of our bioinformatics procedure. unfortunately, the  <dig> other samples could not be genotyped twice due to the formation of homopolymers by particular tags . of these  <dig> samples,  <dig> displayed the same genotype in both replicates. the three samples showing non-identical genotypes were heterozygous for one replicate and homozygous  for the other. in one case, the 'missing' variant had been amplified, but its frequency within the sample  was lower than the t <dig> threshold value . overall, the reproducibility of our genotyping was 95%.

further analysis allowed the examination of  <dig>  sequences, corresponding to  <dig> variants. true variants accounted for  <dig> ± 8%  of the sequences produced within samples, substitutions  accounted for  <dig> ± 5%, insertions  for  <dig> ± 3%, deletions  for  <dig> ± 9%, chimeras for  <dig> ± 7% and other genes  for  <dig> ± 2%.

efficiency of the method
we were able to genotype  <dig>  rodent samples from  <dig> different species at a confidence level of 10- <dig>  maxomys and niviventer genera showed the lowest genotyping success rate . the quadruplication of the drb gene in maxomys  may account for most of the difficulties in genotyping these animals. however, niviventer seemed to have a high occurrence of null alleles, with many individuals producing only a small number of sequences, and most other individuals being homozygotes . the genotyping success rate was fairly high, generally above 90%, for all other species.

the confidence level used for validating genotypes was fixed at 10- <dig> 

discussion
recent development of high-throughput genomic sequencing, considerably reducing the costs of sequencing, has opened up new perspectives for modern biology  <cit> . here, we report a new laboratory procedure allowing the multiplexing and sequencing of one or several pcr amplicons for hundreds of samples in only one  <dig> run, allowing most of the reads generated to be attributed to their samples of origin. data processing procedure and probabilistic model were developed for the validation of new variants and the estimation of confidence levels for each genotype produced. these procedures gave promising results, resulting in the successful genotyping of  <dig> rodent samples from  <dig> different species, and the sequencing of  <dig> different variants of the drb gene  in only one half of a standard  <dig> picotiter plate. replicates confirmed the high reproducibility  of this genotyping method.

comparison with other methods
the method described here is particularly suitable for the determination of genotypes and sequences for highly variable and potentially multiplicated genes. for example, the high level of variant diversity observed for exon  <dig> of the drb gene in myodes glareolus  prevents the use of classical methods like sscp and dgge. these methods are based on differences in migratory patterns during electrophoresis. as they do not directly provide information on the variant sequences, they are subject to homoplasy , thus preventing complete resolution for variants exhibiting a similar conformation or related sequences e.g.  <cit> . nevertheless, these methods are useful for datasets containing a restricted set of variant forms e.g. in endangered species,  <cit> . they may be inadequate, however, for use in population genomics/genetics, involving large datasets of thousands of individuals. indeed, in this study, it is unlikely that as many as  <dig> variants, or even the  <dig> variants identified for the bank vole myodes glareolus, would have been distinguishable on the basis of their migratory patterns. alternatives such as pcr-ssp, which is based on amplification using primers that are specific to a group of variants, were developed to overcome this technical constraint e.g.  <cit> . however, in addition to a poor resolution , pcr-ssp requires a priori knowledge of all the variant forms present in the population under study. as oligonucleotide chips, it is thus not suitable for most studies on non-model organisms. in our study, only  <dig> of  <dig> variants reported were already deposited in genbank. based on these observations, the reproducibility of our genotyping  was very satisfactory. the reproducibility of the classical methods described above is unlikely to ever approach this high value. moreover, at least a part, if not all, of our failed results could be due to the low specificity of our primers for some variants, rather than to our genotyping method. another disadvantage of using these indirect methods for variant characterization is the difficulties encountered to compare datasets generated in different laboratories, or in the same laboratory but at different times. such comparisons require complementary techniques to relate the migration patterns, obtained using different machines or laboratories, to a given allelic form. such limitations inevitably preclude meta-analyses. lastly, indirect methods additionally require many pcr products to be sequenced in order to link the sequence to a particular migration pattern and thus to establish the migration patterns associated with particular allelic forms. in cases involving different allelic forms in the same individual, or in cases where the genes are duplicated or when selection favours heterozygotes  <cit> , further manipulations are often needed before sequencing, such as gel excision or cloning. these additional manipulations are time-consuming and costly.

the  <dig> system overcomes most of these limitations by making the variant sequences directly available during genotyping. furthermore, the variant does not need to be isolated before sequencing. indeed, the  <dig> methodology includes empcr, which separates the different dna strains during the first processing steps. consequently, the datasets can be studied without limitations concerning the number of variants to be detected and without any prior knowledge of the allelic forms present. datasets from different laboratories may then be easily concatenated for the purpose of meta-analyses. this approach is suitable for genotyping individuals harboring high numbers of allelic forms. other methods based on  <dig> system have been developed previously and show some similarities with ours. babik et al.  <cit>  carried out a  <dig> run to genotype  <dig> rodents myodes glareolus at exon  <dig> of the drb gene. they used  <dig> different tags and carried out  <dig> different purifications . by comparison, our method requires only a single purification step after dna pooling, and a far smaller number of tags than samples for barcoding. moreover we did not need to perform a library to ligate the adaptator prior to the empcr. this reduces the number of steps  during the laboratory experiment, and also greatly reduces the total cost of the experiment .

variants and genotype validation
in contrast to previous studies, our data processing relied on a probabilistic model to establish clear and objective thresholds for sequence and genotype validation. other studies have described alternative criteria. babik et al.  <cit>  validated variants on the basis of their frequency within individuals. they considered variants with an observed frequency lower than 3% as artifacts, and thus removed them from the dataset. variants were also validated based on their dissimilarity with the four most commonly found variant in a given sample. the validation score decreased when the similarity increased. this filter did not include the detection of chimeras, since chimeras are very dissimilar from both parent variants and may occur at a non-negligible frequency within individuals. in our study, we found chimeras to occur at a mean frequency of 6%. such limitations in the variant validation procedure could partly explain the high number of variants per individual reported for myodes glareolus in the previous study . using our data validation procedure, chimeras are discarded in the last step involving sequence alignment and blast analyses. another validation criterion used by babik et al.  <cit>  was the need for a sequence to occur in at least two different samples. this criterion could lead to the removal of many variants that are rare in populations. such a bias may lead to misinterpretation of the principal mode of selection operating on the gene under study, or of the demographic tendencies of the population under study. indeed, rare variants may be indicative of certain types of selection or demographic events. for example, population expansion, purifying selection or selective sweeps may result in an excess of rare variants  <cit> . our variant validation procedure overcomes the problem of discarding rare variants because it analyzes each sample separately. our procedure should also provide reliable results in cases where a given variant may be an artifact in one sample but a true variant in another sample. another improvement of our validation process is that we describe a statistically based approach for determining a threshold  for validating genotypes. the value of this threshold t <dig> may be redefined according to the number of copies of the amplified gene and to the ploidy level of the species studied. our findings clearly illustrate this point. indeed, the number of sequences per sample was sufficient for genotyping most of our rodents with the exception of maxomys that displays multiple copies of the gene. finally we recommend the systematic use of replicates for each  <dig> run, allowing the reproducibility of the genotyping procedure and, thus, the reliability of the run, to be estimated.

optimizing tagging and sample numbers
our barcoding method led to 69% of the reads obtained being assigned to samples. this proportion is lower than the >95% reported by binladen et al.  <cit>  and meyer et al.  <cit> , who used alternative barcoding methods. the efficiency of our method could probably be improved by using a titanium kit  that provide longer reads. we estimated that 9% of the reads that were unassigned were too short and did not encompass the full length of the sequence for exon  <dig> of the drb gene. an estimated 8% of unassigned reads were attributed to the use of tags that form homopolymers gg with the key sequence . it should thus be of utmost importance to exclude such tags from the experiment. additionally, our criteria for the validation of reads in the first step of data processing may have been too stringent. the search for perfect matches with the complete primer sequences probably led to the elimination of a large number of reads. this criterion was established to discard reads that could present subsequent shifts in the reading frame of the tag . alternatively, a perfect match with only  <dig> to  <dig> bp of 5' sequences of the primers may have been sufficient to discard reads associated with reading frame shifts, and may have therefore allowed more reads to be assigned to samples. finally, it may be possible to reduce the probability of incorrectly assigning reads to a sample due to sequencing errors within the tags. it is widely advised to use tags that differ by more than one substitution  <cit> . however, this reduces the number of combinations and thus the number of samples that can be multiplexed. increasing the number of nucleotides within tags could counterbalance this limitation.

the probabilistic model that we developed may be used for optimizing the  <dig> run. when designing a  <dig> run, it is important to take into account the fact that intcreasing the number of samples results in fewer reads being retrieved for each of them. the optimal number of samples to be multiplexed for genotyping with a given level of confidence can be determined by simulating data before the run. the number of copies in the genome for the gene of interest must first be fixed, as well as the confidence level required. the model will then generate the number of sequences required per sample to give this confidence level. the number of reads guaranteed by the provider divided by the number of sequences generated by the model will then give the optimal number of samples to be multiplexed.

CONCLUSIONS
we have described a method for barcoding and multiplexing hundreds of pcr-amplicons using half of a  <dig> plate. we were able to reassign about 69% of the reads generated to their sample of origin. the high number of reads obtained for each sample then allowed the genotype of each sample to be generated. we then used a probabilistic model allowing variant validation and attribution of a confidence level for each genotype based on several objective criteria. using this approach, we obtained genotypes for exon  <dig> of the drb gene in  <dig>  samples from  <dig>  rodents, belonging to  <dig> species. the drb gene is a highly variable coding gene that may be duplicated several times in mammalian genomes.

this method may be improved in several ways. first, using longer tags may increase the proportion of reads that are finally assigned to their sample of origin, increase the number of samples multiplexed and decrease the risk of misassignment. second, the number and order of the different filters  may be modified and threshold values  adapted to specific studies and genes. here we applied three different filters that are very different by nature. the first filter  is related to the occurrence of variants within the whole dataset. it consists in withdrawing all the variants occurring only once in the dataset, which considering our criteria would not have been validated at the end of the process in any case. the second filter  is related to the number of sequences yielded for each sample. it allows the elimination of samples  displaying too few sequences to be reliably genotyped according to our probabilistic model. the third filter  is related to the number of sequences obtained for each variant within each sample. it consists in withdrawing variants that are present in low frequency within the samples. it should be noted that we decided to withdraw all variants occurring only once in the data set at the very beginning of our processing mainly for practical reasons. this considerably reduced the size of the dataset  and greatly facilitated further manipulations. yet this filter may be unnecessary because unique sequences will be in any case removed during step  <dig>  besides we found logical to remove samples with too low numbers of sequences  before trying to discriminate true from artifactual variants within samples. this was done because our main objective was to get as many reliable genotypes as possible. this filter may not be optimal for other purposes, like acquiring as many variants  as possible for phylogenetic analyses, for instance. lastly, the probabilistic model that we developed may allow the number of samples multiplexed in one  <dig> run to be optimized, as a function of the confidence level required for each genotype. the probabilistic approach proposed here may be improved in order to take into account biases in pcr-errors and yields. our probabilities strongly depend on restrictive hypotheses . in this respect, our approach may provide null expectations for pcr-bias testing. non-random processes in pcr-errors and yields like unequal probabilities of nucleotide changes, pcr-competition among variants and errors hotspots may  induce significant departures from our predictions. in our paper we provide a rough estimate of the probability of substitution errors based on our data . more accurate estimates may result from inclusion of internal controls , which should be systematically incorporated in future experiments. moreover, because most pcr-biases are expected to depend on data  as well as experiments , we think that more realistic models should further be based on the use of internal controls for model selection and parameter estimation. in the meanwhile we recommend compensating for such potential biases by choosing a high theoretical level of reliability for genotyping  within our neutral model. finally, an automated bioinformatics pipeline based on our stepwise procedure is currently being developed and will be available to other projects that may benefit from this genotyping approach. we believe that this methodology will be very useful for evolutionary and functional studies in the near future.

authors' contributions
the study was conceived and designed by mg, and was coordinated by nc and jfc. nc, gc and jfc performed the statistical analyses. mg and eg carried out the molecular biology procedures, the sequence alignment and the validation of the  <dig> sequencing data. gc devised the probabilistic program. mg and jfc wrote the manuscript. gc, eg and nc helped to draft the manuscript. all authors have read and approved the final manuscript.

supplementary material
additional file 1
additional information. probabilities of observing artifactual sequences by substitution errors. probability f of observing at least r sequences of each of the m variants potentially observed for the n sequences of a given sample.

click here for file

 additional file 2
fig s <dig>  fig s <dig>  fig s <dig>  fig s <dig>  figure s <dig>  histograms showing the number of sequences obtained for individual variants  for pools a and b. insets display distributions for values below fifty. figure s <dig>  histograms of the number of sequences obtained for each sample  after the first step of data processing for pools a and b. figure s <dig>  confidence level for genotyping. f is the probability of amplifying, at least r times, all the different variants of the gene studied for a given sample. this probability depends on n, the total number of sequences by sample, and m, the maximal number of variants for the gene within a sample. t <dig> is the threshold value that corresponds to the minimal number of sequences required per individual to determine its complete genotype, with a 10- <dig> probability of missing variants. plots are given for different values of r =  <dig>   <dig>   <dig> and  <dig>  figure s <dig>  the number of sequences obtained for each forward and reverse tag after the first step of data processing for pools a and b.

click here for file

 additional file 3
fig s <dig>  fig s <dig>  figure s <dig>  histograms showing the distributions of fij, the frequency of each variant j within each individual sample i. data were grouped as a function of rodent genera. m is the maximal number of variants for the gene within a sample. figure s <dig>  true and artifactual variants of drb exon  <dig> for a black rat . the two variants validated by our data processing are shown in green and blue, respectively. we obtained  <dig> sequences for the variant highlighted in green and  <dig> for the blue variant. other variants are artifactual . variants corresponding to a mixture of blue and green correspond to recombinant chimeric sequences derived from a mixture of sequences of drb* <dig> and drb* <dig>  other artifactual variants corresponded to substitutions , indel , pseudogenes orthologous to rt1-hb  and the paralog dqb .

click here for file

 acknowledgements
we thank s morand and jp hugot for managing research projects in asia, h hentonnen for research projects in europe, and y chaval for help in field work. jf martin and n bierne provided helpful comments on laboratory protocols, j serret helped in some laboratory experiments and e meglécz helped for bioinformatics. r streiff gave constructive comments on early drafts and l manso-silván improved the style of written english. this work was supported by the institut national de la recherche agronomique , the french national agency for research project ceropath  and the european project eden . e guivier was funded by a mnrt  phd grant. the manuscript is catalogued by the eden steering committee as eden <dig> http://www.eden-fp6project.net.
