BACKGROUND
metagenomics has been defined as the thorough analysis of the genetic material as directly recovered from environmental samples, including that which is obtained from unculturable organisms  <cit> . following the emergence of metagenomics, its quick development responded to the popularization of next-generation platforms. these enabled faster and higher throughput approaches to accurately describe the genetic diversity and elucidate the complex relationships existing between the organisms in different ecological niches. more recently, metagenomics has proven useful for the discovery of new enzymatic functions  <cit> , microorganisms and gene products that may be used for bioremediation  <cit>  and has contributed to the understanding of host-pathogens interactions  <cit> .

the human microbiome has been of special interest in this field, with significant efforts to understand changes in the microbiota or dysbioses that may have an important role in human health and disease  <cit> . the gut is the most densely populated niche in the human body, housing over  <dig> microorganisms. it has been determined that the core of the intestinal microbiome is constituted by a definite number of nearly ubiquitous species that show a high variability in terms of abundance  <cit>  and that this core of species is not shared between close relatives  <cit> . even though this has been thoroughly explored, as much as 75% of the predicted open reading frames from metagenomic analyses fail to be assigned a function  <cit> .

most of the previous efforts in metagenomics have been directed towards the survey of prokaryotes and only a few have had bacteriophages and other viruses as their main focus of study. published viral metagenomes display a low intrapersonal viral diversity and population stability over time but higher levels of interpersonal viral variation  <cit> . unlike bacteria, gut bacteriophage populations do not seem to be related between mothers and their twin descendants  <cit> . the main limitation of working with viral metagenomes is that nearly 80% of the reads yield no significant matches against extant database entries, whereas the remaining 20% are mainly identified as of bacterial origin  <cit> . such limitations may be explained by the lack of closely related sequences in databases, a common issue with previously unreported viruses and prophages. since data availability is generally biased towards the most studied human viruses, most databases do not contain enough information to successfully assign identity to the great majority of viral sequence queries from environmental samples. read length is an additional limitation as reads that are too short often fail to yield functional or taxonomic assignments. as these issues are not restricted to viral metagenomes, microbiome-specific programs have been adapted to address them.

in recent years, several next-generation sequence assemblers have been developed to deal with specific features such as read length, uneven genome coverage values within datasets, efficient managing of computational resources and highly mutational sequence reads. this study focuses on those assemblers that can operate with  <dig> pyrosequencing data, a technology that has been widely used because of the reads length and sequence coverage, desirable characteristics for de novo assemblies and functional annotation  <cit> . only assemblers previously used or hinted as possible alternatives for viral metagenomic projects have been considered.

overlap-layout-consensus  algorithms have proven more efficient for dealing with  <dig> outputs  <cit> . for this analysis, two of the most popular olc assemblers were used, celera and newbler, which have been extensively used in viral and bacterial shotgun metagenomic projects  <cit>  and in silico experiments  <cit> . additionally, two other olc assemblers were tested following the authors’ recommendations for working with virus: minimo, designed for the assembly of small datasets  <cit>  and previously used for virome analyses  <cit> ; and vicuna, an assembler specialized in de novo assembly of data from heterogeneous viral populations  <cit> . its authors had only used this assembler with single viral populations .

assemblers that make use of different algorithms have also been included in this study as alternatives to olc assemblers. velvet is one of the most popular de bruijin graph assemblers  <cit>  and has been used on viral metagenomes using  <dig> sequence data  <cit> . metavelvet, designed for metagenomic assemblies, is capable of handling different genome coverage values within the different species in the metagenome  <cit> . finally, genovo, an assembler based on generative probabilistic model of read generation, was selected because it uses an iterative algorithm able to estimate the number of genomes in the populations and denoise  <dig> sequence data  <cit> .

to compare the assemblers, two metagenome datasets were simulated, one composed solely of viral genomes and a second one including prokaryotic and viral genomes . both were based on actual abundance data obtained by reyes et al. <cit> , using the corresponding organisms' reference genomes, obtained from the viral and bacterial ncbi genome database, with the same coverage shown in the actual data.

a critical limitation in viral metagenomes assembly is the lack of a ubiquitous marker, analogous to bacterial 16s rdna, to identify viral particles and estimate their diversity within ecological niches. additionally, viral phylogeny based on sequences is impaired by extensive horizontal gene transfer and genome modularity within taxa, which is further complicated by the large numbers of viral particles within environmental samples. this makes it very difficult to find homologous sequences in reference databases. to cope with this, different databases  <cit>  and algorithms have been designed which base or complement their taxonomic assignments with genomic features, outperforming pairwise alignment-based approaches such as phylopythia  <cit>  and phymmbl  <cit> . other methods that determine taxonomy based solely on k-mer frequencies  <cit>  to improve the sensitivity of taxonomic assignations have not been tested in the context of viral metagenomes. information on viral communities is still vague and feedback is required for the bioinformatic tools currently in use.

in this work, three approaches for taxonomic assignation were tested. they were selected on the base of their high sensitivity and because they had been used on published viral metagenomic studies:

 tblastx  <cit>  was chosen because is part of the widely used blast suite for sequence alignments. this version enhances the sensitivity to distantly related sequences and has been used widely in viral metagenomic projects  <cit> .

 phymmbl  <cit>  has been used for bacterial and viral metagenome analyses  <cit> . it complements sequence alignment information with interpolated markov models  based on frequencies of oligonucleotide sequences. this enhances sensitivity without losing specificity. phymmbl outperforms blast predictions when query sequences have no reference in the target database  <cit> .

 the distribution of the k-mer frequencies was used to find potential distant phylogenetic relationships. trifonov and rabadan  <cit>  proposed a method based on the kullback–leibler distance between k-mer frequencies to apply taxonomic assignations using the gamma distribution to assess its significances.

for assessing the functional annotation of viral metagenomes, a third simulated dataset was generated from genomes found in the ncbi viral genome database to test algorithms that have been used for taxonomic classification in previous works and modified phymmbl scripts to improve the sensitivity of its taxonomic annotation. the simulations of reads for each of the three metagenomes were carried out using the error rate of 454-pyrosequencing technology.

RESULTS
genome mapping and relative abundance
the frequency of each taxon in the simulated metagenomes was estimated to assess how many of the main taxonomic groups of real data were present in the simulated data. the taxonomic frequencies for viruses in the metagenome simulations  were consistent with those resulting from the taxonomic classification performed by reyes and collaborators  <cit> . this was expected since the same taxonomic method, based on tblastx  <cit>  with an e-value <  <dig> , was used for determining the taxonomic frequencies, and the viral genome database from the ncbi, used for mapping the reads into reference genomes, shares most entries from the vlp database used by reyes. in our dataset, the temperate bacteriophages are the most represented type of viral particles  and a low percentage of eukaryotic viruses  were found. our simulations showed that composition was dominated by double-stranded dna bacteriophages  from the order caudovirales  and single-stranded dna bacteriophages from the family microviridae. the most representative eukaryotic viruses were double-stranded dna viruses from the order herpesvirales.

the taxonomic analysis of the viral-bacterial simulation showed that  <dig> % of the reads belonged to viral genomes. the reads that were not assigned as viral genomes were compared against the bacterial genomes from the ncbi genome database using ssaha <dig>  <cit> . this fraction displayed the same species distribution present in the viral simulated metagenome. the bacterial species from phyla proteobacteria, firmicutes and actinobacteria were the most represented. these bacteria are the main hosts for the bacteriophages present in the actual metagenome  <cit> .

assemblies
six de novo whole-genome shotgun dna sequence assemblers were tested using the two simulated metagenome based on those by reyes and collaborators  <cit> . several statistics for each assembly were calculated in order to evaluate their assembly quality  and their contig taxonomic precision  in order to estimate the advantages and disadvantages for each assembly . the n statistics are weighted median statistics reporting the length of the contig in the upper limit of a quantile when all contigs are arranged by size. thus, 50% of the contigs would be equal to or larger than the n <dig> whereas 10% of the contigs would be equal to or larger than the n <dig>  additional values of the n <dig>  n <dig> statistics are reported in additional file 1: table s <dig> 

olc algorithms
they are the most commonly used to assemble  <dig> reads. three different implementations were tested: newbler, celera and minimo.

for viral metagenomes, newbler 60/ <dig>  showed closer results to the optimal assembly. it had the highest percentage of reads assembled  and a high percentage of reads matching their original genome  , enabling the recovery of a complete genome. however, around 20% contigs were chimeric, a similar result to newbler 100/ <dig> . newbler was the most accurate in terms of the identity median against its original genomes, showing the smallest variation across the alignments against the original genomes . this characteristic makes newbler a good alternative for genome assembly and recovery in viral shotgun sequence data.

minimo produced the lowest percentage of chimeric contigs, presenting the strictest assembly  in both metagenomes. it had the lowest percentage of reads assembled, the lowest n <dig> value and the highest percentage of reads within a viral-bacterial hit . a less stringent version  resulted in higher percentage of reads assembled and reads matching their original genome, and the largest contig values as well as in lower percentage of reads within a viral-bacterial hit, the percentage of chimeric contigs and n <dig> values when compared against the most stringent version . reducing the collapsing parameters  values helps assemble a higher percentage of reads into the assembly with the fewest number of chimeric contigs. minimo stands as the best candidate to deal with taxonomic annotations.

the celera assembler had similar results for assemblies 60/ <dig> and 100/ <dig>  its metagenomic parameters improved the percentage of reads assembled and the n <dig> value, therefore increasing the percentage of chimeric contigs and the reads in their original genome . despite the high percentage of chimeric contigs the celera meta showed highly accurate results in its identity median  obtaining a low number of large contigs in the viral metagenome simulation. these characteristics are, as well as for newbler, advantageous for the recovery of entire genomes . the main drawback of this assembler is that it reports the highest variation in the percentage of identity .

as for viral-bacterial metagenomes assemblies , there was a decrease in the n <dig> value, the number of genomes recovered and the percentage of reads assembled. the percentage of similarity within its original genome remained similar, with the exception of celera, which decreased its variation across the genome mapping despite the higher complexity of the metagenome . the percentage of chimeric contigs between viruses and bacteria was insignificant, due to the low effect of the inserted prophages into the bacterial genomes to create chimeras. newbler again obtained the longest contigs, with more reads assembled and genomes recovered per assembly. celera with the metagenomic settings produced an assembly similar to that of newbler with less stringent parameters. both assemblers maximized the percentage of reads assembled, but also increased the percentage of chimeric contigs . minimo showed similar statistics as the ones in the viral metagenome.

as in other studies  <cit>  we showed that the stringency of the parameters involving overlapping in both metagenomes influences the quality of the assembly. a decrease in the stringency in the assembly results in the increase of the n <dig> and the percentage of reads assembled in all assemblers. however, in our analysis, the number of chimeras and misassembled contigs seemed to be independent of these parameters as well as of the percentage of identities. thus, when overlapping parameters stringency is increased , only the contig length and the percentage of reads assembled decrease.

the last olc assembler that was tested, vicuna  <cit> , did not produce useful results. when the divergence variable is set to 2% none of the assemblies were able to recover a single contig. by setting it to 10%, the viral assembly yielded six contigs, the maximum number of contigs for vicuna. the assemblies were not considered for subsequent analyses.

de bruijn algorithms
these algorithms, commonly used for short-reads, improve the length of the resulting contigs, therefore minimizing the problem of repetitive sequences  <cit> . no significant difference between velvet and its metagenomic version metavelvet  <cit>  was found for neither metagenome.

for the viral metagenomes, de bruijn algorithm assemblers exhibited the strictest assembly , assembling only a small percentage of the reads with the fewest number of chimeras . the percentage of reads within a viral-bacterial hit was lower than for assemblies with a similar n <dig> value such as minimo 100/ <dig> 

unlike the olc algorithm assemblers, velvet and metavelvet assembled more reads in complex metagenomes. the n <dig> and the percentage of reads within a viral-bacterial hit were also increase. the number of chimeras increased with complexity but remained lower than for the olc strategy .

n <dig> values resulting from de bruijn assemblers varied depending on the k-mer length but not on the complexity of the metagenome. a scaffolding software may be used in order to increase these low n <dig> values although it would increase the percentage of chimeric contigs  <cit> .

generative probabilistic model of read generation algorithm
genovo is based on a chinese-restaurant-process and it can use different coverage values for distinct species within the same metagenomic dataset  <cit> . genovo uses a generative probabilistic model of read generation, contrary to single sequence reconstruction. this depends on a prior to randomly partition the reads, which is obtained using a chinese-restaurant-process model. the model is a discrete-time stochastic process generating clusters that accounts for the undetermined number of genomes in the sample. it considers the probability of a read to be assigned to an existing or an empty cluster and continues hill-climbing steps iteratively until convergence is met.

it proved to be the assembler with the best performance in generating long contigs, maximizing the percentage of reads assembled, with a higher value than that expected for the optimal assembly . however, it generated a large number of chimeras and other misassembled reads . this may be avoided by increasing the number of iterations. furthermore, genovo was time and resource consuming, requiring approximately  <dig> days for our viral metagenome and up to  <dig> days for the viral-bacterial metagenome, approximately  <dig> times more than the second slowest assembler .

this assembler drastically increased the percentage of chimeric contigs and the percentage of reads matching their original genome proportionately to the complexity of the metagenome . closely related species in the datasets may originate these chimeric contigs.

clustering and correlation from assembly parameters
the spearman rank correlation coefficient measures the statistical dependence between two variables and creates clusters based on the effect of each assembly statistic on the others . the correlation gives information about the performance of non-quantifiable variables in real data  using variables that can be measured . our results show that the correlation values were lower in the viral-bacterial matrix , given that its higher complexity reduced the number of reads assembled and the possible observations to create correlations. the hierarchical clustering obtained by the correlation matrix  associated the statistics into two clusters based on the contig length and the number of reads assembled . cluster  <dig> is characterized by its positive correlations between the number of contigs, the percentage of reads within a viral-bacterial hit, and the percentage of reads matching their original genome; and by the negative correlations between the largest contig with the n <dig>  the number of reads assembled and the number of chimeric contigs. conversely, cluster  <dig> associates the same statistics in the opposite direction. the number of genomes recovered was located in a different group in each metagenome due to its low number of observations. longer contigs with higher read counts resulted in an increased amount of chimeric assemblies whilst small ones resulted in taxonomic annotations between viruses and bacteria.

clustering and correlation from assemblies
the principal components analysis  was performed using the correlation matrix to understand the effects of the statistics on the assemblies . for this analysis, we introduced an optimal assembly that maximizes the number of reads assembled into long non-chimeric contigs  to determine which assembler or set of parameters had a closer distance to this optimal result.

the pca from the viral and the viral-bacterial metagenomes show that the optimal assembly is separated from the rest . genovo and the olc celera with the recommended parameters for metagenomics  and newbler 60/ <dig> are the ones with more reads assembled, longer contigs and the shortest euclidean distances, which cluster them with the optimal assembly . however, they are driven away from the latter in the pca because of the effects of the percentage of chimeric contigs and the percentage of reads matching their original genome.

the pca clusters the assemblies into two main groups . these clusters are seen across both metagenomes with different structure . one cluster consists of minimo 60/ <dig>  minimo 100/ <dig>  velvet and metavelvet  characterized by a large number of short-length contigs, a low percentage of reads assembled, lower percentage of chimeric contigs, and higher percentage of reads within a viral-bacterial hit values. minimo 60/ <dig> differs slightly from the other elements in this cluster, as it has a higher percentage of reads assembled and a lower percentage of reads within a viral-bacterial hit. a second cluster includes the remaining olc assemblers and genovo , driven by the n <dig>  the largest contig, identity median, and the percentage of chimeric contigs. celera meta and genovo, in the viral dataset, show the greatest distance from the optimal assembly due to their high the percentage of chimeric contigs.

taxonomic analysis of chimeras in assemblies
the taxonomy level at which one or more reads have the same classification is known as the lowest common ancestor . this was determined for every set of reads within chimeric contigs. for all the assemblers, the lca tended to be found in lower taxonomic levels , suggesting that chimera formation arises from conserved functions or sequences in closely related species. neither the complexity of the metagenome nor the collapsing parameters  noticeably influenced the percentage of chimeric contigs. instead, it seemed that the contig length, reflected in the n <dig> value, and the percentage of reads assembled increased the number of chimeric assemblies .

the lca of the chimeras obtained in our viral-bacterial metagenome assemblies were mainly detected at two taxonomic levels: species  and family  . we showed that with less stringent parameters for overlapping , the lca of chimeric contigs tend to be placed at lower taxonomic levels , as seen in the olc assemblies. few chimeras were detected between viruses and bacteria in all assemblies .

chimeras in the viral metagenome mainly occurred at the genus and family levels. the assemblies of viruses had also high percentages of chimeras at the superkingdom  and order levels. the percentage of higher rank lca chimeras increased as the overlapping parameters became stricter , as seen both for the viral and the viral-bacterial metagenomes .

functional analysis of the contigs
the improvement in functional annotations after assembling was tested by contrasting the number and accuracy of the assembled reads annotation against the results from the unassembled reads annotation . this was achieved by counting the number of times that blastx annotation for each read succeeds in assigning the “true annotation”  to each of the assemblies and the two simulated metagenomes.

assembling increased the number reads that were assigned a function. the difference between the assembled and unassembled annotations was magnified as the overlapping cut off  values increased. when the overlapping cut off was set to the 30% of the alignment length, virtually no hits were recovered for the unassembled reads . this is mainly due to the fact that the unassembled reads do not contain enough information to create an accurate annotation. when the cut off was set below 10%, the differences between the assembled and unassembled functional results were smaller, and in some cases the unassembled recovered more functional hits . if the overlapping percentage cut off was increased , so was the proportion of correctly annotated functions for most of the assemblers, except for newbler and celera meta.

genovo showed outstanding results in the functional analysis. unlike the other highly-assembled long-contig assemblies, those obtained by genovo correctly assigned functions to a higher number of reads, regardless of the overlapping values. its accuracy was similar to the most stringent assemblies  .

function that causes chimeric assemblies in virus metagenome
horizontal gene transfer within bacteriophages and between them and their bacterial hosts is a common phenomenon  <cit> . in order to determine the number of functions involved in chimeras formation, their taxonomic groups and the assemblies in which they were occur chimeric collapses, blastx was used to assign annotations of the chimeric region of the contigs. assemblies with higher percentage of reads assembled and n <dig> values accounted for the majority of the events of pairwise alignments between different organisms, hereafter chimeric collapses , mainly seen in those from genovo .

a total of  <dig> different functions were detected to be involved in chimeric collapses in the viral metagenome assemblies with chimeras occurring between different organisms sharing functions. in viral-bacterial assemblies, this number adds up  <dig> functions that produce chimeric collapses. the most represented known functions  were taken from both metagenomes assemblies . the over-represented functions, defined as the outliers from the interquartile range of the frequency distribution of functions involved in chimeric collapses, mainly contained conserved proteins across genomes, such as dna replication proteins, dna polymerase, snf <dig> domain-containing protein ; proteins involved in dna packaging such as gp <dig> terminase, phage-terminase large subunit, terl, portal proteins gp <dig> and gp <dig>  <cit> ; hydrolases and lysis proteins such as phage-associated cell wall hydrolase, xhlb and membrane proteins related to metalloendopeptidases   <cit> ; dna transfer proteins such as gp <dig>  <cit> ; adhesion proteins such as phislt orf636 − like protein  <cit> ; genome integrase  <cit> ; structural proteins, including characterized measure protein  <cit>  and finally unclassified functional proteins.

most of the chimeric collapses occurred at the genus level . chlamydiamicrovirus  represents ~50% of all chimeric assemblies for both metagenomes. genomes from this genus are characterized by their short length. given this feature and the huge number of reads simulated, the coverage of the genomes was very high and consequently, the number of chimeric collapses tended to increase.

finally, the low percentage of chimeric collapses observed between bacterial reads may be a consequence of the low coverage for each of the genomes sampled.

alternative methods for taxonomic classification
in order to assess the taxonomic classification, their specificity and sensitivity were calculated to standardize the results, based on the correct/incorrect assignations  on a simulated query dataset of  <dig> reads taken from  <dig> genomes that were subtracted from the subject database. three databases were constructed with the remaining genomes, restricting their contents to species, genera or families not included in the query dataset . the objective was to assess the performance of different taxonomic classification software when sequences belonging to the same species, genus or family were not found in the database.

the removal of related species, genus or family is reflected by a decrease in the sensitivity for all methods on all taxonomic levels whereas the specificity remains virtually unaltered . the overall proportion of accurate results  is higher than that of incorrect ones , mainly influenced by the number of true negatives and false positives respectively . within each database analysis, classification at the higher taxonomic levels produces smaller sensitivity values. this is constant with all custom databases.

the frequency of k-mers was the least sensitive of all three methods, with a low number of true positives and a high proportion of true negatives . tblastx was the most specific for all taxonomic levels with the three databases and the most sensitive in the species-excluded and genera-excluded databases. it yields the highest number of true positives, reporting up to >50% in the order level with the species-excluded database. the number of false positives it produces is lower than those of the other methods.

as for phymmbl, we tested for changes in sensitivity and specificity by modifying the options for model structure  and for alignment method . from the four different permutations, we selected the one with the confidence score that maximized specificity and sensitivity to compare it with the other taxonomic classification methods . the scores that maximized this value at the genus, family and order levels were  <dig> ,  <dig>  and  <dig> , respectively. the specificity did not vary significantly between the permutations. the sensitivity of phymmbl using tblastx was higher than with blastn. the former was selected as the alignment method along with single models for the rest of the analysis with this program.

phymmbl produces similar results to those of tblastx, but gets a lower proportion of true positives and a higher number of false positives resulting in a decrease in sensitivity and specificity in all taxonomic levels, except for the family-excluded database, in which phymmbl obtains higher sensibility values.

discussion
the performance of several read assembly and gene annotation tools has been tested to study simulated viral and viral-bacterial metagenomes. taking into account the lack of information in the current databases we tested the impact of the assembly process on the accuracy of the taxonomic and functional annotations  <cit> .

even though simulated metagenomic datasets are an oversimplified emulation of actual metagenomic data, the conclusions drawn from these analyses are still valid as the focus of this study was to assess the performance of different assemblers rather than recovering the exact underlying taxonomic distribution of the data.

viral metagenomic assemblies have been classified into two groups. the first one is characterized by their low percentage of chimeric contigs, high prevalence of the reads within a viral-bacterial hit and short contigs while the second is defined by their high percentage of reads assembled, as well as long and chimeric contigs. for both types of assemblies the percentage of reads matching their original genome was high, with similar identity median.

the olc-algorithm assemblers show a wider spectrum of results, requiring less time and computational resources, making them more suitable when dealing with highly heterogeneous metagenomes. this allows the user to choose between two types of assemblies: those with many accurate micro-contigs, at the expense of the capacity of taxonomic/functional prediction, and those with longer contigs, enabling the recovery of whole genomes or more taxonomic functions.

newbler and celera, the less strict assemblers, produce the largest olc-assemblies, with the highest percentage of reads assembled, and increase the probability of reconstructing whole genomes. in contrast, minimo, the most conservative algorithm, shows a better accuracy but the percentage of reads assembled and n <dig> values are reduced, while increasing the percentage of reads within a viral-bacterial hit. interestingly, the performance of minimo 60/ <dig> is positioned between that of newbler/celera meta and minimo 100/ <dig>  it assembles significantly higher proportions of reads than its most stringent version, with the same accuracy whilst reducing the number of reads within a viral-bacterial hit. for all of these assemblies the identity median and, except for celera meta, the percentage of reads matching their original genome values are similar.

the stringency of the parameters for length of overlap and minimum percentage of identity does not significantly increase the quality of the contigs or the accuracy in functional annotation . stringent parameters were expected to reduce the number of chimeras, but correlation analysis of the assembly statistics show that they result in a reduction of the percentage of reads assembled and n <dig> values, whereas the percentage of chimeric contigs remained virtually unaltered. assemblies with restrictive parameters have more lca hits resolved at phylum, superkingdom and root taxonomic levels. this may be explained by the fact that only conserved sequences across genomes have a percentage of identity that leads to the formation of chimeric assemblies. some of these proteins are ubiquitous in the microbiome such as housekeeping genes and genes involved in phage structure or replication . higher complexity is associated with lower n <dig> and the percentage of reads assembled values, as would be expected in lower species-level coverage scenarios.

an increased n <dig> value results in a higher number of predicted functions but the percentage of correct assignations decreases. this effect is drastically observed in newbler and celera meta, which obtain around 40-50% of correctly annotated functions. for the recovery of long contigs, including whole genomes, newbler provides the best results, with higher accuracy than celera meta.

minimo 60/ <dig> generates roughly the same number of correctly annotated reads but with much higher accuracy. although the n <dig> value in minimo is  <dig> times lower than that of the optimal assembly, the results suggest that it could be the assembler of choice for diversity analysis of viral metagenomes obtained with  <dig> technology provided that less stringent parameters are selected .

vicuna  <cit> , failed to achieve an acceptable assembly for comparison. this outcome was not unexpected as it had been used for a single viral population per run  and had just been suggested, but not tested, for metagenomics.

previously filtering the reads to separate specific genomes using a mapper such as smalt  <cit>  , would enable the usage of vicuna. the mapper could be used as a first approach along with the viral database to allocate the reads into possible genomes, classifying each set and assembling them separately. still, this would not be equivalent to other of the assemblies and was consequently discarded from the rest of the analysis.

velvet and metavelvet, de bruijn graphs assemblers, are conservative, ensuring good quality contigs and highly reliable functional annotations. however, the resulting contigs, which have short n <dig> and low percentage of reads assembled, may be used for successive rounds of assembly or scaffolding. unlike the percentage of reads assembled, the n <dig> seems to be independent of the assembler and the complexity of the metagenome. our results showed that de bruijn assemblers cannot handle  <dig> sequences optimally, as they generate short contigs and show a low percentage of reads assembled. these results are further supported by other studies  <cit> .

the generative probabilistic model of read generation algorithm assembler, genovo  <cit>  can deal with high levels of taxonomic heterogeneity, because it can input a different coverage for different contigs rendering it more sensitive to underrepresented species. genovo shows the highest n <dig> with the largest contig, assembling most of the dataset into the viral metagenome. horizontal gene transfer, the low number of different functions across bacteriophages, and the effects of multiple coverage estimations lead genovo into successfully merging chimeric contigs that share common functions, rather than reflecting their actual taxonomy. this feature makes genovo the assembler of choice for functional annotation due to its high number of functional assignations and their accuracy.

the high percentage of chimeric contigs may be caused by the clustering of related functions from different organisms. this is consistent with the fact that there are so many chimeras at order, class and phylum taxonomic levels. for most of the assemblies, the number of reads with a correct functional annotation is higher in the contigs than in the original unassembled dataset. if the overlapping percentage value is increased , this effect is magnified. the number of predicted functions from unassembled reads decreases abruptly at higher overlapping percentages, virtually disappearing beyond 50% .

bacteriophage integration into genomes  appears to have just a limited influence in the formation of chimeras, most likely because those occurring between viruses and bacteria are mainly determined by the contig length, just like the rest of the chimeric events, and are practically non-existent in the assemblies.

as the percentage of reads assembled decreases, so does the contig length, the number of chimeras and the percentage of reads matching their original genome, whereas the percentage of reads within a viral-bacterial hit increases. thus, shorter reads are also less useful for taxonomic and functional profiling. this happens both in the viral and the viral-bacterial metagenomes, meaning that the effect of prophages may arise from a taxonomic assignation bias rather than from an aberrant assembly. increasing the contig length can improve the accuracy when dealing with viral-bacterial metagenomes, despite the chimeric contigs between both. furthermore, the results may be improved by effectively selecting the viral hits rather than the bacterial ones when e-values are identical.

most lcas in chimeric contigs are detected in the class, order and phylum taxonomic levels. this could be explained by the inconsistent levels in viral taxonomy and the high number of functions that are shared between viral genomes.

determining the lca of the assembled contigs can support the taxonomic level assignation at which annotations should be given.

most functions are detected in chimeric alignments. the most over-represented functions are basic for viral replication and are conserved across all viruses . this may be attributed to different causes such as horizontal gene transfer according to the modular theory of bacteriophage evolution in which bacteriophages are considered a group of interchangeable genetic elements  <cit> . furthermore, the combination of closely related species with small genomes and a high prevalence in a niche often leads to the occurrence of chimeric collapses in the assemblies as seen in the genus chlamydiamicrovirus.

assembling provides a useful platform for taxonomic and functional analyses of viral metagenomic datasets but this is also extended to diversity analyses which can be measured using programs such as phaccs  <cit>  and catchall  <cit> , which take into account the contig spectrum to measure the overall diversity within samples.

with respect to the comparison between different taxonomic assignment approaches, we suggest they may be combined to obtain a better result, although this approach was not fully tested for this study. because of the intrinsic differences of the algorithms, each one provides an advantage in different applications and may be used complementarily.

as for the second part of the analysis, the methods for taxonomic classification are mostly conservative as they show a high proportion of true negatives, low numbers of true positives and high specificity scores for all the analyses. values are consistent with previous studies  <cit>  and support all three programs as reliable alternatives for viral taxonomic assignation in different specific scenarios, even though the total true positives are limited. this number is further affected by the removal of the sequences from the databases.

the frequencies of k-mers within the genomes were not very sensitive with any of the databases and taxonomic levels. however, this method presents the highest numbers of true negatives in most analyses. although it is not the aim of this study, the k-mer approach may potentially be used to differentiate bacterial from viral sequences so that the set of reads may be cleansed. this method stands out because it does not depend on alignments between the databases and can thus detect sequence homology in relatively distant genomes.

tblastx is a good taxonomic assignation approach for viral metagenomes, displaying higher sensibility and the specificity scores of phymmbl and k-mer frequencies in most cases. it is highly specific because it produces a high number of true positives and few false positives. because of the low number of available viral genomes this program may be limited to extant sequences in the databases and does not retrieve information from other genomic features unlike the other two methods. this limitation is reflected by the loss of sensibility with the families-excluded database.

phymmbl yields results that fairly resemble those of tblastx. however, it stands out as the most sensitive program for viral taxonomic assignation when no genera or families match those in the query dataset . the algorithm can be enhanced by selecting tblastx instead of the default blastn. even if no significant alignment is possible, the program can resolve the taxonomy of any query using imms. nevertheless, phymmbl is computationally demanding and its code was developed for usage with bacterial datasets, as input database structure is expected to contain all taxonomic levels used in bacteria.

when the query dataset is analysed using all three different programs with the species-excluded and genera-excluded databases, it is shown that lower sensitivity scores are obtained in higher order taxonomic levels, namely in the order and family levels. these may seem counterintuitive, since the exact opposite is seen in bacteria, and may be due to the broad genetic heterogeneity in viruses  <cit> . map   <cit>  and ray meta  <cit>   came out around the time when this work was being carried out. map  is expected to improve olc single genome assembly by taking into account mate-pair information for the lay-out stage  <cit> . our datasets were modelled after 454-pyrosequencing data and included no mate-pair information. a new customized dataset especially designed for map would have been required. this would render direct comparison impossible. ray-meta may be one of the best ngs assemblers for short-read sequence data. however, as stated above, the results from this and other studies suggest that de bruijn assemblers are not an optimal approach. furthermore, we tried to limit the study to those assemblers that had at least been tried for viral genomics. therefore, we decided not to include them in the analysis.

CONCLUSIONS
in this work, we measured the effect that assembling simulated viral gut metagenomes with different assemblers had on the quality of taxonomic and functional annotations. none of the assemblers managed to generate results that truthfully resemble the optimally assembled metagenomes.

the success of most assemblies is greatly hindered by the formation of chimeric contigs. as supported by our data, chimeras are ubiquitous in all assemblies. they are formed at virtually any taxonomic level or function, regardless of the stringency of the parameters and the existence of reads of bacterial origin in the dataset.

depending on the objective of each project, we propose two ways to assemble  <dig> sequence data from viral metagenomic data. diversity and taxonomic analysis may benefit from using minimo with ml <dig> and mi <dig> parameters as it minimizes the number of chimeric contigs with an acceptable percentage of reads assembled. on the other hand, genovo stands out in functional annotation analyses, as it forms the longest contigs and has the highest percentage of reads assembled. since genovo is time and resource consuming, newbler can be considered as a cost-efficient alternative.

additionally, different taxonomic assignment programs were tested to evaluate specificity and sensitivity of taxonomic assignations as well as the effect of removing sequences that were close to the query dataset in different taxonomic levels. methods vary in terms of assignation success, with tblastx as the most successful and accurate in most cases. the frequency of k-mers was the method that yielded the lower overall scores for virus analysis. because of the intrinsic differences of the algorithms, each one provides an advantage in different applications and may be used complementarily, although this approach was not fully tested for this study. to make the most out of them the k-mers frequency method could be used to separate bacterial or specific subtypes of viral particles, tblastx, due to its specificity and sensitivity, would be a good option as the main taxonomic classification program and, phymmbl due to its sensitivity could be a good choice to obtain information where others cannot, especially if the available reference database lacks closely related species.

