BACKGROUND
the goal in proteome studies is to characterize as many proteins as possible in the samples being analyzed, in order to assign to these proteins a role in cellular activities, including cases of severe disease occurrence due to protein malfunction  <cit> . for this purpose, liquid chromatography coupled with tandem mass spectrometry  is the most commonly used approach .

an lc-ms/ms run generates thousands of spectra, where each one represents a peptide. the next step is to assign a peptide sequence to each spectrum based on its spectral peak pattern  <cit> . there are basically two techniques to interpret ms/ms spectra. one is the so-called de novo approach that analyzes the peak patterns without using any external information  <cit> . the most common technique, however, uses protein sequence databases, which is the case of computational programs such as sequest and mascot  <cit> . these programs perform an in silico digestion of proteins present in the database  and generate virtual spectra from the resulting virtual peptides. thus, for each observed spectrum, the program finds its best match to a virtual spectrum and the respective peptide sequence is assigned to the given ms spectrum. the programs normally report the ten best matches. several scores are attributed to a peptide-spectrum match  to measure its quality  <cit> . this strategy can be used to identify and quantify peptides/proteins  <cit> . nevertheless, a major issue in this procedure is that a single lc-ms/ms run usually leads to thousands of spectra, where fewer than 20% are interpreted correctly  <cit> .

in this work, we are primarily interested in the identification task. in particular, we aim at performing a computational curation of sequest psms, given the enormous volume of spectra that is usually produced and the potentially large number of false positive hits. in this context, it is important to efficiently estimate the false discovery rate  of the identifications  <cit> .

a common strategy to fdr estimation is the use of a target-decoy database   <cit> . in this approach, decoy protein sequences are generated to be used along with target protein sequences for the search, which can be performed using a composite target-decoy db or in two rounds, i.e., one search for each db . common methods for generating decoy sequences are to reverse or shuffle the target sequences, keeping the amino acid distribution. the tddb strategy relies on the premise that the decoy psms are good models of the incorrect target psms. hence, for a wrong psm, the probability of the assigned peptide sequence to pertain to the target db is assumed to be the same probability of the sequence to pertain to the decoy db. as a result, a good estimate for the number of wrong spectrum interpretations among target psms is simply the number of decoy psms  <cit> . however, even though the tddb strategy has been used successfully for fdr estimation, it has not been, in general, suitably applied to optimize sensitivity, i.e., more sophisticated combinations of the psm scores are not fully explored to increase sensitivity  <cit> . furthermore, important scores are left out from the fdr estimation process  <cit> .

peptideprophet is another known approach used to psm assessment. this method considers mixed statistical distributions of psm scores to predict correct and incorrect spectrum interpretations  <cit> . in the case of sequest psms, for example, the gaussian and gamma distribution parameters for incorrect and correct psms, respectively, are estimated by the expectation-maximization algorithm  <cit> . when the dataset presents the assumed distributions, peptideprophet can provide an accurate probability that a psm is correct. on the other hand, in certain datasets the scores might present completely different distributions. particularly in the case of phosphopeptides, the peptide fragmentation process in the ms/ms run is biased towards phosphate groups, which suppresses important ions and leads to odd spectra .

mude and mumal are two more recently introduced methods proposed by our group that explore the tddb strategy without assuming and relying on a data distribution  <cit> . both methods describe a more comprehensive use of psm scores to enhance sensitivity.

mude considers in addition to xcorr and △cn, normally used in tddb analyses, four alternative scores: △m, sprank, and percions, provided by sequest, and rtp-value, provided by the openms proteomics tool  <cit> . furthermore, the problem of finding threshold values for the scores that lead to a desired fdr is treated as an optimization problem. even though it provides a significant increase in sensitivity, the mude approach is capable of producing only linear decision boundaries to separate false positives from true positives because the score thresholds are defined individually.

as in mude, the mumal method to assess psms applies a tddb analysis using a multivariate approach. however, this is accomplished with machine learning techniques, aimed at providing more flexible decision boundaries to further increase sensitivity in the fdr estimation process  <cit> . mumal replaces the optimization procedure in mude with an artificial neural network  algorithm to perform psm classification. the resulting roc  curve is analyzed according to the decoy count idea, i.e., for each point in the curve, the respective discriminant probability threshold t is used to count the number of decoy hits with probability  equal or greater than t. this count is the estimate for the number of target hits with p ≥t that are incorrect. for the ann model construction, the training set is the data to be analyzed itself, i.e., all sequest hits, where the attributes are composed by the six scores mentioned above, and the class labels are:  <dig> for decoy hits, and  <dig> for target hits. if, on one hand, all of the decoy hits are obviously wrong, on the other hand, only a minor part of target hits are correct. for this reason, by using classical evaluation methods such as accuracy, precision, and recall, the resulting model is regarded as unsatisfactory because most target hits have characteristics similar to decoy hits. however, the roc analysis is an optimal tool to find appropriate discriminant probabilities that provide the desired fdr with good sensitivity  <cit> . nevertheless, there is room for improving sensitivity even further, particularly concerning the classification procedure, because other techniques could be applied for using decoy hits to characterize the wrong interpretations among target psms.

in this vein, we again propose to use anns as in mumal to keep delineating good decision boundaries. however, two important approaches are included in the psm assessment procedure. the first one is the use of a cost matrix for making the cost of misclassifying an instance of class  <dig>  higher than the cost of misclassifying an instance of class  <dig>   <cit> . it provides a bias toward the correct classification of decoy hits, for which the class labels are definitely correct . in this way, the incorrect target hits, i.e., the ones with the same characteristics of decoy psms, but with different label , tend to be correctly classified as class  <dig> by the model. therefore, decoy hits help to pin down incorrect target hits, providing better decision boundaries, which leads to a higher sensitivity.

the second technique we use for improving the mumal approach is to apply a threshold selector algorithm   <cit> . after building the model with an ann with a cost matrix, and analyzing the roc curve to see which discriminant probabilities provide suitable fdrs, the discriminant probability that leads to a 1% fdr is selected to be the final threshold value t that separates correct from incorrect psms. next, threshold t is set to tsa, which replaces the probabilities generated by the ann approach with probabilities that make more sense in terms of indicating the psm correctness. for hits with probability = t, tsa replaces their probabilities with  <dig> , and all other psm probability values are proportionally normalized, keeping the range  <cit> , so that  <dig>  is the point of separation between a set of psms with high fdr  and a set of psms with low fdr . note that the previous version of mumal provides a good approach for separating psms with low fdr. however, due to the model problem caused by the fact that many class- <dig> instances have similar characteristics to class- <dig> instances, the probability value generated by the ann approach for a target psm is not appropriate for its individual evaluation. with the probability value adjustment provided by tsa, in turn, individual assessment of psms is now possible, which is very important for the protein inference stage, such as the one performed by proteinprophet  <cit> .

in this work, we performed experiments with  <dig> datasets, in a comparison with standard methods for psm assessment, to demonstrate that our method, named mumal <dig>  could achieve an average increase of 15% in sensitivity concerning the best current method, for fdrs varying from  <dig> to 5%. still, by using venn diagrams with peptides identified for a 1% fdr, we demonstrated that almost 4-fold more exclusive peptides were found. furthermore, in an additional experiment using a dataset with known proteins, the roc area calculated after the adjustment of probabilities by tsa was  <dig> , showing coherent probability values. it is worth noting the demonstration of the predictive power of our method for phosphopeptides. in these cases, the score distribution might be very different from non-phosphopeptide psms, which complicates the analysis of traditional computational tools such as peptideprophet.

methods
datasets
eleven datasets used in the validation of mude and mumal were again utilized in our experiments  <cit> . figure  <dig> illustrates the datasets with their respective amounts of psms. note that in all cases the number of target psms is slightly higher than half the total number of psms. this is reasonable because it is expected that less than 20% of target hits are correct. therefore, the total amount of psms is composed by this small percentage plus the rest of incorrect psms, where, roughly, one half is composed of decoy hits and the other half contains wrong target hits.
fig.  <dig> the eleven datasets used in most of our experimental work and evaluation




these datasets were obtained from three lc-ms/ms runs with three independent phospho-enriched mouse samples. for each resulting set of spectra, sequest was used for peptide sequence assignment. each psm dataset produced as output was split into two parts: the first part contained spectra whose best result was reported as a phosphopeptide, and the second part was made up of spectra whose best hit was attributed to a non-phosphopeptide. these sets were further split based on the precursor charge state, where only + <dig> and + <dig> charges were considered. as a consequence, the three sequest outputs turned into  <dig> datasets that were labeled s1_ph_ch <dig>  s1_ph_ch <dig>  s1_nph_ch <dig>  s1_nph_ch <dig>  s2_ph_ch <dig>  s2_ph_ch <dig>  s2_nph_ch <dig>  s2_ph_ch <dig>  s3_ph_ch <dig>  s3_ph_ch <dig>  s3_nph_ch <dig>  and s3_nph_ch <dig>  where ph and nph denote phosphodata and non-phosphodata, respectively, while ch <dig> and ch <dig> represent + <dig> and + <dig> charge states, respectively. the dataset s3_nph_ch <dig> was removed from the experiments since it had fewer than ten correct assignments. finally, for each of these datasets, the sequest files in the “out” format were converted into a single idxml file, which is the format used by openms, the computational toolkit we applied to predict retention time   <cit> . the details on the protocol and chemicals in sample preparation, ms technology applied, versions of programs and formats, parameters and database used in the sequest search, etc., can be found in the previous works of cerqueira et al.  <cit> .

another dataset we used in our experiments was taken from the work of pfeifer et al.  <cit> . they used three samples containing known proteins. in our work, the psms of each mixture were also generated by sequest and were joined in a single idxml file that we refer to as m <dig>  the proteins present in the mixtures are: β-casein , conalbumin , myelin basic protein , hemoglobin , leptin , creatine phosphokinase , α1-acid-glycoprotein , albumin , cytochrome c , β-lactoglobulin a , carbonic anhydrase , catalase , myoglobin , lysozyme , ribonuclease a , transferrin , β-lactalbumin , and thyroglobulin . knowing the proteins we are supposed to identify facilitates the development of experiments to validate the performance of our method to appropriately curate psms. the details to produce this dataset can be found in the papers of pfeifer et al. and cerqueira et al.  <cit> .

target-decoy database strategy
as recommended by elias et al.  <cit> , we used a composite target-decoy db for the searches, where decoys were produced by reversing the target sequences. in this way, the peptide sequence of an incorrect psm has an equal chance of coming from either a target or a decoy sequence. as a result, to estimate the number of wrong target hits, it suffices to count the number of decoy hits, i.e., the fdr estimate for target hits is given by: d t /, where d t is the number of decoy psms found with a score equal or greater than a predetermined threshold t, and n t is the total number of psms  according to the same threshold t.

in order to enhance sensitivity, as proposed previously  <cit> , the tddb strategy is used here in a multivariate manner, taking into consideration six key psm scores: △c
n, xcorr, △m, sprank, percentage of ions found , and rt p-value . a careful statistical analysis was previously performed to evaluate the impact of each of these scores on psm curation  <cit> .

in addition to the multivariate approach, machine learning techniques are applied to promote a better separation between correct and incorrect hits, using decoy psms as a key part in this procedure, as described in the next sections.

cost sensitive artificial neural network
classical decoy approaches typically use no more than two scores that have their threshold values analyzed individually. such a procedure leads to linear decision boundaries. in order to construct more appropriated decisions boundaries between correct and incorrect hits, an ann is used so that the six scores  mentioned previously are applied in combination to produce a final score in the range  <cit>   that can be interpreted as a probability value. then, using the decoy counting idea, a suitable threshold for this score is pursued to reach a desired fdr. figure  <dig> illustrates the ann architecture.
fig.  <dig> architecture of the artificial neural network used in mumal and in this work. it illustrates the input layer , the hidden layer , and the output layer , where the activation function is the sigmoid to map the ann’s output into a value in the range  <cit> 




in the mumal work, the authors compared support vector machines with anns and showed that the latter approach was capable of delivering higher sensitivity. the authors still observe that labeling decoy psms as class  <dig> and target psms as class  <dig> leads to a difficult classification task because most target psms are incorrect, i.e., they are similar to decoy hits. however, the goal is not providing a perfect separation between class- <dig> and class- <dig> instances. once a model  is created, different discriminant probabilities are tested to obtain one that results in a sought fdr. this threshold exploitation using decoy counting is the key to separate what really matters, i.e., correct from incorrect hits among target psms.

in this work, we improve the mumal approach to further increase the sensitivity in psm assessment. the selected strategy is to use the decoy instances in the data-set to pin down wrong target instances, so that the model’s capacity to separate correct from incorrect hits is improved. for this purpose, a cost matrix is introduced to the classification task  <cit> , where, considering target instances as positives, the cost of a false positive  is set higher than the cost of a false negative . therefore, the final model will tend to classify class- <dig> instances correctly, while class- <dig> instances will be mostly “misclassified”. the double quotes are to call the attention to the fact that the final goal is to construct a model to separate correct from incorrect psms, not separating target from decoys. hence, when most target instances are classified as class  <dig> by the model, they are being, actually, correctly relabeled to class  <dig> because their peptide sequences were incorrectly assigned. table  <dig> shows an example of a cost matrix that forces the model to favor decoy instances. the idea is to provoke a model bias toward decoy instances, leading to the relabeling of wrong target instances to class  <dig>  resulting in better decision boundaries to separate correct from incorrect psms.
in this case, the cost of a false positive is  <dig> times higher than the cost of a false negative. ctn = cost of a true negative, cfp = cost of a false positive, cfn = cost of a false negative, and ctp = cost of a true positive




as can be seen in the results of our experiments, this relabeling process could be successfully accomplished. however, after fixing cfn =  <dig> and trying different values for cfp, we have realized that a certain cfp that leads to a good model for a given dataset is not necessarily the best choice for another dataset. as a result, for each dataset given as input to our pipeline, ten different models are created varying cfp with the integer values in the range  <cit> , and many discriminant probabilities resulting in different fdr values for each case are reported. next, the model with the highest average number of correct psms, for fdrs varying from  <dig> to 5%, is selected as the final classifier. this cost sensitive classification was implemented in the java programming language using the weka api v <dig> . <dig>  <cit> .

roc curve
as already mentioned, several discriminant probabilities are explored after the model construction, so that the count of decoys considered as positives serves as an estimate to the number of wrong positive targets. this task is accomplished by analyzing the resulting roc curve  <cit> . for each point in the curve, the respective discriminant probability t is used to count the number of decoy hits with probability  equal or greater than t. this count is the estimate for the number of target hits with p ≥t that are incorrect. as described before, class labels in the datasets are:  <dig> for decoy hits, and  <dig> for target hits. it is expected that a minor part of target hits are correct. for this reason, by using classical evaluation methods such as accuracy, precision, recall, and area under the curve , a very poor classification model is expected. however, we stress the fact that the goal is not separating decoys from targets, but incorrect from correct hits, and the roc analysis suffices to establish appropriate discriminant probabilities that provide the desired fdr with a better sensitivity when compared to classical target-decoy approaches.
fig.  <dig> analysis of a roc curve obtained from a model built with dataset s2_nph_ch <dig>  for each point of the curve a, the threshold and several statistical measures b related to that point are known. false and true positives are, respectively, instances of class  <dig>  and class  <dig>  that were considered positives  by the model. in c, it is shown how to estimate fdr among target hits for a given discriminant probability  of the model. it is simply the number of fps over the number of tps




threshold selector
we could see that the roc analysis gives us the chance of selecting an appropriate probability threshold value leading to a desired fdr. this is enough if the goal is just the selection of a low-fdr set of psms. nonetheless, such a set is normally used in the protein inference stage, where the proteins in the sample being analyzed are ultimately identified. to this end, the probability associated to each psm is of great importance, mainly for computational tools that use this value as a key measure to infer proteins, e.g., proteinprophet. on the other hand, the probability values originally assigned by the ann to the instances in the dataset do not reflect the correctness of psms. these values indicate, instead, whether psms are decoys or targets because the class labels where defined this way. considering that most targets  are similar to decoys, even the distinction of decoys and targets is not very well characterized in these probabilities. the auc =  <dig>  seen in fig.  <dig> clearly shows this fact.

in order to obtain appropriate probability values indicating psm correctness, we came up with another improvement by using the threshold selector algorithm  implemented in the weka api. this algorithm can work in two ways. in the first setting, tsa automatically finds a discriminant probability that optimizes some given measure such as f-measure, accuracy, precision, and recall. in the second setting, tsa is given a fixed threshold value. then, tsa forces the classifier to predict as positive all instances with probability greater or equal to the given threshold, or as negative, otherwise. our pipeline uses the latter option along with the probability range correction that tsa provides. in this correction procedure, tsa replaces the probabilities that are equal to the given threshold with  <dig>  and expands the other values so that the minimum probability observed maps to  <dig>  while the maximum maps to  <dig> 

the threshold given to tsa is defined as follows. after building a model with a cost-sensitive ann, with the best cost matrix, and analyzing the roc curve to perform fdr estimations, the discriminant probability that results in 1% fdr is selected to be the final threshold value t that separates correct from incorrect psms. we have chosen 1% because this is the best trade-off between sensitivity and precision, as described by elias et al. and balgley et al.  <cit> . next, the threshold t is given to tsa that adjusts the probabilities generated by the ann, producing new values that are more appropriate to indicate the psm correctness. for psms with p = t, tsa replaces their probabilities with  <dig> . all other psm probability values are modified as described above. as a result, we finally obtain a classifier that separates correct from incorrect psms  with the usual mid-point probability value  <dig>  as the point of separation between negatives and positives.

frameworkfig.  <dig> flowchart to illustrate mumal2’s framework. ten different values for the cost of a false positive are tested in the cost matrix. after selecting the best value in terms of the resultant sensitivity, the final model is built, including the use of tsa with probability range correction. the probability threshold for a 1% fdr identified in the roc analysis is converted to  <dig>  by the tsa. therefore, the end model uses  <dig>  as the discriminant probability, i.e., the set of psms with fdr =  <dig>  are characterized as the ones with high probabilities 




RESULTS
to evaluate mumal <dig>  the parameters were kept with default values, i.e., number of nodes in the hidden layer =  <dig>  momentum =  <dig> , learning rate =  <dig> , and epochs =  <dig>  the experiments were performed on a linux machine equipped with intel® celeron® cpu n <dig>  <dig>  ghz ×  <dig>  and  <dig> gb of ram. our intention was to prove that mumal <dig> can provide a quick answer even on personal computers. in fact, one iteration of mumal <dig>  i.e., one execution of the strategy cost matrix + ann, takes  <dig> s on average. because eleven executions to produce the final model are needed, the total time taken is  <dig> s, in general. we realized that it is not significantly different from mumal’s running time because mumal has also to execute a number of iterations to produce its best results. therefore, we concentrate the analyses of our experiments on the capacity of our approach to assess psms.

measuring the predictive power of mumal2
first, dataset m <dig>  whose proteins are known, was used to measure the predictive power of our method. we analyzed whether the relabeling of wrong psms in class- <dig> to class- <dig>  i.e., the establishment of a suitable decision boundary between correct and incorrect hits, could be satisfactorily accomplished. figure  <dig> contains plots of △cn vs xcorr for dataset m <dig> before  and after  running mumal <dig>  class- <dig> psms are represented in blue, whereas class- <dig> psms are shown in red. a dense cloud of points in fig. 5
a can bee seen composed of approximately 50% of decoys and 50% of targets. according to the target/decoy principle, this dense cloud represents the set of wrong psms. therefore, we are interested in the part that is comprised mostly of red points . as already mentioned, the use of a cost matrix to construct an accurate model for the class- <dig> instances is an attempt to keep these instances as such, since decoy psms are obviously wrong, whereas correctly relabeling the wrong class- <dig> instances, the ones mixed with decoys in the dense cloud, to class  <dig>  figure 5
b shows that the decision boundary produced by mumal <dig> seems to provide a good separation of the mixture of decoys/targets from the homogeneous part composed of red points. notice that the confusion matrix on the top makes evident the huge amount of target psms that were classified as class  <dig>  which was expected because most of these psms are known to be wrong. the plot built as a result of the instance relabeling shows that the vast majority of instances in the dense cloud turned into blue.
fig.  <dig> instance relabeling provided by mumal <dig>  a plot of △cn vs xcorr for dataset m <dig> is shown in a and b, before and after applying mumal <dig>  respectively. class- <dig> instances are shown in blue, while class- <dig> instances are shown in red. part b includes also the confusion matrix on the top to show the huge number of class- <dig> instances that were classified as class 0




even though the plot in fig. 5
b indicates that the region of interest  could be identified, it is possible to provide more precise measurements of the quality of our solution because the proteins of dataset m <dig> are known. the confusion matrix on the top of fig. 5
b shows that  <dig> decoy hits were mistakenly classified as class  <dig>  probably, some correct target hits were incorrectly relabeled to class  <dig> as well. thus, to provide a more precise assessment of our strategy, the  <dig> instances predicted as class  <dig> and the  <dig> predicted as class  <dig> had their peptide sequences inspected to check whether or not they came from the set of expected proteins. as a result, we could build a more useful confusion matrix, considering positive or negative those instances whose peptide sequence came from the list of known proteins or from a random protein, respectively. as a consequence, we could use classical metrics that express the predictive power of an ml model, as shown in tables  <dig> and  <dig>  it can be seen that mumal2’s classification was highly accurate. only  <dig> instances  were misclassified, also leading to very high values of sensitivity, specificity, and precision. however, it is important to highlight that the decoy hits are known to be wrong psms. therefore, the  <dig> misclassified decoys shown in fig. 5
b have no importance, i.e., only target instances are further considered after the classification.
a confusion matrix is shown, where positive and negative instances are not target and decoys anymore. instead, an instance is considered positive if its peptide sequence came from the list of known proteins. otherwise, the instance is considered negative





it is clear, thus, that the application of a supervised ml method here does not follow the classic steps: build the learning model using a training set, and apply the resultant model to unknown instances. in our case, the ann is trained and applied using the same data. notice that the target instances are the ones of interest. our final aim is to separate wrong targets from correct targets. to this end, we use a higher cost for fps to force the model to learn how to correctly classify decoys whose labels are obviously correct. that is why we say that decoys help to pin down wrong targets. next, we apply the final model on the same data to relabel the wrong target hits, i.e., the ones with similar features to decoy hits, to class  <dig>  thus, it does not make sense to talk about cross-validation to evaluate the model. instead, we have to verify whether correct and incorrect targets are being identified.

another important aspect to analyze is whether the probabilities produced by our model are coherent. this is a very relevant matter if the intention is to use a method for protein inference that takes psm probabilities into account. as shown in fig.  <dig>  the auc and other measures are low because the wrong target hits that are correctly relabeled to class  <dig> are counted as misclassification. in fact, the blind application of mumal <dig> to dataset m <dig> leads to an auc of  <dig> . however, as we know the proteins of dataset m <dig>  we can produce the real roc curve to evaluate the probabilities generated by tsa. figure  <dig> shows the roc curve built for dataset m <dig> counting as tps those instances whose peptides came from the list of known proteins, and counting as fps, otherwise. as can be seen, the auc is very satisfactory , showing that the probability values are appropriate, and corroborates the high predictive power of mumal <dig> 
fig.  <dig> roc curve of mumal2’s model for dataset m <dig>  an instance is regarded as tp if its peptide sequence came from the list of expected proteins. otherwise, the instance is considered fp




mumal <dig> was also applied to the other datasets for which the proteins are not known a priori. however, it is possible to use plots of △cn vs xcorr, as previously shown for dataset m <dig>  to perform a visual inspection. figure  <dig> shows this analysis for dataset s1_ph_ch <dig>  it can be seen in the confusion matrix  that a significant number of class- <dig> instances were relabeled to class  <dig>  as expected. in the plot of fig. 7
b, the colors of the points indicate that the classification seem to be appropriate because the blue points correspond to those in fig. 7
a composed of a mixture of targets and decoys, i.e., the part where targets are probably wrong, according to the target/decoy principle. performing the same analysis for the other datasets led to very similar outcomes , i.e., mumal <dig> promoted an expressive migration of target hits to class  <dig>  resulting in a plot where class- <dig> instances correspond to the mixture of class- <dig> and class- <dig> instances before the application of mumal <dig> 
fig.  <dig> instance relabeling performed by mumal <dig> for dataset s1_ph_ch <dig>  a plot of △cn vs xcorr for the dataset is shown in a and b, before and after using mumal <dig>  respectively. class- <dig> hits are shown in blue, whereas class- <dig> hits are shown in red. part b addtionally presents the confusion matrix on the top, demonstrating the significant number of class- <dig> examples that were classified as class 0




comparing mumal <dig> with previously proposed methods
the next experiments demonstrate the superior sensitivity of mumal <dig> in relation to important methods for psm assessment: mumal, mude, peptideprophet, and bivariate decoy/target analyses, where the thresholds of two scores, often △cn and xcorr, leading to a desired fdr are pursued. for comparisons with phosphodata, we included a bivariate analysis with △m and xcorr, following beausoleil et al. and jiang et al. recommendation  <cit> . according to them, △cn scores are often suppressed when phosphopeptides have more than one potential phosphorylation site. therefore, △m should be used instead. for a detailed description of how the methods used in the comparison were run to produce the results shown next, refer to the works of cerqueira et al.  <cit> .

figures  <dig> and  <dig> show the curves of the number of identified psms vs estimated fdr for all above-mentioned methods applied to the eleven datasets of unknown proteins. it is possible to build such curves because all those approaches provide an effective way to estimate the fdr value for a given set of selected psms. the curves show fdr values varying from  <dig> to 5%, which are the error rates commonly accepted. it can be seen in all cases that mumal <dig> is superior than mude, peptideprophet, and the bivariate analyses.
fig.  <dig> comparing the sensitivity of mumal <dig> and other approaches with data of non-phosphorylated proteins. for each dataset, a curve of the number of identified psms vs estimated fdr is shown. fdr values vary from  <dig> and 5%


fig.  <dig> comparing the sensitivity of mumal <dig> and other approaches with data of phosphorylated proteins. for each dataset, a curve of the number of identified psms vs estimated fdr is shown. fdr values vary from  <dig> and 5%




regarding mumal, mumal <dig> has an equal or greater sensitivity. it is expected because mumal <dig> performs  <dig> executions with cfp varying from  <dig> to  <dig>  the execution with cfp =  <dig> is equivalent to the mumal execution. therefore, mumal <dig> cannot be worst, but it can eventually present the same sensitivity as mumal. notice, however, that the number of cases where mumal <dig> has a greater sensitivity is higher than the cases of equal performance. our method could provide an average increase of  <dig>  and  <dig> % in relation to mumal for non-phosphodata and phosphodata, respectively. it means about  <dig> and  <dig> more peptides, on average, respectively.

in particular for a 1% fdr, which is a commonly pursued fdr value, mumal <dig> demonstrates superiority in all cases. for non-phosphorylated proteins, the psm evaluation provided by mumal <dig> for this fdr led to an average improvement in sensitivity of  <dig> % compared with mumal, meaning about  <dig> additional peptides. for phosphorylated proteins, in turn, the increase was approximately 12%, resulting in nearly  <dig> more peptides.

figures  <dig> and  <dig> demonstrate that mumal presented the best performance among the methods being compared with our approach. for this reason, we performed an additional experiment to compare mumal <dig> with mumal by means of venn diagrams to call attention to the higher number of exclusive peptide identifications provided by the former. figure  <dig> shows this counting for a 1% fdr in both methods. in all cases, an expressive superiority of mumal <dig> can be noted. on average, the number of exclusive psms that our method could find is almost 4-fold greater. this is an important result because more peptides may imply more identified proteins and a higher proteome coverage.
fig.  <dig> comparison of mumal <dig> with mumal by venn diagrams containing the number of psms selected for fdr=1%. for each diagram, the left-hand side contains the number of peptides identified exclusively by our method, while the right-hand side shows the number of identifications found exclusively by mumal




CONCLUSIONS
the target-decoy database strategy is widely used for data analysis in shotgun proteomics. many previous studies have demonstrated the effective capacity of this approach for fdr estimation. however, the classical tddb procedure does not take sensitivity into account. fortunately, this fact has been changing since the introduction of mude and mumal.

in this work, we have further improved sensitivity in ms/ms-based peptide/protein identification by using advanced machine learning methods that use decoys to establish more appropriate decision boundaries. furthermore, the probabilities assigned to psms by our method are proven to be highly accurate. this is a fundamental matter to improve protein inference when the applied approach depends on such probability values, as in the case of proteinprophet.

we could demonstrate that our new approach has great potential to provide important improvements in protein identification, which will impact future studies that seek a broader understanding of notable cell activities. hopefully, future research on drug discovery, diseases, and many other studies in life sciences will be positively affected by this new computational strategy for peptide/protein identification.

abbreviations
ms/mstandem mass spectrometry

lc-ms/msliquid chromatography coupled with tandem mass spectrometry

psmpeptide-spectrum match

dbdatabase

fdrfalse discovery rate

tddbtarget-decoy database

ann, artificial neural network; rocreceiver operating characteristic

aucarea under the curve

tsathreshold selector algorithm

rtretention time

cfpcost of a false positive

cfncost of a false negative

