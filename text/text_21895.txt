BACKGROUND
the development of chromosome conformation capture  techniques and their high throughput derivatives  has enabled the analysis of nuclear architecture  at an unprecedented resolution  <cit> . hi-c data analysis comprises a large variety of approaches, including point-to-point looping interactions , three-dimensional modeling of chromatin  <cit> , identification of structural domains , or comparison of different genetic backgrounds .

the large number of reads produced by hi-c experiments  requires efficient tools for processing, filtering, and simplification of the data to best match the demands of the downstream analyses. several open-source tools are available, each with its own scope and requirements. hicup  <cit>  performs mapping and quality control on hi-c data but no downstream analysis. sushi  <cit>  and hitc  <cit>  provide data visualization functionality, but no pre-processing or statistical analysis of hi-c data. hicseg specifically focusses on identification of domains in hi-c data  <cit> . chromor  <cit>  offers data pre-processing and sample comparison, but does not support the analysis of additional genomic and epigenomic features. hicpipe  <cit>  implements a computationally very intense normalization method, which does not perform better than the parametric approach in hicnorm  <cit>  . homer  <cit>  and hiclib  <cit>  offer a large variety of functionalities, including pre-processing and higher-level data analysis. however, these tools may be inaccessible to users with limited programming experience: homer requires some command-line skills and only generates plain-text output, which needs to be further processed by the user; hiclib requires familiarity with python. the latter is less well known among molecular biologists and geneticists who are likely more familiar with r. alternatively, hibrowse offers many functionalities in an easy-to-use web-interface  <cit> , which, however, constrains the users by forcing them to adhere to the available procedures and the requirement of uploading their data to a web server.

envisioning nuclear architecture  as an ordinary phenotype of an organism or a specific tissue type , comparative hi-c experiments may soon be of very broad interest, raising the need for data analysis tools that are not only well-accessible to bioinformaticians. we therefore developed hicdat. it includes a fast and easy-to-use gui tool for hi-c data pre-processing and an r  <cit>  package, which implements all data analysis approaches employed in  <cit> .

implementation
hicdat was developed with a focus on speed, user-friendliness, and flexibility in terms of file formats. the gui tool for data pre-processing serves to convert large-scale genomic and epigenomic data into simple tables, which can be efficiently loaded and processed within r. the r-package provides a collection of functions, which allow higher-level data analysis  with only a few lines of code. data formats are kept as simple as possible to ensure that the user can easily integrate hicdat into a pre-existing workflow or combine it with other tools.

RESULTS
hicdat is divided into two parts :  a gui tool for data pre-processing  and  an r-package for higher-level data analysis .
fig.  <dig> schematic hicdat workflow.  after sequencing and initial quality checks have been performed, the read-ends  are aligned separately to a reference genome.  after pairing the separately aligned read-ends, each end is mapped to genomic fragments, which are either genomic bins with a fixed size or restriction fragments with variable size.  genomic fragments can be associated with various data types to test for correlation and enrichment of hi-c data with genomic and epigenomic features.  finally, the data can be conveniently analyzed in r using hicdatr



data pre-processing with hicdat
hicdat takes as input two alignment files  in bam format , a reference genome, and various data types from additional experiments . there are five automated steps during data pre-processing:  pairing aligned reads,  creating fragments,  mapping of read-ends to fragments,  processing data from additional experiments, and  creating organism-specific r-code.

pairing aligned reads
the read-ends are first aligned seperately to the reference genome using, for example, subread  <cit> . uniquely aligning read-ends are then paired based on their common read name to create read-paris .

creating fragments
hi-c data analysis can either be carried out on restriction fragments or genomic bins with fixed size. both types of fragments can be created by supplying the reference genome sequence and one or more restriction enzymes or a fixed bin size.

mapping read-ends to fragments
to calculate the interaction frequency between two fragments, the read-pairs are first mapped to the fragments’ coordinates and then summarized as number of interactions per fragment pair . during this procedure, the read-pairs can optionally be filtered using the approach proposed by  <cit> . read-pairs with each end aligning at the opposite strand are thereby removed if they are too close to each other. there are two cases:  a read-pair where the two ends point towards each other , and  a read-pair where the two ends point away from each other . inward-pairs spanning only a short region may be caused by uncut dna. outward-pairs spanning only a short region can be a result of self-ligation.

processing data from additional experiments
to analyze the interplay between the hi-c interactome and genomic/epigenomic features, a large variety of such information can be automatically added to the fragments. in principle there are two fundamentally different types of data: counts and densities. during higher-level data analysis, counts are generally log-transformed, whereas densities are kept as percentages. likewise, if data are summarized over multiple fragments , counts are summed up, whereas densities are averaged. both data types comprise two sub-types, resulting in four different types of “tracks” which can be processed:  genome annotation features ,  short count features ,  density features , and  dna-methylation density .

genome annotation features  can generally be very long and possibly span multiple fragments. the number of elements per fragment is therefore counted as follows: if the feature spans the entire fragment, a value of  <dig> is added. if the feature only partly overlaps  the fragment, a value of  <dig>  is added. in contrast, short count features  are mostly entirely within a fragment and are therefore simply summed up per fragment.

density of a certain feature  is calculated as the number of bases covered by at least one element  divided by the length of the fragment . likewise, dna cytosin-methylation density corresponds to the percentage of methylated c’s per fragment.

creating the organism-specific r-code
higher-level data analysis requires some organism-specific r-code, which can be obtained by supplying the reference genome sequence and the restriction enzyme used for the hi-c library preparation.

data analysis with hicdatr
in-depth hi-c data analysis is done in r with hicdatr. the only inputs required are the interaction counts per fragment pair and, optionally, the annotation of the fragments holding the genomic and epigenomic tracks. for most of the functions, it is furthermore possible to supply tables specifying genomic regions of interest . the functionalities include  data normalizations as proposed by  <cit> ,  sample correlation matrices,  data visualization,  sample comparisons,  calculation of distance decay exponents,  principle component analysis  including correlation of the first principle component to genomic and epigenomic features,  test for increased interaction frequencies between genomic regions of interest compared to randomly sampled regions, and  test for enrichment or depletion of genomic and epigenomic features within genomic regions of interest compared to randomly chosen regions.

data normalization
multiple data normalization strategies have been proposed and implemented in various languages and packages . three of them have been re-implemented in hicdat:  the distance  and coverage  normalization described in  <cit> ,  the iterative coverage normalization proposed by  <cit> , and  the more sophisticated but highly efficient normalization using poisson regression as implemented in hicnorm  <cit> , which performs similar or better  <cit>  than the procedures from  <cit> .

sample correlation
to visualize the similarities between samples and replicates, hicdat uses sample correlation matrices. correlation between two samples is thereby calculated as the average, or median, correlation between all the individual bins of the interaction matrices .

data visualization
hi-c interaction frequencies and differences between multiple samples are visualized as heatmap-like images. individual samples can either be displayed natively  or in a correlated manner .

sample comparison
three different approaches to compare two samples to each other are implemented. in a first approach, the difference of a given fragment pair between the two samples is divided by the average interaction frequency among the two samples resulting in “relative differences”  <cit>  . considering that neighboring genomic regions are physically linked to each other, it is likely that they change accordingly. to visualize these domains, the relative differences can be correlated to each other . the disadvantage of these approaches is that they rely on visual inspection of the difference matrices. to estimate the significance of the difference and identify the affected regions, we introduced signed difference matrices   <cit> . additionally, they also provide an overall estimate of the extent and significance of the difference between two samples .

calculation of distance decay exponents 
the extent to which interaction frequencies change dependent on the distance to a given point in the genome can be characterized with the interaction decay exponent . ides are calculated as the slope of a linear fit to the average interaction frequencies observed at given distances . ides were initially used to predict the folding principles of the human genome using two polymer-folding models , which result in distinct values for the expected ide  <cit> . alternatively, they can also be used to describe differences between certain sub-compartments of the genome, or between samples  <cit> .

identification of structural domains using principle component analysis 
the correlation between the interactomes of different genomic regions can be used to identify larger compartments  <cit>  or structural domains  <cit> . the approach relies on principal component analysis  of the distance-normalized and correlated intra-chromosomal interactions . the first principal component  can then be used to differentiate for example the a and b compartments in homo sapiens  <cit> , or loose and compact structural domains in arabidopsis thaliana  <cit> . the interplay between the fpc and the epigenomic/genomic landscape can be analyzed with two methods:  either by using the built-in cor.test()  <cit>  function to test for significance of correlation between fpc and the density/count of a given feature , or  by using an approach in which the fragments are split into two groups according to the sign of the fpc . enrichment of a given feature can then be calculated as the ratio of the average density/count in one over the other group, and tested for significance using a two-sided wilcoxon rank sum test  <cit> . for the identification of more refined structural domains, as for example topologically associated domains , hicdatr provides a simple wrapper around the hicseg package  <cit> . its algorithm relies on two-dimensional segmentation to identify cis-interacting regions, and the results were shown to be in good concordance with biologically confirmed regions  <cit> .

testing selected regions for increased interaction frequency and enrichment/depletion of epigenomic/genomic features
given a set of genomic regions of interest, hicdat can test for increased interaction frequencies between the regions of interest compared to randomly sampled regions. considering that the interactome can be strongly influenced by the linear position of a certain region along the chromosome , or the chromosome number itself  <cit> , random sampling is performed in a “balanced” fashion: within each random set, the randomly chosen regions reflect the numbers, as well as the locations, of the regions of interest. the procedure creates an empirical distribution of interaction frequencies between random sets, which can then be used to calculate an empirical p-value  for the enrichment of interactions between the sets of interest  <cit> . the same sampling approach can be applied to test for enrichment or depletion of epigenomic or genomic features within a set of genomic regions of interest.

CONCLUSIONS
in short, hicdat allows rapid hi-c data analysis as described in  <cit> , requiring only little programming experience. the focus lies on the identification of larger structural features of chromosomes, their interplay with the epigenomic/genomic landscape, and on comparative studies. input and output is kept as simple as possible to enable easy integration into pre-existing workflows, or the combination of a part of the tool with another tool.

availability and requirements
project name: hicdat

project home page:github.com/mwschmid/hicdat

operating systems: windows , macosx , ubuntu-like linux distributions 

programming language: c++ and r

other requirements: r-packages: randomizebe, gplots, mass, hicseg  <cit> 

license: gnu gpl v3

any restrictions to use by non-academics: none



endnote
 <dig> run-times were measured on a  <dig> bit kubuntu running on an intel core i <dig> 930@ <dig>  ghz with  <dig> gb ram and a 7’ <dig> rpm samsung hdd using hi-c data from mouse embryonic stem cell  and cortex  samples from  <cit>  .

additional files
additional file  <dig> 
figure s <dig>  correlation between five samples of arabidopsis thaliana seedlings  <cit>  aligned with either bowtie  <cit> , bowtie  <dig>  <cit> , or subread  <cit> , and processed with either hicdat or hiclib  <cit>  using a resolution of  <dig> kb. 



additional file  <dig> 
figure s <dig>  visualization of hi-c interaction frequencies in a pooled wild-type sample of a. thaliana  <cit>  . 



additional file  <dig> 
figure s <dig>  visualization of distance-normalized and correlated hi-c interaction frequencies in a pooled wild-type sample of a. thaliana  <cit>  . 



additional file  <dig> 
figure s <dig>  enrichment  and depletion  of interaction frequencies in the wild-type compared to the crowded nuclei <dig>  mutant sample of a. thaliana  <cit>  . 



additional file  <dig> 
figure s <dig>  correlation of differences between the wild-type and the crwn <dig> mutant samples of a. thaliana  <cit>  . 



additional file  <dig> 
figure s <dig>  visualization of the difference between the wild-type and crwn <dig> mutant samples of a. thaliana,  <cit>  using the signed difference matrix . 



additional file  <dig> 
figure s <dig>  distance-dependent decay of interaction frequencies along entire chromosomes in a pooled wild-type sample of a. thaliana  <cit>  . 



additional file  <dig> 
figure s <dig>  visualization of distance-normalized and correlated hi-c interaction frequencies , the resulting first principle component , and the distribution of the correlation values . data shown for the right arms of chromosomes  <dig>   <dig>  and  <dig> from a pooled wild-type sample of a. thaliana  <cit>  . 



additional file  <dig> 
figure s <dig>  significant correlation  of the first principle component with various genomic and epigenomic features. data shown for the right arms of chromosomes  <dig>   <dig>  and  <dig> from a pooled wild-type sample of a. thaliana  <cit>  . additional data from www.arabidopsis.org and . 



additional file  <dig> 
figure s <dig>  significant enrichment  and depletion  of genomic and epigenomic features in regions with positive eigenvalues compared to regions with negative eigenvalues. data shown for the right arms of chromosomes  <dig>   <dig>  and  <dig> from a pooled wild-type sample of a. thaliana  <cit>  . additional data from www.arabidopsis.org and . 



additional file  <dig> 
figure s <dig>  distribution of epigenomic and genomic features in the structural domains with either positive  or negative  eigenvalues. data from www.arabidopsis.org and . 



abbreviations
gffgeneral feature format

gtfgene transfer format

bambinary alignment map

ideinteraction decay exponent

pcaprinciple component analysis

fpcfirst principle component

competing interests

the authors declare that they have no competing interests.

authors’ contributions

conceived and discussed approaches for hi-c data analysis: mws, sg, ug. designed andimplemented the pre-processing tool: mws. designed and implemented higher-level data analysis in r: mws sg. wrote the manuscript: mws. helped to write manuscript: sg ug. all authors read and approved the final manuscript;

