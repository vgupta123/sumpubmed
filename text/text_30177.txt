BACKGROUND
skin cancer is one of the most prevalent cancer types in the united states. the prevalence of skin cancer is increasing dramatically in the united states  <cit> . each year the number of patients being diagnosed has raised compared to the previous year. the most common skin cancer type for young adults between  <dig> and  <dig> years old is melanoma  <cit>  which can lead to metastatic disease with serious complications from surgery such as scarring, deformity, and death.

dermoscopy is a method in which pigmented and non-pigmented skin lesions’ features are examined with a handheld device, known as dermatoscope, by health professionals. dermoscopy is also known as dermatoscopy, skin-surface microscopy, epiluminescence microscopy   <cit> . the ultimate goal of dermoscopy is the early diagnosis of malignant lesions, especially melanomas, by distinguishing them from benign. in order to differentiate malignant skin lesions from benign ones, the abnormal structural features and the borderline of non-pigmented skin lesions need to be taken into account.

due to the fact that microstructure of the epidermis, the dermoepidermal junction and the papillary dermis are not detectable by the naked eye, dermoscopy is an invaluable asset for diagnosing particularly pigmented skin lesions. according to vestergaard et al.  <cit> , in the case of the diagnosis of melanoma, the use of dermoscopy provides more accurate results than using clinical evaluation alone by the naked eye.

potential signs and symptoms of melanoma could be identified by taking the abcd  rule  <cit>  into account during examination of a skin lesion. the abcd rule assesses geometric and morphologic variables such as asymmetry, color, and border of a given melanocytic lesion  <cit> . each of these a,b,c,d features has a preassigned clinical weight factor . b stands for border and it indicates abrupt cutoff in the region of interest . abrupt cutoff is the region where lesion has sharp circumscription. a virtual pie refers to quarters  of lesion circumference. figure  <dig> illustrates a virtual pie and marks  pie pieces with sharp lesion circumscription. for instance b scores 2* <dig>  in fig.  <dig>  since there are two pie pieces marked with abrupt cutoff . a lesion’s b value is calculated if there exists abrupt cutoff at least one quarter of the lesion circumference. due to applicability of the abcd rule, it is also recommended for use by clinicians who are not fully trained in dermoscopic observation  <cit> . reliability of the abcd  <cit>  rule has been tested by nachbar et al.  <cit> . in this study, it is reported that diagnostic accuracy for melanoma was  <dig>  % by using abcd rule compared to  <dig>  % by the naked eye. assessment of asymmetry, color, differential structure, and border in abcd rule was used to build a total dermoscopy score . each of these features in abcd contributes to tds score according to their preassigned clinical weights . if tds value is less than  <dig> , it is an indicator for lesion being benign. if it is between  <dig>  and  <dig> , then that lesion is suspicious for malignancy. if tds score is greater than  <dig> , it indicates that the lesion is malignant  <cit> .fig.  <dig> a virtual pie illustrated with white lines in a sample lesion, asterisks indicate abrupt cutoff in a virtual pie




a clinical study conducted on  <dig>  histopathologically examined skin neoplasms  <cit>  shows that sensitivity in the clinical diagnosis of malignant melanoma is  <dig>  %. even though there have been improvements in the clinical diagnosis of melanoma, melanomas have different clinical accuracies based on their subtypes. for instance, a study by lin et al.  <cit>  shows that melanoma subtypes of superficial spreading melanomas , acral lentiginous melanomas , nodular melanomas , and desmoplastic melanomas  have different clinical diagnosis sensitivity rates. sensitivity rates of these melanoma subtypes are reported as 77 % for ssm, 73 % for alm, 41 % for nm, and 21 % for dm.

moreover, the diagnostic accuracy of a dermatologist is significantly depended on the degree of experience of the examiner. thus, interobserver variability for diagnosis of pigmented skin lesions amongst dermatologists is an important aspect for clinical diagnostic accuracy. tan et al.  <cit>  shows up to  <dig>  kappa value differences between different dermatologists on the diagnosis of the same cases of melanoma lesions. in the same study  <cit> , interobserver difference reaches up to  <dig>  kappa value for benign lesions. kappa value is a statistical measure for finding inter-rater agreement. for instance, a perfect agreement between two dermatologists on diagnosis of the same cases will result in a kappa value of  <dig> , whereas a perfect disagreement on diagnosis of the same cases results a kappa value of  <dig> .

one of the criteria for detecting melanoma is abrupt cutoff . in current clinical practice, in order to detect abrupt cutoff feature for malignancy detection; the lesion is segmented into eight virtual pies  in which a dermatologist examines for abrupt cutoff and assigns a score for each of the pie pieces. this process is a manual and a tedious process, over simplified, and it is subjective based on the experience of the dermatologist examining the lesion. to address this challenge, in this study we offer a novel approach to quantify abrupt cutoff along the periphery of the skin lesion border. instead of analyzing eight virtual pies, we scan whole lesion border’s inner region and quantify each region. to do that, the first step was to accurately define the lesion border.

there are different lesion border detection methods in the literature  <cit> . we use our density-based lesion detection method   <cit>  for skin lesion border detection. then freeman chain code  <cit>  is used to extract extreme border pixels from the detected lesion border. after that, the shrinking  and the shifting operations are applied to detected border to identify inner border contour. this contour  is needed for texture homogeneity analysis. shadow border refers to a contracted border of the lesion. shadow borders are found by using vector operations and dynamic scaling operations. then, along shadow borders, pigment patterns’ statistical texture measures and statistical texture features, especially homogeneity, are computed in various scales in various color spaces. different color models and color channels are used to investigate which color model is more effective in dermoscopy image analysis. reader is referred to  <cit>  for details on analysis of color models and color channels on biomedical image processing.

textures in an image refer to visual patterns with different characteristics such as color, brightness, slope, size, uniformity, roughness, regularity, randomness, granulation, fineness, and coarseness etc. there are mainly structural, statistical, model-based, and transform methods for texture analysis  <cit> . structural methods define textures in micro and macrostructural level and there is no clear distinction between them. structural methods fit better for texture synthesis than texture analysis. statistical methods attempt to capture non-deterministic properties of an image. more specifically, statistical methods capture distributions and relationships of grey levels. the most popular statistical texture analysis is based on co-occurence matrix. three of the most common statistical texture analysis methods are based on the gibbs random field, the gaussian random field, and the markov random field  models  <cit> . model based methods use fractals and stochastic models; however, estimation of parameters in both fractal and stochastic based models is a major bottleneck. transform based methods use different transformation functions such as fourier, gabor, and wavelet. in this group of texture analysis methods, image is represented in a different coordinate space. in transform based methods, fourier poorly performs because after the transform, spatial localization information is lost. on the other hand, gabor provides better spatial localization; however, it needs multiple filter resolutions to capture spatial structures such as natural textures. this makes the use of gabor impractical for most cases. wavelet, on the other hand, represents textures at varying spatial resolutions with varying wavelet functions. however, wavelet transform is not translation invariant.

in a recent study  <cit>  investigators used  <dig> texture descriptors for melanoma detection in dermoscopy images. however, they obtained up to 83 % specificity and 53 % sensitivity in grayscale images for melanoma detection. in this study, they also found out that image’s uniformity is the best descriptor with standalone 70 % accuracy.

methods
dermoscopy image analysis
preprocessing
we describe essential image processing operations to make the dermoscopy image and its mask  ready for the further steps. these operations include: color space transformations, lesion border detection with density-based lesion detection method  <cit> , complement operation, clearing region remains outside of the rectangle , and morphological opening operations. the flow diagram of preprocessing phase is shown in fig.  <dig> fig.  <dig> preprocessing flow scheme




in the color transformation phase, rgb color space of dermoscopy image is transformed into different color spaces; gray scale, ycbcr, and hsv color spaces respectively . in the next step, in order to obtain the mask from dermoscopy image, density-based lesion detection method  <cit>  is used. these steps are illustrated in fig.  <dig> fig.  <dig> color space conversion


fig.  <dig> preprocessing operations: lesion border detection with dbld and complement




moreover, since the mask is a negative version of a regular standardized mask, the complement operation is applied to the mask to generate a standardized mask. some of the images’ masks include noisy pixels other than the region of interest. thus, we clear the region outside of the region of interest . for finding this rectangular region we use following equations which incorporate percentage clipping parameter from left, right, top, and bottom from the mask.  <dig>  leftboundary=1+w2∗percentage_of_edges_to_clip <dig> 
  <dig>  rightboundary=w−w2∗percentage_of_edges_to_clip <dig> 
  <dig>  topboundary=1+h2∗percentage_of_edges_to_clip <dig> 
  <dig>  bottomboundary=h−h2∗percentage_of_edges_to_clip <dig> 


in the same methodology, the right, top, and bottom boundaries’ pixel locations are determined by the equations above. percentage of edges to clip parameter is empirically determined for our dataset. this parameter is based on the observations on dermoscopy images that lesion is always on the center of dermoscopy images. thus, the boundary rectangle tightly encapsulating the lesion can be drawn around the region as seen in fig.  <dig>  region remains outside this rectangle is discarded from further processing. this provides two-fold benefit. first, this reduces overall computation time; second, removes noise and eventually increases accuracy of the results. noise refers to clustered regions that are separated from the lesion.fig.  <dig> preprocessing operations: clear outside of the rectangle and opening operations




the final step of the preprocessing phase is morphological opening operation  <cit> . morphological opening operation aims to even further remove the leftover noisy pixels from the mask. opening simply removes small objects from the foreground of the image and puts them back into the background. the mathematics behind morphological opening operation is described in the following equation.  <dig>  a∘b=a⊖b⊕b where a denotes an image, b refers to a structuring element and two operation symbols are an erosion and a dilation respectively. dilation is a morphologic operation which causes objects to dilate or grow in size; whereas erosion causes objects to shrink. the amount of growth or shrinkage depends on the choice of the structuring element. structural element differentiates dilation/erosion from classical low pass filter. two of the well-known common structuring elements  are the 4-connected and 8-connected sets, n <dig> and n <dig> respectively. morphological opening operation is applied to the mask. this morphological opening after edge clipping operation , the increase of numbers progresses in the counter-clockwise direction.fig.  <dig> 
a rectangular-grid and b digital boundary on grid




interpretation of the numbers is that one walks along the pixels on the object’s boundary from starting and ending at the same pixel. for instance, for the given digital boundary in fig.  <dig>  when one walks around the shape in the clock-wise direction, it would result in a number sequence such as { <dig> , <dig> , <dig> , <dig> , <dig> }. this sequence simply is referred to as an encoding form of the boundary.

the goal of this stage is to determine extreme pixels at the lesion border. the idea behind this approach is to first scan through the entire pixels and record the ones which belong to the foreground. then, find the minimum among all rows  pixels. with the help of this minimum row value, the lowest value among all column pixels is detected in the image mask. by doing so, this approach gives us the row and column of the starting pixel for the chain code. once starting pixel for the chain code is determined, the chain code generates a list of clockwise or counter-clockwise adjacent pixels. the starting pixel is shown in fig. 6b. by applying the chain code, the boundary of the region in a dermoscopy image is captured as depicted in fig.  <dig> fig.  <dig> 
a the finalized dermoscopy image mask b the starting pixel




feature extraction
for feature extraction, we developed three different approaches: texture feature extraction along the lesion border , along the inner border which is found by utilizing vector operations towards the center of the lesion’s mass , and along the inner aligned/shifted border by utilizing a scaling factor  respectively. from these three different methods, we extract statistical measures and statistical texture features of dermoscopy images and compare each method’s accuracy for malignancy detection. statistical measures that are considered here are mean and standard deviation  <cit> , whereas gray level co-occurrance matrix   <cit>  is described as a texture descriptor in the texture analysis.

the gray-level co-occurrence matrix   <cit>  is a statistical method that scrutinizes texture characteristics that rely on the spatial relationship between pixels. glcm is also referred to as the gray-level spatial dependence matrix and co-occurrence distribution. the texture of an image can be represented with glcm functions where specific values of pairs of pixels are computed and spatial relationship that arises in the image are represented by the glcm. thus, statistical measures can be extracted from the glcm matrix. mathematically, the gray-level co-occurrence matrix  can be described over an image in which co-occurrence distribution parameters are illustrated for specific offset values.  <dig>  cΔx,Δyij=∑p=1n∑q=1m <dig> ifipq=iandip+Δx,q+Δy=j <dig> otherwise where c is the co-occurrence matrix, i is the image with nxm size, i and j are the image intensity values, p and q are the spatial coordinates in the image, and lastly  is an offset parameter which is the function of the direction θ and the distance d. the co-occurrence matrix is susceptible to rotation due to offset parameters. in order to create the glcm, the gray co-matrix function  <cit>  is taken into account which constructs the gray-level co-occurrence matrix . glcm is a square matrix where its columns and rows are equal to the number of gray levels in the image. the matrix element c
Δx,Δy corresponds to a relative frequency of two pixels with intensity values i and j respectively. moreover, these pixels are separated by a pixel distance .

however, other spatial relationships can be defined among the two pixels such as ∆x =  <dig>  ∆y =  <dig>  the sum of the frequency occurrence of pixel intensity value i with respect to the pixel intensity value j based on the particular spatial relationship which builds up the basis of each element  in the glcm matrix. the size of the glcm refers to the number of gray levels in the image.

moreover, numerous statistical features can be acquired by utilizing the glcm matrix. homogeneity measures how similar the gray levels are in the spatial distribution of the image. homogeneity of an mxn image can be expressed with the equation below.  <dig>  ∑i=1m∑j=1nglcmijm−Δxn−Δy 


in eq. , m denotes number of pixels in the vertical direction and n denotes number of pixels in the horizontal direction of an image.

in most cases, the spatial relationship between two pixels is described as the pixel of interest which is the right adjacent pixel of the current pixel. this means that ∆x =  <dig>  ∆y =  <dig>  for instance, if ∆x =  <dig>  ∆y =  <dig> is the spatial relationship between two pixels of an exemplary 5 ×  <dig> image as given below:

image   <dig> 


then the corresponding co-occurrence matrix will be a 4 ×  <dig> matrix as given below:

co-occurence matrix  0/202/200/200/200/202/203/201/202/200/201/202/202/200/201/200/ <dig> 


for instance first  element of co-occurrence matrix corresponds to the frequency of neighboring two pixels in entire image with both pixels having intensity value of  <dig> with the defined spatial neighborhood relationship of ∆x =  <dig>  ∆y =  <dig>  this relationship corresponds to the number of times that  <dig> intensity pixel’s right next neighbor pixel also has intensity value of  <dig>  this relation never exists in the sample 5x <dig> image; thus, co-coccurence matrix’s  element’s value will be  <dig>  the term 1/ <dig> comes from * in eq.  <dig> . for the given 5x <dig> image example, m =  <dig>  n =  <dig>  ∆x =  <dig>  and ∆y =  <dig> 

1st method: texture feature extraction on the boundary
the goal of this approach is to extract the features mentioned in previous sections from the border of dermoscopy images by employing circular masks at different scales. in order to carry out utilizing circular masks on the border of dermoscopy images, first, the radius and the coordinates of the center of the circle must be determined. hence, for the first circle’s center, we pick a pixel at the lesion border which is the upmost pixel. this is illustrated in figs.  <dig>   <dig>  and  <dig> fig.  <dig> the detected boundary


fig.  <dig> the first circle on the boundary


fig.  <dig> zoom in the circle





the next step is the feature extraction from where the circular mask, which is illustrated in fig.  <dig>  is located. feature extraction is a computation of statistical features of a particular region. in our case, in order to obtain the region from the image, an element by element matrix multiplication is performed in between a color channel of the image and the circular mask. this is expressed in the following equation.fig.  <dig> the circular mask


  <dig>  circular_region=image_channel.∗circular_mask 


the result of this element by element matrix multiplication operation is shown in fig.  <dig>  the obtained circular_region now can be taken into account to accomplish feature extraction operations which are mean, standard deviation and homogeneity with the help of glcm matrix.fig.  <dig> the circular region mapped on an actual dermoscopy image




in essence, this feature extraction cycle is simply performed in a particular image channel for each circle along the lesion border. this process continuous for each circle along the lesion border until the cycle is completed. cycle is completed when process returns back to where it is started . this method is employed on all  <dig> images with varying radius of the circles. algorithm  <dig> summarizes this entire process below.


2nd method: texture feature extraction on the inner-shifted by vector scaling
the purpose of this method, which is also summarized in the algorithm  <dig>  is to describe how the vector scaling operation and polygon techniques are achieved in order to identify the intersecting polygon region and extract them from a dermoscopy image. first and foremost, the centroid of the segmented skin lesion is located and marked on the finalized dermoscopy image mask. for this method, a vector is defined in between the starting point on the boundary of the mask and the centroid of the segmented skin lesion. then, the unit vector is computed from this vector by utilizing eq. . moreover, the unit vector is used to perform a vector operation, namely vector scaling, and to shift boundary points towards to the centroid of the segmented skin lesion. this vector scaling and the shifting operations are shown with the eqs.  and  respectively. for the given equation,  <dig>  u→=centroidxy−boundaryxycentroidxy−boundaryxy where centroid  is the center of mass of the skin lesion, boundary  is the starting point  on the boundary of skin lesion and finally u→ is the unit vector at the boundary directed towards the center. the vector scaling is given by  <dig>  u→⋅r=u∗r=ux∗r,uy∗r where u→ is the unit vector directed towards the center and r is the radius . furthermore, in order to perform shifting operation to the boundary, simply, the result of a vector scaling operation, which is u→⋅r, is added to the original boundary coordinates, boundary. equation  basically shows how to perform shifting operation. for the given equation,  <dig>  boundaryx′,y′=boundaryx+ux⋅r,boundaryy+uy⋅r where r denotes radii, u
x and u
y refer to x and y coordinates of u unit vector. figure  <dig> illustrates how to create the vector between centroid and boundary and finding a unit vector along that direction. after applying shifting operation  to each point of the original boundary, it would create a boundary which is illustrated as dotted boundary in fig.  <dig> fig.  <dig> the vector and the unit vector in between centroid and boundary


fig.  <dig> the shifted boundary




the next step is to investigate texture features of the circular regions along the contracted new boundary. as it is seen in fig.  <dig>  there are two boundaries; actual lesion boundary and contracted boundary where in-between distance of these boundaries are always r. we find the texture homogeneities and statistics between these two boundaries in circular regions whose centers are placed on the inner boundary. those circular regions are equally distanced from each other. these circles distances are set as 3/2*r  and this is measured by using the chain code. for instance if r is  <dig> then next center will be 3 pixels apart in the chain code. after locating all circular regions’ centers on the inner boundary, we apply polygon intersection operation between these circular regions and the actual boundary for each circular region. this helps us to remove noisy data coming from pixels out of the actual boundary, which reduces the automated diagnosis accuracy. it is noted that the intersecting region must be inside of the outer boundary, the reason is that outside of the boundary is considered as noise or outliers that is not incorporated into the intersecting region. since these regions insert noises into the region of interest, it reduces the accuracy of the results. an exemplary polygon intersection operation between a circular region and the boundary is illustrated in figs.  <dig> and  <dig>  mask of the intersecting polygon is generated for further steps of the work. the mask is illustrated in fig.  <dig> fig.  <dig> the intersecting polygon regions on both borders


fig.  <dig> the red polygon is the resulting polygon after set operations


fig.  <dig> the mask of intersecting polygon region 




in the last step of this method, in order to extract the intersecting polygon region, an element by element matrix multiplication operation is performed between actual image and the intersecting polygon mask. this helps us to extract texture information of the corresponding region of interest which are the pixels located at the coordinates of the mask’s elements . the extracted region is illustrated in fig.  <dig>  this matrix operation’s equation is described as following:fig.  <dig> the extracted region of the intersecting polygon region mapped on an actual dermoscopy image


  <dig>  polygon_region=image_channel.∗polygon_mask 


then, the statistical texture measures  and the statistical texture features, particularly homogeneity features, are computed over this polygon . figures  <dig> and  <dig> illustrate the intersecting polygon feature extraction at different scales .fig.  <dig> the intersecting polygon circle with radius size   <dig>   <dig>  10


fig.  <dig> the intersecting polygon circle with radius size 15




additionally, there are some images which include certain characteristics where this method  simply fails while determining the intersecting polygon region. for instance, a sample case is shown in fig.  <dig> where the extracted region is simply outside of the boundary. this is due to the imbalance of the mask where the unit vector’s definition becomes invalid. another reason is that when the border is contracted towards the center of mass, many points are mapped to a single point . that’s the reason why we developed a 3rd method to overcome these deficiencies in the 2nd method.fig.  <dig> the failing case of the dermoscopy image





3rd method: texture feature extraction on the inner-shifted by dynamic scaling
the aim of this method is to scale down the boundary by means of a dynamic scaling approach, so that the original boundary would be shifted to the inside and with the help of circular regions, the polygon intersection is determined, and features are calculated over the intersecting polygon region.

first of all, the centroid of the segmented lesion is located and marked on the finalized dermoscopy image mask. the novelty of this method is to explore how to obtain scaling factor. the proposed approach is that the segmented lesion and the scaled region are assumed as perfect circles in a coordinate system. this assumption is shown in fig.  <dig> on the right. under this assumption, the radius is known and the distance between the starting point  and the scaled point  can be written by means of the following eq. .fig.  <dig> from irregular to perfect circle



  <dig>  sx−x2+sy−y2=r <dig> 
  <dig>  sx2+x2−2sx2+sy2+y2−2sy2=r <dig> 
  <dig>  x2s2+1−2s+y2s2+1−2s=r <dig> 
  <dig>  s−12x2+y2=r <dig> 
  <dig>  s−12=r2x2+y <dig> 
  <dig>  s−1=±r2x2+y <dig> 
  <dig>  s=1−r2x2+y <dig> 


by deriving the distance eq. , the scaling factor becomes  and the negative one  is taken into account due to the fact that the operation would be a scale down operation . next step is applying this scaling factor to each and every pixel at the lesion border.

scaling  <cit>  is a transformation where the image size gets bigger or smaller. we are interested in scaling down the original image’s lesion boundary since out of lesion boundary is considered as noise/outlier . this transformation is expressed with the eqs.  and .  <dig>  x′=sxx 
  <dig>  y′=syy where x’ is a scaled down x coordinate and y’ is a scaled down y coordinate of a corresponding boundary pixel’s x and y coordinates respectively, and s
x and s
y are scaling factors along x and y axes for 2d.

this can be also written in a matrix form with homogenous coordinates where last column represents translation  as follows.  <dig>  x′y′1=s0dx0sdy001xy <dig> 


after obtaining the scale factor, the new boundary coordinates boundary can be calculated by using eq. . this is illustrated in fig.  <dig>  since the goal is to extract the regions inside the original boundary, the new boundary has to be shifted  from new center to the old boundary’s center. for that reason, a difference vector d→=dxdy is defined in between the centroid of two boundaries which is demonstrated in fig.  <dig>  this vector is also expressed in the following equation.fig.  <dig> the original and scale down boundary


fig.  <dig> the distance vector and the inner-shifted boundary


  <dig>  d→=centroidxy−centroidx′,y′ 


in the next step, the d→ vector is utilized to locate the inner shifted boundary with the help of the eq.  <dig> . the inner shifted boundary n_boundary is displayed in fig.  <dig>   <dig>  n_boundarynxny=boundaryx′+dx,boundaryy′+dy 


moreover, the circle can be located and drawn on the inner-shifted boundary as depicted in fig.  <dig>  now, in order to figure out the intersecting polygon regions among two boundaries and the circle, the polygon set operations are applied to all of the circular regions. the outcome of polygon set operations is given in fig.  <dig> which is the intersecting polygon region.fig.  <dig> the intersecting polygon region


fig.  <dig> the result of polygon set operations




after having the intersecting polygon region, the mask of the intersecting polygon region is obtained with the help of polymask operations. the resulted mask is shown in fig.  <dig> fig.  <dig> the mask obtained by polymask operation




moreover, the region extraction operation is carried out in between the image channel and polymask. this is essentially element by element matrix multiplication that can be computed with the eq.  <dig> .  <dig>  polygon_region=image_channel.∗polygon_mask 


finally, statistical measures  and statistical texture feature, particularly, homogeneity, are calculated over these masks. intersecting polygon feature extraction is shown at different scales  by computing features in figs.  <dig> and  <dig> fig.  <dig> the extracted region by matrix multiplication mapped on the dermoscopy image


fig.  <dig> the intersecting polygon circle with  radius size  <dig>  radius size 7




all these processes are carried out on dermoscopy images in our dataset by considering  <dig> different color channels along with different scales. in brief, algorithm  <dig> simply summarizes all steps mentioned in this section.


experiments and data analysis
a set of  <dig> dermoscopy images obtained from the edra interactive atlas of dermoscopy  <cit>  is used as a test bed to perform experiments and validate the proposed approach. these dermoscopy images are 24-bit rgb color images with dimensions ranging from 577 × 397 pixels to 1921 × 1285 pixels.

initially, the structure of features is created based on the following variations: <dig> dermoscopy images

color spaces and channels:  <dig> base colors 

circle radius size:  <dig> different scale 

average and minimum:○ homogeneity,

○ mean

○ standard deviation







a sample of features is illustrated in table  <dig>  in each circle’s radius size; average homogeneity, minimum homogeneity, average mean, minimum mean, average standard deviation, and minimum standard deviation are described, and there are  <dig> different circle radius sizes under red color channel of rgb color space. moreover, each row also refers to a dermoscopy image and there are  <dig> rows for the given sample table.table  <dig> the structure of  <dig> sample features in red color channel of rgb color space




radii sizes determined through trials and errors from dermatologist drawn lesion borders. we realized that homogeneity reduces drastically right at the lesion border. thus, starting from radius size  <dig>  we increased the radius size by one and tried to find out whether that radius size capturing drastic homogeneity change or not. we continued increasing the size of radius up until the point that it no longer captures homogeneity of an abrupt change at the border. we chose  <dig> different radii sizes since they captured sudden homogeneity changes at the lesion border. for instance, results obtained for radius size  <dig> was almost same with having radius size  <dig> or  <dig>  thus, we picked only one of them, radius  <dig>  since lesion border cutoff happens close to the lesion border, for radius sizes > <dig> we observed that these cuttoffs are missed. thus, we stopped at radius size 15 pixels.

one of the major preparation steps to make the features ready is to normalize all features in the range of . as described above, there are  <dig> distinct base colors and also each circle radius has  <dig> unique texture feature types, and finally  <dig> different scales are considered for this experiment. all these make  <dig> total number of features per a single dermoscopy image. we extract all these features for  <dig> dermoscopy images. with these in mind, the challenging question is which features are more significant or in other words, which features will yield better result when the classification experiment is performed by support vector machine   <cit>  classifier. hence, in order to select significant features among all, svm recursive feature elimination   <cit>  algorithm, which iteratively works backward from the given set of features, is employed. in each cycle, it essentially sorts the features according to their weights in the svm classifier by discarding the features that have lower weight. once the svm rfe is applied to all features, it basically yields an order, based on rank  and sorts these features accordingly. the higher value r has, the more significant the feature is. the color based sorting is illustrated in the table  <dig> along with individual rank  score. after generating the ranking of these features, the most informative color-based feature is selected in which each color channel  for different color spaces is ranked with the following equation,  <dig>  tc=∑k=124rk,rofc 


where k is the feature number and r is the ranking value. the eq.  will generate a total score for each color channel by summing up r in each color set. ranking of total score is shown in the table  <dig>  what can be interpreted from table  <dig> is that the sum of the rank of all blue-based features is  <dig> which ranks top in the list. the second best color is cr, and green is the third one. thus, two sets of features, which are listed below, are considered to perform classification experiments.blue, cr, green 

blue, cr, green and fractals by kockara et al.  <cit> .





as seen from scoring results in table  <dig>  blue color channel has scored the highest for detecting malignancy in dermoscopy images. it is followed by the green channel from rgb color space. this indicates that malignant lesions are more distinctive in blue. there are some studies investigating effects of phototherapy in visible blue and green light that may enlighten why blue channel is more informative for malignancy detection.

phototherapy with visible light  has been commonly used as a treatment for certain skin diseases such as acne treatment and psoriasis  <cit> . red light penetrates deeper in tissue when compared to blue light  <cit> . it is proven in  <cit>  that combination of both blue  and red  light produces an overall decrease in the melanin level. it is also shown that helium-neon laser irradiation with visible light significantly enhances the attachment of melanocytes to type iv collagen and stimulates migration and proliferation in melanocytes  <cit> . this stimulates nerve growth factor which is a major paracrine maintenance factor responsible for melanocytes’ survival in the skin  <cit> . it is iterated in  <cit>  that the green and blue light  of the argon laser is especially absorbed by melanin which is produced by melanocytes  <cit> .

in the classification scheme of this study, svm  <cit>  is used. the aim of the classification is to correctly classify dermoscopy images as malignant or non-malignant. the following parameters of svm are varied to select the best classifier over others: svm type , kernel , c , r , d , and g .

these parameters are determined after several experiments. we used three classification assessment methods in order to find the best set of features. these assessment methods are leave-one-out, 10-fold cross validation, and model accuracy. in terms of classification accuracy assessment methods, model accuracy, leave one out , and 10-fold cross validation  are standard methods in the machine learning and information gain related studies. model accuracy gives a sense that how the problem posed in the feature space  and how we should approach to this problem. loo and 10cv methods are similar to each other and assess how a classification model reacts to a new data point or dataset. the advantages of these methods are that they represent very significant information about the classification models we build. on the other hand, in loo and 10cv assessments, we should leave out one or more than one sample from the original dataset so that they can be tested. this means that we should shrink the dataset to some extent. in the case of loo, this issue is minimized because only one sample is removed from the dataset before the training of the classification model.

for our case, loo uses  <dig> dermoscopy images for building a model and training the svm classifier. then, one of the dermoscopy images is used for testing purposes. in 10cv,  <dig> of the dermoscopy images are used for building a model and training the svm classifier whereas  <dig> of the dermoscopy images are intended to use for testing the classifier. this process is repeated  <dig> times for different randomly selected  <dig> test data. in model accuracy, we use entire set of dermoscopy images for building a model and training purposes.

RESULTS
in the assessment of classification accuracy, we used standard metrics, precision, recall, and f-measure. recall is the percentage of positive  labeled instances that were predicted as positive and found by tp/. precision is defined as the percentage of positive predictions that are correct, and calculated by tp/. tp means true positives. in our case, tp corresponds to the melanoma lesions which are correctly classified as melanoma. tn means true negatives. tn corresponds to the non-melanoma lesions which are correctly classified as non-melanoma. fp means false positives. fp corresponds to the non-melanoma lesions which are incorrectly classified as melanoma. fn means false negatives. fn corresponds to the melanoma lesions which are incorrectly classified as non-melanoma.

f-measure is a harmonic mean of precision and recall and given as:  <dig>  2*precision*recallprecision+recall 


a high score of f-measure indicate that the classifier successfully finds targeted lesion without compromising precision and recall.

the graph in fig.  <dig> is shaped by using the best three features, which are blue, cr and green-based features, each of them has  <dig> possible features and  <dig> color channels which makes a total of  <dig> features. as seen in the graph,  <dig> is the starting point for the x axis. this graph is obtained as follows. first, svm classifier starts to run with these  <dig> features, and the best achieved accuracy is obtained and marked on the graph. in the next step, the worst feature is discarded from the  <dig> features, and  <dig> features are left behind to train and test svm. the value which is obtained by this process is also marked on the graph which simply corresponds to  <dig> in the x axis. this discarding of one feature process is plotted until  <dig> feature is left behind in this routine. by doing so, the graph is formed and finalized as seen in fig.  <dig> fig.  <dig> experiments with only blue, cr, and green-based features. the top   <dig> features are: gre-5-ah, cr-10-am, gre-15-am, blu-10-mm, blu-7-mh, gre-15-ms, gre-5-mh, cr-7-am, blu-5-ms, and blu-7-as




results presented in fig.  <dig> are for the third method that we developed . the other two methods given in sections  <dig> . <dig>  and  <dig> . <dig>  as expected have not produced higher accuracies for malignancy detection. this is due to having noise  incorporated in these methods. since the model accuracy is 100 %, this emphasizes that the proposed model for 3rd method  can accurately distinguish malignant lesions from benign lesions. this means that the proposed model is an accurate approach for classification purposes.

according to the graph in fig.  <dig>  it can be inferred that  <dig> features could yield optimal result. the feature size was determined through a supervised learning, which is a feature selection method with svm rfe  <cit> . the subset with  <dig> features was selected from  <dig> candidates. this basically implies that  <dig> features are sufficient to model and train the svm classifier. in the  <dig> feature scenario on fig.  <dig>  leave-one-out  methodology achieves up to 96 % classification accuracy and 10-fold cross validation  accomplishes up to 90 % classification accuracy. it should be noted that less than  <dig> features cannot represent the proposed model well based upon the graph.fig.  <dig> the intersecting polygon circle with  radius size  <dig>  radius size  <dig>  the fixed case




in fig.  <dig>  the graph is formed by using the best three features plus fractal features. that means  <dig> total number of features are used for the experiments. the idea behind generating this graph is the same as one explained in the first case. in each training and testing cycle, the worst feature, based upon its ranking score, is eliminated from the  <dig> feature set, and training and testing is applied to the remaining feature and obtained classification accuracy is recorded and plotted on the graph. again, this cycle routine is carried out until one feature is left behind. thus, the graph is built up as illustrated in fig.  <dig> fig.  <dig> experiments with only blue, cr, and green-based homogeneity features and fractal features. top  <dig> features, where it seems all assessment models yield better cumulative: gre-5-ah, cr-10-am, blu-10-mm, blu-5-am, massrads, blu-15-ms, gre-5-mh, cr-7-am, blu-7-mh, blu-7-am, cr-15-am, blu-15-ah, gre-7-ah, blu-10-as, blu-5-mh, massradl, blu-5-ms, cr-15-ah, cr-15-mh, fast-hyb, blu-5-ah, cornerc, cr-5-am, blu-15-am, gre-15-ah




with the same analytical approach, as it is comprehended from the graph,  <dig> features stand out a promising result with 94 % correct classification accuracy for loo method and 91 % correct classification accuracy for  <dig> cv. less number of features also can be considered to represent the model.

CONCLUSIONS
accurate detection and objective evaluation of abrupt pigment pattern cutoff at the perimeter of a skin lesion is one of the important criteria for malignancy detection. however, it remains a challenging task and biased by a dermatologist’s experience level. in this article, a novel approach is proposed where abruptness of pigment pattern along the lesion perimeter is measured. the boundary of the skin lesion is determined with the help of the density based lesion border detection technique. by using two different methods, the detected boundary is step by step scaled down. then, throughout scaled down borders, pigment motifs’ homogeneities are extracted and computed in various color channels and at different scales.

the proposed method has been experimented and validated by selecting a test bed which includes  <dig> dermoscopy images . the results prove that the proposed approach is highly effective to detect malignancy in dermoscopy images. more specifically, up to 96 % classification accuracy,  <dig>  specificity value, and  <dig>  sensitivity value are accomplished in detection of malignancy in a particular color space. finally, in addition to that,  <dig>  of the f-measure is attained on malignancy detection.

