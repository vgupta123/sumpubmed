BACKGROUND
up to 12% of the humane genome is present in a variable number of copies, referred to as copy number variation   <cit> . a small subset of specific cnvs is shown to associate with a wide spectrum of diseases  <cit> .

before the development of array-based comparative genomic hybridisation, visual inspection of karyotypes under the microscope limited the detection of chromosomal aberrations to events larger than  <dig> to  <dig> mb. a major breakthrough was achieved with the generation of bac-arrays, initially consisting of about  <dig> large-insert clones spotted on a glass back plate  <cit> . with the capacity to screen a whole genome at once at a practical resolution of about  <dig>  mb, this type of array launched the cnv-analysis field in routine diagnostics. more recently, the resolution of bac-arrays was improved using over  <dig> tiling probes  <cit> . at present, bac-arrays are gradually replaced by higher resolution platforms such as oligonucleotide- and snp-arrays  <cit> . the major advantage of snp-arrays over oligonucleotide- and bac-arrays, is that they provide genotype information in addition to intensity ratios. combining both information layers gives these platforms the potential to detect cnvs at a significantly higher resolution than the first generation platforms  <cit> .

this increased resolution, in combination with the wide variety of data analysis methods, causes a shift of focus from data generation to data interpretation. to interpret these calls in a clinical context several aspects typically need to be taken into account  <cit>  and several tools are available to aid in this process  <cit> . while many tools exist for either data analysis or presentation and interpretation, few exist that efficiently combine both  <cit> . here, we present cnv-webstore, a web-based platform that couples data analysis with data storage, visualisation, several downstream analysis methods and reporting tools, to serve as a complete data to report pipeline .

the presented platform incorporates a majority vote based analysis pipeline specific for illumina beadarray data, capable to detect cnvs with a lower limit of  <dig> consecutive probes, mosaicism and uniparental disomy. though analysis of data generated on other platforms is not supported, cnv sets from any platform can be uploaded for downstream analysis. this enables the integration of multiple experimental techniques in a single interpretation pipeline.

platform implementation
interface architecture
cnv-webstore is hosted on an  <dig> core, 64bit suse linux enterprise enterprise server with  <dig> gb ram, running apache v <dig> . <dig>  php v <dig> . <dig> and mysql v <dig> . <dig>  all interface components are composed of php and javascript, with support for most major browsers. annotation data is automatically updated on a weekly basis using scheduled perl scripts. default data analysis times range from  <dig> minutes per sample for  <dig> k arrays, to  <dig> minutes for  <dig> m arrays.

data analysis packages
all analysis methods were run in their native programming language in a 64bit linux environment, and combined by a wrapper script written in perl v <dig> . <dig> with multithreading support.

quantisnp v <dig>  was installed and used confirming to the academic licence. parameters were set mainly at default values, namely  <dig> expectation-maximisation steps,  <dig> m as characteristic length for cnvs and a maximal copy number of  <dig>  additionally, correction for local gc content was applied. minimal log bayes factor was set at  <dig>  based on experimental experience  <cit> .

penncnv rev <dig> was installed and run with the generic markov model and population frequency of b-alleles, since no chip-specific files were available. no family information was used and minimal confidence was set to  <dig> based on experimental experience  <cit> .

vanillaice v <dig> . <dig> was installed under r v <dig> . <dig> and configured according to the authors suggestions for analysing illumina data. expected intensity ratios were adapted following technical guidelines from illumina and emission probability calculations were set to cope with non-polymorphic probes. samples were analysed individually, so we chose a robust in sample estimate of intensity variability as proposed by the author  <cit> . a complete overview of the used settings is available as additional file  <dig> 

bafsegmentation v <dig> . <dig> was installed under r v <dig> . <dig>  program parameters were set to  <dig>  as 'informative_treshold',  <dig>  as 'triplet_treshold',  <dig>  as 'ai_treshold' and  <dig> as 'ai_size'  <cit> .

snptrio  <cit>  calculations were implemented as described by the authors using perl.

RESULTS
data analysis approach
to make a correct functional interpretation of cnv data, it is necessary to be able to start from a reliable set of candidate regions. we therefore implemented an analysis pipeline for the illumina beadarray platform, aimed at detecting rare, small scale cnvs. since many methods have already been published and mutually compared for the analysis of snp-array data, we decided to use existing methods, instead of creating yet another  <cit> . the pipeline uses the widely used approach of majority vote based calling, as previously described for the affymetrix platform  <cit> , to generate a restrictive set of results, with a higher sensitivity and specificity . specificity is increased by discarding cnvs called by only  <dig> of the  <dig> methods, usually representing method specific artefacts. an increase in sensitivity over each single method is reached by adding regions that were called by  <dig> methods, but not by the third. cnv delineation is done with a conservative overlap, retaining only regions seen by more than one method.

previous studies comparing multiple computational methods for microarray analysis showed that hidden markov model  based methods perform best in detecting rare and small cnvs. these methods explicitly combine intensity and genotype data, take the non-uniform probe spacing into account and have an underlying assumption of general diploidy, although they have a significantly larger computational footprint than classic acgh segmentation methods  <cit> . in addition, results are sample size independent, in contrast to some recent methods that use a joint calling algorithm over multiple samples  <cit> . although joint-calling can be a very powerful tool in gwa projects for the detection of recurrently variable regions, population dependent cnv calls are unacceptable in a clinical context where all results have to be reproducible under any circumstance. we chose quantisnp and penncnv because they are the two most widely accepted and used hmm methods for illumina data analysis today, and vanillaice for its claimed high sensitivity to deletions, which are responsible for approximately 70% of pathogenic events described so far  <cit> .

besides general copy-number analysis, the data are screened for indications of mosaicism based on quality control parameters, as described below. bafsegmentation is used with default settings to detect regions of aberrant b-allele frequency, and to estimate the proportion of cells containing the allelic imbalance  <cit> .

finally, uniparental disomy detection is implemented using the method described by ting et al.  <cit> . based on informative combinations of mendelian inconsistencies, uniparental heterodisomy, isodisomy and non-paternity can be deduced from the provided genotype data.

performance estimation
to estimate performance of the proposed majority voting, its stringency and sensitivity were compared against the separate methods using a reference dataset generated by pinto et al. using an approach similar to ours  <cit> , and a dataset of  <dig> hapmap samples generated by illumina on the humancnv370-quad beadchip, from which  <dig> samples were also present in the former study. none of the separate methods performed significantly better in picking up the previously published cnv regions from the illumina data . similar results were obtained using a set of cnvs seen in a study by mccarroll et al on the affymetrix  <dig>  array  <cit>  .

results are averaged over  <dig> hapmap samples. p-values are calculated using a one-tailed z-test for difference between proportions, comparing the majority vote against each separate method.

the slight sacrifice in sensitivity towards duplications, caused by incorporation of vanillaice in the majority vote, can be countered by taking advantage of the observed high power of penncnv in detecting duplication events. to do so, an option for asymmetric voting, where penncnv duplication calls do not need to be confirmed by a second method, is available.

when applied to the full panel of  <dig> high quality hapmap samples, we retrieved a set of  <dig> aberrations. this corresponds to a mean of  <dig> aberrations per sample and to 4% of the genome present in a variable number of copies over all the samples. this high number of cnvs per sample seems out of range with previous studies. when classified by size or coverage , it is clear that most of the called cnvs are found in the category of 3- <dig> consecutive probes. thus, it appears that the increase in resolution results in an increase in the number of additional small cnvs detected. indeed, using an artificial resolution of  <dig> kb, corresponding to  <dig> consecutive probes, we detected  <dig> cnvs per sample, in range with an average of  <dig> cnvs per sample detected on a  <dig> k oligonucleotide platform with a practical resolution of  <dig> kb  <cit> .

quality control
quality control parameters are stored during analysis and user feedback is given if they exceed preset values. high quality samples are considered to have a call rate of > <dig> %, logr standard deviation <  <dig> , b-allele standard deviation <  <dig>  and absolute genomic wave <  <dig> . in case of genomic waving, an event where the intensity data shows typical fluctuation across the chromosomes, normalisation is performed during cnv analysis  <cit> . qc-values are taken from penncnv output.

chromosome specific b-allele standard deviation, calculated by quantisnp, is screened for significant outliers, as these might be an indication of mosaicism. when mosaicism is suspected, the user is informed of possible mosaicism and bafsegmentation is started  <cit> .

other platform data
to import generic cnv reports, custom parsers can be generated for any tab-separated file. once imported into the database, family relations and raw probe level data can be added. when this raw data is available, inheritance examination and parent of origin analysis can be carried out as described below.

sample annotation
default annotation of samples consists of quality control data, used platform type, gender and the total number of detected aberrations. additionally, clinical data can be added. structured clinical information, conforming to the london neurogenetics nomenclature  <cit> , aids in unambiguous comparison and grouping of samples based on their phenotype.

cnv annotation
clinical interpretation of cnvs requires a comprehensive cross-linking of available annotation data. besides experimental data such as aberration size, copy number state, inheritance data and genome build, several additional annotations are automatically added .

affected refseq genes  <cit>  are listed, with associations to phenotypes extracted from omim  <cit> . known disease related loci and published case reports are extracted from the decipher and ecaruca databases  <cit> . finally, information on flanking segmental duplications is available, as these often flank recurrent microdeletion and -duplication regions  <cit> . the toronto database of genomic variants is a major collection of known benign variants detected in control populations  <cit> . the database comprises a total of almost  <dig> studies, from which a user can select a subset used for automatic annotation. as a second source of healthy controls, all hapmap samples analysed by illumina to create the reference cluster files, passing our quality control requirements, were analysed by the described pipeline for all supported chip types and presented to the user as a chip-specific control set  <cit> .

based on supplied family information, cnvs are further annotated with inheritance information, parent of origin information for de novo events and uniparental iso- or heterodisomy prediction  <cit> .

data management and protection
all data are stored in a relational database which is backed up on a daily basis. access to specific data using cnv-webstore is regulated by user-level permissions. users are allowed to manage and share their own data with different users or user groups, with varying privileges, ranging from read-only access, over the privilege to only edit clinical or cnv annotations, to the right to further share data with more users. in order to guarantee data integrity, all changes in annotation are kept by a logging system. sample anonymity is ensured as there is no storage of personal information, such as names or birth dates. sample identification relies on arbitrary identification codes specified by the user. a typical example would be a numeric identifier linking to the dna sample that was analysed.

data representation
centralised storage of all data allows flexible presentation and searching approaches. by default cnv-webstore presents data in a compact graphical browser . cnv regions are denoted by bars using a color code representing copy number and clinical significance. results from multiple experiments can be combined in a single overview or can be visualised separately. the graphical representation allows intuitive correlation of results with previous results, gene content, known pathogenic regions and benign variants. it further provides access to inheritance information, probe level data for visual examination, quality control results, general sample information and several public resources for extensive investigation of annotation data  <cit>  . individual users can select the resources they consider relevant to be included, or add new resources available to all users.

alternatively, data for a single sample can also be presented in a tabular format. here, clinical data is bundled with experimental data, cnv annotation, occurrence statistics and reporting tools. additional annotation tools present from here are a direct pubmed querying tool to intersect the clinical data with gene content, and a cnv prioritization option based on the endeavour program  <cit> .

reporting
the reporting module of cnv-webstore provides uniform and comprehensive summaries of annotated data. users have the option to include clinical and experimental details, a schematic karyogram, iscn representation  <cit> , all or a filtered subset of detected aberrations, gene content and annotation history.

exporting
to analyse data using other tools, results can be exported as tab separated files, bed files compatible with ucsc and ensembl genome browsers, or xml files compatible with illumina genome viewer.

discussion
snp-based microarray platforms are used more and more in daily diagnostics, providing the potential to analyse a patient's genome at high resolution on both genotype and copy number level. as for many of today's technologies, the amount of produced data is vast and interpretation becomes a cumbersome task.

to overcome this, and to help sieve through the many generated cnv calls, we developed cnv-webstore, a centralised analysis and interpretation platform, able to go from raw data to reports from a single interface. it implements a majority vote analysis pipeline combining three hmm based methods, each using slightly different underlying models, with a net effect of filtering out model specific artefacts. a similar approach has been successfully applied on affymetrix  <dig> k snp array data, to obtain a stringent cnv set consisting of the most reliable calls  <cit> .

from our results, two observations were made underscoring that obtaining the correct functional correlation between genotype and phenotype is the major hurdle in routine microarray usage. first, about 30% of the smallest detectable cnvs on the used platform disrupt  <dig> or more known coding sequences, often affecting exonic sequence. second, cnvs affecting only intronic sequence might still contribute to specific phenotypes, as intronic sequences often harbour non-coding transcripts, which are currently emerging as key regulators in many diseases  <cit> . furthermore, we expect that with the rising probe density of current and future microarray platforms, and with new techniques such as next generation sequencing based cnv calling, the amount of small variants detected will keep increasing, stressing the importance of a straightforward interpretation platform such as cnv-webstore.

interpretation tools made available to the user are presented in a unified way, offering maximal information with minimal effort. cnv-webstore offers both molecular data, automatic cnv annotation and clinical information, in the context of public reference data or previous experimental results. the option to correlate clinical information with extended annotation data from a single view is a feature seen in some public platforms such as decipher, but lacking in other platforms for routine usage  <cit> . furthermore, the option to analyse data from the platform itself, without the need to use a command line interface is a major benefit of our platform over existing, similar interpretation solutions  <cit> . finally, the capability to infer parent of origin and uniparental disomy from stored genotyping data is a unique feature of cnv-webstore with clear impact on functional interpretation of imprinting related disorders  <cit> . a drawback might be that hmm based methods assume integer copy number values, limiting the possible application of the presented analysis pipeline in cancer research  <cit> . on the other hand, as incorporation of post-analysis results is supported for any type of data, including better suited segmentation based methods, the platform can create a substantial added value for interpretation of these data.

by integrating both data analysis, storage and presentation into a single platform, the problem of computational resources might impose a practical limit on usability. to address this, a system monitor is implemented in the analysis pipeline that distributes the system load to those processors that are spare in the system. cloud computing, as illustrated recently for the reciprocal smallest distance algorithm, was also considered  <cit> . as a hosting server with  <dig> cores and  <dig> gb ram per core is able to analyse samples with  <dig> m markers in less than  <dig> minutes, the actual limit lies in data storage and not in computational power, which is nowadays easily managed, without the large financial overhead of renting cloud-based storage.

CONCLUSIONS
by combining microarray data analysis with centralised storage, a comprehensive start point was created for data interpretation, the major task in current diagnostic usage of microarray data. the ability to compare results against clinical information, previously analysed samples, known variant regions and gene content allows a sensitive selection of cnvs to obtain the most relevant results for further research. extensive logging enables the tracking of changes to every sample or region, making cnv-webstore a useful tool in a collaborative setup.

in conclusion, we have developed a web based platform providing an intuitive pipeline to go with minimal effort from raw data to functional interpretation and reporting of results. because both lab technicians and clinical staff can annotate the data from their own expertise, the most relevant regions will most likely come forward. this makes cnv-webstore a valuable tool in daily clinical practice, where modern techniques often produce overwhelming amounts of data.

availability and requirements
• project name: cnv-webstore

• project home page: http://sourceforge.net/projects/cnv-webstore

• webservice address: http://medgen.ua.ac.be/cnv

• operating systems: unix-like 64bit os

• programming language: perl/php/r/mysql

• other requirements: lamp server

• license: gnu gpl, free for academic usage

authors' contributions
gv developed the software platform described and wrote the manuscript. er and lr performed validation studies and contributed to the conceptual design of the platform. ww contributed to the conceptual design of the platform. rfk supervised the project and the final manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
vanillaice code and settings. vanillaice settings were adapted to optimise performance on illumina beadchip data. this files contains the resulting r-code that can be used with version  <dig> . <dig> 

click here for file

 acknowledgements
funding: our work is supported by the belgian national fund for scientific research - flanders  and the marguerite-marie delacroix foundation.
