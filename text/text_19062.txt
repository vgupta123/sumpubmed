BACKGROUND
using microarrays techniques, researchers can measure the expression levels for tens of thousands of genes in a single experiment to provide scientists functional relationship information between the cellular and physiological processes of biological organisms and genes at a genome-wide level. the preprocessing procedure for the raw microarray data consists of back-ground correction, normalization, and summarization. after preprocessing, high level analyses, such as gene selection, classification, or clustering, are executed for profiling gene expression patterns  <cit> . in the past decade, two main tracks of analyses of microarray data have been to partition genes into closely related groups across time using clustering techniques and to classify patients with different health statuses based on selected gene signatures  <cit> . various standards related to systems biology are discussed by brazma et al.  <cit> . when sample sizes are substantially smaller than the number of features/genes, statistical modeling and inference issues are challenging, which is known as the "large p small n problem". two important questions and challenges for the high dimensional data analyses are how to choose features that provide reliable and good prediction and how to determine the final optimal feature set that is best for prediction and classification.

to address the "curse of dimensionality" problem, three strategies have been proposed: filtering, wrapper and embedded methods. filtering methods select subset features independently from the learning classifiers and do not incorporate learning  <cit> . one of the weaknesses of filtering methods is that they only consider the individual features in isolation and ignore their possible interactions. yet, the combination of these features may have a combined effect that does not necessarily follow from the individual performance of features in that group  <cit> . one of the consequences of filtering methods is that we may end up with many highly correlated features/genes; this highly redundant information will worsen classification and prediction performance. furthermore, if there is a limit on the number of features to be chosen, we may not be able to include all informative features.

to avoid weakness in filtering methods, wrapper methods wrap around a particular learning algorithm that can assess the selected feature subsets in terms of estimated classification errors to build the final classifier  <cit> . wrapper methods use a learning machine to measure the quality of subsets of features. one recent well-known wrapper method for feature/gene selection is support vector machine recursive feature elimination , proposed by guyon et al.  <cit> , which refines the optimum feature set by using support vector machine . the idea of svmrfe is that the orientation of the separating hyper-plane found by the svm can be used to select informative features: if the plane is orthogonal to a particular feature dimension, then that feature is informative, and vice versa. in addition to gene selection, svmrfe has been successfully used in other feature selection and pattern classification situations  <cit> .

wrapper methods can noticeably reduce the number of features and significantly improve classification accuracy  <cit> . however, wrapper methods have the drawback of high computational load. with better computational efficiency and similar performance to wrapper methods, embedded methods process feature selection simultaneously with a learning classifier. examples of embedded methods are lasso  <cit>  and logistic regression with the regularized laplacian prior  <cit> .

combining the sequential forward selection  and sequential floating forward selection  with ls  bound measure, zhou and mao proposed sfs-ls bound and sffs-ls bound algorithms for optimal gene selection  <cit> . tang et al. also proposed two gene selection methods, leave-one-out calculation sequential forward selection  and the gradient based leave-one-out gene selection   <cit> . diaz-uriarte and de andres  <cit>  presented a new method for gene selection that uses random forest  <cit> . the main advantage of this method is that it returns very small sets of genes that retain high predictive accuracy. the algorithms are publicized in the r package of varselrf. additionally, guyon and elisseeff elaborated a wide range of aspects in feature selection including a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods and feature validity assessment methods  <cit> .

in human genetic research, exploiting information redundancy from highly correlated genes may potentially reduce the cost of classification in terms of time and money. to deal with redundancy issues and to improve classification for microarray data, we designed a gene selection method recursive feature addition  in our previous work  <cit> , however, the optimal feature set associated with the best training was not solved. in this paper, we compare this method to svmrfe, loocsfs, glgs, sfs-lsbound, sffs-lsbound and t-test by using six benchmark microarray data sets; meanwhile, we propose an algorithm, lagging prediction peephole optimization , to choose the final optimal feature/gene set. we evaluate lppo by comparing it with random strategy under the best training condition and valselrf  <cit> .

RESULTS
under feature dimension j, the training accuracy of the ith experiment is r, and the testing accuracy of the ith experiment is s, i =  <dig>   <dig> ..., i; j =  <dig>   <dig> ..., j; where i is the number of experiments and j is the number of chosen features. the average testing accuracy of the experiments under the feature dimension j, s, j =  <dig>   <dig> ..., j, is calculated as follows:

  s=1i∑i=1is 

the average testing accuracy, ms_hr, of the ith experiment under the condition that the associated/corresponding training accuracy is the highest, which is defined as follows:

  ms_hr=meansi,mri,m= max),∀m,j∈{ <dig> ,..j} 

the average testing accuracy ms_hr is the expected value of the random strategy under the best training classification of the ith experiment.

the highest testing accuracy, hs_hr, of the ith experiment under the condition that the associated/corresponding training accuracy is the highest, which is defined as follows:

  hs_hr=max)|r= max),∀m,j∈{ <dig> ,..j} 

average testing accuracy
testing results under the best training
in each data set, the highest mean value is highlighted in bold

gene
on the other side, to see whether the new methods are superior to others, regression models were built based on average testing accuracy  and highest testing accuracy , respectively, with data set , gene selection method  and classifier  as independent variables. after adjusting data set effect and classifier effect, the main effects for the new feature selection methods  and others  are  <dig> %,  <dig> %,  <dig> %,  <dig> %,  <dig> %,  <dig> %,  <dig> %,  <dig> %,  <dig> %, and  <dig> % for the highest testing accuracy, and  <dig> %,  <dig> %,  <dig> %,  <dig> %,  <dig> %,  <dig> %,  <dig> %,  <dig> %,  <dig> %, and  <dig> % for the average testing accuracy, respectively. table  <dig> gives the p-values of testing superiority of each new method to other six methods, which are calculated based on one-tailed t-test from the output of the regression models. from the p-values, the performances of our new methods are statistically significantly better than all other methods  except for glgs. from table  <dig> msc-based methods  are significantly better than glgs based on both highest testing accuracy and average testing accuracy at a significance level of  <dig> . although the p-values for nbc-mmc and nmsc-mmc to glgs are not small enough due to the small sample size  and therefore lower power, we would expect that the differences will be detected at lower significance levels if more data sets are used. to see whether the four new gene methods perform differently, we also test each pair of the four methods and calculate the p-values based on two-tailed t-test from the output of the regression models. all the p-values are bigger than  <dig> , so the four new methods perform equally well.

comparison of lppo and random strategy
data
breast
comparison of lppo and varselrf
computational efficiency
in microarray data analysis, generally, the number of features in the final feature set is far smaller than the total variables. suppose the number of total variables is n, the number of features of the final feature set is m . in forward feature selection, with the use of some learning classifier, the computational time is f for a s×d feature matrix, here s is the number of data samples  and d is the feature dimensionality at each sample. without losing the generality, if d1<d <dig>  f <f. the computational cost of our feature selection algorithm is analyzed as follows.

let t <dig> denote the total computational time for supervised learning

  t1= n*fs,1 +n-1*fs,2 + … + n-m+1*fs,m≤n++...+*f=m*2*f 

let t <dig> denote the computational time for similarity calculation among the candidates and chosen genes, the calculation time between two single- variant vectors with s samples is c, then

  t2≤*c+2**c+...+m**c=c*12nm-∑i=1mi <dig> 

due to the fact of m << n and s << n with microarray data, the computational cost of our feature selection is obtained by

  t=t1+t2~o 

CONCLUSIONS
our study shows that our gene selection method recursive feature addition  obtained the best classification performance in the comparison. rfa utilizes supervised learning to obtain the best classification, and indentifies the subsequent gene recursively based on the similarity measures between the chosen gene set and the candidates to minimize the redundancy of the genes within the selected subset; hence it obtains more informative and differently expressed genes. based on rfa, we also propose an algorithm, lagging prediction peephole optimization , to determine the optimal feature set. using six popular benchmark data sets, we compared rfa with other gene selection methods. our studies showed that rfa outperformed other methods with the use of the four popular classifiers: nmsc, nbc, svm, and random forest. results also showed that, on average, lppo is superior to a random strategy under the best training and that it outperformed the random forest based gene selection method varselrf.

