BACKGROUND
graphs naturally model a multitude of complex objects in the real world. a chemical compound can be represented by a graph where atoms are vertices and bonds are edges. biological networks model the complex of interactions among components in cells, . social networks, the web, the water system and the power grid are all represented by graphs. a basic operation is the search of a query graph in a target graph or, more generally, in a database of graphs. searching a molecular structure in a database of molecular compounds is useful to detect molecules that preserve chemical properties associated with a well known molecular structure. this can be used in screening and drug design. searching subnetworks in biological networks helps to identify conserved complexes, pathways and motifs among species, and assist in the functional annotation of proteins and other cell components. the problem of searching for a query graph in a target graph is called subgraph isomorphism and is known to be np-complete. since the subgraph isomorphism test is expensive, screening all graphs of a large database can be unfeasible. recently, indexing techniques for databases of graphs have been developed with the purpose of reducing the number of subgraph isomorphism tests involved in the query process. in a preprocessing phase the database of graphs is analyzed and an index is built. a query is processed in two phases. in the filtering step the index is used to discard the graphs of the database which cannot contain the query, producing a small set of candidate graphs. the set of candidates is then verified  by a subgraph isomorphism algorithm and all the resulting matches are reported.

most graph indexing tools are based on the concept of feature. depending on the particular system, a feature can be either a small graph  <cit> , a tree  <cit>  or a path  <cit> . the filtering property is based on checking whether the features of the query are contained in each target graph. in the preprocessing phase the database of graphs is scanned, the features are extracted from each graph and stored in the index data structure. during the filtering phase, the features are extracted from the query and the index is probed in order to discard all graphs which do not contain some feature of the query.

existing indexing techniques are effective on databases of small graphs but they become unfeasible when applied to huge graphs  <cit> . the reason is that features that may be rare in small graphs are likely to be found in enormous graphs just by chance. this implies that filtering systems based only on the presence or number of features are not effective for large graphs. moreover the subgraph isomorphism test over a large graph is extremely expensive. unfortunately, alternative indexing systems which do not make use of features  <cit>  show similar problems on large graphs.

to make the verification phase faster, graphgrep  <cit>  stores all the feature occurrences of each graph, and discards the part of the graph which does not contain features of the query thus restricting the search to small portions of the target graph. however, this produces a large index which is more difficult to manage and can lead to a reduction in filtering performance. furthermore, the features of the query often occur in many parts of the graphs, reducing the filtering power.

in this paper, a novel approach to cope with large graphs is proposed. the present approach makes use of paths as features. in contrast to systems that use more complex features such as subgraphs or subtrees, our index includes all paths of bounded length. the position of a feature within the graph is considered. this additional information is used to both improve the filtering power and guide the verification phase allowing an effective pruning of the search tree. in contrast to graphgrep, only the starting point of a feature is stored and bit arrays are used to reduce the index size. furthermore this information is used to optimize the verification phase. notice that this approach cannot be used for graph features since graphs have no starting points. although a similar approach could be used for tree features , the resulting preprocessing time would be higher since enumerating subtrees is much more expensive than enumerating paths. despite using path features, our system is effective in capturing the topology of graphs and it is shown to perform better than existing systems in terms of query processing time, while keeping the size of the index comparable. an extensive experimental analysis on real and synthetic data shows that the proposed system is efficient and effective on both databases of small graphs and single large graphs.

preliminaries
this paper considers undirected node-labeled graphs. however, the concepts introduced in what follows can be easily extended to edge-labeled and directed graphs. an undirected labeled graph  is a 4-tuple g =  where v is the set of vertices, e ⊆ v × v is the set of edges , Σ is the alphabet of labels and l: v → Σ is a function which maps each vertex onto a label. if e =  is an edge, then v <dig> and v <dig> are called its endpoints. we set size = |e| and indicate with  the set of all possible graphs. a graph g <dig> =  is said to be a subgraph of another graph g <dig> =  iff v <dig> ⊆ v <dig> and e <dig> ⊆ e <dig> 

given two graphs g <dig> = , g <dig> =  an isomorphism between g <dig> and g <dig> is a bijection ϕ: v <dig> → v <dig> so that:

•  ∈ e <dig> ⇔ , f ) ∈ e2

• l <dig> = l2)∀ u ∈ v1

a subgraph isomorphism between g <dig> and g <dig> is an isomorphism between g <dig> and a subgraph of g <dig>  a graph g <dig> is said to be isomorphic to another graph g <dig> if there exist an isomorphism between g <dig> and g <dig>  for the sake of simplicity we say also that g <dig> is equivalent to g <dig> and write g <dig> ≈ g <dig>  notice that ≈ is an equivalence relation on . a graph g <dig> is said to be subgraph isomorphic to another graph g <dig> if there exist a subgraph isomorphism between g <dig> and g <dig>  in this case we say that g <dig> is contained in g <dig> and write g <dig> ≾ g <dig> 

in this paper, the following two problems will be discussed:

first_query_occurrence problem: given a database of n graphs d = {g <dig>  g <dig>  ..., gn} and a query graph q, executing the query q on d is equivalent to finding all graphs g of d such that q is subgraph isomorphic to g. in the following we assume, without loss in generality, that all graphs of d and the query graph, share the same alphabet Σ.

all_query_occurrences problem: given a database of n graphs d = {g <dig>  g <dig>  ..., gn} and a query graph q, executing the query q on d is equivalent to finding all subgraph isomorphisms between q and elements of d. we will make extensive use of the notion of feature. features are formally introduced by the following definition.

definition  <dig> let be the set of all possible graphs in a given alphabet of labels. a set ℱ is a set of features on iff there exists a binary relation is_a_feature ⊆ ℱ × such that the following property holds :

∀ f ∈ ℱ, q, g ∈ ;

is_a_feature ∧ q ≾ g → is_a_feature

in what follows, is_a_feature is expressed by saying that g contains f.

every set of features defines a pruning rule for the subgraph isomorphism problem:

pruning rule  <dig> if is_a_feature and ¬ is_a_feature then q cannot be subgraph isomorphic to g.

examples of set of features are:

• the set paths≤ k of all labeled paths of length ≤ k. here a labeled path is the sequence of labels.

• the set subtrees≤ k of all labeled subtrees of depth ≤ k.

• the set subgraphs≤ k of all labeled subgraphs of size ≤ k.

this paper considers the set of features paths_occ≤ k of pairs , where p is a labeled path of length ≤ k and n is a lower bound on the number of occurrences of p in the given graph. the corresponding pruning property asserts that if the query graph q contains at least n occurrences of a given labeled path p and g does not contain at least n occurrences of p, then q cannot be subgraph isomorphic to g and g can be pruned.

notice that in all above examples if a feature f is a subfeature of a given feature f' of g then f' is also a feature of g. the following definition formalizes this notion.

a downward monotonic set of features is a partially ordered set of features  such that,

∀ f, f' ∈ ℱ, g ∈ ,

f  f' ∧ is_a_feature → is_a_feature

for instance paths≤ k is a downward monotonic set of features with respect to the subsequence relation between labeled paths. paths_occ≤ k is downward monotonic with respect to the number of occurrences. however it is not downward monotonic with respect to the subsequence relation. indeed in figure  <dig>   is a feature of g <dig> but  is not a feature of g <dig> 

a downward monotonic set of features allows an additional optimization in the pruning process: the pruning rule can be restricted only to maximal features f in the query. this means that no other feature f' in the query can be strictly greater than f in the partial order of features.

related work
graph indexing systems are based on a filter-and-verification scheme which includes two main phases:  preprocessing: an index is built by scanning the database;  query processing: the index is probed to efficiently answer the query. the query processing is divided in two sub-steps: filtering and matching. the filtering step prunes all graphs of the database which cannot contain the query graph, generating a set of candidate graphs. the matching step executes a subgraph isomorphism algorithm on all candidate graphs. all graph indexing systems except ctree  <cit>  and gcoding  <cit>  use the concept of feature. table  <dig> synthesizes the characteristics of the main graph indexing tools. in the next subsections we briefly survey feature-based and non-feature-based systems respectively.

review of the main graph indexing systems.

feature-based graph indexing systems
all feature-based graph indexing systems are characterized by choosing a set of features ℱ and apply a pruning rule  <dig> to features of ℱ. to prune as many graphs as possible, the graph indexing systems consider a set of features fq ⊆ ℱ such that each feature f ∈ fq is contained in q, and prune all graphs g ∈ d which do not contain some feature in fq. the filter-and-verification scheme is performed in the following way:

• preprocessing: each graph of the database is examined off-line in order to extract all features of ℱ which are contained in the graph. an inverted index is generated, which maps each feature f ∈ ℱ into the set graph_set of all graphs containing f.

• query processing:

-filtering: the given query q is examined in order to extract a suitable set fq ⊆ ℱ of features contained in q. a set of candidate graphs c is then computed by .

-matching: each candidate graph is examined in order to verify that the given query is subgraph isomorphic to it. if the all_query_occurrences problem must be solved, then an exhaustive enumeration of all distinct subgraph matches is executed.

the differences among the various graph indexing systems lie mainly in the choice of the sets ℱ and fq. ℱ can be a set of bounded-size graphs, trees or paths. since the number of features can be very high, some graph indexing systems select a restricted feature set from the database. for example gindex  <cit>  selects frequent subgraphs of bounded size. this operation requires the performance of an expensive graph data mining step during the preprocessing phase. a possible choice for fq is fall = {f ∈ ℱ|is_a_feature}. if ℱ is an ordered feature set, fq can be chosen, without loss in pruning power, to be the set fmax of all maximal features in fall. it is also possible to choose any set fq : fmax ⊆ fq ⊆ fall. this is the choice made in sing.

some indexing systems consider also more effective pruning rules based on the number of feature occurrences  <cit>  and the distances between features  <cit> . some systems define compact representations of the index  <cit> . a description of the various indexing systems follows, with a discussion of the positive and negative aspects of the various choices.

graph features. some systems such as gindex  <cit> , gdindex  <cit>  and fgindex  <cit>  use graphs as features. they consider a set of features ℱ = , where  is the universe of graphs and  is the partition of  induced by graph isomorphism. all isomorphic graphs are considered as a single feature represented by their equivalence class. the main advantage of using graph features is that they are more suitable to capture the topological structure of graphs. consequently they tend to produce fewer candidates.

unfortunately, the number of graph features grows exponentially with the graph size, leading to a large index which degrades the performance of the preprocessing and filtering phases. to solve this problem, gindex  <cit>  and gdindex  <cit>  choose as features a set of frequent subgraphs. gindex  <cit>  considers also the concept of discriminative subgraphs to further reduce the number of features. all these approaches require the performance of an expensive data mining step in the preprocessing phase, leading to a loss of efficiency. moreover, when it comes to coping with large graphs the mining step may become impractical. fgindex uses a small index resident in main memory, and stores the remaining index in secondary storage. the authors of fgindex use a novel concept of δ-tolerance closed frequent subgraph to distinguish from main-memory-resident features and secondary-memory-resident ones. when the query cannot be performed using only the main-memory-resident index, the main-memory index is used to identify the blocks of the secondary memory index to be loaded. to avoid expensive disk accesses, a small set of maximal features which cover the whole query graph is selected.

gdindex enumerates all induced subgraphs contained in each graph of the database. it organizes all the features in a dag representing the partial order relation  among features. the size of the index is reduced by avoiding redundancy. each feature is associated with the set of graphs containing it and not containing any ancestor-feature in the dag. during the filtering phase, the set of graphs containing a feature can be deduced by the feature-dag. enumerating all subgraphs of a graph is very expensive, therefore this approach can be used only on databases of very small graphs.

tree features. tree features are easier to manage since the tree-isomorphism problem can be solved in polynomial time. treepi  <cit>  is the first attempt to use trees as features. the authors describe a linear-time algorithm for computing the canonical labeling of a tree. they experimentally show that tree features capture the topological structure well enough. therefore, using them may result in a good compromise between efficiency and effectiveness of filtering. as shown by authors, a unique center can be defined for a tree. consequently the distance  between pairs of features in a graph can be computed. treepi uses an additional pruning rule based on distances between features to improve the quality of the match. more precisely, this pruning rule is based on the observation that for a query graph to be subgraph isomorphic to a target graph, the distance between each pair of query vertices cannot be less than the distance between corresponding vertices in the target graph. tree+δ  <cit>  uses as features both trees and a restricted class of small graphs to improve the filtering performance. as for graphs, enumerating all trees of bounded size still produces a large number of features. consequently, a restricted set of features needs to be selected by an expensive data mining step.

path features. graphgrep  <cit>  and graphfind  <cit>  consider as features all paths of length up to lp . formally a k-length path of a graph g =  is an ordered sequence of vertices  ∈ vk such that  ∈ e for  <dig> ≤ i ≤ k -  <dig>  we say that a path is simple if all of its vertices are distinct. a path feature on Σ is an ordered sequence of labels  where a <dig>  a <dig>  ..., ak ∈ Σ.

given a graph g =  and a path feature f =  ∈ Σk, f is said to be contained in g, in symbols is_a_feature, if there is a simple path  ∈ vk such that l = ai for  <dig> ≤ i ≤ k. in this case  is called a path occurrence of f starting from v <dig> 

fixed an integer lp >  <dig>  the set  is a partially ordered feature set with respect to the relation  defined by:

   if n ≤ m and ai = bi ∀i =  <dig> ... n.

therefore, a pruning rule  <dig> can be used to select candidate graphs.

to improve the quality of filtering, the number of path occurrences of each path feature is stored in an inverted index. when a query q is processed, a set fq of path features is extracted from it and the number of occurrences of each path feature in the query is compared to the corresponding number of occurrences of the same path feature in each graph of the database. a graph is a candidate if the number of occurrences of each path feature in it is greater than the corresponding number in the query.

graphgrep also stores the location of each path occurrence in the graphs of the database. moreover, for each candidate graph, it prunes all parts of the graph which do not contain any path feature of the query. this choice produces an improvement of the matching phase. however the resulting index size is quite large.

the choice of using path features in graphgrep leads to a very efficient preprocessing phase. on the other hand, it limits the filtering power since paths cannot fully synthesize the topology of graphs.

non-feature based graph indexing systems
recently, two non-feature-based graph indexing systems have been proposed. they have been shown to outperform many feature-based indexing systems, probably because they are able to better capture the structure of graphs.

ctree  <cit>  organizes the graphs of the database in a r-tree-like data structure. the leaves represent single graphs while internal nodes represents sets of graphs synthesized in graph structures called closure graphs. the closure graph of a set of graphs is obtained in the following way. all graphs in the set are aligned by a fast approximate algorithm, called neighbor biased mapping. the vertices of the closure graph are labeled by the sets of labels of the corresponding aligned vertices. similarly, the edges of the closure graphs are the union of aligned edges. when a query is given, an approximate matching algorithm with no-false-negatives is executed on the closure graphs of the tree in a top-down fashion. when the closure graph of a node has a negative response, all the subtrees rooted at that node are pruned and all its leaf graphs are discarded. the remaining graphs are the candidates, and they can be verified by an exact matching algorithm.

despite the flexibility and filtering power of ctree  <cit> , its filtering efficiency is limited since the execution of the approximate matching algorithm is expensive and needs to be applied to many closure graphs.

gcoding  <cit>  uses the eigenvalue properties of the adjacency matrix for pruning graphs. in particular, it makes use of the interlacing theorem which bounds the eigenvalues of the adjacency matrices of matching graphs. in the preprocessing phase, all the graphs of the database are scanned. for each vertex v of a given graph, a vertex signature is computed. this computation involves its label, its neighbor's labels together with the higher eigenvalues of the adjacency matrix of the tree rooted on v and representing all n-length paths starting from v. the vertex signatures of a graph are then merged to form the graph signature. finally the graph signatures are organized in a b-tree-like structure for efficient search. when a query q is given, the vertex and the graph signatures of q are computed. the graph signature is used to identify in the b-tree a first set of candidate graphs. than, a second set of candidate graphs is selected from the first one by discarding all graphs whose vertex signatures do not match the vertex signatures of the query. the correspondence between graph signatures and vertex signatures is defined by applying the interlacing theorem.

thanks to its coding strategy based on eigenvalues, gcoding  <cit>  allows a compact representation of the index. however the computation of eigenvalues is expensive, leading to a slower preprocessing phase. finally, the loss of information introduced by the chosen coding produces a less effective pruning compared to ctree  <cit> .

RESULTS
approach
the proposed approach is based on a new feature-locality-based pruning rule that reduces the set of candidates resulting from the application of pruning rule  <dig>  the new pruning rule captures the structure of the graphs much better, leading to a strong reduction of candidates. locality information is also used to reduce the search space of the verification phase. our concept has been inspired by treepi  <cit> , which uses the concept of distance between features, requiring the computation of all-pair-distances. in certain cases, especially when it comes to deal with large graphs, the approach of treepi is computationally expensive. enumerating all trees produces an explosion of the number of features that must be reduced by a data mining step. this leads to increase the preprocessing time as well as keep the filtering performances limited, due to the small number of feature selected. moreover, treepi requires the computation of the pairwise distances between features. to limit the preprocessing and filtering time, a small number of features need to be selected. consequently, an high number of candidates is produced. in contrast, sing considers all paths starting from a node. it requires much less computation producing low preprocessing and filtering time. moreover, sing is able to capture the topology of the tree induced by a node, using simple paths. consequently it requires a lower number of features and avoid the expensive feature selection process. consider the graphs in figure  <dig>  it is easily verifiable that q is subgraph isomorphic to g <dig> but not to g <dig>  q contains the features  and  and they are also contained in both g <dig> and g <dig>  based on these features the graph g <dig> cannot be pruned. note that the occurrences of both features in q start from the same vertex. the same situation holds in g <dig> but not in g <dig>  more precisely in g <dig> there is no vertex from which occurrences of both features start. consequently vertex labeled a of q cannot match with any vertex of g <dig>  which can be pruned. the following statements formalize this concept. they are immediate consequences of the definition of subgraph isomorphism. let start be the set of vertices v such that an occurrence of f starts from v in g.

statement  <dig> given two graphs q =  and g = , let ϕ: vq → vg be a subgraph isomorphism between q and g. for each vertex v∈ vq the following holds:

{f ∈ ℱ|v ∈ start} ⊆ {f ∈ ℱ |ϕ  ∈ start}.

statement  <dig> given two graphs q, g. if q ≾ g then for each vertex v of q must exist at least a vertex u in g so that

{f ∈ ℱ|v ∈ start} ⊆ {f ∈ ℱ|u ∈ start}.

statement  <dig> suggest a more effective way to prune the graph database. given a candidate graph g, for each vertex v of the query graph q, there exists a vertex u of g such that each feature starting from v also starts from u. consequently, if for some vertex of q there is no such corresponding vertex u, g can be pruned. statement  <dig> gives a method to reduce the search space of the matching algorithm. that is, it introduces a more restrictive condition on the matching pairs of vertices. a detailed description of each phase of the proposed graph indexing system is given in section methods.

experimental analysis
this section compares the proposed system to the most popular tools. three different dataset classes are used. tests on real data coming from a database of small molecules  and a database of biological networks labeled with gene expressions are performed. we evaluate sing on large graphs by generating a synthetic scale-free network of  <dig> nodes and executing several queries of sizes ranging from  <dig> to  <dig> 

the proposed system was implemented in c++ and compiled with the gnu compiler gcc  <dig> . experimental analysis was performed on an intel xeon with  <dig> gb of memory using linux os. the executable used to perform all the experiments here reported is available as additional file  <dig>  the other tools used for the comparison are: ctree  <cit> , gcoding  <cit> , gindex  <cit>  and tree+delta  <cit> .

molecular data
experiments on molecular data were performed over the dtp aids antiviral screen dataset published by the national cancer institute  <cit> . the complete dataset contains about  <dig> chemical compounds. the experiment took three subsets containing respectively  <dig>   <dig> and  <dig> graphs. each compound corresponds naturally to a graph whose nodes are the atoms labeled with their atomic symbol. each simple or multiple chemical bond between two atoms is represented by a single edge.

for each database, a set of queries is generated in the following way. randomly choose a graph g of the database and one of its vertices v. starting from v, proceed randomly in a breadth-first fashion until a fixed total number t of edges is reached. this yields groups of  <dig> queries, each having a number of edges equal to  <dig>   <dig>   <dig> and  <dig> respectively.

tables  <dig> and  <dig> show the comparison results of sing against ctree  <cit>  and gcoding  <cit>  with respect to preprocessing time and index size, respectively. sing builds the index more rapidly than gcoding. since ctree  <cit>  does not extract the features from the graphs, its preprocessing time is much lower than the other tools. figure  <dig> reports the average number of candidates passing the filtering phase on each query group of a given size. figures  <dig> and  <dig> compares sing in terms of average query processing time against ctree  <cit>  and gcoding  <cit> , respectively. as above, tests are performed on query groups of a given size. ctree  <cit>  and gcoding consider first_query_occurrence and all_query_occurrences, respectively.

preprocessing time on aids molecular compounds. the times are expressed in seconds.

index size on aids molecular compounds. the sizes are expressed in kb.

consequently, figure  <dig> reports comparisons on the first_query_occurrence problem whereas figure  <dig> refers to the all_query_occurrences problem. sing outperforms all the other tools in all tests except 4-size queries. at size  <dig>  ctree  <cit>  outperforms the other tools, but its filtering and matching steps scale less well as size increases. more in detail, ctree  <cit>  uses an expensive filtering process based on an approximated algorithm for subgraph isomorphism. as a matching algorithm it uses a variant of the ullmann algorithm  <cit>  integrated in the framework, which has been shown to be outperformed by vf <dig>  <cit> . the advantage of ctree  <cit>  in the preprocessing phase suggests its employment in applications having a small number query executions per graph. in high query environments, using sing may be more appropriate. table  <dig> shows the best-performing tool depending on the number of queries and the query size. the table takes the total of preprocessing and query time into account.

the best-performing system depending on the number of queries of a given size. experiments on the aids database  <dig>  molecular compounds. comparison between sing, ctree and gcoding.

since the gindex  <cit>  data mining step is expensive, especially over large graphs, this system was not able to run on these databases. for example, in the experiments reported in  <cit>  all h atoms, together with their bonds, were deleted. in order to compare sing against gindex, we generated a dataset of small molecular compounds as follows. from the whole aids compounds database,  <dig> graphs having more than  <dig> nodes or edges were first discarded. then,  <dig> graphs were selected at random from the resulting dataset. gindex  <cit>  was executed for  <dig> different configurations. the the maximum feature size was set to  <dig> and  <dig>  gindex  <cit>  uses a support threshold which grows with the feature size. the maximum support threshold was set to  <dig>  and  <dig>  figure  <dig> reports the results. here lp denotes the maximum feature size and s denotes the maximum support threshold. since gindex  <cit>  does not perform the matching task, the total query time is not reported.

with lp =  <dig>  the building time, the index size and the filtering time are much lower than sing because of the small number of features considered by gindex  <cit> . for the same reason, the filtering performances are worse than that with lp =  <dig>  and, with the exception of query size  <dig> with s =  <dig> , the number of candidates is always higher than sing.

with lp =  <dig> and s =  <dig> , the index size is comparable , but gindex  <cit>  require  <dig> times more to build it . the filtering time of gindex  <cit>  tends to be constant with respect to the query size. compared to gindex  <cit> , sing takes more filtering time on low-size queries. on the other hand sing takes less time when the query size increases. the filtering power of sing and gindex  <cit>  are comparable over small queries. gindex  <cit>  produces a smaller number of candidates on larger queries at the expense of a longer preprocessing and filtering time. with lp =  <dig> and s =  <dig> , gindex  <cit>  shows a little improvement in pruning power, but the preprocessing performances drop and the filtering time is higher, mainly due to the high number of features considered. we also performed a comparison with tree+delta  <cit> , a recently proposed system which uses as features trees and a small set of selected graphs. tree+delta  <cit>  performs better than treepi, consequently, we do not compare sing with treepi.

similarly to what we observed for gindex  <cit> , tree+delta  <cit>  could not run on the whole aids dataset. therefore, in order to perform the comparison with sing, we randomly generated a small dataset of  <dig> molecular compounds from aids database. the size of the graphs in this dataset ranges from  <dig> nodes and  <dig> edges to  <dig> nodes and  <dig> edges. the evaluation was performed by using  <dig> queries of size   <dig> and  <dig> queries of size  <dig>  the parameters of tree+delta  <cit>  was set according to . more precisely we set the maximum feature size maxl to  <dig>  the size of the index generated by tree+delta  <cit>  is  <dig> kb  and the pre-processing time is  <dig> seconds . as reported in figure 6a and figure 6b the number of candidates of tree+delta  <cit>  is lower than that produced by sing, . furthermore, sing always outperforms tree+delta  <cit>  on query processing time. the filtering time of tree+delta  <cit>  is about one fold lower than sing for query size  <dig> and about one fold higher than sing for query size  <dig>  in contrast the filtering time of sing is almost constant, which confirms the good scalability of sing compared with tree+delta  <cit> . concerning queries of size greater than  <dig>  comparison are not reported since tree+delta  <cit>  requires too much time on the average.

transcription networks
to evaluate the performance of sing on large networks, we generated a database of gene networks labeled with discretized gene expressions, based on a transcription regulation network of escherichia coli annotated with gene expressions. we extracted the largest connected component from the complete network, available with the supplementary material of  <cit> . gene expression profiles of  <dig> samples of the experiment gds <dig> , concerning the analysis of e. coli k <dig> strains adapted to grow in benzalkonium chloride  were used. we discretized each gene expression value by mapping it into a set of  <dig> levels: very low, low, medium, high, very high. those levels became the node labels of the regulatory networks.

following alon  <cit> , we attempted to identify groups of nodes connected with a given topology and annotated with a certain gene expression level profile. one can use this approach to understand a gene regulation mechanism, by verifying if a given pattern is present in a set of samples, where it occurs and which genes are involved.

we queried the networks database with a set of motifs labeled with gene expression levels using motifs found by u. alon et. al.  <cit> . each vertex was labeled with the gene expression level "very high". preprocessing time and index size are reported in table  <dig>  figure  <dig> reports the total processing time of each query, named as in  <cit> . sing outperforms the other methods in query processing time.

preprocessing time and index size over biological networks

synthetic data
to evaluate the performance of sing over a single large graph, we generated a scale free network of  <dig> nodes having about  <dig> edges. the network was generated adding the edges one by one in the following way. each new edge is connected to an existing node of the network with probability proportional to the degree of that node. this procedure guarantee that the produced network has a power law degree distribution. the labels were assigned distributing  <dig> different labels at random  over the network nodes. we used as queries three different sets of  <dig> queries with size  respectively  <dig>   <dig> and  <dig>  the queries were generated at random using the same procedure discussed above . we then evaluated the query time of sing against vf <dig>  <cit> . we did not consider the other tools because the filtering phase is useless for a single graph which contains the query, and the verification phase is usually performed by vf <dig> . sing generated a  <dig>  mb index in  <dig> seconds. the query time is reported in figure  <dig>  for small queries , sing and vf <dig> show similar performances whereas for query size  <dig>  sing outperforms vf <dig> 

protein-protein interaction networks
protein-protein interaction networks  are in general very complex to manage by most of graph minining tools  <cit> . indeed, ppi networks are scale free and the degree of their nodes follows the power law. these networks are characterized by the presence of nodes, called hubs, carrying hundreds of connections . in these graphs most of the nodes are connected through a few hubs. the matching phase for this kind of networks is very heavy for most of the available tools.

to illustrate the performance of sing over these networks we consider the whole human ppi network containing  <dig> nodes and  <dig> edges. as a set of queries we used  <dig> protein complexes of yeast. protein nodes were retrieved from sgd, whereas edges were inferred from ppi data by biogrid  <cit> . we executed all-pair-blast on the set of proteins of yeast and human, and then clustered them by single-linkage clustering. to avoid grouping dissimilar proteins in the same cluster, we applied a score cutoff of  <dig> bits. moreover we set  <dig> as the maximum cluster size. the human network and the yeast complexes were then labeled by the id of the clusters, obtaining  <dig> labels. the distribution of labels in this network, is described in figure 9a. notice that, approximately  <dig> labels show a frequency of about  <dig> % . removing the complexes with a number of edges less than  <dig> produces a set of  <dig> yeast complexes, whose size ranges from  <dig> to  <dig> edges .

feature based tools such as gindex  <cit> , tree+delta  <cit> , do not perform on large graphs since they were not designed for such purpose. therefore, we compared sing only with vf <dig>  <cit> .

the human network was preprocessed by sing in  <dig> seconds producing an index of  <dig> kb. we then queried the human network with the yeast complexes. we found that only  <dig> yeast complexes have at least one match in human. table  <dig> reports the total query processing time performed by sing and vf <dig> when execute in this small set of  <dig> queries and in the set of remaining queries . as expected, sing outperforms vf <dig> when applied on queries which are not contained in the target network. when applied on queries with at least one match, sing and vf <dig> perform nearly equal query time.

preprocessing time and index size over biological networks

to compare the algorithms on a more difficult environment, we considered the whole yeast network . this network contains  <dig> nodes and  <dig> edges. figure 9b describes the degree distribution for this network.  <dig> different labels were assigned to the nodes at random with uniform distribution.

 <dig> queries of size  <dig> and  <dig> and  <dig> queries of size  <dig> were randomly extracted from the network. since a query can have a huge number of matches, we report the running time after at most  <dig> matches were reached.

CONCLUSIONS
we have introduced a new algorithm for graph search called sing and compared it with its most popular competitors. sing performs filtering to discard graphs and additional semantic filtering during the detailed graph search. our experiments suggested that ctree  <cit>  should be used when few  queries need to be performed on the graphs. on databases of small graphs , gindex  <cit>  may give better filtering at the expense of longer construction cost compared with sing. sing is best when a high number of queries will be performed on databases of large graphs. figure  <dig> provides a decision tree which suggests the system to be used over different scenarios.

