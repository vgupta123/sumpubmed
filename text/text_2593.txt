BACKGROUND
transcription factors need to locate their target sites on the dna within a time frame that is shorter than can be achieved by random diffusion. the search process is further complicated by the fact that target sites are usually similar to a significant number of other sites , and by the fact that there are other molecules searching for their target sites simultaneously. to understand transcriptional regulation better, it is therefore essential to have a complete understanding of the mechanistic way in which this search process takes place.

in the last  <dig> years, both theoretical and experimental research were able to identify that the search mechanism is a combination of a three-dimensional diffusion and a one-dimensional random walk, which is often referred to as the facilitated diffusion mechanism  <cit> . despite considerable progress and mainly due to the technical limitations  <cit> , there is still a significant gap in our understanding of how tfs locate their target sites  <cit> . one issue is the way in which the tf performs the one-dimensional random walk, in the sense that there is still no consensus whether the tf molecules predominantly slide   <cit>  or hop   <cit> . another example is the disagreement between the values for the proportion of time that tf molecules spend on the dna: analytical computations of an optimal search process  <cit>  differ from values measured experimentally  <cit> .

one way to address these questions are stochastic simulations of the facilitated diffusion mechanism  <cit> . in  <cit>  we proposed a computational model, grip, that allows genome-wide simulation of the facilitated diffusion mechanism. in particular, the cpu time required to simulate  <dig> s of an e.coli k- <dig> cell and lac repressor  tfs in grip resides between  <dig> h and  <dig> h on a 2× <dig>  ghz quad-core intel xeon macpro computer, see  <cit> .

despite the significant speed-up compared to previous tools, it is still not feasible to use the full genomic sequence as a search space. to address a scientific question with grip, multiple simulations need to be performed to allow a meaningful statistical analysis of the results. thus, even small improvements in simulation speed can add up to some significant time saving. the optimization of the algorithm or of the implementation can potentially increase the speed of the simulations, but this is limited by the level of detail in the simulated model. in addition, even in the case of significant algorithm optimisations, simulating eukaryotic systems that have more than  <dig> mbp and  <dig> tfs becomes impractical.

one strategy to increase simulation speed consists of system size reduction, following the logic that the properties of the search process are the same irrespective of simulating only a subset or the full genomic sequence. however, this requires a few simulation parameters to be adapted to the size of the subsystem . this change in system parameters is required in order to avoid biases in the results, e.g. tfs could locate the target sites faster or target sites might be occupied for longer time intervals if there is an inappropriate number of tfs. the main advantage of this approach is that smaller systems will display faster speeds due to smaller dna regions and, consequently, due to lower number of molecules bound to the dna which perform the one-dimensional random walk.

our results indicate that if the diffusion parameters are conserved and if the proportion of covered dna is similar for the original system and the subsystem, then the subsystem captures the dynamic and steady state behaviour of the original system with negligible error.

in this contribution, we present two adaptation methods  that managed to keep the simulation results for the full system and the subsystem constant. we systematically investigate the degree to which the simulation results are affected when reducing the size of the system. the first method  is simpler to implement, but is limited with respect to how much the system can be reduced and in terms of accuracy. this is caused by the fact that tf copy numbers are integers and values lower than  <dig> cannot be considered while intermediary values need to be rounded to the closest integer value.

the second approach, the , is slightly more difficult to implement , but surpasses all the limitations of the previous method .

overall, we show that copy number method performs well in the case of high abundance tfs, while for low abundance tfs, one needs to rely on the association rate method.

RESULTS
in this study we consider the lac repressor  tf, since this is one of the best described tfs with respect to the facilitated diffusion mechanism. details regarding the laci parameters used in this paper are presented in the methods section. for the purpose of this study, we did not aim to provide a complete and exact description of the lac repressor system, but rather to describe under which conditions one can reduce the size of the system.

we consider six subsystems which are smaller than the full system , namely:   <dig>  mbp,   <dig>  mbp,   <dig> kbp,   <dig> kbp,   <dig> kbp and   <dig> kbp. all subsystems contain the o <dig> site , see figure  <dig>  note that, when reducing the system size, we keep the o <dig> site in the new dna subsequence and, to avoid artefacts resulting from the boundary conditions, we keep the o <dig> site far from the dna margins, see figure  <dig> 

next we present two models that are intended to keep the subsystems equivalent to the full system with respect to the facilitated diffusion mechanism.

model i: tf copy number reduction
if the full system contains a dna molecule of size m, base pairs and tf number of molecules, which are each bound f  percent of the time to the dna, then the expected number of molecules bound per base pair is 

  tf·fm=tfboundm 

where tfbound represents the number of bound molecules.

a subsystem with a dna molecule of size λm , is equivalent to the full system if the one-dimensional random walk behaviour in the two systems are the same and if the local crowding  remains the same in both the full system and the subsystem. we assume that the one-dimensional diffusion parameters are the same in all systems  and then we need to impose that the local crowding is also the same. one measure for crowding is the number of bound molecules per base pair and this leads to the following condition on crowding 

  tfboundm=tfλboundλm⇒tfλbound=λtfbound 

where tfλbound is the number of bound molecules in the subsystem λ.

one way to alter the number of bound molecules is to keep all the parameters the same and only reduce the total number of molecules in the cell proportionally to λ. this model  assumes that the tf copy number in the subsystem scales as: 

  tfλ=λtf 

model ii: association rate reduction
alternatively, the number of bound molecules can be modified without changing the total tf abundance, but only by changing the association rate of the molecules  accordingly. in  <cit> , we derive the association rate for the full system as 

  kassoc=1trtfboundtffree·aimaxaitotal 

where tr is the residence time of a molecule on the dna, tffree the number of free molecules and aimax/aitotal the ratio of free dna. note that, in the additional file1: supplementary material, the accuracy of this estimate is systematically investigated in the case of dna crowding. the results confirm that for a dna occupancy up to 50%  the equation displays negligible errors.

the ratio of bound tf is given by: 

  tfboundtffree=f·tf·tf=f1−f 

in the case of the subsystems, the association rate becomes 

  kλassoc=1trtfλboundtfλfree·aimaxaitotal 

in the association rate model, the total number of molecules in the system remains constant  and, thus, we have 

  tfλbound+tfλfree=tfbound+tffree 

from equation : 

  tfλbound+tfλfree=tfbound+tfbound1−ff 

from equation : 

  tfλbound+tfλfree=1λtfλbound1f⇒tfλboundtfλfree=fλ1−fλ 

the association rate of the subsystem  scales by a term γ compared to the full system . 

  kλassoc=γkassoc 

from equations  and : 

  γ=λ−fλ1−fλ 

comparison of the two models
next we will compare the two models  and investigate under which conditions one model is better than the other. the comparison includes four performance parameters, namely:  the occupancy bias,  the time to first reach the target site,  the probability that the target site is occupied and  the simulation speed. note that when none of the two methods are applied, the values of the first three properties in the subsystems will deviate significantly from the values of the full system; see top panels of figures  <dig>   <dig>   <dig> and  <dig> 

we consider three cases with respect to tf abundance, namely:   <dig> molecules ,   <dig>  and   <dig> . the corresponding values of the six subsystems for the abundances  and for the association rates  are listed in table  <dig> 

the full system consists of   <dig>    <dig> and   <dig> laci molecules. when computing kλassoc, we assumed that, for the full system, the time spent on the dna is: i) 〈f10〉≈ <dig> ,  〈f100〉≈ <dig>  and  〈f1000〉≈ <dig> .

note that the association rate for the full system  leads to a slightly different occupancy on the dna than initially computed . this is due to the fact that the value of  <dig> s−1was computed under the assumption that the system consists of both cognate and non-cognate molecules which cover 25% of the dna. since in this case we consider a significantly lower occupancy, then the proportion of time the tfs spend on the dna increases. this is important due to the fact that the association rate model requires that the correct value for the proportion of time spent on the dna  is provided.

the proportion of time spent on the dna can be computed using the approach described in  <cit> , but the accuracy can slightly suffer in the case of crowding on the dna; see additional file1: figure s <dig>  to ensure a parameter estimation characterised by a high accuracy, we used a set of  <dig> simulations and measured the observed proportion of time spent on the dna ; see additional file1: figure s <dig> 

in addition, table  <dig> shows that for low abundance proteins, it is not possible to apply model i  to reduce the size of the system beyond certain limits. for example, in the case of a low abundance protein with only  <dig> molecules per cell, the genome cannot be reduced further than  <dig> times .

occupancy bias
the correlation between the occupancy bias of the full system and all the subsystems indicates that the peaks in the occupancy bias data are captured by all subsystems for both models . however, to capture the complete perspective on the occupancy bias we need to investigate if the size of these peaks is conserved, i.e., we are interested whether the same ratio between occupancy and affinity is found in the subsystems as compared to the full system. to do this, we use the ratio between normalized affinity and normalized occupancy for all sites that have a certain minimum affinity. this minimum affinity threshold removes low affinity sites from the data, where the noise in occupancy bias is high .

for the sites with the affinity above a certain value we compute the ratio between the normalized affinity and the normalized occupancy. in the low and medium abundance tfs we expect the ratio to be around one, but in the case of high abundance tfs, due to the high crowding, the ratio should be significantly lower than  <dig>   <cit> .

time to reach the target site
next, we are interested in how the system size reduction influences the search process. figure  <dig> shows that, for both models, reducing the size of the system does not significantly change the time required to locate the target site for all types of tf abundances. again, the association rate model seems to slightly outperform the copy number model, due to higher accuracy of how the scaling factor is incorporated into the model, i.e., in model i the copy number can take only integers, resulting in lower accuracy for low abundance tfs, while for model ii due to the fact the association rate can take real positive numbers the accuracy is only limited by the accuracy of the floating point number representation in computers.

the probability that the target site is occupied
usually, the activity of tf regulated genes is controlled by the presence or absence of tf molecules at certain target sites. using our model, we measured the proportion of time the target site was occupied. for long time intervals, this proportion of time approximates the probability that a target site is occupied by a tf.

simulation speed
the main reason we reduced the size of the system was to increase simulation speed. figure  <dig> shows that one can obtain a significant decrease in the cpu time required to simulate  <dig> s by decreasing the size of the system being simulated. both models performed similarly. this speed-up is not only a consequence of having a fewer number of molecules performing the one-dimensional random walk, but also of a significant increase in the number of events processed per second. for example the machine used simulates  <dig> s of the full system in approximately  <dig> s, but a  <dig> times smaller system  in less than  <dig> s.

both models produce accurate results compared to the full system and lead to significant enhancement of the simulation speed. in particular, the errors in the approximate subsystems compared to the full system are negligible and are overshadowed by the speed enhancement produced by these methods.

CONCLUSIONS
when simulating the facilitated diffusion mechanism, one usually needs multiple long runs for the same set of parameters. this can take a significant amount of cpu time and can lead to undesirable simulation time . one solution is to enhance the current algorithms, but this might lead to coarser grained models unable to capture enough details of the mechanism of facilitated diffusion. alternatively, one could simulate a subsystem of the full system. figure  <dig> shows that by decreasing the system size  <dig> times the cpu time required to simulate  <dig> s in the cell can be decreased  <dig> fold.

to keep the full system and the subsystems equivalent, we developed two models:  the copy number model  and  the association rate model . model i is easier to construct, but has two main drawbacks. first, there is a limit on how much one can reduce the system due to the fact that tf copy number has to be at least  <dig>  this is mainly an issue for low abundance proteins . secondly, due to the fact that tf copy numbers are integers the accuracy of the method might suffer. for example, when we reduce the size of the system from  <dig>  mbpto  <dig> kbp for a tf with  <dig> molecules the ratio between the affinity and the occupancy of the subsystem deviates significantly from that of the full system. nevertheless, this approach is easy to apply and displays negligible errors for high abundance proteins.

the association rate model surpasses both drawbacks of the copy number model by managing to reduce the system independently of tf copy number and reproduces the results of the full system with high accuracy. however, this model assumes measuring the actual time the tf molecules spend on dna in the full system a priori, which might be time consuming.

in the context of grip software  <cit>  this indicates that, when we reduce the system size of high abundance tfs , one could use the copy number model, while, for low abundance proteins, the association rate model needs to be applied.

in conclusion, this paper offers a comprehensive description and analysis of the methods that need to be applied when performing non-genome-wide stochastic simulations of the facilitated diffusion mechanism. more specifically, we show that one does not have to perform genome-wide studies of the tf search process for their target sites as long as the parameters of subsystem  are correctly adjusted.

