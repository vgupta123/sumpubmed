BACKGROUND
rna interference  describes the property of short  rna molecules, or short interfering rna , to associate with naturally occurring cellular machinery, the rna-induced silencing complex  and reduce the quantity of a second rna molecule, or the target gene rna  <cit> . in the relationship between the sirna and the target rna, the sirna must be able to watson-crick base pair with some segment of the target rna using standard base pairing rules. the risc then catalytically cleaves the target rna.

in addition to the risc mediated silencing mechanism, the sirna can reduce target gene levels utilizing two other methods. first, sirna can inhibit transcription of the target gene's dna  <cit> . second, it can utilize a mechanism similar to an endogenous and highly conserved class of small rnas known as micrornas . micrornas mediate the reduction of target gene protein level by repressing target rna translation through imperfect base pairing to the target gene transcript  <cit> . all of these various methods and mechanisms result in target gene knockdown  <cit> . in addition to the epigenetic gene knockdown, sirna sequences can cause sequence expulsion from the genome  <cit>  and small dsrnas are implicated in the induction of transcription  <cit> .

sirna molecules are not all equally effective in their ability to knockdown target genes  <cit> . some combination of the properties of the sirna, the target rna sequence and their interacting components are thought to account for the differential effectiveness. furthermore, it is not known whether specific characteristics of an sirna molecule contribute differently to the  <dig> gene knockdown mechanisms of risc mediated, transcription inhibition and translation repression, since presumably each mechanism interacts with distinct subsets of cellular components and possibly different optimality criteria  <cit> . in addition to the mechanism of knockdown, there is also possible variation among transcripts  <cit> , organisms, cell type, developmental time course, transfection methods  <cit>  and environmental treatment in gene knockdown, and many of these properties are not accounted for in sirna effectiveness. although several rules describing properties of functional sirna sequences have been proposed and proven to work with variable effectiveness, the fundamental questions of what properties comprise an effective sirna for gene knockdown, by any mechanism, are unsettled. more realistic models will be needed for further dissecting sirna mechanism or mechanisms  <cit> . once appropriate experiments are derived for taking each of the complex series of variables into account, researchers will need to identify the critical components to model rna interference activities and then use those models to develop reagents with the desired properties.

several methods for identifying the properties of effective versus ineffective sirna molecules from empirical data have included the following:

a. classification by statistical grouping  <cit> 

b. classification and regression by neural networks  <cit> 

c. classification by boosted genetic programming  <cit> 

d. classification by decision trees  <cit> 

e. classification and regression by support vector machines   <cit> .

many of the classification approaches have taken empirically derived continuously distributed data, and used it to map "effective" versus "ineffective" sirna sequences and their associated properties by cutoffs and binning. a comparison of various algorithms in predicting sirna efficacy by classification  <cit>  suggests a large variance in performance. furthermore, several features have been shown to associate with predictive models of activity including the following:

a. position specific base composition  <cit> 

b. guide strand thermodynamics  <cit> 

c. guide strand secondary structure  <cit> 

d. structure features that discriminate micrornas  <cit> 

e. n-grams  <cit> 

f. target strand secondary structure  <cit> 

g. the energetics of multiple guide strand binding sites within the target  <cit> .

support vector algorithms or support vector machines  are a group of machine learning methods that build a maximum margin hyperplane through n-dimensional space to separate the m elements in a discrete classification problem  <cit> . the n-dimensional space is comprised of some set of factors that describe the m elements being classified. in addition to discrete classification, svms can also be used to build regression models in n-dimensional space. generally this can be done by describing the regression as a set of 2m classification support vectors that separate the m-elements in the dataset. in fact, the single hyperplane svm classification problem is a special case solution of the more general multi-hyperplane svm regression problem  <cit> . finally, svm methods can extend beyond linear models to describe the maximum margin hyperplane of the support vector solution space by non-linearly mapping the initial vector into higher dimensional feature space  <cit> .

svm regression kernel methods produce varied results depending on the application, and kernel performance needs to be determined empirically  <cit> . also, feature-mapping methods have an effect on svm performance  <cit> . given the observation that svm kernel methods are effective at defining maximum margin hyperplanes and the knowledge that results can depend on feature mapping to vector space, this study investigates several feature mapping methods and examines their utility in creating predictive regression models for sirna activity.

given that several types of sequence based features can be used to build predictive models of rnai, one of the main intentions of this study is to first ask what features individually correlate with rnai efficacy to help identify additional sirna properties that may have structural or functional importance previously not seen. a second intention is to ask if there is a consensus as to the feature mapping methods that can be used either alone or together and do they contribute to developing models generally predictive of activity on data not seen during model training. furthermore, do feature selection methods, such as feature filtering, on large feature sets actually improves predictive models or if feature subsets are found in common. two datasets are used in the present study. the first is a set of  <dig> sirna sequences of  <dig> nucleotides in length from  <cit> , specifically from the corrigendum  <cit> , referred to as dataset <dig>  the second is a compiled set of  <dig> sirna sequences of  <dig> nucleotides in length from  <cit>  referred to as dataset <dig> 

methods
rna interference and target sequence data
dataset <dig> was from  <cit> , the 21-mer sequence and activity data used was from the corrigendum  <cit> . dataset <dig> was from the compiled  <dig> 19-mer sequences and activities dataset used by  <cit> , with the exception of five sequences that did not precisely correspond to their target gene dna sequence. of these five sequences, two were discarded due to ambiguity of matching to their target and three were changed at one or two positions to correctly correspond to the target mrna sequence. the target mrna sequences were either from  <cit>  or downloaded from the ncbi  <cit> .

data mapping methods for svm
the following eight general approaches, in roman numerals, were used to map a sequence to a vector space, to result in  <dig> methods, labeled in arabic numerals:

i. position specific base composition 

ii. thermodynamics 

iii. entropy 

iv. guide strand structure 

v. guide strand structure features 

vi. n-grams 

a. n-grams n =  <dig> 

b. n-grams n =  <dig> 

c. n-grams n =  <dig> 

d. n-grams n =  <dig> 

e. n-grams n =  <dig> 

f. n-grams n =  <dig> through  <dig> 

vii. target strand structure 

a. target strand structure – nondirectional 

b. target strand structure – directional 

viii. target imprecise thermodynamics 

method 1: position specific base composition
each position in the sirna sequence was mapped to four dimensions in vector space, where each dimension corresponded to one of the bases in the dna alphabet. the relationship between the length of the sequence  and the number of dimensions of vector space  was then m = s xl, where s is the size of the alphabet, in this case  <dig> for nucleic acids. for example, using the coding system between dna base and vector results in the following mapping:

a = <  <dig> , <dig>  >

c = <  <dig> , <dig>  >

g = <  <dig> , <dig>  >

u/t = <  <dig> , <dig>  >

method 2: thermodynamics
the thermodynamics mapping method has  <dig> dimensions, with  <dig> of the dimensions corresponding to the gibbs free energy stabilities of the nucleotide pairs of the 21-nucleotide rna molecule. an additional two dimensions were for the stability energetics of the terminal 5' and 3' ends, encompassing  <dig> nucleotide sites. the final dimension is the gibbs free energy stability of the entire sequence. the nearest neighbor model predicted gibbs free energies with the rna parameters of xia  <cit> .

method 3: shannon entropy
the shannon entropy mapping method is similar in dimensionality and implementation to the thermodynamics method, but the  <dig> dimensions of the  <dig> nucleotide pairs, the 5' and 3' terminal ends and the final dimension of the entire  <dig> nucleotide sequence were populated with shannon's measure of bitwise information content  <cit>  by formula .

 h=−∑i=1lplog⁡2)
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgibascqggoaakcqwgybawcqggpaqkcqgh9aqpcqghsisldaaewbqaaiabdchawjabcicaoiabdiha4naabaaaleaacqwgpbqaaeqaaogaeiykakiagiibawmaei4ba8maei4zac2aasbaasqaaiabikdayaqabagccqggoaakcqwgwbaccqggoaakcqwg4baedawgaawcbagaemyaakgabeaakiabcmcapiabcmcapawcbagaemyaakmaeyypa0jaegymaedabagaemibawganiabgghildaaaa@4cd9@ 

where l is the length of the sequence, p is the frequency of the character at position i.

method 4: guide strand secondary structure
nucleic acid secondary structure describes the ability of a single molecule of nucleic acid sequence to form one or more intramolecular bonds, thereby stabilizing some sequence segments as double stranded. sirna sequence secondary structures were predicted with the rnafold as implemented in the vienna package  <cit> . energetics were predicted by partition function and by minimal free energy algorithms for evaluation purposes. partition function energetics produced models with higher predictive accuracy and was used in this study. first, a 21-length feature vector was produced with one dimension for each base position in the sirna sequence corresponding to whether the position was involved in an intramolecular secondary structure. second, a single dimension was added corresponding to the overall intramolecular stability as measured by the gibbs free energy of folding. finally, two additional dimensions were numerical counts of the number of bases in the  <dig> most 5' and  <dig> most 3' bases of sirna sequence involved in a predicted secondary structure  <cit> .

method 5: guide strand secondary structure features
the guide strand secondary structure features mapping method is an implementation of the sequence feature method described by xue et al.  <cit>  for discriminating real and pseudo mirnas. briefly, a 32-length feature vector is comprised of the occurrence frequencies of three nucleotide sequence-structure features. the middle base of the  <dig> base triplet has one of  <dig> possibilities  and each position could be in either a bonded or non-bonded state resulting in a  <dig>  dimensional feature space. the nomenclature used is the base at the middle position and then  <dig> binary symbols. for example, 'u000' indicates the middle position is 'u' and this  <dig> base triplet is not within a secondary structure, whereas 'c111' indicates the middle base position is a 'c' and this triple is completely paired within a structure. see xue et al.  <cit>  for complete details.

methods 6–11: n-gram
the n-gram approach mapped the presence or absence of each possible sub word of a given length and character composition from the original sirna sequence <cit> . for example, there are  <dig> =  <dig> possible 2-grams from the  <dig> base dna alphabet, . the  <dig> length 2-gram vector for the dna 'acgt' alphabet would then be:

< aa, ac, ag, at, ca, cc, cg, ct, ga, gc, gg, gt, ta, tc, tg, tt >

and mapping the previous example sequence of "atgcatg" onto this vector space by presence or absence would yield:

<  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> >

the n-gram method is therefore position independent, and vector space can be adjusted to account for frequency and position in addition to simply presence or absence.

methods 12–13: target strand secondary structure
the predicted secondary structures for the mrna target sequences were determined in the same identical manner as the sirna guide sequences. regions of structure prediction were limited to the guide strand binding region plus  <dig> bases up and down stream. however the guide strand binding region was used to map structure to vector space. in the case of direction independent structure, this resulted in a total of  <dig> dimensions:  <dig> dimensions with one for each nucleotide position plus an additional dimension as the gibbs free energy of structural stability. for directional binding in the target structure, the dimensions were  <dig> plus the gibbs free energy, totaling  <dig> 

method 14: target strand multiple binding patches
the guide strand of the sirna sequence could imperfectly pair with multiple regions of the target strand. the  <dig> most stable imperfect sites of guide strand to mrna pairing were predicted by rna thermodynamics  <cit>  and their thermodynamic stabilities populated the dimensions of the feature vector.

svm regression kernel methods
four regression kernel functions were tested:

 <dig>  linear kernel

 <dig>  polynomial kernel

 <dig>  radial basis function  kernel – this is a similar in implementation to the radial basis function neural network.

 <dig>  sigmoid kernel – this is similar to another type of neural network, a multilayer perceptron with no hidden layers.

svm kernels were implemented with the libsvm library  <cit> .

sv regression was used rather than sv classification, since the activity data were continuously distributed on the interval  <cit> . here we tested classification models to predict rnai activities, but choosing arbitrary division points in the outcome classes resulted in highly variable model performance. this observation suggests that data categorization has a sufficient impact in model building and that the optimization of data categorization is important.

n-fold cross validation within a dataset
cross validation  was performed by the method of dividing the original data into n equally sized  partitions and trained on  partitions and tested on the nth partition. this was performed for all n partitions and the pearson correlation coefficient  and mean squared error  between predicted and observed on the testing partition was averaged for all n tests. specifically, 10-fold cross validation on dataset <dig> divided the dataset into  <dig> datasets of size  <dig>  a model was then trained on a dataset of size  <dig>  and then tested on the remaining data of  <dig>  this procedure was repeated  <dig> more times on the remaining partitions. values of r and mse are comparable within tables from cross validation in that the same pseudo-random number seed was used to produce the dataset divisions. cross validations involving feature selection were performed by using the feature selection method only on the training set and applying this feature subset to the training set. performing feature selection within the cross validation reduces the bias in cv model estimates, but can result in different feature sets being used among the partitions of cross validation. the average number of features used among partitions, and the similarities among the cv feature subsets is reported where appropriate.

individual feature correlation to rnai activity and feature filtering
individual features were tested for their significance of correlation to activity by correlation and the t-test of significance, calculated by formula .

 t=|r×))| 

where

r = pearson correlation coefficient

o = number of observations

r <dig> = pearson correlation coefficient squared 

feature filtering used only the training portion of the dataset to perform feature subset selection, along with appropriate calculation metrics on the training dataset, and this feature subset was then applied to the naive testing dataset. evaluating feature selection within cross validation reduces bias in assessing model performance metrics when the same dataset is not in both model training and then model testing. by contrast, when the entire dataset is used for both training and testing, the results are optimistically biased due to model over fitting. when the training and testing are performed alternatively between dataset <dig> and dataset <dig>  the results are likely to be pessimistically biased, principally due to the dissimilarities between the datasets.

the feature selection method of correlation based feature selection   <cit>  was used to select feature subsets with presumed high effectiveness. cfs is a maximum-relevance minimum-redundancy method that greedily adds features to a feature subset by maximizing a scoring metric. cfs used equation  to maximize gs in selecting features for the subset.

 gs=krcik+krii
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwghbwrdawgaawcbagaem4camhabeaakiabg2da9maaliaabagaem4aasmaemocai3aasbaasqaaiabdogajjabdmgapbqabaaakeaadagcaaqaaiabdugarjabgucariabdugarjabcicaoiabdugarjabgkhitiabigdaxiabcmcapiabdkhaynaabaaaleaacqwgpbqacqwgpbqaaeqaaaqabaaaaaaa@4319@ 

where k is the number of features in the subset, rci is the mean correlation of the feature to the outcome and rii is the mean feature intercorrelation or feature to feature cross correlation.

multicollinearity exists within and between some of the feature mapping methods. for example, the base composition at positions  <dig> and  <dig>  correspond to the thermodynamics measurement for this area  and these share significant cross correlations.

software architecture
a group of c++ classes are made available to the research community that performs the following functions:

 <dig>  svm model construction, given a feature set and rnai sequence dataset

 <dig>  perform n-fold cross validation given a model, feature set and rnai sequence dataset

 <dig>  predict rnai activities given an svm model, feature set and a candidate rnai sequence set

 <dig>  predict sirna sequences given a feature set, candidate gene sequence and a svm model,

 <dig>  predict various types of feature filters, feature comparisons as well as feature cross-correlation

the most recent library classes and associated main functions can be downloaded  <cit> .

software was developed with c++ under linux kernel  <dig> .9- <dig>  with the gcc compiler  <dig> . <dig>  the classes for manipulating and modeling sirna sequences and their activities compile without warnings with the -wall -ansi -pedantic-errors compilation flags, including wrapper classes for libsvm- <dig>  and librnafold- <dig>  libraries. additional platforms and compilers have not been systematically tested, but the package is distributed with the gnu autotools and should compile on supported architectures. further development of additional functionality for this library is intended and the resulting code will also be released. areas of development include interfaces to other machine learning techniques including ann's, additional feature mapping methods and implementing wrapper methods for model construction and optimization. contact the author if you intend to develop functionality, primarily to ensure a minimal duplication of effort, if the method has already been constructed and not released.

RESULTS
the results section is divided into three major sections with the following structure. the first investigates individual feature correlation with rnai activity involving only dataset <dig>  this section specifically examines the methods of site-specific base composition , guide strand thermodynamics , guide strand entropy , guide strand secondary structure , guide strand secondary structure feature , target sequence secondary structure  and finally n-grams .

the second section investigates these single feature mapping methods and their abilities to train and test svm models on two datasets: dataset <dig> and dataset <dig>  the second section also introduces feature filtering by t-test, features removed by increasing stringency of t-test of individual feature to rnai activity.

the final section investigates the effectiveness of both combining individual feature mapping methods and feature filtering by correlation based feature selection  to produce feature subsets in the training and testing of svm models on dataset <dig> and dataset <dig>  also feature subset comparisons are made, investigating the commonality between predictive feature subsets derived from either within the same dataset between cross validations or between different datasets.

i a. site specific base composition
the correlation of position specific base composition to rnai activity was calculated for each of the  <dig> features in the position specific base composition vector. overall, there are  <dig> features that have a correlation with rnai activity with a t-test value of  <dig>   or greater . statistical tests have not been corrected for multiple comparisons and there are several kinds of non-independence within the data, features, models and tests presented. many of these bases and positions are consistent with previous observations of site-specific base composition , but several have not been previously identified as statistically significant. previous analyses even from the same dataset yield inconsistencies in features found to be or not be significant.

briefly, the method for identifying position specific biases in base composition from this data previously used the  <dig> most potent and  <dig> least potent sirna sequences rather than the entire dataset  <cit> , so differences are not unexpected. for example, sites that have not previously been shown as significantly associated with rnai efficacy: c <dig> , c <dig>  c <dig>  g <dig>  g <dig> are overly associated with lower potency and u <dig>  u <dig>  a <dig>  t <dig> are overly associated with higher potency, numbering from the 5' end of the guide strand. in general, from the  <dig> features that have values of t greater than  <dig> , the features are relatively evenly distributed across bases:  <dig> a's,  <dig> c's,  <dig> g's and  <dig> u/t's, but not in their association with lower potency:  <dig> a's,  <dig> c's,  <dig> g's,  <dig> u/t's versus higher potency:  <dig> a's,  <dig> c's, 2'g's,  <dig> u/t's, and their distribution across positions are irregular .

in addition to the guide strand of the sirna, site-specific base composition biases might exist in the target mrna as well. investigating this possibility in the target mrna surrounding the guide strand-binding region resulted in  <dig> overall patterns. first, the guide strand binding area on the target strand has the largest magnitude of site-specific base composition biases, when compared to the surrounding  <dig> bases . second, the magnitude of the positive correlation drops with distance from the guide strand whereas the magnitude of the negative correlation appears reasonably constant. third, the overwhelming trend for positive correlations with activity relates to the bases a and t/u. the trend for negative correlations with activity relates to the bases g and c . despite these suggestive patterns, no dominant features of site-specific base composition were obvious outside of the guide strand binding area, and further study of site-specific base composition was limited to the guide strand region.

i b. guide strand thermodynamics, entropy, secondary structure
guide strand thermodynamics , guide strand sequence entropy , guide strand secondary structure stability  and overall target strand secondary structure stability  all have correlations with rnai activity that have high t-values. in addition, these features have position specific distributions from within the guide strand . correlations between activity and guide strand thermodynamics, guide strand secondary structure and target secondary structure have been shown before and we see overall correlations between these features and rnai activity as well. also, position dependence of guide strand thermodynamics has also been shown previously and this is seen in the present data as well . additionally, there is a general positive association between the entire guide sequence's information content  and activity, where guide sequences with higher information content  have higher potency. there is also a weak indication that this pattern is seen in positions  <dig> through  <dig> of the guide strand .

i c. sequence structure features
recently, a sequence structure mapping method was proposed that allowed the discrimination of real versus pseudo micrornas  <cit>  by combining sequence and secondary structure. applying this method on the guide strand sequence, several sequence-structure features were observed that had positive or negative correlations with activity. using the nomenclature described in the methods section, features such as u/t <dig>  and a <dig>  had a positive correlation as well as sequence-structure features that had a negative correlation c <dig>  and g <dig> . generally, open structures are preferred to bonded structures and the bases a and u/t are preferred to c and g .

i d. target secondary structure
investigating the target strand secondary structure more fully, the target strand secondary structure was predicted and the positions surrounding the guide strand binding area were interrogated to see whether they form pairs in an intramolecular target strand structure. intramolecular interactions that were limited to  <dig> nucleotide sites upstream and downstream of the guide strand binding area were used in the presented data. folding areas of  <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and the entire target strand were investigated and were, on the whole consistent. however,  <dig> sites resulted in the highest correlation between target strand structure stability and rnai activity, similar to the observations of  <cit> . graphing the correlations between each position in the target strand that is within an intramolecular structure and the rnai activity resulted in two overall patterns . first, there is an overall negative correlation between any site within the local target area being paired and rnai activity  that is consistent with the observation that there is a correlation between target strand structure stability and activity. second, the most dominant negatively correlative position that results in lower potency sirna sequences occurs where the 5' most site of the guide strand would pair to the target strand within an intramolecular watson-crick pair.

target secondary structure was further investigated by asking whether there are any structural patterns in the overall orientation of the watson-crick pairing within the immediate region of the guide strand. intramolecular bonds were categorized into those occurring to a base more 5' on the target strand and those occurring to a base more 3' of itself  on the target strand. there are two patterns that emerge from this analysis. the first pattern is the highly deleterious position where the guide strand's 5' most base would pair. it is fairly equally comprised of structures that involve sites that are both 5' and 3' of itself, suggesting guide strand access is not asymmetric. second, there appears to be a weak symmetry of sites immediate to the 3' of the guide strand binding area,  on the target strand to be positively correlated with activity if bonding with a 5' more site and negatively correlated with activity if bonding with a 3' more base. this weak symmetry is reflected within the guide strand binding area  where these positions are weakly positively correlated with activity if bonding with a 3' more site and negatively correlated with activity if bonding to a 5' more base. the overall suggestion might be that structures that hold the 5' most site of the guide strand's pair in a target secondary structure are deleterious whereas nearby target secondary structure stems that hold this position in an unstructured loop are more  positive for rnai activity. since this is an analysis that comprises several thousand guide strand regions, it is necessarily a population average. therefore, individual cases where this is not observed would not be surprising.

i e. n-grams
sequence motifs, or n-grams, simply a subsequence of n items from a given sequence, were then investigated for motif specific correlation with rnai activity . overall,  <dig> of the  <dig> possible 2-grams had t-values greater than  <dig> ,  <dig> with positive correlations tending to be a and u/t rich  and  <dig> with negative being the four possible combinations of both c and g base . this overall pattern holds true for the  <dig> through  <dig> length n-grams with a general preference for a and u/t and aversion for c and g. higher order patterns are seen in the preference or aversion to specific longer motifs as well. for example, there are  <dig> possible guide strand 3-grams and  <dig> of these  <dig> have t-values greater than  <dig> . furthermore, there are  <dig> of the  <dig> 4-grams with t-values for their correlations greater than  <dig> . one striking observation is that overall for 3-grams, their individual 3-nucleotide motif associations with rnai activity negatively correlate with their corresponding codon usage frequency , reverse and complementing the guide strand 3-gram into the target strand codon sequence. also, the magnitude of deviation for each 3-gram, as measured by t, negatively correlates with both the codon usage frequency  and with synonymous codon usage frequency .

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

the observation that there may be some association between  <dig> nucleotide motifs associating with rnai activity and codon usage preferences may be due to several non-mutually exclusive relationships. one possible relationship is the mutual lack of preference for specific dinucleotide pairs and higher order n-grams, which are clearly comprised of lower order n-grams and the relationships seen within the 3-grams and their underlying 2-grams. it is well known that there is to be an overall under abundance of the dinucleotide pair "cg" in most eukaryotic genomes  <cit>  as well as a reduced preference for codons with the dinucleotide "cg" when compared with the dinucleotide "gc". however, concerning those specific dinucleotides within rnai guide strands, the occurrence of the dinucleotide "cg" in the guide strand is significantly negatively correlated with activity  as is the dinucleotide "gc" . furthermore, neither the guide strands nor the target sequences appear to have any specific over or under abundance, beyond what has been previously observed, of the "cg" dinucleotide.

to further investigate dinucleotide composition, there are  <dig> 4-grams. each 4-gram occurs in the present rnai sequence dataset and either correlates positively or negatively with rnai activity. a  <dig> ×  <dig> contingency analysis was performed looking for an association between a 4-gram's positive or negative correlation with activity and the presence or absence of a specific dinucleotide pair. the results for negatively contributing dinucleotides were similar to the 2-gram correlations in that the dinucleotides "cc" g =  <dig> , "cg" g =  <dig> , "gc" g =  <dig>  and "gg" g =  <dig>  had significant, g-test , overabundance in negative correlated 4-grams when compared to 4-grams that did not contain those dinucleotides. by contrast, with the negative associating 2-grams, only three positively contributing dinucleotides, "at" g =  <dig> , "ta" g =  <dig>  and "tt" g =  <dig> , showed a significant g-test overabundance in positively associated 4-grams when compared to 4-grams that do not contain those dinucleotides.

again, to more closely investigate dinucleotides in 4-grams with the intention of trying to reduce base composition biases, only those 4-grams with equal base composition were selected. there are  <dig> 4-grams that each contains one of each of the four bases. of those  <dig> 4-grams,  <dig> have negative correlations with activity and the remaining  <dig> have positive correlations with rnai activity. performing a  <dig> ×  <dig> contingency test on the presence versus absence of each of  <dig> dinucleotides  for positive versus negative correlation yields a significant interaction  only for the "cg" dinucleotide. this occurs in the "cg" dinucleotide, where  <dig> "cg" containing 4-grams positively correlate,  <dig> "cg" containing 4-grams negatively correlate, while  <dig> "cg" missing 4-grams positively correlate and the remaining  <dig> "cg" missing 4-grams negatively correlate with rnai activity. the remaining hetero-dinucleotide pairs, including "gc" , do not suggest significant interactions between dinucleotide presence/absence and positive/negative correlation with rnai activity in 4-grams with equal base composition. these observations may indicate some differential effect of nucleotide sequences on rnai activity. the intent of these preliminary n-grams analyses is not necessarily to be complete, but to simply provide an initial description of some of the complexity seen in the present data as well as some possible explanatory patterns.

ii a. building predictive svm models with features correlative with rnai activity
one aspect of finding features that are correlative with an outcome, in this case rnai activity, is to better understand the mechanisms that are important in the system. a second aspect of feature finding is determining how well these features, alone or together, are able to model the phenomenon under study and additionally, to determine specifically what features are able to predict outcomes that were not seen during model building.

in our research, we used the  <dig> feature mapping methods listed below:

 <dig>  position specific base composition

 <dig>  thermodynamics

 <dig>  entropy

 <dig>  guide strand structure

 <dig>  guide strand structure features

 <dig>  n-grams n = 2

 <dig>  n-grams n = 3

 <dig>  n-grams n = 4

 <dig>  n-grams n = 5

 <dig>  n-grams n =  <dig> 

 <dig>  n-grams n = 2–5

 <dig>  target strand structure non-directional pairing

 <dig>  target strand structure directional pairing

 <dig>  multiple guide strand binding patch energetics on the target strand

we compared these  <dig> features in their abilities to yield predictive models by radial basis function  support vector machine , table  <dig>  additional svm kernels were investigated, but overall the polynomial and rbf kernels performed slightly better than the linear and sigmoid on these data. briefly, examination of the position specific base composition mapping  across kernels by 10-fold cross validation within dataset <dig> resulted in the following kernel performance metrics, implementing a course grid search for kernel parameters:

fndataset = feature number count from dataset, r = pearson correlation coefficient, mse = mean squared error * theoretical, but five 5-grams and several 6-grams are absent in the present dataset, reducing the effective feature set size.

linear r =  <dig>  mse =  <dig>  

polynomial r =  <dig>  mse =  <dig>  

rbf r =  <dig>  mse =  <dig>  

sigmoid r =  <dig>  mse =  <dig>  

additionally, rbf kernels overall resulted in the largest correlation values between predicted and observed activities in cross validation across kernel methods. rbf kernels used parameters of gamma =  <dig>  and p =  <dig> , both empirically derived by cross validation as optimal from the method  <dig> and dataset <dig>  deviations in these kernel parameter settings across additional methods and datasets had minimal influence on the resulting models, but parameter optimization across feature mapping method, feature subsets and dataset was not investigated in detail.

across feature mapping methods, overall, the number of features in the model varied from  <dig> to over  <dig>  as did the correlation coefficient  from  <dig>  to  <dig> , table  <dig>  however, the entire dataset being used to both train and test the model is not a realistic measure of how well the model might perform on data that was not seen during model building. therefore, 10-fold cross validation was performed. additionally, over fitting a model is a concern, particularly when the size of the feature space grows to exceed the size of the dataset. evidence of this is seen in some of the longer n-grams, specifically where n=  <dig>  feature set size exceeds  <dig> and the dataset size is  <dig>  during 10-fold cross validation, r's were, as expected, lower than their corresponding complete dataset r's. all mapping methods result in significantly  positively predictive svm models, on data not seen during model training within dataset <dig>  ranging from r =  <dig>  to r =  <dig> .

comparisons among feature mapping methods suggested that all feature mapping methods provided some degree of predictive utility by cross-validation . additionally, as a compromise between predictive utility and feature set size, the n-gram method was limited to n =  <dig> through  <dig>  method 11-n-gram n = 2– <dig> results in greater predictive accuracy than individual n-grams where n =  <dig>   <dig>   <dig> and  <dig> separately and results in a moderate feature set size. finally, comparisons between target secondary structure mapping methods that incorporate directionality of base pairing  performed better in cross-validation than not incorporating directionality .

eight feature mapping methods  were investigated by training and alternatively testing svm models on two datasets: dataset <dig> and dataset <dig>  table  <dig>  five methods, position specific base composition, thermodynamics, guide strand structure, guide strand features and n-grams n = 2– <dig> , resulted in positive predictive models both within and between datasets. namely, each of these five methods resulted in a significantly positive predictive models by cross validation and when trained on one dataset and tested on the other dataset. both target strand structure and off target thermo  are consistently predictive within either dataset <dig> or dataset <dig> by cross-validation but not alternatively between datasets. finally, the feature of guide strand entropy  yields positively predictive models when training on dataset <dig>  but not when training on dataset <dig>  table  <dig> 

method numbers are from table  <dig> 

fndataset = feature number count from dataset

r = pearson correlation coefficient, values with a † are not able to reject the ho: r =  <dig> 

mse = mean squared error

ii b. feature filtering on individual feature mapping methods
methods  <dig>   <dig>   <dig>   <dig> and  <dig> resulted in positive predictive models both within datasets by cross validation as well as between datasets. individually, these methods were investigated to examine whether feature filtering, to exclude less significant individual features, could improve predictive models. feature filtering by t-test for individual methods of position specific base composition  resulted in minor improvements by cross validation on dataset <dig>  but no improvements when training on dataset <dig> . by contrast, feature filtering for thermodynamics  resulted in model improvements for both datasets in either cross validation or reciprocal training and testing, tables  <dig> and  <dig>  additional improvements can be seen with guide strand structure , tables  <dig> and  <dig>  guide strand structure features , tables  <dig> and  <dig>  however, feature filtering for n-grams n = 2– <dig>  resulted in the most dramatic model improvements for both training on dataset <dig>  as well as training on dataset <dig> . feature filtering for n-grams caused the reciprocal training and testing of the datasets to be more effective when compared to the unfiltered n-grams method. target strand structure-directional  generally results in predictive models when performed without feature filtering, but improvements of model building between datasets can occur with feature filtering, tables  <dig> and  <dig> 

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

iii a. combining feature mapping methods
the position specific base composition, thermodynamics and n-gram feature-mapping methods yield predictive models on separate training and testing datasets . combining methods  <dig>   <dig> and  <dig> resulted in the improved accuracy of svm models during training and testing, tables  <dig> and  <dig>  when compared to each method individually . however, pair wise combinations of methods  <dig>   <dig> and  <dig> can result in models that are more effective when compared to models constructed with more features. the modeling results for methods  <dig> and  <dig> combined are presented in tables  <dig> and  <dig>  likewise the modeling results for methods  <dig> and  <dig> combined are in tables  <dig> and  <dig> and methods  <dig> and  <dig> combined are in tables  <dig> and  <dig>  methods that limit the additional modeling features can result in more effective models when compared to models constructed with more features. for example, by cv within dataset <dig> the maximal predictive model from methods  <dig>   <dig> and  <dig> results in r =  <dig>  mse =  <dig> , table  <dig>  whereas a higher predictive model can be generated by cv within dataset <dig> with just methods  <dig> and  <dig> combined, r =  <dig>  mse =  <dig> , table  <dig>  a similar, but less dramatic, pattern can be seen within dataset <dig> cv, where a model constructed with methods  <dig>   <dig> and  <dig> performed r =  <dig> , mse =  <dig> , table  <dig>  but a model constructed with methods  <dig> and  <dig> performed r =  <dig> , mse =  <dig> , table  <dig> 

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

several features such as the guide strand structure and guide strand structure features  individually contribute to positively predictive svm models when training and testing is within datasets by cv or between datasets. combining feature mapping methods  <dig> and  <dig> with methods  <dig>   <dig> and  <dig>  had little positive influence on the general predictive ability of the models' ability to predict data not seen during model building. with the exception of training on dataset <dig> and testing on dataset <dig>  performance generally degraded from combining methods  <dig>   <dig> and  <dig> to combining methods  <dig> , <dig>  and  <dig>  comparing tables  <dig> and  <dig>  a similar pattern is seen by adding method  <dig>  tables  <dig> and  <dig>  overall adding predictive features to models did not result in a deterministic improvement of model performance, but when models incorporate large number of features there are some benefits to feature filtering to improve model performance.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

models trained on dataset <dig> and testing performed with dataset <dig>  dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums and are simply visual landmarks.

iii b. feature selection on multiple feature derived models
the overall effects of combining feature mapping methods and feature filtering to increase the predictive accuracy of svm models construction are summarized in table  <dig>  there are multiple feature set and filtering optima , depending on the criteria desired for model construction. for example, if the intent is to construct a model that best predicts dataset <dig> by cv, choosing methods  <dig> and  <dig> without feature filtering results in a maximal r =  <dig>  and mse =  <dig> . however, if the intention is to construct a model that best predicts dataset <dig> by training on dataset <dig>  combining methods  <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> without feature filtering results in a highly predictive model, r =  <dig>  and mse =  <dig> .

method numbers are from table  <dig> 

models trained on dataset <dig> and testing performed with dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

models trained on dataset <dig> and testing performed with dataset <dig> and  <dig> × cross validation on dataset <dig>  features removed by increasing stringency of t-test of individual feature to activity from dataset <dig> 

feature numbers in parentheses are the average number of features in cross validations.

entries in bold are column maximums from their respective tables and are provided as visual indicators. italicized entries are column maximums within the table and are again provided as visual indicators.

feature set selection and feature subset selection is clearly influential on model performance. we investigated whether the implementation of an algorithmic method of feature subset selection could result in improved model construction. for this exploration, dataset <dig> and dataset <dig> were used as training and testing sets by cv and all features from methods  <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> were included in the starting pool of  <dig> candidate features. features were then selected for inclusion based on the correlation feature selection  method. briefly, cfs is a maximum-relevance minimum-redundancy method and greedily adds features to maximize the growth of equation  <dig>  where the numerator is the feature to outcome correlation and the denominator is comprised of the feature to feature cross correlation. models constructed in this fashion had an average r =  <dig>  with mse =  <dig> , by cv within dataset <dig> and models contained on average  <dig>  features. likewise performing cfs on dataset <dig> starting with  <dig> features resulted in models with an average r =  <dig>  and mse =  <dig>  and an average of  <dig>  features.

to investigate whether improvements in model predictability and model interpretability could be made the candidate feature set was filtered. features were included in models by retaining only the most significant features, by t-test of feature to outcome, in the training model and then testing the resulting model on the naive testing data partition . eliminating features from the  <dig> candidate features at a t-test filter of  <dig> can result in maximally predictive models with an average r =  <dig>  and an average of  <dig>  features in the final model, by cross validation within dataset <dig>  on average the same features were consistently found in  <dig>  of pair wise comparisons among models from the training and testing sets within dataset <dig>  further increasing the stringency for feature inclusion can result in highly predictive models with substantially fewer features . however, as feature inclusion stringency increased, the commonality of features found between models declined. for example, a cfs t-test filter of  <dig>  results in a nearly maximal predictive model with r =  <dig>  and mse =  <dig> , and reduces the average number of features in each model to  <dig> , but only half  of the features are consistently found in pair wise comparisons among the resulting predictive models. the effect of feature subset selection and the resulting feature models are summarized in the venn diagrams in figure  <dig>  it is evident that reducing the number of features within a model can improve model performance, and can also yield multiple nearly equally predictive models. feature commonality among equally predictive models decreases as only the most significant features are considered for model inclusion.

similar findings are found by performing cfs within dataset <dig>  first, an improvement to model predictive effectiveness is seen when implementing cfs, when compared to all features, figure  <dig>  second, further improvements in generating predictive models by cfs can be realized by eliminating some of the less predictive features. finally, reducing feature set sizes by using only the most predictive features can result in models with nearly equal effectiveness, but the resulting features subsets tend to be increasingly distinct. supplementary files contain the distinct feature sets and subsets for dataset <dig> and dataset <dig> for the cross validations by cfs with feature filtering by t-test .

all features across all training and testing sets were itemized, for dataset <dig> and dataset <dig>  by cfs at the maximally predictive t-test value of  <dig>  totaling these features for dataset <dig> and dataset <dig> resulted in  <dig> and  <dig> features being used in all training and testing models, respectively. formally these feature sets can be referred to as s <dig> and s <dig>  where s2431⊂ sall, s579⊂ sall, |s2431| =  <dig>  |s579|=  <dig> and |sall| =  <dig>  itemizing the features found in common from data <dig> and dataset <dig>  results in  <dig> features found in both feature models  and  <dig> features are in neither feature model | = 257). by comparison,  <dig> features are found only in the dataset <dig> model  and  <dig> features are found exclusively in the dataset <dig> model . comparing the observed values with expected values of  <dig> ,  <dig> ,  <dig>  and  <dig> , in the above presented order, these feature subset congruencies reject the null hypothesis of independence among feature subsets between datasets . this indicates that dataset <dig> and dataset <dig> yield feature subsets by cfs more similar to each other than by chance.

discussion
several previous studies have developed predictive models of rnai activity based on various methods of statistical association of features with activity or by machine learning methods. there were several intentions of this study. the first intent was to investigate individual features and their contribution to activity in the hopes of finding novel patterns suggestive of rnai mechanism. the second intent was to compare multiple feature mapping methods in their relative effectiveness in building machine learning models. the third intent was to combine feature-mapping methods to generate useful machine learning models. finally, the fourth intent was to implement feature filtering and subset selection in machine learning to improve model building and then to begin to provide a set of model building and testing tools to further the research in the properties of small non coding rna sequences. the results of this study have revealed several features associated with rnai activity. one feature class includes the identification of novel site-specific nucleotide compositions. a second feature class further elucidates 5' versus 3' biases in guide strand thermodynamics, suggesting a 5' bias in both guide strand and target strand secondary structure. finally several previously unknown n-gram or motif patterns have been identified as features associating with rnai activity.

n-grams
the negative correlation of each 3-gram to codon usage frequency and to synonymous codon usage frequency suggests that sirna sites in coding regions that code for rare amino acids and that deviate from using high frequency codons may provide higher rnai activity. these observations are from using human codon usage preferences. while human and mouse codon usage frequencies show similarities in their relationship  <cit>  and the activity data are derived from human and mouse genes, a larger comparative study with multiple organisms and genome specific motif preferences would be needed to demonstrate convincing evidence of codon association with sequence preference and rnai activity. further examination of 4-gram and 2-gram sequences and their association with rnai activity suggests that a reduced preference for cpg dinucleotides could be solely used to explain these sequence motifs to activity relationships. some of the higher-order n-grams are then consistent with their lower-order n-grams, but there appears to be some higher-order effects that influence lower-order n-gram observations or vice versa.

features
the two datasets examined here, dataset <dig> and dataset <dig>  are considered to be acting under the same rnai mechanism, and consistent with this assumption predictive models built from these datasets converge to an overall common sub set of features. identifying features that associate with a molecule's functionality allows for the development of a pharmacophore model, namely a molecular framework that carries the essential features responsible for a drug's biological activity  <cit> . assuming a broad pharmacophore definition of the set of structural features responsible for that molecule's biological activity, the continued identification of structures, sequences or chemical moieties  <cit>  with influence on rnai activity will continue to enhance the pharmacophore model of small rnas and the interference pathways. it will also assist in the rational design of artificial rnai effectors and inhibitors to modulate biologically relevant processes. furthermore, the continued dissection of specific events within the rnai pathways, rnai delivery, dicing, guide strand uptake, target strand turn-over or risc localization could result in the identification of specific molecular properties associated with discrete events. this would allow the fine-tuning of delivered reagents to specific rna pathways and locations or allow for avoidance of unintended effects. some of the similarities and differences in the various rnai pathways are becoming known as well as the similarities and differences among organisms  <cit> . further development of methods that discriminate among predictive features or feature subsets will be necessary to associate the specific causality of candidate features with their molecular outcomes.

development of minimally predictive models has several advantages. advantages include reducing model dimensionality, improving model generalization, reducing the time of model construction and arguably the most important in the case of computational biology enhancing the ability to interpret the model by separating the least useful features from the most useful. several previous model building efforts have focused on the reduction of the model feature set to a minimal size, enhancing the interpretability of the feature set. while feature set reduction can certainly have a positive influence on the predictability and interpretability of a model, excessive feature set reduction can result in multiple equally predictive models with distinct or minimally intersecting feature sets. interpretation of these distinct feature sets should then not be based on differences in the underlying biological events or differences between datasets, but can simply be due to multiple nearly equal optimal regions within feature subset space.

position specific base preferences, as well as other feature preferences for rna interference, suggest there are some structural biases in either risc loading or once the guide strand is within risc, by the short rna sequences examined here. there are alternative mechanisms for loading risc other than providing duplex  <dig> mer with  <dig> base 3' overhangs to cells. alternative mechanisms for loading risc would retain the need for any biases once loaded into risc. however, the alternative-loading pathway might have different requirements for effective risc loading, assuming only  <dig> discrete steps. comparison between the features that allow predictive effectiveness of rnai for alternative risc mechanisms loading mechanisms may allow both consensus rules to establish which features are shared in common as well as the mechanism specific features for providing effective knockdown. an obvious example of sirna's that share much of their pathway but differ in risc loading would be to compare  <dig> mer sirna sequences to dicer-substrate sirna  <cit>  sequences. additional experiments that investigate individual events or end points will be necessary to build more realistic predictive models of the entire rnai pathway as well as for additional organisms.

target secondary structure
rnai activity appears to be influenced by the structural stability of the target rna, with the most influential sites being nearest the binding site of the guide strand's 5' end. guide strand interaction with target strand is thought to require some minimal amount of base pairing in order to recognize a site within the target strand as effective. the precise degree of base pairing is not well established, but some sites within the guide strand are more influential than others. the seed region, positions  <dig> through  <dig> of the guide strand, are thought to provide a large contribution for guide strand to target strand interaction without complete complementarity  <cit> . this suggests that target accessibility for the seed region might be a primary determinant of rna interference activity, perhaps limiting the number of target molecules that are able to initiate rnai guide strand base pairing. target site structure could then modulate off-target effects as well as the target sequence specific knockdown. despite the statistically significant association of target strand secondary structure to rnai activity within dataset <dig> and the ability of this feature alone to produce predictive models , the addition of target strand structure features to models that already contain other predictors of activity do not substantially improve most predictive models . we are left with two seemingly contradictory conclusions: i) secondary structure influences rnai activity and ii) including secondary structure in overall predictive models is not necessary if other feature classes are included. reconciling these ideas requires additional data, but one possible explanation is that the rnai activity models may be dominated by one or a few steps of the rnai activity pathway, namely risc loading, and these features dominate the signal within the present data.

furthermore, position specific contributions to guide strand and target strand secondary structure, namely the occurrence of a position being within a watson-crick pair, have not been shown to have an overall association with predictive modes, but see patzel for a case where this is observed in an engineered guide strand structure  <cit> . by contrast, patzel et al. saw a reduction in guide strand efficacy if either the 5' or 3' end were involved in a secondary structure. however, the present observations across a population of guide strands shows a trend where positions closer the 5' end tend to have more negative influence on activity if it is involved in a secondary structure. for example, the 5' most positions from within the guide strand have the large and negative correlation between sites being within a watson-crick pairing event and rnai activity, with rnai molecules with sites within pairing events having overall lower potency . a similar trend for a site-specific dependency on target strand structure is seen for the overall target rna sequence. this trend would appear where the site that is predicted to interact with the 5' most base of the guide strand is within a watson-crick pair within the target strand and this is associated with lower predicted rnai activity. there is also a rough positive correlation between base-pairing occurring within the guide strand or within the target strand. this rough positive correlation occurs despite the folding of the guide strand only accounting for interactions between the  <dig> bases of the guide strand and the folding of the target strand only accounting for interactions between any sites within the target strand. the observations from both guide and target strand suggest some increased importance of the 5' end of the guide strand or its complement in the target strand, when compared to the 3' end.

v. comparisons with previous machine learning models for rnai activity
several studies have utilized machine-learning methods to develop predictive models given sirna sequences. sætrom et al.  <cit>  compared a combination of genetic programming and boosting algorithms  to develop a string grammar method for learning the differences between  <dig> classes of sequences, effective and ineffective rnai. gpboost was compared to svm based classifiers that used  <dig> separate feature mapping methods. the results suggested that boosted genetic programming produced models with an r =  <dig>  on the entire dataset , r =  <dig>  in 10-fold cross validation was very effective at classifying effective versus ineffective rnai when compared to svm classifiers where the most accurate mapping methods resulted in r =  <dig> . both svm methods were n-gram based, with the first being where n was length one through  <dig> and the second where n =  <dig>  care should be used in comparing model correlation values between classification and regression approaches.

teramoto et al.  <cit>  used svm classification to discriminate between  <dig> effective and  <dig> ineffective sirna sequences with an n-gram based feature method and the 3-gram and  <dig> through  <dig> grams were most effective, resulting in  <dig> % and  <dig> % accuracy, respectively. furthermore, in leave one out cross validation  there was a correlation r =  <dig>  between svm scores developed under the entire dataset versus under loocv, but correlations between predictive model and empirical knockdown for the entire rnai dataset or under loocv were not reported.

huesken et al.  <cit>  used an  <dig> features position specific nucleotide composition to train an artificial neural network  on dataset <dig> to build an activity predictor that correlates predicted to observed activities on a continuously distributed dataset to a correlation of r =  <dig>  on the entire dataset and r =  <dig>  on a single cross validation.

shabalina et al.  <cit>  used  <dig> feature parameters including position specific base composition, free energies and dinucleotides to build an ann with correlation of predicted value within the dataset , r =  <dig> , but selecting the most predictive  <dig> features improved the correlation, r =  <dig> , reducing model complexity. furthermore, using just  <dig> of the  <dig> feature parameters, an ann predicted the data from dataset <dig> to r =  <dig>  for model cross-validation.

vert et al.  <cit>  used position specific base composition and n-grams of length  <dig> through  <dig> to produce predictive linear model from dataset <dig> to r =  <dig>  by cross validation. individual features relative contributions to the resulting models were able to be evaluated in the linear models, as well as compatibility of the modeling procedure between distinct datasets, with training on dataset <dig> and testing on a dataset of  <dig> mers with a size of  <dig>  resulted in a model effectiveness of r =  <dig> . target site accessibility was also examined for  <dig> sequences with the largest differences in predicted and observed activities. some of the discrepancies in predicted activities were attributed to target secondary structures, with particular influence being noted at the site of the 5' end of the guide strand target region.

ladunga  <cit>  developed and compared several regression svm models from a potential pool of  <dig> features of position specific base composition and thermodynamics and  <dig> sirna sequences from the dataset <dig>  model accuracy rates were  <dig> %  with the polynomial kernel and weight-based feature elimination resulting in a final model with  <dig> features. an accuracy of  <dig> % would correspond to an average error of  <dig>  then a mse =  <dig> . model correlations between predicted and observed activities were not reported. also, when feature set sub sampling was occurring by various methods, single features sets are reported, suggesting that cross validation correlations may not be precisely comparable if the feature selection did not occur within the cross validation.

the methods presented here can result in predictive models, specifically summarized from 10-fold cross validation results on dataset <dig>  first, simply applying an  <dig> feature position specific base composition method  can result in an svm rbf kernel model with r =  <dig> . second, filtering these features can result in slight improvements to the model, with an average of  <dig>  features and r =  <dig> . third, combining and filtering features can result in further model improvements, with an average of  <dig>  features filtered from a starting feature set size of  <dig> and a r =  <dig> . fourth, implementing a cfs method for feature selection and using only significant features at t-test of  <dig> or greater, can result in model improvements with an average of  <dig> features selected from a starting feature set of  <dig> and r =  <dig> . finally, maximally predictive within dataset <dig>  but perhaps less applicable to other datasets,  <dig> features from methods  <dig> and  <dig> combined can result in an average predictive model with r =  <dig> .

CONCLUSIONS
here we show several feature mapping methods that reveal features that have associations with rnai activity. each of the mapping methods are able to produce, at least somewhat, predictive models by either cross validation or alternatively training and testing between datasets. many of these features imply biological constraints on the rnai mechanism previously not studied. for example, position specific base composition tends to be highly localized within the guide strand region of the target rna but compositional biases exist outside the guide strand region. additional patterns reveal themselves in the presence or absence of specific short motifs  associating with activity. overall stability and position specific base pairing of the secondary structures of the guide strand as well as the target strand also contain predictive features in determining rnai activity. secondary structures of the target strand that hold the 5' most position where the guide strand would pair in an open structure are predicted to provide more favorable knockdown than structures where this position is within an energetically stable secondary structure. however, both datasets do not show equal correlates to this structure feature and further validation of features contributing to rnai activity may yet need more data to further resolve the specific knockdown mechanism. furthermore, these target sequences and expression knockdown data are from mouse and human genes and cell lines.

suggestive of the relative importance in the rnai mechanism, the rank order of features that best model rnai activity by svm regression are:

 <dig>  position specific base composition

 <dig>  guide strand thermodynamics

 <dig>  n-grams 2–5

 <dig>  guide strand secondary structure features xue et al.  <cit> 

 <dig>  guide strand secondary structure

 <dig>  target strand secondary structure

combining feature mapping methods together resulted in svm regression kernels that can produce effective predictive models using large numbers of features. for example, with  <dig> features and 10-fold cross validation in dataset <dig> yields models with r =  <dig>  and mse =  <dig>  and dataset <dig> yields models with r =  <dig>  and mse =  <dig> . furthermore, combining cfs and filtering features can improve model performance and reduce the number of features being considered in model building, at t-test of  <dig>  dataset <dig> yields models with  <dig> features, r =  <dig>  and mse =  <dig>  and dataset <dig> yields models with  <dig> features, r =  <dig>  and mse =  <dig> . predictive svm models are able to be produced from individual or combinations of features, and methods such as feature filtering or cfs can improve model performance. however, minimizing feature sets sizes can result in distinct sub sets of features being selected with nearly equal model performance among feature subsets.

availability and requirements
project name: seq2svm;

project download: ;

operating system: gnu compliant, linux tested;

programming language: c/c++;

license: gnu gpl;

any restrictions to use by non-academics: none.

supplementary material
additional file 1
suppl1_comparison_position_specific_base_composition. sites and bases within the guide strand found from several studies and datasets to be either significant or not significant in their influence of rnai activity.

click here for file

 additional file 2
suppl2_all_features_corr_descr_tval. features with their associated descriptions, correlations with rnai activity and t-test values of significance.

click here for file

 additional file 3
supplementary_figure_ <dig>  the base composition bias within the localized target site of the sirna guide strand, for  <dig> bases upstream and downstream of the guide strand target area.

click here for file

 additional file 4
supplementary_figure_ <dig>  the base composition bias within the localized target site of the sirna guide strand, for  <dig> bases upstream and downstream of the guide strand target area.

click here for file

 additional file 5
tr_2431_cfsfilters. the features found to be useful by correlation based feature in training and testing the  <dig> dataset by cross validation, at t-test values from  <dig> to  <dig> 

click here for file

 additional file 6
tr_579_cfsfilters. the features found to be useful by correlation based feature in training and testing the  <dig> dataset by cross validation, at t-test values from  <dig> to  <dig> 

click here for file

 additional file 7
seq2svm_ <dig> . an gnu platform deployable gpl code base for performing svm modeling on small rna sequences, with examples. deploy by unzipping, untarring, and building with configure and make. see the included readme files. updated versions will be available at .

click here for file

 acknowledgements
this work was supported in part by a grant from the nih . i thank three anonymous reviewers for their helpful comments and suggestions and patricia allard for clarifications provided by a meticulous reading of the manuscript.
