BACKGROUND
serial analysis of gene expression  is a technique for obtaining a quantitative, global snapshot of the transcriptome  <cit> . the method extracts short sequence tags  from each messenger rna; these are serially ligated, cloned and sequenced, and can then be counted to obtain a profile  <cit> . sage has been used to study the transcriptome of a variety of tissue and cell types from a diverse set of organisms. the technique was originally conceived to study the cancer transcriptome, and has been utilized extensively to do so.

as a counting technology, sage produces profiles consisting of a digital output that is quantitative in nature. for example, a statement can be made with reasonable certainty that a sage tag observed  <dig> times in a library of  <dig>  tags corresponds to a transcript that comprises  <dig> % of the total transcriptome; the same statement cannot be made reliably with analog values, like that obtained from a microarray. accordingly, a reliable statistical model should account for the discrete, count-based nature of sage observations. when testing for differential expression between groups, where each group can contain multiple libraries, statistical methods that incorporate a continuous probability distribution  should be avoided. indeed, such tests require tag counts be normalized by division with the total library size; this removal of library size from the set of sufficient statistics discards an informative facet of the data.

the sampling of sage tags can be modeled by the binomial distribution which describes the probability of observing a number of successes in a series of bernoulli trials. here, the library size corresponds to the number of trials and the count of a particular tag is the number of successful trial outcomes. when the probability of an event is small, the binomal distribution approaches the poisson distribution as the number of trials increases. this is the case for sage , so the form of the poisson and binomial distribution is essentially the same. a fortunate characteristic of both of these distributions is that they are a function of a single parameter only, since the variance in observed data is directly calculable from the mean.

however, in practice, the variance of sage data is often larger than can be explained by sampling alone. several authors have attributed this effect, termed "overdispersion", to a latent biological variability  <cit> .  <cit>  refers to this as "between"-library variability, as opposed to "within"-library variability caused by sampling. examples of factors that could contribute to this variability are numerous, including: sample preparation or quality, artefacts intrinsic to the library construction protocol, differences in gene transcription due to environment, or the intrinsic stability or regulatory complexity of transcription at a particular locus. this will adversely affect statistical analysis because additional variance results in an overstated significance. procedures for using hierarchical models which incorporate a continuous prior distribution to explain the excess variance have been presented for both the binomial  and poisson  distributions. attempts to use the log-normal and inverse-gaussian as prior distributions  did not show an appreciable improvement and are computationally difficult to fit .

here, it is argued that the excess variation is due to a mixing of two or more distinct poisson  components, and this mixing is the predominant source of total variation. this assumption corresponds to a finite mixture model, which have found wide applicability in several fields . to illustrate, consider a tag from ten sage libraries of equal size  that has observed counts where half are realizations of an expression of  <dig>  and the other half of  <dig> . as a result, the probability distribution of observing a particular tag count will be a combination of these two components . note the similarity between the shapes of the probability distributions estimated from a fitted negative binomial  and a poisson mixture model .

if the poisson mixture model is an accurate foundation to explain sage observations, it is attractive for several reasons. first, this approach does not rely on a vague and continuous prior distribution to explain additional variance. rather, the model asserts that a gene's expression level will take on one of a number of distinct states. second, overdispersed models applied to sage data tend to show a wide range of excess variation; in many cases, far greater than can be attributed to counting. this is a troubling prospect for studies that utilize a limited number of libraries , since the observed count may differ wildly from the underlying expression. if a mixture model provides an improved fit to sage data, this concern would be assuaged. finally, mixture models, by nature, allow for the concept of subsets  in the expression values of each tag. dysregulation of genes in disease processes such as cancer are often observed in only a proportion of profiled samples, and these will be naturally identified during model fitting. this property can also be utilized to identify sets of co-expressed genes.

RESULTS
goodness of fit
in order to evaluate the efficacy of a mixture model approach, a comparison of the goodness of fit of this and previously described models on  <dig> sets of biological replicates from publicly available sage data was performed .

goodness of fit was assessed for: 1) the canonical log-linear  model, 2) negative binomial  model, and 3) k-component poisson mixture model . since maximum likelihood estimation  is used to fit each of these models, the log-likelihood was the basis for assessing relative goodness of fit. a comparison of the akaike information criterion   <cit>  and bayesian information criterion   <cit>   was performed on each of the datasets .

sage tag counts from fifteen sets of biological replicates were fit to log-linear , negative binomial , and poisson mixture models. the table contains the number of replicates , tags tested, and mean number of mixture components . for each model, mean goodness of fit scores calculated using akaike's information criterion  and bayesian information criterion  are shown. for both scores, a lower value indicates a better fit.

as expected, the canonical poisson model, which does not account for excess variance, performs poorly in all cases. the poisson mixture model consistently outperforms the negative binomial model regardless of the metric used. the competitiveness of the negative binomial model is perhaps not surprising since a comparison of the fit of these two models to simulated data indicates that the negative binomial can often fit better to data generated from a two-component poisson mixture. this becomes more problematic as the component means draw closer . however, several hypotheses can be tested to further strengthen the case for the mixture model approach. these are considered in turn.

tags with ambiguous mappings are represented by a greater number of components
consider an idealized situation where a gene's expression can take on one of two states . a significant proportion of sage tags are ambiguous  and, under the idealized model, would result in tag counts that are modelled by 2g components . therefore, the number of components in the mixture should be higher for ambiguous tags.

simply partitioning the data into ambiguous and unambiguous tags and comparing the number of components is unlikely to be informative since, for any given ambiguous tag, it is not known how many of the possible genes are actually expressed. however, two normal brain libraries used in this study were generated using longsage , which provides  <dig> base pairs of information rather than  <dig>  the tag sequences in these libraries were shortened before inclusion in the normal brain dataset used in the previous section. however, by comparing the shortened tag list to the original library, tags that actually correspond to two or more longsage tag sequences  were identified. tags counts of one or two were considered artefacts of pcr amplification or sequencing and were not used in this determination.

the number of ambiguous and unambiguous tags was tallied for each estimated number of components . ambiguous tags are represented more highly in the set of model fits that consist of a larger number of components. this effect, which is statistically significant, is consistent with the mixture model hypothesis.

expressed ambiguous and unambiguous  <dig> base pair tags for two longsage libraries were distinguished based on the number of  <dig> base pair sequences that give rise to the same tag. the tags in each of these two groups were binned according to the number of estimated mixture components. the chi-square statistic was used to test the null hypothesis that these two groups are equivalent.

component assignment of libraries is non-random
if the mixture model approach holds, then the poisson components should cluster the libraries into recurring groups. such an enrichment of certain component assignments would be expected for a number of reasons. two possibilities are: a) if one or more libraries are mislabelled, the tag expression in those libraries should show a preferential assignment to a separate component; and b) if the genes corresponding to a set of tags are co-expressed, the component assignment should be similar amongst these genes. conversely, if the negative binomial model is more appropriate then component assignments should essentially be random, since the distribution assumed to give rise to biological variability is continuous and unconditional.

for each of the datasets, the component assignments for tags where the estimated number of components is two were tallied. the individual assignment was based on the component with the highest posterior probability, given a tag count and library size. in all cases, there were a significant number of tags where the parent libraries were partitioned into the same two components . for example, in the aml libraries containing the cytogenetic abnormality t, of the  <dig> tags that had expression that could be fit to two poisson components,  <dig> were partitioned in the form -++-- . in other words, almost half of the tags that fit to two components were assigned to a single component configuration - <dig> =  <dig> such configurations are possible).

for each set of biological replicates, the top one or two component states were selected from tags where the estimated number of components is  <dig>  one component was represented with -, the other with + . the significance was calculated using a zero-truncated binomial test. the number of possible ways for the libraries to be assigned to the two components is - <dig>  where n is the number of libraries.

determining differentially expressed genes
in previously described overdispersed models, the identity of a library is included a priori as a model covariate. significance is then determined by testing the null hypothesis that the fitted β coefficient for this covariate is zero  <cit> . a bayesian significance score has also described, although this was developed using a beta-binomial model  <cit> . in contrast, the poisson mixture model does not require the identity of the libraries be included . rather, once a mixture model has been fit, the posterior probabilities of membership in a particular component given the observed tag counts can be used to determine how well the components can differentiate between two or more sample types . here, a score is presented based on the confidence that a sample is of type ω given that it arises from component k. using bayes theorem, one can derive the following expression 

 p=∑jωτjk/∑jτjk
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgqbaucqggoaakiigacqwfjpwdcqgg8bafcqwgrbwacqggpaqkcqgh9aqpdawcgaqaamaaqahabagae8hxdq3aasbaasqaaiabdqgaqjabdugarbqabaaabagaemoaaogabagae8xydchaniabgghildaakeaadaaeqbqaaiab=r8a0naabaaaleaacqwgqbgacqwgrbwaaeqaaaqaaiabdqgaqbqab0gaeyyeiuoaaaaaaa@4781@ 

where ω is the set of libraries corresponding to some label of interest  and τjk is the posterior probability of the tag count from library j arising from component k. using this expression, one can determine which tags have a set of mixture components that are closely linked with the sample type of interest.

to illustrate, sage libraries from normal brain  and ependymoma   were analyzed using both the overdispersed log-linear and poisson mixture models. in the former case, significance was calculated using the method described in  <cit>  . in the latter case, the method described above was used. a plot of the two sets of scores shows a moderate correlation and tags that are found highly significant in one test tend to be so in the other .

however, a number of observations are found significant using the overdispersed log-linear model and not the poisson mixture model, and vice versa. a closer look at the most extreme examples illustrates the superior performance of the mixture approach . in the first example, tag acaacaaaga seems clearly expressed in normal libraries, but is completely abolished in the ependymoma libraries. however, according to the overdispersed model, the observation is not at all significant . the mixture model, however, produces a confidence score of  <dig> %, which suggests this tag is highly informative with respect to sample type. this example demonstrates the difficulty that the log-linear model has with fitting groups where tag counts are zero, a problem that is even more pronounced when using a logistic regression model .

in the second example, tag cagttgtggt clearly has increased expression in some libraries from both the normal and ependymoma groups. however, according to the overdispersed model, the observation is highly significant . the mixture model, however, produces a confidence score of  <dig> % which is only nominally better than chance. this example demonstrates how the log-linear model seems to downweight the occasional extreme observation in one group, even if it is in agreement with observations in the other group. this can result in candidate lists based on the log-linear significance containing tags that have extreme observations that occur at a higher rate in one group over another, which are typically of little interest.

similar results were obtained when comparing to the bayes error rate described in  <cit> . again, a moderate correlation is seen and tags found highly significant in one test tend to be so in the other . overall, the bayes error rate is in better agreement with the mixture model confidence score and appears to be more robust in assessing tags with zero counts in one group. however, the assumption of a hierarchical model  used to calculate the bayes error rate versus a poisson mixture model results in differences between the two methods. two examples, analogous to those described above, are highlighted . in both cases, the poisson mixture model appears to give confidence values that are in better agreement with the observations.

discussion
the exploration of statistical approaches to sage analysis is important since the number of studies using the technology has resulted in a continuing rise in the amount of available data. the notion of sampling variability being the predominant source of "within"-library variability and distinct components being the predominant source of "between"-library variability is reassuring for investigators who choose the sage technique to obtain a comprehensive profile of gene expression in a limited number of samples. nevertheless, there is certainly a contribution by a latent biological variability as evidenced by the increased performance of the negative binomial as the number of libraries increases. however, this work demonstrates that a simple overdispersed model may overstate this effect, and that certainly there is a clustering of expression into distinct components, which are then sampled. this is consistent with the view of gene transcription for any one locus consisting of  inactivated or activated state. the same idea holds for some known mechanisms of genetic disease, such as loss of heterozygosity  or amplification of a particular locus .

for this reason, it is recommended that investigators try the mixture model approach in comparisons of groups of biological replicates. failing this, some of the difficulties that can be encountered with the negative binomial model can be lessened by: a) setting a tolerance for how much overdispersion  is acceptable in a final list of candidate tags, although such a cutoff would be somewhat arbritrary; and b) add a small value to the tag count to avoid the problems the model has with groups consisting of many zero counts. one strategy is to assume equal odds that the next tag drawn is the one of interest by adding  <dig> to the count, and  <dig> to the library size /) .

in the future, it may be worthwhile to combine both approaches by defining a negative binomial mixture model. however, at this point, such an approach is unlikely to provide significant improvement given the small number of libraries in a typical set of available biological replicates. in addition, applying the concept of "information sharing" between tags may provide estimates of statistically informative variables that apply library-wide, and could be utilized to improve the power of the method described in this paper  <cit> .

CONCLUSIONS
the poisson mixture model appears to be a rational means to represent sage data that are biological replicates and as a basis to assign significance when comparing multiple groups of such replicates. the use of a mixture model can improve the process of selecting differentially expressed genes, and provide a foundation for ab initio identification of co-expressed genes and/or biologically-relevant sample subsets.

