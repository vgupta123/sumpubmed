BACKGROUND
high-density single nucleotide polymorphisms  covering the whole genome are available in animal and plant breeding to estimate breeding values. first, individuals having snp genotypes and trait phenotypes are used to estimate snp effects , and then genomic estimated breeding values  are obtained for every genotyped individual using those effects. currently, the number of snp genotypes per individual amounts to tens of thousands, but, owing to the rapid advances in genomics, it will soon exceed millions at comparable costs. the statistical challenge is to estimate snp effects in a situation where the number of training individuals is much smaller than the vast number of snps. for this purpose, meuwissen et al.  <cit>  presented two hierarchical bayesian models, termed bayesa and bayesb, that are discussed extensively in animal and plant breeding research . the reason for their popularity is that their implementation as single site locus sampler is straightforward, computing time is reasonable, and both simulations  <cit>  and real data analyses  <cit>  have shown that linkage disequilibrium  between snps and quantitative trait loci  is exploited better than with least-squares or ridge-regression; hence, accuracies of gebvs were higher for these bayesian methods. gianola et al.  <cit>  pointed to statistical drawbacks of bayesa and bayesb that center around the prior for snp effects. a priori, a snp effect is zero with probability π, and normally distributed having mean zero and a locus-specific variance with probability . this locus-specific variance has a scaled inverse chi-square prior with few degrees of freedom and a scale parameter, , that is often derived from an assumed additive-genetic variance under certain genetic assumptions  <cit> . it can be shown that the full-conditional posterior of a locus-specific variance has only one additional degree of freedom compared to its prior regardless of the number of genotypes or phenotypes. this conflicts with the concept of bayesian learning, and as a consequence, shrinkage of snp effects depends strongly on  as detailed by  <cit> . this problem becomes even more important with increasing snp density as shown later. there are at least two possibilities to overcome this drawback: first, a single effect variance that is common to all snps is used instead of locus-specific variances. then, as shown later, the influence of  is smaller. second, the scale parameter of the inverse chi-square prior for locus-specific variances is treated as an unknown with its own prior. the first strategy is referred to as bayesc in the following and the second as bayesd.

another drawback of bayesa and bayesb is that the probability π that a snp has zero effect is treated as known. in bayesa, π =  <dig> so that all snps have non-zero effect, whereas in bayesb, π >  <dig> to accommodate the assumption that many snps have a zero effect. the shrinkage of snp effects is affected by π, and thus should be treated as an unknown being inferred from the data. in the following, π is treated as an unknown in bayesc and bayesd, which will be referred to as bayescπ and bayesdπ, respectively. finally, the question arises how the estimated π is related to the number of qtl.

the objective of this study was to present two bayesian model averaging methods that address the drawback of bayesa and bayesb regarding the impact of  on shrinkage of snp effects, and treat π as an unknown by using bayescπ and bayesdπ. simulations were conducted to analyze estimates of π for the ability to infer the number of qtl depending on the genetic architecture of a quantitative trait and training data size. field data from north american holstein bulls were used to estimate π for milk production traits, and to compare accuracies of gebvs obtained by bayesa, bayesb, bayescπ, bayesdπ, and ridge-regression. cross-validations were applied in a setting where the additive-genetic relationships between training and validation bulls were low so that the accuracies of gebvs were dominated by ld information. this criterion reveals the potential of genomic selection better than accuracy obtained by using training data sets that contain close relatives of validation bulls such as parents, full and half sibs. the reason is that future selection candidates in cattle breeding programs may not have close relatives in training when genomic selection is applied early in life  <cit> .

methods
statistical model
the general statistical model can be written as  

where y is an n ×  <dig> vector of trait phenotypes, x is an incidence matrix of the fixed effects in β, u is a vector with polygenic effects of all individuals in the pedigree, k is the number of snps, zk is an n ×  <dig> vector of genotypes at snp k, ak is the additive effect of that snp, and e is a vector of residual effects. in this study, the only fixed effect in β was the overall mean μ, and snp genotypes were coded as the number of copies of one of the snp alleles, i.e.,  <dig>   <dig> or  <dig> 

prior specifications
the prior for μ was a constant; the prior for u|a,  was normal with mean zero and variance , where a is the numerator-relationship matrix and  is the additive-genetic variance not explained by snps. the prior for ak depends on the variance, , and the prior probability π that snp k has zero effect:   

the models of this study differed in their specifications for π and . in bayesa, bayesb and bayesdπ,  denotes that each snp has its own variance. each of these variances has a scaled inverse chi-square prior with degrees of freedom νa and scale , and thus with probability  the marginal prior of ak|νa,  is a univariate student's t-distribution, . this is the model hierarchy proposed by  <cit> , where  was derived here from the expected value of a scaled inverse chi-square distributed random variable, ; hence,   

where νa was  <dig>  as in  <cit> , and  is the variance of the additive effect for a randomly sampled locus, which can be related to the additive-genetic variance explained by snps, , as   

where pk is the allele frequency of snp k  <cit> . bayescπ and bayesdπ are constructed as follows to address the lack of bayesian learning in bayesa and bayesb.

in bayescπ, , i.e., the priors of all snp effects have a common variance, which has a scaled inverse chi-square prior with parameters νa =  <dig>  and , where  is derived as for bayesa and bayesb. as a result, the effect of a snp fitted with probability  comes from a mixture of multivariate student's t-distributions, . for example, assume that only  <dig> snps are used in the analysis, resulting in  <dig> possible models in which the effect of snp  <dig>  say, is not zero . each of these models has a different multivariate t-prior, where the univariate t-distribution is regarded here as a special case of the multivariate distribution. thus, across the  <dig> models, the effect of snp  <dig> comes from a mixture of multivariate t-distributions.

in bayesdπ, the degrees of freedom for the scaled inverse chi-square prior of the locus-specific variances, νa, are treated as known with a value of  <dig>  as in all other models, but the scale parameter, , is treated as an unknown with gamma prior. thus, for a snp fitted with probability , its effect comes from a mixture of univariate student's t-distributions. in this case, the mixture is due to treating  as unknown with a gamma prior.

the other parameter that must be specified for the prior of ak in  is π, which is treated as known with π =  <dig> for bayesa and, in this paper, with π =  <dig>  for bayesb. in bayescπ and bayesdπ, in contrast, π is treated as an unknown with uniform prior.

the prior for the residual effects is normal with mean zero and variance , and the priors for  and  are scaled inverse chi-square with arbitrarily small value of  <dig>  for the degrees of freedom, and scale parameters  and , respectively. these scale parameters were derived by the formula , where  is the a priori value of  or .

inference of model parameters
two markov chain monte carlo  algorithms were implemented to infer model parameters: one for bayesa, bayesb, and bayesdπ and the other one for bayescπ. the differences between these two algorithms result from how the variances of snp effects are modeled and lead to different strategies for including a snp in the model.

algorithm for bayesa, bayesb and bayesdπ
bayesa is a special case of bayesb with π =  <dig>  the variables μ, ak, u, , , as well as  and π of bayesdπ are sampled by gibbs-steps using their full-conditional posteriors, whereas the decision to fit snp k into the model and the value of its locus-specific variance, , are sampled by a metropolis-hastings  step. in contrast to meuwissen et al.  <cit> , who implemented bayesa using gibbs sampling, bayesa is implemented here as bayesb with π =  <dig> and a reduced number of mh steps.

the mh step used in this study differs from that described for bayesb in  <cit> . in their implementation, the candidate for  is sampled from the scaled inverse chi-square prior with probability , whereas a model without snp k is proposed with probability π. in the latter case both ak and  are equal to zero. the acceptance probability for the candidate sample in iteration t from the currently accepted variance, , to the candidate value, , is  

where  and  denote densities of the data model given  and , respectively, and all other model parameters denoted by else as in sorensen and gianola  <cit> , except for ak which is integrated out here. values of π close to  <dig> lead to candidate samples that are mostly  <dig>  and thus in poor mixing. to increase the probability of non-zero candidates, the mh step is repeated  <dig> times in each iteration of the mcmc algorithm.

the proposal distribution for  used here is different from the prior. regardless of π, the candidate for  is sampled with probability  <dig>  from a scaled inverse chi-square, and with probability  <dig>  from a point mass on zero, which reduces the number of mh steps required for mixing. the number of mh steps used here was  <dig>  further, the scale parameter  of the candidate is chosen depending on whether snp k was in the model in the previous iteration t -  <dig> or not, i.e., whether  or equals to zero:  

the acceptance probability is  

where the prior for  is  

and its proposal is  

this proposal is expected to have better mixing than that of  <cit>  for extreme values of π. the acceptance probability is equivalent to equation  <dig>  in godsill   <cit> .

after  has been updated, ak is sampled from   

where  and . after  and ak have been updated for all k snps, the polygenic effects in u are sampled by the technique of  <cit>  as described in  <cit>  using an iterative algorithm to solve the mixed model equations;  is sampled from a scaled inverse chi-square with degrees of freedom  and scale , where nu is the number of individuals in the pedigree;  is sampled from a scaled inverse chi-square with  and , where n is the number of training individuals. in bayesdπ,  is sampled from a gamma with shape  and scale , where m is the number of snps fitted in the model for iteration t. the parameters of this gamma posterior show that information from all loci contributes to the posterior of the unknown scale parameter and therefore through it to the posteriors of the locus-specific variances. finally, π is drawn from beta +  <dig>  m + 1). the starting value for π was  <dig> .

algorithm for bayescπ
the mcmc algorithm for bayescπ consists of gibbs steps only, where those for μ, u, , , and π are identical to those in bayesdπ. in contrast, the decision to include snp k in the model depends on the full-conditional posterior for the indicator variable δk, which is introduced for this very purpose. this indicator variable equals  <dig> if snp k is fitted to the model and is zero otherwise. following general bayesian rules, the full-conditional posterior probability that δk =  <dig> is  

where p = pp;  denotes the density of the data model given that snp k is fitted with common effect variance  and the currently accepted values of all other parameters, p is the density of the data model without snp k, p = π is the prior probability that snp k has zero effect, and correspondingly p =  <dig> - π. the posterior for ak is identical to  except that  replaces the locus-specific variance in ck so that . the common effect variance is sampled from a full-conditional posterior, which is a scaled inverse chi-square with degrees of freedom  and scale , where m is the number of snps fitted with non-zero effect in iteration t.

the starting value for π, π <dig>  determines  as can be seen from equations  and . however,  can affect to what extent π is used to shrink snp effects, hence the estimate of π. as  increases with π <dig>  less shrinkage is expected through , but shrinkage can be increased with larger π values, which can be regarded as a compensation for the lower shrinkage through . to examine the effect of π <dig> in bayescπ, results are given for π <dig> equal to  <dig> ,  <dig>  and  <dig> . the degrees of freedom of the scaled inverse chi-square prior, νa, also determine  through formula , and thus can affect π estimates. however, in this study νa was not varied, but held constant at  <dig> .

impact of  on shrinkage in bayescπ compared to bayesa and bayesb
the parameters of this full-conditional distribution can be used to contrast the impact of  on shrinkage in bayescπ compared to that in bayesa and bayesb. in the latter, the posterior of the locus-specific variance of snp k is a scaled inverse chi-square distribution with degrees of freedom  and scale  <cit> . that is, that posterior has only one more degree of freedom than the prior. in contrast, the full-conditional of the posterior of the common effect variance in bayescπ will have more degrees of freedom when m >  <dig> and the scale is less influenced by  and more a function of the information contained in the data through .

the impact of  on the shrinkage of snp effects, especially for bayesa, increases with snp density. the scale parameter, , decreases with increasing number of snps in the analyses due to , which depends on π. hence, small snp effects are regressed more towards zero than with a smaller number of snps in the model. consider a chromosomal segment where a qtl is surrounded by many snps that are all in ld with the qtl. in the worst case, all these snps are collinear, which might occur for low effective population sizes. the qtl effect, even if large, will be distributed to all snps such that each snp effect is small. as these effects are strongly regressed towards zero, the qtl effect can be completely lost.

software implementation
these bayesian model averaging methods were implemented in gensel software  <cit>  and are available for web-based analysis of genomic data. it is accessible through bigs.ansci.iastate.edu, and a user manual is attached to this manuscript in additional file  <dig> 

simulations
simulations were conducted to analyze estimates of π from bayescπ and bayesdπ depending on the genetic architecture of an additive quantitative trait, and training data size. two types of scenarios were simulated in this study. the first was an ideal scenario in which all loci were in mutual linkage equilibrium and genotypes of both snps and qtl were available for training and validation. the true value of π is the number of qtl divided by the total number of loci in this analysis. the second was a realistic scenario in which the loci were in ld and only snps were modeled. as a consequence the true value of π was unknown. in both scenarios, loci were biallelic with initial allele frequency of  <dig> , and qtl effects were sampled either from a standard normal or from a gamma with shape  <dig>  and scale  <dig>  as in  <cit> . figure  <dig> depicts the cumulative distribution functions of these two distributions to illustrate the different effect sizes simulated. the sampled qtl effects were standardized before training to exhibit the additive-genetic variance calculated from a specified heritability and a residual variance of  <dig>  trait phenotypes were simulated by adding residual effects sampled from a standard normal to the sum of the genotypic values. simulations were varied with different numbers of qtl and training data sizes, which was either  <dig>  or  <dig>  individuals. the mcmc algorithms were run for  <dig>  iterations with a burn-in of  <dig>  iterations. a higher number of iterations did not change the results.

in the ideal simulations, a total of  <dig>  loci were simulated as if they were all located on different chromosomes to ensure linkage equilibrium. the number of qtl among those loci was  <dig>   <dig>  or  <dig>  and trait heritability was  <dig> . the realistic simulations started with a base population of  <dig>  individuals that were randomly mated over  <dig>  generations to generate ld from mutations and drift. individuals of generation  <dig>  were used as founders of a real pedigree from the north american holstein population, which included  <dig>  bulls used in the real data analysis. this simulated ld similar to that in real livestock populations  <cit> . individuals from the last generation of pedigree individuals were parents of the training individuals, with each parent represented once. the simulated genome consisted of a single chromosome of length  <dig> m that had  <dig>  evenly-spaced snps and either  <dig>   <dig>  or  <dig> qtl that were randomly distributed on the chromosome. the mutation rate was  <dig> •10- <dig> for both snps and qtl, which is larger than estimates of actual mutation rates to ensure that a sufficient number of loci was segregating after  <dig>  generations of random mating; it can be shown that mutation rate has only a small effect on ld in this simulation using the formula derived by  <cit> . recombinations were modeled according to a binomial map function, where the maximum number of uniformly and independently distributed crossovers on a chromosome of  <dig> m was  <dig>  <cit> , i.e., assuming interference. the proportion of segregating loci after  <dig>  generations of random mating was  <dig> , hence the number of segregating qtl in the scenarios with  <dig>   <dig> and  <dig> qtl was  <dig> ,  <dig>  and  <dig>  on average, respectively. to select  <dig>  snps for training and validation, the chromosome was first divided into  <dig>  evenly-spaced bins and then one snp with minor allele frequency greater than  <dig>  was randomly selected in each bin. the heritability was varied with the values  <dig> ,  <dig>  and  <dig>  to modify the size of qtl effects. all simulations were repeated  <dig> times.

real data analyses
data from north american holstein bulls were used to gain information about the number of qtl affecting quantitative traits in real populations and to compare the different bayesian methods with respect to gebv accuracy that results mainly from ld information.

genotyped bulls
the data set consisted of  <dig>  progeny tested north american holstein bulls that were genotyped for the illumina bovine50k array, excluding bulls that had more than 5% missing genotypes. de-regressed breeding values obtained from the official genetic evaluation of the usda in august  <dig> were used as trait phenotypes and were available for the quantitative traits milk yield, fat yield, protein yield and somatic cell score. the de-regressed proofs of the bulls used had a reliability greater than  <dig>  and the square root of the reliability was used to weight residual effects  <cit> . the average reliability of milk, fat and protein yield was  <dig>  and that of somatic cell score  <dig> . furthermore, a pedigree, containing the bulls in cross-validation and their ancestors born after  <dig>  was available to model polygenic effects and to quantify additive-genetic relationships between training and validation bulls.

snp data
snps were selected for the analyses based on minor allele frequency , proportion of missing genotypes , proportion of mismatches between homozygous genotypes of sire and offspring  and hardy-weinberg equilibrium . the total number of snps in the analyses was  <dig> .

training and validation data sets
bulls born between  <dig> and  <dig> were used for training, whereas  <dig> bulls born before  <dig> and with additive-genetic relationships to the training bulls smaller than  <dig>  were used for validation. the reason for generating this cross-validation scenario was that ld rather than additive-genetic relationships was to determine the accuracy of gebvs. the contribution of ld information to the estimates of snp effects is sensitive to the size of the training data set, and thus  <dig> ,  <dig>  and  <dig>  training bulls were randomly selected from the bulls born between  <dig> and  <dig> 

the mcmc algorithms were run for  <dig>  iterations with a burn-in of  <dig>  iterations for  <dig>  training bulls,  <dig>  iterations with a burn-in of  <dig>  iterations for  <dig>  training bulls, and  <dig>  iterations with a burn-in of  <dig>  iterations for  <dig>  training bulls. these numbers of iterations were sufficient in that a higher number did not change the results. posterior distributions were visually inspected for convergence. in addition to the gebvs obtained by the bayesian model averaging methods, breeding values for the validation bulls were estimated using an animal model with the numerator-relationship matrix  <cit> , which provided standard pedigree-based blup-ebvs  to quantify the genetic-relationship information from the pedigree. an animal model with a genomic relationship matrix  <cit>  was used to obtain gebvs , which is equivalent to ridge-regression.

evaluation criteria
estimates of π were studied as , where k is the number of loci used in the statistical analysis. this represents the posterior mean of the number of loci fitted in each iteration of the mcmc algorithm , which is more practical than π for comparisons of scenarios that differ in the number of simulated qtl. the reason is that the true value of π is usually unknown unless qtl are among the loci in the model. the accuracy of gebvs was estimated by correlation between gebvs and de-regressed proofs divided by the average accuracy of de-regressed proofs of the validation bulls. the gebv of validation bull i was calculated as  

where zik is the genotype score  for bull i at snp k and  is the posterior mean of the effect at that locus. the ebvs from p-blup and g-blup were obtained from solutions of the animal model.

RESULTS
ideal scenario
the starting value for π was  <dig> . results are based on  <dig> replicates of the ideal simulation in which all loci were in linkage equilibrium and both snps and qtl were modeled

realistic scenario
results are based on  <dig> replicates of the realistic simulation in which heritability was  <dig> , loci were in linkage disequilibrium, and only snps were modeled

starting value for π was  <dig> . results are based on  <dig> replicates of the realistic simulation in which loci were in linkage disequilibrium and only snps were modeled

real data analyses
additive-genetic relationships between training and validation bulls were small: no validation bull had an additive-genetic relationship to a training bull exceeding  <dig> . the distribution of the maximum additive-genetic relationships between training and validation bulls had a lower quartile, median, and upper quartile of  <dig> ,  <dig>  and  <dig> , respectively. the main cause of the low additive-genetic relationships was a separation of about three generations between the bulls of both data sets, because 90% of the validation bulls were born before  <dig>  table  <dig> shows accuracies of p-blup, g-blup, and the bayesian model averaging methods according to the quantitative trait and training data size. the accuracies of p-blup for fat and protein yield as well as somatic cell score were close to zero as expected, but the accuracy for milk yield was unexpectedly high with  <dig>  and  <dig>  for  <dig>  and  <dig>  training individuals, respectively.

starting value of π in bayescπ was  <dig> .

standard error, 

accuracies of gebvs were similar for the different methods with the following exceptions: bayesb with π =  <dig>  had the lowest accuracies for all traits but fat yield, and g-blup had the lowest accuracies for fat yield. furthermore, the accuracies for milk yield obtained by bayescπ tended to be lower than for g-blup, bayesa and bayesdπ. in general, bayesa tended to give the highest accuracies for all traits except for fat yield. the accuracies of bayescπ did not differ depending on the starting values for π .

the accuracy of gebvs improved markedly with training data size for milk yield, fat yield and somatic cell score from  <dig>  to  <dig>  bulls, but improved only slightly or reduced from  <dig>  to  <dig>  bulls. the increase in accuracy with training data size for protein yield was less than for the other traits from  <dig>  to  <dig>  bulls, but tended to be more from  <dig>  to  <dig>  bulls. somatic cell score had the highest relative increase in accuracy of all traits because accuracies were lowest for  <dig>  training bulls. interestingly, g-blup had the lowest accuracy for somatic cell score with  <dig>  training bulls, but the increase was largest such that the accuracy for  <dig>  bulls was as high as for bayesa.

the posterior distributions for nsnp  were unimodal, symmetric, and standard deviations decreased notably with increasing training data size as in table  <dig>  exceptions were the posterior distributions for protein yield and somatic cell score of bayescπ with  <dig>  training bulls, which were bimodal and rather flat. although the accuracies of bayescπ and bayesdπ were very similar, they fitted very different numbers of snps . as in the realistic simulations, nsnp from bayesdπ was insensitive to training data sizes for all traits, whereas bayescπ showed clear trends with training data size that differed across traits; nsnp was comparatively low for milk and fat yield and increased with training data size, and estimates were very similar for the different starting values of π, π <dig>  nsnp always decreased with training data size for protein yield, but estimates increased for all training data sizes as π <dig> decreased. for somatic cell score, however, the trends changed depending on π0; nsnp increased with training data size for π <dig> =  <dig> , but decreased with lower π <dig> values.

discussion
two bayesian model averaging methods that address the statistical drawbacks of bayesa and bayesb were developed for genomic prediction. these two models were termed bayescπ and bayesdπ to emphasize that the prior probability π that a snp has zero effect was treated as an unknown. the objectives of this study were to evaluate the ability of these methods to make inferences about the number of qtl  of a quantitative trait by simulated and real data, and to compare accuracies of gebvs from these new methods compared to existing methods.

simulations
in ideal simulations, all loci were in linkage equilibrium and both snps and qtl were modeled. bayescπ was able to distinguish the qtl that had non-zero effects from the snps that had zero effects as training data size increased and when qtl effects were normally distributed. in contrast, when qtl effects were gamma distributed many qtl remained undetected. this may have been because the gamma distribution generated fewer large effects and more small effects than the normal . further, the prior of snp effects in bayescπ given the common effects variance was normal and not gamma; a gamma prior may produce better results and should be investigated in a subsequent study. in conclusion, even in this ideal case the estimate of  obtained from bayescπ is a poor indicator for nqtl, unless the qtl distribution is normal. bayesdπ was insensitive to nqtl and inappropriate to estimate nqtl.

in realistic simulations, snps and qtl were in ld and only the snp genotypes were known. as expected, bayescπ fitted more snps than there were qtl, because every qtl was in ld with several snps. however, the number of snps fitted per qtl depended on both training data size and effect size of a qtl, which was varied here by the distribution of qtl effects, h <dig> and nqtl; the size of simulated qtl effects increased with h <dig> and decreased with nqtl. if qtl effects were generally large and easy to detect , nsnp was small with  <dig>  training individuals and increased with training data size. in addition, the larger a qtl effect, the more snps were fitted per qtl . the cause for these findings may be that snps in low ld with the qtl were more likely to be fitted as either qtl effect size or training data size increased. the increase in nsnp with training data size could also have been the result of detecting qtl with smaller effects. if qtl effects were smaller and less easy to detect , nsnp was larger with  <dig>  training individuals, which may be explained by false positive snps in the model, because the power of detection was likely to be low. in contrast to h <dig> =  <dig> , nsnp decreased substantially with training data size. however, the fact that nsnp increased with training data size for h <dig> =  <dig> , normally distributed qtl effects, and a starting value of π =  <dig>   points to another explanation why many snps were fitted with small qtl effect size or small training data size: a higher number of snps explains differences between training individuals better than a smaller number, and thus more snps were required to explain those differences as training data size increased. in conclusion, bayescπ overestimates nqtl, the extent depending on the size of qtl effects, which makes inference difficult. however, information about nqtl can be gained by analyzing the trend of nsnp with training data size, and starting with different π values. furthermore, as snp density increases in the future, overestimation of nqtl is expected to be smaller, because ld between snps and qtl will be higher such that fewer snps are modeled per qtl. sufficiently high snp density guarantees near perfect ld between at least one snps and each qtl in which case the scenario of the ideal simulations will be approached.

real data analysis
number of qtl and size of qtl effects
in agreement with the realistic simulations, estimates of π from bayesdπ were insensitive to both trait and training data size . bayescπ, in contrast, showed clear differences for both: nsnp increased with training data size for milk and fat yield, and decreased for protein yield and somatic cell score. thus, milk and fat yield may have more qtl with large effects than protein yield and somatic cell score, which can be derived from the trends of nsnp in the realistic simulations. this is also supported by the accuracies of gebvs where milk and fat yield had a higher accuracy than protein yield and somatic cell score. furthermore, fat yield may have more qtl with large effect than milk yield, because both the increase of nsnp from  <dig>  to  <dig>  training bulls and accuracy of gebvs was higher for fat yield.

the number of snps in the model estimated by bayescπ may primarily result from the qtl with the largest effects, assuming that qtl with small effects were not detectable. the rather low accuracies of gebvs and especially the low increase in accuracy from  <dig>  to  <dig>  bulls may also point to this conclusion, because many more training individuals seem to be necessary to estimate small qtl effects. another reason may be that ld between snps and qtl was still too low, but this will change as snp density increases; qtl with large effects will be estimated with fewer snps and additional qtl with smaller effect will be detected.

as mentioned earlier, a possible overestimation of nqtl results from the fact that several snps are in ld with a qtl, where each of these snps explains a part of the qtl effect. these snps are likely to surround the qtl on the chromosome, and thus nqtl can be estimated more precisely by calculating the variance of gebvs explained by the effects of all snps in a specified chromosomal region. this can be done by defining a window containing a certain number of consecutive snps that are used to calculate this variance. by sliding the window over the chromosome and observing peaks that are higher than for single snps, nqtl may be inferred better. this can be done with all methods that estimate snp effects.

comparison of the accuracy of gebvs
north american holstein bulls were partitioned into training and validation data sets such that bulls of both data sets were as unrelated as possible. as a result, the contribution of additive-genetic relationships to the accuracy of gebvs was negligible for fat yield, protein yield and somatic cell score as demonstrated by the low accuracy of p-blup. however, that accuracy was unexpectedly high for milk yield, which might be an artifact of previous selection for milk yield because genotypes in the validation data set were only available from selected parents. accuracies of gebvs were similar for the different methods, and no one outperformed all the others across all traits or training data sizes. nevertheless, bayesa performed remarkably well for this snp density despite the statistical drawback of bayesa as described by  <cit> . however, as demonstrated in  <cit> , it is important that the degrees of freedom used for the scaled inverse chi-square prior of the locus-specific variances express little prior belief. bayesa always fits all snps, hence the shrinkage of snp effects results completely from the locus-specific variances, and, in contrast to the other methods, snp effects are not fully shrunk to zero. thus, even snps that truly have zero effects are expected to have small estimated effects adding noise to the gebvs. this applies also to g-blup, which is equivalent to ridge-regression fitting all snps with equal variance. this did not seem to affect the accuracy of gebvs here, but in the simulations of  <cit>  bayesb performed better than bayesa and ridge-regression. the explanation may be that the traits analyzed here are determined by many more qtl than in those simulations. thus, bayesa may be inferior to bayescπ and bayesdπ for traits that are determined by only a few qtl and when many more snps effects are modeled as snp density increases. applying bayesa to the data sets of the realistic simulations with only  <dig> qtl confirmed its inferiority to bayescπ and bayesdπ.

treating π as known with a high value as in bayesb may be a poor choice. this agrees with daetwyler et al.  <cit>  who reported that g-blup outperformed bayesc with a fixed π when the number of simulated qtl was large. this can be explained partly by the fact that  <cit>  considered the gebv accuracy of the offspring of training individuals, meaning that genetic-relationships were important; these were captured better by the snps, when more snps were fitted as in g-blup  <cit> . note further that bayesc with π =  <dig> is similar to g-blup. consider ridge-regression as the equivalent model of g-blup to see this similarity. both methods are equivalent either 1) if the single effect variance of bayesc is treated as known, 2) if νa is very large and  equals to the single effect variance of ridge regression, or 3) if the single effect variance of ridge regression is treated as unknown with own scaled inverse chi-square prior. thus the lower accuracy for bayesc in that study results most likely from treating π as known. another reason may be that the scale parameter of the inverse chi-square prior for the common effect variance in  <cit>  did not depend on the additive-genetic variance nor on the fixed π value as proposed by  <cit> .

the finding that bayescπ and bayesdπ give similar accuracies but different π values reveals that the two methods have different mechanisms for shrinking snp effects. bayesdπ primarily used the locus-specific variances, whereas bayescπ was only able to vary the shrinkage at different snps by using δk; if a snp is not fitted to the model the effect is shrunk completely to zero, otherwise they are all shrunk using the same ratio of residual to common effect variance. in principle, bayesdπ is expected to be more flexible in shrinking snp effects because it could use both locus-specific variances and δk for this purpose. the poor mixing of π in bayesdπ indicates that locus-specific variances dominated over δk, which may explain why π is not an indicator for nqtl.

effect of training data size on bayesian model averaging
another insight into the mechanisms of bayesian model averaging comes from the large increase in accuracy of gebvs with training data size obtained by bayesb for milk yield. the parameter π was treated as known with value  <dig>  resulting in about  <dig> snps fitted in each iteration of the mcmc algorithm for both  <dig>  and  <dig>  training bulls . this indicates that π is a strong prior for δk =  <dig>  therefore, setting π =  <dig>  is analogous to searching for models that fit about  <dig> snps in each iteration of the algorithm and to average them. these models change from one iteration to another as some snps are removed from the model, while others are included. this interchange of snps, however, is expected to be more frequent with a small training data size, because the power to detect significant snps is low. on the other hand, if the training data size is large, fewer snps are interchanged less often so that models differ less from one iteration to the other. this becomes most apparent in the increasing number of snps having moderate to high model frequency as training data size increased from  <dig>  to  <dig>  bulls as shown in figure  <dig>  the implication is that the effects of those snps were less shrunk with larger training data size, whereas effects of all other snps were shrunk more.

comparison of gebv accuracy with other studies
accuracies of gebvs reported by  <cit>  and  <cit>  for the north american and australian holstein populations, respectively, are not comparable to the accuracies found here. accuracies for the milk production traits were higher in those studies, because validation bulls were closely related to those comprising the training data as demonstrated by  <cit> . in that study, accuracy of gebvs due to ld was estimated from  <dig>  and  <dig>  german holstein bulls using bayesb with π =  <dig> . most of those bulls were born between  <dig> and  <dig>  and 60% were offspring of north american holstein bulls revealing the high genetic relationships between the german and the north american holstein population. the strategy used to estimate the accuracy due to ld was a regression approach based on pairs of training and validation data sets with different additive-genetic relationships between the bulls of both data sets. that strategy is very time-consuming when several methods must be compared, and therefore a different approach was chosen here. gebv accuracies obtained by bayesb compared to those in  <cit>  were similar for milk yield, comparable for fat yield when the training data size was greater than  <dig> , but lower for protein yield and somatic cell score. the increase of accuracy with training data size tended to be higher in  <cit> . moreover, in contrast to the present study, g-blup was inferior in  <cit> . the difficulties in comparing the accuracies found here to those in  <cit> , apart from the standard errors, is that there might be genotype-environment interactions, because the environment in which the daughters of the bulls born before  <dig> have been tested might be different from the environment of the last decade relevant to the daughters of the training bulls. in addition, selection and genetic drift may have changed the ld structure in the population so that the accuracies of this study may not represent the gebv accuracies due to ld in the current population.

computing time
computing time, which may become more important as snp density increases, is an advantage of bayescπ, because its gibbs algorithm is faster than the metropolis-hastings algorithm of the other methods. the reason is that the mh step for sampling the locus-specific variances in this implementation of bayesa, bayesb and bayesdπ is repeated in each iteration to improve mixing; the gibbs step for fitting a snp in bayescπ is only performed once. furthermore, computing time depends largely on the number of snps fitted in each iteration, because the following two computation steps are the most demanding ones in the algorithm: the phenotypes have to be unadjusted for the genotypic effects of a snp if that snp was fitted in the previous iteration; similarly, if a new snp effect was sampled in the current iteration, the phenotypes have to be adjusted for the genotypic effects of that snp. bayescπ was more sensitive to both the genetic architecture of a trait and training data size than bayesdπ, and thus computing time was shorter for bayescπ. in this implementation, bayesa always had the longest computing time because all snps were fitted. for example, using  <dig>  training bulls for milk yield and a  <dig>  ghz amd  <dig> opteron processor, computing time for  <dig>  iterations was  <dig> ,  <dig> ,  <dig> and  <dig>  hr for bayescπ, bayesb, bayesdπ and bayesa, respectively.

CONCLUSIONS
bayescπ and bayesdπ that address the drawback of bayesa and bayesb regarding the impact of the prior hyperparameters on shrinkage of snp effects and that treat as an unknown the prior probability π that a snp has zero effect were developed for genomic prediction. estimates of π from bayescπ, in contrast to those from bayesdπ, are sensitive to training data size and snp density, and provide information about the genetic architecture of a quantitative trait; the traits milk yield and fat yield measured in north american holsteins have qtl with larger effects than protein yield and somatic cell score. the statistical drawback of bayesa and bayesb did not impair the gebv accuracy that is mainly due to ld information. accuracies of the alternative bayesian methods were similar and none of them outperformed all others across all traits and training data sizes. therefore the best method must be determined for each quantitative trait separately. in contrast to simulation studies, bayesa was a good model choice for genomic prediction in the north american holstein population at this current snp density. treating π as known with a high value is not recommended as alternative methods such as bayescπ or bayesdπ gave better accuracies. in general, computing time is shorter for bayescπ than for bayesdπ, and longest for bayesa. collectively, accounting for computing effort, uncertainty as to the number of qtl , and fundamental interest in the number of qtl underlying quantitative traits, we believe that bayescπ has merit for routine applications.

competing interests
the authors declare that they have no competing interests.

authors' contributions
all authors contributed to the development of the statistical methods and to the program code of gensel software. dh conducted the analyses and drafted the manuscript. all other authors contributed to the final manuscript, read and approved it.

supplementary material
additional file 1
gensel - user manual  <dig> 

click here for file

 acknowledgements
this research was further supported by the united states department of agriculture, national research initiative grant usda-nri-2009-35205- <dig>  and state of iowa hatch and multi-state research funds.
