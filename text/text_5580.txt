BACKGROUND
with the completion of the human genome project, substantial effort has been made to identify all common genetic variations, such as single nucleotide polymorphisms , from different populations in order to have a detailed understanding of heritable variation in the human genome. while millions of snps have been identified, a grand challenge in the post genomic era is to develop robust strategies for identifying genetic contributions to complex traits that are important to human health, using snps as genetic markers for whole genome-scale wide analyses or fine-scale mapping. complex traits, including most common diseases and many continuously distributed quantitative traits, are usually determined by multiple genetic and environmental factors, and potentially gene-gene interactions and gene-environment interactions. the challenge of identifying and fine-mapping genes underlying complex traits arises for many reasons, including the complexity of the genetic architecture of a trait, the small genetic effects which require a very large sample size, the difficulty of defining appropriate phenotypes, and the lack of effective approaches, among others. nevertheless, vigorous progress has been made in advancing the understanding of the haplotype structure of human populations and in developing novel methodologies for genomic association mapping of disease genes using haplotype information. for case-control designs, the key assumption underlying haplotype mapping is the nonrandom association of alleles in disease haplotypes around the disease genes. the haplotypes from cases are expected to be more similar than haplotypes from controls in the regions near the disease genes. various statistical methods  have been proposed to take advantage of information about shared haplotype segments instead of individual markers because the former type of information may provide higher power and greater accuracy. strategies inspired by data mining techniques  have also been proposed as alternatives to model-based statistical methods.

in addition to binary traits, many continuously distributed quantitative traits are of primary clinical and health significance. examples of such quantitative traits are blood pressure, cholesterol level, and bone mineral density. in many cases, the disease status of an individual is actually defined based on some threshold value of a particular quantitative trait. the traditional linkage methods for qtl mapping are primarily based on family data . the extension of tdt-type  methods to qtl association mapping  <cit>  also requires family information. the development of association mapping methods using unrelated individuals for quantitative traits has received relatively less attention  <cit> . but quantitative values can actually provide much more detailed information than the disease status alone and are collected routinely in most studies. owing to the increasing interest in genomic association studies of complex diseases, there are also increasingly available quantitative data from unrelated individuals. therefore, there is a great need for the development of novel algorithms that could directly map quantitative traits using population samples. in a recent paper, we described a novel algorithmic approach for haplotype mapping of disease genes that utilizes a clustering algorithm. we reason that disease susceptibility  allele embedded haplotypes, especially mutants of recent origin, tend to be close to each other due to linkage disequilibrium, while other haplotypes can be regarded as random noise sampled from the haplotype space. the algorithm considers haplotype segments as data points in a high dimensional space. clusters are then identified using a density-based clustering algorithm  <cit> . pearson χ <dig> statistic or a z-score based on the numbers of cases and controls in a cluster can be used as an indicator of the degree of association between the cluster and the disease under study. we introduced the concept of "density-based" clusters that was shown to be critical to its effectiveness, owing to the nature of the noisy data. in this study, we extend our previous method to qtl association mapping based on haplotype information from unrelated individuals. clusters will be identified first using the density-based clustering algorithm. the degree of association of a cluster and the quantitative trait is measured by a q-score, which is based on the t-statistic for testing the mean difference between two groups. the method can also be incorporated into the one-way ancova framework so that other factors and covariates can be easily included in the analysis. the method is non-parametric in nature, because the significance of the predictions will be validated using permutation tests. like its counterpart for disease mapping, the effectiveness of the approach depends on the similarity measure of haplotype fragments used in the clustering algorithm. we use the haplotype similarity measure proposed in  <cit> , which both captures the sharing of haplotype segments due to historical recombination events and incorporates recent mutations and/or genotype errors.

to systematically evaluate the proposed algorithm, we perform extensive experimental studies using simulated and real data sets. we investigate the power of the proposed algorithm, defined as the proportion of times a significant association is detected from n  independent replicates, and compare our method to two other statistical approaches based on single marker information. one is the most commonly used association test based on allele states of a single snp , which is actually a one-way anova analysis for quantitative traits. the other is a nonparametric test based on the mann-whitney u-test   <cit> . it has been shown  <cit>  that this rank-based statistic has better performance than ssa in detecting qtl associations. in addition to power, we are also interested in the localization accuracy of each method, measured by the distance from the snp with the greatest score to the true qtn. to generate simulated data sets, we have adopted the coalescent model of evolution. the coalescent model provides an efficient way of investigating the effects of population parameters, such as recombination rates, on the power of an association method and has been commonly used in studying the properties of association approaches  <cit> . for our purpose, a candidate gene region with different numbers of snps will be generated using realistic recombination rates and mutation rates. a causative dna polymorphism will be selected randomly from all the snps. the effect of the qtn contributes a varying proportion of the total variation of a quantitative trait. the simulation based on the coalescent theory is a great tool for investigating the influence of population parameters on the power of new approaches in a controlled manner, but it might not capture the true characteristics of the ld in human populations. we therefore further test the proposed algorithm on empirical  human data. we take the phased genotype data of all parents from  <cit> , and compare our algorithm with the other two methods on the complete data set as well as on selected tag snps. results on both simulated and real data sets will be presented in the next section, followed by some discussion on possible future directions. the details of the algorithm are presented in the method section.

RESULTS
model for generating simulated data
the coalescent model has been widely used in assessing the power of association tests  <cit> . it assumes a random mating population with selectively neutral mutations and an infinite-sites model. it is believed that the model could generate samples that are reasonable approximations of human variation with respect to the density, number and frequency spectrum of snps, and the pattern of linkage disequilibrium between them  <cit> , although it involves some simplifications in mimicking human populations. in our simulation, the ms program from  <cit>  was utilized to generate a large number of independent replicates of genealogies and snps under a wide range of population parameters. to examine the power of the three methods, four parameters that have potential effects on the power were investigated, namely, the sample size, the qtn effect, the recombination rate, and the density or number of snps. the size of the region for fine mapping was fixed to be  <dig> kb, with an effective population size  of  <dig>  the total number of snps was set to be  <dig> or  <dig>  corresponding to the density of  <dig> snp per  <dig> or  <dig> base pairs, respectively. only snps with minor allele frequency larger than 5% were included in the calculation, so the actual number of snps  in each replicate varied. haploid data were used in the study to avoid the time needed for haplotype inference. similar results can be expected to hold for diploid data under the additive model. the sample sizes  considered were  <dig>   <dig>   <dig>  recombination rate has a strong influence on the power of ld-based tests. we used realistic values of recombination rates based on the data of human populations. the evolutionary recombination rates  between adjacent sites considered were  <dig> e- <dig>  1e- <dig>  2e- <dig> per individual per generation, corresponding to a rate  of  <dig>   <dig>   <dig> at the population level in the region , respectively. after each replicate was generated, a snp was randomly chosen as a qtn, and was deleted from the data before further analysis. the effect of the qtn  was defined as the proportion of phenotypic variation attributable to the qtn. in most complex traits in human, a realistic estimate of π for a single qtn is usually less than  <dig> . the power of any statistical approaches to detect such a qtn could be quite low  <cit> . in our study, the contribution of the qtn to the total variation of the quantitative trait was set to  <dig> ,  <dig> , and  <dig> . we have taken conservative values of π because they are more likely to represent reality, and the power of detecting associations with larger π would be higher. the model used to generate the phenotypic distribution was similar to that used in  <cit> . details will be illustrated in the method section. for each parameter combination,  <dig> independent replicates were generated. for each replicate, a permutation test with  <dig> shuffles was performed to obtain the experimentwise significate level  <cit> .

hapminer parameters
there are five parameters that need to be specified in hapminer. it has been shown that hapminer is quite robust and has consistent performance across a wide range of parameter values in disease gene mapping  <cit> . in this study, the two weight functions were assigned to be the strength of pairwise linkage disequilibrium measured by d', for the reasons to be discussed in the method section. the haplotype segment length was seven for both the simulated data and the real data with complete snps. the length was three for the real data with tag snps. the other two parameters for the clustering algorithm took their default values.

type i error
to assess the power of different approaches of detecting significant associations between snps and traits, it is important to have a proper control of false positive discoveries due to chance . in this study, we set the error rate to be  <dig> . the false positive rate of each method was estimated as the proportion of significant associations reported in  <dig> independent replicates for each parameter combination while keeping the contribution of the qtn to be  <dig>  all three methods have correct type i error rates. the average false positive rates  over all parameter combinations tested  for hapminer, ssa and mwu are  <dig>  ,  <dig>   and  <dig>  , respectively.

the power of different methods
it is well known that a qtn can be easily detected by any  method if it contributes a large fraction of the total variation in a phenotype, or if a very large sample size has been used. but in reality, for most complex traits, the contribution of a qtn to the phenotypic value is usually less than 10% of the total variance. on the other hand, the sample size in most studies is in the range of hundreds. in this study, we compare the power of the three methods under realistic assumptions that the qtn effect is not greater than 10% and that the sample size is not larger than  <dig> individuals.

the qtn effects and the sample sizes
recombination rates
the power of all three methods decreases with increase in the recombination rate . this is not surprising because linkage disequilibrium breaks down more rapidly with larger recombination rates. hapminer is more robust than the other two methods. the power of hapminer has a smaller decrease than that of ssa if the density of the snps is high . hapminer still consistently outperforms ssa across all the recombination rates for both marker densities when π =  <dig>  . the two methods achieve similar power when π =  <dig>  for all recombination rates . recent human experimental data  <cit>  indicate that the human genome can be partitioned into blocks of various lengths  such that, within each block, there is no or little evidence of historical recombination events. in such regions with low recombination rates, it is not necessary to genotype every snp. a small subset of tag snps can be used to reduce genotyping efforts without losing much information. our results suggest that, in such a case, hapminer has more advantages than ssa. for example, by using about half of the snps in the region with recombination rate of  <dig> , the power of ssa dropped 15%  while hapminer only dropped  <dig> % .

marker density
the power of all three methods increases with increase in the number of typed snps. figure  <dig> compares the power of the three methods when the region has different marker densities with the recombination rates being binned together. figures  <dig> and  <dig> show the power of hapminer and ssa with different marker densities for different recombination rates. for a small recombination rate , the power of hapminer only decreases little when the number of snps decreases by half, while ssa deteriorates much more. when the recombination rates are large , hapminer gains more power than ssa on increasing the marker density. overall, the increase of power for both methods is only small to modest when the number of snps is doubled. therefore if resources are limited and the total number of genotypes to be typed  is fixed in a given region for fine mapping, it is more desirable to have a large number of individuals with modest coverage. on the other hand, dense snps may provide more accurate information on location and this type of effect will be examined in the next subsection.

localization accuracy
we also investigate the prediction accuracy for each data set, when the identified association is significant, by taking the snp with the highest score as the predicted qtn. our simulation results show that the predictions are rather accurate for all three methods when associations are significant, especially when the sample size is large . hapminer performs consistently better than the other two methods. with high density markers, where the average number of snps in the analysis  is about  <dig>  and the average marker interval distance is around  <dig> , , the prediction errors of hapminer are around  <dig>  . the accuracy increases with increase of the recombination rates. the predictions of the other two methods are also reasonably accurate . but no obvious trends are observed for these two methods when the recombination rate increases. when the marker interval distance is around  <dig>  , the absolute values of prediction errors are larger than those with dense markers. but in terms of how many markers away the predicted positions are from the true qtns, the results are comparable in these two cases. the prediction accuracy does not decrease substantially when the sample size decrease, or the qtn effect decrease, which illustrates that these two factors have most of their influence on power. higher marker density improves the prediction accuracy in terms of absolute distances because the highest precision possible is half of the average marker interval distance. high recombination rates might give more accurate results, but with the risk of reduced power. the methods can be used as prediction tools because, under the simulated model, the association of snps with phenotype is mainly due to the linkage of the snps and the qtn. more investigations are needed for more complex population models.

results based on human data
the simulation based on coalescent theory might not capture the true property of ld in human populations owing to its assumptions of a simplified population structure and demographic history. we further test the three methods on empirical human data taken from  <cit> . the data consist of  <dig> trios in a region of  <dig> kb at 5q <dig> that is implicated as containing a genetic risk factor for crohn disease. there is a total  <dig> snps with minor allele frequency > 5%. the whole region shows a picture of discrete haplotype blocks with limited diversity within each block, suggesting great information redundancy. a substantially smaller subset of tag snps should be enough for association studies. we take the phased genotype data of all parents  and mimic a two-stage study design for association mapping. at the first stage, only a small fraction of the total haplotypes is available to us, with all the snps. in this study, we randomly choose  <dig> haplotypes  from the total of  <dig> haplotypes. the top  <dig> tag snps  are then selected using the online program tagger  <cit> , which has been demonstrated to be effective for snp selection  <cit> . in the second stage, all the haplotypes with tag snps are then used in the power analysis. we randomly select a snp from the tag snps as the qtn and the effect is set to be  <dig> . a trait value for each haplotype is then generated according to the allele state of the qtn and the same phenotypic model as in the simulated data. the qtn is removed before further analyses. there are one hundred runs on each such data set and the power is defined as the proportion detecting significant associations. table  <dig> summarizes the power of the three methods and the total numbers of genotypes screened under the two study designs. the two-stage design using tag snps can save more than half of the genotyping cost compared to the design with all snps. the power of hapminer is almost the same for the two designs . the power of ssa drops 9%, although it performs better than hapminer when using all the snps. a possible explanation is that some snps are in almost complete ld with the qtn. in this case, taking the average over a haplotype segment like hapminer does may actually deteriorate the power. mwu achieves better performance using tag snps than using all the snps. the reason for this is probably because the number of multiple tests for tag snps is much smaller than that for all snps. but its power is much lower than ssa and hapminer. the results demonstrate that our haplotype-based approach has higher power when using tag snps than ssa and mwu, and should be used in studies with a two-stage design.

discussion
in this paper, we extend our previous haplotype-based association mapping method to quantitative traits. the algorithm has been implemented in our existing software called hapminer. extensive simulation results illustrate that hapminer is more robust and achieves higher power than two other statistical approaches. the two methods  were chosen because of their popularity and their performance in previous studies  <cit> . we have not compared hapminer with other haplotype-based approaches because of the lack of availability of existing programs for haplotype-based qtl association mapping using population samples.

in reality, most complex traits are the product of joint gene-environment action. the environmental factors may include, for example, smoking habit, drinking habit, times of exercise per week, special diet, among many others. instead of using the t-based q-score, we can easily incorporate the clustering algorithm into the framework of an ancova analysis, thus taking into account environmental factors as well as gender, age, etc. as covariates into our haplotype-based association mapping model. more specifically, the marker information  is taken as one independent variable, and all clusters  are taken as the groups of that variable. ancova  is used to test if the means of the groups are different enough not to have occurred by chance, with confirmation using a permutation test. if the result is significant, multiple comparison tests  <cit>  can be employed to further test which groups/clusters are significantly different. by incorporating the clustering algorithm into ancova framework, our approach has the potential to deal with locus or allelic heterogeneity. because hapminer can return multiple clusters at each marker, each of the clusters may represent a single ancestral mutation event. in such a case, ancova  simultaneously tests if the mean values of different clusters and the group of random noise are the same. if the null hypothesis is rejected, multiple comparison tests  <cit>  can be employed to further test which clusters are significantly different from the group of random noise. but a new permutation schedule is needed in this case and will be investigated in the future.

the method presented here assumes that haplotype information on each individual is available, which in general can be inferred based on genotype data using currently available programs . the mapping accuracy directly depends on the quality of the haplotype inference. the trait value, which is the characteristic of an individual, is assigned to a pair of haplotypes, and the two haplotypes from one individual are assumed to be independent. all these factors may potentially compromise the effectiveness of the algorithm. an alternative to the use of inferred haplotypes is to calculate similarity/distance based on genotype vectors instead of haplotype segments. one way to extend the algorithm to genotype vectors is to consider the number of alleles that are identical in state  at each locus. the pair-wise similarity between genotype vectors can be defined by counting the number of alleles that are iis and properly weighted. the clustering algorithm can then be applied to the genotype vector similarity matrix in the same way as we did before on the haplotype similarity matrix. but our preliminary results have shown that the method based on genotype vectors is not effective. on the other hand, it should also be noted that further  independent information is available in these vectors in the form of departure from hardy-weinberg equilibrium  <cit> , and using this information may make the test more powerful. another possible extension is that, for each individual, we consider multiple haplotype pairs that have high probability and are consistent with the genotypes. further investigation will be needed on how to incorporate hardy-weinberg disequilibrium and/or the uncertainty during haplotype inference.

marker selection is one key issue that will facilitate the process of identifying genetic contributions to complex traits. a number of methods have been proposed for identifying the subset with the minimum number of tag snps according to different metrics  <cit> . so the set of tag snps obtained by different methods may also be different. the discussion of the efficiency and power of different tag snp selection approaches itself may require a separate paper. so in this paper, we have only considered different marker density in the simulated data and only one tag snp selection method in the real data analysis. in the case where the haplotype block structure in a region is known in advance, it is also possible to take into consideration such prior knowledge. instead of using the sliding window approach, one may perform tests block by block.

the q score is based on the t statistic for comparison of means of different groups. one assumption of the t statistic is that it assumes equal variances in the two groups. this might not hold because similar haplotypes are more closely related and thus their trait values should be more similar to each other than haplotypes not forming any clusters. therefore, it is expected that the variance of the trait values inside a cluster will be smaller. in this case, welch's t statistic  <cit>  for two independent samples with different variances can be adopted. our tests have shown that the values of the two statistics are almost the same. however, since we are using a permutation test to obtain the significate level, and not the t distribution, the assumption of equal variances is not an issue for our algorithm.

it is well known that the spectrum of allele frequencies is also an important factor in determining the power of a method. the effect of allele frequency in this study can be easily seen from the model of generating phenotypic values in the method section. with a low frequency, a qtn actually has a large allele effect; while with an intermediate frequency, it will have a smaller allele effect. the results presented in this paper comprise an average across different allele frequencies because each qtn is randomly chosen from all the snps with different frequencies. finally, it should be noted that the permutation test for association is based on an exchangeability assumption. it is therefore important to have a sample from an ethnically homogeneous population or make allowance for the possibility of population stratification  <cit> . to what extent this might be an important issue will be studied in a future publication.

CONCLUSIONS
in summary, hapminer can be complementary to the current model-based statistical methods for qtl mapping and will serve as a useful tool for geneticists to explore their data. our experimental results show that hapminer is more robust and achieves higher power in most cases than two statistical approaches . the rank-based statistic  has much lower power than hapminer and ssa, as shown in our study. in regions with low recombination rates or with blocks between recombination hot spots, two-stage association mapping using tag snps is an efficient study design to reduce genotyping cost without losing too much power. with the availability of hapmap data, such a design will gain much popularity in the near future. in such cases, hapminer is preferable to ssa, as shown in this study, because haplotypes might capture moderate ld between tag snps in different blocks and haplotypes might represent some rare variants that will be missed by methods based on single markers using tag snps.

