BACKGROUND
toxicogenomics  <cit> , or the application of genomic technologies to toxicology, has been recognized as having the potential to revolutionize toxicology. by measuring expression changes of tens of thousands of genes, we can identify mechanistic-relevant genes and pathways, improving our mechanistic understanding of toxicology. nonetheless, toxicogenomics has fallen short of its initial promise  <cit> . while there is no single reason for this, one issue is that the current bioinformatics approaches used in toxicogenomics have not sufficiently dealt with the complexity of the toxicology study. for example, the assessment of a chemical’s toxicity requires data from experiments involving various doses and treatment durations and, in some studies, simultaneously applying several assay platforms. a single gene could have a dynamic profile across different treatment conditions  with a role in multiple pathways which interact in complex manners to affect physiological changes of toxicity. therefore, when analyzing toxicogenomics data, it is essential to ensure that this complexity is adequately captured.

the sheer scale of the data generated by toxicogenomics experiments prevents the easy identification of important genes. instead, methods that cluster or group genes by their gene expression response and thereby reduce the dimensionality of the data are typically used. these include common statistical techniques such as hierarchical cluster analysis , principal components analysis  and k-means clustering. these tools have been widely applied to toxicogenomics data and other high-dimensional genomic data sources. however, a critical drawback to methods like hca and k-means is the mutual exclusiveness of genes with respect to their involvement in biological processes  responding to exposure . therefore, these methods often do not reflect the reality of the genomic response which limits our understanding of the complex interplay between genes and pathways. exploring methods that are capable of holistically analyzing toxicogenomics data will improve the quality of the results and greatly contribute to mechanistic understandings of toxic response.

the genome is often referred to as a book of life: the genome has  <dig> billion letters , ~ <dig>  words  comprised by these letters, and many sentences/paragraphs  that can be constructed with these words to associate with diseases that are repeated and spread across  <dig> chapters . thus, one can conceptualize a relationship between genes and text, which share many commonalities and characteristics. for example, the same word can appear in different sentences while the same gene can be involved in different pathways. such a commonality suggests that text mining tools could be useful alternative methods to analyze genomic data.

topic modeling has been widely applied in the field of text mining, such as the mining of the enormous corpus of biomedical literature  <cit> . we applied this methodology to analyze fda-approved drug labels for drug safety  <cit>  and to explore drug repositioning opportunities  <cit> . topic modeling considers a document to be a mixture of topics, and a topic to be a probability distribution over words. in many ways, a gene expression dataset resembles a set of documents; the dataset consists of mixtures of biological processes, which can be thought of as topics, and a biological process consists of a set of genes, which can be thought of as the words used to present a topic. in fact, topic modeling has already been successfully applied to the analysis of genome-wide biological profiling datasets. for example, manuele et al. applied two different topic modeling approaches, plsa  and lda , for cancer classification using gene expression profiles  <cit> . patrick et al. used a modified lda technique to cluster drugs and genes  <cit> . bing et al. applied a correspondence lda model to discover microrna regulated modules by identifying the microrna and mrna co-occurring frequently within the same latent variable  <cit> .

while several examples mentioned above have successfully applied topic modeling to genomic datasets, the sizes of the studied datasets were small . in addition, the utility of this method has not been explored in toxicogenomics in which the experiment design is usually complex . in this study, topic modeling was applied to a large toxicogenomics dataset that contains gene expression data from over  <dig>  samples  <cit> . the nature of the studied samples are heterogeneous and are generated from three different assay platforms but use the same set of  <dig> compounds, most of which are drugs. these contain data from an in vitro assay using rat primary hepatocytes, an in vivo assay in rats that employed a single dose treatment and an in vivo assay in rats that exposed them to repeated doses. the data were examined to determine how compounds and genes were grouped independently in terms of topics, or in this case, biological processes. these groupings were also extensively studied using network modeling and pathway analysis. in many places, “word” and “gene” as well as “document” and “treatment/experiment condition” were used interchangeably.

methods
dataset
the japanese toxicogenomics project  is one of the most comprehensive efforts in the field of toxicogenomics, yielding a large dataset of gene expression profiles for  <dig> compounds, most of which are are drugs  <cit> . specifically, its phase-i effort produced large-scale gene expression profiles for the effect of  <dig> compounds on rat livers using a short-term single-dose in vivo study , a longer term study with multiple doses used repeatedly in in vivo experiments  and a study using multiple dose level in vitro experiments on rat primary hepatocytes . in total,  <dig> time/dose combinations for each of the  <dig> compounds were profiled for the in vivo samples while  <dig> time/dose combinations for each of the  <dig> compounds were profiled for the in vitro samples. besides gene expression profiles, histopathological examination of the liver along with clinical chemistry and hematology data are also included in this dataset. further information about this dataset, also known as tg-gates, can be found in uehara et al.  <cit> . the dataset we used in this study was downloaded from camda  <dig> .

data processing
for each compound, gene expression profiles were generated for two control samples and three treated samples. as a preprocessing step, the probe-level data of the microarrays were quantile normalized followed with mapping of a probe set into corresponding genes  <cit> , then multiple probes were summarized into one corresponding gene’s intensity ratio by using farms  <cit> . next, we generated a “document” for each compound-assay-dose-time treatment condition, which contained “words” differentially expressed when compared with the matched control. a total of  <dig>  genes were contained in the three assay systems . we considered the same gene with a different transcriptional direction  as two different genes , which led to a corpus of  <dig>  words. the frequency of a word appearing in each document was determined by multiplying the fold change of the treated samples compared to the time-matched controls by  <dig> times. a total of  <dig> ,  <dig>  and  <dig>  documents representing a compound-dose-time combination were generated for the in vitro, in vivo single dose and in vivo repeat dose experiments, respectively.

topic modeling
lda was applied to process the documents mentioned above  <cit> . lda uses the dirichlet prior probability to obtain topic distributions. the basic idea is that a document is represented as a mixture of several topics, where each topic is characterized by a word distribution. thus, two dirichlet distributions are employed, one for topic distribution over the documents and the other for word probabilities within a topic. these distributions are obtained by maximizing the posterior probability of observed documents. in this study, the open-source mallet software package from the university of massachusetts was applied. to determine the optimal number of topics to represent the dataset, we utilized the information loss and maximum likelihood approach to evaluate varying the number of topics ranging from  <dig> to  <dig>  the modeling results include two different distribution files: topic distribution over document and word distribution over topic. the former includes the conditional probability of each topic given a document which, in this study, is a compound-assay-dose-time treatment condition, p. this probability is a signature of the treatment, which will be used to assess similarity between samples assayed in different conditions. the latter represents the conditional probability of each gene  given a topic, p, indicating which genes are important to a given topic.

clustering assays and compounds
after the lda analysis, the conditional probability of each topic given a treatment condition, p, was obtained. for all possible sample  pairs from different treatment conditions, the kullback–leibler  divergence method, which is a measure of the difference between two probability distributions , was applied to calculate similarities between any two samples based on conditional probabilities p <cit> :  da,b=dkla||b+dklb||a <dig>   dklp||q=∑ipilnpiqi where i, p and q denotes the ith topic’s conditional probability given a document p and q, respectively. using the pairwise symmetrized k-l divergence defined in the equations , we identified the top 1% nearest document pairs. then, those highly ranked document pairs were connected to each other in a network. in order to extract sub-networks, the mcode plug-in for cytoscape was applied to the constructed network which is designed to expand the cluster from highly interconnected seed nodes by setting a certain threshold  <cit> .

functional analysis
the second result of lda is the probability distribution of words within a given particular topic, p. specifically, p is the probability of gene wi occurring in the jth topic, giving a measure of the importance of gene wi to the jth topic. since topic modeling is designed to cluster words co-occurring frequently across whole documents, genes with a high rank in a topic are presumably involved in the biological processes determined by that topic. to determine the overrepresentation of biological processes for individual topics, functional analysis was applied with kegg, and the significance test was based on fisher’s exact test.

RESULTS
topic model development
the first step of applying topic modeling in toxicogenomics is to transform the gene expression measurements into a document-based format while retaining the information in the original dataset. a fold-change based transformation method was applied to convert the gene expression profiles of each compound-assay-dose-time treatment condition to a set of documents. each document contained the genes that were dysregulated when comparing treated samples with the matched controls. the fold change value of a gene in a given treatment condition resembles a frequency of a word in a given document. next, the number of topics optimally representing the information across all of the treatment conditions was determined using the information loss and maximum likelihood approach in a space of the number of topics between  <dig> and  <dig>  after selecting  <dig> as the optimal number of topics representing this dataset, the topic model generated two probabilistic distributions. p quantified the relevance of each topic  to a given treatment condition, thus a treatment condition can be characterized by the profile of  <dig> topics . p determined the importance of each gene  to a given topic. in this analysis, we used the top  <dig> genes with the largest p value to represent each topic , resembling the meta-gene concept  <cit> .

analysis of topics
each of the  <dig> topics derived from the topic model was unique, as evident by a pairwise similarity assessment of topics using the tanimoto method  where the largest tanimoto coefficient was only  <dig>  for topics  <dig> and  <dig>  the results implied that each topic represented a unique aspect of biology. subsequently, the same genes presented in multiple topics could perform diverse roles leading to drug-induced toxicity in rat livers. as depicted in figure 1b, the majority of genes only appear once amongst the  <dig> topics, while very few genes were presented in multiple topics. loc <dig>  also known as ddb <dig>  appears in  <dig> topics. it is a damage-specific dna binding protein, which involves various biological functions including protein autoubiquitination, protein polyubiquitination, pyrimidine dimer repair and participates in the nucleotide excision repair pathway. it interacts with 17β-estradiol  <cit> , an endogenous estrogen that usually undergoes a substantial metabolic process in rat livers regulated by cychrome p <dig>  it also interacts with tcdd  and  <dig> -d , two well-known environmental toxicants  <cit> . additional file 2: table s <dig> lists the genes appearing in more than  <dig> topics along with their annotation by metacore .

we also examined the over-represented pathways  in each topic with kegg and the results were summarized in additional file 3: table s <dig>  a total of  <dig> pathways were identified, of which  <dig> pathways were uniquely represented. as shown in figure  <dig>  some topics had few over-represented pathways while others had many. we assigned each treatment condition to a topic with the largest conditional probability value of p . we then examined how the choice of assay platform as well as dose level and treatment duration relates to the number of pathways over-expressed in different experiment conditions. as shown in the pie chart above each bar in figure  <dig>  the number of pathways elicited by three different assay systems followed a general order of in vivo repeated treatment > in vivo single dose test > in vitro assay. however, the trend is less clear at both dose and treatment time level.

assay’s sensitivity to the treatment effect by drug, dose or treatment duration
the most challenging aspect of this toxicogenomics dataset is that a single compound was often exposed to different doses and treated with different time durations in three experiment settings. these variables needed to be analyzed in an integrated fashion to determine the toxic potential of a compound. for that reason, we calculated the distance between any two treatment condition based on the probabilistic distribution of topics over the treatment condition ) using the k-l divergence, and a total of  <dig> , <dig> pairs were generated. we selected 1% of the pairs  for analysis which had the highest pairwise similarity between two treatment conditions. a number of interesting observations were made .

specifically, among the top 1% nearest pairs, 42% were from the in vitro method, followed by 30% from the in vivo repeated treatment and 19% from the in vivo single-dose experiment . similarly, the percentage of the pairs from each assay system within the top 1% nearest pairs also followed the same order of in vitro assay > in vivo repeated treatment > in vivo single-dose experiment . both findings strongly suggested that different assay systems have varying abilities to differentiate treatment conditions . therefore, we investigated which assay systems are more sensitive to each treatment effect related to drug, dose or time. to assess the drug effect, we calculated the number of pairs for each bar  in figure  <dig> which had the same drug in a pair without considering dose and time. the same principle was used to estimate the dose and time effects. the results indicated that the drug effect was more pronounced in the two in vivo systems than the in vitro method . while the three testing methods had relatively similar sensitivity to the dose effect , the in vitro system clearly had a better sensitivity to the time effect followed by the in vivo single-dose method and the in vivo repeated dose approach .

cross-assay extrapolation
assessing whether the expensive in vivo repeated dose approach can be replaced by the short-term in vivo method or even an in vitro assay is of great interest to pharmaceutical industries and regulatory application. therefore, in the top 1% nearest pairs, we also examined how many of them paired two different assays , an implication of a potential cross-assay extrapolation. as shown in the last bar of figure  <dig>  9% in the top 1% pool paired two in vivo systems while none paired in vitro with any one of in vivo systems. the result suggested the potential use of a short-term assay with a single-dose treatment to supplement or replace the repeated dose study. this finding was further confirmed in a network analysis by connecting the top 1% nearest pairs followed with a clustering analysis using mcode  <cit> . as depicted in additional file 5: figure s <dig>  two large network clusters were formed along with many small ones, one associated with the in vitro assay alone and the other mixed both types of in vivo studies, implying that the in vitro system is sufficiently different from in vivo but two different types of in vivo assays share many commonalities at the transcriptional level.

cross-assay extrapolation could be drug-dependent; some drugs may show a better consistency across assays than others. for that, we also examined the cross-assay extrapolation in the context of drugs. specifically, in the top 1% nearest pairs, if we observed two pairs where pair  <dig> was between  and  and pair  <dig> was between  and , we considered that both the in vitro assay and in vivo repeated dose method had an equivalent ability to recognize the similarity between drug a and drug b. as shown in figure 4a, more than half of these pairs were detected by all three assays without considering the effect of dose and treatment duration, followed with an additional 25% that were consistent in any two of three assay systems. the similar analysis was also conducted by using only high dose or longest treatment duration. as shown in figure 4b, the drug pairs recognized by all three assay systems were significantly decreased, but a substantial number of drug pairs consistent across any two assays was observed. the results indicated that some drugs have a better extrapolation across assays than others.

network analysis
the network analysis mentioned in the previous section generated  <dig> subnetworks, ranging in size from  <dig> nodes to  <dig> nodes, with  <dig> nodes as the average network size . none of the subnetworks consisted of both in vitro and in vivo assays. a total of  <dig> subnetworks comprised of both in vivo single and repeated dose studies. eight of the subnetworks contained nodes associated with a single compound, such as ethinylestradiol, ethionine, tamoxifen, colchicine and ethambutol with three of them in more than one assay system. for example, subnetwork  <dig> consisted of ten samples all treated with ethinylestradiol in the in vivo repeat dose study with different treatment conditions . subnetwork  <dig> included three samples treated with ethinylestradiol in the in vivo single dose treatment. . the findings are consistent with the histopathological changes seen with ethinylestradiol treatment ; eosinophilic change is observed in almost all the time/dose points of the in vivo repeat dose assay. tamoxifen, a synthetic estrogen sharing the similar mode of action with ethinylestradiol, has two subnetworks. one of them  includes six samples conditioned in the in vivo single dose study, and the other  includes four samples conditioned the in vivo repeated treatment. while some subnetworks mentioned above are enriched with a single drug using different time and dose conditions, some subnetworks  contained nodes associated with similar treatment conditions and assay types. for example, subnetwork  <dig> was composed of in vitro studies on four compounds  that were each treated for 24 hours at the high dose level. it was found that three of these four drugs, all except phenylanthranilic acid , are considered less likely to cause drug-induced liver injury  in humans as defined by nctr's liver toxicity knowledge base   <cit>  and two drugs, cyclophosphamide and simvastatin, belong to a same anatomical therapeutic category of cardiovascular system. additionally, subnetwork  <dig> includes four drugs, clomipramine, danazol, nitrofurantoin and nitrofurantoin with 8 hours, medium or high dose condition in in vitro model, and all of them are most-dili-concern defined by ltkb.

we found that topic distributions can also be discriminative features for clustering of drugs by therapeutic category. some drugs belonging to a certain anatomical therapeutic categories were clustered together such as cardiovascular system, genito-urinary system and sex hormones, musculo-skeletal system and nervous system. subnetwork  <dig> is composed of four distinct drugs in in vivo repeated treatment, clofibrate, gemfibrozil, simvastatin and benziodarone, all of which belong to the cardiovascular system. subnetwork  <dig> is enriched with a therapeutic category of musculo-skeletal system by including seven drugs, most of them are non-selective cox inhibitor. interestingly, among a total of  <dig> samples, three of them  were conditioned on the in vivo repeated treatment while the rest of them  are from the in vivo single treatment, suggesting a potential replacement of the long-term assay with a short-term one. intriguingly, pparα agonists are clustered together in each assay system, as depicted in figure  <dig>  subnetwork  <dig> includes  <dig> samples treated with three pparα agonists  in the in vivo repeated treatment while subnetwork  <dig> and  <dig> includes  <dig> and  <dig> samples in the in vivo single treatment with the same pparα agonists along with the inclusion of two non pparα agonists, ibuprofen and benziodarone. both subnetwork  <dig> and  <dig> are enriched with the in vivo single study, although their treatment condition is different; subnetwork  <dig> is conditioned on longest duration  while subnetwork  <dig> is conditioned on  <dig>   <dig> and 9 hour. benzbromarone  is not a pparα agonist, however it is known to have a high binding affinity for pparα, showing potential as a pparα agonist  <cit> . ibuprofen  is also known to be potential pparα agonist  <cit> . subnetwork  <dig> has four samples treated with three pparα agonists, fenofibrate, clofibrate and wy- <dig> in the in vitro assay. subnetwork  <dig> is composed of three anti-cancer drugs, cisplatin, carboplatin and puromycin aminonucleoside. both cisplatin and carboplatin are platinum-containing anti-cancer drugs, cisplatin is a parent drug of carboplatin. puromycin aminonucleoside is also an anti-cancer drug, inhibiting protein synthesis  <cit> . subnetwork  <dig>  enriched with a therapeutic category of genito-urinary system and sex hormones, is composed of two drugs, danazol and methyltestosterone which act as androgen receptor agonist. subnetwork  <dig> is composed of phenobarbital and acetaminophen in in vitro study which belongs to a nervous system. it is clear that topic modeling is capable of identifying biologically relevant topics in an unsupervised manner. it groups the drugs under the same therapeutic categories based on their associated topics, which may provide a new avenue for target identification and/or drug repositioning  <cit> .

discussion
two large toxicogenomics datasets were made publicly available recently: tg-gates and drugmatrix  <cit> . while the availability of such large datasets generates tremendous opportunity, it creates challenges as well in the field of toxicogenomics. both datasets apply a study design that includes multiple doses and treatment durations across different assay systems. the complexity of these datasets requires advanced data analysis methods to take advantage of dose- and time-dependent features in toxicity assessment. we explored the utility of topic modeling in toxicogenomics by analyzing the phase  <dig> of tg-gates dataset which includes data from > <dig>  arrays derived from three different assay types . by applying network analysis to the topic modeling results, we made several interesting observations about the impact of assay difference, dose and treatment duration.

classifying samples based on gene expression profiling is a major focus in genomics research, including toxicogenomics. most traditional clustering approaches  classify samples based on the gene-gene correlation principle. however, topic modeling considers samples as a mixture of latent topics and each topic is characterized by the probabilistic distribution of genes. this formula permits samples to be associated with multiple topics and genes to be associated with multiple topics. in doing so, each gene in topic modeling can be assigned to multiple topics, which is a key difference to the traditional unsupervised clustering methods where each gene is assigned to a single cluster. in this study, we focused our analysis on the top 1% similar pairs of treatment conditions based on topics. subsequently, we generated the top 1% of similar pairs using the gene expression correlation matrix and compared it with the topic modeling results. the overlap between two approaches was only 21%, indicating that both methods capture different aspects of the biological process and could be complimentary each other to gain in-depth understanding of underlying mechanisms of toxicity.

toxicogenomics usually applies an experimental design involving multiple time and dose points and different assay conditions. such a design offers an opportunity to comprehensively address a number of key questions in toxicogenomics  <cit> . for instance, whether in vitro assays or short-term assays can supplement or even replace long-term in vivo assays, since the latter are much more time consuming and resource intensive. in this study, we observed similarities identified by the latent topic variable between two in vivo experiment designs , indicating that the short-term in vivo assay with single dose treatment shares similar gene expression responses with the traditional repeated dose assay protocol. in contrast, distinct differences were observed between in vitro and in vivo responses.

the network analysis of the topic modeling results aims to cluster compounds in different treatment conditions with similar biological effects. here, the pair-wise similarity between different treatment conditions  was generated based on topic distribution. this approach offers an alternative solution to study underlying toxic response. a network was developed using the top 1% most similar pairs of treatment conditions. the resulting network showed two distinct groups, one associated with the in vitro assay and the other for the in vivo assays. the network considers that two different in vivo assays  are similar, which is consistent with previous observations that a short-term in vivo experiment can offer comparable insight to long-term in vivo experiments  <cit> . the nodes were clustered according to similarity, generating a total of  <dig> subnetworks. some subnetworks contained settings treated with varying amounts of the same compound. this suggests a response that is less sensitive to dosage. some subnetworks, however, contained samples treated at similar dosage levels  but with different compounds. these subnetworks are suggestive of compounds sharing similar mechanisms of action. a number of subnetworks were over-represented with a certain therapeutic category, non-steroidal anti-inflammatory drug, anti-cancer drug and pparα agonist.

together, our approach demonstrates that topic modeling offers several distinct benefits, particularly when applied to toxicogenomic expression profiling data. first, for high-throughput gene expression profiling, dimensionality reduction and visualization are key aspects in effectively analyzing and interpreting data. topic modeling was able to reduce data dimension very effectively in terms of the latent variable, topic. second, topic modeling is a soft clustering technique which does not assume mutual exclusivity and permits multiple topic assignment to the same sample and gene, reflecting true biological complexity. third, the biological context associated with the topics can be easily interpreted by using functional analysis approaches such as gsea  <cit> .

CONCLUSIONS
this study investigates the applicability of topic modeling for the clustering of gene expression profiles. our results demonstrate that topic modeling offers an opportunity for use in the identification of hidden variables  embedded in gene expression profiles. these topics can be discriminative features for clustering gene expression profiles. additionally, the probabilistic representation of the topic model provides more flexibility for data interpretation. while the application of topic modeling methods to toxicogenomic data was the focus of this study, topic modeling can also be extended for analysis of similar data types such as data generated with next generation sequencing  methods.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
ml performed all calculations and data analysis, and wrote the first draft of manuscript. wt, zl and rk contributed to the data analysis, verified the calculations, and assisted with writing the manuscript. wt and zl developed the original idea and guided the data analysis and presentation of results. all authors read and approved the final manuscript.

additional files
supplementary material
additional file 1: table s1
top  <dig> genes that represent each topic.

click here for file

 additional file 2: table s2
genes assigned to more than  <dig> topics with their functional role information.

click here for file

 additional file 3: table s3
functional analysis results for each topic: fisher’s exact test with a p value cut-off of  <dig>  was used in kegg.

click here for file

 additional file 4: table s4
information for each topic, including mode of action , therapeutic category, and dili annotation.

click here for file

 additional file 5: table s5
information about  <dig> subnetworks including mode of action , therapeutic category, and dili annotation.

click here for file

 additional file 6: figure s1
the global view of the network generated from the top 1% nearest pairs. blue, yellow and orange represent the samples treated with a compound in in vitro, in vivo single and in vivo repeat, respectively.

click here for file

 acknowledgements
ml is grateful to the national center for toxicological research  of u.s. food and drug administration  for post-doctoral support through the oak ridge institute for science and education .

disclaimer
the views presented in this article do not necessarily reflect current or future opinion or policy of the us food and drug administration. any mention of commercial products is for clarification and not intended as endorsement.
