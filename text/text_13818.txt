BACKGROUND
to gain insight into complex, variable diseases like hiv, researchers need to bring together many different types of information from varied sources at early stages of research. software systems that provide secure data integration, analysis and sharing can facilitate collaborative efforts against such diseases; however, existing software has significant limitations. existing software systems typically do not span the full flow of data through an organization, require commercial licenses, focus on limited data types, provide limited extensibility, or cannot easily be used beyond the organizations that designed them. we developed labkey server as an end-to-end, "biology-aware" data integration platform that can be customized to meet the needs of diverse research organizations. the source code is freely available under the non-restrictive apache license  <dig>  <cit> . the system has been proven in heavy production use and is maintained by a professional development team.

one of the largest installations of labkey server is called atlas. it is managed by the statistical center for hiv/aids research and prevention  at the fred hutchinson cancer research center. this installation illustrates the core capabilities of labkey server and demonstrates how these capabilities have helped a large organization accelerate and enhance research efforts.

the vast majority of labkey server features developed for atlas are built into the labkey server platform and available as part of the open source project. certain customizations of the atlas installation are closely tailored to particular projects or studies, so they are not part of the open source project. they are only mentioned here as illustrations of extensibility, and they are noted as such.

atlas has grown out of scharp's efforts to meet the needs of several consortia within the global hiv vaccine enterprise   <cit> . the enterprise is a virtual coalition of researchers that aims to accelerate progress towards one of the most challenging problems in medicine, the development of hiv vaccines <cit> . following the example of the human genome project <cit> , the enterprise aims to set common goals, standardize processes and share data and techniques as soon as they are developed. just like the human genome project, this endeavour requires a massive data integration effort. unlike the human genome project, but like other large-scale, collaborative efforts against intractable diseases, the enterprise must integrate a large number of data types. these include results from diverse assays, clinical records and sample information. though atlas is not a formal project of the enterprise itself and has no official endorsement, it is used by a variety of consortia within the enterprise to accelerate scientific discovery.

requirements
uniting distributed efforts to investigate the biology and the treatment of an evolving disease poses challenges for data management tools. to gain insight into viral/host dynamics, researchers need to bring together diverse types of data  at all stages of research, even when the data originate from multiple labs and clinics across the globe. researchers need to be able to see many different data types simultaneously to investigate study participants who have exceptional immune responses, such as elite controllers or rapid progressors. they require the agility to extract lessons from failed trials and move investigations quickly in new directions, or to swiftly scale up their successes. researchers require tools to support the development, standardization and dissemination of new, improved assay protocols and workflows across organizations. furthermore, they need to be able to quickly apply new analysis techniques to existing datasets without the assistance of computer programmers. tools must be capable of handling the quantity and complexity of data generated by high-throughput technologies. as a team, they need to improve the quality, reproducibility and comparability of data through standardization of lab measurements and procedures. globally distributed teams need to rapidly, securely exchange information and specimens, ideally through a single, unified interface.

alternatives
although existing software tools <cit>  could meet some of the requirements of the atlas project, none meet all of them in the form of a comprehensive, end-to-end platform available as open source. some tools have experienced only limited use. a few broad, commercial systems have recently been introduced ; however, they lack the transparency of open source solutions, so they are not reviewed here. existing open source tools typically lack key features, such as role-based permissions, document sharing, easy extensibility, specimen requests, observational study management, full-text search, dynamic interaction with external data sources, integration with analysis tools like r, and support for describing arbitrary, complex experimental data types. table  <dig> provides an overview of the feature tradeoffs between representative platforms.

this table compares labkey server with a representative sample of open source platforms for data integration. the focus of these platforms ranges from clinical research to high-throughput experiments. documentation for many platforms is incomplete, so we can provide only a reasonable inference of feature availability.

to our knowledge, no other open source tool provides support for both web-based specimen requisitions and integration of specimen data with complex experimental results. for example, passim <cit>  , catissue <cit> , epims <cit>  and base <cit> ) all provide sample provenance tracking, but none of these allow for web-based sample requests. eoncolims <cit>  supports equipment requests and gnomex <cit>  supports experimental work requests, but neither one supports specimen transfers. i2b <dig> <cit>  has some form of a sample request module  under construction, but it has not yet been released. bsi <cit>  provides sample requisition support but does not provide for integration of sample and experimental data. caisis <cit>  is exceptional in providing both specimen requests and deep support for data integration; however, it only supports simple test results entered through online forms, not complex experimental data types.

many tools allow users to describe and collect custom metadata for experiments . several tools  also provide customizable or domain-standardized wizards for collecting metadata for experiments during data import. unfortunately, all of these tools store only metadata in their databases, not results. keeping results out of a database makes perfect sense for exceptionally large result sets ; however, database import is often desirable for smaller datasets because it allows sql-based querying. open source software does not typically provide graphical, run-time tools for describing schemas for arbitrary, complex assay results and then performing advanced queries over both data and metadata.

furthermore, no other open source platform known to us provides graphical facilities for defining a broad range of customizable, scientifically-relevant properties for any column of data . caisis <cit>  allows the definition of a few of these properties  for simple lab and clinical results; however, it provides no support for complex experimental data.

many of the widely known frameworks for data integration  are tailored primarily towards working with published data, after results have reached "finished" form, not for integrating evolving data types during the research process <cit> . even among tools targeted towards research data, such as electronic lab notebooks, alteration or addition of data types typically requires database alterations <cit> . tools designed for integrating raw research data often work only with specific data formats  or support the introduction or extension of data types only when the system is not running . even when tools provide flexibility in defining relationships between tables , they typically lack graphical tools for doing so. such approaches are practical when data types are reasonably static and standard, but not when these types need to evolve quickly, without developer support, as research advances <cit> .

many data integration tools  <cit> ) lack dynamic access to external data sources and require aggregation of all data into a central warehouse. updates can be challenging when external data sources change <cit> . fully decentralized approaches  are not easily amendable to consistent quality control <cit> .

open source clinical data management software tools  typically lack features necessary for managing both study data and highly dimensional experimental data. for example, they typically lack the ability to collect complex assay data in batches of runs. when open source systems do facilitate integration of both study and experimental data types, they typically support only limited data types or allow only narrow queries. for example, simbioms <cit>  understands relationships between participants, specimens and experimental results; however, it lacks extensible types, recognizes only particular data file formats, and allows users to filter only on metadata, not to fully query experimental results. i2b <dig> <cit>  provides more of the querying capabilities desired by scharp. however, it requires that all imported data map to a set of fixed schemas, lacks data type extensibility and does not support experimental data management.

a growing number of tools  <cit> ) furnish client libraries, but few  provide apis both for customizing interfaces and for querying data. many tools that focus primarily on biological data integration  supply some form of integration with open source analysis tools; however, none known to us provides a built-in, graphical r interface.

the atlas installation of labkey server
the scharp team found existing software alternatives to be insufficient, so team members collaborated with the labkey software team to enhance the labkey server platform and to establish atlas. atlas is an installation of labkey server customized with interfaces specific to enterprise studies. atlas does not aim to meet all needs of all researchers within the enterprise; instead, its core mission is to tie together many different lab systems and data sources, as shown in figure  <dig> 

significance of latest enhancements
recent improvements to labkey server have emphasized scenarios that support atlas's role as an information hub. these enhancements are significant in providing:

 specimen requests and tracking. users can track specimen records, execute web-based requests for specimens and integrate specimen information with clinical data and complex experimental results. no other platform known to us supports all of these scenarios.

 management of experimental data types that are invented or modified as projects evolve. labkey server's graphical assay design tools are novel in the way they allow scientists to quickly describe and manage arbitrary assay data types, plus extend built-in assay types. users can graphically associate a broad range of scientifically-relevant properties  with each column of assay data and metadata. these properties can facilitate quality control, visualization and analysis.

 integration, analysis and visualization of diverse data sources. the platform's tools for creating custom, integrated views of data are exceptional in spanning not just built-in data types and sources, but also user-extended data types. furthermore, labkey server is the only open source system known to us that allows users to integrate clinical data, specimen records and complex experimental results by leveraging:  basic relationships between study entities   sql-based queries and  graphical view-building tools. the system is also noteworthy for providing dynamic access to external data sources.

 extensibility. it is unusual for a scientific data management system to provide backwards-compatible, well-documented client libraries that enable developers to both interact with stored data and to construct custom interfaces. it is also unusual for a system to provide such rich client libraries that developers do not need to become well-versed in the system's object model to quickly develop rich content. lastly, labkey server's built-in, web-based interface for writing and deploying custom r scripts is also exceptional among data integration platforms.

implementation
architecture
labkey server is a web application implemented in java that runs on the apache tomcat web server and stores its data in a relational database engine, either postgresql or microsoft sql server. an earlier version of the platform was called cpas   <cit> ; the current version includes all of the features of cpas. labkey server is supported on computers running microsoft windows and most unix variants, including linux, macintosh osx and solaris. production installations can be upgraded in place with minimal down time. some installations are run as software-as-a-service , which moves server management out of the lab.

datasets that reside in external repositories can be made directly accessible through a labkey server. access to such datasets is dynamic, meaning that any modifications to such datasets within an external repository are immediately viewable on the associated labkey server. dynamic access can be configured for postgresql, mysql or microsoft sql server databases, or for other data sources such as sas <cit> . in general, users can work with data from external sources just like any other type of data on a labkey server. authorized users can view shared datasets using labkey server's familiar, accessible grid user interface. users can customize their views with filters, sorts and column lists. they can use the datasets in custom queries and reports, or export the data to excel, web query, or simple text formats. for data sources other than sas, changes can be made to datasets in the external repository using the labkey interface. while datasets from any one data source can be joined to each other, datasets from different data sources cannot yet be joined directly.

basic platform services
labkey server's role-based security model allows tight control of access to sensitive data while permitting broad sharing of content when this information is ready for wider release <cit> . users can be assigned specific permissions outside of their groups and roles, allowing fine-grained control of access. workspaces on a labkey server are arranged hierarchically and permissions can be inherited by children. permissions are enforced no matter how information is accessed, including full-text search, data export and the labkey api . updates to administrative settings and scientific data on a labkey server are logged, enhancing security and enabling auditing.

authentication of users occurs either through labkey server's core authentication system or through external authentication systems. a labkey server installation may optionally connect to an ldap  server to automatically authenticate users within an organization. labkey server also supports single sign-on  through opensso <cit> , allowing authentication of users from a partner web site.

the system provides full-text search for most types of data and documents, plus "science-aware" search for relevant concepts, particularly participant identifiers and study properties. a server can also be configured to display search results from external web sites. labkey server also provides a variety of web-based collaboration tools, including file management, wikis, message boards and issue trackers <cit> .

automated exception reports are generated by labkey server installations and reported back to labkey software. by monitoring exception reports, the labkey team can quickly fix issues and publish patches without the need for users to report these problems.

customizable data types
a key challenge of scientific data integration is the diversity and the rapidly changing nature of the data types that must be integrated. labkey server meets this challenge by combining the flexibility and rich metadata capabilities of rdf   <cit>  with the regular structure and familiar query mechanisms of a sql  database.

the semantic web defines a network of interconnected resources, each of which can be uniquely identified by a uniform resource identifier . these resources are described by a set of properties and property values. because the properties and property values are themselves resources, rich data and metadata can be assigned to every resource. following the semantic web model, data items stored in a labkey server can be addressed with a uri in the form of a life sciences identifier  <cit> . furthermore, they can be associated with an extensible set of properties known within a labkey server as fields.

labkey server provides a set of basic, predefined data types that can be extended with custom, administrator-defined fields. these data types include lists, assays, study datasets, and specimens. fields may include standard sql data types, such as string and numeric types, but may also use semantically richer property types designed for scientific research, such as participant identifiers. fields can be associated with other scientifically interesting properties, such as out-of-range values, custom indicators for missing values, regular expression validators and custom url templates for generating hyperlinks to external or internal resources. fields can also be annotated to indicate that they represent concepts described in curated ontologies, such as those provided in umls  <cit> . labkey server also allows administrators to define lookup properties that behave as foreign keys and allow automatic joining of related data.

query service
all labkey server data types benefit from a core query service that allows users to browse, sort and filter tabular data. this service is diagrammed in figure  <dig>  it supports a graphical interface that allows users to create customized data views and save these views for reuse and sharing with other users. labkey server's built-in tools for creating r views, building crosstab views and drawing simple charts all leverage the query service. the query service also allows developers to write full sql queries that can be executed by other users. finally, the service provides the ability to export tabular data in a variety of formats for analysis with external tools.

• a table and a column list. a column list can include columns from the requested table or columns from related tables.

• a sql query based on pseudo-tables known to the query service. 

for an api call, the following sequence of events occurs:

 <dig>  when the request is received by the server's api layer, the layer checks folder security and translates the request into calls to the query service.

 <dig>  the query service then uses schema information describing physical tables and pseudo-tables to translate the input query into a sql query of physical tables. the query is formulated in the dialect understood by the underlying relational database. schema information is supplied by other labkey modules.

 <dig>  the database returns a tabular result.

 <dig>  the tabular result is annotated with additional information about the columns .

 <dig>  the appropriate labkey client library converts this standard data/metadata into a form easily understood by the client language. for example, an r dataset would be returned as the result of a call by an r client api.

to maintain security, the query service interprets these queries and executes them over a virtual database schema that reflects the permissions of the currently logged in user. for example, the system can perform cohort blinding by prohibiting particular users from viewing data columns that would reveal the cohorts of participants. similarly, if a clinician holds permissions sufficient only for viewing data for locally enrolled participants, the clinician can only access views that are customized to hide data rows for all other participants.

RESULTS
recent enhancements to the labkey server platform enable four core scenarios, all of which have contributed to the success of atlas. full documentation and tutorials for labkey server are available at http://www.labkey.org.

scenario 1: specimen requisition and tracking
labkey server's specimen management system provides more than a centralized repository of specimen information. it also supplies secure, web-based tools for requesting, approving and tracking specimen transfers between clinics, repositories and labs. centralized specimen information can be annotated and integrated with clinical, assay or other data for study participants or animal subjects to allow comprehensive analyses.

 <dig>  an administrator sets up a folder to display the "specimens" web part and configures permissions for those who will be interacting with specimens. the administrator then imports an initial archive of specimen records and information about repositories and sites. a populated "specimens" web part is shown in a. 

 <dig>  a specimen data manager configures the specimen request process, including configuring request steps , identifying actors in the request process , configuring requirements for request approval, and setting up notification procedures .

 <dig>  a scientist logs on the system from a participating lab, then searches for vials or specimens of interest, as shown in a. 

 <dig>  to further narrow down the possible vials of interest, the scientist builds a custom view of the subset of vials she has identified through search. this custom view integrates information from diverse sources using shared identifiers. in the example shown in b, shared participant and visit identifiers are used to join in data from a related dataset. in this case, the gender of the participant who provided the sample  is drawn into the vial data view. 

 <dig>  the scientist then creates a new specimen request and uses the "specimen shopping cart" to add desired vials to this request, as shown in c.

  <dig>  when finished, the scientist submits the finished request, as shown in d. 

 <dig>  designated reviewers are notified of the requests and approve them. 

 <dig>  specimen repository workers are notified of the approved requests, fill the requests and update the web-based interface. vial that have been used are no longer requestable. 

 <dig>  after receiving a specimen vial, the scientist performs an assay on the specimen. results from this assay may be marked with the vial identifier or participant/visit identifiers so that they can be associated with specimen information on the labkey server. the process for associating assay results with specimens is shown later in figure  <dig> 

labkey server also includes built-in tools for building specimen summary reports that allow data managers to leverage the centralized availability of information about specimens. reports can be parameterized by the type of specimen, date of collection, availability of vials, source participant in the study, cohort of the participant, current location and other measures.

this specimen management system is complementary to pre-existing, site-specific tools. most labs already have lims, such as labware <cit>  or the frontier science laboratory data management system  <cit> , for specimen management. these lims are typically set up with freezer layouts, technician identities, mailing addresses, workflow info, and the like. the labkey specimen management system does not aim to replace lab-specific lims; instead, it serves to connect them. cross-site specimen management is typically a missing piece for lims that handle specimens, so labkey helps consortia to "glue together" their lims through cross-site tracking of specimens and specimen requests.

members of the enterprise use atlas heavily for both specimen request management and integration of specimen data with other types of data. the system records approximately  <dig>  specimen vials and  <dig> , <dig> vial transfers. additional usage statistics are covered in the "atlas usage" section of this document.

scenario 2: management of experimental data
typically, labs manage new types of experimental data in spreadsheets, but this can quickly become unsustainable as results proliferate. labkey server provides graphical tools for describing, importing and analyzing assay data that would otherwise reside in a multiplicity of spreadsheets. these tools make it easier to bring data straight from the bench into a common system, minimizing the cost of centralizing data, preserving data provenance information, enhancing standardization of data collection and enabling data integration. assays can also be customized through the labkey client libraries to include specialized analysis capabilities.

lab data managers define custom assay "designs" to formally describe experimental results, then import many sets of experimental results to a labkey server using the formats specified in the designs. the structure of an assay may include the number of input samples; the type and format of experimental result files; and the definition of summaries or visualizations appropriate for sharing.

defining experimental properties in the form of an assay design helps to ensure that appropriate data points are collected for each experimental run or set of runs loaded into the server. for any manual data entry steps, labkey automatically generates the appropriate data entry pages based on the assay design. the design determines which data entry elements are required and which are optional. a lab technician can also use the assay design to set appropriate default values for data items or provide pick-lists of standard values. this reduces the burden of data entry and the incidence of errors.

customized assay designs can be based on a general template, or on specialized assay types that are added to the labkey platform as modules. specialized assay types currently include: neutralizing antibody ; enzyme-linked immunosorbent spot ; microarray; luminex; cell recovery and viability; complete blood count; particle size, high performance liquid chromatography; and enzyme-linked immunosorbent assays . some of these have been developed to match the structured output of tools used by existing platform users, so they can be instrument-centric. just like labkey server's proteomics and flow cytometry tools  <cit> , all assay types are backed by a common experimental design architecture that defines notions of experiments, runs, batches , protocols, inputs, outputs and materials  <cit> .

assay run creation and deletion are audited and run data cannot be modified after runs are imported. annotations can be added to assay runs through the user interface or programmatically through quality control scripts. labkey server's assay infrastructure can support gclp  <cit>  and the establishment of repeatable, reliable, auditable and comparable lab procedures.

 <dig>  an administrator creates an assay-type folder to act as a staging area for assay data before the data has undergone quality control. 

 <dig>  a scientist creates a new assay design to match the contents of experimental results stored in spreadsheets. in this example, the assay design is based on a generalized assay template, but other assay types could be used. the assay design is named "genericassay," as marked by a. 

 <dig>  the scientist then adds a set of batch fields that must be filled out when each batch of runs is imported. user-defined batch fields are backed by the same set of customizable properties as system-defined fields. this image shows label, description, type, lookup and custom url properties for several fields. other properties include conditional formatting, default values and regular expression validators. here, the "machine" batch field  is configured  as a lookup to a simple list . at the time of data import, the user will be presented with a defined list of options for populating the "machine" field that are drawn from the primary keys of the "machines" list. 

 <dig>  next, the scientist defines the run fields  that must be collected for each run. in this example, only one field  is defined. 

 <dig>  finally, to save time, the scientist infers the assay's data fields  from a representative spreadsheet file. these fields could also have been designed manually, in the same manner as the batch and run fields.

 <dig>  the user selects the assay design that matches experimental data and chooses to sequentially import run data. this example uses the assay design from figure  <dig>  

 <dig>  for each batch of data, the user is prompted for batch properties . here, the "machine" options are provided as a defined vocabulary to reduce errors and variability in data entry. 

 <dig>  for each run, the user is prompted for run properties and run data , as described in the assay design. a template of expected columns can be exported to help with matching data formats. 

 <dig>  the user can import several runs sequentially using the same batch properties. c shows a summary view of the three runs that have been imported to this assay design using the same batch properties. 

 <dig>  d shows an example of results imported as a single run for this assay. note that the "machine" column is defined as a lookup to another table, so each of its entries is hyperlinked to details for the appropriate machine, as provided by the "lab machines" list. 

 <dig>  after assay data has been reviewed for quality control, it can be moved into a study folder for sharing with collaborators and integration with other types of study data. during the import process, the participant/visit identifiers for each row of assay data are matched  to identifiers for specimens in the target study. this allows viewers of the assay data within the study to quickly navigate to data for associated specimens.

labkey server's neutralizing antibody assay provides an example of how the system's assay tools can encourage process standardization across labs and catalyze contribution of data to a central repository for integrative analyses. the nab assay tool included in the labkey platform was developed to formalize data management for the tzm-bl nab assay  <cit> . replacing a spreadsheet macro, it simplifies data processing by providing an automated system for uploading, transforming and analyzing data and displaying results  through a web-based interface. data from the plate reader and metadata describing the experiment are imported to the server, where calculations are done automatically and results can be visualized and shared.

as part of atlas, the nab tool has been used successfully by  <dig> labs across  <dig> organizations within the enterprise . as of may  <dig>  these labs have used the nab assay tool to upload and store over  <dig>  nab assay runs. the labs use the tool not just because it enables data transfer, but because it provides immediate value. the tool provides technicians with graphical feedback that indicates whether results fall within expected bounds, and thus whether the assay has been performed correctly. the use of the nab tool facilitates standardization, organization, auditing and integration with other types of repository data, such as specimens.

scenario 3: data integration
users of labkey server can draw together information stored in multiple tables using built-in summary views, a graphical cross-source view designer and custom sql queries. datasets are typically connected through shared identifiers for subjects , samples  and/or time points of data collection . however, tables do not need be related through these types of identifiers to be joined into common views; they may also be joined through administrator-defined lookup fields. joined, integrated views can be used as the basis for complex analyses and visualizations.

figures  <dig> and  <dig> show how labkey server's graphical tools and r can be used to join, analyze and visualize data from multiple source tables based on participant/visit identifiers. figure  <dig> shows how the system's custom view designer can construct a joined view by means of a user-defined lookup relationship between two tables. figure  <dig> shows how labkey server's sql editor enables the construction of more sophisticated queries, including the inclusion of calculated columns and custom metadata. all of these figures use made-up data.

a. the participant-specific chart view marked by a displays the same type of information for each study participant, in sequence. users can toggle between the displayed chart and its associated dataset using the "view" and "data" tabs. this particular chart displays the progression of hiv viral loads and cd4+ counts over time for each study participant. 

b. a crosstab view like the one shown in b could be used to verify that different tests for determining hiv status produce consistent results. 

c. the r script displayed in the "source" tab of the r script editor  uses data from the joined custom view to compare how cd4+ counts and hiv viral loads change over time. the scripting environment makes the source dataset available as the labkey.data data frame, as circled in red. 

d. the results of the script are displayed by selecting the "view" tab of the r script builder, as shown in d. selecting the "data" tab would display the source dataset . r views, just like other views, can be saved privately or made visible to collaborators with sufficient permissions to view the source data. within labkey server's r environment, users can also invoke stored scripts and leverage advanced analysis or visualization packages, such as those provided by bioconductor <cit> .

on a labkey server, a folder-based "study" serves as the primary integration point for connecting heterogeneous data types collected as part of an observational study. a study defines built-in relationships between study data entities  and provides built-in tools for summarizing and visualizing related data.

atlas exemplifies how a labkey server can draw upon both labkey-based data and data from external systems to support observational studies. atlas's flexibility in interfacing with external databases allows it to be different things to different types of data -- a database of record, an integration point, or both. atlas interacts with several sas and postgresql databases in real time. it also imports data exported from other data sources, particularly a database of datafax case report forms, and deposits data into relevant atlas-based studies. for certain types of data , atlas is the database of record. for others , atlas is simply the integration point for diverse, specialized databases of record.

scenario 4: extensibility
labkey server's deep support for customization and rapid application development frees labs to independently adapt their servers, interfaces and analyses to lab-specific needs. client libraries in a range of languages, plus a user interface for r scripting, allow investigators to use familiar tools to build custom applications, interfaces, assays, reports and analyses. developers can add larger features by encapsulating them in modules, create individual data views in r or simply add api-enhanced content to wikis or html pages in the file system.

labkey server's client libraries are backwards-compatible, well-documented and designed to be accessible to developers with varied skill sets, from java programmers to r scripters. the client libraries provide programmatic access to labkey server modules and services  through familiar languages such as javascript, java, r, sas and perl. developers who prefer other languages, such as php, can interact with a labkey server through json over http. familiarity with labkey server's object model is not necessary to quickly produce useful applications.

all client libraries allow users with appropriate permissions to select, insert, update and delete records on a labkey server. the javascript library also includes apis for building user interfaces and executing actions commonly performed through the user interface. these include adding web parts, adding users or groups, checking permissions, executing sql queries, populating datasets, sorting and filtering grid views, requesting specimens, adding folders, building charts, navigating, and building interactive grid views, among many other actions. for example, the entire process of populating an assay  can be accomplished through the javascript client library.

labkey server provides multiple of methods for working with r. users can employ the r client library to load live data from a labkey server into an external r environment for analysis, provided the user has permissions to read the data. the r library also supports querying for available data, then inserting, updating, and deleting data records, given sufficient user permissions. in addition to the r client library, the system provides an interactive r scripting interface that allows users with appropriate permissions to author scripts, view script results and see source data, as shown in figure  <dig>  lastly, r scripts can be included as files in custom modules to define custom views for custom queries.

the sas client library provides very similar functionality to the r client library, enabling interaction with labkey server data from sas.

at present, the javascript client library is labkey server's most fully featured. while the actions available through its apis are broad and deep, they are not yet completely comprehensive. for example, it is possible to define a new assay type  using the client libraries, or to populate an existing assay design , but it is not yet possible to create a new assay design based on an existing assay type, as can be done through the user interface . due to high interest among user-funders, labkey server's client libraries are expanding quickly.

scharp developers have leveraged labkey server's client libraries extensively to quickly meet the needs of evolving studies. for example, a custom application built on atlas was used for adjudicating the results of the thai phase iii hiv vaccine study, also known as rv <dig> <cit> . this trial provided the first modest demonstration of a positive effect for an hiv vaccine. an independent, globally distributed committee judged participant hiv status during this trial by evaluating western blot images and other data through the atlas interface. using atlas, committee members travelling between research sites could log on to a web-based interface from locations across the world, view images and enter findings. the process was formerly conducted through postal mail. a single developer created the custom rv <dig> reporting tool in javascript in a matter of weeks. the tool is available only on atlas.

htvn has built custom data summaries  that allow central labs to view the cumulative success of individual technicians in processing and preserving blood cells, as measured through cell viability tests. study managers can use these summaries to swiftly identify problem areas and improve quality control. the result is a shorter feedback loop between central labs and remote labs. the summaries also provide transparency to project funders and digital historical records that take the place of paper-based tracking.

labkey server adoption
the ability of labkey server to meet core scientific and data management needs in a customizable way is demonstrated by the adoption of the platform by a range of organizations beyond the enterprise. according to data reported automatically by active labkey servers, approximately  <dig> installations are currently in active use. labkey server v <dig> , available in november  <dig>  is the 19th official, public release of the platform.

adoption of the platform has also meant adaptation; research organizations use labkey server for a wide range of purposes. for example, several labs use their installations of labkey server to manage the large quantities of data that stream from flow cytometry <cit> , proteomics <cit>  and/or microarray <cit>  experiments. two systems biology labs use labkey server to integrate diverse data types at the lab level <cit> . the national primate research center at the university of wisconsin, madison, is customizing a labkey server installation to provide an extensible, life-science-aware database for non-human primate electronic health records. these features are being developed as a custom module for labkey server that will be available to other researchers. the primate center also uses labkey server for multiplexed genotyping and next-generation sequencing experiments. a distributed team of cancer researchers based at the fred hutchinson cancer research center uses a labkey server as a place for "virtual research." team members consolidate data from existing, online databases onto their labkey server and then use r to collaboratively mine this data. two labs use labkey server for post-publication sharing <cit> . adaptivetcr, a t-cell sequencing company, has used labkey server to build a customized, proprietary system that allows customers to purchase analyses, submit specimens, view results and interactively visualize data  <cit> . insilicos, a company focused on proteomics, uses labkey server to support cloud-based, scalable computing <cit> .

atlas adoption
atlas's success in achieving adoption across the enterprise can be gauged by considering usage statistics for the system. the number of accounts  is notable given the relatively high bar for gaining access to the system, as compared to open-access databases that publish fully anonymized data. access is restricted due to privacy considerations for clinical studies on a sexually transmitted disease.

atlas held  <dig>  active user accounts in may  <dig>  the number of individual users likely lies closer to  <dig>  because some users  hold multiple accounts. approximately  <dig> additional accounts have been deactivated , so approximately  <dig>  total accounts have existed on the system. the first user account on atlas was created on october  <dig>   <dig> 

approximately  <dig> distinct organizations are represented among user accounts. roughly  <dig> distinct organizations have two or more active atlas users while approximately  <dig> distinct organizations have five or more users.

approximately  <dig> countries are represented among user accounts. the number of accounts associated with each country suggests the degree of usage in each country.  <dig> countries were associated with two or more user accounts while  <dig> countries were associated with five or more accounts.

as of may  <dig>  atlas holds  <dig>  uploaded assay runs,  <dig>  customized data views,  <dig>  unique wiki pages and  <dig>  message board posts. also as of may  <dig>  atlas has tracked  <dig>  specimens . these have been subdivided into  <dig>  vials and transferred during  <dig> , <dig> specimen "events." events record transfers of all types, including active requests for vials  and transfers without request . a total of  <dig> requests have been entered and processed through atlas, resulting in the transfer of  <dig>  individual vials. each request typically includes multiple vials.

during april  <dig>  the atlas web site welcomed  <dig>  unique visitors from  <dig> countries. the average visit included  <dig> page views over  <dig> minutes. overall, a total of  <dig>  site visits produced  <dig>  page views during this time period. these statistics are typical of recent months. the number of countries where visits originated was the only measure that notably increased over the past six months .

discussion
lessons learned
adopting a shared platform like labkey server to accomplish data integration and process standardization can bring network benefits to collaborating organizations. at the same time, achieving adoption of a new platform across a diverse community is not an easy task, even when the community is joined together into a common effort such as the enterprise. as we have learned first-hand, merely providing innovative software features is insufficient-the real challenge is making the software useful to scientists.

other researchers have proposed general principles for developing software for biologists <cit>  or for speeding the broad adoption of innovations <cit> . however, relatively few <cit>  have explored development guidelines that facilitate adoption of software across biomedical research organizations. we attribute adoption of labkey server and atlas primarily to the use of seven successful development strategies:

 enable easy extensibility and customization of interfaces, analyzes and visualizations. scientific insights often come from nonstandard approaches, so scientists have a natural preference for software that can be customized to the particular needs of their labs. tools for rapid customization have proven particularly important to both the adoption of atlas and the dissemination of labkey server. for example, scharp's development of custom applications on atlas only took off with the release of labkey server's first client api. before release of this api, development of custom interfaces typically required assistance from labkey software engineers. furthermore, system-level apis changed often, so custom applications usually broke upon upgrade. over the first  <dig>  years of the life of atlas , scharp created only  <dig> custom applications using system-level apis, for an average of  <dig>  per year. in contrast, in the first  <dig> months after the release of labkey server's javascript api ,  <dig> scharp-authored applications and tools went live on atlas, for an average of  <dig> per year.

 add value at the level of the lab bench, not just the overall enterprise, to entice users to bring data into the system. labs are more willing to adopt new data management practises if adoption makes their own work more efficient, standardized and/or reproducible. labkey server's tzm-b <dig> neutralizing antibody tool has met wide adoption because it brings immediate value to front-line labs. it translates key lab workflows into standardized data management practises that enhance efficiency and reproducibility. in contrast, adoption of labkey server's luminex assay tool has been slow because the tool does not provide a clear, direct benefit to labs. it was designed primarily to help labs put their data into a format useful to central data managers. only  <dig> luminex runs were uploaded to atlas between february  <dig> and january  <dig> ; for comparison, approximately  <dig>  nab runs were uploaded from december  <dig> to january  <dig> .

 interoperate easily with existing, external data sources. easy interoperability enables data integration without the need to first transform a labkey server into the primary or archival repository. for example, labkey server is not the database of record for enterprise specimens. instead, the atlas installation of labkey server synchronizes with existing lims systems. this allows members of the enterprise to retain existing workflows and avoid transferring legacy data to a new platform. given the extent of existing systems, the development of atlas is unlikely to have occurred without interoperability.

 practice agile <cit> , interdisciplinary software development to continually incorporate user feedback. close collaboration between data managers, research scientists and independent software engineers ensures continual focus on actual, not theoretical, user needs. the team uses short, four month release cycles and a formal feature review process to tighten the feedback loop. notably, the features that have received the most user feedback during design and development  have become the most widely used tools. features that did not have significant end-user involvement in the design process  have experienced the slowest adoption. notably, not a single elispot run has been uploaded to atlas since the initial release of the tool in may  <dig> 

 use a platform-based approach to meet shared needs cost-effectively. the labkey team works to identify common, long-term requirements for the platform so that the core system features it builds  meet shared needs using common infrastructure. new, specialized applications can simply leverage these core platform services. this lowers costs, reduces bugs and increases the speed of development. as we have learned, straying from a long-term approach  makes certain features  cost-prohibitive.

 ensure that cross-disciplinary facilitators have bandwidth for adoption. scharp data managers have played a particularly important role in the success of atlas. they have combined their understanding of research objectives with their knowledge of atlas capabilities to facilitate the upload and effective use of data, cementing adoption. for new installations of labkey server, successful adoption has often been attributable to a primary champion in a lab who has set aside sufficient time to become a skilled user of the platform. without in-house advocates and experts, adoption has often faltered.

 establish a reliable track record for ongoing, professional development, maintenance and support. don listwin of the canary foundation has quipped: " open source software has the half life of a graduate student" <cit> . given this type of scepticism and the resources required for adoption, it is particularly important to use development practises that build confidence in the longevity of the system. the labkey software team has used decades of experience in building commercial software to establish enterprise-calibre development practices for design, testing, stabilization, deployment and support. some practises, such as automated exception reporting and public transparency, go beyond those common in the industry. official builds of the platform are released with regularity, three times per year.

limitations of labkey server
most biomedical research organizations have unique and evolving software needs due to their specific suites of pre-existing infrastructure, distinctive organizational processes, and involvement in rapidly changing areas of science. a data integration platform like labkey server must therefore be tailored to such an organization's needs before the system becomes useful. the effort to successfully establish an installation of the platform should not be underestimated.

additional boundaries of the platform stem from its scientific focus. the platform provides little direct support for managing the business side of scientific enterprises. it provides specimen request management and generalized issue tracking, but it does not replace existing tools for such things as ordering reagents, tracking inventory, managing freezer layouts and scheduling work shifts. the platform does not aim to replace mass-market collaboration software, so it does not provide sharepoint-style document co-authoring.

labkey server's facilities for tracking disease progression over time focus principally on associating data with individuals  and time points. these tools are less useful for experimental lab studies that focus on replicates, such as experiments on yeast biochemistry. studies that require location as a key identifier, such as geographic studies of disease spread, would require support that is not yet built into the platform. the system is not currently designed around the execution of clinical trials; nevertheless, organizations such as hvtn still use it to share and adjudicate results.

at present, the study-based specimen tracking and request system requires that uploaded specimen data conform to a specific format based on the output of a particular lims, ldms <cit> . greater flexibility towards specimen input formats would not be difficult to add. the system already provides other tools for tracking arbitrarily shaped specimen data, but these do not support requests.

labkey server provides features  that are designed to meet the requirements of fda regulation  <dig> cfr part  <dig>  however, no installation of the platform has yet undergone full, formal evaluation for compliance. compliance can only be certified for installations of software, not the software itself.

labkey provides for data export in multiple formats, but does not yet provide protocols for data transfer to permanent, domain-specific archives, as do isa and simbioms <cit> .

next steps for labkey server in support of atlas
a key future focus for atlas will be the development of new tools for interactive visualization and data exploration. these tools will allow more efficient extraction of information and insight from atlas. data exploration features will include interactive graphics, new tabular displays tailored to requests from investigators and tools for quickly performing analysis of variance  calculations and other statistical analyses. the data exploration tools will be combined with improved data submission capabilities, allowing investigators to swiftly and easily combine their own data with data stored on atlas. in addition, we expect to simplify the application of existing ontologies to data types, allowing richer integration of data across independent datasets. we are also prototyping a distributed hiv dataspace  <cit>  that would provide a catalogue of data stored in a variety of locations.

additional areas of focus may include the development of new custom assay tools  and the enhancement of full-text search. integrating deeper knowledge of biomedical concepts into full-text search would better enable searches for scientifically relevant information.

additional next steps for labkey server
future areas of focus depend on the needs of users who fund further development of the core platform. enhancements to the labkey client libraries to aid application development have been a particularly consistent area of focus among user-funders. support for next-generation sequencing data and integration with galaxy <cit>  is currently funded and under development. adoption of the platform by consortia studying diseases beyond hiv would require certain enhancements, such as new custom data types, but the basic platform has been designed for use by consortia studying any disease.

CONCLUSIONS
sharing data, analysis tools and infrastructure can accelerate the efforts of large research consortia by enabling new insights and enhancing efficiency. the atlas installation of labkey server demonstrates the utility of the labkey platform for collaborative research. like all labkey server installations, atlas supports secure, web-based data sharing and collaboration from the earliest stages of disease research; enables integration of diverse and changing data types based on subject and/or visit identifiers; allows easy customization of interfaces, wizards, analyses, and visualizations; supports programmatic automation and customization; supplies advanced tools for data querying, search and analysis; provides dynamic access to external databases; enables staging of data based on quality control status; and provides specimen request management.

real-world adoption of atlas by members of the enterprise has helped the labkey server team refine the features of the base platform to suit the needs of a wide range of researchers. functionality tailored to be useful to a broad array of scientists has helped to catalyze adoption of the platform beyond the enterprise. funding agencies' growing enthusiasm for collaboration among disease researchers <cit>  suggests that the platform will become increasingly useful to a wider circle of researchers focused on other diseases.

labkey server's open source license means that other research consortia can freely adapt the base platform to their needs while contributing new features back to the effort and improving the software for all users. the platform's track record of regular, stable releases and ongoing maintenance provide a reassuring complement to its open source availability.

