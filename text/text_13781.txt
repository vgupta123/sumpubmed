BACKGROUND
in recent years the amount of biological data generated have been increasing greatly, and with the advent of new technologies like next generation sequencing this trend is likely to increase. additionally, new analysis and re-analysis techniques help to produce better and more accurate derived results every day. making all this data and results publicly available can be of great benefit for the scientific community as a whole, since valid biological data can be used both by field researchers and by those developing new methodologies and algorithms. sharing raw research data allows others to conduct re-analysis and meta-analysis, usually reinforcing the previous results or even producing novel ones. arrayexpress  <cit>  and geo  <cit>  have had a very positive effect on microarray research development and have been heavily used in the development of both new data analysis techniques and biological knowledge. sharing research results eases rapid spreading of new findings and its incorporation in ongoing research increasing its overall usefulness.

the effects of this sharing can be greatly increased if data and results are made publicly available using some kind of machine readable standard format allowing them to be seamlessly used by other researchers.

while making the raw data available as supplementary material attached to the publication of a paper can be useful and other researchers can certainly use it, its integration with data from other sources will still be difficult and will not help fully automatic approaches such as workflows. however, if this same data is made available in a standard machine readable format it can be easily integrated with data coming from other standard sources and automatically displayed and analyzed.

the distributed annotation system  is a complete system for sharing annotations on biological sequences. it comprises a standard xml based file format, an accurate definition of the semantics of the data -based on the use of ontologies of biological terms-, and an http based rest style protocol for sharing those annotations  <cit> . figure  <dig> is an overview of the das system. many annotation servers can provide annotations of sequence objects provided by a reference server, for example ensembl or uniprot. while initially designed to annotate genomic sequences, das has support for both genomic and protein annotations, for sequence alignment data, and for structural information. other federated systems exist for other types of biological data, such as psicquic  <cit>  for molecular interaction data.

das client-server architecture was designed around the idea of having a small number of complex clients integrating data coming from, potentially, many of different simple sources. some examples of das clients are ensembl  <cit> , dasty <dig>  <cit> , gbrowse  <cit> , jalview  <cit> , spice  <cit> , pepper  <cit> , dasher  <cit> . sharing biological data on das allows data providers to leverage the das ecosystem and make it easy to integrate their data with other existing sources.

das server software is available in different programming languages, such as proserver  <cit>  in perl and dazzle  <cit>  and mydas  <cit>  in java. however, despite the idea of das servers being simple, setting up a das server is not a trivial task. das servers allow for a great flexibility on where the actual data is stored and how it is structured. usually the backend is database, but files and other options are also viable. the downside of this flexibility is that very often data providers will need to implement a custom made data access layer mapping their real data layout to the das concepts used in the server and this will have to be done either in perl or java. there are many research groups who will not have easy access to people proficient enough in programming to implement that access layer. in addition, setting up and managing an internet accessible machine to host the server can be also difficult or a too big overhead for many data generators, mainly for those with small data sets.

thus, the challenge: converting all those data generators into data providers, increasing the amount and variety of the biological data available to the scientific community and contributing to the collective annotation of biological sequences.

RESULTS
easydas has been developed to help on that conversion offering a web-based and ready-to-use system for biological data sharing using das. the user only needs to upload a text file with the data into easydas and set a few configuration options, mainly stating what the data represents, and the system will automatically create a new das source. although the das source will be automatically created and managed by easydas, the user will retain full control over the data and will be able to modify or delete it at any point using the same web interface.

we envision easydas being useful for a wide range of potential das users. biologists producing annotations can create das sources to take advantage of the das infrastructure to integrate their data into ensembl or other das clients. creating a das source can also be used to spread new experimental results and share them with other researchers. computational biologists and bioinformaticians developing new analysis or prediction tools can easily create new sources with the results of applying those new tools to known datasets making their example runs publicly available and usable. finally, and since there is no limit on the number of sources to be created by a user, personal datasets can be also published in easydas, creating as many temporary sources as needed. this would allow bioinformatics service groups to create tailored sources containing, for example, the set of genes resulting from a microarray analysis or study-specific annotations of proteins. in any case, the user is relieved from the burden of setting up and maintaining their own das servers.

easydas is fully compliant with the recently approved das  <dig>  specification  <cit>  and encourages the new systematic semantic annotation of features via an integrated ontology browser based on the ontology lookup service  <cit> .

an easydas is freely available at http://www.ebi.ac.uk/panda-srv/easydas.

easydas is open source software under the gnu lgpl license. the project is hosted at google code and can be freely accessed and downloaded at http://code.google.com/p/easydas/.

system description
easydas exposes two different entry points to the users. the first one is a web interface where sources can be found, created and managed. the other one is the das server, which exposes the data using the das protocol. the main components of easydas web interface are a users management system, a list of the existing data sources and a wizard for creating new sources.

the main page in the easydas web interface is the list of the available sources with their descriptions and urls . this list offers easy access to data sources created by any user, facilitating the use and spreading of that data. links to popular das clients like ensembl are provided too, and will usually attach the source to the viewer automatically. all easydas sources can also be registered in the das registry  <cit>  to further increase their visibility.

to create a new das source based on a custom dataset, a wizard-like interface will guide the user through the whole process: uploading the file and providing some information about the structure and type of data in the file. this wizard can be invoked clicking on the "create a new source" button in the main page. although das supports alignment and  <dig> d structure annotations in addition to the standard sequence annotations, those capabilities are currently not heavily used -about 1% of the registered sources offer them- and usually provided by specialized sources. thus, and since the vast majority of users are willing to share mainly sequence annotations, easydas does not support them.

easydas provides a rich user interface with standard elements like dialogs and wizards resembling those of a desktop application. it is completely ajax driven to increase usability and interactivity and to improve system response time.

user registration
users can register to the system using either openid  <cit>  or a traditional username/password pair. all sources created by registered users can be updated, modified or even deleted after creation and can exist for an unlimited time. sources created by unregistered users will be considered "anonymous" sources and will be online for a limited time only. anonymous sources cannot be modified or deleted.

when a user is logged into the system, a second tab will be activated in the main page listing only the sources created by the user. the source modification and deletion functionality can be accessed from that table.

source privacy
it is very important to note that, as almost any other das source, easydas sources are fully public and accessible by anyone through a simple url. although it's possible to mark a source so it's not published in the main easydas list, this will not control the access to the actual data. it is not currently possible to create private das sources using easydas.

file formats
the currently supported file formats are the general feature format  and a versatile implementation of the comma separated values  where the separator can be any character . while gff is a commonly used format that many bioinformatics software can export, csv can be obtained from any tabular data using a spreadsheet program like microsoft excel or openoffice calc.

some minor extensions and modifications to the formats are supported, like comments on csv files.

additionally, easydas specific information can be added in the form of special comments containing metadata. those special comments can be used to pre-configure the source metadata so even less work is required on the web interface. examples of such comments are the gff options source-name, source-title or source-maintainer that will be used to pre-populate the corresponding source metadata fields.

semantic annotation
one of the important additions of the version  <dig>  of the das specification is the standardization of the semantic annotation of features. each annotation in das has a property describing its type , and another describing how it was generated . both properties could already be expressed using ontology terms, but the inclusion of the cvid attribute to specify the controlled vocabulary identifier associated to types and methods and the recommendation of using specific ontologies standardizes those options and makes semantic management of das sources and features easier. specifying ontology terms for feature types will improve data integration and organization in semantic-aware clients like dasty <dig> that offer ontology based filtering and grouping. by having most of the sources semantically annotated, easydas will be well placed to take advantage of a future semantic search function in the das registry.

easydas encourages the correct use of those new attributes and has a simple ontology browsing and searching widget . that widget offers interactive browsing of ontologies using on-demand leaf expansion and complete text search capabilities. all that functionality is backed by the web services provided by the ontology lookup service. the ontologies recommended in the das specification, sequence ontology  <cit> , biosapiens ontology  <cit>  and psi-mod  <cit>  and evidence code ontology, can be used to annotate the features. any other ontology available on ols can be added upon request.

to help in the process of selecting the right ontology terms and to improve annotation consistency, the selected ontology terms are stored in the database and associated to the user and the identifier used in the data file. thus, when creating other sources using similar data and the same type identifier, the ontology terms will be preselected.

mapping
the mapping of the data file fields into das concepts is one of the most important parts in the process of creating a source. the mapping interface, a table showing the data on the file plus a series of comboboxes, is flexible and allows the user to specify the relations as one-to-one, one-to-many or even many-to-many, where it makes sense.

for semantically specified file formats like gff, a mapping taking that information into account is proposed. for other file formats, when data file fields have names -such as column names on tabular files-some simple pattern-matching heuristics are used to create a proposed mapping. users can always change that proposal to adapt it to their specific needs.

coordinate systems
another important concept in das is that of coordinate systems. they uniquely identify the sequences being annotated. in genomic das, for example, a coordinate system is defined by a species and assembly -i.e. we can specify that we are annotating the current genomic sequence for human by saying its the assembly "grch37" of "homo sapiens". while not required -there are cases when no suitable coordinate system is available, like when annotating a newly sequenced organism-, it is strongly recommended to specify the coordinate system for a new source. most of the clients will refuse to integrate sources without a coordinate system, since it's not possible to ensure that the annotations are referring to the same sequence. easydas provides a simple coordinate system selector with all the coordinates systems available on the das registry. it is possible to filter by any of the fields to help finding the right coordinate system for the source.

source creation
the source creation functionality is based on a wizard-like interface with a series of simple steps that guide the user through the process of defining the new source. at every step as much information as possible is extracted from either the data file or the context to reduce users' work and decisions to the minimum.

the creation process starts with the file upload form where a simple file selector field is available. while the user can specify the format of the uploaded file, some heuristics are in place to detect the format automatically. this will usually be the best option.

the second step in the source creation wizard shows a preview of how the file has been identified and parsed and some additional options to further refine the parsing . in case the automatic format identification mechanism fails, it is possible to amend the format selection in this second step .

the basic source metadata is gathered in the next step. the identifier of the source , its title, description and maintainer are specified here. the source coordinates system dialog is accessible from this step too.

the fourth step is the mapping form. in this step, the user is required to link the data fields present in the uploaded data file to the standard das fields. this is the description of the data required to transform the data in the file into the das format. this is the last required step and it is possible to finish the wizard at any point from here.

to help in the simplification of the data files, it is not necessary to specify all the data fields for every feature in the file. the defaults form allows the user to define default values for absent fields or even for partially filled ones. it would be possible, for example, to specify the same method, type or score for all the features at once, maintaining those das concepts out of the primary data files.

the last two steps are used to specify the semantic annotations of the features. the ontology browser can be used to select the terms best describing the types and methods of the features in the file.

data storage and access
the easydas interface is available at different address to the web interface and can be queried using standard das requests. from a das point of view, each registered user has his own das server and his sources are created in that server. for example a user with a server name john would have a source called dataset <dig> available at http://www.ebi.ac.uk/das-srv/easydas/john/das/dataset <dig> and a list of all his sources at http://www.ebi.ac.uk/das-srv/easydas/john/das/sources. all the das requests are served by a slightly customized proserver  <cit>  also running on the ebi systems.

a mysql relational database is used to store the sources data and can be accessed by both the web interface and the das server.

custom easydas instances
easydas is free open source software. its source code can be downloaded and modified freely in the terms of the gnu lgpl license. although the reference instance is running at the ebi, it also means that it is possible to make custom installs of easydas independent of the ebi servers. it would be possible, for example, for an organization to provide a custom easydas setup in their own network so its groups can publish their data from the organization servers. it would even be possible to install easydas inside a private network and setup the included proserver to reply only to requests coming from inside the network. that could be useful for organizations working with sensitive data but willing to share data between their own groups.

CONCLUSIONS
we have developed a system for the automatic creation of das sources. users can upload data files with sequence annotations in different formats and define and create a new das source via a simple web-based wizard. sources data will be stored on the ebi systems and freely available through a standard das interface. data uploaded to easydas can then be easily integrated with other data on das using any of the available das clients such as ensembl or dasty <dig>  easydas das sources are completely public and no access restrictions of any kind are applied.

as of today, using easydas is the easiest and fastest way of sharing a small or medium datasets over the das network. we think that this ease will encourage researchers with novel and unavailable datasets to publish and share them increasing the total amount of biological information available to the scientific community. additionally, easydas will help those who need to share biological sequence annotations but can not run their own das server.

implementation
easydas has two different entry points to the system: the web interface and the das server. the web interface is a client-server application, with the client being a web application written in javascript and the server a set of cgi perl scripts. the web interface is in charge of uploading and parsing the users datasets and offers the interface to define and manage the das sources. the other entry point, the das server, is a standalone proserver instance with some minor modifications and is the one responding to the actual das commands to access to the data. a mysql relational database accessible by both the web interface server side and proserver stores the actual data .

web interface
the web interface has two different parts, the client and the server. communication between those parts is based on ajax calls from the client to the server with json as the transport format.

client
the web interface client part is a rich internet application  managing the user interaction with the system. it has been written in javascript and takes advantage of the object oriented nature of the language. the client uses the jquery library to ease the dom manipulation and to overcome the cross-browser compatibility issues. while offering a rich interactive user interface, easydas' ui needs were simple and so the interface is custom built and only minimal parts of the jqueryui framework are used .

server
the server side of the web interface has been implemented as a set of perl cgi scripts running behind an apache server. a custom easydas module provides the actual functionality and defines a basic file parser class. the different parsers are specializations of that class and completely independent of other parsers, so adding a new file parser to the system is quite straightforward and does not require the modification of any other file on the system.

database
the data back-end for easydas data is a mysql relational database. the database is used to store both the information regarding the easydas system -such as which users are registered and what sources are available- and the actual biological data, the content of the das sources. the database schema was designed with the goal of isolating the sources as much as possible and so it has a set of six small tables for every source. this table setting maps very well to the hydra capability of the underlying das server and reduces the amount of code needed to implement the multiheaded das server. in addition, it simplyfies data insertion -no concurrent writes can happen on the same table- and deletion of sources -only whole table drops are required. although the performance requirements of the database are low at the moment, it would be relatively easy to span the data over multiple database servers if it was needed.

this database is also accessible from the das server and so is the link between the two sides of the system.

das server
the das server in easydas is a proserver with a minor customization. proserver, written in perl and already extensively used in the ebi systems, offers both the power and efficiency required to potentially serve hundreds or thousands of das sources.

one feature that sets proserver apart from other das servers is its capability to create multi-headed das sources, what it calls a hydra source. hydra sources do not require specific per-source configuration as any other source type, but can be created on the fly by a perl function -which in easydas is querying the database- based on a single basic configuration. without hydras, either the server must be restarted on every source modification or many individual servers should have been created, requiring much more server power than the single proserver instance in use. while it is true that other approaches would have been possible, none of them is so simple and yet powerful as using proserver hydras.

availability and requirements
• project name: easydas

• project home page: http://code.google.com/p/easydas/

• operating system: platform independent 

• programming language: javascript, perl

• other requirements: none

• license: gnu lgpl

• any restrictions to use by non-academics: none

authors' contributions
aj, rj and hh conceived the original idea of the system. bgm, aj and rj designed the system and bgm implemented it. aj helped with the das server implementation. xmp and hh supervised the work. bgm drafted the manuscript. all authors read and approved the final manuscript.

