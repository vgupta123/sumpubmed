BACKGROUND
for over a decade, two-channel transcriptomics microarrays have provided a powerful approach to study genome-wide gene expression events. now, continued development of two-channel microarray technology has enabled extending our experimentation to the next level: regulation of gene transcription. one of the most popular techniques in this field combines chromatin immunoprecipitation  assays with two-channel microarray technology . chip-on-chip studies are used to detect any protein-dna interaction genome-wide, such as transcription factor binding, but also epigenetic events such as histone modifications, as long as a suitable antibody is available. the same approach is used to detect dna methylation, by using either an antibody that interacts with methyl-cpg-binding domain  proteins bound to methylated cpg dinucleotides , or an antibody that interacts with methylated cpg dinucleotides directly  assay  <cit> ).

even though newer technologies such as chip-sequencing  are on the rise, two-channel microarrays still present a valuable approach to understanding gene transcription regulation events, and during the last decade have opened opportunities to identify novel targets and markers in complex diseases such as cancer  <cit> , heart failure  <cit>  and diet-related disorders  <cit> , and psychiatric disorders such as depression, schizophrenia and addiction  <cit> . since the main appliance of this technology at the time being is gene transcription regulation studies - transcription factor and co-regulator binding, dna methylation, and histone modifications - the term 'regulation microarrays' will be used for brevity henceforth.

the design and the experimental approach for regulation microarrays are very different from the more extensively studied transcriptomics microarrays, which has implications for data pre-processing procedures. the key difference is that in transcriptomics microarrays both channels contain amplified transcript samples, usually corresponding to two different experimental conditions, while in regulation microarrays the channels comprise an experimental sample and a reference sample. the cyanine  <dig> , or green, channel of regulation microarrays generally contains the total dna sample that gives the reference baseline signal, and the cyanine  <dig> , or red, channel contains an experimentally enriched dna sample, extracted using a specific antibody binding to a dna-interacting protein  or directly to methylated cpgs on the dna . hence, while the log-ratio between the channel signals represents the differential expression between two conditions in transcriptomics studies, for regulation microarrays it is used as a measure of enrichment: the higher the log-ratio of a probe or set of tiling probes, the higher the likelihood that the corresponding region in the genome has a high level of methylation or is targeted by a dna-interacting protein.

another important assumption in regulation microarrays is that a dna-interacting protein is either bound or not bound  and that a target sequence is either methylated or not . regardless, depending on binding affinity, mean time of residence and other factors, the fraction of cells with bound protein or a particular methylation status is not an all-or-nothing condition, especially in heterogeneous tissues. combined with the characteristics of the data distribution surrounding a site of interest  and probe effects  <cit> , this produces a continuous log-ratio distribution. however, the characteristics of the samples hybridized to the channels force a dichotomy upon the log-ratio distribution, which is comprised of two components  commonly referred to as an enriched and an un-enriched component  <cit> . the enriched component corresponds to the probes to which the experimental dna has hybridized and the un-enriched component to the probes whose targets are largely absent from the experimental dna sample. hence, contrary to transcriptomics microarray data, where low log-ratio values are meaningful as long as the differences between conditions are statistically significant, when interpreting chip-on-chip and dna methylation microarray data, the upper quantile is of most interest, as it generally comprises mostly enriched probes. based on this assumption, enrichment finding algorithms like acme  <cit> , will test if a set of tiling probes is significantly more likely to be a sampling of this upper quantile than of the rest of the data, assuming that if this is the case, this set of tiling probes corresponds to a protein binding site or methylated region. a better separation between the enriched and un-enriched components hence increases the power to identify enriched regions. thus, a crucial aspect in regulation studies is that any separation between the enriched and un-enriched components present in the data before normalization, should be kept afterwards. apart from conserving this separation, other aspects need to be taken into account when normalizing regulation microarray data.

normalization is a process that is applied at multiple levels connected to spatial  <cit> , probe  <cit>  and dye or intensity dependent biases  <cit> . additionally, differences in print quality, differences in ambient conditions when the plates were processed or changes in the scanner settings can cause scaling differences between microarrays. most of the assumptions underlying the process of correcting for these biases are identical for transcriptomics microarrays and regulation microarrays. the exception is the correction for intensity dependent bias, for which the most common approaches in use for transcriptomics microarrays are lowess normalization  <cit>  and quantile normalization  <cit> . both methods are based on the assumption that the majority of probe signals are unchanged between channels and microarrays, which generally holds for transcriptomics studies  <cit> . in regulation studies however, this assumption does not hold since the samples comprising the two channels differ to a large extent.

based on these observations, the main challenge of the normalization of regulation microarrays is  to make the signals of individual microarrays quantitatively comparable and  to retain the separation between the enriched and un-enriched components present in the data. programs like cocas  <cit>  offer a range of normalization methods for regulation microarrays, including quantile normalization  <cit>  and variance stabilizing normalization  <cit> , and r/bioconductor  <cit>  offers many more popular choices, which may not all be suitable for this challenge. hence, we here assess the efficacy in removing technical biases and in preservation of the separation between the enriched and un-enriched components, for six two-channel microarray normalization methods  applied to five published chip-on-chip and medip-on-chip datasets on the nimblegen platform.

RESULTS
to determine the efficacy in correcting for technical biases and improving comparability between microarrays, quality control and bias assessment was performed on all datasets before and after normalization for each of the six normalization approaches. complete results are available in additional file  <dig> and  <dig>  in all datasets scaling effects between microarrays and intensity dependent bias within microarrays are present, visible from the microarray data distributions. all tested normalization methods are able to correct for the observed biases, where from a technical standpoint, normalization approaches that normalize channels together  equalize the data distributions to a larger extent than normalization approaches that normalize the channels separately . in the latter category, t-quantile normalization enhances overall comparability to a larger extent than tukey's biweight scaling.

to evaluate the separation between the enriched and un-enriched components, the gene promoter probe and the negative control probe log-ratio distributions were assessed using roc curves before and after normalization with each of the six normalization approaches . the raw data from dataset # <dig>  shows largely overlapping control probe and gene promoter probe distributions . between individual microarrays, the distributions show larger differences, also resulting in more variation in both the area under the curve  as well as the shape of the roc curves, indicating that comparability between microarrays is hindered by lack of normalization.

the results of the combined data of the individual microarrays from the six normalization approaches  show equal performance of all approaches for dataset # <dig> , resulting in roc curves with similar shape and comparable auc values. based on the auc values, separation between components is best when using peng's method.

dataset # <dig>  the second chip-on-chip dataset gives different results . separation between components is preserved best when using t-quantile or tukey's biweight scaling normalization . the other approaches, including peng's method, alter the ranking of probes resulting in the control probe and gene promoter probe distributions becoming superimposed. vsn normalization appears to scale the distributions, enforcing a larger spread compared to the data acquired through the other normalization approaches .

tukey's biweight scaling and t-quantile normalization appear to perform comparably with respect to conserving the component separation. tukey's biweight scaling adjusts the log-ratio data with a scaling factor for each microarray in the dataset individually, which means that the roc curves will be identical to those of the raw data, and that the distributions will be the same as those before normalization save for a shift. this may explain the variability observed in the individual roc curves and auc values of the tukey's biweight scaling normalized data. t-quantile normalization reduces the variability between the data distributions of individual microarrays, resulting in roc curves that are more comparable in both shape and auc .

the results of the medip-on-chip datasets support the conclusions reached for the chip-on-chip datasets: separation of the components present before normalization  are preserved best with t-quantile and tukey's biweight scaling approaches . lowess, quantile, vsn and peng's normalization alter the distributions and eradicate the separation. in dataset # <dig>  the differences between the normalization approaches is less striking, illustrated by similarly shaped roc curves and auc values . dataset # <dig> shows a larger heterogeneity between individual microarrays than both dataset # <dig> and # <dig>  for both dataset # <dig> and # <dig> tukey's biweight scaling and t-quantile normalization produce higher auc values for these approaches . both methods appear to perform comparably with respect to conserving the component separation. however, as in dataset # <dig>  the differences between both approaches are highlighted by the distributions of the individual microarrays: tukey's biweight scaling adjusts each microarray individually, whereas t-quantile normalization is applied between microarrays. t-quantile normalization thereby results in roc curves with less variation in shape and auc  than those of the raw data and the tukey's biweight scaling normalized data.

any appropriate normalization method should preserve the biological information present in the raw data. assessing the distributions of the negative control probes and the gene promoter probes is a global indicator of this conservation of biological information. in addition, three datasets with suitable positive controls were used to assess the impact of the normalization approaches on the power to identify significant enrichment for specific genomic regions. acme  <cit>  was used for all enrichment calculations. for dataset # <dig>   <dig> validated er-a targets were used as positive controls  <cit> . the results are reported in table  <dig> for all normalization approaches and for several enrichment p-value cut-offs . t-quantile and quantile normalization in general result in identification of more targets at each cut-off.

for dataset # <dig> enrichment of the hoxa group of developmental genes was calculated. hoxa genes are located in a cluster on chromosome  <dig> and are known to be switched off and moderately to highly methylated in most tissues  <cit> . the negative 10log-transformed enrichment p-values plotted along the hoxa region are shown in figure  <dig> . using tukey's biweight scaling or t-quantile normalization results in identification of several enriched loci, most of which are moderately methylated. less loci are found when using vsn, quantile or lowess normalization. peng's method results in identification of only a few loci with moderate enrichment.

for dataset # <dig> enrichment was determined for the dlk1-gtl <dig> cluster on chromosome  <dig>  a region reported in the original results  <cit>  to be highly enriched. for all normalization approaches in dataset # <dig> the same area in this region is identified as very highly enriched .

discussion
two-channel transcriptomics and regulation microarrays should not be pre-processed in the same manner. appropriate normalization strategies for regulation microarrays are characterized by their ability to retain the separation between the enriched and un-enriched components present in the data whilst enhancing comparability between microarrays. six normalization methods were tested by  assessing the separation between the control probe and gene promoter probe distributions before and after normalization using roc curves and  by verifying whether known enriched genes and regions could be identified as such after normalization. we have shown that the result of each approach depends heavily on the situation before normalization, specifically the amount of enriched and un-enriched probes and the separation between the corresponding components in the raw data. these two characteristics are different for each experiment, depending largely on the biological system studied and the applied assay.

in the chip-on-chip datasets used here, the distributions of the control probes and gene promoter probes overlap to a large extent before and after normalization. this may be explained by the small proportion of the genome generally covered by the potential binding sites of a dna-interacting protein and the resulting small contribution of the enriched component. hence in general, the lower the amount of binding sites, the more similar the control probe and gene promoter distributions, and the more comparable the performance of the normalization approaches, based on roc curves of both distributions before and after normalization. however, in some cases vsn can cause a sizeable rescaling of the distributions, and to a spurious control probe distribution with a higher mean and spread than the gene promoter probe distribution. this renders gene promoter probes in the upper quantile of the data indistinguishable from random data, strongly impacting the biological interpretation.

in dna methylation microarrays the amount of enriched probes and un-enriched probes is of the same order, since in general the proportion of methylated cpg di-nucleotides in a genome is substantial. we have shown that for such microarrays, the choice for a normalization procedure will be crucial for the downstream analysis. all three medip-on-chip datasets show a large degree of separation between the gene promoter and control probe distributions. the separation is lost when using normalization methods that normalize channels together, such as vsn, lowess, peng's method and quantile normalization. using lowess approaches on medip-on-chip data has been reported elsewhere to result in increased bias, because the underlying assumption that the log-ratio should be independent of the average individual channel signals does not hold for this type of data. dna methylation levels are related to cpg and gc density, while signal intensity is also known to be influenced by gc content. forcing the log-ratio to be independent of the average signal intensity using lowess normalization thus introduces bias instead of removing it  <cit> .

t-quantile normalization, applied separately on the channels, and tukey's biweight scaling are the only approaches that are able to preserve the component separation in all example datasets. in dataset # <dig>  individual microarrays already showed comparable distributions before normalization; hence for this dataset, tukey's biweight scaling would be sufficient. in contrast, dataset # <dig> for example showed a large heterogeneity between individual microarrays, in which case between-microarray normalization is better suited to improve the overall comparability and enable quantitative data comparison. this can be achieved either by doing an additional normalization step after scaling, but ideally by using a between-microarray normalization approach from the beginning, such as applying t-quantile normalization as demonstrated here.

in regulation microarrays the sequence content of the input dna sample and the experimental dna sample always differs to a large extent. there are also instances for transcriptomics microarrays, such as dedicated microarrays designed for a specific biological context, where the assumption that the majority of genes are not differentially expressed does not hold, hence requiring adapted normalization strategies. most of these strategies involve the use of invariant genes, either present on the slide  <cit>  or determined from the data  <cit> . selecting invariant probes in chip-on-chip and dna methylation data is difficult however, even when selecting the control probes used in the analysis presented here, because this would implicate a normalization based on un-enriched probes. since the sequences meant to hybridize to these probes are largely absent from the experimental sample, they essentially measure background noise in the channel containing the experimental sample. variation in log-ratio values of these un-enriched probes between microarrays therefore reflects methodological effects rather than biology, which compromises their usability. to avoid the use of invariant genes in transcriptomics microarrays, a three-component mixture model has been proposed  <cit> . the normalization parameters are estimated independently in the groups of up-regulated, down-regulated and unchanged genes and normalized separately. such a model in adapted form can be fitted on regulation microarray data and used conjointly with enrichment finding. it has been shown that for dna methylation studies using specific reference samples, such as a fully methylated total dna sample, it is possible to make robust estimates for methylation percentages when using such a model  <cit> .

the research described herein is limited to the normalization of replicate microarrays. in many cases however, a study will consist of multiple conditions, such as different tissues, or treatment and control samples as demonstrated in dataset # <dig>  in these cases, the experimental dna samples may differ to a large extent between treatment and control groups, warranting application of normalization to each condition separately. however, when only a relatively small amount of loci is expected to be differentially enriched and the total amount of enrichment can be assumed constant between conditions, normalization approaches applied to the dataset as a whole are more appropriate. this holds for experiments such as dna methylation studies on the same tissue treated with a micronutrient  <cit> , where only a projected limited amount of important regulatory regions with substantially altered levels of methylation is of interest.

the results of known targets and enriched regions show consistent differences between the various normalization approaches. when looking at the dlk1-gtl <dig> cluster for the dna methylation data of dataset # <dig>  a region reported to be highly enriched in the original findings, it is clear that such highly enriched regions will be identified as such regardless of the chosen normalization approach. this is not the case when studying moderately enriched regions, as illustrated by the results of the hoxa cluster in dataset # <dig>  where the degree to which this region is identified as being enriched depends strongly on the applied normalization approach. overall, t-quantile normalization and tukey's biweight scaling again give the best results. a potential cause of the observed difference between the tested normalization approaches is observed in the results on global level: the ranking of probes changes when using some normalization approaches, increasing the likelihood of un-enriched probes being spread over the whole dynamic range of the enriched probe distribution. ultimately, such changes in the ranking can be destructive on the power to call differences in methylation or protein binding. also, enrichment finding algorithms  <cit>  as used for these results, will test if a group of tiling probes is significantly more likely to be part of the upper quantile than of the rest of the data distribution, assuming that if this is the case, this group of tiling probes shows significant enrichment and thus corresponds to a binding site or methylated region. this upper quantile can be defined for each microarray individually after normalization. hence, it is not the values themselves, but the rank in the data distribution which is biologically relevant. considering this, within channel and treatment normalization approaches do not only enable a more robust data interpretation, but since for many applications the individual values themselves do not need to be comparable, they are also sufficient.

CONCLUSIONS
the main issue of chip-on-chip and dna methylation microarray normalization is to enhance comparability between microarrays, while keeping the separation between the enriched and un-enriched components present in the data. within-channel approaches give the best performance, with enhanced comparability between individual microarrays for approaches that also normalize between microarrays. more specifically, quantile, lowess, peng's and vsn normalization alter the signal distributions to such an extent that it will impact the reliability of the downstream analysis substantially. better results are obtained with t-quantile normalization applied separately on the channels or tukey's biweight scaling. for all datasets tested, these two methods consistently outperform the other tested methods in conservation of separation between the enriched and un-enriched distributions, as well as in identification of genomic regions known to be enriched. the t-quantile approach is preferable because it additionally yields enhanced comparability between microarrays.

