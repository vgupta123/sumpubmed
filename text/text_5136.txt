BACKGROUND
abbreviations are widely used in biomedical text. the amount of biomedical text is growing faster than ever. in early  <dig>  medline included about  <dig> million references. for common technical terms in biomedical text, people tend to use an abbreviation rather than using the full term  <cit> . in this paper we interchangeably use the term short form  for an abbreviation and long form  for its definition. along with the growing volume of biomedical texts the number of resulting sf-lf pairs will also increase. the presence of unrecognized words in text affects information retrieval and information extraction in the biomedical domain  <cit> . this creates the continual need to keep up with new information, such as new sf-lf pairs. a robust method to identify the sfs and their corresponding lfs within the same article can resolve the meaning of the sf later in the article. in addition, an automatic method enables one to construct an abbreviation and definition database from a large data set.

another challenging issue is how to evaluate the pairs found by an automatic abbreviation identification algorithm, especially when dealing with a large and growing database such as medline. it is impractical to manually annotate the whole database to evaluate the accuracy of pairs found by the algorithm. an automatic way to estimate the accuracy of extracted sf-lf pairs is helpful to save human labor and to accomplish a full automatic processing of abbreviation identification and evaluation.

in this paper we propose an abbreviation identification algorithm that employs a number of rules to extract potential sf-lf pairs and a variety of strategies to identify the most probable lfs. the reliability of a strategy can be estimated which we term pseudo-precision . multiple strategies – each performing a specific string match – are applied sequentially, from the most reliable to the least reliable, until a lf is found for a given sf or the list is exhausted. since the algorithm starts from the most reliable strategy it can identify the most probable lf if multiple lf candidates exist. no gold standard is required.

many methods have been proposed to automatically identify abbreviations. schwartz and hearst  <cit>  developed a simple and fast algorithm that searches backwards from the end of both potential sf and lf and finds the shortest lf that matches a sf. a character in a sf can match at any point in a potential lf, but the first character of a sf must match the initial character of the first word in a lf. they achieved 96% precision and 82% recall on the medstract corpus  <cit>  which was higher than previous studies  <cit> . schwartz and hearst also annotated  <dig> medline abstracts randomly selected from the output of the query term "yeast" and achieved 95% precision and 82% recall. their algorithm is efficient and produces relatively high precision and recall.

yu et al.  <cit>  developed pattern-matching rules to map sfs to their lfs in biomedical articles. their algorithm extracts all potential lfs that begin with the first letter of the sf and iteratively applies a set of pattern-matching rules on the potential lfs from the shortest to longest until a lf is found. the pattern-matching rules are applied sequentially in pre-defined order. they achieved an average 95% precision and 70% recall on a small set of biomedical articles. they also manually examined whether  <dig> undefined sfs in biomedical text could be identified in four public abbreviation databases and found that 68% of them existed in these databases. park and byrd  <cit>  also used a pattern-based method and achieved 98% precision and 95% recall on a small data set. they restricted sfs to character strings that start with alphanumeric characters, have a length between  <dig> and  <dig> characters, and contain at least one upper-case letter.

chang et al.  <cit>  used dynamic programming to align sfs with their lf. they computed feature vectors from the results of the alignment and used logistic regression on these features to compute the alignment score. they achieved 80% precision and 83% recall on the medstract corpus  <cit> . their algorithm provided probabilities  for the sf-lf pairs found by the algorithm.

an automatic method of abbreviation identification has also been developed for matching protein names and their abbreviations . they used the method of fukuda et al.  <cit>  to identify protein names in  <dig>  articles published in march and july  <dig> in medline and assumed that these protein names were correct. then, they developed a set of rules to map protein names to their abbreviations and achieved 98% precision and 96% recall. this performance does not represent the actual precision and recall because they assumed that the automatically extracted protein names were all correct.

our approach is similar to yu et al.  <cit>  in that we use multiple rules sequentially for mapping sfs to lfs until the lf is identified. yu et al. tried to find the shortest lf candidate by iteratively applying their five rules on all potential sf-lf pairs. however we used relaxed length restrictions and tried to find the best lf candidate by searching for the most reliable successful strategy out of seventeen strategies. one of the major advantages of our algorithm is that the p-precision provides an estimate of the reliability of the identified sf-lf pairs. thus, our algorithm rates the identified sf-lf pairs without any human judgment. this provides a confidence estimate for applications.

methods
data preparation
potential sf and lf pairs
medline is a collection of bibliographic records pointing to the biomedical literature. all records have titles and about half have abstracts. approximately  <dig> million potential sf-lf pairs were extracted from medline. potential sfs are one or two words within parentheses and are limited to at most ten characters in total length. for our purpose white space and punctuation marks delineate word boundaries. we include single alphabetic characters as potential sfs because such abbreviations occur frequently in medline. sequence or list indicators   ,   ,...) and common strings  were identified and not extracted as potential sfs . a potential sf must begin with an alphanumeric character and contain at least one alphabetic character. a potential lf consists of up to ten consecutive words preceding a potential sf in the same sentence . we used the sentence segmenting function in medpost  <cit> .

example  <dig>  sequence or list indicators and common strings
expression includes three components:  an increase of synaptic currents,  an increase of intrinsic excitability in grc, and  an increase of intrinsic excitability in mf terminals. based on quantal analysis, the epsc increase is mostly explained by enhanced neurotransmitter release.

here 'a', 'b', and 'c' are not extracted as potential sfs.

the major changes have been the recognition of the importance of dominant blood vessel size, the distinction between primary and secondary vasculitis and the incorporation of pathogenetic markers such as anca .

we recommend that the appropriate use of those top  <dig> statistics be emphasized in undergraduate nursing education and that the nursing profession continue to advocate for the use of methods  that may contribute to the advancement of nursing research.

the mean lesion contrasted-to-noise ratio was significantly higher on the t1-weighted images .

here "see", "e.g.", and "p <  <dig> " are not extracted as potential sfs.

example  <dig>  potential sf-lf pairs
comparison of two timed artificial insemination  protocols for management of first insemination postpartum.

potential sf: tai

potential lf: comparison of two timed artificial insemination



the higher the o concentration the faster is the development of atelectasis, an important cause of impaired pulmonary gas exchange during general anesthesia .

potential sf: ga

potential lf: important cause of impaired pulmonary gas exchange during general anesthesia



strategies
the most common case of a sf is an acronym in which each character of the sf matches the first character of a word in the lf. however, many sfs do not follow this rule. there are many variations. a character of a sf may match any character within a word of a lf, not just the first character. also a character in a sf may not match any character in the lf. some words in a lf may be skipped and not contain a match to any character in the sf. in order to identify sfs and their corresponding lfs reliably, numerous strategies that deal with possible matching patterns are necessary. for this reason we developed a variety of strategies, of varying reliability, which cover most matching patterns in biomedical text. first, we implemented the most common and reliable strategy people use to identify an acronym sf. then, we implemented the next most common strategy on the remaining potential sf-lf pairs that were missed by the previous strategy. we kept adding new strategies until we had covered the most common strategies used to construct abbreviations. we did not include all possible strategies as some would be quite complex in construction yet rare in occurrence.

for all our strategies, each character in a potential sf is matched to a particular character in a potential lf. all strategies also try to identify a lf by moving right to left and matching sf characters to characters within a potential lf in the same order. the idea of a backward search was also used in previous studies and worked effectively  <cit> . the first character in a sf must match either the initial character at the beginning of a lf or the first alphanumeric character following some non-alphanumeric character in the first token in a lf. non-alphanumeric characters in a sf are skipped in the matching process. the lf found by a strategy must also pass additional checks. the lf is only considered valid if the number of characters in the lf is greater than that of the sf and the lf does not contain the sf as a space delimited substring. table  <dig> shows basic rules applied in our strategies and table  <dig> provides detailed explanation and examples of each strategy.

a words are white space demarcated strings. this applies to all rules.

b a defined word is at least three letters, a non-stopword, and appears at least  <dig> times in medline.

firstletonechsf: applied for 1-letter sf.
firstletgens: sf consists of upper-case letters and lower-case letter 's' at the end.
fail: alphabeta ingamma 
fail: alphabxx  
a the sf and lf pair must appear in medline at least twice and lf must not be a stopword.

pseudo-precision
for each strategy that we use, we estimate its accuracy by what we term a pseudo-precision. the basic idea is that we try a strategy to match a given sf on potential lfs for which we know it is not the correct sf. the rate at which this produces matches is then our estimate of the tendency to produce erroneous matches with that sf and that strategy. we then discount the matches we find on potential lfs which are paired with that sf at that same rate. what remains are what we count as correct and the resulting fraction of all matches is our estimated pseudo-precision.

to be more formal consider a particular set of potential sf-lf pairs x . label the unique potential sfs st . let xs be the subset of s that has potential sf st and xl be the subset of x that satisfies strategy a using st. .

example  <dig>  examples of xl set
the list of examples are all retrieved using the strategy firstlet with short form "cat" or short form "lba" .

xl 

   atp|material was a mixture of the adenyl compounds adenosine triphosphate

   cat|routine examination of the posterior fossa by computer assisted tomography†

   cat|computerised axial tomography†

   lba|in part i of this communication, a technique

   tfp|ndga); anti-oxidant, vitamin e; and calmodulin antagonists, trifluoperazine

   tsh|) and triiodothyronine  serum concentrations, and thyrotropin

xl 

   bfa|since the fungal lactone brefeldin a

   bga|during the remission course of iss, low-voltage background activity

   bka|the ant ligands bongkregkic acid

   lba|and manufacturing techniques are known from the late bronze age‡

   lba|were compared to its prototype predecessor assay, line blot assay‡

   usa|hla genes of aleutian islanders living between alaska

in example  <dig> the list under xl  are potential sf-lf pairs that satisfy the firstlet strategy using sf "cat". note that the actual sf can be different from "cat". in the pairs whose sf is not "cat", the identified lfs by firstlet are incorrect. the correct lfs can be identified by using a different strategy in some cases . the sf tsh abbreviates a synonym for thyrotropin. the pairs labelled with '†' at the end are elements in the set xs  ∩ xl . similarly the list under xl  are potential sf-lf pairs that satisfy the firstlet strategy using sf "lba". like the previous examples there is a false sf  and some lfs can be correctly identified by using a different strategy than firstlet . the pairs labelled with '‡' at the end are elements in the set xs  ∩ xl .

let us denote the size of sets by

  n = ||x|| 

  ns  = ||xs || 

  nl  = ||xl ||. 

also, define the size of the intersection of xs  and xl  as

  nsl  = ||xs  ∩ xl ||. 

define λ by

  λ=‖xl∩)‖‖x−xs‖. 

here λ is the rate of success for strategy a using st on the pairs whose sf is not st. the denominator is the number of pairs where the sf is not st and the numerator is the number of those pairs where strategy a using st succeeded anyway. thus λ represents the chance rate of success for the strategy without regard to the paired sf. then, we define the p-precision of strategy a for sf st

  preca=nsl−λnsnsl, 

the value λns  in equation  is our estimate of the number of pairs that have sf st and satisfy strategy a using st merely by chance. thus when we remove this portion from nsl  the value of the numerator in equation  becomes significant or meaningful matches using strategy a. this value is divided by nsl , which is the observed number of successes of the strategy, and so the p-precision becomes the estimated success rate  of strategy a using st. the analogy is with the expression for precision

  precision=allpositives−falsepositivesallpositives. 

the p-precision preca  is based on a statistical notion of observing the occurrence of a potential sf-lf match at a rate above chance occurrence. if a strategy matches a sf to its potential lf and this match was not produced by chance and if the strategy is a reasonable one that one might very well use to produce an abbreviation, then it is likely that this strategy was actually used to produce this sf. on this basis we have concluded that p-precision is a useful approximation to true precision. the more reliable the strategy the higher the actual satisfaction ) is compared to the expected chance satisfaction ). hence, the more reliable the strategy, the higher the p-precision. the p-precision of strategy a for a given set is the weighted average over all sfs in the set,

  preca=∑t=1mprecansl∑t=1mnsl. 

assigning p-precision to a strategy
we developed various strategies  and each involves a different type of pattern matching to identify a lf. some strategies are more reliable for defining lfs and some are less reliable. thus, assigning higher priority to a more reliable strategy is necessary to determine the best candidate lf if multiple lf candidates exist. reliability of a strategy can be different for different types of sfs. for this reason, we divided all potential sf-lf pairs obtained from medline into six groups based on the number of characters in the sf:  <dig>   <dig>   <dig>   <dig>   <dig>  and 6+. each group, except 1-letter sf, was further divided into three sub-groups: sfs consisting of all alphabetic characters, at least one digit plus alphabetic characters, and at least one non-alphanumeric character. for each group we evaluated strategies and ordered them based on their p-precision. the sf group 6+ used the same strategies as the 5-character sf group.

the order  of strategies is in descending order of the p-precision – from the most reliable to the least reliable strategies. we evaluate the reliability of our strategies by their p-precision, equation . for each group of potential sf-lf pairs we ordered the list of strategies. figure  <dig> shows the detailed process. this process allowed us to determine the best ordering of strategies for each group based on their p-precisions.

application
our process of abbreviation identification in free text consists of 1) extracting potential sf-lf pairs, 2) for each potential sf-lf pair applying the strategies corresponding to the given sf group, and 3) identifying the most reliable sf-lf pair. each sf group has its own prioritized strategies with their corresponding p-precisions specific to that group. the strategies are applied sequentially in predefined order and the process stops with the first strategy that succeeds. in this way we can find the most reliable lf if more than one possible lf exists. the algorithm identifies a sf-lf pair and assigns the p-precision of the strategy that found it.

to increase recall of our algorithm we look at potential sf-lf pairs associated with square brackets in addition to parentheses. also, we consider both "lf " and "sf " orders. when we consider the "sf " order a potential sf is one word containing at least one upper-case letter. if both "lf " and "sf " cases are successful we choose the one with the higher p-precision. because a sf must consist of at most ten alphabetic characters, if the text inside parentheses or square brackets contains ';' or ',' we treat the text before these punctuation marks as a potential sf  – "ab" is extracted as a potential sf). this also increases the number of potential sf-lf pairs and has a positive effect on recall.

evaluation
for our definitive evaluation we annotated  <dig> records, which have both title and abstract. these were randomly selected from medline. the four authors individually annotated  <dig> records each. the backgrounds of the four are: medical science, chemistry, information science, and computer engineering. an additional  <dig> records were annotated by all four authors in order to test inter-annotator agreement. after initial annotation we checked the pairs that were identified by either our algorithm or the schwartz and hearst algorithm but were not in the gold standard. all four annotators consulted together regarding these pairs and added to the gold standard those judged correct.

we compared each annotator's performance on the  <dig> records judged in common. two pairs of annotators worked to create two reconciled versions. then all four annotators worked together to make final judgments where there was disagreement. the result includes  <dig> sf-lf pairs. this consensus was used to rate each annotator's work and the two pairwise reconciled versions . three annotators' results were similar and one annotator's result was somewhat lower than the other three. however, both pairwise reconciliations were closer to the consensus than any single annotator's work.

a f-measure = 2*/

RESULTS
we tested our algorithm on the medstract corpus  <cit>  which has been used in previous studies  <cit> . the gold standard of medstract has  <dig> sf-lf pairs. we annotated this data set manually since only the text is available to the public. note that the gold standard for other studies might be slightly different. our algorithm produced 97% precision and 85% recall. for comparison schwartz and hearst achieved 96% precision and 82% recall , chang et al. achieved 80% precision and 83% recall, and pustejovsky et al. achieved 98% precision and 72% recall. most pairs missed by our algorithm are ones with unmatched characters in the sf , out of order match , and partial match .

the gold standard of  <dig> medline records includes  <dig> true sf-lf pairs. our algorithm identified  <dig> pairs with  <dig> correct pairs –  <dig> % precision and  <dig> % recall. table  <dig> shows some examples of correctly identified sf-lf pairs along with the p-precision and strategy used. most correct cases were assigned high p-precision except for "gc/ecd" that was identified by the anylet strategy. false positive  pairs with high p-precision were unusual. the sf "iva-siv" was matched to "ivanovas-sieve colony" with  <dig>  p-precision. this pair was annotated as a synonym pair but not considered an abbreviation in our gold standard. the sf "pho" was identified as the lf of "ph" with  <dig>  p-precision from the phrase, "... extracellular ph ...". the true sf-lf pair is "pho|extracellular ph" in which the character 'o' in sf does not match any character in the lf. generally, fp cases were assigned relatively low p-precision , apathy|acquired knowledge, important changes of personality| <dig> , cl-ee|cellulose hollow fiber dialyzer| <dig> ).

pairs missed by our algorithm demonstrate strategies not included in our list of seventeen: pairs with unused characters in the sf , out of order match , mapping digits in a sf to words in a lf , and conjunction . our algorithm does not allow lfs to skip more than one non-stopword between words to avoid inappropriate lf candidates. some sf-lf pairs require skipping more than one non-stopword between words in the lf and our algorithm fails for those pairs .

the gold standard includes  <dig> 1-letter sfs. our algorithm achieved 100% precision and 83% recall on 1-letter sfs. it missed four cases. for one of them the lf consists of two words, which our algorithm does not recognize .

among our strategies anylet is the least reliable strategy and the last option to be tried. it is of interest to apply the algorithm without the anylet strategy. the resulting algorithm achieves  <dig> % precision and  <dig> % recall. the recall is close to the original algorithm  and precision is a little higher than the original algorithm .

this can be extended to any precision threshold. figure  <dig> shows the precision-recall curve on the  <dig> medline records. the precision and recall were calculated with different threshold values of p-precision. for example, with the threshold of  <dig>  p-precision we retrieved the identified sf-lf pairs by the algorithm only if their p-precision is greater than  <dig> . with p-precision threshold  <dig>  the algorithm produced  <dig> % precision at 10% recall, with  <dig>  threshold  <dig> % precision at  <dig> % recall, and with  <dig>  threshold  <dig> % precision at  <dig> % recall. this result shows that the pairs identified with high p-precision are more likely to be true positive .

using our  <dig> medline record gold standard we examined the correlation between p-precision and true precision . the average p-precision of most strategies lies within the 95% confidence interval of precision or a little higher than the upper limit of precision. this suggests that our p-precision is a reasonable estimate of a strategy's actual precision, though it may be at times a mild overestimate.

discussion
in a previous study of automatic abbreviation identification schwartz and hearst  <cit>  developed a simple and fast algorithm that performed better or at least as well as previous methods. we compared the performance of our algorithm with theirs on the same  <dig> medline records used in our evaluation. schwartz and hearst found  <dig> pairs with  <dig> correct pairs –  <dig> % precision and  <dig> % recall. we have 2% and  <dig> % higher precision and recall, respectively. the major differences between our approach and schwartz and hearst's are: 1) we identify 1-letter sfs but schwartz and hearst do not identify them even though they included 1-letter sfs in the gold standard in their experiment; 2) we select highest p-precision lf if multiple lf candidates exist but schwartz and hearst select the shortest lf candidate ; 3) we identify sf-lf pairs occurring within nested parentheses but schwartz and hearst give nested parentheses no special treatment; 4) schwartz and hearst allow more consecutive skipped words without matching. this can result in success  or failure ; 5) occasionally, the schwartz and hearst restriction on lf length ) causes failure on lfs including many stopwords . we believe that the resulting algorithm would perform well on biological text from sources other than medline, such as full text journal articles. this opinion is based on the fact that it is largely the same authors that produce the text in medline that also produce journal articles. however, we have not carried out an evaluation on full text articles. however, for text from a subject area other than biology one might need to repeat the training process described in figure  <dig> 

our algorithm took  <dig> seconds to process our  <dig> medline record test set. applied to the same set the schwartz and hearst algorithm took  <dig>  seconds. while our algorithm is clearly not as fast, it is not so slow as to be a serious issue. our algorithm can process all eighteen million medline records in about  <dig> and a half days.

CONCLUSIONS
in this work we have developed a general approach which allows us to estimate the accuracy of a strategy for identifying an abbreviation, which we term p-precision. by gathering a number of strategies which provide a reasonably complete coverage of how authors actually construct abbreviations and computing their corresponding p-precisions we are able to construct an algorithm for abbreviation definition identification. the algorithm has the advantage that it is very competitive with existing algorithms in terms of accuracy and that it provides a p-precision estimate for each result it produces. such estimates can be beneficial to applications which have stringent accuracy requirements or have accuracy requirements which vary. one could add additional strategies to our algorithm  or start with a completely different set of strategies and apply this same general approach.

one of the issues in automatic abbreviation identification is how to handle special cases that cannot be found by simple string matching, i.e., sfs containing characters that do not appear in the lf. many pairs missed by our algorithm belong to this case. interesting work on this problem has been done by liu and friedman  <cit>  and zhou et al.  <cit> . in future work we would like to find a way to use statistical evidence from multiple occurrences to not only find the matching sf-lf pairs but also make p-precision estimates for those pairs similar to the estimates we are currently making in the case where every letter from the sf is matched into the lf.

availability and requirements
software implementing the algorithm presented here and files containing the  <dig> annotated medline records are available for download at the project home page. at this site the algorithm is given the name ab3p .

project name: abbreviations plus pseudo-precision 

project home page: 

operating system: unix 

programming language: c++

license: united states government production, public-domain

authors' contributions
ss developed methods, implemented the software, and drafted the manuscript. dc and wk were involved in implementing the software and revising the manuscript. jw was responsible for all aspects of the project, contributed software, and helped revise the manuscript.

