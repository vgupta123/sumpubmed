BACKGROUND
genomic selection is an important task for increasing the efficiency of plant breeding, disease diagnosis, personalized medicine, and genotyping chip design. genomic selection is improved by identifying a small subset of influential single nucleotide polymorphisms  from high-dimensional genetic information to efficiently predict individual’s phenotype . the rapid developments of high-throughput genomic technologies, such as whole genome genotyping, next generation sequencing, gene expression microarray, and rna-seq, have dramatically boosted the landscape and power of genomic selection  <cit> , while nevertheless bringing unprecedented challenges for statistical modeling.

feature screening has been receiving extensive attention as a powerful approach to handle ultrahigh dimensional data, which is defined as p= exp, for some ζ> <dig>  here p is the number of features and n is the number of observations . specifically, li et al. developed a distance correlation based sure independence feature screening  strategy that defines an association strength measure for each feature based on its distance correlation with the phenotype  <cit> . the idea of dc-sis is to theoretically satisfies the sure screening property, ranks the features from the most important to the least important by decreasing distance correlation values, and filters the majority of noise with low values of the defined association strength measure. a very attractive property of dc-sis is that it effectively captures both the linear and nonlinear association between the feature and the phenotype, and feasible for binary, continuous, and categorical features and phenotype, without assuming any specific model structure, distribution, or data type. in addition, dc-sis outperforms the traditional sure independence screening   <cit>  and sure independent ranking and screening  approaches  <cit> . therefore, dc-sis has great potential in serving genomic selection and recognizing the truly influential snps from millions of candidates covering the entire genome.

however, a limitation that restricts the application of dc-sis and other feature screening approaches is the lack of a clear threshold determination to separate influential features from noise, which is crucial in genomic selection. frequently, an arbitrary decision as to the number of genes to retain is made. for example, some papers used sheer empirical experience to select the  <dig> or  <dig> highest ranked genes . other traditional approaches selected the snps passing the threshold of −log . however, this approach requires that a p-value is accessible, and hence annuls the possibility of applying any approaches that do not compute a p-value. current feature screening literature keeps the top d features having the highest rankings, where d is often computed from an integral multiplier of  ],d
2= <dig>  or d
3= <dig> is suggested)  <cit> . these options may work well for some circumstances, but several drawbacks also present themselves: 1) it is still not clear what d exactly should be. for a real data analysis, we have no any idea whether d
 <dig>  d
 <dig>  d
 <dig>  or an even larger value should be used. 2) a formula such as  is only restricted by the sample size, but unreasonably neglect two indispensable considerations: the number of features, and the signal-to-noise ratio. assuming the sample size is fixed, it is unreasonable to set the same threshold for one dataset with  <dig> features and another dataset with  <dig>  features. for a dataset with a large number of features, but a weak signal-to-noise ratio, the threshold may be relatively large, whereas for a much easier scenario, the threshold may be small. kong et al. recognized these limitations and proposed a theorem to adaptively determine the threshold for dc-sis, pioneering threshold determination research  <cit> . however, they assumed that noise snp was purely independent of the influential snps and the phenotype, which may not be true in the genome-wide datasets.

in particular, determining a threshold that separates influential snps from noise snps is a necessity in genomic selection. but method for determining the threshold is also limited in the genomic selection literature. frequently, an arbitrary decision as to the number of genes to retain was made. for example, some papers used sheer empirical experience to select the  <dig> or  <dig> highest ranked genes. other traditional approaches selected the snps passing the threshold of −log. however, this approach requires that a p-value is accessible, and hence annuls the possibility of applying many other feature screening approaches which do not compute a p-value.

this article extends the work of zhong et al.  <cit> , and proposes a backward elimination iterative distance correlation  procedure that adaptively and automatically determines an optimal threshold for genomic selection while guaranteeing prediction accuracy. the smoothly clipped absolute deviation  penalized regression model fitting the bootstrap samples is used to compute the mean square prediction error . a certain percentage of snps  are backward eliminated after iterative dc-sis ranks the snps from the most important to the least important, and the point at which the minimum mspe is attained is determined as the final threshold. one aim is to optimize the threshold, which is not trivial. if the standard is too stringent and the number of snps selected is too small, we may fail to cover all influential snps, and hence the power will be reduced; whereas if the rule is too liberal and the number of snps selected is too large, too much of the noise will be mistreated as influential features, and hence the false discovery rate will be inflated  <cit> . another aim is to obtain the smallest possible set of snps that can still achieve acceptable prediction accuracy. the proposed be-idc realizes these two aims, serves as a good genomic selection procedure for the ultrahigh dimensional genome-wide dataset, and overcomes the limitation of previous feature screening approaches.and boosts the potential of feature screening approaches to bring a new horizon for genomic selection

we explored the performances of the be-idc approach using six different simulation settings and one real genome-wide dataset. we also compared the results of the adaptive threshold estimated by be-idc with those found by the fixed thresholds suggested by current feature screening literature  <cit> . the average thresholds estimated by be-idc are uniformly lower than the fixed thresholds while yet achieving 100% power. it is worth mention that the be-idc uses an average threshold as small as  <dig>  to achieve a 100% power for example  <dig>  which is only 7% of the fixed threshold, d=2= <dig>  used by the current literature  <cit> . in addition, be-idc can flexibly and automatically adjust the threshold when the dataset has harder conditions . from these six simulations, we conclude that be-idc shows uniformly excellent performances even when the signal-to-noise ratio is low , and when the number of features is much larger than the number of observations . we also demonstrate that the be-idc approach selects a very small set of snps for arabidopsis thaliana data. here, only four snps are selected from a pool of  <dig>  snps covering the entire genome, and the frigida gene, reported to be highly associated with the frigida expression trait being analyzed  <cit> , is successfully picked out.

methods
iterative dc-sis
szekely et al. defined an association strength measure for each feature based on its distance correlation  with the phenotype and showed that the dcorr of two random vectors equals zero if and only if the two random vectors are independent  <cit> . li et al. proposed the dc-sis feature screening approach, ranked the snps from the most important to the least important by decreasing the values of dcorr, and proved the sure screening theorem to theoretically ensure that dc-sis will not miss any influential snps if the sample size is large enough  <cit> .

let y be the analyzed phenotype. let x
j be the genotype of each snp, j= <dig> …,p. for each biallelic locus, the three possible genotypes can be coded as  <dig> ,  <dig> , and  <dig> . the distance covariance between the phenotype and each snp is defined as 
  <dig> dcov2=∫ϕy,xj−ϕyϕxj2×wdtds, 


where ϕ
y and ϕxj are the respective characteristic functions of y and x
j, and ϕy,xj is the joint characteristic function of , and 
 w=π2∥t∥2∥s∥2− <dig>   where ||·|| stands for the euclidean norm. then the dcorr between the phenotype and each snp is defined as 
  <dig> dcorry,xj=dcovy,xjdcovy,ydcovxj,xj. 


szekely et al. gave a numerically easier estimator of dcov^ <dig> as 
  <dig> dcov^2y,xj=Ŝ1+Ŝ2−2Ŝ <dig>  


let y
i <dig>  y
i <dig>  x
i <dig> j, and x
i <dig> j denote the i1th and i2th sample observations for y and x
j, respectively. then 
  <dig> Ŝ1=1n2∑i1=1n∑i2=1nyi1−yi2xi <dig> j−xi <dig> jpŜ2=1n2∑i1=1n∑i2=1nyi1−yi21n2∑i1=1n∑i2=1nxi <dig> j−xi <dig> jp,Ŝ3=1n3∑i1=1n∑i2=1n∑i3=1nyi1−yi3xi <dig> j−xi <dig> jp. 


finally, the point estimator dcorr^ can be estimated by eqs. ,  and . we are then able to rank all snps, from the most influential to the least influential, by decreasing values of dcorr^,j= <dig> …,p  <cit> . let xp={xk∗,k= <dig> …,p}, be the reordered snps, where the asterisk is used to differentiate the top k
th snp after selection by dc-sis from the originally observed k
th snp.

while dc-sis is a very powerful feature selection approach for ultrahigh dimensional data, it may neglect some important snps that are marginally not relevant, but jointly associated with the phenotype; or, it may rank highly some noise snps that are spuriously correlated with the phenotype due to their strong linkage disequilibrium  with other important snps. to overcome these shortcomings, zhong et al. introduced an iterative distance correlation feature screening approach   <cit> . the main idea of idc-sis is to iteratively regress unselected snps on selected snps, regain information from the residuals, and effectively break down the effects of correlation structure among snps.

dc-sis ranks all snps and achieves the set x
p in a single step, while idc-sis builds up x
p gradually with several steps, i.e. xp=xp1⋃xp2⋃…⋃xpm, with p=p
1+p
2+…+p
m, where x
pi stands for the set of snps selected at the i
th iterative step, p
i denotes the size of each set x
pi; i= <dig> …,m, and m is the number of iterative steps. zhong et al. claimed that a small number of iterations is adequate to guarantee good performance and they suggested m= <dig> p
1= <dig> p
2=d− <dig>  and d= <dig>  <cit> . note that this article aims to adaptively determine d without assuming it is given, hence we set m= <dig> p
1= <dig> p
2= <dig>  and p
3=p− <dig> to rank all features. this setting is empirically proven to work well in all simulations.

the details of idc-sis can be summarized as follows  <cit> : 
step 1: use dc-sis for y and x and select the first p
 <dig> features into x
p .

step 2: define xr={in−xp−1xpt}xpc, where xpc is the complement set of x
p. use dc-sis for y and x
r and select the second p
 <dig> features into x
p .

step 3: repeat step  <dig> for m times until all p features are ranked, i.e., xp=xp1⋃xp2⋃…⋃xpm, with p=p
1+p
2+…+p
m. note that the computational cost will be shockingly large if we repeat step  <dig> for too many times for a large number of snps. additionally, the theoretical sure screening property may not continue to be true if too many iterations are applied. to balance the computational cost and accuracy, we only selected the first one hundred snps by idc-sis and then applied dc-sis for all remaining snps. this combination worked well after verifying by quite a few empirical studies .




backward elimination
let d denote the threshold that we need to determine. let xc={xk∗,k= <dig> …,d} be the subset of influential snps, i.e., the conditional distribution function of y depends on x merely through xc, and let xn={xk∗,k=d+ <dig> …,p} be the set of noise snps, i.e., the complement set of xc. the goal of genomic selection is to remove xn and pick the subset xc. dc-sis is able to rank important features before noise, but a genomic selection process cannot be finalized if d is not determined. the current feature screening literature suggests using a fixed threshold of d=    <cit> . but again, this has several limitations as discussed in the introduction section.

starting from the biggest pool, x
p, which contained all reordered snps as ranked by idc-sis, we discarded the noise snps by a backward elimination process through several iterations. for each iteration, we computed mean square prediction error based on its current pool, threw away a certain drop rate of snps from the bottom of the rank , then moved to the next iteration step. the backward elimination considered all snps at the initial stage of the modeling to attenuate possible modeling biases.

scad penalized regression model
to predict the phenotypic values for the test data while accommodating the ultrahigh dimensionality of the genome-wide data , we applied a penalized regression model with the non-concave scad penalty function  <cit> . unlike the traditional regression model, the penalized least squares estimators were obtained by minimizing 
 12t+n∑j=1ppλ,  where the scad penalty function was given as 
 pλ=λ|βj|,|βj|≤λ;−|βj|2−2αλ|βj|+λ <dig> λ<|βj|≤αλ;λ2/ <dig> |βj|>αλ. 


two unknown tuning parameters λ and α are contained in the penalty function. as suggested by fan et al.  <cit> , α= <dig>  is a good choice for various problems, and λ is selected by cross validation. this penalty function corresponds to a quadratic spline function with knots at λ and α
λ. besides its capability of handling ultrahigh dimensional genome-wide data, the scad penalty function satisfied three properties that are important for genomic selection: it is singular at the origin to produce sparse solutions and shrink unimportant parameters to zero to reduce model complexity; the resulting estimator is continuous, which retains stability in model prediction; and it is bounded by a constant to produce nearly unbiased estimates for large coefficients to avoid unnecessary modeling bias  <cit> .

scheme of be-idc
the details of be-idc are summarized as follows: 
step 1: rank all snps by idc-sis, and obtain the reordered set , where p is expected to be ultrahigh.

step 2: start from the biggest pool , x
p, and compute the mspe for the corresponding model.

step 3: remove a certain drop rate of snps having the lowest dcorr values, based on the ranks obtained from step  <dig>  then compute the mspe for the model corresponding to the current pool. for more details about the drop rate, please see the simulation section.

step 4: repeat step  <dig> until the smallest pool  is reached.

step 5: draw a plot of the mspe versus the number of snps and locate the model size for which the mspe is minimized, as model size decreases from p to  <dig>  finally, the selected influential snp set  and the adaptive threshold  can be simultaneously determined from this optimal spot. the noise set xn is already thrown away during the iterations of steps  <dig> and  <dig> 




the computation of the mspe mentioned in above steps  <dig> and  <dig> is done as follows: draw  <dig> bootstrap samples with replacement, divide each bootstrap sample into training data  and test data  observations), fit the scad penalized regression model using the training data, predict for the test data, then compute the mean square prediction errors for all the bootstrap samples.

following this be-idc scheme, the prediction accuracy and reproducibility of results on new datasets should be guaranteed because the minimum mean square prediction error is used. however, if a very small threshold is preferred, we suggest using the smallest number of snps whose mspe is within  <dig> standard error  above the minimum mspe. in this case, the number of snps may be smaller than d^, and the prediction error a little larger than the minimum mspe value but the mspe will still lie within an acceptable range. however, it is expected that the power may decrease and influential snps may be missed if this  <dig> s.e. rule is used. therefore, unless a very small number of snps is preferred for reason of saving experimental cost in breeding or disease diagnosis applications, we suggest taking the threshold to be that for which the mspe is minimized.

RESULTS
simulation studies
the performances of dc-sis and idc-sis have been investigated by li et al.  <cit>  and zhong et al.  <cit>  using a fixed threshold. in this section we examined the performance of the adaptive threshold estimated from the new approach be-idc through six simulation studies. additionally, we compared the performance of the adaptive threshold with the fixed threshold d^=2= <dig> used by li et al.  <cit>  and zhong et al.  <cit> . to make the comparisons fair, the first two examples were imitated from the current literature  <cit> . in the third example, we increased the level of rigor. as with the first two simulations, we also used the same criteria that have been widely used to assess the power of a method in current feature screening literature  <cit> : 

average threshold
d^¯: the average value of the adaptive thresholds estimated from the  <dig> simulation replicates;


strict power
p
a: the proportion of the  <dig> replicates for which all truly influential features are simultaneously selected by d^;


individual power
p
j: the proportion of the  <dig> replicates for which each individual influential feature is selected by d^ respectively.




we simulated  <dig> replicate datasets consisting of n= <dig> observations and p= <dig>  features for example 1- <dig> and additional file 1: supplementary example 1- <dig>  we simulated  <dig> replicate datasets consisting of n= <dig> observations and p= <dig>  features for example  <dig> and additional file 1: supplementary example  <dig> 

example 1
similar to zhong et al.  <cit> , we simulated data for example  <dig> from the model 
  <dig> y=5x1+5x2+5x3−15ρx4+ε, 


where the features were generated from a normal distribution with zero mean, unit variance, and covariance structure following ar design with auto correlation parameter ρ= <dig> . model  actually sets the first four features as the influential ones, and all remaining  <dig>  features as noise. the white noise was generated from the standard normal distribution and the continuous phenotype y was generated from model  accordingly.
a, and individual power p
j, j= <dig> …, <dig>  achieved by fixed threshold d= <dig> and adaptive threshold, respectively. from table  <dig>  we can see that be-idc achieved 100% strict power using only  <dig>  features on average after searching  <dig>  features for  <dig> replications, while the fixed threshold used a threshold of  <dig>  which is  <dig> times larger than the result of be-idc to achieve the same power. simulation further indicated that be-idc only made an average of  <dig>  spurious signal, but that the fixed threshold made an average of  <dig> spurious signals for  <dig> simulations . note that x
 <dig> was jointly important but marginally independent to the phenotype y, so it trapped the dc-sis  but was successfully detected by be-idc using a very small model size . in addition, we assessed the average of  <dig> mean square prediction errors using the 5-fold cross validation for these three methods, respectively. the be-idc achieved the best prediction accuracy . given the fact that idc-sis already beat four other feature screening approaches  <cit> , to wit, lasso  <cit> , sure independence screening   <cit> , iterative sure independence screening   <cit> , and dc-sis  <cit> , this improvement is agreeable. the strict power of be-dc  is zero even using  <dig> times more features because x
 <dig> is purposely designed to be trapped by noise. this example illustrates that the benefits of be-idc over be-dc.
p
a
p
1
p
2
p
3
p
4



we also tested the sensitivity of different drop rates  using this simulation study and empirically verified that the results are quite stable when drop rate varies dramatically from  <dig> to 50% . the thresholds, d^, have only negligible differences according to the five different resolutions of the drop rates. throughout this article, we used a drop rate of 50% to save the computational cost and found that such a big drop rate is able to achieve high powers and small thresholds. but if a high resolution is needed and computational cost is not a concern, a smaller drop rate, say 10%, is suggested.
p
a



example 2
we simulated snp data for example  <dig> following the procedure of li et al.  <cit> . firstly, u
ij was generated from a standard normal distribution with correlation structure of ρ=cov= <dig> . to simulate snps with equal allele frequencies, we set 
 xij=aa,uij>caa,−c≤uij≤caa,uij<−c,  where c is the third quartile of a standard normal distribution. secondly, the additive  and dominant feature  of each snp were coded as follows, 
 xija= <dig> ifxij=aa <dig> ifxij=aa− <dig> ifxij=aa,xijd= <dig> ifxij=aa <dig> ifxij=aaoraa. 


thirdly, we let the set j∈{ <dig> , <dig> ,500} contains the indices of truly influential snps, and the additive  and dominant coefficients  of the influential snps are given by table  <dig> 



finally, the phenotype y was generated following li et al.’s design  <cit> , 
  <dig> yi=∑jβjaxija+∑jβjdxijd+ε, 


where ε∼n. note that x
ij is the feature that we analyzed, therefore the example  <dig> connected y and x
ij indirectly by way of eq. .

as can been seen from table  <dig>  be-idc achieved the smallest average threshold, d^¯= <dig> , which was about 1/ <dig> of the fixed threshold. in addition, be-idc had the minimum mspe of  <dig> .
p
a
p
100
p
200
p
300
p
400
p
500



example 3
to increase the rigor of the above two examples, we 1) weakened the signal of the influential features; and 2) increased the number of influential features. the snps were generated similar as in example  <dig>  except the correlation structure between snps was a little more complex, cov= <dig> |j−k|;j,k= <dig> …,p. we fix the indices of ten truly influential snps from j∈{ <dig> ,...,1000}. the phenotype y and the truly influential snps were directly connected using a similar model as example  <dig>  but we took the indicator function to accommodate the categorical features, yi=∑j+2βji)+ε, where ε∼n. the coefficient β
j was randomly generated from uniform, where the magnitudes of these coefficients were much weaker than those used in example  <dig>  example  <dig> was simulated for p= <dig>  snps, with ten influential and  <dig> features as noise.
 <dig> seems to have very weak signal and trapped the dc-sis. the results of idc-sis are dramatically better than those of the dc-sis. however, the power of idc-sis is only 92% if using a fixed threshold of = <dig>  it indicates that idc-sis includes  <dig> more features in average than the d^¯= <dig>  estimated by be-idc, but was still unable to simultaneously detecting all ten influential features among all  <dig> replicates. to achieve a 100% power as the be-idc did, the idc-sis had to increase the threshold to 2= <dig>  but it sacrificed  <dig> more unnecessary noise features on average than be-idc.
p
a
p
100
p
200
p
300
p
400
p
500
p
600
p
700
p
800
p
900
p
1000



analysis of arabidopsis data
the be-idc procedure was applied to select the most influential snps for a continuous trait of the arabidopsis thaliana disease-resistance phenotype, lesioning and frigida expression , with  <dig> inbred lines and  <dig>  snps covering the entire genome. these data are publicly available from the link . two traditional statistical models have been implemented on this same dataset, i.e., the non-parametric wilcoxon rank-sum test and a linear mixed model implemented in emma .

the four influential polymorphisms that were selected by be-idc are summarized in table  <dig>  using the arabidopsis genome initiative  genetic map and the arabidopsis information resource  gbrowse database, we matched our significant findings with three genes. the rank  <dig> snp lay approximately  <dig> bp away from the frigida region . like all other approaches working on this same dataset, the be-idc procedure also identified exactly the same position  as reported by current literature. this snp was associated with the highest peak on the manhattan plot by all approaches, including be-idc. besides the unanimous agreement on this peak, we detected three new positions that were not found by these traditional approaches for the same dataset. in particular, the rank  <dig> snp lay exactly within the single large exon of frigida or flowering locus a  region , which locates the expected gene more closely than the previously discussed highest peak. specifically, fri encodes a major determinant of natural variation in arabidopsis flowering time and has been reported to regulate this lesioning and frigida expression trait under analysis. additionally, we also found that the rank  <dig> and rank  <dig> snps lay within exon <dig> and intron <dig> in the neighboring rnahelicase-like  <dig>  gene , respectively.
fri or fla
rh8
rh8
fri or fla


a illustrates the mspe plot versus the number of snps, covering the entire search region, during which the backward elimination removed snps from  <dig>  to  <dig> iteratively at a drop rate of 50%. we observed that the minimum mspe is achieved at a very crowded region where the number of snps is small. after magnifying this crowded region , the optimal spot d^= <dig> is recognized. figure  <dig> demonstrates the manhattan plot of the continuous fri trait along the entire genome, based on the iterative dcorr values of  <dig>  snps against their individual physical chromosomal position. unlike the traditional manhattan plot, we did not use the p-value and −log horizontal line to determine the significance. instead, we used the adaptive threshold determined by the be-idc procedure . unlike the regular manhattan plot having dense signals, fig.  <dig> looks very sparse. we knew that the whole genome data had low signal-to-noise ratio and expected that the majority of the noise snps could be dramatically filtered out by the proposed be-idc approach. we also knew that idc-sis iteratively regressed unselected snps on selected snps and regained information from the residuals. it was also known that the residuals contain much weaker information than the original data. this explains why the majority of noise snps were close to  <dig> and why fig.  <dig> looks sparse.
fig.  <dig> the mspe plot. a the mspe versus the number of snps on the interval  <cit> ; b magnification of the mspe over the small interval  <cit> , surrounding the minimum mspe region. the red point is the final threshold determination spot  achieving the minimum mspe  <dig> . the black solid curve is the traditional mspe plot, and the blue dash curve is the mspe +/-  <dig> standard error plot. when the model size is  <dig>  the mspe has the maximum value  <dig> 


fig.  <dig> the manhattan plot. the manhattan plot of the fri expression along the whole genome, based on the dcorr measures of  <dig>  snps against each snp’s chromosomal position. chromosomes are shown in alternate colors. the top four snps represented by the yellow triangles are finally selected by the be-idc procedure




discussion
as the level of difficulty increased from example  <dig> to example  <dig>  the average thresholds d^¯ estimated by be-idc automatically became larger, causing the power to approach 100%. comparing the different results of the three simulation examples, we confirmed that be-idc was indeed able to flexibly and adaptively adjust its estimated threshold value according to the specific scenarios of different datasets. on the contrary, the fixed threshold approaches failed to give a clear and flexible threshold determination. for the real data analysis, where the truth is never known, this data-driven ability is crucial. if a threshold is set too small, influential snps will be neglected and power will be decreased ; on the contrary, if the threshold is set too large, too much of the noise will be mistreated as influential features  .

be-idc works well for snps with either binary feature  or categorical feature , as well as continuous features  such as age or bmi, among others  <cit> . as for the phenotype, be-idc approach proposed in this article is mainly targeted for continuous phenotype/trait, hence the models, simulations, and real data all focus on continuous traits. however, we tried one simulation study with a categorical phenotype and noticed that the results were also nice . we will leave this categorical trait for future examination. this article focuses on the selection of a small subset of influential genes that still achieve sufficient prediction accuracy for new observations, which is a common interest in plant breeding in crop, plant, and cattle species or disease diagnosis and prevention in clinical practices . for the case of several hundreds of influential snps all individually having small effect, the proposed be-idc may not be feasible and we will consider it in future work.

CONCLUSIONS
this article proposes a be-idc procedure with the aims of  selecting the smallest possible set of influential genes from a big pool that are not only associated with the analyzed phenotype, but also enable accurate prediction for new observations; and  determining an adaptive threshold effectively separating influential snps from the noise snps. an approach with accurate prediction capability will make the results obtained in one dataset be reproduced better in a different dataset. the difficulties that be-idc overcomes are as follows: issues of ultrahigh dimensionality when the number of snps is in the tens of thousands or even in the millions, but the number of observations is in the hundreds or the thousands; detecting signals from a sparse structure ; and detecting truly important snps that are confounded by noise due to strong linkage disequilibrium.

additional file

additional file  <dig> supplementary examples. 




abbreviations
be-idcbackward elimination iterative distance correlation

dcorrdistance correlation

dc-sis for distance correlation based sure independence feature screening; fri
frigida expression

idc-sisiterative distance correlation feature screening approach

ldlinkage disequilibrium

mspemean square prediction error

oobout of bag observations

rh8
rnahelicase-like 8


scadsmoothly clipped absolute deviation

snp standssingle nucleotide polymorphisms

