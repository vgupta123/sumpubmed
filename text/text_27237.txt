BACKGROUND
the phenomenal growth in bioscience literature has posed a great challenge in information retrieval both for general researchers and those whose task it is to extract such information from the literature   <cit> . text mining for bioscience data is an active research area and many tools are emerging  <cit> .

extensive work has been done on the categorization of papers with experimental information and the extraction or and retrieval of content from the text in biomedical literature. the most extensively studied data types involve protein-protein interaction  <cit> . categorization of other data types such as tumor, allele, gene expression and gene ontology  terms, and so forth, have been reported  <cit> . efforts to address different information needs of diverse users in the biomedical field have been made by using a multi-dimensional categorization and annotation scheme through identifying contents and classifying papers rich with multiple categories with sufficient generality and applicability to diverse subject areas  <cit> .

although some applications are starting to be incorporated into the biocuration workflow at some databases  <cit> , biocuration remains largely a manual effort. since  <dig>  text classification has been listed as one of the tasks in several grand challenges  <cit> , and many machine-learning methods have been developed for this task. attempts have been made to automate text classification but the performance is not yet satisfactory for a fully automated curation process  <cit> .

various machine-learning methods have been successfully applied to text categorization, including naïve bayesian learning  <cit> , neural networks  <cit> , instance-based learning  <cit> , maximum entropy  <cit> , and support vector machines   <cit> . svm was first successfully applied to text classification in  <dig>  <cit>  and has been shown to perform better than other machine learning methods in some cases, especially when there are few training data  <cit> . briefly, for a given data type, i.e., class, svm learns a binary classifier from its positive and negative training documents presented as data vectors, by formulating and solving a quadratic optimization problem. the classifier is defined by a hyperplane with a maximum margin that separates the sample space to a positive and a negative half space containing positive and negative sample points respectively . the process of applying svm to text classification includes the following steps: selection of features  to represent the documents; construction of the training data vector where the elements of the vector are scores derived from the feature usage in the documents, using a certain term  weighting scheme; learning a classifier by supplying the training data vector into an svm library with the chosen svm kernel function and parameters; and finally, classifying a new document by converting it to a data vector and feeding it into the classifier.

both feature selection and term weighting schemes are active research areas and various methods have been developed  <cit> . the svm algorithm, originated by vapnik  <cit> , has been implemented in several libraries, such as svm-light  <cit>  and libsvm  <cit> , each with a number of selections of kernel functions. however, it is often not clear at the outset what method is most suitable for each of the steps described above when applying the svm algorithm to a particular classification problem  <cit> , and experiments with each of these areas usually need to be conducted to find or develop the most suitable method for each.

we describe here the successful application of an svm procedure for the identification of ten, fifteen, and three different data types curated by wormbase, flybase, and mgi, respectively . this method has been incorporated into the curation workflow at wormbase for the past two years. moreover, we demonstrate a simple automated procedure to combine training papers of similar data types of different databases to train a svm for the identification of these data types for a single database. this work is potentially very useful as the amount of work necessary for any single database to obtain a sufficient number of training papers for a specific data type, especially those that are found with low occurrence in the literature, may take years.

RESULTS
formulation of multi-class problem to categorize multiple curation datatypes
categorizing curation datatypes is a multi-class problem in which more than two datatypes need to be classified. svm is a binary classifier; we converted the multi-class problem of the curation datatype to a binary class problem using the one-versus-rest strategy .

feature selection
we observed that curatable information often resides in a small portion of a document or a few sentences, and rationalized that the frequency of feature usage in a document may not be of significant relevance. this observation was thus taken into consideration for both feature selection in representing the documents and the term weighting scheme for constructing the data vector. we calculated chi-square scores and mutual information scores as described by manning et al.  <cit>  for all the data types and found that the differences between chi-square scores of adjacent ranked features were much larger than those of mutual information. we thus think that chi-square score is a much better criterion for feature selection . as shown in additional file  <dig>  table s <dig>  many features of the top chi-square scores for a given data type, for example, rnai interference, are characteristic of this data type and the same observation was made for other data types as well . along the same line of reasoning, we used a binary scheme to construct a data vector for each of the documents in which a value of  <dig> is assigned if the feature is present and a value of  <dig> if not .

recall and precision measure in biocuration and comprehensive svm scheme
the performance of an svm can be evaluated using a testing set containing documents with known class labels. the commonly used evaluation metrics are recall and precision: recall = tp/; precision = tp/; where tp represents true positive, fn represents false negative, and fp represents false positive. a high precision value is normally more readily achievable than high recall in svm-based text classification  <cit>  and a high precision value has actually been preferred over a high recall in some commonly studied areas such as web page categorization etc. in biocuration, however, the goal is to obtain the highest recall possible while keeping the false positive rate reasonably low because, if recall is not high enough, curators would need to examine all published papers for their data type to uncover false negatives. on the other hand, curators would only need to examine a subset of the papers, those identified as positives, to eliminate potential false positives.

to achieve a high recall, we developed a 9-component comprehensive svm scheme with multiple svms using the top  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>  and  <dig> chi-square score ranked features. we then applied this svm and calculated the final recall and precision by combining all the papers identified from these svms . this scheme increased the recall value by as much as ~10% while only causing a tolerable decrease in precision. this comprehensive svm scheme was also utilized to increase the confidence of the identification . unless indicated otherwise, all the results presented here were analyzed using this comprehensive svm scheme.

the recall and precision values of each single svm component as well as the comprehensive svm analysis were shown in additional file  <dig>  table s <dig>  in general, for each component svm, the recall value is lower than the precision value, and the number of top ranked features required to give the best recall varies in different data types.

the comprehensive svm analysis generally increased recall and decreased the precision value in comparison to the single component svms. the effects are more prominent for some data types than others. for example, in the case of rnai data, the comprehensive svm achieved a recall of  <dig> , whereas the recall of a single svm component is  <dig>  and the worst recall of single svm is  <dig> . on the other hand, the increase of recall in comprehensive svm is not so apparent for the antibody data type. the recall of the comprehensive svm for antibody is  <dig> , which is a slight increase from  <dig> , the best recall of the single svm components, and  <dig> , the worst recall of the single svm components.

the decrease in precision in comprehensive svm also varies with different data types. for example, for the rnai data type, the precision of comprehensive svm is  <dig> , which is much lower than the best precision of  <dig>  of a single component svm and is also lower than the worst precision of  <dig>  of a single component. on the other hand, for the mutant allele sequence data type, the precision of the comprehensive svm is  <dig> , not much of a decrease in comparison to both the best and the worst precision of a single component svm,  <dig> and  <dig> , respectively.

it is not clear whether the same single component svm will give the highest recall in the testing set and different batches of validation set; we do not have sufficient validation sets to do a systematic evaluation. it is thus generally more desirable to do comprehensive svm analysis to improve recall.

automated data type identification for wormbase and flybase curation
to test our method, we applied it to ten data types  of strong interest to wormbase. a sufficient number of papers labeled with these ten data types have accumulated between  <dig> -  <dig> by curators reading each new c. elegans paper and indexing different data types; these labels were used in constructing the training sets. each paper underwent comprehensive svm analysis for each of the ten data types  and the performance for each data type was evaluated by using a testing set with papers from the same time period as that of the training set, which is from papers curated at wormbase between  <dig> and  <dig> . six of the data types were also evaluated every one-two weeks using new c. elegans papers, i.e. the validation sets, over a six-month period  . the recall and precision values of these ten data types from the testing set were in the range of  <dig>  -  <dig>  and  <dig>  -  <dig> , respectively. the recall and precision values from the validation sets agreed well with those from the testing sets for all the data types except the gene expression and gene regulation data types whose precision values decreased from  <dig>  to  <dig>  and  <dig>  to  <dig> , respectively.

the svm analysis was done using training/testing sets specified in additional file  <dig>  table s <dig> and methods. *gene product interaction does not have enough labeled papers and no evaluation was done using the testing set.

the number of papers in each batch varies depending on how many papers on c. elegans were published in the relevant time period. for example, for the five batches validated for rnai data, the number of papers ranged from  <dig> to  <dig>  the svm performance for rnai data type among different batches varied little judging by the standard deviation of recall and precision: recall of these five batches is  <dig>  + <dig>  and precision is  <dig>  ±  <dig> . we also examined the precision value of svm analyses of six batches for gene expression data type. these six batches ranged from  <dig> to  <dig> papers, and the average precision value is  <dig>  ±  <dig> . the performance of a batch was not correlated with its size. for example, the batch with the highest precision , and the batch with the lowest precision , have about the same number of papers,  <dig> and  <dig>  respectively. the precision of the largest batch with  <dig> papers is  <dig> , close to the average.

several factors may contribute to the decrease in the precision value from the validation set for gene expression and gene regulation data type, in comparison to those from the testing set: data type definitions may change over time, and different vocabularies may be used to describe data type-specific information as new experimental methods are invented or old experimental methods become obsolete. for example, when looking at gene expression, northern blotting was commonly used in the past but is now less frequently used, having been replaced by techniques such as reporter gene expression and rt-pcr.

the training papers for gene expression and gene regulation, the data types whose validation set showed much lower precision than the testing set, are obtained from a collection of the past  <dig> years. we do not have sufficient training papers to make large enough training set for different period of time to examine the time effect; this can be done more effectively at a later time when significant number of newly labeled papers are available for systematic comparison.

the svm method does not take into account synonym expansion; the change in the vocabulary of the used terms might lead to decreased performance. this type of change may be one of the reasons that the precision of the validation set for gene expression and gene regulation data types are much lower than those from the testing set. this problem can be addressed by utilizing generalized vector space models, or concept vector space models that map terms into concepts, and the document can then be categorized based on concepts which accommodate terms from different times instead of terms that may change over time  <cit> . it has been shown that the svm performance in precision was significantly increased especially in those cases with small training sets after incorporating wordnet concepts for mapping the terms  <cit> .

we also applied the comprehensive svm method to fifteen data types from flybase . table  <dig> and additional file  <dig>  table s <dig> show the results of five of these data types with high occurrence. their performances were similar to those of the wormbase data types with recall in the range of  <dig>  -  <dig>  and precision in the range of  <dig>  -  <dig> .

the svm analysis was done using training/testing sets specified in additional file  <dig>  table s <dig> and methods.

svm across organism-specific corpora
the same or similar types of data are often curated at different biological databases such as the model organism database, or mods. for some data types, the training set from one mod may not be large enough to achieve satisfactory performance. we thus explored the possibility of utilizing training papers from one mod to help with the svm analysis of similar data types in another mod. both wormbase and flybase label papers containing rna interference  data, albeit using different criteria . wormbase has identified >  <dig> papers indexed with 'rnai', while flybase has identified only  <dig> 'rnai'-labeled papers.

one strategy for utilizing the large training set of c. elegans papers to identify d. melanogaster papers that contain the rnai data type would be to remove c. elegans specific features from the c. elegans rnai feature list. however, while some features such as "fire", the surname of an author of a highly cited c. elegans rnai reference, seemed to be a likely candidate for removal, others were not so readily apparent. thus, manually editing an existing features list could be a difficult and time-consuming process.

we categorized the features of a data type to be either organism-independent or organism-dependent. those organism-independent features found in c. elegans rnai papers could contribute to the svm analysis of d. melanogaster rnai papers whereas those features only found in c. elegans rnai papers probably would not contribute to the d. melanogaster rnai svm. we postulated that by pooling the training papers from wormbase and flybase and then calculating the chi-square score for their features, the ranking of organism-independent features would be more favorable than when the chi-square score was calculated using only wormbase or flybase training papers alone. on the other hand, those organism-dependent features would be less favorable than those found using only wormbase or flybase training papers alone. as shown in additional file  <dig>  table s <dig>  the top-ranked, organism-specific features such as "fire" and "timmons," both author names of a highly cited c. elegans rnai reference, disappeared from the top  <dig> features list of the combined training set, whereas organism-independent features such as rnai, dsrna, interference, etc. remained as top-ranked features.

as shown in table  <dig> and additional file  <dig>  table s <dig>  svm analysis using a training set containing  <dig> wormbase rnai and  <dig> flybase rnai papers effectively increased the recall from  <dig> , obtained using the flybase training papers alone, to  <dig> , while the precision value remained as high as  <dig> , indicating that this pooling strategy worked well. a large training set containing  <dig> wormbase rnai papers gave a much lower recall of  <dig>  but the same precision value of  <dig>  for the same flybase testing papers.

the svm analysis was done using training/testing sets specified in additional file  <dig>  table s <dig> and methods.

performance measure for data type of low occurrence 
many data types have low occurrences, i.e., the number of documents containing the specific data type  is much smaller than those not containing the specific data type  in the document set of interest. this situation is often referred to as an unbalanced class distribution. for these data types the precision measure was inadequate as the precision value could be affected by the size of the negative set  <cit> . the precision value could be very low while in fact the percentage of false positive identification was not high at all. for example, for a data type with a 1% occurrence, if  <dig> of  <dig> papers were classified as positive of which one is true positive and the other is false positive, this would result in a recall of  <dig> and a very low false positive rate of 1%. due to the unbalanced class distribution, the precision value would only be  <dig> . the number of papers that would need to be examined to uncover the true positives is only two after the svm analysis, while  <dig> papers would be needed to uncover the true positives without svm analysis. therefore the precision value reflects neither the false positive rate nor the effectiveness of svm in improving the curation efficiency. if the same recall and false positive rate occurred in a balanced class distribution with  <dig> as positive and  <dig> as negative, the precision value would be a much higher value  which is more in line with the false positive rate and the effectiveness of svm in increasing curation efficiency. we thus focus on the "filtering term", ft =  <dig> * / = 100*/ i.e., ft = /. for the above example, ft = 100*/ <dig> = 2%, a better indicator of the improvement in the curation efficiency by filtering out negative papers. the lower the ft value, the lower the fraction of papers that need to be examined after filtering by the svm analysis and thus the higher the improvement in curation efficiency.

svm results of data types of low occurrence
the svm analysis was done using training/testing sets specified in additional file  <dig>  table s <dig> and methods.

the svm analysis was done using training/testing sets specified in additional file  <dig>  table s <dig> and methods.

tf-idf  is one of the most commonly used term weighting schemes in information retrieval and text mining. we compared svm analyses using the following three different feature selection methods and term weighting schemes: tf-idf weighting on all features, tf-idf weighting on chi-square score ranked features, boolean weighting on chi-square score ranked features using the rnai data type. the results were evaluated using two testing sets and two validation sets, respectively. the two testing sets differ in the ratio of the negative set of the positive set, one with a 1: <dig> and the other with a 2: <dig> ratio, as do the two validation sets. because the tf-idf weighting scheme without feature selection is cpu-intensive with large datasets, these comparisons were done using small training and testing sets , which were constructed by randomly selecting papers from the positive and negative labeled pools. all the different schemes used the same training, testing and validation sets.

the reason we used different ratios to evaluate the results is that we are interested to know how different ratios might affect the evaluation of results. this issue arises because in the curation process, we need to do text categorization of newly published papers on a frequent basis. the ratio of the positive papers over the negative papers in such short period of time could vary batch by batch for any data type and it could differ from the ratio of the training set.

as shown in additional file  <dig>  table s <dig>  additional file  <dig>  table s <dig>  additional file  <dig>  table s <dig>  and additional file  <dig>  table s <dig>  boolean and tf-idf weighting schemes that combine chi-square score ranked feature selection have similar recall, ≥  <dig> . by contrast, tf-idf weighting schemes using all features  have very poor recall, between  <dig>  -  <dig> . as shown in additional file  <dig>  table s <dig>  the tf-idf weighting scheme that combines chi-square feature selection has similar precision as that of the boolean one when using the testing set with the ratio of negative over positive set of 1: <dig>  in the testing set with a 2: <dig> ratio of negatives to positives and both the validation sets, a tf-idf weighting scheme that combines chi-squared score ranked feature selection has much lower precision than the boolean weighting scheme that combines a chi-squared score ranked feature selection. as shown in additional file  <dig>  table s <dig>  in the validation set with a 1: <dig> ratio of negatives to positives, the precision of the tf-idf one is  <dig>  whereas the boolean one is  <dig> . as shown in additional file  <dig>  table s <dig>  in the testing set with a 2: <dig> ratio of negatives to positives, the precision of the tf-idf one is  <dig>  whereas the boolean one is  <dig> . as shown in additional file  <dig>  table s <dig>  in the validation set with a 2: <dig> ratio of negatives to positives, the precision of the tf-idf one is  <dig> , whereas the boolean one is  <dig> . the tf-idf weighting scheme that combines all features gives similar precision values as those of the boolean weighting scheme that combines chi-square score ranked feature selection in all four evaluation sets.

the precision values of the svm analysis using the tf-idf weighting scheme are  <dig> - <dig>  lower than that using the boolean weighting scheme in three out of four cases reported here. this difference may be due to the fact that the ratio of negative over positive papers in a small pool of new papers can deviate from that of the training set. the tf-idf may also cause inappropriate scaling for some features; consequently some features with strong predicting power may be given less favourable score than those with weak predicting power, thereby undermining the performance  <cit> . the ratio of negative papers over the positive papers in each batch of new papers varies and is difficult to predict ahead of time. we think that the boolean weighting scheme that combines chi-square score ranked feature selection maybe a more suitable method than the tf-idf weighting scheme that combines chi-square score ranked feature selection for the categorization of experimental datatypes in a curation process where a small pool of new papers usually need to be analyzed in a timely manner.

numerous machine-learning methods have been used by various groups that participated in the text categorization task in the gt trec  <dig> challenge  <cit> . the methods included regularized linear classifier  <cit> , logistic regression  <cit> , pattern-based learning  <cit> , naÏve bayes learning  <cit> , theme detection  <cit> , k-nearest neighbor  <cit> , rocchio-based classifier  <cit> , svm  <cit> , as well as others. several groups have used svm in their studies on these data types and have reported different performances. the differences in performance might arise from the use of different feature selection strategies and other procedures in their svm analysis  <cit> . one of the svm method submitted to trec  <dig> has an overall high performance in a comparison with all the other methods submitted  <cit> . we did a side-by-side comparison of our method and those methods submitted to the gt trec  <dig> for the categorization of the mutant phenotype alleles, embryologic expression and tumor biology data types  <cit>  originally curated by mgi. as shown in additional file  <dig>  table s <dig>  our method showed equivalent or better results for all the three data types than both the best performance among various methods and a svm method submitted to the gt trec  <dig>  in comparison to the best performance among various methods submitted to gt trec  <dig>  <cit> , our method achieved similar recall for all three data types and a  <dig> - and  <dig> -fold increase in precision for the mutant phenotype allele and the tumor biology data type, respectively. in comparison to the svm method submitted to the gt trec  <dig>  <cit> , our method gave a higher recall value,  <dig>  ±  <dig> , compared to  <dig> , and a similar precision value for the embryologic expression data type. for the other two data types, our method gave similar recall but more than 2-fold increase in precision. furthermore, our method is relatively simple when compared to most of the methods submitted to gt trec  <dig>  which involved multiple steps or required expert domain knowledge in feature selection or document preprocessing etc. our method does not require any data type specific manual input or sophisticated manipulation at any step, is completely automated, and can be readily applied to different data types.

we showed that our method can be applied to the three data types of mgi giving high recall , and thus might save curation time . however, a direct comparison of our method and those methods in trec  <dig> is difficult because we used a different set and number of papers for training and testing  than those used by trec  <dig> participants. as indicated earlier, the pn ratio affects precision value. in the trec  <dig> systems, the number of negative training papers is much larger than that of the positive papers: this disparity may adversely affect precision. we think that this factor may need to be taken into consideration when evaluation schemes are designed.

previously we developed a combinatorial boolean keyword search using textpresso  <cit>  to identify papers that contained the rnai data type  with a recall of  <dig>  and precision of  <dig> . this was obtained after eight iterations of refining keywords in the search query and subsequent manual examination of false negative and false positive articles. this process requires expert domain knowledge for a specific data type and time consuming manual effort, unlike the svm method which is completely automatic with a given training set and can be readily used for different data types. furthermore, for those data types without a sufficient set of specific keywords, this approach may not be applicable.

once documents have been classified for data type identification, a subsequent task in biocuration is extraction of the information of interest. while attempts to automate fact extraction can be undermined by high false positive rates, we have observed that the false positive rate in text extraction of gene ontology cellular component data by a category-based semi-automatic text extraction approach using textpresso  <cit>  is significantly decreased when extraction is performed on only those papers identified as containing gene expression data by svm . we expect that a filtering step provided by svm analysis will have the same effect on other text extraction methods, as well.

CONCLUSIONS
although the svm algorithm has been successfully applied to text classification for nearly  <dig> years, its use in categorizing bioscience literature has been limited to specific cases  <cit> . we present here a methodology for its successful application for a broad range of data types as specified by the following three main points. first, chi-square scores appear to be a suitable criterion for feature selection in the classification of diverse data types in biocuration. second, training papers of similar data type from different databases  can be pooled to train svm for successful identification of a similar data type for different databases. this is especially useful for those data types of low occurrence as it could take a long period of time for each individual database to collect sufficient training papers. third, for data types with unbalanced class distribution, desirable performance can be achieved by using a suitable pn ratio that could be readily implemented for different data types. most studies concerning data with unbalanced class distribution have concentrated on those cases with extremely unbalanced class distribution, and there has not been much systematic study of how different levels of unbalance in the class distribution may affect svm performance in different application fields. we have observed that pn ratio affected performance even with some data types of relatively high occurrence and that the composition of the negative training set also has effects on the performance . a systematic and thorough examination in the future may provide more insight for better utilization of svm algorithms for text classification. the method presented here can be readily adopted by different biological databases for automatic identification of papers of diverse data types, thereby greatly reducing time spent on an otherwise laborious and demanding task  <cit> . we anticipate that the work and observations described herein will help not only biological databases with their curation, but also text mining researchers to improve existing, or develop better, text classification algorithms.

