BACKGROUND
due to the enormous growth of literature in biosciences, several research groups have been developing search engines with more advanced functionalities than pubmed and google . medminer  <cit> , textpresso  <cit> , ihop  <cit>  and ebimed  <cit>  are characteristic examples. such systems are primarily designed to perform information retrieval, i.e. to return documents relevant to a query within a large collection. this is typically accomplished without incorporating advanced natural language processing  techniques such as those discussed in  <cit> . with the exception of the biotext search engine  <cit> , most of these systems are not reported to have been developed by soliciting input from their intended users.

as cohen et al.  <cit>  assert, the time has now come to start exploring the usability of biomedical text mining tools, including systems which use advanced nlp techniques for tasks such as named entity recognition  and anaphora resolution. professional curators, who are responsible for populating databases with information derived from the literature, are among the intended users of these systems. however, as concluded in the most recent exploration of this issue by alex et al.  <cit> , whether advanced nlp technology can facilitate database curation remains unclear.

paperbrowser  <cit>  is the first nlp-powered curation interface to be developed under a user-centered approach. it was integrated within a curation workflow to improve the way in which curators navigate an article. this paper presents the most recent version of paperbrowser and discusses how we assessed it by applying evaluation criteria of human-computer interaction . our results show that paperbrowser improves navigational efficiency by about 58% and provides curators with enhanced utility by over 74% compared to the navigational mechanism that was previously available to them.

the paper is organised as follows: first, we discuss how observing curators at work informed the design and evaluation of paperbrowser. then, we present its main functionalities for indexing an article and outline the nlp processes that underlie them. the rest of the paper is devoted to our methods for appraising paperbrowser as a navigational aid for curation.

implementation
observing curators at work
paperbrowser has been developed under a user-centered approach, in which the intended user is actively involved in every phase of software development  <cit> . its aim is to assist the flybase literature curation team in cambridge, which currently consists of five full-time curators. flybase is a widely used database of genomic research on the fruit fly  <cit> . founded in  <dig>  flybase is updated with information from literature, other biological databases and the research community by curation teams located in three different sites. since the curation paradigm followed by flybase has been adopted by several other curation groups, interest in our efforts is not restricted to the flybase domain but extends to the wider curation community.

flybase literature curation is based on a watchlist of around  <dig> journals. each curator routinely selects a journal from the list and inspects its latest issue to identify which articles to curate. curation takes place on an article-by-article basis . in our previous work  <cit> , we outlined the curation workflow and discussed why extant information retrieval tools which are devised to support the topic-by-topic curation model do not support the article-by-article curation paradigm followed by flybase. in this section, we discuss how observing curators informed our system design.

in accordance with the user-centered model for system development, we observed curators at work to gain insight into their practices. two curators were observed by the first author who was keeping notes. the observations took place in the curators' office and lasted for six working days .

the observer focused on the way in which the curators interact with the curated article, which is typically viewed in printed form or online . we noticed that curators do not read the article from the beginning to the end. rather, they look for regions in the article which contain a lot of curatable information. once such a region is identified, they highlight segments of text within that region on their hard copy with their marker. afterwards, they look further away in the article for another curatable region. the "find" function is often used to search the electronic version of the article for multiple occurrences of the same term and identify a curatable region. since curatable entities are often expressed by various names which may also correspond to common english words  <cit> , the result of this operation contains a lot of noise that hinders curation.

similar information is usually conveyed in various parts of the article, often several pages away, and curators need to compare these excerpts with each other to decide exactly what will be curated. using "find" to "flip back and forth" between the different parts of the article and compare them adds significantly to the curation effort.

the exact way in which the curators navigate the article using "find" varies from one individual to the other. curators also differ in their highlighting density, i.e. the way in which they highlight text: once a single segment that contains several chunks of curatable information is detected, some curators might mark it with just a few actions . other curators prefer to perform more fine-grained highlighting within the segment, one for each curatable chunk of information . the sectioning of the document as well as the names of genes and related entities which are mentioned in it are known to be important clues for curation  <cit> . however, our observations led us to the conclusion that neither the article printout nor its online version enable the curators to make adequate use of these clues. thus, our first aim was to develop nlp technology which can identify such curation clues relatively reliably. additionally, the insights from our observations were used to develop an interface which exploits the nlp analysis to provide the curators with enhanced modes of navigating the text. evaluation criteria from hci were applied to assess this interface.

an alternative option would have been to build a traditional information extraction system such as the one discussed by  <cit>  that would provide the user with automatically filled templates. however, as already argued by  <cit> , this would not have been particularly helpful since it shifts the curators' responsibility to verifying the quality of the nlp output, often forcing them to go back to the text and confirm its validity. instead, we set out to develop a system in which the users maintain the initiative following their preferred curation style but are usefully assisted by software adapted to their work practices. this system is described in the next section.

paperbrowser
paperbrowser is a web browser built on top of existing open source software with several additional functionalities aiming to improve the way in which the curator interacts with the article. to respond to the need to navigate the text more efficiently, paperbrowser is equipped with two navigation mechanisms called paperview and entitiesview. these are organised in terms of the document sectioning and possible relations between groups of words , both of which are useful cues for curation as already mentioned. more specifically, paperview lists gene names such as "dpp" or "toll" in the order in which they appear in each section of the article . entitiesview lists noun phrases related to the gene names such as "the dpp pathway" .

clicking on a node in either paperview or entitiesview redirects paperbrowser to the sentence that contains the corresponding gene name or noun phrase. when a name on paperview is clicked, it is highlighted in a different colour . when entitiesview is clicked, the gene name highlighting is switched off while all noun phrases listed together with the clicked node in entitiesview are highlighted in the same colour . in this way the selected node and the related noun phrases become more visible in the text.

entitiesview and paperview are meant not only to provide the curator with an overview of the gene names and the related noun phrases in the article but also to support focused extraction of information, e.g. when the curator is looking for a gene name in a specific section or tries to locate a noun phrase referring to a certain gene product. they should also enable the curator to detect curatable regions and move back and forth between them quickly and efficiently.

natural language processing pipeline
paperbrowser's backbone is the nlp pipeline which is shown in figure  <dig>  the pipeline can be fed with articles in xml format which are available from certain publishers. for articles which appear in pdf format only, a third-party commercial software for optical character recognition  is used for the initial pdf-to-xml translation. the document structure module translates the xml which is derived from the publisher or the ocr process into scixml, a generic xml scheme defined to represent scientific articles  <cit> . at this stage, the different sections of the document as well as their headings and subheadings are recognised as explained in lewin  <cit> .

this output is then fed to a module for ner that implements machine learning to identify gene names in the text. ner can be performed either by using a hidden markov model  or conditional random fields  as discussed by vlachos  <cit> . then, the rasp parser  <cit>  is employed to identify the boundaries of each noun phrase , its subconstituents and its grammatical relations with other constituents in the text. each np is classified semantically using information derived from the sequence ontology  <cit> . ner, parsing and semantic class information are then used to resolve the anaphoric dependencies between nps as described in gasperin  <cit> .

a version of the article in fbxml  which encodes the outputs of each process is displayed by paperbrowser. the paperview navigator makes use of the output of the ner system and information about the structure of the article, while entitiesview utilises the output of the anaphora resolution module as well.

following the standard evaluation methodology in nlp, the ner and the anaphora resolution modules were found to achieve state-of-the-art performance on full papers . however, in order to appraise whether this performance can facilitate curation, these modules need to be embedded in an interface tailored to the user's needs  <cit> . since evaluating these applications is time consuming and hard to perform in a large scale, most existing text mining systems used by curators have not been subjected to extensive user-based evaluations. the rest of the paper discusses how we assessed paperbrowser's navigational functionalities by applying evaluation criteria of hci.

RESULTS
in our previous study  <cit> , we measured the time it took a curator to complete a curation record. the study revealed a trend for records to be completed faster by about 20% when the curator was interacting with the article via paperbrowser as opposed to extracting information from a hard copy.

in this study, we focus on assessing whether paperbrowser enhances the way in which the curators navigate an article. since curators routinely use "find" to navigate the electronic version of an article, we compare this mechanism with paperbrowser's navigational aids. the text highlighting task, which is an integral part of curation as explained earlier, was used to collect data about how the curators navigate the text.

methods
paperbrowser was updated to enable the curators to highlight text. highlighting events and navigation actions  were logged. paperbrowser was also adjusted to enable loading an article without making its navigational functionalities available. this is similar to viewing the article on a standard browser.

two curators participated in the study, one with low highlighting density and another with high highlighting density as identified during our observations. both participants have more than two years curation experience and have used paperbrowser before. the curators looked at issues from two open-access journals published since  <dig> and identified  <dig> uncurated articles by applying their standard criteria. the articles contain various types of curatable information and were selected without any special adjustment to paperbrowser. each article was processed by the nlp pipeline, using the the publisher's xml as the input. the crf-based system, which was shown to perform better than the hmm-based one in full-articles  <cit> , was used for ner.

the curators were asked to interact with paperbrowser and first identify curatable entities . then, they highlighted text that contains curatable information for each entity. to make the task as clear as possible, the curators were given step-by-step guidelines and examples of the kinds of curatable information that typically occur in an article. the guidelines and the examples are available in additional file  <dig> 

paperbrowser's navigational functionalities were available for half of the articles . for the other half, these functionalities were not available . the "find" function was always available. the presentation order was randomised and the assignment of articles to each condition was counterbalanced . by experimenting with a relatively large number of articles and by controlling the presentation mode, we believe to have overcome any possible selection bias caused by curators favouring certain types of articles. the same type of screen was used by both curators, who were instructed to arrange the windows as shown in figure  <dig>  and figure  <dig> . this arrangement remained constant throughout the study.

data analysis
each of the  <dig> datapoints  was classified as follows:

• whether paperbrowser's navigators were available when the article was viewed  or not .

• which curator did the highlighting .

• whether the navigators , "find"  or a combination of the two  were used between two subsequent highlighting events. navigated events are events immediately preceded by at least one navigation action. unnavigated events were not immediately preceded by any navigation action and are labelled as prev:none. using the slider bar falls in this category too.

• whether the text marked in a highlighting event followed  or preceded  the text that had been highlighted in the immediately previous event. text:before events represent cases of highlighting-back in the article.

• we also measured the distance in tokens  between text regions marked by two subsequent highlighting actions, a variable that we call dist. dist was used to account for unnavigated events as explained below.

experimental questions
the study is designed to investigate the following questions:

• do paperbrowser's navigators provide the curators with an improved way to navigate the text compared to the navigation mechanism that was available to them previously ?

• when are the navigators not used?

with respect to the second question, during our observations we noticed that navigation takes place to highlight segments which are far away from each other in the text. hence, we expect dist for navigated events to be significantly higher than dist for unnavigated events.

the control condition provides evidence about how frequently "find" is normally used. if "find" is used much less frequently in the experimental condition and if paperbrowser's navigators account for most of the navigated events in this condition, we can conclude that they have replaced "find" as a mechanism for navigating the text.

moreover, we compare paperbrowser's navigators with "find" by applying to the text highlighting task two evaluation criteria from hci, namely efficiency and utility  <cit> . to estimate the efficiency of each navigation mechanism, we counted the number of navigation actions that preceded each navigated event. the fewer the actions, the more efficiently the curator accesses information.

to estimate the utility of each navigation mechanism, we measured the number of unnavigated events that followed each navigated event. the larger this count, the less the curators have to "flip back-and-forth" in the article. we also investigate whether our measure of utility is affected by the differences in highlighting density between the curators which were discussed earlier in the paper.

use of navigation mechanisms
as table  <dig> shows, when the navigators were not available , the "find" function was used 45% of the time. moreover, 69% of highlighting-back events  were preceded by using "find". these results indicate that the curators used "find" to navigate the articles quite frequently in the control condition, especially when they were highlighting-back.

however, when the navigators were available , just 3% of the highlighting events were preceded by using "find". notably, only 2%  of the highlighting events in navs:on were preceded by a combined use of both navigation mechanisms . moreover, prev:find accounted for just 11% of highlighting-back events in navs:on.

the curators preferred to use paperbrowser's navigators over "find" when the navigators were available.

as table  <dig> shows, the curators only used paperbrowser's navigators  before 83% of the navigated events in navs:on. moreover, 86% of the navigated events in text:before were also preceded by use of the navigators only. these results indicate that the curators identified curatable text without resorting to "find" in the large majority of the navigated events in the experimental condition, including most instances of highlighting-back. in other words, paperbrowser's navigators have replaced "find" as a mechanism for navigating the article.

navigation distance
as table  <dig> shows, mean dist is much higher for navigated  than unnavigated  events in the control condition . to test whether this difference is significant and whether the result holds for both curators, we conducted a  <dig> ×  <dig> anova followed by planned pairwise comparisons using the independent-samples two-tailed t-test as suggested in  <cit> . this procedure was followed for the statistical analyses reported in subsequent sections too. the "r" statistical software was used to run the tests  <cit> .

mean distance in tokens  between text marked in a navigated event  or an unnavigated event  and the text highlighted in the immediately preceding event in the control condition . curator-specific data are indicated by the curator's id . mean is calculated as the sum of all observations divided by the number of observations .

more specifically, a  <dig> ×  <dig> anova with conditions prev  and curid  showed a significant main effect for prev < <dig> , p <  <dig> ). the effect of curid <  <dig> , p =  <dig> ) and the interaction between prev and curid <  <dig> , p =  <dig> ) were not significant. these results show that the text marked between two subsequent highlighting events tends to be much further away when "find" is used compared to the cases in which "find" is not used. two-tailed t-tests on prev  for each curator  =  <dig> , p <  <dig> ; cur02: t =  <dig> , p <  <dig> ) confirmed that this result holds for both curators.

mean distance in tokens  between text marked in a navigated event  or an unnavigated event  and the text highlighted in the immediately preceding event in the experimental condition . curator-specific data are indicated by the curator's id .

these results show that the text marked between two subsequent highlighting events tends to be much further away when paperbrowsers' navigators are used compared to the cases in which they are not used.

two-tailed t-tests on prev  for each curator  =  <dig> , p <  <dig> ; cur02: t =  <dig> , p <  <dig> ) further confirmed that this finding holds for both curators.

in summary, the results in this section confirm our prediction that dist for navigated events is significantly higher than dist for unnavigated events. this accords with our account for unnavigated events: when the highlighted segments of text appear close to each other, the curators refrain from navigating the article. navigation is more likely to occur to highlight segments which appear further away from each other in the article.

navigation efficiency
as table  <dig> shows, the curators highlighted curatable text after just  <dig> navigation actions when the navigators were available . this represents a relative improvement on efficiency by  <dig> % compared to the average number of preceding "find" actions in the control condition .

mean number of navigation actions occurring before each navigated event using "find"  in the control condition and paperbrowser's navigators  in the experimental condition. curator-specific data are indicated by the curator's id .

a  <dig> ×  <dig> anova with conditions prev  and curid  showed a significant main effect for prev  =  <dig> , p <  <dig> ), no main effect of curid  =  <dig> , p =  <dig> ), and no interaction between prev and curid  =  <dig> , p =  <dig> ). two-tailed t-tests on prev  for each curator  =  <dig> , p <  <dig> ; cur02: t =  <dig> , p =  <dig> ) further confirmed that these findings hold for both curators. these results show that it takes significantly fewer user actions to identify curatable text when paperbrowser's navigators are used in comparison to navigating the article using "find".

navigation utility
as table  <dig> shows, when the navigators were available , the average number of unnavigated events that followed each navigated event was increased by  <dig> % compared to the mean count of unnavigated events that follow a "find" action in the control condition .

mean number of unnavigated events occurring after an event navigated using "find"  in the control condition or paperbrowser's navigators  in the experimental condition. curator-specific data are indicated by the curator's id .

a  <dig> ×  <dig> anova with conditions prev  and curid  showed a significant main effect for prev  =  <dig> , p <  <dig> ). two-tailed t-tests on prev  for each curator  = - <dig> , p <  <dig> ; cur02: t = - <dig> , p <  <dig> ) further confirmed that these findings hold for both curators. this result shows that using paperbrowser's navigators significantly reduces unnecessary "back and forth flipping" in the article.

the effect of curid was also significant  =  <dig> , p <  <dig> ). this is due to the differences in highlighting density between the curators. the highlighting density of cur <dig> is higher than that of cur <dig>  thus giving rise to a significantly higher number of highlighting events in each condition. the interaction between prev and curid was significant too  =  <dig> , p <  <dig> ). this means that the effect for prev is more pronounced for one of the curators. this is also evident by the high ratio  of the difference in mean utility  for cur <dig> over the same difference for cur <dig> 

taken together, these results suggest that the significant improvement in utility occurs irrespective of the different ways in which the curators highlight text in the article.

discussion
the usability of systems developed to address the information overload faced by experts in life sciences has begun to be explored only very recently  <cit> . alex et al.  <cit> , whose work is the closest to ours, report on three experiments measuring whether curation can be speeded up using nlp. although curation appears to be faster sometimes in their experiments, they conclude that a careful consideration of several other factors is required before a verdict on the usefulness of nlp for curation is reached.

in this paper, we extended our previous study on measuring curation time by using additional hci criteria to evaluate the usefulness of paperbrowser. while alex et al. do not discuss whether users were involved in the development of their curation interface, paperbrowser was developed under a user-centered approach. although this adds to the time and complexity of the development process, it increases the likelihood of producing a useful system  <cit> .

among the several engines developed to enhance literature search, only the system of hearst et al.  <cit>  is reported to have been developed and evaluated using hci principles. however, like most other information retrieval systems, it only employs shallow techniques for text analysis. by contrast, paperbrowser indexes an article using the output of several advanced nlp modules.

given that paperbrowser navigators make use of the nlp output, assessing its navigational capabilities provides new evidence in favour of the usefulness of nlp for curation. our results indicate that paperbrowser's navigators essentially replaced "find" as a mechanism for navigating the article. using paperbrowser's navigators leads to a significant improvement on efficiency of about 58%  for both curators compared to navigating the article using "find". a significant improvement on utility of about 74% at the same confidence level for both curators, irrespective of their differences in highlighting density, was also observed. to date, over  <dig> articles have been curated with the use of paperbrowser without aborting it , further suggesting that paperbrowser can support flybase curation successfully.

the dist variable was used to account for unnavigated events. dist for navigated events was found to be significantly higher than dist for unnavigated events in both conditions, as expected from our observations. in other words, highlighting a segment which is far away from the text that had been marked in the immediately previous highlighting event is likely to be preceded by navigation. by contrast, both curators refrained from performing a navigation action when they were highlighting excerpts closer to each other. to the best of our knowledge, this is the first attempt to describe how curators use an nlp-powered interface for a task integral to curation on the basis of empirical data.

to run the reported study, we used articles in the publisher's xml format as the input to the nlp pipeline, thus ignoring the noise that is introduced by the ocr process when this input is not available. we intend to address this limitation in our future studies.

investigating curation accuracy and agreement between curators was left outside the scope of this study to avoid making it too complicated. we assumed that the curators always identify relevant information when they highlight text, which is reasonable given the extensive training that they undergo. extending our evaluation framework to investigate these additional variables constitutes another direction for future work.

CONCLUSIONS
that nlp can be a useful aid for curation has long been assumed within the biomedical text mining community. however, there has been little evidence so far that this is indeed the case. how to utilise this technology within an existing curation workflow has been equally unclear.

paperbrowser is an nlp-engined curation interface developed under a user-centered approach and aiming to enhance the way in which the curator navigates an article. this paper discusses how hci principles have been applied to develop and evaluate paperbrowser, providing the text mining community with a general and replicable framework.

our evaluation study shows that paperbrowser improves navigational efficiency and provides flybase curators with enhanced utility compared to the navigation mechanism that has been available to them previously. we conclude that state-of-the-art performance in ner and anaphora resolution can be combined with the navigational functionalities of paperbrowser to support flybase curation quite successfully. given the large number of groups which curate in a similar way as flybase, this study is likely to have far-reaching implications.

availability and requirements
• project name: flyslip

• project website: 

• programming language: java  <dig> . <dig> or above.

• restrictions:

paperbrowser is implemented on top of mozilla gecko and jrex. it runs on 32-bit linux fedora core  <dig> and is freely available for non-commercial use from the resources section of the flyslip website.

the nlp pipeline uses commercial software for ocr and the ptx reformatter for the initial xml output  <cit> , for which licences are required, and the rasp toolkit and project specific software for ner and anaphora resolution, which are freely distributed under a non-commercial licence.

authors' contributions
nk, rs and pm designed and ran the evaluation study. nk also carried out the curation observations, performed the statistical analyses and drafted the manuscript. il designed and implemented paperbrowser. av and cg implemented the nlp modules for ner and anaphora resolution respectively. tb contributed to the development of the pipeline and led all aforementioned efforts as the project's pi together with rd. all authors read and approved the final manuscript.

supplementary material
additional file 1
step-by-step guide for highlighting. guidelines given to the curators for the text highlighting task.

click here for file

 acknowledgements
flyslip is funded by the uk biotechnology and biological sciences research council .
