BACKGROUND
in recent years there has been an increased interest in the study of serial microarray experiments, particularly time course data. this has been driven by the greater availability of such data and the appeal of elucidating the temporal relationships among genes. often, approaches to the analysis of these data sets have employed traditional methods of exploratory data analysis and clustering, but it has been recognized that methods specifically designed to exploit the temporal relationships are advantageous  <cit> . this has led to approaches based on time series and frequency analysis, hidden markov models, and linear modeling, among others.

one popular strategy in modeling time course data will be referred to here as bilinear modeling. in this approach, the matrix of gene expression data, x , is represented as the product of two lower rank matrices, which we will designate as c and p, and a residual error term, e:

x = cp + e     

 in this representation, c has dimensions m × p and p has dimensions p × n, where p is the number of basis vectors  needed to reconstruct the data within experimental uncertainty. normally, for microarray experiments, the number of genes  is much greater than the number of experiments , which in turn is greater than p. in general, the first goal in bilinear modeling is to obtain the matrices c and p, given the experimental data, x, and some knowledge or assumptions of the statistical characteristics of e. however, for a given data set there are an infinite number of degenerate solutions for c and p due to arbitrary rotation  and scaling  of the basis vectors in the subspace they define. to overcome this problem, some of the approaches commonly adopted in the microarray literature include expression deconvolution, principal components analysis  and independent components analysis , among others.

in expression deconvolution  <cit> , the rotational ambiguity problem in eq.  is addressed by assuming that the matrix c is already known. typically, the vectors that constitute the columns of c would be estimated from cells known to be associated with a specific cellular state, such as certain phases of the cell cycle. once c is known, the solution for p becomes a classical least squares problem. although this approach is quite straightforward, its major drawback is that it requires complete knowledge of one of the constituent matrices, information which is not always available. this information is not required for pca  <cit> , which uses singular value decomposition  to decompose the expression matrix into a set of scores  and loadings  that are truncated to the first p factors. pca imposes the constraint that successive factors in the decomposition must  account for the largest amount of residual variance, and  be orthogonal to all of the factors determined to that point. because of these constraints, the scores and loadings vectors do not normally have an obvious biological interpretation. despite this shortcoming, the extension of svd to compare expression profiles across different data sets has been reported  <cit> . the strategy employed by ica  <cit>  in the decomposition of x is similar to that used by pca, except that the constraints require a minimization of the statistical dependence of the columns of c. although one might expect this constraint to produce more meaningful factors than pca, the biological rationale behind its imposition has not been clearly established. other bilinear modeling approaches have also been used , but these will not be described in detail, except where they relate to the current work below.

in this work, an alternative approach to solving the bilinear modeling problem represented by equation  is described and evaluated. this problem is not new and arises in many disciplines, leading to a variety of solutions. in chemistry, the problem often presents itself in the analysis of chemical mixtures, where neither the concentration nor the identity of the constituents is known. solutions to this problem, collectively referred to as multivariate curve resolution  methods  <cit> , impose constraints on the results that are physically meaningful. the simplest and most common of these is a requirement of non-negativity in the elements of c and p. other constraints include unimodality, equality, and closure. quite often, the imposition of one or more constraints is sufficient to produce a unique or nearly unique solution to the rotational ambiguity problem.  we show that this approach, with some modifications necessitated by the nature of microarray data, can be successfully adapted to study gene expression.

a simple biological model
to rationalize the bilinear model in equation  from a biological perspective, figure  <dig> shows a simple framework illustrated for the case of only three genes and two underlying factors or components. we will refer to the matrix p generically as the "profile matrix" and it can be viewed as representing the evolution of regulatory inputs  as a function of time. in other work, analogous terms have been used to describe the vectors of the profile matrix: "process objects"  <cit> ; "transcription module"  <cit> ; "biological processes"  <cit> ; "arraylets"  <cit> ; "eigenarrays"  <cit> . in all of these instances, a fundamental assumption is that "the coregulation of genes may be described by a small number of effective regulators, each acting on a large set of genes and varying between distinct biological situations"  <cit> . the matrix c will be referred to as the "contribution matrix" and describes how each gene responds to each of the regulating factors. in a conceptual interpretation, these could correspond to receptor elements on a particular gene. in the example given in figure  <dig>  gene  <dig> responds only to the first transcription factor and gene  <dig> only to the second, while gene  <dig> responds in equal measure to both regulators. although only values of unity or zero are used in the example for simplicity, the model in its general form does not impose this restriction. the elements of c are analogously referred to in a variety of ways in other work: "gene objects"  <cit> ; "independent components"  <cit> ; "pure populations"  <cit> ; "genelets"  <cit> ; "eigengenes"  <cit> . the expression profile for each gene is therefore represented as a linear combination of the vectors in the profile matrix in proportions defined by the gene's contribution values. if one could extract the profile matrix from the expression data, it would provide important information regarding the underlying regulatory inputs driving gene expression. likewise, a knowledge of the contribution matrix would illuminate relationships among the genes in the organism.

the model represented in figure  <dig> is amenable to solution through the implementation of non-negativity constraints for the elements of c and p, since a regulatory input can turn the expression of a gene on or off, but it cannot result in negative expression. therefore, it should be possible to apply mcr with non-negativity constraints to expression data, with one important caveat – it cannot be directly applied to log-transformed data. the implications of this are discussed in the next section.

implications of data transformation
while the level of gene expression cannot physically be negative, this is not true of the logarithms, so non-negativity constraints in mcr cannot be applied to log-transformed data. while this represents one limitation of log-transformed data, there is another implication of imposing the transformation that is perhaps more important. it should be apparent that the simple linear relationship represented in figure  <dig>  where the level of expression of a gene is presumed to be in direct proportion to the abundance of contributing regulatory factors, would no longer be valid under logarithmic transformation. despite this fact, there appears to be little discussion in the literature regarding the actual representation of expression values. we have found that many of the authors studying applications of bilinear modeling methods do not explicitly state whether log-transformed values were used, but those who did generally used transformed data, implying that this is the norm. there is a limited discussion of the effects of the log transformation on the linear model  <cit> . these authors point out that a linear model in the log-transformed domain corresponds to a multiplicative model in the untransformed domain; i.e. the expression of a gene is in proportion to the product of two or more regulating factors. while such cooperative effects are entirely possible and even likely, the simple linear model represented by figure  <dig> seems to us to be a more intuitive construct for a first approximation. lee et al.  <cit>  suggested the use of nonlinear mapping to resolve this problem. kreil et al.  <cit>  compared the results of applying ica to transformed and untransformed data and found lower reconstruction errors in the log-transformed space. they suggest that a possible reason for this was the structure of measurement errors in the two spaces.

one of the reasons for the popularity of log-ratio as opposed to ratio data in representing gene expression is the error structure of raw expression data, which is generally accepted to have a multiplicative component . because uncertainty in the intensity ratio is typically proportional to the magnitude of the value, log-transformation gives rise to values with a uniform error variance. moreover, transformation reduces the influence of outliers, which are common in microarray experiments. because most bilinear modeling algorithms are based on least-squares minimization, the effects of heteroscedastic measurement error and outliers can be large. derived models will tend to emphasize large measurements, even though smaller measurements may contain an equivalent amount of information. this problem can be exacerbated with time-course experiments, where variations in expression can be genome-wide and the reference mrna does not always bear a close expression match to the test mrna.

based on the view that the linear model presented in figure  <dig> seems more natural from a biological perspective, and our desire to impose non-negativity constraints, modeling in this work was conducted on untransformed ratios. it was clear that, in order to do this, some method would be need to be developed to accommodate the multiplicative error structure and outliers in the data. liu et al.  <cit>  employed a robust form of svd to address the problem of outliers, but avoided the multiplicative noise issue by applying it to log-transformed data. except in special circumstances, the problem of non-uniform measurement noise cannot be addressed through simple scaling. however, in recent years, a number of techniques, such as maximum likelihood pca   <cit>  and total least squares   <cit> , have been developed to treat heteroscedastic and correlated error structures. in this work, we have adapted a tls approach to mcr and demonstrate its performance through its application to widely studied yeast cell cycle data.

multivariate curve resolution
mcr attempts to solve eq.  for its two constituent matrices based on a prior knowledge of the number of underlying factors, p, and any constraints on the system. generally, non-negativity constraints are assumed and additional constraints are added as required by the problem. in early work, lawton and sylvestre  <cit>  developed an analytical solution for boundaries of solution vectors in the case of two factors, but direct solution for more than two components is made impractical due to the complexities of the problem. a wide range of alternative strategies have been developed since that time, but one of the most popular approaches due to its simplicity and reliability is alternating least squares   <cit> . this is the approach used in this work.

the basic algorithm for curve resolution by als is as follows. initially, one must choose the number of factors , p, that will be extracted for the bilinear model. a variety of approaches can be used for this, many of which are based on the statistics of reconstructing the original data from pca scores and loadings with increasing numbers of factors  <cit> . alternatively, one can examine the results of curve resolution applied with different numbers of factors, seeking results that show a pattern of behavior consistent with the system under study. for example, in a time course study, one would expect that profiles extracted will show a smoothly varying function . the appearance of random patterns would suggest that one has reached the point where noise is being modeled.

once the number of factors has been chosen, an initial estimate for c or p must be provided. because of the symmetry of the algorithm, either of the matrices can be the starting point, but in this application p is suggested since it will be smaller and follow a more systematic variation. one disadvantage of the als algorithm is that the selection of this initial matrix can influence the final solution, in part because this solution may represent only one of a range of feasible solutions. the variability of these solutions will depend somewhat on the structure of the data, but in many cases they will fall into fairly tight boundaries. there are several approaches to defining the initial p. one is to simply assign random positive values to the elements. while this ensures the results will be unbiased, the initial vectors are almost certainly well outside the subspace of the measurements and therefore convergence may be slower and more prone to numerical difficulties. another fairly simple approach is to use p profiles selected randomly from x. these will be close to the true subspace, but may have some problems with collinearity. other more systematic methods, such as simplisma  <cit>  and the needle-search method  <cit> , can also be used. whichever method is used, it is advisable to run the algorithm several times from different starting points to ensure consistency in the generated profiles.

at each stage in the algorithm where a new estimate of p is generated, it is scaled so that the euclidean norm of each row is equal to unity. this is necessary because of the scale ambiguity that results from the fact that the columns of c and the rows of p can be arbitrarily scaled relative to each other to give the same result for x. because of this, the absolute magnitudes of the rows of p and the columns of c are not meaningful except in a relative sense within each vector. this ambiguity can only be resolved if separate absolute standards are available, but generally the relative magnitudes are more important in any case. to avoid infinite degenerate solutions that differ only by a scaling factor, the ambiguity requires that one of the matrices be scaled to a fixed point of reference so that convergence can be determined. in this case, the profile vectors are scaled to unit length, but other criteria, such as unit area, could also have been used.

the iterative part of the als algorithm begins when an estimate of c is calculated based on the initial estimate of p and the microarray data in x. this can be obtained in the usual way, solving the least-squares problem using the pseudo-inverse of the estimated p,

c^=xp^t−1     
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfdbwqgaqcaiabg2da9iab=hfayjqb=bfaqzaajawaawbaasqabeaacqqgubavaagccqggoaakcuwfqbaugaqcaiqb=bfaqzaajawaawbaasqabeaacqqgubavaagccqggpaqkdaahaawcbeqaaiabgkhitiabigdaxaaakiaaxmaacawljawaaewaceaacqaiyagmaiaawicacaglpaaaaaa@3dfe@

in order to observe non-negativity constraints, the negative values in c^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfdbwqgaqcaaaa@2dd1@ are set to zero once this result is obtained. alternatively, a more rigorous solution to the non-negative least squares  problem can be obtained using standard methods  <cit>  which minimize the sum of squares of residuals in x conditional on the constraint that the elements in c are greater than or equal to zero. following this step, the estimated c matrix is used to re-estimate p. once again, this can be done by censoring the standard least squares solution,

p^=−1c^tx     
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfqbaugaqcaiabg2da9iabcicaoiqb=neadzaajawaawbaasqabeaacqqgubavaagccuwfdbwqgaqcaiabcmcapmaacaaaleqabagaeyoei0iaegymaedaaogaf83qamkbakaadaahaawcbeqaaiabbsfaubaakiab=hfayjaaxmaacawljawaaewaceaacqaizawmaiaawicacaglpaaaaaa@3dcc@

or by solving the nnls problem. the rows of p^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfqbaugaqcaaaa@2deb@ are normalized as described above following this step, and the procedure is repeated, estimating c once again from p. eqs.  and  represent the core of the als algorithm and give rise to its name, since each step alternately estimates one matrix given the other. the iterations continue until convergence, which is most easily tested by checking for insignificant changes in p and/or c.

weighted multivariate curve resolution
although the als method for multivariate curve resolution works well in many cases, one of the assumptions that it makes in solving the least squares problem is that the residual measurement errors exhibit uniform measurement variance. while this is true, or nearly true, for many spectroscopic methods used in chemistry, the same cannot be said for microarray data. it has been widely observed that microarray intensity measurements, at least for relatively high intensities, exhibit a multiplicative error structure; i.e. a constant coefficient of variation  <cit> . through propagation of error, it is easily shown that this proportional error structure in the intensities leads to multiplicative errors in the expression ratios as well. this is problematic for mcr-als, since it will tend to ignore the smaller signals, even though they have the same signal-to-noise ratio as the larger signals. this problem is normally addressed through a log transformation, but as noted earlier, this would destroy the bilinear structure of the original expression data and remove the non-negativity constraint used by mcr.

a more general model for the error structure in microarray intensity measurements involves both multiplicative and additive terms  <cit> , with the additive term becoming most important for low intensity measurements. as expected, this additive term leads to a very large coefficient of variation in expression ratios for low intensity signals, which do not follow the general multiplicative error structure. often, these measurements, which are close to the background, are excluded from the analysis, as are spots that are judged to be unacceptable due to their morphology or other reasons. such missing data can be treated in a number of ways. one approach is to simply eliminate the corresponding gene from all experiments, but this may remove important information if the measurement is unreliable in only one or a few experiments. therefore, a number of methods have been developed to accommodate missing data through imputation  <cit> . this would be a desirable feature of a curve resolution algorithm as well.

what is needed is a mcr method that is capable of incorporating measurement error information into the data analysis to obtain an optimal solution under these circumstances, in effect weighting each measurement in proportion to its estimated reliability. with such a method, the proportional error structure of microarray measurements could be accommodated so that a ratio change of  <dig>  to  <dig>  would be given as much weight as a change from  <dig> to  <dig>  moreover, missing measurements could be assigned large uncertainties so they would carry no weight in defining the final model and would effectively be imputed from the other data. in addition to the error models assumed here, such an approach should be able to handle any arbitrary error structure presented in microarray data.

the requirements above describe an errors-in-variables problem for linear regression and this problem has been solved in a variety of ways for different fields of study. perhaps the most general of these is the technique of total least squares , which provides an optimal solution for x in the linear regression problem y = ax given that y and a can have arbitrary error structures  <cit> . typically, the solution proceeds by augmenting y with a column-wise and finding the optimal subspace representation of  using maximum likelihood approaches. the reconstructed y and a matrices are then used to solve the least squares problem in the usual way. this approach is closely related to the technique of maximum likelihood principal components analysis  which has recently been described in the literature  <cit> . the tls approach can be incorporated into the existing mcr-als curve resolution method by employing a tls solution in place of the standard least squares solution. the resulting algorithm will be referred to as weighted alternating least squares . the algorithm is given in the "methods" section, so only a brief description is presented here.

to describe how the wals algorithm works, we will consider the first half of the alternating estimation procedure. in this case, we are given x, which has an arbitrary error structure, and p^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfqbaugaqcaaaa@2deb@, which is assumed to be known with certainty, and must solve for c^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfdbwqgaqcaaaa@2dd1@. the tls solution to the regression problem x = c^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfdbwqgaqcaaaa@2dd1@p^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfqbaugaqcaaaa@2deb@ is solved  by first augmenting x with p^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfqbaugaqcaaaa@2deb@ row-wise and finding the optimal p-dimensional subspace of the augmented matrix. in this case, it is clear that this subspace is defined by the p rows of p^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfqbaugaqcaaaa@2deb@, since it is assumed to be known exactly. it remains to find the optimal representation of x in this subspace. we will assume that the errors in x follow a normal distribution and their variances are described by a companion matrix, s, of equal dimensions. the estimation of x in the subspace of p^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfqbaugaqcaaaa@2deb@ is then given by the maximum likelihood projection of x:

x^i·=xi·Σi−1p^t−1p^     
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwf4baegaqcamaabaaaleaacqwgpbqacqwipm+zaeqaaogaeyypa0jae8heag3aasbaasqaaiabdmgapjabl+y6nbqabaaccegccqgfjowudaqhaawcbagaemyaakgabagaeyoei0iaegymaedaaogaf8huaalbakaadaahaawcbeqaaiabbsfaubaakiabcicaoiqb=bfaqzaajagae43odm1aa0baasqaaiabdmgapbqaaiabgkhitiabigdaxaaakiqb=bfaqzaajawaawbaasqabeaacqqgubavaagccqggpaqkdaahaawcbeqaaiabgkhitiabigdaxaaakiqb=bfaqzaajagaaczcaiaaxmaadaqadiqaaiabisda0agaayjkaiaawmcaaaaa@51c6@

in this equation, xi• indicates the ith row of x and Σi is the corresponding error covariance matrix, given by a diagonal matrix whose diagonal elements are the ith row of s. the maximum likelihood projection weights the projection of each row of x into p^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfqbaugaqcaaaa@2deb@ in such a way that measurements with large uncertainties are given less weight. once each row has been projected in this way, the estimate of c is obtained in the usual way ), except using x^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfybawgaqcaaaa@2dfb@ instead of x.

the second half of the atls algorithm proceeds in a similar manner except that the maximum likelihood projection into the space of c^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfdbwqgaqcaaaa@2dd1@ is carried out using the columns of x instead of the rows:

x^·j=c^−1c^tΨj−1x·j     
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwf4baegaqcamaabaaaleaacqwipm+zcqwgqbgaaeqaaogaeyypa0jaf83qamkbakaacqggoaakcuwfdbwqgaqcamaacaaaleqabagaeeivaqfaaggabogae4hqdk1aa0baasqaaiabdqgaqbqaaiabgkhitiabigdaxaaakiqb=neadzaajagaeiykakyaawbaasqabeaacqghsislcqaixaqmaagccuwfdbwqgaqcamaacaaaleqabagaeeivaqfaaogae4hqdk1aa0baasqaaiabdqgaqbqaaiabgkhitiabigdaxaaakiab=hha4naabaaaleaacqwipm+zcqwgqbgaaeqaaogaaczcaiaaxmaadaqadiqaaiabiwda1agaayjkaiaawmcaaaaa@517e@

in this case x•j is the jth column of x and Ψj is the corresponding error covariance matrix, which is a diagonal matrix consisting of elements from the jth column of s.

the least squares problem is once again solved using an analog of eq.  employing x^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacuwfybawgaqcaaaa@2dfb@.

using the mcr-wals algorithm, the error structure inherent in the microarray data can be incorporated in the curve resolution procedure. furthermore, missing data can be accommodated by assigning a very large variance to the associated measurements.

RESULTS
yeast cell cycle data
to demonstrate the utility of the algorithms proposed here, microarray data related to the cell cycle of saccharomyces cerivisiae described by spellman et al.  <cit>  were employed. specifically, the subset of data related to the α-factor block release experiment were used. the data in the α-factor release subset consisted of microarray measurements for  <dig> open reading frames at  <dig> minute intervals from  <dig> to  <dig> minutes, for a total of  <dig> experiments. this data set was further screened to exclude any genes for which there were more than  <dig> missing measurements. this data set will be referred to as "alpha-full" here and consisted of  <dig> genes. in addition to this, a smaller set of  <dig> pre-selected genes from this group was used as well. these genes, identified as exhibiting cell cycle-dependent changes in mrna expression levels, were the same as those employed by lu et al.  <cit> . this data set will be referred to as "alpha-696" in this work. for both data sets, a corresponding measurement standard deviation matrix was constructed by assuming proportional errors of 20% of the measurement. this value is consistent with observations we have made on other microarrays, but is not critical since the absolute magnitude of the proportional error weighting will not affect the results. in addition, missing measurements  were set to zero and the corresponding error standard deviation was set to a value much greater than the largest proportional error value in the data .

the cell cycle data set was used because it has been widely studied and exhibits some temporally structured patterns of gene expression. in addition, a number of genes postulated to be associated with cell cycle regulation have been identified. it was hoped confirmation of these patterns could be established through curve resolution methods, although a one-to-one correspondence between the underlying regulating factors and the genes related to these cycles is not necessarily required. it should be emphasized, however, that the objective of this work is to demonstrate the utility of the curve resolution method and not to conduct an extensive analysis of the cell cycle using this tool.

curve resolution of alpha- <dig> data
initially the mcr-wals algorithm was applied to the alpha- <dig> data set since this had been prescreened to select for genes with cell-cycle related expression patterns and therefore was thought to be more amenable to successful curve resolution analysis. the data were analyzed by specifying  <dig>   <dig>   <dig>   <dig>   <dig> and  <dig> components  and the extracted time profiles  are shown in figure  <dig> for each case. different numbers of components were used because it was not known a priori how many underlying factors would be present, although it was suspected that a lower limit would be related to the number of different phases in the cell cycle. furthermore, more confidence in the results can be achieved if the profiles remain consistent as the number of components is increased. if extraneous components are extracted, these can often be identified by an inconsistent or irregular pattern, or because they correlate with only a few genes that may represent outliers. the profiles extracted by mcr-wals are not obtained in any particular order, but for the purposes of representation and comparison, they have been arranged in figure  <dig> by the order of appearance of the first significant peak value.

the first and most significant feature to notice about figure  <dig> is that all of the profiles extracted are consistent with the dynamics of the system being studied. in some cases, a unimodal profile compatible with a unique set of conditions is observed, while in other cases a cyclical pattern suggesting a relationship with the cell cycle is apparent. most patterns are clear and smooth, with well defined maxima and minima that fall close to zero. these features alone indicate that the results of curve resolution are meaningful and suggest the potential utility of the method. while it is not essential that these underlying regulatory profiles correlate directly with stages in the cell cycle, since the latter are only required to be linear combinations of the former, there is a natural expectation that this will be the case. because of this, these relationships warrant further investigation.

considering first the four-component analysis shown in figure 2a, the relationships with stages of the cell cycle were investigated in two ways. first, the  <dig> genes classified by spellman et al.  into five categories related to the yeast cell cycle were extracted. the expression profiles of these genes were then normalized and plotted as shown in figure  <dig>  this allowed a visual comparison between the profiles extracted and those observed for genes reported to be representative of that stage of the cell cycle. note that, in this plot, missing measurements were interpolated between the surrounding measurements. a second, more quantitative comparison was made through a correlation study, the results of which are presented in table  <dig>  this was conducted by first finding the genes in the entire set  that correlated most strongly with each of the profiles extracted. correlation coefficients were calculated around the origin  and a cutoff of > <dig>  was arbitrarily chosen to indicate substantial similarity with the profiles. the number of genes meeting this criterion for each profile is listed as the parameter "ntot" in table  <dig>  within this group, the number of genes which were on spellman's list of  <dig> genes is was also determined and is given as "" in the table. for each profile, correlated genes that were found on this list are given in the table in descending order of correlation, along with the cell cycle stages to which they were assigned. also shown in parentheses is the rank of that gene  in the correlation list and the corresponding correlation coefficient. in order to conserve space, a maximum number of  <dig> genes from each list was allowed in the table.

the first of the four curves in figure 2a  is characterized by a maximum at time zero that falls relatively quickly to baseline levels. this curve was initially thought to be associated with genes that are down-regulated after release from α-factor arrest as they do not appear to be part of the regular cell cycle, although there is another small increase around one hour. in table  <dig>  only  <dig> of the genes classified in spellman's list correlate highly with this profile  and only  <dig> genes in the set of  <dig> in alpha-full show this level of correlation. interestingly, the most highly correlated profile of the  <dig> genes is mfa <dig>  which has been classified as being associated with g <dig>  the other four classified genes are associated with m/g <dig>  the fact that only  <dig> genes exhibit an expression profile with a correlation of > <dig>  suggests that this profile is rarely observed in its pure form, but is likely to be a component of many genes. the significance of this is discussed in more detail in the context of curve  <dig> below.

the second curve in figure 2a has a much clearer interpretation. comparison with figure 3a readily suggests an association of this profile with g <dig>  this is further supported by the data in table  <dig>  all of the top five correlated genes have been classified by spellman as g <dig>  as well as  <dig> of the top  <dig>  a total of  <dig> of a possible  <dig> genes classified as g <dig> by spellman have a correlation coefficient of > <dig>  with curve  <dig>  while  <dig> were classified as m/g <dig> and  <dig> were classified as s, for a total of  <dig> genes from spellman's list. in order to make this classification more quantitative, each profile was given a score for each of the five cell cycle classes. this score was calculated by:

score=∑i=1ncprip/nctot     
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgtbwucqwgjbwycqwgvbwbcqwgybgccqwglbqzcqggoaakcqwgwbaccqggsaalcqwgjbwycqggpaqkcqgh9aqpdawcgaqaamaaqahabagaemocai3aasbaasqaaiabdmgapjabdchawbqabaaabagaemyaakmaeyypa0jaegymaedabagaemota40aasbaawqaaiabdogajjabdchawbqabaaaniabgghildaakeaacqwgobgtdawgaawcbagaem4yammaemidaqnaem4ba8maemidaqhabeaaaagccawljagaaczcamaabmgabagaegonaydacagloagaayzkaaaaaa@526c@

this equation describes the score for profile p on class c, where c represents g <dig>  s, g <dig>  m or m/g <dig>  the term rip represents the correlation coefficient between profile p and the expression profile of gene i, where the summation is over all ncp genes in class c  that have a correlation coefficient greater than  <dig>  with profile p. the quantity nctot is the total number of genes in that as class classified by spellman . as an example, if all of the  <dig> g <dig> genes in spellman's list had a correlation coefficient of unity with curve  <dig>  the score would be  <dig>  which is the highest value attainable. in table  <dig>  the score for curve  <dig> on g <dig> is  <dig> , while the next highest is  <dig>  for s, supporting the classification of g <dig> 

curve  <dig> in the four-component case also exhibits a cyclical pattern that is shifted later in time from curve  <dig>  this would be consistent with s, g <dig> or m and all of these classes give high scores with curve  <dig>  with 31/ <dig> of the designated s genes, 27/ <dig> of the designated g <dig> genes, and 38/ <dig> of the designated m genes giving correlation coefficients above  <dig> . visually  and by score, the best match appears to be s, but it is likely that these three groups have merged together in this profile since an inadequate number of components were specified to capture all of the elements of the cell cycle. this is not a very specific group, since more than half of the  <dig> genes give a correlation of  <dig>  or better.

the fourth curve in figure 2a gives a poor score with all of the designated classes except for m/g <dig>  of the  <dig> highly correlated genes with designated classes,  <dig> of these are m/g <dig>   <dig> are m, and  <dig> is g <dig>  the score and number of correlated m/g <dig> genes is not especially high and the reason for this becomes clear on visual inspection of figure  <dig>  in addition to the peak around  <dig> minutes, the m/g <dig> designated genes also exhibit a peak just before the first peak of curve  <dig>  which has been designated g <dig>  thus, it would appear that the m/g <dig> phase is a composite of the two underlying functions shown in curves  <dig> and  <dig>  furthermore, close examination of the expression patterns for the designated m/g <dig> genes in figure 3e reveals that some of these gene expression profiles are dominated by the first peak, some by the second peak, and some show a distinctive rapid decay from time zero. this suggests the presence of two or more processes underlying these genes. this does not mean that all of these genes cannot be considered to belong to the m/g <dig> classification, only that there may be more than one driving force behind the expression of these genes.

this initial four-component analysis was promising, but suggested  that there were too few components to adequately model the cell cycle. it was expected that extension to five components would allow better resolution of the s, g <dig> and m phases. while this did happen, other unexpected observations were made. the results of this analysis are shown in figure 2b and table  <dig> . in this case, curves  <dig> and  <dig> exhibit clear and excellent matches to designated s and m genes, respectively, although curve  <dig> also exhibits some strong g <dig> and m character, as might be expected. also, as for the four-component model, the m/g <dig> phase seems to be a combination of the first and last curves and therefore gives only a moderate score in each case. what is particularly interesting is that the strongly correlated g <dig> pattern that was so apparent in the four-component model has disappeared in the five-component case. instead, in this case, curve  <dig> represents the first peak of the g <dig> profile, but because the second cycle is absent, strong correlations with the designated genes are not observed. it is our interpretation that the second cycle of the g <dig> phase is now represented in curve  <dig> and what is seen in curves  <dig> and  <dig> are two separate regulating profiles for a mix of genes designated as g <dig> and m/g <dig>  note that in the five-component case relative to the four-component case, curve  <dig> falls off more sharply, curve  <dig> is shifted to an earlier time, and curve  <dig>  is shifted to a later time, all of which would be consistent with a blending of g <dig> and m/g <dig>  another notable feature of the five-component analysis is that there is no clearly defined curve for g <dig>  however, the profiles for the designated g <dig> genes shown figure 3c do not show distinctive features and could easily be obtained through linear combinations of the five curves presented.

the six-component model, presented in figure 2c shows essentially the same features as the five-component model, with the addition of one new profile characterized by a single spike in expression levels at the second time point at t =  <dig> minutes. because of the transient nature of this peak, it is not clear whether this represents a real profile, or whether it is simply an artifact of outliers in the data. only one of the genes in spellman's classification  shows a strong correlation with this profile  and there are only  <dig> genes with a correlation above  <dig> . this does not, however, exclude it from being a component of other expression profiles. because the remaining profiles were so similar to the five-component model, a full table of correlation data is not included.

the profiles of the seven-component model shown in figure 2d includes many of the same patterns as were seen in the five- and six-component models, but also brings a refinement that validates some of the hypotheses extended for the simpler models. to conserve space, the full table of results for the seven-component model is included as supplementary data  and only summarized here. curves  <dig>   <dig> and  <dig> are essentially unchanged from the six-component model. curve  <dig>  which is associated with the s phase, has a notable change in that the second cycle is considerably reduced in its magnitude. the score on the s phase genes is reduced to  <dig> , compared to  <dig>  and  <dig>  for the five- and six-component models, respectively. more importantly, however, this profile is now much more specific for the s phase genes. in the five- and six-component models, the scores of this curve on g <dig> were  <dig>  and  <dig> , while the scores on g <dig> were both  <dig> . for the corresponding curve in the seven-component model, the g <dig> score is only  <dig>  and the g <dig> score is  <dig>  furthermore, the number of correlated genes has dropped from  <dig> in the five-component model and  <dig> in the six-component model to only  <dig> in the seven-component model. this clearly indicates that the model expansion has permitted this curve to become much more specific in representing the s phase.

curve  <dig> for the seven-component model, which is representative of the m phase, has remained essentially the same as in the five- and six-component models, but curves  <dig> and  <dig> represent a further refinement of the last profile in the previous models. in earlier models, it was postulated that the g <dig> and m/g <dig> phases were driven by two distinct underlying functions, each correlated with one of the two peaks in the cycles. for the five-component model, it appeared that the last profile was a blending of the second cycle of these two phases. now, in the seven-component model, it appears that this mixing has been resolved in curves  <dig> and  <dig>  curve  <dig>  which has been shifted to shorter times, is representative of the second cycle of m/g <dig> and correlates with four designated genes in that group . curve  <dig> is shifted to longer times and correlates well with the second cycle of the g <dig> phase, again matching four genes in that group. as before, neither of these curves by itself gives a strong correlation with a large number of designated genes in the corresponding phases, but this is because they only represent half of the cycle. even so, the genes that are correlated represent a statistically meaningful group of the overall population. when the time profile is divided into two and each half is considered separately, the g <dig> score for curve  <dig> increases from  <dig>  to  <dig>   and the g <dig> score for curve  <dig> increases from  <dig>  to  <dig>  . likewise, the m/g <dig> score for curve  <dig> increases from  <dig>  to  <dig>   and that for curve  <dig> increases from  <dig>  to  <dig>  . this is further evidence of two independent driving functions for g <dig> and m/g <dig>  one which is active on release from α-factor arrest and another which becomes activated in the second cycle.

extensions of the model to  <dig> and  <dig> components, as shown in figures 2e and 2f, retain essentially the same features as the earlier models, but some more subtle changes are evident. in particular, the profile associated with the s phase  seems to follow the same pattern as the g <dig> and m/g <dig> genes, with the two parts of the cycles separating from one another. for the eight-component model, the second half of the s phase is likely modeled by the newly appearing curve  <dig>  which has a high score on the genes classified as s  as well as a high score on the g <dig> genes . for the nine-component model, curve five develops more g <dig> character and for the first time a profile is classified in this group with a score of  <dig> , although it also exhibits similarity to s and m . in this case, some of the second half of the s cycle has likely been blended into the second half of the g <dig> cycle represented as curve  <dig>  the nine-component model is also characterized by a new profile in curve  <dig>  that appears to be a combination of g <dig> and m.

at this point, the capabilities of curve resolution are approaching their limits and become increasingly speculative. as more components are added to the model, the algorithm diverts its efforts to modeling more subtle changes in the expression patterns and eventually artifacts that may be more related to noise than biological change creep into the profiles. this is evidenced by some of the later models which show more sporadic variations than the earlier ones. also, as the changes being modeled in the cell approach finer and finer resolution in the time domain, our confidence in the results becomes eroded. for example, we can question whether curve  <dig> in figures 2c–f is real or is an artifact of that particular time point. the limits of the curve resolution approach can be extended in several ways that include the acquisition of better quality data, more frequent sampling of the system, and the inclusion of reliable uncertainty information in the measurements.

it is important to remember that this modeling was performed with no prior assumptions about the components present, only assumptions of bilinearity and non-negativity were used. to further illustrate the effectiveness of curve resolution for extracting cell cycle related information, figure  <dig> shows the normalized expression profiles of five genes used by lu et al  <cit>  to represent the phases of the cell cycle. these are shown as solid lines. superimposed on these  are selected curves from the eight-component model with close matches. for g <dig>  two curves are shown because it is postulated here that this cycle is driven by two different underlying processes.  no model profile is compared to the selected curve for g <dig>  since there was no definitive match. overall, the synchronicity of the extracted profiles with the independently selected genes is very good and supports this method of analysis.

as further evidence of the legitimacy of the profiles extracted by curve resolution, figure  <dig> shows each of the curves extracted from the eight-component model  plotted with the  <dig> most highly correlated expression profiles  from alpha-full. this plot confirms the presence of the predominantly unimodal profiles , supporting the case for separate underlying regulatory factors for g <dig> and m/g <dig> 

curve resolution for alpha-full data
in the analysis of the subset of genes represented by the alpha- <dig> data set, it could be argued that the original microarray data had already been screened for genes that are known to be associated with cell cycle regulation. in other studies where such a subset selection may not be possible, the utility of the curve resolution method remains to be demonstrated. in other words, can curve resolution be used to extract original information from microarray data sets with no prior knowledge of gene association? to answer this question, the curve resolution algorithm was applied to the entire alpha-full data set  without any prior information other than the proposed number of components and the non-negativity constraints normally applied. the results of this analysis are presented in figure  <dig>  the correlation and classification analysis for the four-component model is given in table  <dig>  and that for the five-component model is included as supplementary data to conserve space .

on initial examination of figure  <dig>  it is immediately clear that the profiles extracted have some association with the cell cycle. furthermore, comparison with figure  <dig> reveals strong similarities in the profiles, although the profiles extracted from the alpha- <dig> data set are generally more cleanly defined. this was anticipated, since the cell cycle genes in the expanded data set are diluted by other genes that may be unrelated or noisy. another difference between the two sets of results is that, while the profiles exhibited are similar, they do not always appear in the same sequence. for example, in the alpha- <dig> set, the two cycles of g <dig> separate into different components by the five-component model, while for the alpha-full set this does not happen until six components are employed. likewise, in the full data set, the sharp transient at  <dig> minutes does not appear until the seven-component model, where it was evident in the six-component model for the reduced data set. this is expected, since the distribution of gene expression profiles will be different in the full data set compared to the reduced set.

a complete analysis of the alpha-full profiles will not be carried out here, since the treatment is similar to the reduced data set. the tables show correlation data with the genes classified by spellman for the four- and five-component models, respectively. for the four-component model , the classifications for g <dig>  s, m, and m/g <dig>  are clear. for the five-component data  the classifications are less definitive, but the profiles still show a strong association with cell cycle regulated genes. in general, the correlation scores become more ambiguous as the number of components increases. this is due to several factors, including the blending of similar profiles, the resolution of profiles into early and late components, and the noise in the profiles resulting from noisy data. nevertheless, the trends are clear and support the contention that this method can be used to extract underlying information in an unbiased way with no prior knowledge about the data.

uniqueness of mcr-wals solutions
an important consideration in the application of mcr is the uniqueness of the solutions it produces. in the work presented here, one set of solutions was presented for each model/data set combination. this is a common practice in the presentation of mcr results, but it is not very realistic. while it is hoped that the reported solution is representative, a range of equivalent or nearly equivalent solutions is usually possible. reasons for this include:  the possible existence of mathematically degenerate solutions to eq.  ,  computational and numerical limitations of the method used, and  noise in the data.

in their original work on self-modeling curve resolution for two-component systems, lawton and sylvestre  <cit>  recognized that a set of solutions was possible, even in the presence of constraints. therefore, the profiles  were presented in the form of allowed boundaries  where the constraints could be satisfied. although a number of attempts have been made to extend the analytical solution provided by lawton and sylvestre to more than two components  <cit> , this has proven to be very difficult, especially in the presence of noisy data. moreover, the notion of profile "boundaries" is not very meaningful in higher dimensions, since all of the profiles in a degenerate set are linked together and this is not reflected in the presentation of profile boundaries; i.e. it is not possible to mix solutions for the components arbitrarily  <cit> . some attempts have been made to attach boundaries to modern mcr methods such as als with mixed success  <cit> . fortunately, many experimental situations lead to solutions that are unique or tightly bounded, so a single solution is often acceptable. this is because the nature of the data may lead to measurement points  that are unique or highly selective for one component. unfortunately, this is difficult to assess a priori.

another source of multiple solutions is computational limitations. it is possible  that different starting points will yield different solutions, not only because of rotational ambiguities, but also because of local minima or premature termination. the als algorithm is quite stable in its convergence properties  and this is one of the reasons for its popularity, but it is not immune from numerical problems. in this work, the use of the simplisma algorithm  <cit>  removed the random element of initialization, although it should be noted that this method does not work well in the presence of large amounts of noise.

finally, measurement noise plays an important role in the solutions obtained. clearly, the data represents a single realization of the experimental results and mcr solutions for replicate experiments are not expected to be identical. without the availability of replicate data, this contribution to the variability is difficult to assess directly, but it can be inferred through re-sampling methods.

to gain insight into the reproducibility of the solutions presented in figures  <dig> and  <dig>  two approaches, "random initialization" and "random sub-sampling" were adopted and new solutions were generated from ten replicate runs of the mcr-wals algorithm in each case. in the random initialization approach, different initial estimates of p were obtained each time the program was run by randomly selecting individual gene profiles that were used as starting values. in the random sub-sampling approach, ten subsets of data, each half the size of the original data set, were obtained by randomly selecting gene expression profiles from the original data. these were then analyzed by mcr-wals with initial estimates obtained via simplisma. figure  <dig> shows some of the results of these studies. although models with fewer components generally produce more reproducible results, the profiles in figure  <dig> are for the more demanding six-component model. for simplicity, only two components were chosen for display and these were picked on the basis of their consistency among different models and between the alpha- <dig> and alpha-full data sets .

the results in figure  <dig> show good reproducibility among the profiles extracted in terms of the major features that they exhibit. as expected, the range of solutions is generally narrower for the alpha- <dig> data, since these genes were preselected on the basis of cell-cycle association, but good results were still obtained for the full set of genes. for the bimodal curves in the right-hand panels, there is some shifting of the relative contributions of the two peaks and some small changes in their positions, but the association of these profiles with the cell cycle is unmistakable and is clearly not a statistical aberration. in the left-hand panels, a feature that was not apparent in either of the original analyses but was evident in the reproducibility studies is the second peak that occurs around  <dig> min. the presence of this peak is consistent with the second cycle of g1-regulated genes that were associated with the unimodal peak in the original analysis, so its appearance is not surprising and supports the original classification.

clearly this type of reproducibility analysis is useful in assessing the reliability of the profiles extracted by mcr-wals. although there might be an inclination to report the average of these solutions as an overall solution, this is not recommended since the average profiles do not generally define an acceptable solution set. it should be noted that some of the profiles in the higher component models showed significant variability, but this was expected and is intimated at by the shape of the profiles themselves. in addition, obtaining consistent matching of the profiles from replicate runs can be a challenge, since the correlations are not always obvious.

CONCLUSIONS
the primary objective of this work has been to demonstrate that the mcr-wals algorithm is an effective tool for extracting useful information from serial microarray experiments. features of the method include  it is relatively simple and efficient,  it makes no assumptions about the underlying model other than linearity and non-negativity in the contribution and profile matrices,  it is applicable to untransformed expression data, and  it can accommodate arbitrary error structures and missing data . through the application of mcr-wals to yeast cell cycle data, we have demonstrated the utility of the profile vectors in the interpretation of gene expression regulation. with no prior information, the algorithm was able to extract profiles that were clearly associated with cell cycle regulated genes, even when the full data set was used. moreover, the results indicated the possibility of more than one underlying regulatory factor in some cases, suggesting that this approach could be a valuable tool in the inferential study of cellular regulation.

more work needs to be done to establish the utility of this approach and expand its capabilities. this includes further validation of the mcr-wals algorithm through its application to other experiments and the development of better methods to interpret the profile and contribution matrices in a biological context. at present, the complexities of biological models for gene regulation make it difficult to establish a direct physical relationship to the linear model used in this work, although this would clearly be useful. the "components" or "factors" used here are assumed to have some association with regulatory factors in the cell, but it is likely that limitations in the experimental measurements restrict the number of regulatory inputs that can be reliably modeled. nevertheless, the profiles extracted and their relationships to the expression of individual genes should serve as a starting point for more extensive investigation. further algorithmic improvements, such as the inclusion of additional biologically relevant constraints on the solutions and the development of methods to better estimate the number of factors, should also improve the utility of the methodology.

