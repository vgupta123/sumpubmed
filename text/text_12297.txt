BACKGROUND
the nature of dna sequencing has taken a dramatic turn in the last few years, most notably improved through the development and broad use of 2nd generation sequencing methods. the first 2nd generation sequencing method was  <dig> sequencing, introduced in  <dig> with the gs <dig> sequencing machine which produced  <dig> million base-pairs  per run  <cit> .  <dig> sequencing has since been improved steadily both regarding quality and throughput, and the gs flx titanium, introduced in  <dig>  produces  <dig> mbp per run, as reads of approximately  <dig> bp  <cit> . although, since  <dig>  other 2nd generation sequencing methods have emerged,  <dig> still produces the longest reads and is one of the most widely used platforms. the long reads produced by  <dig> sequencing makes the method especially attractive for metagenomic sequencing, where the sample is highly complex and overlapping reads are more rare. the enormous technology improvements represented by novel sequencing technologies do not only enable many new studies but also poses great challenges in terms of processing the sequence data. the major underlying technology for data processing is sequence alignment, which plays a key part in all steps from sequence assembly to annotation.

in  <dig>  the global sequence alignment was proposed and a computational method for solving it  <cit> . the algorithm utilised the fact that the problem can be solved through solving a number of sub-problems, dynamic programming, which greatly reduced the number of pathways to explore. a decade later, through a modified dynamic programming algorithm, smith and waterman defined the local alignment and a method for solving it  <cit> . yet another year later gotoh added non-linear gap penalties to the algorithm  <cit> . in terms of accuracy dynamic programming methods are still the preeminent methods for solving the two problems and later methods such as fasta  <cit>  and blast  <cit>  use the same underlying technology to calculate alignments.

the traits of  <dig> data are different from those of other sequencing techniques, which occasionally cause problems for computer analysis software. to minimise the effect of sequencing error and maximise the efficiency of  <dig> sequencing, it is crucial to consider the particular characteristics of  <dig> data while computing alignments.  <dig> sequencing is a pyrosequencing method, where dna fragments are associated with synthetic beads in picolitre sized reactor wells and sequenced in parallel. nucleotide reagents for detection of thymine , adenine , cytosine  and guanine  are repeatedly cycled over the dna template fragments while elongating the complementary strand  <cit> . the intensity of each reaction is recorded, as a so-called flowpeak, by a ccd camera for each well where the intensity is proportional to the length of the homopolymer at that position, see figure  <dig>  a flowed base in which the complementary strand is not elongated is denoted as a negative flow and consequently flows in which it is elongated are denoted as positive flows, i.e. flow peaks <  <dig>  and â‰¥  <dig> , respectively  <cit> . for example, the flows a, c, g and t would be one negative and three positive flows most likely produced by a "ccgt" 4-mer. because the homopolymer length is estimated from the flowpeak value, homopolymer indels  is the most common type of reading error. to produce a substitution reading error, an undercall must be followed by an overcall, or vice versa  <cit> . at the same time, many scattered indels are normally more rare than dispersed substitutions, and therefore, in standard sequence alignments, more heavily punished  <cit> . as a consequence, current alignment search programs are more optimised towards detecting alignments with occasional substitutions rather than many small gaps.

recently, to improve the alignment quality using  <dig> reads, an attempt was made to utilise the flowgram information through probabilistic flowgram matching  <cit> . the downside of using flowgram matching, i.e. direct matching of flowgrams, is that an snp will either shift the flowgram one cycle or be matched as two insertions, resulting in an insignificant hit or a hit of low significance, respectively. as snps, if not already a factor, also occur as pcr artefacts in sequencing, direct flowgram matching can only be used in conjunction with sequence alignment to improve the accuracy in the cases where homopolymer ambiguity affects the results. another tool named pangea  <cit>  employs a dynamic gap penalty for alignments where the gap penalties are decreased with an increasing homopolymer. the downside of pangea is that it does not consider the pyrosequencing flowpeak values and also uses a linear gap-extension penalty for homopolymer correcting gaps.

through combining the ability to correct for homopolymer reading errors with sequence alignments, more accurate alignments of  <dig> data can be achieved. to address these problems, we suggest the use of flow-space assisted smith-waterman-gotoh alignments, i.e. giving the local alignment algorithm the ability to correct for likely sequencing errors while computing the alignment. we implemented the flow-space assisted smith-waterman-gotoh alignment algorithm in a c++ tool named faast  and performed alignments using both regular smith-waterman-gotoh alignments and faast.

RESULTS
evaluation of the effect of flow-space assisted local alignment
by introducing the possibility to perform flow-peak correction, the 'degrees of freedom' for the maximum likelihood estimate increases, potentially producing untrue alignments. for example, if any flow-peak correction was allowed without penalty, any flowgram could match any sequence identically. therefore, an extensive study of the effect of the flow-space assisted local alignment is needed. the model used for the smith-waterman-gotoh alignment is match/mismatch score = 2/- <dig> and gap open/extended penalty 5/ <dig>  and the additional parameter  for the flow-space assisted local alignment is program default .

three targets of  <dig>   <dig> and  <dig> nucleotides were randomly picked from the ethidium bromide resistance determinant of staphylococcus epidermidis , see additional files. for each of these an additional  <dig> decoy sequences were generated, resulting in a database of  <dig> nucleotide sequences. the decoys were generated through introducing random snps corresponding to 92% identity. this small sequence set would represent the homologs found in an everyday database search.

finally, query sequences were generated from the target sequence and the algorithms were assessed on their ability to recover the target sequence as the highest scoring alignment, thus find the 'correct' homology in a set of similar decoys. the query sequences were generated ranging from 100% down to 72% nucleotide identity  using no  <dig> data simulation  as well as using flowsim  <cit>  to simulate  <dig> data.  <dig> data was generated through flowsim with the generation settings  set to 'titanium' and 'gs20', as well as a 'high noise' model. the 'high noise'-model constituted a lognormal distribution for negative flows and a normal distribution for positive flows of length n.

the results were evaluated using faast with the homopolymer penalty regulating parameter at k =  <dig>  and k =  <dig>   and to provide stable means each sub-test ran  <dig>  times, see figure  <dig>  in general, as expected, the accuracy drops as the identity between the generated query sequence and the target sequence decreases. when the decoy sequences are more similar to the target than the generated query sequence it is hard for both algorithms to find the target. also, with an increasing alignment length , the accuracy in terms of per cent 'correct' homologs identified increases as more non-snps positions still match. for alignments of query sequences not passed through flowsim , the smith-waterman-gotoh algorithm slightly outperforms faast. however, for titanium up to 'high noise'  <dig> data the alignment results are generally improved by flow-peak correction.

to further test the effect of the faast algorithm we evaluated the number of correctly aligned nucleotides in reads sampled from salmonella enterica subsp. enterica serovar typhi str. ct <dig>   <dig>  titanium reads averaging  <dig> bp were generated at an identity of 100% down to 95% using flowsim  <cit> . the results were evaluated using faast with at k =  <dig>  and k =  <dig>  , see figure  <dig>  as expected, both algorithms performed very well aligning close to all nucleotides correctly. however, faast were able to utilise the flowspace information to place more gaps correctly and thus gain a significant amount of correctly aligned nucleotides compared to the smith-waterman-gotoh algorithm.

evaluating the performance of faast
as a straightforward performance test, faast was compared to ncbi blast  <dig> and ssaha <dig> in a moderate sized alignment task. the test consisted of the typical task of aligning a set of sequenced reads against a small database. the query set was made up of giardia p <dig> reads  <cit> , produced using the roche  <dig> gs flx sequencing platform  <cit> . the sequencing run produced  <dig>  reads, in total  <dig>  mbp, averaging  <dig> bp in length. the giardia reads were queried against a database of all giardia sequences in genbank , accessed through taxonomy identifier  <dig>  the database was composed of  <dig>  sequences, in total  <dig>  mbp, see additional files for a complete list of files and scripts used in the evaluation.

the results of the alignment test are shown in table  <dig>  faast finished the task in  <dig> minutes and  <dig> seconds, while ssaha <dig> spent  <dig> min  <dig> sec and blast spent  <dig> min and  <dig> sec. ssaha <dig> both spent the least wall time and spent the least cpu time showing outstanding efficiency. faast in comparison with blast was able to more efficiently make use of the multi-core cpu and blast actually exhausted slightly less cpu time. the giardia sequencing run and the database can be downloaded through http://www.ifm.liu.se/bioinfo/.

resources exhausted by faast, ssaha <dig> and blast in alignment of  <dig>   <dig> reads  against a database of  <dig>  sequences . the test was performed on a 64-bit linux machine with an 'intel core i <dig> 920' processor, ht enabled. faast was executed with default parameters, thus indexing 11-mer nucleotides running in  <dig> threads and reporting  <dig> results per query. ssaha <dig> was executed with the parameters '-kmer  <dig> -skip  <dig> -best  <dig> -seeds 2' and blast with '-v <dig> -b <dig> -a8' also indexing 11-mer nucleotides and reporting top  <dig> hits. the ssaha <dig> and blast times do not include times for building the database .

faast - flow-space assisted alignment search tool
in order to implement our algorithm, we have constructed an alignment search tool called faast . faast is implemented as a c++ program and compatibility has been ensured using gnu gcc, intel icc  <dig>  on linux, but faast also compiles with mingw or intel on the windows platform. faast is an open source project and it is available both as pre-compiled linux binaries and as source code at http://www.ifm.liu.se/bioinfo/. to facilitate searching with flow peak information, faast reads the sff format , which is used to pack  <dig> data. furthermore, since the sff format is a binary format that may be difficult to edit manually, a new format named ffasta  is supported. ffasta is a fasta-like format, but it expresses a flowgram for each entry instead of a nucleotide/amino acid sequence. in the ffasta-format the flowgram is represented as an array of float values for each peak separated by white-space, just as the qual format for quality scores. faast is implemented with a wide range of parameters for adjusting indexing heuristics, the local alignment model, output-format etc. more information can be found in the faast documentation at http://www.ifm.liu.se/bioinfo/ .

discussion
due to the specific nature of pyrosequencing, mostly produced by  <dig> sequencing machines, regular smith-waterman-gotoh alignments may be inadequate. a homopolymer reading error will introduce a gap in the alignment, which needs approximately 4- <dig> identities to be outweighed using typical alignment parameters. thus, any homopolymer indel not flanked by a high enough number of identities will cause early termination of the alignment and/or erroneous alignments. by extending the model to allow the introduction of these gaps at a lower cost at points of homopolymer uncertainties, we show that alignment accuracy can be improved, see figure  <dig>  while flow-space assisted local alignment slightly decreases accuracy for non-pyrosequencing data, accuracy is gained for pyrosequencing data. naturally, the improvement in alignment results also depends on the amount and lengths of homopolymer-tracts present in the original data as well as the complexity of the background, see figure  <dig>  we also note that with increasing sequence length the accuracy is higher at the same query identity level as  <dig> decoys sample less of the combinatorial space . however, when then complexity of the background begin the affect the results the performance difference is similar regardless of nucleotide length. this is illustrated in figure  <dig> where faast is able to improve the alignment results of full-length titanium reads. however, since titanium  <dig> data generally is of very high quality and trivially aligned, regular smith-waterman-gotoh aligned over  <dig> % of the nucleotides correctly and in total the gain of using faast could in some cases be considered small.

even though faast was developed to deal with homopolymer reading errors of  <dig> data, the faast algorithm may be applied to other pyrosequencing methods or any sequencing method or data where homopolymer reading errors occur, for example the ion torrent technology. furthermore, many bioinformatic algorithms and software are based upon or use to some extent smith-waterman, for which the faast algorithm could be utilised to better handle homopolymer reading errors.

while blast relies on query indexing, faast uses database indexing, as implemented in the ssaha alignment search tool  <cit> . this provides a speed advantage at the cost of requiring more ram. the heuristics of faast is rudimentary and restricts the number of alignments performed simply through requiring n number of k-mer hits along the same diagonal not spaced more than j nucleotides apart. although ssaha <dig> is much faster that faast in a single cpu context, faast utilizes the multi-core environment well and still completes the alignment task evaluated in reasonable time. faast also compares fairly well to blast and in general it would be possible to use the faast software for producing alignments with  <dig> data.

CONCLUSIONS
faast provides the possibility to both identify potential homopolymer reading errors in pyroseqencing data as well as providing more accurate alignments with pyrosequencing data. faast does not only provide high quality alignments but it does so using reasonable computational resources. therefore, we propose that faast could serve as a useful tool in the analysis of genomic and metagenomic data as well as analysis where correctly aligned bases are vital, such as snp detection.

