BACKGROUND
deciphering the native conformation of a protein from its amino acid sequence, known as, protein folding problem is a challenging task. the recognition of proteins belonging to same fold/structural class is an intermediate step to protein structure prediction. for the past few decades, several methods have been proposed for predicting protein structural classes. these methods include discriminant analysis  <cit> , correlation coefficient  <cit> , hydrophobicity profiles  <cit> , amino acid index  <cit> , bayes decision rule  <cit> , amino acid distributions  <cit> , functional domain occurrences  <cit> , supervised fuzzy clustering approach  <cit>  and amino acid principal component analysis  <cit> . these methods discriminated protein structural classes with the sensitivity of 70–100% and it mainly depends on the data set. wang and yuan  <cit>  developed a data set of  <dig> globular protein domains belonging to four different structural classes and reported that methods claiming 100% sensitivity for structural class prediction could predict only with the sensitivity of 60% with this data set.

on the other hand, alignment profiles have been widely used for recognizing protein folds  <cit> . recently, cheng and baldi  <cit>  proposed a machine learning algorithm for fold recognition using secondary structure, solvent accessibility, contact map and β-strand pairing, which showed a pair wise sensitivity of 27%. on the other hand, amino acid properties have been used for discriminating membrane proteins  <cit> , identification of membrane spanning regions  <cit> , prediction of protein structural classes  <cit> , protein folding rates  <cit> , protein stability  <cit>  etc. towards this direction, ding and dubchak  <cit>  proposed a method based on neural networks and support vector machines for fold recognition using amino acid composition and five other properties, and reported a cross-validated sensitivity of 45%. further, ofran and margalit  <cit>  showed the existence of significant similarity in amino acid composition between proteins of the same fold. in this work, we have used amino acid occurrence  for discriminating  <dig> different folding types of globular proteins. we have developed a method based on linear discriminant analysis , which discriminated a set of  <dig> proteins with an accuracy of 38%, which is comparable to other methods in the literature, in spite of the simplicity of the method and large dataset.

RESULTS
role of re-weighting for fold discrimination
we have computed the occurrence of all the  <dig> amino acid residues in each protein, which represents the elements of  <dig> dimensional vectors in each protein. we have applied lda to these vectors for discrimination. we have employed two kinds of lda, i.e., with and without re-weighting. in lda with re-weighting, i.e. wk =  <dig> in eq. , all folds equally contribute to maximize the performance of discrimination irrespective of the number of proteins in each fold; i.e., if one fold has hundreds of proteins and another has only few proteins, lda is optimized to achieve the highest performance equally in all folds. this re-weighting is important especially when the number of proteins included in each fold has large variations. on the other hand, lda without re-weighting, i.e. wk = nk in eq. , tends to achieve the maximum performance for the whole dataset.

we have used the measures, accuracy, sensitivity, precision and f <dig> for examining the performance of the method. in general, accuracy has the tendency to show high values without re-weighting since it is computed with all data. sensitivity tends to increase by re-weighting, giving equal weight to each fold. in contrast, precision has the tendency to decrease by re-weighting, since re-weighting increase fp for folds with less number of proteins. on the other hand, f <dig> is independent of re-weighting as it is harmonic mean of sensitivity and precision.

in table  <dig>  we presented the discrimination results obtained with different measures and two kinds of lda . as expected, re-weighting significantly changed all the performances other than f <dig>  re-weighting increased the sensitivity whereas an opposite trend was observed for precision and accuracy. this is due to the divergence in the number of proteins in each fold . f <dig> does not change significantly by re-weighting.

remarkably, we achieved the accuracy of 38% , which is the best performance to our knowledge, for large number of folds  and proteins . further, the method is extremely simple, which indicates that the amino acid occurrence of proteins carry sufficient information to discriminate protein folds.

discrimination of proteins belonging to different folding types
we have examined the ability of the present method for predicting proteins belonging to  <dig> major folds. in table  <dig>  we have shown the performances of discriminating  <dig> different folds. we observed that the folds with less number of proteins have the sensitivity of less than 10% without re-weighting. for example, sam domain like fold has the sensitivity of 8%, which has only  <dig> proteins. similar tendency is also observed for the folds b. <dig>  b. <dig>  c. <dig>  c. <dig>  c. <dig>  d. <dig> and d. <dig>  the sensitivity of these folds increased significantly with re-weighting. on the other hand, many folds with less than  <dig> proteins have the sensitivity of more than 20% without re-weighting . as there are  <dig> folds, the expected sensitivity is only  <dig> % if classification is supposed to be random. in table  <dig>  we have also shown the ratio between the number of proteins in each fold and the total number of proteins, which ranges from  <dig> to 11%. hence the sensitivity of 20% obtained for several folds is significantly higher than that of random for fold discrimination. interestingly, most of the folds that were discriminated with more than 20% sensitivity belong to either all-α or all-β class. this might be due to the fact that these proteins have different secondary structural patterns and hence they are easy to discriminate them. in addition, folds in each of these classes are near-by each other in amino acid occurrence vector space, which caused high sensitivity. on the other hand, an opposite tendency was observed for precision. re-weighting decreased the precision for several folds including a. <dig>  a. <dig>  a. <dig>  a. <dig>  b. <dig>  b. <dig>  b. <dig>  c. <dig>  c. <dig>  d. <dig>  and g. <dig>  most of these folds have less number of proteins.

the re-weighting procedure causes two opposite effects: increased the sensitivity and decreased the precision. hence, f <dig> may be used to balance these effects. only two folds, c. <dig> and d. <dig> decreased the f <dig> with re-weighting and several folds significantly increased the f <dig> by re-weighting .

the comparison between experimental versus predicted folds is shown in fig.  <dig>  in this figure, dark block indicates the presence of many proteins. the data are normalized in such a way that the total percentage of true fold is 100%. fig. 1a showed that mainly the folds with more number of proteins are misclassified without re-weighting . the trend has been changed after re-weighting: the misclassified proteins are observed to be within the same structural class. especially, in α + β class, the block diagonal region is distributed almost uniformly, which is partially caused by re-weighting. since each fold is equally weighted, α + β class is less weighted than other classes. this causes inter-class misclassification between α + β and other classes, because α + β class has only three folds. however, two folds in small structural class can be discriminated with high accuracy/sensitivity/precision/f <dig> and α + β folds are difficult to discriminate using our method.

comparison among different re-weighting procedures
the results presented in tables  <dig> and  <dig> showed that the sensitivity of discriminating protein folds differs significantly between different methods . hence, it would be difficult to choose the best method for fold recognition. however, it may be selected based on the interest of the users, whether the prediction is optimized for each fold or over all dataset.

usually, training and test sets of data are obtained from sequence and structure databases and are culled with sequence identity. however, these data sets do not always reflect proper representatives of all proteins in different folds, e.g., protein population in each fold. further, the proteins available in databases such as, pdb are biased with the proteins that can be solved experimentally, which may be different from the proportion of real proteins. hence, considering these aspects would help to develop "good" methods for protein fold recognition in future.

in essence, based on the methods and data sets used in the present work, we suggest that the performance with re-weighting is better than that without re-weighting.

influence of amino acid occurrence in recognizing protein folds
the importance of amino acid occurrence is illustrated with figure  <dig>  in this figure we show the occurrence of the  <dig> types of amino acid residues in dna/rna binding 3-helical bundle  and immunoglobulin-like β-sandwich . the average number of amino acid residues in these folds are  <dig> and  <dig>  respectively. we observed that the residues gly, pro, ser, thr and val are dominant in the fold b. <dig> whereas an opposite trend was observed for leu and arg. in figure  <dig>  we have shown the distribution of residues in "amino acid occurrence" space. it is clearly seen that the two folds are more or less separated in this space. we observed similar results about the variation of amino acid occurrences among different folds in our data set.

in addition, we have tested the performance of the method using amino acid composition  in each protein. we noticed that the accuracy without re-weighting decreased to 33% indicating the importance of amino acid occurrence  in each fold . similar tendency is also observed for discriminating β-barrel membrane proteins  <cit> . hence, we suggest that the amino acid occurrence is better than composition for discriminating protein folds. in fact, the normalization of amino acid composition produced the problem of co-linearity, i.e., diversity of vectors is not sufficient compared with the number of proteins. the reason for the dependency of f <dig> upon different types of lda  is that four folds have no positive proteins without re-weighting. on the other hand, amino acid occurrence has only two folds without any positive proteins  as seen in table  <dig> 

probability measure of discrimination
in order to have the feasibility of combining the results of our method with other methods we provided the probability of being a protein in a specific fold along with the predicted folding type. in figure  <dig>  we have shown the probability for fold a. <dig> . clearly, the fold a. <dig> has the highest average probability. however, some other folds,  have relatively higher probabilities. this may result in wrong discrimination, which may be fixed by combining the results with other methods.

comparison with other methods
we have compared the performance of our method with other related works in the literature. ding and dubchak  <cit>  introduced a combined method for predicting the folding type of a protein. they have used six parameters, amino acid composition, secondary structure, hydrophobicity, van der waals volume, polarity and polarizability as attributes, and neural networks and support vector machines for recognition. these features have been combined with the number of votes in each method. they reported the sensitivity of 56% in a test set of  <dig> proteins and 10-fold cross validation sensitivity of 45% in a training set of  <dig> proteins from  <dig> folding types. we have used the same dataset of  <dig> proteins and assessed the performance of our method. we observed that our method could predict with the leave-one-out cross validation accuracy of 42% , which is close to that  reported in ding and dubchak  <cit> .

in addition, we have selected the proteins from the folds that are common in both the studies and tested the performance of our method  in predicting the folding types of the proteins used in ding and dubchak  <cit> . the results are presented in table  <dig>  interestingly, our method with re-weighting could correctly identify the folding types with f <dig> value of more than 30% in  <dig> among the  <dig> considered folds. the performances are similar to or better than that reported with the dataset of  <dig> proteins. although our method is optimized with different datasets it has the power to predict the folding type of independent dataset of proteins with similar sensitivity.

further, there are several advantages in our method:  only one feature, amino acid occurrence is sufficient for prediction rather than six features. the comparison of results obtained with only one feature showed that the performance of our method  is significantly better than that of ding and dubchak  <cit>  reported with amino acid composition ,  voting procedure is not necessary; our method can be directly used for multi-fold classifications,  our method uses lda, which requires significantly less computational power compared with svm. in svm one has to diagonalize the matrix with the size of  × ; on the other hand, lda requires only diagonalization of  <dig>  ×  <dig> matrix independent of number of proteins and  although they have reported the dependency of fold specific sensitivities upon number of proteins in each fold, it is difficult to compensate this effect without modifying the complicated voting systems; our method has freedom to compensate it as discussed in the previous sections.

recently, shen and chou  <cit>  reported better sensitivity for the same data set of ding and dubchak  <cit> . however, the results are biased with training set of data. we have evaluated the sensitivity of identifying proteins belonging to the folds, four helical up and down bundle  and ef hand-like  and we observed that the sensitivity is  <dig> % and 24%, respectively. our predicted sensitivities  are better than that of shen and chou  <cit> .

possible reasons for obtaining good performance with amino acid occurrence
we have analyzed the possible reasons for obtaining good performance with amino acid occurrence. in table  <dig>  we have summarized the performance as a function of different features. when we use more than two features to discriminate folds, we simply apply lda to merge feature vectors. this means, if there are two features vectors f→n with n components and f→m with m features,  

 f→m=, 

then we merge and apply lda to

 f→m+n=. 

the usage of five features, i.e., predicted secondary structure, hydrophobicity, normalized van der waals volume, polarity, polarizability  <cit>  along with amino acid composition yielded the accuracy of 45% using sophisticated and time consuming methods. on the other hand, our simple method employing amino acid occurrence and five features has also showed almost the same value .

the in-depth analysis of the results presented in table  <dig> revealed many interesting features. for example, amino acid composition alone showed the accuracy of 35%, which is 7% less than that obtained with occurrence . on the other hand, composition and length  increased the accuracy from 35% to 38%. the composition and five features showed the accuracy of 39%, which is similar  to that obtained with composition and length. hence, length of the protein has an important role as that of five features for discriminating protein folds. this analysis demonstrates the importance of amino acid length and obtaining good performance with amino acid occurrence.

as an individual feature amino acid occurrence showed the best performance among all features, including secondary structure. the combination of amino acid occurrence with other features did not increase the sensitivity and the increase of other parameters is only marginal. this result reveals that the amino acid occurrence contains most of the information that are reflected in other physical features.

generally, any physical feature can be expressed by amino acid occurrence. hence, linear combination of amino acid occurrence may express many of physical properties of proteins. in order to verify this concept, we have computed the correlation coefficients between  <dig> amino acid properties  <cit>  and the first discriminate function. each property consists of  <dig> dimensional vector, like

 p˜k=, 

where pik is the kth physical property of ith amino acid. since discriminant function is also  <dig> dimensional vector and each component of which describes contribution from each amino acid, one can compute correlation coefficient between them.

as can be seen in table  <dig>   <dig> out of  <dig> properties have high correlation coefficients and less than 5% q-values . this analysis shows that linear discriminant function can express many of physical properties, at least, partly. hence, even if we do not consider physical properties directly, the consideration of amino acid occurrence could discriminate folds well.

fold recognition on the web
we have developed a web server for discriminating protein folds from amino acid sequence  <cit> . it takes the amino acid sequence as input and displays the folding type in the output along with probability. further, the server has the feasibility of selecting the method, with and without re-weighting, and the display options to show the probability details for each fold.

advantages and limitations of the method
the main advantage of the present method is the discrimination of  <dig> different folding types of globular proteins with high accuracy/sensitivity/precision/f <dig>  further it will provide the probability of being a protein in a specific fold. the discrimination results along with probability may be helpful to select templates to build models to new protein. further, it can be combined with other methods for better performance. the limitation of the method is the usage of only  <dig> specific folds for discrimination.

CONCLUSIONS
in this paper, we have proposed a simple method for discriminating  <dig> folding types of globular proteins. interestingly, the simplest method is the best method for the truly complicated problems. although complicated methods have several possibilities for tuning they generate over fitting to the data set. further, the method proposed in this work is better than or comparable to other complicated methods, such as, neural networks and support vector machines proposed in the literature for discriminating folding types. in addition, our method has several advantages including the less computational time and classifying the folds at a single run rather than pair-wise comparisons. we have developed a web server  <cit> , which takes the amino acid sequence as the input and displays the folding type in the output. the main limitation of the method is that its application is restricted to  <dig> folds considered in this work. however, the approach can be extended to other folds when significant representatives are available.

