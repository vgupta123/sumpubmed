BACKGROUND
in computational structural biology, a well-established probabilistic methodology towards single sequence rna secondary structure prediction is based on modeling secondary structures by stochastic context-free grammars . in a sense, scfgs can be seen as a generalization of hidden markov models , which are widely and successfully used in the large field of bioinformatics. briefly, scfgs extend on traditional context-free grammars  by additionally defining a  probability distribution on the generated structure class which is induced by the grammar parameters that can easily be derived from a given database of sample structures via maximum likelihood techniques. notably, different scfg designs can be used to model the same class of structures, where flexibility in model design comes from the fact that basically all distinct substructures can be distinguished and with increasing number of distinguished features, the resulting scfg gains in both explicitness and complexity, which may result in a more realistic distribution on the modeled structure class.

traditionally, scfg based prediction approaches are realized by dynamic programming algorithms  that require o time and o storage for identifying the most probable folding for an input sequence of length n. examples for successful applications of several lightweight  scfgs for rna secondary structure prediction can be found in  <cit>  and a popular scfg based prediction tool is for instance given by the pfold software  <cit> .

however, for a very long time, the free energy minimization  paradigm has been the most common technique for predicting the secondary structure of a given rna sequence. the respective methods are traditionally realized by dpas that employ a particular thermodynamic model for the derivation of the corresponding recursions. they basically require o time and o storage for identifying a set of candidate structures for an input sequence of length n. in fact, while early methods, like  <cit> , computed only one structure , several more elaborate mfe based dpas have been developed over the years for generating a set of suboptimal foldings . some implementations are considered state-of-the-art tools for computational structure prediction from a single sequence, for instance the mfold software  <cit>  or the vienna package  <cit> .

in the traceback steps of the corresponding dpas, base pairs are successively generated according to the energy minimization principle, such that the predicted set of suboptimal foldings often contains many structures that are not significantly different . to overcome these problems, several statistical sampling methods and clustering techniques have been invented over the last years that are based on the partition function  approach for computing base pair probabilities as introduced in  <cit> . briefly, these methods produce a statistical sample of the thermodynamic ensemble of suboptimal foldings and rely on a statistical representation of the boltzmann-weighted ensemble of structures for a given sequence  <cit> . they are implemented in the widely used sfold package  <cit> .

in fact, over the past years, statistical approaches to rna secondary structure prediction have become an attractive alternative to the standard energy-based approach . in principle, many of these approaches – in contrast to sfold – rely on  parameters estimated from growing databases of structural rnas. for instance, the contrafold tool  <cit>  is based on a discriminative statistical method and uses a simplified nearest neighbor model for the underlying conditional log-linear model . briefly, cllms are flexible discriminative probabilistic models that generalize upon more intuitive generative probabilistic models , where any scfg has an equivalent representation as an appropriately parameterized cllm. the prime advantage of using discriminate instead of generative training is that more complex scoring schemes can be considered, whereas generative models are generally easier to train and use. actually, contrafold in several cases manages to provide the highest single sequence prediction accuracy to date and eventually closes the performance gap between the best thermodynamic methods and the best  scfgs. however, there are some benchmarks that show better performance by other methods, suggesting in the least that the performance of structure prediction can vary considerably depending on rna family  <cit> .

notably, following contrafold, several other statistical methods have been subsequently developed, such as for instance constraint generation  <cit> , or contextfold  <cit> . these are all classified as discriminative statistical methods which implement different variants of standard thermodynamic models. in fact, they condition on a set of rna sequences being given , whereas a generative scfg approach models the probabilities of the input rna sequences .

anyway, statistical methods for rna folding have previously been chosen to be either purely physics-based  or discriminative and implementing a thermodynamic model , not generative. this might have been due to the misconception that scfgs could not easily be constructed to mirror energy-based models , although it has been demonstrated lately that this is actually possible .

however, a generative statistical method for predicting rna secondary structure has recently been proposed  <cit> . this method builds on a novel probabilistic sampling approach for generating random candidate structures for a given input sequence that is based on a sophisticated scfg design. basically, it generates a statistical sample of possible foldings for the given sequence that is guaranteed to be representative with respect to the corresponding ensemble distribution implied by the parameters of the underlying scfg. particularly, conditional sampling probabilities for randomly creating unpaired bases and base pairs on actual sequence fragments are considered that are calculated by using only the grammar parameters and the corresponding inside and outside probabilities for the sequence. as the underlying elaborate scfg mirrors the thermodynamic model employed in the sfold software, this sampling algorithm represents a probabilistic counterpart to the sampling extension of the pf approach . in fact, the sole difference is that it incorporates only comprehensive structural features and additional information obtained from trusted databases of real-world rna structures instead of the recent thermodynamic parameters.

lately, in an attempt to improve the quality of generated sample sets, this probabilistic sampling approach has been extended to being capable of additionally incorporating length-dependencies <cit> . in particular, the employed  scfg has been transformed into a corresponding length-dependent stochastic context-free grammar  and parts of the respective procedures have been modified accordingly . lscfgs have been formally introduced in  <cit> , where the main difference to conventional scfgs is that the lengths of generated substructures are taken into account when learning the grammar parameters, yielding a more explicit structure model induced by the resulting length-dependent probabilistic parameters. note that in connection with problems related to rna structure, the idea of considering computational methods that actually depend on the lengths of particular substructures is not only motivated by biological aspects but has also been discussed or applied by other authors .

it remains to mention that although all three sampling approaches  need o time and o storage for the generation of a statistically representative sample for an input sequence of length n, they obviously use different ways to define a distribution on the ensemble of all feasible secondary structures for the sequence. applications to structure prediction  showed that none of these sampling variants generally yields the most realistic results. actually, which one of them should be preferred seems to strongly depend on the rna type of the input sequence, but most importantly on the quality of a corresponding training set and on the performance of the thermodynamic model on such rnas. however, if the worst-case complexity of one of these variants could be improved without significant losses in sampling quality , then the corresponding method would be undoubtably the number one choice for rna structure prediction, outperforming most if not all computational tools for predicting the secondary structure of a single sequence.

for these reasons, the main objective of this paper is given as follows: we will consider the scfg based statistical sampling approach from  <cit>  in order to perform a comprehensive experimental analysis on the influence of disturbances  on the quality of generated sample sets. particularly, we want to explore to what extend the quality of produced secondary structure samples for a given input sequence and the corresponding predictive accuracy decreases when different degrees of disturbances are incorporated into the needed sampling probabilities. note that some exemplary intuitive first results and corresponding observations have already been presented and discussed in  <cit> , where it is strongly suggested that a much more meaningful evaluation based on more substantial results  is needed to be able to draw reliable conclusions.

the prime motivation for such a disturbance analysis lies in the following facts: suppose both the samples and predictive results are observed to behave rather resistant even with respect to large errors in the distinct sampling probabilities . then it seems adequate to believe that the sampling procedure does not have to calculate these probabilities in the exact way, but it may efficiently suffice if they are only  approximated. thus, in this case it might obviously be possible to employ an approximation algorithm  for sampling probability calculations in order to decrease the worst-case time  requirements for statistical sampling and hence finally for structure prediction. furthermore, to ensure that the quality of the generated sample sets and the predictive accuracy remains sufficiently high, analysis results on the effects of different disturbance levels and types should be taken into account for the development of an appropriate approximation scheme . from the other perspective, suppose the quality of sampled structures seems to strongly react on rather slight disturbances already. in that case, there is obviously little hope that the worst-case complexities of the sampling method can be improved by finding a suitable heuristic procedure for the computation of the needed sampling probabilities.

the aim of our study might hence be declared as to prove or disprove the hypothesis that a heuristic method could be implemented to improve the worst-case complexity of single sequence rna structure prediction, and to discuss some potential ideas and inherent drawbacks that seem relevant in connection with still guaranteeing highly accurate results. although existing algorithms are in practice quite fast on any sequence for which reasonable structure prediction accuracy is expected , sacrificing little accuracy might still be assumed worthwhile, given the practical speedup of efficient heuristic methods compared the corresponding exact  algorithms .

note that since for any input sequence, the time  complexities are dominated by those of the inside-outside computations  in time and needs o storage), the most straightforward way for reducing the time complexity of the overall sampling algorithm might be based on an efficient approximation algorithm or heuristic method for deriving the inside and outside values of the input sequence. therefore, we will incorporate disturbances into these values  rather than into the underlying grammar parameters . this means that in this work, the source of an error will not come from a flawed learning set, although the study of random errors in the applied grammar parameters would actually be analogous to tests performed in connection with the thermodynamic pf  <cit> . the justification for a disturbance study as aspired in this article is that the parameters of the scfg underlying the statistical sampling algorithm from  <cit>  might be assumed to be available . for this reason, applying random errors on the inside and outside values seems to be a much better test in the context of investigations on the impact of a performance improving heuristic.

as we will see subsequently, the scfg based statistical sampling algorithm strongly reacts to any kind of rather small absolute errors already, whereas its reaction even to rather large relative disturbances is in most cases indeed fair enough to still obtain samples of acceptable quality and corresponding meaningful structure predictions. hence, it seems possible that a reduction of the worst-case time requirements of the evaluated probabilistic sampling approach might be reached – without sacrificing too much predictive accuracy – by approximating the needed sampling probabilities in an appropriate way. throughout this article, we will actually present some useful considerations on how a corresponding approximation scheme  should be constructed in order to ensure that the sampling quality remains sufficiently high.

the rest of this paper is organized as follows: section methods introduces the formal framework, including the scfg model, definitions of various types and levels of disturbances and a corresponding recursive sampling strategy that will be considered within this article. a comprehensive disturbance analysis based on exemplary rna data and the corresponding results will follow in section results and discussion, where both the quality of generated sample sets and their applicability to the problem of rna structure prediction are investigated. notably, we not only compare different ways for extracting predictions from generated samples in order to assess the predictive accuracy, but also present results on the abstraction level of shapes that is of great interest and relevance for biologists. section results and discussion also includes considerations on how to develop a corresponding time-reduced sampling strategy without significant losses in sampling quality. notably, some of the key results are discussed in section errors only on particular values. finally, section conclusions concludes the paper.

methods
in this section, we provide all needed information and introduce the formal framework that will be used subsequently. we start by a recap of the relevant details of the probabilistic sampling method from  <cit>  and proceed with formally defining how a number of different types and levels of disturbances can be incorporated into the corresponding scfg based statistical sampling variants. last but not least, we present a modified version of the employed sampling strategy that  manages to deal with disturbed ensemble distributions.

note that we assume the reader to be familiar with the notions and basic concepts regarding scfgs. a fundamental introduction on stochastic context-free languages can be found in  <cit> . moreover, since for the understanding of this paper, no additional information on length-dependent stochastic models is needed, we refer to  <cit>  for details.

sampling based on scfg model
in general, probabilistic sampling based on a suitable scfg has two basic steps: the first step  computes the inside and outside probabilities for all substrings of a given input sequence based on the considered scfg model. the second step  takes the form of a recursive sampling algorithm to randomly draw a complete secondary structure by consecutively sampling substructures  according to conditional sampling probabilities for particular sequence fragments that strongly depend on the inside and outside values derived in step one.

step one – preprocessing
according to the traditional dpa approach for predicting rna structure via scfgs, a particular underlying grammar, say gr, must be constructed to generate all possible rna sequences of any length , where any derivation tree for a particular sequence r∈lr corresponds to one of the feasible secondary structures  for r. this means any such  grammar gr basically relies on an appropriately designed  grammar gs modeling the corresponding secondary structures ,∘}, where () and ∘ represents any of the possible base pairs and unpaired bases, respectively, see  <cit> ). for our investigations, we decided to rely on a rather elaborate scfg design, namely the exact formal language counterpart to the thermodynamic model applied in the sfold program, which is given as follows:


definition  <dig>  . the  scfg gs generating exactly all secondary structures is given by gs=, where igs={s,t,c,a,p,l,f,h,g,b,m,o,n,u,z}, Σgs={,∘} and for mh:= minhl ≥  <dig> and ms:= minhel ≥  <dig>  rgs contains exactly the following rules: 

 p1:s→t,⇝initiate exterior loopp2:t→c,p3:t→a,p4:t→ca,p5:t→at,p6:t→cat,⇝shape of exterior loopp7:c→zc,p8:c→z,⇝strands in exterior loopp9:a→mslms,⇝initiate helixp10:p→l,⇝extend helixp11:l→f,p12:l→p,p13:l→g,p14:l→m,⇝initiate any loopp15:f→zmh-1h,⇝start hairpin loopp16:h→zh,p17:h→z,⇝extend hairpin loopp18:g→ba,p19:g→ab,p20:g→bab,⇝shape of bulge/interior loopp21:b→zb,p22:b→z,⇝strands in bulge/interiorloopp23:m→uao,⇝fist substructure of multiple loopp24:o→uan,⇝second substructure of multipleloopp25:n→uan,p26:n→u,⇝kth substructure ofmultiple loop,k≥3p27:u→zu,p28:u→ε,⇝strands in multiple loopp29:z→∘.⇝unpaired base 

note that gs has been parameterized to impose two relevant restrictions on the class of all feasible structures: first, a minimum length of minhl for hairpin loops and second, a minimum number of minhel consecutive base pairs for helices, where common choices are minhl ∈ { <dig>  3} and minhel ∈ { <dig>  2}. however, within this work we will only consider minhl= minhel =  <dig>  which corresponds to the least restrictive  choice and usually yields the worst sampling results .

moreover, the needed grammar parameters  are splitted into a set of transition probabilities prtr for rule∈rgs and two sets of emission probabilities prem for rx∈Σgr and prem for rx1rx2∈Σgr <dig>  i.e. for the  <dig> unpaired bases and the  <dig> possible base pairings, respectively. it should be mentioned that in the length-dependent case, these probabilities depend on the length of the subwords generated, meaning we then have to use prtr), where len denotes the length of a specific application of rule in a parse tree, which is defined as the length of the  subword eventually generated from rule. accordingly, we need to consider prem and prem, respectively. note that for the sake of simplicity, we will omit the length  in the sequel, hence using the same notations in either case .

however, according to  <cit> , the computation of all inside probabilities 

  αx:=pr 

and all outside probabilities 

  βx:=pr 

for a sequence r of size n, x∈igs and 1 ≤ i, j ≤ n, can be done with a special variant of an earley-style parser ). notably, both sampling variants  can be implemented to require o time and o memory for this preprocessing step.

step two – random structure generation
once the preprocessing is finished, different strategies may be employed for realizing the recursive sampling step. in general, for any sampling decision , a particular strategy relies on the respective set of all possible choices that might actually be formed on the currently considered fragment of the input sequence. any of these sets contains exactly the mutually exclusive and exhaustive cases as defined by the alternative productions  of the underlying grammar. the corresponding random choice is then drawn according to the resulting conditional sampling distribution . this means the respective sampling distributions are defined by the inside and outside values derived in step one  and the grammar parameters .

in this work, we will only consider the well-established strategy from  <cit> , which is also implemented in the corresponding second step of the physics-based sampling algorithm underlying the popular sfold tool. basically, a secondary structure is sampled recursively by starting with the entire rna sequence and consecutively computing the adjacent substructures  of the exterior loop , where any paired substructure is completed by successively folding other loops. in fact, the base pairs and unpaired base are successively sampled according to conditional probability distributions for the considered fragment, given a partially formed structure.

for example, suppose fragment ri, j:= ri … rj of input sequence r, 1 ≤ i, j ≤ n = |r|, is to be folded, where it is known that the resulting substructure on ri,j must correspond to a  derivation of a particular intermediate symbol x∈igs . then, the strategy considers the corresponding set acx of all choices for  derivations of x on ri,j, which actually correspond to all possible substructures on ri,j . under the assumption that the alternatives for intermediate symbol x are equal to x → y and x → vw, this set is defined as follows: 

  acx:=acxy∪acxvw, 

where 

 acxy:={prob∣prob=βx·αy×prtr≠0}={βx·prob∣βx≠0andprob=αy·prtr≠0} 

and 

 acxvw:={{k,prob}∣i≤k≤jandprob=βx×αv·αw·prtr≠0}={{k,βx·prob}∣i≤k≤jandβx≠0andprob=αv·αw×prtr≠0}. 

consequently, we have to sample from the corresponding conditional probability distribution induced by acx, that is the random choice is drawn according to the following set of sampling probabilities: 

  probnorm∣prob∈acxyor{k,prob}∈acxvw, 

where obviously, 

  ∑prob∈acxyprobnorm+∑{k,prob}∈acxvwprobnorm= <dig> 

must hold, which can in general easily be guaranteed by using norm = βx · αx. however, if there may occur inconstancies in the distribution induced by the underlying grammar model , we should instead use 

 norm=∑prob∈acxyprob+∑{k,prob}∈acxvwprob=βx∑βx·prob∈acxyprob+∑{k,βx·prob}∈acxvwprob=βx·αy·prtr+∑i≤k≤jαvαw·prtr=βx·normα, 

which then ensures that the corresponding sampling probabilities still sum up to unity, such that they indeed define a conditional probability distribution).

note that the sampling strategy effectively works conform with the scfg model, which means that it actually samples one of the possible parse trees of the given input sequence by randomly drawing one of the respective mutually exclusive and exhaustive cases  at any point in the already partially constructed parse tree in order to generate one of the possible subtrees for the given input sequence .

hence, according to the sampling process, we could have never gotten to a point where we have to consider all mutually exclusive and exhaustive cases for a particular premise x∈igs on an actual sequence fragment ri,j, 1 ≤ i, j ≤ n, if the grammar could not derive the sentential form r1 … ri-1xrj+1 … rn from the start symbol  s∈igs, that is if the outside value βx would be equal to  <dig>  this in fact means that the respective probability distribution  from which the strategy randomly samples one of the possible substructures  is not influenced by the corresponding outside probability, due to the fact that βx >  <dig> indeed only represents a scaling factor common to all sampling probabilities for the relevant mutually exclusive and exhaustive cases. for this reason, we can obviously without loss of information remove the outside values from the definitions of the needed sampling probabilities. the correctness of this simplification can easily be formally proven by considering the above defined set acx of all choices for possible derivations of intermediate symbol x on sequence fragment ri,j. in fact, the sampling strategy randomly draws one of the elements from acx according to the corresponding distribution induced by normalizing the probabilities of the elements in acx such that they sum up to unity. particularly, we have 

 1=∑βx·prob∈acxyβx·probβx·normα+∑{k,βx·prob}∈acxvwβx·probβx·normα=1normα·∑βx·prob∈acxyprob+∑{k,βx·prob}∈acxvwprob=1normα·∑prob∈acxyprobβx+∑{k,prob}∈acxvwprobβx, 

since βx ≠  <dig> holds  and acxvw).

formal definitions of all corresponding sets acx, x∈igs and 1 ≤ i, j ≤ n, that are considered by the recursive sampling strategy for any input sequence of length n, including formulae for deriving the respective conditional sampling probabilities, can be found in section sm-ia . notably, all those formulae only depend on some of the parameters of the underlying scfg model and the corresponding inside values, such that after a preprocessing of the given sequence  time in the worst-case), a random candidate structure can be generated in o time.

considered disturbance types and levels
obviously, under the assumption of a particular scfg model , the most straightforward way for improving the performance of the corresponding overall sampling algorithm seems to be by reducing the worst-case complexity of the inside calculations. therefore, we decided to quantify to which extend the algorithm reacts to different types and degrees of disturbances incorporated into the considered inside probabilities in order the get evidence if it could actually be possible to find a corresponding approximation algorithm  that eventually requires less time but causes only acceptable losses in accuracy. in fact, with respect to developing a suitable heuristic method to be applied in practice, it is necessary to know about the effects of different disturbance levels and types to get an idea on how precisely the respective values need to be approximated in order to guarantee sufficiently good results and to find out which types of errors pose fundamental problems and which ones are negligible.

for these reasons, given an arbitrary input sequence r of length n, we decided to consider  skewed inside probabilitiesb

  α^x:=max+αxerr,1),0), 

for x∈igs and 1 ≤ i, j ≤ n, rather than the corresponding correct values αx  for defining the needed sampling probabilities. more precisely, we want to incorporate different stages of  randomly chosen errors into particular inside values for the given sequence, that is into preliminary chosen subsets of the set of all precomputed inside probabilities αx, x∈igs and 1 ≤ i, j ≤ n. note that is actually suffices to consider x∈igsα:={t,c,a,p,f,g,b,m,o,n,u}⊂igs, since only those intermediate symbols are needed for defining the diverse sampling probabilities that are used by the employed sampling strategy for obtaining the distinct conditional distributions for drawing particular random choices.

however, in order to reach our previously declared goal, for any fixed value prob ∈   at random from either of the following sets: 

  funciwin,op:=interval,ifx∈i⊆igsαand,{0},else, 

such that only inside values of particularly chosen intermediate symbols that lie outside  or within  a considered window of preliminary fixed size are actually disturbed, that is only for those values α^x≠αx might result. notably, interval is not centered on αx, as it actually describes the set of error values αxerr that might be drawn  at random – which are then added to αx. anyway, in the sequel, we will basically consider either 

  funcwin,op:=funcigsαwin,op 

, 

  funci:=funcin,+=funci- <dig> - 

, or simply 

  func:=funcigsαn,+=funcigsα- <dig> - 

.

moreover, func ∈ {mep, fep, mev, fev} denotes the actual disturbance type. principally, we distinguish between two degrees of errors: relative and absolute ones. to generate relative errors, we might either use func = mep  or func = fep . formally, this means that either 

  interval:= 

or 

  interval:={-prob·αx,+prob·αx} 

might be employed for randomly drawing a relative error αxerr, where prob ∈ ) is of interest as it models the case that all errors αxerr are bounded but do not need to admit the maximum value possible . when studying relative errors in connection with this variant, this basically corresponds to assuming a particular approximation ratio of the underlying algorithm. the consideration of discrete sets ) corresponds to the case that any error takes on the maximum value possible . this variant hence explicitly describes the worst-case  of the symmetric interval variant and is actually of interest as it enables a more reliable study of the influence of disturbances, particularly in cases where the extenuated symmetric interval variant defined by mep seems to have no effect on the resulting accuracy.

for similar reasons, in order to randomly choose an absolute error αxerr for obtaining a  disturbed probability α^x, we might equivalently consider either 

  interval:= 

or 

  interval:={-prob,+prob}, 

with prob ∈  and func = fev  for causing absolute disturbances.

note that random errors on all outside probabilities βx, x∈igs and 1 ≤ i, j ≤ n, could be generated in basically the same way, but since those values can be deliberately excluded from the definition of sampling probabilities , this is obviously not necessary for the subsequent investigations.

finally, it should be clear that for func ∈ {mep, fep} , only the magnitudes of the corresponding sampling probabilities  change, such that the exact same structures are possible as in the undisturbed case. hence, we might expect that only the consideration of sufficiently large percentages prob ∈  can cause an actual shifting in the ensemble distribution, resulting in significant quality losses. the contrary holds for absolute errors created according to funciwin,op with func ∈ {mev, fev}. in fact, since the  respective sets of relevant sampling choices implied by the skewed ensemble distribution generally differ  from the corresponding exact ones, it must be expected that only rather small fixed error values of prob ∈  for any x∈igsα usually imply different orders of magnitudesd, it seems practically impossible to tell how to find an appropriate fixed error value for creating absolute disturbances.

resulting modified sampling strategy
it should be clear that after the desired errors  have been incorporated into the precomputed exact inside  values for a given sequence, the needed conditional sampling distributions  are induced by the exact grammar parameters and the disturbed inside  probabilities for that sequence. this, however, might create the need to  modify the respective particularly employed sampling strategy such that it finally gets capable to deal with these skewed distributions.

as for this work, consider the previously sketched recursive sampling strategy from  <cit> . without any errors in the conditional probability distributions , it always successfully generates the sampled loop type for a considered sequence fragment. for example, suppose the sampling procedure decides that base pair ri.rj should close a multiloop, then the sequence fragment ri+ <dig> j-1:= ri+1 … rj- <dig> is guaranteed to be folded into an admissible multiloop that by definition contains at least two helical regions radiating out from this loop. however, by using disturbed sampling probabilities scfg model and disturbed inside values for input sequence r, derived by incorporating any sort of errors), the sampling algorithm may choose to form a particular substructure on the fragment ri+ <dig> j- <dig>  although this would actually not be possible.

therefore, we had to slightly modify the sampling procedure such that in any case where the chosen substructure type can not be successfully generated, it settles for the partially formed substructure. that is, it either leaves the complete fragment unpaired , or else it for example only creates a bulge/interior loop although a multiloop should have been constructed . the resulting modified versions of the distinct sampling steps  are given in section sm-i , figure  <dig> gives a schematic overview of the overall sampling process.
s

1

,n 

for a given input sequence 
r 
of length 
n 
according to an inherently controlled strategy with predetermined order, similar to that of  <cit> , <cit> .

note that alternatively, the algorithm could have been modified to revise any decisions that lead to incompletely generated substructures, resulting in some sort of backtracking procedures that obviously would have to be applied in order to sample more realistic overall structures for a given rna sequence. however, as this effectively results in much more complex modifications and eventually yields significant losses in performance, we opted for the simpler and more straightforward first variant to get rid of the described problem.

RESULTS
the aim of this section is to perform a comprehensive experimental analysis on the influence of disturbances  on the quality of sample sets generated by the scfg based statistical sampling approach from  <cit> . in fact, we want to explore to what extend the quality of produced secondary structure samples for a given input sequence and the corresponding predictive accuracy decreases when different degrees of errors are incorporated into the needed sampling probabilities.

rna structure data
for our examinations, we decided to consider different sets of trusted rna secondary structure data for which the scfg based sampling approach yields good quality results when no disturbances are included in the respective sampling distributions for a given sequence. therefore, we took the same trna database  and the identical 5s rrna data set  as collected in  <cit> . these two rich data sets of trusted rna secondary structures will be exclusively used as the basis for the following applications, such that the results can easily be opposed to the corresponding ones presented in  <cit> .

probability profiling for specific loop types
a statistical sample of all possible secondary structures for a given rna sequence can be used for sampling estimates of the probabilities of any structural motifs. actually, probability profiling for unpaired bases within particular loop types can easily be applied for this purpose. in principle, for each nucleotide position i, 1 ≤ i ≤ n, of a given sequence of length n, one computes the probabilities that i is an unpaired base within a specific loop type. these probabilities are given by the observed frequencies in a random sample set.

since this application is rather intuitive, we decided to use it as a starting point for our disturbance analysis. particularly, we derived a number of statistical samples for the well-known escherichia coli trnaala sequence by applying the sampling strategy from section resulting modified sampling strategy on the basis of diverse sets of probabilistic parameters  for that sequence and calculated corresponding probability profiles. all relevant results are displayed in additional file 1: figures s <dig> to s <dig> of section sm-ii. some of the potentially most interesting ones are presented in figures  <dig>   <dig> and  <dig> 

win

,+
  and fev

win

,+
 , respectively, with 
prob 
= 10
- <dig> 
and 
win 
∈ { <dig>   <dig>  60} .

win

,-
  and fev

win

,-
 , respectively, with 
prob 
= 10
- <dig> 
and 
win 
∈ { <dig>   <dig>  60} .

errors on all values
let us first consider the profiles displayed in figure  <dig> . obviously, even if large relative errors on all inside probabilities and hence on the needed conditional sampling probabilities are generated, the sampled structures still exhibit the typical cloverleaf structure of trnas, especially for the length-dependent sampling approach where relative disturbances seem to have no significant negative effect on the sampling quality . however, figure 2b perfectly demonstrates that if the disturbances have been created by adding absolute errors to all inside values, then – even for rather small absolute error values – the resulting samples obtained with both the scfg and lscfg approach are useless.

note that for any given input sequence, it seems to be usually much more important for the employed sampling strategy to be able to identify which ones of the  possible substructures can actually be  formed on the considered sequence fragment rather than to know their exact probabilities , for two contrary reasons: first, in order to avoid drawing practically impossible choices, which later forces it to leave the considered sequence fragment  unpairede. second, for ensuring that none of the actually valid choices is prohibited during the folding process, such that the sampling procedure might inevitably prefer other  substructures.

consequently, in order to prevent a decline in accuracy of generated structures and a reduction of the overall sampling quality, it seems to be of great importance that the sampling strategy is capable of distinguishing between inside values and especially sampling probabilities that are equal and unequal to zero according to the exact  ensemble distribution for the given input sequence. by adding absolute errors, however, inside or sampling probabilities being equal  to zero in the exact case might often become unequal  to zero according to the resulting skewed  distributions, whereas by incorporating relative errors, all considered inside and sampling probabilities obviously stay equal or unequal to zero , which intuitively explains the basic observations made from figure  <dig> 

relevant sampling probabilities
nevertheless, in order to draw more detailed conclusions, we counted and compared the relevant  inside and sampling probabilities that were considered for obtaining the profiles presented in figure  <dig>  the results are collected in additional file 1: tables s <dig> and s <dig> of section sm-ii.

first, it seems obvious that due to the more explicit length-dependent version of the considered grammar parameters , there should generally result a much smaller number of relevant inside values and sampling probabilities when applying the lscfg model rather than the conventional one. tables s <dig> and s <dig> exemplarily prove this intuitive assumption. note that this effect might indeed be responsible for the observation that the lscfg based sampling approach reacts considerably less to large relative errors than the conventional length-independent variant, as indicated by figure 2a: less inside probabilities are effectively disturbed, such that the extend of the relative errors imposed on the corresponding sampling probabilities is inevitably smaller for the lscfg variant than for the length-independent one.

moreover, there are much more relevant exact inside and sampling probabilities than corresponding relevant disturbed values for basically any  symbol when considering the traditional scfg model, whereas for the lscfg variant the contrary holds, that is generally way more inside and sampling probabilities are relevant in the disturbed cases than in the exact case. actually, in both cases , the numbers of relevant disturbed inside values α^x, 1 ≤ i, j ≤ n, are rather similar , in contrast to the numbers of relevant sampling probabilities  for the distinct sampling steps which are in general to a large extend greater when using the traditional scfg approach than under the assumption of the corresponding lscfg model. this behavior might be the reason for the fundamental differences in the resulting  loop profiles presented in figure 2b.

finally, it remains to mention that under the assumption of the conventional scfg model, it happens that for any x∈igsα, most inside values are relevant in both the exact and the disturbed case, whereas significantly less are relevant only in the exact case and very few are only relevant in the disturbed case . considering the lscfg variant, however, for any x∈igsα the least inside values are relevant only in the exact case, as indicated by table s1b. obviously, this seems to be the natural consequence of the previously formulated observations.

errors only on particular values
now, in an attempt to find out in which cases particular absolute errors have a very significant  impact on the resulting sampling quality and to identify potentially existing situations where they barely influence the output of the applied statistical sampling algorithm, we want to consider some of the more specialized variants for generating absolute disturbances . the corresponding profiles are basically shown in figures  <dig> and  <dig> .

notably, even if absolute disturbances may only occur for inside values αx, x∈igsα, with j - i + 1 > win , the corresponding sampling results are of no practical use at all . in fact, there seem to be no noticeable improvements when considering increasing values of win, which means that even if more inside values αx, x∈igsα, namely those satisfying j - i + 1 ≤ win, are guaranteed to be exact , the resulting samples might not be expected to gain in quality. this observation is actually unfortunate as regards the derivation of a corresponding heuristic version of the inside algorithm, since the inside computation starts by calculating the respective values for small sequence fragments and subsequently considers larger ones, meaning the straightforward approach of deriving all values αx, x∈igsα, with j - i + 1 ≤ win in the exact way and approximating only the remaining ones  might not yield results of acceptable quality if absolute errors can not be ruled out .

nevertheless, as we can see from figure  <dig>  if absolute disturbances may only occur for inside values αx, x∈igsα, with j - i + 1 ≤ win , the corresponding sampling results might actually be of acceptable quality, but seemingly only for rather small values of win. this means in order to obtain a practically applicable heuristic, it seems a good idea to consider a constant  window of size win and compute all values αx, x∈igsα, with j - i + 1 > win in the exact way, thus approximating only those satisfying j - i + 1 ≤ win. however, due to the contrary course of action of traditional inside calculations, this approach can obviously not be realized. consequently, this observation does not contribute to developing an appropriate heuristic variant of the preprocessing step, but it actually motivates the construction of an innovative sampling strategy that takes on a reverse sampling direction .

finally, for the sake of completeness, it should be noted that by incorporating absolute errors  only for any of the distinct intermediate symbols x∈igsα at once , 1 ≤ i, j ≤ n, for a particular x∈igsα), we found out that some are more sensitive with respect to disturbances in the underlying ensemble distribution than others . in principle, the strongest  reactions to the influence of the generated absolute errors were observed for symbols t, c, a, f , g and u, whereas less severe quality losses basically resulted for intermediates m, o, n and p. moreover, for two symbols, namely f  and b, we recognized no noticeable impact of the caused disturbances to the accuracy of the generated sample sets.

prediction accuracy – sensitivity and ppv
in connection with sampling approaches, there exist diverse  efficient well-defined principles for extracting a particular structure prediction from a generated set of candidate structures for a given input sequence. in fact, under the condition that a corresponding folding can be calculated in o time and with o storage , the statistical sampling method considered in this work can easily be applied to single sequence secondary structure prediction without significant losses in performance and its predictive power can easily be measured by means of sensitivity  and positive predictive value f. briefly, these two common measures are widely used in order to quantify the accuracy of rna secondary structure prediction methods and are usually defined as follows : 

• sens. is the relative frequency of correctly predicted pairs among all position pairs that are actually paired in a stem of native foldings, whereas

• ppv is defined as the relative frequency of correctly predicted pairs among all position pairs that were predicted to be paired with each other.

formally, they are given by sens. = tp · - <dig> and ppv = tp · - <dig>  where tp is the number of correctly predicted base pairs , fn is the number of base pairs in the native structure that were not predicted  and fp is the number of incorrectly predicted base pairs .

in order to investigate to what extend the accuracy of predicted foldings changes when different dimensions of relative disturbances are incorporated into the needed sampling probabilities, we decided to perform a series of cross-validation experiments based on the same partitions of the trna and 5s rrna databases into  <dig> approximately equal-sized folds, respectively, as considered in  <cit> . in particular, for each sequence, we generated several sample sets on the basis of different relative error types and values, where from each of the produced samples, we derived corresponding predictions according to a number of competing reasonable selection principles and construction schemes .

briefly, we employed two different well-defined selection procedures in order to identify one particular structure from the produced sample as prediction: first, we picked the most likely secondary structure scfg model), in strong analogy to traditional scfg based probabilistic structure prediction methods. this choice will be denoted by most probable  structure subsequently. additionally, as one of the most straightforward and reasonable choices for statistically representative samples of the overall structure ensemble, we took the most frequently sampled folding , which will be named most frequent  structure subsequently.

note that if the samples are indeed representative with respect to the underlying ensemble distribution , then these two predictions should be rather identical in most cases, at least if no disturbances are considered . in fact, any representative set of candidate structures for a given input sequence obtained by scfg based statistical sampling obviously reflects the probability distribution on all feasible foldings of that sequence which strongly depends on the corresponding inside probabilities. thus, if the preprocessed inside values contain any errors, then the mf structure of a particular statistically representative sample set corresponds to the most likely folding of the given sequence with respect to the skewed ensemble distribution induced by the disturbed inside values, whereas the mp structure of that sample is indeed equal to the most likely folding  with respect to the exact ensemble distributiong. hence, the results for mp and mf structure predictions might differ in the disturbed cases, especially as the gravity of generated disturbances grows.

however, we decided to additionally apply two different commonly used construction schemes for computing a new structure as predicted folding, where the predicted structure itself must not necessarily be contained in the given sample. particularly, we first determined a maximum expected accuracy  structure of the generated sample set as defined in  <cit> , which maximizes the number of correctly unpaired and paired positions with respect to the true folding and is computed on the basis of the considered sample . furthermore, we calculated the unique consensus structure of the produced sample, called the centroid structure, which effectively reflects the overall behavior of the sample set and is actually formed by all base pairs that occur in more than 50% of the sampled structures . note that for similar reasons as discussed above for mf structure predictions, mea and centroid structures obtained from statistically representative sample sets can only reflect the skewed ensemble distribution rather than the exact one in the disturbed case.

last but not least, we derived two different sets of so-called γt-o-mea and γt-o-centroid structures for the produced samples, respectively, as defined in  <cit>  , where γt-o ∈ [ <dig>  ∞) is a trade-off parameter for controlling the sensitivity and ppv of the predicted foldings. note that the default choice γt-o =  <dig> serves as the neutral element with respect to the prediction, meaning the prediction is neither biased towards a better sensitivity nor to a better ppv and corresponds to the above described well-known mea or unique centroid structure, respectively. notably, by measuring the performance at several different settings of γt-o  sensitivity and ppv for various values of γt-o), it becomes possible to derive a corresponding receiver operating characteristic  curveh and to calculate the estimated area under this curve , for both the mea and the centroid prediction principle, respectively. this obviously allows for a much more informative and reliable comparison of the predictive powers of the different sampling variants than considering only the corresponding results for the default choice γt-o =  <dig> 

however, the  sensitivity and ppv measures obtained by considering the four different  prediction principles sketched above are listed in additional file 1: tables s3a and s5ai, where a few selected ones are presented in table  <dig>  the corresponding auc values obtained by varying instances of γt-o are all collected in additional file 1: tables s3b and s5b, some of them are presented in table  <dig>  note that in accordance with  <cit> , we considered any value of γt-o ∈ { <dig> k∣ - 12 ≤ k ≤ - 1}∪{2k∣0 ≤ k ≤ 12} in order to obtain appropriate roc curves and corresponding auc values. plots of some of the resulting curves can be found in additional file 1: figures s <dig> to s <dig> of section sm-ii.

all values have been computed by 10-fold cross-validation procedures, using sample size  <dig> and minhel = minhl =  <dig> 

all values have been computed by 10-fold cross-validation procedures, using sample size  <dig> and minhel = minhl =  <dig> 

let us first consider the results reported in table  <dig>  as we can see, the ppv is principally not affected by the different dimensions of disturbances caused according to mep, as only in the case of mf structure prediction one can observe a slight change for the worse. however, with increasing value of mep, there results a moderate decline in sensitivity  of up to about 10% for the traditional and 5% for the length-dependent sampling approach in the case of trnas, whereas for 5s rrnas, the sensitivity values only decrease up to about 3% to 4% for both sampling variants. unsurprisingly, for both rna data, the change for the worse by means of measured sensitivity is less significant when considering mp structure predictions than when employing any of the other three principles, especially in the case of the lscfg model. this is due to the fact that mp structures are always extracted by relying on the exact distribution . altogether, these observations indicate that relative disturbances caused by mep do not have a significant negative effect on the predictive accuracy.

moreover, table  <dig> indicates that generating errors according to the fep variant  yields greater losses in the accuracies of selected predictions. in fact, as prob gets greater, there generally result considerably smaller ppv values for all four prediction schemes  than in the corresponding undisturbed case. furthermore, the respective sensitivity values degrade enormously, albeit again comparatively less in connection with mp structure predictions. however, these changes for the worse are obviously less significant when using the length-dependent sampling approach instead of the more general conventional variant, which matches the observations made above for disturbances caused by mep. nevertheless, errors produced according to fep for moderate percentages prob seem to generally have only a rather small influence on the resulting prediction accuracy. in most cases, only marginal losses in performance can be expected when disturbances are generated by fep with values prob of up to about  <dig> , whereas for percentages of up to about  <dig> , there should usually still result an acceptable accuracy of selected predictions .

finally, it should be mentioned that all these observations and conclusions are actually affirmed by comparing the more reliable auc results given in table  <dig>  which draw a rather similar picture of the behavior of both sampling approaches under the influence of the considered types and dimensions of relative disturbances in the underlying ensemble distribution.

sampling quality – specific values related to shapes
obviously, the sensitivity and ppv measures used in the last section for assessing the accuracy of predicted foldings depend only on the numbers of correctly and incorrectly predicted base pairs . for biologists, however, it is usually much more important to get the correct shape of the native folding. this is due to the fact that a predicted set of suboptimal foldings calculated by modern computational structure prediction methods generally contains lots of similar foldings but for biologists, only those with significant structural differences are of interest. according to these aspects, the concept of abstract shapes was introduced  <cit> , which are defined as morphic images of secondary structures such that each shape comprises a class of analogical foldings. notably, there are five different shape levels which have been proven to gradually increase abstraction by disregarding certain unpaired regions or combining nested helices , where secondary structures can accordingly be considered level  <dig> shapes.

for these reasons, we decided to complete our analysis of the influence of disturbances to the quality of probabilistic statistical sampling by considering the following meaningful specific values related to the shapes of predictions and sampled structures as defined in  <cit> : 

• frequency of prediction of correct structure : in how many cases is the predicted secondary structure  equal to the correct structure ?

• frequency of correct shape occurring in a sample : in how many cases can the correct shape  be found in the generated sample set?

• number of occurrences of correct shape in a sample : how many times can the correct shape be found in the generated sample set?

• number of different shapes in a sample : how many different secondary structures  can be found in the generated sample set?

we can easily compute the respective values from the predicted structures and the corresponding sample sets that were derived for the calculation of the sensitivity and ppv measures in the last section. the obtained results are collected in additional file 1: tables s7a to s8g of section sm-ii. some of the most interesting ones are recorded in tables  <dig> and  <dig> 

freq 
freq 
freq 
freq 
tables record specific values related to shapes of predictions and sampled structures, obtained from our trna database. all results were computed by 10-fold cross-validation procedures, using sample size  <dig> and minhel = minhl =  <dig> 

freq 
freq 
freq 
freq 
tables record specific values related to shapes of predictions and sampled structures, obtained from our 5s rrna database. all results were computed by 10-fold cross-validation procedures, using sample size  <dig> and minhel = minhl =  <dig> 

first, as regards trnas, we observe that for mp predictions, disturbances caused by mep do generally not have a noticeable negative impact on the frequency of correct structure predictions , and for the three other extraction principles, such disturbances do at least not yield a significant decline of the corresponding cspfreq value for shape levels  <dig> to  <dig> and under the assumption of the lscfg approach, where for mf structures, there indeed results a slightly higher cspfreq value with increasing relative error percentage prob . when the more intensive variant as defined by fep is used for incorporating random errors into the considered sampling probabilities, the lscfg based sampling algorithm still yields acceptable results with respect to cspfreq on abstraction levels  <dig> to  <dig>  where for mp and mf structure predictions it obviously behaves quite resistant to the imposed distributions even for large values of prob.

similar results are observed for 5s rrnas  generally do not get significantly worse when applying the lscfg sampling approach with inside values disturbed according to mep for any percentage prob∈ or according to the more intense relative disturbance variant fep for moderate values prob∈ .

moreover, comparing the discussed cspfreq results for the lscfg variant to the corresponding ones for the conventional scfg approach, we get additional evidence that the length-independent sampling method reacts stronger to relative disturbances in the underlying ensemble distribution for a given sequence than its length-dependent counterpart. as already mentioned, this is due to the fact that the ensemble distribution considered in the length-dependent case is much more centered due to the more explicit  grammar parameters, such that randomly generated errors on particular probabilities carry less weight.

now, let us consider the three remaining specific values csofreq, csnum and dsnum that can eventually be used to assess the overall quality of generated sample sets rather than the accuracy of corresponding selected predictions. basically, the obtained csofreq and csnum results for trnas and 5s rrnas , respectively, show a similar picture and thus yield similar conclusions as the corresponding cspfreq values discussed above. as a consequence to the fact that for larger relative error percentages prob, for the less intensive disturbance variant defined by mep and especially for the more grave version implied by fep, the resulting values for csofreq and csnum usually get smaller, the corresponding dsnum values inevitably increase with growing disturbance influences imposed by mep and especially fep . this actually means that the diversity within the generated sample sets generally gets greater as the overall sampling quality  decreases, which could be fully expected.

CONCLUSIONS
in this article, we performed a comprehensive experimental analysis on the effect of disturbances in the ensemble distribution for a given sequence to the quality of corresponding sets of candidate structures generated with the scfg based statistical sampling method studied in  <cit> . basically, two different levels of errors were considered for randomly creating disturbances on all inside values for a given input sequence according to the underlying grammar model: relative and absolute ones.

during our analysis , we immediately observed that even incorporating only rather small absolute errors into  inside values causes problematic disturbances of the resulting sampling probabilities that generally lead to the generation of useless sample sets. this can be assumed to be due to the fact that the installation of absolute errors usually makes it impossible for the employed sampling strategy to identify which ones of the considered inside probabilities for a given input sequence must originally  have been equal or unequal to zero, which inevitably results in a misguided behavior of the strategy, as it is no longer ensured that it creates only reasonable substructures for a considered sequence fragment.

however, both scfg approaches  behave rather resistant to disturbances of the needed conditional sampling probabilities that are caused by generating  relative errors on all  inside values for a given input sequence. in general, even large relative errors seem to have no enormous negative impact on both the predictive accuracy and the overall quality of generated sample sets. that is, the reaction of the scfg based statistical sampling algorithm to the relative disturbances is fair enough to still obtain meaningful structure predictions , and the overall quality of the resulting sample sets is still acceptable such that they might often also be used for further applications .

consequently, it seems reasonable to believe that the needed sampling probabilities do not necessarily have to be computed in the exact way, but it may probably suffice to only  approximate them. in fact, the worst-case time complexity of any particular scfg based sampling method could potentially be reduced by developing a suitable approximation procedure  for the computation of the needed sampling probabilities, where an appropriate approximation ratio  should be attempted to ensure that the sampling quality remains sufficiently high, as indicated by the experimental disturbance analysis results discussed within this article.

endnotes
a all references starting with sm are references to the supplementary material available at http://wwwagak.informatik.uni-kl.de/research/publications/.b note that the function max,0)= min,1) ensures that the resulting value is still a probability, i.e. a real value from  <cit> .c note that prob∈ less than  <dig> to the probability.e if those decisions are not revised by employing backtracking procedures, see the description of the modifications incorporated into the sampling algorithm in order to deal with such situations as given in section resulting modified sampling strategy.f note that the positive predictive value is often called specificity, although this measure formally obeys to a slightly different definition.g this is due to the fact that the probability of a particular folding of a given rna sequence  depends only on the considered set of grammar parameters .h note that we here assume sensitivity as a function of ppv is an roc curve, although correctly an roc curve is sensitivity as a function of specificity.i note that the corresponding standard deviations on sensitivity values and ppv are recorded in additional file 1: tables s <dig> and s6; these allow for a reader to acknowledge which values are different and which ones are identical/close.

competing interests
both authors declare that they have no competing interests.

authors’ contributions
as developed and implemented the algorithms for generating statistical samples based on disturbed ensemble distributions. as performed all experiments and evaluated the decline of sampling quality implied by considering the diverse kinds of disturbances. men supervised the work and development of ideas. as drafted the manuscript; a revision and its final version have also been prepared by as. both authors have read and approved the final manuscript.

supplementary material
additional file 1
supplementary material.

click here for file

 acknowledgements
as thanks carl zeiss foundation for supporting her research. all authors wish to thank an anonymous reviewer for careful reading and helpful remarks and suggestions made for a previous version of this article.
