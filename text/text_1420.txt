BACKGROUND
advances in high-throughput microscopy
in the last decade, improvements in automated microscopy have enabled researchers to conduct two new types of experiments. on the one hand, high-content screening approaches allow to automatically quantify phenotypic changes of cells under a large range of different environmental conditions  <cit> . this technique is extensively used in pharmaceutics, for example in drug development and evaluation  <cit> . on the other hand, high-throughput time-lapse microscopy is a powerful tool to follow hundreds of single cells over many days and has been successfully applied in the field of hematopoietic research  <cit> . equipped with appropriate cell tracking and image processing capabilities, this approach allows to analyze single cell dynamics in a quantitative and time-resolved manner  <cit> .

a bottleneck in the analysis of high-throughput microscopy is the availability of suitable automatic processing tools that make the huge amount of information that is hidden in the data accessible  <cit> . most experimental setups are highly specialized for the study of a single process of interest. thus, different combinations of objectives, cameras or cell culture plates are used for different experiments, leading to great variability of images even for similar experimental setups. in addition, the large amount of images that is taken in high-throughput microscopy, either of many different cell culture plates or over a long time range adds to this variability. since no standardized methods for the acquisition of long-term single cell microscopy exist, bioimage informatics methods have to be adapted for each setup. however, even in a single long-term experiment, images can vary to a degree that makes a unique parameterization for the whole movie challenging. in order to receive robust results from automated image processing it is advantageous to develop the methodology in close collaboration with experimentalists, resulting in an approach that performs best on the given data set.

fluorescence-based high-throughput image processing
several computational methods for automatic processing of high-throughput microscopy experiments have been proposed. for example, fenistein and colleagues  <cit>  developed an automatic method for the segmentation of cell nuclei in fluorescence images for different cell lines in dilution experiments and report an average cell recognition rate of 95%. knapp et al.  <cit>  employed a method to identify single cells in two-channel rnai screens and used this information to improve the statistical power of the analysis. both applications demonstrated the feasibility of automatic high-throughput image processing methods on large amounts of fluorescent images.

the framework cellprofiler <cit>  is a great example of how automated image analysis can be made accessible for a broad range of users, not only specialists. the intuitive gui and wealth of different implemented methods has led to frequent usage , where most applications relate to the analysis of fluorescence images.

analysis of bright field images in the context of high-throughput experiments
in general, analyzing cells in the bright field channel holds several benefits:  since acquisition of fluorescent images over longer time spans  and with short intervals  is difficult due to photo toxicity, in long-term time-lapse experiments it is useful to employ bright field images to track cell genealogies  <cit> .  quantifying cell morphology in bright field images yields the possibility to measure more descriptive features such as texture and shape simultaneously. in addition, the fluorescence staining of e.g. the cytoplasm could be incomplete or less reliable on a special cell type, which would introduce bias in the later analysis.  due to the limited number of different fluorescent dyes that can be detected simultaneously, it is desirable to use as many channels as possible for fluorescence detection. instead of losing a channel for nuclear staining to identify cells, one could observe expression of several fluorescent proteins or lineage markers and detect cell outlines in the bright field channel  <cit> .

a few publications have already shown that incorporating data from bright field microscopy can yield interesting results. by quantifying the morphological behavior of tracked neural progenitors over time, cohen et al.  <cit>  could predict the most likely lineage decision of those cells. scherf et al.  <cit>  recently published a method to quantify changes in morphology of colonies of embryonic stem cells under different environmental conditions. in the field of high-content screening, waehlby et al.  <cit>  developed a toolbox based on cellprofiler to automatically quantify effects of different treatments to c. elegans populations. adiga and colleagues  <cit>  classified the infection state of macrophages by segmentation and morphological quantification in amplitude contrast bright field images.

challenges in high-throughput processing of bright field images
however, the development of an automated processing method for high-throughput bright field experiments is more demanding than in the fluorescence case and holds several challenges. cells imaged by bright field microscopy exhibit heterogeneous intensity levels and are often badly contrasted. in addition, differences in illumination over time and across the cell culture plate hamper the ability to specify a global set of parameters for cell detection algorithms over the whole experiment. this prevents the application of available automatic image processing frameworks, which are mostly developed to perform well on fluorescent images. despite the large amount of methods that are implemented in frameworks like cellprofiler, the available algorithms for illumination correction and segmentation do not perform well enough to achieve satisfying results on many high-throughput bright field microscopy experiments.

by employing active contour and level set methods, many issues of cell segmentation in bright field or phase contrast images have already been solved  <cit> . for example, ambuehl et al.  <cit>  demonstrated the very accurate tracking of a single cell in phase-contrast microscopy images. ali et al.  <cit>  developed a method that combined out of focus image acquisition and segmentation by level sets to identify outlines of adherent cells. however, these approaches are computationally expensive and often highly parameter-depended, which prevents the application in high-throughput image processing, where millions of objects have to be processed in reasonable time and without user interaction.

our contribution
in this contribution, we describe the development and application of a fully automatic image acquisition and processing pipeline. initialized with a set of  <dig> intuitively interpretable parameters, the method performs robustly on long-term high-throughput experiments which exhibit a variety of cell shapes , numerous cell densities , and changing image qualities . the strength of this protocol is the combination of changes in image acquisition that are optimal for automatic computation and a set of robust yet fast methods, which allow the processing of hundreds of thousands of images with high accuracy without changing the parameter settings. the protocol has been optimized for parallelized computing of single images. we demonstrate the robustness in cell detection and computational efficiency of our method by processing and analyzing a  <dig> day high-throughput time-lapse experiment of differentiating hematopoietic stem cells. using  <dig> nodes of a computation cluster, we were able to process ∼ <dig>  images in ∼ <dig> hours, resulting in identification of ∼ <dig> , <dig> cells. we evaluate the method on a manually inspected test set of bright field images as well as statistically on the full time lapse experiment. compared to a pipeline of algorithms available in cellprofiler, our method outperforms the standard approach with an overall cell detection accuracy of at least 82%. to demonstrate the predictive power of our approach, we derive population doubling times directly from the computed cell numbers over the whole experiment, which are in accordance to previously reported cycle times for these cell types  <cit> . in addition, we show that the computed doubling times match up with cell cycle times of  <dig> manually tracked cells.

RESULTS
image acquisition and processing steps
for the development of a method to analyze high-throughput microscopy data, it is especially important to incorporate algorithms that are  robust against heterogeneities between images that are processed and  able to process single images in the range of seconds up to a few minutes at maximum in order to finish a full experiment in reasonable time. in this work, we chose the algorithms used in every step according to these requirements. the complete pipeline is visualized in figure  <dig> 

the first step in our method concerns image acquisition. adapted from selinummi et al.  <cit> , we recorded every image with the microscope’s auto focus set 18μm below the optimal focal plane. in the case of bright field image acquisition with a 10x fluar objective , the change of the focal plane resulted in enhanced contrast of single cells, yet with a loss of textural complexity . the cell body was evenly illuminated and much darker than the background. in addition, every cell exhibited a bright halo that is supporting the identification of touching cells.

after all images were acquired in the proposed manner, differences in illumination across the images had to be resolved. we used an adapted version of the method proposed by schwarzfischer et al.  <cit> . this machine learning based algorithm estimates the background for every image, using a grid of image patches that are classified as showing only background or a mixture of background and foreground pixels. in comparison to standard correction methods like gaussian filtering that is parametrized on the average foreground object size, the machine learning based method is able to estimate the background more robustly. as shown in figure 1b, every cell body was clearly separated from the background. the halo surrounding each cell was corrected, yet clumped cells still exhibited a change in illumination at their touching edges. due to the time-consuming feature calculation during machine learning, this algorithm was occupying nearly 50% of total computing time for a single image, which was in our case  <dig> to  <dig> seconds on a standard laptop .

in the next step, all foreground objects had to be separated from the background. in our method, we used the maximally stable extremal regions  algorithm  <cit> . an advantage compared to thresholding methods such as otsu’s method is its robustness in segmentation when there are inhomogeneities in object illumination or huge differences of cell densities between different images. as shown in figure 1c, mser correctly identifies nearly all cell bodies. the used implementation of mser has linear time complexity, thus it is able to process a single image  in milliseconds  <cit> .

eventually it was necessary to split clusters of multiple cells that were segmented as a single foreground object . we used a two-step approach consisting of an initial marker-based watershedding, followed by merging of cells that were erroneously split into fragments . in this step , the earlier conducted out of focus acquisition was very advantageous: the homogeneous illumination of cell bodies and the slightly brighter interfaces of touching cells simplified the task to find cell centers by ultimate erosion, which then served as seed points for the watershed algorithm. depending on the number of cells in an image this step occupies  <dig> to  <dig> seconds of processing time.

application
we applied our method on a time-lapse experiment of hematopoietic stem cells  under conditions that promote differentiation towards myeloid cells. for a review of blood cell differentiation see for example orkin et al.  <cit> . two wells of a plastic slide were imaged in intervals of ∼ <dig>  minutes for  <dig> days. the wells were sparsely covered with cells at the beginning, yet at the end of the experiment all wells were densely populated by hematopoietic progenitors and differentiated cells . to cover the full area of interest in high resolution, each well was divided into a grid of  <dig> overlapping fields of view . each field of view was recorded once in a time interval. details regarding experimental conditions and the parametrization of our method to process this experiment are described in the methods section.

complete processing of the full data set occupied  <dig> hours, using  <dig> cores of a computer cluster. the average node architecture was equal to an intel xeon 2ghz, 4gb ram running a 64bit linux-based operating system. complete processing of a single image with average cell density  lasted  <dig> seconds. to account for small debris or fragments of dead cells that were erroneously segmented by our method, we discarded all foreground objects with a size <  <dig> pixels and an eccentricity >  <dig> . the final test set comprised ∼ <dig>  raw images with the according object masks and computed background corrections, covering ∼ <dig> , <dig> identified objects.

evaluation
the performance of a segmentation approach can be measured in different ways depending on the analyses that are intended after processing. for the development of automatic tracking approaches it is necessary to identify single cells with high accuracy. especially cells that stick together shortly after division or clusters of multiple cells need to be split correctly. for population analysis or simple cell counting it suffices to detect the number of cells in each image with high accuracy. here, we manually determined the total number of cells after  <dig> hours,  <dig> days,  <dig>  days and  <dig>  days at two randomly chosen fields of view per well. we evaluated if a cell was  correctly segmented,  missed,  over-segmented or  under-segmented. next, we computed the average accuracy, specificity and sensitivity of cell detection based on the number of true positives , false positives  and false negatives . in addition, we calculated the mean and the according standard deviation of cell densities  over all fields of view at the given time point.

after  <dig> hours , all fields of view were sparsely covered with cells . despite the high fraction of correctly segmented cells , debris in the examined fields of view that was falsely identified as a cell by our method lead to a decrease in accuracy . the low number of cells at this early time point resulted in a high variability  between the fields of view.

at day  <dig> , the number of cells increased to a density of  <dig> ± <dig>  1/mm <dig>  pairs of clumped cells appeared. 82% of all cells were correctly segmented, only very few cells were missed or over-segmented  and under-segmentation was not detected. the cell detection accuracy was 82±3%.

at day  <dig>  , the number of cells across the examined fields of view was significantly larger . we observed cells that were clumped together in large clusters and first differentiated cells with more complex morphology were found. cells with round shapes were correctly identified in most cases , especially round clusters of cells were under-segmented  and cells with elongated shape were over-segmented . most over-segmented cells were still only counted once since smaller fragments were discarded by the filtering step . 1% of the cells were missed, mostly because of bad contrast or direct contact to the image border. due to the large increase in cell number, debris did not significantly contribute to a drop in cell recognition accuracy anymore. the accuracy at this time point was 95±1%.

at day  <dig>  , fields of view of both wells were very densely populated by cells  that were exhibiting a variety of shapes. with  <dig> %, the fraction of missed cells was even reduced compared to the time point examined before. over- and under-segmented cells were observed more frequently , yet most cells were correctly segmented . the amount of debris was increased, mostly due to clumps of fragments of dead cells. yet, the cell detection accuracy was very high .

sample images showing the cell densities at different time points for our method are given in figure  <dig>  the object quantification is summed up in table  <dig> 

two randomly chosen fields of view per well were quantified for  <dig> hours,  <dig> days,  <dig>  days and  <dig>  days, respectively. in each field of view, the number of true cells was counted. all segmented objects were classified as correct, over-, under-segmented, or debris. accuracy, sensitivity and specificity of cell detection were calculated based on true positives , false positives  as well as false negatives . note that we deliberately keep differences in the total number of counted cells at different experiment times, since these impact on the standard deviation of accuracy, specificity and sensitivity.

to demonstrate the superior robustness of our method, we conducted the same manual evaluation with the results from a pipeline of methods available in cellprofiler. for details of the pipeline and the parameter settings, see the methods section. we applied the cellprofiler pipeline on the identical set of out-of-focus images and optimized the parameters of each module based on a single image of day  <dig> . for a graphical comparison of the cell detection accuracy of our method against the cellprofiler pipeline, see figure  <dig> 

at  <dig> hours, the cellprofiler pipeline produced highly heterogeneous results. the used thresholding algorithm performed well on images of  <dig> fields of view but produced completely mis-segmented images on the others, leading to a low cell detection accuracy . this was most likely due to errors in the clumped cell splitting step.

for images taken at day  <dig>  the cellprofiler pipeline performance increased . yet the accuracy was rather low and less robust across different fields of view .

at  <dig>  days, the increased cell density lead to an improvement in the cell detection accuracy , with a huge decrease of standard deviation. still, 3% of the cells were missed completely and 9% were under-segmented.

at the last manually evaluated time point of  <dig>  days, cell detection accuracy of the cellprofiler pipeline decreased to 71±9%. this was mainly because of the high fraction of missed  and under-segmented  cells.

taken together, our method showed high robustness in cell detection and low over- and under-segmentation over the full experiment range. even at very late time points where the wells were very densely covered, the cell detection accuracy was satisfying . the out-of-focus acquisition improves the overall segmentation accuracy of our pipeline: applied to a comparable in-focus movie, the segmentation accuracy dropped to 70% due to over-segmentation of badly contrasted cells and complex cell texture.

as shown in figure  <dig>  our method clearly outperformed the standard cellprofiler pipeline. note that the low cell detection accuracy in the early time points does not necessarily mean that cellprofiler in general is not able to segment this type of images . still, the combination of algorithms performed less robustly on images with different cell densities, given the parameter set that we optimized for images with medium cell density .

finally, we would like to note that our pipeline achieved similar robust results  in a second long-term high-throughput experiment.

population doubling time derived from cell counts
a possible use-case in the analysis of high-throughput time-lapse experiments is the control of cell proliferation. due to photo toxicity or different medium conditions, cells could die early or exhibit deviating proliferation rates  <cit> , which would introduce errors in later analyses that are conducted on the data set.

here, we first analyzed the mean cell density over  <dig> fields of view over the full experiment time span . we found that the number of cells increased monotonously until a plateau roughly at day  <dig>  we compared the results with the manually quantified numbers of cells as shown in table  <dig> and found them to reside within the standard deviation of the number of objects. from our accuracy estimation in table  <dig>  we conclude that the plateau is not due to a failure of our method, but resulted from biological or experimental reasons. one explanation could be the differentiation and thus post-mitotic state of the hematopoietic cells, but also a depletion of the medium. in addition, the high density of cells could lead to an arrest in population growth.

plotting the growth curves in log scale  revealed three different phases of population dynamics. at the beginning of the experiment, the number of cells increased sub-exponentially. between approximately  <dig> and  <dig>  days a clearly exponential increase with an average doubling time of 10- <dig> hours was observed. the population stops to grow exponentially and reaches a plateau after ∼ <dig>  days.

based on the cell counts resulting from our image processing method, we derived the population doubling time. due to the high temporal resolution of ∼ <dig>  minutes between measurements, the population doubling time could be estimated by computing the difference of each time point and the time point where the cell number had doubled, respectively . the doubling time decreased from ∼ <dig> hours and stabilized after day  <dig> until day  <dig> at around  <dig> to  <dig> hours.

to validate the estimated doubling times, we tracked  <dig> cells manually using our in-house developed software ttt  <cit> . as shown in figure 4c, the cell cycle times of tracked cells that were born between  <dig> and  <dig>  days  show the same trend, decreasing from ∼ <dig> hours to 9- <dig> hours in the exponential growth phase.

CONCLUSIONS
in this contribution, we described a fully automated method for processing of high-throughput bright field microscopy experiments, that relies on the combination of optimized image acquisition and a concatenation of image processing algorithms that identify cells in in a robust yet time efficient manner. using the same parameter set for all images, we applied the method on a  <dig> day time-lapse movie of differentiating hematopoietic stem cells and achieved a cell detection accuracy of at least 82%, which outperformed a pipeline of algorithms available in cellprofiler. we demonstrated the application of the results generated by our method by computing population doubling times based on the increasing number of cells over the whole experiment in time and space. we compared the results to the cell cycle times of  <dig> manually tracked cells and showed that the automatically derived doubling times coincided with the manually tracked cell cycle times.

the full data set of ∼ <dig>  images was processed within ∼ <dig> hours. note that this value was achieved by parallel computing on  <dig> cores of a computation grid. however, the code used in this work was not optimized for speed. using implementations in c++ or java that are optimized for fast computation, the processing time could be further improved. this would allow on-line processing of a time-lapse or high-content experiment during acquisition, which offers powerful options. for example, a researcher could check population doubling times, and thus cell health during a time-lapse experiment, or acquisition could be stopped automatically when a certain number of cells is reached in the experiment.

the robustness of our method relies on the out of focus acquisition of bright field images, which results in very well defined cell outlines but also in the loss of textural complexity for single cells. however, by acquiring an additional image with an optimally set focus in every interval, the quantification of morphological features such as shape and texture becomes feasible. together with the high accuracy in cell detection of our method, this will support the development of automatic tracking approaches in time-lapse microscopy. for both time-lapse and high-content screening experiments, morphological quantification of millions of cells in one experiment allows the application of machine learning methods to classify, e.g., dying and surviving cells after drug treatment or the fate of differentiating stem cells.

our pipeline will be improved and adapted in the future. a promising avenue is the extension of the mser segmentation algorithm to include more cellular features, like eccentricity or size.

another possible improvement in our pipeline is the splitting of clumped cells. many methods have been developed in the past, e.g. ellipse fitting that is well suited to split nuclei or cells with round morphology  <cit> . unfortunately, the restrictive assumptions in this method do not allow more complex cell shapes that may emerge during a long-term movie of differentiating cells. we showed that our method performs well at the segmentation of hematopoietic stem and progenitor cells, which show round morphology. still, the marker based watershedding we used is flexible enough to also cover more complex cell shapes that are appearing later in the differentiation process. li et al. proposed a method based on gradient flow tracking and showed that it performs well on fluorescent images with hundreds of stained nuclei that are densely packed and are thus exhibiting different morphologies  <cit> . another approach could include the development of a robust and fast performing level set evolution method. this class of algorithms has already been shown to perform very well on complex cell shapes  <cit> , however the computional complexity hinders an application in a high-throughput context. an approach that was already applied on high-throughput screens is to iteratively learn the different cell shapes of a given cell type or system in an experiment  <cit> . due to the modular structure of our method, the extension with algorithms that are able to split cells with a more complex morphology is easily possible. in the time-lapse experiment that was used in this work, these improvements could specifically enhance the cell detection accuracy for differentiated blood cells at the end of the experiment.

in summary, we believe that the high overall robustness in cell detection as well as the fast processing speed of our method will be of great service for the analysis of high-throughput microscopy experiments.

