BACKGROUND
sequence motif discovery has been applied to discover many types of patterns in dna and amino acid sequences. for example, motif discovery has been used extensively to elucidate putative transcription factor binding sites  <cit>  and to discover protein-protein interaction domains  <cit> . in most cases, motif discovery algorithms take as input only a set of sequences hypothesized to contain a biologically important sequence pattern, and search for patterns that are unlikely to occur by chance. usually, the concept of "occurring by chance" is captured in some kind of probabilistic model of "random" sequences. since motifs are usually short and can be highly variable sequence patterns  <cit> , a challenging problem for motif discovery algorithms is to distinguish functional motifs from random patterns that are over-represented by chance.

discriminative motif discovery attempts to find motifs that occur more frequently in one set of sequences compared to another set. this can help with the problem of distinguishing functional motifs from randomly occurring sequence patterns, because the negative set of sequences may be a better representation of "random" sequences than can easily be captured in a probabilistic model. for example, in order to discover the tfbs motif of a transcription factor , the set of dna probes from a chip-chip  <cit>  or dip-chip  <cit>  experiment that do not bind to the tf can be used as the negative sequence set. the actual tfbss may be more strongly over-represented in the dna probes that do bind the tf when compared to a negative set of non-binding probe sequences than when compared to a random model of dna.

another natural application for discriminative motif discovery is in the search for differences in proteins that have evolved in different environments. orthologs of a single bacterial protein can be divided in two sets according to whether the organism is a thermophile or a mesophile  <cit> . using the thermophilic orthologs as the positive set and the mesophilic orthologs as the negative set, discriminative motif discovery can be used to find motifs that are indicative of a high-temperature environment. these motifs might differ only slightly from the corresponding sites in the mesophilic sequences  <cit> , and may be embedded in much longer conserved domains that would be reported by a non-discriminative motif discovery algorithm.

many algorithms have been designed to solve motif discovery problems. most of these algorithms, including alignace  <cit> , consensus  <cit> , meme  <cit> , pattern-branching  <cit>  and ymf  <cit> , are not specifically designed for discriminative motif discovery. some algorithms, such as weeder  <cit> , do make use of a set of negative sequences in scoring candidate motifs. a few algorithms have been developed specifically for discriminative motif discovery, including alse  <cit> , dips  <cit> , dme  <cit>  and seedsearch  <cit> .

both discriminative and non-discriminative motif discovery algorithms can be loosely grouped according to how they represent a motif. a motif may be represented as: 1) strings , 2) position-specific weight matrices , or, 3) collections of sites. string-based methods represent the motif as a sequence of letters, possibly allowing wildcards or "ambiguity characters" to represent variability in the motif. pattern-branching, weeder and ymf  and seedsearch  use a string representation. in contrast, a pwm specifies a score for each base/amino acid at each position of the motif, assuming independence between positions in the motif. when applied to dna binding site motifs, pwms have a strong theoretical basis relating their scores to free energy of binding  <cit> . pwms are used by consensus and meme  and by alse, dips and dme . the representation of a motif as a collection of sites is used by gibbs sampling algorithms such as alignace and glam  <cit>  .

several approaches have been applied to search for discriminative motifs. seedsearch  <cit>  uses exhaustive enumeration in discrete string space to search for discriminative motifs. seedsearch counts the number of occurrences of a string, allowing a specified number of mismatches, then applies a hypergeometric significance test to discover patterns that are enriched in the positive set relative to the negative set. the enriched patterns are expanded to construct a set of pwms and an em-like  heuristic is used refine the model parameters.

dme   <cit>  discovers discriminative motifs using an exhaustive, enumerative search of a discrete pwm space. that is, given a finite set of possible pwm columns, dme constructs all possible matrices of a specified width. dme applies a likelihood function to score the relative over-representation of the motif in the positive set.

dips   <cit>  applies a novel probabilistic score, the "w-score", to represent the number and strength of pwm matches in a sequence. a novel hill-climbing heuristic is used to maximise the difference between the mean w-score for the positive and negative sequences. the alse  <cit>  algorithm has a very similar approach, using an em-like refinement step for refining a pwms and a scoring function based on the hypergeometric distribution, a distribution frequently used for modelling over-representation.

another approach to discriminative motif discovery was taken by segal et al.  <cit>  and extended by sharan et al.  <cit> . they use a discriminative motif finder as a component of a larger system that integrates promoter primary structure, localization and expression data to predict gene expression from sequence motifs. their algorithm, which we will refer to as segal-sharan, uses a two-step process. first, it discovers discriminatory string-based motifs using seedsearch. then, it converts these to pwms and uses conjugate gradient  <cit>  find pwms that maximize a probabilistic scoring function.

the scoring function used by segal-sharan is based on two probabilistic sequence models, one for sequences containing a motif site, and one for sequences without a motif site. sequences with a site are assumed to contain a single motif occurrence, and are modeled using the oops  sequence model  <cit> . motif occurrences are assumed to be distributed according to the pwm, treated as a position-specific frequency matrix. sequences without a site are modelled using a 0-order markov process. the overall data model of the segal-sharan algorithm has two flavors; one forcing all positive sequences to contain a site, and a variation, which we refer to here as the noops  model, allowing a fraction of the positive sequences to contain no motif occurrence  <cit> . in either case, negative sequences are assumed not to contain a motif site.

the sharan-segal algorithm labels the input sequences as "1"  or "0" . the scoring function, f, is the log conditional probability of the class labels given the sequences in the dataset, d, and the data model parameters, θ. the algorithm attempts to maximize the scoring function with respect to θ, where

 f=∑<x,c>∈dlog⁡p.
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwggbgrcqggoaakcqwgebarcqggsaaliigacqwf4oqccqggpaqkcqgh9aqpdaaeqbqaaigbcygasjabc+gavjabceganjabdcfaqjabcicaoiabdoeadjabcyha8hqabiab+hfayjabcycasiab=h7axjabcmcapawcbagaeyipawjae4hwaglaeiilawiaem4qamkaeyopa4jaeyici4saemiraqeabeqdcqghris5aogaeiola4caaa@4c53@ 

here d is the dataset of labeled sequences <x, c >, where c is the class label of the sequence x. the seedsearch algorithm is used to find string motifs, and these are converted to pwms, which are used as initial estimates for θ. conjugate gradient is then used to refine each initial θ.

in this work, we have developed a discriminative motif discovery algorithm called deme . deme is based on the discriminative framework of segal et al.  <cit> . however, we apply a novel combination of global and local search to learn the parameters of the motif model that maximise the discriminative objective function .

since a string based approach has been shown to be effective for both synthetic and real motif discovery problems  <cit> , the deme global search algorithm searches in string space. in contrast to the hypergeometric approach of segal et al.  <cit>  and sharan et al.  <cit> , we use "substring search"  <cit>  and "pattern branching"  <cit>  to find good starting points for conjugate gradient. substring search samples all substrings contained in the positive set and has been shown to work well for both dna and protein motif discovery problems  <cit> . pattern branching follows substring search to expand the search space by considering strings in the local neighbourhood of the sample strings.

to improve the search using conjugate gradient, we reparameterize the objective function to ensure that all solutions are consistent with the underlying sequence models and to allow us to use bayesian priors on the columns of the pwm model to prevent over-fitting.

although intended as a general purpose motif discovery algorithm, deme includes refinements to make it more effective with protein sequences. to improve the search for protein motifs, deme utilises prior knowledge of amino similarities to estimate the motif model parameters. that is, deme uses the pam <dig> substitution matrix and a dirichlet mixture model to assign similar weights to amino acids with similar properties. in contrast, a simple dirichlet prior is used for dna sequences to prevent over-fitting. naturally, other refinements can be imagined to improve performance in particular types of dna or protein motif discovery problems.

a second contribution of this paper is a set of synthetic data problems for discriminative motif discovery. the synthetic problems are intended to simulate situations where algorithms such as deme would be useful. the idea is derived from the so-called "standard challenge problem" introduced by pevzner et al.  <cit>  as a way of testing non-discriminative motif finders. the standard challenge problem specifies a synthetic dna dataset consisting of  <dig> length- <dig> sequences, each containing an artificially generated motif occurrence. the motif is represented a string of length  <dig>  and each occurrence contains exactly four mismatches. we augment the standard challenge problem by including a set of negative sequences and define four synthetic discriminative motif discovery problems. these include problems where a variant of the motif is planted in the negative sequences; where the negative sequences contain a strong, "decoy" motif; and where the motif is underrepresented in the negative sequences. we also describe a synthetic problem where the planted motif is generated using a pwm model based on real transcription factor pwms. we evaluate deme using these synthetic problems, and complement this with an evaluation of its ability to discover transcription factor binding motifs in yeast. we also illustrate the usefulness of deme for motif discovery problems in protein sequences.

RESULTS
algorithm
given a labeled dataset of positive and negative sequences, d, deme discovers a motif of width w that discriminates between the two sets by maximizing the objective function given in eqn.  <dig>  the maximization is done over the model parameters, θ . we use a different type of global search than sharan-segal and apply a local search that enforces informative constraints on the model parameters.

global search is applied first, using substring search  <cit>  followed by "pattern branching"  <cit>  to search for string motifs that can be used as "seeds" for local search. seed motifs are scored using an objective function closely related to eqn.  <dig>  substring and branching search convert each string  to a position-specific frequency matrix , and use the same objective function as used for local search, eqn.  <dig>  to compute the score for the psfm. the seed with the best score is used to initialize the parameters of the motif model  then conjugate gradient  is applied to refine the model parameters.

substring search scores every length-w substring in the positive dataset. a fixed-size heap is used to save the best-scoring candidate seeds. after substring search is complete, branching search expands the search space by mutating single positions in each of the seeds in the heap. one iteration of branching search scores all possible seeds that are exactly one mutation distant from a seed in the original heap. the best scoring seeds are stored in a new heap. multiple iterations of branching search allow seeds to be found that are several mutations distant from any subsequences in the positive dataset.

global search is complete when the last iteration of branching search is finished. local search is now employed to refine the data model. the best scoring seed from global search is used to initialize the parameters of the motif model, θm. since the motif model contains the parameters of discrete distributions, θm is mapped to a weights matrix, w, and conjugate gradient is run in w space. the logarithm of θm is the mapping function that is applied as this maps θm to an equivalent set of unconstrained parameters. deme outputs the best motif found by cg, along with the sites predicted to be occurrences of the motif. the position with the highest log odds score  in each sequence is the predicted site.

the following sections describe the data model, objective function, local search and global search in more detail.

data model
deme discovers a discriminating motif by fitting a data model to a set of labeled sequences. the data model has a set of parameters, θ, which consists of θm , θb , λ  and . the input to deme is a sequence dataset, d, and the desired motif width, w. the sequence dataset consists of a set of labeled sequences <x, c >, where x is a sequence, <x <dig>  x <dig>  ..., xl >, of length l, over the alphabet Σ, of length |Σ|. for each sequence, x, c is its class label. sequences with c =  <dig> are referred to as "positive" sequences and sequences with c =  <dig> are "negative" sequences.

deme models the sequences in its input set as being generated according to the process illustrated in fig.  <dig>  first the labeled class, c, is chosen with pr = γ. then, the true class of the sequence, t, is chosen. then the sequence is generated. if t =  <dig>  a random sequence without a planted motif site is generated using a 0-order markov process with parameter vector θb, where θb  is the probability of observing the letter a at any position in the sequence. if t =  <dig>  a motif site is generated and inserted at a random position in a random sequence generated using θb. the motif site is generated using a psfm, θm, whose entries, θm, give the probability of observing letter a at position i in a motif site.

negative sequences are assumed by deme not to contain a motif site, so pr =  <dig> . positive sequences may contain one or zero motif sites, and the probability of a positive sequence containing a site is pr = γ. if requested by the user, deme can fix λ =  <dig>  in which case all positive sequences are assumed to contain a motif site. this is referred to as the oops data model. by default, deme assumes that some positive sequences may not contain a motif, and will attempt to learn the value of λ. this is referred to as the noops data model.

for simplicity of exposition, we assume in what follows that all sequences have the same length, l, and we introduce variable n to represent the number of possible positions for a motif site, n = l - w +  <dig>  for convenience, we also define two derived variables, v and q. v specifies the ratio of the prior probabilities of a sequence containing or not containing a motif site, and is

 v=pp,=γλ1−γλ.
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaafaqadegabaaabagaemovaylaeyypa0zaasaaaeaacqwgqbaucqggoaakcqwgubavcqgh9aqpcqaixaqmcqggpaqkaeaacqwgqbaucqggoaakcqwgubavcqgh9aqpcqaiwaamcqggpaqkaagaeiilawcabagaeyypa0zaasaaaeaaiigacqwfzowzcqwf7oabaeaacqaixaqmcqghsislcqwfzowzcqwf7oabaagaeiola4caaaaa@466d@ 

the prior probability of a sequence labeled with class c =  <dig> not having a site is referred to as q, and is

 q=pr=γ1−γλ.
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaafaqadegabaaabagaemycaenaeyypa0dcbigae8huaalae8ncainaeiikagiaem4qamkaeyypa0jaegymaejaeiifawnaemivaqlaeyypa0jaegimaajaeiykakcabagaeyypa0zaasaaaeaaiigacqgfzowzcqggoaakcqaixaqmcqghsislcqgf7oabcqggpaqkaeaacqaixaqmcqghsislcqgfzowzcqgf7oabaagaeiola4caaaaa@4931@ 

the probability of a sequence, given that it does not contain a site, is the product of the probabilities for each letter in the sequence according to θb,

 pr=∏i=1lθb.
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiegacqwfqbaucqwfybgccqggoaakieqacqgfybawcqgg8bafcqwgubavcqgh9aqpcqaiwaamcqggsaaliigacqqf4oqccqggpaqkcqgh9aqpdaqewbqaaiab9h7axnaabaaaleaacqwgcbgqaeqaaogaei4waslaemiwag1aasbaasqaaiabdmgapbqabagccqggdbqxasqaaiabdmgapjabg2da9iabigdaxaqaaiabdyeambqdcqghpis1aogaeiola4caaa@4a48@ 

the deme motif site model assumes that positions in a site are independent, so the probability of a site is the product of the probabilities of the letters in the site, as specified by θm. when t =  <dig>  the sequence model assumes that sites can, with uniform probability, appear anywhere in a sequence, so the probability of a sequence, given that it contains a site, pr, is

 1n,
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaadawcaaqaaiabigdaxaqaaiabd6eaobaadaqadaqaamaarahabaaccigae8hude3aasbaasqaaiabdkeacbqabagccqggbbwwieqacqgfybawdawgaawcbagaemyaakgabeaakiabc2fadbwcbagaemyaakmaeyypa0jaegymaedabagaemitaweaniabg+givdaakiaawicacaglpaaadaqadaqaamaaqahabawaaebcaeaadawcaaqaaiab=h7axnaabaaaleaacqwgnbqtaeqaaogaei4waslaemiwag1aasbaasqaaiabdmgapjabgucariabdqgaqbqabagccqggsaalcqwgqbgacqggdbqxaeaacqwf4oqcdawgaawcbagaemoqaieabeaakiabcufabjabdifaynaabaaaleaacqwgpbqacqghrawkcqwgqbgaaeqaaogaeiyxa0faaawcbagaemoaaomaeyypa0jaegimaadabagaem4dacnaeyoei0iaegymaedaniabg+givdaaleaacqwgpbqacqgh9aqpcqaixaqmaeaacqwgobgta0gaeyyeiuoaaogaayjkaiaawmcaaiabcycasaaa@68b4@ 

which is equal to

pr·μ,

where μ is the mean of the odds of a length-w substring in x being a site vs. a non-site. that is,

 μ=1n∑i=1n∏j=0w−1θmθb.
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiigacqwf8oqbcqgh9aqpdawcaaqaaiabigdaxaqaaiabd6eaobaadaaewbqaamaarahabawaasaaaeaacqwf4oqcdawgaawcbagaemyta0eabeaakiabcufabjabdifaynaabaaaleaacqwgpbqacqghrawkcqwgqbgaaeqaaogaeiilawiaemoaaomaeiyxa0fabagae8hude3aasbaasqaaiabdkeacbqabagccqggbbwwcqwgybawdawgaawcbagaemyaakmaey4kasiaemoaaogabeaakiabc2fadbaaasqaaiabdqgaqjabg2da9iabicdawaqaaiabdeha3jabgkhitiabigdaxaqdcqghpis1aawcbagaemyaakmaeyypa0jaegymaedabagaemota4eaniabgghildgccqgguaglaaa@596d@ 

objective function
the objective function used by deme is the conditional log likelihood of the class labels , given the sequence dataset  and the data model parameters .

 f=∑<x,c>∈dlog⁡p.
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwggbgrcqggoaakcqwgebarcqggsaaliigacqwf4oqccqggpaqkcqgh9aqpdaaeqbqaaigbcygasjabc+gavjabceganjabdcfaqjabcicaoiabdoeadjabcyha8hqabiab+hfayjabcycasiab=h7axjabcmcapawcbagaeyipawjae4hwaglaeiilawiaem4qamkaeyopa4jaeyici4saemiraqeabeqdcqghris5aogaeiola4caaa@4c53@ 

for each sequence/class pair in the dataset, the key quantities are f = p which can be shown to be equal to 

 p={),if c= <dig> sig+q),if c= <dig> 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgqbaucqggoaakcqwgdbwqcqgg8bafieqacqwfybawcqggsaaliigacqgf4oqccqggpaqkcqgh9aqpdagabeqaauaabaqaciaaaeaacqggoaakcqaixaqmcqghsislcqwgxbqccqggpaqkcqggoaakcqaixaqmcqghsislcqqgzbwccqqgpbqacqqgnbwzcqggoaakcqwg5bqecqggpaqkcqggpaqkcqggsaalaeaacqqgpbqacqqgmbgzcqqggaaicqwgdbwqcqgh9aqpcqaiwaamcqggsaalaeaacqqgzbwccqqgpbqacqqgnbwzcqggoaakcqwg5bqecqggpaqkcqghrawkcqwgxbqccqggoaakcqaixaqmcqghsislcqqgzbwccqqgpbqacqqgnbwzcqggoaakcqwg5bqecqggpaqkcqggpaqkcqggsaalaeaacqqgpbqacqqgmbgzcqqggaaicqwgdbwqcqgh9aqpcqaixaqmcqgguaglaaaacagl7baaaaa@6cd0@ 

where q is given in eqn.  <dig>  the sigmoid function is defined as

 sig=11+e−y,
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqqgzbwccqqgpbqacqqgnbwzcqggoaakcqwg5bqecqggpaqkcqgh9aqpdawcaaqaaiabigdaxaqaaiabigdaxiabgucariabdwgalnaacaaaleqabagaeyoei0iaemyeakhaaaaakiabcycasaaa@3c9e@ 

and y is the discriminant function

 y=log⁡pr)=log⁡.
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaafaqadegabaaabagaemyeaknaeyypa0jagiibawmaei4ba8maei4zac2aaewaaeaadawcaaqaagqaciab=bfaqjab=jhayjabcicaogqabiab+hfayjabcycasiabdsfaujabg2da9iabigdaxiabcyha8hgaciab9h7axjabcmcapaqaaiab=bfaqjab=jhayjabcicaoiab+hfayjabcycasiabdsfaujabg2da9iabicdawiabcyha8jab9h7axjabcmcapaaaaiaawicacaglpaaaaeaacqgh9aqpcyggsbabcqggvbwbcqggnbwzcqggoaakcqwgwbgvcqghfly1cqqf8oqbcqggpaqkcqgguaglaaaaaa@5b4e@ 

substituting the formulas for μ  and v  completes the definition of the objective function in terms of the data and model parameters.

these formulas apply to protein sequences, however for dna, apply only when sites are not allowed on the negative dna strand. the more general formulas and derivations for dna sequences allowing sites on either strand are given in the additional file  <dig>  details are also given there of the derivation of the partial derivatives of the objective function required by the local search function, conjugate gradient.

global search
deme applies a two-step approach to identify good starting points for refinement by conjugate gradient. first, substring search is applied to sample all length-w substrings from the positive sequences, where w is the width of the motif. the best strings identified by substring search are used as starting points for "branching search". branching search expands the search space by mutating positions in the substrings independently to generate new strings. we use a heuristic implementation of branching using a fixed size heap. during substring search and each iteration of branching, we score strings using the objective function described below and store the top scoring strings in the heap. the strings in the heap are then used for the next iteration of branching. the size of the heap and the number of branching iterations are user inputs to the algorithm.

during substring and branching search, each string is mapped to a corresponding motif psfm, θm, and the objective function  applied to this psfm is used as the score for the string. for dna sequences, we assume that the string is a sample of size one from a motif distribution, and we use mean posterior estimation  with a uniform dirichlet prior estimate the parameters, θm, of the motif model  <cit> . for protein sequences, we use prior knowledge of amino acid substitution frequencies to map the string to a psfm, as described below.

the string mapping for dna sequences to a motif model is given by

 θm=na,i+βa1+b for a∈Σ,1≤i≤w,
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiigacqwf4oqcdawgaawcbagaemyta0eabeaakiabcufabjabdggahjabcycasiabdmgapjabc2fadjabg2da9maalaaabagaemota40aasbaasqaaiabdggahjabcycasiabdmgapbqabagccqghrawkcqwfyogydawgaawcbagaemyyaegabeaaaoqaaiabigdaxiabgucariabdkeacbaacqqggaaicqqgmbgzcqqgvbwbcqqgybgccqqggaaicqwghbqycqghiiizcqqhjowucqggsaalcqaixaqmcqghkjyocqwgpbqacqghkjyocqwg3bwdcqggsaalaaa@558d@ 

where na,i is equal to one if there is a letter a at position i of the string, or is zero otherwise, the pseudocounts βa are b/ <dig> for all letters a, and b is the "seed prior weight" and is equal to the sum of the pseudocounts. the value of b is an input parameter to deme.

we only use eqn.  <dig> to map dna strings to an initial motif model. to map protein strings, we use probabilities derived from a pam <dig> substitution matrix  <cit> . to create the motif model, we replace each letter in the string with the vector of conditional probabilities of that letter being substituted by each of the other possible letters. if the letter at position i of the string is a, we set θm  = pr for all b ∈ Σ. we do this for each position i in the string. this mapping assigns high probabilities to amino acid substitutions that are assumed more likely to occur a priori.

after the final iteration of branching search, the string with the highest score according to the objective function is converted to a weights matrix, w, and input to the local search algorithm, conjugate gradient. to convert from string space to w space, the string is mapped to a psfm, θm, using one of the two methods just described, and then w is set equal to the logarithm of the psfm.

local search
local search in deme, as in the sharan-segal algorithm, consists of maximizing the objective function  with respect to the model parameters, θ, using conjugate gradient optimization. as discussed below, it is necessary to reparameterize the objective function to avoid solutions where θm and λ assume illegal values. no parameterization of θb or γ is required because they are held constant during conjugate gradient. the value of γ is estimated by deme as the ratio of the numbers of positive and negative sequences in the input dataset. the background model θb is estimated as the frequency of each letter a belonging to the alphabet Σ in the dataset.

each column of θm is the parameters of a discrete distribution, which must all be non-negative and sum to one. so performing optimization directly on θ would require using a constrained optimization method. in order to avoid this, the sharan-segal algorithm reparameterized the objective function in terms of a log odds scoring matrix,

 wa,i=log⁡θmθb,
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaieqacqwfxbwvdawgaawcbagaemyyaemaeiilawiaemyaakgabeaakiabg2da9igbcygasjabc+gavjabcegannaalaaabaaccigae4hude3aasbaasqaaiabd2eanbqabagccqggbbwwcqwghbqycqggsaalcqwgpbqacqggdbqxaeaacqgf4oqcdawgaawcbagaemoqaieabeaakiabcufabjabdggahjabc2fadbaacqggsaalaaa@4792@ 

where wa,i is the log odds score of the letter a at position i in a motif site. it is easy to see that eqn.  <dig>  the average odds score of potential sites in a sequence, can be rewritten using the average log odds score of sites. let

 si=∑j=0w−1wxi+j,j=∑j=0w−1log⁡θmθb
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaafaqadegabaaabagaem4cam3aasbaasqaaiabdmgapbqabagccqgh9aqpdaaewbqaagqabiab=dfaxnaabaaaleaacqwgybawdawgaaadbagaemyaakmaey4kasiaemoaaogabeaaliabcycasiabdqgaqbqabaaabagaemoaaomaeyypa0jaegimaadabagaem4dacnaeyoei0iaegymaedaniabgghildaakeaacqgh9aqpdaaewbqaaigbcygasjabc+gavjabcegannaalaaabaaccigae4hude3aasbaasqaaiabd2eanbqabagccqggbbwwcqwgybawdawgaawcbagaemyaakmaey4kasiaemoaaogabeaakiabcycasiabdqgaqjabc2fadbqaaiab+h7axnaabaaaleaacqwgcbgqaeqaaogaei4waslaemiwag1aasbaasqaaiabdmgapjabgucariabdqgaqbqabagccqggdbqxaaaaleaacqwgqbgacqgh9aqpcqaiwaamaeaacqwg3bwdcqghsislcqaixaqma0gaeyyeiuoaaaaaaa@67ca@ 

be the log odds score of the site starting at position i in sequence x. then, μ can be rewritten as

 μ=1n∑i=1nexp⁡.
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiigacqwf8oqbcqgh9aqpdawcaaqaaiabigdaxaqaaiabd6eaobaadaaewbqaaigbcwgaljabciha4jabcchawjabcicaoiabdohaznaabaaaleaacqwgpbqaaeqaaogaeiykakcaleaacqwgpbqacqgh9aqpcqaixaqmaeaacqwgobgta0gaeyyeiuoakiabc6cauaaa@4220@ 

the sharan-segal algorithm expresses the objective function in terms of w and optimizes the reparameterized function using conjugate gradient, allowing the elements of w to assume any real values . all other parameters are held fixed.

this approach has two shortcomings. firstly, not all values of w correspond to legal values of the motif model parameters, θm, so local search can find maxima that do not correspond to valid data models. therefore, constrained optimization should be applied to prevent w from having values that do not map back to valid motif models. this is mainly a technical objection, since the resulting model may still be quite useful. the second shortcoming is that optimizing the objective function with or without the sharan-segal reparameterization can over-fit the data when there are few positive sequences since no regularization is applied to the motif parameters  to account for small sample sizes.

deme overcomes both of these shortcomings by reparameterizing the objective function differently. our approach is based on analogy with non-discriminative motif discovery methods where the motif model parameters, θm, are estimated from observed counts of letters in a local multiple alignment of  motif sites. mean posterior estimation   <cit>  is then used to estimate the true motif parameters, which involves adding pseudocounts based on a dirichlet  or mixture of dirichlet  prior distribution over the parameters of θm  <cit> . doing mpe reduces the chance of over-fitting small sequence sets and brings to bear prior information about likely protein motif columns that captures the tendency of similar amino acids to substitute for each other in motifs.

rather than defining w to be the log odds scoring matrix  as done by sharan-segal, we think of w as being related to the observed counts of letters in a multiple alignment of motif sites. in order for unconstrained optimization over w to be appropriate, the entries in w must be allowed to assume any real values, so we define a one-way mapping from any w to a valid θm as follows. firstly, deme maps w to an "observed" psfm, f,

 fa,i=exp⁡zi,
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgmbgzdawgaawcbagaemyyaemaeiilawiaemyaakgabeaakiabg2da9maalaaabagagiyzaumaeiieagnaeiicaanaeiikagccbegae83vac1aasbaasqaaiabdggahjabcycasiabdmgapbqabagccqggpaqkaeaacqwgabgwdawgaawcbagaemyaakgabeaaaagccqggsaalaaa@4160@ 

where fa,i is the observed frequency of a letter a in position i, and zi is a normalizing constant for the column i,

 zi=∑aexp⁡.
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgabgwdawgaawcbagaemyaakgabeaakiabg2da9maaqafabagagiyzaumaeiieagnaeiicaanaeiikagccbegae83vac1aasbaasqaaiabdggahjabcycasiabdmgapbqabagccqggpaqkasqaaiabdggahbqab0gaeyyeiuoakiabc6cauaaa@3fbb@ 

it is clear that this mapping always gives a legal psfm. that is, all entries are non-negative and all columns sum to one. it is also one-way, since adding a constant to any column of w gives a new matrix that maps to the same psfm as the old one.

secondly, deme converts the observed frequencies  to "observed counts"  by multiplying by the number of positive sequences predicted to contain a site , where np is the number of positive sequences in the input dataset, yielding

 na,i = λnp·fa,i. 

these first two mapping steps  define the analogy between w and a multiple alignment of motif sites. the final step of the mapping is to compute the motif parameters, θm, using mpe  <cit> . this involves mapping n to θm by adding pseudocounts based on a prior distribution over motif columns, and then normalizing so that each column of θm sums to one. for dna sequences, deme uses a uniform dirichlet prior. where the pseudocounts, αa,i, are all a/ <dig> for dna. the value of a, the "motif prior weight", is an input parameter to deme. for protein sequences, deme estimates the pseudocounts αa,i using a dirichlet mixture prior  <cit> , where the pseudocounts for column i are a function of the observed counts in that column of the alignment  <cit> . the mean posterior estimate of θm is given by

 θm=na,i+αa,iλnp+ai,
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiigacqwf4oqcdawgaawcbagaemyta0eabeaakiabcufabjabdggahjabcycasiabdmgapjabc2fadjabg2da9maalaaabagaemota40aasbaasqaaiabdggahjabcycasiabdmgapbqabagccqghrawkcqwfxoqydawgaawcbagaemyyaemaeiilawiaemyaakgabeaaaoqaaiab=t7asjabd6eaonaabaaaleaacqwgwbacaeqaaogaey4kasiaemyqae0aasbaasqaaiabdmgapbqabaaaaogaeiilawcaaa@4ac8@ 

where ai is the sum of the pseudocounts in column i.

deme also reparameterizes the parameter λ to prevent it from having illegal values. to do this, deme introduces a new variable, wλ, which is defined in terms of the original variable, λ, as

 λ = sig. 

this mapping allows unconstrained optimization over wλ, while ensuring that λ assumes only values in the range zero to one.

discriminative motif discovery problems
we define four synthetic problems for use in evaluating the performance of discriminative motif discovery algorithms such as deme on artificial data. these problems are intended to represent typical applications for motif discovery in dna and protein sequences. we create instances of discriminative motif discovery problems by inserting instances of a motif  into randomly generated sequences. motif instances can be generated according to the so-called "fm" model  <cit> , where motifs are represented as a string of width l and each instance is a fixed number of mutations, d, distant from the motif string. in this work, we introduce a second, novel method of generating motif occurrences based on actual tfbs motifs. using the jaspar database, we create artificial motifs, represented as position-specific frequency matrices, by randomly choosing columns from real motifs. each jaspar column is represented as a frequency vector. the columns are gathered into a single, novel motif. for each position in the artificial motif, the user can specify the information content range for the column. only columns in the jaspar database with information content in the given range are considered when choosing a frequency vector for that position in the motif. motif instances are then created by sampling from the distribution defined by the motif. more details are given in the methods section.

 <dig>  random negative problem: in this problem, the negative sequences contain no useful data, and is included for comparison with the "standard" challenge problem  <cit> . instances of the target motif are planted in the positive sequences only. all non-motif positions are randomly generated using a uniform distribution and a 0-order markov process. this is essentially a non-discriminative motif discovery problem, similar to real applications such as discovering motifs shared by orthologous proteins  <cit> , or detecting novel motifs that may be associated genomic imprinting  <cit> .

 <dig>  decoy motif problem: this problem attempts to model situations where the positive and negative sequences contain one or more motifs in common, but the positive sequences contain an additional, unique motif. a real example of the decoy motif problem is the search for functional promoter elements in the promoter sequences of co-regulated genes, when polyadenylation sites are also over-represented  <cit> . to generate an example of this problem, instances of a decoy motif are planted in both positive and negative sequences. the target motif is planted in the positive sequences only. all planted motifs are non-overlapping and are positioned randomly within the sequences. similar problems have been proposed previously  <cit> .

 <dig>  variant motif problem: this problem models the situation where the positive and negative sequences may be distinguishable only because they contain different variants of the same motif. biological contexts where variant motifs may occur include sequence motifs that affect structural stability  <cit> ; that is, different variants of a motif in orthologous thermophilic and mesophilic proteins that are related to thermostability . another example is the discovery of variant motifs in the binding domains of the haemophilus influenzae hmw <dig> and hmw <dig> proteins which contribute to different binding specificities  <cit> . to create an instance of this type of problem, the target motif is mutated to generate a variant motif. instances of the target motif are planted in the positive sequences, and instances of the variant motif are planted in the negative sequences.

 <dig>  impoverished negative problem: in this problem, the motif is over-represented in the positive sequences and the negative sequences are depleted for the motif. a biological example of the impoverished negative problem might be inferring the binding specificity of tfs from chip-chip data  <cit> , where the bound probe sequences are enriched for the binding motif of the immunoprecipitated tf and the non-binding probe sequences are depleted for the motif . for the impoverished negative problem, the target motif  is planted in the positive sequences only. the negative set is constructed so that there are no substrings in the negative sequences that match the pwm with a p-value less than a specified threshold . similar problems have been proposed previously  <cit>  and used for developing algorithms for discriminative motif discovery.

evaluating deme on synthetic datasets
we first evaluate deme using synthetic datasets. we study its behavior on each of the synthetic problems introduced in the last section. we use these problems to determine the effects of the differences between deme and the sharan-segal algorithm and to compare deme with a non-discriminative motif discovery algorithm. in particular, we study the effects of and determine default settings the two parameters a and b, referred to as the "motif prior weight" and "seed prior weight", as well as the size of the heap and number of iterations of branching search to perform.  because the challenge problems plant motif sites in all positive sequences, deme is run using the oops data model in each of the experiments described in this section.

local search: effect of the bayesian motif prior
one of the ways our method differs from the sharan-segal algorithm is that we incorporate a bayesian prior on motif columns in order to avoid over-fitting during local search using conjugate gradient. to test the effectiveness of this approach, we measure the accuracy of predicted motifs as a function of the size of the prior. for these tests, we use the the random negative problem, and run only the local search component of deme, conjugate gradient. this allows us to isolate the contribution of the bayesian motif prior to the accuracy of motif discovery by deme.

using the bayesian motif prior results in a substantial improvement in the accuracy of the motif models learned by conjugate gradient on dna datasets containing planted fm motifs . with fm motifs, values of a  smaller than eight resulted in less accurate prediction of planted motifs sites  and much less accurate prediction of motif sites and sequence class . this is a strong indication that conjugate gradient over-fits the data when the motifs are fm-like. the extreme case is when a =  <dig>  which is similar to the sharan-segal use of conjugate gradient. in this case, pc for the training set for fm motifs is  <dig>  while pc for the test set is  <dig>  and test set acc is  <dig> , compared with training set pc of  <dig> , test set pc of  <dig>  and acc of  <dig>  when the optimal value of the motif prior is applied. similarly, training and test set pc for psfm motifs are  <dig>  and  <dig>  respectively and test set acc is  <dig> , compared with training set pc of  <dig> , test set pc of  <dig>  and acc of  <dig>  for the optimal motif prior weight.

the effect of the size of the bayesian motif prior is very large with fm motifs compared with psfm motifs. test set accuracy using psfm motifs peaks when the motif prior weight is about  <dig>  . the increase in accuracy compared with using no prior  is small, however, which indicates that the there is less over-fitting of the data by conjugate gradient when the motif sites are generated by the arguably more natural psfm model.

in the experiments reported in fig.  <dig>  the seed for conjugate gradient is the consensus of the target motif; the fm consensus string, or the string with the largest probability given the psfm. in mapping the seed to a starting point  for conjugate gradient, we set the seed prior weight, b, to  <dig>  in eqn.  <dig>  we also examined values of the seed prior weight in the range , but found that the value of b has very little effect in this setting .  similar results are also obtained when the seed used to initialize θm for conjugate gradient is hamming-distance four from the target motif . there is, however, an overall decline in the accuracy of the motifs found by conjugate gradient started from these less accurate seeds.

global search: effect of seed prior, heap size and branching
deme's global search algorithm has several tunable parameters. in this section we use the discriminative motif discovery problems to explore their affect on the accuracy of motifs discovered by deme. in contrast to the previous section, the experiments here test the entire deme algorithm, not just the local or global search components. the results, therefore, illustrate the performance of deme on the various synthetic problems.

the seed prior weight, b , directly affects the objective function optimized by deme during global search. thus, b affects which string motif is chosen by deme for refinement using local search, strongly influencing the final motif chosen by deme. fig.  <dig> illustrates the effect of b on the performance of deme for the random negative and decoy motif problems using both fm and psfm motifs. in all cases, the training set pc, test set pc and test set acc measures give similar pictures of deme's variation in accuracy in response to b. deme performs well with values of b smaller than  <dig>  on both fm and psfm motifs in the random negative problem, and with psfm motifs in the decoy motif problem . however, deme often fails to discover the true motif in the fm decoy motif problem when b is less than  <dig>  . this is due to the global search objective function giving a higher score to sites of the decoy motif compared with the true motif when b is small. this effect is absent with the psfm decoy motif problem, where a very small value of b,  <dig> , works best. thus, using b =  <dig>  seems to be a good compromise, giving optimal or nearly optimal accuracy for all problems except the fm decoy motif problem. of course, if the motifs in a real dataset are believed to be fm-like, a value of b of  <dig>  would be appropriate.

the ability of deme to discover good seeds during global search also depends on the size of the heap and the number of iterations of branching search it performs. in the experiments reported in fig.  <dig>  the heap size is  <dig> and the number of branching iterations is six. these were chosen by repeating the experiments in the figure using all combinations of heap size, h, and number of branching iterations, i, chosen from the sets using all combinations of h and i where h ∈ { <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>  256} i ∈ { <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>  10}. with fm motifs, the accuracy of the motifs discovered by deme increases with heap size, where there is only a small improvement in performance when the heap size is larger than  <dig>  for heap sizes of  <dig>  we find that performance plateaus after five iterations of branching. for the psfm motif problem, branching does not have a large effect on performance . therefore, we use six iterations of branching using a heap size of  <dig> for all subsequent experiments.

performance comparison with non-discriminative motif discovery
the fm random negative problem is essentially identical to the well-studied fm challenge problem  <cit>  for non-discriminative motif discovery. the performance of deme on this problem for various numbers of mutations in the planted motif of width  <dig> is shown in fig. 4a. for comparison, we show the performance of meme on the just the positive sequences. deme effectively discovers planted sites that contain up to four mutations, whereas meme fails to discover planted sites that contain more than three mutations. the performance of deme on the  fm random negative problem  is comparable to the performance reported for projection  <cit>   and winnower  <cit>  . these algorithms were specifically designed to solve the fm challenge problem, as was the branching search algorithm, on which deme's global search algorithm is based. the performance of both deme and projection declines significantly on the  problem, where the performance coefficient for these algorithms is  <dig>  and  <dig>  respectively. it is not surprising that the performance of these algorithms are poor on the  problem, since it is expected that the positive dataset contains spurious motifs that are as "strong" as the planted motif  <cit> .

the decoy motif problem is specifically designed to show the ability of discriminative motif discovery algorithms to find motifs that discriminate between the positive and negative sequences when the two groups of sequences share common motifs. fig. 4b shows the performance of deme and meme on the fm decoy motif problem. in this experiment, one exact copy of a length- <dig> string  is planted in each of the positive and negative sequences. the results show that deme effectively discovers the target motif in the presence of the decoy, whereas the non-discriminative meme algorithm does not. deme's performance on the decoy motif problem is similar to the simpler random negative problem when the planted fm motif occurrences contain up to three mutations, and is slightly poorer when there are four mutations. meme finds the decoy motif 50% of the time when the target motif sites have the same number of mutations  as the decoy motif. meme almost always finds the decoy motif if the target sites have more mutations-one or more .

the variant motif problem examines the ability of discriminative motif discovery algorithms to find motifs in the positive sequences when there is a variant of the motif in the negative sequences. fig. 4c shows the performance of deme and meme on the fm variant motif problem. in this experiment, the variant motif was generated by mutating exactly four positions in the length- <dig> target motif. instances of the target motif are planted in the positive sequences while instances of the variant motif are planted in the negative sequences. the same number of positions in the target and variant motifs are mutated to generate the planted motif instances. the results show that the performance of deme on the variant motif problem is similar to the performance of deme on the random negative problem, suggesting that deme is sensitive to subtle differences between the positive and negative sequences. since meme is trained using the positive set only, the performance of meme on this problem is the same as for the random negative problem.

the impoverished negative problem is targeted at illustrating the ability of discriminative motif finders to find motifs that are over-represented in the positive dataset relative to the negative dataset. fig. 4d shows that deme does not outperform meme on the psfm impoverished negative problem when the negative dataset has the same number of sequences as the positive dataset . deme performs slightly worse than meme when the sequences are long . for comparison, fig. 4d also shows the performance of deme on the same positive datasets when the negative datasets contain random sequences . in this case, deme's performance is considerably worse, showing that it is benefiting from the relative impoverishment in motif sites of the negative dataset in the psfm impoverished negative problem. it is evident that the choice of negative set has a significant effect on the performance of deme, where the best performance is achieved using an impoverished negative set.

evaluating deme on biological datasets
in this section, we evaluate the ability of deme to discover motifs in real biological datasets. we test on both dna and protein datasets, and compare with using a non-discriminative motif discovery algorithm. because real biological datasets often are "noisy", deme is run using the noops data model in each of the experiments described in this section.

discovery of yeast transcription factor binding motifs
we evaluate the ability of deme to discover yeast transcription factor binding motifs from the chip-chip data reported in  <cit> . for each experiment, we define the positive training set as the set of probe sequences found to bind the immunoprecipitated transcription factor. for each positive training set, we run two independent experiments. the first experiment uses random negative sequences, where sequences of the negative set are generated by shuffling the letters in the sequences of the positive set. the second experiment uses randomly selected non-binding probe sequences as the negative set . the positive and negative set contain the same number of sequences when shuffled sequences are used as the negative set, whereas the negative set contains twice as many sequences as the positive set when non-binding probe sequences are used as negative examples. for each experiment we compare the discovered motif to an experimentally determined reference motif for the corresponding transcription factor.

for each experiment, we apply the default value for the motif prior weight and seed prior weight . the noops model was applied and both dna strands were searched. in this experiment, it is assumed that the motif width is known a priori and, therefore, the motif width specified to deme is the width of the corresponding reference motif.

for comparison, meme  was also applied to each positive dataset. meme was run using the zoops sequence model and both dna strands were searched. meme was run twice; once using a 0-order background model and once using a fifth-order background model of yeast intergenic regions. only one motif was reported by each run of meme and deme.

we found that deme is effective for discovering transcription factor binding motifs from chip-chip data . when non-binding probe sequences are used as the negative set, deme discovers the binding motif for  <dig> transcription factors. in contrast, when random negative sequences are used , deme discovers the binding motif for only three transcription factors. when random negative sequences are used as the negative set, deme frequently discovers poly and poly motifs, which are known to be common in yeast intergenic regions  <cit> . this result suggests that it is important to select appropriate negative sequences according to the hypothesis being tested.

the first column is the transcription factor name followed by the results for deme and meme. deme is run using randomly shuffled positive sequences  or non-binding probes  as negative sequences. meme is run using a 0-order or a 5th-order background model. an 'x' indicates a match between the discovered motif and the reference motif. results are shown for transcription factors where the reference motif was discovered in at least one deme or meme experiment. the last row shows the total number of motifs discovered by each algorithm .

using an informative negative sequence set, deme can outperform the non-discriminative motif finder meme. with a zero-order background model, meme discovers the binding motif for only eight transcription factors. however, meme performs just as well as deme when provided with a fifth-order background model based on all yeast intergenic regions, in that case, meme discovers the reference motif for  <dig> transcription factors .

it should be noted that our results for the meme experiments  do not reproduce the results of harbison et al.  <cit>  exactly. that is, compared to the results published in  <cit> , we report that meme discovers the binding motifs for an additional two transcription factors . since meme was run using the same parameters, it is likely that this difference is attributed to different distance metrics used to detect a match between the discovered motif and the reference motif. in our experiment, the consensus of the discovered gcr <dig> motif is "ccagcttcc" . the published binding specificity for gcr <dig> is "ggcttccwc". similarly, the consensus of the pho <dig> motif discovered using meme is "acccaccttgtc" , where the pho <dig> consensus is "nnvcacgtrbgn". the strong statistical support reported by tomtom and the similarity between the discovered and reference consensus sequence suggests that meme has discovered the gcr <dig> and pho <dig> motifs.

the ability of deme to discover transcription factor binding motifs from chip-chip data is comparable to meme and to other motif discovery algorithms  <cit> . in combination, both meme and deme discover the binding motifs for  <dig> transcription factors. the binding motifs for the remaining nine transcription factors were also not discovered by any of the six  motif discovery algorithms tested by harbison et al.  <cit> .

discovery of motifs in thermophilic and mesophilic proteins
as another illustration of the usefulness of deme, we applied it to the problem of discovering motifs that distinguish between orthologous proteins in thermophilic and mesophilic organisms. a lack of novel thermophilic proteins was observed by la et al.  <cit>  which suggests that conserved mutations between orthologous mesophilic and thermophilic proteins might be related to increased thermostability. la et al.  <cit>  applied meme, a non-discriminative motif discovery algorithm, to discover evolutionary conserved differences that distinguish thermophilic proteins from mesophilic proteins. although successful, this approach is clearly not optimal when the goal is to find motifs that are specifically responsible, or at least strongly correlated with a biological property such as thermal stability. in such a case, a direct, discriminative motif discovery approach using an algorithm such as deme seems preferable.

we applied deme to the tata-box binding protein dataset reported in la et al.  <cit> . the dataset consists of one tata-box binding protein from each of eight thermophilic microorganisms, and a total of twelve proteins from two mesophilic microorganisms . la et al.  <cit>  used these same two sets of proteins to illustrate a two-step method of finding discriminative protein motifs. they first find motifs using a non-discriminative algorithm , and then filter the motifs, looking for ones that can discriminate the thermophilic set of proteins from the mesophilic proteins.

to compare deme with the results of la et al.  <cit> , we ran deme twice, using one of the sets of proteins, thermophilic or mesophilic, as the positive set, and the other as the negative set. for each run of deme, we created two sequence logos  <cit> , showing the residue preferences of the sites that best match the motif discovered by deme in the positive and negative sequences, respectively.  we ran deme using its default settings and a motif width of  <dig>  the relative heights of the letters in a logo are proportional to the number of times that letter occurs in the aligned sites, and the total heights of the letters equals the information content of the frequencies.

deme finds highly discriminating motifs when either set of sequences  is used as the positive set. using the thermophilic sequences as the positive set, deme finds a motif that identifies a region of the tata-box binding protein that is differentially conserved between the two environments . in other words, the motif corresponds to a location in the multiple alignment of all the proteins where there is a strongly conserved but distinct preference for certain residues in the thermophilic compared with the mesophilic proteins. the motif found by deme motif corresponds to the most highly differentially conserved region in the motif found by la et al.  <cit> . the sites identified by the deme motif show a very strong preference for the salt-bridge-forming residues arginine  and lysine  in the thermophilic organisms. these two residues are the most common residue in five out of  <dig> positions in the thermophilic sites, and are known to enhance thermal stability in proteins. the thermophilic sites also show a very strong preference for isoleucine  and valine , two residues hypothesized by la et al.  <cit>  to promote thermal stability via beta-sheet formation and lower side-chain entropies. these residues  are only very weakly preferred in six columns in the sites in the mesophilic sequences; the difference the prevalence of lysine  is particularly noticeable.

with the roles of the two sequence sets reversed, deme discovers a different motif . the sites in the thermophilic proteins once again show a high preference for salt-bridge-forming residues and the beta-sheet enhancing residues. in this case, the thermophilic sites show a marked preference for glutamate , which can form salt-bridges, compared with the mesophilic sites. glutamate is the most common residue in six out of twenty motif thermophilic site positions. in total, eight thermophilic site positions are dominated by salt-bridge-forming residues  and three columns show a preference for beta-sheet enhancing residues . the corresponding counts are two  and one  dominated columns in the mesophilic sites. these differences show that, in both experiments, deme has discovered motifs that identify biologically relevant features distinguishing the positive and negative sequence sets.

CONCLUSIONS
motif discovery in biological sequences is an important but difficult problem. we have shown using real and artificial datasets that deme is very well suited to finding discriminative motifs in situations where decoy motifs are present in the positive and negative datasets, or when variant motifs are present in the negative dataset. we have also demonstrated that the use of a bayesian motif prior, made possible by a novel reparameterizing of the sharan-segal objective function, can give superior accuracy in dna motif discovery contexts.

one of the novelties of our work is the development of a general-purpose discriminative motif discovery algorithm for protein as well as dna. recognizing the serious problem with over-fitting of motif models in small protein datasets, lehrach et al.  <cit>  used an uninformative, laplacian prior to regularize the sharan-segal model in a special-purpose application  we believe that deme is unique among discriminative motif finders in its use of mixture of dirichlet priors for protein motifs, which previous work on non-discriminative motif discovery with protein datasets  <cit>  has shown to be extremely effective at both reducing over-fitting and at improving the accuracy of motif discovery.

for the yeast tfbs motif discovery problem, deme performs as well as non-discriminative motif discovery algorithms. some non-discriminative motif discovery algorithms  can utilize much of the same negative information present in a set of non-binding probes by using a higher-order markov background sequence model. this probably explains the inability of deme to outperform meme on this problem.

the protein motifs discovered by deme in the mesophilic/thermophilic organism experiment are much more focused and descriptive than the motifs discovered using a non-discriminative approach by la et al.  <cit> . this task is very similar to the variant motif problem, and deme performs very well on it.

the paper on the alse  <cit>  algorithm compares a discriminative pwm-based method  to a string-based method  and to meme. the test case was discovering tfbss in promoters of various organisms. their results indicate that alse may be superior to seedsearch and is definitely superior to meme. however, in this work meme uses a 0-order background model, which we have shown  greatly decreases its performance on this task. it is, therefore, not clear that alse is superior to meme  on this task. because deme failed to show a marked superiority on the yeast tfbs discovery task , we did not pursue this question further.

while deme has many parameters, we have shown that the default parameter settings are effective for discovering biologically significant motifs. the default parameters were determined using the synthetic problems and were found to work very well on the real dna and protein problems. with the exception of optional parameters , the only parameter that the user must specify is the motif width. the ideal width can be determined by a combination of the user's knowledge of the type of motif being sought and trial-and-error.

currently, deme is not optimised for speed. the time complexity of substring search is, as currently implemented in deme, is

 o), 

where n+ and n- are the number of length w substrings in the sequences in the positive and negative datasets, respectively. the quadratic dependency on the size of the positive sequence set could be reduced to a linear dependency using dynamic programming techniques similar to those used by meme. the time complexity for pattern branching is

 o·), 

where i is the number of branching iterations and h is the heap size. the quadratic dependency on motif width could be reduced to a linear dependency using dynamic programming. the time complexity for local search is

 o) 

per iteration of conjugate gradient. it is not clear at this point how to improve on the time complexity of local search, but, fortunately, it is only linear in the size of the sequences and the motif width.

the running time for deme on the chip-chip data reported here ranges from  <dig>  seconds for the smallest dataset  using a motif width of six) to three hours for the largest dataset . here, deme is run on a processor with a  <dig>  ghz cpu and  <dig> gb memory.

for many applications, such as chip-chip datasets, there is an excess of negative sequences. we used a typical chip-chip dataset to examine the effect of the number of negative sequences on the running time of deme. the positive set contained  <dig> probe sequences with an average length of  <dig> bp that gcn <dig> binds . we found that the running time of deme increases linearly as the number of negative sequences increases , as we would expect from the complexity calculations above . the running time of deme is dominated by global search, where for the datasets examined here, less than  <dig> % of the cpu time is used in local search. therefore, the efficiency of deme can be greatly improved by optimising the global search algorithm.

currently, deme can only find one motif in a given dataset. in order to find multiple motifs, it could be extended in a fashion analogous to the meme algorithm to find multiple motifs  <cit> . this can be done by probabilistically "erasing" the predicted sites of a discovered motif, and then repeating the global and local search steps of deme to discover subsequent motifs. another possible future enhancement would be having deme discover the "optimum" motif width.

