BACKGROUND
analysis and interpretation of biological sequence data is a fundamental task in bioinformatics. classification and prediction techniques are one way to deal with such task  <cit> . in fact, biologists are often interested in identifying the family to which a lately sequenced protein belongs  <cit> . this makes it possible to study the evolution of this protein and to discover its biological functions. furthermore, the study and the prediction of oligomeric proteins  are very useful in biology and medicine for many reasons  <cit> . indeed, they often intervene in terms of bio-macromolecules functional evolution, reparation of misfolds and defects  <cit> . they are also involved in many important biological processes such as chromosome replication, signal transduction, folding pathway and metabolism  <cit> . biologists also seek, for instance, to identify active sites in proteins and enzymes  <cit> , to classify parts of dna sequences into coding or non-coding zones or to determine the function of the nucleic sequences such as the identification of the promoter sites and the junction sites  <cit> .

alignment is the main technique used by biologists to look for homology among sequences, and hence to classify new sequences into already known families/classes. since relevant information is represented by strings of characters, this technique generally doesn't enable the use of well-known classification techniques such as decision trees , naïve bayes , support vector machines  and nearest neighbour  which have proved to be very efficient in real data mining tasks  <cit> . in fact, those classifiers rely on data described in a relational format.

meanwhile, different studies have been devoted to motif extraction in biological sequences  <cit> . motifs extraction methods are generally based on the assumption that the significant regions are better preserved during the evolution because of their importance in terms of structure and/or function of the molecule  <cit> , and thus that they appear more frequently than it is expected.

in  <cit> , authors have shown that motif extraction methods can efficiently contribute to the use of machine learning algorithms for the classification of biological sequences. in this case, the classification obeys the knowledge discovery in data  process and hence comprises three major steps:

 <dig>  preprocessing consists of extracting motifs from a set of sequences. these motifs will be used as attributes/features to construct a binary table where each row corresponds to sequence. the presence or the absence of an attribute in a sequence is respectively denoted by  <dig> or  <dig>  this binary table is called a learning context. it represents the result of the preprocessing step and the new sequence encoding format .

 <dig>  in the mining step, a classifier is applied to the learning context to generate a classification model.

 <dig>  the latter model is used to classify other sequences in the post-processing step. these sequences are also encoded into a relational format using the same features as for the learning context i.e., test context.

in a previous work  <cit> , we proposed a new method to encode protein sequences. it extends an existing method, termed discriminative descriptors   <cit> , by taking into account the fact that some amino acids have similar properties and thus can be substituted by each other while changing neither the structure nor the function of the protein  <cit> . hence, there might be several motifs that could be replaced by a single motif. we used amino acids substitution matrices to define such similarity; our encoding method is termed discriminative descriptors with substitution matrix . preliminary experiments conducted with c <dig>  decision tree have shown promising results  <cit> . this manuscript presents a detailed experimental comparison  between several encoding methods using various kinds of classifiers  as well as the standard approach based on alignment using blast  <cit> .

methods and 
RESULTS
some existing feature construction methods
the following is a presentation of five existing methods of features construction: the n-grams , the active motifs , the amino acid composition , the functional domain composition  and the discriminative descriptors . after this, we re-describe our approach which consists of modifying the dd method by the use of a substitution matrix   <cit> .

n-grams
the simplest approach is that of the n-grams, known also as n-words or length n fenestration  <cit> . the motifs to be built have a predefined length. the n-gram is a subsequence composed of n characters, extracted from a larger sequence. for a given sequence, the set of the n-grams which can be generated is obtained by sliding a window of n characters on the whole sequence. this movement is carried out character by character. with each movement a subsequence of n characters is extracted. this process is repeated for all the analyzed sequences. then, only the distinct n-grams are kept.

active motifs
this method allows extracting the commonly occurring motifs whose lengths are longer than a specified length, called active motifs, in a set of biological sequences. the activity of a motif is the number of matching sequences given an allowed number of mutations  <cit> . the motif extraction is based on the construction of a generalized suffix tree  which is an extension of the suffix tree  <cit>  and is dedicated to represent a set of n sequences indexed each one by i =  <dig> .n.

amino acid composition
according to the classic definition of this method, the feature set consists of  <dig> components, representing the  <dig> native amino acids in proteins. the amino acid composition refers to the occurrence frequency of each of these  <dig> components in a given protein. since the information in the primary sequence is greatly reduced by considering the amino acid composition alone, other considerations have been taken into account within several studies such as the sequence-order correlation factors i.e., new features were added to the  <dig> original which yielded several aac variants  <cit> .

functional domain composition
biological databases, such as pfam  <cit>  and astral, contain large collections of multiple sequence alignments and hidden markov model  profiles covering many common protein domains and families  <cit> . functional domains are determined using computational means, especially hmm profiles, combined with biologist knowledge and other databases information. since they allow variable length gaps between several components, where each component is a simple motif  <cit> , functional domains can be considered as structured motifs. but they are more reliable since they obey the expert assessment.

descriminative descriptors
given a set of n sequences, assigned to p families/classes f <dig>  f <dig> .., fp, this method consists of building substrings called discriminative descriptors dd which allow to discriminate a family fi from other families fj, with i =  <dig> .p and i ≠ j  <cit> .

this method is based on an adaptation of the karp, miller and rosenberg  algorithm  <cit> . this algorithm identifies the repeats in character strings, trees or tables. the extracted repeats are then filtered in order to keep only the discriminative and minimal ones.

a substring x is considered to be discriminative between the family fi and the other families fj, with i =  <dig> .p, j =  <dig> .p and i ≠ j if:

 <dig>  

 <dig>  

where α and β are user-specified thresholds between  <dig> and  <dig> 

proposed method: discriminative descriptors with substitution matrix
in the case of protein, the discriminative descriptors method neglects the fact that some amino acids have similar properties and that they can be therefore substituted by each other while changing neither the structure nor the function of the protein  <cit> . indeed, we can find several motifs in the set of the attributes generated by the dd method, which are similar and can derive all from a single motif. in the same way, during the construction of the context , we are likely to lose information when we denote by  <dig> the absence of a motif while another one, that can replace it, already exists  <cit> .

as mentioned, the similarity between motifs is based on the similarity between the amino acids which constitute them. indeed, there are various degrees of similarity between amino acids. since there are  <dig> amino acids, the mutations between them are scored by a  <dig> ×  <dig> matrix called a substitution matrix  <cit> .

terminology
let  be a set of n motifs, denoted each one by  , p =  <dig> . n.  can be divided into m clusters. each cluster contains a main motif m* and probably other motifs which can be substituted by m*. the main motif is the one which has the highest probability of mutating to another in its cluster. for a motif m of k amino acids, this probability, noted pm, is based on the probability pi that each amino acid m  of the motif m does not mutate to any other amino acid. we have:  

pi is calculated based on the substitution matrix according to the following formula:  

s is the substitution score of the amino acid y by the amino acid x as it appears in the substitution matrix. s+ indicates a positive substitution score. aaj is the amino acid of index j among the  <dig> amino acids.

for our purposes, a motif m substitutes a motif m' if:

 <dig>  m and m' have the same length k,

 <dig>  s > =  <dig>  i =  <dig> .. k,

 <dig>  sp > = t, where t is a user-specified threshold such that  <dig> < = t < =  <dig> 

we denote by sp the substitution probability of the motif m' by the motif m having the same length k. it measures the possibility that m mutates to m':  

sm  is the substitution score of the motif y by the motif x. it is computed according to the following formula:  

it is clear, according to any substitution matrix, that there is only one best motif which can substitute a motif m. it is obviously itself, since the amino acids which constitute it are better substituted by themselves. this proves that the substitution probability of a motif by another one, if they satisfy the substitution conditions, will be between  <dig> and  <dig> 

methodology
the encoding method is composed to two parts. first, the number of extracted motifs will obviously be reduced because we will keep only one motif for each cluster of substitutable motifs of the same length. second, we will modify the context construction rule. indeed, we will denote by  <dig> the presence of a motif or of one of its substitutes. the first part can be also divided into two phases:  identifying clusters' main motifs and  filtering.  the main motif of a cluster is the one that is the most likely to mutate to another in its cluster. to identify all the main motifs, we sort  in a descending order by motif lengths, and then by pm. for each motif m' of , we look for the motif m which can substitute m' and that has the highest pm . the clustering is based on the computing of the substitution probability between motifs. we can find a motif which belongs to more than one cluster. in this case, it must be the main motif of one of them.  the filtering consists of keeping only the main motifs and removing all the other substitutable ones. the result is a smaller set of motifs which can represent the same information as the initial set.

example
given a blosum <dig> substitution matrix and the following set of motifs  sorted by their lengths and pm, we assign each motif to a cluster represented by its main motif. we get  <dig> clusters illustrated by the diagram shown in figure  <dig> 

 is a set of motifs  sorted by their lengths and pm. the third row shows the cluster main motifs.

experimental environment
ng, am, dd and ddsm encoding methods are implemented in c language and gathered into a dll library . the accepted format of the input files is the fasta format for biological sequences files. the library code that we have implemented generates relational files under various formats such as the arff format used by the workbench weka  <cit>  and the dat format used by the system disclass  <cit> .

our experiments are divided into  <dig> parts. in the first one, we make a detailed comparison between ng, am, dd and ddsm encoding methods to confirm the results obtained in  <cit> . we perform the sequence classification using dt, svm, nb and nn algorithms as described in section  <dig>  we also conducted classification experiments using blast  <cit>  i.e., we assign to a protein query the class with the best hit score. our method  constructs the features using the substitution matrix blosum <dig>  the choice of this substitution matrix is not based on preliminary experiments, but instead on the fact that it is the most used by alignment tools especially the widespread blast. we examine three aspects:

 <dig>  the effect of each encoding method on the four classifiers to deduce which one is the best in terms of accuracy and number of generated attributes.

 <dig>  the comparison of the four classifiers while varying the encoding methods.

 <dig>  the comparison with blast results.

in the second part, we try to assess the effect of varying the substitution matrices on our method and on the classification quality and hence to determine whether there is a substitution matrix which could be recommended. then we compare our feature-construction method with other ones presented in  <cit> , which means that we compare with nine related works  <cit> .

part 1
to perform our experiments, we use  <dig> datasets comprising  <dig> protein sequences from swiss-prot  <cit>  and scop  <cit>  described in table  <dig> .

we try to conduct our experiments on various kinds of datasets. these datasets differ from one another in terms of size, number of class, class distribution, complexity and sequence identity percentage. the first dataset ds <dig> contains  <dig> distinct and distant protein families. we suppose that classification in this case will be relatively easy since each family will probably have preserved patterns which are different from those of other families  <cit> . ds <dig> represents a bigger dataset comprising two sub-families of protein sequences belonging to the rhodopsin like/peptide family. however, the datasets ds <dig> and ds <dig> present more difficult classification problems. ds <dig> contains seven classes that represent seven categories of quaternary  protein structure with a sequence identity of 25%. the problem here lies in recognizing the 4d structure category from the primary structure. in this case, an important question is to be answered: does the primary structure contain sufficient information to identify the 4d structure? the task relative to ds <dig> is that of distinguishing between the human toll-like receptors  protein sequences and the non-human ones. the difficulty is due to the structural and functional similarity of the two groups. the choice of this dataset came after biologists of pasteur institute of tunis  asked to help them in identifying tlr families especially human ones among the  <dig> tlr that exist. ds <dig> consists of  <dig> domains:  <dig> all-α domains,  <dig> all-β domains,  <dig> α/β domains, and  <dig> α+β domains from scop  <cit> . this challenging dataset was constructed by zhou  <cit>  and has been extensively used to address structural class prediction  <cit> .

part 2
in this part, we consider again the datasets ds <dig>  ds <dig> and ds <dig> since they are considered to be delicate classification tasks and can thus reveal valuable information about the efficiency of the classifiers and the feature-construction methods. we try to investigate the effect of the substitution matrices variation on the quality of our encoding method and hence on the classification quality using c <dig> , svm, nb and nn algorithms. we employ all the substitution matrices used by the standalone version of blast and belonging to the two well-known families: blosum  <cit>  and pam  <cit>  i.e., blosum <dig>  blosum <dig> blosum <dig>  pam <dig>  pam <dig>  pam  <dig> 

since ds <dig> is the same dataset as in  <cit> , these experiments allow us to compare our encoding method with other related ones presented in that paper, where the nearest neighbour algorithm nn was coupled with each of the following methods: functional domain composition fdc, amino acid composition aac and blast alignment tool  <cit> , to predict the quaternary structures categories of the proteins. in fact, the investigation of the quaternary structures prediction using computational tools remains a task with important implications for many reasons. first, these structures are involved in many biological processes and have direct link with known diseases like sickle-cell anaemia. second, the in vitro methods are very slow and costly in spite of being accurate. this comparison allows us to assess whether our feature-construction method could offer any benefits over the above-mentioned methods quoted in  <cit>  while using the same classifier  and learning technique .

since prior information on the structure of a protein can provide useful information about its function, many other works similar to  <cit>  have investigated this topic  <cit> . these works often use kinds of amino acid composition or functional domain composition to deal with the prediction of oligomeric proteins or protein structural classes. ds <dig> represents a challenging dataset that has been extensively used to address structural class prediction  <cit> . this allows us to compare our method with several works existing in the literature.

discussion and 
CONCLUSIONS
experimental techniques
the computations are carried out on a computer with an intel centrino  <dig>  ghz cpu and 1go of main memory. results are shown in the next sub-sections tables. best accuracies, for each dataset, are shown in bold and results below minimum accepted values results are underlined. the minimum accepted value  is obtained by assigning all the sequences of a dataset to its biggest class. hence, we have 35%, 50%,  <dig> %, 65% and  <dig> % as mavs respectively for ds <dig>  ds <dig>  ds <dig>  ds <dig> and ds <dig>  we also show the number of attributes generated by each method.

in the classification process, we use the leave-one-out technique  <cit>  also known as jack-knife test. for each dataset , only one instance is kept for the test and the remaining part is used for the training. this action is repeated n times. the leave-one-out is considered to be the most objective test technique compared to the other ones i.e., hold-out, n-cross-validation. indeed the leave-one-out test allows to obtain the same classification results regardless of the number of runs, which is not the case for the other tests . for the encoding methods, we use default parameters as in  <cit> : ng , am , dd and ddsm , ddsm . these parameters can also be specified by users.

we recall that in part  <dig>  we use the following classifiers: c <dig>  decision tree, support vector machine svm, naïve bayes nb and nearest neighbour algorithm nn of the workbench weka  <cit> . we generate and test the classification models; then we report the classification accuracy . moreover, we conducted the leave-one-out test on the same datasets using blast as already explained in section  <dig> . in part  <dig>  we investigate any potential effect of the substitution matrix variance on the features building and the classification quality, and then we compare it with other classification systems quoted in  <cit> .

part  <dig> 
