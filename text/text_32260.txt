BACKGROUND
a growing number of leading institutions now routinely utilize digital imaging technologies to support investigative research and routine diagnostic procedures. the exponential rate at which images and videos are being generated has resulted in a significant need for efficient content-based image retrieval  methods, which allow one to quickly characterize and locate images in large collections based upon the features of a given query image. cbir has been one of the most active research areas in a wide spectrum of imaging informatics fields over the past few decades
. several domains stand to benefit from the use of cbir including cinematography, education, investigative basic and clinical research, and the practice of medicine. cbir has been successfully utilized in applications spanning radiology
 <cit> , pathology
, dermatology
 <cit> , and cytology
.

there have been several successful cbir systems that have been developed for medical applications since the 1980’s. several approaches utilize simple features such as color histograms
 <cit> , shape
 <cit> , texture
 <cit> , or fuzzy features
 <cit>  to characterize the content of images while allowing higher level diagnostic abstractions based on systematic queries
. the recent adoption and popularity of case-based reasoning
 <cit>  and evidence-based medicine
 <cit>  has created a compelling need for more reliable image retrieval strategies to support diagnostic decisions. in fact, a number of state-of-the-art cbir systems
 have been designed to support the processing of queries across imaging modalities.

with the advent of whole-slide imaging technology, the size and scale of image-based data has grown tremendously, making it impractical to perform matching operations across an entire image dataset using traditional methods. to meet this challenge, a new family of strategies are being developed, which enable investigators to perform sub-region searching to automatically identify image patches that exhibit patterns that are consistent with a given query patch. in practice, this approach makes it possible to select a region or object of interest within a digitized specimen as a query while the algorithm systematically identifies regions exhibiting similar characteristics in either the same specimen or across disparate specimens. the results can then be used to draw comparisons among patient samples in order to make informed decisions regarding likely prognoses and most appropriate treatment regimens.

to perform a region-of-interest  query, vu et al.
 <cit>  presented a sam match framework-based similarity model. the use of a part-based approach was later reported in
 <cit>  to solve the cbir problem by synthesizing a dog detector, and a local hashing table search algorithm. the primary limitation of this approach, however, was the time cost of the large number of features that need to be computed. intra-expansion and inter-expansion strategies were later developed to boost the hash-based search quality based on a bag-of-features model which could more accurately represent the images. recently, a structured visual search method was developed to perform cbir in medical image datasets
 <cit> . the primary advantage of this framework is that it is flexible and can be quickly extended to other modalities.

most cbir algorithms rely on content localization, feature extraction, and user feedback steps
. the retrieved results are then ranked by some criteria, such as appearance similarity or diagnostic relevance, which can also serve as a measure of the practical usability of the algorithm. typically the retrieved images only include those cases with the most similar appearance to a given query image whereas introducing relevance feedback
 to cbir provides a practical means for addressing the semantic gap between visual and semantic similarity.

large-scale image retrieval applications are generally computationally expensive. in this paper, we present the use of the cometcloud
 <cit>  to execute cbir in a parallel fashion on multiple high performance computing  and cloud resources as a means for reducing computational time significantly. cometcloud is an autonomic cloud framework that allows dynamic, on-demand federation of distributed infrastructures. it also provides an effective programming platform that supports mapreduce, workflow, and master-worker/bot models making it possible for investigators to quickly develop applications that can run across the federated resources
. the algorithm that our team developed exploits the parallelism of cbir by combining the hpc assets at rutgers university with external cloud resources. moreover, our solution uses cloud abstractions to federate resources elastically to achieve acceleration, while hiding infrastructure and deployment details. in this way, the cbir algorithm can be made available as accessible services to end users.

the contributions of this paper are: 1) a novel cbir algorithm based on a newly developed coarse-to-fine searching criteria which is coupled with a novel feature called hierarchical annular histogram ; 2) a cbir refinement schema based on dual-similarity relevance feedback; and 3) a reliable parallel implementation of the cbir algorithm based on cloud computing.

methods
research design
after discussing the needs and requirements of pathologists from their perspective, the cbir study is designed to quickly and accurately find images exhibiting similar morphologic and staining characteristics throughout a single or collection of imaged specimens. our team specifically choose to use giemsa stained peripheral blood smear and hematoxylin and eosin  stained renal glomeruli datasets to systematically test the algorithms since these are two routine use case scenarios that our clinical colleagues indicated might benefit from the proposed technology. leukocytes are often differentiated based on traditional morphological characteristics, however the subtle visible differences exhibited by some lymphomas and leukemias result in a significant number of false negative during routine screenings. in many cases, the diagnosis is only rendered after conducting immunophenotyping and a range of other molecular or cytogenetic studies. the additional studies are expensive, time consuming, and usually require fresh tissues that may not be readily available
 <cit> . pre-transplantation biopsies of kidney grafts have become a routine means for selecting organs which are suitable for transplantation from marginal donors. the main histopathology characteristics that are routinely evaluated by pathologists are percentage of glomerulosclerosis, interstitial fibrosis, and degree of vascular pathology
 <cit> . the central incentive for developing the cbir algorithms is to determine a reliable means for assisting pathologists when they are called upon to render diagnostic decisions based on whole-slide scanned specimens.

in this paper, we present a novel content-based image retrieval  algorithm that is systematically tested on both imaged giemsa stained peripheral blood smears and digitized h&e stained renal glomeruli specimens. because of the intense computational requirements of the algorithms, our team systematically investigate the use of high performance computing solutions based on cometcloud to distribute the tasks of performing cbir to significantly reduce the overall running time. the details of datasets, the relevant cbir algorithms, and the cometcloud implementation of the methods are explained in detail in the following sections.

in the case of giemsa stained peripheral blood smear datasets, the algorithms operate on a given query patch to quickly and reliably detect other leukocytes of the same class throughout the imaged specimen in support of diagnostic decisions. these hematopathology datasets were acquired using a 20× objective to provide a gross overview of the specimen while also supplying sufficient resolution to distinguish among different classes of leukocytes. the dataset consisted of  <dig> imaged blood smears . in the case of the h&e stained renal glomeruli datasets, the algorithms are used to process any given query patch to discriminate necrotic glomeruli and normal glomeruli throughout imaged kidney tissue specimens. in these experiments, our team cropped  <dig> images  from within eight whole-slide renal specimens using a 20× objective.

quality control of all datasets was conducted by an experienced pathologist  whereas query image patches and ground-truth classification were determined by two pathologists . the retrieved results were evaluated by both pathologists through a completely independent and blinded process. during the peripheral blood smear experiments, pathologists were asked to assign each leukocyte retrieved using the cbir algorithm to either the relevant or non-relevant class as a means for judging the appropriateness of each returned patch. in all, there were five different classes of leukocytes used in the studies. during the renal glomeruli studies, either a relevant or non-relevant assignment was made to judge the performance of the algorithms in distinguishing between necrotic glomeruli and normal glomeruli.

the cbir algorithms consist of four major steps: 1) regions of interest  localization, 2) hierarchical three-stage searching, 3) retrieval refinement based on dual-similarity relevance feedback, and 4) high performance computing using cometcloud
 <cit> . figure
 <dig> illustrates the actual workflow of the process.figure  <dig> 
workflow of the proposed cbir algorithm.




step 1: regions of interest localization
the first step is to locate the regions of interest  throughout the imaged specimens by excluding the background regions from the candidate objects. using color-decomposition and morphology
 <cit>  based preprocessing, the algorithm identifies application-specific rois. these regions serve as candidate searching regions in the subsequent stages of hierarchical searching. candidate image patches are generated using a sliding window approach with an overlapping ratio within the range of .

step 2: hierarchical three-stage searching
the hierarchical three-stage searching method includes: coarse searching, fine searching, and mean-shift clustering.

coarse searching
let q represents a query image patch and p serves the candidate image patches. each patch is divided into consecutive concentric rectangular bin regions  as shown in figure
 <dig>  as the number of rings, r, increases, more detailed image characteristics are captured and while the computational time increases accordingly. r is determined based on cross-validation. figure
 <dig> illustrates the process of coarse searching. given a query image patch, the algorithm computes local features from the innermost ring. based on a similarity measure between candidate image patches, p, and the query image, q, retrieved image patches, p, are ranked from high to low, and only the top 50% ranked candidates are reserved at each step. this procedure continues until the outermost ring is reached. this cascade structure significantly reduces the computational time, as 50% of the image patches are eliminated in the very first stage of processing by simply evaluating features in the innermost ring.figure  <dig> 
an illustration of the hierarchical searching framework:  region of interest,  coarse searching step, and  fine searching step.




fine searching
after the coarse searching stage has been completed, each rectangular annular ring from both the query and candidate patches are equally subdivided into eight segments, and local features are calculated in each segment. the final candidates are chosen based on a similarity measure of a concatenated feature vector corresponding to the eight segments. figure
 <dig> illustrates the process of the fine searching. this stage is designed to capture the spatial configuration of the local features. due to the limited number of candidates passing through the coarse searching stage, the computational time for completing this stage is dramatically reduced.

mean-shift clustering
in order to assemble the final retrieval results, mean-shift  clustering
 <cit>  is applied to the top ranked candidate patches, which have survived both the coarse and fine searching stages. the bandwidth b for the mean-shift clustering is calculated as
, where w is the width of the query image and h is the height of the query image. in this way, the final cbir results are obtained.

hah feature and feature comparison
hah feature
to implement the hierarchical searching framework, we develop a hierarchical annular histogram . the intensity color histograms of consecutive concentric rectangular rings are calculated and concatenated together to form a coarse searching feature vector, hc=, where hi is the intensity color histogram of the ith ring, i∈  and r is the number of rings selected for the hah feature. for fine searching, each rectangular annular ring is equally divided into eight segments, and the color histogram is calculated from each segment sequentially and then concatenated together to form the fine searching feature vector, hf=, where hi,j is the intensity color histogram of the ith ring within the jth segment, j∈ . here superscript c represents coarse searching and f represents fine searching. throughout the cbir study, we use euclidean distance as the similarity measure. the distance di, between the ith candidate patch vi and the query patch q in coarse searching and fine searching are defined as
 and
, respectively:
  

where
. here hc,hf are the feature vector of query image during coarse searching and fine searching stages, respectively, and
 are the feature vector of the ith candidate patch in the coarse searching and fine searching stages, respectively.

figure
 <dig> and  illustrate the calculation of the hah from the innermost rectangle and the fourth ring from the center. figure
 <dig> and  show an example of two image patches with similar traditional color histogram , but completely different hah . this demonstrates the capacity of the hah to differentiate among image patches exhibiting similar total color distributions, but different spatial configurations.figure  <dig> 
an illustration of hah calculation.  color histogram of the central ring.  color histogram of the fourth ring from the center. an example of two patches with  different hah, but  similar color histogram of the entire image.



in order to compare the performance of the hah feature in cbir, the gabor wavelet feature
 <cit>  and co-occurrence texture feature
 <cit>  were compared with the hah feature with respect to both speed and accuracy using both imaged peripheral blood smear and renal glomeruli datasets. for the purpose of the studies, precision and recall were used to measure the performance of the cbir algorithm. precision is defined as the ratio between the number of retrieved relevant images and the total number of retrieved images. recall is defined as the ratio between the number of retrieved relevant images and the total number of relevant images in the datasets.

the gabor wavelet feature
the gabor wavelet feature is used to describe the image patterns at a range of different directions and scales. throughout the experiments, we utilize a gabor filter with  <dig> directions and  <dig> scales, , and the mean value and standard deviation of each filtered image are concatenated to form a feature vector: f=, in which μm,n and σm,n represent the mean value and standard deviation of the filtered image using gabor filter at the mth scale and nth direction, m∈ ,n∈ . the distance di between the ith candidate patch vi, and the query patch q, is defined as
  

where
.

cooc texture feature
co-occurrence  matrices, also called spatial gray-level dependence matrices, were first proposed by haralick et al.
 <cit> . cooc matrices are calculated from an estimation of the second-order joint conditional probability of the image intensity with various distances and four specific orientations . cooc texture feature using the cooc matrices quantifies the distribution of gray-level values within an image. for the feature comparison experiment, cooc texture feature including contrast, correlation, energy, and homogeneity
 <cit> , is calculated from the cooc matrices within the candidate rois and the query image. the distance, di, between the ith candidate patch vi, and the query patch q, is defined as
  

where
, and f = {contrast, correlation, energy, homogeneity}.

stage 3: cbir retrieval refinement using a dual-similarity relevance feedback
relevance feedback is an interactive procedure which is used to refine the initial retrieval results. upon completion of the initial retrieval, top ranked retrieval images were reviewed by two pathologists with consensus to label them as relevant or non-relevant as previously described. these responses are used as users’ feedback to re-rank the retrieval results accordingly.

two types of similarities are used in the above retrieval and feedback procedure: similarity in visual appearance as measured by image feature distance and similarity in semantic category as measured as relevant or non-relevant. current relevance feedback algorithms typically only consider the second similarity. in our algorithm, we develop a dual-similarity schema that combines both types of similarity measures. this is achieved by rebuilding the initial distributions of training samples in an on-line manner.

for each top ranked retrieved image, a 256×3×r dimension feature vector is constructed, where r is the number of rings defined in the hierarchical searching process. dimension reduction using principal component analysis  is applied to the original hah feature space, and the top principal components accounting for 90% of the total variance are used as inputs for the following relevance feedback procedure.

adaboost
 <cit>  is utilized to train an ensemble classifier composed of a set of weak learners. given a training dataset, a strong classifier is built as a weighted sum of weak learners by minimizing the misclassification errors. define weight wi, to be measured by a normalized euclidean distance di, representing the image appearance similarity between a pair of retrieved image and the original query. the initial distribution of the training samples is recalculated to update the classifier to place more weights on the visually similar cases following the relevance feedback step. the algorithm is summarized as follows.
  

step 4: accelerating cbir using cometcloud
due to the data-independence property of the cbir algorithm, we can formulate our problem as a set of heterogeneous and independent or loosely couple tasks. in this way, we can parallelize and solve our problem using the aggregated computational power of distributed resources. our team has designed and developed a framework that enables the execution of cbir across distributed, federated resources. our framework uses cloud abstractions to present the underlying infrastructure as a single elastic pool of resources regardless of their physical location or specific particularities. in this way, computational resources are dynamically provisioned on-demand to meet the application’s requirements. these resources can be high performance computing grids, clouds, or supercomputers. in the current application, the framework is built on top of cometcloud
 <cit> . cometcloud is purposely chosen for this application since it enables dynamic and on-demand federation of advanced cyber-infrastructures . it also provides a flexible application programming interface , for developing applications that can take advantage of federated acis. furthermore, it provides fault-tolerance in the resulting infrastructure.

the framework used to run the cbir algorithm across federated resources is implemented using the master/worker paradigm. in this scenario, the cbir software serves as a computational engine, while cometcloud orchestrates the entire execution. the master/worker model is suitable for problems with a large pool of independent tasks, where both the tasks and the resources are heterogeneous. using this approach, the master component generates tasks, collects results, and verifies that tasks are properly executed. each task contains the description of the images to be processed. all tasks are automatically placed in the cometcloud-managed distributed task space for execution. workers are dedicated to carry out tasks pulled from the cometcloud task space and send results back to the master.

the implementation that we have presented has several important and highly desirable properties. from the user’s perspective, the framework creates a cloud abstraction on top of the resources that hides infrastructure details and offers the cbir software as a readily accessible service. in this way, one can query the database using different algorithms via a simple interface without consideration of how and where queries are executed. on the other hand, from the developer’s perspective, the integration of the existing cbir software with the cometcloud framework does not require any adjustments on the application side. additionally, the resulting framework completely operates within the limits of the end-user space. this means that it is possible to aggregate computational resources without special privileges, which is very important when using external resources.

RESULTS
cbir results and feature comparison
a dual-processor system based on intel xeon e5530@ <dig>  ghz with  <dig> gb ram and 64-bit operating system was used for the cbir study. initial cbir results using two pathology image datasets and different feature comparison are presented below. figure
 <dig> shows an example of the cbir three-stage hierarchical searching results using one neutrophil as a query image in a peripheral blood smear dataset acquired using 20× magnification objective. green box labeled regions represent the candidate patches that are similar to the query image patch. figure
 <dig> shows cbir results using different classes of leukocytes as query images, including basophil, eosinophil, lymphocyte, monocyte, and neutrophil, respectively. green box labeled regions represent the candidate patches that are similar to the query image patch. each box has a number to indicate the ranking order of every candidate patch in the dataset. figure
 <dig> shows an example of cbir results for a necrotic glomeruli query image using a testing dataset containing multi-scale regions at 1/ <dig>   <dig>   <dig>   <dig>  and  <dig> times of the original size of the query image. red box labeled regions indicate the query image. blue box labeled regions represent the healthy glomeruli for comparison. green box labeled regions represent the top-ranked 10% of retrieval patches of the  <dig> randomly selected regions  cropped from whole-slide scanned images.figure  <dig> 
an illustration of results of the three-stage cbir searching using one neutrophil as a query image from peripheral blood smears acquired at 20× objective, in which green box labeled regions represent the candidate patches.

cbir results using different classes of leukocytes as query images, including basophil, eosinophil, lymphocyte, monocyte, and neutrophil, respectively. here green box labeled regions represent the candidate patches that are similar to the query image patch. each box has a number to indicate the ranking order of every candidate patch in the dataset. the original sizes of the images were adjusted to fit in the figure.
an example of top 10% cbir results for a necrotic glomerulus query image. red box labeled regions indicate the query image. blue box labeled regions represent the healthy glomeruli for comparison. green box labeled regions denote the top 10% ranked retrieved patches, which include multiple scaled regions at 1/ <dig>   <dig>   <dig>   <dig>  and  <dig> times of the original size of the query image. the original sizes of the images were adjusted to fit in the figure.



by varying the number of rings ∈  in the hierarchical searching, the performance of cbir is summarized as follows. for imaged peripheral blood smears, all five classes of leukocytes were correctly retrieved using three inner rings of the hah. for imaged renal glomeruli, as the number of rings increased to  <dig>  all necrotic glomeruli were correctly retrieved. with an increase of the number of the rings, the computational time also increased. the number of rings was shown to be dependent upon the complexity of the dataset.

for local feature comparison, image retrieval was performed on the same datasets with the same query images using hah, gabor wavelet, and cooc texture features. figure
 <dig> and  show precision-recall curves and average of feature calculation times using peripheral blood smear images, respectively. figure
 <dig> and  show precision-recall curves and average of feature calculation times using renal glomeruli images, respectively. the area under a curve  value of each feature for peripheral blood smear images and renal glomeruli images are shown in figure
 <dig> and , respectively. the average of feature computation times are shown in figure
 <dig> and . based on these experiments, it is clear that hah feature outperforms gabor wavelet and cooc texture features with respect to both speed and accuracy.figure  <dig> 
local feature comparison using hah, gabor wavelet and cooc texture features.  precision-recall curves of cbir results using hah, gabor wavelet, and cooc texture features on peripheral blood smears.  average of feature calculation times per image patch using hah, gabor wavelet, and cooc texture features on peripheral blood smears.  precision-recall curves of cbir results using hah, gabor wavelet, and cooc texture features on renal glomeruli images.  average of feature calculation times per image patch using hah, gabor wavelet, and cooc texture features on renal glomeruli images.



validation of relevance feedback
to evaluate the performance of the dual-similarity relevance feedback algorithm, both peripheral blood smear and multi-scale renal datasets were used. table
 <dig> summarizes the numbers of relevant/non-relevant images within initial top retrieved  <dig> images for peripheral blood smear and renal glomeruli datasets, which were labeled by two pathologists with consensus. in general, the percentages of basophils and eosinophils in a given specimen are quite small . in addition, they can be accurately retrieved as we show in table
 <dig>  due to this reason, only neutrophils, monocytes, and lymphocytes were utilized for relevance feedback analysis. in those experiments, we applied relevance feedback on the first  <dig> initial retrieved image patches because this number was sufficient to retrieve all similar cases in the datasets.

the original query images, initial top retrieval results, and re-ranked results after relevance feedback are showed in figures
 <dig> and
 <dig> for blood smear and renal datasets. in both figures, image patches with red rectangles represent the incorrect results , and the blue ones represent the correct results , which were re-assigned to higher ranking after relevance feedback. for the retrieval results of leukocyte image datasets, the ranking of many correct patches were increased from their initial ranking after relevance feedback. relevance feedback corrected for 5/ <dig> of the incorrect retrieval patches and increased the ranking for  <dig> patches from the lower ranking  in the neutrophil dataset. this procedure also amended all  <dig> incorrect patches, and increased ranking for  <dig> patches in the monocyte dataset. this procedure eliminated all  <dig> incorrect patches, and increased ranking for  <dig> patches in the lymphocyte dataset. for the renal dataset, the relevance feedback procedure successfully increased the ranking for all of the  <dig> correct patches of multi-scale renal dataset shown in figure
 <dig> 

ten-fold cross-validation was applied to evaluate the performance of the proposed dual-similarity relevance feedback with receiver operating characteristic  curves for both peripheral blood smear and renal datasets. the roc curves after applying relevance feedback on the peripheral blood smear and multi-scale renal datasets are shown in figure
 <dig> 

another measures of performance for the proposed relevance feedback are the recall rate and processing speed. the relevance feedback  calculation time includes feature vector dimension reduction and adaboost classifier training. the numbers of training samples were  <dig>   <dig>  and  <dig>  and the training samples were randomly selected from the datasets. based on figure
 <dig>  the values of area under recall curves increased as the number of training samples increased for three leukocytes  neutrophil,  monocyte, and  lymphocyte), and  renal glomeruli. the recall rate after rf for neutrophils  using  <dig> training samples was no better than the result before rf. this was because the original retrieval process already provided a good performance. as the value of area under recall curve before rf was already  <dig> , which was much higher than the rest of cases  monocyte,  lymphocyte, and  renal glomeruli). in this specific case, there was no significant improvement using rf in a small training set . however, rf significantly improved the recall rate in larger training sets . in general, the values of area under recall curves were significantly increased after rf with the number of training samples increased.table  <dig> 
numbers of relevant/non-relevant images within top  <dig> initially retrieved images for peripheral blood smear and renal glomeruli datasets, which were labeled by two pathologists with an agreement



top ranked patches before and after relevance feedback of three classes of leukocytes  neutrophil,  monocyte, and  lymphocyte). patches with red rectangles represent the incorrect results , and blue rectangles denote the correct results , which were re-assigned to higher rankings through the relevance feedback process. the original sizes of the images were adjusted to fit in the figure.
top ranked patches before and after relevance feedback of the renal glomeruli dataset. patches with red rectangles represent the incorrect results , and blue rectangles represent the correct results , which were re-assigned to higher rankings through the relevance feedback process.
the roc curves of the dual-similarity relevance feedback using the peripheral blood smear image dataset , and the renal glomeruli dataset.

the recall curves after relevance feedback  and their calculation times using the peripheral blood smear image dataset  neutrophil,  monocyte, and  lymphocyte)), and  the renal glomeruli dataset. the numbers of training samples were  <dig>   <dig> and  <dig> 



acceleration of cbir using cometcloud
we conducted experiments to test the performance of cbir using cometcloud. for hah, we evaluated two leukocytes query images against a dataset of  <dig> peripheral blood smear images. in the case of cbir using multi-scale image candidate patches, we evaluated two different renal glomeruli query images against a dataset of  <dig> renal images. all the experiments were repeated three times to obtain average results.

during the experiments, the input data were initially located on a single site, the required files were transferred as needed. however, once a file was transferred to a remote site, it was locally staged to minimize the amount of data transferred across sites, especially when multiple tasks require the same input data. to address this issue, a pull model was used where workers request tasks when they become idle. in this way, the workload was uniformly distributed across all workers to address the load imbalance.

to accommodate the cbir algorithms, we federated various resources including hpc clusters and clouds. in particular, we federated a hpc cluster at rutgers , a smp machine at rutgers , and  <dig> large instances from openstack
 <cit>  , which is a cloud similar to amazon ec <dig>  currently we are exploiting the inherent task parallelism of the problem, which means that we can divide the algorithm into smaller sub-modules and execute each module independently. this provides a linear scalability as long as we have more tasks than computational cores.

figure
 <dig> presents a summary of the execution time of the proposed hierarchical searching algorithm using two representative peripheral blood smears and a multi-scale renal glomeruli dataset while varying the parameters, respectively. the results illustrate average values, including error bars showing their associated variabilities. please note that the y-axes in the sub-figures represent different scales. the figure also demonstrates the execution time of each stage and the time required to transfer the images for processing. since the image transfer time represents a small fraction of the total execution time , in our current implementation we copy the images sequentially from a central repository. the execution time varies depending on the algorithm we used, the query and dataset images, and the configuration . the fraction of time spent on each stage of the hierarchical searching is shown in figure
 <dig> 

figure
 <dig> compares the execution time of different configurations using a single system and federated cyber-infrastructure. we observe an average acceleration of 70-fold with a maximum of 96-fold. this is achieved by elastically using multiple resources as discussed below. figure
 <dig> shows the contribution of the futuregrid cloud to the execution of the multi-scale algorithm. cloud resources significantly accelerate the execution of the algorithm. during stages with lower parallelism , computation can be performed using local hpc resources and cloud resources can be released to reduce operational costs.

the variability of the execution time of different tasks is shown in figures
 <dig> and
 <dig>  figure
 <dig> shows the average task execution time and variability using different configurations. the variability of task execution time is heterogeneous and depends on the configurations and the machine. in general, the longer the execution takes, the larger the variability. figure
 <dig> shows that the execution time of individual task is relatively heterogeneous. it also demonstrates that the distribution of tasks among different federated resources depends on the number of cores available in each platform . the results show that the parallelization of cbir at the image level can dramatically reduce the overall computational time.figure  <dig> 
the execution time of hierarchical searching process using  peripheral blood smear dataset, and  renal glomeruli dataset, with different combinations of number of the hah rings and the percentage of overlapping.

the execution time of sequential and federated infrastructure using peripheral blood smear dataset and renal glomeruli dataset with different combinations of number of the rings and the percentage of overlapping. here the y-axis is in a logarithmic scale.
the number of completed tasks over time when testing the cbir algorithm using the renal glomeruli dataset. the area under “futuregrid” represents the contribution from the cloud resources.
the average task execution time per platform using the peripheral blood smear and renal glomeruli datasets with different combinations of number of the rings and the percentage of overlapping. here “futuregrid” is abbreviated as “fg”.
the execution time per task using  the peripheral blood smear dataset and  the renal glomeruli dataset.




CONCLUSIONS
in this paper, we present a set of newly developed cbir algorithms and demonstrate its application on two different pathology applications, which are regularly evaluated in the practice of pathology. the experimental results suggest that the proposed cbir algorithm using sequential hah searching follows a progression which parallels to the same logical steps as ever invoked when physicians review digital pathology images. during the review process, the pathologist typically begins by first identifying gross locations of potential regions of interest  before executing the more refined stages  to examine the detailed morphometric characteristics.

for the peripheral blood smear study, we tested performance using a range of different leukocytes and experimentally showed the reliable performance of the cbir algorithm. the success of the proposed cbir algorithm in identifying neutrophils suggests further exploration of the hah feature in detecting abnormal or hypersegmented neutrophils, which are indicators of megaloblastic anemia and potential risk of gastric cancer. similarly, a pathologist’s assessment of normal vs. diseased glomeruli in renal biopsies is often used as an indicator of overall kidney health, such as, the determination of graft function from pre-transplantation biopsies
 <cit> . assisted by the proposed cbir algorithm, physicians and researchers can quickly review a digital biopsy to evaluate the proportion of ischemic or necrotic glomeruli within a given field to quickly assess whether an incoming specimen is suitable for transplantation or not. this type of review can have multiple applications, such as, determining whether a rejection of the organ might occur by identifying areas of focal and segmental glomerulosclerosis
 <cit> . currently, our algorithm requires some external feedback to optimize the search. we are exploring different ways of automatizing this process by applying machine learning techniques. on the other hand, although the proposed hierarchical searching has significantly improved the retrieval speed, it is still a computational demanding procedure. therefore, we are exploring new ways of exploiting parallelism to speed-up this process.

we present a generalizable cloud-enabled cbir algorithm that can be extended to a wide variety of applications. because of the computational requirements needed for retrieving whole-slide scanned images, we explore the use of federated high performance computing  cyber-infrastructures and clouds using cometcloud. comparative results of hpc versus standard computation time demonstrate that the cbir process can be dramatically accelerated, from weeks to minutes, making real-time clinical practice feasible. moreover, the proposed framework hides infrastructure and deployment details and offers end-users the cbir functionality in a readily accessible manner. we are currently working on improving the utilization of resources by exploit the particular capabilities and capacities of each heterogeneous resource, e.g., switching between the usage of the original cbir implementation in matlab  when licenses are available or a parallel implementation using graphic processing unit  and many-core architectures in cases where resources with accelerators are available.

competing interests

the authors declare that they have no competing interests.

authors’ contributions

xq, hz, lg, djf and ly conceived the study. xq, dw, ir, jdm, fx, hz, lg and ly designed and carried out the experiments. xq, dw, ir and jdm wrote the first draft of the manuscript with contributions from other authors. all authors read and approved the final manuscript.

