BACKGROUND
for thousands of years, herbal medicines have played a critical role in the primary health care systems for prevention and treatment of diseases, especially in asian countries, such as china, india, korea and japan  <cit> . however, the therapeutic efficacies of herbal medicines are not evaluated or quantified due to the complexity of herbal extracts  <cit> . herbal medicines contain complex compositions. a single herb may already include hundreds of natural constituents. in addition, synergistic or antagonistic interactive effects may exist among these compounds. furthermore, the concentrations of active ingredients of a herb may vary substantially in different climates, cultivation conditions, storage conditions, extraction procedures, and other unknown factors  <cit> . this means that the bioactivity of herbal products for different batches may not be consistent, and this in turn may lead to unpredictable clinical therapeutic effects of these herbal products.

it is highly desirable to have a robust and efficient way to predict the bioactivity of herbal medicines. the use of whole chromatographic fingerprints is popular in solving herbal medicines' bioactivity prediction problems because the fingerprint provides a more comprehensive picture of herbal medicines  <cit> . a chromatographic fingerprint is a two-dimensional curve with time  as x-axis and intensity  as y-axis. there are two inherent characteristics of chromatographic fingerprints that should be noted. firstly, as the intensity at every measuring time point in a chromatographic fingerprint is treated as the predictor variable, the number of predictor variables is normally larger than the number of samples investigated. this means that the intensity at every measuring time point will be treated as the predictor variable. for instance, a routine hplc chromatographic fingerprint may contain about  <dig>  time points within a  <dig> minutes' elution run constitute the high number of predictor variables in comparison with the limited number of the generally less than  <dig> grossly identified series of "peaks" in the chromatographic fingerprints.

secondly, a chromatographic fingerprint may contain predictor variables that are not of high intensity due to different uv absorption rate, and contribute significantly to the overall bioactivity. thirdly, various forms of multicollinearity may exist among predictor variables where some variables can be highly complementary.

a review of the literature shows that principal component regression , partial least squares regression , and variants of plsr, such as orthogonal projections to latent structures  and elastic net  combined with plsr , have been applied in prediction of biological activity from chromatographic fingerprints  <cit> . these approaches generate latent variables and measure the relationship between latent representations of the chromatographic fingerprints and bioactivities. successful application of these algorithms may lead to useful prediction platforms for future bioactivity of unknown chromatographic fingerprints. however, if the number of latent variables to be used in the predictive model built by pcr, plsr variants or en, is not properly selected, over-fitting may occur and lead to poor generalisation performance of these models.

based on a set of chromatographic fingerprints of astragali radix  and their corresponding bioactivity of cluster of differentiation  <dig>  expression on the robust cell line representing human dendritic cells  measured by flow cytometry, this study aims to propose an approach to develop predictive models with better and accurate generalisation ability to predict the bioactivity capacity of herbal medicines from their chromatographic fingerprints. furthermore, the predictive accuracy of the model developed by the proposed approach will be evaluated in comparison to that of predictive models built by pcr, plsr, opls and en respectively.

this paper is organised as follows. the methods section reviews the ensemble learning and describes the proposed method. in the results and discussion section, the performance of one real world data set is presented and discussed. the conclusion section summarises the results of this study, and the future work section discusses potential tasks that are worthwhile for further investigation. it is then followed by a section of abbreviations used in this paper for easy reference.

methods
ensemble learning
it is a critical problem to machine learning when the training set is small or extremely small. the models built with a small training set may not be strong enough to accurately predict new instances. to improve the overall prediction accuracy, multiple models can be built on the training set, and prediction is made by incorporating and averaging over multiple models. this idea is called ensemble learning  <cit> . ensemble learning combines a collection of base models  to build a composite prediction model . there are two main tasks of ensemble learning: constructing base models from the training data; and combining them to form a composite model  <cit> . generally, there are three approaches to construct base models, also called ensembles.

data manipulation. the first approach is to have a more effective use of the dataset by manipulation upon the data. by resampling the original training set according to a sampling distribution, such as bootstrapping, multiple training sets will be created. then, a model can be created from each training-set using a learning algorithm  <cit> . bagging  <cit>  and boosting  <cit>  are two ensemble methods which generate base models for further processing.

bagging is a method that repeatedly samples from a data set according to bootstrap and train a base model on each bootstrap sample. the base models can be combined by simple averaging or majority voting. bagging improves the prediction accuracy by reducing the variance of base models. however, the performance of bagging depends on the stability of base models  <cit> .

boosting is an iterative method that adaptively changes the distribution of training samples by assigning a different weight to each training sample. the adaptive weight assignment to the base models aims to direct the attention to the poorly classified or predicted training samples. rather than averaging the results or taking majority voting from the ensembles, boosting combines the result from each base model according to its weight  <cit> .

feature manipulation. the second approach to construct base models is by to manipulate the input features, where each training set is formed by selecting a subset of input features. this approach works well when the data contain highly redundant features. the subset of features could be selected randomly or manually according to users' understanding of the data and domain experience. a typical ensemble approach in this category is random forests   <cit> . rf  <cit>  is a combination of decision trees, in which each tree is generated according to the values of a random vector that is sampled independently and with the same distribution. it is claimed that rf is more robust to noise and runs faster  <cit> .

multiple learning algorithms. the third approach to construct base models is to use multiple learning algorithms. the aim is to obtain and to make advantage of the disagreement in sample classification or regression by using various learning algorithms. in other words, the different learning algorithms reveal the diversity of base models  <cit> . this approach is being adopted in this study to embrace the strengths of multiple algorithms.

stacking  <cit>  is an example of multiple learning algorithms. it aggregates the results from the base models, which are generated by different learning algorithms. using a meta-learner, it tries to combine the results from these base learners in an optimal way to maximise the generalisation capability  <cit> . breiman  <cit>  proposed an approach called stacked regression. this approach was a linear combination of predictions from subset regression  and ridge regression . the researcher showed that the prediction performance of a stacked model was better than using sr or rr alone. later on, kedarisetti et al.  <cit>  applied an improved stacking method, stacking c, to combine outputs from  <dig> classifiers, namely logistic regression , support vector machine , nearest-neighbor algorithm and decision trees. they found that the classification performance using stacking c method outperformed those approaches using voting and multi-scheme.

it can be concluded from the above studies that stacking appears to be a good approach to combine predictions of several learning algorithms. the combined classifiers or regression models give better predictive accuracy than any single base learner. however, there is no unique way to combine the predictions of base learners using stacking. simple linear regression with non-negative constraints is a simple way and it should usually work well  <cit> .

stacking multivariate linear regression 
based on the approach of ensemble learning of stacking, in this study smlr was proposed as the model for herbal medicines' bioactivity prediction. essentially, smlr combines the predictions from pcr  <cit> , plsr  <cit> , opls  <cit>  and en  <cit>  with non-negative constraints or coefficients. then, the trained smlr is used to predict the testing set of the chromatographic fingerprints.

the four underlying justifications for using pcr, plsr, opls, and en to build base learners are: firstly, these four methods can all work within the constraint of the size of sample is much smaller than the number of predictors. secondly, plsr and opls are the most commonly used methods to model the correlation between chromatographic fingerprints and the bioactivity of herbal medicines. thirdly, pcr and en are included to increase the diversity of base learners, as it has been reported that the biggest gains come when dissimilar sets of base learners are stacked  <cit> . pcr is different from plsr and opls by extracting principal components that retain as much variation as possible in original space. the original data are projected to the new space , called scores. then, pcr models the scores and the responses using multivariate linear regression . en is a regularisation method which adds two penalties to the least squares function  to penalise the regression coefficients of predictive models, this method is particularly useful when the dataset is sparse. fourthly, only linear regression learning algorithms are considered in this study due to the fact that the linear models can be easily interpreted which is useful for the identification of highly bioactive regions or compounds in chromatographic fingerprints.

the outputs from the base learners are treated as inputs to train the meta-model, called meta-learning instances that are the predictions of base learners. the number of predictor variables of a meta-learning instance is the number of base learners. to train the meta-model, meta-learning training samples need to be formed. a 10-fold cross-validation is used for splitting an original training set into ten folds. each time, one fold is held out to build the base learners using samples in the remaining nine folds. the base learners are trained on this dataset and to predict the responses in the holdout set. these predicted responses are then used to form the meta-learning training data. the rationale of these procedures is to ensure the meta-learning training data are able to reflect the true prediction performance of the base learners without bias and accurately  <cit> .

the learning algorithm used for the development of the meta-model is rr  <cit> . it is under the constraint that the regression coefficients are non-negative, since the responses of a sample predicted using pcr, plsr, opls, and en models respectively are usually strongly correlated. rr adds l <dig> penalty to the least squares function  as a regularisation method. constraining regression coefficients to be non-negative is to guarantee the response of a sample predicted by the meta-model will be within the range  in case the prediction of the meta-model is poor  <cit> .

after determining the coefficients of pcr, plsr, opls and en models in the combination , pcr, plsr, opls, and en models will be built using the original training set. when smlr is used to predict a new sample; the sample is firstly predicted by pcr, plsr, opls, and en models that built on the original training set: each base model gives a predicted response of the sample. these predicted responses are then fed into the meta-model which combines them into a final predicted response.

the mathematical description of the strategy used for combining pcr, plsr, opls, and en in smlr is as follows: suppose we have k base predictive models, v <dig> v <dig> …,vk, where x represents the predictor variables, stacking combines the predictions of these models rather than a single learner. the specific method for combination in smlr is defined as follows: given an original training set t={yn,xn,n= <dig> ,…,n}, and a test sample s=y <dig> x <dig>  where xn is the predictor variable and each x is p-dimensional, yn is the response. divide the data in t into  <dig>  equal parts t <dig> t <dig> …t <dig> using tenfold cross-validation, and define tj=t-tj, where j= <dig> ,…, <dig>  using data in tj train the pcr, plsr, opls and en models respectively, let vkj, where k= <dig> , <dig>  denotes the predictive model built using tj. specifically, v1jx is the pcr model trained using tj, v2jx is the plsr model trained using tj, v3jx is the opls model trained using tj, and v4jx is the en model trained using tj. take the αk to minimise:

   ∑j ∑∈tj2+λ∑kαk <dig> 

under the constraint αk≥ <dig>  λ∑kαk <dig> is l2penalty, which is used to penalise αk  <cit> .

then, develop vkxn using the training set t. the response of the test sample s could be predicted as:

  ŷ0= ∑kαkvk 

regression coefficients of original predictor variables need to be further calculated by using the following equation:

  βsmlr=αpcr×βpcr+αplsr×βplsr+αopls×βopls+αen×βen 

where βsmlr, βpcr, βplsr, βopls, andβen represent the regression coefficients of the original predictor variables in smlr, pcr, plsr, opls and en models respectively. the αpcr,αplsr,αopls,αen are the coefficients of pcr, plsr, opls and en models respectively.

measures of predicting performance
in this study, mean-squared error  is used to measure the predictive performance of a predictive model. the calculation of mse is shown as:

  mse=∑i=1nŷi-yi2n 

where ŷi is the predicted response of the ithsample, yi is the observed response of the ith sample, and n is number of samples.

the prediction error of a numeric prediction model on a test set is defined as:

  msetest=∑i=1tŷti-yti2t 

where ŷti is the predicted response of the ith sample in the test set, yti is the observed response of the ith sample in the test set, and t is the number of samples in the test set.

the prediction error of a numeric prediction model on a training set, also known as training error, is defined as:

  msetraining=∑i=1p  <cit> , alignment of chromatographic fingerprints using correlation optimized warping   <cit> , and standardisation. the chromatographic fingerprints after pre-treatment were then split into a training set and a test set using a bootstrap resampling procedure  <cit> , and this procedure was repeated ten times, so there were ten training sets and ten test sets. pcr, plsr, opls, en and smlr were applied to each training set to build prediction models, where they were evaluated using the corresponding test set.

data description
based on the traditional chinese medicine concepts, ar was chosen in this study because this herb has been believed to enhance the important "qi" of humans that elevates the general well-being and protection against diseases and infections. however, up to now, there is no quantifiable measurement of such "qi" in evidence-based medicine. the hypothesis taken in this study is that herbs that have been traditionally showing the desirable effect of "qi" enhancement will also upregulate the body's natural immunity - therefore the expression level of the costimulatory molecules of cd <dig> on our body's professional antigen presenting cells of dcs was measured  <cit> .

three batches of raw ar  were used to prepare  <dig> extracts in total  according to a modified extraction method based on the chinese pharmacopeia. these extracts were analysed by high performance liquid chromatography with diode array detector  to obtain chromatographic fingerprints. briefly,  <dig> grams of raw herb were pre-immersing with bi-distilled water  for  <dig> hours and refluxed for  <dig>   <dig>   <dig>   <dig> and  <dig> hours. the mixtures were then filtered and concentrated under a rotary evaporator . ar extracts were finally obtained after lyophilisation. each extract was stored under low humidity condition and was kept for biological assay within  <dig> months. all the extracts before chromatographic analysis and biological assay were filtered under  <dig> um filter. bi-distilled water was produced in-house by milli-q® advantage a <dig> water purification systems  and filtered with  <dig>  μm millipak®. all other chemicals and reagents used were of analytical grade unless indicated otherwise. the bioactivity cd <dig> was measured through a thp- <dig> dc flow cytometric platform.

since a chromatographic run was  <dig> min long and the sampling rate was  <dig>  min, the number of points acquired per chromatographic fingerprint of ar was  <dig> . in other words, each chromatographic fingerprint is a signal graph with  <dig>  data points, with the interval between two points being  <dig>  min.

digitised chromatographic fingerprints of ar were gathered in a  <dig> by  <dig>  matrix x where each row represents the fingerprint of one sample and the  <dig>  variables  are the columns. the corresponding bioactivity capacities were represented as a 72-row vector y. when building predictive models, all these  <dig>  points of each digitised chromatogram were used as predictor variables, and the cd <dig> capacity of each sample is the response.

RESULTS
the msetest and msetraining of each model built by pcr, plsr, opls, en and smlr are listed in table  <dig> and  <dig>  the numbers in the first column of table  <dig> and  <dig> represent the predictive model built using the first training set, second training set, ... etc.


msetest 

msetraining
the difference of the predicted bioactivity capacity of a test sample and its corresponding observed bioactivity capacity is another measurement to study and to analyse. the criteria of how good the bioactivity capacity of a new sample is predicted are listed in table  <dig> 

the difference between the predicted cd <dig> expression and the observed response of a test sample can be divided into different grades. in general, cd <dig> flow cytometric expression for replicates of the same ra extract have a standard deviation of about 2% of the mean value. thus a prediction of <10% difference can be considered as excellent; and between 10-20% is good and so on. the first column of table  <dig> is the difference of the predicted bioactivity capacity of a test sample and its corresponding observed bioactivity capacity in percentage. the second column displays the four levels, namely excellent, good, acceptable and poor of how good the prediction is.

the average difference  of the predicted bioactivity capacity of test samples and their corresponding observed bioactivity capacity in each test set  for pcr, plsr, opls, en and smlr models can be found in table  <dig>  the numbers in the first column of this table are the same as table  <dig> and  <dig>  in order to analyse whether the mean msetest and the mean differences of predicted responses and observed responses of pcr, plsr, opls, en and smlr are significantly different, one-way anova was applied. the results are shown in table  <dig> and  <dig> 


source of variation
ss
df
ms
f
p-value
f crit

source of variation
ss
df
ms
f
p-value
f crit
discussion
comparing the msetest of predictive models built by pcr, plsr, opls, en and smlr, smlr had the smallest mean , followed by plsr , opls , en  and pcr , though the differences of them were small, only at the second, third, or even fourth decimal place. and these differences were not statistically significant according to the one-way anova analysis results  =  <dig> , p =  <dig> ).

in terms of the average difference of predicted responses and observed responses in each test set for models built by pcr, plsr, opls, en and smlr, smlr had the smallest mean differences which is  <dig> %. pls came second , opls came third , followed by en , and pcr . again, the differences among the models were also small and not statistically significant; the one-way anova result is f  =  <dig> , p =  <dig> .

the mean differences between predicted cd <dig> capacity and observed cd <dig> capacity for smlr, pcr, plsr, opls and en are around 13% to 14%, which means their predictions for cd <dig> capacity from chromatographic fingerprints of ar samples are good, according to the goodness criteria of predicting the bioactivity capacity of a sample .

the predicting performances of pcr, plsr, opls, en and smlr models, in terms of msetest and differences between predicted responses and observed responses of test samples, had the following ranking: smlr, plsr, opls, en and pcr. however, the improvement of predictive accuracy was not significant.

smlr did not significantly improve the predictive accuracy. this may be because the learning algorithm applied in smlr did not combine the predictions of base learners in the optimal way. another reason could be that the size of samples is too small. there are not enough samples to train the meta-model. in addition, if more learning algorithms were used to create base models, the predictive accuracy might be improved to some extent.

smlr could also be applied in other domains, not just for measuring the relationship between chromatographic fingerprints and the bioactivity capacity of herbal medicines. it is designed to solve the prediction problem when the number of samples is far less than the number of predictor variables, and when the predictor variables are highly correlated.

CONCLUSIONS
in this article, smlr was presented as an algorithm that could develop predictive models for predicting bioactivity capacity of herbal medicines from their chromatographic fingerprints. smlr is a meta-learner that works on the results the constituent base-learners. its generalization capability becomes more obvious when its constituent base-learners are more diversified in nature. the prediction performances of models built by using smlr for predicting cd <dig> from the chromatographic fingerprints of ar samples are superior to pcr, plsr, opls, and en in terms of msetest and differences between predicted responses and observed responses of test samples. however, the differences among the models are small and not statistically significant.

future work
future studies should aim to further improve the predictive accuracy of the smlr algorithm. for instance, more learning algorithms can be attempted to generate more training instances for the meta-learner. another possible investigation is the identification of base learners that has maximum diversity, so that the meta-learner can have optimal performance owing to the complementary behavior of the constituent base learners. in addition, other linear or non-linear learning algorithms could be designed and applied for investigating how to combine the output of the base learners in order to improve the predictive accuracy. furthermore, it is important to perform cd <dig> bioactivity testing on those single chemical compounds that has been predicted to be the highly bioactive components. this may then demonstrate that this chemometrics prediction platform has a strong potential to be an effective drug discovery platform as well.

in this study, smlr has been evaluated using only one dataset, which does not appear to be that sufficient. in the future, a few other datasets, with both quality chemical fingerprints and corresponding bioactivity results, should be used for evaluation of the proposed approach if possible. it is envisaged that this same platform may be applicable for the analysis of other kinds of mixture datasets not limited to the chromatographic fingerprints and bioactivity capacity.

list of abbreviations used
airpls: adaptive iteratively reweighted penalized least squares; anova: analysis of variance; ar: astragali radix; cd80: cluster of differentiation 80; cow: correlation optimized warping; dc: dendritic cell; en: elastic net; en-plsr: elastic net combined with plsr; hplc-dad: high performance liquid chromatography with diode array detector; lr: logistic regression; mlr: multivariate linear regression; mse: mean-squared error; opls: orthogonal projections to latent structures; pcr: principal component regression; plsr: partial least squares regression; rf: random forests; rr: ridge regression; smlr: staking multivariate linear regression; sr: subset regression; svm: support vector machine.

competing interests
the authors declare that they have no competing interests.

authors' contributions
hc designed and implemented the smlr algorithm, conducted the experiment, analysed the results, and drafted the manuscript. jp and skp supervised the manuscript, conceived of the whole method and revised the manuscript. lc gave suggestions on developing the smlr algorithm. kf provided domain knowledge of traditional chinese medicine and critical discussion of the approach to this study. ds provided domain knowledge of traditional chinese medicine, the data used in the experiment and reviewed the manuscript.

