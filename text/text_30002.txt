BACKGROUND
protein-protein interactions play a key role in cellular processes and significant efforts are being devoted world wide to characterizing such interactions on the scale of whole genomes . genome scale data on protein interactions are typically obtained using experimental methods for detecting binary interactions <cit> , or by affinity purifications of tagged proteins coupled to analytical methods for identifying the co-purified partners  <cit> . these data are in general represented as large networks, or graphs where hundreds or thousands of proteins are linked to one another  <cit> . for a recent review of network analysis techniques as applied to protein interaction networks, see  <cit> .

it is well known however that proteins tend to function in groups, or complexes, which in the yeast s. cerevisiae contain on average  <dig>  different types of subunits  <cit> . an important goal has therefore been to reliably identify protein complexes from the protein interaction graphs. this task is commonly carried out using graph clustering procedures, which aim at detecting densely connected regions within the interaction graphs.

clustering is an unsupervised learning method that tackles the task of producing an intrinsic grouping of data elements on the basis of some metric . it requires solving an optimization problem, which is usually achieved with the help of heuristic algorithms whose ability to approximate the best solution  may vary widely <cit> . their application in the context of protein interaction networks encounters the additional problem of dealing with the significant level of background noise in these networks <cit>  . dealing with a high level of noise is a major challenge for clustering procedures, as this requires mitigating the effect of noise by various means – for example by taking into account the topology properties of the network, either during the clustering process or by modifying the distance metric to incorporate such properties prior to clustering.

there exists a wealth of clustering algorithms of which hierarchical clustering  and k-means <cit>  are classical examples. more recently a variety of other algorithms have been proposed <cit> , and some of these have been applied to the identification of highly connected nodes in protein interaction graphs <cit> .

so far, one of the most successful clustering procedures used in deriving complexes from protein interaction networks seems to be the markov cluster algorithm  <cit> . unlike most hierarchical clustering procedures, this algorithm considers the connectivity properties of the underlying network. it has been used to derive complexes from protein interaction data in two recent comprehensive analyses of the yeast interactome  <cit> . furthermore, in a recent benchmark carried out by brohée et al <cit> , mcl was shown to be especially effective for clustering protein interactions in that it possesses a high degree of noise-tolerance in comparison to other algorithms such as the molecular complex detection  <cit>  and super paramagnetic clustering  <cit> .

over a year ago, a novel promising clustering procedure termed affinity propagation  was proposed  <cit> . affinity propagation identifies representative examples  within the dataset by exchanging real-valued messages between all data points. points are then grouped with their most representative exemplar to give the final set of clusters. ap was applied to a variety of problems including face recognition, and gene identification from putative exons using microarray data, and was shown to be faster and more accurate than the k-centers <cit>  clustering algorithm. a subsequent note suggested however, that ap was similar to the earlier vertex substitution heuristic , and that it did not perform any better <cit> . this prompted the ap authors to provide evidence that ap outperforms vsh on large problems – where it runs much faster, and was more accurate than several clustering algorithms tested <cit> .

in view of the interest in applying efficient clustering procedures to biological networks in order to identify and characterize functional modules, this paper expands the analysis of brohée et al <cit>  to the comparison of the ap and mcl algorithms. such comparison has not been previously reported.

following brohée et al, we first derive an unweighted network of protein-protein interactions from a set of up-to-date hand curated protein complexes from s. cervisiae <cit>  and evaluate the performance of the two clustering algorithms in recalling the annotated complexes. in doing so the parameter space of each algorithm is sampled in order to select optimal values for these parameters, and the robustness of the algorithms is assessed by quantifying the level of complex recall as interactions are randomly added or removed to the network to simulate noise.

to test performance on a more realistic weighted protein interaction graph, we also apply the two algorithms to the high confidence consolidated protein interaction network of s. cerevisiae recently derived by collins et al <cit> , and to versions of this network in which varying proportions of the links have been randomly shuffled. the computed clusters are compared to the same set of curated s. cerevisiae complexes in order to assess the robustness of the two algorithms.

the comparative analysis on the unweighted networks proposed here has the advantage of representing a self-consistent approach, in which information on a predefined number of cliques is used to build the network, and hence the expected result from partitioning this network is well defined. the choice of the weighted high confidence consolidated network of s. cerevisiae recently derived from purification data also enables to quantify the performance of the clustering procedures by comparing computed clusters to the annotated complexes. such quantification is difficult with s. cerevisiae protein interaction networks built using yeast two hybrid data, because these interactions differ significantly from co-complex interactions <cit> . partitioning this network using any method is hence unlikely to yield clusters comparable to complexes. the much larger human protein interaction networks compiled from different sources and stored in databases such as hprd , would not serve our purpose either, given the still limited number of fully annotated human protein complexes against which the clustering results can be compared.

the clustering algorithms
the markov clustering algorithm  simulates random walks on the underlying interaction network, by alternating two operations: expansion, and inflation. first, loops are added to the input graph – by default, the loop weight for each node is assigned as the maximum weight of all edges connected to the node – and this graph is then translated into a stochastic "markov" matrix. this matrix represents the transition probabilities between all pairs of nodes, and the probability of a random walk of length n between any two nodes can be calculated by raising this matrix to the exponent n – a process referred to as expansion. as higher length paths are more common between nodes in the same cluster than nodes within different clusters, the probabilities between nodes in the same complex will typically be higher in expanded matrices. mcl further exaggerates this effect by taking entry wise exponents of the expanded matrix, and then rescaling each column so that it remains stochastic – a process called inflation. clusters are identified by alternating expansion and inflation until the graph is partitioned into subsets so that there are no longer paths between these subsets.

affinity propagation  identifies cluster centers, or exemplars, from the graph, which in some sense are a representative member of the cluster. initially, all nodes are considered as exemplars, though each node is manually assigned a "preference" that it should be chosen as an exemplar. if no prior knowledge is available on which nodes should be favored as exemplars, then all nodes can be assigned the same preference value – where the magnitude can be used to control cluster granularity. for each node i and each candidate exemplar k, ap computes the "responsibility" r, which indicates how well suited k is as an exemplar for i, and the "availability" a reflecting the evidence that i should choose k as an exemplar.

  

where the matrix s denotes the similarity  between the two nodes i and k, and the diagonal of this matrix contains the preferences for each node. the above two equations are iterated until a good set of exemplars emerges. each node i can then be assigned to the exemplar k which maximizes the sum a + r, and if i = k, then i is an exemplar. a damping factor between  <dig> and  <dig> is used to control for numerical oscillations.

RESULTS
performance on unweighted protein interaction graphs
both algorithms are first applied to partition unweighted protein interaction graphs. the original version of these graphs was built from a set of  <dig> s. cerevisiae protein complexes hand curated in-house <cit>  . in this graph, nodes represent individual proteins from these complexes, and any two proteins belonging to the same complex are linked by an edge. figure 1a illustrates this graph as rendered by the cytoscape <cit>  network visualization and analysis software. this rather disjoint graph is comprised of  <dig>  interactions and  <dig>  proteins, where the majority of the proteins are linked only to members of the same complex, forming distinct cliques, and only a small fraction are linked to members of different complexes. this graph is clearly a less challenging test for clustering procedures than protein interaction networks built from experimental data, since those networks include an appreciable level of spurious links . networks built from experimental data typically feature more links between proteins in different complexes and not all members of a given complex are always linked to one another. to better mimic these more realistic networks we randomly add or remove links to this original network in various proportions, as done by brohée et al.  <cit>  thereby generating different versions of the original network which include varying levels of noise, representing different proportions of false positives  and false negatives  .

the mcl and ap clustering procedures were each applied to the different versions of the networks and the correspondence between the computed clusters and the original  <dig> curated complexes was evaluated for each network version. the correspondence was quantified using the geometric accuracy  and geometric separation  criteria as previously defined <cit> . acc is computed as the geometric mean of the positive predictive value and sensitivity with which the clusters recall the original complexes. the sep parameter is defined as the geometric mean of two quantities that measure how cluster components are on average distributed amongst complexes and how complex components are distributed among clusters, respectively .

to enable as fair a comparison as possible, values of the adjustable parameters in each clustering algorithm were selected so as to maximize the sum of the acc and sep values for the clusters computed from each network .

figures 1b and 1c present a visual overview of the results obtained from an unweighted network, derived from the original network by adding 20% of the edges, and rendered using the genepro <cit>  plugin for cytoscape. they show that the ap clusters are more fragmented than those obtained with mcl, as components annotated to the same curated complex are often distributed among several ap clusters, whereas the mcl clusters tend to map more fully into the curated complexes. this result is summarized by the acc and sep parameters listed in the additional file  <dig>  to further understand how each algorithm handles noise, simulated here by random addition and subtraction of graph edges, we focus on the effects of either adding  or removing  edges. while ap and mcl yield solutions with virtually identical acc and sep values for the original network , the ap algorithm did not converge for most of the noisier networks. the one with 20% random edge addition was among the few for which it did converge, but the acc and sep values of the resulting clusters were much lower than those obtained with mcl on the same network. ap also did not converge for the majority of networks with simultaneous random edge addition and removal . in contrast, mcl generated clustering solutions with relatively high acc and sep at all noise levels. interestingly however, for networks containing high noise levels, the mcl clusters group only a fraction of the proteins comprising the interaction network, leaving the remaining proteins ungrouped  .

we also tested ap on an unweighted network of  <dig>  <dig> human protein-protein interactions comprising  <dig> unique proteins, annotated as experimentally characterized using affinity capture or reconstituted complexes in version  <dig> . <dig> of the biogrid database <cit> . similar to the results obtained for unweighted networks to which artificial noise was added, ap did not converge for this more realistic network derived from inherently noisy experimental data. mcl produced clusterings containing between  <dig> and  <dig> clusters, depending on the inflation value. a detailed analysis of these clusters is outside the scope of this report, but the size distributions of the clusters in the mcl partitions produced at various inflation values  indicate that they are not all trivial singleton or extremely large clusters.

the acc and sep were also evaluated for the  <dig> curated complexes directly. as expected, acc, which quantifies the maximum extent of overlap between complexes and clusters – and vice versa – is  <dig> for these complexes . lower acc values are obtained for the partitions derived by both clustering algorithms – largely due to shared components in the original complexes, which can obscure their detection, especially for smaller clusters. in contrast, shared components lower the sep values of the original complexes, and hence as the clustering algorithms partition the graphs they can achieve higher sep values at low noise levels .

these results depart sharply from those expected for random partitions, as also illustrated in figures 2a, b, 3a, and 3b. random partitions were generated by randomly permuting the assignments of the proteins to clusters within the mcl and ap predictions.

performance on a weighted biological protein interaction graph
a second series of tests was performed using interaction graphs built from the consolidated network of collins et al <cit> , where each protein-protein link has an associated confidence score ranging in values from  <dig> to  <dig>  as in previous studies <cit> , only the high confidence portion of the network was considered, comprising links whose scores are above a confidence threshold of  <dig>  <cit> . the resulting network comprised  <dig>  interactions and  <dig>  proteins. since this network represents predicted associations from data derived in two recent high-throughput experimental studies <cit> , some noise will naturally be present. we did however generate noisier versions of this network by randomly shuffling increasing fractions of edges, and re-evaluating the results for each of these versions. as for the performance tests on the unweighted graphs, the parameters of each algorithm are adjusted so as to optimize the correspondence with the curated complexes, by maximizing the sum of the acc and sep values as done above for the comparative analysis on the unweighted graphs.

on this more realistic network, both ap and mcl were able to predict clusters at all the tested noise levels. the results illustrated in figure  <dig>  show that, as expected, the acc value tends to decrease with added noise for both algorithms, and that the acc of mcl is higher than ap at all noise levels. the shaded areas in figure  <dig> indicate the ranges in the acc and sep values covered by solutions obtained by varying the parameters of the ap and mcl algorithms, respectively. it can be seen from this figure that our parameter selection procedure was successful in identifying parameter values that approximately maximize the acc and sep measures independently at all noise levels.

we also see that at high levels of noise, the results are no longer meaningful as the clusters predicted by either algorithm consist almost entirely of singletons. both algorithms have a slowly decreasing sep as progressively more edges are shuffled. when no artificial noise is introduced, both algorithms are roughly comparable in terms of acc, although the ap solution has slightly lower sep and incorporates  <dig> fewer proteins than mcl , which are classified as singletons. examples of complexes recovered by mcl, but not ap are given in figure s <dig> of the additional file  <dig>  as the level of artificial noise increases to 10%, both algorithms maintain approximately the same number of clusters and proteins. at 20%–30% noise, the optimal mcl solution in terms of acc+sep happens to correspond to a much coarser clustering than that obtained with ap . however, using different inflation values can generate solutions featuring finer granularities with only a minor decrease in acc+sep . overall, at around 60–70% noise predictions from both algorithms begin degenerating into singletons. the relative performance of mcl and ap does not depend on the objective function acc+sep. we verified indeed that at any preference value used for ap, clustering solutions produced by mcl have higher acc and equivalent or higher sep values at all inflation values tested .

to gain insight into how the mcl and ap clustering solutions change as edges are randomly shuffled, we plotted the mass fraction and area fraction  for the optimal clustering at each noise level as found above. the mass fraction of a clustering solution for a weighted graph is simply the fraction of the total edge weight that is entirely contained within clusters. the area fraction assumes that each identified cluster is a clique, and measures the number of these clique edges relative to the total number of edges in a clique of all nodes . we see that for both algorithms, the mass fraction decreased as edges are shuffled – which is expected given that formerly intra-complex edges are being reassigned as inter-complex edges during the shuffling. the area fractions also decreased for both algorithms, suggesting more granular clusterings.

overall we find that mcl tends to generate a more granular clustering in the presence of noise  – although at very low noise levels ap produces more singletons and 2-members clusters than mcl. we also find that the higher acc obtained with mcl in the presence of noise is maintained across the entire range of complex sizes , so that mcl's ability to recapitulate the curated complexes even at high noise levels  is better than ap for complexes of all sizes. in contrast, ap generally produces coarser clusterings as noise is increased, although the number of very large  clusters does decrease, reducing the overall area fraction.

these results, together with the superior acc and sep values obtained with mcl at high noise levels suggest that this algorithm is a better choice for weighted protein interaction networks.

CONCLUSIONS
in summary, our analysis has shown that the mcl procedure is significantly more tolerant to noise and behaves more robustly than the ap algorithm. the advantage of mcl over ap is dramatic for unweighted protein interaction graphs, as ap displays severe convergence problems on the majority of the unweighted graph versions that we tested, whereas mcl continues to identify meaningful clusters, albeit fewer of them, as the level of noise in the graph increases. it is possible that ap as it stands, is not suitable for unweighted networks , although this is not specified in the instructions for using the program or in the original publication <cit> .

on weighted graphs constructed using data from high throughput experiments believed to be incomplete and usually quite noisy, the difference in performance is also notable. mcl achieves higher acc and equivalent or better sep at all significant noise levels. furthermore, at low to moderate noise levels, these solutions include more proteins than ap. parameters for either algorithm can be adjusted to affect the final granularity of the cluster, but either the acc or the sep will be lower.

thus for physical interaction networks, we find that mcl outperforms ap in terms of its ability to generate meaningful partitions. the other cited advantages of the ap algorithm, namely its speed and ability to tackle very large networks, play only a minor role in the present application. indeed both mcl and ap run very fast  on the weighted consolidated network of  <dig>  interactions and  <dig>  proteins. as noise is added to this network, ap can also fail converge at certain preference values , and it can be difficult to determine which parameters will lead to convergence. for example, ap didn't converge at any of the preference values tested for unweighted networks with edges randomly removed. on weighted networks with 30% noise, the algorithm converged at preference values  <dig>  and  <dig>  only . thus for this application, one difficulty in using ap is to determine an appropriate interval and level of granularity for searching preference values. the ap authors provide tools to assist in choosing sensible preference intervals, but not for choosing granularity. in situations where ap does not converge, the authors recommend increasing the damping factor, the maximum number of iterations, and the number of iterations required for convergence – although increasing these parameters can increase the runtime of the algorithm.

the mcl algorithm effectively considers both edge weight and graph topology  information. ap, on the other hand, can fail in situations where high weight edges connect two clusters. consider the artificial situation where two cliques, a and b, are connected by a single, relatively high weight edge. if one of the nodes comprising this edge is an exemplar in clique a, the adjacent node in clique b may be incorrectly assigned to a by ap, despite being highly connected to members of b. this suggests that mcl achieves its robust performance by always considering network topology, whereas ap relies in part on the 'distance metric'  to capture this information. to overcome this limitation one could define a modified distance metric that simultaneously captures both the propensity of two proteins to interact and the graph topology, and re-run ap on the modified graph. to some extent, the pe score is such a metric as higher scores are assigned to proteins that repeatedly co-purify together in affinity capture experiments, and lower scores are assigned to non-specific interactions that occur between promiscuous proteins. indeed, on the pe weighted network of collins et al, the performance of ap is much closer to that of mcl when the network is unperturbed, as randomly shuffling edges distorts the topology information contained in the edge weights. in the unweighted network, where no topological information is captured by the distance metric, ap is only able to successfully cluster unperturbed networks with very few inter-complex edges .

as noted in  <cit> , the relative accuracy and performance of clustering algorithms can vary greatly for different datasets, and this report makes no attempt to address the breadth of problems for which one algorithm outperforms the other.

