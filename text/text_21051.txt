BACKGROUND
biological articles provide a huge amount of information about genes, proteins, their behaviour under different conditions, and their interactions. the handling of huge amounts of unstructured data  has increased in interest along with the application of automatic natural language processing  techniques to biomedical articles. named entity  recognition is the first and crucial step of an information extraction  system and a major building block of an information retrieval  system as well.

the task of biological entity recognition is to identify and classify gene, protein, chemical names in biological articles  <cit> . taken one step further, the goal of gene name normalisation   <cit>  is to assign a unique identifier to each gene name found in a text. the gn task is challenging for two main reasons. first, although synonym  lists which map gene name variants to gene identifiers exist like that given in  <cit> , they are incomplete and they do not contain all the spelling variants  <cit> . on the other hand one name can refer to different entities . chen et al.  <cit>  investigated gene name ambiguity in a comprehensive empirical study and reported an average of 5% overlap on intra-species synonyms, and ambiguity rates of  <dig> %, and  <dig> % on inter-species and against english words respectively. in general, the word sense disambiguation  approaches  are concerned with this crucial problem. their goal is to select the correct sense – from a well-defined sense inventory – of a term according to its context. a special case of wsd task is the gene symbol disambiguation   <cit>  task where the terms are gene names, the senses are genes referred by unique identifiers and the contexts are biological articles.

there are several earlier studies on general biomedical disambiguation tasks like  <cit> , to name but a few. weeber et al.  <cit>  annotated manually a umls-wsd corpus for supervised learning purposes. savova et al.  <cit>  introduced the utility of unlabeled data in general biomedical entity disambiguation. their unsupervised approach looked for clusters among medline abstracts containing the target word, based on single word and bigram, first- and second order co-occurrence information. liu et al  <cit>  built a train set automatically for each target term based on the co-occurrences of unambiguous synonyms in other documents. he also mentioned that disambiguation on this domain has several features which distinguish it from the general english wsd task, mainly the granularity and nature of sense distinctions. in this paper we will examine the potential utilisation of another particular fact, namely that the authors of the documents are known.

when handling the gsd task, the azure system  <cit>  automatically assigns gene names to their locuslink ids based on the naive bayes model and contextual similarity. it extracted the training sets automatically from medline references in the locuslink and swissprot databases. schijvenaars et al  <cit>  also generates the training set automatically from several existing databases. they build up their vector space from mesh terms and gene names identified by string-matching then a cosine similarity metric based disambiguation is applied. the prominer system  <cit>  gn system contains a disambiguation module as well. it utilises the synonyms of the target gene name which are present in the document of the test gene. in this study we present experimental results on the gsd datasets built by xu et al  <cit> . in  <cit>  xu and his colleagues took the words of the abstracts, the mesh codes provided along with the medline articles, the words of the texts and some computer tagged information  as features while in  <cit>  they experimented with the use of combinations of these features. they used them to get manually disambiguated instances  and applied a vector space model with cosine similarity measure between the abstracts in question and the gene profiles which were in fact the centroids of the training instances. as they pointed out, there was not any significant information gain using the texts themselves along with the manually added mesh codes, so we decided to just use these codes along with some novel features like author information and the year of publication.

the gsd datasets for yeast, fly and mouse are generated using medline abstracts and the entrez 'gene2pubmed' file  <cit> , which is manually disambiguated  <cit> . the dataset for human genes was derived  <cit>  from the training and evaluation sets of the biocreative ii gn task  <cit> .

our main idea here is that an author uses gene names consistently, that is they employ a gene name to refer exclusively to one gene in their publications, hence the co-authorship between articles may contain very useful information. in this study we built an inverse co-author graph on medline abstracts and have introduced two methods based on the graph for the gsd task. our methods utilise unlabelled instances  by looking for paths in the graph, thus it can be regarded as a semi-supervised approach in the middle of supervised  and fully unsupervised techniques.

RESULTS
the inverse co-author graph
generalising the hypothesis that an author habitually uses a gene name to refer exclusively to one gene, we can assume that the same holds true for the co-authors of the biologist in question. but what is the situation for the co-authors of the co-authors? to answer this question – and utilise the information obtained from co-authorship in the gsd problem – we decided to use the so-called co-author graph  <cit> . the co-author graph represents the relationship between authors. the nodes of the graph are authors, while the edges represent mutual publications. in the gsd task we basically look for an appropriate distance  metric between pairs of abstracts, hence we define the inverse co-author graph as a graph whose nodes are abstracts from medline  and there is an undirected edge between two nodes if and only if the intersection of their author sets is not empty.

evaluation issues
we carried out experiments utilising the inverse co-author graph on the human, fly, yeast and mouse gsd tasks. for each test instance a geneid set  along with several manually disambiguated abstracts for these geneids  were present. for details of the evaluation data sets and experimental design, see the methods section.

we used two evaluation metrics in our study, namely precision and coverage. they are the standard measures in the document classification community and this allowed us to make a direct comparison between our results and those in  <cit> . as the goal of our first set of approaches was to construct a system with good precision and then extend its results to obtain full coverage, we decided to examine both measures and not apply their aggregation . precision is defined as the ratio of the correctly classified  test gene names and the number of total test examples for which the disambiguation method could make a decision, while coverage is defined as the ratio of test instances with a decision and the number of total test examples. simply put,

 prec=ncnd,cov=ndna 

where nc is the number of correctly disambiguated examples, nd is the number of cases where a decision was made, and na is the size of the total test set.

the path between the test and train articles
in our first approach we examined how strong the co-authorship was between the test article and the train articles. the strength of the co-authorship can be measured as the distance between two nodes in the inverse co-author graph. when two nodes are neighbours the two articles have a mutual author. when a node can be reached in two steps, starting from a node means that the two articles have no mutual authors, but some of the authors have a mutual publication . we looked for the shortest path from the test node to each train example in the inverse co-author graph. among the closest training points  a majority voting was applied i.e. we made a disambiguation decision in favour of the gene with the closest labelled nodes. table  <dig> lists the precision and coverage values we obtained by this method using non-weighted path lengths. a coverage over 90% was achieved on the mouse, fly and yeast datasets by just considering the neighbours of the test nodes, which implies that test nodes and most of the train nodes have a co-author. significantly fewer articles deal with these organisms than with human and these articles can be processed in a higher coverage by the entrez group.

in our experiments we found that if there was a path between the test node and one of the train nodes  its length was at most  <dig>  we did not examine this property on the complete graph, but – interpreting training and test nodes as a random sample of node pairs from the graph – we can suppose that the average minimum path length between nodes  is surprisingly small .

filtering and weighting of the graph
 w=∑2|a∩b|/min⁡, 

where a and b are the sets of the authors of the articles. to get an aggregated, weighted distance for a path we summed the edge-weights  or used the minimum of the edge-weights, i.e. the bottleneck of the path .

after calculating the weighted path lengths for each train node we chose  the label of the node with the maximal weight as the final disambiguation prediction.

the different degrees of filtering resulted in different precision and coverage value pairs. figure  <dig> shows the precision-coverage curves obtained using the three weighting methods . according to these results, ignoring more authors from the co-author graph yields a higher precision but at the price of lower coverage. thus this filtering approach is a parametric trade-off between precision and coverage. a 100% precision can be kept with a coverage of  <dig> % while the best coverage achieved by this method was  <dig> % with a decrease in precision to  <dig> %. the difference between the performance of the three weighting  methods is significant. the right choice of a method can yield a 2–3% improvement in precision at a given level of coverage. the minmax method seems to outperform the other two, but it does not perform well on the unfiltered graph hence we cannot regard it as the ultimate 'winning' solution here.

automatic expansion of the training set
the absence  of training examples in several cases  makes the gsd tasks intractable. to overcome this problem, we extended the labelled set automatically by articles based on the inverse co-author graph. we assumed here that the probability of an author dealing with the same gene in more articles is higher than the probability of dealing with different genes which share an alias. thus we looked for gene aliases among the articles of the authors and hoped that they used a synonym  of the target gene name. for example, caspase in pmid: <dig> can refer to genes with etrezgeneid  <dig> or  <dig> and the document does not contain any synonym belonging to them. one of the authors  has two other publications pmid: <dig> and pmid: <dig> which contain dcp- <dig> , so we assumed that caspase refers to dcp- <dig> in the test abstract. our assumption is questionable but as our experiments show it is true in over 90% of the cases.

we labelled each article in the neighbourhood of the test node with a gene identifier if a synonym of the target gene name was found  in the document. note that the test abstract  can also contain synonyms of the target gene name. in these cases, we made a decision based on this information as well .

after this expansion we made the disambiguation decision via the non-weighted majority voting method on the new set of train samples. table  <dig> shows the precision and coverage values we got with this procedure on the four datasets. these values tell us that the articles with a distance of two hardly ever contain gene aliases, which leads to a slight improvement in the coverage rate. we should add that there is a strong statistical connection between the achieved coverage by this method on the particular organism and the size of the available synonym list and labelled train sets.

we combined the two co-author graph-based methods  to exploit the advantages of both via the following strategy: when there is at least one training node in the neighbourhood of distance  <dig> of the test node on the filtered graph, we accept the decision of that model. if there is no such close train node we try to label new documents with the synonym list and make a decision based on these automatically labelled instances. we got some results by applying two filtering and weighting procedure combinations, one yielding a maximal precision and the other a maximal coverage. the precision and coverage values we got of the combined co-author based method can be found in table  <dig> 

achieving the full coverage
in a real world biomedical application the aim is usually to make a disambiguation decision on every gene mention found. as the last rows of table  <dig> and  <dig> make clear, the maximum coverage which can be achieved by our best inverse co-author graph based methods is about 85% on human . in the last part of our experiments we investigated what effect our co-author graph based heuristics has in a gene disambiguation system which runs on 100% coverage.

we employed two methods, namely the similarity-based procedure introduced by  <cit>  and a supervised machine learning  approach. we used information provided by medline as features including the mesh headings and information about the release of the articles, the journal title, and the year of publication. table  <dig> summarises the results of these two methods applied separately and in combination with the co-author-based heuristics. in this final hybrid system we first applied these two co-author graph-based procedures with filtering to get the highest precision. then as a second step, we applied a similarity or machine learning technique on the instances where the first step could not make any decision.

the first row of table  <dig> lists the precision and coverage values of a baseline method. as a standard in wsd, we used the baseline of choosing the majority sense  of each gene mention.

¿from a supervised learning point of view the co-author graph-based heuristics eliminate 80% of the errors , while from the co-author graph point of view the doubtful examples can be predicted with an 80% precision by supervised techniques, thus yielding a full coverage with an aggregated precision of  <dig> %.

discussion
differences among species
there are quite significant differences among the tasks of the given species. the human gsd evaluation set is without doubt the most difficult one for the co-authorship-based approaches because of the extremely large number of articles which focus on this organism and the relative modest number of average training samples available. the co-authorship method achieves precision values over 99% with a coverage of over 92% on the other three datasets. the final results with a complex method  correlate with the baseline values  i.e. mouse is the best performing one and a lower precision is obtained on human and fly. the final results on yeast are surprising as baseline methods on this dataset performed the worst but achieved the best results when the co-authorship-based methods were applied . we think that this is because of the small amount of articles which focus on this organism, which might imply a smaller author society with stronger relationships.

features and methods used
in our experiments we used several kind of features. the main contribution of this work, the path-length in the inverse co-author-based method, just uses the authorship information of the whole medline corpus and some manually annotated abstracts . the extension of the training set based on the co-author graph and synonym lists is one step closer to the "classical" context-based approaches – namely looking for gene names in the text of the abstracts. this method can be regarded as a generalization of the one in  <cit>  because we search co-authored documents as well, but it is less sophisticated those described in  <cit>  and  <cit> , both of which use external general mesh term indexing software. in the final supervised learning phase we used a feature set which included mesh headings , the title of the journal and the year of publication but we did not make use of the text itself. there were several reasons for this. first of all, the manually added mesh headings represents very well the biological concepts of the article in a normalised and disambiguated way. second, the empirical results of  <cit>  on two evaluation sets shows that using the words of the text along with mesh headings could not achieve any significant improvement. we also examined the potentials of the combined usage of headings and text  in preliminary experiments but no significant improvement was found either hence the text itself was left out for time complexity reasons.

the difference between the baselines and the purely supervised models and the difference between supervised models and final models which employ co-author graph-based heuristics are statistically significant, due to the mcnemar's test with a p <  <dig>  confidence level, but the difference between the two supervised models was below the statistical level of significance. this holds true for the cases of their usage in the final cascade systems as well. the decision tree  can differentiate the features in a more sophisticated way than the vector space model can. furthermore, the decision tree can learn complex rules like "the papers released before  <dig> and containing mesh code x but not containing mesh code y are...". however, with these complex modeling issues it could not achieve a statistically significant difference compared to the similarity-based approach. this could be because of the small training sets and overfitting. but we suggest using decision trees because its learnt model is human readable so a domain expert can understand and modify it when necessary.

our results are directly comparable just to xu et al's results. table  <dig> lists the situation where just the features embedded in medline were used by both systems, but we achieved better results  than the best system of xu et al  <cit> , who employed external automatic annotation tools  as well.

limitations of the approach
the most obvious limitation of our co-authorship based approach is that it is dependent on a training set derived from manual disambiguated annotation by the entrez group. on viewing table  <dig>  we see that if the number of annotated articles were higher the gsd task would become a trivial one. there are two factors of the graph construction approach which seem to be negligible but nevertheless deserve a mention here. first, an edge is drawn between nodes because of string matching of the author names. of course, the names of the authors are also ambiguous as two authors with the same name does not necessary mean they are one and the same person. second, there should be author-gene pairs which occur in just one publication. in these cases the inverse co-author graph could not help and contextual information has to be taken into account.

when we analysed the misclassified entities we found that most of the errors of two co-author graph-based methods could be eliminated by a sophisticated synonym matching algorithms. our simple string matching approach, it transpires, has two main shortcomings. it does not handle the spelling variants of the gene aliases  and it does not deal with embedded named entities i.e. it matches gene names that are just a substring of a longer name like the name of a protein. the errors of the supervised systems  could probably be eliminated if bigger training sets were available.

CONCLUSIONS
in this paper we examined the utility of co-authorship and experimentally demonstrated the utility of co-authorship analysis for the gsd task. our hypothesis was that a biologist refers to exactly one gene by a fixed gene alias, and in experiments we found evidence for this. moreover, we found that a disambiguation decision can be made in 85% of the cases with an extremely high precision rate  by just using information obtained from the inverse co-author graph. if we need to build a gsd system with a full coverage we can incorporate the co-authorship information into the system and by doing so eliminate about the half of the errors of the original system.

based on the promising results obtained so far from our study, we suppose that for abstracts the co-authorship information, the circumstances of the article's release  and a graph constructed above, can all be crucial building blocks for a sophisticated similarity measure among biological articles and therefore the methods introduced here ought to be useful for other biomedical natural language processing tasks as well. for example, we can reasonably assume that a biologist or biologist author group usually deals with the same special species. hence a co-author graph-based method could be a powerful tool in the identification of the organism dealing with in an article. in addition, all text classification and clustering tasks can achieve better results with a sophisticated similarity measure. besides the biological named entity disambiguation tasks , a task could for instance be one for target disease identification or protocol detection.

