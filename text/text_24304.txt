BACKGROUND
automated interpretation of protein subcellular location
among the most important goals in biological sciences today is to understand the function of all proteins. one of the critical characteristics of a protein is its subcellular location, that is, its spatial distribution within the cell. knowledge of the location of all proteins will be essential for building accurate models that capture and simulate cell behavior, and eventually can be expected to be useful for early diagnosis of disease and/or monitoring of therapeutic effectiveness. the most widely used method for determining protein subcellular location is fluorescence microscopy. given that mammalian cells are believed to express tens of thousands of proteins, comprehensive analysis of protein location will require acquisition of numbers of images that are beyond our ability to analyze visually.

fortunately, the feasibility of automated interpretation of subcellular patterns in fluorescence microscope images has been clearly demonstrated over the past ten years, initially by our group  <cit>  and then by others  <cit> . the result is systems that can classify protein location patterns with well-characterized reliability and better sensitivity than human observers . the heart of such systems is a set of numerical features – subcellular location features  – to describe the spatial distribution of proteins in each cell image. the slfs include haralick texture features, morphological features, and zernike moments. of particular relevance to the work described here is that the addition of simple multiresolution features resulted in a significant improvement of classification accuracy, to the highest reported accuracy of  <dig> % for the 2d hela data set. this dataset contains images of all major subcellular patterns and is a well-established testbed for evaluating subcellular pattern analysis approaches. note that with the aid of a parallel dna channel, that accuracy climbed to  <dig> %. it is important to have methods that work well when dna images are available and also when they are not. we focus here on analysis of patterns without parallel dna images and on improving performance relative to the best previous results.

multiresolution techniques
as the introduction of the simplest multiresolution  features produced a statistically significant jump in classification accuracy, our aim is to explore more sophisticated multiresolution techniques. in particular, the following are the three characteristics of multiresolution  <cit>  we wish to explore: 

 localization: fluorescence microscope images have highly localized structures both in space and frequency. this leads us to mr tools, as they have been found to be the most appropriate tools for computing and isolating such localized structures  <cit> .

 adaptivity: given that we are designing a system to distinguish between classes of proteins, it is clear that an ideal solution is to use adaptive transforms, a property provided by mr techniques. the reasoning is that if there is a different mr transform for each different class, then the transform itself would help in distinguishing the class.

 fast and efficient computation: it is well known that mr techniques such as wavelets have a computational cost of the order o, where n is the input size, as opposed to o typical for other linear transforms including the fft. this is one of the major reasons for the phenomenal success of mr techniques in real applications and one of the reasons to incorporate mr features into the system. 

mr transforms are many; we now give a brief overview. the basic idea behind mr is that we can look at a signal at different scales or resolutions and at different points in time. this should give us information about hidden structures in the signal, with a particular behavior across scales.

the main building block of any mr transform is a filter bank  <cit> ; it is a device that splits the signal into mr subspaces , where each mr subspace contains one part of the signal's spectrum. as an example, in the top part of figure  <dig>  a two-channel filter bank is given, operating on a 1d signal. for images, on both rows and columns , the signal is filtered, followed by downsampling by two . in the simplest case, this produces four subbands; one extracting lowpass information in both directions, one extracting highpass information in both direction and the remaining two extracting lowpass information in one direction and the highpass information in the other. the example in the lower part of the figure shows such a filter bank applied to each subband again , as we will use in this paper.

adaptivity of mr transforms manifests itself in many guises, including a number of popular transforms:  growing a full tree to l levels with specific filters of the same length as the downsampling factor yields the discrete fourier transform  of size 2l.  growing a full tree to l levels but allowing the filters to be longer, leads to the short-time fourier transform, or, the gabor transform.  growing the tree only on the lowpass branch to l levels leads to the l-level discrete wavelet transform .  growing an arbitrary tree leads to wavelet packets .  splitting the signal into more than two channels, allowing filters in the above transforms to be orthogonal and/or linear phase, allowing for true multidimensional filters and/or samplers, etc., leads to even more degrees of freedom.

towards multiresolution classification
we now summarize our initial mr classification effort  <cit> . we started with a simple classification system consisting of haralick texture feature computation followed by a maximum-likelihood classifier, and demonstrated that, by adding an mr block in front, we were able to raise the classification accuracy by roughly 10%  as compared to the system with no mr. this fits within our generic framework shown in figure  <dig>  where the feature computation block uses haralick texture features and the classification block is maximum likelihood. we concluded that selecting features in mr subspaces allows us to custom-build discriminative feature sets. however, although the multiresolution block substantially increased classification accuracy, the accuracy of the overall system was still not high enough, and thus, in this work, we reexamined each step of the system: the features used, the classifier, and the weighting process.

RESULTS
problem statement and philosophy
the problem we are addressing is that of classifying the spatial distribution patterns of selected proteins within the cell. assume that the images are of size n × n and let ℝ denote the set of intensities covered by all the images in the given dataset, compactly represented as an image belonging to ℝn × n. then, the problem can be formulated as designing a map from the signal space of protein localization images x
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfxepwaaa@384f@ ⊂ ℝn × n, to a response space y
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfyefwaaa@3851@⊆{ <dig>   <dig> ..., c} of class labels. thus, decision d is the map, d: x
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfxepwaaa@384f@ ↦ y
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfyefwaaa@3851@ that associates an input image with a class label  <cit> . to reduce the dimensionality of the problem, one sets up a feature space ℱ
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfxeiraaa@3787@⊂ ℝf, f ≤ n <dig>  between the input space and the response space. the feature extractor θ is the map θ:x
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfxepwaaa@384f@ ↦ ℱ
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfxeiraaa@3787@, and the classifier ψ is the map ψ: ℱ
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfxeiraaa@3787@ ↦ y
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbamrthrhal1wy0l2yhvtyaehbnfgdovwbhrxajfwnaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabawaaegaeaaakeaaimaacqwfyefwaaa@3851@. the goal is to find a  pair that maximizes the classification accuracy.

to evaluate mr approaches, we use the well-characterized 2d hela set described previously  <cit> . the proteins in the data set were labeled using immunofluorescence, and thus, we know the ground truth, that is, which protein was labeled in each cell and subsequently imaged. this is useful for algorithm development as we can test the accuracy of classification schemes.

the challenge in this data set is that images from the same class may look different while those from different classes may look very similar . based on the above discussion, we would like to extract discriminative features within space-frequency localized subspaces. these are obtained by mr decomposition; that is, instead of adding mr features as in  <cit> , we compute features in the mr-decomposed subspaces. thus, our system is a generic system with an mr decomposition block in front , followed by feature computation and classification in each of the subspaces. these are then combined through a weighting process. the hypothesis we test here is that adaptive classification in mr subspaces will improve the classification accuracy.

base system 
we denote as no mr  the system consisting of the feature computation and the classifier blocks . in our previous mr work, we used a maximum likelihood classifier that assumed the data to be well-separated gaussian distributions, an assumption we found not to fit the data well. instead, due to their simplicity and generality, we decided to use a two-layer neural network classifier. the first layer contains a node for each of the input features, each node using the tan-sigmoid transfer function. the second layer contains a node for each output and uses a linear transfer function . we then train the neural network using a one-hot design, that is, since each output from the second layer corresponds to a class, when training, each training image will have an output of  <dig> for the class of which it is a member and a  <dig> for all other classes. to maximize the use of our data, our training process of the neural network block uses five-fold cross validation.

we ran the classifier with selected combinations of the three feature types used previously  <cit>  . these are: morphological features , haralick texture features  and zernike moment features . the results obtained are given in the first row of table  <dig>  we can see that the most powerful features on their own are texture features t <dig>  yielding  <dig> % classification accuracy. because of that, we looked into other texture feature sets, such as the second haralick set from  <cit>  we termed t <dig>  which produced a slightly better result of  <dig> % . by examining these feature sets more closely, we developed a novel version of haralick texture features, termed t <dig> . with this set, the classification accuracy of the nmr system jumped to  <dig> % . we also ran the experiment for all possible combinations of feature sets, as shown in the first three rows of table  <dig>  we found that, while the addition of other feature sets to t <dig> did not increase the accuracy significantly, it did increase the number of features and thus computational complexity. this "flat" trend will turn out be general, as we will show later.

t <dig> are the original haralick texture features, t <dig> are modified haralick texture features from  <cit>  and t <dig> are our improved texture
features. nmr denotes the base system with no mr, mrb denotes mr basis classification and mrf denotes mr frame classification. of denotes open-form weighting algorithm while cf denotes closed-form weighting algorithm. nw denotes no weighting as there is no mr block in front. each entry is a number denoting the classification accuracy mean over a number of trials  for a given combination of feature sets. note that the accuracy of nmr with features m is the same across the rows t <dig>  t <dig>  t <dig> since texture features are not involved in the classification when morphological features alone are used . a subset of these results is shown pictorially in figure  <dig>  these results should be compared to the best previously obtained result  of  <dig> %  <cit> .

mr bases 
we now implement our main idea of adding an mr block in front of feature computation and classification, as in figure  <dig>  we start with the mr decomposition being a basis expansion . we grow a full tree to two levels with haar filters . we then test the system with all feature combinations, a neural network classifier as well as two versions of the weighting algorithm .

the classifier is evaluated using nested cross validations . one problem with this technique is that the initial ordering of the images determines which images are grouped together for training and testing in each fold of the cross validation. a different original ordering of the images would result in different groupings, which would be equivalent to presenting different data sets to the classifier, and would thus result in a different overall result. we solve this problem by running multiple trials, each with a random initial ordering of the images. the mean result of these trials is taken as our true classification accuracy. in our experiments, we perform ten-fold cross validation on the weight calculation.

we note the following trends:  for all feature combinations, mrb significantly outperforms nmr, thus demonstrating that classifying in mr subspaces indeed improves classification accuracy.  for the two versions of the weighting algorithm, open form and closed form, the closed-form algorithm slightly outperforms the open-form one for all feature combinations except for m alone . in particular, for texture features t <dig>  the accuracy rose slightly, from  <dig> % to  <dig> %.  while a slightly higher classification accuracy is obtained by using all three feature sets  as well as both t and m , the larger number of features and additional complexity of using m and z features do not justify the slight improvement in accuracy . as for nmr, this "flat" trend is good news as we can use a significantly reduced feature set and still obtain a fairly high classification accuracy.

while we were satisfied that our hypothesis seems to be true, that is, classifying in mr subspaces increases classification accuracy significantly, we decided to look more closely into how we can improve the system even more. a known issue with mrb is that they are not shift invariant . this is due to downsampling used and can create problems as shifted versions of data can lead to different features in mr subspaces.

our hypothesis is that shifts in the testing set produce reduced classification accuracy. we test this hypothesis by running the algorithm with t <dig> features alone and with shifts of t =  <dig>   <dig>   <dig>   <dig> horizontally and vertically in the testing set . as expected, the classification accuracy drops by  <dig> %.

this experiment strongly indicates the use of mr techniques which are shift invariant . these are called frames and we examine them next.

mr frames 
the simplest mr frame which is completely shift-invariant is called à trous  <cit>  and is obtained by removing downsamplers  from the scheme. this leads to redundancy but avoids the problem of shift variance. the results of the experiments with mr frames  are given in the last two rows of table  <dig> .

as for mrb, the three trends are similar:  mrf outperforms mrb .  the closed-form algorithm outperforms the open-form one whenever t <dig> set is involved.  again, the "flat" trend continues: the difference between using t <dig> only as opposed to t <dig>  m or all feature sets is so minor that the added number of features is not worth the complexity. we highlight these trends pictorially in figure  <dig> 

discussion and future work
classification of protein subcellular images was indeed significantly improved by classifying in mr subspaces. one reason for this improved performance over the system using the inherently mr features is that those features are simply energies in the subbands, while here, the features can be any suitable set, leading to a more general space of solutions. a reason for the improved performance of the mr systems over the nmr one could be intuitively understood if we assumed that this data set is highly "texture"-like. for example, it is possible for two different textures to have the same set of haralick texture features , while when decomposed, even at the first level, their co-occurrence matrices would be different, leading to different haralick texture features, and thus discriminative power. an example of this is given in the compendium to the paper .

we plan on exploring a number of issues in our future work.  for example, our system effectively builds an adapted mr decomposition  for the whole data set; we want to adapt that decomposition to each class, arguing that a different mr decomposition for a different class would be a discriminative feature in itself. we are currently working on this by adapting the closed-form algorithm.  we would also like to explore whether improved performance can be obtained by incorporating feature selection methods during classifier training for each subband, as was done in the original work in  <cit> .  it will also be of interest to explore how and whether to include information from parallel dna images, since this information improved nmr-based classification accuracy in  <cit>  from  <dig> % to  <dig> %. this improvement is because the parallel dna image provides a frame of reference for distinguishing proteins that are inside or near the nucleus from those with similar patterns that are not.  lastly, we would like to find a cost function that would allow us to explicitly build wavelet packets. while we implicitly do this now using weights, it would lead to improved computational efficiency if we had a method for building a subtree as opposed to using all the subbands.

CONCLUSIONS
this paper addresses automated and robust classification of major protein subcellular location patterns. with the introduction of a multiresolution approach, we are able to obtain a high classification accuracy of  <dig> % with only  <dig> texture features, proving that adaptive mr techniques improve the classification of the 2d hela data set.

