BACKGROUND
the result of every analysis of microarray data is an outcome of a random experiment. for example, the number of genes declared differentially expressed and the estimated false discovery rate  should be treated as random variables and their variability has to be assessed in the same fashion that the population variance is estimated in the usual statistical inference. the variance of the number of differentially expressed genes  may depend on the chosen statistical test, method of multiple testing adjustment, effect sizes for different genes, and the correlation structure of the data. the latter factor deserves special attention. although some normalization procedures may lead to a significant reduction in the correlation between gene expression levels, and thus between the associated test statistics, the remaining correlation may be strong enough to have a disastrous effect on the statistical inference from microarray data  <cit> . the effect correlations in microarray data on variability of the most basic performance indicators of various testing procedures calls for further investigation.

there is another facet of the problem to consider. every specific analysis of microarray data results in a list of candidate genes that are deemed differentially expressed across the two conditions under study. the composition of this list is subject to random fluctuations and this effect also needs to be quantitatively assessed. even if one concentrates on the selection of individual genes rather than gene combinations, the situation here is similar to that in the regression analysis aimed at selecting significant explanatory variables . when focusing on a specific variable, one can observe a certain degree of instability of this variable selection inherent in any pertinent statistical procedure. the term "stability" means "replication stability" for the selection of significant variables. this kind of stability is easy to assess and interpret in simulation studies where the "true" set of differentially expressed genes is known. when analyzing biological data, one can resort to resampling techniques for this purpose  <cit> . in particular, one can apply a subsampling counterpart of the "delete-d-jackknife" procedure to the sample at hand and estimate the frequency with which a given gene has been selected across all sub-samples. then an additional selection criterion can be imposed by finally selecting only those genes with a frequency of selection greater than, say, 80%.

the above discussion suggests the following two ways of using resampling techniques in microarray data analysis. these techniques can be used to assess stability characteristics of a given selection procedure and compare different procedures. in this case, one is usually interested in certain characteristics of the whole set of selected genes rather than its individual members. in their very interesting paper, pavlidis et al.  <cit>  used leave-one-out resampling to study the stability of gene selection in conjunction of the required number of replicates in the analysis of differential expression of genes. the authors proposed two stability measures  to compare the ranked list of the genes originally selected to the ranking obtained when one replicate is removed. then the stability measures are averaged over the subsamples. the first measure refers to the fraction of genes among the originally selected ones that are recovered in a given subsample. stolovitzky  <cit>  proposed a similar measure which is not conditioned on the set of genes originally selected from the data prior to resampling. however, statistical properties of the robustness index introduced by stolovitzky remain unclear. the second measure by pavlidis et al.  <cit>  is more subtle; it has to do with the degree to which the ordering is preserved and can be used whenever the number of selected genes does not show strong variations among subsamples. we propose the delete-d-jackknife variance of the number of selected genes  across subsamples as a pertinent measure of stability of a chosen testing procedure. this measure has clear statistical properties and is easier to interpret. the distribution of the number of selected genes can also be estimated using the delete-d-jackknife method  <cit> . another way of using resampling techniques is to assess the stability of selection for individual genes in line with the currently practiced methodology of significance testing in microarray analysis. this can be accomplished by estimating the frequency of selection of each gene given it has been selected at least in one subsample. as we show in the present paper, this measure also provides valuable information on the performance of each selection procedure when its dependence on adjusted p-values is included in the analysis.

we have conducted a simulation study to evaluate the effect of correlation between gene expression levels on the performance of several selection procedures in terms of the variability of such important indicators as the number of selected genes and the proportion of falsely rejected among all rejected null hypotheses. all these indicators are directly accessible in computer simulations, thereby providing an explanatory insight into the performance of different procedures. from this perspective, the bonferroni and westfall-young multiple testing procedures are explored in conjunction with the student t, kolmogorov-smirnov, and cramér-von mises two-sample tests. the latter two tests are distribution free. the bonferroni and westfall-young step-down procedures  <cit>  are designed to control the familywise error rate . the fwer is defined loosely as the probability of at least one type  <dig> error in the context of multiple testing. the fdr-based procedures are also explored; these are represented by the empirical bayes method  <cit>  as well as the benjamini-hochberg and benjamini-yakutieli procedures  <cit> . the fdr is defined as the expected fraction of falsely rejected among all rejected hypotheses. it should be noted that our simulation studies do not attempt to model the actual correlation structure of microarray data; their only purpose is to see which specific performance indicators may be sensitive to the presence of correlation in the data. the quantitative characteristics we report from the simulated data cannot be extrapolated to biological data and can only be viewed as proof of principle.

another set of experiments was concerned with actual biological data. we assessed probabilistic characteristics of the number of selected genes by resampling from a large set of data on two types of childhood leukemia available from the st. jude children's research hospital database  <cit> . using this data set, we also assessed the replication stability of gene selection and its dependence on adjusted p-values.

methods
biological data
for the purposes of this study, use was made of the st. jude children's research hospital  database on childhood leukemia which is publicly available on their website under the supplemental data section:  <cit>  the whole sjcrh database contains gene expression data on  <dig> subjects, each represented by a separate array  reporting measurements on the same set of  <dig> genes. we selected two groups of patients with hyperdiploid  and t-cell acute lymphoblastic leukemia , respectively. the groups were balanced to include  <dig> patients in each group. since the nature of our study was purely methodological, the choice of the data set was quite arbitrary; it was dictated solely by sample size considerations. the microarray data thus chosen were background corrected and normalized using the bioconductor rma software. this software implements the quantile normalization procedure  <cit>  carried out at the probe feature level. after the normalization, each gene is represented in the final data set by the logarithm  of its expression level.

simulated data
our simulation study was designed to illustrate the effect of correlation on the performance of gene selection procedures. we simulated 2n independent multi-variate normal random vectors with exchangeable correlation structure, each representing log-intensities of  <dig> genes of which the first  <dig> genes were designated to be differentially expressed. two sets of simulations were conducted with the sample size chosen to be n =  <dig> and n =  <dig>  respectively. we use the following self-explanatory notation for the four sets of simulated data: sim <dig>  sim15corr, sim <dig>  sim43corr. in total,  <dig> independent data sets, each consisting of 2n simulated vectors, were generated for each sample size. the marginal distributions of the log-intensities of "not different" genes were standard normal, while the log-intensities of "different" genes expressions followed the normal distribution with mean two and unit variance.

the exchangeable pairwise correlation structure was superimposed on the normal vectors with independent components as discussed in  <cit> . briefly, we first generate a  <dig> × 2n matrix with each entry being an independent realization of a standard normal random variable. to model a set of "different" genes, we add a value of  <dig> to the first  <dig> rows in the first group and denote the resultant matrix by x = {xij}, i =  <dig>  ..., 1255; j =  <dig>  ..., 2n. all the elements xij of this matrix are stochastically independent, but those with i =  <dig>   <dig>  ...,  <dig> and j =  <dig>   <dig>  ..., n are normally distributed with mean  <dig> and unit variance. expression levels of the genes outside this special set of  <dig> genes follow the standard normal distribution. next we generate a 2n-dimensional random vector with independent and identically distributed components, each component having a standard normal distribution. denote this vector by a = {aj}, j =  <dig>  ..., 2n. define yij=ρaj+1−ρxij
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwg5bqedawgaawcbagaemyaakmaemoaaogabeaakiabg2da9maakaaabaaccigae8xwdihaleqaaogaemyyae2aasbaasqaaiabdqgaqbqabagccqghrawkdagcaaqaaiabigdaxiabgkhitiab=f8aybwcbeaakiabdiha4naabaaaleaacqwgpbqacqwgqbgaaeqaaaaa@3fe1@, i =  <dig>  ..., 1255; j =  <dig>  ..., 2n, so that for any i <dig> ≠ i <dig> and j we have corr  = ρ in the present study, the correlated data were generated for a single value of the correlation coefficient ρ =  <dig> . this high correlation coeffcient was chosen to more clearly demonstrate the effects of correlation. however, this value is not overly unrealistic because the mean  correlation coefficient estimated from the raw data referred to in section  <dig>  is equal to  <dig> .

in order to see whether or not the stability of gene selection is related to the power, our explanatory simulations were conducted under two different scenarios. under the first scenario, the sample size was small  so that the power was lower than 100%. under the second scenario the sample size was sufficiently large  to attain a 100% power.

resampling techniques
when analyzing biological data, we used a subsampling version of the delete-d jackknife method  <cit> , which is technically equivalent to the leave-d-out cross-validation. it can be proven that if n
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaadagcaaqaaiabd6gaubwcbeaaaaa@2e2c@/d →  <dig> and n - d → ∞, then the delete-d-jackknife is consistent for the median  <cit> . therefore, the general recommendation is to leave out more than d = n
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaadagcaaqaaiabd6gaubwcbeaaaaa@2e2c@ but much fewer that n observations. a similar recommendation holds for the variance  <cit> . we used d =  <dig> to perturb the data set, which is only slightly greater than n
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaadagcaaqaaiabd6gaubwcbeaaaaa@2e2c@, to be as close as possible to the most widely used delete-one version of jackknife. it should be noted that the delete-1-jackknife method may be inconsistent for some estimators  and the delete-d-jackknife was proposed to remedy this problem  <cit> . when implemeting the delete-d-jackknife method, we resorted to sampling without replacement because the empirical bayes method is very sensitive to ties. as far as subsampling versions of the delete-d-jackknife method are concerned, the schemes with and without replacement are essentially identical when the number of subsamples is large  <cit> .

the total number of subsamples was typically equal to  <dig>  in a separate study, we ascertained that the results for  <dig> subsamples were largely similar. let z be the number of selected genes. the variance of z is estimated by a resampling counterpart of the jackknife sample variance  <cit> :

v=n−ddb∑l=1b <dig> 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgwbgvcqgh9aqpdawcaaqaaiabd6gaujabgkhitiabdsgakbqaaiabdsgakjabdkeacbaadaaewbqaamaabmaabagaemowao1aasbaasqaaiabd6gaujabgkhitiabdsgakjabcycasiabdygasbqabagccqghsisldawcaaqaaiabigdaxaqaaiabdkeacbaadaaewbqaaiabdqfaanaabaaaleaacqwgubgbcqghsislcqwgkbazcqggsaalcqwgrbwaaeqaaaqaaiabdugarjabg2da9iabigdaxaqaaiabdkeacbqdcqghris5aagccagloagaayzkaaaaleaacqwgsbabcqgh9aqpcqaixaqmaeaacqwgcbgqa0gaeyyeiuoakmaacaaaleqabagaegomaidaaogaeiilawcaaa@5779@

where b is the total number of subsamples , zn-d, j is the statistic z evaluated at the jth delete-d jackknife subsample. the variance of the number of selected genes was used as a criterion of stability of the testing procedures under study. the corresponding distributions were also estimated. another criterion was the selection stability for each individual gene measured by the frequency of selection conditional on the event of selection in at least one of the subsamples.

selection of differentially expressed genes
when resorting to the bonferroni adjustment, one needs to compute unadjusted p-values from the sampling distribution of the test statistic under consideration. for the t-test we used quantiles of the student distribution. among the distribution-free methods, the cramér-von mises test  <cit>  represents an appealing alternative to the kolmogorov-smirnov test. the reason is that the granularity of the cramér-von mises statistic  is much smaller than that for the kolmogorov-smirnov test. as a result, the p-values corresponding to the critical region increase much more steeply for the kolmogorov-smirnov test than for the cramér-von mises test, thereby making the kolmogorov-smirnov test less powerful.

to describe the cramér-von mises test, consider two independent samples x <dig>  x <dig>  ..., xm and y <dig>  y <dig>  ..., yn from distributions f and g, respectively, and let fm and gn be their respective empirical distribution functions. we wish to test the following null hypothesis h0:f = g for all x versus the alternative: f ≠ g. the cramér-von mises test-statistic for the hypothesis h <dig> is defined as the  l <dig> distance between fm and gn:

w2=mn2{∑i=1m2+∑j=1n2}.
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgxbwvdaahaawcbeqaaiabikdayaaakiabg2da9maalaaabagaemyba0maemoba4gabagaeiikagiaemyba0maey4kasiaemoba4maeiykakyaawbaasqabeaacqaiyagmaaaaaowaaiwaaeaadaaewbqaaiabcufabjabdaeagnaabaaaleaacqwgtbqbaeqaaogaeiikagiaemieag3aasbaasqaaiabdmgapbqabagccqggpaqkcqghsislcqwghbwrdawgaawcbagaemoba4gabeaakiabcicaoiabdiha4naabaaaleaacqwgpbqaaeqaaogaeiykakiaeiyxa01aawbaasqabeaacqaiyagmaagccqghrawkdaaewbqaaiabcufabjabdaeagnaabaaaleaacqwgtbqbaeqaaogaeiikagiaemyeak3aasbaasqaaiabdqgaqbqabagccqggpaqkcqghsislcqwghbwrdawgaawcbagaemoba4gabeaakiabcicaoiabdmha5naabaaaleaacqwgqbgaaeqaaogaeiykakiaeiyxa01aawbaasqabeaacqaiyagmaaaabagaemoaaomaeyypa0jaegymaedabagaemoba4ganiabgghildaaleaacqwgpbqacqgh9aqpcqaixaqmaeaacqwgtbqba0gaeyyeiuoaaogaay5eaiaaw2haaiabc6cauaaa@722f@

the asymptotic theory for the cramér-von mises test was developed by anderson and darling  <cit> , rosenblatt  <cit> , anderson  <cit> , and csorgo and faraway  <cit> . the asymptotic approximation of the distribution of w <dig> under h <dig> is of little utility in microarray data analysis because it is very inaccurate whenever one works with extremely small p-values required by the fwer controlling multiple testing procedures. for example, when n = m =  <dig> and the exact p-value for the cramér-von mises test is equal to  <dig>  × 10- <dig>  its asymptotic approximation gives  <dig>  × 10- <dig>  a much larger p-value. the above-mentioned exact p-value of  <dig>  × 10-6corresponds to the adjusted  p-value of about  <dig>  when testing  <dig> hypotheses as in our application described in section  <dig> . therefore, one needs an algorithm for computing exact quantiles of the cramér-von mises sampling distribution. we used the method proposed by burr  <cit>  for this purpose. it should be noted that the needed small p-values for the cramér-von mises test cannot be estimated with sufficient accuracy by permuting the test-statistics, because the required number of permuations is astronomical  <cit>  and cannot be accomplished with present-day hardware.

the westfall-young step-down algorithm  <cit>  bypasses the stage of computing unadjusted p-values and goes directly to the estimation of adjusted p-values at a given level of the fwer. we carried out  <dig>  permutations to model a null distribution of each test statistic. we also used the multiple testing adjustment proposed by benjamini and hochberg  <cit>  and its modification by benjamini and yekutieli  <cit> . the more conservative benjamini and yekutieli procedure is warranted with normalized data because the quantile normalization is known to induce negative correlations in microarray data  <cit> . the nonparametric empirical bayes method by efron et al.  <cit>  was one more method of choice in the present paper. we used kernel smoothing  for density estimation to implement the empirical bayes method. the threshold level of the posterior probability was set at  <dig> .

to distinguish between different statistical procedures, we use the following notation:

b/t – t-test with bonferroni adjustment;

b/ks – kolmogorov-smirnov test with bonferroni adjustment;

b/cvm – cramér-von mises test with bonferroni adjustment;

wy/t – t-test with westfall-young algorithm;

wy/ks – kolmogorov-smirnov test with westfall-young algorithm;

wy/cvm – cramér-von mises with westfall-young algorithm;

bh/t – t-test with benjamini-hochberg adjustment;

by/t – t-test with benjamini-yekutieli adjustment;

eb/t – t-test with gene selection by nonparametric empirical bayes method.

false discovery rate and power
we provide estimates of the fdr only for simulations. we do not report fdr estimates for biological data because only indirect methods  <cit>  are available in this case. such methods introduce an additional variation in the estimates which is impossible to distinguish from that caused by a given selection procedure. in our simulation studies, the true fdr was estimated directly as the proportion of false discoveries among all discoveries. then the sample mean  of this nonparametric estimate is reported together with the corresponding standard deviation. it happened only once  that we set the estimated fdr at zero . since the expression levels of the  <dig> differentially expressed genes are identically distributed, the power can be defined as the expected proportion of correct discoveries among the  <dig> true alternative hypotheses. we provide the usual nonparametric estimates of the power thus defined and its standard deviation.

software
the relevant software is included in the additional material files .

RESULTS
analysis of biological data
shown in figure  <dig> are the proportions of genes with different frequencies of selection among those genes that have been selected at least once in the course of delete-seven subsampling. it is seen from this figure that the histograms are u-shaped so that one can distinguish two extreme groups of genes characterized by high and low stability, respectively. the proportions of genes in each "intermediate-frequency" category are relatively small. this phenomenon persists for all the statistical tests under study when the fwer is controlled either by the bonferroni adjustment or by the westfall-young permutation algorithm. it is clear from figure  <dig> that the population of genes selected at least once across all subsamples is heterogeneous with respect to their stability characterized by the frequency of selection.

to gain a better insight into this heterogeneity, it makes sense to look at the relationship between the frequency of occurrence and the corresponding p-values. to this end, we produced scatter-plots for the frequency of occurrence in the set of selected genes across the sub-samples and the original adjusted p-values determined by the application of each testing procedure to the whole set of arrays. the results for the t-test with bonferroni adjustment are given in figure  <dig>  the leave-seven-out resampling reveals a non-linear  pattern showing that the relationship in question may be quite complex. for comparison, we also present the result for the leave-one-out procedure, in which case the dependence appears to be almost linear but the scatter of points is wide because this procedure does not perturb the data sufficiently. in what follows, we will discuss only the observations resulted from the delete-7-jackknife subsampling.

the results for the t-test and the cramér-von mises test with bonferroni adjustment are compared in figure  <dig>  it is clear that the genes selected by the cramér-von mises test are uniformly more stable than those selected by the t-test. the difference is much less pronounced with the westfall-young algorithm as evidenced by figure  <dig>  both multiple testing procedures yield similar scatter plots for the t-test showing its overall poor stability in comparison to the cramér-von mises test . in contrast, the stability of the cramér-von mises test can be increased substantially when using the more conservative bonferroni adjustment in place of the westfall-young procedure . these results show that the stability of gene selection provides an important additional information on each selected gene and this information can be extracted from real data by resorting to resampling techniques.

the mean values and standard deviations of the number of genes selected by different multiple testing procedures are reported in tables  <dig>  it is also interesting to look at the shape of the corresponding distribution. figure  <dig> shows that this shape varies widely for different procedures. the nearly symmetric form of this distribution in combination with a relatively small variance is an appealing feature of the cramér-von mises test.

analysis of simulated data
to demonstrate the effect of correlation between gene expression levels on the performance of gene selection procedures, we carried out simulation studies as described in section  <dig> . table  <dig> presents the most basic performance indicators for the sample size n = m =  <dig>  since the simulated data are normally distributed it comes as no surprise that the t-test proves itself as the most powerful one among those under study. with this small sample size, however, even the t-test tends to be underpowered when used in combination with the bonferroni adjustment or westfall-young adjustments. the power of the t-test is much higher with the benjamini-hochberg and nonparametric empirical bayes procedures. the variance of the estimated power as well as the number of selected genes increases dramatically with increasing correlation between gene expression signals.

we also include the histograms for the number of selected genes resulted from our simulation studies . note that the high variance observed for the bh/t and eb/t procedures  is mainly attributable to outliers.

discussion
numerous publications have considered the utility of multiple testing procedures in the context of microarray data analysis . however, little attention has been given to the replication stability of such procedures which is related to the reproducibility of scientific results. our study shows that the variance of the number of the genes declared differentially expressed can be very high for multiple testing procedures even with reasonably large sample sizes. whenever this is the case, the stability of membership in the list of candidate genes should be expected to be low. however, the reverse is not true. if the variance of the total number of selected genes is low, there still can be tangible variations in the stability of selection for individual genes, thereby affecting the composition of the resultant list of candidate genes. this obviously can have a strong effect on the ranking of candidate genes based on purely statistical criteria.

the present study demonstrates that the proportion of highly stable  genes appears to be almost the same for all the selection procedures under study. at the same time, the overall stability of gene selection varies among different methods. the cramér-von mises seems to be superior to other methods in this respect. it is difficult to control the stability of gene selection by an additional adjustment of p-values. indeed, for the fwer-controlling procedures, the relationship between the original  p-values and the selection frequency appears to be non-linear. however, resampling techniques represent a universal tool for assessing the stability in question with the data at hand. as was emphasized in section  <dig>  our simulation studies were designed to demonstrate the fact that the correlation between gene expression levels can affect the results of testing two-sample marginal hypotheses. the fdr-controlling procedures appear to be especially sensitive to this effect. our recent study  <cit>  pinpoints specific components of the empirical bayes methodology where this effect manifests itself. the quantitative contribution of the correlation between gene expression levels to the outcomes of microarray data analysis is diffcult to estimate because no tools are available to model the actual correlation structure of such a large number of variables in computer simulations.

tables  <dig> and  <dig> also illustrate the importance of sample size. however, the number of genes selected by the benjamini-hochberg and nonparametric empirical bayes procedures is very sensitive to correlations even when the power of these methods reaches 100%. the variance of the true fdr is also quite high for such procedures. our simulations show that the fwer-controlling procedures are more stable to the effect of correlation and this stability increases with increasing sample size. pavlidis et al.  <cit>  proposed to approach the sample size problem from the stability perspective and we find their idea very promising and deserving of further exploration.

the distribution-free methods are generally more stable than the t-test. it is our firm belief that such methods will play an increasingly important role and gradually replace the t-test in microarray studies. robust versions of two-sample tests in general and of the t-test  <cit>  in particular can be quite competitive with distribution-free methods  <cit>  and this avenue invites a special investigation.

CONCLUSIONS
as larger sets of microarray gene expression data become more readily available, the stability of gene selection is becoming easier to assess using resampling techniques. we have found that some genes are selected much less frequently  than other genes with the same adjusted p-values. the relationship between the stability of gene selection and the original  p-values may be rather complex but resampling techniques can advantageously be used to select the most stable genes. using these techniques, it is also possible to assess variability of the number of selected genes. in reference to the latter indicator, all the selection procedures studied in the present paper appear to be highly unstable. for the fwer-controlling procedures, this property correlates well with the level of random fluctuations in the estimated power of a given procedure. the more conservative fwer-controlling procedures appear to be more stable to the effect of correlation than the fdr-based procedures. the stability characteristics discussed in this paper provide an additional information that should be utilized in gene selection procedures. we suggest that resampling techniques be routinely used for selection of individual genes whenever the sample size is not prohibitively small.

authors' contributions
the basic idea behind this study emerged from discussions between ay and ag. the detailed study design was developed by all the members of the research team. yx and xq carried out the needed computations and simulations.

supplementary material
additional file 1
includes the executable programs employed in this study

click here for file

 additional file 2
four figures representing histograms for the number of selected genes pertaining to the simulation studies reported in section  <dig> .

click here for file

  <dig> acknowledgements
we are grateful to the three anonymous reviewers for their insightful comments. this research is supported by nih grant gm <dig> .
