BACKGROUND
most systems in biology exhibit dynamical behavior. their properties change as a function of time and space in a complex manner. considering a dynamical biological system to be a well-stirred mixture of its constituents, the most commonly used mathematical model of its dynamics takes the form of a system of coupled ordinary differential equations, treating the entity properties as continuous and assuming they evolve deterministically through time. however, the deterministic nature of ordinary differential equations renders them inadequate for systems with a small number of copies  of its constituents. furthermore, ordinary differential equations fail to account for the underlying stochasticity of natural systems  <cit> . in molecular systems, stochastic fluctuations are responsible for the divergence in phenotype and genetic activities . in such cases, models based on stochastic kinetics are more suitable, as they allow for treating of the modeled systems as either discrete or continuous in terms of the properties of the observed entities and stochastic in terms of the reactions between them.

establishing a deterministic or a stochastic model of an observed biological system is an omnipresent and often complex, tedious task. this task comprises the two subtasks of structure identification, i.e., selecting an appropriate model structure, and parameter estimation, i.e., determining values of the model parameters that, together with the selected structure, lead to accurate reconstruction of the observed system behavior. while many existing approaches integrate methods for simulation and parameter estimation of a single model, only few of them provide support for the task of structure identification  <cit> . in this paper, we design and implement a computational tool that can deal with uncertainty in both model structure and the values of model parameters for both deterministic and stochastic models. the central component of our tool is the process-based modeling formalism that allows for modular, compositional specification of the space of candidate model structures.
fig.  <dig> the relation of the process-based modeling formalism to other formalisms used for modeling dynamical systems in biology



the formalisms of differential equations allow for encoding models with all the details needed for their execution, i.e., simulation of the behavior of the corresponding dynamical systems. ordinary differential equations are limited to deterministic model interpretation, while stochastic differential equations are used for stochastic modeling. differential equations are models at the lowest abstraction level, where every detail has to be fully specified and are used to encode a single model; on their own, they allow neither for parameter nor structural uncertainty.

at a higher abstraction level, the models in the domain of biology are often casted in the formalism of reaction equations. following this formalism, the biological system is described as a reaction network. when coupled with appropriate kinetic rates, the model defines a network of possible transitions between system states. reaction equations allow for both deterministic and probabilistic interpretation stemming from the propensity of each reaction  <cit> .

the systems biology markup language, sbml  <cit> , is a standard modeling formalism in system biology. it allows for encoding and exchange of individual models based on ordinary differential equations or reaction equations. like equation-based formalisms, sbml focuses on encoding a single model structure with parameter uncertainties and does not support the specification of structural uncertainties.

furthermore, a number of formalisms have emerged that deal with the issue of combinatorial complexity, i.e., the exponential complexity of the space of the combinations of elementary interactions between the entities observed in a given biological system. these formalisms allow for specifying rules  that limit the space of potential interactions between entities based on their properties. note that the encoded constraints do not address the issue of structural uncertainty: their application in the context of a given observed system leads to a single model structure. there are several classes of such formalisms.

the first group of rule-based  languages, most notably bionetgen  <cit>  and kappa  <cit> , define the constituent entities of a system at the level of objects with different properties. the network of interactions between the system entities is implicitly described by a set of rules that transform properties or create new entities . by defining the rules directly on the properties, the rule-based modeling approach efficiently deals with the problem of combinatorial complexity, which may arise when modeling protein-protein networks within complex signalization pathways. the rules are encoded using formalisms based on reaction equations.

the second group of agent-based formalisms, which includes process algebras  <cit> , model individual entities as agents in a complex system that act according to a set of predefined rules for communication with other agents. the process algebras describe the behavior of each agent through processes describing the inter-agent communications via different channels. a biological system described using process calculi is treated as a constrained distributed system of communication. this formal description allows for more detailed representation of the basic principles of interaction. examples of process algebra extensions that have been adapted to and are being used in the domain of biology are the stochastic pi-calculus  <cit> , bio-pepa  <cit>  and beta binders  <cit> .

related to the process algebras group, the formalisms in the third group are based on constraint programming  <cit> . in contrast to the process calculi, the constraint programming approaches allow for defining interactions not only through specific communication channels, but by concurrently posting global constraints on the properties of the agent entities.

the limitation that is common to all aforementioned formalisms is that they can not properly represent the structural uncertainty. uncertainty in parameter values is typically addressed by various formalism extensions that are complementary to the computational tools that offer support for them. copasi  <cit>  is an example of a such a tool that allows for introducing uncertainties in model parameter values and performing parameter estimation for models based on equations. the mathworks simbiology toolbox  <cit>  is a proprietary software for modeling and analysis of dynamical systems in biology providing features similar to the ones of copasi. both tools provide a range of methods for the analysis of models , but do not provide computational methods for addressing structural uncertainty; users can only perform manual comparative analysis of different model structures.

network inference methods  <cit>  explicitly address structural uncertainty: most often, given gene expression data, the methods seek for a network of interactions between the observed genes. since these methods focus on the structure of the observed network of interactions, they seldom deal with the reconstruction of the dynamical behavior of the observed system. several methods are exception to this general rule and cast the reconstructed networks into the formalism of ordinary differential equations . in contrast to the process-based modeling approach presented in this paper, these methods are limited to deterministic models. furthermore, these methods follow the assumption that the same interaction dynamics applies to all of the network interactions: the process-based modeling formalism can encode different classes of model structures  with different assumptions about the interaction dynamics. finally, when it comes to constraining the space of possible model structures, some methods employ data-driven heuristics  <cit> , while some of them additionally limit the search for plausible structures based on the interactions already documented in the literature  <cit> . the method by wahl et al.  <cit>  also allows for user-defined boolean constraints specifying implausible network interactions.

finally, abc-sysbio  <cit>  is most closely related to the process-based modeling approach presented here. it builds on sbml and addresses structural uncertainty by allowing the user to explicitly enumerate the alternative model structures. the process-based modeling formalism the we propose addresses exactly this limitation of the existing formalisms, i.e., the ability to properly address structural uncertainty. it allows for modular and flexible specification of the space of candidate model structures to be considered in the modeling process. instead of specifying a fixed list of candidates, like abc-sysbio  <cit> , our formalism allows users to specify model components, which are then used in a compositional modeling setting, where combinations of components correspond to candidate model structures. thus, we approach the structure identification task as a search problem  <cit> , where we search for the most appropriate combination of model components.

this paper builds upon our previous work on inductive process-based modeling that combines knowledge and data to automatically build explanatory models of dynamical systems . while inductive process-based modeling has been successfully applied to modeling tasks in the domain of systems biology  <cit> , its scope has been limited to building deterministic models of dynamical systems cast as ordinary differential equations.

here, we extend the scope of the process-based modeling formalism to models cast as reaction equations, hence the arrow in the top-right corner of fig.  <dig>  in this way, we combine the benefits of process-based modeling  with the benefits of different model interpretations . finally, the formalism is implemented within a computational tool probmots for automated induction of models that combines domain knowledge represented in our formalism with measurements of the observed system behavior.

in the remainder of the paper, we first introduce the process-based modeling formalism, its extensions towards handling stochastic models of biochemical systems and the computational tool for process-based modeling, probmots. we present then two examples of use of the proposed computational tool, i.e. modeling gene regulatory networks and modeling the spread of pathogens, illustrating the use of the proposed tool and evaluating its utility. finally, we discuss the results of the evaluation, put them in the context of existing work and outline directions for further research.

methods
in this section, we introduce the notion of process-based models and a formalism for their representation. we illustrate the formalism use on an example of encoding knowledge for modeling gene regulatory networks and a process-based model of a specific network, the repressilator  <cit> . we then introduce methods for inducing process-based models from knowledge and data by selecting appropriate model structures and parameters.

process-based modeling
scientists often describe dynamical systems in terms of processes that govern the system dynamics and the entities involved in the processes <dig>  following this high-level model description, modelers assign lower-level detailed equation-based specifications of the dynamics to individual processes and combine them into a system of coupled differential equations. the differential equations can be in turn used to simulate the behavior of the observed system or to extrapolate the simulation and predict future system behavior. however, by transforming the high-level model description into equations, its explanatory power is lost, since the equations fail to reveal  the structure of the observed system in terms of the interacting entities and processes.

process-based modeling  clearly relates a high-level model description , that carries significant explanatory power, and a lower-level mathematical model , that allows for simulation and prediction. to build process-based models, we first formalize the modeling knowledge by establishing templates of generic  entities that appear in the generic  processes that govern the dynamics of systems in the particular domain. each process-based model then refers to these template components and instantiates them into specific components of the studied system.

existing process-based formalisms rely on a coarse description of dynamics, based on fragments of differential equations. the formalism introduced in this paper relies on reaction equations, which are closer to the basic principles of system biology and are more comprehensible to biologists. a reaction equation rs→ps  specifies a set of reactants rs and a set of products ps, as well as the reaction rate. reaction equations are a powerful and flexible formalism for modeling the temporal evolution of dynamical systems.

representation of modeling knowledgetable  <dig> templates of entities and processes for modeling gene regulatory networks. the template entity gene typifies network nodes, while the process templates represent gene regulation, as well as translation and protein degradation processes. the empty set symbol ∅ denotes the absence of reactants or products





furthermore, the library specifies templates for modeling the processes of gene interaction, gene translation into proteins, and protein degradation. the degradation template specifies two reaction equations that correspond to the degradation of the encoded protein molecules with the kinetic rate of g.beta  and the degradation of the mrna molecules with the rate of g.delta. similarly, the translation process integrates the reaction equations of the gene transcription to mrna and the mrna translation to protein molecules.

finally, the regulation process template represents gene interactions via their protein products. it has two mutually exclusive alternatives of activation and inhibition. the first corresponds to the case where one gene increases the transcription rate of the other, while the second alternative models repression, where one gene decreases the transcription rate of the other by binding the source gene protein to the promoter region of the repressed gene. in both cases, the reaction rate  is modeled using a hill function, derived as a steady-state approximation of the biochemical kinetics  <cit> .

the templates from table  <dig> represent generic knowledge on modeling gene regulatory networks. they can be instantiated to entities and processes of an arbitrary network model. note the hierarchical structure of the regulation template process: it constrains the space of instantiations by rendering the two subordinate templates of activation and inhibition mutually exclusive. this reflects the simple fact that only one regulation type applies to a given pair of genes. in the following, we will illustrate the use of this knowledge for modeling a simple regulatory network.

process-based models
the repressilator  <cit>  is a regulatory network of three genes interacting in a single feedback loop of inhibitions as depicted in fig.  <dig>  the repressilator is a synthetic network designed to exhibit a stable oscillatory behavior. its in-vivo implementation in e. coli has been proven to exhibit the desired behavior. the three genes involved are tetr, often used for fine regulation in synthetic gene networks, and two repressor genes, ci and laci.
fig.  <dig> graphical representation of the repressilator gene regulatory network



using the domain knowledge for modeling gene regulatory networks from table  <dig>  we can establish a process-based model of the repressilator, presented in table  <dig>  it provides a high-level representation akin to the graphical network layout depicted in fig.  <dig>  where entities correspond to network nodes, and processes are represented by arcs. the model does not give details about the particular modeling choices for degradation, translation and inhibition, since they are inherited from the corresponding process templates. each entity specifies the boundary conditions for the variables  and the parameter values, while each process specifies the involved entities and the parameter values. note, for example, the value assignments for the parameters alpha and n in the inhibition processes.





the process-based model retains the understandability of the graphical model representation and provides a clear, high-level insight into the structure of the studied system. at the same time, by using the detailed knowledge of the reaction equations encoded in the templates, we can automatically translate the high-level description into a mathematical model and use it for simulation and analysis. consider the process translation <dig> in table 2: by combining it with the template translation from table  <dig>  we instantiate a set of two reaction equations modeling the uncontrolled transcription of tetr to mrna  and the translation of the mrna to the tetr protein molecules .
table  <dig> list of reaction equations stemming from the process-based model of the repressilator from table 2






the evolution of the probability p that the system is in a state x at a given time t, given the initial state x <dig> at time t <dig>  can be then defined using the following ordinary differential equation   <cit> : 
  ∂∂tp=∑j=1m, 

for dt→ <dig>  where νj is a vector specifying the changes of the number of reactant molecules after the reaction rj. we can then model the system dynamics using coupled differential equations, where each equation models the probability that the system state equals a unique combination of values of the state variables x.

for real biological systems, the master equation is too complex to be solved analytically or numerically. to this end, alternative approaches to estimating the exact or approximate probabilities have been developed. one of the most popular exact approaches is based on monte carlo sampling and is known as the stochastic simulation algorithm  proposed by gillespie, where others include the gibson-bruck method of next reaction and the class of τ-leaping methods  <cit> .

if we assume that the propensity does not significantly change in infinitesimal time intervals and that the expected number of firings of each reaction is significantly large , we can derive the langevin equation. it represents a mathematical model of the reaction equations cast in terms of coupled itō stochastic differential equations  <cit> . these stochastic differential equations can further be reduced to ordinary differential equations, under the assumption that we observe a negligible amount of noise in a system with a large number of reactants.

thus, from a process-based model, we can automatically infer the reaction equations and then simulate them using the gillespie algorithm or its improvements  <cit> . alternatively, we can transform them to a system of ordinary differential equations. figure  <dig> shows the simulated trajectories of the number of tetr molecules obtained by simulating the reaction equations  and the system of ordinary differential equations  inferred from the process-based model of the repressilator.
fig.  <dig> stochastic and deterministic simulation of the number of tetr protein molecules using the process-based model of the repressilator



to summarize, process-based models have four important properties that make them particularly suitable for modeling dynamical systems. first, they retain the understandability and explanatory power of graphical model representations by providing clear insight into the structure of the observed system. at the same time, they inherit the utility of mathematical models for simulation and analysis of system behavior. third, process-based models provide general model descriptions that support both stochastic and deterministic approaches to modeling, simulation and analysis. the fourth property is the modularity provided by the knowledge representation formalism: the templates can be instantiated into a number of model components. this last property is particularly relevant for the algorithms that induce process-based models from data.

inducing process-based models
the formalized knowledge on modeling gene regulatory networks brings another benefit. it represents a source of constraints that limit the space of candidate model structures to be explored when modeling a particular gene regulatory network. consider the repressilator model again and assume that we are only provided with information that it involves the three genes of tetr, laci and ci. now we can infer all the instances of the process templates from table 1: the degradation process template that involves one gene, leads to three process instantiations, one for each gene. similarly, the translation template leads to three processes. finally, each pair of genes results in one instance of the activation and one instance of the inhibition template. thus, for the three repressilator genes, we obtain six instances of the activation and six instances of the inhibition template. in sum, the three repressilator genes lead to  <dig> process instances.

each of the process instances represents a valid model component. following a naïve approach, one can consider any subset of components as a legitimate model structure, which yields 218= <dig>  candidates. however, these include many implausible models, e.g., ones that do not include gene translation for some of the genes. to avoid implausible models, the inductive process modeling approach relies on the use of constraints that limit the ways model components are combined. for example, a constraint ruling out models that do not include translation and degradation processes for all the genes, reduces the search space to 212= <dig> candidates. furthermore, the constraint specifying the mutual exclusivity of the activation and inhibition processes for a given ordered pair of gene entities further reduces the number of candidates to 36= <dig> .

the constraints discussed above can be classified in two groups. first, the mutual exclusivity of the activation and inhibition processes is specified in the domain knowledge library shown in table  <dig>  second, the constraint ruling out models that do not include translation and degradation of individual gene/protein are defined at the level of process instances. the constraints from the second group are specified in the incomplete model, which is one of the inputs to our software tool probmots. one such incomplete model is depicted graphically in fig.  <dig> and shown in table  <dig>  the lower part of the table specifies that the model must include both a translation and a degradation process for each of the three genes/proteins . figure  <dig>  specifies the three modeling alternatives for each of the six possible pairs of genes.





finally, the inductive process-based modeling approach validates each candidate model structure by matching its simulation against the observed system behavior. in order to simulate the model , we first have to determine the values of its constant parameters. to this end, we employ parameter estimation and find parameter values that lead to a model reproducing the observed behavior as closely as possible. we formulate the parameter estimation task as an optimization problem: we aim at minimizing an objective function that measures the goodness of fit of the model simulation to the observed behavior using the maximum-likelihood estimator  <cit> .

the algorithm for inducing process-based models, presented in table  <dig>  puts together the components outlined above. its input is a library of template entities and processes, such as the one presented in table  <dig>  the specific entity instances observed in the system at hand, a set of constraints that limit the way we combine components into models, and time-series data comprising measurements of the system variables/outputs of observed system. the algorithm first instantiates the templates from the library using the entities of the observed system into a set of model components. then, taking into account the constraints, the algorithm enumerates the plausible combinations of components as candidate model structures. for each model structure, the algorithm performs parameter estimation that fits the model simulation against observed data. at output, the algorithm returns a list of models ranked with respect to their fit against the measured data.




different implementations of the induction algorithm make different design choices. in the following, we provide a brief overview of the different implementations: a detailed overview is given by džeroski and todorovski  <cit> . lagramge  <dig>   <cit>  transforms the library and constraints into a grammar that enumerates candidate model structures. ipm  <cit>  takes a naïve approach and uses constraints on the number of components involved in the model to address combinatorial explosion. hipm  <cit>  encodes the constraints into a hierarchy of process templates and approaches enumeration as a combinatorial search problem. scipm  <cit>  explicitly encodes the constraints and approaches the enumeration using constraint satisfaction methods. finally, probmot  <cit>  extends hipm with explicit constraints referring to the particular system at hand and meta-heuristic optimization methods for parameter estimation.

note, however, that the above inductive process-based modeling approaches have limited their focus on inducing deterministic models cast as ordinary differential equations. probmots, our extension of probmot presented in this paper that allows for inducing stochastic models of dynamical systems cast as reaction equations. the extension is based on the novel formalism for encoding a library of components that supports the specification of reaction equations as models of individual processes. probmots also integrates standard simulators for reaction equations  <cit> .

both probmot and probmots are released as open-source software packages available for download at http://probmot.ijs.si <dig> 

experimental setup and model selection
to evaluate the algorithm for inducing stochastic process-based models, we apply it to several problems of modeling dynamical behavior of biological systems at different scales. we consider two synthetic modeling problems from the domain of gene regulatory networks and two real modeling problems from the domain of epidemiology. in each domain, we first encode process-based knowledge for modeling dynamical systems. in this paper, our focus is limited to encoding domain knowledge in two domains, covering models on fundamentally different scales. note, however, that the process-based modeling approach can be applied to other domains as well, given that modeling knowledge about the domain of interest is encoded as a library of entity and process templates. for example, when modeling metabolic networks, the central entity templates will represent enzymes and metabolites, while process templates would represent different metabolic reactions , formulating different models of the dynamical interactions among them. for further examples of domain knowledge libraries for process-based modeling, we refer the reader to the probmot web site. second, for the synthetic modeling problems, we select a target model and simulate it to obtain a data set for inducing models. on the other hand, the real modeling problems come with data sets of measured system behavior. third, for each modeling problem, we define an ordered list of plausible model structures p. for the synthetic problems, this list includes the target model only, while for the real modeling problems, it includes all the structures of the models that have been reported in the literature as plausible explanations of the measurements. note that for all problems, the list of candidate models considered by the induction algorithm includes all the model structures from the list p.

to perform induction, for each modeling problem we run probmots using the corresponding modeling knowledge  and the data set as inputs. recall that the modeling knowledge defines the space of candidate model structures. the values of the model parameters are estimated by using the differential evolution method  <cit>  with the recommended parameter settings: crossover probability of  <dig> , differential weight of  <dig> , population size  <dig> and the rand/1/bin strategy. we set the number of evaluations of the objective function to  <dig> times the number of constant model parameters. to assess the stability of the parameter estimator, we use  <dig> restarts of the differential evolution method. for simulating the reaction equations, probmots employs the gillespie direct method  <cit>  to obtain  <dig> realizations.

the parameter estimation method in probmots can use different objective functions for measuring the discrepancy between the realizations and the observed data. the first objective function we use in the experiments corresponds to a typical laboratory setting used in biology, where the measurements from multiple replicates of an experiment are averaged. thus, the  <dig> realizations  are averaged just as the observed data: 
  rmsear=∑i1n∥xi−x^i∥,x^i=1k∑kx^ik, 

where m denotes the model, i iterates over the observed variables xi and k iterates over the realizations, where x^ik denotes the k-th realization of xi, and n is the number of observed time points.

alternatively, in situations where the data are measured within a single experiment, we use the second objective function. instead of averaging the realizations, we average the error of each realization, i.e.: 
  rmsesr=1k∑k∑i1n∥xi−x^ik∥. 

recall that the result of probmots is a list of models ranked with respect to their descending fit against the measured data, in our case, ascending model error. the trivial model selection strategy would be to select the model with the optimal value of the objective function. note, however, that error-based estimates of model performance tend to overfit observations, a problem especially relevant in the context of noisy experimental data. to address the problem of overfitting, we use an alternative model selection approach that introduces a penalty for model complexity, measured as the number of reaction equations in the model. to additively combine the model complexity and the degree of fit into a single score, we normalize both to the  scale. the normalization is based on the minimal and maximal values of the degree of fit and complexity, respectively, over all the candidate model structures considered by probmots.

we visualize the result of probmots  using an error profile, as depicted in fig.  <dig>  each point of the error profile corresponds to a model induced by probmots and the y-axis of the profile corresponds to the respective value of the model selection criterion. in our experiments, we use the error profile to evaluate the probmots results in two ways. the first one selects the left-most model in the error profile, i.e., the model with the lowest model selection score, as the most appropriate model. we refer to this method as the singular method. this method is short-sighted since it only considers the best model. as an alternative to the singular method, we propose the inclusive method that considers models in the left-most plateau of the error profile. we employ a simple heuristic to identify plateaus: a relative change of error between two consecutive error-profile points that is above a threshold value of  <dig>  indicates a plateau end. the first  plateau of the error profile in fig.  <dig> includes the cluster of ten points in the lower-left corner of the graph. note that it includes ten top-ranked model structures that are indistinguishable in terms of the model error and therefore better represent the results of induction. the plateaus of the error profile lead to a partial ordering of the models.
fig.  <dig> an example error profile of a probmots output that includes  <dig> models ranked according to increasing model error



finally, to evaluate the results of induction, we compare the list of selected models to the list of plausible models p using a triple of metrics . the recall is the proportion of the plausible models in the first plateau of the error profile. the indicator hit tells us whether the first plateau contains the first model structure in p. the size of the plateau  indicates the discriminative power of the induction method: the smaller the plateau, the larger the discriminative power. the ideally performing induction method would lead to the triple .

RESULTS
in this section, we present the results of the evaluation of probmots on the four problems of inducing stochastic process-based models from knowledge and data. the first two are from the domain of gene regulatory networks, the other from the domain of epidemiology.

gene regulatory networks
we first address the task of modeling the simple gene regulatory network of the repressilator, introduced in the previous section. we select the model from table  <dig> as a target model and set the list of plausible model structures p to contain a single structure that corresponds to the target model. we then perform two experiments. in the first, we assume that the kinetic rates in processes belonging to a single class of regulatory processes  have the same values. to this end, we restructure the library of templates to introduce an global template entity that declares the global kinetic rates, which are then used by the process templates. in the second experiment, we perform induction without the assumption of global kinetic rates and therefore use the library of templates as presented in the previous section.

global kinetic rates
the model of the repressilator considered here has been already addressed in other studies  <cit> . note, however, that both studies address only the task of parameter estimation from synthetic data assuming a single model structure. in our experiment, we also aim at identifying the structure of the model. we select the single model structure used in previous studies as our target and use the following values of the global kinetic rates: =. to obtain experimental data, we average  <dig> realizations of the target model in the time interval t∈. accordingly, we use the rmsear objective function.

in order to define a structure identification problem, we describe the space of possible model structures as represented in fig.  <dig>  each rectangle represents a gene entity, while the dashed lines represent a regulation interaction between the entities. the interactions in the incomplete model are instantiated from the regulation process template from table  <dig>  this results in 36= <dig> possible model structures, one of which is the target model structure of the repressilator.
fig.  <dig> graphical representation of the space of model structures considered during the induction of the repressilator model. note that we do not assume fixed forms of the regulation interactions between the genes


fig.  <dig> error profile for the task of inducing the repressilator model with global kinetic rates. complete error profile . the top six models in the first two plateaus with error bars showing the standard deviation across restarts. the gray horizontal lines depict plateaus 



local kinetic rates
to test the robustness of our method, we remove the assumption of global kinetic rates from the modeling scenario. thus, we forget the changes we made to the library in the previous experiment and use the library as described in table  <dig>  other than the different formalization of the domain knowledge, given the relaxed assumptions, the task remains the same: we use the same target model, the data set, the objective function  and the list of plausible models as in the first experiment. the relaxed assumptions lead to an explosion in the parameter space, while the structure space remains the same. we want to test whether  the relaxed modeling assumption will influence  the results of probmots.

the obtained error profile for the described task is shown in fig. 7; note again the small standard deviation of the error over the parameter estimator restarts. the first plateau of the error profile includes four models. the second model has the structure that exactly matches the structure of the target model leading to the performance triple of . the structures of the other three models in the plateau contain the repressilator motif and a number of additional gene regulation interactions, indicating an overfit of the experimental data. indeed, fig.  <dig> shows that if model complexity is taken into account when selecting models, the first plateau of the error profile includes only the target model, leading to the ideal performance triple of .
fig.  <dig> error profile for the task of inducing the repressilator model with local kinetic rates. complete error profile . the top six models in the first two plateaus with error bars showing the standard deviation across restarts. the gray horizontal lines depict plateaus 

fig.  <dig> error profile for the task of inducing the repressilator model with local kinetic rates based on a model selection score that takes into account model complexity penalization. complete error profile . the top seven models in the first three plateaus with error bars showing the standard deviation across restarts. the gray horizontal lines depict plateaus 



compartmental epidemiological models
in the domain of epidemiology, we first formalize the knowledge to be used for establishing stochastic models, using the basic principles of compartmental modeling as presented by brauer et al.  <cit> . there, the spread of disease is modeled by the flows of individuals between healthy and infected populations, referred to as compartments. each flow is modeled using a reaction equation, where reactants and products correspond to compartments.
fig.  <dig> graphical representation of a general compartmental model in epidemiology. the boxes correspond to compartments, i.e., subpopulations, and arrows denote the flows of individuals between compartments



at the point of introduction of a pathogen in the population, the entire population can be considered to consist of susceptible individuals , except for the individuals by whom the pathogen is introduced. from this point on, we can observe different processes of flow between compartments. one way to model the infection of individuals is to assume that all infected individuals manifest the disease symptoms. in this case, the a compartment is not populated. an alternative, more complex, model assumes that we can also have infected individuals that do not manifest the symptoms. in both cases, the infection might cause a direct flow from s to i  or indirect flow through the l compartment of latently infected individuals.

the recovery of individuals from a disease can either cause flows from the a and i compartments to the population of recovered  individuals r or cause flows from the a and i to the population of susceptible individuals s. in any case, the recovery of the individuals from i can be controlled by moving the infected individuals to the quarantine compartment q. finally, the general model involves a flow of individuals from the recovery compartment to the population of susceptible individuals.

the general model can be instantiated to a number of variants, ranging from the simple sir model that assumes only three compartments of susceptible, infected and recovered individuals, through the slir model that introduces the population of latently infected individuals, to the most complex sliaqrs model that comprises all the compartments depicted in fig.  <dig>  for example, the sir model includes two processes. the first instantiates the template process of infection_symptomatic that includes a single reaction equation: s.noi + i.noi → i.noi + i.noi , where i represents the rate of infection. the other process represents the template of recovery_symptomatic that includes the reaction equation i.noi → r.noi , where r denotes the recovery rate.

in contrast to the previous synthetic tasks, here we use two data sets of real measurements for induction. these come from two epidemic outbreaks, the outbreak of the great plague in eyam in  <dig>  <cit>  and the outbreak of influenza type a subtype h3n <dig> in tristan da cunha in  <dig>  <cit> . the measurements for the case of the outbreak in eyam are taken bimonthly at seven time points in the period from 3rd of july to 20th of october  <dig>  they include two variables: number of healthy individuals and the number of individuals that have complained of symptoms. the measurements from tristan da cunha are taken daily at  <dig> time points in october  <dig>  they also include two variables: number of individuals showing symptoms of infection and the number of recovered individuals.

to match the compartment variables to the variables in the data sets, we calculate the number of healthy  as the sum of the number of individuals in the s, l and a compartments, the number of infected as the sum of the number of individuals in the i and q compartments and the number of recovered as the number of individuals in the r compartment.

in accordance with the experimental setting for obtaining the measurements, we use the second objective function rmsesr. since the experimental data comes from real and therefore noisy measurements, we take into account model complexity to obtain the model selection score.

eyam plague outbreak
for this task, we consider all possible instances of the general model as previously described, by introducing a small set of constraints of mutual exclusivity of symptomatic and asymptomatic infection, thus instantiating only the corresponding recovery for each type of infection. the total number of model structures under these constraints is  <dig>  the initial conditions at the first time point were set to  <dig> individuals in the s,  <dig> individuals in the i and  <dig> in the other compartments, which exactly matches the initial conditions from the original study by ragget  <cit> . the same paper proposes two plausible model structures: sir, the structure that has been analyzed in the paper, and slir, suggested as the most promising one for further study. thus, our list of plausible models structures p is .

the first plateau of the error profile, depicted in fig.  <dig>  contains a single model that has the sir structure. therefore the recall is  <dig> %, the hit is true and the plateau size is  <dig>  the model with the slir structure is ranked as second and comprises the second error-profile plateau. thus, when considering the two models in the two left-most plateaus, probmots successfully reconstructs the two plausible model structures suggested before  <cit> . note that the complexity-based model selection score bears high discriminative power, since each model forms its own plateau. the next four plateaus of the error profile include the sirs, slirs, siqr and sliqr models, which render model structures that extend the basic sir and slir with the assumptions of survivors  or a quarantine compartment to provide plausible explanations of the observed data.
fig.  <dig> error profile for the eyam plague modeling task. the error bars show the standard deviation of the model selection score across the runs. the gray horizontal lines depict plateaus



tristan da cunha influenza outbreak
for this task, we consider the same set of  <dig> model structures that instantiate the general model from fig.  <dig>  based on the data available, we set the initial number of infected individuals to  <dig>  other initial values to  <dig>  except for the initial number of susceptible individuals that was fitted as a model parameter. we selected the two best performing model structures from toni et al.  <cit>  as plausible and set p to . the other two model structures considered in the study are a modified slir structure, that includes time-delayed flow models, and a sirs structure.

the first plateau of the error profile, depicted in fig.  <dig>  contains the slir model that is the first model in p, leading to a recall of  <dig> %, the hit indicator is true and the plateau size is  <dig>  the second ranked model in the second plateau has the sir structure of the second model in p. as in the case of the eyam plague experiments, probmots perfectly reconstructed the results of the previous modeling experiments reported by toni et al.  <cit> .
fig.  <dig> error profile for the tristan da cunha influenza outbreak modeling task. the error bars show the standard deviation of the model selection score across the runs. the gray horizontal lines depict plateaus



discussion
the formalism for stochastic process-based modeling, that we introduce in this work, retains the modular and straight-forward specification of entire classes of model structures from its deterministic counterpart. in contrast to the formalisms commonly used in systems biology that employ different levels of abstraction but focus primarily on the efficient description of a single model structure , the process-based formalism allows for describing uncertainty in both the structure and parameter values of a model by representing classes of model structures. the introduction of reaction-equation based description of processes improves the understandability of process-based models and allows for their stochastic interpretation, improving the generality and utility of the process-based modeling approach and bringing it closer to the domain of biology.

the experimental evaluation shows that our approach can be successfully applied to a range of problems of learning stochastic models. these can come from different biological domains and represent phenomena at different scales. our approach exhibits excellent performance on the considered tasks, producing accurate and understandable models and successfully reconstructing the results of previous modeling efforts. the proposed approach can be applied to an arbitrary domain of interest by encoding an appropriate library of template entities and processes encountered in the particular domain.

however, several limiting issues may arise during the application of the proposed approach.

first, solving the parameter estimation task for each model structure can lead to both identifiability and distinguishability problems. the identifiability of the model parameters is a problem often encountered when modeling biological systems  <cit> . performing identifiability analysis for each candidate structure is in principle possible. however, this can be challenging in terms of computational complexity when considering a large number of candidate model structures. a more tractable problem is the one of distinguishability of the candidate model structures in terms of the applied model selection criteria. within process-based modeling, this problem presents itself in the form of long plateaus in the error profile. this problem has been studied for the task of learning deterministic models of dynamical systems from data and domain knowledge  <cit> . the study shows that the problem of distinguishability can be successfully addressed by the introduction of problem specific, domain dependent criteria for parameter optimization and model selection. although this study is limited to the case of deterministic models, further work can extend its scope to stochastic modeling.

second, the encoding of very large and complex systems in the proposed formalisms may be cumbersome. the use of reaction equations to encode a system with many entities, that is comprised of a large number of simple and repeating interactions might lead to excessively lengthy descriptions. following concepts from related work, the issue of combinatorial complexity of composing models from elementary interactions may be solved by rule- or agent-based formalisms by introducing further abstraction.

finally, the third limitation of our approach is related to computational cost. the simulation of a candidate model is the computationally most expensive step of the process of model induction. therefore, the computational cost is proportional to the number of evaluations  needed for each model during the parameter estimation task. our method requires exhaustive enumeration and optimization of a number of candidate model structures defined by entity/process templates organized in multiple-level hierarchies of alternatives within a library of domain knowledge. subsequently, a combinatorial explosion is possible if the problem is not well constrained. this is exactly why the process-based modeling approach includes the facility for imposing constraints on the space of possible model structures by allowing for the definition of an incomplete model.

CONCLUSIONS
the area of computational biology lacks a unified methodology for modeling dynamical systems that would include a formalism for representing complex dynamics in a manner easily understandable to biologists and modeling experts. in this paper, we advocate the use of process-based modeling for this purpose. it allows for understandable description of a space of candidate model structures for a given modeling task. it allows for both deterministic and stochastic interpretation of process-based models. also, it allows for automated induction of models from data and knowledge.

in order to bridge the gap between the existing and commonly used tools for modeling the dynamics of biological systems and the machine learning approaches to computational scientific discovery, we have extended the scope of process-based modeling approaches, specifically probmot, to include stochastic models. as an intermediate representation, our probmots formalism includes the finer, more intuitive and easier to comprehend representation of reaction equations, which should increase the ease of use of process-based modeling in biology. this finer-grained representation of processes is a feature that broadens the possibilities of interpretation, mainly in the direction of capturing the inherent stochasticity of dynamical systems in biology.

through the tasks considered in this work, we have shown that our approach can deal with complex parameter and structure search spaces, in lightly constrained settings, with synthetically generated tasks and in less constrained real world problems. we have thus demonstrated the potential of our approach for automated discovery of novel scientific knowledge in domains that require stochastic modeling of dynamical systems. our results also point at an array of possibilities for further evaluation and improvement.

the presented extension of the process-based formalism integrates reaction equations as a proxy that allows for multiple interpretations of the process-based models. however, we can continue this initial step by integrating other higher-level formalisms. combining rule-based modeling languages with the process templates from the process-based modeling formalism can be considered as a first direction for further work. the introduction of rule-based constraints would allow for automated modeling of more complex systems.

another direction for further work stems naturally from the formulation of the modeling task as a combinatorial search problem. it concerns the implementation of incomplete, heuristics-based search strategies over the space of candidate models. although a comparative evaluation with the method using exhaustive search is needed to establish its utility, this extension will scale-up our approach towards applications to large-scale modeling problems.

other factors might also contribute to the overall success of our approach, e.g., the choice of a parameter estimation method and a method for simulation. existing literature offers comparisons of the performance of different parameter estimation methods on single model structures for modeling tasks from the domain of systems biology   <cit> . a comparison of the performance of different parameter estimation methods has also been performed in the context of deterministic process-based modeling of aquatic ecosystems  <cit> . the conclusions from these studies are a good starting point to investigate their performance in the context of stochastic process-based modeling tasks.

ethics approval
no aspect of this study required ethics approval.

availability of data and materials
the libraries of domain knowledge, incomplete models and data supporting the conclusions of this article are available in the zenodo repository https://zenodo.org/record/ <dig> .

endnotes
 <dig> the notions of entities and processes are ontologically well-grounded and are present  in the basic formal ontology.

 <dig> probmot and probmots are released under the terms of the bsd license http://probmot.ijs.si/licence.html.

competing interests

the authors declare that they have no competing interests.

authors’ contributions

lt and sd initiated the work. jt implemented the new formalism and integrated it within probmot. jt encoded the domain knowledge in the new process-based formalism. jt designed and performed the experiments. jt and lt analyzed the results. jt and lt drafted the manuscript. sd gave critical advice on how to revise the manuscript. all authors read and approved the final manuscript.

we acknowledge the financial support of the slovene human resources development and scholarship fund, the slovenian research agency ), and the european commission .
