BACKGROUND
the humoral immune response is based on the amazing ability of antibodies to recognize and bind to antigens of intruding organisms, such as bacteria and viruses  <cit> . antibodies bind specifically to a contiguous amino acid sequence of a protein known as the linear b-cell epitope or to a folded structure formed by discontinuous amino acids known as the conformational b-cell epitope  <cit> . prediction of b-cell epitopes is critical for immunological applications. specifically, predicted peptides can be synthesized and can be used to replace the intact antigen molecules as reagents for detecting anti-protein antibodies in immunoassay  <cit> , as immunogens for raising anti-peptide antibodies to cross-react with the protein of interest  <cit> , or in the development of synthetic peptide vaccines  <cit> . although the majority of b-cell epitopes are conformational  <cit> , most b-cell epitopes prediction approaches concentrate on the “easier” linear epitopes  <cit> .

earliest linear b cell epitope prediction models were based on propensity profiling. blythe and flower  <cit>  demonstrated that the propensity profiling methods cannot be used to reliably predict the epitope. even the best propensity profiling method only yielded a success rate marginally better than that produced randomly using a receiver operating characteristics  plot. later, machine learning methods have been explored to improve the prediction performance  <cit> . however, most of these methods were developed on very small datasets  with negative dataset that were randomly selected peptides instead of experimentally verified non-epitopes  <cit> .

in this work, based on the antigen’s primary sequence information, a novel linear b-cell epitope prediction model was developed using the multiple linear regression . a large dataset called beod which was derived from beoracle dataset  <cit>  was used to train and test our model. it is worthwhile to note that all epitopes and non-epitopes of our beod dataset were experimentally verified. nevertheless, experimental non-epitope data still have the potential to be epitopes due to flawed interpretation of the results or simple experimental errors  <cit> . models built on different subsets of such noisy negative dataset may produce very different results. in order to alleviate the noisy problem caused by the negative dataset and report a reliable prediction result of our model, we have performed  <dig> experiments utilizing  <dig> sub-datasets of which each negative sub-dataset was randomly selected from the beod negative dataset while each positive sub-dataset was the unchanged beod positive dataset. 10-fold cross-validation was employed to evaluate the performance of our model. our model produced average sensitivity  of  <dig> %, precision  of  <dig> % and area under the receiver operating characteristic curve  of  <dig>  over the  <dig> experiments. a web server epmlr implementing linear b cell epitope prediction is available at: http://www.bioinfo.tsinghua.edu.cn/epitope/epmlr/.

RESULTS
sliding window size selection
to evaluate the effect of sliding window size n on the prediction performance, we conducted modelling trials on beod dataset using different window sizes from  <dig> to  <dig>  representing the range in which peptides can be synthesized relatively easily for immune experiments. as shown in the figure  <dig>  the f-measure value of 10-fold cross-validation test achieved its highest value when the window size n was  <dig>  moreover, at  <dig> point, the f-measures obtained by the 10-fold cross-validation test and the self-consistency test are very close to each other, which further validates the reliability of the performance using sliding window size of  <dig>  it is generally accepted that the closer the f-measures obtained by the cross-validation and self-consistency tests are, the more reliable the performance of the cross-validation test is. therefore, in this work,  <dig> was set as the default window size.figure  <dig> 
the effect of the sliding window size on the overall prediction f-measure. red: self-consistency test; green: 10-fold cross-validation test.



prediction performance
we performed  <dig> experiments on 10-fold cross-validation utilizing  <dig> sub-datasets that are the same in the positive datasets but different in the negative datasets. for each trial, the positive dataset of  <dig> epitopes are exactly same with beod’s  <dig> epitopes while the negative dataset of  <dig> non-epitopes are randomly selected from beod’s  <dig> non-epitopes. the roc plots for the best and worst performances among the  <dig> trials are shown in figure  <dig>  the performances of all  <dig> trials are summarized in table  <dig>  as shown in table  <dig> and figure  <dig>  the variance of the  <dig> results is large, with sn ranging from  <dig> % to  <dig> %, p from  <dig> % to  <dig> %, f-measure from  <dig>  to  <dig> , and auc from  <dig>  to  <dig> . these large discrepancies corroborate our speculation of the noise of non-epitopes even if they are experimentally verified and support our means of randomly constructing many negative sub-datasets and reporting the average result instead of the best result. in conclusion, our sequence-based linear b-cell epitope prediction method achieved an average sn of  <dig>  ±  <dig> % , p of  <dig>  ±  <dig> % , f-measure of  <dig>  ±  <dig>  , and auc of  <dig>  using 10-fold cross-validation.figure  <dig> 
roc curves of the best and worst performance among  <dig> modeling trials using 10-fold cross-validation. red: the best performance; green: the worst performance.
summary of the  <dig> trials’ performances using 10-fold cross-validation



performance
sn 
p 
f-measure
auc


comparison with other prediction methods
we compared our epmlr method with the methods of abcpred  <cit> , aap  <cit>  and bcpred  <cit>  through applying their web servers to the beod dataset. the roc plots for performances of abcpred, aap, bcpred and epmlr are shown in figure  <dig>  the auc values for abcpred, aap, bcpred and epmlr are  <dig> ,  <dig> ,  <dig>  and  <dig> , respectively. it is clear from the roc plots that epmlr produced better performance in comparison with abcpred, aap and bcpred.figure  <dig> 
roc curves of abcpred, bcpred, aap and our epmlr method performed on the beod dataset. green: abcpred; blue: bcpred; yellow: aap; red: epmlr.



next, we compared our method with svmtrip method which is a recently published large dataset based method  <cit> . we performed a 5-fold cross-validation on the svmtrip dataset. our method obtained sn of  <dig> % and p of  <dig> % which is similar to the performance of svmtrip method  using 5-fold cross-validation. our method observed similar sn  but a decreased p  on the beod dataset and svmtrip dataset. the decreased p value could be resulted from the fact that the negative non-epitope dataset of the svmtrip dataset was from the remaining segments which have not been marked as epitopes in the corresponding antigen sequences.

similarly, we compared with lbtope method which is the most recently published large dataset developed method  <cit> . we applied our method to the lbtope_fixed_non_redundant dataset  whose epitopes and non-epitopes were all experimentally verified. using the same experimental procedure of lbtope, on the lfnr dataset, our method obtained an auc of  <dig> , which is comparable to the aucs  obtained by lbtope method by training using 5-fold cross-validation on 90% of the data and testing on the remaining 10% of the data with various features.

table  <dig> lists the comparison of our epmlr with these methods in detail.table  <dig> 
comparison of epmlr with other methods



methods
dataset used
performances

sn 
sp 
p 
acc 
auc


discussion
the development of epitope prediction research was accompanied by the development of a large and experimentally well-characterized dataset that comprises both positive epitopes and negative non-epitopes  <cit> . in contrast to the simplicity of the construction of a positive dataset, the construction of a negative dataset has been still debated. non-epitopes were not used in the early studies. some authors attempted to construct negative datasets by randomly choosing peptides either from a protein database  where no antibody binding is reported or from the antigen areas not encompassing any of the reported epitopes. in recent years, researchers have begun to construct negative datasets from the immune epitope database iedb  <cit>  database. iedb collects both epitopes and non-epitopes from experimentally validated data. however, experimental non-epitope data still have the potential to be epitopes due to flawed interpretation of the results or simple experimental errors  <cit> . thus, models built on different subsets of such uncertain dataset may produce uncertain predictions, as demonstrated by the results of the  <dig> trials of our model. although we can produce a good result by subjectively selecting a self-reinforcing negative dataset, the reliability of such good performance is not guaranteed. thus, in this work, we performed many parallel trials using the same positive dataset but different negative datasets that are randomly selected from the noisy negative dataset and reported the average of all results as the final result. such an averaging method could help produce a reliable result.

CONCLUSIONS
in this work, a novel sequence-based linear b cell epitope prediction model was developed. a web server epmlr implementing the prediction is available at: http://www.bioinfo.tsinghua.edu.cn/epitope/epmlr/. as a reliable method developed based on a large dataset, epmlr offers new insights into the linear b cell epitope prediction and a new option for scientists to do their prediction.

