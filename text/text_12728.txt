BACKGROUND
currently, genomics lies at the heart of an extraordinary number of discoveries, innovations and applications. this revolution is a direct result of the rise of next-generation sequencing  technologies . in the area of genotyping, the combination of ngs and reduced representation methods, which focus the sequencing effort on a small subset of the genome, has made it possible to simultaneously perform genome-wide single nucleotide polymorphism  discovery and genotyping in a single step even in species with large genomes  <cit> . this has facilitated greatly the genotyping of very large numbers of snps using a number of related methods  . these various methods make it possible to study important questions in molecular breeding, population genetics, ecological genetics and evolution using thousands to millions of genetic markers in a wide array of species  <cit> . genotyping-by-sequencing  is a particularly attractive complexity reduction method that offers a simple, robust, low-cost, and high-throughput method for genotyping in both model and non-model species  <cit> .

advanced sequencing technologies  have reduced both the cost and the time required to generate sequence data. the efficient and accurate computational processing, variant and genotype calling of large-scale ngs data is the new bottleneck in genomics. to meet this need, numerous bioinformatics pipelines have been developed  and all need to accomplish a similar set of steps such as: 1) acquiring raw sequence data, 2) demultiplexing pooled sequence read data, 3) filtering out low-quality reads, 4) assembling or aligning reads, and finally 5) discovering polymorphic loci and inferring actual genotypes at these loci. each step represents a set of specific challenges and ambiguities. generally, various genomic characteristics such as the number of detected variants, the complexity of the genome, the degree of heterozygosity, the proportion of repetitive sequences throughout the whole genome, the level of polymorphism and divergence among populations can contribute to these challenges  <cit> . on the other hand, technical factors such as dna quality, the degree of sample multiplexing, the total number of reads per sample, the length of reads, and the sequencing error rate interact with these biological factors . therefore, it is necessary to select appropriate parameters such as the required depth of coverage, the quality of read mapping or the allowable degree of divergence for successful mapping. finally, because of these two different sources of variation  in gbs data, the optimal parameters need to be adjusted for each species and desired marker coverage and throughput.

conventionally, bioinformatics pipelines for handling gbs data are categorized in two groups: de novo-based and reference-based. in the presence of a reference genome, the reads from reduced-representation sequencing can be mapped to the reference genome and snps can be called  <cit> . up to now, several reference-based gbs analysis pipelines have been developed. the most widely used reference-based gbs analysis pipelines are: tassel-gbs , stacks, and igst . but when a reference genome is not available, pairs of nearly identical reads  need to be identified. the most highly used pipelines for such a de novo-based approach are uneak and stacks  <cit> .

herein, we describe a new reference-based pipeline, fast-gbs, and we benchmark the pipeline based upon a large-scale, species-wide analysis of soybean, barley and potato. it is easy to use with various species, in different contexts, and provides an analysis platform that can be run with different types of sequencing data and modest computational resources.

test datasets
to test the performance of fast-gbs, we used existing sequence datasets for panels of  <dig> unrelated accessions/clones for three species covering a range of genomic situations: soybean  <cit> , barley , and potato . table  <dig> shows the species which we used in this study. these vary in terms of their ploidy, genome size and mode of reproduction . we used sequence datasets composed of  <dig> samples for each species.table  <dig> list of species genotyped using a gbs approach and analyzed using fast-gbs. for the three different species used in this work, relevant characteristics  influencing gbs analysis are shown

glycine max
hordeum vulgare
solanum tuberosum



genotype validation
to estimate genotype accuracy for fast-gbs calls, we compared the called snps with independently derived genotypic data resulting from either whole-genome resequencing  or genotyping on a snp array  for the same samples. for soybean, we compared the gbs-called snps with whole genome resequencing data for the same  <dig> samples. in the case of barley, gbs-derived genotypic data for one of the  <dig> barley samples  was compared to the barley reference genome produced using this same cultivar. for potato, we compared the gbs-derived genotypes with those obtained for the same  <dig> samples at a set of  <dig> snps that were in common with the solcap infinium chip   <cit> .

implementation
the fast-gbs analysis pipeline was developed by integrating public packages with internally developed tools. the public packages include sabre   <cit> , cutadapt   <cit> , bwa   <cit> , samtools   <cit> , and platypus   <cit> . fast-gbs functions and software tools are presented in fig.  <dig> fig.  <dig> schematic representation of the analytical steps in the fast-gbs pipeline. the main steps in the analytical process are indicated in the central portion of the diagram, while the different software tools used are indicated to the left and inputs and outputs of each step to the right




creating directory structure
we developed a bash script to create the directory structure before running the fast-gbs pipeline. this command line creates the directories for data , barcodes , reference genome, and results .

input
the input data are sequenced dna fragments from any restriction enzyme–based gbs protocol. fast-gbs handles raw sequencing data in fastq format.

preparing the parameter file
the parameter file is a text file containing key information about the analysis including the path to the fastq files, barcodes and reference genome. it also contains information about the type of sequence , the adaptor sequence and the sequencing technology. in this file we can define critical filtering options such as the minimal quality scores for reads, minimal number of reads required to call a genotype, and maximal amount of missing data allowed. number of cpu, names of output files are also defined in this file. this file comes with the fast-gbs pipeline.

data demultiplexing
the cost efficiency of gbs is partly due to the multiplexing of samples and the resulting pooled reads will need to be demultiplexed prior to snp calling. fast-gbs uses sabre  <cit>  to demultiplex barcoded reads into separate files. it simply compares the provided barcodes with the 5′ end of each read and separates the reads into the appropriate barcode files after having clipped the barcode from the read. if a read does not have a recognized barcode, it is put into an “unknown” file. sabre also has an option  to allow mismatches within barcodes. sabre supports gzipped input files. after demultiplexing, sabre outputs a bc summary log file of how many reads went into each barcode file.

trimming and cleaning
after demultiplexing, fast-gbs uses cutadapt to find and remove adapter sequences, primers, and other types of unwanted sequence from high-throughput sequencing reads  <cit> .

read mapping algorithms
fast-gbs uses the mem  algorithm implemented in bwa that works by seeding alignments and then extending seeds with the smith-waterman  algorithm using an affine gap penalty  <cit> . this algorithm can perform local alignment for reads of  <dig> bp up to 1mbp. this algorithm can perform parallel alignment, thus markedly increasing the speed of the analysis. the ability to align reads of variable size allows the use of data obtained using different sequencing platforms . aligned reads may be gapped to allow for indels.

post-processing of mapped reads
after initial alignment, the mapped reads are further processed by platypus  <cit>  in order to improve the sensitivity and specificity of variant calling. this post-processing seeks to improve the quality of mapping by performing a re-examination of poorly mapped reads and reads mapping to multiple locations. platypus classifies poorly mapped reads in three categories: 1) reads with numerous mismatches , 2) reads mapping to multiple locations in the genome, and 3) any remaining linker or adaptor sequences . variants called using such potentially incorrectly mapped reads  are highlighted using a badreads flag.

haplotype construction and variant calling
in fast-gbs, variants are called using platypus. unlike alignment-based variant callers which focus on a single variant type , platypus uses multi-sample variant calling that helps to exploit information from multiple samples to call variants that may not look reliable in a single sample. this approach decreases the errors around indels and larger variants . at first, the local assembler looks at a small window  at a time and uses all the reads in the window to generate a colored de bruijn graph, then using all candidate variants, it generates an exhaustive list of haplotypes. candidate haplotypes are generated by clustering the candidate alleles across windows. haplotype frequencies are estimated by the expectation-maximization  algorithm. then variants are called using the estimated haplotype frequencies. this approach works on the local haplotype level rather than on the level of individual variants and does well on highly divergent regions. this also decreases computational requirements.

variant and individual-level filtering
platypus was originally designed and used to detect variants in human, mouse, rat and chimpanzee samples. to optimize platypus options in the context of the analysis of gbs-derived single-end reads, we modified several options . some of the filters used in fast-gbs variant calling steps are: number of reads  per locus , mapping quality score of reads to call a variant , minimum base quality , mnps distance , and maximum missing data  allowed . see fast-gbs user manual for a full description of all filtering options.

output data
the main output file of fast-gbs is a.vcf file  <cit>  containing detailed information on each of the variants. in addition, fast-gbs also generates a simple text file containing only the genotypic data. the fast-gbs log file contains the completed steps of the pipeline as it is running. in cases where an error occurs and prematurely terminates the running of the pipeline, the log file shows the step at which the analysis stopped. an analysis can be started at any point on the existing intermediate files simply by creating a log file in which the previously completed steps are listed. fast-gbs will re-initiate the analysis starting from that point onwards.

RESULTS
performance of fast-gbs
to assess the performance of the fast-gbs analysis pipeline, we used it to analyze existing gbs-derived read data from sets of  <dig> soybean, barley, and potato samples. table  <dig> presents a summary of this analysis. as can be seen, a total of  <dig> k snps were called using  <dig> m 100-bp illumina reads on apeki-digested dna from  <dig> different soybean lines. similarly, for barley,  <dig> k snps were successfully called from  <dig> m ion torrent reads  derived from a 24-plex mspi/psti library. finally, in potato,  <dig> k snps were obtained from sequencing a 24-plex mspi/psti library .table  <dig> number of variants detected among  <dig> soybean, barley, and potato samples. the sequencing platform, number of reads, filtering options, and genotype accuracy for each dataset are also provided


afiltering options: minnr minimum number of reads to call a variant , minmaf minimum minor allele frequency, and maxmd maximum missing data allowed




gbs was originally demonstrated for soybean by sonah et al  <cit>  using the igst pipeline. using  <dig> diverse soybean lines, they called ~ <dig> k snps. later work by the same group lead to the calling of  <dig> k snps on a large collection of  <dig> soybean lines for the purpose of conducting a gwas study  <cit> . analysis of this dataset using igst took four days while the same analysis using fast-gbs at the same sample size and condition took only  <dig> h and called ~ <dig> k snps . as can be seen fast-gbs present a high level of performance for soybean samples.

barley has one of the larger genomes  among cultivated plant species. because of the huge size and high level of complexity of its genome, complexity reduction is highly recommended in barley, an important crop species for which a draft genome has been published  <cit> . mascher et al  <cit>  genotyped  <dig> barley ril lines using gbs  and they called  <dig> k and  <dig> k snps using either the reference genome  or a de novo pipeline , respectively. in this study we used fast-gbs for snp calling in barley and, as can be seen in table  <dig>  fast-gbs called  <dig> k snps for a small number of samples . this showed the capability of fast-gbs to run with large and complex genomes.

because of the high level of ploidy and heterozygosity, potato is a challenging species for genotyping. the most often used method for genotyping in potato is a snp array. two snp arrays have been developed so far, the solcap  <dig> k and  <dig> k arrays  <cit> . recently, endelman  <cit> , genotyped  <dig> f <dig> diploid potato samples using gbs. using an r-based bioinformatics pipeline to filter the gbs variants, they identified  <dig> k snps. in this study, we called  <dig> k snps from  <dig> samples which had also been genotyped using the solcap  <dig> k snp array. using a simplified genotyping mode  in which only three genotypic classes were distinguished ,  <dig>  k snps on this array had been found to be polymorphic among this set of  <dig> potato samples  <cit> . as can be seen in table  <dig>  using fast-gbs to call snps in an equivalent diploid mode, we called almost seven times more polymorphisms than using a snp array .

validation of fast-gbs data
an important aspect to consider for any variant calling tool is the accuracy of called genotypes. in this study, we estimated the accuracy of genotypes called by fast-gbs  by comparing them to the “true” genotypes . for soybean, for all  <dig> samples, we compared the snp genotypes called by fast-gbs to the genotypes assigned to the same loci following whole-genome sequencing. we found a very high level of concordance, as almost all genotypes  proved identical. for barley, we compared the snp genotypes called by fast-gbs with the true genotypes for one of the  <dig> lines , the only one for which we had whole genome sequencing data. again, a high degree of agreement between the two datasets  was obtained. finally, for potato, we used data obtained on the solcap  <dig> k infinium chip for the same  <dig> samples used to perform gbs. these two datasets shared  <dig> snp loci. in our initial comparison, only  <dig> % were in agreement. when we examined the proportion of concordant calls, we discovered that more than 50% of all discordant calls came from only three samples and the degree of discordance in these was so great that it suggested we were not comparing the same clones. after removing these outliers from the analysis, 94% of genotypes called by fast-gbs and the snp array were in agreement in the remaining  <dig> clones. we conclude that fast-gbs can accurately call snps in species with different characteristics .

flexibility to run different sequencing platforms
in this study, to assess the performance of fast-gbs, we used both illumina and ion torrent reads. soybean and potato samples were sequenced using an illumina hiseq platform and barley samples on an ion torrent  platform. typically for gbs, illumina sequencing generates reads of uniform length , while ion torrent reads are in  <dig> to  <dig> bp. ion torrent sequencing usually leads to a higher rate of sequencing errors  <cit> . thus, it is preferable for an analytical pipeline to be versatile and capable of using reads derived from either technology . most gbs bioinformatics pipelines are able to proceed with ion torrent reads, but often need to be modified to be suitable for this type of read data. tassel, uneak, and stacks generate tags of a fixed length . this will lead to an important loss of sequence information and can lead to inaccurate or ambiguous mapping of reads. also, because of the increased amount of sequencing errors, these pipelines can generate false tags which produce false snps. as shown above, fast-gbs proved the capacity of accurately proceed maximum snp calling using reads obtained from both sequencing platforms .

CONCLUSIONS
gbs provides an extremely powerful and versatile tool for identifying and calling genetic markers to be used by researchers working in numerous species and fields of study. this genotyping approach, like all applications based on ngs, generates a huge amount of raw data. these data need to be analyzed as quickly and efficiently as possible, all the while yielding snp data that is highly accurate. fast-gbs showed itself to be a powerful pipeline to generate large numbers of highly accurate snps using sequence read data obtained from different sequencing platforms and diverse species characterized by different levels of ploidy, zygosity, and genome complexity. by combining efficiency and accuracy in this way, fast-gsb constitutes a useful tool for a broad array of users in different research communities.

availability and requirements

project name: fast-gbs


project home page:
https://bitbucket.org/jerlar73/fast-gbs



operating system: linux


programming language: bash and python


license: gnu gpl v


any restrictions to use by non-academics: no

sequence data are available in ncbi sequence read archive  with the srp# study accession, srp <dig> 

abbreviations
cropscomplexity reduction of polymorphic sequences

gbsgenotyping-by-sequencing

indelinsertion-deletion

maxmdmaximum missing data

minmafminimum minor allele frequency

minnrminimum number of reads

mnpmultiple nucleotide polymorphism

mqmapping quality

ngsnext-generation sequencing

rad-seqrestriction site associated dna sequencing

snpsingle nucleotide polymorphism

