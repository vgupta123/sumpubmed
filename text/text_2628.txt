BACKGROUND
the natural world presents a rich mixture of auditory events that overlap in frequency and time. one of the brain's greatest perceptual challenges is to segregate this mixture into distinct "streams", so that it can attribute acoustic energy to discrete sources in the environment. this analysis of an auditory scene is essential for much of our daily acoustic experience, notably for communication where it is posed as the 'cocktail party problem'  <cit> . in addition to its importance for healthy listeners, stream segregation may be impaired in various neurological disorders such as dyslexia  <cit> , schizophrenia  <cit>  and asperger syndrome  <cit> , and the inability to segment and selectively attend to sounds is a major problem with hearing impairment  <cit> .

decades of psychoacoustic studies have characterized the basic phenomenology of streaming with sequences of sounds. the classic paradigm uses alternation between two sounds that differ along one stimulus dimension  <cit> , such as spatial location  <cit> . the sounds  typically alternate along with silent gaps  in an aba- pattern. when these stimuli are close in the relevant dimension they are grouped into a single stream and perceived as triplets with a galloping rhythm. at larger separations the streams segment, and subjects perceive a repeating stream of a sounds  and a separate, more slowly repeating b stream . at intermediate frequency separations the single and two stream percepts are bistable, where listeners switch between perceptual states after an initial buildup  <cit> . however, despite its perceptual importance, the neural mechanisms of streaming remain unclear.

a central area of contention is the role of early auditory cortex in forming and maintaining streams  <cit> . evidence from different methodologies has failed to converge on a single answer. animal studies have relied mainly on recordings from early auditory cortex that characterize the changing neural representation of tones during the buildup of streaming  <cit>  or physical changes to the stimulus that correlate with perceptual state  <cit> . theories based on this data posit that auditory cortex  plays a key role in both the formation and maintenance of auditory streams through modulation of the receptive fields of auditory neurons  <cit> . however these conclusions are practically limited since it is difficult to record extracellularly in many regions of cortex simultaneously and since animals cannot signal their perceptual state unambiguously. meanwhile, human studies using both electroencephalography   <cit>  and magnetoencephalography   <cit>  have also supported the importance of ac in streaming. these studies found correlates of segregation in electrical and magnetic waveforms believed to be generated in ac and time locked to the individual tones within a sequence. however the stimulus-locked nature of waveform analysis could not characterize non-ac signals which occur on the time scale of percepts rather than individual sounds.

in contrast, an influential fmri study by cusack in  <dig> challenged the importance of ac by showing a single area in right posterior ips where activity was greater during the split percept relative to the grouped percept  <cit> , and failing to find any effect of percept in ac. these findings led cusack to propose a model of stream segregation that relied on top-down control of auditory information for the maintenance of streams rather than automatic segregation in early sensory cortex. he argued that ips is a multimodal region sensitive to object number and provides the key neural mechanism for the segmentation of auditory sources. finally, recent fmri experiments have found effects related to streaming in ac, either as stimulus properties change in a way that correlates with streaming  <cit>  or during the momentary switches from one percept to another  <cit> . however, it is unclear how these stimulus driven effects or switch events are related to the persistent neural activity that maintains a single percept over an extended period of time.

taken as a whole, these findings from multiple methodologies present an inconsistent picture of the neural mechanisms of auditory streaming. animal researchers have clear theories for the neural mechanisms in ac that could sustain streaming, but have thus far not recorded from cortical regions outside of auditory cortex. eeg and meg evidence suggests an involvement of ac in the continuous maintenance of auditory streams yet fmri experiments have failed to find corroborating evidence. therefore, in this study, we used fmri to provide some continuity between disparate lines of evidence: specifically, to test if the same networks that strongly represent incoming auditory information are sensitive to perceptual state by showing an overall activity difference between group and split percepts. we observe an effect in early ac which is sustained through the length of the percept.

methods
participants
fifteen subjects participated in the study . all subjects had no history of neurological disorders or hearing loss. participants gave written informed consent in accordance with procedures approved by the university of california institutional review board and were paid for their participation. two of the subjects were removed based on behavioral performance inside the scanner .

stimulus design
the stimulus consisted of repeating sequences of two sets of harmonic pitch sounds  and gaps , presented binaurally at a comfortable level, approximately  <dig> db. the sounds were arranged in an aba- pattern. each of the complex tones in the aba triplets had a stimulus onset asynchrony  of  <dig> ms, with a  <dig> ms linear ramp. the long gap  had a duration of  <dig> ms to ensure that the sounds in segmented a and b streams were isochronous . this arrangement of tones is known to induce streaming when the a and b sounds are separated along some stimulus dimension. for this study, the a and b sounds were separated in perceived spatial location using interaural level difference . the ild was calibrated for each subject during a pre-scan session targeting 50% of the time spent streaming . in different versions of this basic aba- pattern, the a tone was alternatively perceived on the left or right side of the midline. the b tone was always perceived on the opposite side of the midline from the a tone with equal spatial disparity. this gives two sequences: a left-right-left-gap  and a right-left-right-gap . both the a and b sounds had a fundamental frequency of  <dig> hz and equal intensity harmonic stacks up to  <dig> khz. the fundamental frequency was chosen to be in the range of the human voice, a highly ecologically relevant stimulus subject to streaming. each stimulus block consisted of either a lrl or rlr sequence continuously for  <dig> seconds. when outside of the fmri scanner, a recording of the scanner's epi noise was presented with the aba- triplets to ensure accurate estimation of behavioral thresholds. the epi noise was recorded using an optimic  <dig> optical microphone  between each tone. tones were separated by interaural level difference . the coloring reflects two possible perceptions of an identical tone sequence. above, the single stream or grouped percept has all tones as part of the same perceptual object. below, the two-stream or split percept has tones with different features grouped into different perceptual objects. two types of tone sequences were presented that were either perceived as left-right-left or right-left-right sequences.

intensity deviants
in addition to the basic streaming stimuli, we included increased intensity deviants for both a and b sounds to ensure that subjects were actively attending to the sound sequences, and so we could confirm that detection - as a proxy measure of attention - does not explain any perceptual streaming effects. deviants occurred  <dig> times for each sound at pseudo-random times throughout the  <dig> second block. the deviants were also calibrated for each subject to target a d' of  <dig> .

task and calibration
subjects were given a short training on how to distinguish the two percepts, which typically alternated spontaneously and categorically between a single stream containing both the a and b tones  and two separate streams of the a tones alone and the b tones alone . once they were comfortable with the distinction, subjects began the full calibration. first, a rough psychometric function for streaming as a function of ild separation was calculated using three  <dig> second long blocks. subjects were instructed to press and release one of two buttons with their right middle and right index fingers to indicate a switch to a grouped and split percept, respectively. all subjects were assumed to begin each block in the grouped percept  <cit> . subjects were given a self-timed break between each  <dig> sec block. streaming thresholds, defined as the spatial disparity necessary for the subjects to spend 50% of a block in the split percept, were estimated from each subject's approximate three-point psychometric function through linear interpolation. then, with spatial disparity held at this threshold, detection thresholds for the intensity deviants were estimated in a similar fashion. subjects pressed a button with their left index finger each time they detected a deviant. responses occurring from 200- <dig> msec after the onset of the deviant were scored as hits; responses outside of this window were counted as false alarms. to further refine our estimate of each subject's ild and deviant detection thresholds, subjects then began an adaptive 1-up 1-down staircase procedure  <cit> , with the initial values set at the previously estimated thresholds. this algorithm targeted 50% of the time spent in the split percept during each  <dig> sec block, and a d' of  <dig> for deviant detection across both deviant types. subjects performed both tasks simultaneously, and after each block the values for spatial separation and deviant disparity were adapted independently. the spatial separation had a step size of  <dig> db and the detection task had a step size of  <dig>  db. subjects proceeded until the direction of change reversed at least  <dig> times for each of the two metrics, a procedure that usually lasted 10- <dig> blocks. then, the values for each reversal were averaged to find a threshold for streaming and deviant detection. this threshold was finally confirmed with a  <dig> block run, and adjusted by hand if the average streaming differed from 50% by more than 10%, and if the d' was less than  <dig>  or more than  <dig>  this calibration procedure occurred within two weeks before a participant's scanning session, and lasted approximately  <dig>  hours.

scanning procedure
scanning was separated into six,  <dig>  minute sessions. sessions began and ended with a  <dig> second fixation period that served as a baseline. subjects performed the previously described streaming and deviant detection tasks during four,  <dig> sec blocks each separated by a  <dig> sec fixation period. each session consisted of  <dig> lrl and  <dig> rlr stimulus blocks in pseudo-random order.

imaging
mri data were collected in a siemens magnetom tim trio system  <dig> tesla scanner with a 32-channel rf headcoil and a whole body gradient system. foam padding was used to minimize head motion. each session began with a series of images to determine regional anatomy, including a sagittal localizer  =  <dig> ms, echo time  =  <dig>  ms). single-shot gradient-echo echoplanar images  were acquired for thirty-six near-axial slices. the functional scans had the parameters: tr of  <dig> s, te  <dig> ms,  <dig> ×  <dig> acquisition matrix,  <dig>  mm slice thickness, a  <dig> mm field of view,  <dig>  mm in plane resolution, bandwidth of  <dig> hz/px and a flip angle of 90°. a high resolution three-dimensional mprage image for use in intersubject coregistration was taken at the end of the session with a voxel size of  <dig>  ×  <dig>  ×  <dig>  mm. auditory stimuli were presented with a piezoelectric audio system customized for use in high magnetic fields . the earbuds of the audio system passively attenuated the scanner noise to  <dig> db , and stimuli were played at  <dig> db. all sounds were filtered to account for known frequency response of the earbuds, ensuring that stimuli were perceived as intended.

data analysis
behavioral data was analyzed using custom in-house scripts written in matlab  <dig>  . fmri data was analyzed using a combination of in-house scripts and the modified general linear model  in spm  <dig> http://www.fil.ion.ucl.ac.uk/spm/software/spm8/. epis were slice time corrected, realigned to the first scan, coregistered to the subject's mprage, normalized to the montreal neurological institute  template  <cit> , and smoothed with an  <dig> mm gaussian smoothing kernel unless otherwise noted. the following covariates were added to the design matrix: a block regressor for the  <dig> second sound sequences , a perceptual regressor which had the value of  <dig> when subjects grouped sounds and - <dig> when subjects split sounds, and separate impulse regressors for deviant onsets, hits and false alarms. the standard approach in neuroimaging studies would be to model the key conditions  separately, and then contrast their parameter estimates or betas. for bistable perceptions this standard method poses significant problems. the categorical nature of the perceptual phenomenon requires that when one of the two possible states ends, the other begins. thus after standard high-pass filtering, perceptual states are strongly collinear . models with highly collinear regressors are mathematically unstable and can lead to unreliable results  <cit> . the inclusion of a bimodal covariate to model perception surmounts this limitation by combining the strongly-anticorrelated regressors into a single covariate. this bimodal regressor is functionally equivalent to a grouped > split contrast between the parameter estimates of independent regressors. therefore, positive regression coefficients associated with the perceptual regressor signals regions which have higher activity levels during grouped percept relative to split percept, while negative parameter estimates indicate the inverse. all these regressors were convolved with the standard spm <dig> hemodynamic response function . motion parameters and session covariates were also included as nuisance regressors. all group level statistical tests were t-tests on beta parameter estimates against the null hypothesis that they equal zero.

RESULTS
behavior
in order to maintain statistical independence between regressors used to code sound onset and perceptual state, only subjects who streamed between 35% and 65% during the scanning session were used. subjects with larger or smaller streaming percentage would by definition have large portions of sound blocks spent in a single percept, which would cause the sound onset and percept to have similar time courses, leading to collinear regressors. thirteen of the  <dig> subjects met this criterion, and represent the group referred to in all subsequent analyses. within this group, the mean proportion of streaming was  <dig> % . there was no significant difference in streaming percentage between the two stimulus types, lrl and rlr and all subsequent analyses are collapsed across both stimulus types. the group mean of each subject's median inter-switch interval was  <dig>  seconds , putting it in a range which is amenable to detection by a glm after filtering with a hrf.

the mean d' for deviant detection was  <dig>  , indicating that subjects actively attended to the stimuli. to further analyze the effect of perceptual state on deviant detection, we performed an analysis of variance  on the target hit rate in a repeated measures  <dig> ×  <dig> design, with the factors of deviant side and perceptual state. hit rate was used for the anova because false alarms cannot be attributed to a particular side. this anova revealed that there was a main effect of target location on hit rate  =  <dig> , p =  <dig> ), with left targets being detected with more frequency than right targets. there was no effect of perceptual state  =  <dig> , p =  <dig> ) or interaction between location and perceptual state  =  <dig> , p =  <dig> ).

fmri
when testing for an effect of the sound covariate relative to baseline, we observe robust activations along portions of superior temporal gyrus  and brainstem. only auditory cortex  and inferior colliculus were found to be significantly modulated when the conservative bonferroni family wise error  correction for multiple comparisons was used . the cortical activation likely contains both primary and secondary auditory regions, and our paradigm was not meant to distinguish between them. to test the direct hypothesis that perceptual state is encoded by regions that process attributes of the stimulus, we used only those voxels passing fwe correction bilaterally along the superior temporal gyrus as a region of interest  . we averaged all parameter estimates, or betas, within the roi and tested for a non-zero beta for our streaming regressor across all subjects. a positive beta would indicate that activity in those voxels is higher for the grouped percept than the split percept, while a negative beta would signify the inverse. for more details about the perceptual regressor, see the methods section. we find a significant effect of percept in voxels that are strongly responsive to sound . the average beta across the roi and subjects is negative, indicating that the split percept results in higher levels of activation within ac than during the grouped percept. a similar test on the voxels within the inferior colliculus yielded no effect of percept. however, our scanning procedure was not optimized for detection of subcortical signals  <cit> .

in addition, the spatial pattern of perceptual modulation and the representation of sound within ac covaried on a voxel by voxel basis. using the same ac roi, we analyzed the relationship between beta values for the sound regressors and the perceptual regressors in unsmoothed data. for each subject, correlation coefficients were transformed to z-scores using the hyperbolic arctangent, and then group z-scores were tested against the null hypothesis. this analysis indicated that there was a significant  negative correlation between the beta values, indicating that those voxels which had a stronger level of activation for sound also had a stronger effect of percept, where the split percept caused greater activity than the grouped percept. the mean z-score across the group corresponded to a correlation coefficient of - <dig> . the data for the subject with the median correlation coefficient  is presented in figure  <dig> 

an exploratory analysis of the whole brain reveals voxels in right intra-parietal sulcus  and the precuneus which surpass a threshold of p < . <dig>  for an effect of perceptual state . the region in rips is 3- <dig> cm anterior to the two regions found by cusack  to be sensitive to perceptual state. in contrast, perceptual sensitivity has not been reported in the precuneus region before. a list of the mni coordinates and effect sizes of cluster maxima can be found on table  <dig>  in order to directly asses if our data were consistent with the previous findings, we analyzed our smoothed data  at both sets of mni coordinates reported by cusack. the posterior ips region  showed a trend level effect of percept , while the anterior region  showed a significant effect of percept . all parietal regions discussed in this section showed a negative beta, indicating that the split percept produces a higher level of activity than the grouped percept. the sign of this relationship is also consistent with cusack's findings. unlike auditory cortex, an analysis of the patterns of these parietal activations yielded no significant correlation  between the betas for acoustic response and perceptual state.

discussion
our results show that early ac reflects the sustained perceptual phenomenon of streaming, and that the spatial patterns of ac subregions most sensitive to sound also show the greatest perceptual effect. this broadly supports the theory that sound segregation modulates the same neural circuits that process basic sound object features  <cit> . the direction of our perceptual effect, that ac activity is greater for separate streams than a grouped stream, and the existence of buildup in streaming supports the notion that the grouped percept is the default perception and that additional metabolic effort occurs when perceiving two or more streams. animal models of streaming propose that this effort manifests as narrowing receptive fields of neurons sensitive to the stimulus dimension along which the putative streams are separated  <cit> . while there are examples where the local circuits of a cortical region can promote sharpening of receptive fields through short-range reciprocal inhibition from audition  <cit> , vision  <cit> , and olfaction  <cit> , an alternative explanation is that other cortical regions could direct or otherwise interact with local streaming related sharpening. theories of auditory streaming have so far not made specific claims about whether this modulation arises from local network processes or interaction between ac and higher level areas.

our data suggests that ac is only one of several regions involved in streaming. higher cortices may play a cooperative role by interpreting a segregated scene or modulating the streaming itself. for instance, consistent with cusack's previous work  <cit> , rips may track the number of distinct objects after they have been segregated by auditory cortex or it may allow broad behavioral goals to influence streaming mechanisms. such high level control of auditory streaming mechanisms is evident behaviorally as listeners can consciously influence the number of perceived objects  <cit> . further studies that are optimized to detect functional connectivity between multiple cortical regions and explicitly modulate top down signals such as task demands or expectation may shed light on the interaction between higher level areas and ac.

technical challenges may have played a key role in the prior lack of fmri based evidence for ac's involvement in the continuous maintenance of auditory streaming. cusack's study used sparse scanning techniques, and a number of stimuli that spent a large amount of time in a single percept  <cit> . both of these factors would drastically reduce statistical power, possibly giving a false negative for the effects of perceptual state. in addition, general linear models  can have difficulty dissociating the activity for bi-stable percepts. if regressors are included for each perceptual state independently, the alternating nature of bi-stable percepts can cause the regressors to become collinear after standard filtering needed to remove known low frequency noise in fmri data. we instead used a single bimodal perceptual regressor that, although precluding analyses on each percept alone, offers a powerful measure of the activity distinguishing between percepts.

it is also worth considering why eeg and meg studies have not found effects outside of auditory cortex. clearly, models of streaming would benefit from data on non-ac  neural signals with the excellent temporal resolution of eeg and meg. one possibility is that higher level processes lack consistent phase-locking with the stimuli. so while previous studies have focused on stimulus-locked event related potentials/fields, induced activity  may have remained undetected. in addition, the meg studies cited used source-filtered waveforms that ignored currents generated outside of ac  <cit> . designs and analyses that detect non-stimulus locked activity and integrate data from multiple current sources may improve the correspondence between findings in these different modalities.

surprisingly in our attentional control task, subjects were no worse  at detecting targets while streaming separate objects. this has direct relevance for theories of how attention operates within, or spreads across, object representations  <cit> . our results suggest that there is no cost associated with small numbers of objects. in general, auditory streaming appears to be a relatively untapped paradigm for the study of object-based attention considering the advantages of having a single controlled stimulus which fluctuates between two different object schema every few seconds. some investigations have suggested that certain task sets, such as deviant detection in a single stream, may promote perceptual segregation  <cit> . even though the recorded d' values between our two perceptual states is equivalent, it may be that performing a secondary task designed to spread attention across multiple streams may have impacted participants' overall streaming percentage. however, this contextual effect should not influence the interpretation of our results because our calibration procedure ensures that we find a streaming threshold in the presence of both simultaneous tasks and such task demands are equally present during both split and grouped percepts. thus any comparison between the two percepts controls for task related factors.

CONCLUSIONS
using carefully calibrated stimuli and a focused approach, we are the first group to show sustained activity in ac that distinguishes between perceptual streaming states. auditory cortex showed higher levels of activity for split percept compared to the grouped percept. these results strengthen the continuity between multiple lines of evidence supporting a role for ac in the formation and maintenance of auditory streams. at the same time, our work is consistent with previous fmri experiments to suggest that ac does not function alone in this task. future studies will address the interaction between multiple cortical regions and improve our understanding of this important perceptual phenomenon.

authors' contributions
kh designed the study, collected data, performed the analyses and drafted the manuscript. cb participated in the design of the study, analysis selection, collection of data and editing of the manuscript. dy participated in data collection and reviewed the manuscript. lm participated in study design and coordination and edited the manuscript. all authors read and approved the final manuscript.

acknowledgements and funding
this work was supported by the national institutes of health: national institute on deafness and other communication disorders .
