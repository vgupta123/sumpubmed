BACKGROUND
after the findings of down syndrome in the 1950s, the relevance between copy number variation  and genetic disorders has been extensively researched, and many studies have found crohn’s disease, type  <dig> diabetes, rheumatoid arthritis, and mental and development disorders to be connected with cnv  <cit> . furthermore, as next-generation sequencing  technology became more widely used, the genome-wide association study accelerated, hence amplifying the importance of finding cnvs related to diseases and phenotypes. the connection of cnvs found in the long qt syndrome genes kcnq <dig> and kcnq <dig> has recently been stated  <cit> , and primary open-angle glaucome has been found to be connected with  <dig> rare noble cnvs  <cit> . additionally, cnvs related to attention deficit hyperactivity disorder and schizophrenia have been concluded to show disease-specific patterns  <cit> . these studies indicate the importance of cnv detection and analysis, especially in the personalized medicine that is based on race-specific or disease-specific genetic expressions.

since  <dig>  researchers in  <dig> colleges and companies worldwide, through a consortium called the  <dig> genome project, have found 95% of the diversity in the human genome, as well as  <dig> million genetic diversities that had not been studied before  <cit> . many genome projects are actively being carried out around the world, individually or by forming consortiums, to analyze genomic sequences not only of humans, but also of other living organisms . therefore, it is expected that a massive amount of data regarding various genetic sequences is being produced, resulting in the urgent need to develop a way to extract and analyze structural variants, such as cnvs, from the massive and various genetic sequences.

originally, microarray technology  <cit>  and the sequence-based method  <cit>  were used to find cnvs in human genetic sequences. in particular, the sequence-based method, a computational approach, compares different genome sequences. this method is known to detect cnvs more accurately than microarray technology, enabling the detection of small or intermediate-sized cnvs. moreover, the appearance of ngs technology enables rapid and cost-effective sequencing, offering extensive bioinformatic analysis of the generated data and highlighting the importance of computational approaches in finding and analyzing cnvs. the sequence-based method can be divided into two categories: comparing completed assembly sequences and directly using ngs data. the method using ngs data aligns short reads of ngs data onto a completely assembled sequence, a reference sequence, to find cnvs by analyzing the alignment results produced; it is cheaper than the method that compares completely assembled sequences. however, errors in the read data are common, and the probability of errors occurring in the repeat areas of reference sequences is high. it is difficult to find exact locations of cnvs using these data consisting of many errors.

to solve this problem, methods based on paired-end read mapping , which map paired-end reads made from ngs onto known genome sequences to find cnvs  <cit> ; methods using event-wise testing  algorithms, which analyze read coverage data in finding cnvs  <cit> ; and methods based on bayesian statistics  <cit>  have been developed. pem-based methods, however, make it difficult to find cnvs in areas with complex structural mutation, since these methods rely on technologies for producing paired reads. methods using ewt algorithms limit the findable cnv size because of their having a fixed window size. moreover, pem-based methods, ewt-based methods, and bayesian statistic-based methods all need high coverage for reads.

recently, methods based on a sliding window approach, such as cnv-seq  <cit>  and cnv_shape , were proposed for detection of even small cnvs at low coverage read data. however, cnv-seq still uses the ratio of the read coverage between control and test sequences, as microarray technology does, causing errors in the decision of cnv types. cnv_shape, which is excellent in the type decision, also has errors in the exact localization of cnvs because it is based on the shape variation of read coverage data. methods based on the sliding window approach, such as cnv-seq and cnv_shape need to optimize the size of the sliding window according to the coverage and noise levels of target data. however, a larger sliding window size decreases the noise effect and also results in a decrease of the resolution in cnv detection. therefore, if an initially optimized and fixed sliding window size is used as in both cnv-seq and cnv_shape, small cnvs could be missing due to its limited resolution especially when the coverage level is low and the noise level is high. therefore, there is an urgent need to develop a method to detect the exact types and locations of cnvs from low coverage read data, since most genome projects need to accurately predict the probability of an individual catching a disease or having genetic disorders by analyzing sequences with fairly low-coverage read data.

this manuscript proposes a new method, cnv_ss, to detect cnvs by using the multi-resolution system of scale-space filtering, enabling the detection of the types and the exact locations of cnvs of all sizes even when the coverage level of read data is low . the scale-space filtering is a technique that can produce qualitative and hierarchic symbolic descriptions of a signal by transforming it into a continuum of versions, scale-space image, of the original signal convolved with a kernel containing a scale parameter. the scale-space image provides a concise but complete qualitative description, such as local extrema and intervals bounded by dominant points, covering all scales of observation. in this study, the scale-space filtering is evaluated by assuming a gaussian distribution of read coverage data and the scale-space image is obtained by applying to the read coverage data the gaussian convolution for various scales according to a given scale parameter. next, inflection points, zero-crossing points of the second derivatives of the scale-space image are calculated per scale. then, the types and the exact locations of cnvs are obtained by analyzing the contours of the inflection points of the scale-space image.

scale-space filtering
real-world objects are composed of different structures at different scales. that is, real-world objects may appear in different ways depending on the scale of observation. for example, the concept of a “tree” is appropriate at the scale of meters, while concepts such as leaves and molecules are more appropriate at finer scales. for extracting cnvs of unknown sizes and locations by analyzing read coverage data, there is no way to know a priori what scales are appropriate for describing the structures of cnvs in the read coverage data. hence, the reasonable approach is to consider descriptions at multiple scales in order to be able to capture the unknown scale variations that may occur. scale-space filtering, proposed by witkin, is a method that describes signals qualitatively covering all scales of observation  <cit> . it is a framework for multi-scale signal representation which handles a signal at different scales and represents it as a one-parameter family of smoothed signals, called scale-space image, parameterized by the size of the smoothing kernel used for suppressing fine-scale structures. the parameter in the family is referred to as the scale parameter. the gaussian kernel is generally used for smoothing signals, because it is symmetric and readily differentiable, with the standard deviation σ as the scale parameter. a signal convolved with the gaussian kernel satisfies “well-behavedness” criteria, in which the signal is smoothed more as σ increases, and eventually approaches the mean value of the signal  <cit> .

let f be a signal. the scale-space image f of f is then defined by the convolution of f and the gaussian kernel g as follows:

  f=f∗g=∫−∞+∞f1σ2Πe−22σ2du. 

here, zero-crossing points, where the signs of the derivatives of the scale-space image f change, cannot newly appear, but only disappear as σ increases, since the scale-space image f gets smoother as σ increases. it is particularly useful for the second-order derivative because the zero-crossing points at which δ2fδt2= <dig> represent the inflection points of the scale-space image f. notice that the gaussian kernel is the only one guaranteed to satisfy this property  <cit> .

cnv is one of alterations of the dna of a genome that results in the cell having an abnormal number of copies of one or more sections of the dna. cnv regions on read coverage data can be defined as regions where the levels of the coverage vary greatly between different regions. therefore, in terms of scale-space filtering, cnv regions can be regarded as intervals bounded by dominant points where the read coverage data vary greatly between different regions. in other words, cnv regions can be regarded as intervals between two neighboring inflection points, one from positive curvature to negative curvature and the other from negative curvature to positive curvature, vice versa. in cnv_ss, scale-space filtering evaluates scale-space image by applying the read coverage data the gaussian convolution for various scales according to a given scale parameter. the scale-space image represents noise-filtered read coverage data with variable sliding window size corresponding to the scale parameter for every scale. cnv_ss selectively chooses the scale for cnv detection depending on the coverage level as well as the size of cnvs, that is to have adaptable window size for various noise levels as well as various cnv sizes and then localizes the exact position of the cnv at the lowest scale.

methods
cnv_ss proceeds in two stages: up and down stages. figure  <dig> describes the overall processes. the up stage includes preprocessing, gaussian convolution, and finger print mapping. the down stage includes baseline adjustment, interval search, and cnv detection.

first, in the up stage, read coverage data are generated by mapping reads of input data to a reference genome. then, they are decomposed into l layers by gaussian convolution with increasing σ. next, the zero-crossing points of the second-order derivatives of the decomposed data are evaluated per layer. finally, a finger print map is obtained from the zero-crossing points.

in the down stage, the baselines of each layer are calculated using the mean and the standard deviation of the read coverage data for each layer with decreasing σ. intervals are also searched by using the baselines through the finger print map with decreasing σ. here, an interval is a region of the input sequence where a cnv gain or loss is detected. more than one interval is not permitted in a region of the sequence. therefore, once an interval is obtained at a layer, the exact position of the detected cnv is decided by localizing the positions where the start and the end points of the interval converge at the lowest layer; no more interval searching at the corresponding region is necessary at the sub-layers.

preprocessing
read coverage data are generated by aligning reads of input data to a given reference sequence, and then they are filtered by a median filter. the median filter is an effective method that can suppress isolated noises without blurring sharp edges of a signal which is affected by the size of the sliding window. in other words, the size of the sliding widow in median filtering should be chosen not to blur sharp edges of the signal. the read coverage data c=c1c2…cn consist of a series of the number ci of reads aligned to the genome position i . the read coverage data c are median filtered to reduce the noise errors before proceeding to the gaussian convolution. the median filtering is accomplished by replacing each entry ci with the median of entries, ci−w/2…ci…ci+w/ <dig> in a sliding window with size w+ <dig>  the value for w was set to  <dig> which was determined as around 15% of the smallest cnv size by a heuristic evaluation in order to keep cnv signals while suppressing isolated noises in the read coverage data. figures  <dig> and  <dig> show virtual read coverage data before and after the median filtering, respectively. it can be seen that the large spikes are reduced and the data become less noisy after filtering.

gaussian convolution
the read coverage data c=c1c2…cn are decomposed into l layers by gaussian convolution with increasing σ as in the following equation: 

  c=c∗g=∑j=−mmc1σk2Πe−j22σk <dig>  

where c is called the scale-space image of c=c1c2…cn, k  represents the index of the layer of the scale-space image, σk is the value of the scale parameter at layer k, and m is the window size of the gaussian kernel g, which is set to m=3σk. the scale parameter σk is the standard deviation of the gaussian kernel g, and is set to σk=103×k considering the range of detectable cnv size and time complexity. the range of the scale parameter σk determines the range of cnv size detectable in this method. the ratio of two adjacent scales determines both the time complexity and the resolution in cnv detection. the smaller ratio of two adjacent scales, the better in resolution of cnv detection but the worse in the time complexity. therefore, trading off between the resolution and the time complexity can be controlled by the ratio of two adjacent scales. the value of σk increases exponentially as k increases.

the computational complexity to get a scale-space image c of c is oln). it is well known that the convolution in the time domain is the same as the product in the frequency domain. therefore, we obtain the scale-space image c of c by applying discrete fourier transform in frequency domain to reduce the computational complexity. let c and g=e−w2σk2/ <dig> be the discrete fourier transform of c, and g, respectively. the scale-space image is then obtained by 

  c=f−1{gc}, 

where f− <dig> is the inverse discrete fourier transform operator. the computational complexity to get a scale-space image c of c by discrete fourier and discrete inverse fourier transform is o if the fast fourier transform algorithm is used. when the number of the layers of the scale-space image is large, the computing time can be greatly reduced in the frequency domain. specifically for n= <dig>  l= <dig>  the computational complexity can be reduced about  <dig>  times. figure  <dig> shows the scale-space image obtained by using the read coverage data of figure  <dig> representatively for k =  <dig>   <dig>   <dig>   <dig>   <dig>  and  <dig> 

finger print mapping
the zero-crossing points of the second-order derivatives of the scale-space image c are searched for each layer k. here, the second derivative c′′ of c is approximated by the second-order difference, that is, c′′ ≈ c − 2c +c. a zero-crossing signal z is defined as follows: 

  z=+ <dig> c′′>0andc′′<0− <dig> c′′<0andc′′> <dig> ,else 

where the condition c′′ >  <dig> and c′′ <  <dig> represent the zero crossing point i at which c′′ crosses zero from minus to plus, and the conditions c′′ <  <dig> and c′′ >  <dig>  from plus to minus.
k for 0 ≤ k ≤ l −  <dig>  in the figure, the values + <dig> and − <dig> of z are represented by markers ‘o’ and ‘+’, respectively. the values  <dig> of z are not marked in the figure. the vertical dotted lines indicate the zero-crossing points. all the zero-crossing points for k =  <dig> are indicated by the vertical dotted lines but some of them for k =  <dig> and  <dig> 

baseline detection
at the down stage, three baselines, m∗, m∗+dδ∗, and m∗−dδ∗ are calculated using the effective mean m∗ and the effective standard deviation δ∗ of the scale-space image c for each of the layers that have more than two non-zero elements in zero-crossing signal z, where d is a parameter for the baseline adjustment. here, we set the value of d to  <dig>  the effective mean m∗ and the effective standard deviation δ∗ at layer k are evaluated by the average and the standard deviation of c, respectively, excluding the points whose values are out of the normal range. the normal range is set at m±2δ, where m=∑ic/∑i and δ=∑i2/∑i are the mean and the standard deviation of c, respectively.

interval search
intervals are searched from the zero-crossing signal z using the baselines m∗±3δ∗ for each of the layers that have more than two non-zero elements in zero-crossing signal z. the mth interval  at layer k is defined as a closed interval {i|lm,k≤i≤um,k} in the position index i of the zero-crossing signal z, that is a set of the position indices of z between lm,k and um,k inclusive, satisfying the following three conditions to be a putative cnv region. first, interval  does not include position indices corresponding to all the regions of cnvs already declared at layers above the layer k. second, z • z <  <dig> and z =  <dig> for all the position indices between lm,k and um,k. third, the average ∑i=lm,kum,kc/ of the scale-space image on the position indices between lm,k and um,k inclusive is beyond the given baselines, m∗−3δ∗ or m∗+3δ∗.

once we have the mth interval  as a putative cnv region, then we trace the zero-crossing signal z from the positions lm,k and um,k at layer k until we get the corresponding positions lm,k′ and um,k′, respectively bounded at layer k= <dig>  where the closed interval ={i|lm,k′≤i≤um,k′} is to be declared as a cnv. in other words, the interval  is a precisely fine tuned cnv region corresponding to the interval , a putative cnv detected at layer k. cnv search is proceeded from the top layer to the bottom layer, layer by layer. therefore, for searching intervals at layer k, the sum of sets, ⋃s=k+1kmax⋃m=1mmax,s corresponding to all the regions of cnvs already declared at the upper layers from k+ <dig> to kmax should be excluded, where mmax,s is the total number of cnvs detected at layer s. in other words, all the sum of intervals, ⋃m=1mmax,k searched at layer k should not be overlapped with the sum of intervals, ⋃s=k+1kmax⋃m=1mmax,s already declared as cnvs at the upper layers, which is the first condition. the second condition is that if lm,k is a zero crossing point from minus to plus then um,k should be from plus to minus, vice versa as well as there are no other zero crossing points between lm,k and um,k. the meaning of the second condition is that the values of the scale space image c between lm,k and um,k, inclusive have significantly different values from others of c to be declared as a cnv. the third condition is for the definition of baselines m∗, m∗±3δ∗, the guidelines for determining whether the values of the scale space image c between lm,k and um,k, inclusive have significantly different from others of c for 1≤i≤n, where m∗ and δ∗ are the effective mean and the effective standard deviation of c for 1≤i≤n at layer k, respectively.

cnv detection
the type and the localization of a cnv are determined by using the results of interval search. an interval  identifies the region where a statistically significant variation occurs on the input sequence and a cnv gain or loss is to be detected. that is, a cnv gain or loss is identified if the average ∑i=lm,kum,kc/ of scale-space image in the interval is above m∗+3δ∗ or below m∗−3δ∗, respectively. then the localization of a cnv is defined by tracing to the corresponding region  as the layer k converges to zero. figure  <dig> shows a cnv calling as a gain by the vertical solid lines below the finger print map representing the corresponding region  of the interval  at k= <dig> where the average of the scale-space image c in the interval  is above m∗+3δ∗.

materials
a simulation data generator  was developed to generate simulated data. it generates a reference sequence and a test sequence, which contain cnvs of various sizes and types, as well as single nucleotide polymorphisms  and short indels. the sdg starts with a given dna sequence both as a reference sequence and as a test sequence. it then copies some of the cnvs of the sequence referring to the cnv database of the database of genomic variants  and substitutes them in random positions of the reference sequence or the test sequence so that the test sequence has cnv gains or losses that differ in size and location compared with the reference sequence. an indel is constructed by inserting or deleting a short sequence at a random position of the reference or the test sequence. for snps, the sdg replaces the nucleotides at random positions of the test sequence so that each of the replaced positions in the test sequence has a different nucleotide from that in the reference sequence. once a reference sequence and a test sequence are generated, reads of the test sequence are generated by simulating the shotgun sequencing process of the solexa machine.

a total of  <dig> simulated data were generated by sdg, in which ncbi build  <dig>  chromosome   <dig> genomic contig nt_ <dig>  was used as the starting sequence and the corresponding information of the  <dig> potential cnv regions  referring to dgv were used. specifically,  <dig> of the  <dig> potential cnv regions were randomly selected and inserted in random positions of the reference sequence or the test sequence. the test sequences were treated to have a given sequencing error rate . then, paired-end reads of length  <dig> bp were randomly extracted at a given read coverage  from each of the  <dig> simulated test sequences.

read data downloaded from the site of the  <dig> genome project  were used for the experiment with real human data. the downloaded data were paired-end reads of six hapmap samples: na <dig> , na <dig> , na <dig> , na <dig> , na <dig> , and na <dig> , which were generated by the solexa ga machine.

the performance of cnv_ss was assessed by comparing the detected cnv regions with those reported to dgv on each individual, in which we used the cnv database of dgv updated on november  <dig>   <dig>  cnv_ss was also compared with three other cnv detection methods: cnv_shape , cnv-seq  <cit> , and modified cnv-seq  with optimized parameters for each method.

soap <dig>   <cit>  was used for the alignment of the read data, and a random match method, one of various alignment algorithms that soap <dig> supports, was used with e =  <dig> mismatch criteria as a tolerable limit with regard to noise, such as sequence errors. the experiments were carried out in the platform of windows  <dig> and centos  <dig>  on intel core i <dig>  <dig> ghz cpu, 8gb main memory, and 2tb hard drive. the programming language used for the development of cnv_ss was matlab.

RESULTS
experiments with simulated data
the first experiment was carried out to assess the performance of cnv_ss for various read coverage levels:  <dig> x,  <dig> x, 1x, 2x, 3x, 6x, and 10x. here, the sequencing error rate e=2% was considered according to a typical error rate existing in real data generated by shotgun sequencing technology, even though the sequence error rate keeps improving due to the advancement of the technology. performance was assessed by estimating the false negative rate  and the false positive rate  on the basis of the size of detected cnv regions. more than  <dig> experiments for each read coverage level were accomplished with different simulated data, the results from which were averaged for the assessment. the performance of the cnv_ss was then compared with those of cnv_shape and cnv-seq.

compared with cnv_shape and cnv-seq, cnv_ss gave a little increased fprs. this is due to the fact that cnv_ss searches cnvs at every layer of the scale-space image from the top to the bottom not to exclude small  cnvs, inevitably resulting in calling small noise signals as cnvs as well. to exclude noise signals in cnv detection, our future work considers an algorithm for selectively adjusting the range of layers of the scale-space image according to the properties of the input data set in cnv detection, which will decrease fprs even at very low coverage levels.

the second experiment was carried out to assess cnv_ss for various sequencing error rates, 1% through 10%. figures  <dig> and  <dig> show the fnrs and fprs as the sequencing error rate increases when the read coverage levels are 1x and 3x, respectively. the fnrs and fprs increase as the sequencing error rate increases. as can be seen in figure  <dig>  the fnrs both for cnv-seq and the cnv_shape increase rapidly as the sequencing error rate increases when the read coverage level is low. while cnv_ss has fairly good fnr  and fpr  even when the sequencing error rate e is high  and the level of read coverage c is low . the overall fnrs and fprs for cnv_ss were in the range of  <dig> % to  <dig> % and  <dig> % to  <dig> %, respectively, at the read coverage level c=1x, and in the range of  <dig> % to  <dig> % and  <dig> % to  <dig> %, respectively, at the read coverage level c=3x. the result suggests that cnv_ss can be very robust in error-prone environments at a moderate level of the read coverage.

the third experiment was carried out to assess the performance of cnv_ss in conjunction with two other methods as the threshold for determining a cnv is varied. we calculated the receiver operation characteristic  curves of cnv_ss using two data sets. these roc curves, together with the roc curves of cnv-seq and cnv_shape based on the same data sets, were plotted in figure  <dig>  figures  <dig> and  <dig> show the roc curves for the cases of  and  data sets, respectively. these curves show that cnv_ss and cnv_shape are more sensitive than cnv-seq. as cnv_ss detects larger cnvs at higher scale and smaller cnvs at lower scale, the sensitivity can be increased compared to the conventional methods using a fixed window size. for the case of lower coverage level and higher error, cnv_ss gave better performance results than other methods.

experiments with hapmap samples
paired-end reads of six hapmap samples, na <dig> , na <dig> , na <dig> , na <dig> , na <dig> , and na <dig> , were used for the experiments with real human data. fpr and fnr were evaluated on the basis of the cnv database of the dgv and then compared with those of cnv_shape, the conventional cnv-seq, and the modified cnv-seq.

in the first experiment, paired-end reads from the human leukocyte antigen  region of chr.  <dig> of na <dig>  and na <dig>  were used. the hla region, which resides on the short arm of human chr.  <dig> and is  <dig>  mbp long, is known to have around  <dig> genes related to the human immune system and several potential cnv regions involving disease-specific genes  <cit> .

as shown in the middle and the bottom panels of figure  <dig>  cnv_ss accurately detects the cnv types, gain or loss, for both na <dig> and na <dig>  which is considered because of the typical characteristics of the scale-space filtering. however, cnv_shape may incorrectly detect the types of small cnv regions when the noise distribution is irregular in low-coverage sequencing data, because the method is based on the variations in the shape of the read coverage data. furthermore, cnv-seq cannot verify the types of detected cnvs because the method is based on the coverage ratio of test to control samples. as shown in the bottom panels of figures  <dig> and  <dig>  cnv-seq failed to detect as cnvs a region of  <dig> , <dig> bp through  <dig> , <dig> bp on chr.  <dig> of na <dig> and a region of  <dig> , <dig> bp through  <dig> , <dig> bp on chr.  <dig> of na <dig>  which are both reported as cnv loss regions in the cnv database of the dgv. furthermore, the region  <dig> , <dig> bp through  <dig> , <dig> bp on chr.  <dig> was detected as a cnv loss by cnv_ss, while it was estimated to be a cnv gain on na <dig> and, at the same time, a cnv loss on na <dig> by cnv-seq, as shown from the top panels of figures  <dig> and  <dig> 

as shown in table  <dig>  the smallest cnv detected by cnv_ss has a 100% overlap with the smallest  <dig> kbp cnv in dgv on na <dig>  while the smallest ones detected by cnv_shape, cnv-seq, and modified cnv-seq have  <dig> %,  <dig> %, and  <dig> % overlaps with the smallest  <dig> kbp cnv in dgv on na <dig>  respectively. the largest cnv detected by cnv_ss has a 100% overlap with the largest  <dig> kbp cnv in dgv on na <dig>  while the largest ones detected by cnv_shape, cnv-seq, and modified cnv-seq have  <dig> %,  <dig> %, and  <dig> % overlaps with the largest  <dig> kbp cnv in dgv on na <dig>  respectively.

for na <dig>  any method listed in table  <dig> does not have a cnv call on the smallest  <dig>  kbp cnv in dgv, which is regarded due to the low level of read coverage data of na <dig>  the smallest cnv detected by cnv_ss has a 100% overlap with the  <dig>  kbp cnv in dgv on na <dig>  while the smallest ones detected by cnv_shape, cnv-seq, and modified cnv-seq have  <dig> %,  <dig> %, and 100% overlaps with  <dig>  kbp,  <dig>  kbp, and  <dig>  kbp cnvs in dgv on na <dig>  respectively. the largest cnv detected by cnv_ss has a 100% overlap with the largest  <dig> kbp cnv in dgv on na <dig>  while the largest ones detected by cnv_shape, cnv-seq, and modified cnv-seq have 100%,  <dig> %, and  <dig> % overlaps with the largest  <dig> kbp cnv in dgv on na <dig>  respectively.

fnrs of  <dig> % and  <dig> % were derived for na <dig> and na <dig> in cnv_ss. in contrast, cnv_shape yielded fnrs of  <dig> % and  <dig> %. cnv-seq and the modified cnv-seq yielded fnrs of  <dig> % and  <dig> % for na <dig> and  <dig> % and  <dig> % for na <dig>  respectively.

in the second experiment, paired-end reads from the whole region of human chr.  <dig> of na <dig> and na <dig> were used. human chr.  <dig> is  <dig>  mbp long, and a total of  <dig> cnvs  and  <dig> cnvs  are reported in the cnv database of the dgv for chr.  <dig> on na <dig> and na <dig>  respectively.

the sizes of cnvs detected by cnv_ss on na <dig> and na <dig> are in the range of  <dig>  kbp to  <dig> kbp and  <dig>  kbp to  <dig> kbp, respectively. these results confirm that cnv_ss is superior to cnv_shape, the conventional cnv-seq, and the modified cnv-seq in terms of detecting cnvs of various sizes. the results also show that small cnvs can be accurately detected from low-coverage data. we can deduce therefore that cnv_ss is very effective at reducing the noise inherent in the read coverage data and in detecting cnvs of various sizes and types.

in the third experiment, paired-end reads from the whole region of human chr.  <dig> of na <dig> , na <dig> , na <dig> , and na <dig>  were used for additional experiments for low-coverage data. table  <dig> describes the comparative performance results of the four methods. the overall fnr for cnv_ss is between  <dig> % and  <dig> %, the fpr between  <dig> % and  <dig> % with relatively low coverage data. it can be seen that fnr and fpr may decrease as the level of read coverage increases. however, the performance of the proposed method has low dependency on the level of the read coverage. the results show that our method has fairly good fnr and fpr even at a very low level of read coverage , and the proposed method outperforms the other methods by as much as  <dig> % to  <dig> %.

CONCLUSIONS
a new method to detect cnvs based on scale-space filtering, called cnv_ss, is proposed. cnv_ss proceeds in two stages: up and down stages. in the up stage, read coverage data are transformed into a scale-space image with several layers by gaussian convolution, and then the finger print map is obtained from the zero-crossing points of the second-order derivatives of the scale-space image per layer with increasing σ. in the down stage, baselines and intervals of each layer are calculated using the mean and the standard deviation of the read coverage data for each layer with decreasing σ. the intervals are the regions of the input sequence where cnv gains or losses are detected. the exact positions and the types of the cnv gains or losses are decided by the intervals and the baselines of each of the layers.

to verify the performance of this method, experiments using simulated data and real human data were undertaken. the simulated data with average coverage c  and error rate e  were produced using contig nt_ <dig>  of chr.  <dig> of ncbi build  <dig>  by inputting structural variations reported to the dgv, such as snps, indels, and cnvs, into its random positions. when the e error rate was fixed at 2% in the experiments using simulated data, the results showed that fnr and fpr decrease as the read coverage level increases, and stay in the range of  <dig> % to  <dig> % and  <dig> % to  <dig> %, respectively, even at a relatively low coverage . moreover, in the experiments using simulated data with average coverage c  and the e error rate increasing by 1% within the range of 1% to 10%, the results yielded fprs of  <dig> % to  <dig> % and fnrs of  <dig> % to  <dig> % at c=1x, and fprs of  <dig> % to  <dig> % and fnrs of  <dig> % to  <dig> % at c=3x. the result suggests that cnv_ss can be very robust in error-prone environments, and the effect of errors can be reduced as the read coverage level increases. the experiments using simulated data discovered the relation between the scope of standard deviation and accuracy , which should be considered in scale-space filtering, according to the change of value in the c coverage rate and the e error rate.

in the experiments with real human data, pair-end reads of six hapmap samples, namely, na <dig> , na <dig> , na <dig> , na <dig> , na <dig> , and na <dig> , downloaded from the  <dig> genome project website, were used. the fprs and fnrs by the proposed method cnv_ss were evaluated on the basis of the cnv database of the dgv and then compared with conventional methods such as cnv_shape, cnv-seq, and modified cnv-seq. the proposed method gave a relatively similar output of fpr  with the conventional methods, whereas in fnr, the proposed method was found to be much more effective than the conventional methods, by  <dig> % at the least and  <dig> % at the most. these results show that cnv_ss can find cnvs effectively, using relatively low-coverage data, and also can find various cnvs regardless of their size.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
jl designed algorithms and performed experiments and analysis. bk, el and jy designed algorithms, performed analysis, and drafted the manuscript. all authors read and approved the final manuscript.

