BACKGROUND
predicting protein tertiary structures directly from one-dimensional sequences remains a challenging problem  <cit> . the studies of solvent accessibility have shown that the process of protein folding is driven to maximal compactness by solvent aversion of some residues  <cit> . therefore, solvent accessibility is considered as a crucial factor in protein folding and prediction of protein solvent accessibility, also called accessible surface area  prediction, is an important step in tertiary structure prediction  <cit> .

traditionally, predicting solvent accessibility is regarded as either a two-  or three-state  classification problem. various machine learning methods have been adopted, including neural networks  <cit> , bayesian statistics  <cit> , logistic functions  <cit> , information theory  <cit>  and support vector machines   <cit> . among these machine learning methods, neural networks were the first technique used in predicting protein solvent accessibility and are still extensively adopted in recent works. in addition, svms were also effective for asa prediction. several features were used to train these machine learning methods, such as local residue composition  <cit> , probability profiles  <cit>  and position specific scoring matrix   <cit> .

however, subdividing residues into states requires selection of specific asa values as thresholds, which are not well-defined in real protein structures. the applicability of state asa predictors is thus limited as their performance is highly dependent on arbitrarily defined thresholds  <cit> . ahmad et al. addressed this problem and developed a method, rvp-net, to predict the real values of relative solvent accessibility   <cit> . the rvp-net used the local amino acid composition to train a neural network and yielded a mean absolute error  of  <dig> – <dig> %. yuan and huang  <cit>  also used the local amino acid composition and adopted support vector regression   to achieve an mae of  <dig> – <dig> %. adamczak et al.  <cit>  used the pssm to train neural networks, which yielded an mae of  <dig> – <dig> %. after adamczak's work, the pssm was widely used for real value asa prediction with some success. wang et al.  <cit>  proposed a real value asa predictor with an mae of  <dig> – <dig> % by combining the pssm with multiple linear regression. garg et al.  <cit>  combined the pssm and secondary structure information with neural networks to predict rsa with an mae of  <dig> – <dig> %. nguyen and rajapakse  <cit>  used the pssm to construct a two-stage svr, which further improved the mae to  <dig> – <dig> %.

1mean absolute error of real rsa values. all the methods were evaluated with a three-fold cross-validation on the barton dataset, except adamczak et al. used their own dataset. 2neural network. 3support vector regression. 4position specific scoring matrix. 5the maes reported in this work were evaluated on a different dataset to other works. 6multiple linear regression.

for a protein sequence, the pssm describes the likelihood of a particular residue substitution at a specific position based on evolutionary information  <cit> . the basic idea of the enhanced pssm is to merge similar residues into groups and use group likelihood to generate novel features  <cit> . the likelihood of a residue group is obtained by accumulating the pssm columns of member residues into a single column. a feature selection mechanism is proposed to identify the residue groups appropriate for real value asa prediction. based on the proposed selection mechanism, grouped residues are guaranteed to have similar physicochemical properties and solvent propensities. finally, the features produced by selected residue groups are combined with a two-stage svr to construct a real value asa predictor.

the present method is compared with five real value asa predictors using a widely used benchmark. in addition, the predicted asa values are transformed to asa states for comparison with seven state asa predictors. experimental results demonstrate that the features produced by the proposed selection process are informative for asa prediction. moreover, the feature selection mechanism incorporated in this study can be applied to other regression problems using the pssm.

RESULTS
datasets
this study collects three independent datasets, barton, carugo and manesh, from previous works for evaluating alternative asa predictors. additionally, two small datasets, sma <dig> and sma <dig>  are created for the feature selection mechanism by sampling the barton dataset. table  <dig> lists the detailed statistics for these datasets.

1this is a subset of the barton set <dig>  2this is a subset of the barton set <dig> 

the barton dataset, prepared by cuff and barton in  <dig>  <cit> , includes  <dig> non-homologous protein chains with <25% pairwise-sequence identity. according to previous work  <cit> , this dataset was divided into three subsets with equal protein chains for cross-validation. these three subsets were used for training, testing, and validation data, which resulted in six evaluation combinations. the performances of the six combinations were averaged as overall performance. the second dataset, carugo, was prepared by carugo in  <dig>  <cit> , and includes  <dig> non-homologous monomeric proteins with <25% pairwise-sequence identity. the third dataset, manesh, was prepared by manesh et al. in  <dig>  <cit> , and has  <dig> non-homologous protein chains with <25% pairwise-sequence identity. these two datasets, carugo and manesh, were also divided into three subsets of equal size for cross-validation.

the three evaluation datasets – barton, carugo and manesh – are used to evaluate the present method and to compare alternative asa predictors. moreover, the proposed feature selection mechanism requires two datasets. to prevent overfitting, this work uses only a small number of samples from the evaluation subsets with the worst prediction performance in previous work. the worst prediction performance implies that the selected subsets are more distinct than other subset combinations. consequently, two small datasets, sma <dig> and sma <dig>  are constructed by randomly selecting  <dig> protein chains from set <dig> and set <dig> of the barton dataset, respectively. both small datasets account for ~1/ <dig> of the original set from which they are extracted.

the real values of asa in barton and carugo were determined by the dictionary of protein secondary structure  program  <cit> , whereas the values in manesh were determined by the analytical surface calculation  program  <cit>  based on the suggested van der waals radii by ooi et al.  <cit> . the rsa value of a residue was then computed by dividing the real asa value by that observed in the extended ala-x-ala conformation of the residue. in this study, rsa is used as the main measure for evaluating real value asa predictors.

evaluation measures
two widely used measures for real value asa prediction are adopted in this study to evaluate existing asa predictors. the first measure, mean absolute error , is defined as follows:

 mae=∑for each residue|rsapredicted−rsaobserved|n, 

where n is the total number of residues to be predicted, and mae is the absolute difference between predicted and observed  rsa values. the second measure is pearson's correlation coefficient , which is defined as follows:

 cc=1n−1⋅∑for each residue, 

where n is the total number of residues to predict; x and y are the predicted and observed rsa value of each residue, respectively; x¯ and y¯ are the average of predicted and observed rsa values of all residues, respectively; sx and sy are the standard deviation  of predicted and observed rsa values of all residues, respectively; cc is the ratio of the covariance between the predicted and observed rsa values to the product of the standard deviations of the predicted and observed rsa values.

feature selection
this study enhances pssm-based features by considering the physicochemical properties and solvent propensities of amino acid types. the concepts of using the property- and propensity-based pssm  have been used in some classification problems. shimizu et al.  <cit>  first introduced the concept of the property-based pssm by grouping residues belonging to a certain physicochemical property. such residue groups exploit evolutionary information of a particular property at a specific position. the construction details of pssm and pssmp features can be found in the methods section.

however, considering only the physicochemical property to identify residue groups generates an important question: do all amino acids in a property group contribute consistently in various bioinformatics problems? hence, su et al.  <cit>  proposed that physicochemical groups can be further divided into sub-groups according to residue propensities for order/disorder to predict protein disorder regions. for example, the property small  was divided into small with order propensity  and small with disorder propensity . such residue groups consider class propensities and can generate novel pssm-based features for different problems.

real asa prediction, unlike order/disorder classification, lacks a well-defined threshold for measuring solvent propensities of amino acids. thus, this study develops a novel iterative selection process that identifies the residue groups appropriate for real value asa prediction without defining a propensity threshold. this process uses a physicochemical property  as the initial residue group and removes a member residue with the smallest or largest solvent propensity in each round, until prediction performance cannot be improved . starting from these properties ensures that grouped residues have similar physicochemical properties. moreover, removing residues from those with extreme propensities indicates that the remaining residues have similar propensities.

this study compares prediction performance to that of the original pssm and identifies five residue groups with improved performance . finally, all possible combinations of the five groups are evaluated. care has been taken to prevent the inclusion of polarsel and chargedsel in a group combination – chargedsel is a subset of polarsel. the combination with the best prediction performance is the pair composed of chargedsel and tinysel. the final feature set with two selected properties is named pssm-2sp, and is used as the feature set in the present method. the whole feature selection process is based on the two small datasets; that is, the prediction performances of all residue groups and group combinations are obtained using sma <dig> to predict sma <dig> 

polar
                              sel
small
                              sel
charged
                              sel
tiny
                              sel
1no amino acid type is removed from the property negative in the iterative selection process.

two-stage regression
following the design by nguyen and rajapakse  <cit> , this study adopts two cascading regressions to predict real asa values. in the first stage, this study uses pssm-2sp as the feature set, which encodes the level of conservation at a position and the properties of substituted residues. a drawback of this feature set is that it lacks asa information of neighbor residues. thus, a second regression is included to account for the contextual information of neighboring solvent accessibility.

the second regression uses the output of the first regression as an estimation of neighboring solvent accessibility. the i-th residue in a protein sequence is represented as a 2w+ <dig> dimensional vector v = , where ai is the predicted rsa value of the i-th residue in the first regression, ti is the terminal flag as either  <dig>  or  <dig> , l is the sequence length and w = 2h+ <dig> is window size.

the svr  is used as the regression tool for both stages in the present method. for a test protein sequence, this study encodes the residues with pssm-2sp and invokes the first svr to obtain the first-stage rsa values. these rsa values are then used to encode residues for the second svr. the rsa values predicted by the second svr are the final output of the proposed asa predictor. this study adopts the widely used libsvm package  for svr implementation  <cit> . all required parameters are determined using sma <dig> to predict sma <dig>  these parameters are constant in all  <dig> evaluation combinations of the three evaluation datasets. table  <dig> shows these parameters.

performance on evaluation datasets
the performance of the proposed method is compared to five real value asa predictors . the predictors for comparison are the neural network method developed by ahmad et al.  <cit> , the single-stage svr developed by yuan and huang  <cit> , multiple linear regression developed by wang et al.  <cit> , multiple neural networks developed by garg et al.  <cit>  and the two-stage svr developed by nguyen and rajapakse  <cit> . all predictors included the barton dataset as one of the evaluation datasets . although some variants exist in the prediction pipeline , the performance on the barton dataset is still a good benchmark for measuring the effectiveness of these predictors. for the barton dataset, the mae and cc of the proposed method are  <dig> % and  <dig> , respectively, both of which are better than those of the compared predictors.

wang et al. applied five-fold cross-validation on barton dataset. garg et al. applied seven-fold cross-validation on barton dataset and five-fold cross-valuation on manesh dataset. all other results were obtained by three-fold cross-validation. 1mean absolute error. 2pearson's correlation coefficient. 3indicates that the corresponding result was not available from the literature.

however, the construction of the proposed asa predictor  is based on sma <dig> and sma <dig>  which are part of the barton dataset. thus, the results from the carugo and manesh datasets are helpful in investigating the overfitting effects during the construction process. the improvements to the two datasets by the proposed method are analogous to the improvement to the barton dataset, suggesting that the overfitting effects of using sma <dig> and sma <dig> are negligible .

furthermore, the predicted rsa values using the proposed method are transformed into binary asa states  for comparison with state asa predictors. the predictors for comparison are phdacc  <cit> , jnet  <cit> , the information theory approach developed by manesh et al.  <cit> , netasa  <cit> , the probability profile method developed by gianese et al.  <cit> , the two-stage svm  <cit>  and two-stage svr  <cit> . the two-stage svr approach is also a real value asa predictor, the results of which were transformed into binary asa states. table  <dig> shows a comparison of existing state asa predictors. in this experiment, a set of  <dig> proteins from the manesh dataset is used as the training set, and the remaining  <dig> proteins of the manesh dataset are used as the test set. the proposed method achieves the best accuracy for most thresholds, except at 5% and 10% thresholds . nevertheless, the proposed method still yields an accuracy rate >80% at 5% and 10% thresholds. these experimental results show that the present asa predictor can classify the buried/exposed state of residues.

this table reports the accuracy  of alternative methods based on the training set of  <dig> proteins from the manesh dataset to predict the remaining  <dig> proteins of manesh. 1indicates that the corresponding result was not available from the literature. 2nguyen and rajapakse proposed a two-stage svm approach in  <dig> which treats solvent accessibility as a classification problem  <cit> , 3and then proposed a two-stage svr approach in  <dig> which treats solvent accessibility as a regression problem  <cit> .

prediction performance vs. amino acid type
this study develops a systematic process to identify appropriate residue groups for asa prediction. however, some amino acid types are not included in the chargedsel and tinysel properties. this analysis investigates if the proposed pssm-2sp improves these amino acid types. table  <dig> compares the prediction performance for  <dig> amino acid types with and without the chargedsel and tinysel information. table  <dig> reveals some important facts in current real value asa prediction, such as amino acids that are more hydrophobic  are better predicted than those less hydrophobic . these mae differences among amino acid types concur with and have been discussed in previous works  <cit> . here, this study focuses on improving pssm-2sp over the pssm. the pssm-2sp improves ≥  <dig> % mae for most amino acid types, although the chargedsel and tinysel properties include only a, g, k and d . this can be explained by the multiple sequence alignment in constructing the pssm-2sp. namely, a non-a, -g, -k and -d residue is still affected by the chargedsel and tinysel properties when some of its homology sequences have a, g, k or d residues within the corresponding window.

CONCLUSIONS
there is an enormous gap between the number of protein structures and the huge number of protein sequences. thus, predicting protein structures directly from amino acid sequences remains one of the most important problems in life science. the pssm generated by psi-blast is a useful feature set for sequence-based methods in various bioinformatics problems. this study proposes a novel feature selection mechanism that enhances the pssm-based features for real value asa prediction. based on the selected pssm-2sp features, this study adopts two cascading svrs to construct an asa predictor. the performance of the proposed method is compared with that of five real value asa predictors and seven state asa predictors. experimental results show that the proposed predictor performs best in evaluating datasets. it can predict real asa values with an mae of  <dig> – <dig> % and predict state asa with an accuracy of  <dig> – <dig> %. these experimental results demonstrate that the selected features are informative for asa prediction. another contribution of this study is the proposed systematic process for generating novel pssm-based features for regression problems. this is achieved by shrinking the initial physicochemical property from residues with extreme propensities. the feature selection mechanism in this study can be applied to other regression problems using the pssm.

