BACKGROUND
the functioning of the human brain relies on the interplay and integration of numerous individual units in a complex network. insights into its topology are thus essential to promote our understanding of the brain in general, as well as its maladaptive states associated with dysfunction and disease. an increasingly popular approach to the analysis of functional brain networks is based on the framework of graph theory  <cit> . a graph is a mathematical structure designed for modelling pairwise relationships, known as edges, between an assortment of objects, referred to as nodes. in applications to fmri, the node set is defined as a collection of brain sites, and edges are established by measuring internodal functional connectivity  <cit>  based on the regions’ associated time series. the obtained functional connectivity graph, serving as a simple model of the brain’s functional organization in a complex network, is subsequently examined drawing on a rich collection of graph-theoretical metrics that target various aspects of its topology  <cit> . several studies indicate, for instance, that the brain’s functional network conforms to a small-world architecture  <cit> . beyond that, the usefulness of graph-based functional connectivity analyses has been demonstrated in applications to brain development and aging  <cit> , gender differences  <cit> , intellectual performance  <cit> , and neurological disorders, such as alzheimer’s disease  <cit>  or schizophrenia  <cit> .

in most previous studies, functional connectivity graphs have been constructed at the level of regions  <cit> , meaning that graphical nodes are defined based on a parcellation of the brain into regions of interest , each consisting of several voxels. due to the limited number of nodes, such analyses are computationally inexpensive and their results are comparatively easy to visualize and interpret. however, region-level nodes involve mixing fmri time series from the incorporated voxels, thus obliterating more detailed spatial information  <cit> . roi-based analyses are therefore highly dependent on the quality of the parcellation: if roi boundaries and actual functional boundaries are inconsistent, the results can be erroneous  <cit> . voxel-level analyses, in contrast, are not subject to these limitations, since the parcellation inherent to the original data is used for node definition  <cit> . consequently, voxel-level graphs provide a finer model of the brain’s functional network organization, since the original spatial resolution of the fmri data is preserved  <cit> .

because of the large number of nodes, the construction and analysis of voxel-level graphs can involve considerable computational efforts. in response, the computational burden has often been reduced by sacrificing spatial resolution  thus reducing the number of nodes in the graph  <cit> . while reduction of spatial resolution is undesirable in general , it can even render a study infeasible, e.g., when investigating very small brain structures or different regions that lie in close proximity to each other. efficient algorithms and implementations are therefore required in order to take full advantage of the data’s original spatial resolution  <cit> .

here, we propose a novel approach aiming to increase the computational efficiency of voxel-level graph construction by combining time series dichotomization, tetrachoric correlation estimation, and efficient implementation, while retaining the full spatial resolution of the data. comparison with conventional graph construction  shows that the new approach not only produces highly similar results, but also executes an order of magnitude faster.

methods
this section consists of three parts. we begin with a short introduction to voxel-level functional connectivity graphs and explain their construction from fmri data. in particular, it is established how time series dichotomization can be combined with tetrachoric correlation estimation to efficiently measure functional connectivity. the second part describes analyses comparing pearson’s r and the tetrachoric correlation coefficient r
t
  as correlation estimators in the controllable environment of synthetic data,  as measures of functional connectivity in the context of graph construction from fmri data, and  with respect to the similarity of graphs resulting from . the last part provides implementation details regarding the programs created for this study and assesses their computational performance.

voxel-level graph construction
formally, an undirected binary graph is defined as an ordered pair g
b
=, comprised of a set of nodes n and a set of pairwise internodal connections, or edges, e. individual edges are unordered pairs {i,j}, where i,j∈n. g
b
 can be represented by a binary adjacency matrix b|n|×|n|=, where b
i,j
∈{ <dig> }, i,j∈n, and b
i,j
= <dig> indicates that {i,j}∈e, i.e., that a connection between the two nodes i and j exists. in order to represent not only the presence or absence of connections but also their strength, a graph can be extended by assigning a weight to each edge.

in applications to fmri data, graph-based analyses rely on the derivation of a graphical representation of the brain’s functional network, which is then examined in terms of graph theory . voxel-level functional connectivity graphs are constructed based on individual voxels as nodes, that is, the set of nodes n is a collection of voxels. in the literature, n is often defined as all in-brain voxels, or all gray matter  voxels. functional connectivity is estimated between all pairs of nodes based on their corresponding time series using a measure of association.

to construct a binary graph, edges are established by thresholding the functional connectivity estimates: two nodes are connected by an edge if their functional connectivity exceeds a given threshold. alternatively, one can take the pairwise functional connectivity matrix as a basis for a weighted graph, thus conserving the strength of individual functional connections between nodes  <cit> . for simplicity, and in a manner consistent with the majority of previous work on voxel-level functional connectivity graphs, we presently focus on binary graphs for our analysis.

measuring functional connectivity
in most previous studies investigating voxel-level functional connectivity graphs, internodal functional connectivity is measured using pearson’s sample correlation coefficient r <cit> . when using pearson correlation as a measure of functional connectivity, it seems sensible to assume bivariate normality with respect to the distribution of pairwise observations arising from each pair of voxel time series. this is because pearson correlation may be a poor measure of association if the data are not normally distributed  <cit> . encouragingly, in a recent study employing region-level graphs, data for the most part appeared to meet the assumption of bivariate normality  <cit> .

assuming bivariate normality between pairs of voxels, an alternative correlation estimator, the tetrachoric correlation coefficient r
t
 <cit> , can be used instead of r. given two dichotomous variables x
d
 and y
d
, r
t
 estimates the correlation of the latent continuous-valued variables x
c
 and y
c
 associated with x
d
 and y
d
, under the assumption that x
c
 and y
c
 follow a bivariate normal distribution. thus, if we dichotomize, i.e., binarize, the voxel time series data, r
t
 can be used to estimate the pairwise correlation of the original continuous-valued time series from the dichotomized ones.

consider two voxels, v and w, and their corresponding time series, 
s

v
 and 
s

w
. using the medians of 
s

v
 and 
s

w
, i.e., s~v and s~w, as dichotomization thresholds, we obtain the binary time series 
d

v
 and 
d

w
. formally, d
v,k
= <dig> if the signal intensity value s
v,k
 amounts at least to s~v and d
v,k
= <dig> otherwise, where k∈{ <dig> …,t} and t is the number of acquired fmri volumes  <cit> . see section s. <dig> for details.

by virtue of s~v and s~w, the pairs  are divided into four partitions corresponding to four quadrants in the x-y-plane of a cartesian coordinate system . thus, by counting the number of points falling into each quadrant, a pair of voxels gives rise to a 2× <dig> contingency table, the  frequencies of which can be expressed in terms of 
d

v
 and 
d

w
. for example, n <dig>  the frequency of points in time where s
v,k
 and s
w,k
 amount at least to s~v and s~w, respectively, is given by n11=∑k=1tdv,k·dw,k. in other words, n <dig> is the number of points where both 
d

v
 and 
d

w
 are equal to  <dig>  yielding the associated relative frequency p <dig> through p11=n11t.

the probability masses corresponding to the table’s relative frequencies are equal to the respective partial volumes belonging to the four quadrants in the x-y-plane under the curve representing the bivariate normal distribution . the correlation coefficient r
t
, for which these partial volumes resemble the relative frequencies in a given table, is an estimate of the population correlation ρ belonging to the underlying distribution. since a 2× <dig> contingency table is uniquely defined by the marginal probabilities and one joint probability, r
t
 can be found by solving, e.g., p11=∫Φ−1∞∫Φ−1∞fdzxdzy, where Φ is the standard normal distribution function, Φ− <dig> is its inverse, and f is the probability density function of the bivariate normal distribution. while this would typically be solved using numerical techniques, an analytical solution, r
t
=− cos, exists for the case under consideration . see section s. <dig> for details.

given a pair of voxels, we can determine p <dig> from the dichotomized time series and use the relationship r
t
=− cos in order to obtain r
t
. as a consequence, r
t
 can be used instead of r to estimate pairwise functional connectivity in the process of graph construction from fmri data .

simulations
building upon the theoretical considerations presented above, we analyzed the characteristics of r
t
 in the controllable environment of synthetic data. more specifically, we assessed its usefulness relative to r in estimating the correlation parameter ρ of bivariate normal populations of known properties.

data
bivariate normal populations were generated, such that each of them exhibited a predefined population correlation ρ, where ρ∈{− <dig> ,− <dig> ,…,  <dig> …, <dig> , <dig> }. then,  <dig> bivariate samples of size t  were randomly drawn from each of the populations. for each sample, r and r
t
 were calculated. prior to calculating the latter, the data were dichotomized as described above. the entire procedure was conducted separately for two different sample sizes, t= <dig> and t= <dig>  resulting in two data sets, where the choice of these numbers was guided by the parameters of the real fmri data we analyzed.

correlation estimation
for each data set and estimator ρ^∈{r,rt}, joint histograms  with associated marginal histograms were calculated. for the joint histograms a linearly spaced 199× <dig> grid was used, such that bin centers in both dimensions corresponded to correlations exhibited by the generated bivariate populations. for each estimator, means and standard deviations, as well as mean signed differences msd were calculated per ρ-bin. mean signed differences are defined as msd=n−1∑in, where n is the number of samples per ρ-bin, i.e., n= <dig>  and ρ^i is the correlation estimate for sample i. since ρ is not known in the case of real data, additional joint histograms  were calculated in order to facilitate comparability with respect to real data applications. as both estimators exhibit errors with respect to ρ, deming regressiona was used in order to fit a linear relationship to the  data.

application to fmri data
comparative graph-based analyses of resting-state fmri data were carried out based on r vs. r
t
 as measures of functional connectivity.

data
mri data were obtained from the “ <dig> functional connectomes project” repository  <cit> : we used the “cambridge” and “pittsburgh” data sets, contributed by r.l. buckner and g. siegle, respectively. these data sets contain resting-state fmri data from  <dig> subjects  and  <dig> subjects , respectively. both data sets also include anatomical scans for each subject.

preprocessing
using spm <dig>  <cit>  functional data were motion-corrected by alignment to the mean functional image, then anatomical scans were coregistered to the mean functional image and segmented. in order to account for low frequency intensity drifts and high frequency noise, frequencies below  <dig> hz and above  <dig> hz were removed from the voxels time series by band-pass filtering, as is customary for resting-state data  <cit> . in order to minimize the impact of preprocessing on the data’s correlation structure, we refrained from spatial smoothing and spatial normalization  <cit> .

correlation estimation
based on r and r
t
 as a measure of functional connectivity, two voxel-level graphs were constructed for each subject from the two data sets. nodes were defined as supra-threshold voxels in the subject-specific gm probability maps obtained from the segmentation . to measure internodal functional connectivity, two correlation matrices, c
r
 and crt, were calculated based on all pairwise correlations between nodes. c
r
 was obtained by calculating pearson correlations based on the voxels’ associated continuous-valued time series from the preprocessed fmri data, and crt was obtained analogously, except that tetrachoric correlations were calculated instead of pearson correlations, and binary voxel time series were used instead of continuous-valued ones. again, binary voxel time series were derived from the continuous-valued ones through median-based dichotomization. in order to compare c
r
 and crt, their entries were used to calculate joint histograms  in the same fashion as for the synthetic data.

functional connectivity graphs
subject-specific binary functional connectivity graphs, b
r
 and brt, were derived from c
r
 and crt, respectively, via density-based thresholding: the density κ of a binary undirected graph b is the proportion of potential edges that actually exist, i.e., κ=2·|e||n|·. in order to facilitate comparability across graphs, an individual correlation threshold θ was determined for each correlation matrix, such that the resulting binary graphs exhibited the same density κ. given c, where c∈{cr,crt}, and θ, the entries of b are given by b
i,j
= <dig>  if c
i,j
>θ, and b
i,j
= <dig> otherwise, where 1≤i,j≤|n|.

node degree maps
in graph-based fmri functional connectivity analyses, one of the most popular graph-theoretical metrics is the node degree, or degree centrality, a measure aiming to characterize the importance of individual nodes in a binary graph. given a binary graph b, the degree k
i
 of a node i is defined as the number of nodes that are connected to i via an edge, or, more formally, ki=∑j|n|bi,j, where i,j∈n and i≠j <cit> . the node degree has recently been employed in several neuroimaging studies aiming to identify potential hub regions in the human brain  <cit> .

here, node degrees k were calculated for all subject-specific functional connectivity graphs b
r
 and brt. degrees were standardized in order to afford comparable scaling across subjects  <cit> . the spatial distribution of degrees was analyzed by constructing k-maps in individual brain space for each subject. in order to generate group average k-maps for each data set , the subject-specific k-maps were spatially normalized to icbmb -template space based on transformation parameters estimated with respect to the mean functional image using spm <dig>  <cit> . since the normalized k-maps have different overlaps due to anatomical differences and differing gm masks, a varying number of subjects "supports" each standard space voxel. thus, group-level k-maps were derived by voxel-wise averaging of the k-values from the supporting subjects. for enhanced reliability, k-values of voxels supported by less than 20% of all subjects were discarded.

implementations
the most time-consuming step when constructing a graph from fmri data consists in the computation of a functional connectivity matrix, which here corresponds to the computation of a correlation matrix based on r or r
t
. in the following, the programs created for calculating the voxel-level pairwise correlation matrices c
r
 and crt will be referred to by pcc and tetracc, respectively. for both programs we opted to store only the upper triangular part of c, in order to save memory. in doing so, no information is lost, since c is symmetric. because efficient implementation plays an important role when aiming to accelerate large-scale analyses, implementation was conducted using the c programming language, providing matlab integration via its c interface mex. a matlab toolbox and c sources are available for download  <cit> .

calculation of c
r

pearson’s sample correlation coefficient r is calculated for a pair of voxels v and w using 

 r=∑k=1t∑k=1t2·∑k=1t <dig>  

 to avoid redundant operations, subexpressions depending on one voxel only are precalculated for all voxels before computing c
r
.

in order to take advantage of the processor’s cache without the need for explicit knowledge about its size, we adopted a so-called cache-oblivious algorithm <cit>  to compute the correlation matrix, rather than explicit blocking . the core idea is to recursively divide the problem so that the computations are carried out on smaller and smaller blocks of data. given that the minimum block size is small enough, there is a division step from which on all computations use only data that fits into the processor cache , thus making optimal use of the cache by localizing the computations. the division scheme we implemented is illustrated in additional file 1: figure s <dig>  which shows the first three steps of dividing the upper triangle of the correlation matrix.

in addition, we exploited sse <dig>  and avx  instructions , which allow for parallelization on a single core by carrying out the same operation on multiple data elements in parallel . using sse <dig> , the computation of the numerator of the correlation coefficient can be parallelized by computing four  sums in parallel . the procedure is illustrated in additional file 1: figure s <dig> for sse <dig> using float or avx using double .

calculation of
crt
for each pair of voxels, r
t
 is computed in three steps. first, the bitwise and operator is applied to the voxels’ associated binary time series. second, the set bits in the result are counted to obtain n <dig>  third, r
t
 is retrieved from a lookup table of the function r
t
=− cos. the table is indexed by n <dig> and contains the corresponding r
t
 values for those values that n <dig> can attain. depending on t being even or odd, these are  <dig> , <dig> …,t <dig> or  <dig> , <dig> …,t+ <dig>  respectively.

storing the binary time series in integers of, e.g.,  <dig> bit,  <dig> points in time can be processed in parallel, so that the above three steps need to be executed only ⌈t/32⌉ times per pair. hence, it seems conceivable that the computational cost in terms of cpu time could be lower for the calculation of crt than for the calculation of c
r
.

following the procedure outlined above, two programs, tetracc/ <dig> and tetracc/ <dig> were created. tetracc/ <dig> uses  <dig> bit integers for storing binary time series and a  <dig> bit lookup table for bit-counting. tetracc/ <dig> uses __mm128i variables  for time series storage. using the intrinsics _mm_and_si <dig> and _mm_popcnt_u <dig> for bitwise and and bit-counting, respectively, it is expected to improve over tetracc/ <dig>  since more data can be processed in parallel and no extra memory access  is needed. while tetracc/ <dig> is platform-independent, tetracc/ <dig> is only applicable on fairly modern cpus, because _mm_and_si <dig> and _mm_popcnt_u <dig> depend on the availability of sse <dig> and popcnt instructions, respectivelyd.

parallel versions
for additional performance gains, parallel versions of pcc and tetracc have been implemented using multiple threads. this aspect is, however, beyond the focus of this article, since the resulting benefits relative to single-threaded programs are expected to be fairly independent of the choice of r versus r
t
 as a measure of internodal functional connectivity.

performance tests
in order to assess the performance of the programs described above, we compared them to three other programs: matlab’s built-in function corrcoef, corr from matlab’s statistics toolbox, and ipn_fastcorr, a function from the matlab toolbox ipnvoxelgraph by x.n. zuo. experiments were conducted from within matlab  on a desktop computer with an intel core i7-3960x cpu  and 64gb main memory running linux . the c/mex routines that are part of our programs were compiled using the gnu c compiler gcc . in order to prevent programs from making use of multiple cores, matlab was restricted to one cpu core.

input data sets  were generated using pseudo-random numbers of type float. while the length of time series t was fixed at t= <dig>  the number of voxels v was varied between  <dig> and  <dig> in steps of  <dig>  the maximum number of voxels,  <dig>  follows from the fact that storing the resulting matrix  requires  <dig>  gb 2floats,  <dig> bytes per float). since the machine used has 64gb of main memory, this seemed a sensible choice in order to leave some memory for other applications and subsequent processing of the matrix. because corrcoef, corr, and ipn_fastcorr return the complete symmetric matrix, they were only tested using input data sets with up to  <dig> voxels corresponding to  <dig>  gb of memory required to hold the matrix .

RESULTS
correlation estimation
overall, the correlation estimation from dichotomized data using r
t
 yielded results strongly resembling those obtained through estimation from continuous data using r. for synthetic data, as expected, r and r
t
 exhibited linear relationships to ρ and also to each other . standard deviations  were greater for r
t
 than for r, but were reasonably small for both. peaking at ρ= <dig> with  <dig>  and  <dig>  , and  <dig>  and  <dig>  , for t= <dig> and t= <dig>  respectively, they exhibited a gradual decrease towards the range limits of ρ. naturally, deviations from ρ were larger for t= <dig> than for t= <dig>  because for t= <dig> each calculated correlation is based on fewer values than for t= <dig>  close inspection of the mean signed differences msd and msd revealed a small systematic bias of both r and r
t
 as estimators of ρ . the expected value of r, e, can be approximated by e=ρ−ρ <cit> . e−ρ closely matched the empirical results from the simulation represented by msd, while msd follows a curve of similar shape but larger amplitude. the pearson correlation between r and ρ, r
t
 and ρ, and r
t
 and r, amounted to  <dig>  ,  <dig>  ,  <dig>  , respectively, for t= <dig> .

for fmri data, r
t
 and r followed a linear relationship in both data sets, although there was a slight counterclockwise rotation about the origin as reflected in a slope > <dig> as opposed to  <dig> for a perfect relation r
t
=r . this suggests only limited deviation from the assumption of pairwise bivariate normality, and, moreover, indicates that r
t
-based graphs closely resemble r-based graphs. furthermore, the results for the cambridge data set  showed a greater variance than those for the pittsburgh data set . since this feature was also observed in the results for the synthetic data sets, we presume that this was caused by the smaller sample size for the calculation of each sample correlation. the overall correlation between r and r
t
 amounted to  <dig>   and  <dig>  .

note that the vertical gaps in bin occupation in those histograms involving r
t
 are due to the fact that r
t
 can attain a distinct set of values only, as explained earlier. the number of attainable values, and hence the  performance of r
t
 as an estimator, increases with t.

node degree
group average node degree maps from r- and r
t
-based binary graphs b
r
 and brt  are presented in figure  <dig>  other thresholds  led to similar results and are hence not shown. in accordance with the strong correlation between r and r
t
 reported in the previous section, both approaches yielded highly similar spatially distributed node degree maps . in line with this, k
r
 and krt were very strongly correlated = <dig>  for cambridge and r= <dig>  for pittsburgh; figure 4b), although degrees tended to be slightly higher for r
t
-based than for r-based graphs. prominent clusters of high-degree nodes were found within circumscribed regions of the occipital , parietal , temporal  and frontal lobes  with a similar distribution pattern as reported in previous work employing r-based node degree mapping  <cit> .

performance tests
the most time-consuming step when constructing a graph from fmri data consists in the computation of a functional connectivity matrix. we compared the performance of our programs on this task to three other programs: matlab’s built-in function corrcoef, corr from matlab’s statistics toolbox, and ipn_fastcorr, a function from the matlab toolbox ipnvoxelgraph by x.n. zuo. table  <dig> shows memory requirements, execution times, and speedups relative to corrcoef which was selected as reference since it is available to any matlab user out of the box and we therefore assume that it has a higher prevalence than corr or ipn_fastcorr. figure  <dig> illustrates the performance in terms of data troughput measured in correlation coefficients per second. this measure does not depend on the performance of a reference program and offers more immediate access to the key results. in this sense, it is complementary to table  <dig> 

|
n
|/10
3
m
t
t
s
[
×
t
s
[
×
m
t
s
[
×
t
s
[
×
t
s
[
×
t
s
[
×
t
s
[
×
results are averages from  <dig> runs on a desktop computer with an intel core i7-3960x cpu  and 64gb main memory. all programs were restricted to one cpu core. length of time series t was fixed at t= <dig>  |n|: number of nodes. the programs corrcoef , corr , ipn_fastcorr , and pcc  computed c
r
, while tetracc  computed crt. m : memory requirements for result in gb; t : elapsed time in seconds; s : speedup relative to corrcoef.

in line with expectations, execution times increased quadratically with the number of nodes for all programs . while pcc’s basic variant  was considerably slower than corrcoef , its sse2- and avx-based variants achieved speedups around  <dig> × and  <dig> ×, respectively. the performance of corr  was comparable to that of pcc/sse <dig>  while ipn_fastcorr  ranked between pcc/sse <dig> and pcc/avx. the tetracc variants  were considerably faster than all programs computing r with speedups  around  <dig> × and  <dig> ×, respectively.

as an aside, we note that ipn_fastcorr as well as pcc and tetracc scaled better with the number of cores than corrcoef and corr. for example, using  <dig> cores and a data set of  <dig> nodes , the speedups were  <dig> × ,  <dig> × ,  <dig> × ,  <dig> × ,  <dig> × , and  <dig> × , compared to corrcoef’s execution time of  <dig>  seconds. using the same data set but only  <dig> core the respective speedups were  <dig> ×,  <dig> ×,  <dig> ×,  <dig> ×,  <dig> ×, and  <dig> × as compared to corrcoef’s execution time of  <dig>  seconds . thus, the speedup gained by using  <dig> cores instead of  <dig> amounts to  <dig> × ,  <dig> × ,  <dig> × ,  <dig> × , and  <dig> × , while corr and corrcoef gain only  <dig> × and 3×, respectively.

note that pcc and tetracc require only half the amount of memory  that corrcoef, corr, and ipn_fastcorr require , because they store only half of the symmetric matrix for memory efficiency . in addition, corrcoef, corr, and ipn_fastcorr failed with an out-of-memory error for input data sets with  <dig> or more nodes. we assume that these programs internally use more memory than we expected, since the resulting matrix of correlation coefficients would require less than half of the available memory . hence, the speedups of the remaining programs compared to corrcoef could not be computed for t≥ <dig> 

discussion
graph-based functional connectivity analysis at the level of individual voxels allows for spatially fine-grained characterization of functional networks in the human brain. however, with high-resolution data sets, such analyses can become infeasible due to the computational demands involved. most previous studies investigating voxel-level functional connectivity graphs relied on pearson’s r for estimating internodal functional connectivity  <cit> . as demonstrated here, the tetrachoric correlation coefficient r
t
 constitutes a time-efficient alternative to r as a measure of functional connectivity.

in order to reduce the computational costs associated with the analysis of voxel-level graphs, previous studies reduced the data’s spatial resolution  <cit> , spatially restricted the graphical edges incorporated into the analysis  <cit> , or utilized parallel computing  <cit> . in contrast, efficiency benefits from r
t
-based graph construction are achieved without sacrificing spatial resolution, disregarding graphical edges, or exploiting parallel computing. an open source software package containing the created programs is freely available for download  <cit> . note that parallel versions of r- and r
t
-based graph construction have been implemented in addition to the sequential ones, thus providing additional efficiency gains that depend on the number of available processors. while this aspect is not the main focus of this article, as the resulting benefits  can be expected to be fairly independent of the choice of r versus r
t
 as a measure of internodal functional connectivity, the parallel implementations are still included in the software package  <cit> .

even though the dichotomization procedure  entails discarding information in the time domain, important characteristics of the original data appear to be preserved. in applications to artificially generated as well as real fmri data the new technique proved capable of closely reproducing results obtained in conventional ways. more specifically, the usefulness of the r
t
-based approach was assessed by comparison with r in estimating the correlation parameter ρ of bivariate normal populations of known properties. in this setting, both the bias and standard deviation were greater for r
t
 than for r, but still reasonably small. thus, r
t
-based correlation estimation yielded results closely resembling those obtained when using r. beyond that, r- and r
t
-based graph construction and node degree computation were carried out for real fmri data. a strong linear relationship was found between r- and r
t
-based correlations indicating that r
t
-based graphs closely resemble r-based graphs, since the graphs are derived from the correlation matrices. in line with this, the spatial distribution of node degrees was highly similar for r- and r
t
-based graphs and also in good correspondence with previous work  <cit> .

as data mining approaches are currently gaining momentum in the neuroimaging community  <cit> , the amount of publicly available experimental data is steadily growing. consequently, development and implementation of efficient exploratory methods, such as the one presented here, are necessary in order to take full advantage of this wealth of data, especially with respect to connectivity analyses  <cit> . fast construction and subsequent analysis of graphs may thus open new avenues for applications, including those within a clinical setting, where the voxel-level approach may be of particular importance. it is worth noting in this context that voxel-level graph construction can operate at the original data resolution, thus avoiding the reduction of the analysis’ spatial sensitivity  <cit> . for example, disease-related patterns, once identified, may serve as connectivity-based biomarkers that could aid, guide, or facilitate diagnostics and may increase prediction accuracy with respect to disease occurrence, recurrence, severity, or treatment outcome. here, again, efficient methods are essential to facilitate assessment of individual patients within a narrow time frame  <cit> . if combined with efficient tools for subsequent analysis, the presented methods for fast graph construction may also be useful for online evaluation of functional connectivity in the context of real-time fmri. this would allow for connectivity-based adaptation of experimental stimulation and interaction with the subject, for example, in task-based fmri studies, or neurofeedback-based training. taken together, we believe that there is a multitude of applications  that could benefit from the methods presented here, highlighting the growing importance of efficient tools for graph-based analysis of voxel-level connectivity.

limitations
as illustrated by the results, the accuracy of a correlation estimate naturally increases with the number of data points, i.e., the number of scans. along the same lines, it has recently been shown that the reliability of functional homogeneity increases with scan duration  <cit> . for both correlation estimators, it is therefore recommended to avoid a low number of scans . since the deviation from the population correlation ρ is generally higher for r
t
 than for r, a low number of scans will affect r
t
 more severely than r.

the main focus of this work lies with the comparison of r and r
t
 as functional connectivity estimators. to reduce the impact of preprocessing on the data’s correlation structure prior to this comparison, we limited the preprocessing of the fmri data to a minimum. the effect of additional preprocessing steps, or a different preprocessing pipeline altogether, on the robustness of the proposed methods should be subject of future research. unpublished results from our group indicate, however, that the comparability of r and r
t
 remains essentially consistent.

CONCLUSIONS
voxel-level graphs allow for spatially fine-grained analyses of functional connectivity networks. in order to reduce the considerable computational demands involved, many previous studies reduced the spatial resolution of the data. here, a new method for graph construction—exploiting time series dichotomization and tetrachoric correlation estimation—was devised, efficiently implemented, and compared to the conventional approach based on continuous-valued data and pearson’s r. in applications to artificially generated as well as real fmri data the new technique proved capable of producing highly similar results. through efficient bit-based implementation adapted to the dichotomized data the novel method runs an order of magnitude faster while the original spatial resolution of the data is retained. hence, its demonstrated performance, not only in producing consistent results, but in obtaining them substantially faster, makes the new approach a sensible and economical alternative to customary practice. an open source software package containing the created programs is freely available for download  <cit> .

endnotes
a deming regression is a linear regression method that accounts for errors in both variables.

b international consortium for brain mapping.

c sse <dig> was introduced by intel with the pentium  <dig>  it is also supported by amd cpus starting with the athlon  <dig>  avx is supported starting with the sandy bridge  and bulldozer  microarchitectures.

dpopcnt became available starting with the nehalem  and barcelona  microarchitectures.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
kl conceived of the study and carried out the data analyses with conceptual input from mg, cms, and cb. kl and cb created the software package and carried out the performance tests. kl drafted the manuscript. mg, cms, rk, and cb edited the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
supporting information.

click here for file

 acknowledgements
the authors would like to thank sarah donohue, joseph harris, martin von kurnatowski, christian moewes, and mircea ariel schoenfeld for their support.

this work was supported by deutsche forschungsgemeinschaft sfb  <dig>  and stsm grant  <dig> of cost action ic <dig> 
