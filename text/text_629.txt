BACKGROUND
the post-genomic revolution has ushered in an ensemble of novel crises and opportunities in rethinking molecular biology. the two principal directions in genomics, sequencing and transcriptome studies, have brought to light a number of new questions and forced the development of numerous computational and mathematical tools for their resolution. the sequencing of whole organisms, including homo sapiens, has shown that in fact there are roughly the same number of genes, for example, in mice and men. moreover, much of the coding regions of the chromosomes  are highly homologous. the complexity comes then, not from a larger number of parts, or more complex parts, but rather through the complexity of their interactions and interconnections.

coincident with this biological revolution – the massive and unprecedented volume of biological data – has blossomed a technological revolution with the popularization and resulting exponential growth of the computing networks. researchers studying the topology of the internet  <cit>  and the world wide web  <cit>  attempted to summarize these topologies via statistical quantities, primarily the distribution p over nodes of given connectivity or degree k, which was found to be completely unlike that of a "random" or erdös-rényi graph. instead, the distribution obeyed a power-law p~k-γ. as a consequence many mathematicians concentrated on  measuring the degree distributions of many technological, sociological, and biological graphs  and  proposing various models of randomly-generated graph topologies which could reproduce these degree distributions . the success of these latter efforts reveals a conundrum for mathematical modeling: a metric which is universal  cannot be used for choosing the model which best describes a network of interest. the question posed is one of classification, meaning the construction of an algorithm, based on training data from multiple classes, which can place data of interest within one of the classes with small test loss.

systematic enumeration of substructures has so far been used to find statistically significant subgraphs or "motifs"  <cit>  by comparing the network of interest to an assumed null model. recently, the idea of clustering real networks into groups based on similarity in their "significance profiles" has been proposed  <cit> . we here use and extend these ideas to compare a given network of interest to a set of proposed network models. rather than unsupervised clustering of real networks, we perform supervised classification of network models. in this paper, we present a natural mapping from a graph to an infinite-dimensional vector space using simple operations on the adjacency matrix. the coordinates  reflect the number of various substructures in the network . we then use support vector machines  to build classifiers that are able to discriminate different network models. the performance of these classifiers is measured using the empirical test-loss on a hold-out set, thus estimating the probability of misclassifying an unseen test network. we selected  <dig> different mechanisms proposed in the literature to model various properties of naturally occurring networks. among them are various biologically-inspired graph-generating algorithms which were put forward to model genetic or protein interaction networks. we are then able to classify naturally occurring networks into one of the proposed classes. we here classify data sets for the e. coli genetic network, the c. elegans neuronal network and the yeast s. cerevisiae protein interaction network. to interpret and understand our results further we define a measure of robustness to estimate the confidence of the resulting classification. moreover, we calculate p-values using gaussian kernel density estimation to find substructures that are characteristic of the network model or the real network of interest. we anticipate that this new approach will provide general tools of network analysis useful to a number of communities.

RESULTS
we apply our method to three different real data sets: the e. coli genetic network  <cit>  , the s. cerevisiae protein interaction network  <cit>  , and the c. elegans neuronal network  <cit>  .

each node in e. coli's genetic network represents an operon coding for a putative transcriptional factor. an edge exists from operon i to operon j if operon i directly regulates j by binding to its operator site. this gives a sparse adjacency matrix with a total of  <dig> nodes and  <dig> edges.

the s. cerevisiae protein interaction network has  <dig> nodes and  <dig> undirected edges. its sparseness is therefore comparable to that of e. coli's genetic network.

the c. elegans data set represents the organism's fully mapped neuronal network. here, each node is a neuron and each edge between two nodes represents a functional, directed connection between two neurons. the network consists of  <dig> neurons and  <dig> edges, and is therefore about  <dig> times more dense than the other two networks. we create training data for undirected or directed models according to the real data set. all parameters other than the numbers of nodes and edges are drawn from a uniform distribution over their range. we sample  <dig> examples per model for each real data set, train a pairwise multi-class svm on 4/ <dig> of the sampled data and test on the 1/ <dig> hold-out set. we determine a prediction by counting votes for the different classes. table  <dig> summarizes the main results. all three classifiers show very low test loss and two of them a very high robustness . the average number of support vectors is relatively small. indeed, some pairwise classifiers have as few as three support vectors and more than half of them have zero test loss. all of this suggests the existence of a small subset of words which can distinguish among most of these models.

the predicted models kumar  <cit> , middendorf-ziv   <cit> , and sole  <cit>  are based on very similar mechanisms of iterated duplication and mutation. the model by kumar et al. was originally meant to explain various properties of the www. it is based on a duplication mechanism, where at every iteration a prototype for the newly introduced node is chosen at random, and connected to the prototype's neighbors or other randomly chosen nodes with probability p. it is therefore built on an imperfect copying mechanism which can also be interpreted as duplication-mutation, often evoked when considering genetic and protein-interaction networks. sole is based on a similar idea, but is an undirected model, and allows for two free parameters, a probability controlling the number of edges copied and a probability controlling the number of random edges created. mz is essentially a directed version of sole. moreover, we observe that none of the biological networks were predicted to be generated by preferential attachment even though these networks exhibit power-law degree distributions. the duplication-mutation schemes arise as the most successful. however, it is interesting to note that every duplication-mutation model by construction gives rise to an effective preferential attachment  <cit> . our classification results therefore do not dismiss the idea of preferential attachment, but merely the specific model which directly implements this idea.

kumar and mz were classified with almost perfect robustness  against 500-dimensional  subspace sampling. with  <dig> different choices of subspaces, e. coli was always classified as kumar. we therefore assess with high confidence that kumar and mz come closest to modeling e. coli and c. elegans, respectively. in the case of sole and the s. cerevisiae protein network we observed fluctuations in the assignment to the best model.  <dig> out of  <dig> times s. cerevisiae was classified as vazquez , other times as barabasi , klemm , kim , or flammini  depending on the subset of words chosen. this clearly indicates that different features support different models. therefore the confidence in classifying s. cerevisiae to be sole is limited. the statistical significance of individual words in different models is investigated using kernel density estimation  by finding words which maximize ηij ≡ pi/pj for two different models  at a word value of the real data set x <dig>  figure  <dig> shows training data for two different models used to classify the c. elegans network: the mz model  <cit>  which wins in the classification results, and the runner-up grindrod model  <cit> . the histograms for the word nnz d are shown along with their estimated densities, nnz d extremely disfavors the winning model over its runner-up . the opposite case is shown in figure  <dig> for e. coli, where the plotted word distribution supports the winning model  and disfavors  the runner-up krapivsky-bianconi model  <cit>  . more specifically we are able to verify that the likelihood to generate a network with e. coli's word values is highest for the kumar model for most of the words. indeed, out of  <dig> words taking at least  <dig> integer values for all of the models, the estimated density at the e. coli word value was highest for kumar in  <dig> cases, for krapivsky-bianconi  <cit>  in  <dig> cases and for krapivsky  <cit>  in only  <dig> cases.

the svm results suggest that one may only need a small subset of words to separate most of the models. the simplest approach to find such a subset is to look at every word for a given pair of models and compute the best split, then rank words by lowest loss. we find that among the most discriminative words some occur very often, such as, nnz  or nnz , which count the pairs of edges attached to the same vertex and either pointing in the same direction or pointing away from each other, respectively. other frequent words include nnz d, nnz d and Σu. figures  <dig> and  <dig> show scatter-plots of the training data using the most discriminative three words.

CONCLUSIONS
we proposed a method to discriminate different network topologies, and we showed how to us the resulting classifier to assess which model out of a set of given network models best describes a network of interest. moreover, the systematic enumeration of countably infinite features of graphs can be successfully used to find new metrics which are highly efficient in separating various kinds of models. our method is a first step towards systematizing network models and assessing their predictability, and we anticipate its usefulness for a number of communities.

