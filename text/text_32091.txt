BACKGROUND
recent advances in microscopy, fluorescent tagging and automated image analysis have led to the development of high-throughput methods for monitoring gene expression at single-cell resolution over time  <cit> .

we focus in this work on a particular protocol for tracking the expression of individual c. elegans genes during embryonic development. briefly, the protocol works as follows. first, histones are genetically tagged with green fluorescent protein . during development, a stack of confocal microscopy images of the embryo is taken every 50- <dig> seconds. each stack contains 31- <dig> image planes with a spatial resolution of  <dig> micron. a sample image stack is shown in figure  <dig>  where the z-axis is coded using a red-green-blue color scale . in this figure, nuclei of nondividing cells are spherical, and nuclei of dividing cells have elongated shapes. typically, the diameter of a cell nucleus is from 3- <dig> microns; therefore, each nucleus is represented in 4- <dig> image planes. a typical image series might track development over 150- <dig> time points until the embryo consists of  <dig> cells. with  <dig> images per time point, such a series consists of 5000- <dig> images. these images show approximately  <dig> cell divisions and  <dig>  nuclei at different time points. if we continue to the  <dig> cell stage, then the series contains 180- <dig> time points, approximately  <dig> cell divisions and  <dig>  nuclei. in addition to tagging all nuclei using a ubiquitously expressed histone, the protocol can be extended to trace the expression of individual genes. in figure  <dig>  a histone is tagged with gfp, and a second histone is tagged with rfp, where the rfp histone's expression is driven by the promoter associated with the gene pha- <dig>  hence, the pattern of red nuclei shows in which cells the pha- <dig> promoter is active.

once the image samples are collected, the primary analysis task is to identify individual nuclei and to trace the lineage of the individual cells. because the lineage is highly stereotyped, this task amounts to mapping the observed data onto a lineage tree with fixed topology and variable branch lengths. such a tree is shown in figure  <dig> for a two-channel experiment, where the lineage is colored according to whether the monitored gene is expressed along a given lineage. the software tool starrynite was developed specifically to solve this cell lineaging task  <cit> . starrynite can trace a 350-cell stage image series in approximately  <dig> minutes on a desktop computer. however, annotation with starrynite must typically be followed by a manual curation step, because the automatic annotation contains errors. this curation generally takes approximately two hours to edit a lineage up to the 194-cell stage and four hours to the 350-cell stage  <cit> . in this work, our goal is to use machine learning methods to reduce this manual annotation time. using a collection of manual annotations, we systematically analyze the types of errors made by starrynite. for the most common type of error, we then design a collection of features that encode relevant information about the source of the errors. finally, we use these features, in conjunction with labels derived from manual annotation, to train a support vector machine  classifier to identify starrynite errors with high accuracy. the resulting classifier significantly speeds up the time required to manually curate expression image series. the classifier is built into the latest version of starrynite http://starrynite.sourceforge.net.

RESULTS
analyzing starrynite errors
initially, we investigated the types of errors produced by starrynite, with the goal of focusing our analyses on the most common errors. to this end, we grouped starrynite errors into five categories:  false positives,  false negatives,  positioning errors,  incorrect diameter estimation and  tracing errors. a false positive occurs when starrynite mistakenly detects a nucleus, which in fact is non-existent. conversely, false negatives are nuclei that starrynite fails to identify. positioning errors occur when starrynite makes mistakes in finding the coordinates of the centroid of the nucleus. incorrect size estimation happens when the inferred diameter of a nucleus differs from the true value. tracing errors include cases where a nucleus at a particular time point is not matched to the right nucleus  in the next time point. for each nucleus, there can be three possible matches: one to one, one to two, or one to none, corresponding to movement, cell division , and cell death  <cit> . a moving nucleus simply changes its location from one time point to the next. a dividing nucleus splits into two children nuclei in the next time point. finally, a cell death corresponds to the case where a cell disappears. once the embryo finishes its development it starts to crawl away from the imaging foci. hence, in the final stages of development, some cells will start to disappear from the image data and some will still be present. note that all of these errors are subjectively defined, ultimately, by visual inspection by a human expert. hence, there is no hard and fast rule for, for example, how far off the centroid must be in order to qualify as a positioning error.

we collected statistics for each error type on a single benchmark series , which contains image data up to the  <dig> cell stage. this series contains a total of  <dig>  nuclei annotations by starrynite and  <dig>  annotations in the manually edited version. the results, summarized in figure  <dig>  suggest that false negatives are the most common error types, followed by tracing errors, dislocations, incorrect diameter estimations and false positives. although false negatives are the most commonly observed errors, we chose to concentrate on the second most common error type, tracing errors. we made this choice for two reasons. first, tracing errors are directly amenable to correction by a simple classifier, which can be applied systematically to all division calls made by starrynite. in contrast, a classifier that attempts to correct false negative annotations would have to be applied to all empty regions of all image stacks. second, tracing errors have a more complex morphology than simple false negative annotations, allowing us to use a rich set of features, as described below.

tracing errors can be further subdivided into eight categories:  division annotated as movement,  movement annotated as division,  division annotated as cell death,  movement annotated as cell death,  cell death annotated as division,  cell death annotated as movement,  indexing errors of moving nuclei and  indexing errors of dividing nuclei. an indexing error of a moving nucleus occurs when a moving nucleus at a particular time point is linked to the wrong nucleus at the next time point. similarly, an indexing error of dividing nuclei occurs when the indices of the newborn children are incorrectly assigned. figure  <dig> shows that "movement annotated as division" is the most frequent type of tracing error:  <dig> % of the tracing errors in series  <dig> are of this type. indeed, this series contains a total of  <dig> division calls, and  <dig>  of those were in fact movements. in addition to being the most frequent tracing error type, movements detected as divisions are biologically important as well. figure  <dig> illustrates one such error. in the figure, a moving nucleus at a particular time point t is encapsulated by a white square box. for simplicity, the figure shows only a single image slice, corresponding to a fixed z-value. alternatively, figures  <dig> and  <dig> contain 3d image representations of all the nuclei present at t and t +  <dig>  respectively, where t =  <dig> in this example. according to the human annotator, m <dig> and m <dig> move from t =  <dig> to t =  <dig> and p <dig> at t =  <dig> divides into c <dig> and c <dig> at t =  <dig>  however, starrynite annotates m <dig> at t =  <dig> as the parent nucleus and links it to m <dig> and c <dig> at t =  <dig>  which are incorrectly annotated as the children of m <dig>  thus, in this example a moving nucleus  is annotated as dividing, causing a deviation from the true topology of the lineage tree. based on these analyses, we decided to focus our initial efforts on the automatic recognition of movements detected as divisions.

feature design
often, success in machine learning depends critically upon the ability of the researcher to successfully incorporate into the learning framework significant prior knowledge about the problem domain. such prior knowledge can be represented, for example, using a formal, probabilistic prior or, for kernel methods, by selecting an appropriate similarity function. however, perhaps the most straightforward way to encode prior knowledge is by designing feature extraction routines that are tailored to the task and the data. in our case, we examined the "movement annotated as division" tracing errors in several of our image series and, on that basis, designed a collection of  <dig> features that provide a rich view of the types of errors produced by starrynite. the  <dig> features are summarized in table  <dig> and explained below.

time index
the time index denotes how much time has elapsed since the start of embryonic development. the relationship between developmental age and time index depends, of course, on the time resolution of the experiment. in general, starrynight makes more errors, on a per-nucleus basis, at later time points, simply because the images at later time points contain more nuclei and are hence more crowded.

age
a cell needs to mature to a certain age before dividing into two nuclei. therefore, by including age information we aim to eliminate incorrect division annotations that correspond to divisions of very young cells or lead to very long-lived cells. we compute ages of the parent nucleus as well as the two children nuclei, as described in methods.

diameter
we obtain the diameter, in pixels, of the parent and the two children nuclei directly from starrynite's annotation. we expect the diameters of the children to be similar to one another and smaller than the diameter of the parent.

distance
we include  <dig> distance features that capture the spatial relationships among the parent, the parent's neighbors and the two children.

normalized nucleus support
during mitosis, a cell typically elongates in one direction, deviating from its usual spherical shape. to enable discriminating between dividing and non-dividing nuclei, we introduce a feature called normalized nucleus support that quantifies how spherical the nucleus is. details are provided in methods.

angle
during mitotic division, the two children typically move in opposite directions. to capture these directional changes, we define a set of five angle features, as described in methods.

gfp signal
similar to the diameter features, we expect the gfp signals of the two children to be similar to each other and less than the gfp of the parent. to capture this information, we include six gfp features: the gfp signals of the the parent at t -  <dig>  the parent at t, children at t +  <dig> and children at t +  <dig> 

number of nuclei at a given time
this feature allows the learner to exploit the correlation between the number of nuclei at a given time point and the probability of error. when an image stack contains many cells, the nuclei are packed more tightly together and more likely to experience collisions that affect the direction of moving nuclei. accordingly, we observed that starrynite makes more errors when the number of nuclei is high.

coordinates
we included the x-y-z coordinates for the centroids of the parent as well as the two children . with this set of features, we allow the learner to identify a tendency for starrynite to make more errors at particular locations.

preliminary feature analysis
prior to performing any machine learning, we measured the discriminative power of each feature individually. the goal of this analysis is two-fold: to identify features that are not individually informative, and to provide a performance baseline against which to compare our machine learning results. using a development data set consisting of  <dig> experimental series , we ranked all of the division calls according to each of the  <dig> features. each such ranking induces a receiver operating characteristic  curve, which plots the true positive rate as a function of false positive rate as we traverse the ranked list. we use the area under the curve  as a performance metric to rank features. figure  <dig> shows the roc curves for the top five features, according to this metric, and figure  <dig> illustrates sorted auc values across  <dig> features . in figure  <dig>  the features are sorted by their auc values.  <dig> features along with their auc scores are listed in additional file 1: features_and_aucs.xls.

this roc analysis leads to several observations. first, some of the normalized nucleus supports  are zero for all examples in the dataset we used, suggesting that all the nuclei we evaluated are smaller in size than expected. these non-informative features were eliminated from all subsequent analyses. second, the best feature is "distance from parent to child-1" with an auc of  <dig> . this provides a baseline against which to compare our trained classifier.

in general, the single-feature rankings are consistent with our biological expectations. for instance, correct divisions have a higher average distance between parent and child- <dig> than incorrect divisions, because we expect a certain amount of separation between parent and children. when a child candidate is too close to a candidate parent, then starrynite is more likely to make an incorrect division call linking those close cells. furthermore, in mitosis we expect the children to move rapidly from each other, resulting in a certain amount of separation between them. this separation is related to the second best feature. we expect the children to move in opposite directions from each other, which can be captured by the third best feauture. we expect the age of a newborn child to be larger than the time it takes a regular moving cell to divide starting from the current time point. this information is represented in the fourth best feature. finally, we expect a distance relation between a parent and its neighbors, as we observed in the fifth best feature, because if they are close to each other starrynite is more likely to get confused about choosing the right parent and labeling a moving nucleus as a dividing one.

initial testing of an svm classifier
we performed a 10-fold cross-validation experiment on the development data set. at each cross-validation iteration, we chose one experimental series as the test set and used the remaining series as the training data. then we learned the optimal parameters and hyperparameters of the svm classifier by performing internal cross-validation on the training set , and we classified each division call in the test set as correct  or incorrect .

at the threshold selected by the svm, we achieve an accuracy of  <dig> %, which represents a  <dig> % improvement over starrynite . several additional performance metrics are detailed in table  <dig>  by definition, starrynite has 100% sensitivity, since we only consider division calls made by starrynite. on the other hand, our method is  <dig> % better than starrynite in terms of the precision rate  although it annotates some of the true division calls made by starrynite as errors. we should note that, for guiding manual reannotation, it is better to identify more errors to speed up the editing process even if some of the movement annotations made by the svm are in fact divisions that are correctly captured by starrynite. such incorrect annotations of our method can still be corrected by the human expert, reducing the overall effort that needs to be spent for the editing phase. figure  <dig> shows the roc curve achieved by the svm, with a point indicating the selected decision threshold. for comparison, we also include the roc curve produced by the best-performing single feature. the auc score of the svm classifer is  <dig> , which is better than the auc score of the best feature . these results show that the svm classifier is capable of identifying this particular class of starrynite errors with high accuracy.

sensitivity/recall is defined as tp/ and positive predictive value /precision is computed as tp/

feature selection
having established a baseline accuracy in the previous experiment, we next explored the possibility of achieving improved performance by eliminating uninformative or redundant features from the classifier. we performed two such experiments, both of which suggest that feature selection for this particular task is not necessary.

in the first feature selection experiment, we adopt a simple filter, based on the per-feature aucs shown in figure  <dig>  figure  <dig> shows the result of a series of tests conducted with smaller and smaller feature sets. in each step, we eliminated one feature with the lowest auc. we then performed the same cross-validation experiment described in the previous section, including internal cross-validation to select hyperparameters. for each cross-validation split, we compare the accuracy of the reduced-feature svm with the accuracy of the baseline svm that uses all  <dig> features. the figure shows that, although some reduced feature sets yield a slight improvement in accuracy--e.g., eliminating the worst  <dig> features gives an improvement of  <dig> % --the mean is always less than one standard deviation from zero. this result suggests that this simple feature selection strategy does not significantly improve the performance of the classifier.

in the second feature selection experiment, we considered the joint effect of groups of related features. in this analysis, we used the nine feature groups introduced in the "feature design" section. rather than considering all  <dig> -  <dig> =  <dig> possible combinations of groups, we considered  <dig> possibilities: each one of the nine feature groups alone, and all combinations of eight feature groups. as before, we performed a cross-validation experiment on each reduced feature set and then compared the accuracy of the reduced-feature classifier to the accuracy of the baseline svm. the results shown in figure  <dig> agree with the previous experiment: in no case does the reduced-feature svm significantly out-perform the baseline svm.

although these two experiments do not prove that feature selection for this particular task is a bad idea, they do suggest that any gains provided by feature selection are likely to be modest. on the basis of these experiments, we therefore decided not to pursue more sophisticated feature selection experiments.

evaluation on two validation sets
finally, we tested the svm classifier on independent data. our goal was to find a set of svm parameters that yield good generalization performance with respect to previously unseen data. in pursuit of this goal, we performed two rounds of analyses, on the two validation sets described in tables  <dig> and  <dig> 

for each experimental series, the table lists the total number of division calls made by starrynite  as well as the number of those calls that are actually divisions  and that are erroneous annotations 

 for each experimental series, the table lists the total number of division calls made by starrynite  as well as the number of those calls that are actually divisions  and that are erroneous annotations 

initially, we performed a similar cross-validation experiment as before using this new data. the results are shown in table  <dig>  in the column labeled "cv svm." apparently, this data set is easier for starrynite, which achieves a  <dig> % improvement in accuracy, compared to the development data set . however, the svm still provides a significant boost in performance, giving a  <dig> % improvement relative to starrynite .

two sets of svm results are included: from a collection of svms trained via cross-validation on the validation data set , and from a single svm trained on the development set 

unfortunately, when we use the validation data set as a test set--i.e., when we train on the development set and test the resulting svm on the validation set--our results are not as good. the svm, using hyperparameters selected on the development set, achieves an accuracy of only  <dig> %, which is only  <dig> % better than starrynite's accuracy of  <dig> %. this difference is statistically significant according to mcnemar's test with a p-value of  <dig> . on the other hand, this improvement is smaller than what we achieved via cross-validation on the development set  or the validation set , suggesting that, although the svm does a good job of learning to identify errors, those two data sets contain systematic differences that make it difficult for the svm to generalize from one to the other. we have thus violated the basic premise of most machine learning algorithms, that the test data is drawn from the same underlying distribution as the training data. this hypothesis is supported by the observation that the hyperparameters selected during internal cross-validation are quite different from one another: the learned hyperparameters for the development set were c =  <dig> , γ = 2- <dig>  and for the validation set c =  <dig> , γ = 2- <dig> 

as mentioned above, our ultimate goal is to produce a static svm classifier that yields robust performance across a variety of possible data sets. because our experiments suggest that our initial development and validation sets contain systematic differences, we next trained an svm on the combination of the two data sets and tested the performance of the classifier on a second validation data set, which contains ten new series . as shown in table  <dig>  the svm performs  <dig> % better than starrynite when tested on the new validation set. furthermore, the similarity between the first and the second columns implies that the test data and the training data come from similar sources.

two sets of svm results are included: from a collection of svms trained via cross-validation on the new validation data set , and from a single svm trained on the new development set , which is the combination of the initial development and validation sets

note that in table  <dig>  the accuracies of both starrynite and the svm are lower than the results presented in tables  <dig> and  <dig>  this is mainly because all the images in our first dataset are sampled with  <dig> minute time resolution while some of the series in the second dataset have  <dig>  minute resolution . we also trained and tested our svm classifier only on series with  <dig>  minute resolution and obtained a similar drop in performance . this result can be explained as follows. when the time resolution increases from  <dig> min to  <dig>  min, the newborn cells that are sampled by the imaging protocol move further away from the parent cell, which makes it more difficult to detect divisions because right after a division we expect the parent and the children to be close to each other to some extent. having a larger separation between parent and children cells leads to an increase in divisions detected as movements. on the other hand, because the newborn cells come closer to other cells that are actually moving, the number of movements detected as divisions increases. therefore, having experiments with  <dig>  min time resolution in our test set makes the classification task more challenging for both methods. nonetheless, the performance of the svm was significantly better than starrynite, validating the success of our approach.

the final trained svm, which is incorporated into the starrynite program, is trained from all three data sets, in an effort to provide the best generalization performance.

discussion
to date, several experimental protocols have been developed to monitor differential gene expression during embryonic development in which image analysis plays a fundamental role for efficient recognition and annotation of cells  <cit> . to correctly identify and classify cells, these methods employ a collection of features, such as shape, geometry, texture, wavelet and moment features  <cit> . often, feature reduction techniques are applied to the computed features  to achieve greater discriminative power  <cit> .

in this work, instead of using features described by other research groups, we focused on relatively simple, biologically motivated features that have the potential to discriminate dividing cells from moving ones. there are a couple of reasons for this preference. first, the classification task we are solving is relatively straightforward compared with, for example, recognizing the individual phases of mitosis. second, having a large feature set does not always guarantee improved recognition performance  <cit> , even in the presence of sufficient training data. this is mainly because many features share the same information. in this paper, we also did not apply commonly used feature reduction techniques because, first, we have enough training data and, second, our preliminary feature analysis experiments suggest that feature selection is unlikely to lead to dramatically improved performance on this set of morphological features. on the other hand, the extension of the feature set to include other feature types is a possible direction. for instance, depending on the source of the image data, it may often happen that additional cell features might also be exploited that are specific to the tissue type or species. these features could be introduced to add even stronger support to automated error detection. in that case, more sophisticated feature selection methods can be exploited to extract the most informative feature set for a more accurate classifier. we leave this extension as future work.

CONCLUSIONS
in this work, we concentrated on one of the most common errors made by starrynite, which is image analysis software for automatic recognition and tracing of developing c. elegans cells in a 3d imaging protocol. we have shown that the error rate for calling a nucleus as dividing can be significantly reduced by an svm classifier. the original level of errors that must be identified and corrected in a new starrynite dataset constitutes approximately 12-30% of the original observations. automated correction using the svm then can be expected to reduce this error rate by 2-9%. this cuts the amount of manual corrective work by 16-30%. our method may over-predict potential annotation errors in some cases, but those false predictions can actually be helpful in drawing attention to trouble spots for final, manual data cleanup, and thus speed that process.

this work suggests several avenues for future research. perhaps most obviously, this post-processing approach can also be applied to other types of errors. it is also possible to relate one type of an error to another, because errors are frequently coupled. for instance, movement detected as division error can be coupled with division detected as movement. similarly, a movement detected as cell death can be coupled with a movement detected as division at a later time point. in the future, by considering correlations among error types, it should be possible to design more accurate classifers. alternatively, the decision mechanism of the svm can be used in the context of the starrynite algorithm, rather than as a post-processing step. furthermore, it should be possible to utilize the topology of the c. elegans cell lineage tree during the annotation process. though the exact time instances of divisions might vary from one embryo to another, the topology of the tree and the average division times are known a priori. such information could be exploited by a more elaborate statistical model. finally, the use of the svm classifier is not limited to starrynite only. it can easily be applied to other data types or utilized in projects in which a methodological error correction step is essential due to large data size. therefore, our method offers a guide to a wider audience on how to test and assess such algorithms in general. further advances in accurate annotations will make it possible to analyze gene expression in the later cell stages, which is important because the majority of genes responsible for embryonic development start differentiating after the  <dig> cell stage.

