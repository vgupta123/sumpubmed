BACKGROUND
data from genome-wide association studies are now being mined for genotyping as well as for copy number estimation. often, the primary objective is genotyping and secondarily the data are interrogated to evaluate copy number variation . it is well recognized that the genotyping algorithms are usually highly concordant for most snps, particularly for the two most common snp array vendors: illumina and affymetrix. however, although the probe intensities produce concordant snp calls, this does not imply that the probe intensities are sufficiently clean to accurately estimate copy number. in fact, copy number estimation is more susceptible than genotyping to variability in sample processing procedures as well as analytical processing steps. for example, copy number data obtained from snp arrays are highly prone to batch effects, which reflect systematic variability during sample processing  <cit> . although genotype clustering algorithms are relatively robust to these batch effects, copy number data are not. this systematic variability will result in biased estimates of copy number and thus can negatively impact downstream statistical analyses.

there are numerous software packages available for genotyping and for copy number estimation, of which most have options available for removing systematic variability. however, each software package uses different algorithms for removing this variation resulting in different effects on downstream statistical analyses. in an attempt to compare cnv software for oligonulceotide data, baross et al.  <cit>  compared four software packages for preprocessing and analyzing cnv data obtained from the affymetrix 100k snp array platform: copy number analyzer for genechip , dchip, affymetrix genechip® chromosome copy number analysis tool , and gain and loss analysis of dna . baross and colleagues found that the numbers and types of cnvs varied significantly across the four software packages and thus concluded that at least two software packages are necessary in order to identify all real copy number aberrations. their assumption is that the algorithms have different strengths and thus taking the union of all the copy number aberrations should increase sensitivity. more recently, winchester et al.  <cit>  compared various freely- and commercially-available software for detecting germline cnvs using both illumina and affymetrix snp arrays. with respect to freely-available software they primarily evaluated quantisnp and penncnv. winchester and colleagues also suggest applying two algorithms on a single dataset in order to obtain the most informative results and recommend using software that was designed specifically for the cnv array platform being used.

both baross et al.  <cit>  and winchester et al.  <cit>  compared results obtained after segmentation, and thus did not evaluate the agreement, or lack thereof, in the locus-level copy number data. furthermore, since the baross et al.  <cit>  publication, the technology has advanced and there have been additional algorithms developed that are now routinely used. thus, the goal of this paper is to compare freely-available software that is routinely used for cnv data obtained from the affymetrix genome-wide human snp array  <dig>  platform, the newest affymetrix snp platform that has an order of magnitude more probes than the older 100k platform. the snp array  <dig>  has  <dig>  million genetic markers, including more than  <dig>  snps and  <dig>  probes for the detection of cnv.

herein, we provide a description of four freely-available software packages that are commonly used for cnv analysis of data generated from affymetrix genome-wide human snp array  <dig>  platform. we compare both the bias and variance in the locus-level copy number data as well as concordance of the segmentation results obtained using a hidden markov model . throughout, we report on results from autosomal chromosomes only and we often use chromosome  <dig> as an informative example.

RESULTS
we used a germline dataset consisting of  <dig>  caucasian samples to empirically evaluate four software packages developed for the affymetrix  <dig>  snp array platform. the four software packages evaluated were penncnv  <cit> , aroma.affymetrix  <cit> , affymetrix power tools   <cit>  and corrected robust linear model with maximum likelihood distance   <cit> . it is important to note that penncnv, aroma.affymetrix and apt estimate relative copy number, relative to a reference sample or cohort of reference samples. in contrast, crlmm estimates absolute copy number. scharpf et al.  <cit>  advocates estimating absolute copy number in comparison to relative copy number stating that the disadvantages of estimating relative copy number are that a reference set is necessary, a deviation from the normal two copies can either represent an aberration in the test sample or the reference set, and lastly, that the allelic copy number at polymorphic loci is often ignored.

as discussed above, copy number estimation is very susceptible to variability in the analytical processing steps. analytical processing can entail numerous steps including, but not limited to, background correction, normalization, genomic wave correction, batch effect removal and choice of denominator in calculating relative copy number. a list of the default settings for each of the analytical processing steps for the four software packages is presented in table  <dig> and discussed in detail below.

† a denotes the a-allele intensity and b the b-allele intensity for the corresponding probe.

* rexp is computed from linear interpolation of canonical genotype clusters  <cit> .

** corrects for optical noise and non-specific binding in the linear model.

log2r denotes the relative locus-level copy number of the sample of interest relative to a reference sample. penncnv utilizes the hapmap samples as the reference data  for calculating log2r, whereas aroma.affymetrix and apt utilize the data at hand as their reference data. crlmm estimates absolute copy number using a linear model and thus does not require a reference sample; according to their documentation, crlmm requires at least  <dig> samples in order to obtain accurate estimates of the model parameters.

background correction attempts to remove optical background and non-specific hybridization  <cit> . penncnv and apt do not correct for background hybridization. aroma.affymetrix corrects for allelic crosstalk prior to performing quantile normalization and crlmm corrects for optical background and non-specific hybridization using a linear model after performing quantile normalization.

across-array normalization attempts to correct for systematic variability induced by array manufacturing, sample preparation, and labelling, hybridization and scanning of the arrays  <cit> . by default, all four software packages apply quantile normalization, which makes the distribution of probe intensities for each array equivalent  <cit> . although each of the software applies quantile normalization, they utilize different target distributions. particularly, aroma.affymetrix and apt utilize the data at hand to define the target distribution, whereas penncnv and crlmm use the hapmap samples to define a target distribution.

genomic-wave is an artefact that has been observed in both array comparative genomic hybridization  and snp data and is thought to be correlated with gc content  <cit> . by default, only aroma.affymetrix corrects for genomic waves; however, options are available in penncnv and apt to correct for genomic waves. specifically, aroma.affymetrix corrects for gc content and pcr fragment length to the post quantile-normalized data.

batch effects are an artefact of processing samples in multiple laboratories, by multiple technicians, using reagents from multiple batches, or other sample processing steps that are not constant across samples and effects individual probes differently  <cit> . quantile normalization corrects for global systematic effects, whereas the goal of batch-effect removal is to correct for probe-specific artefacts. of the four software evaluated, only crlmm has an option to correct for batch effects; scharpf and colleagues assume that batch can be easily identified and thus model batch as a fixed effect  <cit> . for the empirical data used herein, batch was defined according to the 96-well plate that the sample was processed on. as a preliminary evaluation, for each locus on chromosome  <dig>  we performed analysis of variance  on the post-processed locus-level copy number data by 96-well plate; there were  <dig> plates utilized in the genoa study. the post-processed locus-level copy number data produced by penncnv and crlmm resulted in larger f-statistics in comparison to the post-processed data from aroma.affymetrix and apt . furthermore, although crlmm corrects for batch effects as part of the analytical processing, locus-level batch effects are still present in the post-processed data.

the anova provides an f-statistic with  <dig> and  <dig> degrees of freedom for each locus; the associated critical value for the  <dig>  quantile is  <dig> .

an example of the post-processed locus-level copy number data for chromosome  <dig> is displayed in figure  <dig> for each of the four software packages. each point in figure  <dig> represents a locus  on the affymetrix  <dig>  snp array. as expected for germline data, the locus-level copy number data are randomly scattered around a value of two, which represents the normal two-copy state.

comparison of bias and variance of locus-level data
the distribution, across the  <dig>  samples, of the median locus-level copy number  for chromosome  <dig> is presented in figure 2a. on average, crlmm produced slightly larger median locus-level copy number  in comparison to apt , penncnv  and aroma.affymetrix . across the  <dig>  samples, apt most consistently obtained a median copy number of two, ranging from  <dig>  to  <dig> . of note, samples with a median copy number larger than  <dig>  or less than  <dig>  were not from the same 96-well plate nor did the same samples consistently produce large  median copy numbers across all four software. figure 2b provides the distribution of the median absolute deviation  on chromosome  <dig> for each of the  <dig>  samples. the mad is a robust measure of variability and is defined as the median of the absolute deviations from the data's median. thus, the mad is the variability about the median as the standard deviation is the variability about the mean. the locus-level copy number data produced by penncnv and aroma.affymetrix are less variable, on average,  in comparison to crlmm and apt . the derivative log ratio spread , another robust estimator, was also used to evaluate variability and produced results similar to mad . to summarize, although apt produced median locus-level copy numbers closest to the normal two-copy state across all samples evaluated , the locus-level copy numbers produced by apt are more variable in comparison to penncnv and aroma.affymetrix . the results are similar across all autosomes .

agreement of locus-level copy number data
bland-altman plots  <cit>  comparing the four software packages for a single representative sample for chromosome  <dig> are presented in figure  <dig>  each point on the plot denotes a locus on chromosome  <dig> and the line represents a locally-weighted average . if the differences in estimated copy number between two software packages are not related to the magnitude of either copy number measurement, then it is expected that the data will be randomly scattered around the zero horizontal reference line. for the representative sample displayed in figure  <dig>  the difference in the locus-level copy number between any two software packages is in fact related to the magnitude of copy number; with the exception of the comparison of aroma.affymetrix and crlmm  particularly, the software packages tend to disagree most for copy number values larger than the normal two-copy state. the exception being aroma.affymetrix and crlmm, where the average differences between the locus-level copy number is approximately zero, as suggested by the loess line that nearly perfectly overlays the zero horizontal reference line.

whereas figure  <dig> displays data for a single sample, figure  <dig> displays bland-altman plots across all  <dig>  samples for chromosome  <dig>  the individual locus-level data points are not plotted in figure 4; instead, a loess line is provided for each sample. in general, all samples tend to follow a similar trend. particularly, the software packages tend to disagree most for copy number values less than one and copy number values larger than three. furthermore, although aroma.affymetrix and crlmm appeared to produce the most similar locus-level copy number values on average for the single representative sample displayed in figure 3c, this was not universally true across all  <dig>  samples studied . for the data studied here, penncnv and aroma.affymetrix produced the most similar locus-level copy number values on average .

up to this point, for ease of explanation, we have only used data from chromosome  <dig> to compare the four software programs. similar trends were observed across the other autosomes .

concordance of detected segmentation regions
in addition to evaluating the agreement of locus-level copy number data across the different software, we also evaluated the concordance  of identified regions of copy number gain and loss as obtained from the hmm algorithm. here, we only compare the results obtained from crlmm and penncnv; of the four software packages evaluated, they are the only two that contain a segmentation algorithm. although crlmm itself does not contain a segmentation algorithm, the same authors developed vanillaice  <cit>  and thus the results from crlmm can be directly imported into vanillaice without extra effort .

it is important to note that while neither crlmm/vanillaice nor penncnv apply cnv-specific quality-control metrics to the segmented data by default, only penncnv provides cnv-specific quality-control metrics that can be used to identify potentially poor cnv samples . of the  <dig>  samples analyzed,  <dig> samples were identified as potentially poor cnv samples in the penncnv analysis. crlmm suggests using a signal-to-noise measure to identify samples that have poor quality for genotype calling but do not have additional cnv-specific quality-control measures. using the signal-to-noise measure, crlmm identified  <dig> samples that were poor samples for genotyping purposes,  <dig> of which penncnv also identified as poor samples. the  <dig> samples identified as poor samples via penncnv and crlmm were removed when evaluating concordance between penncnv and crlmm/vanillaice.

a summary of the number of cnvs that were detected for crlmm/vanillaice and penncnv across the  <dig>  samples that passed the penncnv cnv-specific quality-control metrics is presented in table  <dig>  overall, penncnv detected more cnvs than crlmm/vanillaice; the median number of cnvs detected per sample was  <dig> and  <dig>  respectively. furthermore, the maximum number of cnvs per patient was  <dig> by penncnv and  <dig> by crlmm/vanillaice. remember, a sample was eliminated if it had more than  <dig> cnvs detected by penncnv. thus, there is at least one sample in which crlmm/vanillaice detected  <dig> cnvs but penncnv detected less than or equal to  <dig> cnvs. lastly, both packages detected many more deletions than amplifications, which others have also observed  <cit> . the median number of loci  contained within a segment for crlmm/vanillaice was  <dig> , whereas the median number of loci contained within a penncnv segment was  <dig> .

concordance of detected cnv regions by penncnv and crlmm/vanillaice was also evaluated. again, we limited the comparison to the  <dig>  subjects that had cnv calls using both software packages and passed the cnv-specific quality control metrics that were provided by penncnv and the signal-to-noise metric suggested by crlmm. table  <dig> provides the percent of concordant loci per sample; a locus is defined to be concordant if both penncnv and crlmm/vanillaice identified a deletion/duplication that contained the corresponding locus. concordance was defined with respect to regions identified as duplicated or deleted and not with respect to the actual copy number state. across all loci contained within regions that were identified to be duplicated, the median concordance between penncnv and crlmm/vanillaice was  <dig> %. similarly, across all loci contained within regions that were identified to be deleted, the median concordance between penncnv and crlmm/vanillaice was  <dig> %. the fact that crlmm/vanillaice identifies segments that consist of a single locus and penncnv requires at least three loci does not affect these results to any large extent since only  <dig> % of the segments detected by crlmm/vanillaice consist of fewer than three loci. although the agreement seems to be poor , it agrees with a previous publication comparing software packages that were designed for the 100k affymetrix snp array  <cit> . baross and colleagues  <cit>  reported that 63% of duplications and 37% of deletions were detected by two or more software packages. interestingly, penncnv detects almost all of the regions that crlmm/vanillaice does as well as additional regions of copy number gain and loss .

the discordance between penncnv and crlmm/vanillaice can be largely attributed to the variability of the locus-level copy number data obtained from penncnv and crlmm. figure  <dig> displays three regions on chromosome  <dig> that are concordant between penncnv and crlmm/vanillaice; the locus-level data are denoted by black dots and the identified segments are denoted by red horizontal lines. although the locus-level copy number data are clearly more variable for crlmm in comparison to penncnv, the software identified three common regions: two regions of amplification and one deleted region. additionally, penncnv detected a small region of amplification at ~ <dig>  mb that crlmm/vanillaice did not likely due to the variability associated with the crlmm locus-level copy number data. as another example, figure  <dig> displays the same region on chromosome  <dig> as figure  <dig>  but for a different subject. again, penncnv identified a region of amplification that appears to be valid from visual inspection whereas crlmm/vanillaice was unable to identify the region above the noise in the data. there are two deleted regions detected by penncnv and one deleted region detected by crlmm/vanillaice that are discordant, but from visual inspection it is difficult to determine if these regions are real or in fact false positives.

false-positive rate
ultimately, it is important to know what proportion of the detected segments are false positives for both penncnv and crlmm. to do so, we took the approach described by baross et al.  <cit>  and assumed that deletions should not contain heterozygous genotype calls . thus, we evaluated the  <dig>  deletions detected by crlmm and  <dig>  deletions detected by penncnv and compared the estimated false-positive rate amongst the two software. baross and colleagues  <cit>  defined a deletion as a false positive if the rate of heterozygous snps was more than 10% of the total snp count. figure  <dig> displays the cumulative density of the rate of heterozygous snps across all autosomes for penncnv and crlmm; both hemizygous and homozygous deletions were included. using a 10% threshold, as suggested by baross and colleagues  <cit> , 26% of the  <dig>  deletions detected by crlmm are probable false positive regions whereas approximately 24% of the  <dig>  deletions detected by penncnv are probable false positive regions. this implies that the extra regions detected by penncnv are not likely to be false positives. additional file  <dig> provides the heterozygous rate for each of the  <dig> autosomes individually and shows that the false-positive rate differs across the autosomes. figure  <dig> displays the relationship between the size of each detected deleted segment  and the estimated rate of heterozygous snps. to note, deleted segments that have 100% heterozygous rate include both hemizygous and homozygous deletions.

CONCLUSIONS
our objective was to compare commonly-used freely-available software algorithms for analyzing cnv data obtained from the affymetrix  <dig>  snp array platform. specifically, we compared affymetrix power tools , aroma.affymetrix, penncnv and crlmm. of the four software packages that we compared apt performed the best with respect to bias; that is, apt on average had median locus-level copy numbers closest to a value of two. in fact, the tight bounds associated with the bias for apt suggests that there could be an algorithmic assumption made by the software; however, we could not identify any such discussion in their documentation. although apt had the smallest bias, penncnv and aroma.affymetrix had the smallest variability associated with the median locus-level copy number. thus, if one is interested in performing statistical tests on the locus-level copy number data, our empirical results suggest that penncnv and aroma.affymetrix are the optimal software packages of those evaluated herein.

batch effects are an artefact of processing samples in multiple laboratories, by multiple technicians, using reagents from multiple batches, or other sample processing steps that are not constant across samples and affects individual probes differently  <cit> . methodologies to remove probe-specific batch effects are an area of active research. here, we have shown empirically that the extent of probe-specific batch effects post analytical processing is dependent on the software used. furthermore, even though crlmm has a default option to remove batch effects, probe-specific batch effects were present in the post-processed locus-level copy number data. additionally, probe-specific batch effects were more evident in the post-processed crlmm and penncnv locus-level copy number data in comparison to the aroma.affymetrix and apt post-processed data. this empirical observation was surprising and thus warrants additional evaluation.

it is interesting - and maybe surprising - that so many deleted segments were estimated to be false positives, especially since both penncnv and vanillaice utilize genotype and b-allele frequency information in their hmm algorithms. even though our estimated false-positive rate appears high, our results agree with the rates shown by baross et al.  <cit> . undoubtedly, the gold standard would be to have known-spike in data in which to compare software and likewise determine the true false-positive rate or to validate each candidate cnv region using an independent technology. unfortunately, validation is not feasible for the thousands of candidate cnvs identified in the genoa data.

of the software evaluated, only penncnv and crlmm  provide locus-level copy number data as well as a segmentation routine and thus allow the analyst to complete all data processing steps without having to reformat the data for use in another software package. penncnv provides cnv-specific quality-control metrics to aid in identifying potentially poor cnv samples, whereas crlmm or vanillaice does not. that is, crlmm suggests using a signal-to-noise measure to identify samples that have poor quality for genotype calling but do not have additional cnv-specific quality-control measures. we observed that penncnv detects almost all of the regions that crlmm/vanillaice does as well as additional regions of copy number gain and loss. although some of these additional regions may be false positives, the estimated false-positive error rate associated with deletions was similar for penncnv and crlmm/vanillaice and thus the additional regions are likely not all false positives.

as discussed by lai et al.  <cit> , it is very difficult to compare complicated algorithms as each algorithm has its own set of parameters that must be optically tuned. therefore, it is possible that the results discussed herein would change if the parameters associated with the software were fine tuned to fit the data more precisely. unfortunately, there is little-to-no guidance provided by most software for evaluating and choosing optimal parameter settings. this was particularly true for the hmm algorithms provided by penncnv and vanillaice. thus, we evaluated each algorithm using the default parameters. although not optimal, this is what many analysts - even experienced analysts - will ultimately do until developers of software provide adequate documentation and guidance for evaluating and choosing parameters for complicated algorithms. until such guidance exists, we recommend trying multiple algorithms, evaluating concordance/discordance as we have done here and subsequently consider the union of regions for downstream association tests. others have suggested a similar approach  <cit>  assuming that algorithms have different strengths and thus taking the union of all the copy number aberrations should increase sensitivity.

