BACKGROUND
elucidating the relationship between human genetic diseases and their causal genes is an important emerging topic in current systematic biology. understanding the inherited basis of these interactions could both improve medical care and better understand gene functions, interactions, and pathways. typically, a disease is associated with a linkage interval of  <dig> - <dig> cm on the chromosome if single nucleotide polymorphisms  in this interval are correlated with an increased probability to have the disease  <cit> . then, these linkage intervals define a set of  candidate disease-causing genes  <cit> .

with the rapid accumulation of different kinds of genomic data, a lot of computational methods for prioritizing candidate casual genes of a given phenotype were proposed at the beginning of the 21st century. these methods are largely based on the similarity of characteristics of disease genes, including sequence-based features  <cit> , expression patterns  <cit> , and functional annotation data  <cit> . despite their good performances, these methods suffer from some inherent limitations, e.g., the incomplete and false-positive disease-causal genes data, ambiguous boundary between different diseases, and highly heterogeneous of diseases.

recently, network-based analysis showed that gene products related to the same disease are prone to physically interact with each other  <cit> . based on this observation, a number of computational approaches have been proposed to predict associations between genes and diseases. these methods mainly begin with an artificial disease interval and test their ability to identity a real causing gene among a fixed number of nearby control genes. according to their underlying methodology, these methods can be loosely grouped into three categories  <cit> . the first category is the linkage methods, which assumed that the direct interaction partners of a disease protein are likely to associate with the same disease phenotype. it was found that gene products interacted with a known disease protein were shown to be tenfold enriched in true disease-causing genes  <cit> , so many researchers searched the ppi network for direct or indirect interacting partners of known disease genes to find new possible causing genes  <cit> . the second category is module-based methods, which are based the observation that gene products belonging to the same topological, functional or disease module have a high likelihood of being involved in the same disease. these methods inspect disease modules by graph partition algorithms and treat their members as potential disease genes  <cit> . the last category consists of diffusion-based methods  <cit> . in these algorithms, 'random walkers' are released from the protein products of known disease genes, and then diffuse along the ppi network, with a certain probability to return the original nodes. compared to linkage-based and module-based methods, diffusion-based methods used information encoded in the full network topology as well as the placement of all known disease genes. so a recent comparative research found that diffusion-based methods achieved the best predictive performance on the same data set  <cit> .

in the present paper, we propose a new diffusion-based method to prioritize candidate disease genes. the diffusion profile of a disease was defined as the stationary distribution of all candidate genes in the ppi network under a random walk with restart where similarities between phenotypes are incorporated. similarly, the diffusion profile of a gene was obtained by smoothing the probability distribution over the whole network when starting a walk from this gene. then, candidate disease genes are prioritized by comparing their diffusion profiles with that of the disease, measured by the linear correlation coefficient and cosine of the angle between profile vectors. finally, the effectiveness of our method was demonstrated through the leave-one-out cross-validation against control genes from artificial linkage intervals and randomly chosen genes. comparisons of our method with two classical diffusion-based methods showed that our method achieves improved performance. to further illustrate our method, we also used our algorithm to predict new causing genes of  <dig> multifactorial diseases including prostate cancer and alzheimer's disease, and our top predictions are in good consistent with literature reports.

methods
protein-protein interaction data and known disease-gene associations
the protein-protein interaction network  is modelled as an undirected graph with nodes representing the genes and edges representing the physical or binding interactions between proteins encoded by the genes. in the present paper, ppi network is obtained from release  <dig> of the human protein reference database   <cit> . after removing duplications and self-linked interactions, we obtain  <dig>  <dig> manually curated interactions between  <dig> human genes.

disease-gene association data are downloaded from the online mendelian inheritance in man  knowledgebase  <cit> . the dataset contains  <dig> diseases and  <dig> disease-gene associations after removing the duplications, with an average of  <dig>  gene associations for each disease. to facilitate the cross-validation, diseases currently associated with only one causal gene were discarded. meanwhile, associations not correlated with the  <dig> human genes in the ppi network were also excluded. after these steps, a total number of  <dig> validate disease-gene associations are left for further consideration.

phenotype similarities between  <dig> disease phenotypes obtained from the literature  <cit>  are incorporated for prioritization of candidate disease genes. these similarities are calculated by text mining of omim phenotype records using medical subject headings  terms  <cit> . according to their analysis, similarity values below the threshold  <dig>  are not informative, while for similarity values beyond  <dig>  the associated genes show significant functional similarity. so in our analysis, similarity values below  <dig>  are not considered for the computation of the diffusion profile of a disease .

random walk with restart and diffusion profile of a protein
given a ppi network g=<v,e> where  v is the set of proteins,  e is the set of interactions. the random walk on ppi network is defined as an iterative walker's transition from its current node to any neighbouring node with equal probability starting at a given source node. in a statistical point of view, a random walk is a finite markov chain that is time-reversible.

for example, if a random walk begins with a node g∈v, the initial distribution p <dig> of the random walk was formulated as a vector of dimension ||v||, in which the element in position corresponding to v was  <dig> and  <dig> otherwise. the rule of the walk can be expressed by the equation

  pt+1=m⋅ptt= <dig> , <dig> ⋯ 

where m is the column-normalized adjacency matrix of the graph. after a certain steps, the probability will reach a steady  state. this can be implemented by performing the iteration until the difference between pt+ <dig> and pt  fall below 10 -  <dig>  i.e.,

  |pt+1-pt|<10- <dig> 

if the walk has a certain probability  γ to return the start node at each step, that is,

  pt+1=m⋅pt+γp0t= <dig> , <dig> ⋯ 

which is the random walk with restart. the restart probability  γ enforces a restriction on how far we want the random walker to get away from the start node  v. if  γ is close to  <dig>  the stationary probability vector reflects the local structure around the  v, and as  γ gets close to  <dig>  a more global view is observed. finally, we define the diffusion profile of a protein g as the stationary distribution p∞ of the random walk with the initial distributionp <dig> 

random walk with restart  provides a good relevance between two nodes in a graph, and it has been successfully used in numerous settings, like automatic captioning of images, generalizations to the "connection subgraphs", personalized pagerank, and so on  <cit> . the main advantage of the random walk method is that its computational complexity is relatively low and applicable to handle large ppi networks. moreover, the method can be used to compute the proximity of a node to a set of source nodes . this property is especially beneficial when a core set of members of a phenotype is known and the network is queried for candidate members.

diffusion profile of a disease by incorporating omim phenotype similarity and prioritizing function
similarly, in order to compute the diffusion profile of a disease, we should first get the initial distribution of a disease. here, the initial probability vector d <dig> of a disease  d was constructed such that equal probability was assigned to each node representing the causing gene of the disease, with the sum of the probabilities equals  <dig>  then

  dt+1=m⋅dt+γd0t= <dig> , <dig> ⋯ 

in this way, proteins that interact with several disease proteins will gain a high probabilistic weight, as well as those that may not directly interact with any disease proteins but are in close network proximity to them.

it was found by researchers that similar phenotypes are caused by functionally related genes. based on this observation, for a disease d, we used initial distributions of phenotypes which have similarity exceeds a threshold with d to optimize its initial distribution. we assume that the contribution of a given disease di is proportional to the initial distribution of d. so the weighted initial distribution of the disease d is formulated as

  d ˜0=d0+λ⋅∑i=15080δ⋅sim⋅d0i 

where δ=1sim≥ <dig> otherwise, d0i is the initial distribution of disease di.

then

  d ˜t+1=m⋅d ˜t+γd ˜0t= <dig> , <dig> ⋯ 

we called the stationary distribution d ˜∞ of the random walk diffusion profile of the disease d.

finally, for a given disease and a set of genes in the ppi network, the prioritizing function can be defined by the linear correlation coefficient  or cosine angle of their corresponding diffusion profiles. explicitly,

  dlcc=lcc=∑i=1n-d ˜∞¯)-p∞¯)∑i=1n-d ˜∞¯) <dig> ∑i=1n-p∞¯) <dig> 

  dcos=cos=∑i=1nd ˜∞⋅p∞∑i=1nd ˜∞ <dig> ∑i=1np∞ <dig> 

if a gene has very similar stationary distribution profile with a disease, it may have strong evidence to be the causing gene of the disease. following this observation, given a disease d, its candidate genes were ranked according to the lcc and cos values between their stationary distributions. we referred the two proposed candidate gene prioritization algorithms as dp_lcc and dp_cos respectively, where 'dp' is the abbreviation of 'diffusion profile'.

cross-validation and evaluation criteria
we used two leave-one-out cross-validation methods to validate our algorithm. first is the artificial linkage interval approach, which assumes the singled out interaction is unknown and prioritizes the gene against a set of control genes in the genome. here the control set consists of the nearest  <dig> genes around real disease causing genes according to the ucsc refgene table. actually, there may be few undiscovered disease causing genes in the control set. second, we used validation against random genes, i.e., in each run, a known disease-gene association is singled out as the test sample against a set of  <dig> control genes that are selected at random from all genes in the interactome. so, a total of  <dig> genes  are served as test data, and performance of our method is validated by capability to recover the real causing gene from the rest  <dig> control genes.

we used two measures to evaluate the performance of the proposed method. for each cross-validation run, we calculated the proportion of disease genes that obtain the top prioritization score against the corresponding  <dig> control genes, and called this measure precision . also, given a threshold of rank ratio, we calculated the sensitivity  as the fraction of disease genes ranked above this threshold and the specificity  as the fraction of control genes ranked below the threshold. varying the threshold of rank ratio from  <dig> to  <dig> with the scale  <dig> , we are able to draw a receiver operating characteristic  curve and further calculate the area under this curve . clearly, a larger pre/auc values indicate a better prediction performance of a prioritization method.

RESULTS
effects of parameters
there are two free parameters in our model, the restart probability  γ in the random walk algorithm and the weight parameter  λ in computing the initial probability of a disease. we tested our algorithm on different values of  γ  and  λ  and found that the best performance are got at the weight parameterλ= <dig> , while the restart parameter  γ only has slight effect on the results . in detail, for both dp_lcc and dp_cos, the highest pres are got at γ= <dig>  and λ= <dig> , and the largest auc for dp_lcc is got at γ= <dig>  and λ= <dig> , while for dp_cos the values are γ= <dig>  and λ= <dig> , respectively. but in general, pres and aucs did not change significantly at different values of  γ, which is in accordance with the observation of kohler, et al. .

we tested our algorithm  by two leave-one-out cross-validation methods, i.e., artificial linkage interval approach  and random genes approach . results are shown in figure  <dig> and suggest a similar performance of dp_lcc by ali and rand validations. the only slight difference lies at low values of false positive rates between  <dig> and  <dig> , with a slight superiority of rand. but when false positive rate increases from  <dig>  to  <dig>  two roc curves are nearly coincident, with aucs  <dig>   and  <dig>   respectively. the similar performance of our algorithm by two cross-validation approaches demonstrates that:  the control genes by random chosen and from artificial linkage interval are unbiased;  our algorithm is robust to the selection of control set.

the parameter  λ controls the contribution of other related phenotypes to the initial distribution of a phenotype. large  λ introduce more global dependence of ranking between different correlated phenotypes. when λ= <dig>  the proposed method could be very similar to the rwr algorithm. to investigate the effect of this parameter, we set various values of  λ ranging from  <dig>  to  <dig> , the performance of our algorithm measured by two evaluation criteria are shown in table  <dig>  the performances of our algorithm evaluated by two criteria, i.e., lcc and cos, have no significant difference at different values of  λ. the performance is improved when  λ ranges from  <dig>  to  <dig> , and decreased when  λ is larger than  <dig> , especially at  <dig> . therefore, we suggest the  λ value of  <dig>  or  <dig> .

comparison with other diffusion-based methods
to illustrate the utility of the present method, we compared the performances of dp_lcc and dp_cos with two diffusion-based methods, i.e, the rwr and prince on the same gene-phenotype network. both methods used random walk with restart algorithm to prioritize disease-candidate genes, and achieved relatively better performance compared to linkage-based methods and graph partitioning-based methods  <cit> . the only difference between rwr and prince is the construction of initial distribution of a disease, where the initial probability vector of rwr was constructed such that equal probability was assigned to each causing gene of a disease, and in prince, the prior information vector was initialized by incorporating disease similarity information by using a logistic function. in our implement, two free parameters c and d in logistic function are set to - <dig> and log respectively, which are in accordance with prince.

we use leave-one-out cross-validation to evaluate the performance of different diffusion-based methods in recovering the gene-phenotype relationship. in each round, a gene-phenotype link was removed, and the rest causal genes and associating phenotypes were used as training set to recover this link. we evaluated the performance of an algorithm in terms of precision  and the area under roc curve  at different values of the rank ratio. the results are shown in table  <dig> and figure  <dig>  as is shown, the proposed method is superior to rwr and prince at nearly all parameter settings in terms of both pre and auc. for all these three algorithms, the highest precisions, i.e,  <dig>   <dig> and  <dig> for rwr, prince and our method, respectively, are obtained at γ= <dig> . at parameter set λ= <dig> , our methods  successfully ranked  <dig> and  <dig> known disease genes as top  <dig> out of the total  <dig> disease-gene interactions. in contrast, only  <dig> and  <dig> disease genes were ranked at the top by rwr and prince. while for auc, the tendency was a little different. aucs of the rwr algorithm drops with the increase of  γ, and the highest value  <dig>  was achieved at γ= <dig> . similar phenomenon was observed for prince. it is worth mentioning that this phenomenon is slightly different from the result of kohler  <cit> , who found that the best performance was achieved at γ= <dig> . however, the prince algorithm, which also took into consideration the phenotype similarity data, did not achieve high predictive accuracies especially when  γ is larger. this phenomenon may be attributed to the setting of parameters c and d, which are tuned using cross validation over a totally different dataset, are not quite suitable for the current dataset. we believed that after a careful optimization of the parameters, the prince would achieve a better accuracy than rwr due to the incorporation of phenotype similarities.

a the pensions are divided by/1238; run time of our algorithm is  <dig> minutes. computations were performed on a single processor of a dual-core intel  core p <dig>  <dig>  ghz and  <dig> gb gb of shared memory.

the roc curves for these three methods at γ= <dig>  are shown in figure  <dig>  we used the receiver operating characteristic  curve to compare our method with two diffusion-based methods, which plots the sensitivity versus 1-specificity subject to the threshold separating the prediction classes  <cit> . sensitivity refers to the percentage of disease genes that were ranked above a particular threshold. specificity refers to the percentage of non-disease genes ranked below this threshold. as shown in figure  <dig>  the curve of our algorithm is above those of rwr and prince, which suggest that our algorithm obtained both higher sensitivity and higher specificity. the auc value of our algorithm is  <dig> , which is much higher than rwr  and prince .

another popular method for evaluating the performance of a prioritization method is to consider the precision-recall curve  <cit> . given the association scores calculated for candidate genes, we define positive calls as all genes whose association scores are higher than a certain threshold and define the precision as the proportion of disease genes among the positive calls. and the recall, also called the true positive rate, is defined as the proportion of positively called disease genes among all disease genes. by varying the threshold value, we can compute a series of precision and recall values and obtain a precision-recall  curve. the pr-curves for rwr, prince and our method are shown as figure  <dig>  as is shown, the curve of our method also lies above those of rwr and prince, which suggests that the performance of our method is superior to the other diffusion-based methods. the superior performance of our model may be attributed to the incorporation of omim phenotype similarities, as well as the global similarity measures between diffusion profiles of diseases and candidate causing genes.

predict novel causing genes of prostate cancer and alzheimer's disease
after validating our method, we proceeded to execute our algorithm to predict new causing genes of  <dig> multifactorial diseases that are linked to multiple genomic regions . according to the mim record, all these  <dig> diseases are associated with more than  <dig> known valid causing genes locating at different genomic regions. we used our algorithm to predict new causing genes for these  <dig> diseases, where known causing genes are served as training data and the rest genes in the ppi network are served as candidate disease genes. the top- <dig> predictions for each disease are shown in table  <dig>  we selected alzheimer's disease , prostate cancer , diabetes mellitus, type  <dig>  as three case studies.

alzheimer's disease  is the most common cause of dementia in the elderly. it is characterized clinically by progressive memory loss that leads eventually to dementia. as is shown in table  <dig>  the third prediction for ad is trem <dig> , which is a member of the innate immune receptor trem family  <cit> . it is expressed on the cell surface of the monocyte-macrophage lineage including monocyte derived dendritic cells, osteoclasts and microglia in the central nervous system   <cit> . recent researches showed that trem <dig> deficiency originates a genetic syndrome characterized by bone cysts and presenile dementia  <cit> . another prediction, mapt, was also a suspicious driver gene for ad  <cit> . genetic variability at the mapt locus was shown to be associated with increased risk for the sporadic tauopathies, psp  <cit>  and corticobasal degeneration  <cit> . the fifth prediction is psen <dig>  which is also a driver gene of ad in the literature. it was reported that mutations in the human presenilin genes  are associated with early onset familial alzheimer disease  <cit> .

diabetes is a chronic condition associated with abnormally high levels of sugar  in the blood. the disease can be classified into three different categories: the type i, type ii and the gestational diabetes. the top  <dig> predictions of our algorithm for diabetes mellitus are abcg <dig>  abcg <dig> and ppp1r3a, respectively. the first two genes, i.e., abcg <dig> and abce <dig>  are atp-binding cassette transporters that are located in a head-to-head orientation on chromosome  <dig>  the proteins are expressed in the liver, intestine  <cit> , and gallbladder epithelial cells  <cit> . polymorphisms in abcg5/abcg <dig> genes might contribute to the genetic variation in plasma lipid levels and in cholesterol saturation of the bile  <cit> . down-regulation of hepatic and intestinal abcg <dig> and abcg <dig> expression associated with altered sterol fluxes in rats with streptozotocin-induced diabetes  <cit> . in addition, defects in rp <dig> and ppp1r3a are also causes of susceptibility to diabetes mellitus of type i and ii, respectively  <cit> .

prostate cancer is the most common malignancy in men and the second leading cause of male cancer-related deaths in the western world. according to the omim record, prostate cancer has  <dig> validate causing genes. based on these  <dig> known genes and causing genes of textual related phenotypes, we predicted novel causing genes of prostate cancer using our method . as is shown in table  <dig>  the top  <dig> predictions for prostate cancer are tp <dig>  ret and dhcr <dig>  where tp <dig> is an important suppressor involved in several types of cancer  <cit> . according to the iarc tp <dig> mutation database  <cit> , inactivating tp <dig> mutations are detected at frequencies in the range of 10-20% in primary prostate cancer  <cit> . tp <dig> was also predicted as the tops by prince. our second prediction for prostate cancer is ret, which was also found to be overexpressed in high-grade  prostatic intraepithelial neoplasia  and prostate cancer  <cit> . so ret was supposed to play a role in the growth of both benign and neoplastic prostate epithelial cells. another two predicted causing genes, dhcr <dig> and stk <dig>  were also consistent with the literature. specifically, dhcr <dig> is one of androgen receptor-regulated genes implicated in prostate carcinogenesis  <cit> , and stk <dig> was reported to be inactivated in prostate cancer, through mutation analysis of  <dig> known cancer genes in the nci- <dig> cell line set  <cit> .

CONCLUSIONS
in this paper, a diffusion-based method incorporating pairwise similarities of phenotypes was proposed to prioritize candidate disease genes. the novelty of our method lies in the incorporation of disease phenotypes  from the literature to the initial state of the rwr, and the usage of global similarity between diffusion profiles of disease and genes. diffusion profiles of diseases and genes are obtained by walking over the protein-protein interaction network under a given initial distribution, where the initial distribution of a disease was weighted by omim phenotype similarities exceeding a threshold. then the linear correlation coefficient and cosine of the angle between profiles of a disease and given genes were computed to rank the priorities with the disease. leave-one-out cross-validation on a benchmark dataset showed that our method achieved a higher precision  than existing diffusion-based methods. this result suggests that the proposed algorithm effectively captures the interplay between gene network and phenotype network. we finally predicted causing genes of  <dig> multifactorial diseases including prostate cancer and alzheimer's disease using our algorithm and found that parts of our predictions are in good accordance with current experimental reports.

the superior performance of our method was attributed to the following aspects. first, integration of multiple information sources, especially the phenotype similarity profile data. second, global similarity measures  between diffusion profiles of diseases and genes are introduced to prioritize candidate disease genes. in contrast to previous methods that prioritize candidate disease genes through comparing their corresponding components in the diffusion profile of a disease, our global-based method could take into consideration the distribution values of other genes in the ppi network,

consequently, in the future work, we can integrate some other genomic information to further improve our method, such as gene expression data, functional annotations, pathway membership and so on. moreover, many researchers pointed out that some diseases might be attributed to a certain protein complexes composed by multiple proteins or a certain pathways. so furthermore attention should be paid on elucidating associations between diseases and protein complexes or pathways.

competing interests
the authors declare that they have no competing interests.

authors' contributions
jz conceived of the algorithm and drafted the manuscript. yfq participated in the algorithm design and the analysis of the data. tgl carried out the programming. xqz and jw were responsible for the overall design and coordination and helped to revise the manuscript. all authors read and approved the final manuscript.

