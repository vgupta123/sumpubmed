BACKGROUND
single nucleotide polymorphisms  are single base pair differences between individuals in a population. the recent completion of the human genome project has helped facilitate the discovery of millions of snps and their use in genetic association studies for human disease  <cit> . association studies work on the premise that snp genotypes are correlated with a disease phenotype. individual snps are genotyped and the frequency of alleles are compared between groups of affected and un-affected individuals. snps that are tested for association either must be the causative allele or be in linkage disequilibrium  with the causative allele. ld is the non-random association of alleles between adjacent loci  <cit> . snps that are in ld with causative allele serve as a proxy and the association with the disease phenotype is maintained.

numerous studies have shown that the human genome contains regions of high ld with low haplotype diversity  <cit> . these regions are called haplotype blocks. the existence of haplotype blocks reduces the number of snps required in association studies by identifying and typing only the subset of tag snps which uniquely identify common haplotypes present in a block. the frequencies of these haplotypes can be compared in groups of affected and unaffected individuals  <cit> .

haplotype blocks are defined computationally by various algorithms and can be classified into three categories: diversity based  <cit> , ld-based  <cit> , and information-theoretic  <cit> . patil et al.  <cit>  used a diversity based greedy algorithm to partition chromosome  <dig> into haplotype blocks in a sample of  <dig> re-sequenced chromosomes. their algorithm considers all blocks of consecutive snps of one snp or larger, and defines a haplotype block boundary where at least 80% of observed haplotypes within a block are represented at least one or more times in their sample of chromosomes. overlapping block boundaries were eliminated by choosing the block with the maximum ratio of snps in the block to the number of snps required to discriminate all haplotypes represented in the block. the process was repeated until the entire length of the chromosome was partitioned into haplotype blocks. zhang et al.  <cit>  subsequently provided a dynamic programming implementation for this approach in their software hapblock  <cit> .

gabriel et al.  <cit>  used a ld-based algorithm to define haplotype blocks in a worldwide sample of chromosomes from africa, asia, and europe. the authors computed confidence bounds of the value of d', a standard measurement of ld  <cit> , and defined pairs of snps to be in strong ld  if the one-sided 95% d' confidence bound is between  <dig>  and  <dig> . the authors defined a haplotype block if least 95% of pairwise snp comparisons in a region show little evidence of recombination based upon their d' confidence bounds. the program haploview  <cit>  implements this method of gabriel et al.

anderson and novembre  <cit>  use the minimum description length  principle for defining haplotype blocks which incorporates ld decay between blocks and haplotype diversity within blocks  <cit> . the mdl principle is an application of information theory to statistical modeling which searches for patterns in data  <cit> . the description length of a data set is a function of the length with which data can be encoded in binary digits, or bits  <cit> . the best set of block boundaries defined by anderson and novembre's method is the set of block boundaries that has the shortest description length for a set of snp genotypes that span a genomic region. the authors use a dynamic programming algorithm they call the iterative dynamic programming algorithm  and a faster, but approximate, dynamic programming algorithm called iterative approximate dynamic programming algorithm  to find the minimum description length for a set of haplotypes. their method is implemented in the program mdblocks  <cit> .

previous studies on the empirical performance of block partitioning methods have focused on data sets with differing minor allele frequency cutoffs. the studies of daly et al.  <cit> , patil et al.  <cit> , and gabriel et al.  <cit>  used minor allele frequency cutoffs of 5%, 10%, and 20%, respectfully. schulze et al.  <cit>  assessed the effects of varying the minor allele frequency cutoff on the number of blocks and tag snps inferred by the ld based method of gabriel et al.  <cit>  and diversity based method of zhang et al.  <cit> . as rarer snps were removed and the allele frequency cutoff raised, the number of blocks inferred decreased for both methods, showing that the block structure is highly influenced by the allele frequency of snps used in their analysis.

ke et al.  <cit>  studied the impact of snp density on block boundaries from three different partitioning algorithms: the previously discussed ld approach of gabriel et al., the four-gamete test  <cit> , and a d' threshold approach of phillips et al  <cit> . the author's study genotyped over  <dig> snps in a  <dig> mb region of chromosome  <dig> in four different populations: ceph families, u.k. caucasians, african americans, and east asians. block boundaries of the algorithms were assessed with differing marker densities starting at  <dig> kb and going to  <dig> kb. their results show that longer blocks at sparser densities are broken into smaller blocks as more snps are added in. other studies describing the ld block structure of the human genome also used varying marker densities. the study by phillips et al.  <cit>  on chromosome  <dig> used an average marker density of one snp per  <dig>  kb with a median value of  <dig>  kb. gabriel et al.  <cit>  used an average density of one snp every  <dig> kb. daly et al.  <cit>  used a density of one marker approximately every  <dig> kb. patil et al.  <cit>  used a higher density of snps with one snp every  <dig>  kb. this study was also the only one that completely re-sequenced the entire chromosome for all  <dig> samples.

the ideal data set to fully assess the performance of block partitioning algorithms would be a comprehensively re-sequenced large genomic region in a large number of independent chromosomes. unfortunately, such data are not available at this time. only a limited number of samples have been re-sequenced extensively. in addition to the study by patil et al., as of june  <dig> the seattlesnps  <cit>  data set has re-sequenced  <dig> human genes in  <dig> african-american and  <dig> european ceph samples spanning a total of  <dig> kb of sequence. the encode project  <cit>  intends to re-sequence five  <dig> kb genomic regions in the  <dig> individuals of the hapmap consortium data set  <cit> .

therefore, to fully assess the performance of block partitioning algorithms we generated three populations consisting of  <dig> haplotypes using the coalescent, a stochastic technique that simulates the genetic history of a sample of chromosomes  <cit> . haplotypes representing a  <dig> kb chromosomal region for three world populations – european, african american, and east asian – were simulated using an implementation of the coalescent that uses a population-specific demographic history. the population specific profiles we used were previously published in marth et al.  <cit> , where the authors derive a closed mathematical formula for computing the allele frequency spectrum for a specified demographic profile. the demographic profiles for each of the populations were derived by computing allele frequency spectra predicted by marth's equation for numerous demographic scenarios and testing the fit between it and the observed spectra from the snp consortium data set  <cit>  for each respective population.

in the study presented here, we partitioned our coalescent-derived haplotypes into blocks using the three algorithms described above . we assessed algorithm differences in number, size, and coverage of blocks under different values of marker density, allele frequency, and sample size on the performance of block partitioning algorithms. our results show a great divergence in haplotype blocks predicted by each method, and supports the notion that it may be advisable to use multiple algorithms in parallel to comprehensively account for all haplotype blocks in the human genome.

RESULTS
data simulation and block partitioning
one thousand haplotypes representing a  <dig> kb region were generated via the standard coalescent with population specific demographic profiles for three world populations: european, african american, and east asian. all datasets were analyzed with the three block partitioning algorithms described in the methods section.

in addition to the complete dataset of  <dig> haplotypes,  <dig> bootstrap sub-sample replicates of  <dig> or  <dig> haplotypes were sampled and filtered for different snp density  and minor allele frequency  cutoff values . each bootstrap replicate was partitioned using three methods . computer memory constraints prevented mdblocks from partitioning all  <dig> chromosomes using all snps for each coalescent-derived population. for the same reason we were only able to analyze  <dig> bootstrap subsamples of  <dig> or  <dig> chromosomes with mdblocks. more details on coalescent simulations and bootstrap sampling is given in the methods section of the paper.

european population partitions using all chromosomes
all  <dig> european chromosomes were analyzed with hapblock and gabriel's method. there were  <dig> polymorphic sites with an average snp density of one snp per  <dig> bp. figure  <dig> displays the resulting block partitions using all snps from the two methods, with the hapblock partition denoted as hb and gabriel's method denoted as ga. table  <dig> displays descriptive statistics for the hapblock and gabriel's method population partitions. no matching block boundaries existed between hapblock and gabriel's method. hapblock inferred a larger number of blocks of smaller physical length than gabriel's method, but 74% of the sequence was common to blocks inferred by both methods. both algorithms gave similiar values of coverage, which is defined as sum of the physical haplotype block lengths in base pairs divided by total length of region  <cit> , with values of  <dig> % for hapblock and  <dig> % for gabriel's method, respectively.

when analyzing all chromosomes using only snps with a maf of 10% or greater, the total number of markers was reduced to  <dig> with an average of one snp every  <dig> bp. table  <dig> also shows descriptive statistics using only snps with a maf of 10% or higher. the number of inferred blocks for hapblock dropped dramatically from  <dig> to  <dig>  for gabriel's method the change was not as large, with  <dig> blocks inferred. mdblocks inferred  <dig> blocks which had the largest physical size. hapblock, gabriel's method, and mdblocks covered  <dig> %,  <dig> %, and  <dig> % of the  <dig> kb region in blocks. hapblock again inferred a greater number of blocks of smaller size when compared to the other two methods. of each possible pair of partitions, only gabriel's method and mdblocks contained one set of matching boundaries. still, a large fraction of sequence, 57%, was common to all three partitions. table  <dig> shows percentage of total sequence common to all population block partitions with this population and condition, as well as other populations examined in this study. figure  <dig> shows the population partitions for all three methods using only snps with at least a maf 10%, and block regions common for all three algorithms.

next, we compared the population partitions of hapblock and gabriel's method using all markers vs. all markers with a maf of at least 10%. for hapblock, 46% of the blocks inferred with snps with the higher maf were broken up with the addition of rarer markers however,  <dig> % of the chromosome is common to both partitions. for gabriel's method 73% of the sequence is common to partitions resulting from the two differing allele frequency conditions. only 3% of gabriel's method blocks were broken into smaller markers with the additon of rarer snps.

african american population partitions using all chromosomes
a total of of  <dig> polymorphic sites with an average density of one snp every  <dig> bp defined the  <dig> haplotypes in our sample. table  <dig> contains descriptive statistics for hapblock and gabriel's method partitions using all snps. hapblock identified  <dig> blocks while gabriel's method identified  <dig>  figure  <dig> displays the hapblock and gabriel's method population partitions using all snps. gabriel's method resulted in a slightly larger sequence coverage of  <dig> % compared with 85% for hapblock. hapblock identified a larger number of blocks of smaller size, however 76%, of the sequence was common to both partitions with no exact matching boundaries between them.

using only snps with a frequency of at least 10% resulted in a total of  <dig> markers with an average spacing of one snp every  <dig> bp. table  <dig> also displays descriptive statistics for these block partitions. the number of blocks inferred by hapblock dropped sharply to  <dig>  for gabriel's method the difference was smaller with a total of  <dig> blocks inferred. mdblocks inferred the smallest number of blocks with  <dig>  but had the largest average size. percent coverage dropped for hapblock and gabriel's method to  <dig> % and 80%, respectively. mdblocks still included 90% of the region in blocks. when comparing all the partitions, 60% of the  <dig> kb region was common to blocks inferred by all three methods . hapblock and gabriel's method shared two matching boundaries, and hapblock and mdblocks shared one matching boundary. figure  <dig> displays all three block partitions and shared block regions between each partition. comparing the hapblock and gabriel partitions with the full marker set to the corresponding partition of the same method with rarer snps filtered out shows that there were common regions identified in both. for hapblock 67% of the  <dig> kb region was common to blocks for both conditions. for gabriel's method 74% of the sequence is included in both partitions.

east asian population partitions using all chromosomes
a total of  <dig> snps with an average spacing of one snp every  <dig> bp defined the  <dig> asian haplotypes. table  <dig> shows descriptive statistics for hapblock and gabriel partitions. hapblock identified  <dig> blocks, gabriel's method inferred  <dig>  and 70% of the chromosome was common to block regions inferred by both methods. no matching boundaries existed between the two partitions. figure  <dig> shows hapblock and gabriel's method block partitions. the hapblock partition inferred a larger number of blocks of smaller size. coverage values for hapblock and gabriel's method were  <dig> % and  <dig> %, respectively.

removing rarer snps and using only markers with a maf of 10% or higher left  <dig> markers. there was a sharp drop in the number of blocks inferred by hapblock with  <dig> blocks compared to  <dig> when using the full marker set. gabriel's method inferred  <dig> blocks. mdblocks inferred the fewest with  <dig>  none of the partitions shared the same set of snps for a block boundary. table  <dig> shows descriptive statistics for the resulting block partitions. the amount of sequence coverage drops for two of the methods: 74% for hapblock and  <dig> % for gabriel's method. coverage for mdblocks remains at 90%. the shared block regions between all three methods shown in figure  <dig> account for 46% of the chromosomal region.

population partitions at other conditions
descriptive statistics for population partitions of each method at other density and maf conditions are shown in additional file  <dig> 

bootstrap partitions using all markers with frequency of ≥10%
to assess variation in block structure on more realistic sample sizes  we bootstrap subsampled  <dig> or  <dig> chromosomes from our original set  <dig> times. figure  <dig> shows the block partitions resulting from hapblock for the first  <dig> individual bootstrap subsamples of size  <dig> using all snps with a maf of at least 10%. it was clearly evident that the block structure varied between the bootstrap subsamples and the population partition. to find snps that were consistently inferred together in blocks above a threshold frequency across all bootstrap subsamples we defined consensus block partitions for hapblock for threshold values from  <dig> to  <dig> percent.  as the threshold for defining a consensus block is lowered, the physical length of a block increases monotonically and blocks defined at higher thresholds are combined. table  <dig> shows the percentage of chromosomal region common to both the population partition and consensus block partitions of hapblock using only snps with a maf of at least 10%.

gabriel's method and mdblocks partitions also showed within population variation in block structure.  table  <dig> also contains the percentage of total sequence common between the population partitions of gabriel's method and mdblocks, and each consensus block definition. similar to the hapblock results as the threshold for defining a consensus block is lowered, the amount block regions common to both partitions increased. of the three methods, mdblocks consensus blocks had the greatest amount of total sequence in common with the population partition. table  <dig> shows the percentage total sequence common to all three consensus block definitions at each threshold value. figure  <dig> displays consensus blocks from each algorithm defined at a 80% threshold, and block regions common to all three consensus blocks. while these common block regions cover only 40% of the  <dig> kb region in blocks, it was encouraging to find that our consenus block partitions overlapped.

figures  <dig> and  <dig> show the average number of blocks and base pairs per blocks of each partitioning algorithm tested for european haplotype bootstrap subsample sizes of  <dig> and  <dig> chromosomes for other density and maf conditions. there is an inverse relationship between the number of blocks inferred and their average size in base pairs per blocks as snp density increased. coverage generally increased with an increased density of snps .

similar patterns for african american and east asian bootstraps were found. variation in block structure between bootstrap samples existed. the same pattern of an inverse relationship between the number of blocks and their average size as snp density increased, remained. as the threshold for a consensus block is lowered, the percentage of sequence common between the population block partition increased monotonically. also as the threshold is lowered, there is a greater percentage of total sequence common to all consensus blocks defined from each method. .

discussion
we generated three populations of haplotypes via coalescent simulations to assess the performance of three block partitioning algorithms under different marker density and allele frequency conditions. each of the block algorithms employed in this study partitions a genomic region into haplotype blocks using vastly different approaches. in addition to the three algorithms described here, there are other definitions for haplotype blocks not examined  <cit> . despite all these algorithms, there is no widely accepted definition of how to best define haplotype blocks  <cit> .

the descriptive statistics of each population block partition using all  <dig> chromosomes clearly show that results are different in number, size, and coverage of inferred blocks, particularly with a higher density of markers. hapblock generally inferred the largest number of blocks of smallest size and mdblocks inferred the fewest number of blocks of largest size. while there are few exact matching block boundaries between different partitions, there is a large amount of common block regions between them. increasing the density of markers had a more dramatic effect on the percent coverage for gabriel's method than the other two methods due to fact that ld patterns are sensitive to marker density and can change with the addition of more markers  <cit> . the amount of coverage, in turn, influences the percentage of total sequence common to all partitions since there is a greater chance of overlap between them.

to assess within population variation in block structure we bootstrap subsampled haplotypes of sizes  <dig> or  <dig> chromosomes. the descriptive statistics of the bootstrap partitions indicate that the number of inferred blocks increases as a higher density of markers is used. also, the average number of base pairs per blocks decreases with a higher density of markers, hence there is an inverse relationship between the number of blocks inferred and their physical size. removing rarer snps does not necessarily decrease the number of blocks inferred for each of the methods when conditioning on a density value. this result is in contrast to the results of schulze et al.  <cit> , who found that removing rarer snps decreased the number of blocks inferred by the hapblock and gabriel's method. this maybe a result of the stochastic nature of the coalescent. to get a clearer picture of the effect of allele frequency on the performance of block partitioning algorithms, it may require the simulation of many more genealogies.

our consensus block definitions attempt to identify snps consistently inferred together in blocks across all bootstrap replicates. the amount of common block regions between the population partition and consensus block definitions from bootstrap samples depends heavily on the threshold to define a consensus block, as well as the percent coverage of the bootstrap and population partitions. if a significant proportion of the chromosome is inferred in blocks in both the population and consensus definitions, there is a greater chance of finding common block regions. however as discussed earlier, this attribute is influenced by snp density and allele frequency of markers.

for gabriel's method, the number, size, and coverage of inferred blocks varied dramatically between the bootstrap samples and population partitions. the average number of blocks inferred from gabriel's method for bootstrap samples of size  <dig> and  <dig> of european haplotypes, using all markers with a maf of at least 10% was  <dig>  and  <dig> , respectively. on average  <dig> % and  <dig> % of the  <dig> kb region were inferred in blocks. these numbers differ from the population partition numbers of  <dig> blocks and  <dig> %. these disparate numbers illustrate the effect sample size has on estimating confidence bounds of d'. this also explains the fact that in certain bootstrap samples, gabriel's method failed to infer any blocks. the percent overlap between the consensus blocks defined from bootstrap samples of size  <dig> and the population partition never exceed 16%, even at the most liberal consensus threshold of 50%. for consensus blocks defined from bootstrap sample sizes of  <dig>  the percent intersection with the population partition is 53% even at the fairly high threshold of 80%. for hapblock and mdblocks, differences between average coverage values from the bootstrap experiments to the population partition are not as large, and they showed a larger percentage of sequence intersection between the consensus blocks.

comparing the consensus blocks for one method to the population partition of the same method addresses the block structure variation within a particular algorithm. to find common block regions in bootstrap subsamples from differing algorithms, we found the overlapping boundaries between consensus block regions from each algorithm. for certain density, maf conditions, and consensus block thresholds, there was very low or non-existent overlap. these numbers can be severely reduced if a particular method fails to infer a large number of blocks covering a significant portion of sequence, as was the case for gabriel's method at the sparsest marker density of  <dig> kb. when using all snps with a 10% maf for european haplotypes, the percentage overlap between all consensus blocks ranges from 9–57% depending on the consensus threshold. finding block regions common to all three methods is an encouraging sign because each algorithm takes a different approach to the block partitioning problem. if the haplotype block paradigm is an accurate description of underlying ld patterns of the human genome, different algorithms should find common block regions since the three methods base their algorithms on various attributes of the paradigm.

rather than searching for exact matching boundaries using schwartz concordance test statistic as a measure of block concordance  <cit> , we chose to compute the percentage of common block regions between two different block partitions as our metric of concordance. while using the block concordance test statistic is a valid approach, the method cannot assess the significance of block boundaries which may differ by few snps, but still have a significant degree of overlap between block regions. there was only one matching boundary between each possible of pair of partitions using all  <dig> european haplotypes using all snps with a maf of 10%. however, 57% of the  <dig> kb region was common to blocks defined from all three methods.

in our analysis we focused on the number, size, and coverage of haplotype blocks inferred by three different algorithms. we do not discuss tag snps identification because we view it as a separate problem. however, it should be pointed out that the dynamic programming approach of hapblock is closely tied to tag snps because it defines blocks which minimize the number of snps needed to distinguish common haplotypes within a block. recently, a method formulated by halldorsson et al.  <cit>  selects tag snps which does not require a haplotype block definition. also, the tag snp algorithm ldselect  <cit>  chooses tag snps independent of chosen haplotype block boundaries.

another point to address in our study design is that the simulated haplotypes used were derived from a single realization of a coalescent simulation, hence our study does not address genetic sampling  <cit> . since we bootstrap subsampled  <dig> or  <dig> individuals from a population of  <dig>  we fix the genetic history of our data set and focus on the statistical sampling on the performance of block partitioning algorithms used in this study. we also chose not to vary recombination rate or incorporate recombination hotspots in our simulations since we only analyzed a  <dig> kb region. due to these limitations, we did not compare populations to each other. rather, we examined the trends seen in each population and used coalescent simulations with three different population histories to ensure that the results from the three block partitioning algorithms were not due to the coalescent parameters chosen. the recent study of ding et al.  <cit>  address the affects of population genetic parameters, such as the mutation and recombination rate, on the diversity and ld based algorithms discussed here for multiple realizations of coalescent genealogies.

CONCLUSIONS
in summary, our results show that for the population partitions using all  <dig> chromosomes, there is a varied range of number, size, and coverage of blocks between the different methods. the percentage total sequence common to all three partitioning algorithms ranges from 3–61% depending on the population and is generally higher using a high density of snps with a wide range of maf. bootstrap sampling of haplotypes from the population shows there is within population variation in block structure for all three methods. our consensus block definition attempts to define blocks based on sets of snps consistently found together in blocks across all bootstrap replicates. using a higher density of markers there is an increased percentage of total sequence in common with consensus blocks and population partitions. the percentage of common block regions between consensus blocks defined from all three methods is influenced by the percent coverage of individual partitions, which itself is influenced by the density and allele frequency of markers that comprise the haplotypes to be partitioned. it is evident that each algorithm gave a different picture of haplotype block structure at differing density and maf values and few, if any exactly matching block boundaries existed. an open question that remains is how best to merge or integrate block definitions from different algorithms. for empirical studies, it is advisable to subject collected data to a variety of block algorithms and identify common block regions. if distinct partitioning algorithms show a large portion of overlap in inferred block regions, then these genomic regions can be investigated further to identify genetic variants causing disease.

