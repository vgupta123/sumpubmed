BACKGROUND
automation technologies developed during the last several years have enabled the use of flow cytometry  to generate large, complex data sets in both basic and clinical research applications  <cit> . a serious bottleneck in the interpretation of existing studies and the application of high throughput fcm to even larger, more complex problems is that data management and data analysis methods have not advanced sufficiently far from the methods developed for applications of fcm to small-scale, tube-based studies  <cit> . in particular, the data often need to be organized into groups of samples based on combinations of additional covariates and similar operations need to be applied to these groups in a transparent and reproducible manner. furthermore, the growing depth of knowledge in the field of immunology, for instance the characterization of distinct human t-cell sub-population  <cit> , clearly argues for more systematic approaches.

some of the consequences of the lag of efficient software solutions are difficulties in maintaining the integrity and documentation of large data sets, assessing measurement quality, developing validated assays, controlling the accuracy of gating techniques, automating complex gating strategies, and aggregating statistical results across large study sets for further analysis. in addition, new analysis approaches face difficulty in finding their way into standard practice. we believe that these barriers to the development and dissemination of new analysis methods is one of the fundamental restraints on the future expansion of fc-hcs in both clinical and research applications.

traditionally, for the majority, fcm experiments were being analyzed by manual data inspection in one or two dimensions, or by very basic comparisons of summary statistics. most of the currently available analysis tools are designed to reflect this work flow. we believe that these approaches, in addition to being expensive and labor intensive, do not fully address the highly complex nature of fcm data; in particular, they disregard many of the fundamental aspects of the data, such as sample groups or cohorts, the underlying distribution or its high-dimensional nature. furthermore, the subjective character of manual analyses are a major obstacle to reproducibility. in a recent study of flow cytometric standardization involving  <dig> institutions, the mean inter-laboratory coefficient of variation ranged from  <dig> to 44%, even though preparation was standardized and performed using the same samples and reagents at each site  <cit> . for fc-hcs data, unassisted manual inspection is extremely time consuming, and robust statistical methods need to be developed to point investigators to interesting aspects of the data, or to potential problems. while the expert knowledge of immunologists and researchers remains crucial for the understanding of fcm data, we believe that collaboration with other research fields such as statistics and computer science can greatly improve the relevance of fcm in today's high-throughput paradigm. in this paper, we describe a set of flexible and well structured computational tools to efficiently analyze fc-hcs data. our intent is to provide a shared research platform that enables bioinformaticians, computer scientists, and statisticians to work collaboratively with biologists and clinicians to develop novel methods for fcm data analysis, a process deemed crucial by many for the further development of the technology  <cit> .

implementation
the computational tools we have developed are distributed in the r software language  <cit>  as the bioconductor  <cit>  package flowcore. the package flowcore is a freely available, highly functional, and extensible fcm data analysis platform that enables researchers to efficiently handle fc-hcs data and encourages open development of tools for their coherent analysis. in our implementation of flowcore we rely on two important lessons learned from the field of gene expression data analysis: the first being the importance of data structures that reflect the underlying data and facilitate the manipulations that are of most interest, while the second is the importance of a modular architecture that allows for many developers to extend and use the underlying infrastructure and to combine tools in complex work flows. flowcore implements such computationally efficient data structures and a range of specialized methods addressing all components of a typical fcm analysis work flow, including compensation, transformation, and gating. flowcore runs on windows, mac os x, and linux/unix operating systems.

existing data standards and conventions
currently, data from fcm experiments are stored in single files according to the flow cytometry standard   <cit> . however, recent developments in high-throughput fcm are shifting the focus of interest away from single-tube based measurements towards large and complex experimental designs with dozens of covariates and influencing factors. for example, experiments consist of large numbers of samples from different patients, measured at different time points  <cit>  or following different drug treatments  <cit> . modern fcm data analysis tools have to deal with an additional layer of sample metadata and they need to provide infrastructure to process and to compare groups of samples in a concise and coordinated manner. the notion of classes from an object-oriented programming language provides one coherent way to describe these richer data structures. in addition, functions or methods that work on those classes allow for interaction and manipulation. many of the currently available software solutions offer only limited support for such self-contained structures, or make use of binary storage containers that are designed specifically for the needs of particular user interfaces and hence are not easily amenable to programmatical access. in addition, the closed-source nature of these products often makes them impractical to integrate into analysis pipelines. in this manuscript we describe classes for fcm data analysis and their implementation in r, however, they could just as easily be implemented in any other language . software written in those languages could use similar data structures, thereby simplifying communication and the interchange of data between analysis tools.

flowcore does not provide a graphical user interface and all operations are done using a command line interface. it is possible to add a more elaborate user interface on top of this infrastructure, however the focus in this paper is on a programmatic approach to enable the convenient development of novel analysis methods and automation of complex analysis approaches. by taking the burden of data management from the programmer, and by providing well-defined application programming interfaces , it is possible to readily test new ideas and to easily extend the framework's functionality.

the flowcore framework presented here can import and process raw data fcs files along with their complete set of file-specific metadata . moreover, it is a software implementation of the gating markup language candidate recommendation, an emerging standard developed in collaboration with the international society for analytical cytology  data standards task force, which makes it possible to integrate flowcore in existing work flows and to communicate with any other fcm tool that adheres to the proposed standard  <cit> . adherence to standards also plays a critical role in the ability of new methods based on flowcore to find their way back into the standard practices for fcm data analysis.

basic data structures
flowframe: sample unit
flowcore's primary task is the representation and basic manipulation of fcm data. this is accomplished through a data model very close to that adopted by other successful bioconductor packages. all information from a single fcs file, i.e., the collection of events and the accompanying metadata, is stored in one single container. we call the structure that hold this data a flowframe . raw data values as well as associated metadata of a flowframe can be accessed programmatically. most commonly, the metadata consist of descriptors of the stains used in the experiment and the respective measurement channels, information about compensation performed at the instrument side and any additional keywords the user deems to be important to annotate the data. during the creation of a flowframe, a number of quality checks are performed to ensure data integrity.

flowset: a collection of flowframes
in high-throughput fcm, many of the analysis tasks need to be performed consistently across multiple samples, hence we introduce the concept of a collection of flowframes called a flowset . a flowset is a container for multiple flowframes along with relevant information associated with each individual frame such as descriptions of the cell sample, the treatment to which the sample was subjected, or the location of that sample in a microtitre plate. the objects are self-contained and can be shipped to other computers, platform independently. flowsets manage the consistent application of operations on the individual flowframes and shift the burden of keeping score of the metadata from the user to the infrastructure, thus reducing the risk of errors . crucial operations like taking subsets, data transformations and gating, or computation of summary statistics are greatly facilitated and all relevant annotation information is constantly passed on along the analysis pipeline. the flowset structure can be readily extended to incorporate the potentially complex metadata associated with even larger fc-hcs experiments such as clinical trials, where hundreds of patients might provide samples at different time points over the course of the experiment. the flowset data structure is one of the key features in the flowcore package and it is fundamental to the implementation of many of the high level functionalities such as quality assessment and control, visualization and automated gating.

standard flow operations
typically, the basic operations in fcm analyses adhere to the following common work flow: the data need to be compensated  and transformed, and sub-populations of interest need to be selected based on a set of  gates. all software solutions for fcm analysis offer support for these operations, most often in an interactive, graphical user interface. in flowcore we have taken the approach to abstractly describe these operations and build a set of tools to perform them on both flowframes and flowsets. typically, the results of these operations are again flowframe or flowset objects. while transformation, and to a certain extent compensation, are fairly routine operations with only limited potential for improvement, being able to implement new methodologies for gating of fcm data, and extend the capabilities of flowcore through object oriented programming are features that clearly sets our framework apart from other fcm analysis tools. by factoring out as much of the bookkeeping as possible, programmers can focus on the actual operations rather then having to deal with the tedious details of data integration and access. third-party methods can act on their own as first-class citizens in the analysis framework, without breaking the work flow or the basic infrastructure. this design allows for the straightforward extension of flowcore's capabilities, and has already fostered the development of a number of valuable add-ons  <cit> .

transformation and compensation
data transformation is essential for both data visualization and modeling  <cit> . the major transformations that are routinely used in fcm analysis have been implemented in flowcore . furthermore, the design of the r language makes it easy to define arbitrary functions to apply to the data of individual flowframes or entire flowsets, respectively. compensation, that corrects for fluorescence spillover originating from the inherent overlap of emission spectra from antibody fluorescent labels, is available for both flowframes and flowsets. in addition, the software offers functionality to compute spillover or compensation matrices from a set of appropriate single stain controls.

within these formulas, x is the variable corresponding to value being transformed, a, b, c, d, f, p, m, t, and w, are constants affecting the transformation function, e is the base of the natural logarithm . other transformations can easily be implemented in r.

gating
in flowcore, gating operations are represented by classes that can be extended in an object-oriented manner . basic gate types such as rectangular gates, ellipses and polygon gates are implemented as part of the framework. in addition, we introduce the notion of data-driven gates, or filters, for which the necessary parameters are computed based on the properties of the underlying data, for instance by modeling data distribution or by density estimation. this approach is fundamentally different from the traditional application of static gating regions across samples, as it is able to take into accounts unforeseen changes in signal intensities, such as drifts in the instrumentation over time or sample variability.

filters are automated, data driven procedures. gates are static, user-defined methods.

the ability to programmatically access gates is a prerequisite for semi-automated or automated gating. by utilizing an unified interface for all different types of gates, the user is able to subset data sets as well as to create summary statistics, as for instance the proportions of events falling in a single gate or in a combination of gates. complex combinations and hierarchies of gates can be captured in multi-step gating strategies. the definition of gates in flowcore follows the gating markup language candidate recommendation  <cit> , thus any flowcore gating strategy can be reproduced by any other software that also adheres to the standard and vice versa.

gating, as well as all other operations in flowcore, can be applied over each individual frame in a flowset, and summary methods provide information about the outcome of these operations. in addition, the result of a gating operation can be used to subset the input flowframe or flowset, either by filtering out negative events or by splitting in multiple sub-populations. this design allows to easily combine all of flowcore's components into complex work flows.

RESULTS
from quality assessment to batch gating
the flowcore package has been successfully applied in the analysis of several data sets, both originating from clinical trials  <cit>  and drug discovery experiments  <cit> . a complete description of the methods implemented in flowcore is beyond the scope of this publication. much more comprehensive documentation and users guide information with programmatic examples are available online , as part of the package distribution. here, we want to briefly exemplify some of the software's key features, that is, the coherent treatment of all samples in a potentially large experiment, the concept of data-driven automated gating, the integration of existing software into the framework, and the generation of publication-quality graphics for data visualization.

data analysis for most experiments usually begins with a quality assurance step. in a fcs analysis work flow, we can use functionality from the flowq package, build upon flowcore, to create an html report that highlights potential quality issues. assuming that the data has already been imported as the flowset object "dat", using for instance the read. flowset method, the following simple lines of code produce the output shown in figure 2:

> library

> qareport)

the report is interactive and provides drill-down to more detailed aspects of the analysis, starting from a concise overview. the design of flowcore's data model allows for a coherent treatment of all the samples, hence we are able to compare features between individuals, or between groups of individuals, based on the available metadata information.

according quality of the measurements, the next steps of a fcs analysis work flow are potentially the compensation and transformation of the data. once again flowcore's data structure and its methods allow a flexible processing. one can use the basic transformation and compensation functions implemented in flowcore  or develop its own approaches that could then be apply to flowframe or flowset. ultimately, a flow cytometry experiment aims at identifying and characterizing cell population of biological interest, using static gating or data-driven procedures . static gating for all samples in a high-throughput fcm experiment is often impossible, since the measured variables tend to vary between different treatments, over time or between different experiment batches. automated or data-driven gating has the potential to estimate the gating regions from the underlying data, thus providing a fast objective solution to the analysis of potentially very large and diverse data sets  <cit> . one of the automated gating methods implemented in flowcore is based on identifying areas of significant curvature in a kernel density estimate of the data  <cit> . assuming that the regions of interest are of high density, the software is able to reliably detect them in a one- or two-dimensional density landscape.

> cf <- curv2filter

> fres <- filter

kernel density estimation is a well-known problem in statistical computing, and a lot of effort has been invested in the development of good software to address it. the modular design of flowcore allows to easily integrate these existing solutions into our framework. in this example, we directly use r code from the feature package  <cit> . instead of re-writing existing code, we are able to include it via the well tested distribution mechanism provided by r's software package system. this process is bi-directional, and all functionalities implemented in flowcore are available to other package authors.

finally, we can chose one of the many visualization options from the flowviz package to plot the results of the recent filtering operation. a very basic matrix of density plots is shown in figure  <dig>  where each panel in the matrix represents the fluorescent measurements of two channels for one individual patient.

> xyplot

scripting languages like r provide a natural representation of work flows through a sequence of code instructions in regular text files. this allows for the rapid development and testing of new ideas, however it is not very well suited for routine data analysis tasks. furthermore, the overhead of data management and variable tracking can be considerable. to that end, flowcore also provides data structures that help organize sequences of typical fcm data analysis operations and complex gating strategies into concise work flows. these structures are self-re effective, they contain all intermediate results and offer a unified user interface to assess the progress and the outcome of an analysis.

related flow packages
in addition to the flowcore package that offers basic infrastructure, we have implemented a range of additional bioconductor packages that are dedicated to more specific tasks of fcm data analysis. as exemplified in the previous section, the flowviz package  <cit>  provides sophisticated data visualization tools, that make use off multivariate trellis plotting  <cit> . these functions can be used to quickly generate customized plots for extended cytometry data sets for both direct data inspection and quality control. the objects metadata information can be used to arrange the layout and composition of the plots.

furthermore, the design and the api of the visualization software is very generic, and users can readily extend its capabilities by providing self-defined plotting functions. the flowq package offers more advanced quality assurance methodology and a framework to create interactive web-based reports of quality assurance results. the flowutil package implements data import and export including flow-cytometry specific standard markup language. finally, the flowstats package provides elaborate statistical methods that are relevant in the context of flow cytometry data analysis.

more recently,  <cit>  have developed an automatic gating approach via robust model-based clustering using flowcore's data model and infrastructure which is implemented in the bioconductor package flowclust. another package, platecore, providing more specialized support for experiments conducted on microtitre plates and facilitating the handling of spatial metadata, is under development.

CONCLUSIONS
through flowcore, we have provided the fcm community with an open source, freely available, highly functional, and standards compliant, development and analysis platform for high throughput data analysis. we hope to foster collaborative development of new analysis methods and to facilitate the transition of these new methods to a larger flow community. our experience has been that such collaborative effort has proven beneficial for a number of different biological and computational biology challenges, greatly elevating their applicability. we hope that our framework will be the foundation for fruitful shared research by many collaborators from multiple scientific fields and will help resolve bottlenecks that currently prevent further development and deployment of fc-hcs to increasingly complex and important scientific and clinical applications.

availability and requirements
project name: flowcore; project home page: ; operating system: a wide variety of unix platforms, windows and macos.; programming language: r; license: the artistic license, version  <dig> .

the flowcore package and its associated packages are part of the r/bioconductor project, an environment for statistical computing and bioinformatics. the r software environment is freely available at . flowcore and its dependencies  are available on the bioconductor project website  as freely distributed and open source software packages with an artistic license. they are fully integrated into the r/bioconductor environment for statistical computing and bioinformatics and run on operating systems windows, mac os x, and unix.

authors' contributions
the project was conceived by rb, rg, ph. it was designed, and developed by all the authors. nlm, fh, ds, and be wrote most of the software's code. the manuscript was prepared by fh and nlm, then revised and approved by all authors.

