BACKGROUND
the major goal of functional genomics is screening genes that determine specific cellular phenotypes  and modeling their activities in such a way that normal and abnormal behaviors can be differentiated. the pragmatic manifestation of the above goal is developing therapies based on the disruption or mitigation of aberrant gene function contributing to the pathology of certain disease. mitigation would be accomplished by the use of drugs to act on the gene products. there are three things involved in engineering therapeutic tools, namely, synthesizing nonlinear dynamical networks, characterizing gene regulation and developing intervention strategies to modify dynamical behavior. in this paper, we introduce a new optimization finite-horizon control problem with multiple hard-constraints. first we review some models for studying genetic regulatory networks, boolean networks  and probabilistic boolean networks . a brief review of intervention strategies is also given. we then introduce our mathematical formulation of the problem and the reserving place algorithm. the upper bound for the computational cost is also estimated. we report the results of computational experiments for different genetic regulatory networks by reserving place algorithm and  the genetic algorithm. finally, conclusions are given at the end of the paper.

a review on boolean networks  and probabilistic boolean networks 
in computational systems biology, building mathematical models and efficient numerical algorithms to study regulatory interactions among dna, rna, proteins and small molecules are important issues  <cit> . there have been many mathematical models proposed to study genetic regulatory networks such as boolean networks   <cit> , regression model  <cit> , probabilistic boolean networks  <cit>  and reviews on other mathematical models can be found in  <cit> .

among these models, bns and its extension pbns have received much attention as they can capture the switching behavior of the biological process  <cit> . boolean networks  are introduced by kauffman  <cit> . in a bn, each gene i is regarded as a vertex in the network and the gene expression state at time t is quantized to two levels: on and off . a bn consists of a set of genes {v <dig> v <dig>  …, vn} and a set of boolean functions {f <dig>  f <dig>  …, fn}. the boolean function fi : { <dig> }n → { <dig> } represents the rules of the regulatory interactions among the genes: vi = fi), i =  <dig>   <dig>  … ,n. here v = , …,vn)t is called the gene activity profile . the gap can take any possible form from the set s = {τ : vi ∈ { <dig> }}, thus totally there are 2n possible states. a bn is indeed a deterministic model and the only randomness comes from its initial state. given an initial state, the bn will eventually enter into a set of state called the attractor cycle and stays there forever  <cit> . the attractors have biological significance such as states of cell proliferation or cell apoptosis  <cit> . 

however, genetic regulation process exhibits uncertainty and microarray data sets used to infer the model have errors due to experimental noise in the complex measurement process. thus it is more realistic to consider stochastic models. to extend bns to pbns, the main idea is as follows. to determine vi the state of gene i , there can be more than one boolean functions  to be chosen. here  is the total number of possible boolean functions for gene i. the probability of choosing  as the predictor function is , where  and  one can estimate the probability  by the method coefficient of determination  with real gene expression data sets  <cit> . there are at most  different possible realizations of bns. in an independent pbn, the selection of the boolean function for each gene is assumed to be independent, the probability of choosing the corresponding j th bn is given by  in fact, the transition probability matrix a can be written as the sum of the boolean network matrices  where  <dig> ≤ qi ≤  <dig>  and  given a pbn, assuming that the underlying markov chain is irreducible, its long-run behavior is characterized by its steady-state probability distribution  <cit> .

review of intervention strategies
intervention strategies are applied to drive the whole genetic network into a desirable steady-state probability distribution. the intervention studies used three different approaches:  resetting the state of the pbn to a more desirable initial state and letting the network evolve from there,  changing the steady-state behavior of the genetic network by minimally altering the rule-based structure and  manipulating external control variables which alter the transition probabilities of the network and therefore desirably affect the dynamic evolution. in  <cit> , the potential effect of individual gene on the global dynamical network behavior is studied, by means of random gene perturbation and intervention. a model for random gene perturbation is given and a formula for the transition probabilities in the pbn model with perturbation is also provided. the effects of deliberately affecting a particular gene by means of intervention are also studied. a methodology for altering the steady-state probabilities of certain states or sets of states with minimal modification to the underlying rule-based structure is developed in  <cit> . in  <cit> , an optimal finite-horizon control problem for gene intervention is formulated as a minimization problem with penalty costs. the penalty costs include both control cost and cost of the terminal states. the control cost is defined as the cost of applying control inputs in some particular states. relatively higher terminal costs are assigned to those undesirable states. other control problems such as imperfect information, context-sensitive pbn and infinite-horizon control are discussed in  <cit>  separately. in  <cit> , an algorithm is proposed to study the problem of controlling a gene network  such that it reaches a target state set with a prescribed maximum or minimum probability.

our contribution
all the above optimal control formulations did not consider the realistic hard constraints that the number of times of applying controls are bounded. in case of disease such as cancer, control inputs can be medication or radiation, etc. they are typically applied during a time period. certain treatments such as radiation can not be applied too many times. the study in  <cit>  fills the blank by studying an optimal finite-horizon problem with such hard-constraint. it discusses the problem with only one control variable. observing that usually there are multiple treatment methods applied together, we study a finite-horizon external control problem with multiple hard-constraints. our objective is to minimize the cost of control strategy over certain time period. beside setting the upper boundaries for the number of times each control method applied, we adopt the idea that the network should fall into a desirable state set with a prescribed minimum or maximum probability from  <cit> . apart from introducing the finite-horizon control problem with multiple hard-constraints, we provide an algorithm, the reserving place algorithm, to generate all optimal control strategy . as the problems proposed in our paper and in  <cit>  are both for a fixed time interval say t, the optimal control strategy is the sequence of control actions of length t. in  <cit> , the authors start from set { <dig> } which is the possible control strategies at time t =  <dig> and check if the hard-constrain is met, and recursively find those control sequences of length t meeting the constraint on the number of applied times. our algorithm directly focus on control strategies of length t. moreover the constraints of the numbers of times that each control method can be applied is involved in the generation of control strategies. besides the optimal control strategy, given a fixed number of times that certain control method is applied, the algorithm can provide all the optimal control sequences. we remark that our proposed formulation can be applied to both perturbed and context-sensitive pbns, though we only discuss examples of instantaneously random pbns.

methods
we first give some necessary notations to introduce the mathematical formulation of our optimization control problem. we then describe an algorithm, the reserving place algorithm, for obtaining all the optimal solutions. the upper bound of computational cost is also estimated. based on this, the drawbacks of the reserving place algorithm is stated and we apply the genetic algorithm to networks of large size. here we study an optimization control problem with multiple hard-constraints. our goal is to find an optimal strategy for manipulating external control variables to desirably affect the dynamic evolution of a random pbn over a finite time horizon with minimum corresponding cost. without loss of generality, here we only consider two control methods. at each time point t , one of the following three control options will be conducted: control  <dig> , control  <dig> and control  <dig>  represented by u <dig>  u <dig> and u <dig>  their corresponding transition probability matrices p <dig>  p <dig>  p <dig> are given. the optimal control problem can be stated as follows. given an initial probability distribution x <dig> = , …,vn)t and a set of target states s′ ⊆ s, our goal is to find a sequence of actions σ over a finite time horizon t that leads the system reaching a target state with a minimum probability  is the state of gene i at time t) while minimizing the sum of the costs of the control actions applied at each time point  thus we obtain the following optimization control problem:

   

here si is the number of times that control i is conducted, and ki is the maximum number of times that control i can be applied, i =  <dig>   <dig>  we use ij ∈ { <dig> , 2} to represent that control ij is applied to the network at time j. then the control string i1i <dig> …, ik represents the control actions conducted from time  <dig> to time k. we define set u = {σ = i1i <dig> … it : ij ∈ { <dig> , 2}, and  <dig> ≤ si ≤ ki, i = <dig>  2} as the set containing all the possible control strategies satisfying the multiple hard-constraints. given the initial probability distribution vector x <dig>  the state probability distribution vector  represents the state vdistribution vector at time t obtained by control strategy σ = i1i <dig> … it. the feasible solution set v is a subset of set u, where  

optimal solution exists if v is not empty.

algorithms
reserving place algorithm
our proposed problem is np-hard. here we develop an algorithm for computing all the optimal solutions. in order to find the feasible solution set for the optimal control problem with hard-constraint,  <cit>  applied a recursive method as follows. they first start with the set { <dig>  1}, which contains all the possible control strategies at time t =  <dig>  then one can obtain the set { <dig>   <dig>   <dig>  11} for time t =  <dig>  recursively one can get the feasible solution set while checking whether the control strategies satisfy the hard-constraint. the problem proposed in this paper involves more than one control methods under multiple hard-constraints. the recursive method in  <cit>  can be applied. here we introduce a more efficient algorithm, the reserving place algorithm to find the feasible solution set  our algorithm focuses on control strategies of length t at the right start. for the generation of set u, the numbers of times that each control method can be applied are also involved into consideration. then one only need to check whether the state probability distribution obtained by any control string in the set u satisfies the constraint  thus the key point is to generate the set u, the set of all possible control strategies satisfying the hard-constraints.

we first assume that the number of times that control  <dig> is applied is fixed as k,  <dig> ≤ k ≤ k <dig>  we reserve k places in the control string of length t for control  <dig>  then there are totally  cases. now we only need to find all the control strings of length t − k where control  <dig>  and control  <dig> can be applied and the maximum number of times that control  <dig> can be applied is k <dig>  we note that among all the possible control strings, binary string  is the biggest one. thus by translating decimal digits from  <dig> to 2t−k −  <dig> to binary digits and checking the number of times that control  <dig> is applied, one can generate all the control strings of length t − k satisfying the hard-constraint for control  <dig>  finally we can obtain the set u by increasing k from  <dig> to k <dig> 

computational cost
here we provide an upper bound of the computational cost for our reserving place algorithm.

theorem 1the computation cost of the reserving place algorithm is bounded above by mt22n where  

proof: the main computational cost of the algorithm comes from the matrix-vector multiplication. for each control strategy, the number of matrix-vector multiplication is t, where t is the length of time interval. if we search an optimal solution in the set w = {σ = i1i <dig> … it : ij ∈ { <dig> , 2}} the computational cost is t3τ22n, where n is the number of genes in the network. since we only need to consider the strategies in the set , the computational cost is t22nn, where n is the number of control strategies in the set v. we note that v ⊆ u, the computational cost is bounded above by t22nn. by the reserving place algorithm, we have


genetic algorithm
it has been shown that finding a control strategy for a bn to a global state is actually np-hard  <cit> . by theorem  <dig>  we know that the computational cost of the reserving place algorithm depends a lot on the length of the time interval t and the number of genes n. note that the number of possible states in the network increases exponentially with respect to the number of genes n, thus the computational cost for solving the optimal control problem can be enormous even for moderate n. for any of the above two cases, we apply the genetic algorithm  for the proposed multiple hard-constraint problem. ga is inspired by evolutionary biology such as inheritance, mutation, selection, and crossover. it is a search technique used in computing to find exact or approximate solutions to optimization and search problems. in the first step, we generate a random population of size n =  <dig>  consisting policy vectors of length t =  <dig>  the cost of each policy vector is evaluated which is subsequently turned into the probability that it would be picked for the next generation. second, we pick  <dig> policies from the current generation with replacement according to their corresponding probabilities. then, with cross over rate pc =  <dig> , crossover of the two policies occurs at a random position. after that, each position of the policies mutates with mutation rate pm =  <dig> . after the above operations, the two resulting vectors are placed in the new population. two policies are picked at a time from the current population and then the crossover and mutation operations are performed whenever necessary until there are n or n + <dig> policies in the new generation. we then calculated the cost and the probability of each policy vector. if n is odd, we randomly remove one policy vector from the new generation. the cost and probability of each policy vector are then calculated. the process returns to the second step unless the stopping criteria is met. since the ga starts by randomly generating an initial population, it cannot guarantee to obtain an optimal solution. thus to obtain a reasonably good solution, in numerical experiments, we apply ga many times, and obtain an optimal solution from all the results obtained.

RESULTS
this section is organized into three parts. first, we provide a 2-gene hypothetical genetic network. both the reserving place algorithm and genetic algorithm are applied. the contrast in computational time is also given. then both algorithms are applied to a 3-gene hypothetical genetic network. finally, the comparison of the two algorithm is conducted.

2-gene network
we start with a 2-gene hypothetical genetic network. the network consists of two genes denoted by a and b. the states of gene a and gene b are given in table  <dig>  there are three external control methods:  control 0: no control,  control 1: medication, and  control 2: radiation. their corresponding transition probability matrices are given as follows.


our objective is to find a control strategy that ensures after time length t the total probability of gene a being expressed is at least  <dig>   with the minimum cost, given an initial state distribution of x <dig> = t. the maximum numbers of times that control  <dig> and control  <dig> can be conducted are k <dig> = <dig> and k <dig> =  <dig> respectively. the cost for conducting control  <dig> is  <dig> , the cost for control  <dig> is  <dig>  and no cost for control  <dig>  we first apply the reserving place algorithm to the 2-gene network when t =  <dig>  table  <dig> lists the obtained sub-optimal strategies with minimum cost for each fixed k from  <dig> to k <dig> =  <dig>  where k is the number of times that control  <dig> is conducted. from table  <dig>  there is only one optimal control strategy: conduct control  <dig> at time point t =  <dig> and control  <dig> at time point t =  <dig>   <dig> , with total cost  <dig>  and corresponding state probability distribution vector xt = t. for various values of time interval length t, table  <dig> provides the corresponding optimal strategies and their costs by genetic algorithm. the genetic algorithm cannot always find the optimal solution due to the random initial guess. here we repeatedly apply the ga  <dig> times, and the control strategy is chosen from those results. the ga algorithm can also obtain  the optimal solution obtained by the reserving place algorithm. to contrast the computational cost, table  <dig> gives the computing time for the reserving place algorithm and the average computing time for the genetic algorithm for the 2-gene network under various values of t.


                              k
k = 0
k = 1
k = 2
t = 10
t = 11
t = 12
t = 13
t = 14
t = 15
3-gene network
here we consider a hypothetical network consisting of  <dig> genes a, b, c. the states of genes a, b and c are given in table  <dig>  there are three external control methods:  control 0: no control,  control 1: medication, and  control 2: radiation. their corresponding transition probability matrices are given as follows.

   

our objective is to find a control strategy that ensures the total probability of gene a unexpressed and gene b expressed is at least  <dig>   with the minimum cost, given an initial state distribution of x <dig> = t. the maximum numbers of times that control  <dig> and control  <dig> can be conducted are k <dig> =  <dig> and k <dig> =  <dig> respectively. the cost for conducting control  <dig> is  <dig> , the cost for control  <dig> is  <dig>  and no cost for control  <dig> 


                              k
k = 0
k = 1
k = 2
a comparison of the two algorithms
based on the numerical experiments, we draw the following remarks for the comparison of the reserving place algorithm and the genetic algorithm. the reserving place algorithm obtains all the optimal control strategies, meanwhile the genetic algorithm provides one possible optimal solution. moreover, the reserving place algorithm can give all the sub-optimal control strategies for a fixed number of times that certain control method is applied. this is useful in practice as the results can provide more applicable control strategies to be chosen and more information about the effects of combining various control methods. in the aspect of computing time, the computing time of the reserving place algorithm is closely corresponding to the length of time interval t as shown in table  <dig>  on the other hand, the average computing time for the genetic algorithm is not much influenced by the increase of t. by theorem  <dig>  the computational time of the reserving place algorithm increases exponentially with respect to the number of genes n. for the genetic algorithm, the computing time depends on n, but not as greatly as the computational cost of the reserving place algorithm. all numerical experiments were performed via matlab  <dig>  in window xp using an intel  <dig>  ghz processor.

CONCLUSIONS
in this paper, we introduced a new optimal finite-horizon control problem with multiple hard-constraints. we proposed an algorithm, the reserving place algorithm, to generate all optimal solutions. the upper bound for the computational cost was also estimated. we remark that our formulation can be applied to both perturbed and context-sensitive pbns.

competing interests
the authors declare that they have no competing interests.

authors' contributions
wai-ki proposed the optimization problem. yang designed and analyzed the reserving place algorithm, performed the numerical experiments. yang, wai-ki and nam-kiu wrote the manuscript. wai-ki and ho-yin contributed to the numerical experiment analysis and modification of the manuscript. all authors have read and approved the final version of the manuscript.

