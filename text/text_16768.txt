BACKGROUND
micrornas
micrornas  are small  non-coding rnas that are part of a eukaryote-specific system of gene regulation at the rna level. mirnas act as post-transcriptional regulators of gene expression by base pairing with their target mrnas. mirnas are primarily transcribed by rna pol ii  <cit>  as regions of longer rna molecules   <cit> . individual pre-mirna loops  are cleaved from the pri-mirna by rnase iii enzyme, drosha and transported into the cytoplasm by ran-gtp and exportin  <dig>  <cit>  to be processed further to a ~ <dig> nt long duplex, with 3' overhangs, by dicer  <cit> . this duplex is commonly referred to as the mirna:mirna* duplex, where mirna* is complementary to the mirna. the mirna:mirna* duplex is subsequently unwound and the mature mirna is loaded into multi-protein risc   <cit>  while mirna* usually degrades. in some cases, both mirna and mirna* are functional  <cit> . the mirna biogenesis is illustrated in figure  <dig>  mature mirnas can cause translation inhibition or mrna cleavage, depending on the degree of complementarity between the mirna and its target sequence. each mirna can have multiple targets and each gene can be targeted by multiple mirnas. it has been predicted that more than one third of human genes is regulated by mirnas  <cit> .

plant and animal mirnas differ not only in their biogenesis, but also in target-mirna interactions. plant mirnas base pair with their targets with perfect or near-perfect complementarity and they regulate their targets mostly through mrna cleavage at single sites in coding regions. animal mirnas usually base pair with 3' utrs of the mrnas at multiple target sites through imperfect complementarity. due to these and other differences, it has been suggested that this regulation mechanism may have evolved independently in plants and animals  <cit> . some viruses have also been shown to encode mirnas that play a role in expression regulation of host genes  <cit> .

mirna identification
the first animal mirna genes, let- <dig> and lin- <dig>  were discovered in caenorhabditis elegans by forward genetics  <cit> . currently, mirna genes are biochemically identified by cloning and sequencing size-fractionated cdna libraries. the main limitation of this method is that lowly expressed mirnas may be missed  <cit> . although deep sequencing can help overcome this problem, this is currently a costly solution. still, some mirnas may be difficult to clone due to their sequence composition and possible post-transcriptional modifications  <cit> . deep sequencing is being used on a large scale to identify small non-coding rnas, but this is an expensive method and can only identify mirnas expressed in a single cell type or in a given condition.

computational predictive methods are fast and inexpensive and a number of approaches have been developed to predict mirna genes, genome-wide. however, most of these approaches depend heavily on conservation of hairpins in closely related species  <cit> . some methods have used clustering or profiling to identify mirnas,  <cit> . the approach of bentwich et al.  <cit>  is interesting in that the whole genome is folded and scores are assigned to hairpins based on various features, including hairpin structural features and folding stability.

machine learning approaches in the past have used support vector machines with high dimensional basis functions for classification of genomics hairpins  <cit> . some of these methods depend on cross-species conservation for classification, while others do motif finding using multiple alignments. more recently, hmms have been used in modelling mirnas using both, evolutionary information and features related to the secondary structure  <cit> .

hierarchical hidden markov models
hierarchical hidden markov models  constitute a generalization of hidden markov models . they have been successfully used for modelling stochastic levels and length scales  <cit> . in biology, hhmms have been used in the past to model vertebrate splice sites  <cit>  and more recently in modelling cis-regulatory modules  <cit> . an hhmm has two types of states: internal states and production states. each internal state has its own hhmm but cannot emit symbols by itself. it can activate a sub-state by a vertical transition. sub-states can also make vertical transitions, until the lowest level in the hierarchy  is reached. production states are the only states that can emit symbols from the alphabet via their own probability distributions. sub-states at the same level of hierarchy will be activated through horizontal transitions till an "end state" is reached. every level has only one "end state" for each parent state that shifts control back to the parent. thus, each internal state can emit sequences instead of single symbols. the node at the highest level of the hierarchy is called the "root" node while the leaf nodes are the productions states. please refer to methods for information about hhmm parameters and their estimation.

in this article, we report the results on the performance of an hhmm we developed for modelling mirna hairpins. although the model was trained on human sequences only, it was able to classify accurately hairpins from species as distant as worm, flies and plants, indicating that the degree of sequence and structural conservation for these genes may be high.

RESULTS
data summarization
we consider the hairpin stem-loop for predictions since it is structurally, the most prominent feature during biogenesis . mirna genes can be divided into four regions depicted in figure 2a. after transcription, the rna strand folds to form the hairpin precursor . the "loop" is the bulged end of the hairpin. the "mirna" region defines the mirna-mirna* duplex  that is processed by dicer and further unwound. the region of the precursor extending from the end of the loop to the "mirna" region is called the "extension". this region can be of variable length. the part of the hairpin sequence beyond the "mirna" region may be part of the pri-mirna in the nucleus and processed by drosha. thus, it has been named as "pri-extension", as suggested in saetrom et al.  <cit> .

the results presented in table  <dig> show that the differences that exist between vertebrate and invertebrate mirna genes are rather small. so, a probabilistic method trained in data from one organism is likely to perform well in another organism. as evident from the results in table  <dig>  the differences between length distributions of plant and animal precursors are relatively drastic, with the former having longer extension regions. the lengths of mirnas and loops, however, are conserved across the two kingdoms. more information about species-specific differences is provided in additional file  <dig>  these genomes constitute an excellent test set for our algorithm in that they span various taxonomic groups, with different mirna characteristics. thus, it will be very useful to see how well an hhmm trained on  human sequences will be able to predict mirna stem-loops in another vertebrate or invertebrate species and plants.

hp: hairpin length; lp: loop length; mir: mirna length; ext: distance of mirna duplex from end of loop; pri: length of extension from end of mirna to end of precursor. the list of organisms used for this table is provided as supplementary data.

hhmm model
hhmmir is built around the mirna precursor template illustrated in figure 2a. the figure presents the four characteristic regions of stem-loop of a typical mirna gene as described above. the length distributions of each of these regions are derived from table  <dig>  each region, except the loop itself has three states: match, mismatch, and insertion/deletion . match means a base pairing at that position in the stem-loop, while mismatch means bulges on both arms at that position in the folded hairpin.indel means that a base in one strand has no counterpart in the opposite strand. the loop will only have the indel state. examples of these states are presented in figure 2a.

the hhmm resulting from this scheme has three levels . hairpin is the root node and can vertically transition to its loop substate only. in our model, every hairpin begins with a loop. the four internal states at the second level correspond to the four main regions of the hairpin from figure 2a. this level also has an end  state to transfer control back to the hairpin. each internal state has a probabilistic model at the next lower level. a loop cannot have base pairs and thus, has only one substate: i . the extension state can only emit an m  state, when entered, since a mismatch or indel would become part of the loop. the mirna and pri-ext states can begin with a match, mismatch or indel. each of these states has an end state .

datasets and alphabet selection
the training dataset contained a total  <dig> human mirna precursors  and ~ <dig> random hairpins , based on criteria derived from summarization . the rnafold program from vienna package  <cit>  was used to obtain the secondary structure of these hairpins with the minimum fold energy . the parameters of the model were estimated using a modified baum-welch algorithm . all tests were conducted with 10-fold cross validation with random sampling.

we tested our model on two alphabets: Σ <dig> with matches m = {au, gc, gu}, indels i = {a-, g-, c-, u-} and mismatches n <dig> = {aa, gg, cc, uu, ac, ag, cu}; and Σ <dig>  which is similar to Σ <dig> except that the mismatch set is more concise: n <dig> = {xx, xy}, where xx stands for one of {aa, gg, cc, uu} and xy stands for one of {ac, ag, cu}. in our alphabet, a match, say, au has the same probability as ua, that is, an 'a' on either stem base paired with 'u' on the other stem. cross-validation tests using maximum likelihood estimate  showed that the model with alphabet Σ <dig> performed substantially better, both in terms of sensitivity and specificity  .

sn: sensitivity; sp: specificity; fpr: false positive rate; fdr: false discovery rate. all numbers are in percentages.

it is surprising that Σ <dig> performs better than Σ <dig>  because one would expect that mismatches in the stem-loop would not be characteristic of the mirna sequence, since they do not contribute to the base pairing of the stem and thus the overall folding energy, on which other algorithms are based  <cit> . furthermore, Σ <dig> alphabet has more parameters. in order to rule out that the better performance is due to parameter overfitting, we repeated training with multiple datasets of different sizes and the results remained the same . in the remaining of this paper we use the Σ <dig> alphabet.

training algorithms: performance evaluation
we implemented and compared variations of two existing algorithms for parameter estimation: baum-welch and mle. the positive model was trained using mle since by nature the positive training data  can be labelled as loop, extension, mirna and pri-extension  using existing annotations. negative data on the other hand, are obviously unlabelled, so both algorithms were compared for training with this dataset. we will call the mle trained negative model, mle-hhmmir, whereas the baum welch trained model will be called bw-hhmmir for this evaluation. for mle-hhmmir, we used length distributions from database summarization  to perform random labelling of the four regions on the negative datasets. overall, we found both methods to perform practically the same. the area under the roc curve  for the mle-hhmmir is  <dig>  whereas for bw-hhmmir is  <dig> . the ratio of the log-likelihoods output by the two models decides the fate of the test hairpin. in order to decide a threshold for this ratio, the trade-off between sensitivity and specificity was considered by calculating the mathews correlation coefficient . the highest mathews correlation coefficient value was  <dig>  for bw-hhmmir and  <dig>  for mle-hhmmir, corresponding to likelihood ratio thresholds of  <dig>  and  <dig> , respectively. bw-hhmmir achieved an average 84% sensitivity and 88% specificity using the  <dig>  ratio as thresholds. even though, the difference between the performances of the two algorithms is not great, we choose bw-hhmmir for further tests. this is because mle-hhmmir depends on random labelling of hairpins and thus, performance will vary according to the labelling. the drawback of the baum-welch method is that it might be trapped on local optima, depending on the initialization. this problem is sometimes addressed by running the algorithm multiple times with different starting points. we use a uniform distribution for this initialization but can also use background frequencies for the same by folding the entire genome in question and then performing hairpin extraction for the same. in order to account for the absence of certain base pairs or indels in a certain sequence while using baum-welch, we introduce pseudo-counts to correct for the same.

sn: sensitivity; sp: specificity; mcc: mathew's correlation coefficient; fdr: false discovery rate. sn, sp and fdr report the average percent values; standard deviations are reported in parentheses.

testing prediction efficiency in other organisms
next, we examined how well our model trained on human sequences could predict known mirnas in other species. in particular, hhmmir was tested on the following species: m. musculus , g. gallus , d. rerio , c. elegans , d. melanogaster , a. thaliana and o. sativa. these species were chosen as representatives of their respective taxonomic groups, and because they are well studied and annotated. the results are shown in table  <dig>  hhmmir is able to predict 85% of most animal precursors. its overall sensitivity was also about 85%. what is more surprising, however, is the higher performance we observe in prediction of plant precursors, given the differences in length distributions of the mirna stem-loops between plants and animals . the fact that mouse mirnas are predicted at lower rate probably reflects the larger number of hairpins registered for this species, many of which are not biochemically verified. such discrepancies have been observed in other studies as well, although at a lesser extent . the specificity over the mouse data is very high  and remains surprisingly high in the two invertebrate species  .

comparison with other approaches
as described earlier, there are very few machine learning methods that do not require evolutionary information to predict mirnas. to our knowledge, the only other probabilistic model is a motif finding method for mature mirna region prediction  <cit> . an svm-based approach has been proposed  <cit>  that parses the mfe structure in "triplets": structural information about the pairing states of every three nucleotides, represented using dot-bracket notation. this method showed an accuracy of ~90% using the data available in the registry at the time. we used the same training and test sets used by the "triplet svm" to train and test our model, hhmmir, and we found it to perform better in almost all datasets . the only exceptions are the mouse  and a. thaliana . also, their model was able to predict all of the then five known mirnas from epstein-barr virus, whereas hhmmir predicted four. overall, hhmmir exhibits sensitivity of  <dig> % and specificity of 89% in these datasets. if we limit the comparison of the two methods in one representative species from each taxon  in order to minimize the statistical dependence of the data, the difference in the performance becomes statistically significant at the 5% level .

the percentages represent the ratio of hairpins correctly predicted.

discussion
mirna genes constitute one of the most conserved mechanisms for gene regulation across all animal and plant species. the characteristics of the precursor mirna stem-loops are well conserved in both vertebrate and invertebrate animals and fairly conserved between animals and plants. as seen in table  <dig>  plant hairpins tend to be generally longer than those in animals, while vertebrates have shorter precursors than invertebrates. although, the "extension" and "pri-extension" regions may vary in length between animals and plants , the lengths of the "mirna" and "loop" regions are more similar. thus, even across evolutionary time, the basic characteristics of mirnas have not changed dramatically.

we designed a template for a typical precursor mirna stem-loop and we built an hhmm based on it. hhmmir was able to attain an average sensitivity of 84% and specificity of 88% on 10-fold cross validation of human data. we trained hhmmir on human sequences and the resulting model was able to successfully identify a large percentage of not only mouse, but also invertebrate, plant and virus mirnas . this is an encouraging result showing that hhmmir may be very useful in predicting mirna genes across long evolutionary distances without the requirement for evolutionary conservation of sequences. this would be very beneficial for identification of mirna hairpins in organisms that do not have closely related species sequenced, such as strongylocentrotus purpuratus  and ornithorhynchus anatinus   <cit> .

this is the first time a hierarchical probabilistic model has been used for classification and identification of mirna hairpins. probabilistic learning was previously applied by nam et al.  <cit>  for identifying the mirna pattern/motif in hairpins. the advantage of the hierarchy used by our hhmmir is that it parses each hairpin into four distinct regions and processes each of them separately. this represents better the biological role of each region, which is reflected in the distinct length distributions and neighbourhood base-pairing characteristic of that region. furthermore, the underlying hhmm provides an intuitive modelling of these regions. we compared two modifications of the mle and baum-welch algorithms for modelling the negative datasets, and we found them to perform similarly. baum-welch was selected for this study, since it does not require  labelling of the negative set.

the drawback of hhmmir is that it depends on the mfe structure the rnafold program returns  <cit> . in the future, we will test more folding algorithms or use the probability distribution of a number of top scoring folding energy structures returned by this package.

CONCLUSIONS
the success of our approach shows that the conservation of the mirna mechanism may be at a much deeper level than expected. further developments of the hhmmir algorithm include the extension of the precursor template model  to be able to predict pri-mirna genes with multiple stem-loops. another extension would be to train a model to decode all hhmmir predicted hairpins to identify the mirna genes in them. finally, it will be interesting to extend our method to include evolutionary information, which will allow us to assess the significance of conservation in predicting mirna genes.

