BACKGROUND
recent developments in whole genome sequencing, assembly techniques and expressed sequence tag  methods have lead to a vast amount of sequence data flooding the protein and dna databases. over  <dig> complete genomes are now referenced on the gold <cit>  web site <cit>  with many others in the sequencing and assembly stages. in addition, the recent emergence of high throughput functional genomics techniques has increased the rate at which genome and sequence products are being functionally characterized. as a consequence, the majority of new sequences have homologues in the public databases, and new functional or structural data may often be inferred for the sequence under study using database mining.

thus, sequence database mining and analysis have become essential first steps for a wide range of applications in molecular biology. one of the most widely used methods for detecting homologous sequences is blast <cit> . the blast suite of programs is used to find local sequence similarities, which might lead to evolutionary clues about the structure and/or function of the query sequence. the detected sequences can then be used e.g. to build a multiple alignment of complete sequences , which represents an ideal workbench to study all the information related to a set of homologous sequences <cit> . indeed, by placing a sequence in the context of its overall family, the macs permits not only a "horizontal" analysis of the sequence along its complete length, but also a "vertical" view of its evolution among different organisms. macs are typically used to perform comparative analyses at the genome level, to define the phylogenetic relationships between organisms in evolutionary studies, to identify conserved functional residues, motifs or domains and to predict protein or rna secondary and tertiary structures <cit> .

as a direct consequence of the recent database growth, blast searches frequently lead to the identification of hundreds to thousands of potential homologues for a single query sequence. dealing with so much data can be detrimental, not only in terms of computational and human analysis time, but also in terms of the accuracy and the significance of the results. problems, such as sequencing or intron/exon prediction errors, redundancy or the presence of partial sequences, may represent a significant source of noise, depending on the biological question under study.

it is therefore essential to develop novel strategies to reduce the set of sequences to be processed at the earliest possible stage of an analysis, which is generally during the sequence database search. there are clearly two possibilities: an a priori reduction of the sequence database search space or an a posteriori sampling of the sequences detected by the database search program. some types of studies have intrinsic a priori sequence filters; e.g. the construction of a phylogenetic distribution of proteins from complete genomes or the analysis of proteins belonging to specific clades. another a priori strategy is the use of a pre-processed non-redundant database, where sequences are clustered by means of their percent identities, such as the uniref database series <cit>  . the a posteriori sampling methods are generally based on sequence similarity criteria and frequently require user intervention. for example, uniqueprot <cit>  is a fast and simple method that reduces the redundancy of the dataset by removing over-represented sequences, based on a user-defined percent identity threshold. this method works reasonably well when the proteins have similar domain architectures. a similar strategy is incorporated in blast filter <cit> , which generates smaller sequence sets by filtration of blast results based on  <dig> distinct user-configurable rules requiring a complex pre-scanning of the blast results. these methods are therefore not suitable for automatic, high-throughput projects. a more recent study describes a monte-carlo sequence selection strategy <cit>  to improve the detection of residues belonging to a functional surface in the context of a multiple alignment of proteins of known structure. however the latter study samples sequences after the construction of the multiple alignment, which may incur a large time penalty. if possible, it is clearly advantageous in terms of processing time, to address the relationship between sequence sampling and the information content of the resulting alignment during the initial blast search step.

here we analyse a number of different methods for the sampling of protein sequences detected by blastp searches, aimed at significantly reducing the set of sequences to be processed, while maintaining the same information potential. we have considered sampling methods only based on e-values because this parameter integrates several factors such as sequence length, subject and query similarity scores, database size, although it would be theoretically possible to take into account other factors such as the matching sequences themselves or the species from which they are derived. four methods have been studied  which can be divided into two categories:

- two customisable methods with user-defined parameters that determine either the maximal number of sequences to be selected , or the percent reduction rate ,

- two automatic methods based only on the e-values calculated by blastp: the mean method  and the second derivative method . these methods automatically determine the number of sequences in the sampled set.

we focused our analysis on the potential information contained in the sampled sets of blastp sequences, using the macs as our main validation tool. our analysis focused more precisely on the conservation of residues implicated in the active sites of  <dig> proteins with known and annotated 3d structure selected from the protein data bank  <cit> . a good sampling method should not alter the global quality of the resulting alignments, and should preserve the relevant structural and functional information, e.g. the conservation of active site residues. this analysis allows us to propose a suitable strategy to sample homologous sequences, while keeping the pertinent information in the associated macs.

RESULTS
global strategy
the multi-step process used to compare the different sampling methods is shown in figure  <dig>  for each protein in a large test set of  <dig> proteins:

- a blastp search was performed in the uniref <dig> database to identify the set of potential homologous sequences. of the  <dig> blastp searches,  <dig> detected more than  <dig> sequences with e-value ≤  <dig> , which illustrates the necessity for new strategies that are capable of reducing the number of sequences to process in subsequent analyses.

- each sampling method  was independently applied to the set of detected sequences, resulting in a sampled sequence set containing a reduced number of sequences.

five sets of sequences were thus associated with each initial protein: the unsampled set of sequences detected by blastp and the  <dig> sampled sequence sets. these sets of sequences were then multiply aligned , resulting in five multiple alignments of complete sequences : respectively macs_init containing the top  <dig> sequences detected by blastp, macs_mm, macs_sdm, macs_sm and macs_rm.

the first part of the analysis studies the reduction rate associated with the different sampling methods, depending on the initial number of sequences in the blastp results and their e-value distribution. we also studied the amount of sequence coverage between the different methods, in order to estimate their redundancy or complementarity. the second part then studies the effect of the sampling methods on the macs information content by considering the quality of the macs and the conservation of documented active site residues.

large scale comparison of sampled sequence sets
we studied the behaviour of the different sampling methods for a large set of diverse blastp searches . we analysed the effect of the blastp results on the ability of the sampling methods to effectively reduce the number of sequences according to two criteria: the total number of sequences detected and their e-value distribution. we also compared the sequence coverage between the different sampling methods.

sequence reduction rate
for each protein in the  <dig> protein dataset, the evaluation of the reduction rate associated with each sampling method was based on the calculation of the ratio between the number of sequences obtained after sampling and the number of sequences in the initial blastp result file with an e-value ≤  <dig> . for each sampling method, the mean reduction rate is then defined as the average of the  <dig> computed reduction rates. surprisingly, the mean reduction rate obtained with the automatic methods mm and sdm is very similar to that obtained using the customisable method sm, with all methods resulting in approximately 70% reduction in the number of sequences . these preliminary observations prompted us to set the reduction ratio associated with the customisable random method rm to 70%.

however, the standard deviation obtained with the sm  is approximately twice as large as that associated with the automatic methods , suggesting that the methods may have distinct behaviours depending on the blastp results. also, the total number of sequences selected by each method varies significantly. of the total  <dig> sequences detected with e-value ≤  <dig> , sm selects  <dig> sequences, sdm  <dig> sequences, mm  <dig> sequences and rm  <dig> sequences. therefore, in order to gain more insight into the influence of the blastp results on the behaviour of the sampling methods, we divided the  <dig> protein dataset into three subsets of comparable size according to the total number of sequences detected by blastp with e-value ≤  <dig> :

- subset-100:  <dig> proteins for which blastp detected less than  <dig> sequences

- subset100–500:  <dig> proteins for which blastp detected between  <dig> and  <dig> sequences

- subset+500:  <dig> proteins for which blastp detected more than  <dig> sequences

this division of the initial dataset shows that the number of sequences in the blastp results file affects the mean reduction rate associated with all of the sampling methods tested . a similar behaviour is observed for mm and sdm and both can be considered as progressive as their mean reduction rate increases almost linearly from  <dig> to 80% for subset- <dig> to subset+ <dig>  in contrast, the reduction rate obtained with sm is more variable: subset- <dig> is reduced by 42%, subset100– <dig> by 78% and subset+ <dig> by 94%, with the standard deviations decreasing from subset- <dig> to subset+ <dig>  figure  <dig> confirms that in general, the reduction rate increases with the number of sequences detected by blastp for all the sampling methods . moreover, the reduction obtained by mm and sdm is similar for all the tests in the  <dig> protein dataset. closer investigation  showed that, for blastp results with less than about  <dig> sequences, the reduction rate of mm and sdm is higher than the sm reduction rate and for more than  <dig> sequences, the situation is reversed and sm obtains a higher reduction rate. there is clearly a relationship between the number of sequences detected by blastp and the number of sequences in the sampled sets for all the methods . however, the reduction curves are not linear and we hypothesize that the number of sequences detected by blastp searches is not the only parameter that influences the sampling reduction properties.

we therefore analysed the impact of the distribution of blastp e-values on the sampling reduction rate. the  <dig> blastp search results were categorized in  <dig> clusters  according to the type of e-value distribution observed . e-cluster  <dig> corresponds to blastp results containing a majority of highly similar sequences and e-cluster  <dig> contains blastp results with a majority of weakly related sequences. figure  <dig> shows that the three sampling methods are not affected in the same way by the distribution of the blastp e-values. the reduction rate obtained using mm clearly increases from e-cluster  <dig> to  <dig>  this is due to the fact that, as mm is based on the difference between two successive log, the range of log in each e-cluster will strongly influence the reduction rate. for example, e-cluster  <dig> is mainly composed of blastp searches with e-values ranging from  <dig> - <dig> to  <dig> - <dig> while e-cluster  <dig> is mainly composed of sequences detected with e-values ranging from  <dig> - <dig> to  <dig> . as a consequence, when blastp searches detect a majority of weakly related sequences , mm selects very few sequences. for the sdm method, a surprising tendency is observed: regardless of the blastp sequence distribution, reduction rates are mostly between  <dig> and 70% with a slight increase for e-clusters  <dig> to  <dig>  thus, we conclude that sdm is weakly influenced by the e-value distribution. this somewhat surprising result may be due to a biased composition of the databases or may reflect a particular characteristic of the blastp e-value calculation. the sm reduction rate is highly variable for all the e-clusters and is in fact, more closely related to the number of sequences detected by blastp. this behaviour can be explained by the pre-defined maximal number of sequences to be selected, which is equal to the number of strips .

in summary, the reduction rate of mm depends on both the number of blastp sequences and their e-value distribution. in contrast, sdm and sm depend mainly on the number of sequences. nevertheless, sdm and sm behave differently in relation to the blastp e-value distribution: the sdm reduction rate is relatively constant, while the sm reduction rate is much more variable.

sequence coverage
as specified in the sequence reduction rate section,  <dig> sequences with an e-value ≤  <dig>  were detected by the  <dig> blastp searches and the sampling methods resulted in different total numbers of sequences. as shown in table  <dig>  mm and sdm selected approximately the same number of sequences , whereas sm selected a smaller number of sequences  and rm much more . for the sequences specifically selected by only one sampling method, we observed a large difference between their proportions: 7% for sm, 12% for mm, 15% for sdm and an extreme value for the random method, 79%, reflecting a fundamentally different behaviour of this method.

the sequence coverage rate was calculated by considering the number of sequences common to  <dig>   <dig> or  <dig> methods compared to one method chosen as a reference .  <dig> sequences were selected by all  <dig> methods, whereas  <dig>  sequences are common to mm, sm and sdm. the difference between these  <dig> values can be explained by the numerous sequences selected only by rm. the mean coverage rates observed for mm and sdm are quite similar at around 75% . this similarity might be expected, since both methods are fully automatic and entirely based on the e-values.

we also noticed that the sequences common to mm, sdm and sm sampled sets are usually located at positions in the e-value distribution where large differences occur . thus, we conclude that mm, sm and sdm select mainly variable sequences which may supplement the structural and/or functional information of the sampled set of sequences.

impact of the sampling on the potential information in the sequence set
to estimate the impact of the methods on the potential information in the sampled sets, we used multiple alignment of complete sequences  as the main tool. we analysed the diversity of the sequences included in the macs, the global quality of the macs and the extent to which active site residues were observed in conserved columns in the different macs.

sequence diversity
at the structural and functional level, closely related sequences may not add relevant information, whereas diversity is usually more informative <cit> . in the context of blast searches, sequences detected with nearly the same e-values, especially in the case of low e-values, are more likely to be similar, and inversely, a difference in the e-values usually represents a sequence divergence.

as the information content of a set of homologous sequences is generally related to their diversity, we investigated the sds , whose selection increases the diversity of the sampled macs compared to the macs_init .

the proportion of sds selected by the different methods is between 22% for sm and 76% for rm . the sm is the method that selects the least sds because the pre-defined maximal number of sequences inhibits the inclusion of sds compared to a sampling method that is not limited in terms of the number of sequences. based on the proportion of sds , we assume that the variability of the mm and sdm sampled macs is considerably larger than that of macs_init.

* with more than  <dig> sequences detected by blastp with e-value ≤  <dig> 

macs quality
in order to be informative, a macs needs to be of high quality. the quality of the alignments used in this study were evaluated using the normd <cit>   objective function, shown in table  <dig>  normd is an objective function that takes into account ab initio sequence information, such as the number, length and similarity of the sequences to be aligned. of the  <dig> macs_init alignments, a total of  <dig>  had high normd scores. sampling by mm, sdm and rm resulted in similar proportions of high quality macs  whereas sm increases this proportion to 95%. as the  <dig> protein dataset is composed of pdb sequences, it is likely to be enriched in single domain sequences. to verify that the macs quality was not affected by the presence of multidomain proteins, we compared the normd scores obtained with and without the multidomain proteins defined according to pfam <cit>  annotations of the pdb entries, before and after sampling . the normd scores were similar in all experiments. this observation confirms that the computation of macs using the combination of local and global algorithms, as implemented in the pipealign <cit>  cascade , results in high-quality alignments, even in the case of multidomain proteins  <cit> . furthermore, no major differences were observed between the roc curves  obtained for the initial  <dig> protein dataset compared to this reduced dataset of  <dig> single domain proteins .

* considering only good quality macs

in order to investigate the relationship between macs quality and the number of sequences detected by blastp, we also studied the quality of the macs obtained in the three subsets of comparable size defined in the section sequence reduction rate. for subset- <dig>  95% of the macs_init can be considered to be of good quality, with a high mean normd value  as shown in table  <dig>  sampling the sequences using any of the  <dig> methods increases both the proportion of good quality macs  and the mean normd . similar results were observed for subset100– <dig>  where the sampling methods again increased the proportion of good quality macs  and the mean normd . for subset100– <dig>  sm which is the method that reduces the most the set of aligned sequences, results in a higher proportion of good quality macs and a higher mean normd. furthermore, for subset+ <dig>  sm is the only sampling method able to improve the macs global quality compared to macs_init, both in terms of proportion  and mean normd value . it is important to note that the high proportion of sds added in the context of subset+ <dig> by the mm, sdm and rm methods, corrupts the resulting alignments: the proportion of good quality macs falls respectively to  <dig>   <dig> and 37%. increasing the sequence diversity in a macs should normally improve the information content <cit> , but including too many distant sequences can also be harmful in terms of quality, so that the macs becomes less informative. this seeming contradiction clearly reflects the current limitations of the algorithms used to construct multiple alignments.

from a quality point of view, we conclude that sm is the most appropriate sampling method since a higher proportion of good quality macs is obtained after sampling, as well as an increased mean normd value. moreover, by significantly reducing the number of sequences to be aligned, the sm method also reduces the computation time required to construct the macs.

macs information content
the information content of a macs is difficult to measure objectively. we therefore decided to investigate the residues annotated in the pdb database as being involved in functional active sites. these residues are usually well conserved in a protein family <cit>  and well characterized both biochemically and structurally. as an estimate of the information content of a macs, we calculated the number of known active sites that were detected in conserved columns of the alignment. given a conservation threshold cut-off x, a column is considered to be "conserved" if x% of the residues, including gaps, are identical in the column. the sensitivity and specificity of the active site detection can then be computed .

in this study, we only considered those tests for which the init, mm, sdm and sm all resulted in good quality macs, which represents  <dig> of the  <dig> protein dataset. the rm method has been excluded from this study based on the results of the macs quality analysis . in subset+ <dig>  low quality macs were obtained after rm sampling. furthermore, preliminary analyses of active site detection using rm indicated that the mean sensitivity is much lower compared to all the other methods , indicating that the informational content was not conserved.

in order to compare the informational content of the studied macs, we plotted the roc curves for each sampling method using  <dig> conservation thresholds, ranging from 60% to 100% . considering the global set of macs_init alignments, the area under the curve  is  <dig> , indicating that the column conservation measure is a suitable parameter for the discrimination of active site residues. the visual comparison of the auc shows that the quality of the information is well conserved after sampling, particularly with mm and sm, when considering subset100– <dig> and subset+ <dig> 

to confirm these observations, we performed a quantitative analysis. we determined the most suitable column conservation threshold for the discrimination of active site residues with macs_init alignments , corresponding to the inflexion point of the roc curve near the top and left corner. the threshold for macs_init for all the  <dig> good quality macs is 80%. to assess the information content of the sampled macs, we constructed the confusion matrix <cit>  associated with each sampling method, based on this 80% conservation threshold. the geometric means of accuracy  <cit>  values were then computed  and the difference in g-means before and after the application of each sampling method was used as a comparison metric. a smaller g-mean would be characteristic of a loss of information content. the g-mean value associated with macs_init is  <dig> : sm is the only sampling method which has the same g-mean value, while a small g-mean decrease is observed for mm and sdm .

we then considered the three subsets defined in the section sequence reduction rate separately, and the corresponding macs_init roc curves are shown in figure  <dig> 

for subset- <dig>  the most suitable column conservation threshold for active site discrimination is 90%. g-mean values decrease with the application of any of the sampling methods: the macs_init g-mean value  is slightly reduced after sm  and a larger reduction is observed after mm and sdm . this decrease is caused by a loss of specificity of the active site detection, directly linked to the reduction of sequence diversity after sampling. indeed, when only a small number of homologues are detected by blastp, the variability between the sequences is usually relatively low. consequently the associated macs contains a higher proportion of conserved columns, and more false positive predictions are obtained. however, this is not a serious problem as the unsampled macs_init alignments for this subset are generally of high quality and the small number of sequences  in the blastp results means that reduction of the sequence set is not necessary for computational purposes.

for subset100– <dig>  the most suitable column conservation threshold is 75%. the highest sensitivity for active site discrimination was obtained using sm sampling . however, the sensitivity and specificity scores are quite similar for all the sampling methods  and the differences observed between the methods cannot be considered to be significant. nevertheless, we observed previously that in this subset, the sm sampling is more accurate in terms of reduction rate and macs quality, and consequently sm seems to be the most suitable sampling method.

finally, for subset+ <dig>  a 80% conservation threshold was determined. the sensitivity of active site determination after mm and sdm sampling decreases drastically , whereas the sensitivity and specificity of the sm sampled set are both close to the values obtained for macs_init . this leads to similar g-mean values for macs_init and mm , a small decrease is observed for sdm , whereas sm shows a better g-mean value , indicating a better accuracy for active site detection. these observations correlate with the macs quality results in which the proportion of good quality macs is higher after application of sm sampling compared to the other methods. the study of sequence coverage showed that the mm and sdm sampled sets both contain a higher proportion of sds compared to sm . moreover, the sm sampling resulted in a higher reduction rate than the mm and sdm methods under these conditions . without sequence sampling, the average time to construct a multiple alignment for the set of  <dig> alignments with more than  <dig> proteins was  <dig> seconds . after sampling with the sm method, the average time for the same set of alignments was  <dig> seconds . thus, all these observations converge towards the conclusion that sm is the most suitable sampling method for the effective reduction of the number of sequences detected by blastp, while maintaining the powerful information content of the subsequent macs.

CONCLUSIONS
the rapid accumulation of numerous homologues in the sequence databases is a problem for which no unique solution exists. this study demonstrates that it is possible to sample the homologous sequences detected by blastp while at the same time retaining the relevant information concerning the active site residues inside the sampled set of sequences.

we showed that on average 30% of the detected sequences are sufficient to efficiently maintain the relevant functional information, however the sequence selection cannot be performed randomly.

an exhaustive analysis allowed us to define the most suitable sampling strategy depending on the number of sequences detected by blastp searches and in conjunction with the use of a non redundant database:

 <dig>  the reduction of the sequence set is not necessary with proteins having few homologues in sequence databases . in this case, the variability between the sequences is usually relatively low and sampling the sequences results in a loss of information.

 <dig>  the strips sampling  is the most suitable sampling method for the effective reduction of the sequence set when more than  <dig> sequences are detected by blastp searches. this method maintains the potential structural and functional information in the sampled set and by defining the maximal number of sequences  the computation time remains reasonable.

in conclusion, regardless of the size of the initial blastp results, our sampling strategy produces a set of sequences that is computationally and humanly manageable.

in the future, we will study the conservation of other kinds of information that can be extracted from a set of homologous sequences, such as secondary structure information or motif conservation.

