BACKGROUND
cancer is a disease treated with various strategies depending on the type of cancer and the stage of the disease. generally, therapeutic agents are selected according to the specific cancer type and patient population, based on the effectiveness in large-population studies  <cit> . now, with the advances of the genomic era, a massive amount of high-throughput data has been made available for understanding the cancer system biology. the public available datasets composed of genomic data and drug responses offer the opportunity to reveal valuable knowledge about the hidden relationships between gene expression and drug activity of tumor cells, pointing out the conditions that bring a patient to be more responsive than others to a given therapeutic agent. although data collection provides the baseline to enable a better understanding of cancer mechanisms, data integration and interpretation is still an open issue. mathematical and statistical models of complex biological systems play a fundamental role in system biology, and in particular in cancer related issues. they can be exploited for exploratory purposes, to validate hypothesis and make predictions about quantities that are difficult or impossible to be measured in vivo.

in the last decade, several studies have been conducted to develop platforms on which cancer high-throughput computational analysis can be performed. much of these computational approaches are targeted at predicting the drug sensitivity/resistance by means of statistical inference and regression methods able to take into account genomic information of hundreds of genes for determining a specific drug response  <cit> . however, the massive availability of chemical compounds as potential cancer therapies has opened to the investigation of in silico therapy response prediction which requires more sophisticated computational models and methods to optimize the experimental design of cell-drug screenings.

a first attempt of gene-drug integrative analysis was presented in  <cit>  where, thanks to a hierarchical clustering algorithm, several investigations have been performed:  cell-to-cell correlation on the basis of gene expression and drug activity profiles,  relationships between drug activity patterns and mechanisms of action,  gene-drug correlation on the basis of gene expression and drug activity profiles. in subsequent investigations  <cit> , the triangle gene expression profiles, drug responses and cancer types has been explored by integrating unsupervised and supervised machine learning algorithms. the clustering approach based on soft topographic vector quantization   <cit>  has shown that gene expression profiles are more related to the cancer type than to the drug activity patterns, while thanks to the structure learning of bayesian networks  some biologically meaningful relationships among gene expression levels, drug activities and cancer types have been confirmed and in some cases revealed. more recent works  <cit>  are targeted at integrating explorative approaches with predictive paradigm towards a computational gene-drug screening. while  <cit>  and  <cit>  are based on non-deterministic clustering approaches  for identifying relevant genes involved in cancer mechanisms and predictive of drug response,  <cit>  introduces a framework based global optimization to cancel the randomness, and therefore the variance, of stochastic clustering results when predicting a therapy outcome.

the results of the above quoted papers and of a wide set of related approaches highlight several interesting considerations: the explorative analysis performed through clustering approaches reveals that the tissue of origin is more related to the gene expression profile than the drug activity patterns. this suggests that the genomic information of a cell line plays a fundamental role, independently of the organ of origin, to understand anticancer therapy responses. this idea has been supported by the fact that several cell lines with a relatively high expression level of those genes regulating multi-drug resistance have been clustered in the same group. this indicates that chemoresponse mechanisms are distributed across different tissues in the panel and that it should be possible to link drug responses to gene expression profiles.

in order to cancel the variability of results of stochastic clustering and to guarantee the convergence to a global minimum, we need to address the clustering problem by exact approaches able to find globally optimal solutions.

computational approaches based on bayesian networks reveal interesting relationships among subsets of genes and drugs. the potential of bayesian networks encourages us to exploit this probabilistic model not only for deductive purposes, but also for prediction issues.



in order to achieve the final goal of simultaneously predicting the drug response of several compounds given a patient genomic profile, we propose a computational framework based on the following assumption: groups of cell lines homogeneous in terms of both gene expression profile and drug activity should be characterized by a subset of genes that explains the drug responses. to this purpose a three-folds analysis has been investigated: p-median problem formulations to create clusters of homogeneous cell lines, feature selection policies to select relevant genes and finally bayesian networks to predict drug responses of tumour cell lines. computational results show that the proposed consensus p-median, combined with gene selection and bn inference engine, yields homogeneous clusters while guaranteeing good predictive power for inferring drug responses for a new cell line. this is also confirmed by the biological evaluation performed on the selected genes: according to the existing literature the set of genes used to train the bns, which has been selected by using the groups of cell lines obtained by the proposed consensus p-median, has shown to be biologically relevant from an oncological point of view.

methods
problem formulation
the problem of simultaneously predicting the response of several therapeutic compounds given the patient genomic profile is addressed by a computational framework composed of three main building blocks: the creation of homogeneous groups of tumor cell lines by means of p-median formulations. in particular, a novel consensus p-median formulation is proposed and compared with traditional state of the art approaches, i.e. k-means  <cit> , stvq  <cit>  and relational k-means  <cit>  and probabilistic d-clustering  <cit> .

the selection of relevant genes able to predict the response of hundreds of drugs. we explore the potential of the solutions determined by solving the above mentioned p-median problem formulation for identifying a subset of genes that characterizes each cluster, i.e. those subsets of genes that could be responsible of drug responses. to accomplish this task two main feature selection policies have been investigated, i.e. information gain  <cit>  and correlation-based feature subset evaluation   <cit> .

the simultaneous prediction of different drug responses by exploiting the potential of bayesian networks  <cit> . establishing a straightforward dependency structure of the bayesian network, we explore the ability of the selected genes to predict a panel of drug responses given the genomic profiles of patients.



the proposed computational framework exploits the well known dataset provided by the u.s. national cancer institute. the dataset consists of  <dig> cell lines from  <dig> kinds of cancers, all extracted from human patients, where the tumors considered in the panel derive from colorectal, renal, ovarian, breast, prostate, lung and central nervous system as well as leukemia and melanoma cancer tissues.

for the cell lines in the panel, both transcript profiling and chemosensitivity patterns have been considered. in the following we will consider two datasets stemmed from the original one:  scherf et al. based on cdna arrays and  liu et al. based on microrna arrays. in both cases the dataset is defined as a set Ω of all cell lines xi, with i={ <dig> …60}, into the real vector space \documentclass{minimal}

where \documentclass{minimal}

sherf dataset: cdna arrays and dtp-tested chemical compounds
the sherf dataset, originally presented in  <cit> , denotes the gene expression profile \documentclass{minimal}

  \documentclass{minimal}

according to the sherf representation \documentclass{minimal}

liu dataset: microrna arrays and drugs with known mechanism of action
micrornas  are a group of short noncoding rnas that regulate gene expression at the post-transcriptional level. they are involved in many biological processes, including development, differentiation, apoptosis, and carcinogenesis. because mirnas may play a role in the initiation and progression of cancer, they comprise a novel class of promising diagnostic and prognostic molecular markers and potential drug targets. in order to achieve our goal by exploiting the mirna data, we considered the dataset presented in  <cit> . this dataset leads us to represent the sets Ωg and Ωd by means of  <dig> mirna expression profile and  <dig> gi <dig> responses related to drugs with known mechanism of action. the same selection criterion applied on sherf dataset has been exploited for liu dataset. concerning the mirna expressions, in this dataset there are no missing values and more than  <dig> experiments have red-green intensity ratios > <dig>  or < <dig> , implying no selection of mirna and therefore a space \documentclass{minimal}

cluster analysis
cluster analysis is aimed at discovering embedded patterns into a given dataset. from a high level point of view cluster analysis consists of partitioning a set of patterns into subsets  based on similarity, i.e. a cluster has to contain similar patterns and dissimilar patterns have to be in different clusters. this could be accomplished by partitioning data points into a pre-specified number of clusters through the optimization of a cost function related to a similarity/dissimilarity measure between data points.

an important step in any clustering algorithm is to select a distance measure, which will determine how the similarity/dissimilarity of two data points is calculated. in order to perform a cluster analysis we chose one of the most used distance measures  <cit>  based on pearson correlation :   \documentclass{minimal}

where xi and xj represent two cell lines and corr denotes the pearson correlation coefficient between xi and xj. thanks to the distance measure denoted by equation , cell lines having high distance due to anti-correlated genes/drugs are likely placed in different clusters, while cell lines characterized by a small gap are expected to be clustered together. the adoption of a correlation-based metric instead of the euclidean distance is motivated by its sensitivity with respect to magnitude: euclidean distance is sensitive to scaling and differences in average expression level, whereas correlation is not.

in the following we present three different clustering approaches based on p-median formulation: traditional p-median, probabilistic d-clustering and consensus p-median.

traditional p-median
the p-median problem was originally designed for facility location planning  <cit> , where the location of “p-facilities” relative to a set of “customers” has been formulated such that the sum of the shortest demand weighted distance between “customers” and “facilities” is minimized. in our investigation, the p-median problem has been formulated as an assignment problem for creating groups of cell lines by using a “flat” representation of data, i.e. by representing each cell line as a vector in \documentclass{minimal}

let z be a matrix of dimension |Ω|×|Ω|, as:   \documentclass{minimal}

where zij represents the assignment variable that indicates whether a cell line xi is assigned to a cluster center xj. note that the matrix z has dimension |Ω|×|Ω| because each entry zij denotes the potential association of a cell line xi to any of the points xj in Ω .

the clustering problem can be formulated as follows:   \documentclass{minimal}

s.t:   \documentclass{minimal}

  \documentclass{minimal}

  \documentclass{minimal}

  \documentclass{minimal}

according to this formulation, the objective function in equation  denotes a combinatorial optimization problem whose objective is to minimize the distance between all data points belonging to the same cluster through the identification of optimal cluster centers xj∈Ω. constraint  ensures that each cell line xi is assigned to only one cluster, constraint  guarantees that there will be exactly k clusters and constraint  ensures that if xi is assigned to xj then xj is a cluster center and therefore a median. the last constraint  guarantees integrality.

for seek of clarity, the above mentioned p-median is a mathematical programming formulation  for uncapacitated facility location problems. the objective of this formulation is to minimize the sum of the distances from all data points xi to their respective cluster centers . in this paper the p-median problem is solved deterministicallya by means of a canonical “branch and cut” algorithm  <cit> . the solution of the p-median problem finds out not only the cluster assignments, but also the geometric medians as cluster representatives.

p-median must not be confused with approaches like k-means  <cit> , k-medoids  <cit>  and k-medians  <cit> , which represent heuristic algorithms for approximating the above mentioned objective function. while k-means computes a cluster representative  as mean vector of all points belonging to a cluster, k-medoids and k-medians select respectively k of the |Ω| data points as medoids  and medians . on the contrary, a branch-and-cut algorithm on a p-median formulation determines the set of p data points that minimize the sum of weighted distances to any points of the dataset and consequently finds out the cluster assignment for each data point. the geometric medians determined by solving the p-median problem do not coincide neither with the centroids, medians or medoids . in our investigation, the solution of the p-median problem formulations are ensured to be the global optimum, while the ones originated by the heuristic approaches can correspond to local optimum among all possible solutions.

probabilistic d-clustering
the assignment problem presented above assumes to create k mutually exclusive clusters of cell lines, with similar profiles of gene expression and drug response. the crisp formulation can be relaxed by modelling probabilistic  assignments , leading to a probabilistic p-median named probabilistic d-clustering  <cit> .

the formulation reported in - can be therefore approximated by the following minimization problem:   \documentclass{minimal}

s.t:   \documentclass{minimal}

  \documentclass{minimal}

where the decision variables ck and pk denote the cluster centers ck and the probability of assigning the cell line xi to the cluster ck respectively. each cell line can be finally assigned to the cluster center with the highest probability.

it can be easily noted that the formulation of probabilistic d-clustering is a further generalization of the p-median  problem, slightly different from the ones presented in equation - but still belonging to the combinatorial optimization. while for traditional p-median the creation of k clusters is forced by the constraint , in probabilistic d-clustering the generation of k clusters is driven by the objective function.

a natural working principle to solve - is to fix one set of variables and minimize the objective function with respect to the other set of variables, then fix the other set and minimize again, until convergence is achieved. an iterative method has been recently proposed to solve the problem, leading to a generalized weiszfeld method  <cit> , where centers and probabilities are sequentially updated. the iterative method alternates between: step 1: probabilities update. given the centers ck and the distance between each cell line xi and ck, the probabilities that xi is assigned to the cluster k can be estimated as:   \documentclass{minimal}

given the clusters, their centers, and the distances of data points from these centers, the probability of cluster membership at any point is assumed inversely proportional to the distance from  the cluster.

step 2: centers update. given the probabilities pk, the centers \documentclass{minimal}

where   \documentclass{minimal}

the centers are updated as convex combinations of these points, with weights determined by the working principle.



the iterative process stops when the centers stabilize, i.e. when   \documentclass{minimal}

originating a clustering of cell lines in the space \documentclass{minimal}

consensus p-median
the cluster analysis of the nci <dig> dataset relates to a set of objects  that need to be grouped taking into account multiple sources . most of the multi-source clustering approaches follow one of the following paradigms:  clustering each data source separately to then ad-hoc integrate the separate clustering solutions  <cit>  or  combining all data sources to determine a single “joint” clustering  <cit>  as traditional p-median and probabilistic d-clustering. the first kind of approaches is characterized by an independent analysis: while they take advantage of modeling source-specific features, they are not able to capture inter-source associations. on the other side, the second type of approaches is based on a joint analysis that is able to exploit shared structure among data sources, but disregarding the heterogeneity of the data and taking no account important features that are specific to each data source. more flexible methods allow for separate but dependent source clusterings  <cit> .

the characteristics of these more flexible approaches, along with the remarks highlighted in background section, led us to define a consensus p-median formulation based on two steps: the first is aimed at determining groups of cell lines into the gene  space, whereas the second one determines the clusters of cell lines into the drug  space, while constraining the optimal solution in order to take into account the assignment of the first step. this approach aims at finding a trade-off between gene expression and drug response profiles, by defining a sequence of two integer linear programming formulations. while the problem at the first step can be formulated as a traditional p-median , the second step leads to the definition of the following consensus p-median formulation:   \documentclass{minimal}

s.t:   \documentclass{minimal}

  \documentclass{minimal}

  \documentclass{minimal}

  \documentclass{minimal}

  \documentclass{minimal}

where \documentclass{minimal}



the pseudo-code reported in algorithm ?? summarizes the iterative process for solving the consensus p-median until the value of μ∗ is found, i.e. until constraint  becomes redundant. for the sake of simplicity, we will denote with consensus p-median  the approach where at step  <dig> the set Ωg is used and at steps  <dig> and  <dig> the set Ωd is exploited. on the other hand, we will denote with consensus p-median  the approach where Ωd is exploited at step  <dig>  while at step  <dig> and  <dig> the set Ωg is used.

feature selection
the clusters that can be generated by the above mentioned approaches represent sets of cell lines that show a similar response to anti-cancer therapy also taking into account genomic information. this enables a feature selection activity that allows us to to identify the subset of genes that could possibly regulate the cell response behavior. to compactly characterize the obtained clusters, we attempt to select a subset of genes that best represents the cell lines membership. in order to validate the hypothesis that the obtained groups of cell lines embed useful information for helping the pharmacology of cancer, we applied two feature selection techniques known as information gain and correlation-based feature subset evaluation.

information gain
in order to determine the most relevant genes that characterize a cluster and therefore that can be responsible of drug response for the cell lines belonging to that cluster, a feature selection based on information gain has been applied. information gain measures the decrease in entropy when the feature is given vs absent. according to this measure a “good” feature can contribute, independently of any other feature, to reduce the uncertainty of each clusters given the attribute values. formally, given a cluster attribute c representing the obtained clusters and a gene attribute a, denoting the expression level of a given gene, the information gain  is computed as follows:   \documentclass{minimal}

where   \documentclass{minimal}

  \documentclass{minimal}

we can therefore consider equation  as a measure of dependency between the density of variable at  and the distribution of the target ck .to compute the entropy in equation , the t nominal expression values need to be represented as discrete quantities. in order to discretize genes as up-, down- and normo- regulated, a double filtering approach has been applied.

in order to discretize genes as up-, down- and normo- regulated, a double filtering approach has been applied. in particular, genes that are differentially expressed have been identified by applying fdr corrected p-value test  <cit> , with the requirement that the rate of false significant genes should not exceed 5% with a confidence of 99%. once non-significant genes have been identified, a mean difference cut-off  has been applied to discriminate between up- and down-regulated genes among the significant ones. the mean difference cut-off β corresponds to the minimum absolute value of expression such that a gene is not considered as non-significant. with fdr corrected p-value, the mean difference cut-off corresponds once more to β= <dig>  . according to the double filtering approach, genes with a fold change >+ <dig>  are considered as up-regulated, while genes with a fold change <− <dig>  are considered as down-regulated. gene expression values into the interval  are identified as normo-regulated. the discretization threshold can be easily grasped by looking at the volcano plot reported in figure  <dig> figure  <dig> 
volcano plot. volcano plot of l
o
g
 <dig> fold-change  versus −l
o
g
 <dig> fdr-corrected p-value . genes with log fold change above −l
o
g
2= <dig>  are up-regulated, while genes with log-fold change below l
o
g
2=− <dig>  are considered as down regulated.



once genes have been discretized, the value of ig for each attribute can be computed allowing genes to be ranked accordinglyb. the top  <dig> genes have been selected as the most representative to train the predictive model described subsequently.

correlation-based feature subset evaluation
an alternative feature selection method, able to evaluate the contribution of each gene, is the correlation-based feature subset evaluation . this approach assumes that good feature subsets contain features highly correlated with the cluster attribute, while yet uncorrelated with each other. the selection algorithm, which takes as input the genes discretized according to the fdr corrected p-value test introduced above, is a heuristic that evaluates the merit of a subset of features, taking into account the usefulness of individual features for predicting the class label  along with the level of intercorrelation among them. the merit of a subset s composed of g features can be estimated as:   \documentclass{minimal}

where rbf is the mean feature-cluster correlation, and rff is the average feature-feature intercorrelation. the numerator can be viewed as an indication of how predictive of the cluster a set of features are, while the denominator of how much redundancy there is among the featuresb. more details about cfs can be found in  <cit> .

prediction
the results obtained in the previous steps allow us to train a predictive model able to infer, for a new cancer patient, the multiple drug responses by using his/her gene expression profile of selected genes. one way of deriving a predictive model is to estimate a joint distribution for the set q of features that characterize the dataset. the joint distribution for a sample xi∈Ω, where \documentclass{minimal}

a complete joint probability distribution over a set of random variables must specify a probability value for each of the possible set instantiation. for example, if we consider to specify an arbitrary joint distribution p for |q| dichotomous variables, a table with 2|q| entries is required. this complexity makes an infeasible probability model for any domain of realistic size. a possible solution that tries to overcome this problem is represented by bayesian networks  <cit> . the key component, that reduces the probability model complexity, is the assumption that each variable is directly influenced by only few others.

this assumption is captured graphically by the dependency structure: a probability distribution is encoded by a directed acyclic graph whose nodes represent random variables and edges denote direct dependencies. formally, a bayesian network asserts that each node  is conditional independent of its non-descendants given its parents. this conditionally independence assumption allows us to represent concisely the joint probability distribution over the random variables.

if we consider a distribution over |q| features, which can be arbitrarily ordered as x <dig> x <dig> ..,x|q|, it can be decomposed as the product of |q| conditional distributions:   \documentclass{minimal}

instead of specifying the probability of xs conditional on all possible realizations of its predecessors x <dig> ..,xs− <dig>  we can consider only its set of parents pa. more precisely, a set of variables pa is defined as the markovian parents of xs if pa is a minimal set of predecessors of xs that makes xs independent on all the other predecessors.

the joint probability distribution can therefore defined as:   \documentclass{minimal}

where \documentclass{minimal}
nci <dig> bayesian network. the upper part of the network comprises the top ten genes selected either by the ig or cfs feature selection, the central node corresponds the the cluster variable and the bottom nodes correspond to the drug responses to be predicted.



the upper part of the network, which comprises  <dig> nodes, represents the most relevant genes selected by the policies described in the previous sections. the central part of the network, which is composed of only one variable, denotes the cluster obtained by solving the clustering problems. the bottom part, which comprises n= <dig> nodes, represents the drug responses to be predicted. these last variables have been discretized in order to train discrete cpds and consequently a fully discrete bn. in particular, following the discretization introduced in  <cit> , cell lines with log <dig> at least  <dig>  sds above the mean were defined as resistant to the compound, whereas those with log <dig> at least  <dig>  standard deviations below the mean were defined as sensitive. cell lines with log <dig> within  <dig>  standard deviations of the mean were considered to be intermediate. the remaining cell lines within  <dig>  standard deviations were defined as intermediate. after this discretization process, the cpds related to the dependency structure of the bn can be easily estimated, to then simultaneously predict the response of n drugs given the expression value of the  <dig> relevant genes.

RESULTS
in order to evaluate the quality of the proposed framework, a three-fold analysis has been performed. in our experimental investigation we consider k= <dig> clusters to be obtained, which respects the number of tumor types considered by the nci <dig> panel. in order to avoid overfitting and to report unbiased experiments, each step of the proposed framework  has been enclosed in a leave-one-out cross validation. for seek of clarity, the leave-one-out procedure works as follows: a cell line xi is removed from the training set Ω

clustering, feature selection, discretization and bn training are performed on the set {Ω∖xi}

the removed cell line xi is then used as test for prediction in bn



results reported in the following are therefore averaged over the leave-one-out folds. the first analysis is concerned with the average pearson correlation coefficient for estimating how homogeneous the clusters are. given the obtained k clusters, the pearson correlation coefficient r is computed as follows:   \documentclass{minimal}

where nk is the cardinality of cluster k. more specifically, the coefficient r has been computed with respect both to the gene and to the drug space, originating then two correlation coefficients: rg is computed considering the correlation between instances represented by their gene expression profiles, while rd is estimated considering the correlation between instances represented by their drug response profiles.

we also report the correlation indices of some baseline clustering approaches previously investigated for mining the nci <dig> dataset: k-means  <cit> , soft topographic vector quantization   <cit>  and relational k-means  <cit> .

in figures  <dig> and  <dig>  a comparison in terms of correlation  between the investigated clustering approaches is depicted reporting the traditional p-median, probabilistic d-clustering, k-means, svtq, relational k-means and the proposed consensus p-median. for the consensus p-median two series are reported, i.e. consensus p-median  and consensus p-median .figure  <dig> 
correlation indices for the sherf dataset. the y and x-coordinates denote the average pearson correlation in the drug and gene space respectively. the correlation indices for all the reported series have been averaged over the leave-one-out cross validation folds. each point of the series for consensus p-median corresponds to a solution obtained according to the parameter μ, while the series for stvq reports values for α={ <dig> . <dig> . <dig> ⋯, <dig> }.
correlation indices for the liu dataset. the y and x-coordinates denote the average pearson correlation in the drug and gene  space respectively. the correlation indices for all the reported series have been averaged over the leave-one-out cross validation folds. each point of the series of consensus p-median corresponds to a solution obtained according to the parameter μ, while the series for stvq reports values for α={ <dig> . <dig> . <dig> ⋯, <dig> }.



each point of the series for the consensus p-median corresponds to a solution obtained according to the parameter μ. the ordinate axis represents the correlation coefficients in the drug space , while the abscissae axis the correlation in the gene space .

an interesting remark is related to the average correlation indices of the proposed approach. all the solutions provided by the consensus p-median show a slightly better  pearson coefficient than the others. this implies that our approach leads to clusters that are more homogeneous both in terms of gene expression and drug activity than the clusters obtained by the other approaches. this is highlighted by the fact that most of the solutions determined by the consensus p-median dominate the ones generated by the other approaches. the most promising “competitor” is relational k-means, which leads to almost homogeneous cluster configuration. in order to validate the significance of the results, confidence intervals have been estimated on the clustering solutions. confidence intervals provide a range about the observed “effect size”, allowing us to understand how likely the generated solutions are: the smaller the confidence interval, the more certain we are about the solution. in our specific case, the confidence intervals have been computed as follows. first, for each run l of the leave-one-out, the pearson correlation coefficients rl  have been estimated. then, the mean and the confidence interval have been estimated over the leave-one-out results.

in table  <dig> confidence intervals are reported for the investigated clustering approaches on the sherf dataset. we can easily note that the leave-one-out cross validation procedure provides a small effect size for most of the approaches both for correlations in the gene and drug space. we can state therefore that, with a confidence level of 95%, that the results are robust, enabling an easy identification of optimal solutions as pareto points . similar results have been obtained on the liu dataset.table  <dig> 
confidence interval  level of the clustering solutions on the sherf dataset


gene correlation
drug correlation
\documentclass{minimal}
confidence
±
\documentclass{minimal}
confidence
±
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
pareto points have been marked as bold.



concerning the computational complexity related to p-median problems, it is well known that they belong to the np-hard complexity class. however, some recent meta-heuristcs allow to solve the p-median problems in \documentclass{minimal}

a further validation is targeted at the correctness of bayesian networks to predict the drug responses. in particular, we have measured the prediction accuracy of bns trained with the top relevant genes characterizing the groups of cell lines derived by the mentioned clustering approaches. we have also reported the accuracy of a trivial classifier as baseline, where the prediction of a drug response is performed according to its majority class on the training data. in figures  <dig>   <dig>   <dig> and  <dig> the comparison in terms of accuracy, i.e. percentage of drug response correctly predicted, between the investigated approaches is shown. the bns are trained according to the  genes selected by the information gain and correlation-based subset evaluation policies. in particular, considering that the experimental investigation is performed by means of a leave-one-out cross validation, the relevant genes to be used for training bns have been selected as the most frequent over the top ten genes selected for each fold of the cross validation. specifically, given the l= <dig> solutions obtained by performing a leave-one-out , a voting mechanism has been applied. each gene received a vote if, in a given run of the leave-one-out, it appears in the top ten list of relevant genes. once the votes have been collected, the  <dig> genes with the highest number of votes are selected as the most important and therefore used to train the bn. it can be easily noted that all the solutions generated by the proposed approach outperform the ones obtained by the other methods. concerning the sherf dataset , the bns trained according to the consensus p-median are able to ensure an average prediction accuracy of  <dig> % with ig and  <dig> % cfs selection policies, outperforming the accuracy of probabilistic d-clustering , p-median , stvq , k-means , relational k-means  and the trivial classifier .figure  <dig> 
comparison of bns accuracy on sherf dataset. the bns have been trained according to the selection of genes by means of ig policy.
comparison of bns accuracy on sherf dataset. the bns have been trained according to the selection of genes by means of cfs policy.
comparison of bns accuracy on liu dataset. the bns have been trained according to the selection of genes by means of ig policy.
comparison of bns accuracy on liu dataset. the bns have been trained according to the selection of genes by means of cfs policy.



confidence intervals reported in table  <dig> show not only the ability of ig selection policy to obtain small variability in the expected predictions, but also the correspondence between pareto points and the most promising  bayesian networks . this correspondence allows us to assert that the proposed consensus p-median is able to create groups of homogeneous cell lines taking into account two different data source and, as consequence, to derive a prediction model that outperforms the others. a similar result is obtained on the liu dataset , where the proposed approach achieves more accurate predictions with respect to the other ones.table  <dig> 
confidence interval  level of the bn predictions  on the sherf dataset


ig
cfs
average
confidence
±
average
confidence
±
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
 <dig> 
predictions corresponding to pareto points have been marked as bold.



considering that the ultimate goal of this paper is the prediction of anticancer drug responses, we have also compared the bns trained according to the consensus p-median with some traditional supervised methods. in particular, our approach has been compared with naive bayes   <cit> , decision tree   <cit> , 1-nearest neighbor   <cit>  and linear support vector machines   <cit>  classifiers. each model has been trained to predict one drug at a time by using all the available genes. also for these classifiers a leave-one-out validation has been performed. for the sherf dataset, our approach obtained the highest performance with  <dig> % of accuracy, against the ones of dt , 1-nn , nb  and svm . concerning the liu dataset, similar results have been obtained. in particular, the proposed approach is able to achieve an accuracy of  <dig> % compared with dt , 1-nn , nb  and svm . a summary of the accuracy confidence intervals, both for sherf and liu datasets, is depicted in figure  <dig>  we can easily point out that the models based on rna  are able to achieve higher average accuracy, with smaller confidence intervals, than the models based on microrna . a more interesting remark relates to the comparison of the considered models. figure  <dig> confirms that the proposed approach, based on consensus pmedian, guarantees not only the highest average prediction accuracy of drug response, but also a non-overlapping confidence interval. it’s also interesting to note that the performance of all the trained models have a small gap with respect to the trivial classifier, highlighting that  a relatively small number of drugs can be actually predicted better than the trivial baseline.figure  <dig> 
comparison of confidence intervals on prediction accuracy. results for sherf and liu dataset are reported . accuracy of traditional classifiers, i.e. dt, 1-nn, nb and svm, are based on train/infer one drug at a time by using all the available genes. results corresponding to the clustering approaches are concerned with bns trained according to the clustering output and the ig feature selection policy.



the last evaluation has been performed from a biological point of view in order to highlight the functional role of the most informative genes characterizing each cluster. indeed, since clusters represent sets of cell lines that show a similar response to anti-cancer therapies also taking into account genomic information, the feature selection activity should be able to identify the subset of genes that could possibly regulate the cells response behaviour. in order to validate this hypothesis we searched for the biological functions associated to the selected genes by accessing the entrez gene database , which is a ncbi’s  database for gene-specific information . in tables  <dig> and  <dig> we report the  <dig> genes that have been used to train the best bayesian network for the sherf dataset, that correspond to the configuration obtained by the consensus p-median  with μ= <dig>  both for ig and cfs. column one reports the official gene name on entrez gene, column two contains a description of the main biological processes in which the gene is involved, and finally column three reports a description - extracted from the literature - of the role of the gene with respect to cancer mechanisms. concerning ig selection policy on the sherf dataset , it’s interesting to highlight that most of the selected genes are recognized in the literature as biologically relevant. it’s also interesting to underline that some of the selected genes have been identified as relevant in previous investigations  <cit> : sparc, sgk <dig>  dnaja <dig>  elf- <dig> and gja <dig>  a remarkable evidence is provided by genes cdkn2a and dnaja <dig> as tumor suppressors, genes sparc and gja <dig> as tumor marker and finally sgk <dig> as prognostic marker. in particular sparc, considered relevant in this study as well as in  <cit>  and  <cit> , has a reputation for being a potent anti-cancer. it has been shown to be involved in cell cycle, cell invasion, adhesion, migration, angiogenesis and apoptosis both in vitro and in vivo . regarding cfs selection policy on the sherf dataset , we can note that some of the selected genes can be considered marginal from an oncological point of view, while others are shared with the ones obtained by applying ig .table  <dig> 
gene selection  based on consensus p-median on the sherf dataset



gene name
biological process
role 
the reported genes refer to the outperforming bn  trained according to the solution generated by the consensus p-median  with μ= <dig> .
gene selection  based on consensus p-median on the sherf dataset



gene name
biological process
role 
the reported genes refer to the outperforming bn  trained according to the solution generated by the consensus p-median  with μ= <dig> .



concerning the liu dataset, the analysis of the selected relevant mirnas can be only preliminary. although mirnas represent a recently discovered class of non-coding rnas that play a fundamental role in the regulation of gene expression, most of their functions still remain to be discovered. for this reason, we can only report the genes whose mrna can interact with the considered mirna . the listed genes have been selected by accessing the data available at “microrna.org - targets and expression” , which is a freely available open-source software able to provide microrna target predictions  <cit> . in order to provide a preliminary evaluation of the selected mirna, we can point out their involvement in the “microrna in cancer” pathway . as highlighted in table  <dig>  some mirnas belong to the above mentioned pathway: hsa-mir-200a, hsa-mir-200b, hsa-mir-200c, hsa-mir- <dig>  hsa-mir- <dig> and hsa-mir- <dig> identified by the ig selection, and hsa-mir- <dig> and hsa-mir-17* determined by the cfs policy. we highlight that  some mirna are shared between the two selection policies .table  <dig> 
mirna selection  based on consensus p-median on the liu dataset



ig
cfs

mirna
target gene
mirna
target gene

hsa-mir-200a

hsa-mir-200b

hsa-mir-200c

hsa-mir-141
hsa-mir-145

hsa-mir-100

hsa-mir-494
the reported mirnas refer to the outperforming bns : for ig the optimal bn is denoted by consensus p-median  with μ= <dig> , while for cfs the optimal bn is obtained by means of consensus p-median  with μ= <dig> . mirnas belonging the “microrna in cancer” pathway are marked as bold.



in order to analyze the computational time of the entire framework, a comparison over the considered datasets has been reported in tables  <dig> and  <dig>  the execution time  has been reported for the three phases, i.e. clustering, feature selection and prediction. concerning the clustering phase, it can be noted in tables  <dig> and  <dig> that the most efficient approach is traditional p-median, followed by the proposed consensus p-median . tables  <dig> and  <dig> report the computational effort required by the feature selection policies  and training and inference phases needed for prediction with bns. the selection strategy based on cfs is clearly computationally intensive because it requires the search of the sub-optimal set of features that could compactly represent the clusters. on the contrary, ig is more efficient thanks to its ability to evaluate each feature  independently on the others. considering bns, the training step requires a quite limited computational effort because only conditional probability tables need to be estimated . the time required by the inference step is mainly influenced by the number of drugs that are simultaneously predicted, i.e. more therapeutic compounds are considered and more time is necessary to estimate their posterior probability of being sensitive, resistant and intermediate.table  <dig> 
efficiency comparison  ofthe entire framework on sherf dataset



 clustering

clustering
execution time

 feature selection and prediction

feature selection
execution time

prediction
execution time



 clustering

clustering
execution time

 feature selection and prediction

feature selection
execution time

prediction
execution time


as final remark, considering both qualitative and quantitative results, we can assert that consensus p-median together with information gain and bayesian network represent an optimal trade-off between efficacy and efficiency to simultaneously predict  anticancer responses.

CONCLUSIONS
in this paper the problem of identifying a suitable profile of cancer patients by linking gene expressions, drug responses and types of cancer has been addressed. a learning framework based on three building blocks has been proposed. the experimental results highlight three main findings:  the proposed consensus p-median is able to create groups of cell lines that are highly correlated both in terms of gene expression and drug response;  from a biological point of view, the gene selection performed on these clusters allows the identification of genes that are strongly involved in several cancer processes;  the prediction of drug responses, by using the patient profile obtained through clustering and gene selection, represents a promising step for predicting potentially useful drugs. concerning the ongoing research, several issues are still to be investigated. among them the next future work will be focused to the identification of a suitable number of clusters and the use of more “selective” discretization policies. as far is concerned with the methodological approach, an interesting comparison relates with those approaches, belonging to the multiple tasks learning, able to simultaneously predict the drug responses given a  of gene expressions. instances of future investigations are marginal regression  <cit>  and support vector machine  <cit>  for multitask learning. a further development of the proposed investigation relates to the exploitation of additional data sources, such as proteomic expression profiles, to better predict the drug response in tumour cells.

availability of supporting data
the data sets supporting the results of this article are included within the article .

endnotes
a the solutions of the p-median problems have been determined by using the cplex commercial solver.

b for the feature selection process, the weka environment  <cit>  has been exploited  <cit> .

c for training and inference of bayesian networks, the bnt matlab toolbox has been used. the toolbox is available for download at  <cit> .

additional files
additional file  <dig> 
sherf gene expression data. gene expression profiles of nci- <dig> cell lines:  <dig> genes for  <dig> cell lines.



additional file  <dig> 
sherf drug activity data. drug activity patterns of nci- <dig> cell lines:  <dig> compounds for  <dig> cell lines.



additional file  <dig> 
liu mirna expression data. mirna expression profiles of nci- <dig> cell lines:  <dig> mirna for  <dig> cell lines.



additional file  <dig> 
liu drug activity data. drug activity patterns of nci- <dig> cell lines:  <dig> drugs in clinical use for  <dig> cell lines.



competing interests

the authors declare that they have no competing interests.

authors’ contributions

ef, em and fa conceived the algorithm and designed the experiments. ef performed experiments and analysed the results. all authors read and approved the paper.

