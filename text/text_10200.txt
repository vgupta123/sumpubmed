BACKGROUND
preprocessing techniques typically attempt to make expression values from multiple samples comparable in two different ways: 
by scaling expression values such that each sample has an equal value for a statistic such as mean or median; or

by adjusting expression values such that each sample has the same expression distribution across genes.




the first approach includes methods such as mean and median scaling, and is popular for affymetrix genechips. for example, in the mean scaling method, the mean gene expression value of each microarray in the sample is first calculated, and a grand mean is then computed as the mean of all means. finally, expression value of each microarray in the sample is scaled such that the mean expression of each microarray is equal to the grand mean. median scaling also follows the same procedure, with the mean statistic being replaced by median. while these methods are simple to implement, they assume that expression values of all samples share a linear relationship. they – especially mean scaling – also suffer from a few other drawbacks such as sensitivity to outlier distortions  <cit> .

the second approach includes more sophisticated methods such as z-score and quantile normalization. in z-score normalization, the expression values of genes in each microarray are transformed to fit the standard normal distribution with a mean of zero and  <dig> unit standard deviation. on the other hand, quantile normalization uses the rank values of gene expression within individual microarrays to make the distribution of all microarrays identical in statistical properties. since ranks are known to be relatively more robust to batch effects than absolute expression values  <cit> , this is expected to lead to better performance on datasets with batch effects. in the quantile normalization procedure, the expression values of each microarray are first sorted in ascending order, and the mean expression corresponding to each rank across microarrays is stored separately. following this, the original expression values in each microarray are assigned ranks based on their relative quantitative order. finally, a transformed matrix is obtained by replacing each gene rank value by the mean expression value corresponding to that rank as stored earlier.

the z-score and quantile normalization methods are relatively more robust to outliers, provided that the number of microarrays in a dataset is sufficiently large. however, the actual distributions of underlying data are assumed to be identical in all samples, and specifically assumed to be gaussian in case of z-score normalization. this assumption is especially likely to break down in datasets with disease state samples where the regular functions of the genes and their synchronization with each other may be substantially disrupted. in such cases, the expression patterns within a disease sample may not be identical to samples of the normal phenotype. it also may not be identical to other disease samples if the disease is heterogeneous and is able to manifest itself through the exploitation and/or breaking of multiple mechanisms.

it is also commonly observed that low-expression genes and proteins exhibit a much greater coefficient of variance than highly expressed ones in their expression levels . thus, the expression rank of low-expression genes is highly unstable. this may adversely affect the performance of a ranking-based normalization method such as quantile normalization.

therefore, we are inspired to present gfs as a preprocessing technique for gene expression. like quantile normalization, our method also makes use of gene expression ranks instead of absolute values, thus earning more robustness to batch effects. however, unlike the above techniques, we do not make any assumptions on the similarity of distribution or the equality of any mean-, median-like statistic across samples. moreover, in our method, we fuzzify the expression ranks such that irrelevant fluctuations introduced by minor differences in ranks are alleviated, and noise from low-ranked genes is discarded.

the idea of fuzzification has also been used earlier in a few gene expression profile analysis methods  <cit>  and also proteomic profile analysis methods  <cit> . however, these works merely use it as a component of their respective methods, and do not study its role and effectiveness as a normalization procedure.

methods
datasets
we collected datasets  from three different disease types – duschenne muscular dystrophy , leukemia, and acute lymphoblastic leukemia .



a single gene expression matrix was produced by merging the two dmd datasets from haslett et al.  <cit>  and pescatori et al.  <cit> . similarly, data were merged from armstrong et al.  <cit>  and golub et al.   <cit> , as also from yeoh et al.  <cit>  and ross et al.   <cit> .

note that each of the first three pairs of the chosen datasets  are independent and were produced on different microarray platforms. thus, the merged gene expression matrices obtained from them contain batch effects by default. we consider only genes that are common in the two samples of the dataset pair, and run all the four preprocessing techniques – gfs, mean scaling, z-score normalization, and quantile normalization – on these input matrices, and evaluate their effectiveness in dealing with batch effects. to observe the effect of preprocessing on highly heterogenous data, we also use another more heterogeneous dataset from yeoh et al.  <cit>  that has  <dig> disease subtypes  and normal patient samples to compare the selected methods. thus, in total, four sets of input gene expression matrices belonging to three different disease types are used in our analysis.

approach
in gfs, we transform a raw gene expression matrix by making use of the rank values of genes within each microarray, rather than by using their absolute expression values. further, we use two quantile thresholds – θ
 <dig> and θ
 <dig> – to assign a fuzzified score to each gene in each patient. ranks below θ
 <dig> in a sample are all reduced to a score of zero, those above θ
 <dig> are given a score of  <dig>  and intermediate ranks are interpolated to obtain a score between  <dig> and  <dig>  in particular, let r be the rank of gene expression of a gene g
i in patient p
j, and q be the rank corresponding to the upper θth quantile of gene expression in patient p
j. then, the gene fuzzy score s assigned to a gene g
i in patient p
j is given by the following function: 
  <dig> s= <dig> ifq<rr−qq−q,ifq>r≥q <dig> otherwise 


apart from the use of rank values in computing transformed scores, gfs also benefits from the fact that it allows for selection of quantile thresholds such that noise from low-ranked genes is safely removed by assigning a score of  <dig>  while genes with very high expression are all treated equally with a score of  <dig>  for the purpose of uniformity in comparison, we fix θ
 <dig> to 5% and θ
 <dig> to 15% for all gfs runs mentioned in this paper. however, using a θ
 <dig> value between  <dig> to 10% and θ
 <dig> value between  <dig> to 20% also leads to similar results.

in evaluating the proposed approach against other normalization techniques discussed earlier, we focus on three salient questions in this paper: 
does the preprocessing technique produce consistent results across different datasets, provided that they have the same composition of different phenotypes?

what is the quality of the output produced by the processing technique? how well does the processing retain useful information while mitigating obscuring effects?

is the output produced by the technique biologically coherent?




we compared gfs with three standard normalization methods described in the previous section – mean scaling, z-score normalization, and quantile normalization. the description of our design and approach to each experiment is given in the next section.

RESULTS
visualizing data after pca transformation
we preprocess the raw gene expression matrices with each of the four methods – mean scaling, z-score normalization, quantile normalization and gfs. for each method, we select the top 15% genes with maximum variance in the processed matrix, as these are most likely to be the genes contributing to interesting variation. we then reduce the processed matrix to include only these high variance genes, and apply pca transformation on the reduced matrix. a scatter plot of the coordinates corresponding to the first two principal components  of each sample is visualized.

a good preprocessing method is expected to show a clear clustering of samples of the same phenotype, and separation between samples of different phenotypes. moreover, the quality of clustering would ideally not be adversely affected by the presence of samples from multiple batches in the data.


observations: while in the leukemia, dmd, and childhood all datasets, samples from different batches are clearly separated, gfs  shows the best phenotype-wise clustering of samples among all preprocessing techniques. mean scaling  does not perform well on any of the datasets, and in some cases, obscures the separation seen even in raw gene expression . this degredation in peformance is in line with previous findings  <cit> . z-score normalization shows good performance on dmd and leukemia  datasets, and quantile normalization performs well only on the dmd dataset .
fig.  <dig> visualisation with pca scatter plots – raw expression. a all : pc <dig> vs. pc <dig>  b all : pc <dig> vs. pc <dig>  c all : pc <dig> vs. pc <dig>  d all : pc <dig> vs. pc <dig>  e leukemia : pc <dig> vs. pc <dig>  f leukemia : pc <dig> vs. pc <dig>  g dmd: pc <dig> vs. pc <dig>  h dmd: pc <dig> vs. pc3


fig.  <dig> visualisation with pca scatter plots – mean-scaled expression. a all : pc <dig> vs. pc <dig>  b all : pc <dig> vs. pc <dig>  c all : pc <dig> vs. pc <dig>  d all : pc <dig> vs. pc <dig>  e leukemia: pc <dig> vs. pc <dig>  f leukemia: pc <dig> vs. pc <dig>  g dmd: pc vs. pc <dig>  h dmd: pc <dig> vs. pc3


fig.  <dig> visualisation with pca scatter plots – z-score normalized expression. a all : pc <dig> vs pc <dig>  b all : pc <dig> vs. pc <dig>  c all : pc <dig> vs pc <dig>  d all : pc <dig> vs. pc <dig>  e leukemia: pc <dig> vs. pc <dig>  f leukemia: pc <dig> vs. pc <dig>  g dmd: pc <dig> vs. pc <dig>  h dmd: pc <dig> vs. pc3


fig.  <dig> visualisation with pca scatter plots – quantile normalized expression. a all : pc <dig> vs. pc <dig>  b all : pc <dig> vs. pc <dig>  c all : pc <dig> vs. pc <dig>  d all : pc <dig> vs. pc <dig>  e leukemia: pc <dig> vs. pc <dig>  f leukemia: pc <dig> vs. pc <dig>  g dmd: pc <dig> vs. pc <dig>  h dmd: pc <dig> vs. pc3


fig.  <dig> visualisation with pca scatter plots – gfs normalized expression. a all : pc <dig> vs. pc <dig>  b all : pc <dig> vs. pc <dig>  c all : pc <dig> vs. pc <dig>  d all : pc <dig> vs. pc <dig>  e leukemia: pc <dig> vs. pc <dig>  f leukemia: pc <dig> vs. pc <dig>  g dmd: pc <dig> vs. pc <dig>  h dmd: pc vs. pc3




in case of the more heterogeneous all dataset , gfs is the only method to discriminate between samples of the different all subtypes ).

from the pca scatterplots for all the three datasets with batch effects , we observed that samples from two batches are always clearly separated along pc <dig>  this implies that the first principal component is highly enriched in batch effects. therefore, we exclude the first principal component , and draw scatterplots corresponding to the second and third principal component . in pc <dig> vs pc <dig> scatterplots, there is very less separation between samples from different batches but belonging to the same phenotype, as compared to that in pc <dig> vs pc <dig> scatterplots . this trend is consistent across all three datasets with batch effects. thus, removing pc <dig> can be an effective technique to reduce batch effects in gene expression data to a great extent. however, for the more heterogeneous all dataset where batch effects are absent, removing pc <dig> results in loss of important variation information, and subsequently, less clearer separation between different phenotypes.

comparing processing quality
quality of a preprocessing method is determined by its ability to separate interesting from obscuring variation. an inferior preprocessing method will lead to an output in which expression variation across microarrays would be confounded with irrelevant information. in contrast, expression variation across microarrays in the output of an ideal preprocessing method will correspond to interesting biological variation alone.


experiment: we estimate the quality of preprocessing methods with respect to the capability of their transformed output to separate samples of different phenotypes. in particular, we randomly select 15% of the genes, reduce the processed matrix to include the selected genes, and apply pca on the resultant matrix. the pca co-ordinates of all samples are then used to compute a clustering performance metric called the silhouette score. the silhouette score is calculated based on the mean intra-cluster distance a and the mean nearest-cluster distance b for each sample, as /m
a
x  <cit> . the score ranges from - <dig> to  <dig>  in general, a higher silhouette score indicates a better clustering.

for the all dataset with  <dig> subtypes, co-ordinates corresponding to the first three principal components are used, while for the other three datasets with batch effects, co-ordinates corresponding to only the second and third principal components are used. this is repeated over  <dig> iterations, and the distribution of silhouette scores corresponding to each preprocessing method is used to infer the quality of clusters formed by its transformed output.


observations: for all the four datasets, the distribution of silhouette scores obtained using randomly chosen 15% genes is stable at a higher value in case of gfs, in comparison to other preprocessing methods . this shows that the assigned scores to each microarray-gene pair after gfs preprocessing are more relevant to the interesting variation in gene expression and thus, even randomly chosen features are better able to capture the phenotype-based clusters. moreover, the reference silhouette scores obtained from the top 15% variance genes in gfs processed matrices are consistently higher than the 75th percentile score of its null distribution obtained from random 15% genes, across all datasets . for quantile normalization, while the silhouette scores obtained from its top 15% variance genes are also consistently higher than the 75th percentile score of the corresponding null distribution, these observed silhouette scores are consistently lower than those for gfs. on the other hand, the silhouette scores derived using the top 15% variance genes in z-score normalized and raw expression are lower than the 75th percentile score of their corresponding null distributions in the dmd dataset and all dataset with  <dig> subtypes. the silhouette score computed on top 15% variance genes in scaled expression data is lower than the median score of its null distribution in all datasets. this shows gfs-processed expression values are more effective than the other methods.
fig.  <dig> null distributions of silhouette scores obtained with raw and processed expression matrices taking 15% random genes as features . a all . b all . c dmd. d leukemia




the silhouette scores obtained from the pca transformed co-ordinates of samples using the top 15% high-variance genes are recorded in tables  <dig> and  <dig>  in all datasets, with and without the first principal component , gfs is seen to have a better score relative to other processing methods. also, in the three datasets with batch effects, removing pc <dig> improves phenotype-wise clustering, while in the heterogeneous all dataset with no batch effects, removing pc <dig> leads to discarding important variation and thus a reduction in clustering performance.
 <dig> 
 <dig> 
 <dig> 
 <dig> 
silhouette scores corresponding to gfs are the highest among all methods 


 <dig> 
 <dig> 
 <dig> 
 <dig> 
silhouette scores corresponding to gfs are the highest among all methods 




comparing consistency
it is important that a reliable preprocessing method produces an output that remains consistent in multiple runs over datasets of the same type. for instance, if two datasets of the same disease are transformed by a preprocessing method, and the genes indicated to have the highest contribution to interesting variation have very little overlap, it is natural to infer that the variation is confounded by noise and the genes are likely to be false positives. in contrast, consistency in such output affirms that the preprocessing method is indeed reliable, since similarity in input ensures similarity in output. thus, a preprocessing technique assigning meaningfully transformed expression values should indicate a consistent set of high-variance genes, when applied to different datasets with the same phenotype distribution.


experiment: in order to evaluate the consistency of different preprocessing methods, we split each dataset into two datasets such that each contains the same number of samples of each phenotype, independently apply the preprocessing technique on the resultant split data, and obtain the two resulting lists of the top 15% high-variance genes from the splits. further, we apply pca to the normalized data, and remove genes that have a coefficient of zero in all of the first three principal components for the all dataset with  <dig> disease subtypes. for the other three batch effects-ridden datasets, we only remove genes that have a coefficient of zero in the second and third principal component. this process is repeated  <dig> times using different splits of each dataset. we then examine the distribution of similarity  between the two gene lists.


observations: a consistent preprocessing technique would be expected to demonstrate a high overlap in high-variance genes. it is seen that the distribution of jaccard coefficient when the split datasets are processed using gfs, is stable at an equal or higher value in all the datasets . the other methods fluctuate in performance and, in some cases, show worse consistency than raw gene expression.
fig.  <dig> consistency of preprocessed output - jaccard coefficient distribution of top variance contributing genes on comparing  <dig> data splits. a all . b all . c dmd. d leukemia




comparing biological coherence
for a phenotype to manifest, the causal genes often co-ordinate with other genes, and seldom act alone. therefore, genes contributing to interesting variation in data are more likely to be connected to each other in biological pathways. thus, we expect that a more biologically coherent preprocessing technique will result in high-variance genes that induce significantly more and/or bigger subnetworks on known biological pathways.


experiment: we assess the biological coherence of the preprocessing methods by examining the subnetwork size distribution obtained when high-variance genes are used to induce subnetworks on pathways. the subnetwork size distribution for each processing method is obtained as follows: 
preprocess the gene expression matrix using the chosen technique.

select top 15% genes with maximum variance across patient samples.

reduce processed expression matrices to only include the selected genes.

perform a pca transformation on the reduced matrix, and list genes with non-zero coefficients in any of the first three principal components.

using genes in step  <dig>  induce subnetworks on known pathways from the pathwayapi database  <cit>  and store the subnetwork size distribution.




to generate the null model, step  <dig> is replaced with randomly selecting 15% of all genes, and steps 1– <dig> are repeated over  <dig> iterations. finally, for each subnetwork size, a p-value is calculated as the proportion of subnetwork frequencies in the null model found to be greater than the frequency from original distribution.

the same analysis is repeated for the three datasets with batch effects by modifying step  <dig> to include only those genes that have a non-zero coefficient in the second or third principal component.


observations: the distribution of subnetwork sizes induced by the top 15% variance genes are shown in fig.  <dig>  and fig.  <dig> . the figures show the actual subnetwork count distribution across different subnetwork sizes, while the inset figures show the corresponding percentage frequencies. in the leukemia dataset and all dataset with  <dig> subtypes, gfs has the highest percentage frequency of subnetworks of size greater than or equal to  <dig> and, in most datasets, gfs induces more subnetworks overall.
fig.  <dig> distribution for size of subnetworks induced by high-variance genes in different preprocessed outputs ; inset figure shows the same as percentage frequency. a all . b all . c dmd. d leukemia


fig.  <dig> distribution for size of subnetworks induced by high-variance genes in different preprocessed outputs ; inset figure shows the same as percentage frequency. a all . b all . c dmd. d leukemia




from the low p-values in tables  <dig>   <dig>   <dig>   <dig>  we observe that the significance of frequencies is high for subnetworks induced by gfs, regardless of their size. further, comparison with other methods shows that the frequency of subnetworks induced by high-variance genes in gfs-processed datasets is much more significant than those induced on datasets processed with other methods and raw gene expression. hence, we infer that gfs-transformed output is highly biologically coherent. moreover, we observe that on excluding the batch effects-enriched pc <dig> from the analysis, the p-values corresponding to larger subnetwork sizes are lower than those of smaller sizes, indicating higher significance, and hence greater biological coherence, of the large subnetwork sizes. <dig> = p-value using first three pcs, p
 <dig> = p-value using pc <dig>  pc <dig> only

p
1
p
2
p
1
p
2
p
1
p
2
p
1
p
2
p
1
p
2
 <dig> = p-value using first three pcs, p
 <dig> = p-value using pc <dig>  pc <dig> only

p
1
p
2
p
1
p
2
p
1
p
2
p
1
p
2
p
1
p
2
 <dig> = p-value using first three pcs, p
 <dig> = p-value using pc <dig>  pc <dig> only

p
1
p
2
p
1
p
2
p
1
p
2
p
1
p
2
p
1
p
2

p
p
p
p
p



effect of sample size on performance of gfs
to examine the effect of sample size on gfs, we randomly selected samples of the size of  <dig> ,  <dig> ,  <dig>  times the original sample size over  <dig> iterations. we then noted the range of silhouette scores obtained from the iterations for each sample size. . as expected, fig.  <dig> shows that the clustering performance improves with increase in sample size. interestingly, the boxplots in fig.  <dig>  interpreted together with tables  <dig> and  <dig>  also indicate that the median performance of gfs when provided with even  <dig>  times of the entire sample size is still comparable with, and often better than, that of other normalization methods when they are supplied with the entire sample size.
fig.  <dig> effect of sample size on clustering performance of gfs. a all . b all . c dmd. d leukemia




CONCLUSIONS
an effective preprocessing technique is expected to transform the gene expression matrix such that data of the same phenotype from different sources is made similar. this can be achieved by removing or accounting for obscuring noise in gene expression measurement, and retaining interesting variation relevant to properties of biological interest. such a processing is essential to ensure reliable downstream analysis of gene expression data. however, popular normalization techniques do not necessarily improve the quality of expression data, and sometimes even exacerbate the issue by mistaking real variation for noise and discarding it.

we discussed a new approach, gene fuzzy score, to address this issue and compared it with other popular preprocessing methods with respect to three important criteria. first, we assessed the capability of the transformed output of each technique to resolve differences in phenotypes within the dataset. secondly, we estimated the consistency of their output when presented with different datasets with the same phenotype distribution. finally, we analysed the distributions of size of subnetworks induced by genes indicated to be sources of interesting variation in each processed expression matrix. in each of these aspects, gfs was successful in improving the transformation outcome, proving its applicability in datasets with batch effects and heterogeneity. moreover, the performance of gfs improves with increase in sample size.

a recurring observation from our experiments is that in datasets with significant batch effects, the batch effects are generally captured by the first principal component in pca. thus, applying a pca transformation and excluding the first principal component from subsequent analysis leads to significant reduction in batch effects in any dataset, and improves the performance of all preprocessing techniques. further, we note that gfs outperforms other methods irrespective of whether this additional step is implemented.

another merit of gfs is the interpretability of its transformed outcome. a biologist may quickly understand how highly the gene is ranked in a particular patient. for b, when a gene has a gfs score of  <dig>  in a patient, it means the gene is in the top 10% most highly expressed genes in that patient . thus, apart from being a robust and effective preprocessing technique, gfs is also easily interpretable.

while we evaluated gfs only on microarray gene expression, it is conceivable that the method may be applied to data obtained from other high-throughout technologies such as rna-seq and swath proteomics. exploring this possibility remains the subject of our future work.

not applicable.

declarations
this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2016: proceedings of the 27th international conference on genome informatics: bioinformatics. the full contents of the supplement are available online at http://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-17-supplement- <dig> 

funding
funding for the publication of this paper is provided by wong’s research overheads wbs # r252-000-720- <dig> 

availability of data and materials
the datasets analysed during the current study are publicly available, and can be accessed from the corresponding references: duschenne muscular dystrophy  – haslett et al.  <cit>  and pescatori et al.  <cit> , leukemia – armstrong et al.  <cit>  and golub et al.   <cit> , and acute lymphoblastic leukemia  – yeoh et al.  <cit>  and ross et al.   <cit> .

in their processed form, the datasets are available from the corresponding author on request.

authors’ contributions
ab and lw discussed and designed the experiments; ab conducted the experiments and drafted the paper; lw revised the paper. both authors read and approved the final manuscript.

competing interests
the authors declare that they have no competing interests.

consent for publication
not applicable.

ethics approval and consent to participate
not applicable.
