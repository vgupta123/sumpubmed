BACKGROUND
in applying general parsers to specific domains, adaptation is often necessary to achieve high parsing performance . sublanguage is defined by grishman  <cit>  as a specialized form of a natural language that is used within a particular domain or subject matter. it is characterized by specialized vocabulary, semantic relationships, and in many cases syntax.

in this paper, we study lexical adaptation, that is, adaptation addressing the specialized vocabulary. this is an important part of the process of customizing a general parser to a sublanguage. among other issues, the unknown word rate increases dramatically when moving from general language to increasingly technical domains such as that of biomedicine  <cit> . this can lead to increased ambiguity, reduced parsing performance, and errors in establishing the correct relationships between words for semantic mining  <cit> .

until recently, most information extraction  systems for mining semantic relationships from texts of technical sublanguages avoided full syntactic parsing. the quality of parsing has a well-established effect on the performance of ie systems, and the accuracy of general parsers in technical domains is comparatively low. additionally, many domain-specific parsers lack portability to a new domain. finally, the time required for full parsing is also a problem for ie systems. however, the biomedical ie community now faces limitations in pattern-matching  <cit>  and shallow parsing  <cit>  methods that are inefficient in the processing of long distance dependencies and complex sentences. advances in parsing techniques have further created an increased interest in the adaptation of full parsers, and there have recently been several applications of full parsers in the biomedical domain  <cit> .

here, we consider the lexical adaptation of a full parser, the link grammar parser  of sleator and temperley  <cit> . the choice of parser addresses the recent interest in lgp in the biomedical ie community  <cit> . our evaluation is performed using two corpora of sentences from medline abstracts with a focus on protein-protein interactions, the identification of which is the key aim of many biomedical ie systems.

recently, two approaches addressing unknown words in applying lgp to the biomedical domain have been proposed. szolovits  <cit>  introduced a method for heuristically mapping terminology between lexicons and applied this mapping to augment the lgp dictionary with terms from the umls specialist lexicon  <cit> . based on an analysis of a domain corpus, two of the authors have proposed an extension of the morpho-guessing system of lgp for disambiguating domain terms based on their suffixes  <cit> . the effect of the proposed extensions on parsing performance against an annotated reference corpus was not evaluated in these two studies. here we analyze the effect of these lexical extensions using an annotated biomedical corpus. we further propose, implement and evaluate in detail a third approach to resolving unknown words in lgp using information from a part-of-speech  tagger.

the evaluated lexical adaptation approaches address unknown single-word units: related adaptation issues such as multi-word expressions, grammar adaptation, text preprocessing, handling of complex terms, improved parse ranking and named entity recognition fall outside the scope of this study.

link grammar parsing
the lexical adaptation approaches we evaluate require only a light linguistic analysis of domain language, facilitating their application to domain adaptation. similarly, as link grammar is rule-based and its parser makes no use of statistical methods, lgp is a good candidate for adaptation to new domains where annotated corpus data is rarely available.

the link grammar formalism is closely related to dependency formalisms. it is based on the notion of typed links connecting words. the result of parsing is one or more ordered parses, termed linkages. a linkage consists of a set of links connecting the words of a sentence so that links do not cross, no two links connect the same two words, and the types of the links satisfy the linking requirements given to each word in the lexicon. for example, the linking requirements for a singular countable noun specify that the word must form a d link to the left to connect to a determiner. two linkages for an example sentence are shown in figure  <dig> 

lgp has three different methods applied in a cascade to handle vocabulary: dictionary lookup, morpho-guessing and unknown word guessing. the lgp dictionary enumerates all words, including inflected forms, and grammar rules are encoded through the linking requirements associated with the words. some unknown words are assigned linking requirements based on their morphological features, such as the suffix -ly for adverbs. this system is termed morpho-guessing . finally, words that are neither found in the parser dictionary nor recognized by its morpho-guessing rules are assigned all possible combinations of the generic verb, noun and adjective linking requirements. this general approach is, in principle, always capable of generating the correct combination of linking requirements for unknown words. however, with an increasing number of unknown words in a sentence, the approach leads to a combinatorial explosion in the number of possible linkages and a rapid increase in parsing time and decrease in parsing performance. the parser is also time-limited: when a sentence cannot be parsed within a user-specified time limit, lgp attempts parses using more efficient, but restricted settings, leading to reduced parse quality. when parsing sublanguages that contain many words that are not in the lexicon, it is therefore beneficial to attempt to resolve unknown words to reduce ambiguity in parsing.

methods
we evaluate three approaches to lexical adaptation: lexicon extension, morphological clues, and pos tagging. the approaches primarily involve open-class words and use linking requirements from the original lgp. closed-class words, such as prepositions, are considered domain-independent and expected to appear in the original lexicon, and we have chosen not to perform any modification of the existing linking requirements  in this study.

extension of the lexicon
the extension of the lexicon with external domain-specific knowledge is the most frequent approach to adaptation, provided that the resources are available for the domain. this can be done either manually or with automatic mapping methods.

here, we evaluate the heuristic lexicon mapping proposed by szolovits  <cit> . this mapping can be used to automatically add domain-specific terminology from an external specialized lexicon to the lexicon of a parser. words are mapped from a source lexicon  to a target lexicon  based on their lexical descriptions. as these descriptions typically differ between lexicons, they cannot be transferred directly from one lexicon to another. instead, the mapping operates with sets of words that have the exact same lexical description in their respective lexicons.

to assign a lexical description to a word w not in the target lexicon, the mapping finds words that have the exact same lexical description as w in the source lexicon, and that further have a description in the target lexicon. overlap in sets having the same descriptions is then used to select one of these target lexicon descriptions to assign to w.

szolovits applied the introduced mapping to extend the lexicon of lgp with terms from the umls specialist lexicon and observed that the mapping heuristic chose poor definitions for some smaller sets, for which the definitions were manually modified. the created dictionary extension contains  <dig>  words that do not appear in the original lgp dictionary. the effect of adopting this extension has also been considered by pyysalo et al.  <cit> .

we chose to evaluate the version of the dictionary extension that does not include multi-word terms  <cit>  for the following reasons. first, szolovits observed that many of the phrases included in the extension "bear no specific lexical information in specialist that is not obvious from their component words", suggesting that it is sufficient to include the component words in the parser lexicon separately. additionally, multi-word phrases entered into the lgp lexicon are parsed using the lgp idiom system, which does not assign internal structure to the phrases. thus, if the phrases were included, automatic comparison against a reference corpus containing phrase-internal structure would find missing links for the terms.

morphological clues
morphological clues can be exploited by lgp to predict the morpho-syntactic classes  of unknown words. specific domains are an interesting application for this type of adaptation because a great part of technical lexicons presents regular morphological features, which, according to mikheev  <cit> , obey morphological regularities of the general language. we observe that this assumption holds only partially because of the presence of foreign words in specialized texts and argue that a minimal morphological study of the corpus is necessary. such studies have been performed, on the biomedical domain by spyns  <cit>  and aubin et al.  <cit> .

while many pos taggers employ morphological features to tag unknown words, domain extension of a rule-based approach such as the lgp morpho-guessing system can be preferable in lexical adaptation to domains where resources such as tagged corpora are not available for training taggers. further, the mg extension allows assigning specific rules at a finer granularity than pos tags.

we have implemented and evaluated the extension of the lgp morpho-guessing rules proposed by aubin et al.  <cit> . this extension of  <dig> new suffixes for the biomedical domain is presented in table  <dig>  aubin et al. further identified a small number of exceptions to these rules , which were manually added to the dictionary.

pos tagging
finally, we propose to provide the parser with an input sentence enriched with pos tags. in order to retain the decision-making power of the parser and to avoid inconsistencies between tagged words and their entry in the parser lexicon , we restrict the use of pos tags to unknown words only.

we modified lgp so that pos information can be passed to the parser by appending pos tags to input words . we further modified the parser so that when an unknown word is given a pos tag, the parser assigns linking requirements to the words based on a given mapping from pos tags to lgp dictionary entries. we defined such a mapping, presented in table  <dig>  for penn tagset pos categories corresponding to content words. fw  and sym  tags were not mapped due to their syntactic heterogeneity. existing lgp rules were used to define the behaviour of pos-mapped words, and the most generic applicable rule was chosen in each case. for instance, words tagged nn map to the rule for nouns that can be either mass or countable, so that there is no constraint on determiners.

to evaluate the effect of using both a tagger for general language and a tagger for domain language, the experiments were made using two taggers: the brill tagger  <cit>  trained on the wall street journal  and the genia tagger   <cit>  trained on a combination of the wall street journal and the biomedical corpora genia  <cit>  and pennbioie  <cit> . note that in comparing taggers trained on different resources, we observe both effects relating to the training corpus and effects relating to the performance of the tagger.

a detailed evaluation and error analysis of genia tagger is given in  <cit> , finding 98% accuracy on two biomedical corpora. as part of the present study, a linguist evaluated the subset of words in the interaction corpus that are handled by the pos-mapping method and show tagging divergence between the two taggers . on the basis of this comparison and the reported performance of genia tagger, we estimate that for the subset of words that are handled by the pos-mapping method, the tagging accuracy is 81% for the brill tagger and 97% for genia tagger.

evaluation protocol
two corpora are used for the present evaluation: "interaction" and "transcript", both built in the context of ie from biomedical texts. both corpora were tokenized and cleared of bibliographic references in a preprocessing step.

interaction contains  <dig> sentences  annotated for dependencies using the link grammar annotation scheme.  <dig> sentences were initially selected randomly from pubmed with the condition that they contain at least two proteins for which a known interaction was entered into the dip database  <cit> .  <dig> sentences consisting only of a nominal phrase were then excluded as the lgp grammar is only designed to analyse full clauses – this limitation could be overcome by modification of the grammar, but here we decided to avoid grammar adaptation and evaluate lgp with respect to its intended coverage. each sentence was separately annotated by two annotators, and differences were resolved by discussion. links to punctuation were excluded, and link types were not annotated. a total of  <dig>  links were annotated in these sentences.

the transcript corpus is made of  <dig>  sentences  consisting of the result for the query "bacillus subtilis transcription" on pubmed. it was not annotated.

both corpora are used to characterize the vocabulary coverage by the different methods applied in lgp. the annotated interaction corpus is also used as the reference corpus for the evaluation of parsing performance. aubin et al.  <cit>  used the transcript corpus in defining the mg extension rules. by contrast, the interaction corpus, used here to evaluate performance, is a blind test set with respect to all evaluated extensions.

we first evaluate vocabulary coverage in the original and extended versions of lgp. we present the contribution of each method  implemented in lgp to handle vocabulary. results are given separately for types  and tokens  in the corpus.

we assess the ambiguity of the parsing process with two criteria: parsing time and linkage numbers. parsing time is immediately relevant to applications of the parser to systems where large corpora must be parsed. linkage numbers are a more direct measure of the ambiguity of parsing a sentence. for each sentence, the parser enumerates the total number of linkages allowed by the grammar. by taking the ratio of the number of linkages allowed by two versions of the parser, we can estimate the relative increase or decrease in ambiguity. we report the per-sentence averages of both parsing time and linkage number ratios.

to determine the parsing performance of the extensions of lgp, we used each of the extensions to parse the interaction corpus sentences and compared the produced linkages against the reference corpus. for each sentence, we determine the recall, i.e. the fraction of links in the reference corpus that were present in parses returned by lgp. note that for connected, acyclic dependency graphs, precision equals recall: for each missing link, there is exactly one extra link. while there are some exceptions to connectedness and acyclicity in both lgp linkages and the annotation, we believe recall can be used as a fair estimate of overall performance. for each sentence, we measure recall for both the first linkage as ordered by the lgp heuristics and, to separate the effect of the heuristics from parser performance, also the best linkage, that is, the linkage that is most correct with respect to the annotated corpus . as parse reranking methods can be used to improve over the lgp heuristics in parse ordering  <cit> , it is also important that best linkage performance is not decreased in adaptation. we further separately evaluate overall performance and performance for the subset of sentences where no timeouts occurred in parsing.

experiments were performed on a  <dig>  ghz intel xeon with parameter values timeout =  <dig> sec, limit =  <dig>  islands-ok = true. default values were used for other parameters. the statistical significance of differences between the original parser and each of the modifications is assessed using the wilcoxon signed-ranks test  <cit>  for overall first linkage performance, using the bonferroni correction for multiple comparisons, following the recent recommendation of demšar  <cit> .

RESULTS
in this section we present the evaluation results for the original lgp , lgp with the umls specialist dictionary extension , lgp with the morpho-guessing extension  and lgp with the pos extension, evaluated with the two taggers, brill and genia tagger .

vocabulary coverage
the comparison of the results on types and tokens shows that the dictionary has a good recognition rate on frequent types for both the original and the umls versions. by contrast, the mg and pos-map methods contribute to the recognition of a great number of types  but few tokens. in addition, the discrepancy in types between the two corpora for the dictionary method in all versions reflects the increasing presence of low-frequency non-canonical words with the growing size of the corpus. interestingly, we find that the reduction in unknown words due to the umls and xmg extensions is roughly similar, despite the former containing over  <dig>  new words and the latter only  <dig> new rules. the pos extension, as expected, reduces the part of unknown words to almost null.

the nature of the words that remain unknown varies depending on the extension. quite surprisingly, umls specialist lacks a great number of species names  and frequent gene or protein names . in addition, the version of the dictionary extension used here contains no multi-word terms, which prevents the detection of words like vitro and vivo used in the frequent terms in vitro and in vivo. the evaluated xmg extension cannot handle gene/protein names either, and also misses frequent technical terms that have no specific morphological features, such as sigma, mutant and plasmid.

to assess lexicon coverage, we measured the contribution  and the recognition  of the umls specialist dictionary extension. we find that while the contribution of the umls extension is very low, with  <dig> % on interaction and  <dig> % on transcript, the recognition of the dictionary method is augmented significantly by the umls extension . nevertheless, as the size of the dictionary does not significantly penalize the parsing time with lgp, even a generic resource that contributes relatively little can be beneficial.

ambiguity
the results of measuring the effect of the various extensions on ambiguity are given in table  <dig> 

the reduction in the number of unknown words for the umls and xmg extensions is coupled with a roughly 30% reduction in both parsing time and linkage numbers. although the pos extension essentially eliminates unknown words, it only gives a decrease in parsing time and linkage numbers that roughly mirrors the effect of the umls and xmg extensions.

none of the extensions achieves more than 35% reduction in linkage numbers or more than 45% reduction in parsing time. this may reflect structural ambiguity in the language and suggest a limit on how much ambiguity can be controlled through these lexical adaptation approaches.

performance
the evaluation results are presented in table  <dig>  we find that in addition to increased efficiency, all of the extensions offer an increase in overall parsing performance compared to the original lgp for both the first and best linkages. remarkably, this increase occurs even with the brill tagger, which was trained on general english. in overall performance, the umls extension and the pos extension with the brill tagger are roughly equal. the xmg extension outperforms both, and the pos extension with genia tagger has the best performance of all considered extensions.

the positive effect of the extensions on parsing performance is linked to the reduced number of timeouts that occurred when parsing. effects not related to time limitations can be studied on sentences where no timeouts occurred . here the effects of the extensions diverge: for the first linkage, performance with the umls extension and the pos extension with the brill tagger essentially matches that of the unmodified lgp, while performance with xmg and genia tagger remains better. for the best linkage, we observe a negative effect from the umls extension, indicating that for some words the unknown word handling mechanism of lgp finds correct links that are not allowed by the linking requirements given to those words in the extended dictionary. this suggest that some errors have occurred in the automatic mapping process. an example of one such error is in the mapping of abbreviations  to countable nouns, leading to failures to parse in the absence of determiners. we similarly observe the expected decrease in performance for the brill tagger for the best linkage, reflecting tagging errors.

even for the best linkage in sentences where no timeouts occurred, the performance with the xmg extension and the pos extension with genia tagger is better than that of the original lgp. these extensions can thus assign more appropriate linking requirements for some words than the unknown word system of lgp. this indicates high tagging accuracy for genia tagger as well as an appropriate choice of linking requirements for both extensions, and suggests some limitation in the unknown word system of lgp.

despite significant improvements in parsing performance, the best performance achieved by any lgp extension is 88%. this may again suggest a limit on what performance can be achieved through the lexical adaptation approaches.

combinations of the extensions
the umls, xmg and pos tagging extensions are to some extent complementary as their coverage of the corpus vocabulary does not completely overlap. the umls extension provides the most frequent domain-specific lexical items while the xmg extension has the advantage of being able to handle non-canonical  and rare words and misspellings. the pos extension can benefit from the context-sensitiveness of the tagger to disambiguate words.

we evaluated all possible combinations of the three extensions. in these experiments we only used genia tagger for the pos extension. the results are given in tables  <dig> and  <dig> 

on ambiguity, we observe small advantages for many of the combinations, but rarely more than a 10% reduction for either metric compared to the simple extensions. the effect of the combinations on overall performance is mixed. while all combinations outperform the original lgp, combinations involving the umls extension appear to perform worse than those that do not, while combinations involving the xmg and pos extensions perform better. for sentences where no timeouts occurred the effect is simple: for the best linkage, all combinations involving the umls extension perform worse than the original lgp; only the combination of the xmg and pos extensions is better.

the performance of the best combination approach essentially matches that of the pos extension with genia tagger alone, suggesting that no further benefit can be derived from combinations when an accurate domain tagger is available.

CONCLUSIONS
we have studied three lexical adaptation approaches addressing biomedical domain vocabulary not found in the lexicon of the link grammar parser: automatic lexicon expansion, surface clue based morpho-guessing, and the use of a pos tagger. we found that in a time-limited setting, any approach resolving unknown words can improve efficiency and overall performance. in more detailed evaluation, we found that the automatic dictionary extension and the use of a general english pos tagger can reduce performance, while the morpho-guessing approach and the use of a domain-specific pos tagger had only positive effects. we found no further benefit from combinations of the three approaches.

generally, our results suggest that when available, a high-quality domain pos tagger is the best solution to unknown word issues in the domain adaptation of a general parser, here providing an overall 10% relative reduction in error combined with a 45% decrease in parsing time. we note that a comparable 14% reduction was also achieved by lease and charniak through pos adaptation for a statistical constituency parser  <cit> . this further enforces our conclusion on the value of accurate pos tags in support of the parsing process.

in the absence of a domain pos tagger, the use of a general pos tagger is a poor substitute, and can lead to decreased performance. the use of heuristic methods for lexicon expansion carries the risk of mapping errors and should be accompanied by an evaluation of the effect on parsing performance. conversely, surface clues can provide remarkably good coverage and performance when tuned to the domain, here using as few as  <dig> new rules.

our implementation of the adaptations to lgp combines the morpho-guessing extension with the capability of using information from a pos tagger. thus, the adapted parser is faster and more accurate than the unmodified lgp in parsing biomedical texts both when used as such and when used together with a domain pos tagger. further, both extensions are implemented so that defining other morpho-guessing rules and pos-mappings is straightforward, facilitating adaptation of the modified parser to other domains. the adapted lgp is available under an open-source licence at  <cit> .

while we found that the considered approaches can significantly improve efficiency and parsing performance, our results also indicate some limitations for lexical adaptation. as future work, complementary approaches addressing multi-word expressions, grammar adaptation, text preprocessing, handling of complex terms, improved parse ranking and named entity recognition can be considered to further improve the applicability of lgp to the biomedical domain.

