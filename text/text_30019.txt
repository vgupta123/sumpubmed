BACKGROUND
dna microarray is a popular high-throughput technology for the monitoring of thousands of gene expression levels simultaneously under different conditions  <cit> . the typical purposes of microarray studies are to identify similarly expressed genes under various cell conditions and associate the genes with cellular functions <cit> .

the analysis performed to meet the purposes of microarray studies mentioned above usually involves clustering genes according to their pattern of expression levels in various experimental conditions. in fact, cluster analysis means grouping samples  by similarity in expression patterns. to measure the similarity in cluster analysis, correlation distance and euclidean distance are widely used <cit> . principal component analysis  is also a powerful technique when used with the clustering method to specify the number of clusters <cit> . however, these widely-used methods in microarray data analysis can be both seriously biased and misled by missing values in the dataset <cit> .

missing values of microarray data commonly occur during data preparation mainly due to imperfections in the various steps in dna microarray experiments. one of the yeast microarray data sets shows that the number of genes having at least one missing value was  <dig> of  <dig> rows   <cit>  and  <dig> of  <dig> rows   <cit> ; and  <dig> of  <dig> rows   <cit>  had missing values in other reports. as mentioned previously, some statistical analyses require complete data sets and one should discard the entire data in a row, usually all the values for one gene, that have a single missing value. the rows with missing values can be utilized for further analyses after the imputation of the missing values in many cases. imputation has been used in many fields to fill the missing values in incomplete data using observed values. there are many different algorithms for imputation: hot deck imputation and mean imputation  <cit> , regression imputation  <cit> , cluster-based imputation  <cit> , and tree-based imputation  <cit> , maximum likelihood estimation  <cit> , and multiple imputations  <cit> . proper selection of an algorithm for a given data set is important to achieve maximum accuracy of imputation.

recently, several methods have been applied to the imputation of microarray data, including row average  <cit> , singular value decomposition   <cit>  and knn imputation  <cit>  methods. in general, it seems the recently developed knn-based method is most efficient. knn imputation method is an improved hot deck imputation method  <cit>  that uses the mean values of most similar genes for estimating missing values. the knn imputation method can be considered a cluster-based method since missing values are imputed using selected similar genes. in the previously developed method, the efficiency of imputation was limited both in accuracy and computational complexity in that it did not efficiently use the information of the gene having missing values. the existence of missing values in a gene limits the use of other observed values of that gene in the conventional imputation method. in our work, this problem could be improved by using the imputed values sequentially for the later nearest neighbor calculation and imputation. we suggest a sequential knn  imputation method that boasts improved accuracy in estimation of missing values in a wide range of missing rates with high computational speed. we also suggest an em-style sequential knn  method that uses a sequential knn method repeatedly to improve accuracy. we evaluated the efficiency of the sknn imputation method through comparison with the known knn-based method and other well known imputation methods such as maximum likelihood estimation  and multiple imputations .

RESULTS
we evaluated the efficiency of our new sknn method and the em-sknn method with three other imputation methods: knn-based imputation, the mle method, the mi method, by applying them to three different types of microarray data sets with different missing rates. the appropriate number  of nearest neighbors was dependent on the data types and missing rates. the rms errors were minimal when k was  <dig> for time-series data and mixed type data regardless of the missing rate, and the rms errors of the non-time series data showed similarly low values when k values were between  <dig> and  <dig>  for comparison of different imputation methods, we used  <dig> for k which showed a minimal rms error in every data type with different missing rates.

the performance of the knn-based imputation method depends on the similarity of k-nearest neighbors to be used for imputation. the overall similarity of the entire data set can affect, on average, the similarity of all possible k-nearest neighbors. the time-series data set, which has the narrowest distribution of euclidean distances among genes, shows the least rms error after imputation as we can see in figure  <dig> and  <dig>  figure  <dig> also shows that the performances of the sknn and em-sknn methods are better than that of the conventional knn method over a whole range of tested missing rates. the range of rms error by the new sknn method, for example, was  <dig>  to  <dig>  in comparison with  <dig>  to  <dig>  of the knn method in time-series data. the accuracies of our new methods are especially superior when the missing rate is over 30%. the rms errors for time-series and non-time series data nearly approached their maximum values at missing rates of 50% and 60%, respectively, in the knn method. the rms error of the mixed data set is stable over a wide range of missing rates, but becomes unstable and increases dramatically after a 40% missing rate. the slight difference of knn algorithm could lead to a large improvement in the accuracy of imputation at a high missing rate because the sknn method is able to select more similar k-neighbors than the conventional knn method as the missing rate grows. in the conventional knn method, the selection pool and the dimension  of the distance measurement of neighbor genes are reduced according to the increase of missing rate. in this situation, the method inevitably selects less related  neighbors for imputation. in addition, the size of data set can limit the maximum missing rate for stable imputation. in our data sets, the size of a mixed data set is about 20% larger than other data sets, which may affect the mixed data set in terms of having stable rms error in a relatively larger  range of missing rate.

we tested the performance of other well known non-knn-based methods such as maximum likelihood estimation  and multiple imputations  methods. these methods are well known imputation methods but there has been no report on their application in microarray data analysis. the efficiency of the mle method was much worse than the sknn method for all tested data sets. the rms errors in the mle method were  <dig>  to  <dig>  in time-series data,  <dig>  to  <dig>  in mixed data, and  <dig>  to  <dig>  in non-time series data. the efficiency of the mi method was generally similar to sknn but the former is more dependent on data types. the efficiency of the mi method was better at a lower missing rate, but slightly worse at a higher missing rate for the time-series data set. the mi method was worse than sknn in terms of overall range of missing rate of non-time series data. however, the best imputation method for mixed data set proved to be the mi method. we can conclude that the mi method is as efficient as the sknn method for the imputation of microarray data, even though the efficiency of the mi method experienced more fluctuations than the sknn method depending on the data type.

the result is similar in a comparison of overall rms error after imputation of a data set having unequally distributed missing entries over the columns. we show a comparison of one of the data sets  in table  <dig>  as expected, the efficiency of the sknn method is higher, especially for the data sets having a higher missing rate.

for more careful estimation of imputation efficiency, we examined the structure of data after imputation. we calculated the pearson correlation coefficients for each column  between original data and imputed data. the larger the correlation coefficient is, the better the relationship between original complete data and imputed data is preserved in a column. figure  <dig> shows that the sknn method preserves the structure of the original data set better than the conventional knn method and mi method for all columns of the time-series data set. the situation was the same for the other data sets . interestingly, the mi method was much worse than the sknn method, differing from rms error analysis. this column-wise comparison gives us more specific information on the efficiency of imputation method. in figure 3-b, we can see that the performance of sknn is relatively better for the column with highly missing entries  than for other columns. through measuring the means and standard deviations for each column of data sets, we discovered that the dispersion of values in a column does not affect the accuracy of knn-based imputation.

the sknn algorithm improves execution time for imputation. the computational complexities are approximately o in the conventional knn method and o in the sknn method for a matrix with m rows  and n columns . this is because the sequential knn algorithm imputes all missing values in a gene simultaneously with given nearest neighbors, while the conventional knn method must calculate neighbors for each missing entry. the application of expectation maximization  to the sequential knn method marginally improved the accuracy in compensation for the increase of computational time proportional to the number of iterations. for mi methods, the execution time increased as m times of single imputation method when mi used m multiple imputation. using the sknn imputation method, it took  <dig>  seconds on a pentium iv  <dig>  ghz computer to estimate missing values for a data set with  <dig> genes,  <dig> experiments and a 40% missing rate. the processing time using the em-sknn method was proportional to the number of iterations.

discussion
the sknn method offers better performance than the previously developed knn method for both time series and non-time series microarray data sets and for data sets having different missing patterns. as the missing rate increased, sequential reuse of imputed data did not propagate errors of imputation as in the conventional knn method. it showed the best improvement of accuracy for the data set with a high missing rate.

notably, the sknn method is also robust on the imputation of a data set with unequally distributed missing entries. a real microarray data set usually has non-random distribution of missing data. furthermore, some systematic errors during the experiment can generate an abnormal increase in distribution of missing entries for the corresponding column of microarray data set. in this type of data, the sknn method, which is especially efficient on the data set having heavy missing entries, can exert relatively more accurate imputation than other imputation methods as shown in our model data set. the mi method has not been well introduced in the field of microarray analysis, although it is a well known imputation method in other fields  <cit> . in comparison with the sknn method, we discovered the potential of the mi method for microarray analysis. the mi method did not preserve original data structure as well as the sknn method, but the overall rms error was close to the sknn method. the mi method is executed under the assumption of multiple normality of all dimensions of data. this assumption may not be satisfied in real-world data. nevertheless, the performance of the mi method was much higher than the simple knn method, which suggests that the mi method is practically applicable for the imputation of microarray data.

the computational complexity is reduced in the sknn method for the dimension of both the number of genes and the experiments compared with the simple knn method. particularly, computation time can be saved substantially for microarray data with a large number of experiments. the sknn method works efficiently in a wider range of missing rate with high speed. we want to emphasize that our results showed that the method using estimated values achieved even better accuracy than the method using only observed values in the case of the knn-based imputation method. we suppose that this result could be applicable to other cluster-based analysis. it would be hardly acceptable for the experimentalist to use imputed data for further analysis. however, analysis could become more errorneous without imputation due to loss of information caused by missing values. the use of imputed data should definitely depend on the type of later process. if the next process is a cluster-based analysis, the genes with imputed values could be efficiently used, as we had good results for knn-based imputation with the reuse of imputed values. for future works, it may be possible to integrate the imputation and gene clustering of microarray data for classification of genes with proper evaluation steps. this may offer more and better information sources of microarray data for the final decision of gene classification. all the procedures used in this paper are done by r-code and c++ and the programs are available upon request.

CONCLUSIONS
the sknn method is an especially efficient imputation method on data having high missing entries. it can be practically useful in saving data of some accidental microarray experiments having high missing entries. our results also suggest that the imputed values generated by the sknn method can be used reliably for further cluster-based analysis of microarray data.

