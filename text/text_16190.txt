BACKGROUND
micrornas  are ∼ <dig> bases long rnas that post-transcriptionally control multiple biological processes, such as development, hematopoiesis, apoptosis and cell proliferation  <cit> . mature mirnas are derived from longer precursors called pre-mirnas that fold into hairpin structures containing one or more mature mirnas in one or both arms  <cit> . their biogenesis is highly regulated at both transcriptional and post-transcriptional levels  <cit> , and disregulation of mirnas is linked to various human diseases, including cancer  <cit> .

identification of mirna is a challenging task that allows us to better understand post-transcriptional regulation of gene expression. in last ten years a number of experimental and computational approaches were proposed to deal with the problem. however, experimental approaches, including direct cloning and northern blot, are usually able to detect only abundant mirnas. micrornas that are expressed at very low levels or in a tissue- or stage-specific manner, often remain undetected. these problems are partially addressed by applying the deep-sequencing techniques that nevertheless require extensive computational analyses to distinguish mirnas from other non-coding rnas or products of rna degradation  <cit> .

computational approaches in mirna search can be homology-based, take advantage of machine learning methods, or use both of these. homology-based approaches rely on conservation of sequences, secondary structures or mirna target sites . as a result, these methods are not suitable for detection of lineage- or species-specific mirnas and mirnas that evolve rapidly. moreover, they are strongly limited by the current data and performance of available computational methods, including alignment algorithms  <cit> . another problem is that there are as many as ∼ <dig> million sequences that can fold into mirna-like hairpins in the human genome  <cit> , some of which originate from functional, non-mirna loci. it is therefore no surprise that a large number of hairpins that are conserved between species could be mistakenly classified as mirnas. nevertheless, homology search has been successfully applied in many mirna gene predictions, in both animals and plants  <cit> .

in some approaches, e.g. palgrade  <cit>  or mirdeep  <cit> , experimental and computational procedures are combined. however, as mentioned above, experimental methods can not easily detect low-expression or tissue-specific mirnas and/or they have to meet computational challenges, as in the case of deep sequencing technology. mirdeep, for instance, aligns deep sequencing reads to the genome and selects the regions that can form a hairpin structure. then, using a probabilistic model, the hairpins are scored based on the compatibility of the position and frequency of sequenced reads with the secondary structure of the pre-mirna. this method achieves high specificity at the cost of relatively low sensitivity.

machine learning methods are amongst the most popular ways of mirna identification nowadays. they share the same overall strategy. first, the features of primary sequence and secondary structure are extracted from known mirnas  and non-mirna sequences . then, the features are used to construct a model which serves to classify candidate sequences as real pre-mirnas or pseudo pre-mirnas. there are several machine learning methods that have been applied in the field of mirna identification. these include hidden markov models   <cit> , random forest  <cit>  and naïve bayes classifier  <cit> . support vector machine, however, seems to be the most popular framework nowadays and has been used in a number of well recognised tools. for instance, triplet-svm  <cit>  classifies real human pre-mirnas and pseudo pre-mirnas using  <dig> structure- and sequence-derived features that refer to the dot-bracket representation of the secondary structure i.e. it considers the frequencies of triplets, such as "a. secondly, most of existing mirna classifiers work well on data from model species and closely related ones; the classifiers trained on human data best fit the mirna identification problem in human and other primates but perform unsatisfactorily when applied to, for example, invertebrates. finally, the imbalance problem between the positive and negative classes is usually not addressed properly, while this is a crucial issue, as the number of micrornas throughout a genome is much lower than the number of non-micrornas . the resulting difference in misclassification costs of positive and negative classes requires special techniques of learning from imbalanced data as well as a proper assessment metrics. moreover, in order to accurately judge classifier performance in real-life applications, the problem of imbalance should be reflected in the testing datasets.

in this study we addressed all these issues. we made no preliminary assumptions about mirna structure and carefully took into account class imbalance problem. we implemented a procedure of thresholding score function produced by traditional classifiers and called it roc-select. this strategy turned out to be superior to other imbalance-suited techniques in mirna classification. from all classifiers for which roc-select procedure was applied we chose random forest as it yields the best balance between sensitivity and specificity. regarding the data representation, we introduced seven new features and show that they further improve the classification performance. in the experiments we considered large and strongly imbalanced up-to-date sets of positive and negative examples, paying much attention to the data quality. the tests were performed using stratified 10-fold cross-validation  giving reliable estimates of classification performance. finally, we show that the method outperforms the existing mirna classification tools, including micropred, without compromising the computational time.

our mirna classification method is freely available as a framework called huntmi. huntmi comes with trained models for animals, plants, viruses and separately for h. sapiens and a. thaliana. as a result, the tool can be used in mirna classification experiments in a wide range of species. the user can use built-in models in the experiments or train new models using custom datasets prior to classification.

methods
datasets
in order to create positive sets, we retrieved all pre-mirnas from mirbase release  <dig>  <cit>  and filtered out the sequences lacking experimental confirmation. by using evidence-supported mirnas only, we minimize the chance of introducing false positives into the set. the sequences were divided into five groups: h. sapiens, a. thaliana, animals, plants, and viruses.

negative sets were extracted from genomes and mrnas of ten animal and seven plant species as well as twenty nine viruses . additional sets were prepared for h. sapiens and a. thaliana. start positions were randomly selected, whereas end positions were calculated so that the sequence length distribution in the resulting negative dataset is the same as in the corresponding positive one. with this approach, the classifier achieves better performance when applied in real-life experiments, where mirna candidates tend to have lengths similar to those of known mirnas. finally, in order to remove known mirnas together with similar sequences that possibly represent unknown homologs of mirnas, we ran blastn search against mirbase hairpins and filtered out sequences that produced e-value of 10− <dig> or lower.  <dig> % of negative sequences prepared in this way possess structural features of real pre-micrornas, including the minimum free energy below - <dig>   and number of pairings in the stem above  <dig>  . at the same time these criteria are met by  <dig> % of hairpins stored in mirbase.

positive and negative sequences from the analysed species were gathered to form complete datasets that correspond to mirna classification problem in the taxa. they will be referred to as human, arabidopsis, animal, plant and virus . in addition, we used the dataset from micropred. it contains  <dig> non-redundant human pre-mirnas from mirbase release  <dig>   <dig> non-mirna ncrna,  <dig>  <dig> pseudo hairpins and is denoted as micropred.

characteristics of biological datasets used in the experiments. imbalance is defined as a ratio of #negatives to #positives. we limited dataset imbalance to several tens for practical reasons even though proportions of mirnas to non-mirnas in genomes are more extreme. in the case of virus dataset the imbalance is exceptionally low as we wanted to know how methods perform on moderately imbalanced problems. in addition, it is difficult to create representative dataset for viruses as their genomes differ significantly in sizes and most of them do not contain mirnas.

features
the twenty one features selected by  <cit>  were used as a base representation in the experiments. thus, we employed micropred scripts for extracting necessary attributes. in the case of micropred dataset we took precalculated features from webpage to make our results comparable with the existing research .

beside twenty one micropred features, we calculated seven additional sequence- and structure-related attributes. first, we considered the frequencies of secondary structure triplets composed of three adjacent nucleotides and the middle nucleotide. we chose four of them that were shown to have the highest information gain  <cit> : "a.

imbalanced learning
extensive research on imbalanced data classification has proven that standard machine learning techniques often overlearn a majority class sacrificing minority examples  <cit> . therefore, special approaches for imbalanced problems have been developed. they can be divided into sampling methods, cost-sensitive learning, kernel methods, active learning and others  <cit> . micropred authors carried out exhaustive study of how several classification strategies from above perform in a microrna prediction task  <cit> . they used standard support vector machine as a base classifier and combined it with random over/under-sampling, smote  and multi-classifier system. they additionally tested cost-sensitive svm modifications like zsvm and dec , finding smote to be the best strategy. in the research, geometric mean  of classification sensitivity  and specificity  was used as an assessment metric. gm is common in imbalanced learning problems, including mirna identification, as it takes into account unequal misclassification costs. therefore, we also decided to use gm in huntmi study.

our approach to microrna prediction relies on the fact that classification with unequal costs is equivalent to thresholding conditional class probabilities at arbitrary quantiles  <cit> . many classifiers provide continuous score function s describing degree of a membership of instance x to particular class. ideally, such a function estimates perfectly a class conditional probability p and is denoted as well-calibrated score function  <cit> . in reality, classifiers produce scores which are often not calibrated  <cit>  thus a lot of algorithms for calibrating them have been developed  <cit> . in addition, many meta learning techniques like bagging or classifier ensembles can be employed to produce score function on the basis of class labels alone  <cit> . as long as scoring function ranks instances properly, that is s<s⇔p<p, one can successfully use s directly to classify instances with unequal costs.

our method combines the idea of thresholding classifier score function with receiver operating characteristics   <cit> . for each threshold value t established at s function, a point in a roc space can be generated. varying t from −∞ to +∞ produces entire roc curve. one can select a point on it with highest evaluation metric  and read corresponding t value. in real applications roc curves are generated by simply sorting elements of dataset by s values and updating true positive  and false positive  statistics for consecutive points. in order to prevent threshold selection procedure from overfitting towards training data, a separate set should be used for constructing roc curve. hence, an internal cross-validation with k <dig> folds is employed for this purpose. as we are not interested in variance, roc curves are averaged in a straightforward way - instances from all tuning folds together with assigned s values are gathered in a single set on which roc generation procedure is applied  <cit> . threshold leading to the highest value of evaluation metric is stored and used for classification of unknown instances. the threshold selection procedure described above will be referred to as roc-select.

in the research we apply roc-select only on classifiers directly providing scoring function, no meta learning techniques were examined. these classifiers are naïve bayes  <cit> , multilayer perceptron  <cit> , support vector machine  <cit>  and random forest  <cit> . we used radial basis function as an svm kernel as it is known to produce best classification results in wide range of applications  <cit> . in order to compare proposed strategy with other methods, we additionally tested smote filter  <cit>  combined with svm as it gave best results in micropred experiments and a novel method of asymmetric partial least squares classification , which came out to be superior to other strategies on several strongly imbalanced datasets  <cit> .

parameter selection and complexity analysis
in many studies including microrna prediction, classifier parameters are selected in order to obtain best possible results for a particular domain. hence, we decided to place parameter tuning phase in our pipeline as a preceding step for threshold selection. parameter selection is also done with an internal cross-validation with a number of folds equal to k <dig> and is straightforward. at first, a search space is defined by specifying a number of discrete values for each parameter to be tuned. then, full cross-validation procedure is performed for each point in that space. combination of parameter values leading to the highest average evaluation metric  is stored and used in threshold selection and, finally, for classification of unknown instances.

let us denote number of points in the parameter space to be examined as λ. in addition, let l and t indicate time complexities of training and testing procedures for given classifier with respect to the dataset size n. roc-select and parameter tuning are performed in o/k1)+t)+nlogn) and o/k2)+t)) time, respectively. as /k< <dig> entire procedure is bounded by expression ol+k1t+λk2t+nlogn).

experimental setting
all classification experiments were carried out using stratified 10-fold cv, hence distributions of testing samples are exactly the same as for the entire datasets. taking into account strong imbalance of examined sets, obtained results approximate well the expected performance of a classifier in practical applications. additionally, 10-fold cv was proven to be the best method of model evaluation in terms of bias and variance  <cit> .

the detailed configuration of examined classifiers together with parameter values tested in a tuning phase are listed below . parameters not mentioned here remained default. 

•naïve bayes: kernel estimation turned on,

•multilayer perceptron: validation set size v=20%, validation threshold e= <dig>  learning rate η= <dig> , <dig> ,…, <dig> , momentum μ= <dig> , <dig> ,…, <dig>  ,

•svm: feature normalization turned on, cost c=10− <dig> − <dig> …, <dig>  exponent in radial basis kernel γ=2− <dig> − <dig> …, <dig> ,

•random forest: number of trees i= <dig> ,…, <dig> ,

•aplsc: number of dimensions d= <dig> , <dig>  .

preliminary experiments on naïve bayes classifier confirmed that kernel estimation improves classification results, so this feature was turned on. validation threshold parameter in a multilayer perceptron indicates how many times in a row the validation set error can increase before training is terminated. early tests showed that introducing validation with this stop condition does not influence classification results but significantly reduces training time, therefore we decided to use it in our research. smote filter was configured to balance positive and negative sets perfectly. svm parameters in smote + svm combination were tuned with a wider range of values, that is c=10− <dig> − <dig> ..., <dig>  and γ=2− <dig> − <dig> …, <dig> . authors of micropred used a more exhaustive scanning strategy, however it is inapplicable for larger problems because of computational overhead. hence, we limited search space to cover parameter values selected most commonly in preliminary experiments. geometric mean  was chosen as an evaluation metric to be maximised. numbers of folds, k <dig> and k <dig>  were set to  <dig> and  <dig>  respectively. we decided to use 5-fold cv in the parameter tuning because it allowed us to reduce times of analyses with respect to 10-fold cv almost by half , rendering slightly inferior results  <cit> . this approach follows micropred, which also used 5-fold cv for parameter tuning.

roc-select strategy described in the paper was prepared as a plug-in to weka  <cit>  package which had been chosen as the basic environment for all classification experiments. it provided us with implementations of naïve bayes, multilayer perceptron, random forest and smote filter. weka interface for libsvm was used for support vector machine experiments. the original aplsc code written in matlab was wrapped in java class and also attached to weka as a plug-in.

RESULTS
threshold selection
the first step of the experiments was to check how the threshold selection strategy influences classification results. for each classifier undergoing roc-select procedure four tests were carried out: no selection , threshold selection only , parameter selection only , both parameter and threshold selection . relative gm changes of variants ii, iii and iv with respect to the variant i were calculated and averaged over all datasets beside micropred . as one can see, applying threshold selection procedure leads to significant improvement in gm values. the exception is naïve bayes for which the gain is moderate. this can be explained by intrinsic resistance of naïve bayes to the class imbalance problem - it performed well without applying roc-select. in the case of naïve bayes no parameters were tuned, thus variants iii and iv are the same as i and ii, respectively. in other cases the best results were obtained with combination of parameter and threshold tuning. it is important to note that variant ii overtakes relevantly variant iii. this confirms that standard machine learning techniques are not suited for imbalanced datasets and adjusting classifier parameters can reduce the problem of overlearning majority class only by a small marigin. to achieve best possible performance, classifiers suited for imbalanced problems  were always tested with parameter tuning turned on . for computational reasons we decided to limit parameter space from  <dig> points to  <dig> while running smote + svm on animal set .

relative percentage gains in gm obtained by applying parameter and/or threshold selection on different classifiers averaged over all datasets.

absolute values of sensitivity, specificity and gm for particular classifiers and datasets are given in table  <dig>  as applying roc-select procedure improved performance much more relevantly than parameter tuning, only results for variants iii and iv are presented. the general observation is that traditional classification algorithms at default threshold  clearly overlearn majority class and lose with smote + svm and aplsc in terms of gm. the greater class imbalance, the more visible is this regularity. for instance in the case of virus dataset, which is only slightly imbalanced, traditional algorithms perform almost as good as imbalance-suited methods. the opposite is human set, in which methods are strongly biased towards negative class giving low sensitivity  and high specificity  which results in unsatisfactory values of gm. the only exception is naïve bayes which produces results similar to smote + svm or aplsc.

applying roc-select procedure to traditional classifiers  balances their sensitivity and specificity significantly improving gm values . the best results were on average obtained for random forest which beats smote + svm and aplsc in all datasets. however, multilayer perceptron and svm also overperformed imbalance-suited methods in the majority of cases. the conclusion is twofold:  score function returned by examined classifiers properly ranks instances with respect to the conditional class probability,  roc-select procedure successfully applies this knowledge to solve imbalanced classification problem.

another interesting observation comes from comparison of imbalance-suited strategies, that is smote + svm and aplsc. our experiments confirm previous findings that aplsc is superior to smote  <cit> . it is especially visible in large and highly imbalanced sets like human or plant. we explain this by the fact that smote is able to produce only a limited number of informative examples. above some threshold value, synthetically generated instances introduce only noise. an important observation is that aplsc seems to be the only classifier which is biased towards minority class  which may be a useful feature in some applications.

if one analyses absolute results for particular datasets, it becomes clear that animal sets  are more resilient to classification than plant sets , even though they are more balanced. this is probably caused by the fact that plant mirnas are better separated from non-mirnas in the attribute space, hence they are easier to distinguish. the worst absolute results in terms of gm were observed for micropred dataset. we explain this by the low quality of this set  and lack of experimental evidence-based filtering.

statistical analysis
in order to statistically evaluate differences between classifiers, friedman rank test  <cit>  at significance level α= <dig>  was carried out with gm being chosen as a performance metric. all the datasets beside micropred were used in the procedure. we tested imbalance-suited methods  together with naïve bayes, perceptron, svm and random forest in variant iv. the resulting critical difference  diagram for post-hoc nemenyi tests  <cit>  is shown in figure  <dig>  as one can see, random forest, svm and perceptron  outperform aplsc, naïve bayes and svm + smote . random forest and svm + smote were confirmed to be the most and least accurate classifiers, respectively. the difference between them as well as the difference between svm + smote and the second best classifier  are statistically significant.

running time
time of analysis is an important issue determining applicability of presented methods for real-life problems. as all investigated algorithms are eager learning strategies, testing time was always irrelevant with respect to the training time and is not considered here. in table  <dig> medians of training times of all cv runs are given. we show results for the micropred set as it was used in other studies, together with arabidopsis , plant and animal . execution times of most time consuming algorithm variants  are given. as all the algorithms were implemented in a serial manner, single analysis utilised just one core of quad-core intel xeon w <dig>  <dig>  ghz cpu used for the experiment.

classifier training times for selected datasets . times are given in format hh:mm:ss.

one should remember that training times are influenced not only by the classification method itself, but also by the number of points in the parameter space to be analysed in a tuning stage. in the case of naïve bayes classifier no parameters were tuned, thus it was the fastest classifier in the comparison . for other classifiers undergoing roc-select procedure, 20- <dig> points were evaluated. for smaller sets, training times obtained by multilayer perceptron, random forest and svm were similar . for larger sets support vector machines scaled worse than competitors . in the case of smote + svm strategy,  <dig> points were checked . it is important to keep in mind that original micropred included more exhaustive, thus more time-consuming parameter tuning strategy. limitation of search space did not prevent smote + svm from being the slowest strategy in our experiments though. in the case of plant and animal datasets single training took more than ten days which makes micropred strategy inapplicable for larger problems. in contrast, aplsc classifier  was very fast.

eventually, we decided to use random forest combined with roc-select as a basic strategy in huntmi package due to its superior classification results and reasonable computation time.

additional features
the next part of the experiments was to check how introducing additional features influences classification results. these experiments were carried out for random forest + roc-select combination, selected earlier as a basic strategy in huntmi. as table  <dig> shows, new features introduced additional information into classification procedure and improved final results. the absolute gain in gm varied from  <dig>  to  <dig> . wilcoxon test  <cit>  performed on all datasets beside micropred confirmed predominance of the extended representation with p-value equal to  <dig> . for this reason we decided to use seven new features together with twenty one previously introduced to represent sequences in huntmi package.

classification results obtained by roc-select + random forest combination for extended representation including seven new features. these are also the final results for huntmi software.

comparison with other tools
the majority of mirna classification studies focus on h. sapiens. as micropred was proven to be the best software in this field at the time of its publication, we decided not to consider its predecessors such as triplet-svm, mipred or mipred in the comparison. the results produced by smote + svm combination on micropred dataset were very similar to those obtained by  <cit>  , which confirms that our experiments accurately estimate micropred performance. the small discrepancy is probably caused by different splits in cross-validation procedure . huntmi software gave gm= <dig>  , which is a noticeable improvement over micropred. the predominance of huntmi method over smote + svm combination employed by micropred holds also for all other sets and is statistically significant. to further test the performance of huntmi, we prepared a set of animal micrornas newly introduced in mirbase issues 18- <dig> and examined it on a classification model trained on the entire animal dataset . the obtained results clearly demonstrate that huntmi is able to efficiently identify novel micrornas in animals, achieving the sensitivity of over 90% in  <dig> out of  <dig> analysed species . at the same time the sensitivity achieved by micropred is considerably lower, exceeding 90% only for o. latipes.

classification sensitivity of micropred and huntmi on animal mirnas added in mirbase issues 18- <dig> 

several studies on improving micropred have been carried out. they exploited techniques like sample selection  <cit>  or genetic algorithm-based feature selection  <cit>  resulting in very high values of gm . all these methods were, however, evaluated on balanced subsets of micropred dataset and some of them suffered from important methodological incoherences like lack of random split of data into training and testing set and, more importantly, inclusion of training sequences in a testing set. therefore, reported results do not accurately estimate the performance of presented strategies in real mirna identification problems. in addition, these methods are not available as a ready to use packages.

another strategy, mirensvm  <cit> , employed svm ensembles for mirna classification. it was tested on moderately imbalanced dataset  with 3-fold cv resulting in gm= <dig> . this value is very similar to the one obtained by huntmi on micropred dataset which consisted of same positive examples and 50% more negatives. mirensvm was also tested on a set of  <dig>  <dig> animal mirnas successfully identifying  <dig> % of them. as no negative sequences were included, specificity of the method is unknown. in our experiments, huntmi was examined on a set consisting of  <dig>  <dig> animal mirnas and  <dig>  <dig> pseudo hairpins. it outperformed mirensvm giving sensitivity of  <dig> % and specificity of  <dig> %. as mirensvm is not available as a tool, we were not able to compare its performance with huntmi on mirnas introduced in latest builds of mirbase.

separate group of methods specialising in plant microrna identification has been developed, of which the most recent is plantmirnapred  <cit> . it joins feature and sample selection strategies to improve svm classification results. the main dataset used in the research consisted of  <dig>  <dig> real pre-mirnas from mirbase  <dig> and  <dig>  <dig> non-mirnas generated by authors.  <dig> positive and  <dig> negative examples were selected using proposed sample selection method to train the classifier. majority of the remaining sequences and  <dig> new mirnas from mirbase 15- <dig> constituted the testing set. surprisingly, as many as  <dig> training positives were also added to this set. this, together with lack of random split of data into training and testing sets results in overestimation of classification performance. despite these incoherences, huntmi performed smililarly to plantmirnapred. after summing up results from plantmirnapred study we obtained gm= <dig> , while huntmi gave  <dig>  and  <dig>  on plant and arabidopsis datasets respectively. to further evaluate performance of huntmi package in plant microrna classification, we tested it on mirnas introduced in 18- <dig> builds of mirbase. classification model was trained on the full plant dataset . as plantmirnapred permits only for manual submissions of single sequences  we examined it on species with at most  <dig> newly introduced mirnas. the results are presented in table  <dig> 

classification sensitivity of plantmirnapred and huntmi on plant mirnas added in mirbase issues 18- <dig>  plantmirnapred failed to process some arabidopsis thaliana mirnas successfully. however, these sequences were treated as properly identified.

based on obtained results, all the plant species examined by huntmi can be divided into two groups. in the first group  the classification sensitivity varied from  <dig> % to  <dig> % and is clearly superior to the performance of plantmirnapred. the second group  was characterised by much lower sensitivity . two of the latter species belong to monocotyledons, which could suggest that our tool is inefficient when analysing sequences from this plant group. however, we obtained satisfactory sensitivity for s. bicolor . this encouraged us to look closer at micrornas from low-sensitivity group and we discovered that a large fraction of mirnas in these species do not meet commonly recognised criteria for annotation of plant mirnas e.g. in the case of osa-mir <dig>  osa-mir <dig>  hvu-mir <dig>  hvu-mir <dig>  mtr-mir5741d and some other mirnas the mature microrna lies outside the stem part of the hairpin. additionally, most of new mirnas were discovered using deep sequencing approach only, where it is sometimes only one or several reads that support the mirna . this data is insufficient to confirm that the mirna is precisely excised from the stem. similarly to huntmi, plantmirnapred produces unsatisfactory results when applied to h. vulgare or o. sativa mirnas .

to sum up, in majority of cases huntmi was able to obtain better results than competitors even though it was evaluated on larger and more imbalanced datasets. experiments on animal and plant mirnas introduced in releases 18- <dig> of mirbase confirmed that huntmi outperforms other tools like micropred and plantmirnapred. there are methods reporting higher gm values than huntmi. however, they were all tested on balanced datasets, often with important methodological flaws, which obstructs proper judgement of their performance in real-life tasks. moreover, none of these methods is available as a ready to use package.

CONCLUSIONS
in this study we present a new machine learning-based mirna identification package called huntmi. it exploits roc-select, a special strategy of thresholding score function output by classifiers, combined with random forest, which we find to produce best classification results. twenty one features employed by micropred software together with seven new attributes are used as a data representation. the method was tested on large and strongly imbalanced datasets using stratified 10-fold cross-validation procedure. classifiction performance was further verified on mirnas newly introduced in latest builds of mirbase. as a result, huntmi clearly outperforms state-of-the-art mirna hairpin classification tools like micropred and plantmirnapred without compromising the training time.

huntmi comes with gm-optimised models for h. sapiens, a. thaliana, animals, plants and viruses. there is a possibility to train a model on any dataset and subsequently use it in classification analysis. this feature may be useful if one is interested in predicting mirnas in particular species or in applying different optimization criterion than gm in roc-select procedure. therefore, huntmi offers the highest flexibility of all existing microrna classification packages.

abbreviations
aplsc: asymmetric partial least squares classification; cv: cross-validation; fp: false positive; hmm: hidden markov model; mfe: minimum free energy; roc: receiver operating characteristic; se: sensitivity; smote: synthetic minority over-sampling technique; sp: specificity; svm: support vector machine.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
ag and mws contributed to the manuscript equally. ag prepared implementation of roc-select method and performed experiments. mws designed features used in classification and prepared datasets. both ag and mws analysed experimental results and drafted the manuscript. ms and im revised the manuscript and supported the research from statistical and machine learning  as well as biological  side. all authors read and approved the final manuscript.

supplementary material
additional file 1
a file with supplementary tables. table s <dig> summarises animal and plant species and viruses from which non-mirna sequences were extracted.

click here for file

 acknowledgements
this work was supported by the european social fund grant uda-pokl. <dig> .01-00-106/ <dig> to ag; national science centre grant 2011/01/n/nz2/ <dig> to mws; national science centre grant 2011/01/b/st6/ <dig> to ag, mws, im; national science centre grant dec-2011/01/d/st6/ <dig> to ms; faculty of biology at amu grant pbwb-08/ <dig> to mws. we wish to thank adam adamarek for proofreading the manuscript.
