BACKGROUND
much of the population-wide variation of the human genome can be attributed to single nucleotide polymorphisms , which are changes in single base pairs within the genome. snps are of specific interest because they allow disease association studies; this means that the involvement of genes in particular diseases can be studied by the analysis of snp alleles within these genes  <cit> . for the study of population genomics, snps can be used to measure linkage disequilibrium, an indication of how much more  likely, compared to chance, certain combinations of neighboring snp alleles are  <cit> .

after the completion of the human genome project emphasized the importance of snps to study the location of disease genes, the snp consortium project produced a genome-wide map of more than  <dig>  million snps  <cit> . due to linkage disequilibrium, the distribution of possible alleles at snps is not uniformly random, and some combinations of neighboring alleles occur more often than others. such a combination of snp alleles is called a haplotype, and a given set of snps can give rise to a wide variety of haplotypes.

it is an important problem to identify a subset of snps within a haplotype that allows the unique identification of all possible allele variations within a haplotype. if such a subset can be found, a haplotype can be uniquely identified by knowing only the allele values at a few snp positions. snps that satisfy this requirement are called haplotype tagging snps .

the problem of identifying a minimal set of htsnps is known to be np-hard. np-hardness means that there currently does not exist a way of solving the problem optimally with reasonable computing resources. even though it is strongly believed among theoretical computer scientists that this state of affairs will prevail, np-hardness does not exclude the possibility of finding an adequate solution with a reasonable effort. the validity of this last statement hinges on the definitions of the adequacy of a solution and what constitutes reasonable effort. we will define reasonable effort to be polynomial time computability, while adequacy will be achieved by an approximation algorithm, the solution of which is provably no worse than a certain factor r times the optimal.

in recent years, a number of algorithms for calculating htsnps were developed. due to the high computational complexity of the problem, these algorithms were either stochastic or, when deterministic, only applicable to haplotypes with a few hundreds to thousands of snps. at present, this is not a limitation, since there are few samples that contain these many snps. given the speed of progress and innovation in the biosciences it will, however, be only a matter of time until brute-force approaches will no longer be feasible. stochastic algorithms do not have this limitation; due to their nature they can give only probabilistic bounds on the results achieved. we believe that approximation algorithms are a viable alternative to both stochastic and brute-force approaches. the advantage over the former is that the bounds on the results are guaranteed to hold; the advantage over the latter is that approximation algorithms can be executed in polynomial time.

the theoretical question of how many snps are required to tag a given number of haplotypes was investigated, using boolean algebra, by wiuf et al.  <cit> . the number of htsnps required for association studies was investigated by thompson et al.  <cit> . previous work on exact algorithms for identifying htsnps were based on search strategies  <cit> ; a stochastic algorithm is given by johnson et al.  <cit> . wiuf et al.  <cit>  and bafna et al.  <cit>  both present polynomial time algorithms that find a minimum cardinality set of snps for the special case that wiuf et al. call pairwise compatible and bafna et al. call complete ld, i.e., the four gamete test by hudson and kaplan  <cit>  fails for any pair of snps. we will in this exposition focus on the general unrestricted case.

RESULTS
the main results are summarized as follows.

theorem  <dig> the haplotype tagging problem is np-hard and approximable within 1+ln(), but np-hard to approximate within cln for c >  <dig> and not approximable within ln for any ε >  <dig> unless np ⊂ dtime. if we bound n from above by a constant q, the problem is apx-complete.

we have that cln = Ω and  <dig> + ln/2) = o, by which we can see that the approximation bound is asymptotically tight. we present an algorithm with running time o) where p = min, for the mht problem that exhibits the above approximation bound. this algorithm is easily implemented, the detailed pseudo code listing presented in this paper contains only  <dig> lines.

a second algorithm is presented that can be seen as an instance of a schema that lets us approach a family of haplotype tagging problems including the problem of tagging the haplotypes using a set of snps with minimal diameter. this latter result addresses the problem of selecting practical "window" size bounds in approaches where such are needed .

discussion
for  <dig> million samples  the size of the set of tags returned would be at most  <dig> times larger than the optimum. if we assume that our computer is capable of doing  <dig> trillion operations per second , and we wish to search among  <dig> million snps, the computation using the algorithm presented in this paper would only take about  <dig> days. if we happen to know that an optimal solution uses at most  <dig> of these snps , we would be done in about  <dig> hours. hence, to approach truly large scale experiments, the authors believe that implementations would likely come from the field of parallel algorithms.

our analysis of the minimum haplotype tagging problem  relies on a relationship we establish to the minimum set cover problem . exploiting this relationship, we can relate variants of the msc problem to mht. this we can do as we describe an algorithm that transforms a mht instance into a msc instance, solves this instance, and transforms this solution into a solution of the mht problem. we can form variants of this algorithm by substituting particular variants of the msc algorithm in this process. below we list msc variants, their known approximation properties, and if substituted into our algorithm schema, the corresponding resulting mht problem that it solves.

• minimum exact cover. this problem is approximable within  <dig> + ln m  <cit>  and the associated tagging problem is to find a minimum set of snps such that the sets of haplotype pairs each of the snps distinguishes are as disjoint as possible.

• maximum coverage by at most k sets. this problem is approximable within e/  <cit>  and not approximable within e/ - o  <cit>  for e >  <dig>  the associated tagging problem is the problem of discerning a maximum number of haplotypes with at most k snps.

• minimum k-redundant coverage is the problem of creating a minimum cover such that each element is covered at least k times. this problem is approximable within b - k +  <dig>  <cit>  for a constant b. the associated tagging problem is the problem of requiring each snp in a minimum tagging set to discern between at least k pairs of haplotypes.

• minimum diameter coverage is the problem of finding a cover where the greatest distance between two elements in the cover is minimal. this problem is in general not approximable within a constant, but approximable within  <dig> if the distance measure observes the triangle inequality and no better approximation is possible  <cit> . the associated tagging problem is to find a tagging set of snps such that the maximal pairwise distance is minimal.

• minimum cluster diameter coverage is the problem where we assume that the cover can be partitioned into k clusters and the objective is to minimize the greatest distance between two elements in the same cluster. this problem is approximable within  <dig> for any fixed k and upper bound of cluster size l if the distance measure satisfies the triangle inequality  <cit> . the associated tagging problem is to find k disjoint sets of maximally l snps such that the greatest distance between two snps in the same set is minimized.

• maximum dispersion cover is the problem of finding a cover that maximizes the min imum pairwise distance between elements in the cover. this problem is np-hard and assuming p ≠ np, no polynomial time approximation with bounded error guarantee exists  <cit> . the corresponding tagging problem is to find a set of snps that lets us discern between all haplotypes such that the minimum distance between two of these snps is maximized. we see that this problem is the most difficult to solve of all the problems considered in this exposition.

all these variations can be implemented by substituting the corresponding cover algorithm for the greedy set cover algorithm in the mht algorithm schema. approximation bounds and non-approximability results for the above variations can be used to establish the same for the resulting variation of the haplotype tagging problem analogously to what we do for the minimum set cover problem.

CONCLUSIONS
although the haplotype tagging problem is hard, it can be approached with a simple, fast and practical algorithm. the contribution of this work is not only yet another fast and simple algorithm for the tagging problem, but also the proof that this algorithm delivers a solution with the asymptotically best error bound possible.

furthermore, the algorithm schema we present via the connection to the minimum set cover problem is applicable to not only the original problem as it is defined in our analysis, but is applicable to a family of related problems, which address problems presented in published research.

as the algorithms presented are asymptotically optimal with respect to approximation bounds, meaning that solution quality cannot be significantly improved upon in polynomial time, efforts in tackling truly large scale problem instances should concentrate on distributing the computational efforts in parallel.

