BACKGROUND
hepatitis c virus  infects nearly  <dig> % of the world’s population and is a major cause of liver disease worldwide  <cit> . hcv infection is an important us public health problem, because it is the most common chronic blood-borne infection and the leading cause for liver transplantation  <cit> . since  <dig>  hcv surpasses hiv as a cause of death in the us  <cit> . it is estimated that  <dig>  million to  <dig>  million people in the united states have chronic hcv infection and that more than  <dig>  die each year from hcv-related disease, with mortality expected to rise in the coming years  <cit> . approximately 80% of patients who become infected with hcv develop chronic hepatitis and are at risk for advanced liver disease; 15–30% of these patients have progression to liver fibrosis and cirrhosis and up to 5% will die from liver failure due to cirrhosis or hepatocellular carcinoma  <cit> .

outbreaks of hepatitis c virus  infections are associated with unsafe injection practices, drug diversion, and other exposures to blood and blood products. given the long incubation period  and that hcv infections can remain asymptomatic in >70% of infected persons for years, the detection and investigation of hepatitis c outbreaks is a challenging task.

molecular phylogenetic analyses of rna viruses have been used frequently in the study of outbreaks and transmission chains , usually by analysing a single sequence per infected individual and comparing these sequences to ascertain if their genetic distances are below a previously defined threshold. however, hcv exists as a population of numerous variants in each infected individual and it has been observed that minority variants in the source are often the ones responsible for transmission, a situation that precludes the use of a single sequence per individual because many such transmissions would be missed  <cit> . our laboratory has been using molecular analysis of viral hepatitis populations  for more than a decade  with a simple and accurate threshold-based approach for detecting hcv transmissions that streamlines molecular investigation of outbreaks, thus improving the public health capacity for rapid and effective control of hepatitis c  <cit> .

now with the advent of next-generation sequencing  we expect an increase in the sensitivity of transmission detection due to the sampling of minority variants  <cit>  but this advantage comes with a considerable computational challenge because all sequences need to be compared among all pairs of samples. for instance, for our relatively small dataset of  <dig> samples, a total of  <dig> pairwise sample comparisons are performed, which account for  <dig>  ×  <dig> pairwise sequence comparisons. given that the molecular surveillance of hcv is just starting, this number will certainly grow in the near future and the detection of transmission will soon become impractical. we present an efficient three-step filtering strategy that removes  <dig> % of all the pairwise sample comparisons and  <dig> % of all pairwise sequence comparisons, accurately establishing which pairs of hcv samples are below the relatedness threshold.

methods
problem definition
given p = {p <dig> p <dig> …}, a set of samples where each pi is associated with a set si = {si
 <dig> si
 <dig>  …} of homologous sequences, enumerate all sample pairs  where any pairwise sequence comparisons  has an edit distance lower than the relatedness threshold, t . given that every sample-pair needs to be considered, it yields an o algorithm, where n is the number of samples.fig.  <dig> transmission detection overview. in this example, there are  <dig> samples: pi contains  <dig> different sequences, pj contains  <dig> and pk contains  <dig>  in addition, pi and pj are related, whereas pk is unrelated to the other two. a total of  <dig> pairwise sequence comparisons must be performed to find the minimal distance between each pair of samples. the rationale of our approach is to quickly remove the sample-pair comparisons with zero probability of having a minimal distance lower than t




however, we have observed than less than 1% of all sample-pairs are linked by transmission in a typical study . therefore, an exhaustive search over all pairs of sequences is very inefficient due to the fact that the great majority of sample pairs are above t. briefly, it would be very advantageous to remove most of these pairs in order to reduce the number of computations needed to establish transmission on a set of samples.fig.  <dig> transmission network density this is an example of a real hcv transmission network obtained during an outbreak study. a link is drawn if the minimal edit distance between the two samples is smaller than t, whereas the size of the node is proportional to its genetic heterogeneity. in this particular example, only  <dig> % of all sample-pairs are linked by transmission




datasets
sample description
we analyzed two set of files that cover the spectrum of genetic relationships among hcv cases. the “unrelated dataset” is comprised of  <dig> hcv cases that are epidemiologically unrelated to each other and were obtained from national collections and other research projects  <cit> . the “related dataset” is comprised of  <dig> hcv cases from an outbreak where a surgical technician diverted drugs and infected patients at a health-care setting  <cit> . all samples in the related set are epidemiologically linked and their minimal edit distance is smaller than t . the average number of different sequences per sample is  <dig> 

experimental methods
for each sample, we used the sequences obtained and described in  <cit> . briefly, we amplified the e1/e <dig> junction of the hcv genome , which contains the hyper variable region  <dig> region) using our nested pcr protocol as previously described  <cit> . pcr products were pooled and subjected to pyrosequencing using gs flx titanium sequencing kit . low-quality reads were removed using the gs run processor v <dig>   and then processed by matching to the corresponding identifier. the ngs files were processed using the error correction algorithms kec and et  <cit> .

algorithms
we developed a three-step strategy that filters pairs of samples according to different criteria. figure  <dig> shows an overview of the filtering strategy.fig.  <dig> overview of the filtering strategy




k-mer bloom filter
for a sequence pair  to be similar enough to link two samples, the following condition must be satisfied: the edit distance between si
x and sj
y is < lt . this means that when we align si
x and sj
y, the lower bound of the maximal common substring is k = /, which for our particular t would be  <dig>  we took advantage of this maximal common substring requirement and created for each sample a bloom filter of all its 26-mers. a bloom filter is a space-efficient probabilistic data structure supporting dynamic set membership queries with false positives  <cit> . false positive matches are possible, but false negatives are not, thus a bloom filter has a 100% recall rate  <cit> . for any pair of samples, we tested the intersection of k-mer sets: if it is empty, the sample pair is considered unrelated and removed from the sample-pair candidate list; if it is non-empty, the sample pair may be related and remains in the sample-pair candidate list.

hamming radius filter
for each sample pi in the database, we calculated and stored the following:  its multiple sequence alignment ;  its consensus, ci, defined as the majority nucleotide state at each position in the alignment; and  its hamming radius, ri, defined as the maximum edit distance found between the consensus and all other variants of the sample.

for any pair of samples we calculated a sample distance, sd, defined as: sd = dist – . each sample-pair is tested in this fashion and if sd is higher than lt, it is removed from the sample-pair candidate list because these two samples cannot have any sequence-pair with a distance lower than t . if sd is lower than the threshold, the sample pair may be related and remains in the sample-pair candidate list.fig.  <dig> hamming radius filter. if sd is higher than lt these two samples cannot have any sequence-pair with a distance lower than t




identical sequences filter
we have previously estimated that  <dig> % of sample-pairs coming from the same transmission cluster share at least one identical sequence  <cit> . candidate pairs that share one or more sequences do not be need to be fully evaluated because their minimal distance is zero and therefore are ensured to be below the t. we take advantage of this fact to create a simple filter that quickly identifies those sample-pairs sharing identical sequences. in order to achieve this, we calculate for each sequence in a sample its hash “fingerprint” with a standard cryptographic function . the set of such strings is constructed for each sample file only once and then stored. when comparing sample-pairs, we check for intersection in their hash sets and if the size of the intersection is at least  <dig>  then the sample-pair is considered related. if it is not, the sample pair remains in the sample-pair candidate list.

detection of transmission
for each sample-pair remaining in the candidate list, all its sequences are used to create a msa, which is then used to calculate the edit distance between every pair of sequences. the two samples are considered related if the minimal edit distance between any of their sequences is smaller than t.

all edit distances were calculated with hdist, a custom-made, highly optimized distance calculator that minimizes processor pipeline stalls and takes advantage of modern superscalar architecture. the procedure involves breaking a sequence pair into consecutive 3-mers, converting them into base  <dig> integers and using them as indices into a pre-calculated look-up table. the choice of 3-mers was made by testing different word sizes to maximize processor cache memory hits.

RESULTS
filtering strategy
we developed a three-step strategy that filters pairs of samples according to different criteria. the rationale of the approach is that the great majority of sample pairs are very different  and it would be advantageous to remove these pairs in order to reduce the amount of computation needed to establish transmission on a set of samples. every sample-pair is still considered, yielding an o algorithm, where n is the number of samples. however, the 3-step filtering strategy efficiently prunes most comparisons from the candidate list with much lower computational effort than the full distance calculation, even though both have the same order.

filtering performance
for the unrelated dataset, the whole algorithm can be performed under 5 min on a desktop computer, accurately removing  <dig> % of all possible candidates and  <dig> % of all pairwise sequence comparisons. the number of sample-pair candidates that are removed by each filter can be seen in table  <dig>  on this dataset, the best individual filter is the hamming radius filter, which removes  <dig>  of all sample-pairs. only  <dig> candidates are removed by the k-mer bloom filter that are not removed by the hamming radius filter, whereas  <dig> candidates are removed by the hamming radius that are not removed by the k-mer bloom filter. with regard to the overlap,  <dig> candidates are removed by both filters.table  <dig> filtering results on the unrelated dataset

number of candidate pairs removed by each filtering approach




we studied the behavior of the bloom filter with different k-mer values. figure  <dig> shows how the percentage of removed sample-pairs increases with the value of k. with our particular t value, the 26-mer bloom filter removes  <dig> % of all sample-pairs are removed. as the k value increases, the percentage of removed sample-pairs increase very quickly. for instance, a common relatedness threshold used in hiv molecular epidemiology is 1%, which on this dataset yields a k-mer of  <dig> that filters  <dig> % of all sample-pairs.fig.  <dig> percentage of removed sample-pairs by the k-mer bloom filter




for the related dataset, the whole algorithm can be performed under 10 s on a desktop computer, accurately identifying  <dig> % of all possible candidates and removing them from the workflow . on this dataset, both the k-mer bloom and the hamming radius filter do not remove any candidates, as is expected given that all of them are below t.table  <dig> filtering results on the related dataset

number of candidate pairs removed by each filtering approach




implementation
the k-mer bloom filter was implemented in java, whereas the hamming radius filter, the identical sequence filter and hdist were implemented in python and cython. although all the programs are available upon request, they are part of our recently developed web system for the advanced molecular detection of hcv transmissions, the global hepatitis outbreak and surveillance technology . the web system includes the analytical methods described in this article, improving the accuracy and response time of transmission detection by integrating epidemiological evidence, ngs and data analysis. the tool is available to public health laboratories to identify outbreaks by simply uploading viral sequences.

discussion
the utility of the “identical sequences filter is only evident when there are samples coming from the same geographical region or from a suspected outbreak, as we have previously estimated that  <dig> % of sample-pairs coming from the same transmission cluster share at least one identical sequence  <cit> .

the hamming radius filter seems to be outperforming the k-mer bloom filter on this dataset. however, the hamming radius filter requires a pre-calculation step for each sample, which involves a msa. this msa can be performed efficiently with mafft but it has high memory requirements depending on the number of sequences. therefore, the hamming radius filter is contingent on the feasibility of the msa, whereas the k-mer bloom filter is alignment free. this particular ngs dataset was obtained with  <dig> life sciences, where the average number of different sequences per sample is  <dig> . our initial tests on the illumina miseq platform indicate that although the number of different sequences is around  <dig> times greater, the msa step is still feasible.

the idea behind the hamming radius to exclude sample-pairs could be generalized to exclude sequences within a patient that are too distant from the sequences of the other sample. we are currently using just the maximum distance to the consensus , but all those distances could be used to filter a great amount of sequences that are very close to the consensus. a reduced number of sequences will decrease the number of pairwise comparisons that are calculated at the last hdist step.

until recently, molecular phylogenetic analyses of rna viruses used a single viral sequence per patient to detect transmission. however, the advent of ngs data immensely increases the computational burden of this simple approach. our proposed filtering strategy can be used for detecting transmissions of any heterogeneous virus where a threshold-based method has been validated.

the number of samples in our database is now in the order of  <dig>  but it is constantly increasing with time as hcv molecular surveillance becomes more commonplace with the aid of cheaper and more effective ngs technologies. just in the united states, it is estimated that  <dig>  million to  <dig>  million people have chronic hcv infection  <cit>  and if we want to respond to a rapidly growing database of ngs data, there is a great need for our highly efficient workflow to accurately infer the network of hcv transmissions. the availability of this system for the detection of hcv transmissions will foster deeper involvement of public health researchers and practitioners in hcv outbreak investigation in the united states and worldwide. improvement in molecular detection capacity also will increase the rate of detection of transmissions in the united states, thus providing opportunity for a rapid and effective response to the growing number of hepatitis c outbreaks.

CONCLUSIONS
we present a fast and efficient three-step filtering strategy that removes most sequence comparisons and accurately establishes transmission links of any threshold-based method. this highly efficient workflow will allow a faster response and molecular detection capacity, improving the rate of detection of viral transmissions with molecular data.

