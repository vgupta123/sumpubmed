BACKGROUND
we provide an insight into the design choices of epiviz  <cit> , a tool for interactive visual and computational analysis of genomic data. we include design choices behind the tool and introduce new features that greatly broaden our support for interactive analysis workflows of genomic data over our previously published general overview of its architecture and design. we present a use case of epigenomic data analysis that makes use of the improvements of epiviz based on these new extensions and features.

motivation
the design of epiviz responds to the need of integrating computational and visual interactive and exploratory analysis for genomics data. existing tools usually treat these steps: 1) computational and statistical analysis, and 2) interactive integrative visualization, as distinct , while they are more effective when used iteratively.

consider the case of finding differentially methylated regions  associated with cancer. statistical inferences from smoothing methods built on base-pair level measurements of dna methylation   <cit>  are used to carry out this task. in a general sense, these methods use a statistical model of expected methylation mljk at genomic locus l for replicate j belonging to class k : mljk=f+gk+eljk where fl is a smooth function over genomic loci and gk is another smooth function that measures deviation in methylation for class k, so that contiguous regions where |gkl| is large enough are considered differentially methylated and a level of significance can be determined by parametric or non-parametric statistical methods. this stipulates a chain of measurements and estimates that lead to the final list of regions found: the base-pair level dnam measured for each sample, the smooth functions used in the above model, and the regions where methylation differences are determined to be significantly different .

note that these smooth functions are parameterized by bandwidth to adjust their smoothness, which in turn determines the size of dmrs found: e.g., large smoothing windows leading to longer dmrs detected. for data derived from illumina humanmethylation 450k beadarrays this methodology is implemented in the minfi  <cit>  bioconductor package.

once these regions are determined, they would be exported, as bed file for example, and visualized on a genome browser to integrate with other annotations , providing context and interpretation based on the relationship between estimated dmrs and other genome annotations. unfortunately, at this point most information pertinent to the statistical analysis driving these inferences is lost . furthermore, interaction in the genome browser is not informed by statistical properties of the inferred regions .

current tools make it difficult to simultaneously perform statistically informed visualization by allowing exploratory analysis of measurements and estimates across this multi-stage statistical procedure and visualization informed statistical analysis where parameters of this multi-stage procedure are explored based on integrative visualization.

some of the ways epiviz advanced the field of genomics interactive visual analysis include:

 <dig>  introducing the first genomic data visualization software that brings code to interactive visualization by allowing computational environments such as r or python to use it as an interactive display device and by allowing scripts stored externally  to be dynamically integrated into the framework. the epivizr package is designed to integrate epiviz with the state-of-the-art bioconductor infrastructure for genomics statistical analysis.

 <dig>  introducing the concept of community-contributed plugins for web applications through javascript dynamic extension. epiviz is the first web-based visualization tool whose code base can be extended by actively incorporating third-party scripts. combined with the workspaces feature, which allows users to persistently save, replicate and share analysis steps - including code customizations done in the ui - this opens the door to social collaboration within the genomic community, which has never been done before.

 <dig>  creating the first genome browser that makes use of the following set of concepts and features simultaneously: brushing and linking, binning, supporting data transformations in the ui, predictive caching based on navigation, aggregating data from multiple sources - both cloud-based and local - and persistently saving and sharing data analysis steps as workspaces.

contributions
in this paper, we present specific extensions and features introduced posterior to the initial launch of our project and consequent publication, as well as aspects of the architecture that have not been described before.

 <dig>  visualization code customization in the ui. previous versions of epiviz allowed users to create custom visualizations and data providers, as well as to override existing settings by storing scripts on the cloud and referencing them within the tool. a lot of data analysis workflows however, require customizations that are so simple, that creating a whole new visualization for them would be too much overhead. for cases such as these, epiviz provides a window straight into the parts of the visualizations code that matter for the user, who can customize this code directly in the user interface, using a javascript code editor dialog.

 <dig>  data transformations directly in the ui. in epiviz, data transformations can be easily applied by coupling a computational environment to the interactive visualization environment. also, new measurements can be created as combinations of existing ones using the computed measurements feature. however, in our work we recognize the need of being able to make such transformations as close to the user interface as possible, in order to optimize the data analysis workflow. for this reason, we expanded our framework's api to include a series of customizable and extensible transformations over data within visualizations. measurement and feature sorting, aggregation, as well as dynamic coloring are a few examples of transformations currently available within our tool. epiviz exposes a fully-featured javascript code dialog which scientists can use to define complex ways in which these transformations can be applied.

 <dig>  the extension of user workspaces to include user-defined code customizations. reproducibility is an essential aspect of genomics data analysis workflows, which was one of the central concepts in the epiviz design from the beginning. to keep our framework in tune with this concept, we extended the workspaces feature to include code customizations, for both visualizations as well as data transformations described above.

 <dig>  securing third-party code. the introduction of the data and visualization code transformations described earlier, as well as storing these user-scripts into the database as part of workspaces poses security risks for server-side data integrity, as well as user information. for this reason, we implemented a series of security features, of which the most important is utilizing a code sanitizing library that ensures no malicious code will be executed within either the user session or our servers, and no such code will be stored on our databases.

 <dig>  a series of new visualizations, as well as advanced features of the existing visualizations, such as heatmap clustering, which we exemplify, alongside the new code features, in the results and discussion section. the section also includes results derived from these new features and visualizations, which constitute important insights over the relationship between different genomic measurements.

 <dig>  we discuss the current challenges brought by data specific to genomic analysis and present an abstract data format designed with these challenges in mind. we describe ways in which the architecture of our framework takes these into account in defining a uniform data format we provide an in-depth description of the data abstraction and standardization of epiviz, which is the cornerstone of our plugin api, facilitating the usage of the same visualizations for different data types, as well as using different visualizations for representing different dimensions of the same data type. the uniform data format is also an essential aspect of integrating data from different sources, both computational environments and cloud-based databases.

considerations about genomic data
data used by bioinformaticians in data analysis is complex in its variety, heterogeneity, and size. sometimes, this data consists of records mapped to a genome - for example, dna methylation, or read coverage, which are commonly displayed in genome browsers  <cit> . in other cases, the main coordinate is replaced by time or some other user-defined dimension.

the size of genomics data also tends to vary greatly. usually, a single dataset corresponding to the genomic data for a single sample will range from a few hundred records to a few hundred million  <cit> , all of which can easily fit into the memory of a modern day computer. however, in the workflow of a single data analysis task, a scientist may involve a large enough number of datasets for it not to be feasible to load all data in the memory of a workstation at once, or even store it locally. for this reason, there now exist several large databases aggregating and making available various types of genomic datasets for a multitude of use cases  <cit> . there have been large efforts geared to storing efficiently and providing large selections of these datasets to bioinformaticians  <cit> . often these sit behind genome browsers, which offer, to some extent, help with the dissemination of subsets of these datasets. however, in the past, no tool has been able to interactively visualize data from a multitude of these different sources simultaneously, and at the same time facilitate dynamic statistical analysis of new datasets derived from user experiments, residing locally.

in our work we recognize the need to analyze, model, navigate over, correlate and interactively visualize data that is both varied in terms of format and semantics, as well as source and size. current data analysis workflows of individual researchers as well as research groups usually involve the usage of a multitude of tools as part of the same process, including a number of genome browsers and statistical environments such as r/bioconductor or python. to reduce the time spent by users switching between tools in the course of one data analysis process, genome browsers take one of two paths. the first is to duplicate data already available in other databases  <cit> ; this approach is unfeasible when taking into account the rate at which new data becomes available  <cit> , the sizes of some such databases  <cit> , as well as the efforts aimed at making these databases efficient in terms of query time and data format  <cit> . the other path is to serve data directly from the cloud  <cit> . we find the latter preferable, given the data considerations made earlier. but, in addition to genome browsers, data analysts often revert to computational platforms, for quick access to data widely used in their scientific community as well as quick manipulation and complex modelling of small datasets. for genomics data, the r/bioconductor framework is a state-of-the-art platform for implementation and dissemination of computational and statistical analysis methods.

however, before epiviz, no existing tool by itself was able to accomplish both of the following: 1) integrate simultaneously data from different genome browsers without replicating it on the local database, and 2) bridge the gap between genome browsers and computational environments, by coupling interactive visualization with statistical data modelling. genome browsers sit in front of large databases and are highly interactive, but have little to no data transformation capability. computational environments on the other hand, are powerful data modelling tools, but do not expose interactive visualizations, nor are they capable of easily manipulating extremely large datasets, being limited to the physical memory of the local machine.

one of the purposes of epiviz is to make different datasets in various locations and formats easy to access and manipulate in the same tool. through epiviz, we propose a system that is able to visualize datasets directly from their existing locations, as well as custom user data residing on the local machine, side by side. not only this, but the users are now able to model and change their custom data in a computing environment of their choice and immediately visually explore these changes, all in the same view, without the need to switch between tools or to constantly upload new versions of transformed data to a web server. epiviz introduces a framework that features a data provider api which can be used to integrate both data available through online services, as well as data loaded in the memory of a computing environment. in addition, users of epiviz gain the benefits of new data sources and formats available only to services within these environments  <cit> . these services provide uniform access to a large number of data sources to support data integration by providing infrastructure that supports a large variety of data types based on community standards . development of interactive and integrative visualization tools that are able to interact with frameworks such as r/bioconductor is a strong motivation for epiviz. through them, it is assured of high visibility and impact in the scientific community. tools that directly benefit from our system include a number of frequently used, state-of-the-art methods for a) chipseq , where iterative visualization of data and results of peak-calling algorithms is necessary; b) rnaseq analyses using deseq  <cit> , edger  <cit> , or limma  <cit> , and cufflinks/cuffdiff  <cit>  through the cummerbund package, where both location-based coverage and feature-based expression levels are required; c) methylation analyses using bsmooth  <cit>  or minfi  <cit> , where location-based analysis at multiple genomic scales is important.

implementation
bringing code to interactive visualizations
coupling between computational environments and visualizations has been done before, to some extent, either in areas of computer science unrelated to genomics, or for different audiences than the one targeted by epiviz. in this section we briefly describe two categories of tools that attempt to do this, underlining aspects that we considered worth replicating for our purposes, and ideas we decided to take a step further. combined with the interactive features of a genome browser, these make epiviz the first tool of its kind.

web-based computational environments
one category of tools that has gained a lot of traction in the past years is represented by web-based computational environments, such as ipython notebook  <cit>  and rcloud  <cit> . they are much similar to regular computational environments, but in addition, they combine code execution in browser, plots, and rich media. what we find particularly useful about these tools is the ability of users to create custom notebooks, and share them with each other. this is done either via individual files that can be viewed using an online notebook viewer, or using cloud-based source control providers such as github. this collaborative approach has been proven extremely effective for the audiences of these tools, consisting mainly of programmers and data analysts.

but neither of these tools can substitute a genome browser, because they are not specialized on interactive visual exploration of genomic datasets. they feature a set of static charts, the same as regular computational environments, but operations specific to genome browsers, such as navigation, or brushing, to link data across different charts are not naturally supported.

shiny
shiny  <cit>  is an interactive web application framework for r, which features a set of predefined web widgets which can be used to visualize custom sets of data loaded in memory. what is especially useful about this tool is a feature called reactivity, which consists of binding web controls to r functionality that responds to user actions on the web interface. this opens the door for r to visualizations that are more interactive than conventional static plots. this, along with the fact that its native environment is r, makes the tool extremely popular within the computational genomics community.

although it is a great addition to the r computing environment, shiny is a general framework that cannot replace genome browsers in a data analysis workflow without significant extensions. it is not built to link data across charts using brushing, nor does it support navigation over subsets of the same data. in addition, custom visualizations and visual optimizations cannot be built directly in r - knowledge of javascript and visual libraries built on top of it is required to create advanced complex views. in addition, shiny is not built to display partitions of data at a time, but rather, relies on the entire data to be loaded in memory of r. also, there is no easy way to put together subsets of data from a multitude of large databases.

visualization systems with similar functionality
harger et al.  <cit>  and zhang et al.  <cit>  provide two comprehensive surveys and comparisons of the state-of-the-art visual analytics open-source toolkits and commercial systems respectively taking into account a wide variety of features, from visualizations offered, to analysis functionality and portability. based on these studies, the titan  <cit>  toolkit and the system spotfire  <cit>  stand out through their extensive combination of visualization and statistical analysis functionality. all other tools analyzed in these surveys lack support for multivariate statistical analysis - the statistical analysis of data in three or more dimensions , which is essential for genomic data analysis workflows.

titan
titan is not in itself a visualization tool, but rather a toolkit providing an environment for data visualization and analysis. unlike most other desktop-based visualization toolkits, it is os-flexible, offers a good set of multiple coordinated interactive visualizations, as well as a computational facet for c++, python and tcl. the architecture is also extensible by allowing users to create custom plugins for data transformations.

in contrast, one of the goals of our efforts in developing epiviz was to provide support for frequently used state-of-the-art methods for genomic data analysis. this is currently best addressed by r/bioconductor, through an extensive suite of libraries and packages that are able to both manipulate different types of genomic data , and facilitate workflows for a number of established domain-specific analysis methods, as outlined in considerations about genomic data. the titan toolkit is bound to c++, offering limited ways in which a connection to the r/bioconductor infrastructure could be established. in addition, customizing the code of epiviz is an easy task partially because of our choice of javascript as the main programming environment for the framework. with titan, in order to create a plugin, one needs to instantiate and build the entire framework on the local machine. in contrast, the current design of epiviz requires no download, being able to interpret and execute third-party code from cloud-based locations such as github. our option also implicitly solves a security concern since javascript is given limited access to the user file system, which is ensured by web browser vendors. desktop-based software on the other hand, is vulnerable to a wide variety of security vulnerabilities.

spotfire
spotfire is a commercial desktop-based data analysis and visualization tool which also comes with a wide variety of analytic features, like brushing and linking, multivariate statistical functions, as well as a feature which allows users to define custom data transformations by writing ironpython code directly into the ui. as powerful as it is, the tool comes with a number of limitations which make it difficult to use for genomic data analysis workflows. the most evident is the fact that the tool is os-dependent, being able to run solely on windows. this is a serious drawback for the genomics community, where more than half of the users work on either macintosh or linux . like titan, spotfire does not natively support common genomic data types, and relies on loading the entire data in memory, making it unfeasible to use for extremely large datasets.

epiviz
epiviz brings code to visualizations in ways similar to those described in the previous sections.

first of all, it features a websockets api similar to that used by shiny, which allows communication between the web framework and any environment that implements the corresponding endpoint protocol. this api is used by epivizr, a bioconductor package that permits communication between the r computational environment and the epiviz user interface.

secondly, epiviz exposes a plugin api for both data providers and visualizations, so that new data sources can be easily added as needed, and new visualizations can be defined to display the same data from different perspectives. custom javascript code for new visualizations or data providers, can be plugged in on-the-fly using github gists, similar to the way ipython and rcloud incorporate custom user notebooks.

finally, a set of code features provides a gateway into the parts of javascript code that matters for the effective transformation of visualizations and data depicted in them. these are described in detail in visualization customization in the ui and data transformation in the ui.

epivizr
epivizr is an r/bioconductor package that uses the data provider websocket protocol to connect to the epiviz framework. through it, epiviz makes requests to the r environment so data in r objects is served in response. all data sources catalogued by the annotationhub bioconductor resource are available for integration as measurements via epivizr: the ucsc genome browser database  <cit> , ensembl  <cit> , and biomart  <cit> . infrastructure from the core bioconductor team and hundreds of contributed packages are used in a large number of projects analyzing data that ranges from expression microarrays to next-generation sequencing. due to epivizr, users of epiviz immediately benefit from the fundamental data structures exposed by bioconductor in their analyses. conversely, developers of new methods in r and bioconductor have now access to an interactive way of visualizing data at each step of development.

epivizr features updating, filtering and subsetting operations on r objects that trigger updates in their corresponding visualizations in epiviz. one of its most important capabilities is that it supports interactive exploratory browsing by, for example, allowing users to navigate in order through a set of genomic regions defined in r, using the slideshow feature. thereby, users can rank regions of interest according to some predefined, or computed attribute. a canonical example is navigation through regions of differentially expressed genes from an rnaseq experiment obtained from packages like deseq or edger.

software extension using javascript dynamic code interpretation
one powerful feature of javascript is its ability to evaluate strings of text into runnable code, which epiviz makes use of, to dynamically incorporate custom user logic into the framework. in this section we expand over the different kind of functionalities based on this feature available in epiviz. also, in the results and discussion section we discuss the security implications of taking this path, as well as our approaches to addressing them.

external scripts
one way in which we make use of this capability is by providing an extension in the api which permits automatically incorporating user specified external scripts that can override existing functionality, such as visualizations, data providers and settings, or define new ones. the new visualizations, data providers and custom settings are ready to use immediately, alongside predefined ones. on launch, epiviz first loads the base framework logic and searches for scripts specified using user-provided parameters. epiviz then executes the code in these scripts in sandbox mode and ui elements are immediately updated. epiviz supports the github gist api, which makes it possible for users to specify code stored on this source control provider. using this functionality, users can collaborate on a set of scripts simultaneously, sharing their work while using a common set of workspaces as the functionality contained in the scripts evolves.

visualization plugins can be easily created using the epiviz visualization api, which exposes a series of interfaces and base classes. these classes implement basic functionality, like drawing axes, creating a main svg canvas where drawing is done, drawing legends etc., which can in turn be used by plugins that only need to implement a draw method, greatly simplifying the complexity of plugin code. figure  <dig> shows an example of an externally defined visualization that follows this api, and whose code is hosted using github gist.

new data providers can be specified in epiviz using the same mechanism, and a data provider api, designed to allow users to dynamically plug in custom sources of data. using the data provider plugin mechanism, epiviz can display data located remotely or on the local machine. conceptually, epiviz data providers represent proxies to real data sources. for example, the websocket data provider enables connections with r/bioconductor through the epivizr package. different data providing services are interfaced through an api that de-centralizes data storage by allowing users to easily integrate external data sources. figure  <dig> contains a track that displays human genome genes from the refgenes sql table, in the ucsc database. this is done through a custom data provider, plugged into epiviz using the gist feature.

visualization customization in the ui
epiviz also introduces a mechanism that permits users to customize charts' code directly in the ui, as well as to define simple data transformations. using this, users can alter individual visualizations in place to match their needs. the code of chart instances can be modified such as to incorporate additional functionality per user needs. for example, the scatter plot in figure  <dig> contains a line at y= <dig>  separating positive and negative gene expression differences. in sup. figure  <dig> in additional file  <dig> we show the dialog where users can edit the visualization code, and the code necessary to apply this particular transformation to the scatter plot.

data transformation in the ui
the same type of functionality is used to apply data transformations for individual visualizations. these define ways in which the data that comes into a visualization should be transformed prior to rendering. currently, epiviz provides support for the following transformations: 1) filter by data object properties; 2) color by measurement or coordinate properties; 3) group by measurement properties; 4) order by measurement properties.

in the following lines we expand on these transformations. each of them exposes two functions that users can implement using the code editor controls in the code dialog . the first is called before any transformation, and is used to define and initialize variables to be used throughout the transformation; the second function corresponds to the actual transformation, and is called for each object, measurement, or feature coordinate in the selected genomic region, depending on the transformation.

in the filter by transformation, the inputs correspond to records in a data source . each input contains coordinate information, as well as a feature value. the filter by function yields a boolean with the following semantics: 1) a returned value of true signifies that the item should be drawn in the visualization, while 2) false means that it should be hidden.

the color by, group by and order by transformations, all have the same signature : they can be set up to take as inputs either data source records, measurements, or feature coordinates. based on the input, the function returns a label, in the form of a text string or a number. labels are used by each transformation accordingly. for example, color by will use them to color the objects with the same label with the same color. group by uses a user-selected aggregation function to aggregate all objects with the same label into one visualization object. finally, order by sorts objects in the visualization according to the lexicographic order of their corresponding labels.

for example, the stacked plot in figure  <dig> uses a color by transformation, which is used to highlight genes with various expression differences - 0- <dig>  light blue, 4- <dig>  dark blue, 8- <dig>  orange, and > <dig>  red. the code necessary to apply this transformation is depicted in figure  <dig> which shows a screenshot of the contents of a code transformation dialog.

another example is the lines track depicted in figure  <dig> which uses a group by transformation, where the two labels are tumor, if the measurement corresponds to a tumor sample, and normal otherwise.

the epiviz api also implements a simple computing language for creation of new measurements from combining existing ones. we call the result computed measurements. these differ from the previously mentioned transformations in that they act like regular measurements in the framework, and are available globally for all visualizations to use. for example, based on the gene expression values for normal and cancer colon tissues, we generated a particular kind of scatter plot also known in genomic data analysis as an ma plot - the x axis shows the average gene expression for normal and cancer colon tissues, while y corresponds to the difference. this plot is used in the use case presented in the results and discussion section and shown in figure  <dig>  dudoit et al.  <cit>  offers an in-depth analysis of the motivation behind choosing this kind of plot for differential gene expression analysis. computed measurements values are calculated lazily, as needed by visualizations, just for data represented on the screen.

in the use case illustrated in the results and discussion section, we provide several examples of each of these features - chart code customization, data transformations, as well as computed measurements.

visualization system concepts put together for the first time in genomics
apart from bringing code to visualizations on various levels, epiviz also uses a series of design choices and features of which some have been used before for genome browsing, others for other various types of systems. what makes epiviz stand out is that it is the first software to put all of them together in an integrative genomics interactive visual software. in this section we present some of the most important of these choices, underlining, where necessary, the motivation that led to their development, as well as benefits that follow their implementation.

visual encodings
the epiviz ui offers data scientists a combination of multiple coordinated views and overlays, featuring brushing and linking. the main goal behind this is to enable both data comparison and visual validation in order to help users extract insights and gain both an overall and detailed understanding of the data. epiviz provides out-of-the-box visualizations that are both feature- and genomic location-oriented, to help provide a multidimensional comprehension of the explored domain. both types of visualizations offer in turn different kinds of graphical representations; for example some of the available feature-oriented views are the heatmap and stacked plot, while some of the available location-oriented views are the genes and line tracks . this differentiates epiviz from most other genome browsers, which usually feature only genomic location-oriented visualizations.

all graphics are rendered using scalable vector graphics , an xml vector format that all modern browsers can interpret. choosing this format allows users to treat objects in charts independently, as direct representations of data  <cit> , as well as to perform specific operations on them, by customizing their properties - shape, color, size, stroke, transparency, etc. this opens the door to a wide variety of options available directly to visualizations, of which perhaps the most important are brushing and linking, object tooltips, and the ability to save views as both vector and raster static images.

brushing
through brushing, users have the ability to visually link data from all visualizations on the screen . by hovering over/selecting a particular object in one chart, related objects are automatically highlighted in all other charts as well. the unified data types used in epiviz include identifiers for data source groups which declare keys for each set of observations, to establish data relationships used in the brushing feature. therefore, all data sources from the same group are assumed to have the same keys. in the absence of keys, we use feature coordinate overlap to establish these relationships as well. notice that this design is extremely flexible since keys defining data relationships are defined dynamically. brushing is available in epiviz due to the choice of svg as the rendering mechanism, since each object on the screen corresponds to an html element in the dom. hovering or clicking on an object thus triggers events that all visualizations listen to in order to decide which objects will be highlighted at their end.

collaboration through sharing of analysis steps
one important functionality essential to scientific data analysis, and yet inexistent in current genome browsers, is that of persistently saving and sharing steps of an analysis within the scientific community. often times, operations that should be straightforward, such as replicating results presented in publications pose big challenges and come with heavy overhead. through epiviz, we take the first steps in the direction of simplifying this process, through a feature called workspaces. workspaces were first introduced in our previous work  <cit> ; however, following that, we extended them with new analysis state components, such as code customizations and data transformations, so that any user action within the software could be tracked and reproduced.

workspaces contain complete information needed to reproduce analysis states in epiviz. all visualizations on the screen, including their customizations , and the current genomic location in view are included as part of a workspace. workspaces are stored in a database on the epiviz server hosted at the university of maryland. to save analysis steps, users need to authenticate using an openid account. once logged in, users can create new workspaces and replicate existing ones shared with them. storage management for persistent workspaces is part of the data provider api. source code for this type of server is publicly available on the epiviz project page and can be installed on a standard php/mysql system to provide the same functionality if users desire to keep their workspaces private on a local server. once created, a workspace is associated with a unique id that can be used to share individual work with other users, through permanent hyperlinks. using the workspace id, any user can view a particular workspace, and copy its contents to their own account. this mechanism can be used for either sharing data analyses between users or even for referencing figures in publications .

RESULTS
exploring the relationship between gene expression and dna methylation
we present a use case that highlights the most powerful features of epiviz, with an emphasis on the ones introduced following the work presented in chelaru et al.  <cit> . we used epiviz to explore the relationship between dna methylation and gene expression within normal and tumor colon tissues. our goal was to examine regions in the genome where the difference in gene expression between the two is large.

we started with a genes track showing gene models from the ucsc database. to fetch this data, we used a custom data provider plugin stored on github gist. in order to find regions in the genome where expression differences are large, we used two computed measurements, corresponding to the average, and difference gene expression, respectively, for rna-seq data from chromosome  <dig>  we displayed these using a scatter plot. in order to better observe expression differences, we dynamically customized the code of the scatter plot to show a line at y =  <dig> . we identified two genes with large expression difference by selecting the outliers in this plot from all genes in chromosome 11: mmp <dig> and mmp <dig>  the brushing feature allowed us to observe that these outliers are also adjacent in the genome. to find the exact genomic locations of these genes, we hovered over them to trigger a tooltip .

we zoomed into a smaller genomic region to examine these genes at high resolution. to check whether expression differences are consistent across tissue types, we added a heatmap with aggregated expression data from the gene expression barcode  <cit> , for six different tissue types, both normal and tumor: colon, stomach, breast, kidney, lung and esophagus. we used this visualization's clustering feature to group tissues based on gene expression similarity within this genomic region. the high expression differences for the mmp <dig> and mmp <dig> genes, between normal and tumor tissues, across tissue types, played a decisive role in the clustering result .

next, we added a new visualization called stacked plot, showing two columns, corresponding to the summed gene expression for normal and cancer tissues respectively. this visualization stacks values for different genes, one on top of the other, depicting each gene with a different color. using a color by transformation, we customized this plot to color-code different genes according to the expression differences . analyzing the result yields a couple of insights: first, that overall gene expression tends to be higher for cancer tissues; and second, that genes with high expression difference tend to be collocated in the same region of the genome .

to examine gene expression along the genomic coordinate in relation with dna methylation, we created a custom track plugin, which we stored on github gist. the track displays genes as blocks aligned to the genome, whose height corresponds to the gene expression. we also added a new visualization called stacked track, which we used to display a computed measurement, corresponding to the difference in methylation levels between normal and cancer samples . the data for these measurements corresponds to base-pair-resolution smoothed methylation log ratio resulted from sequencing of bisulfite-converted dna  <cit> . the advantage of this type of visualization over the traditional blocks track which we used in the previous version of our work is that this offers not only information about the location of hypomethylated blocks, but in addition, it provides a two-dimensional high resolution understanding of the structure of these blocks. for example, examining these two tracks side by side, we were able to extract a number of insights: first, the density of genes increases as methylation difference decreases; second, gene expression for both normal and tumor samples increases in regions where methylation difference is smaller; and third, we were able to differentiate between hypomethylated regions by their level of auto-correlation  at base-pair level, which links well in this region with gene expression differences.

finally, we created a line track showing the methylation levels for six different samples, three normal and three tumor. we used the group by transformation, to aggregate normal and cancer samples together respectively . a high resolution view over the data allowed us to further differentiate between the two hypomethylated blocks in view: the first, ranging from  <dig>  mbp to  <dig>  mbp, and the second, ranging from  <dig> mbp onward.

we discovered that although at the block-level there is an overall difference between cancer and normal methylation, the degree of auto-correlation in the methylation data at base pair resolution varies within the block. furthermore, we observed that genes that show high differences in expression tend to collocate with regions of low methylation auto-correlation  while genes that are not differentially expressed collocate with regions of high methylation auto-correlation . this analysis suggests that understanding the relationship between expression and methylation within long epigenetic domains requires that methylation data is analyzed at multiple genomic resolutions. using epiviz, it was easy to switch between low and high resolutions to facilitate these type of multi-resolution analyses.

notes about software security
one challenge that comes with allowing epiviz to incorporate and run third-party scripts consists of the security risks associated with sql injection and cross-site scripting   <cit> . the main concern is that, having access to private user information, third-party scripts could be used to compromise user content, privacy, and sensitive data. in this section we underline the ways in which epiviz addresses these concerns in order to provide a safe data analysis environment.

epiviz features a server side component, and a client javascript component, the latter containing the entire framework functionality, described in this paper. the server side component contains a web service for a number of public epigenetic datasets, similar to those hosted on other genome browser servers, as well as private epiviz user information, such as their openid account data provided when signing up, and workspaces associated to it. the public sets of epigenetic data are served in a read-only fashion, no changes to it being permitted to users accessing the service. openid information cannot be retrieved using the web services endpoint; in addition, information about a particular user cannot be modified externally after the user has logged in for the first time, having successfully authenticated using the corresponding openid provider. the only information that can be both retrieved and modified externally on the server side is that of user workspaces. changes to workspaces can be made within the session of their owner. all database access for the webserver is achieved through php prepared statements  <cit>  which are guaranteed safe from sql injection.

this implementation leaves room for only one type of potential attacks. malicious external javascript code, being incorporated into epiviz using the dynamic code interpretation feature, might gain access to the user session and potentially compromise workspaces information, the only kind of private information that can be accessed and modified externally. alternatively, it could extract private information such as that stored in user cookies, and transmit it to a phishing server using, for example, ajax calls. this constitutes a great vulnerability, and therefore, we needed to find a solution which would allow the execution of third-party scripts in a sandbox mode, with no access to sensitive information or actions that might compromise data integrity.

to address this vulnerability, we used a javascript sanitizing library called caja  <cit> , which allows third-party scripts to be executed by the same javascript runtime environment as the framework code, but in sandbox mode, with restrictions defined within the host script.

whether the scripts are stored externally, or they consist of custom code inserted using the web-browser code editor, they are executed in protected mode, which effectively defends against xss attacks. this security feature allows epiviz to be the first visualization tool to allow its users the wide range of power that comes with expanding functionality through third-party plug-ins and code customization.

future research directions
performance and optimization
there are three ways of addressing the limitations brought by the choice of javascript as the main programming environment for our framework. in this section we describe some which we are looking to implement in our future work: 1) a clearer separation of data processing operations from visualizations, to better use with web workers; 2) the use of the webgl technology, which comes with all the power of gaining direct access to the gpu  <cit> ; 3) as the new technology webcl  <cit>  becomes available, and execution threads are introduced into the language, move some of the most cpu-consuming operations of epiviz into secondary execution threads.

the choice of svg for rendering visualizations also comes with a number of limitations which we describe in the supplementary material. in chelaru et al.  <cit>  we discussed a number of optimizations for individual charts, as well as their effects over render latencies. what is not said there is that these optimizations cannot, because of the design decisions of epiviz, be generalized so that new visualizations can take advantage of them. a solution for this drawback, which we are looking at implementing in future versions of our software, is to alternate between raster views and vector views, depending on the amount of data loaded in memory. we anticipate this approach to significantly improve user experience for the visualization of extremely large datasets.

research directions in collaboration
epiviz has taken a few preliminary steps in the direction of providing a collaboration-friendly environment. two features in particular are aimed to help teams that work on a joint data analysis project: 1) workspaces, which provide a way of storing analysis steps persistently, and sharing them among the community; 2) an api that has support for custom software plugins created within the scientific community, stored on github gist, which can be used to share visualizations and data providers among users. in addition, as the entire code base of epiviz is open-source, users from the scientific community are able to report errors or new ideas, as well as contribute to the development of the project. however, these represent only our preliminary efforts in a long-term plan of creating a truly collaborative data analysis environment and by no means do we consider them complete. in this section we briefly introduce the next two steps we mean to take in this direction, based on previous research on this topic  <cit>  as well as related examples  <cit>  where approaches have proved to provide a high level of collaboration, enhancing usability, transparency and interaction among users.

a first step is to centralize workspaces, as well as custom user code used for both plugins and data transformations, in a webpage similar to those provided by ipython and rcloud for user notebooks. we intend to allow our users to browse existing workspaces and plugins, copy and extend them, as well as rank them using a starring system. the goal for this feature is to introduce transparency and awareness within the epiviz community, allowing users to dynamically interact with each other and expand the usability of the framework.

the second step is to introduce same-workspace concurrent collaboration. the current functionality already allows the same epiviz instance to pull data from multiple sources, of which several can be either r or python sessions. these sessions can be located on any network-accessible machine. this opens the door to a peer-to-peer type of collaboration similar to that of google docs, where multiple users can connect to the same data sources and computational environment sessions, and interact from different workstations over the same joint workspace simultaneously. changes made to the workspace by one user will be immediately propagated and become visible to all other users connected to the same r session. the current architecture of epivizr is one step away from permitting this kind of functionality. the only thing missing is an awareness component within the epivizr package which will track the activity of each connected user, and propagate it to all the others. the peer-to-peer approach also implies that no centralized server would be necessary for this architecture, delegating that functionality to the r/epivizr sessions instead.

incorporating new technologies
epiviz was designed with the goal of easily incorporating new technologies, both on the data integration side  and the visualization side. for example, new technologies such as htmlwidgets  <cit> , released after the initial launch of epiviz, consists of an r package that provides a framework for creating r bindings to javascript libraries. users and developers are tasked with creating wrappers around javascript libraries, in order to use them directly in r applications. the package can be used alongside shiny to facilitate two-way communication between r and javascript. the design of epiviz permits the creation of bindings for the epiviz visualizations tier using htmlwidgets, to facilitate the use of our visualizations independently of genomics data analyses. generic visualizations included in epiviz, such as the heatmap or scatter plot, which have grown to be very feature-rich - exposing options for coloring by data features, clustering, binning, brushing and linking, etc. - can thus be made available to the entire r community in a lightweight fashion, without the tight coupling to the entire epiviz framework, or the epivizr bioconductor package.

CONCLUSIONS
we gave an overview of the motivations that led to the development of epiviz as well as a series of design decisions and features that have never been put together before genomics interactive visual analysis. epiviz is the first genomic data analysis software that brings code to interactive visualization, bridging the gap between computational environments and genome browsers. the software also sets a precedent for genomic data analysis collaborative workflows by enabling reproducible and shareable steps, and allowing custom user code to be dynamically incorporated, while guaranteeing the security and integrity of user data.

availability and requirements
epiviz is available at http://epiviz.cbcb.umd.edu. epivizr is available as a bioconductor package . documentation is available at http://epiviz.cbcb.umd.edu/help.

list of abbreviations
dnam: dna methylation; dmr: differentially methylated region.

competing interests
the authors declare that they have no competing interests.

authors' contributions
fc and hcb designed the software, analyzed data and wrote the manuscript.

supplementary material
additional file 1
click here for file

 acknowledgements and declarations
we thank the bioconductor core team and members of the bioinformatics and computational biology department of genentech research and early development for helpful suggestions and comments. this work and publication was partially supported by us national institutes of health grants r <dig> hg <dig> to h.c.b. and f.c., r <dig> hg <dig> to h.c.b., and support from genentech.

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2015: proceedings of the 5th symposium on biological data visualization: part  <dig>  the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/16/s11
