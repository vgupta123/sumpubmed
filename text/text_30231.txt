BACKGROUND
the very large and continuously increasing amount of data obtained by genome sequencing makes the development of reliable computational methods capable to infer protein structures from sequences a crucial step for functional annotation of proteins. in fact, functional annotation is often strictly dependent on the availability of structural data, which in turn are still difficult to obtain experimentally. as a consequence, efforts and progresses in high throughput x-ray and nmr methods need to be accompanied by computational techniques suitable for three-dimensional structure predictions, such as homology modeling, fold recognition or ab-initio methods  <cit> , which are intrinsically characterized by different levels of accuracy.

in parallel to the development and improvement of prediction methods, reliable and accurate evaluation tools are necessary to check the quality of computational protein models  <cit> . moreover, in the context of protein structure refinement, which has been recently identified as one of the bottlenecks limiting the quality and usefulness of protein structure prediction  <cit> , it has been noted that improvements in the selection of the most native-like model from an ensemble of closely related alternative conformations can be crucial. the increasing importance of the field of quality assessment methods is demonstrated by the introduction of a dedicated section in the latest casp edition   <cit> .

to evaluate protein structures, several different scoring functions have been developed, which can be classified into different categories depending on the principles and on the structural features considered in the evaluation. physical scoring  functions aim to describe the physics of the interaction between atoms in a protein and are generally parameterized on molecular systems smaller than proteins  <cit> . knowledge-based scoring functions are designed by evaluating the differences between some selected features of a random protein model and the characteristics of a real protein structure  <cit> .

learning-based functions can be developed by training algorithms to discriminate between correct and incorrect models  <cit> . independently by the category, scoring functions are generally tested by examining their capability to detect the native structure among a set of decoys  <cit> , which can be generated in several different ways  <cit> .

it is important to note that the performance of learning-based functions are generally strongly dependent on the specific aim for which they were developed, and consequently on the training set used. as an example, proq, a neural network based method developed to predict the quality of protein models  <cit> , was specifically designed to discriminate between correct and wrong models, i.e. to recognize folds that are not compatible with a protein sequence. in fact, proq was recently combined successfully with the pcons  <cit>  fold recognition predictor and ranked as one the best methods in a recent survey of quality assessment methods  <cit> . other reliable and extensively used computational methods used to validate the quality of protein structures are prosa  <cit> , errat  <cit> , verify 3d  <cit> , procheck  <cit> , what-if  <cit> , prove  <cit>  and victor/frst  <cit> .

in the present contribution, we present a computational method  that is able to reliably and consistently discriminate between correct and incorrect protein models. in particular, the quality of the protein structure is evaluated with neural networks using as input  <dig> structural parameters, which include solvent accessible surface, hydrophobic contacts and secondary structure content. in the first section of the paper, the neural network structure and the training procedure are presented and discussed. in the second section, the performance of the neural network is evaluated, compared to available methods, and critically discussed.

RESULTS
the evaluation of the quality of protein structures is generally carried out calculating a score which is a function of a set of parameter values computed for the protein model under study. in our computational procedure, the description of the relation between the parameters space and the scoring values is obtained using neural networks, because of their ability to describe complex non-linear relationships among data.

selection of protein parameters related to structure quality
among the possible parameters that can be computed for a protein structure, we have selected some properties that are expected to be related to structure quality: solvent accessible surface of hydrophobic and hydrophilic residues, secondary structure content, the fraction of secondary structure content of the model fitting with that predicted by psipred  <cit> , number of hydrophobic contacts, and selected procheck parameters  <cit>  . it should be noted that other possibly relevant parameters, such as the number of hydrogen bonds, have not been used due to intrinsic difficulties in the normalisation of their values.

selection of the parameters used to evaluate structure similarity
a key issue for evaluating the quality of a predicted protein structure is the measure of its "distance" relative to the "real" structure, experimentally obtained by x-ray diffraction or nmr. since aide has been developed to evaluate protein models that are often characterized by the correct fold but may differ for local details, the backbone root mean square deviation  of the protein model relative to the x-ray structure can be considered a suitable measure of structure similarity  <cit> . in fact, it is well known that the proper evaluation of the quality of protein structures can be a non-trivial task, often depending on the methods used to generate protein models. therefore, several other measures of protein structure similarity have been formulated, the most commonly used being: gdt-ts  <cit> , lg-score  <cit> , tm-score  <cit>  and maxsub  <cit> , which have also been adopted in the present work.

selection and optimization of the neural networks
a preliminary evaluation of the relative importance of each parameter in the description of structure quality was obtained using a linear models built with the m5-prime attribute selection algorithm  <cit> , as implemented in weka  <dig> . <dig>  <cit> . a different linear model was computed for each accuracy measure. analysis of the linear models revealed that the secondary structure content and the solvent accessible surface have the highest importance in all models. moreover, results show that it is not possible to exclude any parameter since non negligible weights are associated to all selected parameters, when the accuracy measures chosen are considered as a whole .

the neural networks forming the core of aide are four layers feed forward neural networks with fifteen neurons  in the input layer, two hidden layers formed by two neurons each, and one neuron in the output layer. a linear activation function was chosen for all neurons. indeed, different combinations of hidden layers  and different numbers of hidden neurons per layer  were tested. in addition, we tested also different activation functions of the neurons . it turned out that, among the different combinations, the neural network featuring two hidden layers formed by two neurons gave the best results. in fact, an increase in the number of neurons led to poorer performances, probably due to the increased difficulties in the optimization procedure arising from the augmented network complexity. to carry out the optimization of neural networks, we have implemented the attractive-repulsive particle swarm optimization algorithm   <cit> , as explained in methods. training of the neural networks using more conventional approaches , led to slightly lower performances . this may be due to the greater exploration ability that characterize the pso methods.

aide was trained and tested on datasets of all-atoms protein decoys for which the three-dimensional structures are available. since it is known that methods used for building decoys may introduce some systematic bias, it is important to benchmark a scoring function on different decoy sets in order to assess its generality. the overall dataset used in the present study is composed by an ensemble of widely used all-atom datasets containing models of different proteins , plus a molecular dynamics set that was generated in our laboratory from x-ray structures .

after computation of the structural parameters to be inserted in the neural networks, the overall dataset was subdivided into a training and a test set, which were composed by  <dig> and  <dig> structures, respectively. the training-set includes only the proteins belonging to the livebench <dig> and casp <dig> decoy sets . the test-set includes the lmds, casp <dig>  hg_structal, md, rosetta and 4state-reduced subsets . the livebench <dig> and casp <dig> decoy sets were chosen as training sets because they contain models build with different methods and of different protein size, ranging from  <dig> to  <dig> residues. no protein contained in the training set is present also in the test set.

then, a population of  <dig> neural networks was trained starting from different initializations of the structural parameters. the network featuring the best performance  was selected as the working network in aide.

a different neural network was trained for each measure of structure similarity chosen to evaluate proteins quality . therefore, five different versions of aide were obtained from the training procedure, referred to in the following as aide rmsd, aide tm-score, aide gdt-ts, aide lg-score and aide maxsub.

assessment of aide performance
the performances of the different version of aide have been compared to results obtained from widely used methods developed to evaluate protein models quality.

the performances of the different methods were evaluated using a test-set which includes lmds, casp <dig>  hg_structal, md, rosetta and 4state-reduced subsets. the livebench <dig> and casp <dig> sets were already used for training aide and therefore were not used in the comparative evaluation.

the pearson correlation coefficient, znat and fraction enrichment , which give indications about a method ability to assign good scores to good models, have been computed and results are collected in tables  <dig>   <dig>   <dig> 

analysis of pearson correlation coefficients  shows that, according to this statistical indicator, the different aide versions behave quite similarly. most importantly, average aide performances are similar or slightly better than those obtained by two state-of-the-art methods such as proq  <cit>  and victor  <cit> . it is also noteworthy that the performance of aide changes significantly moving through the different subsets forming the test-set. in particular, very high correlation coefficients are obtained with the md and hg_structal datasets , whereas low values of pearson coefficients are associated to the casp <dig> dataset . relatively different values of pearson correlation coefficients are obtained also with proq and victor. in particular, and differently from aide, low correlation coefficients are obtained by proq for the rosetta subset, and by victor for the fisa subset . the factors responsible for such non-homogeneous performances of the methods, when applied to different datasets, could not be unrevealed and might require further dissection of the test-set. in light of these results and observations it can be concluded that, even if the overall performances of aide, proq and victor are similar, these methods can behave very differently on protein models obtained using different approaches, suggesting that the combined use of aide, proq and victor could be useful to properly evaluate the quality of a protein structure.

analysis of f. e. values  shows again quite similar overall performances of aide, proq and victor. however, the average f. e. values obtained using proq are consistently higher  relative to the corresponding values obtained with victor and aide. a more detailed analysis of f. e. values obtained from the different subsets composing the test set highlights some interesting trends. f. e. values obtained from the lmds and fisa subsets are consistently lower than the average. moreover, aide and proq versions trained using different parameters to evaluate structure similarity can give quite different results. the latter observation is particularly evident for the lmds subset. it is also interesting to note that the best performances on the different subsets forming the test set are often obtained by different methods. as an example, the best f. e. values for the fisa subset are obtained using aide, whereas the best values for the hg_structal subset are obtained with proq, further suggesting that the combined use of the different methods can be a good strategy to obtain a more confident evaluation of the quality of a protein structure. znat allows to evaluate how  the different methods distinguish the native  structure from the ensemble of its models . in this case it was possible to extend the comparison to other methods widely used to evaluate protein structures quality . only the lmds and 4state_reduced subsets have been used in this comparison because these are the only datasets in common among all the compared methods for which data are available. analysis of znat values reveals that proq and victor have better performances in this statistical test, whereas aide results are generally comparable to those obtained with errat, prosa ii and verify 3d. notably, very low znat scores are obtained using aide rmds and aide lg-score on the 4state_reduced subset.

it should be noted that znat and f.e. do not give information about the ability of a method to assign low scores to bad models, i. e. these statistical indicators do not allow to check if a method is confusing different classes. to explore this issue we have qualitatively compared aide and proq performances, superposing the roc plots  computed on the test-set for each different performance function . according to this analysis, proq maxsub exhibits the greatest overall accuracy, whereas aide gdt-ts has the lowest accuracy.

considering the different aide versions, a clear distinction can be observed when comparing the overall accuracy of aide rmsd and aide maxsub relative to aide lgscore, aide gdt-ts and aide tmscore . notably, a similar difference was not evident when considering the correlation coefficients or the fraction enrichment test. it is also important to note that aide lgscore behaves very similarly to proq lgscore until about 60% of sensitivity, whereas at higher sensitivity levels aide outperforms proq lgscore. these observations further corroborate the hypothesis that the combined use of proq and aide should give improved results in the evaluation of the quality of three-dimensional protein models.

the web interface of aide
the availability of five different aide versions gives a nice picture of the overall performance of the method. however, the overloading of output information can become a drawback for the user interested only in the most relevant results. in fact, the analysis of aide performance has shown that the five different versions of aide are generally characterised by similar behaviour . to better evaluate the degree of correlation among different aide versions we have carried out a principal component analysis on the pearson correlation matrix of the descriptors chosen to evaluate models quality. this analysis reveals a strong correlation between tm-score, gdt-ts and maxsub. the different clustering of tm-score, gdt-ts and maxsub relative to rmsd and lg-score is mainly due to the inverse relationship between the two families. therefore, two  of these highly correlated parameters have been excluded from the output of the aide program available on the internet  <cit> . moreover, to help the user in the evaluation of aide results, we have defined a threshold for each predicted parameter, in order to discriminate between incorrect and correct models. in particular, correct models should have tm-score ≥  <dig> , rmsd ≤  <dig>  Å and lg-score ≤  <dig> . these thresholds were chosen using a dataset of manually assessed models composed by some casp <dig> targets belonging to the new fold and fold recognition categories. according to the visual evaluation of aloy and coworkers  <cit> , the models were divided into three class: class  <dig>  when the overall fold is correct, class  <dig>  when the model is considered partway to the correct fold, and class  <dig> for all the other models. for each model, the tm-score, lg-score and rmsd were computed  and the average value for the models belonging to the "excellent" class was used as threshold. to further evaluate the classification ability using the chosen thresholds, the sensitivity and the specificity based on the roc plots were also computed .

CONCLUSIONS
in this paper we have presented aide, a neural network system which is able to evaluate the quality of protein structures obtained by prediction methods.

aide differs from other evaluation methods mainly for : i) a different choice of the parameters used to describe the protein structure, ii) a different choice of the parameters related to structure quality, iii) a novel strategy used to optimize the neural networks. aide overall performances are comparable to recently published state of the art methods, such as proq  <cit>  and victor  <cit> . however, detailed comparative analysis of results obtained using aide, proq and victor reveals that the three methods have different and often complementary ability to properly assess the quality of protein structures. this observation suggests that the combined use of aide, proq and victor could increase the reliability in the evaluation of protein structures quality. aide is presently available on the internet  <cit> .

