BACKGROUND
obtaining stable mutant strains with mutations in high-priority genes is essential for a mechanistic understanding of biological processes. over the last decade, with the increasing knowledge from whole genome sequencing, reverse genetic approaches are playing more and more important roles in providing genetic loss-of-function tools to the research community. tilling  involves identifying and recovering rare mutant alleles in specific genes of interest from a large library of randomly mutagenized individuals, and is one of the most widely used reverse genetic techniques.

first developed in arabidopsis in  <dig>  <cit> , tilling has been applied to a range of plant and animal species  <cit> . the classical tilling process involves pcr amplification of a specific target from the entire mutagenized library with fluorescent labeled primers and cel <dig> enzyme digestion of the resulting pcr amplicons to cut any heteroduplexes caused by the presence of induced mutations that occur only once in the entire library. full-length and rare cleaved fragments are detected by li-cor gel analysis, and point mutations are confirmed by sanger sequencing  <cit> . although this process has proven effective, it is limited to screening a single target at a time and its poor sensitivity only allows a low level of library pooling. thus it is both labor-intensive and time-consuming. in addition, mutation detection relies on li-cor gel imaging which constrains the fragments that can be screened to 750– <dig> bp, a size that is frequently incompatible with intron-exon structure. furthermore, the approach is limited by the intrinsic specificity of the cel <dig> endonuclease and is influenced by the level of pre-existing polymorphism in target genes.

we established an enu-mutagenized library of  <dig>  f <dig> male zebrafish, each with a unique set of ~ <dig>  enu-induced heterozygous mutations and have used cel1-based tilling to identify and recover deleterious mutations from this library in over  <dig> genes  <cit> . in recent years, however, next-generation sequencing  has provided the capability to process multiple tilling targets at the same time. the general strategy for ngs-tilling is to amplify multiple target exons from pools of template dnas, and then to pool and barcode all of the targets from a single library pool for sequencing. to date, two groups have applied ngs to tilling  <cit> . however in order to detect mutations over background pcr and sequencing errors, template pooling was limited to  <dig> individuals and the entire library was limited to fewer than  <dig>  individuals. furthermore, shearing of the pcr amplicons in preparation for illumina sequencing resulted in uneven sequence coverage and thus incomplete screening of target fragments.

here we introduce a new ngs-tilling strategy that allows us to screen up to  <dig> pcr amplicons at a time in a library of over  <dig>  mutagenized individuals with high efficiency and accuracy. our method involves three innovations: 1) rather than using a complex pooling strategy that triangulates on one or a few potentially mutant individuals  <cit> , we simply use illumina sequencing to identify mutations in a pool of  <dig> individuals under a single barcode; we then deconvolve that pool using high resolution melt  analysis; 2) rather than amplifying large genomic fragments and shearing them to generate short overlapping fragments appropriate for illumina hiseq, a process which is time-consuming and yields uneven sequence coverage, we amplify  <dig> bp fragments corresponding to exons of interest and sequence them directly using the illumina miseq platform; 3) in order to eliminate sequencing error as a source of false positives, we do paired-end sequencing of the entire  <dig> bp amplicon, align the two sequences from each cluster and reject any overlapped reads with less than perfect sequence identity. this “paired-end low-error” analysis is described elsewhere  but is similar in principle to the method recently described  <cit> . we have confirmed that our ngs-tilling method is able to identify known mutations previously identified by cel <dig> tilling, and furthermore demonstrate that it can identify mutations that were previously not found with cel <dig>  we have gone on to test our method with  <dig> target fragments from  <dig> zebrafish genes, and identified  <dig> nonsense mutations in  <dig> of these genes with an acceptable false-positive rate of  <dig> %. while being developed for mutation identification in the zebrafish, our approach is applicable to any species that is amenable to chemical mutagenesis.

RESULTS
library pooling and fragment preparation
for any tilling approach, a large population of mutagenized individuals is required. we generated a library of  <dig> enu-mutagenized f <dig> male fish by treating wild type  adult male fish with enu to mutagenize their spermatogonia, crossing them with wt females, and raising f <dig> male progeny to adulthood  <cit> . each f <dig> fish carries a unique set of heterozygous enu-induced mutations, so any given mutation occurs only once in the entire library, i.e. at a ratio of  <dig> mutant:  <dig>  wt alleles. sperm from these males was cryopreserved and their carcasses were used for the preparation of genomic dna as described  <cit>  .figure  <dig> 
ngs-tilling process. a: a long-term resource for many tilling screens consisting of a genomic dna sample and a corresponding cryopreserved sperm sample was prepared from  <dig>  f <dig> enu-mutagenized male zebrafish. b: library pooling. normalized genomic dna  was pooled twice: first, gdna from  <dig> fish was pooled together to make  <dig>  6-fish pools in  <dig> 96-well plates. these six-fish pools will be used for hrm identification of carrier fish . second, groups of  <dig> 6-fish pools were pooled together into 288-fish pools . c: target preparation. gdna from 288-fish pools was used as a template for pcr amplification of ~ <dig> bp fragments corresponding to exons of genes of interest using gene-specific primers with p5/p <dig> seq tails . after normalization, amplicons from each 288-fish pool were combined and used as template for a brief second pcr that added nextera index sequences  and illumina p5/p <dig> sequences . d: sequencing: all amplicons from the entire library were combined and sequenced , generating fully overlapping  <dig> bp paired-end sequences. e: data analysis. sequence analysis using pele and podata identified rare deleterious variants  in single 288-fish pools. f: deconvolution. a fragment centered on a putative variant call was amplified from each of the 48-six-fish pools used to make up the 288-fish pool in which that variant was detected, and was subjected to high resolution melt  analysis. then hrm of the six individual fish in the six-fish pool that showed distinct melting kinetics identified the individual carrier. g: mutant recovery. finally, the presence of the variant identified by pele and podata was confirmed in that fish by sanger sequencing. f <dig> heterozygotes were generated by in vitro fertilization of wt eggs with the corresponding cryopreserved sperm sample.



this genomic dna library from  <dig> fish was normalized and subdivided into pools of  <dig> fish each  for ngs-tilling. the 288-fish pool size was determined empirically to be the largest number of fish that allowed us to unambiguously identify induced mutations, which are expected to occur in a single pool at a frequency of 1: <dig> alleles, over mutations introduced by the pcr or sequencing steps . we have also sequenced pools of  <dig> fish  and were able to identify known variants but this incurred a 2-fold higher false positive rate to identify most of the known variants. therefore, we chose to screen pools of  <dig> fish.

we amplified and directly sequenced the largest fragments possible using available ngs technology, without shearing or otherwise fragmenting the template. the miseq platform generates  <dig> million  <dig> bp paired-end sequencing reads . we estimated, given this capability, that we could sequence  <dig>  <dig> bp fragments in two directions from each of the ~ <dig>  haploid genomes in the library at sufficient coverage to detect multiple reads of a mutant allele that appears only once in a single 288-fish library pool. we chose  <dig> bp fragments rather than  <dig> bp fragments so that the miseq paired-end reads would be fully overlapping .

the detailed protocol for target fragment preparation is provided . briefly, we used gene-specific primers to amplify 210- to  <dig> bp fragments corresponding to conserved exons in genes of interest. the genes were identified by members of the zebrafish community as being of high biomedical interest, and were submitted via an online request site  . for each gene of interest, multiple exons were selected as target fragments. wherever possible, we used coddle   <cit>  to identify exons in which enu has the highest likelihood of generating nonsense mutations. a first round of pcr  amplified target fragments from genomic dna using a pair of gene-specific primers with illumina p5/p <dig> seq tails. equal amounts of each of the  <dig> gene-specific pcr products from each 288-fish pool were combined and briefly amplified  using illumina nextera index primers to add a pair of specific illumina indices and p5/p <dig> tail to the amplicons from each pool . finally, the indexed fragments from all  <dig> pools were pooled for loading onto an illumina miseq desktop sequencing machine using the miseq v <dig> reagent kit per manufacturers instructions.table  <dig> 
summary of ngs-tilling findings



genes
fragment screened
exon screened
total target size
coding size
variants tested
variant confirmed
deleterious mutations
 <dig> target fragments, from  <dig> exons in  <dig> genes screened by ngs-tilling. the total amount of genomic dna screened was  <dig>  kb in each of  <dig>  fish, corresponding to almost  <dig> mb of sequence. of this  <dig>  kb,  <dig>  kb coding sequence.  <dig> deleterious mutations  were found in  <dig> genes out of  <dig> genes.



miseq sequencing
using the approach outlined above we screened our  <dig> -fish library for  <dig> target fragments from  <dig> genes  in five miseq runs . in each of the sequencing runs we loaded 15– <dig> pm sample and obtained an average cluster density of 802/mm <dig> and an average of 85% of clusters passing the quality filter , corresponding to an average of  <dig>  gb of raw sequence  per run. in the first step of the data analysis, ~15% of the raw data  was identified as sequencing error and discarded . the rest of the data was processed for alignment of each target fragment. coverage of each fragment was very even within a pool, with read depth varying only 2-10% across the length of fragments , while read depth for different fragments varied as much as 10-fold  and read depth for the same fragment in different pools varied as much as 3-fold .figure  <dig> 
sequence coverage from direct miseq pe <dig> sequencing. a: direct sequencing of target amplicons without shearing produces homogeneous sequence coverage. representative average read coverage of three amplicons under a single barcode with high , medium  and low  coverage. even the poorest sequence coverage exceeds the minimum coverage needed to accurately identify mutations in our 288-fish pools . b: amplicon coverage across all library pools. different colors represent the same amplicon from each of the  <dig> pools in the library. c: variable coverage of different fragments. each bar represents the average coverage across the entire library of a single randomly selected nucleotide in each of  <dig> fragments screened.  <dig> of  <dig> fragments exceeded the minimum coverage needed to accurately identify mutations in our 288-fish pools .



we chose  <dig>  reads as the minimum number of reads at each position in each pool for screening, as this corresponds to  <dig> reads per allele assuming equal amplification of each allele in the pool: 2880reads/pool288fish/pool×2alleles/fish=5reads/allele . at this level, a mutant allele that is present in the heterozygous condition in a single fish in the pool should be detected at least once.  <dig> out of  <dig> target fragments exceeded this minimum, with an average read coverage of  <dig>  ±  <dig>  per pool . the remaining two fragments were analyzed  but were not considered fully screened.

sequence analysis and filtering
we used paired-end low-error  analysis to detect rare enu-induced mutations in our miseq dataset . briefly, pele concatenates and processes data from several sequence analysis programs. first, it merges the two overlapping sequences generated by paired-end sequencing of each cluster using the seqprep program  and filters out any imperfectly aligned sequences, thereby eliminating errors that occurred during the sequencing process that would occur in one but not both paired-end reads.

next, pele aligns the reads that passed the first filter to our reference sequences using the novoalign  software and detects all single-base variants using samtools   <cit> . for each variant, pele assesses its frequency  in the pool in which it occurred as: f=numberofvariantreadstotalnumberofreadsatthatpositioninthatpool. 

using pele, in each miseq run we identified 3000– <dig> variants at frequencies ranging from f = 1/ <dig> to f = 1/ <dig> . single base variants have three possible origins: 1) they may be the enu-induced mutations we wish to identify; 2) they may be polymorphisms that existed in the parental fish prior to mutagenesis; 3) they may have been introduced during the pcr amplification of target fragments. an enu-induced mutation is expected to exist in a single f <dig> fish in the library in the heterozygous condition, so it should appear in a single 288-fish pool at f≅1/ <dig> assuming equal amplification of all alleles in a pool. pre-existing polymorphisms are expected to be much more frequent, since the library was made from less than  <dig> closely related enu-mutagenized g <dig> fish  <cit> . we assume that pre-existing polymorphisms occur at a frequency of f > 1/ <dig>  so we excluded from further analysis any variants occurring at f > 1/ <dig> figure  <dig> 
mutation distribution and validation. a: frequency distribution of all variants from one miseq run after pele analysis.  <dig> variant calls were made by pele analysis, ranging from 1/ <dig> to 1/ <dig>  we selected  <dig> putative variants that occurred at a frequency between 1: <dig> and 1: <dig> for validation . b: frequency of  <dig> variants chosen for validation using podata. green diamonds are variants that were confirmed as being genuine enu-induced mutations; red triangles are variants that failed to be confirmed . the x axis shows the frequency with which each variant appeared within its pool. variants in the dark grey area  were filtered out as pre-existing polymorphisms. the vertical green line is the theoretical frequency for a unique enu-induced mutation within a pool . the red line is the upper bound of verified calls . c: summary data in figure 3b. green bars represent confirmed variants, red bars are false positives in each of three frequency bins. d: comparison of cel <dig> vs ngs-tilling using a control fragment. ngs-tilling detected  <dig> variants of which  <dig> were verified  including all  <dig> mutations found previously using cel1-based tilling .



variants introduced by pcr can appear at any frequency depending on when in the amplification process they occurred, but even if they arose very early in the amplification process their frequency is not anticipated to be higher than that of the enu-induced mutations in the template genomic dna. we determined the frequency threshold at which variants introduced in the amplification process outnumber enu-induced variants empirically, by attempting to validate  <dig> sequence variants that occurred at a frequency between  <dig> : <dig>  and 1: <dig> . the  <dig> variants we attempted to validate were chosen from among all the variants in all  <dig> fragments that were called based on their high likelihood of causing loss-of-function phenotypes. to facilitate selection of potentially deleterious variants, we developed a program, “predictor of deleterious alleles in target amplicons”   that predicts all possible single nucleotide substitutions in target fragments that can cause a nonsense mutation or change an rna splice site, and then flags ngs-tilling variants that fall into this data set.

of these  <dig> variants, we confirmed 30/ <dig>  of variants that were called at a mutant/wildtype ratio between 1/100 > f > 1/ <dig>  we also confirmed 18/ <dig>  of variants that were called between 1/576 > f > 1/ <dig> . none  of the variants that appeared at lower frequencies  could be validated; we conclude that these represent errors introduced by pcr. thus by setting our frequency filters at 1/100 > f > 1/ <dig> we were able to validate  <dig> %  of putative mutant calls ; the false positive rate is thus 100– <dig> % =  <dig> %. these validated mutations included  <dig> deleterious mutations  in  <dig> genes; an efficiency of  <dig> deleterious mutation per  <dig> bp of coding sequence. this compares favorably with an efficiency of  <dig> nonsense mutation per  <dig> bp of coding sequence screened in the same library with cel <dig> tilling  <cit> .

importantly, in the  <dig> target fragments we screened, we included one fragment that, using the cel <dig> tillng methodology, we had previously identified  <dig> enu-induced mutations in our library . using the ngs-tilling approach described above, we made  <dig> variant calls in this fragment, and verified  <dig> of them, including all  <dig> mutations previously identified by cel <dig> tilling plus  <dig> new mutations . thus based on our overall nonsense mutation recovery rate and this direct comparison, ngs-tilling is significantly more effective at identifying rare mutations than cel <dig> tilling.

validation of pele method for identifying rare mutations
the merging of overlapping paired-end sequences with pele identified  <dig>  ±  <dig> %  of the raw data as error and discarded it. to determine whether this step was necessary for eliminating false positives, we compared the number of variants identified with and without this merging step. in one miseq run with a total target size of  <dig>  kb, pele analysis identified a total of  <dig>  variants in the range of 1/100 > f > 1/ <dig>  however, direct alignment of raw sequences against reference sequences without merging identified  <dig>  variant calls -  <dig>  times more calls in the same f range. we attempted to validate  <dig> of the extra calls that were generated without paired-end sequence merging  and failed to validate any of them. these data demonstrate that pele analysis efficiently reduces noise of sequencing error from real variants: at the cost of losing ~15% of the raw sequence data, pele analysis filtered 98% of the noise generated in the sequencing process.

mutation verification and recovery
the ngs-tilling method described above identifies a pool of  <dig> fish that includes a single fish with a specific single heterozygous nucleotide change. since at this point we knew the exact sequence of the variant, we reasoned that we could use a standard genotyping approach to locate that fish within the pool. high resolution melt  analysis detects mutations in double stranded pcr amplicons due to their different disassociation kinetics at increasing temperatures  <cit> . we determined that a known single nucleotide mutation is detectable by hrm when present as one allele in  <dig>  and can be robustly detected at a ratio of 1: <dig> alleles . accordingly, we re-pooled the genomic dna library into 6-fish pools such that each 288-fish pool comprised  <dig> 6-fold pools, and amplified ~ <dig> bp fragments centered on the variants identified by ngs-tilling from each of the 6-fold pools from the 288-fish pool in which that mutation was found . hrm of these fragments efficiently identifies the 6-fold pool containing the mutant fish  and a second round of hrm of these six fish identifies the mutant individual, which was confirmed by sanger sequencing and recovered from cryopreserved sperm . we note that mutations that alter base pairing , which account for ~75% of mutations generated by enu, are more easily detected by hrm than mutations that maintain nucleotide valence . in some cases, difficulty of detecting a:t ↔ t:a mutations in 6-fold pools necessitated screening all of the  <dig> fish in a pool individually by hrm.figure  <dig> 
variant validation using high resolution melt analysis. a, b: hrm on 6-fish pools identifies a single pool  with distinct denaturation kinetics. each line represents a single six-fish pool. the x axis is temperature and y axis is the fluorescent difference compared to the wildtype melt curve. c → t mutations  cause a larger temperature shift than t → a mutations . c, d: hrm on single fish of the six-fish pool identified above. each line represents one fish .



discussion
tilling is one of the most widely used reverse genetic approaches to detect single base pair mutations in specific genes of interest in mutagenized or natural genomes  <cit> . the low throughput of the cel1-based tilling strategy  <cit>  has motivated several groups to develop alternative methodologies including direct mutation detection using hrm  <cit> , or massively parallel  sequencing  of specific targets  <cit> . the approach we describe here improves on these by allowing higher throughput and better target coverage at reduced cost and increased efficiency. in our hands, one person can screen  <dig> 250-bp fragments on our library of  <dig>  individuals, from primer design to mutant recovery in  <dig> weeks.

the ngs platform offers the ability to detect rare mutations simultaneously in multiple target genes in a large mutagenized population, ideally, a population large enough to include at least one loss-of-function mutation in every gene in the genome. the first major challenge is in detecting a specific mutation, which is expected to occur only once in the entire population, over a background of mutations introduced during pcr preparation and sequencing of target fragments. ngs is associated with a ~1% error rate  <cit> , which in previous ngs-tilling attempts has limited the size of the pool of individuals under a single barcode to  <dig>  <cit>  and the entire library to  <dig>  <cit>  or  <dig>  <cit>  individuals. by merging the two fully overlapped sequences generated by paired-end sequencing of  <dig> bp amplicons and eliminating any imperfectly aligned reads, we have effectively eliminated sequencing error as a source of noise  in our analysis. this has allowed us to increase the pool size to  <dig> heterozygous fish under a single barcode.

a second source of false positives is mutations introduced during the preparation of target amplicons for sequencing. these pcr-introduced mutations are expected occur at a lower frequency than the enu-induced mutations present in the template . by eliminating from our analysis variants called at a frequency lower than 1/ <dig> we were able to confirm more than 60% of variant calls in our enu-mutagenized library without discarding any genuine enu-induced variants. the remaining false positives are likely to represent variants introduced in the early cycles of target amplicon preparation.

a number of bi-directional and multi-directional pooling strategies have been proposed that allow the unique identification of rare mutant individuals directly by tilling  <cit> . the large number of pools required by these strategies significantly increases the amount of pcr involved in preparing targets and the number of barcodes required, while limiting the total number of alleles that can be screened: in these strategies, over  <dig> barcodes are needed to screen only  <dig> individuals. we reasoned that once a variant has been identified in a single one-dimensional pool by ngs-tilling, that pool can be deconvolved secondarily using a simple allele-specific genotyping method such as hrm. this, combined with our pele analysis that identifies and eliminates errors introduced during sequencing, enabled us to screen a library of over  <dig>  individuals using only  <dig> barcodes. a further efficiency we have introduced is the use of the relatively long sequencing runs available on the miseq platform, which eliminates the need for fragmentation of pcr amplicons, a process that has been shown to introduce uneven sequence coverage of pcr-amplified target sequences  <cit>  .

sensitive detection of very rare mutations is needed not only for tilling but increasingly for other areas of biomedical research where complex mixtures of cells with different genotypes, as in cancer and somatic mosaic disease, are studied  <cit> . to discriminate genuine mutations from variants introduced during pcr or sequencing, a variety efforts have been made from sample processing to data analysis  <cit> . these methods use deep sequencing of the samples tagged with long and redundant barcodes, random barcodes, or endogenous random shear points. while all of them significantly improved signal-to-noise ratio, they do not apply well to tilling because of their high cost, complex of pcr and ligation strategies, and/or their inability to track a mutation back to a specific mutation carrier. our methodology identifies one induced point mutation in more than  <dig>  alleles, and distinguishes it from pre-existing polymorphisms and errors introduced during pcr and sequencing with just  <dig> pairs of commercially available barcodes. the 96-index system currently available from illumina could be used to expand tilling capability to a library of  <dig>  heterozygous individuals. furthermore, the new miseq system v. <dig> generates 40m 300-bp reads, doubling the amount of target sequence that can be screened in a single run. importantly, every aspect of the methodology that we have developed for ngs-tilling of zebrafish can be applied to other organisms for rare mutation detection and recovery.

CONCLUSIONS
tilling is a widely used technique to screen for rare mutations in large populations. in this work, we present a simplified and rapid tilling approach using direct illumina miseq sequencing of  <dig> bp target amplicons, pele data analysis to remove false positive mutant calls and hrm to identify specific mutant carriers within our library. our new ngs-tilling system is able to detect unique point mutations among more than  <dig>  alleles using only  <dig> pairs of barcodes. we detect one strongly deleterious  mutation per  <dig> bp screened in the library, with an acceptable false positive rate of  <dig> %. in principle, our ngs-tilling system can be expanded to detect a unique variant among  <dig>  wildtype alleles and is directly applicable to any organism.

