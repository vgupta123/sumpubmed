BACKGROUND
second-generation technologies are rapidly coming to dominate modern dna and rna sequencing efforts  <cit> . among the available systems, illumina sequencing  is playing an increasingly prominent role. however, the error profiles of high-throughput short read sequencing technologies differ markedly from traditional sanger sequencing  <cit> ; they tend to exhibit a steep, exponential increase in error rates along the read length, and are susceptible to a wider range of chemistry and machine failures . although the quality of second-generation sequencing data affects downstream applications, monitoring and diagnosis of data quality has not kept pace with the rapid rate of improvement seen in other aspects of the technology.

owners of illumina machines have access to on-board diagnostic tools, which give detailed information about data quality for each lane, tile and nucleotide position. however, these tools are not available to most users, the majority of whom now outsource data collection to dedicated sequencing centers. in our experience, these centers do not usually release data quality information, although we advocate strongly that they should. lacking this information, users must turn to publicly available software packages to quantify data quality. the r package tileqc  <cit> , which offers similar functionality to illumina's proprietary software, can help identify some problems at the level of tiles , and in many cases, can even track variation at individual read positions. however, the underlying algorithm relies on errors determined from read mapping, thus requiring a reference genome sequence. tileqc is less useful for the many sequencing projects now being performed on non-model organisms. several other software packages offer similar functionality for assessing data quality  <cit> , but seldom in a quick, automated way that can easily be run by users with limited bioinformatics skills and/or computer resources.

in complementary fashion, software has been written to help correct sequences containing some of these errors, such as image boundary effects  <cit>  - at least for earlier versions of the illumina technology. however, the ever-increasing quantity of data produced by illumina sequencers seldom makes such detailed analysis of individual tiles feasible, or indeed, a cost effective use of expensive  bioinformatics resources. nevertheless, major quality defects, particularly failures of entire tiles or individual nucleotide positions must still be accommodated in downstream analyses . simple tabular and graphical summaries of run quality are therefore a necessary prerequisite for any downstream analysis.

here, we present solexaqa, a user-friendly software package that provides rapid, at-a-glance assessment of read quality for data generated using illumina's sequencing technology.

implementation
programs, manuals and example datasets for the solexaqa package can be downloaded from the project website http://solexaqa.sourceforge.net/.

solexaqa has minimal runtime requirements, but is nevertheless designed primarily for use on the high-performance unix machines that are necessary for analyzing illumina sequence data. solexaqa is primarily written in perl, but integrates graphical capability from the statistics package r  <cit>  and the heatmap visualizer matrix2png  <cit> . by default, the program produces tables summarizing data quality, but r and matrix2png must be installed for proper functioning of the package's graphical features. note that matrix2png also requires a working installation of the gd graphics library http://www.libgd.org/.

solexaqa inputs one  sequence read files in solexa- or illumina-style fastq format, which contains information about base calls as well as associated quality scores  <cit> . we checked whether these quality scores match actual error rates by mapping reads back to a haploid reference sequence that was de novo assembled from the same read dataset. we found that the quality scores returned by the illumina pipeline  are quite accurate, and if anything, slightly conservative.

solexaqa reads in fastq sequence files containing any number of cycles  or tiles , including those produced by early versions of the illumina pipeline, right up to current pipeline version  <dig> . the package also accommodates the virtual tiles employed by the latest revisions to illumina's sequencing technology .

solexaqa calculates a range of summary statistics for a subset of reads drawn randomly from each tile at each nucleotide position; by default,  <dig>  reads  are sampled per cycle and tile, but users can tune this parameter via a command line flag. from our observations, we suggest that summary statistics should be calculated from no fewer than  <dig>  reads per cycle and tile; the accuracy of statistical calculations begins to erode quickly when fewer reads are sampled. solexaqa only calculates mean quality scores by default, but users may also request variances, as well as the minimum and maximum quality scores observed. for convenience, the software returns these summary statistics in tabular form. however, solexaqa also produces graphical displays of mean quality per tile and cycle. this information is presented both as a heat map  and a line graph ; the latter also indicates global mean quality for the entire dataset.

solexaqa also produces a histogram of maximized read lengths  . users can select a quality threshold ; otherwise, the software defaults to p =  <dig>  . this histogram  can be considered one representation of the 'usable' information content of a given dataset. for convenience, an additional program, dynamictrim, has been released as part of the solexaqa package. this software trims each read to its longest contiguous read segment  where quality scores exceed a user-defined threshold, and writes this information to a standard solexa- or illumina-style fastq file  <cit> . a more detailed discussion of the trimming algorithm is provided online at the project website.

finally, we note that sequence quality is often described in terms of log probabilities. for instance, q =  <dig> is the equivalent of p =  <dig>  . this notation is convenient for computational reasons; ascii characters can readily encode log probabilities rounded to integer values . however, although this shortcut is convenient for reducing file sizes, log probabilities are not particularly intuitive. indeed, some summaries of data quality can even be misleading when calculated as log values . for this reason, the tables and graphs produced by solexaqa report actual probabilities of error, not log-based quality scores.

RESULTS
example dataset
using default settings , solexaqa can process a single fastq input file  in under  <dig> minutes with negligible memory demands on a computer with a fairly standard  <dig>  ghz xeon processor. to illustrate the package's capabilities, we consider the first read of a 75-bp paired-end run generated on the genome analyzer ii . this example dataset can be represented by a heat map , and illustrates several different types of errors. firstly, the heat map shows the failure of an entire tile; no reads in tile  <dig>  passed the quality threshold required by illumina's pipeline software. secondly, individual tiles suffered cycle specific failures, as indicated by dark squares in cycles  <dig>   <dig> and  <dig> . these drops in data quality are often due to tile-specific air bubbles, although they can be caused by other factors as well . finally, tiles on this version of the illumina platform are arranged in a u-shape: spatially, tiles  <dig> and  <dig> are located together at one end of the flow cell, tiles  <dig> and  <dig> lie together at the other end, and tiles  <dig> and  <dig> fall together in the middle. the clustered association of darkened horizontal lines around tiles  <dig> and  <dig> indicates that data quality in this particular run eroded near the middle of the flow cell, but improved towards either end. for some applications , one or more of these defects may require manipulation of sequence reads. in some instances, these issues may be sufficiently disruptive to require data collection to be repeated. here, these various data defects are readily apparent after very simple quality analysis using the solexaqa package. the generally poor quality of this particular dataset, which was chosen solely for didactic purposes, is also captured in graphs that show mean data quality per nucleotide position , as well as the distribution of longest contiguous read segments for which base quality scores have an error rate less than 1-in- <dig> . nevertheless, we emphasize that some proportion of good quality data can usually be obtained even from very poor quality runs. dynamic trimming  is one way to extract these high quality reads. finally, we note that we have observed no association between cluster density and read quality within the current standard working range of cluster density.

examples of good and bad datasets can be downloaded from the project website http://solexaqa.sourceforge.net/.

effects of dynamic read trimming
to determine the benefits of dynamic trimming on downstream applications, we briefly explored one such application: the effects of read trimming on de novo assembly. here, miscalled bases will produce k-mers  that do not reflect the true genome sequence. these false k-mers unnecessarily complicate the de bruijn graph, and might be expected to produce poorer assemblies. to test this, we examined a dataset containing the genomes of  <dig> bacterial isolates from two closely related species, campylobacter coli and c. jejuni, which were sequenced as indexed  samples using 50-bp single-end sequencing on an illumina genome analyzer ii. these data were pre-processed with illumina's proprietary pipeline software , which yielded ~ <dig> million reads per genome . individual reads were either trimmed dynamically using dynamictrim or submitted unaltered to velvet   <cit>  for de novo assembly. in both cases, we explored a k-mer parameter sweep of  <dig> to  <dig>  with a fixed coverage cutoff of  <dig>  and expected k-mer coverage inferred from the number of reads used and the expected genome size. de novo assemblies were summarized using n <dig> and the maximum contig size.

mean values of these summary statistics, normalized by the number of reads used in each assembly, are plotted in figure  <dig>  on average, dynamic read trimming produced larger n <dig> and maximum contig sizes. importantly, fewer trimmed reads were used to produce these assemblies, and the genome sequences therefore assembled much more quickly and required fewer computational resources. as expected, the benefits of dynamic trimming are reduced for extremely good datasets - if data quality is high, there is little difference between trimmed and untrimmed datasets.

we have also encountered instances of run- and species-specific assembly effects. in our experience, the same library preparation sequenced on the same machine on different occasions can produce data of quite different quality. we have also noticed that read quality often differs between species, even where sample quality is similar and samples are run - as indexed reads - in exactly the same flow cell lane. we suspect that the specific characteristics of individual genomes, such as g+c content and repeat prevalence, have important effects on sequence data quality. these anecdotes illustrate the idiosyncratic nature of individual datasets and emphasize the need to test a range of assembly algorithms and data manipulations  before settling on a final assembly. generally speaking, however, we found that dynamic trimming of reads produced better de novo assemblies of several campylobacter genomes using the velvet assembler, and we have noted similar improvements in other downstream applications for a range of prokaryotic and eukaryotic datasets. for instance, dynamically trimmed reads appear to improve the signal-to-noise ratio substantially when calling single nucleotide polymorphisms .

CONCLUSIONS
the solexaqa package produces tabular and graphical summaries of data quality for sequence datasets generated with illumina's second-generation sequencing machines. this package aims, firstly, to create standardized diagnostic information to help identify low-quality data rapidly and easily, and secondly, to provide a dynamic trimming function to manipulate sequence data at the level of individual reads. the solexaqa package processes even large files within minutes, and produces trimmed datasets that yield significant improvements in downstream analyses, including snp calling and de novo sequence assembly.

availability and requirements
project name: solexaqa

project home page: http://solexaqa.sourceforge.net/

operating system: platform independent with primary unix support

other requirements: requires perl http://www.perl.org/, r http://www.r-project.org/, matrix2png http://www.bioinformatics.ubc.ca/matrix2png/, and the gd graphics library http://www.libgd.org/.

programming languages: perl and r

license: gnu gpl version  <dig> or later

authors' contributions
mpc and pjb proposed the algorithm. mpc designed the code. mpc and dap implemented the software. mpc, dap and pjb performed the analyses. mpc wrote the paper. all authors have read and approved the final manuscript.

