BACKGROUND
the advent of high-throughput methods and sheer volume of medical publications covering various diseases, mining undiscovered public knowledge  from these resources is a daunting challenge. the concept of upk was introduced by swanson in discovering raynaud disease and fish-oil relation in  <dig>  <cit> . swanson defined upk is public and yet undiscovered in two complementary and non-interactive literature sets of articles , when they are considered together, can reveal useful information of scientific interest not apparent in either of the two sets alone  <cit> .

swanson semi-automatically analyzed scientific articles by using exploratory methods so as to mine for cause-effect relations. he showed that chains of causal implication within the medical literature can lead to hypothesis for cause of rare diseases, some of which may receive scientific supporting evidence.

the underlying discovery method is based on the following principle: some links between two complementary passages of natural language texts can be largely a matter of form “a cause b”  and “b causes c”  . from this, it can be seen that they are linked by b irrespective of the meaning of a, b, or c. however, perhaps nothing at all has been published concerning a possible connection between a and c, even though such link if validated would be of scientific interest. this allowed for the generation of several hypotheses such as “fish's oil can be used for treatment of raynaud's disease”  <cit> .

one major issue with the swanson’s approach is that it requires the labor intensive work of a domain expert in the process of screening out the intermediate concepts   <cit> . to overcome this issue, several approaches  <cit>  have been proposed to automate the swanson’s udk method. even though these approaches have successfully replicated the raynaud disease/fish-oil and migraine/magnesium discovery, it still requires substantial manual intervention to reduce the number of possible connections. in addition, existing approaches do not cover hidden relations resided at the molecular level.

several techniques have been proposed to automate the swanson’s udk model. early studies on the udk model applied advanced information retrieval techniques such as latent semantic indexing  and tf*idf to find candidate intermediate concepts on top of ranking term lists  <cit> . they easily identified high ranking intermediate terms of interest. however, applying the same statistics to the intermediate literatures, the already known  target terms such as fish oil could not be found directly in higher ranks. apart from statistical approaches to the udk model, rigorous attempts were made to integrate external knowledge in ontologies into the discovery process in the udk model  <cit>  <cit> . srinivasan  <cit>  viewed swanson’s method as two dimensions. the first dimension is about identifying relevant concepts for a given concept. the second dimension is about exploring the specific relationships between concepts. however, srinivasan  <cit>  dealt only with the first dimension. the key point of her approach is that mesh terms are grouped into the semantic types of umls to which they belong. however, only a small number  of semantic types are considered since the author believes those semantic types are relevant to b and a concepts. for each semantic type, mesh terms that belong to the semantic type are ranked based on the modified tf*idf. there are some limitations in their method. first, the author used manually-generated semantic types for filtering. second, the author applied the same semantic types to both a and b terms. because the roles of a and b terms for c term are different, different semantic types should be applied.

hristovski, et al.  <cit>  used the mesh  descriptors as features and employed association rule algorithms to find the co-occurrence of the words. their technique first found every intermediate b concepts related to the concept c and then all a concepts related to b concepts were selected by searching pubmed. since each concept can have one or many relationships with other concepts, the size of b→c and a→b combinations can be extremely large. in order to deal with this combinatorial problem, the algorithm incorporates filtering and ordering capabilities. hu et al.  <cit>  utilizes the semantic types and semantic relationships of the biomedical concepts through unified medical language system . their system identifies the relevant concepts collected from medline and generates the novel hypothesis between these concepts. pratt and yetisgen-yildiz  <cit>  used umls concepts instead of mesh terms and limited the search space to the document titles as a starting concept which is similar to swanson’s method to reduce the number of terms . they also reduced the number of terms/concepts by classifying terms into three categories: “too general”, “too closely related to the starting concept”, and “meaningless”. with the qualified and grouped umls concepts, they used the well-known apriori algorithm  <cit>  to find correlations among the concepts. by concept grouping they were able to discover swanson’s migraine-magnesium implicit connection. however, their technique required strong domain knowledge in selecting semantic types for a and b concepts.

atkinson and rivas  <cit>  used nlp techniques, in a similar manner, to extract cause and effect relationships related to diseases from biomedical text and infer new hypothesis from the information extracted. the system used the concept types of “substances”, “symptoms” which represented symptoms of a disease, “diseases” and “body parts”. while the system aims to infer emergent knowledge, it was limited in scope. the system was extracting at the physiological level. humanly created discovery patterns were defined by biomedical experts using the training corpus. and additionally, manual extraction patterns were also used to create a symptom list. validation for information extraction part of the system was not performed and instead, some of the transitive relationships that the system developed were given to human experts for evaluation, thereby representing a weak evaluation of the system. inferring indirect relationships from biomedical text is generally considered challenging however it is also potentially more rewarding. as the literature is so vast that each researcher can only read a small subset, it might be that no person is aware of all the facts that are required to make a logical indirect inference of related facts. these research works have made significant progress on swanson’s method. however, none of the approaches considers the various different biological entities such as body parts, dna, and rna other than disease and cure.

in addition, several studies have identified and extracted biological information from unstructured biological corpus by building on the umls knowledge sources  <cit> . semrep is an outcome of such studies that serves as a general knowledge-based semantic interpreter and a host of tools to extract important knowledge contained within large text corpus.

the goal of this paper is to propose a novel and fully automated approach to mine undiscovered public knowledge from biomedical literature and develop a flexible discovery model that can be applied to various different biological entities.

the contribution of this paper is 1) proposing a flexible knowledge emergence model to extract implicit relationships across different levels such as molecular level for gene and protein and phenomic level for disease and treatment, 2) employing metamap for tagging biological concepts, and 3) providing an empirical and systematic approach to discover novel relationships based on similarity between substances/drugs thereby providing a measure to gauge the newly formed relationships. our mkem model is not only differentiated from but also a sophisticated model than swanson’s upk model as swanson’s method does not perform any similarity measure between substances/drugs. our approach requires presence of multiple extracted relationships containing similar substances before we could aim to produce new hypotheses. in addition, swanson’s method does not provide any measure to gauge the newly formed hypotheses.

we fully automate the discovery process in the udk model based on the semantic knowledge about the medical concepts and their relationships. we also propose similarity measure to prune irrelevant medical concepts and bogus or non-interesting relationships among the medical concepts. our use of an intermediate set of automated identified semantic types helps to manage the sizable branching factor.

methods
in this section, we describe our approach for knowledge emergence. first we give an overview of our system  and describe how it works in steps. second we introduce the sepdb information model defining entities extracted from the biomedical text. the learning process for relation rules is described under the “learning a rule set” section. third we describe the extraction process and the concept of similarity measure.

input: medline abstracts

output: new relationships

step 1: selected sentences are provided to the tagger for concept tagging. these sentences contained the relationship on which our sepdb model is based. about  <dig> sentences were selected by the authors from biomedical texts to use for rule generation, from which  <dig> rules were generated.

step 2: rule sets are generated by the tagger for extraction purposes. step  <dig> and  <dig> is to learn rules. we select candidate sentences that contain terms representing relationships based on the sepdb model. these sentences are then fed to the “tagger” for tagging important concepts. the concepts are based on the sepdb information model of the system. this leads to rule creation where each rule defines a path between different concepts. the user “tags” words of interest in the tagger. this provides an intuitive as well as a faster way of creating rule set.

step 3: medline abstracts are downloaded and given to the sentence selector.

step 4: effect word list is fed into the sentence selector. these words are searched in the new sentence and represent the main connector in our relationships.

step 5: any matched sentence containing the effect keyword is handed over to the relation extractor which performs the extraction process.

step 6: for the sentence containing the effect keyword, the rules related to the keyword are read by the relation extractor.

step 7: the extracted data is given to the information element recognizer for named entity recognition.

step 8: metamap is employed as a ner  engine and tags the information provided.

step 9: after the ner process, a set of biological entities is extracted by the system for further analysis. step  <dig> to step  <dig> is to extract entities and their relation. sentences that contain certain effect words are extracted from medline abstracts. these sentences are then parsed by the link grammar parser. rules that were created by the tagger are applied to extract the relevant information from the sentences. additionally, metamap is used as a ner for identification purpose as well as sorting of the concepts if required. metamap used umls metathesaurus which provides better coverage of the concepts involved as well as uses standard semantic types.

step 10: the extracted information is utilized for the similarity measure.

step 11: the application of similarity measure produces new relationships and it is given as output. step  <dig> and  <dig> is for hypothesis generation. similarity measure is used for formation of new relationships/hypothesis. this similarity measure is used to gauge the similarity between substances, the more similar the substances, the more possible the newly created relationships.

sepdb information model
our information model is termed as sepdb , which stands for substance, effects, processes, disease, body part. each of this is a concept extracted from natural language text. we include low-level processes that a substance may affect or that may occur in a disease or body part. this provides us with a better insight as to function of a drug or a substance and what low-level processes it is affecting. in addition, our system also extracts information that contains processes that occur in a specific body part e.g. a cell.

“effect” node acts as the main node that connects the whole relation. substance node is directly related to the effect node as an effect is an attribute of a substance. such attribute can influence a process or a disease. lastly process or disease can occur in a body part. the effect keywords and their types are given in table  <dig>  these effect words are searched in the sentences for learning or extraction purposes. their types describe the general action taken by the substance. they act as a connector between the substance concept and either the disease or the process concept in the extracted relationships.

learning a rule set
to create a rule set, candidate sentences are selected to represent the relationship identified by our data model. the sentence is fed to the tagger that parses the sentence using link grammar parser and displays the parsed sentence. the relevant concepts such as disease, substances, processes, effects, body parts are then tagged visually.

we can think of a parsed sentence as a graph where words are vertices and links are edges. therefore a rule is the shortest path between an effect word or a keyword and a concept. this connection is stored as a rule. hence, a rule is created by first selecting a word as an effect and traversing the graph to the other tagged concepts.

 the link labels are stored in their reduced form, storing information only about the primary link. directionality information is also stored by using “+” and “-” signs that represents search directions for right and left respectively. intermediate words are termed as nodes and a rule can have any number of nodes. an example provided in figure  <dig> illustrates the aforementioned concept.

the words are stemmed by porter stemming algorithm  <cit>  to solve the problem of inflection. for a rule to be satisfied, the input sentence must contain words and links defined in the rule. in other words, with a sentence being a graph in link grammar, a rule is a route. rule satisfaction occurs when the portion of the parsed sentence, starting from the effect word, contains the links and words defined in the rule and the route completely traversed.

an example of how a rule set is created using the proposed technique is as follow :

1) a sentence is selected and parsed by the link grammar tagger. as illustrated in figure  <dig>  a sentence is entered into the tagger to be parsed, and the user tags the concepts. the system displays the word linkages and the resultant rule set.

2) the user tags the concept of importance and the effect word in the sentence.

3) the program also displays the sentence linkage provided by the link grammar parser.

4) finally, when tagging is complete, a rule set is formed and displayed by the system. it can then be stored in the rule set file.

 as an example , one of the rules generated by the tagger is “s- @ substance”. beginning from the effect word, in this case “induces”, we move towards the left, following the s link. on the left, we find the word “acid”, which is the substance inducing an effect. the system automatically expands the name of entities. hence the system follows such rules to traverse the generated graph to extract the entities of concern.

as shown, a rule may have the following place holders for concepts:

@substance : representing substances, drugs and related concepts.

@symptom: representing symptoms and processes.

@disease: representing diseases.

@bodypart: representing body parts.

effect words do not have a placeholder as they are represented in the rule set. in this manner, using different sentences, a rule book is created and used by the extraction system for information extraction purposes. as is seen in the newly formed rules, directionality information is shown with “+” and “-” signs. the information is extracted from natural language text when these rules are satisfied by the sentences.

extraction
medline abstracts in xml format are fed to the sentence selector. the “sentence selector” extracts sentences from abstracts and for each sentence; the words are stemmed and checked against a list of effect words. if a match occurs, the sentence is passed to the “relation extractor” module and rules related to the effect word matched are applied on the target sentence and relevant information is extracted. after extraction of data, the output is fed to the “information element recognizer” process to the followings: 1) removes any unknown word from the dataset: this reduces false positives. for the words that do not occur in metamap, they are removed.

2) correctly sorts the identified word and allocates it to its correct position as one of the four concepts: it is possible that a disease is incorrectly extracted as being a symptom based on the rule set being used. in order to resolve this incorrect assignment, metamap is used to properly shift the concept into its correct place.

extracted data is mapped onto the sepdb information model, and the relationships conforming to the model are then stored as output. after the data sets have been created, they are then used to infer new knowledge by combining multiple pieces of information using similarity measure.

similarity measure
to discover novel relationships, we propose a semantic similarity measure that calculates resemblance between substances. the assumption for this measure is that if the substances shares similar properties with each other, novel connections exist among related concepts to the substances... the similarity measure is also used to rank the newly formed relationships.

the similarity measure comprises of four units.

• metamap semantic type

• structural similarity

• atomic count

• xlogp

metamap semantic type represents the umls semantic type assigned to the substance. as metamap categorizes the substances into predefined umls semantic types, it assumes that substances under same category may perform similar actions.

structural similarity is calculated using the smsd  system  <cit> . structural similarity plays a very important role in medicinal sciences. substances having highly similar structures are more likely to exhibit the same actions.

atomic count and xlogp values are taken from the chemdb database. atomic count defines the enumeration of constituent atoms of the chemical under consideration. for small molecules like drugs, atomic count is considered valuable for similarity purposes.

in the fields of organic and medicinal chemistry, a partition  coefficient is the ratio of concentrations of a compound in two phases of a mixture of two immiscible solvents at equilibrium . xlogp represents its logarithmic form. hence this describes whether a substance would dissolve more in a water based medium like blood or hydrophobic medium like lipid bilayers of cells. partition coefficients are useful in estimating distribution of drugs within the body. therefore, for similar drugs, their dissolution in hydrophobic or hydrophilic medium should be same or similar. comparative values for the similarity measures are shown in table  <dig>  the sum of these values is used for ranking of newly created relationships.


the similarity measure can have a maximum value of  <dig>  we selected a threshold value of  <dig> for the created hypotheses. therefore relationships having a score greater than or equal to the threshold are considered and all others are dropped. additionally, the score values are also used for sorting the newly formed relationships.

similarity measure working scenario
the following scenario is given to help understanding of how similarity measure is calculated and applied. for two substances, “cordycepin” and “fludarabine”, we check the semantic type assigned by metamap for each substance. “pharmacologic substance” is assigned to both of them by metamap. next we calculate structural similarity of these substances. for that purpose we find out their structural formula or smiles  value available at chemdb database. smiles is a specification for unambiguously describing the structure of chemical molecules. after acquiring the smiles values, we supply the smsd system the values to calculate the structural similarity, which in this case comes out as  <dig> . this denotes the two chemical being structurally very similar.

atomic values and xlogp values can be acquired from the chemdb database. entering either the chemical name or smiles formula gives us the information on the chemical under question, including the atomic values and xlogp. cordycepin has the atomic value c10h13n5o <dig> and fludarabine has c10h12fn5o <dig>  xlogp values are - <dig>  and - <dig>  respectively. lastly, when all of these four values are acquired, we use our comparative values table to calculate the total similarity measure 

with a high similarity value, we can assume that both substances perform similar action and therefore we can make new relationships from combining extracted information containing them.

RESULTS
performance analysis
for the medline abstracts, we searched “cancer” on pubmed database and downloaded  <dig> abstracts in xml format. total  <dig> relationships were extracted from the downloaded dataset statistics of the extracted entities is shown in table  <dig>  as gold standard is not available to evaluate the performance of our system, we conducted the performance analysis of our information extraction module by randomly selecting  <dig> sentences containing relationships and calculated the precision and recall using the formulae given in figure  <dig> 

precision means the proportion of relevant documents from all the results retrieved, recall refers to the proportion of retrieved documents, out of all relevant results available. results of the analysis are shown in table  <dig>  true positives are those relationships that were correctly extracted from the dataset. false positives are incorrectly extracted relationships whereas false negatives are those relationships that were present in the text but were not extracted. we calculated the correct and incorrect relationships. considering the complex relationship structure represented by our sepdb model, the performance of our system looks promising. with 75% in precision, the system extracted correct information with very few false data considered as true. concerning recall, the system was able to extract 56% of the information that was present in the input text.

the experiment of hypothesis generation was carried out for only those substances that exhibited similarity to each other. in total we were able to infer  <dig> hypotheses from the extracted data set. table  <dig> shows selected four examples of extracted data set along with the raw sentences. this represents the extraction of information from sentences. after the extraction process, we apply the similarity measure to create new hypotheses.

pubmed id: 19264955
pubmed id: 19262372
pubmed id: 18070986
pubmed id: 19258429
hypothesis generation example
two relationships taken from the extracted data set are given in table  <dig>  from these extracted relationships, the names of the substances are extracted and similarity measure is calculated as showed in table  <dig> 

the two substances, “wogonin” and “fisetin”, belong to the same metamap semantic type. using smsd, their structural similarity value comes up as  <dig> . from chemdb, their atomic count and xlogp values are very similar. therefore, based on the comparative values, the total similarity score comes up as  <dig> 

as the substances are similar to each other, we proceed to create new relationships. in this case, both processes are identical except for difference in the body part in which these processes occur. therefore we create new relationships with the substance, effect type and process taken from one relationship and the body part taken from the other. the newly created relationships are shown in table  <dig> 

in table  <dig>  the first relationship state that “woginin” can induce “apoptosis” in “hct- <dig> cells”. comparing that with table  <dig>  the original “woginin” relationship had “malignant t cells” as the body part. in essence, with the process “apoptosis” being the same for both drugs, the body parts in which the process occurred were switched and the two new relationships were created.

in our approach, the generation of new hypothesis does not require any human input. the initial relationship information is extracted automatically from biomedical text  and similarity measure calculation  is performed using chemical information from freely available chemical databases. next, the hypothesis generation utilizes this information to form new relationships from biomedical text . application of similarity measure to extracted relationships produced new hypotheses and a sample data set of such relationships is given in table  <dig> 

discussion
given that the main goal of our approach is for automatic hypothesis generation, we attempt to verify validity of the discovered novel connections discovered by searching for such findings published in the scientific literature. as listed below, we have found two scientific articles that support the existence of the novel relationships discovered by our approach.

taking example of the first generated relationship in row  <dig> of table  <dig>  wogonin increases apoptosis in hct- <dig> cells. hct- <dig> cells represent human colon cancer cells. this newly formed relationship is supported by the research article by dae-hee lee et al.  <cit> .

row  <dig> states that genistein can induce apoptosis in hct- <dig> cells. by searching pudmed, we came across a research article by mao li et. al.  <cit>  in this article, they state that genistein has chemopreventive effects in several human malignancies, including colon cancer and induces apoptosis in a variety of human cancer cell lines. for the rest of discovered relationships, literature search did not find any relevant research articles. it may be a good research topic to investigate whether there exists such a novel connection among them.

CONCLUSIONS
we proposed a new system that extracts relationships from biomedical text and infers new information. this system can be used for knowledge emergence tasks as it combines information from multiple disjoint sets of information  and provides novel hypotheses that may either be correct or would lead to a promising research direction. the system was applied on sepdb-driven relationships and we achieved good extraction accuracy from natural language text. in addition, using the similarity measure concept, we were also able to infer new relationships, showing that our system is able to perform its task well.

there are multiple options for further improvements. first, we plan to replace metamap with machine learning techniques for named entity recognition. this should improve the results as more entities such as drugs and processes are recognized by the system. second, we will extract anaphoric relationships that exist within a sentence to increase the performance. in addition, we are improving link grammar lexicon to reduce incomplete or incorrect word linkage considerably and in consequence providing better parsing results. last, we plan to carry out rule generalization to reduce the rule sets and provide better coverage of extracting possible relationship from the text.

competing interests
the authors have no competing interests to this research.

authors' contributions
azi developed the system for information extraction and hypothesis generation and drafted the manuscript along with ms. ms also critically revised the manuscript for important intellectual content. dl supervised the work and gave final approval of the version of the manuscript to be submitted.

