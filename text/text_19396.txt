BACKGROUND
a heterogeneously and differentially expressed gene  is a gene which has an inconsistent expression pattern across its experimental samples. typically, a large proportion of the experimental samples and the control samples form a tight cluster in low expressions. the remaining small proportion of experimental samples, namely the outliers, are observed to significantly deviate from the tight cluster towards high expressions. we use the word ‘tight’ to describe the cluster of null  expressions of a hdeg as the null variance is typically small compared to the null-outlier distance. in situations where the few highly expressed outliers of a non-differential gene are caused by measurement error, it is also useful to distinguish such genes with hdeg characteristics. the existence of hdegs has been established in various experiments . suppose we have the expressions of m genes. the standard t statistic under-estimates the significance in testing the difference across the control and experimental samples of a hdeg. copa 
 <cit>  proposed modifying the student t statistic to be a ratio of the distance between the rth  percentile of experimental samples and the median of all samples over the median absolute distance , i.e., 

  ticopa=qr−λiσii= <dig> …,m 

where
σi= <dig> ×med, xi and yi represent control samples and experimental samples of the ith gene respectively, qr is the rth percentile of yi and λi is the median of both xi and yi. the quantile-median difference in  summarises the null-outlier distance using a single value of yi. to make outlier detection more efficient, the outlier-sum  statistic
 <cit>  sums over outliers,
tios=∑jσi− <dig> where the outliers are defined as
{y∈yi:y>q75+iqr}. outlier robust t statistic  uses the same statistic but defines the outliers in relation to the control samples only
{y∈yi:y>q75+iqr} <cit> . maximum ordered subset t statistic  defines the outliers to be the top k experimental samples and chooses k by optimising a normalised t statistic
 <cit> . the least sum of ordered subset square t statistic 
 <cit>  also compares the controls with a subset of the top k experimental samples,
tilsoss=k−x¯i)si− <dig> where
x¯i is the mean of control samples,
y¯i is the mean of top k experimental samples and si is the pooled standard deviation of the set of control samples plus non-outlier experimental samples and the set of outlier experimental samples. k is optimised iteratively to minimise the within-cluster variance. we propose a new algorithm for detecting hdegs with a small number of outliers by detecting outliers via gap  maximisation. what makes this approach different from the existing methods is that we assess each potential outlier in relation to a tight cluster of non-outliers. this avoids modelling the highly expressed outliers explicitly. this is especially important when the number of outliers is small. the proposed algorithm classifies each gene as a hdeg or non-hdeg by locating potential outliers and summarises it using the average of the standardised outlier expressions. we will use simulated examples and a breast cancer dataset to illustrate the effectiveness of the proposed algorithm in detecting hdegs with few outliers. we will also show how effective test algorithms are when varying conditions.

RESULTS
simulated examples
scenario  <dig> - identification of a single hdeg
the algorithms are compared for the detection of a single hdeg with the number of outliers varied from one to nine. the results are summarised in table
 <dig>  for a small number of outliers, copa, most and lsoss demonstrated relatively poor performances while dog consistently gave significant p-values.

scenario 1: average p-values for the simulated hdeg with variable outlier number from one to nine. m is the average number of outliers detected using dog.

scenario  <dig> - identification of multiple hdegs 
over a critical p-value range from  <dig> to  <dig> , dog demonstrated the highest average cumulative matthews correlation coefficient  across five sets of simulations with one to five outliers - figure
 <dig>  table
 <dig> shows that dog had very high classification rates compared with the other five algorithms. when the number of outliers exceeded two, os, ort and lsoss gave more reasonable classification rates. copa and most gave poor predictions overall.

scenario 2: total classification rates for the six algorithms in five simulations with  <dig> non-hdegs and  <dig> hdegs.

 figure
 <dig> shows the roc curves for the one-outlier simulations, it can be seen that dog had a superior roc curve with an partial auc value of  <dig>  figure
 <dig> illustrates the same roc curves oover the complete range of false positive rate, copa and lsoss remained poor. we also found that as the number of outliers increased to five, most algorithms worked well with the exception of copa. 

further simulated examples
we look at the sensitivitiy of dog with respect to changes in certain assumptions and parameters.

variable marginal null-outlier distance
we revisit the single-hdeg simulation but vary the marginal null-outlier distance  from  <dig>  to  <dig> with increments of  <dig>  - table
 <dig>  dog’s p-values increased for a reduced marginal null-outlier distance but retained the most significant mean p-values for larger marginal null-outlier distances. most and lsoss failed to detect the hdeg. dog gave accurate estimates of the outlier number when the null-outlier distance was greater than one.

average p-values for single-hdeg simulations with two outliers and a varying distance, δ, between non-outliers and outliers. m is the average number of outliers detected using dog.

non-gaussian tight cluster
we simulated a gaussian-mixture tight cluster + <dig> n) to examine how dog is affected by non-gaussianity in the tight cluster. all other parameters were kept the same as those used in the single-hdeg simulation. the results were very similar to those seen previously - table
 <dig>  in particular, the performances of copa, os and ort have improved for the simulated non-gaussian tight cluster.

average p-values for the simulated hdeg with variable numbers of outliers for a mixture gaussian + <dig> n) distributed tight cluster. m is the average number of outliers detected using dog.

control samples containing outliers
dog can be modified to enable the detection of hdegs when control samples contain outliers . the rankings of the genes were based on the order of the test statistics. the defining feature of dog’s top four hdegs, pex <dig>  tfp <dig>  ugt2b <dig> and slc4a <dig> , is that they contain a few highly expressed outliers. figure
 <dig> shows the top  <dig> predictions of hdegs using dog for this data set. existing literature have established these genes to be of biological relevance to the progression and treatment of breast cancer .

 most other algorithms chose genes with a reasonably large pool of differentially expressed experimental samples expressed at a more moderate level. lsoss also generally favoured ordinary degs. most chose a set of top four genes with only one or two moderately expressed outliers. table
 <dig> shows how the top  <dig> predictions of these algorithms overlap - copa and os are most similar in their rankings whilst dog has a maximum of 15% overlap with os. using the ordered log <dig> expressions of each algorithm’s unique top  <dig> genes, figure
 <dig> illustrates the median expressions minus the minimum expressions for each experimental sample index. the unique top  <dig> genes for dog and copa showed the largest change across their experimental samples, their difference being that copa favoured hdegs with a larger number of outliers whilst dog picked out hdegs with small numbers of outliers. 

using the significance analysis approach discussed in ‘’significance analysis for real data of methods, we estimated p values from sampling the replicates which then give us alternative p values based rankings of the genes. we also found the top four predictions ranked using the p values of dog to be near identical to those ranked using its t statistics, though there were discrepancies in rankings for the lower ranking genes. similar results were observed for the remainingfive algorithms.

CONCLUSIONS
the difficulty in identifying hdegs arises from the fact that only a small number of experimental samples are highly expressed at a much higher level than the non-outliers. as a result, various modified t tests target the subset of potential outliers which are then tested against the control group. in practice, for hdegs with very few outliers, we found that these algorithms often identify hdegs with insignificant deviations between the outliers and the tight cluster of non-outliers. based on this observation, the proposed algorithm assesses each potential outlier in relation to the gaussian tight cluster without making an explicit assumption about the outlier distribution. at each step, we update the posterior mean and variance of the tight cluster which are then used to evaluate the probability of an outlier being a random sample of the tight cluster. examples of simulated and breast cancer data sets verify the suitability of the proposed algorithm in identifying hdegs with small numbers of outliers. an extension of the algorithm which fully takes into account gene correlations will be presented in future work. for the breast cancer data, we found negligible correlations across the top ranking genes and very low correlations among the less significant genes.

breast cancer data: the overlap  between top  <dig> predictions of the six algorithms.

