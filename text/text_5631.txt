BACKGROUND
the development of high-throughput sequencing technologies has revolutionized the field of microbial ecology by offering a cost-efficient method to assess microbial diversity at an unseen depth. initial ecological applications mainly relied on the usage of the  <dig> pyrosequencing platforms, resulting in an impressive repository of bioinformatics analysis tools for processing this kind of data, as used for example in 16s rrna gene amplicon sequencing data. linking different tools developed for the preprocessing of amplicon sequencing data has resulted in frequently used analysis pipelines such as mothur  <cit> , qiime  <cit>  and uparse  <cit> .

due to the recent advances in other high-throughput sequencing technologies regarding throughput and read length, and the announcement of roche to shut down its  <dig> services by  <dig>  sequencing platforms provided for example by pacific biosciences and illumina gain importance for assessing microbial diversity using amplicon sequencing. however, analysis pipelines developed for  <dig> pyrosequencing data cannot be translated into an illumina miseq specific pipeline in a straightforward way due to fundamental differences between both sequencing technologies.

indeed, the  <dig> pyrosequencing technology has difficulties in predicting the exact length of homopolymers, as such mainly leading to indel errors  <cit> . illumina sequencing data do not suffer from indel errors to the same extent, but rather from nucleotide substitutions , mainly originating from two effects: 1) high correlation of the intensities of a and c as well as g and t due to similar emission spectra of the fluorophores , and 2) dependency of the signal of each cycle on the signal before and after this cycle, caused by inadequate flushing of fluorophores, incomplete removal of the 3’ terminators, or integration of nucleotides without effective 3’ terminators  <cit> , known as phasing and pre-phasing. additionally, it has been shown that such substitutions are often linked to the presence of the ggc motif, or more in general, to the gc-richness of the amplified region .

different approaches have been developed for reducing sequencing errors originating from the illumina miseq sequencing platform. these approaches can be categorized into three types: 1) denoising tools which actively resolve sequencing errors, 2) paired-end assemblers that merge overlapping reads into one contig represented by a consensus sequence , and 3) quality filtering approaches which remove poor-quality reads or regions.

a large number of denoising algorithms has already been developed for  <dig> pyrosequencing reads, for example denoiser  <cit> , ampliconnoise  <cit> , slp  <cit> , acacia  <cit>  and node  <cit> . however, due to fundamental differences in the nature of both sequencing technologies, denoising algorithms developed for  <dig> pyrosequencing data are likely to perform suboptimal when applied to illumina sequencing data in a naive way. at this moment, a few algorithms for denoising illumina miseq paired-end amplicon sequencing data have been developed. one of the  <dig> pyrosequencing denoising algorithms, i.e. slp  <cit>   and the more recently released algorithm called unoise  <cit> , have been shown to be applicable to illumina miseq specific analysis pipelines  <cit> .

however, next to denoising tools, a plethora of tools has been developed for assembling paired-end reads into one amplicon contig, by merging both the forward and reverse reads into one consensus sequence. apart from the assembly tools integrated in the amplicon sequencing pipelines like mothur, qiime and usearch, other more general paired-end assembly algorithms have been developed such as flash  <cit>  pandaseq  <cit> , cope  <cit>  and pear  <cit> . additionally, several quality filtering approaches were implemented to identify and remove or trim reads with poor quality, according to specific criteria defined within each tool, as implemented in mothur, qiime and usearch. despite the fact that paired-end assemblers and quality filtering approaches cannot be seen as genuine denoising tools, they will have an effect on the error rate, and should be included in a benchmark when assessing denoising tools.

in this work we propose the illumina paired-end denoiser  algorithm, an error correction algorithm specifically developed for denoising illumina miseq 16s rrna gene amplicon sequencing data. our machine learning methodology was benchmarked using four different mock datasets, each of them containing sequencing data of different hypervariable regions in the 16s rrna gene, including completely as well as partially overlapping paired-end reads. working with mock communities consisting of a known set of species had the major benefit that we can use the error rates as most prominent evaluation criterion. since the amount of data produced within one sequencing run is steadily increasing for the illumina miseq technology, we evaluated the additional computational cost associated with our algorithm.

methods
mock communities
four publicly available illumina miseq sequencing datasets of mock communities were used within this work. the first mock community – called mock <dig> – is composed of  <dig> species added in equimolar concentrations   <cit> . the second mock community, termed mock <dig>  has almost the same composition as mock <dig>  however omitting one species, resulting in  <dig> different organisms  <cit> . the dna of the mock communities can be obtained from bei resources . both illumina miseq libraries were prepared using primers as described in the work of kozich et al.  <cit>  for the amplification of the v <dig>  v <dig> and v <dig> hyper-variable regions of the 16s rrna gene for mock <dig>  and in the work of nelson et al.  <cit>  for the amplification of the v <dig> and v <dig> region for mock <dig>  both mock communities were sequenced on the illumina miseq platform using the 2 × 250 bp paired-end protocol. merging both reads into one contig resulted in different contig lengths for each primer pair: contigs resulting from the v <dig> primer pairs in mock <dig> and mock <dig> resulted in a length of 251–253 bp , v <dig> contigs in mock <dig> and mock <dig> in lengths of 375 nt and 390 nt respectively  and v <dig> contigs in mock <dig> in a length of 430 nt . in mock <dig>  four sequencing runs were performed with various cluster densities . in mock <dig>  samples for each region  were run in duplicate .

the third mock community – called mock <dig> – consists of three samples , each consisting of  <dig> species . the mock <dig> community was sequenced on the illumina miseq platform using the 2 × 300 bp paired-end protocol. merging both reads into one contig resulted in a length of 422–428 bp after clipping the primers . table  <dig> provides a detailed description of the mock <dig>  mock <dig> and mock <dig> sequencing datasets.table  <dig> overview of the mock sequencing data discussed in this work. it contains information on the amplified regions, samples id’s, number of paired-end reads , average contig length , and average length of the overlapping part between both paired-end reads



the fourth mock community - called mock <dig> - consists of  <dig> samples and was recently published in schirmer et al.  <cit> . their microbial composition ranges from a single species to diverse mock communities , mixed either in even or uneven concentrations. five different illumina miseq library preparation methods were used to amplify the v <dig> and the v <dig> region. contigs constructed by merging both reads resulted in two different lengths, ranging from  <dig> nucleotides  to  <dig> nucleotides . a detailed description of mock <dig> and the sequencing protocols used can be found in the original publication  <cit> .

pre-processing steps
for all datasets  contigs were created by merging the paired-end reads using a heuristic based on the difference in phred quality scores of both reads as implemented via the make.contigs command in mothur  <cit> . contigs were culled if they had an ambiguous base or if they were not properly merged. all sequencing data were trimmed, aligned, screened, filtered and dereplicated using the mothur software package , thereby following the sop as described on the mothur website . afterwards, reads were denoised  and chimeras were identified using the “seq.error” command in mothur  <cit>  using the full length 16s rrna genes of the mock community species as reference. this “seq.error” command was also used to identify sequencing errors. to assess the performance of our newly introduced algorithm, iped was benchmarked against the pre-cluster and unoise algorithms, both using the recommended parameter settings as proposed by the initial developers .

despite the fact that paired-end assembly algorithms cannot be considered as denoising algorithms in the strict sense, their potential influence on the error rate required a comparison with the error rates obtained using iped. therefore, different paired-end assembly algorithms used for amplicon sequencing were tested on the mock <dig>  mock <dig> and mock <dig> datasets. algorithms included are the standalone tool pear as well as the assembly steps as included in mothur, qiime and usearch, together with their proposed quality filtering. an overview of the commands used for those tools is given in additional file 1: section  <dig> 

for mock <dig>  mock <dig> and mock <dig> the sequencing reads were clustered in operational taxonomic units  using the mothur recommended clustering approach  as well as uparse  <cit>  with default parameters, with the exception of singleton removal. the default setting of singleton removal was deactivated to accurately assess the effect of sequencing errors on all the otus produced, including singletons. the exact commands are given in additional file 1: section  <dig> 

training data
an important component of the iped algorithm is the machine learning method developed to predict potentially erroneous positions. a dedicated dataset for training and testing this machine learning method was created by randomly selecting reads from sample  <dig> of mock <dig> , resulting in a dataset of  <dig>  reads. important to notice is that all three samples used to construct the training data were completely disregarded in the subsequent benchmarking analysis. each nucleotide in those reads was evaluated as being either erroneous  or correct, identified as such by aligning those reads against the reference genomes. in order to obtain highly reliable training instances, the same parameter setting was applied as used in gilles et al  <cit>  for running blast  <cit>  and subsequently clustalw  <cit> . this led to a dataset consisting of  <dig> , <dig> instances . these data were cleaned as follows: dereplication, randomization and simplification via selecting a subset of the features . next, the data were split into three subsets, thereby respecting the initial ratio between erroneous versus non-erroneous instances throughout the three subsets:  a learning data set for training the classifier,  a validation set for selecting the most optimal kernel and  a test data set for testing the accuracy of the classifier. subset  and  were further modified by adjusting the ratio between erroneous and non-erroneous instances: for subset , several ratios between erroneous and non-erroneous instances were applied to select the one resulting in the best performance when training the classifier, while for subset  we used an equal ratio between both classes. extra information on the feature-selection step and selecting the correct ratio in subset  is given in section  <dig> of additional file  <dig>  all machine learning methods for training and testing iped were used as implemented in the weka software version  <dig> . <dig>  <cit> .

evaluation parameters
for the evaluation of iped, we calculated the number of true positives , false negatives , true negatives  and false positives  as follows: if an erroneous nucleotide was correctly detected as such, it is a tp, if it was not it is a fn, if an non-erroneous nucleotide was correctly detected as such it is a tn, if not it is a fp. we used the mathews correlation coefficient   <cit> : /√), sensitivity ), specificity ), and receiver operating characteristics . the latter analysis combines both sensitivity and specificity by plotting the sensitivity  against one minus the specificity ). roc curves were produced by swiping the threshold cut-off of the probability estimated by each classifier, and plotting the sensitivity versus one minus the specificity value.

RESULTS
our newly developed algorithm for denoising illumina miseq amplicon sequencing data was developed in two steps. first an artificial intelligence classifier was trained to detect potentially erroneous positions in the sequencing reads. secondly, a modified version of the previously published algorithm   <cit>  , was adapted in such a way that it does not penalize those potentially erroneous positions during clustering. the development of both the classifier and clustering component of the iped algorithm is discussed in the first part of this results section. once the setup and training of iped has been finalized, the algorithm was tested on a wide range of datasets against pre-cluster and unoise, and this at the level of error rate, computational cost and the accuracy of the otu clustering.

iped development
iped classifier
the performance of the iped algorithm is largely depending on the ability of its classifier component to correctly identify erroneous positions. the machine learning approach followed to develop this classifier is based on supervised learning, where we trained the classifier to identify such positions by training it on a dedicated data set . training of the iped classifier consisted of four consecutive stages: 1) identify those parameters that are potential predictors of sequencing errors , 2) select the most informative parameters , 3) train the classifier to identify sequencing errors based on those parameters , and 4) check whether the classifier correctly predicts sequencing errors on unseen sequencing data .

the first stage consisted of extracting a list of features potentially predicting erroneous positions. different sequencing characteristics have been taken into consideration such as the position in the read, the homopolymer status and phred quality score, the presence of the ggc motif in front of the position in question, the homopolymer status  and the phred quality score of the preceding and succeeding position for both the forward and reverse reads, totaling up to  <dig> features. an additional feature was added indicating whether the nucleotide was situated in the overlapping region of both paired-end reads, and if so to indicate whether they have no conflict, a conflicting base call , or unknown overlap .

importantly, integrating too many uninformative features would have led to an inflation of the computational cost. accordingly, reducing the total number of available features  while retaining the predictive power of our algorithm has a beneficial effect on the performance of the classifier as it increases its accuracy and reduces the computational cost. therefore, in a second stage, a feature-selection step was applied using a three-fold cross-validation on the training data. this approach allowed us to identify those features having a high predictive power for recognizing erroneous positions , while having a low correlation with other predictive features. performing this step resulted in a subset of six features i.e. for the forward read: the position in the read, homopolymer status and phred quality score; for the reverse read: the position in the read and phred quality score; and as last feature the overlap status between the forward and reverse read. important to notice within this context is the absence of the ggc motif after the feature selection step. however, this might not be surprising as we could clearly see a drop in the phred quality score in the positions succeeding this motif . as the phred quality score was retained after applying the feature-selection step, the ggc motif was removed from the features list. this could be explained either by the weak evidence of error incidences related to the presence of the ggc motif  <cit>  or due to the high correlation between this motif and the phred quality score, making this feature superfluous.

in the third stage, these six features were used to train a wide range of classifiers available in weka based on subset  of the training data. the goal of this step was to select the type of classifier that obtains the highest accuracy in predicting erroneous positions. in order to optimize the balance between specificity and sensitivity, a range of ratios balancing the number of erroneous versus non-erroneous instances was tested. the highest sensitivity while maintaining an acceptable specificity was obtained using a ratio of 1: <dig>  . the training process was further evaluated by plotting the learning curves for each of the classifiers, which confirmed that a training dataset size consisting of  <dig>  erroneous and  <dig>  non-erroneous instances  gave the best performance . subset  of the training data was used to evaluate each of the individual classifiers using sensitivity, specificity, mcc measurements and roc analysis as performance parameters. additional analyses tested the performance obtained when different sets of classifiers  were combined using plurality voting. in a plurality voting approach, each of the considered classifiers outputs a confidence score for the classification made and the class with the highest confidence is selected as output for the respective instance. comparing the performance of the individual classifiers as well as the different voting combinations , the best performance was achieved via plurality voting combining multilayer perceptron  and random forest . this combination achieved a sensitivity of  <dig> , specificity of  <dig> , mcc of  <dig>  and roc area under the curve  of  <dig>  on subset  of the training data, thereby outcompeting the other machine learning approaches. the additional computational burden resulting from this plurality voting approach was minimal, as the best performing single classifier  required  <dig>  sec compared to  <dig>  sec for the plurality voting approach   of the training data, containing around  <dig>  instances).

iped clustering
as mentioned above, the first step in the development of iped consisted of training a classifier able to predict potentially erroneous positions with high accuracy. in the second step a modified version of the slp algorithm  <cit>  as implemented via the pre-cluster command in mothur  <cit>  has been developed  <cit> . in the original pre-cluster implementation, sequences are sorted based on their abundance level in descending order. when a rare sequence is at maximum 1 nt per 100 nt differing from a more abundant one, it is merged with the more abundant one and its abundance is added to the latter one. in the first step of iped, the classifier has marked some of the positions as potentially erroneous. we have developed a modified version of the mothur pre-cluster algorithm that will not penalize those marked positions when calculating the amount of conflicting positions between two reads. this means that any position in the alignment containing a nucleotide which is marked as potentially erroneous, will not increase the distance score . after the clustering step, those masked positions are reverted to their original nucleotide as they were before running iped. a schematic representation of this approach is given in fig.  <dig>  the iped software can be downloaded via https://github.com/m-mysara/iped or http://science.sckcen.be/en/institutes/ehs/mcb/mic/bioinformatics/.fig.  <dig> schematic overview showing the different steps of the iped algorithm



benchmarking of iped
impact of denoising algorithms on the error rate
once the development of the iped algorithm has been finalized, its performance was compared with those of the pre-cluster and unoise algorithms. both those tools are the only denoising algorithms currently applicable for illumina amplicon sequencing data. using the reference 16s rrna gene sequences from the organisms present in the mock <dig>  mock <dig> and mock <dig> communities, we calculated the error rates before applying the denoising algorithms, which were subsequently compared with the error rates obtained after applying iped, pre-cluster and unoise on all three mock datasets. the error rate was calculated using the seq.error command by taking the ratio of the number of deletions, insertions and substitutions over the total number of bases.

the average error rate before denoising  was  <dig>  and  <dig>  for v <dig> ,  <dig>  and  <dig>  for v <dig>   <dig>  and  <dig>  for v <dig> . the fact that the error rate of v <dig> was up to an order of magnitude lower than both other regions is not surprising since the v <dig> amplicon fragment consists of two completely overlapping reads, as such assuring a two-fold prediction for each nucleotide.

when comparing the output of iped with the raw error rates, our algorithm was able to reduce on average the error rate with 72 % . when benchmarking those results with unoise and pre-cluster, unoise was able to reduce the error rate on average by 52 %  while pre-cluster was able to reduce it by 51 %  . on average , iped diminished the error rate to  <dig> , while unoise and pre-cluster reduced the overall error rate to the same value of  <dig>  . however, compared to other denoising algorithms, the effect of iped is more pronounced for those regions with no complete overlap between both paired-end reads . importantly, it should be noted that unoise  results in an additional loss of on average 13 % of sequencing data due to its more stringent pre-processing steps, as illustrated in supplementary file  <dig> section  <dig> table  <dig> overview table comparing error rates of the samples treated with unoise  and those without applying a denoising algorithm, after applying pre-cluster or after applying iped . due to the difference preprocessing steps applied in usearch and mothur, the amount of reads removed differ, where around 53 % and 39 % of reads are removed in respective order



the same trend in lowering the error rate was observed when running iped on the mock <dig> dataset. indeed, when both reads are almost completely overlapping , iped was able to reduce the error rate from  <dig>  to  <dig> . this effect was more prominent when dealing with contigs with a smaller overlap between both paired-end reads , showing a decrease in the error rate from  <dig>  to  <dig>  . however, important to mention within this context is the elevated error rate of this data set, which is significantly higher than should be expected for illumina miseq sequencing data. as such, caution should be given when extrapolating those results.

plotting the error rates for the mock <dig> and mock <dig> datasets versus their position in the amplicon, indicated that the beneficial effect of iped is mainly situated in the uniquely covered region of the second read , and to a lesser extent also the overlapping part  .fig.  <dig> plot showing the error rate versus the position in the read after being treated with pre-cluster , unoise  and iped . the raw error rates  are colored black




as stated in the introduction, a plethora of algorithms is available for assembling paired-end reads into one amplicon fragment. even though those algorithms are not denoising algorithms in the strict sense, they can have an impact on the error rate of the resulting fragment. for this comparison, error rates were calculated for mock <dig>  mock <dig> and mock <dig> after running different assembly algorithms, being fastq_mergepairs , make.contigs , join_paired_ends  and pear, which resulted in error rates of  <dig> ,  <dig> ,  <dig>  and  <dig>  respectively . important to notice is that the number of reads retained is correlated with the error rate: pear returned the highest error rate, however it managed to retain 86 % of the reads, while usearch reached the lowest error rate but removed more than 53 % of the data. anyhow, it is clear from those data that the error rates obtained using those assembly algorithms did not come close to the error rates obtained with iped  i.e.  <dig> . similar effects were obtained by including iped after the qiime assembly step, leading to an error rate of  <dig> , which was also significantly lower than the error rate obtained with the assembly steps solely . those data suggest that whatever currently available assembly algorithm is used, running iped afterwards will still have a beneficial effect on the error rate.

to investigate the extra computational cost related to iped, the calculation time was registered for all three samples of the mock <dig> dataset covering the v <dig> region, where each sample was subsampled to  <dig> unique reads. when one processor  was used for each sample , iped required 70 s for running all three samples, while pre-cluster and unoise could end the analysis in 14 s and 12 s respectively. similar relative differences in calculation time were also observed for other mock <dig>  mock <dig> and mock <dig> samples .

impact of denoising algorithms on the otu clustering
as the negative effect of sequencing errors has an influence on the amount of spurious otus, ideally an improvement at the level of denoising step should be reflected in a decrease of the number of otus. although the otu clustering step is influenced by the number of reads and level of complexity in the mock samples,  <cit> , it has been used by others as a metric for sequence quality . in order to get an idea to which extent iped, unoise and pre-cluster have a beneficial effect on the otu clustering step, sequencing data denoised by either one of the three approaches were clustered using the average neighborhood hierarchical clustering algorithm via the “cluster” command , and subsequently compared with the number of otus obtained when no denoising algorithm was applied. as the amount of species present in both mock communities is known, in the most ideal scenario the amount of otus returned should be  <dig>   <dig> and  <dig> for mock <dig>  mock <dig> and mock <dig> respectively. it is important to emphasize that any undetected chimera or possible contamination would lead to an inflation of the number of the otus. however, as their effect is the same for all tools, we assume that the number of otus still provides a good indication of the performance.

the average number of otus produced when the denoising step was omitted returned on average  <dig>   <dig> and  <dig> otus for the v <dig>  v <dig> and v <dig> regions respectively . iped was able to reduce these numbers to an average of  <dig>   <dig> and  <dig> while pre-cluster resulted in  <dig>   <dig> and  <dig> otus respectively and unoise resulted in  <dig>   <dig> and  <dig> otus respectively. again, it is important to highlight the impact of the strict pre-processing approach followed by unoise, resulting in a removal of almost all of the reads in mock <dig> v <dig> samples in this pipeline, and therefore returning a very low number of otus for the unoise approach. similarly, for mock <dig>  the number of otus for the non-denoised data was  <dig>  while integrating iped, unoise or pre-cluster in the preprocessing pipelines led to  <dig>   <dig> and  <dig> otus respectively. altogether, this analysis showed a more beneficial effect of iped on the otu clustering step than pre-cluster and unoise . concerning the number of otus for the v <dig> region of mock <dig>  it was not possible to calculate the number of otus due to high memory requirements, leading to the exclusion of these data sets from the otu analysis.

it should be noted that all mock samples analysed in this work contain a high number of reads per sample , which is significantly higher than the number of sequences obtained for most real-life microbial diversity studies. in order to work with more realistic numbers, we rarified the datasets to  <dig>  – as proposed in kozich et al.  <cit>  – and  <dig>  reads per sample. again, iped outperformed unoise and pre-cluster when applied on the rarefied mock <dig>  mock <dig> and mock <dig> samples . moreover, similar results were obtained upon using the uparse clustering algorithm on both complete and rarefied datasets .

however, the analysis performed above starts from an ideal situation, since all chimeras can accurately be removed using the reference sequences from the species present within the mock community. additionally, the species present in the mock communities are well-known species, incorporated in the reference alignment database, as such resulting in an accurate alignment. to get an idea on the effect of the different denoising tools in case of a more realistic scenario, i.e. using a regular chimera removal algorithm and the presence of species not represented in the reference alignment database, we applied a regular chimera detection tool   <cit>  on the mock <dig> dataset in order to remove chimeric sequences from the mock community. additionally we removed the corresponding sequences of the species represented in the mock community from the 16s rrna reference alignment database, together with any other sequence showing a similarity higher than 97 % to any of those twelve species. as reported in section  <dig> of the additional file  <dig>  iped was able to outperform pre-cluster and unoise with a reduction of the error rate in the same range as reported earlier, and additionally led to the lowest number of otus.

in order to check the effect of the denoising algorithm on the otu clustering quality, sequencing data were analysed using a preprocessing pipeline where the only varying factor was the denoising algorithm . this way we could assess whether the anticipated species of the mock community could be retrieved. applying pre-cluster and unoise led to less accurate clustering results as reads originating from the same species where more frequently scattered over different otus. in general we can conclude that applying iped has a beneficial effect on the otu clustering step when compared with the pre-cluster and unoise results, since for all mock samples the number of otus produced with iped was the closest to the actual number of species. details on the number of otus are given in section  <dig> of the additional file  <dig> 

as a proof of principle, iped was applied on a real data set  to emphasize the effect on a more complex dataset. however, it is important to stress that unfortunately for those real-life datasets no error rates could be calculated, forcing us to revert to the number of otus as evaluation criterion. despite the fact that this criterion is inferior to the error rate, it has been used in previous publications  <cit> . in this data set, presented in kozich et al.  <cit> , murine fecal samples of mice were used to assess the shifts of the microbial community after weaning at two different stages: early  versus late  after weaning. iped was able to reduce the number of spurious otus, as illustrated by the rarefaction curves, and produced a more clear separation of clusters of late versus early stage samples when visualized in principle coordinate analysis  biplots .

discussion
new sequencing technologies have revolutionized the assessment of microbial diversity via amplicon sequencing. however, each of the currently available high-throughput sequencing platforms suffers from sequencing errors originating from the sequencing technology itself . in order to prevent the inflation of artificial otus due to these sequencing errors, different algorithms have already been developed for the correction of sequencing errors in  <dig> pyrosequencing data, for example slp  <cit> , ampliconnoise  <cit>  and denoiser  <cit> . however, assessment of bacterial diversity using the illumina miseq technology is now the standard, as it offers high throughput in combination with an acceptable read length. recently, the slp-based algorithm pre-cluster  and unoise  have been proposed as denoising tools in illumina miseq specific pipelines  <cit> . in this work, we introduced iped as the best denoising tool specifically oriented towards illumina miseq 16s rrna paired-end reads.

iped was shown to outperform pre-cluster and unoise, as observed on the three mock datasets where our newly introduced algorithm could on average correct double the amount of sequencing errors. this effect seems to be less pronounced in those paired-end reads having a complete overlap between both reads, as every nucleotide position in the amplicon is covered twice, once by the first read, and once by the second read. therefore, the added effect of iped is smaller in those latter cases.

moreover, reducing the error rate has a significant effect on the quality of the reads in the otus. adding an error-correction step before running the otu clustering algorithm, led to a very close correspondence between the number of otus returned, and the true number of species known to be present in the mock communities. such a significant correspondence could not be obtained when omitting the denoising algorithm in the amplicon sequencing preprocessing pipeline, or via using any other denoising tool. however, caution should be given when extrapolating this to real-life environmental communities, since the diversity linked to the latter samples will be significantly higher than in the tested mock communities. despite this increased complexity, running iped on real biological samples still showed a clear improvement, which was visualized using rarefaction curves showing a clear decrease in the number of otus. moreover, a more accurate correlation was found between biologically related samples when comparing the otu tables produced where iped was integrated into the workflow, as shown in the results by producing denser clusters distinguishing two different biological conditions.

where pre-cluster and unoise have an impressive speed, iped needs more calculation time due to the machine learning classifier required in the first step of iped. however, as seen in the results, iped led to a more pronounced improvement in accuracy compared to both of them.

at this stage we only tested our iped algorithm on mock datasets containing paired end reads that are at least partially overlapping, or in some cases completely overlapping. recent papers suggest the usage of primer pairs for amplicon sequencing producing paired-end reads which are not overlapping at all, as this approach allows flexibility in development of pcr primers and selection of the hypervariable regions. this way those primers can be selected that allow the most optimal distinction for a specific type of sample  <cit> . within this area iped can have a more pronounced effect on the final results as our algorithm was shown to be most effective in the non-overlapping part of the second read, which in such a case would mean the complete second read. iped has only been tested on 16s rrna gene amplicon sequencing data. in principle our tool can be used for any amplicon sequencing data set, such as 18s rrna, 23s rrna or 28s rrna, whenever a reliable reference alignment dataset is available. iped was developed to be applied after the mothur make.contigs command; yet, further adjustments are needed to make it compatible with other paired-end assemblers. preliminary data showed that iped was able to reduce the error rate of qiime to the same extent.

CONCLUSIONS
we have presented in this work the denoising algorithm iped specifically developed for illumina miseq 16s rrna gene amplicon sequencing data. iped obtains a better performance on mock datasets compared with the available alternatives pre-cluster and unoise, and on average can correct double the amount of errors compared to both algorithms. the beneficial effect of this improved denoising was reflected in more accurate otu clustering results.

ethics approval and consent to participate
not applicable.

consent for publication
not applicable.

availability of data and materials
four publicly available illumina miseq sequencing datasets of mock communities were used within this work. the first mock community  is available at http://www.mothur.org/miseqdevelopmentdata.html as presented in kozich et al.  <cit> . the second mock community  is available in the ebi european nucleotide archive under the project id prjeb <dig>  and is presented in the work of nelson et al.  <cit> . the third mock community  is available at the ncbi sequence read archive under the accession number srp <dig>  the fourth mock community  is available on the european nucleotide archive under the project number prjeb <dig> as presented in schirmer et al.  <cit> .

the software developed within this work  is available via github  or via http://science.sckcen.be/en/institutes/ehs/mcb/mic/bioinformatics/, including documentation and a tutorial video.

additional file
additional file 1: extra information describing the development of the machine learning implementation , pre-processing of the sequencing data, computational costs and comparative analyses. 



abbreviations
ipedillumina miseq paired-end denoiser

otuoperational taxonomic unit

tptrue positives

fnfalse negatives

tntrue negatives

fpfalse positives

mccmathews correlation coefficient

rocreceiver operating characteristics

mlpmultilayer perceptron

aucarea under the curve

pcoaprinciple coordinate analysis

competing interest

the authors declare that they have no competing interests.

authors’ contributions

conceived and designed the experiment: mm, jr and pm. computational analysis and analysis of the data: mm and pm. wrote the paper: mm, nl, jr and pm. all authors read and approved the final manuscript.

funding
this work is funded by an sck-cen phd grant.
