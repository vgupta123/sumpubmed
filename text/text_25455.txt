BACKGROUND
researchers using dna microarrays in their studies are widely encouraged, and sometimes compelled by journals or funding agencies, to increase the usefulness of their individual research efforts by making their experimental information easily accessible to the community at large. conversely, many researchers would like to gain easy access to microarray data from other experimenters' work. the need to exchange and aggregate large-scale biomedical data motivates requirements for universal and easy-to-use tools and file formats to do this. this, in turn, has engendered efforts to describe microarray experiments in a standard way.

the need for a standard format led to the development of the microarray gene expression markup language   <cit> , a standardized extensible markup language  format for describing microarray experiments and their result data. unfortunately, some characteristics of actual documents have limited mage-ml's usefulness as a standard. specifically:

 mage-ml documents can be so large that most native xml viewing and transformation tools are unable to open them. also, even if mage-ml documents were typically of a more modest size that allowed viewing and editing tools to digest them, most working experimental biologists find the xml format challenging to "parse" visually and are unfamiliar with those xml tools that try to ameliorate this problem with a reformatted display.

 the semantics of mage-ml are so complex that any two mage-ml producers are likely to interpret a given mage-ml document differently. conversely, because there are frequently different choices for representing the same information, different producers are likely to produce different mage-ml representations of it. in our discussion, we use the term semantic variant to refer to one particular semantic use or interpretation of mage-ml that one particular producer generates.

the result of the large file sizes together with the need to deal with many semantic variants is that microarray data are represented in many, sometimes non-interchangeable mage-ml documents, with no existing xml approach to reconcile this "tower of babel".

various approaches to transforming mage-ml semantic variants are possible. for example, one might import mage-ml into a relational  database, which can handle the large size of the information set. once in an sql database, sql queries can be used to transform the now-relationally represented mage-ml. finally, the results of this sql transformation can be exported. unfortunately, this approach has at least two serious drawbacks. first, the description of a microarray experiment in mage-ml is complex, multilayered, hierarchical in some parts, dag -like in others, and generally interconnected in ways that do not admit a simple relational representation. as a result, it is practically impossible to verify, or even have high confidence that an algorithm for transforming xml into and out of relational tables  preserves the intended semantics. second, even if correct, the import and export of xml into and out of an sql database is costly and inefficient.

we describe here a new approach to inter-translating different semantic variants of mage-ml that does not suffer from these drawbacks.

xbabelphish is a powerful, general-purpose, native xml document translator. it accepts a mage-ml file  for translation and enters it into a native xml database. it then executes xquery  <cit>  statements supplied in a translation definition to transform the loaded document into the desired xml format. if the original file was mage-ml and the translation definition defines a mapping from mage-ml to mage-ml, then the result of the translation will be mage-ml. but depending on the translation definition, the result could be an xml file in any desired format. finally, xbabelphish unloads the translated document from the xml database into the native file system.

xbabelphish runs on most major computing platforms, including windows, linux, bsd unix, mac os/x and all posix-compliant operating systems. it should run on the 64-bit versions of these platforms on which berkeley db xml runs , but this has not yet been tested.

xbabelphish exceeds the capabilities of other native xml translation mechanisms, such as xslt  <cit>  , both in its expressive power and in the size of documents that it can handle. compared to non-native approaches based on a relational database, it is far simpler to install, manage, and run; and it provides a far simpler and more reliable way to arrive at correct translations. the reliability derives largely from the complete absence of convoluted and impossible-to-verify transformations of the xml into relational tables and back again. therefore, it is relatively easy to know what a translation does. 

the simplicity comes from xbabelphish's ability to define or change a translation with absolutely no programming in the conventional sense. defining a translation is essentially a matter of writing one or two xquery statements in a small translation definition document. changing a translation is simply a matter of changing these xquery expressions. this also contributes to xbabelphish's reliability because xbabelphish does not have to change when the translation does.

the expressive power of xbabelphish comes from its use of xquery to define translations. xquery is a powerful proper superset of xpath  <cit>   to identify change locations. in contrast, xslt uses only xpath. xquery is a w3c standard  <cit>  language that so far lacks an update component. however, xbabelphish is able to modify xml documents by using berkeley db xml's  <cit>  xquery implementation, which extends standard xquery with a rich set of modification operations. xbabelphish's ability to handle large documents comes from its use of berkeley db xml as a native xml database. berkeley db xml is an open-source product that may be used freely in freely redistributable software such as xbabelphish. xbabelphish's platform requirements  are just those of berkeley db xml.

 <dig> implementation
xbabelphish is a standalone, pure java  <dig>  program that uses the storage and xquery services of berkeley db xml, a native xml database , which in turn, is built on berkeley db .

xbabelphish has a very simple modus operandus: it streams a user-supplied source xml document into a berkeley db xml "container". once deposited in the xml database, xbabelphish transforms the source document according to a user-supplied translation definition. finally, it streams the translated document out of its database container and into a new xml document. this is the translation or required semantic variant of the original source document. this simple arrangement is illustrated in figure  <dig> 

the translation definition is itself an xml document that xbabelphish streams into the xml database . it is typically quite small, and conforms to a simple xml translation schema defined by xbabelphish. a translation definition comprises a sequence of translation steps that xbabelphish executes in a berkeley db xml context. each translation step contains an xquery statement whose result set is a sequence of xml nodes in the source document. the nodes in this sequence are the locations for possible change. each step also includes an operation verb that specifies what kind of change to make at each identified change location – for example, insert an element, add an attribute, update an attribute's value, or delete the node. usually, a translation step also includes a second xquery statement that computes any new content  for the change.

the second, content-computing xquery in a translation step may be a "context query" that executes in the context of each change location defined by the first xquery in the step. in this way, the local xml "environment" around a change location  may be used to define the change at that location. using this device, a single translation step may compute differing, context-appropriate new content for each of any number of change locations. this is a very compact and powerful idiom for specifying how to transform an xml document.

a key attribute of an xbabelphish translation definition is that it is not tied to any particular xml document. it uses symbolic document references that permit its use in translating a document without regard to name. this facilitates the development of libraries of translations for any xml document domain of interest. in the world of mage-ml, work may be done to identify the important semantic variants and develop translations between them. this approach, which would result in n  translations for n semantic variants, may be refined into a 2n approach by settling on one canonical variant vc, and defining the two translations vc → vn and vn → vc for each non-canonical variant vn.

xbabelphish works well on very large documents up to and beyond  <dig> mb. for documents substantially less than this size and requiring modest numbers of changes, berkeley db xml's xquery engine provides completely adequate performance. for example, in one of our test cases running on a mac os x g <dig>  <dig> ghz processor, xbabelphish takes around  <dig> minutes to execute a four-step translation on a  <dig>  mb. mage-ml document. for a very large document, or one whose translation involves large numbers of changes, the current version  <dig> . <dig> of berkeley db xml has scaling problems that reduce xbabelphish's translation performance unacceptably. xbabelphish solves this problem and still works quite well by splitting such a source document into fragments, translating each of the resulting fragments, then reassembling the translated fragments into a single translation result. xbabelphish uses a streaming, stax "pull" parser to implement this function efficiently.

splitting and merging increase translation time by a factor that depends on the number of steps in the translation and the number of fragments into which the source document is split. for the four-step translation of the  <dig>  mb. mage-ml document mentioned above, splitting the document into  <dig> fragments increases the translation time from  <dig> to  <dig> minutes. in another of our test cases running on a mac os x g <dig>  <dig> ghz processor, xbabelphish takes about  <dig> minutes to execute a two-step translation on a  <dig>  mb. mage-ml document by splitting the document into  <dig> fragments. however, splitting and merging is the only way to translate this larger document; direct translation does not complete within  <dig> hours. we expect berkeley db xml to overcome its scaling problems. this will give xbabelphish a big performance boost and virtually eliminate the need to split and merge documents.

the xbabelphish distribution includes a javadoc that completely documents how to install and run the translator. installation is mostly a matter of installing berkeley db xml. documentation for constructing translation definitions is provided by comments in the translation schema itself. an xbabelphish command  prints this schema. the distribution also provides sample translation definitions and source files drawn from the world of mage-ml. these samples illustrate the power of xbabelphish and provide a guide-by-example for creating translation definitions. for those less familiar with xquery, there are gui tools for constructing and validating xquery statements, such as the <oxygen/> xml editor  <cit> , whose academic license fee is nominal.

it is worth reiterating that absolutely nothing in xbabelphish ties it to the syntax or semantics of mage-ml. it is a completely general xml translator.

 <dig> 
RESULTS
 <dig>  translation definitions
to have a good understanding of xbabelphish's capabilities, we need to look at translation definitions. as previously mentioned, an xbabelphish translation definition takes the form of an xml file that conforms to a translation.xsd built into xbabelphish. along with a file to be translated, a translation definition is passed to xbabelphish to tell it how to perform the translation.

the discussion in the following subsections may be better understood by referring to figure  <dig> for the example discussed in section  <dig> .

 <dig> . <dig> symbolic names
translation definitions contain xquery statements that refer to the document being translated. typically, there will be many documents with many different names that must be translated in the same way from one semantic variant to another. so that one translation definition can be used for each of these documents, xbabelphish recognizes symbolic document names in xquery statements:

 doc: the unaltered source document being translated.

 doc: the  altered document after zero, one, or more translation steps have been executed.

 doc: an xml value in the result set of a previously executed changelocationquery  in the same translation step. an xquery that uses this construct is a "context query".

 <dig> . <dig> target locations
as mentioned in section  <dig>  each step in a translation contains an xquery statement whose result set is a sequence of  nodes that define where that step's changes are to be applied. these are the "change locations" or "targets" for that translation step. the xquery that defines these targets is either a changelocationquery, or a targetwithvaluequery, as explained in section  <dig> . <dig> 

 <dig> . <dig> defining new content
each operation primitive except delete defines new content to apply at each target location. there are three ways to define this new content, listed below. in a translation step that uses either of the first two ways of defining new content, the step's first query is a changelocationquery whose role is confined to defining change locations. the third way of defining new content is with a targetwithvaluequery that defines the change locations and the new content in one result set:

1) newcontentquery: after a changelocationquery that identifies the target locations, a newcontentquery is executed exactly once in the step; it defines a single, unchanging value that is applied at each target location.

2) locationvaluequery: also used after a changelocationquery, a locationvaluequery is a "context query" . it is executed once for each change location to define location-dependent new content.

3) targetwithvaluequery: this is the one and only xquery in the step. it defines both the change locations and their new content. new content elements in the result set alternate with change location nodes, with the new content for a change location immediately following it. a targetwithvaluequery typically uses a flwor expression  <cit> . . in xbabelphish, it would have the form:

for $x, at $y in doc//... return , g)

where f() and g() represent some xquery function. doc is a symbolic reference to the document being translated – in the transformed state produced by the execution of all preceding translation steps.

see figure  <dig> for an example  of a translation definition used in a translation.

 <dig> . <dig> translation operations
xbabelphish provides a rich set of operation  primitives for adding, deleting, updating, and renaming xml nodes in a document. these primitives focus on the element, attribute, and text nodes that are the ones most commonly requiring transformation.

the primitive operations are presented in table  <dig> 

<a/> <b/> <c/> <d/>
name="xfamily"
<a/> <b/> <c/> <d/>
start name="xfamily"
<a/> <b/> <c/> <d/>
start name="xfamily"
<a/> <b/> <c/> <d/> end
start name="xfamily"
<a/> <b/> <c/>
end
start title="xfamily"
<a/> <b/> <c/> end
start title="abcgroup"
<a/> <b/> <c/> end
the operation in the first row is applied to the simple, abstract xml snippet:

<x> </x>

the operation in each succeeding row applies to the result of the row immediately preceding it.

 <dig>  an example
xbabelphish has been vetted with use cases in the mage-ml document domain drawn from: the stanford microarray database  <cit> , the computational biology and informatics laboratory  at the university of pennsylvania  <cit> , and european bioinformatics institute  microarray informatics group, which runs the arrayexpress microarray database  <cit> . using its split/merge capability, it has translated fairly large  documents in translations that apply tens of thousands of changes. for other documents, it has demonstrated the effective use of complex flwor expressions in xquery. following is a modest example.

 <dig> . <dig> translation definition
the single step in this translation defines:

1) the set of locations where changes may be made with a changelocationquery – in this case, a simple xpath expression that selects all featureextraction elements within measuredbioassay elements.

2) the new content – the value of a new name attribute for each of the featureextraction elements selected by the changelocationquery – with a locationvaluequery. in this case, the locationvaluequery is a flwor expression with three bound variables that constructs the value of a new name attribute by concatenating the values of two other, existing attributes  connected by a string literal. xbabelphish executes this xquery once in the context of each selected featureextraction element. as a result, the value of the new name for each featureextraction is "customized" for that particular element.

3) the operation  that uses the new content – in this case, addattribute.

4) the name of the new attribute  – in this case, "name".

 <dig> . <dig> source and target
 <dig> . <dig> run output
 <dig> discussion
 <dig>  assumptions
like any other technology solution, the xbabelphish's design was based on several assumptions concerning the characteristics of a document domain's semantic variants, and the possibility of knowing their differences:

limited differences: there are a manageably small number of differences between the rule sets used by the constructors for distinct semantic variants – typically fewer than  <dig> 

limited number of semantic variants: there are a manageably small number of semantic variants. this is important because this determines the number of translations that a document domain needs – either n  pairwise translations or 2n canonical translations for n semantic variants.

difference discovery: it is possible and practical for domain experts to discover differences in the rules that two different producers  use – where rules in the corresponding producers map the same piece of domain  information into different xml  elements, attributes or text.

it is possible, and in fact may be common to discover differences between two sets of construction rules without necessarily being able to characterize either set of rules independently.

using difference information: it is possible and practical for domain experts to clearly characterize the differences between a translation pair of semantic variants in terms of their xml schema  <cit>  or dtd  <cit> , and to convey these differences to computer experts.  the ability to characterize these differences hinges on how simple or complex the differences are, and how simply they can be couched in terms of xbabelphish's primitive operations. the ability to convey the differences would likely  be present when these experts were one and the same person.

 <dig>  experience
experience with xbabelphish in the mage-ml document domain is still limited. however, domain experts have so far shown a good ability to understand how various semantic variants differ from their preferred variant. to date, no domain expert has also tried to assume the role of translation definer.

the process of conveying domain knowledge of semantic differences to someone able to formulate the xquery statements in an xbabelphish translation definition has been slower and more interactive than anticipated. but, as can be seen from the example, this has been done for nontrivial translations. since this example and other more complex ones have been drawn from real mage-ml translation use cases, this is good evidence that xbabelphish can address the real translation needs for mage-ml documents.

 <dig>  other approaches
xbabelphish uses a native xml database for storing xml documents in conjunction with xquery, with update extensions, for transforming stored documents. this is not the only approach for inter-translating xml semantic variants. a number of alternative approaches were considered, and put aside for various reasons. approaches vary in their use of different storage vehicles and transformation languages, or in their use of different xquery engines. the following survey is a small sample:

 <dig> . <dig> xslt
the tool most obviously comparable to xbabelphish is xslt  <cit>  – a w3c language for transforming xml documents. unlike xbabelphish, xslt is not intended to be a general-purpose tool. rather, it is designed for the kinds of transformations most commonly needed for xsl  <cit>  style sheets. in line with this limited goal, xslt relies on xpath  <cit> , which is a small proper subset of the more powerful xquery language that xbabelphish uses. just as telling, existing xslt implementations cannot handle documents anywhere near the size commonly encountered in xbabelphish's initial document domain of mage-ml.

 <dig> . <dig> ldap directories
one approach is to store mage-ml documents in ldap directories, translate them within this storage vehicle, and then extract them. there are open source ldap implementations, such as openldap  <cit> , and tools that wrap ldap structures in xml, such as ldapxml  <cit> . but a general translation algorithm for xml -> ldap is problematic. additionally, the verbs for ldap transformations are far more primitive that those available through an approach using xquery-based update.

 <dig> . <dig>  relational database storage
another approach is to "shred" mage-ml documents into a set of relational database tables, transform the tabularized representation inside the sql database, and then extract this transformed representation as the translated xml document. there are many variants of this approach, all with major problems. one approach is to use a generalized xml shredding tool that:

1) generates a relationally efficient sql schema that preserves both the structural and constraining properties of an xml schema.

2) "shreds" an xml document that is an instance of the xml schema into a database defined with the generated relational schema.

3) transforms the shredded document via sql statements that are automatically generated from xquery statements based on the xml schema.

4) "unshreds" the document back into xml.

this is a very difficult problem. to date, there has been no successful implementation of this approach. the most promising effort at the time of our initial investigation was shrex  <cit> , whose documentation seems to promise much of items 1) – 4). unfortunately, the only known extant implementation does not fulfill this promise.

 <dig> . <dig> other xquery engines
berkeley db xml is not the only open source xml database/xquery engine. exist  <cit>  is another. unfortunately, when exist was evaluated, its indexing scheme limited its ability to handle xml nodes with a branching factor greater than the capacity for a 16-bit integer. large mage-ml documents far exceed this limit, and therefore exist's ability to accommodate them. this limitation was in the process of being fixed . however, some of exist's supporting tools, for example its java console-based browser, were also severely limited in capacity.

yet another xquery engine is galax  <cit> . unlike berkeley db xml and exist, galax is not coupled with a database. but it includes an implementation of xquery!  <cit>  for updating xml documents. its technology probably makes it more capable than most xquery engines in running queries on extremely large documents. despite this, simple tests  showed that exist's performance for larger mage-ml documents is marginal. it should be noted, too, that galax's installation is extremely cumbersome.

 <dig> 
CONCLUSIONS
xbabelphish is a very powerful and efficient tool for inter-translating semantic variants of mage-ml, thereby improving the interchange of microarray experiment information. initial use cases show a promising potential in this document domain. in addition, xbabelphish is completely independent of mage-ml semantics, or indeed the semantics of any document domain. it is perhaps unique in this independence, in its expressive power, and in its ability to translate very large documents.

availability and requirements
project name: xbabelphish xml translator

project home page: xbabelphish distribution archive: 

operating system: all platforms that berkeley db xl supports, including windows, linux, bsd unix, mac os/x and all posix-compliant operating systems; not tested on the 64-bit versions of these platforms

programming language: java , c, and c++ 

other requirements: j2se  <dig>  or newer  berkeley db xml version  <dig> . <dig> or newer  web browser or html viewer for viewing the javadoc

open source licenses: xbabelphish: mit 

stax: apache license  <dig>  

berkeley db xml: oracle/apache  <dig>  

berkeley db: oracle/university of california/harvard for berkeley 

xerces: apache license  <dig>  

pathan: decisionsoft/bsd 

any restrictions to use by non-academics: commercial license for berkeley db xml needed .

authors' contributions
cab and gs provided information about the needs of the mage-ml-using community. dm determined the specific requirements for xbabelphish, designed it, implemented it, tested it, wrote all the documentation, and when necessary, helped debug problems in berkeley db xml. fw provided some initial use cases and technical consultation. cab and fw consulted on general approaches to some thorny problems encountered along the way. dm wrote the manuscript, and cab and gs edited the manuscript and provided comments and suggestions. all authors have read the manuscript and approve of its content.

