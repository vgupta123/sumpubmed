BACKGROUND
rna degradation is a common concern in gene expression analysis, especially for clinical samples where rna degradation may occur before sample collection
 <cit> . a wealth of archival material, either snap frozen or formalin fixed and paraffin embedded , could potentially be used for gene expression analysis, given an appropriate method to evaluate and account for the effect of rna degradation on the quality of downstream gene expression data. methods such as the rna integrity number  algorithm reliably assesses rna integrity by extracting features from the rna electropherogram. the rin algorithm was developed using learning tools to identify regions  indicative of rna integrity in the electropherogram, which are then used to compile the rna integrity number on a scale of  <dig> to  <dig>  however, the relevance of rna integrity in gene expression analysis, especially when there is large variability between samples, requires further investigation and validation on a platform specific basis. the impact of rna integrity on gene expression analysis has been investigated on both qrt-pcr and certain microarray platforms
 <cit> . opitz et al investigated the impact of rna degradation on agilent  <dig> k gene expression profiling by subjecting rna from clinical biopsies to temperature-induced rna degradation and comparing gene expression to the original, intact samples. notably, less than 1% of genes were affected, even after substantial rna degradation, where control and test samples had rins of  <dig> and  <dig> respectively. the affected transcripts were relatively shorter, had lower gc content, or had probes relatively closer to the 5' region of the gene compared to more robust genes
 <cit> . although the process of rna degradation is not fully understood, both exonuclease and endonuclease activity is likely to play an important role
 <cit> . classical oligo-dt based cdna synthesis, which starts at the poly-a tail, will most certainly be compromised by exonuclease activity. in contrast random priming does not rely on full length mrna and therefore is in theory at least partially relieved from the affects of rna degradation
 <cit> .

when using semi-degraded rna for gene expression studies, reliable measures of array quality provide valuable information that can be used to guide downstream analysis. microarray data quality may be defined in terms of accuracy , precision , specificity  and sensitivity 
 <cit> . any attempt to utilise array quality results to guide downstream analysis should ideally take into account the possible effects of rna degradation on sensitivity, specificity and accuracy. in previous work, binder et al proposed a single-array preprocessing method that allows correction for systematic biases such as rna degradation by utilising information on the 3'/5'-amplification bias and the sample-specific calling rate
 <cit> . lassmann et al proposed using a data adjustment method to allow comparative analysis of microarray datasets derived from fresh frozen vs. ffpe samples by centering the log intensities of each probe set independently to a mean of zero in both groups
 <cit> . chow et al evaluated the suitability of different quality control and preprocessing strategies for use with partially degraded rna samples on the illumina dasl-based gene expression assay using mean inter-array correlation and multivariate distance matrix regression  as a measure of success
 <cit> . unfortunately none of these studies are directly applicable to one of the most commonly used human transcriptomic microarray platforms, namely affymetrix gene  <dig>  st arrays, either because they do not use a random priming approach or because the design of the microarray platform differs substantially from gene  <dig>  st arrays. we therefore identified two alternative approaches that might be used as compensatory methods: firstly, johnson et al developed an empirical bayes algorithm, combat, to directly adjust for non-biological experimental variation. as the name implies, this method is most often used to adjust for batch effects i.e. when microarrays are processed on different dates
 <cit> . secondly, leek et al developed a method called surrogate variable analysis , which examines the contribution of sources ofsignal due to unknown  variables in high-dimensional data sets, which may confound the biological signal of interest
 <cit> . the surrogate variables are constructed directly from the gene expression data where groups of genes that are affected by each source of variation are identified, factors are then estimated for each array which can be included in a linear model to adjust for unknown sources of noise e.g. rna- or array-quality.

here, we investigate the relationship between rna integrity and array quality on affymetrix gene  <dig>  st arrays for  <dig> paired colorectal tumour and adjacent normal biopsies of highly variable rna integrity. we assume that at a certain point on the rin scale, rna will be degraded to the extent where fragments are too small to analyse reliably and for the purpose of this analysis we arbitrarily select a rin cutoff of  <dig>  we describe the within- and between-array quality control measures and analysis methods that we found most relevant for gene expression analysis of samples with highly variable rins on affymetrix gene  <dig>  st arrays. we then investigate the possibility of a transcript-length dependency in rna degradation. finally, we apply array quality information to either exclude quality-flagged arrays, to directly adjust the data using the combat algorithm, or to account for unknown sources of variation  in the model fitting process using sva. the data discussed, have been submitted to arrayexpress, with accession number e-mexp- <dig> 

RESULTS
array quality
we assessed array quality using within- and between-array measures – the former to assess raw data quality , and the latter to assess the quality of an array relative to a large publically available collection of high quality gene  <dig>  st arrays . raw array quality was investigated at the probe level by calculating the difference between the means of perfect match- and background-probes for each array as well as the coefficient of variation  across all probes for each array. preprocessed data quality was assessed using the global normalised, unscaled standard error 
 <cit> . see methods section for details.

the  <dig> rna samples used in this study had a mean rin of  <dig>  and a standard deviation of  <dig> . samples that failed all three measures of quality had rins between  <dig> and  <dig>  as summarised in table
 <dig>  samples were ranked by gnuse median and we found a good concordance in terms of ranking between the different quality control metrics. samples that failed at least two out of the three quality measures were flagged for downstream analysis, resulting in  <dig> out of  <dig> samples being flagged . interestingly, for one sample with a rin of  <dig> , array quality was not compromised, judged by our quality measures. the possibility of a rin-independent rna quality factor, such as chemical purity, was investigated by performing a two-tailed student’s t-test, comparing a260/ <dig> ratios between quality-flagged and quality-passed sample groups but no significant association was found .

 <dig>  gene st  <dig>  arrays, do not display the same probe-positional intensity bias typically seen in oligo-dt based arrays such as the hgu133-plus <dig> arrays.

we next investigated which genes were most affected in our quality-flagged category and identified  <dig> out of  <dig> annotated transcript clusters  that were significantly different  between the two quality categories previously discussed. of the  <dig> uniquely identified genes,  <dig> and  <dig> showed decreased or increased intensity in the quality-flagged category respectively . to investigate transcript characteristics in the genes most affected, we compared transcript lengths  between the different groups. compared to the unaffected genes, median cdna lengths of genes that showed increased intensity were significantly shorter  while those with decreased intensity significantly longer  with regards to quality, judged using the mann whitney test .

quality dependent methods of data adjustment and analysis
after assigning samples to two categories according to array quality measures, we next assessed the performance of the five preprocessing and analysis methods. broadly speaking, the data was either directly adjusted for quality effects using combat, or quality-flagged samples were excluded from the analysis, or possible quality effects were addressed by including known or unknown sources of non-biological variance in the linear model fit to assess differential expression.

the five methods of data preprocessing and analysis, further detailed in the methods section, were: 1) estimating array quality weights which were then included in the linear model fit; 2) excluding quality-flagged arrays from the analysis; 3) applying a batch correction algorithm, combat,
 <cit>  to directly adjust the data according to quality, where arrays were divided into two categories according to the array quality assessment; 4) “quality” and “batch” were included as a factors in the linear model together with disease status; 5) possible unknown sources of non-biological variance, such as quality, was estimated by sva, with the output incorporated into the linear model fit
 <cit> .

to assess the effect of using combat for direct data adjustment, hierarchical clustering using euclidian distance was performed before and after direct adjustment . we chose to use euclidian distance based on research by gibbons et al who demonstrated that, for log-transformed expression data, using euclidian distance is more appropriate than pearson’s correlation coefficients
 <cit> . before adjustment, samples that were flagged during quality assessment cluster closely together, irrespective of the disease status of the samples. after adjustment, the maximum distance between samples is greatly reduced, and quality-flagged samples no longer cluster together. also, samples segregate more clearly by disease status after adjustment. furthermore, applying combat clearly has a stabilising effect on the transcript clusters most affected by rna quality .

sva identified two surrogate variables that were subsequently used in downstream analysis. plotting the estimates of these surrogate variables for each sample revealed a pattern whereby samples were clearly grouped by batch and quality . importantly, sva identified these two variables without supervision.

to evaluate the performance of each method, we first compared the number of differentially expressed genes detected between tumour and normal samples at a stringent p-value of  <dig> . for our analysis, we did not use a fold change cutoff since we feel that artificial fold change cutoffs, which exclude subtle changes in the expression of many genes, may result in the loss of valuable biological information, or worse, affect the interpretation of the data – this is particularly true for applications such as network/pathway analysis
 <cit> .

sva and combat detected  <dig> and  <dig> genes , respectively. the top four methods had  <dig> differentially expressed genes in common . at the commonly used p-value- and fold change-cutoffs of  <dig>  and  <dig> respectively, sva, combat, arrayweights and excluding arrays, produced  <dig>   <dig>   <dig> and  <dig> differentially expressed genes respectively, suggesting similar performance under these criteria. we next assessed the relevance of these differentially expressed genes in colorectal cancer using ingenuity pathway analysis where, statistically significant over-representation of our listed genes in a given process such as “colorectal tumour” or “infection of embryonic cell lines” is scored by p-value.

we considered the top  <dig> functions for each method  from which it was clear that the  <dig> and  <dig> additional genes identified as differentially expressed by sva and combat, compared to that obtained when excluding quality-flagged arrays, were certainly relevant to colorectal cancer. using ipa, we considered the top  <dig> upstream regulators  when comparing tumour vs. normal samples, to further investigate the utility of sva or combat as suitable analysis methods when including low-rin samples . we found considerable overlap in the identity and direction of activation of these upstream regulators between the methods compared.

a - excluding quality-flagged arrays from the analysis. b - applying sva to batch corrected data. c - combat used to correct for batch and quality. d - array weights included in the linear model. e - including batch and quality as factors in the linear model.

a - excluding quality-flagged arrays from the analysis. b - applying sva to batch corrected data. c - combat used to correct for batch and quality.

qrt-pcr validation of select genes
in order to ascertain whether or not data obtained by microarray analysis with low-rin samples were comparable to the results obtained using the method designed by antonov et al for qpcr analysis of low-rin samples, we selected two genes, dipeptidase  <dig>  and claudin  <dig> , for qrt-pcr validation. given that our microarray data analysis suggests ~95% of genes are unaffected by rna integrity, we wished to compare microarray and qpcr data for genes that were apparently unaffected by rna integrity; dpep <dig> and cldn <dig> were found to be significantly differentially expressed in our microarray data by all of the five methods used and, in addition, there is strong literature evidence for their differential expression between tumour and normal samples. from reference genes previously cited as suitable for colorectal cancer studies, we selected those most stably expressed in our cohort using the normfinder algorithm 
 <cit> . we found good correlations, for both cldn <dig>  and dpep <dig> , between qrt-pcr- and microarray-based fold change values , irrespective of rin score.

discussion
rna is extremely vulnerable to degradation and as such has the potential to introduce a systematic bias in gene expression measures. reliable measures of sample and data quality are therefore essential to evaluate the effects of rna integrity on accuracy, sensitivity and specificity of gene expression results. from previous studies as well as our own, it is now clear that the level of acceptable rna degradation within an experiment depends largely on the experimental design, platform and application. multiple studies have demonstrated an improvement in microarray and qrt-pcr performance by using random priming when rna integrity is in doubt. here we observed a direct association between rins and array quality in the majority of cases. to gauge the consequences of using these arrays in downstream analysis, we compared quality-flagged to quality-passed arrays and found a relatively small subset of genes, 1172/ <dig>  to be significantly affected  in our samples on the gene  <dig>  st platform. it is of course possible that the exact identity and proportion of the affected genes may differ between studies on gene  <dig>  st arrays but, based on our data, we suggest that the overall proportion of affected genes is unlikely to be significantly different to that observed here. depending on the application, this may or may not have an effect on the study outcome. however, the most common microarray applications such as finding differentially expressed genes between two conditions, pathway analysis, and clustering do not rely on interrogating specific genes and appear to be largely robust to the effects of rna degradation on this platform .

using within- and between-array quality measures, we investigated the relationship between rna integrity and array quality on affymetrix gene  <dig>  st arrays. we found a combination of within- and between-array quality measures useful to rank samples by array quality. however, the single most useful array quality measure appears to be gnuse, since it provides a more general measure of array quality relative to a large set of publically available arrays. we found that 86% of samples with rins ≤  <dig>  were flagged by at least two of our quality control measures. one sample with rin score <  <dig> passed all three quality measures, although it did have relatively low array quality weight. furthermore,  <dig> out of  <dig> samples with rin scores ≤  <dig> passed at least  <dig> out of  <dig> quality measures, suggesting that the widely used rin cutoff of  <dig> is too stringent for gene  <dig>  st arrays.

we then examined the genes most affected by rna degradation and demonstrated a relationship between accuracy and length of the original transcript, with both longer than average, and very short transcripts being under- and overrepresented in quality-flagged samples respectively. this is in contrast to the findings by opitz et al who found that short transcripts were more vulnerable to the perceived effects of degradation, whereas long transcripts were more stable relative to the average length transcript
 <cit> . interestingly, of the genes that were overrepresented in quality-flagged samples, 70% were small non-protein coding rnas, including  <dig> small nucleolar rnas, and  <dig> micrornas, consistent with reports that micrornas are more robust to rna degradation compared to mrna
 <cit> , perhaps because they are more thermodynamically stable than mrnas.

without excluding any genes, we then compared the orthogonal approaches of either excluding quality-flagged arrays or compensating for rna degradation at different steps in the analysis. sample clustering showed that when using combat adjustment, quality-flagged samples no longer clustered together. furthermore, samples tend to segregate more clearly by disease status following adjustment, which suggests that the algorithm is not introducing artifacts. it is worth noting that patients  <dig>   <dig> and  <dig> were diagnosed with a hereditary form of crc  – it is therefore not surprising that the ‘normal’ samples from these patients form a separate cluster.

irrespective of sample/array quality, applying compensatory measures for rna degradation performed at least as well as excluding arrays that were flagged during quality assessment, as judged by gene expression analysis and ipa. at a p-value of  <dig> , sva and combat detected the highest number of differentially expressed genes between tumour and normal samples and the top four methods applied here had  <dig> differentially expressed genes in common. to evaluate the biological plausibility of the genes deemed significantly differentially expressed between tumour and normal samples, we harnessed the results from ipa to show that, in terms of the top scoring biological functions and upstream regulators, there is considerable overlap in the identity and direction of biological activation when comparing analysis methods that either excluded or included quality-flagged arrays. these results suggest that our analysis strategies are biologically sound and not biased by non-biological variance.

the relevance of each method will depend on the downstream application and the proportion of quality-flagged arrays: if a small percentage of arrays are flagged, there might not be much benefit in including them for downstream analysis. however, if a large proportion of the arrays are affected by rna quality – which is likely to often be the case where the rna is derived from irreplaceable historical clinical samples – the ability to retain all arrays and to account for these effects in the analysis will be valuable. here, combat may be useful if direct data adjustment is required, e.g. for sample/gene clustering. on the other hand, for analysis of differential expression, especially when the source of non-biological variance is not immediately apparent, sva may be most useful since it does not require supervision; notably, in our hands sva was able to identify two surrogate variables which closely corresponded to “batch” and “quality” factors, judged by the grouping of samples. to establish whether the measures used here to compensate for quality-effects are superior to excluding these arrays from the analysis will require a controlled study with known true- and false-positives where the discriminatory power of each method can be objectively investigated. however, the significant overlap observed between the differentially expressed genes identified by the different approaches used here, combined with the considerable overlaps in both biological function and upstream regulators identified by pathway analysis of the resultant data, argues against a simple expansion of false positives when lower quality array data is included in the analyses. the quality assessment and data analysis methods discussed here should in principle be as useful for affymetrix exon st array analysis as well.

CONCLUSIONS
in conclusion, array quality measures can be used to set quality thresholds, to provide valuable information that can be used to improve the linear model of differential expression, or to correct expression signal prior to assessing differential expression. we suggest that accounting for known or unknown sources of variation, such as variable rna integrity and batch, by implementing combat or surrogate variable analysis for analysis of differential gene expression enables robust analysis of microarray datasets derived from variable and low quality rna, thereby extending the range of clinical samples that are suitable for microarray analysis.

