BACKGROUND
whole genome doubling  creates two identical copies  of each chromosome in a genome, with identical gene content and gene order. from this ensues the wholesale shedding of duplicate genes over evolutionary time through random excision - elimination of excess dna - namely the deletion of chromosomal segments containing one or more genes, or through gene-by gene events such as epigenetic silencing and pseudogenization  <cit> .

when a duplicate gene is lost, it may be lost from one copy  of a chromosome or the other, but generally not both, because of the necessity of conserving function. this fractionation creates an interleaving pattern; the full original gene complement becomes apparent only by consolidating  <cit>  the two homeologous single-copy regions. in most cases, there is a degree of bias, more genes being lost from one of the homeologous regions than the other  <cit> . fractionation is an important process in many evolutionary domains, in particular the flowering plants, since it results in a genome that is highly scrambled with respect to its pre-wgd ancestor. for this reason as well, fractionation raises a number of interesting and difficult problems for comparative genomics.

the study of fractionation is basically a study of runs, that is runs of duplicate genes on two homeologous chromosomes alternating with runs of single-copy genes on one or both of these chromsomes. because of the way these runs are generated biologically, and because they involve two chromosomes evolving in a non-independent way, standard statistical or combinatorial run analyses are not directly applicable.

in this paper, we present a detailed version of the excision model of fractionation with geometrically distributed deletion lengths, for which we previously analyzed a tractable, but biologically unrealistic, special case  <cit> . the key problem in this field is to determine μ, the mean of the hypothesized geometric distribution ρ, since this bears directly on the main biological question of the relative importance of random excision versus gene-by-gene inactivation. the relevant data consist of runs of single-copy genes  as well as runs of remaining duplicate pairs in two homeologous regions. the inference of μ is complicated since each run of l single copies may have been produced by an unknown number r of deletion events, either r = l events  or  <dig> ≤ r <l -  <dig> , and these r samples of the distribution ρ turn out not to be independent. thus a fundamental aspect of finding μ, and hence ρ, is to derive π, the proportion of runs of single-copy genes with r terms, for r =  <dig>   <dig>  ⋯.

a further complication arises from the way deletion events accumulate into longer runs of single-copy genes. the deletion of a certain number of duplicate genes may overlap the site of a previous deletion event on the same chromosome, but it is blocked by the functional constraint  as soon as it starts to overlap the site of a previous deletion event on the homeologous chromosome.

another biologically important question is to determine ϕ, the proportion of deletion events that operate on one of the homeologous chromosomes, while a proportion  <dig> - ϕ operates on the other. we explored this question at some length in  <cit> , but a detailed mathematical treatment of the effects of this "fractionation bias" remains to be done.

it is not difficult to simulate the fractionation process, but this gives little insight into its mathematical structure. given that it is unlikely for any closed form of π to exist, nor for any simple computing formula, our goal here is to develop a recurrence for the distribution of π for r =  <dig>   <dig>  ⋯ as a function of μ, ϕ and θ .

this work is an attempt at creating a rigorous "null" model of duplicate loss, based on parameters μ, ϕ and θ. this should provide a principled basis for developing statistical tests on real wgd descendants, to see if the geometric excision hypothesis is acceptable and to see if fractionation is unbiased or not. we will not explicitly investigate the alternative hypothesis of gene-by-gene deletion, nor do we take chromosomal rearrangement events into account; our task here is simply to set up the null statistical model with a view to enabling useful statistical tests of hypothesis for this problem.

the models
the structure of the data
the data on paralog reduction are of the form , where g and h are binary sequences indexed by ℤ, satisfying the condition that g + h >  <dig>  this condition models the prohibition against deleting both copies of a duplicated gene. we may also assume that whatever process generated the 0s and 1s is homogeneous on ℤ.

the sequence g + h consists of alternating runs of 1s and 2s. we denote by p, l ≥  <dig> the probability distribution of length of runs of 1s. for any finite interval of ℤ we denote by f, l ≥  <dig> the empirical frequency distribution of length of runs of 1s.

the use of ℤ instead of a finite interval is consistent with our goal of getting to the mathematical essence of the process, without any complicating parameters such as interval length. in practice, we use long intervals of at least  <dig>  so that any edge effects will be negligible. see  <cit>  for ad hoc ways of handling biological scale intervals.

the deletion events
let ϕ, where  <dig> ≤ ϕ ≤  <dig>  be the fractionation bias. we assume a continuous time process, parameter λ >  <dig>  only to ensure no two events occur at the same time.

• we start  with h = g =  <dig> for all i.

• at any t >  <dig>  consider any i where h = g =  <dig>  with probability λdt, a deletion event occurs anchored at position i: we choose a positive number a according to a geometric variable y with parameter 1/μ, i.e., p=γ=1μ1-1μa- <dig> a≥ <dig> 

• then with probability ϕ we choose to carry out the deletion on g; with probability  <dig> - ϕ, on h.

• if the deletion is on g we convert g =  <dig>  g =  <dig>  ⋯, g =  <dig> unless a "collision" occurs.

• one type of collision, skippable collision, arises when one or more of g, ⋯, g is already  <dig>  in this case we skip over the existing  <dig> values and continue to convert the next available 1s into 0s, until a total of a 1s have been converted, or a collision of the second type is encountered.

• the second type of collision, blocking collision, arises when one or more of h, ⋯, h  is already  <dig>  in this case, further conversions of 1s to 0s are blocked, starting with the first g for which h =  <dig> 

skippable collisions are a natural way to model the excision process, since deletion of duplicates and the subsequent rejoining of the dna directly before and directly after the excised fragment means that this fragment is no longer "visible" to the deletion process. observationally, however, we know deletion has occurred because we have access to the sequence h, which retains copies of the deleted terms. blocking collisions are a natural way of modeling the constraint against deleting single-copy genes.

when the deletion event has to skip over previous 0s, this hides the anchor i and length a of previous deletion events. denote by r the random variable indicating the total number of deletion events responsible for a run. then, given r = r, the run length z is distributed as the sum of r geometric variables, which would result in a negative binomial distribution were these geometric variables independent. they are not, however, since events with large a tend to group together in runs with large r, while an event with small a is more likely to constitute by itself a run with r =  <dig>  <cit> .

if we observe g at some point in time, as in the last pair of rows of table  <dig>  all we can observe are the run lengths of 0s and 1s. we cannot observe the a, i or r, while t and λ are unknown and, as we shall see, only mathematical conveniences that are supplanted by θ in our calculations. the parameters about which we wish to make statistical inferences are the deletion length distribution parameter μ, and the fractionation bias ϕ since it is these quantities that are at the heart of the biological controversies about paralog reduction. this inference can only be based on the two observable quantities: the run lengths l and the proportion θ of remaining  1s.

i
a
r
five deletion events affecting two homeologous chromosomes, leading to two runs of single-copy genes. the fourth step illustrates the "skip" process, at i =  <dig> where the pre-existing deletion is incorporated into a longer run with r =  <dig>  the fifth step shows how further deletion  and the "skip" process  are blocked when a single-copy gene is encountered  on the homeologous chromosome. this creates a single-copy run with length l =  <dig> and r =  <dig>  part on one chromosome, part on the other. note that r is not observable from the genome data.

RESULTS
simulations to determine π
we carried out simulations on an interval of ℤ of length  <dig> . this enabled us to use a discrete time process instead of the continuous time process on ℤ. the "anchors" for the deletion events were chosen at random among the currently undeleted genes. the remaining steps were carried out as described in the previous section and table  <dig>  because each simulation run samples thousands of deletions, it sufficed to do  <dig> runs for each value of the parameters μ and ϕ studied.

the top row of figure  <dig> compares π when θ =  <dig>  and θ =  <dig>  for μ =  <dig>   <dig>   <dig>  and  <dig>  when ϕ =  <dig> . we can see that the number of deletion events contributing to a run is somewhat dependent on μ when half of the the sequence has been deleted, but is strongly dependent when 90% has been deleted. in the bottom row, the graph on the left shows that run length l is distributed very differently for μ =  <dig>   <dig>   <dig> and μ =  <dig>  when the proportion of the sequence deleted is exactly the same. this strongly suggests that observing the run length distribution and the overall proportion of deletions should allow us to infer μ. moreover the shape of these distributions is sensitive to ϕ.

we mention that any edge effects in our simulation are negligible. whether we work with g and h on an interval of ℤ of length  <dig>  or, as previously  <cit> , length  <dig> , gives virtually the same results.

a recurrence for π
we are interested in inferring μ from the observed distribution of run lengths and the proportion θ of undeleted terms, i.e., undeleted genes. at the outset θ =  <dig>  as t → ∞, θ →  <dig>  we are not, however, interested in t, since it is not observable and any time-based inference we can make about μ will depend only on run lengths and θ in any case. on the other hand, r, the number of deletion events per run is an interesting variable since we can assume run length is close to rμ on average, at least for small values of θ, and we can model the evolution of r directly we consider the distribution π as a function of μ, ϕ and θ.

as π changes, probability weight is redistributed among several types of run:

 <dig>  new runs  falling completely within an existing run of undeleted terms, not touching the preceding or following run of deleted terms, type a in figure  <dig> 

 <dig>  runs that touch, overlap or entirely engulf exactly one previous run of deleted terms with r ≥  <dig>  thus lengthening that run to r +  <dig> events, types b and c in figure  <dig> 

 <dig>  runs that touch, overlap or engulf, by the skipping process, two previous runs of r <dig> and r <dig> events respectively, creating a new run of r <dig> + r <dig> +  <dig> events, and diminishing the total number of runs by  <dig>  including types d and e in figure  <dig> 

 <dig>  runs that touch, overlap or engulf, by the skipping process, k >  <dig> previous runs of of r <dig>  ⋯, rk events respectively, creating a new run of r <dig> + ⋯ + rk +  <dig> events, and diminishing the total number of runs by k -  <dig>  not illustrated in figure  <dig>  case  <dig> above may be considered a special case of this for k =  <dig> and case  <dig> for k =  <dig> 

the first process, involving a deletion event of length a requires a run of undeleted terms of at least a +  <dig>  what can we say about runs of undeleted terms? we know that runs of deleted terms alternate with runs of undeleted terms, so that there is one run of the former for each of the latter. the mean lengths  and v¯ of the deleted runs and the undeleted runs, respectively, should satisfy:

  v¯=θ1-θū. 

the distribution ρ of lengths of the undeleted runs is assumed to be geometric. similarly the lengths of successive undeleted runs  are assumed to be independent. while we do not have a rigorous proof of these assumptions, they have been confirmed by extensive simulations.

let ϕ <dig> and ϕ <dig> be the proportion of deletion events affecting homeologous chromosomes  <dig> and  <dig>  respectively, so that ϕ <dig> + ϕ <dig> =  <dig>  let τ be the proportion of runs of single-copy genes with terms in both chromosomes.  ≡  <dig> and, initially, τ =  <dig> for r =  <dig>   <dig>  ⋯.) note that in such a run, the term at the extreme left were  deleted from chromosome i with probability ϕi and the same for the terms at the extreme right.

the proportion of undeleted terms in runs of length l is lρ/eρ, where eρ = ∑l> <dig> lρ. as depicted in figure  <dig>  the probabilities pa <dig> and pa <dig> that a deletion event affects chromosomes  <dig> or  <dig>  respectively, and falls within a run of undeleted terms of length l without deleting the terms at either end is, for i ∈ { <dig>  2}

  pai=ϕi ∑l>2lρeρ ∑j-2l-11l∑a=1l-jγ=ϕieρ ∑l>2ρ∑j=2l-1∑a=1l-jγ=ϕieρ ∑l>2ρ∑a=1l-2γ 

where j indexes the starting position of the deletion within the run, and a is the number of terms deleted in the event. we define the contribution to mean run length of a events to be

  μa= ∑i=12ϕieρ ∑l>2ρ∑a=1l-2γa. 

events of type ai create runs of deleted terms with r =  <dig> from one chromosome only. note that the last line of equation , and equation , involve the collection of terms, reducing the number of nested summations in order to speed up calculation. while these are not lengthy calculations to start with, we display the speed-up as a simple illustration of the important efficiencies implemented for more difficult cases to be treated below.

the probability pbif that a deletion event on chromosome i touches only the run of deletions on chromosome f on the left of the run of undeleted terms is, for i ∈ { <dig>  2} and f ∈ { <dig>  2},

  pbif=ϕiϕfeρ ∑l>1ρ∑a=1l-1γ. 

we define the contribution to mean run length of b events to be

  μb= ∑i=12∑f=12ϕiϕfeρ ∑l>1ρ∑a=1l-1γa. 

events of type bii turn a deleted run with r events from one chromosome, into a run with r +  <dig> events. events of type bif, with i ≠ f, turn a deleted run with r events, into a run with r +  <dig> events.

the probability pcii that a deletion event, on either chromosome, does not touch the run of deletions on the left, does touch or overlap the run of deletions on the right entirely on the same chromosome , but does not extend over the entire run of undeleted terms beyond that is, for i ∈ { <dig>  2}:

  pcii=ϕi2eρ ∑l>1∑k≥1ρρ∑j=2l∑a=l-j+1l-j+kγ=ϕi2eρ ∑l>1∑k≥1ρρ×∑a=1minaγ+∑a=minmaxminγ+∑a=maxl+k-2γ. 

we define the contribution to mean run length of cii events to be

  μcii= ∑i=12ϕi2eρ ∑l>1∑k>1ρρ∑j=2l∑a=1-j+1l-j+kγa, 

which can be calculated using an expansion such as that in . events of type cii turn a deleted run with r events from one chromosome, into a run with r +  <dig> events.

the probability pcif that a deletion event, on either chromosome, does not touch the run of deletions on the left but does touch the run of deletions on the right, partly or entirely on the other chromosome, is, for i ≠ f ∈ { <dig>  2}:

  pcif=ϕiτ+ϕiϕfeρ ∑l>1ρ∑j=2l∑a=l-j+1∞γ. 

we define the contribution to mean run length of cif events to be

  μcif= ∑i≠f=12ϕiτ+ϕiϕfeρ ∑l>1ρ∑j=2l∑a=l-j+1∞γ. 

events of type cif, with i ≠ f, turn a deleted run with r events, into a run with r +  <dig> events. note that  does not contains terms of form aγ as do , since in this event deletion is blocked beyond the existing run of deletions; the probability weight is thus concentrated on deletions of lesser length.

the probability pdiii that a deletion event completely overlaps the run of deletions on the right and touches or overlaps the run of deletions beyond that, all on the same chromosome, but does not extend over a further run of undeleted terms:

  pdiii=ϕi32eρ ∑l>1∑k≥1∑h≥1ρρρ∑j=2l∑a=l-j+k+1l-j+k+hγ=ϕi32eρ ∑l>1∑k≥1∑h≥1ρρρ×∑a=k+1minγ+∑a=minmaxminγ+∑a=maxl+k+h-2γ  

in which the reduction of the number of nested summations is key to the computability of the entire calculation.

we define the contribution to mean run length of diii events to be

  μdiii=ϕi32eρ ∑l>1∑k≥1∑h≥1ρρρ∑j=2l∑a=1-j+k+1l-j+k+hγa, 

which can be calculated using an expansion such as that in . events of type diii turn two deleted runs with r and s events, respectively, both from the same chromosome, into a run with r + s +  <dig> events.

the probability pdiif that a deletion event completely overlaps the run of deletions on the right, on the same chromosome, and touches the run of deletions beyond that, partly or entirely on the other chromosome, is:

  pdiif=ϕi2τ+ϕi2ϕf2eρ ∑l>1∑k≥1ρρ∑j=2l∑a=l-j+k+1∞γ. 

and the contribution to mean run length is

  μdiif=ϕi2τ+ϕi2ϕf2eρ ∑l>1∑k≥1ρρ∑j=2l∑a=l-j+k+1∞γ. 

events of type diif, with i ≠ f, turn two deleted runs with r and s events, respectively, with the latter containing terms from both chromosomes, into a single run with r + s +  <dig> events.

the probability peiii that a deletion event touches the run of deletions on the left of the run of undeleted terms and touches or overlaps the run of deletions on the right, all on the same chromosome, but does not extend over the entire run of undeleted terms beyond that is:

  peiii=ϕi3eρ ∑l≥1∑k≥1ρρ∑a=1l+k-1γ, 

where

  μeiii=ϕi3eρ ∑l≥1∑k≥1ρρ∑a=ll+k-1γa. 

the probability peiif that a deletion event touches the run of deletions on the left of the run of undeleted terms, both from the same chromosome, and touches the run of deletions on the right, partly or entirely on the other chromosome, is:

  peiif=ϕi2τ+ϕi2ϕfeρ ∑l≥1ρ∑a=l∞γ 

and

  μeiif=ϕi2τ+ϕi2ϕfeρ ∑l≥1ρl∑a=l∞γ. 

the probability peiii that a deletion event touches the run of deletions on the left of the run of undeleted terms and touches or overlaps the run of deletions on the right, all on the same chromosome, but does not extend over the entire run of undeleted terms beyond that is:

  peifi=ϕi2ϕfeρ ∑l≥1∑k≥1ρρ∑a=ll+k-1γ 

and

  μeifi=ϕi2ϕfeρ ∑l≥1∑k≥1ρρ∑a=ll+k=1γa 

the probability peiff that a deletion event touches the run of deletions on the left of the run of undeleted terms and touches or overlaps the run of deletions on the right, all on the same chromosome, but does not extend over the entire run of undeleted terms beyond that is:

  peiff=ϕiϕfτ+ϕiϕf2eρ ∑l≥1ρ∑a=l∞γ 

and

  μeiff=ϕiϕfτ+ϕiϕf2eρ ∑l≥1ρl∑a=l∞γ 

events of type eiii turn two deleted runs with r and s events, respectively, all from one chromosome, into a single run with r + s +  <dig> events. events of type eiif, eifi and eiff,, with i ≠ f, turn two deleted runs with r and s events, respectively, into a single run with r + s +  <dig> events.

we reiterate here that the last lines of each of , and  include the collection of terms, significantly cutting down on computing time when these formulae are implemented, especially in the case of .

in this initial model, we neglect the merger of three or more runs of deletions. there is no conceptual difficulty in including three or more mergers, but the proliferation of embedded summations would require excessive computation. thus we should expect the model to be adequate until θ gets very small, when mergers of several runs at a time become common.

let pa=pa1+pa <dig>  and similarly let each of pb, ⋯, pe be the sums of their respective subscripted terms . we define the change δπ in the number of runs of deleted terms with r =  <dig>   <dig>  ....

  δπ=pa-π. 

  δπ=π-π. 

for r >  <dig> 

  δπ=π+∑s=1r-2ππ-π. 

in an implementation on a finite interval of ℤ, the number of runs of deleted terms will change from some value r to r', where

  r′=r+ ∑r=1∞δπ. 

the distribution of number of events per run will also change from π to π', where

  π′=rπ+δπr′, 

and where the mean of the number of deleted genes per run increases from  to ū′, so that

  ū′=rū+ ∑x=a,b,c.,d.,e.μxr′. 

the mean v¯′ of the new distribution ρ' of run lengths of undeleted terms satisfies

  v¯′=rr′-ū′. 

the new proportion θ' of undeleted terms is v¯′∕.

in the same interval of ℤ, we define the change δτ in the number of runs containing single copy genes in both chromosomes with r =  <dig>   <dig>  ....

  δτ= <dig>  

  δτ=π-πτ. 

for r >  <dig> 

  δτ=πτ+π)+∑s=1r-2ππ)-τπ. 

in the implementation, the number of runs of deleted terms with genes on both chromosomes will change from t to t', where

  t′=t+δτ. 

the proportions of runs with deletion events from both chromosomes will also change from τ to τ', where

  τ′=t′r′π′. 

we implement equations  to  as a recurrence with a step size parameter Λ to control the number of events using the same pa, pb, pc, pd, pe, δπ and δτ between successive normalizations, and using Λδπ and Λδτ instead of δπ and δτ in -. the choice of Λ determines the trade-off between computing speed and accuracy.

biased fractionation with large deletion sizes leads to slow initial growth in the proportions of events of types d and e and "other".

there are at least two reasons for the discrepancies between the simulations and the recurrences observed in figure  <dig>  at the outset, since we used a large step size Λ for the computationally costly recurrence, its trajectory lags behind the simulation, especially with respect to the slower decrease in pa and slower increase in pb + pc. later discrepancies are partially due to not accounting for the merger of three or more runs. these can be estimated and are summarized as "other " in the diagram, but the quantities involved are not fed back to the recurrence through .

other possible sources of error might be due to the cutoffs in x used for calculations involving γ and ρ. however, extensive testing of various cutoff values has indicated such errors to be negligible in our implementation.

CONCLUSIONS
we have developed a model for the fractionation process based on deletion events excising a geometrically-distributed number of contiguous paralogs from either one of a pair of homeologous chromosomes. the existence of data prompting this model is due to a functional biological constraint against deleting both copies of a duplicate pair of genes.

the mathematical framework we propose should eventually serve for testing the geometric excision hypothesis against alternatives such as single gene-by-gene inactivations, although we have not developed this in this paper. in addition, further developments could treat the gene-by-gene inactivation model as the null hypothesis, and the geometric excision model, with mean greater than  <dig>  as the alternative hypothesis.

simulations of these models indicate the feasibility of estimating the mean μ of the deletion event process and the fractionation bias ϕ from observations of the length of runs of single-copy genes and the overall proportion of single-copy genes.

the main question we have explored is the exact derivation of π, the distribution of the number of deletion events contributing to a run of single-copy genes. the simulations are convenient in practice, since they depend on only the parameters μ and ϕ as they evolve over time, but they give little mathematical insight. our most important advance is a deterministic recurrence for the π as the proportion θ of undeleted genes decreases. this takes into account the appearance of new runs over time, the lengthening of existing runs, as well as the merger of two existing runs with the new deletions to form a single, longer one. this calculation fits the process as simulated rather well and seems promising for further development.

in order to validate our fractionation model empirically, we will have to expand it to incorporate the rearrangement events that are pervasive in genome evolution. our previous work on this problem shows that the effect of rearrangement is to seriously bias the observable, credible instances of fractionation towards smaller runs of deleted genes  <cit> . future work on this difficult problem will have either to rely on careful modeling of this ascertainment bias or else find a way to incorporate into the model deleted runs that have been interrupted by rearrangements.

competing interests
the authors declare that they have no competing interests.

authors' contributions
ds, cz and bw formulated the problem, carried out the calculations and simulations, and wrote the paper. all authors read and approved the final manuscript.

