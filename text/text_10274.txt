BACKGROUND
new genomic technologies allow researchers to determine dna sequences of organisms existing as communities across different environments  <cit> ,  <cit> . the collective sequencing of organisms without culturing and cloning each organism individually is known as "metagenomics". metagenome samples consist of several dna sequences originating from all organisms in the examined environment. through metagenomics, it is possible to study the vast majority of microbes on earth and systematically investigating, classifying, and manipulating the entire genetic material extracted directly from environmental samples. metagenomics enables scientists to conduct a survey of different microorganisms present in a specific environment, such as water, soil and human body  <cit> . by comprehensive study of nucleotide sequence, structure, regulation, and biological functions within the community, the roles played by microbial communities can potentially be examined.

however, sequencing technologies do not provide the whole genome of different co-existing organisms, but produce short contiguous subsequences called sequence reads from random positions of the entire genome. one of the grand challenges in the study of metagenome data involves reconstructing the different microbial genomes from a mixture of sequence reads. this is referred to as the metagenome assembly problem. due to the high species complexity and the short length of sequencing reads from current sequencing technologies, the genome reconstruction goal becomes more difficult to attain if not impossible. also within a community, microbes  vary in abundance, diversity, complexity, genome lengths and may have not been individually sequenced before. likewise, the current sequencing technologies produce large volume of sequence reads, and reads that may have varying error idiosyncracies  <cit> . as such,the metagenome assembly problem is complex and challenging  <cit>  and is often subject to further analysis as a collection of short reads.

targeted metagenome or 16s rrna gene sequencing has been widely used for the analysis of genetic diversity estimation, enabling deep views into hundreds of complex microbial communities simultaneously. 16s sequences are marker genes, which exist in most microbial species but have variations in their sequences that allow them to be separated into different taxonomical groups  <cit> . several metagenome analysis projects use sequencing of 16s genes as a first step in estimating the diversity within a sample. various computational methods have been developed for the rapid analysis of large sets of reads obtained from targeted metagenome  or "whole" metagenome studies  <cit> . clustering methods have been developed to compare metagenome samples by grouping similar metagenome sequences into bins  <cit> . other methods use classification techniques to categorize metagenome samples into different phylogenies  <cit> .

in general, two sets of approaches are considered for species diversity estimation in metagenome analysis. the first approach consists of comparative or sequence similarity based methods that rely on homology to separate sequences into different taxonomic levels and classes using annotated database  <cit> . these methods align reads or contigs using global and local sequence alignment algorithms  to identify regions of similarity between sequences  <cit> . the second approach contains unsupervised clustering methods that identify groups of similar sequences within metagenome samples. this grouping of similar sequences is commonly known as "binning" problem. different groups in a particular sample is also referred to as operational taxonomic units  and the number of otus gives an approximation of species diversity in a sample  <cit> . otu-based approaches are not constrained due to the absence of a complete coverage in taxonomic databases. several environmental samples contain microbial organisms that have never been laboratory cultured, and as such do not exist in genomic databases.

the otu assignment can be used to estimate several species diversity estimates such as chao <dig> index  <cit> , shannon diversity index  <cit>  and abundance-based coverage estimator  index  <cit> . these otu assignments and diversity estimates facilitate the process of comparative metagenomics i.e., comparing the genomic content of different community samples. mothur, dotur and esprit are the most widely used methods for otu estimation  <cit> . qiime  <cit>  is an open source software package for otu estimation, taxonomic assignment, statistical analysis and comparison of microbial communities and is primarily used for analyzing high-throughput 16s metagenomic data, generated on a variety of platforms.

one of the purpose of developing clustering methods is to handle the large output of metagenome sequencing projects. we propose a new, scalable metagenomic sequence clustering algorithm  for targeted metagenome sequences  that utilizes an efficient locality sensitive based hashing  function  <cit>  to approximate the pairwise sequence operations. lsh algorithm maps the original dimension of input sequences into reduced dimensional space by randomly choosing subset of sequence positions. lsh-based method is also used by buhler et. al.  <cit>  to detect all pairs of similar segments within long genomes. our lsh-function is enriched to use gapless, subsequences of fixed length , which helps us to reduce the number of false positives and improve cluster quality. the lsh-div algorithm follows a greedy and iterative framework for assigning otus  to each sequence. lsh-div further uses these otu assignment results and introduces standard species richness metrics which bring more explanation to clustering results.

we assess lsh-div algorithm on eight environmental samples and one synthetic sample taken from sea water. these samples contain varying complexities of microbial community which give in-depth representation of microbes in sea water <cit> . our evaluation metrics include quality of otus, species diversity estimation, computational speedup and pairwise sequence similarity of sequences within each otu. we demonstrate that lsh-div is computationally efficient and also produces meaningful and accurate results in comparison to the state-of-the-art otu estimation algorithms. this work is an extension of our previous work on species diversity estimation  <cit>  and clustering  <cit> .

related work
in this section, we briefly explain three state-of-the-art otu estimation algorithms. mothur  <cit>  and dotur  <cit>  use a phylip-formatted pairwise distance matrix  <cit>  for computing the species richness metrics. in esprit  <cit> , the computation is reduced by using k-mer distance between sequences.

mothur and dotur are hierarchical clustering approaches that take as input an all-pairwise similarity/distance matrix. the distance matrix calculated by performaing sequence alignment between every pair of sequences within an input metagenome sample. both approaches support three merge criterion to perform hierarchical clustering given by nearest-neighbor, furthest-neighbor or use of group average. these approaches also use a distance cutoff as an input parameter. this cutoff varaible d, defines the maximum allowable distance between sequences within the final cluster , such that sequences within a given cluster are at most d% distance apart.

dotur reports bio-diversity metrics  with varying distance cutoffs. on the other hand, mothur generates statistics such as count of otus, singletons, doubletons and number of sequences in the largest otu. as a computational expenses, both approaches require memory space for loading the entire all-pairwise distance matrix.

esprit is another sequence clustering algorithm that avoids performing the computationally intensive all-pairwise distance calculation. instead, the algorithm computes a k-mer based distance between pairs of input sequences and achieves computational efficiency. for each sequence, esprit builds a complete genomic alphabet profile of selected k-mer and uses that representation to calculate all pairwise distances  <cit> . in order to reduce further computational complexity, esprit also uses various heuristics. for example, if two sequences are identical or one sequence is a subset of the other sequence, then only longer sequence is kept and the number of occurrence for identical sequences are recorded. this technique reduces the total number of sequences and therefore reduces the time taken by k-mer pairwise distance matrix calculation. using the pairwise input matrix, esprit then performs standard hierarchical clustering.

methods
we present our approach to determine species diversity by estimating otus from 16s rrna metagenome sequences using a locality sensitive hashing  based function. the lsh function reduces the complexity of exact pairwise similarity or sequence alignment. we call our method as lsh-div  and the work flow is described in figure  <dig>  we first review the basic fundamentals of lsh and then discuss the implementation of the lsh-div algorithm.

locality sensitive hashing
we denote  s as the input set of n sequences. a sequence within  s of length n is denoted by s. for each n length sequence, we choose k indices in a random manner. these uniform, random indices are denoted by i <dig>  . . . , ik are used to define a hash function for the sequence s, given by

  hs =si <dig>  si <dig>  . . . , sik 

the hash function h in equation  <dig> extracts a contiguous k-length string from original n-length string s. the hash function, h is responsible for transforming the original 4n-dimensional space to a reduced 4k-dimensional space. the hash function is "locality-sensitive", as the probability of two strings hashing to the same value varies in direct proportion with their pairwsie similarity  <cit> . given two similar strings sx and sy which contain at the most p different nucleotides, the probability of their hash values being identical is given by:

  p≥1-pnk 

where parameter p is the maximum allowable mismatch between the two pairs of strings and p  is the probability which is computed over random choices of the k indices, i <dig>  . . . , ik.

naturally, the lsh-based procedure will lead to either false positives  or false negatives   <cit> . when the two strings, sx and sy are mapped to same hash values even if they are not similar i.e., h = h, then a fp has occured. this is because of the random sampling procedure that chose only those k nucleotide positions that were identical in the two sequences. when the two sequences sx and sy are similar but not exactly same, then a fn can occur when the hash function samples those k indices where the sequences diverge. this leads to h ≠ h even if two sequences are similar in terms of practical purposes. fns can be substantially reduced by iterating the sampling procedure, multiple times. l denotes the parameter for the number of iterations.

in order to improve the hashing mechanism, we use a contiguous fixed-length subsequence , when defining our hash function. instead, of using a single dna alphabet at the randomly chosen index i, we select the a subsequence around the chosen indices. this is shown in figure  <dig>  the w-mer captures local sequential similarities within the sequences and is used in several bioinformatic applications  <cit> . by comparing a contiguous subsequence rather than single nucleotide at different indices, the method produces more accurate hashing function and reduces fps.

algorithm overview
lsh-div parameters
in this section, we describe the parameters of lsh-div algorithm in detail.

number of sampled indices  and subsequence length 
the hash function provides a mapping from the 4n-dimensional space into 4k-dimensional space. using small values for k will lead to small number of partitions, and large number of false positives, since the number of sampled bits or indices will not be enough to disambiguate dissimilar reads.

the use of gapless, subsequence of length w enhances the filtering quality as we compare a w-mer rather than single nucleotide at a given index position. for pairs of strings to hash to the same key value, requires an exact matching of k * w nucleotides. this makes the matching process more stringent and will lead to a reduction in the number of false positives. the selection of k sampled indices along with subsequence length w is shown in figure  <dig> 

number of hash functions or iterations 
the use of multiple hash functions within the lsh-div framework reduces the number of false negatives i.e., two sequences that are similar will have a higher chance of being accepted by our filter due to repeated sampling of k indices. the results of multiple iterations is combined using a union set operation i.e., a pair of strings are considered to be similar, as long as we see the strings hash to the same values in one of the l iterations . however, using large values of l will lead to dissimilar sequences being mapped to the same hash value and will lead to an increased number of false positives. a good choice of l and k allows lsh-div algorithm to produce sensitive partitioning of the sequence data.

percentage of mismatches 
in order to allow for pairs of strings that are not exactly identical, but similar  to pass the lsh-based hamming distance filter, the mismatch factor parameter p is implemented as the percentage of allowable mismatches. when p is set to 0%, the lsh-based function will consider strings to be equivalent if and only if all the k nucleotides or k w-mers are exactly identical in both the strings. as an example, when k is set to  <dig> indices and p is set to 10% mismatch, then pairs of strings that differ by at most  <dig> nucleotides or  <dig> w-mers will be considered equivalent. in our current approach, each w-mer can be considered a symbol. we do not allow for mismatches within a w-mer and is considered as a part of the future directions of this work.

lsh-div details
lsh-div framework consists of different modules such as the hashing module, otu assignment module and application module. the algorithm begins by first generating lsh functions for all the input sequences in set  s. h is defined using the parameters of k and w defined earlier. after computing all the different hash values, the algorithm enters into the otu assignment module.

the assignment process starts by choosing a random sequence sx from set  s and assigns the first otu to that sequence. then for every other sequence sy in set  s, lsh-div performs hamming distance calculation denoted by sim, and computes similarity between using the hash values. using the sim function we assign every sequence sy in the cluster  that differs from sx by a few fraction of nucleotides. exactly similar strings are be accepted by the hashing function. sequences, once assigned are removed from the set  s. we repeat the above assiged procedure for assigning otu labels to all the sequences in the input. to improve the performance of lsh-div, whole otu assignment module is repeated l times. a new lsh function is created for every iteration. finally, a union operation is performed on the otu assignments obtained on each successive iterations.

previous approaches  have are computationally intensive and need a computation of all-pairs of sequence distances for otu/cluster assignment. in comparison, the lsh-div algorithm does not require all pairwise distances computation for otu assignment.

computation of pairwise distance cut-offs
an input parameter that is implemented in all diversity estimation approaches includes the distance cutoff parameter. the cutoff parameter provides a maximum allowable distance between all sequences within an otu. as an example a distance cutoff of  <dig>  implies that a sequence within an otu is at the most 5% distant from every other sequence within the same otu. for lsh-div, we first generate the otu assignments for each sequence. we then compute all pairwise distances  between all pairs of sequences within the otu. we then report the maximum pairwise distance computed, which allows for validation of the distance cutoff parameter. this procedure allows us to compare our approach to mothur and dotur, both of which use the alignment distance cutoff and esprit, which uses the k-mer distance cutoff.

RESULTS
in this section we report on a thorough set of experimetal results. we evaluate lsh-div on several metrics. specifically, we assess the performance of lsh-div algorithm with respect to the number of otus, different species diversity metrics and run time. we also perform comparative evaluation.

synthetic dataset
to formalize the accuracy and completeness of the lsh-div algorithm, we evaluate the performance of our method on a synthetic dataset. we would like to assess whether lsh-div was able to correctly estimate the numbers of otus within an input sample. since, the synthetic dataset was simulated from  <dig> species-specific gene sequences,  <dig> was considered to be the ground truth. figure  <dig> shows the number of otus at various distance cutoff levels for lsh-div. we use two synthetic datasets that were simulated to have reads with less than 3% and 5% errors. we observe that lsh-div efficiently converges towards the ground truth. lsh-div correctly estimates the number of otus  at a 4% distance cutoff for the reads that were simulated with a 3% error rate.

environmental samples
in table  <dig>  we present the diversity estimation results for lsh-div algorithm on the eight environmental samples. we vary the global alignment cutoff distance and show different diversity estimation metrics for cutoffs at  <dig> ,  <dig>  and  <dig> .

hi
several species diversity metrics and number of otus produced by lsh-div algorithm on samples taken from sogin et. al.  <cit> . the experiment uses three otu definitions  <dig> ,  <dig> , and  <dig>  which define the cutoff levels in distance units. otu denotes the number of otus observed, chao <dig> denotes the chao <dig> estimate, h´ denotes the shannon diversity index and ace denotes the abundance-based coverage estimator. the parameter setting used by lsh-div algorithm to obtain these results is k =  <dig>  w-mer =  <dig> 

runtime performance
evaluation of esprit on global alignment pairwise distance
previous results have shown that esprit underestimates the different diversity metrics. to identify the reason, we setup an experiment to assess the results produced by lsh-div and esprit using different distance functions for defining the cutoff parameter. specifically, we implemented the k-mer distance cutoff  to estimate the otus for different inputs varying from  <dig>  to  <dig> . for the validation purpose, we first compute the maximum pairwise global alignment distance for each otu produced by esprit and report as the final result, the maximum score obtained across all the different otu assignments. we also report the validation results by computing the maximum pairwise k-mer distance and the global alignment distances for each otu, produced by lsh-div. these results are reported in table  <dig>  we see that esprit fails to meet the global alignment distance-based cutoff criterion whereas lsh-div satisfies the global aignment distance based cutoff criterion. a similar observation regarding esprit's performance was made in the study by schloss  <cit> .

the results produced by esprit using k-mer distance is assessed on needleman-wunsch  global alignment distance. the results generated by lsh-div is evaluated on esprit's generated k-mer distance and nw distance. the parameter setting used by lsh-div algorithm to obtain these results is k =  <dig>  w-mer =  <dig> 

parameter analysis
we performed an experiment to further reduce the run time of lsh-div algorithm and maintain the quality of otu estimates. this was done by reducing the number of sampled indices , and increasing the w-mer size, and thus maintaining the total coverage of the observed sequence. figure  <dig> shows the otu estimates for different parameter settings on 112r sample. exact match  shows the baseline result when all the sampled bits are used for estimation. we can observe that for several parameter combinations, equivalent otu quality results are produced.

we also notice that by using half the sampled indices  in comparison to exact match , with w-mer size of  <dig>  we produce the same diversity estimates. for these parameter settings, we observe a  <dig>  times reduction in the run time. figure  <dig> shows the run time of lsh-div with respect to varying k and w-mer parameters for sample 112r.

significance and impact
metagenome projects aim to determine the species similarity and diversity across different ecological samples. we use our algorithm to provide an enriched analysis of the variation of microbial species across different skin locations . this dataset contains  <dig>  near-full-length 16s rrna sequences sampled across  <dig> different skin locations, from ten healthy human controls. these skin sites were selected because they show a predisposition for bacterial infections. the skin sites are categorized as:  sebaceous or oily,  moist  and  dry, flat surfaces. as given by grice et. al.  <cit> , the sebaceous sites include locations like glabella , alar crease , external auditory canal , retroauricular crease , occiput , manubrium  and back. moist sites include the nare , auxiliary vault , antecubital fossa , interdigital web space , inguinal crease , gluteal crease , popliteal fossa , plantar heel , toe web space and umbilicus . dry sites include the volar forearm , hypothenar palm  and buttock. we use the information about skin locations and "genera" as ground truth in our study. the sequence lengths varied from  <dig> to  <dig> nucelotides .

clustering of metagenome sequences  tends to group sequences that are closely related in the taxonomy/phylogenetic tree  together. using the lsh-div algorithm, we cluster all the metagenome sequences. sequences in this dataset are taken from different skin locations where each skin location is a metagenome sample i.e., genomic sequences of microbes co-existing on the specific skin locations. after binning sequences across all the skin locations, each sequence is associated with one of the otu labels. using the otu label as features for a skin location, we compute the jaccard index between all pairs of skin locations. jaccard index measures the proportion of shared clustering labels  between the pair of skin locations. a higher index value indicates that the two skin locations are more similar to each other.

CONCLUSIONS
we developed an efficient and accurate species diversity estimation algorthm referred to as lsh-div. the key features of our algorithm include the use of a randomized, locality-sensite hashing approach that reduces the complexity of computing expensive global alignments across all pairs of input sequences. the algorithm also incorporates the use of w-mers that reduces the number of false positives, and does not increase the run time but leads to better otu estimation results. lsh-div was evaluated on synthetic datasets, real world datatsets and after a thorough study, we were able to demontrate that lsh-div is computationally efficient in comparison to the best otu estimation algorithms. it also reports the key diversity estimation metrics that are widely used by different biologists. the lsh-div code is written in python programming language and is available publicly with the gnu gpl license.

materials and implementation
in this section, we describe the datasets and species richness metrics used in the experiments.

dataset description
lsh-div was assessed on both synthetic and real environmental 16s rrna metagenome samples. the synthetic data was obtained from a previous study conducted in  <cit> . the synthetic dataset had a total of 345k sequence reads and the reads were generated from forty-three known 16s marker gene sequences. more details about the dataset can be found in  <cit> .

the eight seawater-based metagenome samples were taken from sogin et. al.  <cit> . these samples use the 454-based sequencing technology to provide a global in-depth description on the diversity of microbes and their relative abundance in seawater. the description of the samples are given in  <cit> . the mean length of sequence reads within thesese samples was found to be  <dig> bp.

we also use a real environmental skin dataset to show the application and significance of lsh-div algorithm. the dataset covers  <dig> different skin locations represented by 16s rrna sequences samples. the total number of sequences is  <dig>  with an average length of  <dig> bp.

species richness estimation metrics
chao <dig> index
chao <dig> index  <cit>  is based on the number of otus with an individual sequence called "singletons" and the number of otus containing a pair of sequences is called "doubletons". the chao <dig> estimate is given by:

  schao1=sobs+n <dig>  

where sobs is the number of observed species , n <dig> is the number of otus with only one sequence and n <dig> is the number of otus with only two sequences.

shannon diversity
shannon diversity index  <cit>  uses the number of sequences in each otu and the total number of sequences in the community for calculation.

  h′=-∑i=1sobsninlnnin, 

where sobs is the number of observed otus, ni = the number of sequences in otu i and n is the total number of sequences in the sample. we denote shannon index as h′ in this paper.

ace index
abundance-based coverage estimator  index  <cit>  is based on an "abund" threshold which sets a limit on the number of assigned sequences in an otu. the number of otus with "abund" or fewer sequences are referred to as rare otus. the default value for "abund" threshold is set to  <dig> for every method. the equations for ace estimate is given by

  nrare= ∑i=1abundini 

  cace=1-n1nrare 

  γace2=maxsrarecace∑i=1abundininrare- <dig>  

  sace=sabund+srarecace+n1caceγace <dig>  

where ni is the number of otus with i assigned sequences, srare is the number of otus with  <dig> or fewer assigned sequences and sabund is the number of otus with more than  <dig> assigned sequences.

the results produced by lsh-div can also be used to compute other richness metrics. also, the rarely occurrent otus can be compared against annotated databases in order to identify new species.

hardware and software details
the lsh-div algorithm is available on the supplementary website. it is written using the python programming language. for experimental evaluation, a single desktop was used. the workstation had 6gb ram memory witn an intel-i <dig>  <dig>  ghz processor. the competing approaches were all run on the same machine using executables provided by the authors of respective software.

competing interests
the authors declare that they have no competing interests.

authors' contributions
zr, hr and db developed the algorithm details. zr and hr wrote the code. zr performed the experimental evaluation. all authors read the manuscript.

