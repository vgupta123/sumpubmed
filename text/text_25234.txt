BACKGROUND
biological databases are key computational tools used daily by biologists. such a large number of biological databases have been developed for biology that the nucleic acids research journal has published an annual database issue since  <dig>  from the point of view of the user, these resources are most useful when they are regularly updated and when they provide user-friendly ways to browse, search and view information. these user needs are generally recognized as important requirements by the designers and developers of biological databases. to cope with these requirements, bioinformaticians who develop the biological databases have typically responded by developing increasingly customized software to manage the data and the information . in doing so, and to facilitate the software development effort needed to create a biological database, bioinformaticians have used a variety of information technologies. these technologies range from the ones that make it possible to create dynamic web applications , to technologies needed to store the data and the information in a persistent manner .

in this article, we report on our experience with the java data objects persistence technology and take a critical view at the advantages and drawbacks of this emerging java persistence standard for the development of advanced biological databases. we have ported the sigpath information management system  to the jdo api and have defined an application-specific benchmark. we used this benchmark to evaluate the performance of two jdo implementations that target either a relational or an object database backend. this article summarizes the performance results that we obtained, announces the availability of the sigpath jdo benchmark , and identifies areas where the jdo api could be refined to facilitate portability and scalability of applications.

data persistence
biological databases are built with software that executes on computers. most biological databases are of a size that could fit entirely in the central memory of modern computers. however, because computers may need to be shutdown for maintenance – or may crash inadvertently – data for a given database cannot be kept in computer memory for the life of a biological database. this problem is not specific to biological databases so that a variety of data persistence approaches and technologies are available. the key role of these technologies is to guarantee that data persists safely between the invocations of the programs that may modify the data.

the pros and cons- of persistence technologies for biological databases
data can be stored in text files with limited structure and important information can be stored in unstructured text files expressed in english. unstructured flat-files do not help perform large-scale analyses, structured queries or integrate data across multiple sources, all of which are important requirements for biological databases. therefore, unstructured files are now widely recognized throughout the field as inadequate for the management of biological information.

highly structured data formats, such as asn. <dig>  <cit>  and more recently xml, are a more favored alternative. they can support structured queries, large scale analyses and data federation. structured file formats, however, do not provide support for concurrent manipulation of the information by several users . as such, they are adequate for data exchange among systems, but not for concurrent access. since the file format offers no support for synchronization, locking or complex domain-dependent data validation rules , using structured data formats for biological information storage forces system developers to implement these services explicitly as a layer between the business code and the data storage. for instance, since xml schemas are not capable of validating xml data with respect to information outside of the scope of the file being validated , developers must implement custom validation code. xml schema focus on syntactic validation, while most applications require semantic validation  <cit> .

database management systems  have been historically developed to abstract the services  needed by systems that need to support large number of users accessing a shared storage of data. a few types of dbms exist that differ in the way they represent data. relational dbms represent data as tables that contain rows and columns of various types, while object dbms support the concept of object classes and object instances directly.

relational dbms such as postgres, mysql or oracle have been used to store biological information in many laboratories, including ours  <cit> . a short introduction to using rdbms for biological information storage was recently offered in  <cit> . briefly, complex relationships among elements of information are stored in relational databases by expressing relations among records in several tables. the technology is useful for a variety of biological databases, where the mapping between the biological data and the relational data model is simple.

however, the technology has two major drawbacks for advanced biological databases. the first problem is because of a mismatch between the object-oriented programming style and the relational data model. advanced biological databases often require programs that manipulate tens or hundreds of object classes. data in the instances of these classes needs to be made persistent, and this requires writing mapping code. the mapping code takes a graph of objects and transfers the data in this graph into records in the various tables of the relational database. mapping code needs to be developed for the reciprocal operation, from the relational records to the object instance graph. depending on the complexity of the relationships among objects in the graph, the development of the mapping code may represent a significant part of the code developed for the overall database.

object dbms such as o <dig>  <cit>  and fastobjects have been developed to eliminate the need to write mapping code, and to store objects directly in native form in the database. this approach was reported to offer substantial performance improvements and reduced development and maintenance costs for data organized in an object graph with complex relationships.

java data objects technology
the java data objects technology  is a java application programming interface . this api was developed as a java specification request  <cit>  to offer: "a standard way to store java objects persistently in transactional data stores..., a standard way to treat relational database data as java objects, and a standard way to define transactional semantics associated with those objects."

jdo appears as an attractive technology for the development of biological databases for the following main reasons:

 <dig>  it is designed to offer portability across a wide range of transactional stores or database backends, from open-source relational databases to native object oriented databases.

 <dig>  it transparently handles object persistence when relational or object persistence backends are used .

 <dig>  jdo also handles persistence transparently for object oriented databases, where mapping code is not needed.

 <dig>  it is a java technology that integrates seamlessly with web application servers  often used to create the web front-ends of a biological database.

a critical evaluation of the jdo technology
given the stated advantages of the technology we decided to carry out a critical evaluation of jdo to determine if the technology can routinely be used for the development of advanced biological databases. our evaluation focused on the following questions:

portability: is jdo a mature api that can guarantee portability of the application across database backends?

performance: if portability is achieved, how do relational and pure object oriented backends compare in term of performance?

biological database specific requirements: do complex biological databases have specific requirements that jdo  <dig> . <dig> does not address?

to answer these questions, we have ported a biological information management system  to the jdo  <dig> . <dig> api. . in the first step of the port, we compiled the new code with the fastobjects jdo implementation  <cit>  fastobjects jdo is an implementation of the jdo api that connects to the native fastobjects object database. in a second step, we have adapted the existing code to support exchanging the jdo implementation and database backend between the fastobjects implementation and the solarmetric kodo implementation of jdo  <cit> . kodo is an implementation of jdo  <dig> . <dig> that connects to a variety of relational database backends. the aim of the second development was to modify the code to make it possible to switch from fastobjects jdo to kodo jdo by changing a configuration property, and then simply recompiling. our aim was to create a code-base that was fully portable from a relational database backend to an object-oriented database backend to address the portability question.

the sigpath information management system
sigpath is an open-source project aimed to develop an information management system  to foster modeling and simulation of cell signaling pathways and networks   <cit> . the sigpath ims appears to the end-user as a web application that provides search, browsing and visualization capabilities. the project home page provides tutorials that explain how the system is typically used.

most traditional biological databases focus on one type of database entry  and store information in database entries. this approach has been very useful to create detailed catalogs of biological parts and is a critical and essential element of the bioinformatics resources that support modern biological research. however, certain integrative studies, such as systems biology and modeling and simulation of biochemical pathways call for databases that integrate several types of information.

the sigpath ims is an example of an advanced biological database that encodes information through a number of information types and a set of relationships among them. figure  <dig> illustrates how sigpath encodes information about a biochemical reaction: the reaction is represented as a graph of object instances.

introduction to the sigpath ontology/database schema
a fragment of the sigpath ontology is given on figure  <dig> as a uml diagram. the description of the complete set of persistent classes used in sigpath is given on the project web site .

the sigpath system supports several types of biological information, ranging from information to represent small molecules and proteins to the interactions between these molecules. the main information types supported by sigpath are listed on table  <dig>  in sigpath, information is represented in an object-oriented manner, with information types often associated with classes. the sigpath object-oriented database schema was adapted from the ecocyc ontology  <cit> . several classes presented on table  <dig> have an equivalent in the ecocyc ontology. in the rest of this article, we will use the terms ontology and jdo database schema indistinctively, as they represent very similar concepts: a class in the object-oriented schema of sigpath is equivalent to a frame in the ecocyc ontology, and an attribute of an object class is similar to the slot of a frame.

this multiplicity of sigpath information types and the variety of relationships among them makes it important to clearly define what type of information can be represented by the system . this information is formalized in the sigpath ontology. this ontology is implemented in a jdo database schema. . the jdo schema consists of the set of sigpath java classes that are persistent and of meta-data about these classes. meta-data is expressed in jdo files and provides information about the classes that cannot be expressed directly in the java language, for instance, type of the elements for the collection field of the persistent classes. figure  <dig> shows a small jdo file and illustrates the type of information that it provides. a thorough presentation of the structure of jdo files is given in  <cit> , vendor-specific extensions are documented in each jdo implementation.

the sigpath code base has specific characteristic that make it a useful resource for evaluating jdo technology:

• sigpath is an open-source project released under the gpl, so that the benchmark code is freely available for others to study, reproduce our results, or extend the benchmark to other jdo implementations or database backends.

• sigpath is both a web-based application and a batch-oriented application.

• the sigpath code-base includes unit tests  <cit>  that help verify that the application behaves correctly against two different database backends.

• the sigpath system provides varied use cases that exercise different behaviors of the database backend and jdo implementation .

in the next section, we present the methods that we used to evaluate jdo technology for the creation of advanced biological databases.

RESULTS
this section describes the results of the sigpath jdo benchmark and addresses the portability and performance questions described in the introduction.

sigpath: porting from one jdo implementation to another
we modified the fastobjects jdo version of sigpath to compile indifferently with the fastobjects and kodo implementations of jdo. the modifications that we had to make to the project were  modifications to the jdo file,  modifications of the code base and  modification of the code base and application data.

modifications to the jdo file
the kodo enhancer tool performs stricter semantic validations on the jdo files than the fastobjects enhancer. modifications needed to pass the validation tests were:

 <dig>  added persistence-capable-superclass attribute to classes that have a persistence capable superclass. this attribute is optional for fastobjects, which uses java reflection by default, but is strictly required by the kodo implementation .

 <dig>  removed all interfaces from the jdo file. enhancing with kodo failed when interfaces were listed in this file. since fastobjects requires interfaces to be listed as persistent classes, the sigpath build script conditionally includes such statements in the jdo file when fastobjects is configured. the jdo specification does not mention interfaces, so that the behaviour of jdo implementation is left undefined.

 <dig>   replaced references to interfaces with references to implementation  throughout the jdo file.

 <dig>  added collection element types to all persistent collections. fastobjects requires the type to be specified when the collection is used in a query. kodo requires the type to be defined for each collection, otherwise kodo will try to serialize the collection and store it as a binary object. if the persistent class is not serializable, this mechanism will fail. therefore, for this benchmark, we explicitly defined the collection types for each collection.

 <dig>  removed field definitions from sub-classes when they refer to fields of a super-class. . removing these duplicate declarations is consistent with the jdo specification.

furthermore, the kodo enhancer expects classes to be listed in the jdo file in a specific order. the enhancer fails if a class appears in the jdo file before another class that the first class references. therefore, we reordered the class definitions in the jdo file. .

finally, we added kodo extensions to the jdo file to create indexes on the tables that were used extensively in queries. all changes to the jdo file were consistent with the jdo specification. index tuning was performed by running the boot and test part of the benchmark and the small molecule import with various indexes choices.

modifications to the code base
we modified the code base to work-around a limitation of the kodo implementation. with kodo, instances of classes that contain java.lang.object fields are made persistent with the object field stored as a blob in the database. storing objects as blobs puts strong limitations on their use. for instance, it is impractical to query for these objects by their fields . storing such fields as blobs was therefore not acceptable for certain types of persistence objects, and we implemented the work-around shown on figure  <dig> 

another code modification was required to work-around a problem with the database backend that did not handle appropriately empty strings . the database backend used for this benchmark stored empty strings as null. reading these strings back from the database resulted in null being obtained from kodo instead of empty strings. this resulted in several unexpected nullpointerexception being thrown during the junit tests. figure  <dig> illustrates the approach that we used to work-around this problem.

modification to the code base and benchmark/application data
finally, we had to modify the code base to put a limit on the length of long strings. using a relational database backends imposes to define the maximum length of each string attribute defined in the persistent classes of the application. for instance, a limit must be set on the name attribute of the sigpathentityimpl shown on figure  <dig>  we initially used the default maximum length for all fields and found that certain fields could be longer than this limit when running the test and the benchmark. for instance, description fields of proteinimpl are imported into sigpath from the de line of swissprot and trembl entries. some entries have long descriptions . to test the impact of this limit on the code of the application, we arbitrarily choose to use a maximum length of  <dig>  characters. we excluded from the benchmark input data proteins and small molecules that had aliases or descriptions longer than  <dig>  characters, and other entries that would exceed any string field limit. this was done to make sure that the same input data was used for both the fastobjects and the jdo relational benchmarks.

performance measurements
a brief summary of the performance measurements obtained with the sigpath benchmark is given in table  <dig>  the table presents time measurements for each use case of the benchmark. the measurements are listed both for the fastobjects jdo implementation  and for the kodo implementation. columns marked %fo/kodo indicate the percentage of the time running the benchmark with fastobjects takes compared to running the benchmark with kodo. the last column of the table fo/kodo cv indicates the coefficient of variation of the total time across four independent measurements. small values of cv  indicate consistency between the four measurements. however, some use cases showed higher variations , so we report as well the minimum value of the four time measurements for both fo and kodo .

the raw data used for the calculation of these performance measures is provided in the supplementary material and on the sigpath jdo benchmark pages. these pages also provide the logs from which the raw data has been collected.

discussion
portability
our port of sigpath confirms that jdo greatly facilitates the porting of a bioinformatics application from one database backend to another. however, we report here several modifications that we had to make to the sigpath system to achieve this level of portability. this suggests that there is a need to develop jdo compliance tests that could be used to test that a specific implementation of a jdo-aware database is really compliant with the standard. this test suite would validate that jdo enhancers accept correct jdo files and correctly reject jdo files that break the specification. the differences in the interpretation of jdo files that we noticed between fastobjects and kodo  practically limit the portability of jdo applications. this article has presented techniques that can be used to work around these limitations until a jdo compliance test is developed and used. we note that the work arounds that we described may be specific to the two jdo implementations that we tested, and that other work arounds may be needed to achieve portability with other jdo compliant backends.

surprisingly, we found that an outstanding portability problem is in the way the different jdo back-ends store long strings of characters. while the fastobjects backend put no limitation of the length of long strings, the relational back-end used with kodo limited the length of long strings to  <dig>  characters. this limit had to be chosen and set for each persistent string field used in the application . although  <dig>  characters may appear a large limit, it is likely to be reached in bioinformatics application either with textual or with sequence data. when this happens, the application will have to be re-engineered to work around the fixed limit. a work-around could be to use a data type that does not have a length limitation, but these data types also have other limitations . whichever solution is chosen, this issue must be considered early during the design of the application. it would be useful if the jdo standard offered a mechanism for the application developers to specify which string length their application requires to function properly with jdo backends. each enhancer could then check that the application is requesting a maximum string length that is compatible with the database backend and fail early if it does not. 

performance
the sigpath benchmark provides precise measurements of the performance of one biological database application against two jdo compliant database backends. the measurements were performed on use cases that are typical of the activities needed to develop the code of sigpath and to deploy a production sigpath system. .

as shown in table  <dig>  performance varies widely with the type of use case, but is overall significantly better with the object database backend. use cases that perform batch loading of protein information into the database benefited the most from using the native object database fastobjects backend . an exception to this trend is the sm import use case, which shows only a 3% performance difference. this use case reads an xml file and loads small molecules into the database. to do so, it checks for each molecule that the accession code of the new molecule does not already exist in the database . since the database does not contain small molecules, the query used to perform this check returns an empty set for each molecule of the import. it appears that this specific operation is slower with the object-oriented backend that we have used for the benchmark.

the last column of table  <dig> indicates the coefficient of variation  of the individual measurements . the cv values indicate that the performance of certain steps vary significantly from execution to execution. these differences are likely to be caused by the caching behavior of the database server and of the operating system. caching can occur because we have not restarted the database server between the benchmark runs, or rebooted the machines. these differences may also be caused to a lesser extent by variations in what operating processes were active and the amount of io wait at the time that the specific use case was executed. we have tried to reduce such causes of variability  but have not attempted to eliminate them completely . our rationale is that such variability, including caching, is representative of a typical production system. given the cv, the average execution time may not be an accurate representation for some use cases, so we report also the minimum execution time across the four independent executions of the benchmark.

the benchmark provides an indication of how well an object-oriented database system performs compared to a relational database backend for the sigpath use cases. a known limitation of benchmarks is that the performance measure that they provide are specific to the application tested, and may not generalize well to other use cases. also, the sigpath benchmark does not cover multithreaded/multiclient operations. results may vary depending on the chosen locking strategy and the number of clients/threads running parallel. given these caveats, however, this benchmark indicates that, for most of the sigpath use cases, the performance of the sigpath system is significantly improved when using a native object database system. particularities of the sigpath benchmark that may correlate with this result are  the complexity of the database schema  and  the number of connections that exist among instances of these various classes.

finally, these results and our distribution of the sigpath benchmark source code can help vendors diagnose performance problems with their implementation of the jdo implementation, and provide users with an objective measure of the performance a given jdo implementation, for similar types of applications.

biological database specific requirements
during our evaluation of the jdo technology, we have noted that two common requirements of advanced biological databases are currently not being addressed by jdo.

support for interfaces
when designing a biological database schema, it is often useful to express that one class shares the properties of two or more classes. in a programming language such as c++ this can be represented as multiple inheritance  while in a programming language such as java, this concept is represented with interfaces . in the context of jdo, consider the class diagram shown on figure  <dig>  the diagram illustrates one way to represent the phosphorylated forms of protein and small molecules. on this diagram, one has represented a "phosphorylated" interface which is implemented by phosphoprotein and phosphosmallmolecule. while this way to represent biological information is useful, jdo does currently not specify the handling of interfaces, so that the design shown on figure  <dig> can not be implemented with jdo in a portable way.  the jdo specification should clarify if interfaces must be supported by for a jdo implementation to be compliant with the standard.

support for large number of objects
biological databases often need to manage large number of objects . for instance, sigpath stores information about several hundred of thousands of proteins. we found that jdo  <dig> . <dig> lacks some features that would facilitate writing scalable applications.

an example is that the jdo standard does not provide a scalable way to determine the number of persistent instances of a given class. the jdo compliant way to accomplish this operation is to obtain a reference to a collection of instances of this class , and to call the size() method on this collection. since the collection must first be obtained from the database server before the size() method can be invoked, this procedure takes a time proportional to the number of instances of this class. most database backends store the number of instances of a certain class in the database and can determine this information in a constant time, so a standard way to obtain this information from a jdo implementation would be very helpful .

a second example is that jdo  <dig> . <dig> does not provide support for queries that return large result sets. under standard jdo  <dig> . <dig> behavior, traversing a persistent collection  brings the entire contents of that collection into memory. this behavior is appropriate for small result sets. however, there are cases where the complete set of instances returned by a query cannot be processed within a single transaction. this occurs for instance when all the results returned by a query do not fit in the fixed memory limit allocated to the java virtual machine. in such cases, it may be necessary to obtain the result of a query in chunks of a certain number of records/instances , and process them in independent transactions. upon transaction commit, memory associated with a chunk is released and can be used to process the next chunk. implementing this type of scalable processing in an efficient manner usually requires making modifications both in the persistent class of elements in the result set and in the query filter. the class of the elements in the result set can be modified to add an instance identifier that can be used both to sort the instances and to select only those within the current processing chunk. the query filter can be modified to add a clause that selects only instances of the next chunk, based on the identifier introduced in each element. an alternative is to provide an api call to notify the jdo implementation that instances which have been processed can be evicted from memory. since several vendors already have their own extensions to provide scalability feature, it would be useful for jdo to support such features through a standard api.

CONCLUSIONS
here, we have shown that it is possible to develop a bioinformatics database that can be reconfigured automatically and recompiled to run either against a relational database backend or against an object database backend. the key advantage of this added flexibility is that the bioinformatics database becomes portable with respect to the database backend. this has important implications for the development of open-source bioinformatics databases. in such projects, usually more than one laboratory contributes to developing the software of a specific biological database. therefore, it is useful if each laboratory can choose a database backend for development and deployment, yet contribute to the project in a shared code base.

the java data objects standard offers the productivity gains of transparent object persistence, and a fine-grained object persistence model useful to represent many biological concepts. we discussed why jdo can appear as an attractive option for the development of advanced biological databases and the type of problems that we encountered when implementing and deploying a biological database against two different jdo implementations. the future jdo standard  should address some of the issues that we discussed in this article . when jdo  <dig> implementations become available, we expect that jdo technology will have a significant impact on the design of high-performance biological databases that need to represent and manage complex biological information types.

