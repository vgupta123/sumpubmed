BACKGROUND
functional genomics represent a hot topic in biological research nowadays, embracing the analysis of large datasets, through the quantitative measurement of the genomic expression of the organisms probed, under numerous conditions. gene expression microarrays represent an established, high-throughput measurement technology. it is an indispensable tool for genome-wide inspection of changes in the total gene expression of an organism, which proved to be a major discovery tool in biological research. important goals of global gene expression monitoring experiments are, among others, the identification of significant alterations in transcript levels resulting from the exposure of a living system to a given agent at a specific administration regime  <cit>  or the derivation of prognostic and diagnostic genetic signatures. additionally, high-throughput gene expression profiling is used in clinical studies in order to: i) identify and categorize diagnostic or prognostic biomarkers ii) classify diseases, e.g. tumours with different prognosis that are indistinguishable by microscopic examination iii) monitor the response to therapy and iv) understand the mechanisms involved in the genesis of disease processes  <cit> . however, the vast amount of data produced from even a single microarray slide, requires powerful computational tools in order to mine valuable information. with statistical scaling and proper normalization, differentially expressed  genes can be selected on a statistical basis and provide investigators with a sound basis for meta-analysis and further research focused on specific biological processes or pathways.

in a typical microarray gene profiling experiment, mrna is extracted from cells or tissues of interest, reverse-transcribed, labeled and hybridized onto the array surface. subsequently, washing under stringent protocols diminishes through dilution the possibility of non-specific hybridization. the next step is image acquisition and segmentation. thus, quantitative estimates of the relative fluorescence intensities of each spot/probeset, related to a gene, are obtained. the signal values thus acquired form a dataset, which must undergo pre-processing for the mitigation of several systematic measurement errors. typical pre-processing steps are, image background noise correction to adjust for non-specific hybridization, presence of array artifacts, washing issues or quantum fluctuations, filtering procedures to eliminate non-informative genes and data normalization  <cit> .

although a growing number of commercial or open source microarray data analysis software packages has already been developed, most of them are either closed black-box tools  precluding any further intervention or modification of their inner logic, or contrary, they are open source routines, which usually perform very specific and small steps of the analysis, lacking a standard and consistent framework of parameterization for their coordinated use, given that they are also addressed to experimental biologists  <cit> . although numerous software tools have been developed  <cit> , a major limitation in most of them, is the absence of predefined analysis protocols or batch processes, encompassing all analysis stages from raw image analysis up to the rational derivation of de gene lists. exceptions to this rule exist, such as midas  <cit> , where the definition of analysis workflows in forms of batch procedures is possible and flexarray  <cit> , which does not support 2-colour microarrays and practically reaches up only to the point of extraction of de gene lists. only in its most recent versions it has started providing only basic clustering functions.

specifically, as the field of microarray data analysis field is continuously expanding also in terms of available software, one would expect that tools developed recently, would tackle and standardize several important issues. reduced software complexity for the novice user, multiple microarray platform support, expansion capabilities coupled with friendly interfaces, customizable ad hoc, to a wide range of users , and predefined or interactively built analysis workflows are only few to mention. nevertheless, recent tools either lack support for multiple microarray platforms, or they focus only on parts of the analysis, or ultimately do not properly apply data filtering steps to each specific dataset  <cit> . for example, in flexarray, although the user is able to construct basic analysis workflows, it is not possible to combine for example the results of the mas <dig> algorithm for detecting absent probesets in affymetrix arrays, in order to directly filter the dataset and proceed to statistical analysis with a less noisy dataset. as a consequence, the user has to import two different outputs from flexarray to spreadsheet or database software  in order to construct filtering queries and then re-import the data to the main program for further analysis.

another trend in recent software  <cit> , seems to be the inclusion of as many statistical methodologies as possible, under the umbrella of one sophisticated tool, with enhanced graphical functionalities. even though many alternative options are provided in one tool, our experience indicates that users with limited experience, regarding the correct application of statistical methodologies, can find themselves befuddled in an endless series of analysis scenarios. this is further exacerbated by the lack of pre-defined or interactive analysis workflows. furthermore, the complexity of this category of tools as well as of those that focus more on data management and less on data analysis  <cit> , often necessitates the organization of special training sessions for the potential users, a rather undesired side-effect from a user group's perspective that craves for quick yet cost and time effective solutions.

moreover, many of the current analysis packages are provided only as sets of routines, extremely unwieldy to biologists with limited programming or scripting skills. the most characteristic example is bioconductor  <cit> . despite the fact that it represents, undoubtedly, one of the richest repositories of statistical algorithms and has become, by all means, a standard for microarray data analysis, its command line interface limits its usability to many, wet-lab oriented, biological experts. several bioconductor packages have been assembled through graphical user interfaces, developed with the use of tcl/tk modules of r  <cit> . however, these gui solutions lack uniformity, something that often confuses inexperienced users  <cit> . in addition, they are often insufficiently documented. finally, in the case of gui embedded solutions, lack of direct support of various raw image analysis formats is often observed, thus imposing several rounds of manual transformation first.

taking into account the aforementioned limitations, gene armada was developed with the scope to provide both a step by step and a batch mode analysis environment, beginning from the import of raw image analysis microarray data. thus it supports several widely used microarray image analysis formats as well as more flexible user-defined formats that ends in annotated de gene lists, gene clusters and classifier models. alternatively, circumventing one or more analysis steps, it can further analyze already processed data, providing the same sets of aforementioned results. emphasis is placed equally on automation and flexibility. in this sense, analyses can be fully automated by using the batch programming module, or adjusted to ensure specific data manipulations through a very handy gui. depending on the user's programming skills, the open-source nature of the software allows further adjustment of analysis workflows and the addition of new analysis algorithms. apart from the batch programming module, experienced users are also able to directly build their own workflows. this is done by using the command line version of the algorithms behind gene armada, designed to easily operate in command line mode. in its current version, gene armada fully supports the automated processing of  <dig> coloured cdna and affymetrix oligonoucleotide arrays. yet through the incorporation of a powerful versatile custom import data editor, its workflows are easily adjusted to support the analysis of numerous types of already processed results through its versatile import editor. the program utilizes a set of gene filtering, normalization, parametric or non-parametric statistical tests, clustering and classification algorithms to analyze any number of experimental conditions and replicates. additionally, it imports novel features in microarray signal processing, as the well established from systems theory concept of the signal-to-noise ratio for background correction in 2-colour microarrays, or the condition-based imputation of missing values 

implementation
implementation
gene armada has been implemented in matlab, a very powerful and globally renowned programming environment for scientific computing, and can be downloaded from . it has a complete gui front-end created using matlab's language programmable user interface objects and guideâ„¢. being developed on matlab, gene armada is platform independent and can be used either as a matlab tool, when matlab is installed on the computer, or as a stand-alone application distributed together with matlab component runtime . expert users are given the ability of further adjusting the analysis workflow to their own specific needs, by using or editing routines running behind the gui, as they are designed to be used also in command line mode . gene armada represents therefore a stable operating framework for versatile, transparent, seamless algorithmic integration addressing numerous facets of microarray analysis and meta-analysis.

gene armada excels among many tools which specialize either in data visualization, normalization, statistical testing, supervised or unsupervised learning and data annotation by integrating all the above, through a friendly interface. data analysis can be performed through a predefined workflow with minimal user interaction through a batch programming module, or by performing analyses step by step upon user's requests. the following subsections summarize those features.

data import
currently, the output formats of  <dig>  widely used image analysis software, are supported  for automatic data import of both cdna and oligonucleotide arrays. the user can also import a wealth of microarray signal files in tab-delimited text or excel form, through a data import wizard where the user can easily import the minimal necessary parsed raw data required, for the subsequent analysis. apart from raw data, the user can import any kind of already pre-processed data through a powerful data import wizard in order to exploit any of the rest of the functionalities of gene armada . through the data import wizard, the user can easily associate columns in the file  with any number of user-defined experimental conditions.

background correction
there are  <dig> options for spot background correction in 2-colour microarrays supported:

 <dig>  background subtraction: in this case, the net signal for each channel is calculated, by subtracting the background signal, from the foreground estimated spot signal. then, by taking the log <dig> ratio between channels, a measurement of expression for each spot on the array is obtained. this option represents the widely used background subtraction method for spot signal correction.

 <dig>  calculation of the signal-to-noise ratio: in this case, a different approach is used, where the net signal for each channel is estimated as the ratio of the foreground estimated spot signal to the background signal. therefore, the log <dig> ratio between channels which measures the expression levels for each spot is differently and more robustly scaled than in case  above, across all intensities.

 <dig>  no background correction: in this case, only the foreground estimated spot signal is taken into account in order to calculate the expression level of each spot on the array.

for affymetrix arrays, rma  <cit>  and gcrma  <cit>  algorithms are available for background adjustment.

spot quality filtering
poor quality spots are identified in 2-colour microarrays as follows:

firstly, spots marked as poor either manually, or by the image analysis software are excluded. noise sensitive genes are further isolated for each array based on  <dig> possible filters applied to both channels:

 <dig>  a signal-to-noise threshold filter below which noisy spots are filtered out from the slide. the default filter value is  <dig> 

 <dig>  a filter based on the distance between the signal and background distributions; spots satisfying the inequality  are filtered out, where s and b denote the signal and background and x and y are user-defined parameters defining the strictness of the filter: as x and y increase, more spots are filtered out, as only those that have clearly separated foreground and background distributions can pass the filter. the default parameters for this filter are  = .

 <dig>  a custom filter based on the signal and background means, medians and standard deviations. the user can use the above descriptive statistics parameters to format a personal filter when imported data are known to exhibit a special or known behaviour, or simply when the user wishes to explore multiple data filtering possibilities. by providing a custom filtering option, gene armada also allows the experienced user to define a more complex filter based on the aforementioned parameters.

for affymetrix arrays, the first step of poor quality signal identification is performed using the mas <dig> detection algorithm to call present/absent probesets.

secondly, outlier detection is performed for each spot, among the replicates of each experimental condition. parametric or non-parametric tests are applied, to check if values follow the normal  distribution with mean  equal to the average for this spot among all replicates. error prone spots are excluded from the estimation of the normalization curve, to mitigate the impact of systematic measurement errors. for the case of affymetrix arrays, this step is performed posterior to background adjustment/normalization/summarization steps.

normalization
currently,  <dig> within slide normalization methods for 2-colour microarrays are supported: global mean/median, linear lowess, robust linear lowess, quadratic loess, robust quadratic loess and rank invariant  <cit> . the robust lowess/loess versions  <cit>  execute additional fitting iterations while readjusting each point's weight on each iteration to alleviate the impact of possible outliers. if subgrid coordinates exist for the imported array type, subgrid normalization is also possible and there is also full support for dye-swap experiments. between-slides normalization is part of the statistical analysis workflow and can be performed using quantile normalization  <cit>  or mad centering  <cit> . for affymetrix arrays, either quantile or rank invariant normalization can be performed.

statistical selection
selection of de genes is implemented by using a graphical interface where the user can define  several parameters and contrasts for each analysis, performed in a workflow manner. it starts with the calculation of the trust factor  which is defined for each gene as the ratio of its number of qualified replicates after the filtering step, to the total number of replicates, for each condition. the definition of the tf according to user's requests sets a reliability threshold, excluding genes from further analysis. the imputation of missing values for a gene is based on the average expression of the remaining present values of that gene from the same experimental condition or the knn imputation algorithm  <cit> . it can be performed before or after between-slides normalization . differentially expressed genes are acquired using parametric  or non-parametric  statistical tests. multiple testing correction is performed by controlling the fwer  <cit>  or the fdr  <cit> . after the completion of each contrast, the user is prompted to accept the results or repeat the analysis using different parameter sets.

data clustering and classification
currently, gene armada supports  <dig> fully customizable clustering algorithms: hierarchical and k-means clustering based on the statistics toolbox of matlab and fuzzy c-means clustering  <cit> . a novel contribution is the automated derivation of the optimal number of clusters for the appropriate classification/partition of the dataset in gene groups. this is performed through the utilization of the gap statistic  <cit> , in a routine implementation which, by using distance metrics comparison with different reference gene signal distributions and iteration, selects the optimal number of clusters. principal component analysis  <cit>  is also provided for the derivation of the critical features of datasets. supervised classification can be performed using discriminant analysis, k-nearest neighbors or support vector machines  <cit>  using the osu-svm toolbox  <cit> , which supports multiclass classification and is based on the widely utilized libsvm  <cit> . classifier parameterization can be performed, through an implemented interface for the appropriate tuning of each algorithm. this interface includes flexible dialogs where the user can define several parameters to be tested , as well as several classifier performance plots and detailed output depicting statistics concerning the performance of each classifier.

visualization tools
gene armada provides a variety of visualization, exploration and quality assessment graphs, such as array spatial images for several spot quantitation types, normalized and un-normalized expression values, individual and array versus array plots for several quantitation data, expression distribution histograms, boxplots, ma, volcano and expression profile plots, clustering heatmaps and classifier evaluation plots. most graphs are interactive and users can select and export data directly in various graphic formats. the variety of provided visualization tools can be utilized for numerous purposes, encompassing among others, quality control and analysis  assessment, in order to aid in threshold and parameter estimation for several procedures, like statistical analysis, clustering and supervised classification.

data export
the results of the analyses can be exported in tab delimited or excel file formats, or as .mat files so that the experienced user can further process the data with other matlab built-in algorithms. the output is customizable through an export wizard, allowing either basic data export for exploratory purposes, or the export of rich specific formats for direct use with other tools, such as genmapp  <cit>  for mapping gene expression on cellular pathways, or for gene ontology terms based statistical analysis, through the utilization of the software package named rankgo  <cit>  . outputs can be massively annotated through an annotation module.

batch programmer
gene armada offers a batch analysis programming module which can be used to schedule several analysis rounds, encompassing different methods and parameters. this feature offers the user the ability to simply import the data and then pre-define multiple analysis workflows without having to personally monitor the whole procedure. upon completion of the execution of the batch processing, the user can collect the multiple outputs, and directly compare the differences among different method/parameter sets. specifically, through the batch scheduling module, users can set: i) filtering and normalization steps, ii) define multiple analysis dispatches of multiple statistical comparisons among different experimental condition and replicate sets and also iii) define different clustering procedures. in this way, they are capable of conducting multiple algorithm exploration tests at once. the batch analysis options can be saved in a separate file, so that they can be easily recalled. the batch analysis results can be saved as a gene armada project so that they can be later loaded into the main program for visual data explorations or exporting in other storage formats.

data analysis structures
the data analysis structures implemented in gene armada allow users to define several experimental condition and slide replicate subsets in distinct analysis objects, each carrying the essential data required to maintain and/or easily recall analysis steps performed for each analysis run. this implementation allows the conduct of different comparisons without repeating the computationally intensive normalization task when not necessary. in addition, it enables the examination and assessment of the performance of different filtering and normalization steps, with respect to dataset specific optimized tuning of the algorithmic processing pipeline.

RESULTS
gene armada aims to provide investigators with a complete, open-source, flexible and handy platform for both cdna and oligonucleotide  microarray data analysis. it encompasses all levels of analysis to easily interpretable and simply manipulated gene lists. it addresses a very wide category of users, practically meeting all levels of competences regarding analysis and interpretation of microarray experiments, by providing a friendly software environment equipped with a graphical user interface, plus automated workflows for the analysis of microarray experiments together with absolutely open source routines, adjustable to meet specific data processing needs. the adoption by gene armada of a specific analysis protocol , represents one of the major strengths of it, as it provides a solid base of standardization of the microarray experiments processing, where the data handling steps among different experiments can be boiled down to very specific descriptions that unequivocally characterize the type of transformations applied to various data populations. additionally, gene armada integrates several major steps of microarray data analysis  under one tool, and represents a connection point for annotation tasks, as well as customizable integration of numerous other, microarray data analysis tools.

the total computational cost of an experiment depends heavily on the amount of arrays to be analyzed, as well as the type of data processing workflow selected for implementation . yet the inherently parallel structure of the gene armada analysis workflows renders it an amenable environment for parallel computing. in this sense, gene armada represents the prototype, upon which the development of a web-based microarray analysis application, integrating in its programming, principles of grid computing, grissom  has been developed. concerning the program use, apart from the graphical interface, the user can program several analysis rounds through the batch programming module. a snapshot of the program is illustrated in figure  <dig> 

it is to be noted that the signal-to-noise ratio implemented background correction method that utilizes the signal-to-noise content of a signal, is an established notion in systems theory and image processing  <cit> . it represents a pre-processing step, in line with the perception of the experimentalist about signal quality, emphasizing in the signal strength compared to noise. given the reported controversy on background subtraction  <cit> , this approach is critical, especially regarding weak signal datasets, whereas a majority of spot signals is close or even below the background levels. to our knowledge, there is no other analysis tool using the signal-to-noise ratio for background correction for 2-colour microarrays.

finally, it should be also stressed here the novelty regarding the automated derivation of the optimal number of clusters, for the appropriate classification/partition of the dataset to gene families through the utilization of the gap statistic  <cit> . this is another crucial feature for automated clustering procedures. gene armada has been successfully used so far for the analysis of several microarray datasets, including datasets concerning interstitial pulmonary fibrosis  <cit>  and gene expression profiling of progestin-induced canine mammary hyperplasia and spontaneous mammary tumors  <cit> . it has also been used for processing microarray datasets concerning gene expression profiling of mouse liver and lung tissues after treatment with different dosages of polycyclic aromatic hydrocarbons . additionally it has been used for clustering rna polymerase ii occupancy in  <dig> chip-seq datasets  <cit>  from next generation sequencing experiments, thus proving the generic design of the gene armada algorithmic modules, which render it adjustable to versatile processing tasks. software efficiency and good functionality has also been extensively tested with several microarray datasets retrieved from public repositories such as arrayexpress and geo.

CONCLUSIONS
gene armada aspires to provide a unified, automated and flexible platform for both 2-colour and affymetrix oligonucleotide microarray data analysis and interpretation. it is programmed in matlab, exploiting elements from the statistics and bioinformatics toolboxes and offering friendly integration with numerous other tools. gene armada has been successfully used to process several microarray datasets and has been tested with multiple public datasets some of which are available for download at .

availability and requirements
home page: .

operating system: windows, if used as a stand-alone application or platform independent, if used under matlab.

requirements: if used under matlab, statistics and bioinformatics toolboxes should be also installed. if used as a stand-alone application, matlab component runtime   <dig>  is required, which is distributed with the application installer from the software's home page. in order to parse affymetrix .cel and library files, the affymetrix gdac runtime libraries are required, which can be found under the bioinformatics toolbox if matlab is present on the installation machine, or they are distributed with the stand-alone application installer from the software's home page. in some machines, .net framework  <dig>  can be also required.

license: gene armada is distributed under the academic free license  v. <dig> . the software is available to all users without registration.

further information: all versions of the software  together with an analytical user's guide, installation instructions, several video tutorials, screenshots and several test datasets are available for download at the software's homepage.

list of abbreviations
the abbreviations used throughout the article are: armada: automated robust microarray data analysis; de: differentially expressed; gui: graphical user interface; mcr: matlab component runtime; tf: trust factor; fwer: family-wise error rate; fdr: false discovery rate; afl: academic free license.

competing interests
the authors declare that they have no competing interests.

authors' contributions
ac conceived the idea of software implementation and the analysis workflow, designed the structure of the analysis pipeline, contributed to the implementation of the routines, coordinated the development of the software, tested the software and contributed to the drafting of the manuscript. pm designed and implemented the gui, contributed to the implementation of the routines, tested the software, created the software's website and documentation and contributed to the drafting of the manuscript. fnk contributed to the evaluation of the software regarding the biological data management, and revised the manuscript. all authors have read and approved the final manuscript.

supplementary material
additional file 1
source code of gene armada. gene armada's matlab source code. the file should be extracted using a suitable program  and the extracted files and folders should be placed in matlab's path. the program can then start by typing armada in matlab's command line.

click here for file

 acknowledgements
the authors want to express their acknowledgements to dr vassilis aidinis for his heedful remarks concerning the evaluation of the performance of the gene armada algorithms and dr olga papadodima for useful comments after software usage. they would also like to thank prof. g palaiologos for proofreading the manuscript. this work was financially supported by the general secretariat of research and development in the frame of the program for the evaluation of the national research centres .
