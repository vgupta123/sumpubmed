BACKGROUND
the smith-waterman  algorithm is a well-known algorithm in bioinformatics that finds the optimal alignment between two dna or protein sequences   <cit> . determining how well two sequences align is important in discovering homologous genes and studying the evolutionary history of molecules and species  <cit> . however, the sw algorithm is not commonly used to search sequence databases because it is too slow when executed against many sequences. instead, faster heuristic algorithms such as fasta  <cit>  and blast  <cit>  are used, even though they can not guarantee that the score for the optimal local alignment will be found. therefore, to achieve both increased speed and the optimal alignment score, it is necessary to develop an approach to reduce the processing time of the sw algorithm. the sw algorithm first creates a two-dimensional  matrix with size equal to the lengths of the two dna sequences. the score of each cell in the matrix is calculated from neighbouring cells. the optimal alignment score between the two dna sequences is the highest score in the matrix and the corresponding alignment is determined by back-tracing from the cell with the highest score to the first cell with a zero score.

many attempts have been made to accelerate the sw algorithm using either software or hardware by focusing on parallel processing of the score matrix  <cit> . this has been implemented using vlsi   <cit>  and fpga   <cit>  by simultaneously evaluating the cells along the minor diagonal of the score matrix. alternative implementations have been used recently to accelerate the sw algorithm using software parallel programming on common microprocessors with a speed improvement up to six-fold  <cit> . here, we dramatically reduced the computation time of the sw algorithm using an fpga. our implementation uses custom instructions to accelerate cell scoring in the sw matrix and divides the sw matrix into grids of  <dig> by  <dig> cells. our approach is different from previous fpga approaches in that the cell scores in each grid are calculated through unclocked signal propagation within the fpga circuit, whereas previous methods process the minor diagonal values synchronously by the clock. using our approach, we reduced the expensive writing and reading time of intermediary data between each computation of the diagonals. furthermore, we eliminate the overestimation of the computation time of the circuit caused by a clock. the cost of this improvement is utilizing more logic elements on the fpga.

RESULTS
smith-waterman algorithm
the sw algorithm belongs to a class of algorithms known as dynamic programming. dynamic programming is used when a large search space can be structured into a succession of stages such that the initial stage contains trivial solutions to subproblems  <cit> . typically, this involves structuring the problem to an iterative calculation of cells in a scoring matrix. the following is the commonly used scheme to compute the score of a single cell, score_x, in the score matrix:

score_x = max {score_nw + match_bonus,

   score_nw + mismatch_penalty,

   score_n - opening_gap_penalty - extension_gap_penality,

   score_w - opening_gap_penalty - extension_gap_penality,}

score_nw, score_n and score_w are the scores of the cells to the upper-left , above  and left  of cell x, respectively . for simplicity, in our case, the match_bonus was  <dig> if the additional letters to the alignment are equal; the mismatch penalty was  <dig> if letters are not equal; the opening_gap_penalty was 1; the extension_gap_penalty was  <dig>  for each additional gap. thus, the score of each cell in the 2d matrix  is calculated by three of its neighbouring cells.

software implementation
a pure software implementation of the sw algorithm was developed in the c language to benchmark against fpga-based implementations. a single_cell_module  was programmed containing the following i/o parameters: score_nw, score_n, score_w, flag_nw, flag_n, flag_w, flag_gap and result_score. the input parameters score_nw, score_n and score_w are scores of the nw, n and w neighboring cells, respectively. the input parameters flag_nw, flag_n, and flag_w indicate the direction of the gap  of the nw, n and w neighboring cells, respectively. since the direction of the gap is known from the neighboring cells by the flags, we can determine if the incremental gap penalty of the cell of interest is an opening or extension gap penalty.

thus, we can perform an affine gap penalty. the output parameters  give the direction of the gap and the final score of the cell of interest, respectively.

the program first loads the target and search sequences into local memory from two text files stored in the flash memory. then, their sequence lengths are determined and the scoring and gap matrices are created with dimensions of the above sequence lengths. next, the score of each cell in the sw scoring matrix is calculated using the scm. lastly, the completed sw scoring matrix outputs the highest score in the matrix.

custom instruction  for scm using an fpga
since calculating the scm in the sw scoring matrix is repeated, this routine is a good candidate for fpga-based hardware acceleration. the reconfigurable logic elements in fpga can be optimally configured to run specific functions through the implementation of custom microprocessor instructions, which are assigned logic elements that perform user-defined operations. custom instructions, in particular, allow the passing of multiple inputs and outputs in a single clock cycle while the pure software implementation using a conventional microprocessor is limited by the instruction set.

the scm in the pure software implementation was converted to an equivalent fpga-based custom instruction  written in the verilog hardware description language. since the format for the custom instruction provided by our fpga board  only permits two 32-bit inputs  and our 1×scm requires  <dig> inputs , the inputs are partitioned and rearranged to be all read in a single clock cycle. recall that the inputs for the scm in the pure software implementation are score_nw, score_n, score_w, flag_nw, flag_n, and flag_w. using bit masking and shifting bit operations, all input scores and their flags are passed to the 1×scm of cell of interest in one clock cycle . the ci produces the cell score and flags quickly because it makes use of custom hardware, rather than using the standard instruction set of the nios ii as in the software version. the maximum field propagation delay of the 1×scm was estimated to be  <dig> ns. thus, the clock speed of this computation could be no faster than  <dig>  mhz. using the 1×scm, we computed the cell score and gap flag calculations using a single instruction rather than several.

lastly, we added the ci for the scoring of a single cell to the instruction set of the nios ii soft microprocessor on the fpga, so that it can be called in a c program. the flow of computation is identical to that of the software implementation, except that instead of calling a function which describes the scm, we call the ci.

a grid design of scms using an fpga
to further improve the computation speed, we combined  <dig> instances of 1×scm into an  <dig> by  <dig> grid module  , the maximum size allowed by our fpga board. we programmed the fpga such that within the grid, the score update of each 1×scm is not synchronized to a clock, but rather triggered by the changes of scores in neighbouring cells in the w, nw and n direction . this asynchronous data processing method allows scores to propagate throughout the grid as fast as the field propagation speed allows in the fpga logic gates, hence drastically improving the computation speed. this implementation can be thought of having all  <dig> 1×scms processing at the same time, while the score updating propagates in the grid. the sw matrix is divided into as many grids as needed, which are then calculated with 64×scm one by one. because all logic circuits are connected inside the 64×scm, it takes only one clock cycle to compute the entire  <dig> by  <dig> grid. the maximum field propagation delay of the 64×scm was estimated to be  <dig> ns. thus, the clock speed of this computation could be no faster than  <dig>  mhz.

as input, this module requires segments of the search and target sequences with a length of up to  <dig> characters . also, it requires the scores and gap flags stored from prior 64×scm calculations in the nw, n and w direction. a second module was created to calculate the maximum score of the 64×scm by a cascade of max-finders that first finds the maximal score of each column and then finds the maximum of the columns to determine the overall maximum . in order to process sequences longer than the dimension of 64×scm , a controller module was programmed to reuse the 64×scm. this module included a sram  block to store scores and gap flags from previous 64×scm calculations as well as a finite state machine  to control loading and storing values to the sram . lastly, to access this hardware from a c program, a final interface module defines a set of registers to hold the sequences, lengths, various flags and the final score.

the flow of computation of this hardware controlled from a c program is as follows. first, the search and target sequences are loaded from flash memory and copied to local memory. once this is done, an on-chip timer is started. second, score and gap matrices are initiated and the values reset. third, the search and target sequences are encoded by a custom instruction and loaded into the 64×scm with their lengths. dna bases are encoded into two bits . lastly, the result propagates through the grid and completes in a time determined by the field propagation delay. if the sequences are longer than  <dig> characters, steps  <dig> and  <dig> are repeated for the next grid . once all grids have finished, the timer is stopped and the running time is displayed on the screen.

testing
we tested and compared the performance of the three implementations  for aligning two dna sequences with identical lengths ranging from  <dig> to  <dig> base-pairs. we performed the same input for each implementation and measured the time to complete the computations . alignment of the each sequence length was performed three times to produce the statistical variance, which was less than  <dig> %. the scoring matrices from the three implementations were compared to ensure identical alignment results. the performance of the implementation was found to be independent to the sequence-similarity between the two dna sequence queries .

the 1×scm implementation produced a maximal 2-fold speed improvement over the pure software implementation running on the same fpga with an altera nios ii softprocessor, while the 64×scm implementation produced a maximal of 160-fold improvement over the pure software implementation . when the sequence length was smaller or equal to the size of the 64×scm implementation, the computation time did not increase as the length of the sequence increased . in comparison to the pure software and 1×scm implementations, the computational time increased proportionally to square of the sequence length. when the sequence length was larger than the size of the 64×scm implementation, the slopes of the log  vs. log  graphs of all three implementations approach the same value  and the speed per cell approaches a constant value . thus, in this case, the computation time of all three implementations increased proportionally to square of the sequence length. this is expected as the field propagation of the 64×scm implementation is restricted to the  <dig> by  <dig> grid. however, if we increase the size of the grid to cover the average size of sequences comparisons , we could significantly improve the computation time for the majority of sequence alignment queries.

discussion
while this fpga implementation using a single altera stratix fpga board does not compute cells per second in a comparable speed to existing software implementations, it is likely that expanding this design to state-of-the-art fpga architectures will outperform them. rognes and seeberg's software implementation running on a pentium iii  <dig> mhz processor  showed a performance of  <dig> million cells per second  <cit> , while recently farrar's software implementation running on a xeon core duo  <dig> ghz processor  showed a performance of  <dig>  million cells per second  <cit> . in table  <dig>   <dig> cells were computed by the 64×scm implementation in  <dig>  ms, which is equivalent to  <dig>  million cells per second. it is important to note that most of the processing time is consumed by writing and reading intermediary data to and from static ram from multiple executions of the 64×scm module that is necessary when computing a sw matrix that is larger than an  <dig> by  <dig> grid size. for example, the computation of a sw matrix with grid size  <dig> by  <dig> would require  <dig> executions of the 64×scm module. this loading and reading time could be dramatically reduced by using a larger grid size encompassing the average length of query sequences, perhaps  <dig> by  <dig> cells. using this grid size, the computational time is the initial load time of sequence data added with the field propagation delay across the grid which is at most  <dig> 1×scm across and  <dig> down for a total of  <dig> 1×scm propagation delays. our above estimation for the maximum field propagation delay of one 1×scm on our fpga board is  <dig> ns. if that estimate is used, the computation of the  <dig> by  <dig> grid will be completed in at most  <dig>  ns. this corresponds to a computation speed of  <dig>  million cells per second. this would actually be an underestimate in what can be achieve in state-of-the-art fpga boards as the field propagation delay is faster because the density of the transistors is higher and therefore field propagation distance is shorter.

while a  <dig> by  <dig> grid size is desired, the  <dig> by  <dig> grid size was limited by our fpga board because it only has  <dig>  logic elements. a single 1×scm utilizes  <dig> logic elements. if only 1×scm modules were programmed on this fpga board, there could be a maximum of ~ <dig> 1×scm, however only  <dig> 1×scms could be programmed because other internal fpga hardware requires logic elements as well. one way to reduce logic element utilization is to decrease the bit-size of the score. currently, state-of-the-art fpga hardware  have  <dig> xilinx virtex ii fpgas on single board for a total of  <dig> million logic elements.

this fpga hardware could create a maximum of ~ <dig>  1×scm. thus, we could potentially have a maximum grid size of  <dig> by  <dig>  with ever improving hardware, the gap to a  <dig> by  <dig> grid size will inevitably be bridged.

CONCLUSIONS
since the sw algorithm becomes computationally expensive for comparing sequences in a large database, we accelerated the computation time by using fpga hardware. to quantitatively assess the computational improvement, we compared an implementation of the algorithm in pure software running on the altera nios ii softprocessor with fpga-based implementations that had a scm ci  and a scm grid . the implementation with a 64×scm accelerated the algorithm by a maximal of 160-fold in sequence lengths less than or equal to the grid length. the computation is significantly improved because it is occurring as fast as electrons can propagate through the fpga circuit. by using a grid length that is the size of an average sequence length, the computation time of the average sequence comparison can be further significantly improved. thus, expanding our fpga design to more powerful fpga systems with parallel and higher density logic elements is a promising direction to significantly improve genomic sequence searching.

