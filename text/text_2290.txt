BACKGROUND
clustering terms based on string similarity is a common task in text processing and is used to abstract varying of representations of the same concept in natural language texts. to address the task, several string similarity methods have been developed and have been successfully applied  <cit> .

when we apply similarity methods, at least two problems arise:  the choice of a good similarity method, and  the choice of an optimal threshold. for example, cohen et al.  <cit>  reported that softtfidf generally works the best for the term clustering of entity names, and okazaki et al.  <cit>  reported that the use of a hybrid distance with  <dig>  as the optimal threshold was the best setup for the problem of abbreviation-full form clustering.

the work presented in this paper was carried out as a part of a dictionary-building project for abbreviations in life science. the project was motivated by the observation that abbreviated terms are abundant in life science literature and that there is a significant need for a dictionary lookup service for such abbreviated terms.

it has been reported that a new abbreviation appears in every five to ten abstracts in pubmed  <cit> , and  <cit>  showed that the number of medline entries increased by approximately  <dig>  <dig> entries per year on average from  <dig> to  <dig>  these facts indicate the necessity for an abbreviation dictionary to be continuously updated, thus implicating the necessity for an automated process to extract abbreviations from texts in medline and integrate them into the existing dictionary entries. there have been several studies in which such systems were developed  <cit> . these systems typically employ two processes:  the extraction of abbreviation-full form terms, and  the clustering of these terms per their meanings. our focus in this paper is the clustering problem.

we have been developing and maintaining the allie database, in addition to an online service that provides abbreviation-full form information, by referencing pubmed entries and the subject domains in which they appear. allie is updated monthly to include new abbreviated terms that are found in pubmed. because new abbreviations are constantly added to the database, the clustering of abbreviation-full forms also needs to be updated. therefore, we have been developing an automatic term-clustering method. there have been several works sharing this same goal  <cit> .

we have tested several similarity methods. we observed a significant difference in the distribution of string similarities between terms according to the semantic classes of those terms. in particular, we focused on chemical names that seldom allow even small variations in spelling to qualify as a matching. for example, although both diethylene glycol monoethyl ether and diethylene glycol monomethyl ether are abbreviated as dgme in medline abstracts and the difference between these terms is only the insertion of a single character, m, these terms denote different chemical compounds. the motivation of our study described in this paper was to solve this problem.

in this study, we proposed the following hypothesis: "chemical names and other terms have different distributions of character sequences; thus, the computation of their similarities should be carried out in different ways."

to argue this hypothesis, in this study, we compared the results of four string measures for chemical names with the results for the other full forms. the four measures used were the edit distance, the monge-elkan score, softtfidf with the jaro-winkler distance, and the bigram dice coefficient.

methods
similarity measures
for the clustering of full forms that share the same abbreviation, we chose to test four similarity measures: the length-normalized edit distance, the monge-elkan score, softtfidf with the jaro-winkler distance, and the dice coefficient based on character bigrams. the selection of these measures was motivated by their popularity , performance reported in  <cit>   and simplicity .

the edit distance, also known as the levenshtein distance, is one of the most commonly studied string distance measures. the edit distance of two strings is defined as the minimum number of edit operations to transform one string into the other string, where an edit operation is an insertion, a deletion, or the replacement of a single character. in this study, we employed the length-normalized edit distance, defined as follows, to eliminate the influence of the length of the full forms:

 d=edmax{n <dig> n2} 

where ed indicates the edit distance between two strings s <dig> and s <dig>  and n <dig> and n <dig> are the lengths of s <dig> and s <dig>  because the levenshtein distance between s <dig> and s <dig> is computable by dynamic programming with o  <cit> , the length-normalized edit distance is computable with the same order.

the monge-elkan score  <cit>  is another alignment-based similarity measure. this measure is defined as the minimum sum of the scores for all possible alignments of two strings. a score matrix for the monge-elkan is { <dig>   <dig>  -5}, where the result is  <dig> if two characters are the same,  <dig> if two characters are in one set of {d, t}, {g, j}, {l, r}, {m, n}, {b, p, v}, or {a, e, i, o, u}, and - <dig>  otherwise. in addition, an affine gap penalty is defined as g = α + βk, with α =  <dig> and β =  <dig>  note that if you employ the score matrix { <dig>  - <dig>  -1} and the gap penalty g = k, the score is equal to -d where d is the edit distance. in  <cit> , the monge-elkan score was reported to perform the best among alignment-based measures in most cases, if the score matrix { <dig>   <dig>  -3} is used, and if the score is scaled to the interval  <cit> . therefore, in our experiment, we also employed this score matrix as the monge-elkan score.

the softtfidf, which was introduced by  <cit> , is a variation of tfidf, but allows approximate string matchings of words, instead of only allowing exact matchings. the softtfidf with a similarity measure s' for a certain set s of strings is defined by:

 s= ∑w∈swvs×vs×maxwi∈s2s′ 

where sw is set of words in string s <dig> such that, for each word w in sw, there exists a word w' in string s <dig> such that s' is at least a given constant a,

 vs=log+1)×log)∑wi+1)×log)) <dig> 

where t f  is the frequency of the word w in s, and idfs is the inverse of the fraction of strings in s that contain the word w. because they employed the jaro-winkler score as the similarity measure s' and  <dig>  as the constant a in their experiment, we also employed these values in our experiment.

the jaro score is defined as follows:

 sjaro=13n1′n1+n2′n2+n1′-ts <dig> s22n1′ 

where n1′ and n2′ are the numbers of matching characters in s <dig> and s <dig>  respectively, where a character in one string is matching if the same character is present in the other string, and they are not farther than min/ <dig> apart. then, the jaro-winkler score is

 sjw=sjaro+max{p,4}10), 

where p is the number of common prefix characters between s <dig> and s <dig> 

n-gram analysis is also frequently used as a string similarity measure for various purposes  <cit> . bigrams or trigrams are mainly used as a string similarity measure for clustering terms. in our initial experiment, we found that bigrams are better than trigrams, for our purposes. therefore, we employed bigrams in our experiment. the similarity used in this paper is the dice coefficient, defined as follows  <cit> :

 sn=2×cn 

where cn indicates the number of substrings of length n in s <dig> that match length n substrings in s <dig>  note that the edit distance is a distance measure, whereas the others are similarity measures. thus, the lower the edit distance, and the higher the other similarities, the better the chance that the two strings will be clustered.

term clustering
the problem we want to address is the clustering of the full form terms corresponding to abbreviations based on their string similarities.

we assume that every term s is assigned to be a hidden element in a certain set of concepts. many methods for clustering terms are based on predicating whether two terms are mapped to the same concept or not. therefore, we cast the problem as a binary decision task, to determine whether to cluster two given terms. this decision was made based on a similarity measure and a threshold as a cutoff point. a hybrid model combining multiple similarity measures was not considered, since the purpose of this work was to test the effect of different similarity measures when applied to different groups of terms.

with the task setting, our goal was, for a given set of terms, to identify the similarity measure and the threshold value that yielded the best set of matchings between two terms .

data preparation
this section describes the data-set that we prepared for the abbreviation-full form clustering experiment. we defined the pair consisting of an abbreviation and its full form, as an a-pair. we considered two a-pairs to be mapped to each other when  they shared the same abbreviation, and  the full forms belonged to the same concept class. the goal of our experiment was, for pairs of a-pairs with the same abbreviation, to compare the performances of the clustering methods using a string similarity of the full forms between chemical names and non-chemical names.

we began with the set of a-pairs  obtained from the current allie database. among the entries, we collected the a-pairs for which the full form appears in the umls metathesaurus  <cit>  with cui . the umls metathesaurus is the largest thesaurus in the biological domain, and includes  <dig>  <dig>  <dig> concepts in the current version . the cui was then used to determine the fold clustering of the collected a-pairs . because we wanted to compare the performances of the similarity measures for chemical and non-chemical names, we divided the set of a-pairs with the gold standard of clustering into two subsets: one containing chemical names  and the other containing non-chemical names . to identify chemical names, we used oscar <dig>  <cit> . in a set of a-pairs, all a-pairs sharing the same abbreviation were candidates for mapping. we found  <dig>  <dig> and  <dig>  <dig> pairs  in the c and d sets, respectively.

in our preliminary experiment, we confirmed that the frequencies of each letter for chemical names and non-chemical names were similar. therefore, the results should be minimally impacted by the difference of the letter frequency distributions between chemical names and non-chemical names.

experimental setup
we experimented with the two sets x and y of mapping candidates. for each pair of mapping candidates , the gold mapping, true or false, was obtained using the cui. if the cuis of the full forms of both a-pairs were the same, then the mapping was true; otherwise, the mapping was false. in a series of experiments, similarity measures were used to predict the mapping, and the performance was evaluated by comparing the predictions with the gold mappings. we first computed the four string measures described in the subsection "similarity measures" for all the pairs, in both x and y. after that, for each string measure, we computed the recalls, precisions, and f-measures of the matchings of chemical names for every  <dig>  threshold from  <dig>  to  <dig>  or from  <dig>  to  <dig> . similarly, we computed those values for the non-chemical names. in addition, for softtfidf, we computed these values for every  <dig>  threshold from  <dig>  to  <dig> , since the peak f-measure for softtfidf was unclear when using the  <dig>  threshold.

furthermore, we constructed two 26-dimensional vectors, each element of which indicates a weight of an edit operation of an insertion or a deletion of a character from 'a' to 'z' for the length-normalized edit distance. one vector is optimized by chemical names, and the other is optimized by non-chemical names. we compared the f-measures of the matchings computed by using these two weight vectors for chemical names and non-chemical names.

finally, we compared the performances of the two methods. in the first method, all full forms were matched using the edit distance with the same threshold. in the second method, after dividing the set of full forms into two subsets according to whether a full form is a chemical name or not, the full forms were matched using different thresholds for the two subsets.

RESULTS
we compared the length-normalized edit distance with the softtfidf result by plotting pr curves . as shown in this chart, softtfidf is unsuitable for use with chemical names, whereas the length-normalized edit distance is suitable for chemical names. for non-chemical names, the difference between the two methods was smaller: although the maximum f-measure of the length-normalized edit distance was larger than that of softtfidf, softtfidf may be better if we prioritize precision. as we wrote in the subsection "similarity measures", the essential difference between the edit distance and the monge-elkan score is the weight of the score for an operation. because we could obtain the best f-measure for both x and y datasets by applying the length-normalized edit distance, we considered the weighted version of the length-normalized edit distance. to simplify our analysis, in this paper, we only consider 26-dimensional weight vector whose i-th element corresponds to weight for an operation of an insertion or a deletion of the i-th character among the letters 'a' to 'z'. to show the difference of weights for computing scores between chemical names and others, we computed the two 26-dimensional weight vectors vc and vn. to compute vc, we started an initial weight vector for which all the elements are 1: <dig>  then, we selected one character, in alphabetical order. we fixed values of all the elements of the vector, with the exception of the element corresponding to the selected character, and searched the value of the element for the selected character with the highest f-measure for x, by changing the value of the element in  <dig>  at a time. if all the characters were selected, and all the values with the highest f-measures were found, we set the vector vc. in a similar way, we computed vn for non-chemical names. table  <dig> shows the two vectors: vc and vn. for the bold characters 'e', 'h', 'p', 'x', 'y', and 'z', the weight values are very different. figure  <dig> and table  <dig> show that the weight vector vc improved the f-measure for chemical names, and the weight vector vn improved the f-measure for non-chemical names, although vc and vn are used only for insertions and deletions. however, in comparing the three f-measures for chemical names obtained by using the non-weighted edit distance, the edit distance weighted by vc, and the edit distance weighted by vn, the f-measure obtained by vn is the lowest. it is slightly lower even than the f-measure obtained by the non-weighted version. therefore, we can see that suitable weights are also different between chemical names and non-chemical names.

the vector vc indicates the optimized weight vector for chemical names when operations of insertions and deletions of edit distance are weighted from  <dig>  to  <dig> . similarly, the vector vn indicates the optimized weight vector for non-chemical names.

finally, to support our hypothesis presented in the section "background", we compared the following two results: one result was obtained by using the length-normalized edit distance with the best threshold for x and y combined, and the other result was obtained using the best threshold for x and the best threshold for y. to simplify the comparison, we fixed the recall at  <dig> . then, we were able to compute the threshold for x by sorting elements in x by the length-normalized edit distance, and for each i, by computing the recall when the top i elements are selected as matched. table  <dig> provides the thresholds and precisions when recalls were the closest to  <dig> : the results indicate that we can obtain a better result by simply dividing chemical names and non-chemical names into separate sets.

CONCLUSIONS
string similarity measures are frequently used to absorb the surface variation of terms; e.g., spelling variations, inflections, and derivations. a typical assumption is that the terms belong to the same language, and that the distribution of the characters is fixed. however, the distributions of characters used in chemical names and those used in non-chemical names vary significantly, because chemical names are often generated based on particular nomenclature systems, such as iupac. based on this observation, we proposed a hypothesis: "chemical names and other terms have different distributions of character sequences; thus, the computation of their similarities should be carried out in different ways." to test the hypothesis, we conducted a series of experiments that can explicate the difference. the results strongly support this hypothesis.

we performed experimental comparisons of chemical names and other full forms based on the length-normalized edit distance, the monge-elkan score, softtfidf and the bigram dice coefficient. we demonstrated that  the length-normalized edit distance method performs the best when matching full forms according to our data;  for any string similarity measure above, the optimal thresholds by which to group terms differ between chemical and non-chemical names;  the matching method using softtfidf performed better for non-chemical names than for chemical names, whereas the opposite results were obtained for the other three measures;  the weight vectors optimized by using non-chemical names is not suitable for chemical names; and  the matching result using the edit distances further improved by dividing a set of full forms into two subsets according to whether a full form is a chemical name or not. these results indicate that the distributions of the string similarities of semantically similar terms are different between chemical names and non-chemical names; thus, methods using string similarities can be potentially improved by dividing a set of terms into two sets: one consisting of chemical names and the other consisting of non-chemical names, and applying different similarity measures and different thresholds for these two sets.

it would be benefical to expand the domains of full forms including: gene names, protein names, disease names, etc. to do so, some non-trivial tasks must be completed. such tasks include: determining how to divide appropriate domains and determining the appropriate way to divide terms into the domains. to define term domains, information such as the top  <dig> categories  of mesh  may be helpful. in addition, providing suitable string similarity measures, along with providing parameters for each domain, remains as a task to be completed in the future.

from an engineering perspective, a hybrid model incorporating multiple similarity measures in combination, e.g. support vector machines , is more popular than using individual models. our plan is to implement a hybrid model. the hypothesis confirmed in this work will provide a guideline for designing an effective hybrid model.

competing interests
the authors declare that there are no competing interests.

authors' contributions
aty designed this study, implemented the codes, and wrote the manuscript. yy provided the allie dataset and contributed to the discussion. aty and jk designed the experiments. tt and aky supervised the project. all authors have approved the final manuscript.

