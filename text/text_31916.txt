BACKGROUND
protein–protein interaction networks are known to exhibit modular structure. a module in a protein interaction network could be a protein complex, an organelle, proteins involved in a functional pathway, etc  <cit> . identifying the complexes within a protein interaction network is a challenging task due to two factors: first, interaction data from current high throughput methodologies have significantly high false positives and negatives. second, a protein could belong to multiple complexes. we propose a protein complex discovery algorithm that uses genetic algorithms  to identify complexes in protein interaction networks from yeast. compared to earlier clustering algorithms proposed for this problem, our algorithm possesses several advantages that are enumerated below. 
this approach recognizes that protein complexes are not cliques or near-cliques; the method is capable of identifying clustering with varying densities depending on the local density of edges in subnetworks .

the approach is more robust and scalable. an example of this is that the clustering algorithm is capable of clustering large–size networks , or it can cluster a large number of networks  without problems by ensuring that the many steps of the algorithm have costs that increase modestly with the number of nodes and edges in the network.

the algorithm can be tuned using parameters to obtain clusterings with a desired density and an average size of clusters.



related works
three major graph clustering approaches have been employed to identify protein complexes.

the first approach searches for subgraphs with specified connectivities, called network motifs, and characterizes these as complexes or parts of them. a complete subgraph  is one such candidate, but other network motifs on small numbers of vertices have been identified through exhaustive searching. due to the time-complexities involved, this approach is restricted to searching for small subgraphs in large networks.

in the second, graph–growing approach, a cluster is grown around a seed vertex using graph search algorithms . these are local algorithms that begin with single, or several known nodes and then expand from there. the mcode algorithm  starts with a single seed vertex, and adds more vertices based on a pre-computed set of weights. a vertex in the neighborhood of a cluster is added to it as long as its weight is close  to the weight of the seed vertex. similarly, bader  <cit>  proposed the seedy algorithm, which progressively adds proteins to a seed protein to form complexes, based on a particular distance metric. another software package called complexpander by asthana et al.  <cit>  functions in this way to help identify protein complexes, including the seed proteins from a ppi network. however, our experience comparing this approach with the graph  clustering approach that we describe next shows that this approach is less stable than the latter .

the third approach, the graph clustering approach, includes many variants. algorithms in this category attempt to maximize or minimize certain cluster measures such as connection density, edge cut, or a novel distance metric between nodes in a cluster. in general, these are global algorithms that seek to optimize an objective function for the whole graph. one algorithm by spirin and mirny  <cit>  employs the super-paramagnetic clustering , which is a technique based on a principle observed in physics to maximize the cluster density. another algorithm by przulji et al.  <cit>  uses the concept of a minimal cut, which is a partition of the nodes of the network into two complementary sets such that the least number of edges cross from one set to the other. in their method, they perform recursive minimal cuts until they end up with densely connected subgraphs. another method by king et al.  <cit>  called restricted neighborhood search clustering  begins by randomly assigning nodes to clusters, then reassigns nodes so as to minimize a cost function. yet another such method by enright et al.  <cit>  uses a method called markov clustering  to simulate the “flow” of the matrix. it does this by calculating increasing powers of the network’s adjacency matrix. with the increased powers, the areas of high flow become increasingly separated from those with little flow.

the methods described so far compute exclusive clusterings, i.e., they permit nodes to be members of at most one cluster. however, in biological systems many proteins and gene products participate in multiple functions  <cit> . pereira-leal et al.  <cit>  used the mcl clustering algorithm in order to detect overlapping clusters. their algorithm first turns a network with individual proteins as nodes, into a network with protein interactions as nodes . then, the mcl algorithm is used to cluster the network of interactions. finally, the algorithm re-converts the identified clusters from the interaction line graph back to the original graph with proteins as nodes. when the interaction network clusters are converted back to the original network, the same protein can appear in multiple clusters. nepusz et al.  <cit>  proposed the clusterone algorithm in order to detect overlapping clusters that is very similar to mcode by starting from a single seed vertex. but the algorithm merges each pair of groups where the overlap score is above a specified threshold. finally, it removes all clusters of a size less than three vertices or whose density is below a given threshold. ramadan et al.  <cit>  used the spectral clustering algorithm in order to detect overlapping clusters. their algorithm first find all possible exclusive clusters using the spectral clustering method. upon identifying all of exclusive clusters, it defines bridges  by examining the boundary nodes in the exclusive clusters . this gives highly connected clusters, but still permits overlapping clusters, as nodes in one cluster may be involved in another cluster.

another overlapping clustering algorithm is the procomoss algorithm proposed by anirban et al.  <cit> . the procomoss algorithm detect overlapping clusters using the genetic algorithm technique. they rely on the properties captured in the graph modeling the ppi network, and they also utilize the go terms to consider the biological properties of the proteins. their approach can be described as follows: first, encode the chromosome as a vector of integer numbers representing the indices of the proteins in the proteins set. then, initialize the population based on applying k-means clustering on both dimensions of the adjacency matrix a of a graph modeling ppi network. next, calculate the fitness values of each individual of the population using two objective functions. finally, select parents by adopting the same method used in nsga-ii  <cit>  and mutate the selected chromosome as follows: select a random node and then either remove that node or add its neighbors to the selected chromosome with the same probability. the main drawback of this algorithm is that the predicted clusters cover a small percentage of the network.

methods
genetic algorithm
genetic algorithm  is a bio-inspired meta–heuristic algorithm that generally founded on the theory of evolution  <cit> . ga searches for optimal solutions by sampling the search space at random and creating a population of candidate solutions. ga uses genetic operators  to evolve into a population of new generations that is hopefully fitter according to a given objective  function. survival of an individual to the next population is normally based on its fitness; that is survival of the fittest. however, the survival strategy normally does not preclude the survival of the less fit. using ga to solve a given problem requires the following problem-dependent design: genetic representation of the problem solutions, the fitness function, candidate selection methods, and genetic operators . the basic steps of ga are the following  <cit>  : 
create an initial population of candidate solutions.

loop until any/all the candidate solutions become solution. 
compute the fitness values of each of these candidates.

select candidates based on their fitness values.

create offspring from selected candidates using genetic operators

mutate each of these offspring using genetic operators.





spectral clustering
the graph clustering problem is that of finding the highly connected subgraphs  within the graph. the spectral clustering algorithm works by finding the minimum cut between two hcs subgraphs . the cut is the number of edges between the two distinct clusters. finding the minimum cut is solved by the eigenvector x∗ corresponding to the smallest positive eigenvalue of the generalized eigen problem 
 qx=λdx,  where q and d are the laplacian matrix and the diagonal matrix of the graph, respectively. we consider the graph initially as one cluster, and proceed to obtain two clusters from it. we choose the size of the two clusters by applying the k-means clustering algorithm on x∗ with k= <dig> to choose the value of the eigenvector component that makes the objective function value is as small as possible. by a recursive application of this procedure, we obtain a clustering of the entire network. the number, size, and density of the clusters is determined by the network topology and the threshold value of the objective function used to determine if a cluster will be split again, and are not pre-specified  <cit> .

we apply a spectral clustering method to identify initial subnetworks and clusters in the collins protein interaction network.

objective functions
in this paper, we use the following three objective functions  <cit>  to evaluate the quality of possible cluster structures. we compare the clustering achieved using these objective functions to the one achieved by our proposed objective function discussed later. we also compare clustering of all four objective functions to two gold standards. 
min-max-cut:

 jmcut=w12w11+w12w <dig>  

ratio cut:

 jrcut=w12|v1|+w12|v2|. 

normalized cut:

 jncut=w12d1+w12d <dig>   where dk=∑i∈vkdi the degree of each vertex belongs to vk and k={ <dig> } and 
 wil≡w=∑j∈vi,k∈vl,∈ewjk,  where i,l= <dig>  and wjk is the weight on edge jk.



clustering algorithm
in this section, we present a new overlapping clustering algorithm to help facilitate the different demands and purposes of cluster analysis. the structure of the new overlapping clustering algorithm, algorithm  <dig>  is shown in fig.  <dig>  algorithm  <dig> employs ga for clustering the ppi network. starting with an initial population of individuals , the algorithm generates a new set of individuals using genetic operators . the goal is to get individuals to converge to solutions  of maximum fitness according to the objective function.
fig.  <dig> clustering algorithm flowchart





representation and initialization
we represent each individual  as k lists {c <dig> c <dig> c <dig> ...,ck}, where k is the number of clusters. each list can store integer numbers in the range { <dig> ,...,n}, where n is the size of the data set, as illustrated in fig.  <dig>  the element j of a list is a node’s index of the graph g modeling the ppi network. it is possible that some elements of different lists can hold the same value j, which means that a protein with index j can exist in more than one cluster; this is in case of overlapping clustering.
fig.  <dig> population initialization



the population is composed of a number  of individuals, or possible clusterings. we use two different methods to initialize the population. the first approach generates m random individuals, where m is the size of the population, as follows: for each individual consisting of k lists, assigning an integer value j in the range { <dig> ,...,n}, where n is the size of the data set for each element randomly. for example, as illustrated in fig.  <dig>  the node with index  <dig> is assigned to the cluster c <dig>  while the node with index  <dig> is assigned to two clusters c <dig> and c <dig>  such a method should take into account the variety among the individuals of the population, which is supposed to be rather high.

in the second approach, we use the resulting clusterings of the spectral clustering algorithm  <cit>  to create the initial population.

density–based objective function
the objective function aims to calculate the fitness values for each individual of the population to indicate how well each individual is suited to be the solution of a given problem. in our case, the fitness value of an individual reflects the intra–cohesion of each cluster proposed by the individual, as well as the inter–cluster coupling of those clusters. the goal is to maximize intra-cohesion and minimize inter-coupling. we represent intra-cohesion and inter-coupling by the number of edges within and across clusters, respectively. we compute the fitness of an individual as follows: 
 jdcut=∑kwkkak+wki,  where wkk is the number of edges in a cluster ck, wki is the number of edges that has one endpoint in ck, and ak is the maximum possible number of edges in the cluster ck.

genetic operators
the most common operations used in genetic algorithms are selection, crossover, and mutation. we exclude the crossover operation because it creates too many explorations that disturb the potentially good solutions. regarding the parent–selection process, it is defined as the process of selecting individuals from the current population to create offspring for the next generation. this process aims to emphasize that the individuals with high fitness values are chosen in hopes that their offspring will have higher fitness as well. there are many ways to select parents, or individuals, from the current population for reproduction. algorithm  <dig> illustrates in detail the parent–selection process.



the mutation operation is defined as performing some changes in the values of a specific chromosome, or individual. consequently, the ga may reach to a better solution with the obtained individuals. we adapt the mutation operator used in  <cit>  and modify it in such a case to be suited to, and more efficient for, our problem. this operation can be described as follows: after selecting an individual to be mutated, its nodes are either moved from one cluster to another, or some nodes of the network are added to the selected individual, as shown in fig.  <dig>  figure 3a shows the selected node of the cluster and fig. 3b illustrates the cluster after adding the selected node’s neighbors from the network. algorithm  <dig> illustrates in detail the mutation process.
fig.  <dig> the mutation operation. a shows the selected node of the cluster c. b shows the cluster c after the mutation operator





quality assessment
we consider an approach for quality assessment that finds statistically significant matches between discovered clusters and the reference data such as precision , recall , and f−measure   <cit> . this approach measures the level of correspondence between discovered clusters and the reference data set by computing statistically significant matches between the two collections using hyper-geometric p-value, and used these matches to evaluate the precision and recall of the suggested clustering solution as follows. let c be the initial set of discovered clusters, and let c^⊆c be the subset of clusters that had a significant match based on hyper-geometric p-value.

here, p-value is used to determine whether a discovered cluster is annotated by certain terms from the reference data set at a frequency greater than that would be expected by chance. it is calculated according to the following hypergeometric distribution: 
 p−value=1−∑i=0k−1min−mn−ini,  where n is the total number of proteins, m is size of a list of proteins g marked to the reference term of interest , k is the number of proteins in a discovered cluster c, and i is the number of proteins shared between c and g.

for each predicted cluster c, let true positive  be the set of proteins shared between the cluster c and a reference protein complex g, while false positive  is defined as the set of proteins that exist only in the cluster c, and true negative  is defined as the proteins that are members of the reference complex g but not found in the cluster c. hence, p, r, and f-measure are calculated according to the following equations: 
 p=tptp∪fp,r=tptp∪tn,f-measure=2×p×rp+r. 

RESULTS
data source
we study the protein interaction network from the yeast organism since there are abundant high-confidence data sets for its protein interaction network. in our experiment, we applied our clustering algorithm on the collins protein interaction network extracted from the biogrid data set  <cit> . this network has  <dig>  interactions among  <dig>  proteins. it has an average degree , where the degree of a node in a network is the number of links connected to the node; the density of this network is  <dig>  .

high–quality data collections are needed as gold standards to validate clustering approaches. we assess the coherence of the discovered clusters based on the gene ontology   <cit> . we have used the cellular component ontology from go as the primary gold standard to compare the clusters obtained from the interactions data. we used the cellular components ontology in the go since it includes more proteins in the protein interactions network than the other ontologies. we have also used collections of protein complexes in the yeast that have been culled from the literature and cataloged in the mips yeast genome database  <cit> , as well as a hand-curated reference complex set called cyc <dig>  <cit> .

clustering comparisons
we compare the performance of our algorithm  with some of the methods mentioned in the related works section, which were commonly utilized for extracting complexes from protein interaction networks. we report the performance measures that were mentioned earlier. table  <dig> presents a comparison of the performance of our algorithm  with other existing methods for clustering for the collins data set. we used cyc <dig> complexes and mips complexes as the reference data sets in order to compute the performance measures.


a study by brohee and van helden  <cit>  that compared these algorithms  showed that the mcode and mcl algorithms, in particular, were very effective in identifying protein complexes from protein interaction networks. we investigated the performance of our method when compared to these two algorithms. in addition, we also investigated the performance of one of the recent algorithms for clustering . in short, we used the mcode, mcl, and clusterone algorithms to extract clusters from the yeast collins network.

clearly, our clustering algorithm , which was based on initial spectral clustering and used density cut as an objective function , has the lowest discard ratio  over all the other approaches; a low value of discard ratio indicates that a high proportion of the proteins in the considered protein network are clustered. on the other hand, the mcode algorithm has the highest discard ratio  because it searches for high–density clusters only. also clustering algorithm  yields a high precision value with cyc <dig>  and also a high recall value . mcode has a similar results, but with one major drawback, which is that not all the proteins in the network are clustered, as illustrated by the high discard value. it can be seen that our clustering algorithm outperforms the mcode algorithm by a significant margin in terms of discard and recall values. in addition, our algorithm with different objective functions and initializations  usually discover more clusters, while mcode predicts fewer clusters; and the other approaches, mcl and clusterone, predict fewer clusters than our method and more clusters than mcode, as illustrated in table  <dig> 

in comparison with the mcl and clusterone algorithms, our algorithms exhibit better correspondence with the complexes catalog within cyc <dig> data set, and has higher recall and precision levels than those attained by the mcl and clusterone.

clustering quality
we assess the biological significance of the clusters in the collins network by comparing them with components in the gene ontology. we use the go term finder  <cit>  to get the most significant go-terms, go-id, and p-values for a list of proteins . table  <dig> tabulates some of the clusters of the collins network that have a significant p−value. each cluster is listed by its id used in this study, and the number of proteins in it. also tabulated is the number of cluster proteins in a go component that has the highest overlap with it. this number is expressed as a percentage . these percentages are  <dig> for most clusters, showing that these clusters in the network overlap well with the corresponding go components. proteins in a go component are not found in the cluster, mostly when the proteins are not present in the collins network. table  <dig> clearly shows that genetic algorithm–based methods are capable of identifying the protein complexes.
the go component that has the lowest p-value with these clusters is listed, the number of proteins in the cluster that overlap with the go component are listed as percentages of the number of proteins in the cluster . p-values defined in the text are also shown



CONCLUSIONS
in this paper, we proposed a robust approach for identifying protein complexes in ppi networks. the approach takes advantage of ga to help address the complex and heterogeneous nature of protein networks clusterings. we designed a new objective function to allow, overall, for the maximizing of intra-cluster cohesion, and the minimizing of inter-cluster coupling. experimental results have shown that our objective function performs better than other objective functions proposed in the literature to identify overlapping clusters in ppi networks. in general, our clustering approach is found to be more accurate and consistent than existing methods  when compared with two reference sets: mips and cyc <dig>  using the collins network.

in conclusion, our approach outperformed competing approaches and is capable of effectively detecting both dense and sparsely connected biologically relevant protein complexes with fewer discards.

