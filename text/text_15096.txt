BACKGROUND
transcriptome sequencing
recent advances in dna sequencing technology have greatly reduced the cost, time and effort required to generate large volumes of sequence data  <cit> . while new sequencing approaches have been used to great effect in well-studied species  <cit> , perhaps the biggest beneficiaries have been research programmes focussing on non-model organisms. for such organisms, which typically lack a reference genome sequence, transcriptome sequencing offers an efficient way to explore the regions of the genome likely to be of most interest to researchers  <cit> . the production of a novel transcriptome typically involves several steps  <cit> . mrna is extracted from the organism of interest, purified, fragmented and reverse transcribed into cdna. several such cdna collections may be made in order to capture transcripts that are only produced in specific tissue types, life stages, environmental conditions, etc. the cdna molecules are then ligated to sequencing adapters and size-selected before having one or both ends sequenced. the result is a very large number of short reads that must undergo significant processing before they can be used to investigate the biology of the organism.

the details of the data-processing steps depend on the details of the experiment and the sequencing technology, but the steps themselves remain the same  <cit> . read sequences are cleaned to remove low-quality regions and sequencing adapters before being assembled to give a collection of contigs, or putative transcripts. to gain an insight into the functions of the genes represented by these transcripts, and to identify novel transcripts, the contigs are annotated using a variety of methods. typically, researchers annotate contigs using a combination of similarity to known sequences and protein domains  <cit>  and machine-learning methods which identify features such as transmembrane domains and signal peptides  <cit> . these annotations can be used to put the putative transcripts in biological context  <cit> .

need for tools
the increase in the availability of transcribed sequence data places corresponding demands on the bioinformatic tools used to make sense of it. while tools have been developed to carry out the tasks of cleaning  <cit> , assembling  <cit>  and annotating  <cit>  transcribed sequence data, integration of these tools into a pipeline is generally on an ad-hoc basis and in a manner that is not user-friendly. as high-throughput sequencing becomes more pervasive, analysis tools that can be used by biological researchers who are not expert bioinformaticians to both create and investigate annotated transctriptomes will become essential. the increasing volume of sequence data also puts pressure on methods of data dissemination. publications and raw sequence data resulting from transcriptome sequencing projects are generally made available and archived, but intermediate, detailed annotations are typically not.

existing solutions
some tools exist that partially address these needs, most focussing on either the process of annotation or visualization . partigene  <cit>  is an integrated pipeline for processing sanger dideoxy expressed sequence tag  data. it employs a similarity-based assembly process, built for clustering sanger sequence data, that is not suitable for next-generation sequence data, and the analysis portion of the tool requires considerable technical expertise to use. cbrowse  <cit>  is a recently-published web application that provides an interface to pre-assembled contig and read mapping data. its focus is on identifying polymorphisms, repeats and sequencing errors rather than on annotation. many existing annotation tools also have user-friendly web interfaces  <cit> , but they are generally geared towards small numbers of input sequences and do not integrate multiple types of annotation.

the scope of this table is restricted to tools designed for transcriptome analysis – genome browsers are not included. we define a project as being in active development if the most recent change to the source code repository was made less than one year ago.

several tools offer potential solutions for data exploration. brigep  <cit>  is a suite of tools that includes a transcriptome browser to address the need for data visualization. however, brigep is focussed on integration with proteomic data, requires significant technical ability to set up, and does not assist the user in creating annotation. similarly, the transcriptomebrowser  <cit>  tool offers an interface to existing transcript data with a focus on molecular interactions. genome browsers  <cit>  are feature-rich, but they typically require considerable effort to set up, and the gene-centric requirements of transcriptome analysis and visualization do not fit well into their genome- and chromosome-centric paradigm  <cit> .

to address the need for an integrated, dependency-free, intuitive tool for transcriptome annotation and publication we have developed afterparty, a web application that runs entirely within a browser and functions both as an annotation tool and a transcriptome browsing and visualization tool. afterparty takes as its input either raw reads or assembled contigs, and uses existing best-practice tools and databases to annotate them, resulting in collections of annotated putative transcripts  along with metadata describing how the sequences were produced. afterparty also acts as a web interface to datasets, allowing non-bioinformatician users to browse contigs, search annotation, and define and visualize sets of contigs. using afterparty, a biologist can turn a collection of next-generation sequencing reads into a durable, web-accessible transcriptome resource without the need for expert knowledge, software dependencies, or extensive computing power.

implementation
the afterparty web application functions as an interface to two sets of tools – one for creating datasets, and one for searching, browsing and visualizing them. to create a new dataset, the user uploads either a set of raw sequencing reads which afterparty assembles into contigs, or a collection of pre-assembled contigs  and, optionally, coverage and quality data. contigs are then annotated and the annotations indexed for rapid searching. to investigate an existing dataset, a user can browse individual contigs or search within datasets for contigs of interest. searches can interrogate the annotations or contig properties  and can be performed across multiple assemblies in a dataset . afterparty is implemented as a web application and is written in groovy  <cit>  using the grails  <cit>  web framework and the postgresql relational database management server  <cit>  for data storage. it is offered as a publicly-available server at http://afterparty.bio.ed.ac.uk, but can also be downloaded and run locally.

dataset structure
afterparty datasets are organized into a structure with two overlapping hierarchies – one for raw sequence data, and one for assembled sequence data . the raw sequence data hierarchy has been designed to be congruent with the the international nucleotide sequence database collaboration  bioproject  <cit>  schema to ease integration with raw sequence archives, and is described here from the bottom-up for clarity. a run contains read data for a single sequencing run, and an experiment may contain reads from several independent runs. each experiment in a dataset may have different rna preparation and sequencing technologies. experiments are grouped together into samples, which reflect separate biological sources of rna material – for example, different tissue types, life stages, or environmental conditions. a compound sample represents a collection of samples and usually corresponds to a single species or strain of source organism. finally, a study is a collection of related compound samples, such as a group of closely-related species.

putative transcripts are represented in afterparty by contigs, which are grouped into assemblies. a compound sample can have multiple assemblies. using this mechanism it is possible to have multiple versions of an assembly for a single set of reads. a contig may be decorated with multiple pieces of information, each of which is represented by an annotation. each individual input sequence that makes up a contig is represented as a read. arbitrary collections of contigs are stored as contig sets. a contig can belong to any number of contig sets.

adding data
afterparty is able to accept input at any stage in the annotation workflow outlined above. briefly, there are three ways to create a dataset within afterparty . for data derived from  <dig> pyrosequencing, afterparty can be used for both assembly and annotation . for data derived from other sequencing methodologies  afterparty, assembly must be carried out before data are uploaded to afterparty .

workflow a: upload a collection of raw sequencing reads, and allow afterparty to assemble and annotate them
in this scenario, the user uploads a collection of  <dig> pyrosequencing reads in fastq format. afterparty will carry out read assembly using the mira assembler  <cit> , optionally trimming adapter sequences using ea-utils  <cit> . it will then annotate each resulting contig by carrying out a sequence similarity search using blastx  <cit>  against the uniprot  <cit>  database of known protein sequences, and running interproscan  <cit>  to identify known protein domains. quality and coverage information for each base in each contig as reported by the assembler will be stored along with the contig sequence, annotation, and read mapping locations.

workflow b: upload a collection of assembled contigs, and allow afterparty to annotate them
in this scenario, the user has already assembled their sequencing reads into contigs and has various choices for uploading them. they can upload a fasta format file containing contigs, in which case no coverage, quality or read mapping data will be stored, or they can upload an ace  <cit>  format file which contains coverage, quality and read mapping information. once uploaded and stored, contigs are annotated as described in workflow a.

transcriptome assembly from high-throughput data remains an active field of research. thus workflow b allows users to apply methods best suited to their data type and organism to generate an optimal contig set. in particular, this scenario is likely to be useful for illumina rna-seq sequence data, as well as for complex or large  <dig> or sanger transcriptomes that are unlikely to be assembled well by the default mira assembler. hybrid approaches to transcriptome assembly, in which output from multiple assembly tools is merged, can also be used under this scenario  <cit> .

workflow c: upload a collection of assembled contigs along with annotation
in this scenario, the user has already assembled a collection of contigs and run the necessary annotation tools. contigs are uploaded as described for scenario b, and annotation data are uploaded in either xml  or gff <dig>  format. no assembly or annotation is carried out by afterparty; the data are merely stored and indexed. this scenario is likely to be useful for users who have access to parallel compute facilities that can carry out the annotation more rapidly than could be accomplished using afterparty. this workflow allows the use of any blast database for annotation – for instance, a genome database for a closely-related organism.

in all three workflows datasets remain private, and only visible to the logged-in owner, until explicitly made public.

annotation
for the workflows where annotation is carried out inside afterparty , annotation proceeds in two steps. first, blastx  <cit>  from the blast+  <dig> . <dig> package is used to search the uniprot  <cit>  protein reference database for sequences showing sequence similarity to the contig sequence. the ten most highly similar uniprot entries are stored as annotation, along with their e-value scores and the regions of the contig to which they show similarity. second, the interproscan  <dig> package  <cit>  is used to identify protein domains and regions of interest on the contig using the following applications: prodom- <dig> , pfama- <dig> , tigrfam- <dig> , smart- <dig> , gene3d- <dig> . <dig>  coils- <dig> , phobius- <dig>  <cit> . all interproscan matches are stored along with their e-value scores  and positions.

browsing, searching and contig sets
once a dataset has been created, afterparty offers users a variety of ways to explore it. all annotations, whether generated by afterparty or uploaded by the user, are indexed using postgresql's full-text indexing tools. these improve the quality of search results by removing common english words, dealing with suffixes, and allowing boolean search terms. users can browse a table of the contigs belonging to a particular assembly, compound sample, or study. alternatively, they can use any of afterparty's search tools to identify contigs of interest. there are three ways to search in afterparty. to search by annotation, users supply a search string  and afterparty will identify the set of contigs that have matching annotation. to search by similarity, users supply an input dna or protein sequence and afterparty uses blastn, tblastn or tblastx to carry out a sequence similarity search and identify contigs with significant similarity. to search by contig property , users select a region of a scatter plot encompassing the values they wish to include.

search results can be saved as contig sets, so that they can be retrieved or shared with colleagues without having to re-run the search. searches can also be restricted to contig sets, leading to a powerful and intuitive way to identify contigs of interest by iteratively combining different types of search. for example, a user can start with a set of contigs from a particular developmental stage, search inside that set for contigs with a particular protein domain, then search inside the resulting set for contigs longer than a minimum length.

viewing contig data
once contigs of interest have been identified, afterparty allows users to view all the information associated with a particular contig on a single page. figure  <dig> shows an example overview page for a contig derived from previously published data  <cit> . the contig annotation display gives a graphical overview of the annotation and metadata associated with the contig, including charts of quality and read coverage , location and significance of sequence similarity and protein domain annotations, and alignment of sequencing reads. quality and read coverage will only be available if the assembly was either carried out inside afterparty or uploaded in ace format. quality scores are reported by the assembly software and follow the phred specification  <cit> ; coverage scores are calculated by afterparty from the positions of the reads. below the graphical overview are tables listing details of individual annotations, along with links to relevant external resources .

visualization
grouping of contigs into contig sets allows in depth exploration of properties within and between sets. afterparty automatically creates contig sets for entire assemblies, compound samples, and studies. database owners and users can define additional contig sets based on particular properties of contig annotation, such as stage-specific expression, or the results of a sequence similarity search.

to view and compare contig sets, afterparty contains a number of interactive visualization tools . numerical attributes of contigs  can be displayed either as a scatter plot or a histogram. scatter plots can have any combination of available axes, which can be linear or logarithmic. trend lines can be included, and the user can zoom in on any portion of the chart. hovering over a single point, corresponding to a single contig, displays a pop-up with detailed information about the chosen contig, and clicking takes the user to the overview page for that contig. users can save contigs that fall within a zoomed region as a new contig set. histograms can show the distribution of contigs along any single axis, and the frequency axis can be linear or logarithmic. when comparing multiple contig sets, frequencies can be scaled relative to contig set size in order to facilitate comparisons. both scatter plots and histograms allow the user to exclude very short contigs or those with very low coverage. when comparing multiple contig sets, each is shown on the same axes as a different coloured data series. the user can toggle the visibility of a given contig set, or bring a particular contig set to the top of the chart to ease comparisons.

RESULTS
to demonstrate the capabilities of afterparty we used the system to generate publicly available annotated datasets for three transcriptomes from 'neglected' organisms .

litomosoides sigmodontis transcriptome
we assembled and annotated a collection of transcriptome sequence data from the filarial nematode litomosoides sigmodontis using the workflow depicted in figure 2a. l. sigmodontis is the subject of an ongoing transcriptome project  <cit> , and the transcriptome data is typical of the type for which we expect afterparty to be useful.  <dig>  reads from five libraries were assembled, and annotated using an installation of afterparty on an 8-core server. assembly took ~ <dig> hours and annotation took ~ <dig> days. the resulting dataset has  <dig>  contigs.  <dig>  have at least one uniprot annotation, and  <dig>  have at least one protein domain annotation. the dataset can be explored on the afterparty web server  <cit> . a subset of these raw l. sigmodontis data are available as a test dataset for new users.

anguilicolla crassus transcriptome
we used a collection of already-assembled transcripts to create a transcriptome resource for the nematode anguilicolla crassus using the workflow depicted in figure 2b. sequencing reads for male, female, and l <dig> individuals were generated using roche/ <dig> flx titanium chemistry and assembled using a hybrid strategy. the assembled contigs were uploaded before being annotated using afterparty. the resulting dataset has  <dig>  contigs.  <dig>  had at least one uniprot annotation and  <dig>  had at least one protein domain annotation. the dataset can be explored on the afterparty web server  <cit> . a. crassus transcriptome assembly data were kindly provided by emanuel heitlinger   <cit> .

plodia interpunctella transcriptome
we used a collection of already-assembled transcripts along with existing annotation to create a transcriptome resource for the indian meal moth, plodia interpunctella, using the workflow depicted in figure 2c. the assembly was built using trinity  <cit>  from rna-seq data derived from four samples of fourth instar lavae, each consisting of  <dig> pooled individuals. annotation was generated using blast  <cit>  and interproscan  <cit>  on a sun grid engine  compute cluster. the assembled contigs and annotation files were uploaded to afterparty to create a dataset with  <dig>  contigs.  <dig>  contigs had at least one uniprot annotation and  <dig>  contigs had at least one protein domain annotation. the data can be explored on the afterparty web server  <cit> . p. interpunctella transcriptome assembly data were kindly provided by seanna mctaggart .

assembly and annotation timing
since afterparty acts as a wrapper around existing third-party tools for assembly and annotation, the overhead imposed versus running the tools manually is minimal. for a test dataset of  <dig>  roche  <dig> reads take from the l. sigmodontis dataset <cit> , assembly using mira  <cit>  took  <dig> minutes using afterparty compared with  <dig> minutes when run manually. annotating a subset of  <dig> contigs using a blastx  <cit>  search vs. uniprot  <cit>  took  <dig> seconds in afterparty compared with  <dig> seconds when run manually. running interproscan  <cit>  against the same set of  <dig> contigs took  <dig> minutes in afterparty compared with  <dig> minutes when run manually. timing tests were carried out on a workstation with  <dig> intel xeon l <dig>  <dig> ghz cpus.

development and deployment
we have designed afterparty to be locally deployable for researchers who wish to host datasets themselves, take advantage of local compute facilities, and maintain fine-grained access control. local deployment of afterparty can be carried out in two ways. the source code is freely available  and can be installed  on a standard web server. alternatively, we have made available a virtual disk image including afterparty and all dependencies, which may be used to create a virtual machine running afterparty. afterparty has been tested using multiple datasets of between ~ <dig>  and ~ <dig>  contigs and found to run satisfactorily for dataset browsing and visualization on a 2-core web server with  <dig> gb ram.

a single afterparty instance is capable of serving multiple datasets, so we anticipate that a single local installation will be sufficient to serve the needs of a group of researchers working on different projects. the afterparty interface has been designed to facilitate collaboration and sharing of information and is designed such that each study, compound sample, assembly, contig set and contig has a unique url. users can easily share a link to a given resource by embedding the url in an email or web page.

an entire afterparty instance  can be archived either as a database dump or as a virtual disk image. database dumps are more compact and hence easier to store. however, recent long-term archival solutions achieve storage costs on the order of $ <dig>  per gigabyte per month  <cit> , making the storage of complete virtual machines a realistic option .

outlook
we anticipate that the need for tools like afterparty will increase as next-generation sequencing technologies become ever more accessible. in particular, we see a role for afterparty in presenting transcriptome studies which encompass multiple related organisms, aggregating data across research projects.

obvious extensions to afterparty are the inclusion of additional assembly options and of new types of annotation data. although the mira assembly tool has been shown to produce suboptimal assemblies for some datasets  <cit> , we chose it for use in afterparty because of its modest computational requirements, non-restrictive license, and ease of integration. we plan to integrate additional assembly tools and strategies into afterparty, which will allow the use of input data from other sequencing platforms. the modular design of afterparty's annotation framework ensures that new types can be easily added. we plan to add storage for expression data, such as microarray data and sequence-counting estimates of transcript abundance, open reading frames, matches to proteomics resources, and pathway annotations. we believe that the use of cross-species contig sets to store ortholog relationships will be particularly useful. we also plan to add export tools to afterparty that will aid users in preparing data for submission to annotation archives, such as the international nucleotide sequence database collaboration  third party annotation  databases.

the computational requirements of afterparty vary throughout the workflow in a distinctive way. the assembly stage can have high memory requirements, and the annotation stage can have high cpu requirements. once a dataset has been assembled and annotated, however, the memory and cpu resources needed to serve it are modest. cpu-intensive operations such as searching annotations are very brief . this pattern of transient high demand  and long-term low demand  makes afterparty a good candidate for cloud-based compute infrastructure. we are currently investigating the possibility of implementing a highly parallel cloud computing model for the afterparty annotation pipeline.

CONCLUSIONS
afterparty is an open-source tool for turning raw transcriptome sequencing reads and assembled contigs into searchable, browsable transcriptome resources with powerful visualization tools. in contrast to existing solutions, afterparty integrates all steps of the transcriptome annotation workflow and presents an intuitive user interface for non-expert users, while being flexible enough to accommodate assemblies and annotations produced by more experienced users. it implements best-practise assembly and annotation methods, and facilitates data sharing and visualization. it is our hope that, by easing the process of annotation, publication, and stable archiving, afterparty will facilitate the distribution and exploration of richly-decorated transcriptome data that would otherwise remain inaccessible.

availability and requirements
project name: afterparty

project home page: https://github.com/mojones/afterparty2

operating system: platform independent 

programming language: groovy 

other requirements:

git 

java   <dig>   

grails  <dig> . <dig> 

grails plugins:

executor 

spring security 

spring  security  ui  

postgresql  <dig>  

ncbi blast+  <dig> . <dig> 

uniprot 

interproscan  <dig> 

mira  <dig> . <dig> 

license: gnu gpl

any restrictions to use by non-academics: no

availability notes
because of the number of dependencies that afterparty relies on, we have made the software available in three different ways.

via the public server at afterparty.bio.ed.ac.uk
no special credentials are necessary to browse published datasets. we are happy to host new transcriptome datasets on this server; please contact the corresponding author  to obtain a user account. to get started, follow the various tutorials either on the wiki , or as screencasts .

by downloading the source code and installing dependencies
the source code for afterparty is hosted at github . pull requests are welcome. bugs and feature requests can also be submitted at the above address. follow the installation instructions here: https://github.com/mojones/afterparty2/wiki/localinstall.

by downloading a virtual disk image
to assist researchers who would like to run a local installation of afterparty, we have prepared a virtual disk image, based on ubuntu   <dig> , which can be run under a virtual machine hypervisor such as virtualbox. the virtual disk image expands to around  <dig> gb and requires a 64-bit host. this is the easiest way to get afterparty running locally as all necessary dependencies and permissions are already set up. follow the installation instructions here: https://github.com/mojones/afterparty2/wiki/vminstall.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
the project was conceived by mj and mb. the software was designed by mj and mb and implemented by mj. the l. sigmodontis afterparty dataset was assembled by mj. both authors read and approved the final manuscript.

