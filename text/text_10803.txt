BACKGROUND
gene expression studies can reveal genes and pathways critical for specific disease phenotypes  <cit>  and can identify molecular subtypes , allowing for a better understanding of the etiologies and features of many diseases. the large numbers of formalin-fixed paraffin-embedded  tissues which are routinely collected for clinical and diagnostic purposes represent an important resource for genomic studies. while it is possible to perform whole genome expression assays and sequencing in ffpe samples, it is currently cost-prohibitive to do so in the very large collections of ffpe samples that are available. most ffpe-based research to date has focused on assaying a subset of genes selected based on a current hypothesis of interest  or a reduced gene set classifier of molecular subtypes . the number of genes included is determined both by scientific rationale and cost, and by definition, represent only a subset of gene expression information. we sought to develop a method to maximize the amount of gene expression information obtained from assayed samples by inferring the expression levels of unmeasured genes.

conceptually, this problem is similar to genotype imputation. loci physically located near each other on a chromosome tend to be inherited together, and sets of highly associated loci can be identified using linkage disequilibrium  which is a measure of co-occurrence of alleles. representative or ‘tag’ single nucleotide polymorphisms  from these sets can be selected to be assayed and the remaining values inferred based on ld  <cit> .

in an analogous manner, we propose to use the organism-, disease-, and tissue-specific gene expression correlation structure to identify genes which indirectly provide information about the expression of other genes in that tissue. the correlation of gene expression values is well studied and has been used to help inform molecular pathway definitions  <cit> , disease subtype discovery  <cit> , and clinical prognosis and treatment  <cit> . just as it is important to select tag snps based on allele correlations in a population similar to the population studied, it is also important to use gene expression patterns from the specific tissue of interest  <cit> . the robustness of the co-expression relationships directly affects the inference of expression of unmeasured genes; for this reason, our method is valid for stable systems of co-expression, e.g., for design of large-scale targeted assays following initial genome-wide measurements, not dynamic systems such as differentiation where the co-expression relationships are expected to change. we focus on high grade serous ovarian cancer  for the development and evaluation of our algorithm, but also apply our method to a breast cancer dataset. the wealth of publicly available expression data allows our method to be used for studies of a wide variety of different organisms, tissues, model systems, and disease types. while our intention is to identify genes that broadly capture gene expression information for many genes, recent work suggests that these genes may also be enriched for disease drivers  <cit> . herein, we present our method of gene selection that can be combined with candidate gene sets as a cost-effective way to increase the amount of gene expression information obtained in large studies where using a genome-wide measurement platform is not feasible.

RESULTS
our greedy geneset selection  algorithm uses pairwise gene expression correlation  to identify sets of correlated genes, and within those sets selects genes to directly measure and genes to attempt to infer using the directly measured genes. we applied this algorithm to the cancer genome atlas  hgsc data , and compared the ability of ggs to maximize the number of inferred genes given a user defined size of directly measured  genes to that of a ranked-degree gene selection method. we tested the ability to infer unmeasured expression by constructing regression models for unmeasured genes and evaluating the accuracy of these predictions in independent studies .fig.  <dig> gene selection a and expression prediction b workflows. a.1) the workflow starts with the tcga hgsc affymetrix gene expression data which is filtered to remove no/low expressed genes. a.2) a symmetrical gene-by-gene correlation matrix is created by calculating pairwise pearson’s correlation coefficients . a.3) a user-determined threshold is applied to the absolute value of the pearson’s correlation coefficients  in order to generate a binary adjacency matrix. here, black indicates no correlation beyond the threshold between two genes, and white indicates the existence of such a correlation. a.4) a greedy geneset selection algorithm iteratively builds a set of genes to directly measure  and a set of genes that are predictable using the dm set . the predictable set is defined as those eligible but unmeasured genes that are strongly correlated to at least n dm genes where n is the redundancy chosen. b.1) the expression prediction workflow starts with splitting the tcga hgsc data into training and testing partitions. the training partition is used to build a regression model for each gene in the predictable set. only the genes in the dm set that are correlated to the specific predictable gene above the |rp| threshold are used as predictors. if there are multiple predictors, a forest of regression is trained. otherwise, a polynomial regression of degree  <dig> is trained. b.2) the regression models are then used in the testing partition of the tcga hgsc data to predict expression. the true and predicted values are compared using the spearman rank correlation . b.3) the accuracy of the regression models are assessed across populations and platforms using four independent hgsc datasets. in each dataset, the regression models are used to predict expression and rs is calculated



characterization of eligible genes
we removed genes that did not appear to be expressed , leaving  <dig>  genes for analysis . we calculated pairwise correlations between these genes to identify those for which an expression level could be predicted. the minimum number of genes to which an eligible gene must be correlated in order for it to be eligible was set at  <dig>   <dig>  or  <dig>  for three different correlation thresholds  of  <dig> ,  <dig> , or  <dig> . ggs selects the directly measured genes and the theoretically predictable genes from these eligible genes. the number of genes eligible to be directly measured or predicted varies as a function of the correlation threshold and the minimum number of genes to which an eligible gene must be correlated . more stringent correlation thresholds reduce the number of genes correlated to at least one other gene at or above that threshold. when the minimum number of correlated genes is  <dig> and |rp| is  <dig> ,  <dig> , and  <dig> , there are  <dig> ,  <dig> , and  <dig>  eligible genes  respectively. to determine the extent to which the eligible genes represent a wide variety of biological processes, we performed enrichment analysis on the protein analysis through evolutionary relationships  go-slim biological process terms  using the  <dig>  eligible genes identified using the  <dig>  threshold with background frequencies determined by the  <dig>  truly expressed genes. after applying a bonferroni adjustment for the  <dig> enrichment tests, only  <dig> processes were underrepresented, and  <dig> processes were overrepresented at a p-value cutoff of p <  <dig>  . this suggests that the distribution of the eligible genes may be generally representative of the distribution of all expressed genes across most of these high-level biological processes.fig.  <dig> definition of eligible genes. a distribution of the 90th quantile of expression values for all genes in the tcga data. the distribution is bimodal, and we excluded genes below the cutoff of  <dig>  because most samples have low/no expression for these genes. b number of eligible genes  by the correlation threshold  when the minimum number of genes to which an eligible gene must be correlated is set to  <dig>  highlighted in red are specific values when the correlation threshold is set to  <dig> ,  <dig> , and  <dig> . c same as b but with the minimum number of genes to which an eligible gene must be correlated is set to  <dig>  d same as b but with the minimum number of genes to which an eligible gene must be correlated is set to 3



ggs-selected gene sets can predict the expression of a larger number of genes compared to ranked-degree-selected gene sets
we compared the performance of ggs to a ranked-degree method using all tcga samples. the ranked-degree method builds a set of n genes to directly measure by selecting the top n genes correlated with the largest number of genes. in contrast, as ggs constructs the dm and predictable sets, the edges are removed; i.e., correlations associated with those genes are ignored for the remainder of the set construction . both approaches require:  <dig>  a binary matrix indicating whether pairs of genes are correlated beyond a specified threshold ;  <dig>  a minimum number of directly measured genes which must be correlated with an unmeasured gene in order to consider that unmeasured gene predictable ; and  <dig>  the targeted size of the dm set. we used the tcga hgsc gene by gene correlation matrix and three |rp| values  to create binary matrices, then applied both the ranked-degree and ggs approaches specifying redundancy as  <dig>   <dig>  or  <dig> and a targeted dm set size of  <dig>  and calculated the size of the resulting predictable sets . ggs consistently returned at least approximately three times the number of predictable genes across this range of redundancy values and |rp| thresholds. under the most conservative parameters, with redundancy of  <dig> and |rp| =  <dig> , the ggs predictable set was approximately 11-fold larger than that of the ranked-degree approach. therefore, the edge removal portion of the algorithm likely improves ggs performance by preventing over-representation of correlated genes in the dm set.fig.  <dig> example run of greedy geneset selection . we represent the binary adjacency matrix as a network in which the nodes are genes, and an edge exists if the genes are correlated beyond the |rp| threshold. dm size and redundancy are set to  <dig> and  <dig> respectively



predictable gene set size across ggs parameter values and for candidate gene sets
we performed a parameter sweep across |rp| of  <dig> ,  <dig> , and  <dig> , redundancy of  <dig>   <dig> and  <dig>  and dm set size , totaling  <dig> individual ggs runs with resulting dm sets. for each of the dm sets, the size of the corresponding predictable set was calculated . as shown in fig. 2b–d, the total number of eligible genes for given parameter values is known, and we subtracted the number of genes in the dm and predictable sets from the number of eligible genes to quantify the eligible genes missed . a consistent pattern was observed; the size of the predictable set increased with increasing dm set size and decreasing |rp| and redundancy. redundancy strongly influences the number of predictable genes. for example, for |rp| of  <dig>  and a dm set size of  <dig>  the number of predictable genes is  <dig> -fold higher when redundancy is  <dig>  compared to redundancy of  <dig> . the correlation threshold  also has a strong effect; when redundancy is  <dig> and the dm set size is  <dig>  the number of predictable genes is  <dig> -fold higher for |rp| of  <dig>   compared to |rp| of  <dig>  . the increase in number of predictable genes as the number of directly measured genes increases is expected. however, a plateau is reached as the size of the dm set increases. this plateau is caused by ggs exhausting the larger sets of correlated genes, and subsequently adding genes to the dm set with a smaller return in increased predictable set size. a network representation of the eligible genes when |rp| is  <dig>  and redundancy is  <dig> is presented in additional file 2: figures s <dig> and s <dig>  the average number of neighbors was approximately  <dig>  the ggs-identified dm set genes are red , the predictable genes are blue , and the remaining eligible genes are grey. ggs selects from the dense neighborhoods first but with  <dig> genes in the dm set the algorithm has started to select from the small  <dig> node connected components which means only  <dig> predictable gene is gained for every dm gene added. this explains the diminishing returns in number of predicted genes observed in fig.  <dig> which occurs when selecting from the small connected components.fig.  <dig> predictable gene set size across ggs parameters. the number of predictable genes by fold redundancy , number of directly measured genes , and correlation threshold . solid lines indicate the number of predictable genes given a ggs-selected dm set of size indicated by the x-axis. the dotted line indicates the remaining eligible genes that are neither predictable nor directly measured



we performed parallel analyses of breast cancer gene expression data from tcga. we observed results similar to the hgsc datasets, with increasing predictable set size as a function of increasing dm size, decreasing redundancy, and decreasing correlation threshold. predictable set sizes were consistently larger than those found in hgsc. for example, with a set of  <dig> dm genes and a correlation threshold and redundancy of  <dig>  and  <dig> respectively,  <dig>  predictable genes were identified in the breast cancer data, versus  <dig> predictable genes observed in the hgsc data. these results are provided in our source code repository  <cit> .

we developed ggs to augment hypothesis-driven candidate gene sets with small numbers of additionally measured genes that allow inference of many unmeasured genes. in this scenario, ggs automatically adds all of the candidate genes to the dm set and selects additional dm set genes using the specified binary adjacency matrix. to characterize the performance of ggs with candidate gene sets, we performed the parameter sweep using either the yoshihara et al.  <cit>  or tcga  <cit>  prognostic gene sets for hgsc which contain  <dig> and  <dig> genes respectively. starting with a dm set that includes the candidate gene set, the number of predictable genes was quantified across the remaining parameter sweep categories . the yoshihara and tcga candidate gene sets predicted  <dig> and  <dig> genes respectively when |rp| was  <dig>  and redundancy was  <dig>  these candidate gene sets were created to capture specific biological signals and are not optimized to predict unmeasured gene expression . once ggs augmented the yoshihara et al.  <cit>  and tcga  <cit>  candidate gene sets with  <dig> additional dm genes, they predicted  <dig> and  <dig> genes respectively. this suggests that with a minimal investment in additional assayed genes, ggs can more than double the amount of gene expression data captured.

using directly measured genes as predictors, regression models predict unmeasured expression values with high accuracy
to test whether the dm set accurately predicted unmeasured genes, we built a regression model for each gene in the predictable set using the tcga training partition  . for a specific predictable gene, only the genes in the dm set that were correlated beyond the |rp| threshold were used as predictors in the regression model. to evaluate the performance of the regression models, we predicted expression of specific genes using the regression models in the tcga testing partition , and then correlated the true and predicted values using the spearman rank correlation . expression prediction was carried out for all parameter sets defined by the parameter sweep  and for the parameter sweep results with the two candidate gene sets.

we also assessed the performance of these regression models in four independent hgsc expression datasets  . we summarized the accuracy  of the regression models in the tcga testing partition and the four independent datasets , and repeated analyses including the two candidate gene sets . we observe similar average rs across most datasets for a given set of parameters. as expected, the average accuracy of our prediction increases as redundancy and |rp| increase. in most of the data sets , accuracy generally increases with increasing dm set size. however, in the yoshihara and mayo data, the maximum rs is achieved when the dm set size is very small ; as more genes are predicted the average rs slightly decreases and levels out . a similar pattern is observed when using ggs augmented candidate gene sets across all datasets . the highest rs is achieved using the candidate genes alone to predict a relatively small number of genes. however, as the dm set size increases and there is a concomitant increase in the number of predicted genes, the rs decreases and levels out. importantly, when redundancy is 3-fold the average rs  consistently exceeds the |rp|used to identify the genes in the dm and predictable sets . the highest confidence in imputation accuracy is achieved with redundancy of  <dig> and |rp|  <dig> .fig.  <dig> expression imputation accuracy. average expression prediction accuracy by number of directly measured genes , fold redundancy , correlation threshold , and dataset . the y-axis indicates the mean and bootstrapped standard error of the spearman rank correlation between actual expression and predicted expression



for  <dig> of the tcga samples assayed on the affymetrix platform, rna sequencing  gene expression data is also available. we used the regression models to predict expression in these samples and in the subset of these samples, which were included only in the tcga testing partition . the overall pattern of rs is similar to that observed in the validation datasets.

discussion
large collections of paraffin-embedded tissue are a rich resource to test hypotheses based on gene expression patterns; however, measurement of genome-wide expression is cost-prohibitive on a large scale. using the known expression correlation structure within hgsc, we demonstrate that our ggs approach can efficiently identify reduced sets of directly measured genes which accurately predict a maximized number of unmeasured genes in independent data sets, with the ranked correlation between true and predicted expression of  <dig>  or greater in all testing scenarios, and nearing  <dig>  for conservative parameters. this testing accuracy was observed across affymetrix and agilent mrna expression array platforms and was also demonstrated in rna-seq expression data. while we emphasize the utility of ggs for the selection of genes to be assayed in future studies, it can also be used to increase the utility of existing targeted gene expression data by using the existing gene set to impute predictable genes.

gene expression covariance relationships are highly tissue-specific  <cit> , and successful ggs-based expression prediction requires a stable tissue-specific co-expression structure. we demonstrate that in two very different cancer types, breast and hgsc, the same trends in predictable gene set size as a function of redundancy, correlation threshold, and dm set size were observed. the number of predictable genes was consistently much higher in breast cancer than in hgsc. when predicting gene expression, increasing the number of genes required to be correlated with a predictable gene tends to increase the prediction accuracy, since more predictor variables are added to the regression models. however, it also decreases the total number of eligible genes that could either be predicted or used for the prediction. the overall success of expression prediction depends on the redundancy and |rp| selected and may vary by tissue type. if the tissue-specific gene expression correlation structure has fewer but larger sets of correlated genes, then larger redundancy values will have little impact on the number of eligible genes. if, however, there are many small sets of correlated genes, high redundancy values would exclude many of the genes from being eligible. in selecting gene sets to assay, higher values for redundancy may be chosen to better accommodate probe failures, but such failures will result in decreased accuracy.

there are several key differences between our work and the national institutes of health library of integrated cellular signatures  program selection of a set of  <dig> “landmark” genes that can be used to infer 80 % of the genome. the goal of the lincs project is to increase the capacity of high throughput screening and generation of expression signatures for small molecules across cell lines. the  <dig> genes were purposely selected based on their minimally correlated expression across a large number of cell lines, and their utility in inferring the expression of other genes  <cit> . in contrast, we designed ggs to tailor gene selection using organism-, disease-, and tissue-specific gene expression patterns, identify genes that can be imputed from a given candidate gene set, and select a user-specified number of additional genes to assay which maximize the gene expression information obtained. additionally, we use a range of correlation thresholds and redundancy to identify gene sets whose values can be imputed with varying degrees of confidence, allowing the user to choose a set of parameters that balances cost and prediction accuracy.

while we demonstrate that ggs-augmented prognostic ovarian cancer gene sets greatly increase the number of genes that could theoretically be predicted, and the prediction models using these genes generalize across studies and platforms, ggs has several limitations. in order to apply our algorithm, a binary correlation matrix must be generated using readily available expression data, which may not exist for a given tissue type or disease. also, while it is possible to consider higher order interaction between gene expression values, we simplify our method by only considering pairwise correlation between genes. despite this simplistic modeling of co-expression relationships, we achieve high imputation accuracy across populations and platforms. another possible limitation is that dm gene set performance can suffer from population or study variance in the correlational structure. for example, imputation accuracy is lower in the bonome et al. data compared to the other data sets we evaluated, suggesting that the correlational relationships differ between these populations. since there are various methods to define grade  <cit>  and there have been changes over time in the groupings of histologic types of ovarian cancer  <cit> , this could potentially be due to differences in the characteristics of cases included in the studies. finally, our choice of a greedy algorithm balances the need for dm sets that maximize the number of predictable genes while minimizing the running time, and therefore there is no guarantee that the dm set selected is optimal. a brute force approach which would guarantee the optimal dm set selection that truly maximizes the possible predicted genes would increase the running time by many orders of magnitude. in contrast, our greedy algorithm runs with the number of iterations equal to the number of dm genes the user desires. while a variety of methods could have been used to predict relative expression, we chose polynomial regression and random forest models because of their simplicity. predicting relative expression is useful for associative analyses of subtype, outcome, or other sample features, and is more resilient to differences in batch, platform, and population than predicting absolute expression. if absolute expression is modeled and predicted, care should be taken to address these issues.

in summary, we demonstrate that ggs augments candidate gene sets selected for their biologic relevance by increasing the amount of gene expression information captured from the assay and potentially providing preliminary support for future work.

CONCLUSIONS
for a given tissue, disease, organism, or model system, ggs can select a set of genes to directly measure that efficiently capture the expression levels of additional genes across populations and assay platforms. ggs can build from candidate gene sets as a cost-effective way to increase the amount of gene expression information obtained in very large studies where using a genome-wide measurement platform is not feasible. this improves the utility of existing studies and enhances the efficiency of future studies by allowing researchers to use both the directly measured and predicted expression values to test unknown and difficult to anticipate future hypotheses.

