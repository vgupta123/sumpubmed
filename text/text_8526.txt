BACKGROUND
dna microarrays are a ubiquitous platform, the original form of highly multiplexed assays for conducting genome-wide experiments. the arrays are designed as two-dimensional grids of oligonucleotides , affixed to a solid support at a specific location  via spotting or direct synthesis. when a solution of some labeled, purified cellular fraction  — most often polynucleotides — is applied to the array, a stable interaction forms between those subsets of probes and targets sharing sufficiently complementary regions. after the required reaction time, unbound target is washed from the array and then a scanner captures the induced signal emitted by the bound molecules. the resulting image file is ultimately used as the baseline measurement for a multitude of sophisticated standardization, normalization and statistical techniques whose goal is to infer the amount of bound target as a function of a feature's intensity.

although dna microarrays offer a powerful method for high-throughput molecular profiling, it is difficult to reproduce experimental measurements between platforms, to determine the magnitude of target abundance and to detect low-abundance target molecules  <cit> . several sources of systematic error contribute to this problem, including incorrect array design  <cit> , batch effects  <cit>  and instrument limitations or error  <cit> . researchers have developed a number of statistical techniques to minimize non-biological measurement variation resulting from all of these types of systematic error, including rma , dchip and mas  <dig>   <cit> . however, these statistical techniques tend to be general rather than specific in identifying or modelling processes that affect hybridization. since the sensitivity and specificity of a probe's hybridization affinity to a target dramatically changes its scanned intensity, and since the probe sequences on the array cannot be changed  <cit>  after it is manufactured, it is of utmost importance to use the most current information when interpreting intensity values for each feature on the array. naturally, our understanding of what probes have been influenced changes as the annotations for an organism's genome evolve. researchers have identified probes on various arrays whose sequences show different types of hybridization problems, such as interfering secondary structure in either component, probe misassignment, and several categories of cross-hybridization  <cit> . once identified, some researchers modify the array's specification file so that their removal or reassignment can be easily propagated to new analyses, but most simply explain how to identify them. because different microarray platforms have unique design and construction features, as well as custom software for communicating how a probe is to be interpreted with respect to the target genome, the strategy for modifying the specification file for a given type of dna microarray requires platform-specific strategies.

the most complex and high-density dna microarray designs come from the affymetrix platform products. their complexity results from the promiscuous placement of probes with respect to target elements and the multiplicity of probes per biological target. their high density means that there are hundreds of thousands to millions of simultaneous measurements to be considered. there are other unique design features of these arrays: the probes are relatively short oligonucleotides  synthesized directly onto the array; for several generations of the 3' expression arrays, the basic measurement 'unit' was determined by a probe pair, consisting of a perfect match  and a mismatch  probe, although on some of the latest designs this has changed; finally, there is the conceptual grouping of probes into a probe set whose members interrogate a specific, and longer, target molecule. a probe set might discriminate among known variants of a transcript, exon, or snp location; depending on the platform the number of probes in a probe set varies. the specification file for affymetrix arrays is called a chip definition file  and delineates which, and how, probes are grouped into probe sets. there is a great deal of public data and software available for these arrays, so solutions to the problems they present have the potential for broad impact.

the advantage to such a design is the redundancy of the measurements: probe or target characteristics that confound measurements are easily remedied by removing or reassigning problematic probes from a probe set while leaving probes that faithfully report on the original target of interest. in fact, shortly after affymetrix released the sequence information for their arrays into the public domain, several researchers analyzed the probe set definitions  <cit> , identifying a number of potential problems with the original definitions that could produce measurement error within a probe set. they then proposed several bioinformatics methods for re-defining the probe sets to solve these problems , intending to reduce the measurement error and to make the aggregated measurements more biologically relevant. in many cases, these groups validated their re-definition strategy by showing that their custom probe set definitions, when compared to the affymetrix default, significantly changed the differential expression results. in some cases, subsequent studies showed that the re-definition strategy significantly improved the correlation between microarray measurements and experimental results. the custom probe set definitions of dai et al.  <cit> , and two later studies using them  <cit> , illustrate how custom array specifications can significantly improve microarray measurements and the conclusions drawn from them.

for several affymetrix expression arrays, dai et al.  <cit>  re-defined the original probe sets into gene-, transcript- and exon-specific probe sets. they used the most up-to-date versions of several public genome databases, such as unigene  <cit>  and refseq  <cit> , in this process, and then created custom cdfs for each source. in one case, they used an updated version of unigene to define a gene-specific cdf for the affymetrix hg-u133a chip and then reanalyzed data from a cardiac tissue study   <cit> ; comparing the updated cdf and the original cdf, they found between 30-40% differences in those genes predicted to be significantly differentially expressed between the two. when performing a similar analysis with other custom cdfs, they found between 30-50% differences in predicted differential expression. subsequently, sandberg et al.  <cit>  showed that dai's custom probe set definitions, when compared to the original definitions, improved the accuracy and precision of transcript estimates for a set of cross-lab replicate arrays  <cit> . in particular, their accuracy metrics showed that the microarray measurements became more similar to those measured by rt-pcr. later, mieczkowski et al.  <cit>  showed that dai's custom cdfs significantly improved the correlation between microarray expression profiles and rt-pcr expression profiles. thus, re-defining array specifications can potentially improve the down-stream analysis of affymetrix microarrays. however, biological researchers who want to test, or simply adopt, new probeset definitions, are likely to be hindered by the way the methods are communicated.

these researchers communicated their re-definition strategies in a variety of ways. some of them only published their general strategies for re-defining the probe sets, without providing custom specifications for individual microarrays; others published custom array specifications for a limited subset of microarrays, although in a file format different from the standard cdf format; still others provided custom cdfs, but again, for a limited subset of microarrays. for those research groups who can simply use a provided custom cdf, this bewildering variety of formats does not pose a problem. however, it is a problem for those groups who are not in this fortunate situation: those who want to use a published re-definition strategy, but don't have access to a custom array specification file ; those who want to modify an existing method; those who want to combine multiple re-definition strategies; and those who want to develop and implement their own re-definition methods. for example, one of our research interests is to test different gene models by assigning probes to transcript-specific sets and then creating model-specific cdfs. what are the options for these researchers?

one option is to create custom versions of the algorithms for summarizing probe set intensities, such as rma. however, writing these custom algorithms is likely to be daunting, error-prone, and hard to test. a better option is to create a custom cdf. researchers can then generate summarized probe set intensities using any of the well-accepted and tested analysis packages provided by affymetrix or bioconductor  <cit> . though easier, creating a custom cdf still presents challenges. in the worst case, creating a custom cdf from scratch, researchers need to thoroughly understand the file formats  and platform-specific logical rules for defining probe sets  necessary to parse and write cdfs. using an existing application programming interface  or software development kit , such as affymetrix's fusion sdk  <cit>  or affxparser  <cit>  , is an easier and more efficient solution than writing in-house methods for reading and writing cdfs. however, this still requires a degree of proficiency in a specific programming language , knowledge of the cdf file formats and probe set construction rules, and knowledge of the language-specific data structures for representing a cdf. a lab with in-house programming resources may opt for either of these viable approaches, but it is not ideal for labs with minimal programming expertise or those not wanting to immerse themselves in cdf minutiae. they need a new set of tools that makes creating a custom array specification easy and unambiguous.

it is for this group of biological researchers that we developed arrayinitiative: a standalone, cross-platform desktop application for creating and managing custom versions of manufacturer-provided  microarray specification files, such as a cdf, and for generating easily understandable, non-standard cdf representations. it requires only minimal knowledge of array specification standards  and zero programming expertise. the manufacturer's array specification file format is completely hidden from arrayinitiative users, and they need only understand the most abstract notion of array organization for an array type. as such, arrayinitiative users only have to understand and create a simple file  to define their own custom array specifications. for example, when creating a custom affymetrix 3' ivt expression array, users only need to understand that a probe set contains pairs of perfect match and mismatch probes and be able to create a minimal text-based representation of probe set membership. arrayinitiative greatly simplifies the task of creating custom array specifications, allowing labs with less computational expertise to test, use, tweak and invent alternative methods for re-defining microarray specifications.

implementation
we developed arrayinitiative as a standalone, rich client desktop application with an integrated backend database. the user interface was implemented with pyqt  <cit> , a python  <cit>  binding of qt from riverbank computing. we used sqlite  <cit>  as the backend database, as implemented in python's sqlite <dig> module  <cit> , because it requires minimal installation/setup, administration and maintenance tasks for the user and is a standard library module in python  <dig> +. each of the main components is cross-platform and freely available. arrayinitiative can be downloaded from the "downloads" section at http://wellerlab.uncc.edu/arrayinitiative/index.html and as additional file  <dig> in this publication.

RESULTS
application overview
arrayinitiative is a rich client application for creating custom array specifications built upon a default array specification. the default array specification is typically the one provided by the manufacturer and the custom array specification is a user-modified version of that default. users can:  import default array specifications,  import probe sequences for the default array specification,  import a custom array specification,  export any array specification to multiple output formats  export the probe sequences for any array specification and  browse high-level information about the array, such as version and number of probes. this release of arrayinitiative supports affymetrix 3' ivt expression arrays, and all of the subsequent sections will assume this type of array.

arrayinitiative's default main window, shown in figure  <dig>  consists of an array specification browser, a dashboard and a main menu. the array specification browser displays a list of a user's array specifications, organized as a hierarchical tree, while the dashboard displays summary information about the currently selected browser item. for example, when the "affymetrix → expression" browser item is selected, arrayinitiative shows how many default and custom affymetrix 3' expression array specifications there are; when a user clicks on an array specification in the browser, summary information for that specification is displayed in the dashboard. all of arrayinitiative's tools, such as the one for importing a default array specification, can be opened from either the main menu or from context-sensitive  menus available in the specification browser. each of the tools in arrayinitiative open as modal dialog windows.

context-sensitive  menus
the array specification browser gives right-click access to the main menu items; the resulting form values are pre-populated based on the current browser selection. renaming and deleting array specifications can only be done using the context menu.

creating and managing multiple arrayinitiative databases
when first using arrayinitiative, users will need to create at least one database before they can access any of the array-specific functionality of arrayinitiative. multiple arrayinitiative databases can be created to logically separate distinct sets of arrays, if desired. in addition, users can update the information for an existing database and switch between databases by setting the active database.

importing a default array specification
users can import the array specification  for an array from a cdf file . usually, users will import a default array specification from a cdf provided by affymetrix, but they can also import a default array specification from a custom cdf instead. users must import at least one default array specification before importing custom array specifications and writing custom cdfs.

importing probe sequences for the default array specification
after importing a default array specification, users can import the probe sequences for a default array specification, using the fasta or tab-delimited probe sequence file provided by affymetrix for that array. arrayinitiative will automatically generate the missing mismatch probe sequences. see the "file formats" section of the manual — available online in the supplementary site — for details about the supported formats for a probe sequences file.

creating a custom array specification file
after importing a default array specification, users can create a custom array specification for any imported default array specification. when creating a custom array specification file to import, users can instruct arrayinitiative to copy an existing probe set, re-define an existing probe set or define an entirely new probe set. when defining, or re-defining, a probe set, users can use any of the probe pairs from the default array specification. arrayinitiative treats probe pairs as atomic units, and as such, users can't add just the pm or mm probes to a probe set definition. currently, arrayinitiative accepts a full specification file type , requiring that users explicitly define every probe set. see the "file formats" section of the manual — available online in the supplementary site — for details about the supported formats of a custom array specification.

importing a custom array specification
after creating a full specification file, users can import them into arrayinitiative. users can define multiple custom versions for any default array specification.

exporting an array specification
users can export default and custom array specifications as a cdf , an xml file or a delimited file. see the "file formats" section of the manual — available online in the supplementary site — for details about the output types.

exporting probe sequences for an array specification
users can export the probe sequences for a default or custom array specification as a fasta, xml or delimited file. see the file formats page for details about the output types. when exporting a custom array specification as a cdf, the type — ascii or xda — will be the same as the parent default array specification.

discussion
in this section, we illustrate why arrayinitiative is useful to microarray researchers by presenting a case study in which we create custom cdfs based upon two different, published probe-filtering techniques and then use bioconductor algorithms to investigate the effect of the probe set re-definitions on the summarized expression values. the complete case study code, data and results are available under the "downloads" section at http://wellerlab.uncc.edu/arrayinitiative/index.html. we then discuss the limitations and future directions of arrayinitiative.

case study
introduction
imagine that you, as a researcher who is reasonably proficient with programming, discover two different probe-filtering techniques for affymetrix arrays while reading the literature. both of them seem reasonable and you think that, by incorporating such qc steps, you could improve the results you get when analyzing your expression arrays with bioconductor tools. since your favorite bioconductor packages require a well-formed cdf, you search the web to see if someone has created a custom cdf based upon both filters. unfortunately, you can't find one and must generate the custom cdf yourself or rewrite and test several complicated algorithms. convinced that the filters will improve your results, you decide to create a custom cdf from scratch. the developers of technique a conveniently provide a comma-delimited text file with the new probe set definitions for the array type that you're interested in, while the developers of technique b provide a custom cdf with their filter, also for your array type. you then need to compare the two different probe set definitions to make sure they don't conflict and then merge their individual probe set definitions into a single custom cdf. examining the delimited files is relatively straightforward, so filter a's probe set definitions are already usable; however, to get the probe set definitions for filter b, you need to parse the rather complex cdf file. after some time and effort, you manage to learn the cdf format and successfully retrieve the probe set definitions for filter b. with some coding magic, you create a joint probe set definition that is the intersection of the two filters. confident in your knowledge of the cdf format, you write some code to create the custom cdf, which eventually is accepted by the analysis packages after much trial-and-error. upon analyzing your arrays, it appears that, indeed, the two filtering techniques, in tandem, significantly improve your results. excited by your success, you want to apply the same probe-level filters to an expanded set of arrays, some of which were done on a later version of the array. as you acquire the necessary files you realize that the later version of the array is described by a different kind of cdf, in the xda format, which is entirely different from the cdf format that you learned. dispiritedly, you set out to learn another format and start the process over again.

not only is the above scenario likely, it is also fairly optimistic. many research labs do not have the in-house computational expertise to create custom cdfs easily, nor should every lab be required to learn about the cdf formats to reap the benefits of research into probe-level filters on affymetrix microarrays. this is exactly why a custom cdf creator like arrayinitiative is useful.

the case study presented here illustrates the merging of two real sets of probe filters, that we term 'bafl' and 'upton' . we created custom hg-u95av <dig> cdfs for each of them and then used three different bioconductor packages — rma, dchip and mas  <dig>  — to determine the independent and joint effect of each filter. lest the reader be unconvinced that such filters would alter the outcome, for a given custom cdf and summarization method, we compared the probe set intensities calculated using the custom cdf to those calculated using the default cdf.

hg-u95av <dig> microarray and the bhattacharjee data set
the 'bhattacharjee' data set, which contains data for arrays reporting on  <dig> distinct macro-dissected human lung adenocarcinoma samples, was assayed using  <dig> hg-u95av <dig> arrays  <cit> . of these,  <dig> samples had 2- <dig> replicate arrays . the hg-u95av <dig> array has  <dig>  probe sets and  <dig>  probe pairs , with most probe sets having  <dig> probe pairs . the full distribution of probe pairs per probe set is presented in table s <dig> 

for this case study, we analyzed twenty randomly selected arrays  from  <dig> bhattacharjee adenocarcinoma arrays, shown in table s <dig>  when selecting the arrays, we excluded any arrays that exhibited array-wide technical problems, as identified by thompson et al.  <cit> , from the sample pool.

probe-filtering techniques
bafl
thompson et al.  <cit>  developed a "white box" pipeline - biologically applied filter levels  - to identify and filter microarray probes that are likely to report incorrect or misleading intensities based upon certain biological properties, such as the presence of snps in the probe sequence , probe cross-hybridization, internal structure in either the probe or target sequence that reduces binding affinity, and probe intensities that fall outside the linear range of the scanning device  <cit> . thompson et al. provided comma-delimited files of filtered  probe set definitions for the hg-u95av <dig> and hg-u <dig> array types.

upton
upton et al.  <cit>  reported that probes with certain sequence motifs have intensities that are uncorrelated with the other probes in the same probe set; however, they tend to correlate well with any probes having the same sequence motif, regardless of probe set membership. in this case study, we will focus on the two major types of problematic sequence motifs identified by upton et al.  <cit> : g-runs and primer spacers. probes with the g-run motif, ≥  <dig> gs in a row, tend to produce consistently high intensities, with some position dependence. the primer spacer motif, cctcc, is related to the incorporation of a t7-binding site when a mrna is amplified during target preparation. when the target is amplified in this manner, the probe intensities tend to be higher than most, introducing a spurious correlation similar to that seen with g-runs. since both of these sequence motifs introduce a systematic bias when summarizing probe set intensities, any probes including them should be removed from a cdf prior to calculating expression values. this is always true for the g-run motif and is true for the primer spacer motif when the target is amplified by incorporating a t7-binding site. the reports by upton et al. provided good insights about identifying problematic probes, but they did not provide a modified cdf, a flat-file of probe set definitions nor a list of deprecated probes for a given array version.

are the probe-filtering techniques independent?
when different groups develop qc filters independently there may be overlap or conflicts of which they are unaware. therefore, before proceeding with creating custom cdfs and downstream analysis, we first assessed the overlap between the bafl and upton filter sets to determine if they are truly independent filters.

creating the custom cdfs
we created three custom cdfs using arrayinitiative: a bafl-only custom cdf, an upton-only custom cdf and a bafl plus upton joint cdf. each filter set required a unique approach for generating the probe set definitions due to the different ways that they were communicated; however, after we defined the probe sets for each filter set, the steps for creating the custom cdfs were identical. figure  <dig> shows a graphical summary of the cdf creation workflow.

the first actions were common steps. we created a new arrayinitiative database and imported the default hg-u95av <dig> cdf from the file provided by affymetrix. next, we imported the pm probe sequences using the tab-delimited file provided by affymetrix and instructed arrayinitiative to automatically generate the corresponding mm probe sequences. finally, we exported the default cdf probe set definitions  as a comma-delimited text file. when generating the custom probe set definitions in the subsequent steps, we queried the arrayinitiative database directly for information about the default probe set definitions as querying databases tends to be more efficient and straightforward than searching for information in flat files. the end-point of the custom probe set definition stage was to have in hand a comma-delimited file  with the following columns per line:  probe set id,  pm probe id,  x-coordinate of the pm probe,  y-coordinate of the pm probe,  mm probe id,  x-coordinate of the mm probe and  y-coordinate of the mm probe. in order to keep the method comparison fair we required that each probe set have at least  <dig> probe pairs remaining; if it did not, we removed it before creating the custom cdfs.

when creating the bafl probe set definitions, we started with the comma-delimited filtered probe set definitions for the hg-u95av <dig> array provided by thompson et al. since that probe set definition file included only the pm probes, we first queried the arrayinitiative database to get the full probe set definitions of the default cdf. when creating the standardized probe set definition file, we included only those probe pairs whose pm probe was in the author's probe set definitions. we then uploaded the standardized probe set definitions into the arrayinitiative database.

creating the upton probe set definitions was somewhat trickier because we needed first to identify the g-run probes on the hg-u95av <dig> array. again, we first queried the arrayinitiative database to get the full probe set definitions of the default cdf, including the pm and mm probe sequences. when creating the standardized probe set definition file for this filter, we identified probe pairs — using regular expressions — that had at least one g-run or primer spacer in either the pm or mm probe sequence and then excluded that probe pair from the final probe set definition. we then uploaded the standardized probe set definitions into the arrayinitiative database.

since the bafl + upton cdf is the intersection of the probe pairs that survived the bafl and upton filters, we retrieved the joint probe set definitions from the arrayinitiative database by intersecting  the bafl probe set definition table and the g-run probe set definition table . now having a list of the surviving probe pairs, we created a standardized probe set definition file and uploaded this data into the arrayinitiative database.

having standardized probe set definition files for each of the probe filters, the final steps for creating a custom cdf for each are identical. we first created arrayinitiative specification files for each of the filters using the standardized probe set definition files and then imported the custom cdf specifications into arrayinitiative. finally, we created a standard ascii cdf file for each of the custom probe set definitions in arrayinitiative.

modifications to the default hg-u95av <dig> specification made by each set of filters.

creating and validating bioconductor cdf packages
many of the bioconductor packages aimed at analyzing affymetrix arrays use a specialized r package representation of a cdf instead of the actual cdf; there are pre-generated packages for many of the default cdfs. since we are using custom cdfs for downstream analysis, we first created and installed our own r packages for the three custom cdfs generated by arrayinitiative, as follows:

 <dig>  made the packages using the make.cdf.package function in the makecdfenv package  <cit> .

 <dig>  installed the custom cdf packages using r cmd install.

with the custom cdf packages successfully installed, we compared, for each filter, the probe set definitions in the existing r packages with the probe set definitions in arrayinitiative, as follows:

 <dig>  exported bioconductor's internal probe set definitions for the custom cdfs - using the ls and get r functions - to a set of delimited files and then uploaded the data to the arrayinitiative database .

 <dig>  verified that the number of bioconductor probe pairs equaled the number of arrayinitiative probe pairs .

 <dig>  verified that the member probe pairs in bioconductor were the same as the member probe pairs in arrayinitiative .

using the above procedure, we verified that the probe set definitions for each filter were consistent between bioconductor and arrayinitiative, showing that arrayinitiative-generated cdfs are compatible with one of the most widely used microarray analysis packages. since the probe set definitions were consistent, we can reasonably assume that any differences in downstream analysis will be the result of the custom probe set definitions, not from misinterpreting set membership.

differences in summarized probe set intensities
how do the bafl and upton filter sets independently, and jointly, affect summarized probe set expression values? for the three summarization methods chosen , we determined how, on average, the custom expression values changed with respect to the default expression values as we removed probe pairs.

we only analyzed the  <dig>  probe sets with  <dig> probe pairs in the default cdf  and only removed from  <dig> to  <dig> probe pairs, so that at least  <dig> remained to a set. we did this for several reasons:  standard probe sets represent the vast majority of those on the array and most are designed to interrogate transcripts,  the majority of non-standard probe sets represent the minority of those on the array and most are designed for diagnostic or quality control purposes and  we wanted to use a consistent probe set size to eliminate that as a factor when analyzing the downstream effect on expression values.

for each unique combination of summarization method and rand array, we calculated the expression values of the standard probe sets using the default and custom probe set definitions. then for each probe set, we calculated the percent change between the expression values, as follows:  

where ec is the custom expression value and ed is the default expression value. for each distinct combination of summarization method and custom cdf, we calculated the average delta, across all of the rand arrays, as we removed probe pairs. the workflow is depicted in figure s <dig> 

before running the analysis, we postulated that the upton filter set would decrease probe set intensities as we removed probe sets, since probes with g-runs and primer spacers tend to have a much higher intensity than other probes in the probe set; we expected that the bafl filter set would increase the probe set expression values as we removed probe sets because its filters tend to remove low intensity pm probes; we expected that the joint filter probe set expression values would fall between those produced by the two independent filter sets, but heavily weighted towards the bafl probe set expression values, since it removed many more probe pairs.

mas  <dig> 
dchip
rma
case study discussion
the upton filter set decreased the probe set expression values when they were summarized by dchip and rma, a trend not observed when we summarized the probe sets with mas  <dig> . the mas  <dig>  expression values were unresponsive to the upton filters when we removed 1- <dig> probe pairs, while its effect was fairly erratic in the 6- <dig> range. the bafl filter set consistently increased the probe set expression values for all of the summarization methods, with mas  <dig>  and rma being particularly responsive. the joint filter set produced intermediate expression values that were a blend of the two independent filter sets when summarized with either dchip and rma; the effect was generally additive. the bafl filters had a stronger influence on the expression values, but this is not surprising, given that the bafl filter set removed significantly more probe pairs than the upton filter set. when summarizing with mas  <dig> , changes in the expression values were largely driven by the bafl filters, with the upton filters having little effect.

in considering the joint filter set, rma exhibited trends in expression value changes that best fit our prior expectations. considering the magnitude of expression value changes, the joint filter changed the mas  <dig>  expression values the most, followed by rma and then dchip. while the expression values for mas  <dig>  and rma changed by factors of 20-100% for many of the data points, the changes seen with dchip were much lower, in the 2-15% range, suggesting that dchip is the least responsive to changes in the probe set definitions.

from these results, we may conclude that the filter sets significantly alter the value of the estimated target concentration when using any of the summarization methods, although we can't speculate if it drives the values towards or away from the true value. also, we note that arrayinitiative has finally allowed our lab to apply mas  <dig> , dchip and rma to a bafl-filtered data set, which has been one our research goals for a while.

future development
in the long term, we intend to develop an open api that will support module development by external programmers for a large number of array types and manufacturers. for example, the research community might create modules that implement a specific strategy for re-defining probe sets  or modules that pre-process and remove probes that contain undesirable sequence motifs, such as runs of gs. our immediate research goals dictate adding support for affymetrix snp and exon arrays, adding support for agilent human  <dig> ×  <dig> k arrays, development of a tool to report just the differences between two cdfs, development of a tool to convert between the affymetrix ascii and xda formats and development of a tool to merge two or more different probe set definitions  for the same array type. we also need a variant of the merging tool that can define consensus probe sets among different, but related, platforms. in particular, we have pooled data from adenocarcinoma studies assayed on four versions of the affymetrix human genome arrays: hg-u <dig>  hg-u <dig>  hg-u133a and hg-u <dig> plus  <dig> . these arrays share many same-sequence probe pairs, but the names of their parent probe sets and their location on the arrays are different. a consensus merging tool will identify the common probe pairs by their sequence and then group them into biologically relevant probe sets. the probe set identifiers and probe sequences will then be consistent across arrays, differing only in probe coordinates. this would require a custom cdf for each array version, but all of them would consistently measure the same subsequences in each transcript. finally, we intend to add support for a difference specification type, which will allow users to specify a custom cdf as an exact copy of the baseline cdf, except for any explicitly stated differences, most likely useful for those studying only a few genes in great detail.

CONCLUSIONS
arrayinitiative is for those biological researchers who want to create custom microarray specifications, such as a cdf, without the additional burden of learning the manufacturer's specification file format or learning an api. it provides graphical tools for importing a manufactuer's microarray specification, defining custom versions of a manufacturer's specification, writing array specifications in their standard format or in an easily understandable, non-standard representation. creating a custom array specification requires only minimal knowledge of a manufacturer's specification standards  and the ability to create a simple delimited or xml file.

the case study illustrated two concepts: the simplicity of using arrayinitiative to create custom array specifications and how those modified specifications can significantly change summarized expression values. by not being constrained to a specific strategy for re-defining an array specification, arrayinitiative enables researchers to create new specifications based upon their own requirements. these array specifications might be the result of a new probe-filtering technique or may help to answer a specific biological question. since it is unclear which re-definition strategies are the best, arrayinitiative will make it easy to test competing approaches and compare them to the manufacturer's array specification, using established, tested software.

availability and requirements
project name: arrayinitiative

project home page: http://wellerlab.uncc.edu/arrayinitiative/index.html

operating system: windows, linux and mac os x

programming language: python  <dig>  -  <dig> 

other requirements: sqlite, pyqt4

license: lgpl

restrictions for non-academic use: none

list of abbreviations
api: application programming interface; ascii: text-based version of affymetrix cdfs; bafl: biogically applied filters; cdf: chip definition file; mm: mismatch; pm: perfect match; rand: set of randomly selected arrays; sdk: software development kit; snp: single nucleotide polymorphism; xda: binary version of affymetrix cdf.

authors' contributions
co designed and developed arrayinitiative, designed and carried out the research for the case study and wrote the manuscript. dc and et developed first-generation code for parsing ascii and xda cdfs. kt helped to design the case study. jw supervised the research - helping with the feature requirements for arrayinitiative and helping to design the case studies - and revised the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
arrayinitiative  <dig> . the first release of arrayinitiative.

click here for file

 acknowledgements
we would like to thank david figueroa and deepthi chaturvedi for testing arrayinitiative. both co and et received support from the department of bioinformatics and genomics at uncc. additionally, co received support from a gaann fellowship.
