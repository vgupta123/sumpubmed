BACKGROUND
structural variations  are polymorphisms that change the structure of the genome, e.g. deletions, insertions, translocations, inversions and tandem duplications  <cit> . they induce functional change in genes and regulatory regions, which can cause various diseases  <cit> , e.g. autism  <cit> , parkinson's disease  <cit> , schizophrenia  <cit> . not only inherited svs, but also somatic svs can be responsible for various diseases including cancer  <cit> . however, until a few years ago, there were no efficient methods to detect genome wide svs in high resolution. one of the microarray analyses, array-cgh, can only detect limited svs, since this approach can neither detect small size svs nor clarify the single nucleotide level sequence of the target sample. recently, next-gen sequencing  has drastically changed this situation. ngs enables us to measure large number of short digested sequence reads  with short time with at once  <cit> . additionally, alignments of sequenced reads to the reference genome, which were impossible using the microarray approach, are now applicable. thus, we can detect svs with higher resolution.

until now, three types of methods have been developed to detect svs from ngs data: discordant pair approach, depth of coverage approach and split read approach  <cit> .

the first approach, discordant pair, uses paired-end reads of ngs data, and calls svs when the distance of two paired-end reads is discordant  <cit> . when svs occur, paired-end reads generated from these locations cannot be mapped to the reference in concordant distance. breakdancer  <cit> , variationhunter  <cit> , modil  <cit>  and abi tools  <cit>  can be categorized into this method. this idea has been developed in the early times when the depth of coverage was low and the length of the read sequences  was short. thus, this method is appropriate for smaller datasets of short-read. however, this method cannot detect svs with shorter lengths, and it has difficulties to know the exact position of sv events.

the second approach, depth of coverage, is used in segseq  <cit> , cnvnator  <cit>  and abitools  <cit> . it uses the frequency of mapped short reads or bases to each position on the reference genome. the main concept of this method is similar to array-cgh. when deletions occur, the number of mapped reads to regions in the reference genome will decrease. in contrast, in the case of duplications, the number of mapped reads to regions in the reference genome will increase. different from the first approach, this does not require paired-end reads, while it requires high coverage and still has difficulties detecting shorter sv events.

the third approach, ‘split read’, is the method to detect svs using unsuspected reads, which are not correctly mapped to the reference genome or remain unmapped. in general, split read approach is applicable only to paired-end reads. while it needs sufficient read lengths and depth of coverage, the method can detect svs with single-base resolution. reads on an sv event contain a ‘breakpoint’, a boundary of a region affected by sv and its flanking region which is the same as the reference genome. an sv is called when the same breakpoint is detected in unsuspected reads. the algorithm of detecting breakpoints varies with tools. pindel  <cit>  and slope  <cit>  use orphaned reads, unmapped reads whose mate were succeeded in mapping to the reference genome, as unsuspected reads. slope attempts partial alignment between the either end of each unmapped read and the reference genome to obtain breakpoints. pindel gets substrings from two different regions around the mapped mate read; one region is two fold of average insert size from 3’ end of mapped mate read and the other region is the sum of maximum deletion size and read lengths from the appropriate position. it then checks whether the unmapped read can be reconstructed by concatenating two substrings from each region.

major mapping tools, such as the burrows-wheeler alignment tool,  if they failed to map full length short read to reference genome, still try to map part of the short read. if the short read is mapped partially, then the information of the partial mapping is stored into a major mapping format sam  <cit>  as soft-clipping information. the number of soft-clipped reads is comparable to that of orphaned reads which is adopted in pindel and slope. thus, our new method clipcrop employs soft-clipping information and advances the third 'split read approach.' by using the boundary position between mapped sequence and the soft-clipped sequence in a clipped read, we can obtain putative breakpoints. ideally, among these putative breakpoints, true breakpoint will be contained. we then remap soft-clipped sequences around the detected putative breakpoints and infer which type of event is really occurred at this region. the detailed method is described in section  <dig>  section  <dig> demonstrates the comparison of clipcrop, pindel, slope and breakdander to various simulation data set. section  <dig> details the result in section  <dig> 

methods
in the first process of clipcrop, reads with soft-clipping information are chosen for the next analysis. the soft-clipping information is written as a cigar string in sam format. here is a sample data of cigar string: “31s69m” means  <dig> bases from the left end are clipped, and the rest  <dig> bases are matched.

the sam file must be generated from paired-end mapping tools, and the mapping tool must generate a sam file with soft-clipping information. in some mapping tools , mapped result information file does not contain whole read sequence, but only mapped part of the sequence. in such cases, a generated sam file from them contains hard-clipping, partially unmapped sequence that is not in the seq column in sam format. we can convert hard-clipping information to soft-clipping information by using the original fastq file to put information about the original sequence of each read. as a result of partial alignment, there are some reads where both ends are soft-clipped . we ignored such reads because they don’t carry relevant information.

second, breakpoints are obtained from the soft-clipping information. the marginal point between a clipped sequence and matched sequence is denoted as a breakpoint. when the left side of the breakpoint is clipped, it is denoted as an l-breakpoint, and r-breakpoint in the opposite case ). after identifying breakpoints, they are sorted and clustered within 5-base differences.

in the next process, soft-clipped fragments with lengths larger than 10bases are collected and remapped to the reference genome around the whole breakpoint. before mapping, the reference genome is cut around each breakpoint with 1000-base elongation to both sides. this process can reduce the probability of clipped sequences to be mapped in the wrong position. in our current implementation, bwa is used for this remapping process. by checking the mapped pattern of clipped sequence, clipcrop infer the sv type from deletion, inversion, tandem duplication, insertion and translocation as follows.

in deletion events, clipped sequences from an l-breakpoint are mapped to the left side of an r-breakpoint and vice versa . as we can see in figure  <dig>  reads generated from nearby deleted region are soft-clipped and remapped.

in inversion events, the same as deletion events, clipped sequence from an l-breakpoint are mapped to the left side of an r-breakpoint, but mapped reversely, and vice versa . figure 2b explains the reason why the clipped sequences are mapped reversely.

in tandem duplication events, clipped sequences from an l-breakpoint are mapped to the right side of an r-breakpoint and vice versa . unlike deletion events, clipped sequences are made outside the two breakpoints, and mapped inside the two. soft-clipped sequences are generated from the marginal point of two duplicated sequences ).

in insertion and translocation, an l-breakpoint and an r-breakpoint are in the same position . reads containing inserted / translocated sequence are clipped, and remapped if it is a translocation event, and unmapped if it is an insertion event.

after checking the type of sv from each soft-clipped reads, these are clustered by its type and position allowing  <dig> base difference at most. if two sv calls with the same type are overlapped each other, then only one sv with higher reliability score is finally selected. reliability score is defined with the following formula:   

, where bl and br are the number of clipped reads supporting the l/r-breakpoint of the sv event, cl and cr are the number of clipped read remapped to the l-breakpoint of the sv event. in this formula, the higher the clipped and the remapped reads, the higher the score. also, the score tend to be high when the number of left and right reads are balanced.

RESULTS
we prepared various simulation data to evaluate the performance of cripcrop and other sv-detecting tools. table  <dig> shows the parameter set in these simulations. in each simulation, we generated  <dig> svs to the human chromosome  <dig> . the type of each sv was randomly chosen from insertion, inversion, deletion and tandem duplication . the length of each sv event followed the normal distribution determined in each data. we also set single nucleotide alteration frequency as one per  <dig>  bases. after creating slightly modified chromosome  <dig> sequence in fasta format, we generated paired-end short reads with fastq format. the depth of coverage was set to  <dig>   <dig>   <dig>   <dig> or  <dig> and read lengths was set to  <dig>   <dig>   <dig> or  <dig> bases. the distribution of the insert length  was set to n. in order to compare the performance of our method with other three methods - discordant-pair method, depth of coverage method and split read method -, we chose the following tools as the representative of each method; breakdancer, cnvnator and pindel, respectively. we removed the results of clipcrop with its reliablity score zero.

n, n, n, n
n, n, n
we generated various data each of which has different distribution of sv length, mean depth of coverage or read lengths. values with bold type are the default  and  <dig> )

we defined discovery rate and true call rate to compare their performance to detect true svs . let real svs be sr = {r <dig> = , …, rn} and called svs be sc = {c <dig>  …, cm}, where  is the start and end positions of the ith sv. if the type of sv ri is insertion, then the inserted point pi to the reference genome is only given. in this case, we set the range of a real sv ri = . the range of a called sv ci is defined in the same way. discovery rate d and true call rate t are determined by the following formulas:      

, where the function f is   

as tools with high sensitivity can detect with high discovery rate, it can be regarded as the similar concept to sensitivity. in the same way, true call rate can be regarded as the similar concept to specificity.

discussion
in all types of svs, clipcrop and pindel could detect most of svs with high accuracy . it is because these two tools uses split read approach. this approach can detect svs of any size with single-base resolution. breakdancer, which employs discordant-pair approach, cannot detect short svs, and its accuracy cannot be single-base resolution. cnvnator, adopting depth of coverage approach, firstly splits reference genome with a certain window size, so it cannot detect svs with shorter length than the window size. as we set the window size to  <dig> bases in our analyses, cnvnator couldn’t detect svs with length < <dig> bases. the resolution in cnvnator is also limited to the window size. as well as clipcrop, pindel also marked high discovery rate and true call rate, but it couldn’t detect short duplications . this is because of the following reason. pindel tries to reconstruct split reads by concatenating two subsequences generated from two regions near the position of mapped mate. in short duplications, reads from duplicated region would contain more than two breakpoints, which means it requires more than three subsequences to reconstruct. thus, pindel cannot generate these reads and fails to detect short duplications. clipcrop, on the other hand, uses only soft-clipped sequences. some of the short soft-clipped sequences don’t contain any breakpoints, and they can remap and support tandem duplication calls. clipcrop also excelled over pindel in true call rate of insertions. as formula of reliability score  shows, clipcrop sets zero to svs called from only one-side clipping and only one breakpoint, i.e.  =  or  = . thus, by removing svs with score zero, we can obtain reliable svs with both-side supported, which is thought to contribute its higher accuracy.

the results in figure  <dig> shows that clipcrop could detect tandem duplications with high discovery rate and true call rate even the depth of coverage is  <dig>  this is because the depth of tandem duplicated regions is much higher than surroundings, and there are sufficient numbers of reads which support tandem duplications. also, as inversions can be supported by twice as many reads as deletion and insertion , discovery rate and true call rate were higher than those of deletion and insertion. the discovery rate and true call rate were saturated at depth  <dig>  therefore the sufficient depth for clipcrop is turned out to be  <dig>  which is not so high in current ngs data.

from the results in figure  <dig>  the sufficient read lengths for clipcrop is more than  <dig> bases. thus, clipcrop can be applied to most of current ngs data.

there is another recently published sv-detecting tool called crest  <cit> , which also uses soft-clipping information. unlike clipcrop, crest cannot detect tandem duplications. crest assembles soft-clipped sequences, and remaps the assembled sequence. thus, assembled reads from the region of tandem duplications cannot be mapped to the original reference genome.

currently, as clipcrop is focusing only on soft-clipping information, it doesn’t calculate the length of insertion. however, as clipcrop calls the position of insertion with high accuracy , we will easily be able to obtain these information by combination of other methods. in future, we will combine other methods and run with real data.

CONCLUSIONS
clipcrop is a tool for detcting svs with soft-clipiing information. soft-clipped sequences are partially unmatched fragments in a mapped read. clipcrop remaps these sequence and infers which type of sv events exists from the mapping pattern. clipcrop can detect svs with higher discovering rate and call accuracy than any other tool in simulation data set, especially in short size duplications and insertions. in addition, as clipcrop does not require a large depth of coverage or long read lengths, it can handle most of current ngs data. currently, the implementation of clipcrop is only available in our environment, and we are in the process of deploying. we provide current implementation if you contact us.

competing interests
the authors declare that they have no competing interests.

authors' contributions
ss conceived the project and design, implemented the algorithms and simulators, generated simulation data, and performed the computational analysis. ty helped running other sv-detecting tools for comparison. ys made the concept of mapping soft-clipped sequences. sm and mn critically revised the manuscript.

