BACKGROUND
high-throughput genomic technologies continue to present both rewarding opportunities and novel challenges to biologists and medical researchers. dna microarray technologies allow researchers to characterize the expression profiles for thousands of genes for samples of interest. however analysis methods for these data are troubled by the "curse of dimensionality" and by small sample sizes due to practical and economic constraints. however because of widespread efforts to arrange genes into meaningful biological subsystems, gene sets, or pathways, have become a widely used unit of analysis. the kyoto encyclopedia of genes and genomes , gene ontology , and biocarta are three widely-used curated resources for warehousing up-to-date gene set information. as researchers move beyond one-dimensional single gene or snp comparisons researchers will be confronted with a need to compare measures efficiently on functional sets of genes. subtle differences in expression and co-regulation not detectable with a series of univariate tests may be recovered with a multivariate test. for a complex disease such as cancer this enhancement in statistical power can better equip a researcher to answer the following, "do the transcription levels for this suspected tumorigenic pathway differ between the normal and cancerous tissue samples?" a more efficient approach to answering this question could lead to improvements in patient treatment regimen or better allow pharmacologists to target their limited resources in the effort to develop novel therapeutic compounds.

recently a number of tools, either as standalone applications or integrated into a database platform, have appeared to aid in the analysis of gene sets on a genome-wide scale. tian et al.  <cit>  cite the commonplace use of fisher's exact test  or its large-sample approximation χ <dig> form in various software and web tools. page  <cit> , gsea  <cit> , and gsea's subsequent refinement  <cit>  are examples of algorithms that combine a set of traditional univariate gene measures into a new composite pathway statistic. one then compares the difference in these composite measures for a family of pathways for the two or more groups under study. khatri et al.  <cit>  and goeman et al.  <cit>  review several issues in the analysis of gene sets. however some difficulties attend approaches based on univariate statistics, such as: if the pathway is formed assuming a set of  co-regulated genes then the pathway is intrinsically a multivariate object, the need to apply a multiple comparison correction procedure to the numerous  single-gene test results to control the overall false alarm rate for the genes within a single pathway comparison, and univariate tests that assume gene independence can lack the power to detect noticeable differences should the genes under comparison be co-regulated. hotelling's t <dig> is a classical multivariate test statistic for comparing the difference in multivariate means between two groups which circumvents these difficulties. this test was introduced to the gene-set analysis problem by kong et al.  <cit> . song et al.  <cit>  compared a similar test to several other popular tests and found that the inclusion of correlation information could improve test quality in their comparison of several gene set analysis methods. unfortunately the traditional hotelling's t <dig> test requires that the number of samples exceeds the number of genes in the set, i.e., n>p, and that a weighted average of the two sample covariance matrices be invertible. in genome-scale microarray studies it commonly occurs that n<p and the combined sample covariance matrix is not invertible and therefore the distribution of the resulting statistic is either unknown or intractable. to circumvent these concerns we have developed a regularized covariance matrix multivariate statistical test  to test for a difference in gene set average transcription levels. in this work we regularize the weighted average of the two sample covariance matrices to guarantee that the resulting matrix is nonsingular. our measured approach to regularization adapts the familiar hotelling's t <dig> test statistic to the ill-posed n<p case.

an early and illustrative application of regularization is ridge regression  <cit> . in standard linear regression the regression coefficients are estimated using βestimate = -1x'y. when the x'x matrix is ill-conditioned, attributable to high correlations among the regressors and compounded by small sample sizes, the resulting regression coefficient estimates are highly variable. investigators replace x'x by the quantity x'x + ki where k is a small constant and i is an identity matrix of appropriate dimension. the constant k is generally determined via some heuristic mechanism. in practice in exchange for a small estimator bias a dramatic reduction in estimator variance is often achieved. james-stein estimators are another well-known class of shrinkage estimators that use a biased estimator to achieve a smaller mean square error for a multidimensional parameter  <cit> . james-stein estimators generally assume a )*y form; in general, a simple prescriptive form for shrinkage estimators is not trivial.

friedman  <cit>  states that regularization techniques are known to be successful in the solution of ill- and poorly-posed inverse problems. variations of our approach are common in the context of classifying observations via discriminant analysis  <cit>  but have not been fully explored for testing the equality of gene sets. a recent application of regularization has also appeared for use in cluster analysis  <cit> , another common microarray analysis tool. kong et al.  <cit>  applied a hotelling's t2-based test; they projected the original data onto a reduced subspace via a singular value decomposition to sidestep the covariance singularity that arises when n<p. song et al.  <cit>  provide a hotelling's t2-based test, pcot <dig>  which uses a principal coordinate approach to project the original data onto a reduced subspace. in the formulation of our statistic we use permutation testing to determine the significance level of the test statistic. a closed-form solution for the null distribution of our proposed statistic does not exist.

methods
regularized covariance matrix approach to testing
the theoretical basis for the rcmat statistic is the classical hotelling's t <dig>  the standard two-sample form of hotelling's t <dig> can be located in  <cit> . hotelling's t <dig> is a scaled distance defined via a positive definite quadratic form, x'ax, for testing h0: μ <dig> = μ <dig> versus h1: μ <dig> ≠ μ <dig>  for each phenotype group the expression averages and sample covariance matrix of the expression levels within that group is computed for the genes included in the pathway. the two estimated covariance matrices, one for each phenotype group, are combined using the standard pooled covariance estimator,  Σ <dig> +  Σ2)/. in the implementation of rcmat we allow the unpooled covariance estimator to be utilized, if desired. this option can prove useful should the researcher have cause to suspect that differences exist between the two phenotype covariance structures. the inversion of the combined estimate, which is necessary for the test statistic, is ill-posed when n<p. matrix theory states that the combined estimate must be positive definite and that the eigenvalues of this quantity must be strictly positive  <cit> . this issue may be addressed by the method of kong et al.  <cit> .

however the estimate of the inverse of the covariance matrix is very unstable when n is only moderately greater than p or large correlations are present in the data. this fact could pose serious problems for the method of kong et al. in many realistic situations. we regularize  or bias the estimator in the hopes of achieving a more stable estimator, as in ridge regression. the regularized estimate is Σreg = αΣ + *i, where Σ is the combined covariance estimator obtained with the data and i is an identity matrix of the same dimension as Σ. both  <cit>  provide an overview of shrinkage estimation, discuss the counterintuitive behaviour of james-stein estimators, and provide examples in the normal distribution case. Σreg could also be viewed as an empirical bayes estimator; one hopes that through the introduction of bias with the inclusion of i a reduction in the total variance of Σreg is obtained. similar to the classification procedure of tai et al.  <cit>  rcmat employs a heuristic measure to determine the amount of regularization to be applied, comparable to ridge regression. the constant α is incrementally reduced from  <dig> towards  <dig>  in increments of  <dig> , until the smallest positive eigenvalue is greater than one divided by the number of genes in the gene set. controlling the eigenvalues of Σreg insures that the resulting matrix is positive definite. other approaches to select α are possible. schäfer et al.  <cit>  provide an overview of various shrinkage estimation approaches for use in estimating large-scale covariance matrices in genomics applications. if Σ is highly unstable, e.g., the number of genes in the gene set is markedly greater than the sample size or the genes within the gene set are highly co-regulated, then the regularized estimator Σreg could be heavily biased towards the identity matrix as α approached  <dig>  that is, the variables are assumed to be nearly independent with unit variance; apart from the biased variance estimates and a reliance on large sample theory this assumption would lead to a test similar to page. once a suitable α is selected the inverse of the regularized estimate is incorporated into the traditional hotelling's t <dig> 

despite our efforts to form a stable test statistic with the desired properties we still need the statistic's sampling distribution. a closed form distribution for this test statistic does not exist under the null hypothesis of no average separation between the two phenotypes for the selected gene set. traditional n>>p large sample asymptotic theory is not applicable due to the customary n<p ill-rank estimate for Σ. therefore, permutation testing  <cit>  is used for assessing significance.  <dig>  permutations of the observation phenotype labels were used to determine the significance of the regularized covariance multivariate test. at each permutation step a new α value was selected for the shuffled data. despite a two-sided hypothesis the use of a quadratic form for our test statistic requires a one-sided rejection region. if one elects to test more than one pathway, i.e., a set of gene sets, then one can apply a multiple comparison procedure to attempt to control for the overall false discovery rate.

computer simulation
a total of  <dig> conditions were simulated. at each condition  <dig> data sets were generated. both the method of kong et al.  <cit>  and the rcmat algorithm were applied to the simulated data. the expression levels within each phenotype were simulated with a multivariate normal distribution, mvn, where μ is the vector of gene means and Σ is the covariance matrix of the genes within the gene set. with each new data set generation the same random covariance matrix was used for each of the two phenotypes, i.e., phenotype  <dig> x ~mvn and phenotype  <dig> y ~mvn. the phenotype gene set variances were set at one. we did not restrict ourselves to simulating highly structured covariance matrices since we have observed pathways where the pathway members do not exhibit strong pair-wise correlations. similar observations were noted in song et al.  <cit>  for both diabetes and leukemia data sets. limited simulation work, not included here, was also performed under the assumption of unequal covariance matrices with similar results. simulation conditions were intended to reflect typical practice in genomics:  <dig> or  <dig> genes were assumed to be in the pathway , the within-group phenotype sample size was  <dig>   <dig>  or  <dig> , phenotypes were separated on either the major axis of variation  or a minor axis of variation , and the amount of separation as a multiple of the axis of variation was either  <dig> ,  <dig> , or  <dig>  . the aforementioned settings were arranged in a factorial layout. to examine the null distribution of the statistic for possible type i error concerns we selected  <dig> conditions  where no separation existed between the two phenotypes, i.e., μ <dig> = μ <dig> =  <dig>  finally, we selected one interesting condition  and allowed the within-phenotype sample size to vary at additional increments between  <dig> and  <dig> 

gsea diabetes data sets
we evaluated rcmat with the human diabetic muscle microarray data found in  <cit> . both the transcription data and the gene set data sets from the original gsea study were obtained from the authors' website . the microarray data included transcriptional profiles obtained from  <dig> normal and  <dig> diabetic muscle biopsies. the authors selected  <dig> of the gene sets for analysis based on their involvement in metabolic pathways with the remainder representing gene clusters based on co-regulated genes from a mouse expression atlas.  <dig>  genes were analyzed. zeros were removed from these data and the logarithm base two transformation was applied to all entries. a median plus/minus three times the median absolute deviation winsorization algorithm was applied to the expression levels of each gene for each phenotype to mitigate the effect of potential outliers. this compares to the "mean plus/minus three standard deviations" recommendation of draghici  <cit> . the website contains the  <dig> gene sets analyzed in the original study. two gene sets contained a single gene and were removed from the analysis.

implementation of rcmat
rcmat was written using the freely available language r  <cit> . r is available for most computing platforms including windows, macos, linux, and solaris. the code for rcmat and generating the simulated data can be found at the author's website .

RESULTS
simulated data comparison
we evaluated the performance of rcmat with both simulated data and the data from the original gsea paper  <cit> . due to the lack of a benchmark standard for comparing n<p test procedures we chose to compare the performance of our statistic with the approach of kong et al.  <cit>  via simulation. apart from rcmat's use of a regularized covariance estimate the method of kong et al. is a close hotelling's t <dig> parallel to rcmat. the kong et al. method was independently presented as pcot <dig> in  <cit> . we first examine the distribution of p-values when no difference exists between the groups in the averages of expression measures of genes in the pathway, i.e., the null hypothesis case. in a two-group null comparison each p-value between  <dig> and  <dig> is equally likely. figure  <dig> depicts the distribution of p-values for both rcmat and the procedure of kong et al. when no difference is present between the two groups. each plot graphs the  <dig> ranked p-values for each of the six settings in a uniform qq-plot. the number of genes in a pathway was either  <dig> or  <dig> and the within-group sample size was  <dig>   <dig>  or  <dig> for both groups. both methods exhibit a somewhat conservative bias relative to the expected p-value.

we now turn our attention to the power of the rcmat approach. figure  <dig> illustrates the cumulative distribution function of the rcmat nominal p-values under select simulation conditions; figure  <dig> provides a paired comparison of the rcmat p-value with the corresponding p-value produced by the method of kong et al. summary statistics for the  <dig> non-null simulated conditions can be found in additional file  <dig>  to facilitate the paired comparison a logarithm base ten ratio  is graphed. permutation p-values of zero, the only allowable value less than  <dig> , were replaced with  <dig>  in the computation of the ratio.

rcmat is a computationally intensive procedure. computing time is strongly influenced by the number of permutations, the number of genes in the gene set analyzed, the amount of regularization required, and the increment used in selecting the regularization constant α. on a standard single cpu personal computer with a  <dig>  ghz microprocessor and  <dig> gb of computer memory computing times ranged from  <dig> to  <dig> hours to process  <dig> 10-gene gene sets using  <dig>  permutations and an α increment of  <dig> . on the order of  <dig> to  <dig> hours of cpu time were necessary to process  <dig> 30-gene gene sets.

comparison using diabetes data
for each of the gene sets from mootha et al.  <cit>  both the rcmat and the method of kong et al. were applied. nominal  permutation p-values for each of the two procedures are given. the number of genes in the pathway is also provided.

in the tabled comparison  <dig> of the  <dig> ranked rcmat p-values were less than the p-value produced by the kong et al. method. a direct relationship between rcmat p-values, obtained through the use of a  biased covariance estimator, and p-values obtained with a method utilizing subspace projections is complicated by the nature of the test and the features of the data. across all  <dig> comparisons the kong et al. algorithm produced  <dig> p-values less than the corresponding rcmat p-value. the complete comparison data are listed in additional file  <dig>  our approach recovered the oxidative phosphorylation gene set originally found in  <cit> . song et al.  <cit>  did a detailed comparative analysis of these same data using the sigpathway, gsea-category, gsea-limma, safe, globaltest, and pcot <dig> algorithms. they obtained the largest number of significant gene sets with the gsea-limma algorithm, using a nominal unadjusted p-value of  <dig> . but, the top ranked gene set results varied across the  <dig> methods tested. apart from  <dig> or  <dig> exceptions, all of the gene sets identified under the various algorithms with a nominal unadjusted p-value of  <dig> , including the  <dig> gene sets determined by gsea-limma, are a subset of the  <dig> gene sets located with rcmat. these results also largely encompass the results obtained with the page  <cit>  approach and the method of  <cit> . interestingly enough, applying the benjamini-yekutieli false discovery rate procedure with an overall α level of  <dig>  indicated that a single pathway, c25_u133_probes, would be declared significant. these results are in broad agreement with the fdr adjusted p-values found in  <cit>  where only one pathway met this cut-off across the  <dig> gene set analysis algorithms tested.

discussion
in traditional n>p two sample multivariate testing problems hotelling's t <dig> statistic is commonly used to compare two multivariate means  <cit> . two features of this multivariate test are that: 1) the test statistic incorporates the co-regulation or correlation among the features and may provide an improved ability to detect a separation between two multivariate groups that are not distinguishable with any single feature, and 2) all of the mean comparisons are integrated into a single statistical test, which simplifies the problem of multiple comparisons; i.e., there is no need to appeal to a multiple comparison correction procedure within a gene set. hotelling's t <dig> has already been used to investigate differentially expressed genes in the two sample case  <cit> . the multivariable gene set approaches found in  <cit>  attempt to resolve the n<p problem through the use of a gene selection procedure. feature/subset selection approaches often involve intermediate statistical tests and can vary in their use of the researcher's available data. tomfohr et al.  <cit>  use the single largest metagene, obtained with a singular value decomposition of expression values of genes in the group, to compare two phenotype groups. in a related extension kong et al.  <cit>  use a singular value decomposition to locate a reduced gene subspace defined by the eigenvectors whose corresponding eigenvalues exceed a small positive number. however the directions of the subspace corresponding to smaller eigenvalues of Σ can be poorly estimated. we conjecture that rcmat is more powerful relative to the procedure of kong et al. since rcmat does not restrict the magnitude of the phenotypic transcription differences included and it reduces the noise in the estimate of the covariance matrix, which is inverted. a degree of caution is still advised - highly unstable or p > >n gene set covariance estimators may be heavily biased by rcmat due to the need for a large amount of regularization.

both song et al.  <cit>  and ackermann et al.  <cit>  offer a comparison of existing methods for analyzing gene sets via one-dimensional gene enrichment procedures and multivariate comparisons. song et al.  <cit>  found that pcot <dig>  a hotelling's t2-based test statistic which projects the original data onto a reduced subset via a limited number of principal coordinates, could provide an increased ability to detect altered gene sets through the inclusion of the correlation structure relative to the other gene set methods. they also suggested that including the co-regulation structure can outperform the one-dimensional measures contingent on the features of the data. large fdr-adjusted p-values were also commonplace in the gene set comparisons. ackermann et al.  <cit>  focused primarily on one-dimensional enrichment procedures although the method of kong et al. was also included in their comparison. in the small sample case they advocated the use of regularization procedures for the tests based on one-dimensional measures. they also noted that the strength of the procedure was impacted by the extent of the correlation structure present in the data. data comprised of mostly independent features did not appear to benefit from a multivariate procedure relative to the best univariate approaches. ackermann et al. also found that the transformation applied to the one-dimensional measures was critical in the performance of the enrichment procedures. the most accurate transformation tested, a squared transformation, essentially corresponds to a hotelling's t2-test with a diagonal covariance matrix. if co-regulation is a negligible concern in a gene set's definition or is weakly present in experimental data the choice between either a multivariate or an enrichment procedure for testing a gene set's significance is moot.

the regularization methodology employed here is related to the shrinkage methods commonly applied to univariate gene analyses. shrinkage techniques appear in the bioconductor package limma  <cit> , sam  <cit> , and its gene set extension sam-gs  <cit> . whereas typical shrinkage methods borrow information from other genes to improve estimates for a single gene our approach shrinks the pooled covariance estimate towards a fixed diagonal covariance matrix. cui et al.  <cit>  and schäfer et al.  <cit>  outline some of the theoretical properties of univariate and multivariate shrinkage estimators, respectively, in the context of microarray studies. not surprisingly, the use of other forms of regularized covariance estimators is possible. in recent work tsai et al.  <cit>  provide a multivariate analysis of variance test based on wilks' Λ that makes use of a shrinkage covariance matrix estimator for gene set comparisons. this method applies to the comparison of two or more phenotypes. regularization towards a diagonal covariance matrix has the benefit of transforming the multivariate distance from the traditional mahalanobis distance to a euclidean distance. rcmat shifts, to the extent necessary, from an explicit and complete use of the co-regulation among the gene set constituents to an independent-genes framework. should large differences exist between the two phenotype covariance structures the traditional combined estimator can begin to resemble the independent-gene scenario. these points bear mention in addition to the usual comments regarding the numerical stability associated with regularization procedures. bickel and levina  <cit>  offer the intriguing finding that a naïve bayes classifier, which assumes that each pair of genes are conditionally independent, can outperform the classical fisher's linear discriminant rule in the context of p > n classification problems.

bickel and levina  <cit>  provide a related theoretical work outlining the benefits of tapered or banded matrices when the number of variables exceeds the number of observations. restricting the complexity of the covariance estimator can allow for a more stable estimator. this creates a dilemma for the proposed method between ease-of-use and accuracy for a researcher - restricting the number of unknowns improves accuracy but requires that the gene set structure be precisely defined. theoretical work on p > n problems, such as  <cit> , often assume that the ratio of the number of variables monitored and the sample size obey a fixed relationship. definitive guidance for addressing p > >n problems for small-yet-realistic samples, e.g., the gsea diabetes data presented here investigated gene sets consisting of hundreds of genes with only  <dig> samples, is still lacking.

CONCLUSIONS
as the era of integrative or systems biology expands researchers' concerns will shift from analyzing single genes to analyzing shifts in coherent sub-systems within the cell. powerful and well-understood analysis tools will need to be developed to address these challenges. methods that rely on sophisticated corrections to individual test p-values to screen genes or disregard the correlation structure for a gene set known to consist of co-regulated genes carry risks. in this paper we have outlined a multivariate test statistic that bridges the classical hotelling's t <dig> to the current "many genes are measured with a minimal number of samples" environment. our multivariate statistic parallels the one-dimensional gene shrinkage/enrichment methods currently enjoyed in the microarray analytic lexicon. despite the simplicity of rcmat it enjoys favorable limiting traits, resembles a classical "diagonalized" pooled estimator in the event of unequal covariances, and offers greater power relative to a method that reduces the dimensionality of the data using the observed data. the merits of rcmat have been illustrated via a simulated comparison and verified with the gsea data. we offer rcmat as a microarray platform-independent analytical tool for use in the analysis of gene sets.

authors' contributions
pdy designed and implemented rcmat, performed the analyses, and drafted the manuscript. mar suggested the problem, the approach, supervised the development of rcmat, and edited the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
summary statistics of the rcmat nominal p-values under the simulated non-null conditions. under each of  <dig> select conditions   <dig> simulation experiments were performed and permutation p-values obtained. for each condition various percentiles for the p-values obtained are listed.

click here for file

 additional file 2
comparison of rcmat with the procedure of kong et al. for each of the gene sets from mootha et al.  <cit>  both the rcmat and the method of kong et al. were applied. nominal  permutation p-values for each of the two procedures are given. the number of genes in the pathway is also provided.

click here for file

 acknowledgements
the authors thank dr. kellie archer for a critical reading of the manuscript. the authors also thank the two referees for their helpful comments and suggestions.
