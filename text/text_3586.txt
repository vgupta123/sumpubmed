BACKGROUND
sequence comparison is still one of the most important methodologies in the field of computational biology. it enables researchers to compare the sequences of genes or proteins with unknown functions to sequences of well-studied genes or proteins. however, due to a significant increase in whole genome sequencing projects, the amount of sequence data is nowadays very large and rapidly increasing. therefore, pairwise comparison algorithms should not only be accurate and reliable but also fast. the smith-waterman algorithm  <cit>  is one of the most advanced and sensitive pairwise sequence comparison algorithms currently available. however, it is theoretically about  <dig> times slower than other popular algorithms  <cit> , such as fasta  <cit>  and blast  <cit> . all three algorithms generate local alignments, but the smith-waterman algorithm puts no constraints on the alignment it reports other than that it has a positive score in terms of the similarity table used to score the alignment. blast and fasta put additional constraints on the alignments that they report in order to speed up their operation: only sequences above a certain similarity threshold are reported, the rest is used for the estimation of certain parameters used in the alignment calculation. because of this smith-waterman is more sensitive than blast and fasta. the smith-waterman algorithm finds the best matching regions in the same pair of sequences. however, blast and fasta are still far more popular because of their speed and the addition of a statistical significance value, the expect-value , whereas the original smith-waterman implementation relies only on the sw-score without any further statistics. the newer smith-waterman implementations of paracel  <cit> , ssearch  <cit>  and paralign  <cit>  do include the e-value as a measure of statistical significance, which makes the smith-waterman algorithm more usable as the engine behind a similarity search tool. the e-value is far more useful than the sw-score, because it describes the number of hits one can expect to see by chance when searching a database of a certain size. an e-value threshold can be used easily to separate the 'interesting' results from the background noise. however, a more reliable statistical estimate is still needed  <cit> . the z-score, based on monte-carlo statistics, was introduced by doolittle  <cit>  and implemented by gene-it  <cit>  in its sequence comparison suite biofacet  <cit> . the z-score has been used in the creation of the sequence annotation databases clustr  <cit>  and protein world  <cit>  and was used in orthology studies  <cit> . the z-score has also been implemented in algorithms other than smith-waterman, such as fasta  <cit> . it is calculated by performing a number  of shuffling randomizations of both sequences that are compared, completed by an estimation of the sw score significance as compared to the original pairwise alignment. this makes the z-score very useful for doing all-against-all pairwise sequence comparisons: z-scores of different sequence pairs can be compared to each other, because they are only dependent on the sequences itself and not on the database size, which is one of the parameters used to calculate the e-value. however, this independency of the database size makes the z-score unsuitable for determining the probability that an alignment has been obtained by chance. the randomizations make the z-score calculation quite slow, but theoretically it is more sensitive and more selective than e-value statistics  <cit> . unfortunately, this has never been validated experimentally.

some methods have been used to combine the sensitivity and selectivity of a sequence comparison algorithm into one single score  <cit> . receiver operating characteristic  is a popular measure of search accuracy  <cit> . for a perfect search algorithm, all true positives for these queries should appear before any false positive in the ranked output list, which gives an roc score of  <dig>  if the first n items in the list are all false positives, the rocn score is  <dig>  although researchers have devised many ways to merge roc scores for a set of queries  <cit> , one simple and popular method is to 'pool' search results so as to get an overall roc score  <cit> . another method to evaluate different methods is the errors per query  criterion and the 'coverage versus error' plots  <cit> . epq is a selectivity indicator based on all-against-all comparisons, and coverage is a sensitivity measure. the assumption for epq is that the search algorithm can yield a 'normalized similarity score' rather than a length-dependent one, so that results from queries are comparable. like roc, the coverage versus error plot can give an overall performance comparison for search algorithms. a third method, the average precision  criterion, is adopted from information retrieval research  <cit> . the method defines two values: the recall  and the precision , which are plotted in a graph. the ap then is an approximate integral to calculate the area under this recall-precision curve. these methods were used to compare several sequence comparison algorithms, but we use them to compare the e-value and z-score statistics. analyses of blast and fasta are also included as reference material.

here we show that two out of the three smith-waterman implementations with e-value statistics are more accurate than the smith-waterman implementation of biofacet with z-score statistics. furthermore, the comparison of blast and fasta with the four smith-waterman implementations shows that fasta is a more reliable algorithm when using the astral scop structural classification as a benchmark. the smith-waterman implementation of paracel even has lower scores than both blast and fasta. ssearch, the smith-waterman implementation in the fasta package, scores best.

RESULTS
we used a non-redundant protein-domain sequence database derived from pdb as the target database. it is automatically generated using the astral system  <cit> . according to the structural classification of proteins , it includes  <dig> sequences and  <dig> families. true positives are those in the same family as the query sequence. scop as an independent and accurate source for evaluating database search methods has been used by other researchers  <cit> . astral scop sets with different maximal percentage identity thresholds  were downloaded from the astral scop website  <cit> . their properties  are shown in table  <dig>  three different statistical measures were applied: receiver operating characteristic , coverage versus error  and mean average precision . we compared six different pairwise sequence comparison algorithms, which are listed in table  <dig>  together with the parameters used in this study.

* is = average matrix identity score

receiver operating characteristic
the mean roc <dig> scores increase if more structurally identical proteins are included, for both the e-value and the z-score measurements . the roc <dig> scores of the pdb <dig> set show a large difference between the several smith-waterman implementations:  <dig>  for paracel,  <dig>  for biofacet ,  <dig>  for paralign and  <dig>  for ssearch. the advantage of paralign over biofacet decreases with increasing inclusiveness of the astral scop set that is used. the roc <dig> scores of the pdb <dig> set are  <dig>  for paracel,  <dig>  for both paralign and biofacet  and  <dig>  for ssearch. ssearch scores best of all studied methods, regardless of which astral scop set is used. the reference methods fasta and blast give quite different results: fasta is a good second and blast has scores similar to paracel and biofacet.

coverage versus error
this method differs from the roc analysis on one crucial point: instead of looking at the first  <dig> hits, we varied the threshold at which a hit was seen as a positive. hence the results are somewhat dissimilar: the differences between the several algorithms in the coverage versus error plots  are not as obvious as they are in the roc <dig> graph . figure 2a shows the coverage versus error plot for the smallest astral scop set , figure 2b shows the plot for the largest astral scop set  and figure 2c shows the plot for the intermediate set pdb <dig>  an ideal algorithm would have a very high coverage but not many errors per query, which places it in the lower right corner of the graph. ssearch has the best scores when using the pdb <dig> set, followed by paralign and fasta, with the latter scoring best in the lowest-coverage range . biofacet with z-score has the lowest scores. the pdb <dig> plot shows some differences between the low-coverage range  and the high-coverage range . in the low coverage range, fasta and paracel have the highest scores, whereas ssearch and paralign have the highest scores in the low-coverage range. it should be noted that the high-coverage range might statistically be more reliable because of the larger number of hits. the pdb <dig> set gives similar results.

average precision
the average precision graph  shows some minor differences from the roc <dig> graph : for the pdb <dig>  pdb <dig> and pdb <dig> set, paracel  scores better than biofacet . however, the advantage of the biofacet smith-waterman with z-score increases from that point on  to the right side . the z-score seems to score better when more similar proteins are compared. once more, ssearch has the highest scores for all structural identity percentages, with fasta as the second best.

case studies
we included two examples of our statistical analysis, which show how the roc and mean ap measures differ from each other and how results can be different for each studied protein. we choose two well-studied proteins: enoyl-acp reductase and the progesterone receptor, the first from a prokaryote  and the second from a eukaryote . both case studies were done using the pdb <dig> set, which is the most complete astral scop pdb set used in our study.

bacterial enoyl-acp reductase
human progesterone receptor
timing
* estimation because of unavailability paracel system

discussion
the theoretical advantage of the z-score over the e-value appears to be rejected by our results. our results show that the e-value calculation gives an advantage over the computationally intensive z-score, at least when looking only at the results from the smith-waterman algorithm. some caution should be taken however, drawing any definite conclusions. first, the z-score was designed to make a distinction between significant hits and non-significant hits that have high sw scores. it might have an advantage over the e-value when applied to the top hits only, but might have less advantage for the hits with lower sw scores. this idea is supported by the fact that the z-score is better at scoring high-similarity sequence pairs. this is also reflected in the different roc and ap scores for the pdb <dig> set and the pdb <dig> set: the difference between z-score and e-value increases when structurally more similar protein pairs are being included. second, the z-score can differ for each run, because of its different randomizations  <cit> . the standard deviation of the z-score increases almost proportionally with the z-score itself, i.e. for higher z-scores the variance will be larger  <cit> . however, the z-score increases its precision when more randomizations are calculated . third, the pdb set is somewhat biased: it only contains crystallized proteins, and it contains no hypothetical proteins and membrane proteins. the crystallized proteins in the pdb are on average smaller than proteins included in large sequence databases such as the uniprot  <cit>  database , whereas the amino acid distribution is approximately the same for these databases .

finally, we would like to stress that the results from the cve analysis might be more reliable than those from the roc and mean ap analyses. roc and mean ap make use of a ranking system based on the e-value or z-score, instead of looking at the e-value or z-score directly. this means that in some cases, especially the smaller protein families, a large number of very low-scoring hits  is still used for the calculation of the scores. this is not the case for the cve plots, because we varied the e-value and z-score thresholds above which a hit is seen as a true positive, instead of relying on a ranking system. however, because the results from the cve plots are similar to the results from the roc and mean ap graphs, the use of a ranking system does not seem to give a large disadvantage.

CONCLUSIONS
for a complete analysis we need a less biased database, having a wide range of proteins classified by structure similarity. until such a database is available, it will be difficult to pinpoint the reasons for the different results between fasta, blast and smith-waterman, and the theoretical advantages of the z-score. regardless of all these theoretical assumptions, the computational disadvantage of the z-score is smaller for larger databases. z-scores do not have to be recalculated when sequences are added to the database, in contrast to e-values, which are dependent on database size. for very large databases containing all-against-all comparisons, this is an important advantage of the z-score. although recalculating the e-values does not take much time when the alignments and sw scores are already available, this may cause a change in research results that were obtained earlier. despite these considerations, we recommend using ssearch with e-value statistics for pairwise sequence comparisons.

