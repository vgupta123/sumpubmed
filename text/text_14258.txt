BACKGROUND
the function of the rna molecule depends on the way it folds – structural changes can change protein binding sites, or affect activity for ribozymes, for example. rna folding allows the single strand of nucleotides to fold upon itself and form more complex structures such as helical junctions and pseudoknots; almost as soon as rna started to be sequenced, methods were established to determine the structure from the sequence of nucleotides. early attempts include
 <cit> , who simply summed over all possible secondary structures and evaluated them with respect to free-energy functions. biological and thermodynamical principles have since been applied to formulate more advanced free-energy functions facilitating more accurate and efficient predictions, which have been used to great effect in methods such as unafold
 <cit>  and rnafold
 <cit> . stochastic context-free grammars have also been used to great effect in programs such as pfold
 <cit> . for a review of rna secondary structure prediction, see
 <cit>  or
 <cit> .

the inverse rna folding problem is defined as follows: given a particular rna secondary structure , find a sequence of base pairs that would fold into this structure. one could adopt two possible solution techniques: either find an exact match, i.e. a sequence whose predicted structure matches the target structure exactly, or look for a sequence whose predicted structure is as close as possible to the target structure . then, the inverse folding problem becomes an optimization problem: the goal is to minimize the distance metric defined between a given target structure and the predicted structure of a sequence. here we consider only base pairs {a−u,u−a,c−g,g−c,g−u,u−g}, and, since experimental verification of the folded structure is not feasible, the structure predicted computationally by rnafold is used as a proxy for the true secondary structure of a designed sequence.

there are several existing approaches to the rna inverse folding problem. rnainverse
 <cit>  is the most basic method, inspired by local guided search. given a target structure, it produces a random sequence that is then randomly changed at points where its predicted structure differs from the target structure. rna-ssd
 <cit> , info-rna
 <cit> , nupack: design
 <cit> , and inv
 <cit>  are also local guided search based methods, using various combinations of intelligent initial sequence design and/or hierarchical decomposition of the target structure. modena
 <cit>  is the only algorithm that introduces a genetic algorithm approach. this approach is multi-objective: it aims to maximise the closeness to the target structure and minimize the free energy of a solution. it facilitates a better exploration of the search space, and avoids the limited prediction capabilities of the local guided search methods. however, a strong focus on energy minimisation causes an extreme bias towards c-g base pairs.

however, there are currently no implementations available capable of solving the inverse folding problem under multiple structural constraints. to our knowledge, the only existing method for inverse folding with multiple structure targets was published by
 <cit> . this method has not been made publically available as part of the vienna package. with the current interest in using bio-molecules in nano-technology, the ability to design artificial riboswitches reacting to changes in conditions will become increasingly important. hence an implementation capable of solving the inverse folding problem for multiple structures is a key development in structure design.

methods
the inverse folding is implemented by a fairly standard genetic algorithm  approach
 <cit> , expanding a population by mutations and recombinations and selecting the most fit individuals for propagation to the next generation. the main deviation from a completely generic ga is that the method is aware of the aim of designing sequences folding into one or more target structures. rather than search the full sequence space, we direct the search by ensuring all sequences can fold into the target structure forming only canonical base pairs. this can be viewed as a similar approach to the local search/adaptive walk on a hierarchical decomposition of the target structure implemented by some methods
 <cit> , except that the recombination operation chooses a random decomposition and assesses two complementary structural components in conjunction, rather than independently.

in addition to a random search, our method also implements several strategies for more directed evolution. instead of making uninformed evolutionary changes and leave it to the selection part of the ga to direct the search, it is also possible to bias the choice of change towards e.g. mutating positions with a predicted structure that does not match the target, or in a recombination towards parts that have a good match to the target structure in the regions where they contribute sequence. these strategies are all available through command line options  to allow experimentation and tailoring to specific applications. through experimentation, a set of parameters was found which worked reasonably on all types of structure, which is set as a pre-defined default. in the following, we will use
t={τ}τ∈t to denote a target consisting of a non-empty set of structures, all of length n, and s to denote a sequence in the ga population.

positional fitness
a key concept in the ga is the fitness of positions. this allows directing evolutionary changes by choosing unfit positions for mutations – an approach also taken in
 <cit>  and to a lesser extent in
 <cit>  – and regions with fit positions for recombination. positional fitnesses take a value of  <dig> for maximally unfit positions and a value of  <dig> for maximally fit positions.

we define positional fitness schemes relative to a single target structure τ. if
t consists of multiple target structures, the final positional fitness is computed as the average positional fitness over all structures in
t. let τi denote the required structure for position i in τ, i.e. either forming a base pair with another position j or unpaired. let σdenote the optimum structure predicted for s , and let
s denote the set of possible structures for position i, i.e. base pairs with position i as one base in the pair and the unpaired configuration. finally, let
p:s↦r be the marginal boltzmann probability in the form of a mapping from positional structure to marginal probability. our method provides the following choices for the fitness of position i, denoted f.

scheme  <dig>  binary indicator of whether position has correct predicted structure, f=  <dig> − δσ ,τ where δ is the kronecker delta. this corresponds to the μ based objective in
 <cit> , providing a binary view of whether the design matches at position i that may be too coarse grained. however, it does also capture σis correct at position i, or the design needs to change.

scheme  <dig>  boltzmann probability of target structure, f = 1 − p. this corresponds to the n objective in
 <cit> , providing a measure of how likely a structure drawn from the boltzmann ensemble is to match τat position i. this provides more fine grained information than scheme  <dig>  but measures proximity rather than match to τ.

scheme  <dig>  truncated negative logarithm of boltzmann probability of target structure, f = min{−log)/ <dig> }. this penalises decreasing probability to match τwith increasingly severity, and is particularly useful for multiple structure targets where the average corresponds to a sum of logarithms, thus penalising designs failing to match just one of the target structures. truncation is performed to allow mapping to  <cit> .

scheme  <dig>  binary indicator of whether probability of target structure exceeds threshold
θ,fi=1pτi<θ. this allows requiring all elements of τto be present with a given probability when sampling the boltzmann ensemble, but being oblivious to further improvements beyond that. it is particularly useful when
t specifies a multi-stable design, i.e. a target with multiple structures for the same temperature, by measuring the number of target structures the design matches with probability at least θ at position i.

scheme  <dig>  sigmoid transformed difference between boltzmann probability of target structure and most probable alternative structure,
f=12+34x−14x <dig> where
x=maxν∈s∖{τ}{p}−p. this allows accepting lower probabilities of τiin regions where the structure is generally less well defined, although a position is still most fit iff p =  <dig>  the transformation corresponds to
∫−1x−dy, normalised to yield values in  <cit> , and causes changes to have larger effects when the probability of τiand the most probable alternative are close to being equal.

the p and σ are computed at the temperature specified for τ, and may thus differ between the τ’s when a multiple structure target is specified.

finally, the following positional fitness schemes specifically designed for multiple structure targets
t are defined.

scheme  <dig>  minimum boltzmann probability of target structures,
f=1−minτ∈t{p}.

scheme  <dig>  product of boltzmann probabilities of target structure,
f=1−∏τ∈tp.

for single structure targets, they are equivalent to the boltzmann scheme, scheme  <dig>  for multiple structure targets, scheme  <dig> exclusively focuses on the worst fitness over all target structures, while scheme  <dig> includes boltzmann probabilities from all target structures. however, by multiplying the probabilities, having a low fitness on just a single target structure will have a much more notable effect, than under the sum implicit in the averaging of scheme  <dig> 

in addition to a single of the above schemes, there is the possibility of using a weighted combination of any subset of them to define positional fitness. e.g. combining the first two schemes would divide positions based on whether they have a predicted structure matching the target, but further graduate the fitness by the marginal boltzmann probability of the target structure at each position.

the concept of positional fitness underpins most operations of the ga: mutation, recombination, selection, and termination. whenever fitness of a region  or the entire sequence  is needed, this is obtained as the sum of the positional fitnesses in the region or sequence. different positional fitness schemes can be used for these four aspects, with the limitation that negative logarithms of boltzmann probabilities are only used for mutation, and product of boltzmann probabilities cannot be used for mutation.

fitness and objective
often fitness and objective of gas are considered equivalent, but we make the distinction of using fitness for the selection in each round of the ga and objective for determining when an adequate solution has been found and the search can be terminated. in a standard design problem where the aim is to find a sequence folding to one specific target structure, it is natural to base the objective on whether positions are correct in the predicted structure and terminate when the number of errors reaches  <dig>  however, a more fine grained selection may be desirable, for example substituting or combining the number of errors with scheme  <dig> – instead of choosing randomly between two sequences with e.g. 10% positions that are wrong in the predicted structure, we would prefer the one with higher probabilities of positions being correct.

a global, i.e. non-positional, scheme

scheme  <dig>  logarithm of structure probabilities in boltzmann ensemble and their variance:
f=x¯+ξ1|t|∑τ∈txτ2−x¯ <dig> where
x¯=1|t|∑τ∈txτ and xτ = −logpτ is the negative logarithm of the probability of target structure τ in the boltzmann ensemble of sequence s, and ξ ≥  <dig> is the weight assigned to the contribution from the variance

based on the cost functions discussed in
 <cit>  and corresponding to the Π objective in
 <cit> , is also available for defining fitness and objective. this provides a means of requiring an exact match to the target structures, rather than basing the fitness on the distance to predicted or expected structure as in e.g. schemes  <dig> and  <dig>  this is particularly relevant when designing for multiple structures at the same or very similar temperatures, where some of the position based schemes may be confused by designs where positions exhibit a good match to varying subsets of the target structures.

finally, to maintain diversity in the ga population, the fitness can be augmented with a weighted contribution from the average hamming distance to already selected sequences. if
p denotes the set of sequences already selected in the selection stage at the end of a generation in the ga, each remaining candidate sequence s has its fitness augmented by
ζ∑t∈p)/|p|, where h is the hamming distance between sequences s and t, and ζ >  <dig> is the weight assigned to the contribution from diversity, before selecting the next individual carried forward.

mutation
the position targeted for mutation in a sequence is chosen either uniformly at random, or with probability proportional to positional fitnesses. similarly, sequences can be chosen for mutation either equally many times, uniformly at random, or with probability proportional to the reciprocal of the sequence fitness .

when choosing a new nucleotide for a position chosen for mutation, we want to maintain compatibility with all target structures. that is, the modified sequence should fold into each target structure using only canonical watson-crick and gu wobble base pairs. when the target consists of a single structure, unpaired positions can be updated independent of the rest of the sequence, while base pairing positions can be updated by sampling a new base pair for the two positions independent of the rest of the sequence. however, with two or more target structures, dependencies can extend to more positions, as a position can be base paired to multiple other positions in the different target structures.

the target dependency graph   implied by
t is the graph on nodes { <dig> …,n} where two nodes i, j are connected by an edge iff
∃τ∈t:i·j∈τ, where i · jdenotes a base pairing of positions i and j. the compatibility of a position will depend, directly or indirectly, on all positions in the connected component it belongs to in the tdg, so the entire connected component may have to be updated in a mutation. it can be observed from , that with canonical base pairing compatible sequences will exist iff the tdg is bipartite, and if
|t|≤ <dig> the tdg will be bipartite. if
|t|≥ <dig>  no compatible sequence may exist. for example, if three target structures contain base pairs i·j, j·k, and i·k, respectively, then there is no assignment of nucleotides to positions i, j, and k that will leave all base pairs canonical.

in
 <cit>  formulas for sampling an assignment of nucleotides on a connected component when the maximum degree of any node is at most  <dig> is provided. however, we have chosen a simpler, heuristic update algorithm for two reasons. first, our method was developed to also cope with larger sets of target structures. secondly, even for
|t|= <dig> the maximum node degree may be  <dig> and hence one may suspect assignment of nucleotides, i.e. colouring of the nodes, uniformly at random to be difficult – with a three letter nucleotide alphabet with base pairs allowed between any two non-identical nucleotides, the problem becomes #p hard
 <cit> . finally, it is unclear whether sampling uniformly from the set of compatible assignments is the best strategy. as g’s and u’s can pair with two other types of nucleotides, while c’s and a’s can pair with only one other type, the set of compatible assignments will be biased towards a high gu content.

the following forms our method for sampling nucleotides on a connected component in the tdg, starting with position i, ensuring all positions form canonical base pairs following the update. 

 choose σfrom {a,c,g,u}∖{s} and set s = σ

f = {i}, n = {j∣i · j}

whilen ≠  ∅ do

 choose j ∈ n uniformly at random

 choose σ from
∩k∈f:j·kc and set s = σ

f = f∪{j}, n = n∪{k∣j·k}∖f

end while

where j · k denotes that two nodes are connected by an edge in the tdg and
c is the set of nucleotides compatible with σ. it performs a traversal of the connected component of i, at each step choosing a random node neighbouring the already updated nodes. new nucleotides are drawn from a distribution which can be specified – if the default uniform distribution is used, this will tend to favour high gu content for the same reason as for choosing complete compatible assignments uniformly at random discussed above – truncated to the possibilities allowed. if the current nucleotide is among the choices, there is an option either always to keep the current nucleotide  or to bias the draw with 1 − f  for the current nucleotide and f  for alternatives .

recombination
due to the hierarchical nature of rna secondary structures, the ga uses recombination mimicking gene conversion rather than cross over, i.e. an infix of one sequence is recombined with the corresponding prefix and suffix of the other sequence. the easiest way to keep all base pairs canonical, is to always take two positions forming a base pair in a target structure from the same sequence. if we create a recombinant on sequences s and t from a crossover point i,j by forming the sequence s t  s , no base pairing positions come from different sequences iff there are no base pairs in the target structure for which one of i +  <dig> and j is inside the base pair and the other one is outside the base pair. this means that we can partition break points into sets of pairwise permissible points, such that the aim of taking base pairing positions from the same sequence is achieved iff crossover points are chosen as pairs of points from the same set in this partition. for single structure targets, these sets are exactly the loops of the structure, when stacking base pairs are viewed as internal loops of size  <dig>  and the set of all external positions. the following outlines the procedure used for constructing the sets of pairwise permissible points, where sets of size  <dig> are discarded. the target is denoted by
t, and when the algorithm terminates c is the set of non-singleton sets of points that are pairwise permissible. 

c={{ <dig> …,n}}

forτ∈t,i·j∈τdo

c′ = ∅

 for s ∈ c do

c′ = c′∪

 [ ,s∩ }:|x|>1

endfor

c = c′

end for

as a starting point, pairs of points are chosen by first choosing a set of pairwise permissible points with probability proportional to the set size, then choosing a pair from the set uniformly at random, ensuring an overall uniform probability that a point is chosen. this distribution can be biased proportional to 

 ϕi,js,t=∑k=1nfsifk≤iork>jftifi<k≤j 

 where fs and ft are positional fitnesses for s and t respectively. similarly, the pair of sequences s, t can be chosen uniformly at random, based on individual fitness as described for mutations above, or based on the sum over all pairs i, j of permissible points of
 <dig> to preferentially choose pairs of sequences complementing each other.

initialisation
initialisation of sequences in the starting population can either be done randomly, by sampling nucleotides for each connected component in the tdg as outlined for mutation, but without the presence of current nucleotides, or by running rnainverse from a random starting point. the latter option, an approach also used by rnaexinv
 <cit> , allows solutions to be found rapidly for easier targets. when rnainverse is used and the target
t consists of multiple structures, a random
τ∈t is chosen for each run. hence, the initial sequences may not be compatible with
t. additionally there is also the option to read the initial sequences from file, for example if specific sequence motifs are present it may be desirable to litter the initial population with them – it does also provide a simple means for using an alternative inverse folding method to create the initial population of sequences.

data
data was taken from two main sources, to benchmark frnakenstein and other inverse folding methods. the first data set used in our benchmarks is the data set used in
 <cit> . this was downloaded from the modena website. it consists of a structure from each of the  <dig> out of the first  <dig> families in rfam
 <cit> , with the tmrna family  left out due to a high content of pseudoknot forming base pairs. we refer to this data set throughtout as the rfam data set.

secondly, data was taken from rnastrand
 <cit> , which itself takes data from many sources
 <cit> . the data was filtered so that the sequences and structures could ensure reliability of predictions. we removed identical sequences and disregarded synthetic data and sequences with ambiguous base pairs. further, any sequences with greater than 80% base pair similarity with another structure in the data set were removed, as well as all sequences with pseudoknots, as rnafold does not predict pseudoknots. the resulting data set consisted of  <dig> rna molecules, containing  <dig> unique secondary structures with a total length of  <dig> , which we refer to as the rnastrand data set.

however, with both data sets, it may be possible that there is no sequence which rnafold will fold into the reference structure, and so the method might not be able to acheive 100% accuracy, due to rnafold, not the search heuristic. consequently the sequences corresponding to the structures in the rnastrand data set were re-folded using rnafold, so there is known to be at least one sequence which will correctly fold. this dataset will be denoted as the rnastrand-refolded, and consists of  <dig> unique structures with a total length of  <dig> .

RESULTS
multi-structure targets
one of the main objectives of frnakenstein was to develop a method capable of solving the inverse folding problem under multiple structural constraints. as mentioned earlier, the only existing method for inverse folding with multiple structure targets was published by
 <cit> . this method has not been made part of the vienna package, so we were unable to benchmark against this method. however, the paper does provide an example of a  <dig> nucleotide rna molecule, sv <dig>  that exists in two major conformations, a meta-stable multicomponent structure and a rod-like native state. they present a design for these two structures as target in . applying frnakenstein to this two-structure target we obtained the design shown in figure
 <dig>  this provides an almost perfect match to the target, including the isolated base pair 33· <dig> completely missing in  – as observed in
 <cit> , designing sequences for targets with isolated base pairs is at best difficult and sometimes impossible.

for all benchmarks on multiple structure targets we set the number of generations to the total target length, i.e. the number of structures in the target multiplied by the length of the sequence to be designed. again frnakenstein was run with default values, which means that compared to the single structure target default outlined above, positions for mutations were chosen based on a 1:1: <dig> combination of schemes  <dig>   <dig>  and 3; cross over points were chosen based on a 1:1: <dig> combination of schemes  <dig>   <dig>  and 7; fitness was based on a 1:1:2: <dig> combination of schemes  <dig>   <dig>  and  <dig>  and the diversity maintaining contribution from hamming distances, except for the sv <dig> example above where a fitness based on scheme  <dig> with ξ =  <dig> and an objective based on scheme  <dig> with θ = 1/ <dig> was used.

to some extent the sv <dig> target poses an impossible challenge, as we cannot find a sequence having both conformations as the most stable structure. hence, for bi-stable targets, we cannot measure performance by simply reporting successes and failures. to avoid this problem, we decided to test the performance of multiple structure target design by providing target structures at two different temperatures. we folded the  <dig> sequences with at most  <dig> nucleotides of the rnastrand data set under 20°c and 37°c, simulating a change from room temperature to normal body temperature. after eliminating duplicates,  <dig> two structure targets remained.

 <dig> targets, with a total of  <dig>  nucleotides, had identical structures at the two temperatures.  <dig> targets, with a total of  <dig>  nucleotides, had different structures at the two temperatures, with an average of  <dig>  positions where the structures differed. even when the structures differ, it will be possible to design a sequence that successfully folds to the correct target structure at each temperature, allowing a simple and easy to understand measure on performance of number of successes. this does not directly test the ability to design a bi-stable molecule. however, it does test performance on multiple structure targets in a related realistic scenario for inverse rna folding, where the aim is to design a molecule that under different conditions, either remains stable or performs as a riboswitch reacting to the change in conditions.

table
 <dig> shows the performance of frnakenstein on this data set. results are categorised based on whether target consisted of identical or different structures, and whether the best design was successful for both, one, or none of the target structures. a success is frnakenstein finding a sequence which folds correctly into the target structure. for each category we list the number of targets in the category , the average length of the targets , and where relevant the average number of differences between the targets  and the average number of differences between target and design per target structure the design failed on . note that identical structures mean that a sequence has to fold into the same structure at both 20°c and 37°c.

performance on  <dig> two-structure targets generated by folding shorter rnastrand at 20°c and 37°c.

successful designs were obtained for  <dig> targets. of the remaining  <dig> targets, the design folded correctly at one temperature for  <dig> targets, with an average of  <dig>  positions where the predicted structure of the design differed from the target at the other temperature. for the remaining  <dig> targets, the design did not fold correctly at either temperature, with an average of  <dig>  positions being wrong. it should be remembered that targets were created by folding a specific sequence at two different temperatures using rnafold, so in all cases we know that a perfect design does exist. comparing this to the results obtained on rnastrand-refolded, it is evident that the multiple structure target problem is considerably more difficult than the single structure target problem, in particular when the target structures differ.

single-target structures
since frnakenstein works for single targets too, the performance of our method on single targets could be benchmarked against other methods that are publicly distributed as source code or executables. this includes rnainverse
 <cit> , modena
 <cit> , info-rna
 <cit> , nupack: design
 <cit> , and inv
 <cit> . all benchmarks were done on a  <dig> core dell poweredge with  <dig> ghz amd opteron processors and 128gb  <dig> ghz memory. despite the availability of source code of rna-ssd
 <cit> , it could not be successfully compiled, so the web server was used where appropriate.

for each method being benchmarked, efforts were made to give it the same number of attempts at the problem, despite them employing different search heuristics. our method and modena were both run  <dig> times with a population size of  <dig>  and a number of generations equal to the number of positions in the structure . rnainverse, rna-ssd, info-rna, nupack: design, and inv were all run  <dig> times with default parameters. all methods apply the vienna rna package for structure prediction, except for nupack: design that uses the nupack suite, and inv, which uses its own thermodynamic model. nupack allows interior loops of arbitrary sizes, whereas the vienna package limits interior loops to a maximum size of  <dig>  this allows nupack: design to report a successful design on target structures with large interior loops, where all other methods will necessarily fail due to this limitation of rnafold. notably this is seen on the rf <dig> and rf <dig> structures in the rfam data set, which contains interior loops with  <dig> and  <dig> unpaired nucleotides, respectively. inv is even more restrictive on permissible structures, allowing only structures with a minimum stack size of  <dig>  and minimum arc length of  <dig>  this means that many trusted structures in, for instance, the rfam database it deems as invalid, and thus will produce an error, suggesting it will perform badly in the benchmarks.

frnakenstein was run with default values, which means mutation was biased towards fit sequences, positions were chosen based on a 2: <dig> combination of schemes  <dig> and 2; recombination was biased towards pairs of sequences with good complementary match and cross over points chosen based on a 1: <dig> combination of schemes  <dig> and 2; fitness was based on a 1:1: <dig> combination of schemes  <dig> and  <dig>  and the diversity maintaining contribution from hamming distance to already selected sequences, while objective was simply the number of erroneous positions in the predicted structure, cf. scheme  <dig>  as one cannot determine statistically what fitness, mutation, and recombination schemes will optimise success of the algorithm, the defaults were determined heuristically to make frnakenstein most likely to find a successful sequence for the target structure.

rfam structures
results from benchmarking on the rfam data set are shown in table
 <dig>  accession numbers have in the table been shortened by replacing the three leading 0s with ·. a ‘success’ indicates that the program has found a sequence which folds in silico into the target structure, with rnafold being used by all excepting nupack: design, which uses its own thermodynamic folding model similar to rnafold. each entry then lists the fraction of runs that successfully designed a sequence for the target, with non-zero fractions in bold, followed by the average running time in seconds. rna-ssd results were obtained from the rna-ssd server, with run times as reported from the server – run times are only reported for successful runs, so the average run time listed is the average over successful runs. an asterisk for inv indicates that inv reported that the target structure it was given was invalid and so did not make an attempt. several of the nupack: design benchmarks could not be fully completed, as each of the  <dig> independent searches were still incomplete after several days of run time, having neither found a successful design nor terminated the search.

comparison of five inverse folding methods on  <dig> rfam structures.

this data set was sufficiently small that rna-ssd could be included in the benchmark by manually uploading the targets to the rna-ssd server. our method and modena, the only two genetic algorithm based methods in the benchmark, exhibits the best performance, each successfully designing sequences for  <dig> of the  <dig> targets. info-rna also performs well, with  <dig> successful designs, while rna-ssd and rnainverse have more limited success, and inv performing poorly. every target inv considered to not be invalid it succeeds with, but it is so limited on what it permits that it does not attempt the majority of structures.

of the  <dig> target structures for which all rnafold based method failed, two  have internal loops with more than  <dig> nucleotides, which makes it impossible to reach a successful design as discussed above. all methods, including nupack: design, failed on the remaining three . these all contain a bulge of a single nucleotide separated from either a large hairpin loop or the exterior of the structure by an isolated base pair. with the current energy parameters, it is impossible to design a sequence where the same structure with the isolated base pair removed would not be more stable
 <cit> . hence, frnakenstein is the only method which does design sequences for all targets which are possible. for the remaining targets, the best designs differ in one or at most a few base pairs, e.g. by introducing an isolated base pair separating the large internal loops into two parts.

if we look at how nucleotides and base pairs are utilised by the different methods, table
 <dig> shows the distribution of base pairs and nucleotides in the successful designs for each method. the first group shows the distribution over the three types of base pairs in paired positions in the targets, the second group shows the nucleotide distribution for unpaired positions in the targets, and the last group shows the overall nucleotide distribution in the sequences. modena, info-rna, and to an extent nupack: design clearly differs from the rest of the methods, by having a base pair distribution heavily biased towards gc base pairs. this should come as little surprise. info-rna starts from a sequence designed to have lowest possible free energy over all sequences when folding in to the target structure. modena uses the free energy on the target structure as one of the objectives it optimises. this emphasis on minimising the free energy on the target structure causes a heavy bias towards the more stable cg base pairs with info-rna likely to start from a sequence with almost exclusively cg base pairs and modena consistently preferring replacing other base pairs with cg base pairs. what causes the slightly less pronounced bias for nupack: design is less clear, though. observing that modena furthermore has a strong bias towards a in unpaired positions, the method is close to limiting itself to designing sequences over a one letter alphabet for unpaired positions and a two letter alphabet for paired positions. if sequences are designed to plant in simulated data, e.g. to test an rna gene finder, it will also be preferable to obtain sequences with more natural distributions.

comparison of the nucleotide distributions of the successfully designed sequences from different methods on the rfam dataset, with distribution observed across the original sequences from rfam shown in the first row.

the other four methods have less bias in the base pair uses, although only frnakenstein, rnainverse, and inv utilise wobble gu base pairs to any real degree. indeed, the base pair distribution observed in the frnakenstein distribution is very close to the distribution observed in the original data. there is, in the unpaired nucleotides, a mild overrepresentation of cs and a mild under representation of gs, though. this is perhaps due to the increased thermodynamic stability in cg base pairs– it is perhaps easy to have cs unpaired, or gs unpaired, but too many will form a pair eventually. rnainverse, on the other hand, had an unpaired distribution very close to the real data set, but the base pair distribution is off a little. while it may in many cases be less important whether the distributions observed in the designed sequences are heavily biased, one consequence of this bias will be a reduced diversity in the set of solutions that are generated. in this sense, given frnakenstein’s performance against rna inverse and inv, when application dictates a sensible nucleotide distribution, frnakenstein is the clear winner.

frnakenstein was designed with little focus on running time, choosing python as implementation language for the ease of development and flexibility it offers. additionally, the more advanced choices in mutation and recombination selection provide additional computational burden. not only do you now have to calculate the full partition function for the thermodynamic model necessary to obtain boltzman probabilities, but the selection of individuals for recombination and the recombination points themselves becomes considerably more computationally expensive. it is thus not overly surprising that among the methods tested frnakenstein is one of the slowest. only nupack: design vies with frnakenstein for bottom slot regarding speed. even accounting for the fact that average running times should be divided by success ratio to get an approximate value of total time until first successful design, frnakenstein and nupack: design tend to be three to four orders of magnitude slower than the other four tested methods on some targets. for easy targets, frnakenstein mitigates this concern by the application of rnainverse for sequence initialisation. for applications where minimising time to find a successful design is the key priority, as opposed to nucleotide distribution, modena is a strong contender with run time at most a few minutes and a high rate of success on most of the rfam targets.

additionally, we analysed the performance of different positional fitness schemes. a subset of structures were taken from the rfam data set and frankenstein run many times with different positional fitness options, and for each run, the minimum objective recorded for each generation. for each positional fitness option, averages were then taken over runs, and results are found in figure
 <dig>  the main thing which is clear from this is the much slower reduction in minimum objective seen when the mutations are decided uniformly at random. this is the method employed by modena. otherwise, it is difficult to distinguish the different positional fitness schemes. the default has been chosen for good success ratio , but other choices may be faster/better for specific situations.

rnastrand data
results for both the rnastrand and rnastrand-refolded can be found in table
 <dig>  a ‘success’ indicates that the program has found a sequence which folds in silico into the target structure, with rnafold being used by all excepting nupack: design, which uses its own thermodynamic folding model similar to rnafold. the data sets contain  <dig> and  <dig> structures, respectively. the numbers reported are the number of target structures for which a sequence was successfully designed. again, several of the nupack: design benchmarks for the rnastrand data set could not be fully completed, as each of the  <dig> independent searches were still incomplete after several days of run time, having neither found a successful design nor terminated the search.

successes of the benchmarked approaches on the rnastrand and rnastrand-refolded.

these results confirm the general picture seen for the rfam data set: frnakenstein, modena, and info-rna have similar success rates with rnainverse lagging slightly behind, although only on the re-folded structures and not quite to the same degree as for the rfam data set. inv once again performs poorly, although there are more structures it permits in this data set, once again succeeding on all of them. the dependency of performance on target length, cf. table
 <dig>  is somewhat inconclusive, with all methods except inv performing best, by far, on the bin with length between  <dig> and  <dig> nucleotides. given the limited size of the bins, strong conclusions should probably not be drawn from this. however, whereas all methods do seem to struggle more with longer targets, there does seem to be a tendency for rnainverse, and to a lesser extent modena, to show a more rapid decline in performance on long targets. on shorter targets, these two methods perform as well as the other methods. for the re-folded targets, frnakenstein, info-rna, and nupack: design do achieve a 100% success rate, with successful designs for all targets across the full range of target lengths, so performance is more affected by the nature of the target than target length. the biases in base pair and nucleotide distributions for the successful designs were similar to the ones observed for the rfam data set , as should be expected.

the  <dig> unique structures of the rnastrand data set were binned according to length in  <dig> bins of roughly equal size, and for each bin, the range of lengths covered by the bin, the average length of structures in the bin, the number of structures in the bin are listed, as well as the success ratio on each bin computed for each method.

CONCLUSIONS
in this paper we have described how to use a genetic algorithm approach to find useful solutions for the inverse rna folding problem. the method allows a combination of the predicted minimum free energy structure and the computed boltzmann distribution over the ensemble of structures to be used to guide the main aspects of the genetic algorithm, in particular mutation, recombination, and selection. it performed as well, or better, than the other methods tested on all benchmarks, without introducing strong biases in the composition of the designed sequences.

one of the major advantages of our method is that it allows multiple structures, either at identical or different conditions, to be specified as targets. to our knowledge, only one previously published method has this capability, and the software implementing this method is only available on request. while the benchmarks were done on two targets, there are no upper restrictions to how many targets can be aimed for.

our method uses the rna secondary structure prediction software as a black box. while a more efficient solution could be obtained by a more complex interaction with the folding software, allowing reuse of already computed values when mutating and recombining sequences, the chosen approach makes frnakenstein much more flexible. the folding method can be replaced with relative ease, e.g. to use a grammar based method or a method capable of predicting structures with pseudoknots, simply by providing an alternative implementation of the module invoking and parsing the output from the folding software. combining predictions from several folding methods, possibly using a multi-objective framework similar to modena, allows designs more robust to the uncertainties of structure prediction, and is an interesting direction for future research.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
rl and jwja developed the initial idea for the method, which was tested and implemented by rl, ab, th, and es. benchmarks were designed and carried out by jwja, rl, es, ab, and th. manuscript was drafted by rl, jwja, and es. all authors read and approved the final manuscript.

