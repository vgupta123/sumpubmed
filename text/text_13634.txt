BACKGROUND
recent advances in massively parallel sequencing have dramatically increased throughput compared to the classic sanger technology, with several commercially available platforms including  <dig>  illumina, abi solid, and helicos delivering billions of bases per day. this has enabled sequencing of several individual genomes  <cit> , ushering the era of personal genomics. thousands of other individual genomes are currently being sequenced as part of large scale projects such as the international  <dig> genomes project  <cit> , and whole genome sequencing is likely to become routine as sequencing costs continue to decrease. however, analysis of whole genome sequencing data remains challenging  <cit>  and experimental design optimization has only recently started to receive attention  <cit> .

in this paper we focus on one of the most fundamental genomic analyses, namely determining the genotypes at known loci of genome variation such as single nucleotide polymorphisms . diploid organisms including humans inherit two  variants or alleles at autosomal loci, and most medical applications of personal genomics require accurate identification of both variants, the combination of which is referred to as genotype. of particular interest are loci that are heterozygous, i.e., loci for which the two chromosomes carry different alleles. however, identifying heterozygous loci from low-coverage whole-genome sequencing data poses a significant challenge. sequencing data is obtained using the so called “shotgun” approach, whereby millions of short dna fragments called reads are generated from randomly selected locations on the two chromosomes. if, for example, there are only two reads generated from a heterozygous locus, there is a 50% chance that one allele would be missed. to compensate for sequencing errors, existing methods for detecting heterozygous loci have even higher minimum allele coverage requirements, e.g., in  <cit> , calling an allele requires the presence of at least two reads supporting it. consequently, due to the relatively low sequencing depth used in these two studies , the reported sensitivity of detecting heterozygous snps was of only 75%.

a simple way to improve genotype calling accuracy is to increase sequencing depth, as the probability of “missing” an allele decreases with the number of reads. after taking into account the effect of sequencing errors it has been estimated that, in the absence of additional information, achieving 99% sensitivity at detecting heterozygous snps would require an average sequencing depth of over 21×  <cit> . our main contribution is to demonstrate that high accuracy snp genotypes can be inferred from shotgun sequencing data of much lower depth by exploiting the correlation between alleles at nearby snp sites, commonly referred to as linkage disequilibrium .

ld patterns over millions of common snps have been mapped for several populations as part of the hapmap project  <cit> . the strong ld observed in human populations has already been exploited by methods for imputation of genotypes at untyped snp loci based on nearby snp genotypes  <cit> , see  <cit>  for a recent review, and more recently, for improving genotype calling accuracy from microarray hybridization signals  <cit> . another striking demonstration of the power of ld has been the inference of watson’s apoe status  <cit>  despite the removal of sequencing reads covering this region from the published dataset  <cit> . in this work we introduce a novel hierarchical factorial hidden markov model  that allows integrated analysis of ld information extracted from reference population panels such as hapmap and short-read sequencing data generated by current technologies. although the ensuing multilocus genotype inference is computationally hard, we develop a scalable heuristic similar to the posterior decoding algorithm for hmms. a software package implementing this algorithm has been released under the gnu general public license and is available at http://dna.engr.uconn.edu/software/geneseq/. we also present experimental results on publicly available  <dig>  illumina, and abi solid whole-genome sequencing datasets showing that integration of ld information leads to significant improvements in genotype calling accuracy compared to prior ld-oblivious methods. for example, at 6× average mapped read coverage, our algorithm calls heterozygous snp genotypes with about 96% accuracy, and accuracy can be further increased to 98-99% by leaving uncalled a small percentage of snp genotypes with low posterior probabilities. this accuracy is comparable to that achieved by microarray-based genotyping platforms. coupled with continued decreases in sequencing costs, the reduced sequencing depth required when using ld information renders low-coverage sequencing as a potentially more cost-effective alternative to microarrays for the next generation of genome wide association studies . for example, the abi solid 4hq is expected to deliver 300gb of sequencing data per run, or the equivalent of  <dig> individual genomes at 6× coverage, with a cost of only $ <dig> per genome  <cit> . undoubtedly, cost will be an important factor in future gwas studies, which are expected to use much higher sample sizes compared to past studies in order to enable the study of gene-gene and gene-environment interactions  <cit> .

methods
in this section we begin by describing a simplified statistical model that assumes independence between loci, then extend it to include dependences between alleles at different snps due to ld. we next formalize the multilocus genotype calling problem in the context of the extended model and show that computing the most likely multilocus genotype is computationally hard. finally, we present a posterior decoding heuristic which independently selects the most likely genotype at each locus conditional on the entire set of reads.

notations
we use uppercase italic letters  to denote random variables and lowercase italic letters  to denote generic values taken by them. vectors of random variables and generic values are denoted by boldface uppercase , respectively boldface lowercase letters . when there is no ambiguity on the underlying probabilistic event we use p to denote p, with similar shorthands used for joint and conditional probabilities of multiple events. for simplicity we consider only bialelic snps on autosomes. for every snp locus, we denote the two possible alleles by  <dig> and  <dig>  and the three genotypes by  <dig> , and  <dig>  with  <dig> and  <dig> denoting the homozygous  <dig> and homozygous  <dig> genotypes, and  <dig> denoting the heterozygous genotype.

single snp genotype calling
in this section we describe a genotype inference model that assumes the snps to be unlinked as in  <cit> , but further incorporates allele uncertainty quantified by sequencing quality scores, read mapping uncertainty, and population genotype frequencies estimated from a reference panel.

let r be a read mapped onto the genome. if r covers snp locus i, we denote by r the allele observed in the read at this locus. since our focus is on genotyping snps represented in a reference panel, we further assume that panel snps at which the individual under study has novel allele variants  have been identified in a preliminary analysis, e.g., by using binomial probability test of  <cit> . based on this assumption, all reads with alleles not represented in the panel population are ignored, and for remaining reads r we have that r ∈ { <dig> }. the probability that allele r is affected by a sequencing error is denoted by εr. in our experiments we set εr = 10-qr/ <dig>  where where qr denotes the phred quality score of r  <cit> .

let gi be a random variable denoting the unknown snp genotype at locus i, and let ri = {ri, <dig>  … ,ri,ci} be the arbitrarily ordered set of shotgun reads covering locus i, where ci is the coverage at this locus. since for a homozygous genotype the allele of origin for a read is the same regardless of which chromosome is sampled, we get:   

and   

for a read r covering a heterozygous snp locus i allele r can be observed either as the result of sampling r from the chromosome bearing allele r and correctly sequencing it, or as the result of sampling the other chromosome followed by a sequencing error. hence:   

a natural approach to single-locus snp genotyping is to call a genotype of ĝi = argmax gi∈{ <dig> ,2}p for every snp locus i, where the posterior probabilities p are obtained from - by applying bayes’ formula:   

and p denotes the population frequency of genotype g, estimated from the reference panel. if read mapping uncertainty is available in the form of probabilities m that read r is mapped at the correct position, such information can be accounted for in genotype calling by replacing the above conditional probabilities with genotype weights obtained from - by rising the terms corresponding to read r to power m. although the resulting weights can no longer be interpreted as conditional genotype probabilities, they naturally allow interpreting the presence of a read r with mapping confidence m <  <dig> as the equivalent of observing an m fraction of an identical read mapped with confidence  <dig> 

a statistical model for multilocus genotype inference
in this section we introduce a statistical model that allows us to integrate shotgun sequencing data and ld information in the inference of snp genotypes. our model, represented graphically in fig.  <dig>  can be thought of as a hierarchical factorial hmm . indeed, we use a distributed state  to exploit the independence between maternal and paternal chromosomes , while also employing a multilevel state representation as in hierarchical hmms  <cit>  to capture the structured nature of the data. this structure leads to a reduced number of model parameters and enables highly scalable inference algorithms.

at the core of the model are two left-to-right hmms m and m′ , each emitting haplotypes with frequencies corresponding to those in the populations of origin for the sequenced individual's parents. under m and m′, each haplotype is viewed as a mosaic formed as a result of historical recombination among a set of k founder haplotypes, where k is a population specific model parameter. formally, for every snp locus i ∈ { <dig>  … , n}, we let  be a random variable representing the allele observed at this locus on the maternal  chromosome of the individual under study, and  be a random variable denoting the founder haplotype from which hi  originates. as in previous works  <cit> , we assume that fi form the states of a first order hmm with emissions hi, and estimate probabilities p, p, and p) using the classical baum-welch algorithm  <cit>  based on haplotypes inferred from a panel representing the population of origin of the individual’s mother. probabilities , and  are estimated in the same way based on haplotypes inferred from a panel representing the population of origin of the individual’s father.

we define  to be  <dig> if  and  <dig> otherwise. finally, assuming that each read covers no more than a snp locus, we set   

this implies that p are given by equations -, and in the following we will assume that probabilities p are precomputed in o time, where  is bounded above by the total number of reads. we can now formulate the following:

multilocus genotyping problem 
given:trained hmm models m, m′ and set of shotgun readsr = 

find:multilocus genotypeg* ∈ { <dig> ,2}n with maximum posterior probability, i.e.,

g* = argmaxgp        

computational complexity
in this section we show that mgp is np-hard. let maximum multilocus genotype probability problem  denote the optimization version of mgp that requires finding maxgp.

theorem  <dig>  for any ∊ >  <dig>  mmgpp cannot be approximated withinunless p=np, and it cannot be approximated withinunless zpp=np. furthermore, this holds even if m′ = m.

proof. lyngsø et al.  <cit>  give an approximation preserving reduction from the clique problem to the problem of computing the maximum probability of a string emitted by an hmm. it is not difficult to modify their construction to show that this reduction holds for left-to-right hmms that emit 0/ <dig> strings of fixed length. next, we show that computing the maximum probability of a string emitted by such an hmm m <dig> can be reduced in approximation preserving manner to mmgpp with m′ = m. the haplotype models m and m′ are obtained from m <dig> as follows :

• the number of snps n is set to one plus the length of the strings emitted by m <dig> 

• at the first snp, for two founder states  and  we have ; all other founder states have zero initial probability.

• for every snp locus i >  <dig> we add a new founder  as well as a set of founders corresponding to the states at “column” i —  <dig> of m <dig> 

• all founder , emit  <dig> with probability  <dig>  furthermore,  for every i =  <dig>  … , n.

• founder  emits  <dig> with probability  <dig>  and has transitions to founders , according to the initial probabilities of m <dig> 

• all other emission and transition probabilities are identical to those for the corresponding states of m <dig> 

finally, we set r = {r <dig>  r1} where r <dig> is a read that supports allele  <dig> at first snp and r <dig> is a read that supports the allele  <dig> at first snp. error probabilities for both alleles are set to zero.

note that p ≠  <dig> only for multilocus genotypes with g <dig> =  <dig> and gi ∈ { <dig> } for i =  <dig>  … , n.

furthermore, for such a genotype g,   

the last equality comes from the fact that g can only be observed when the maternal haplotype is 0n and the paternal haplotype is g or vice-versa, and each of these configurations have a probability of p/ <dig>  the innaproximability result follows from  <cit>  since, by , p is constant fraction of p.

since an algorithm similar to the forward algorithm for hmms can be used to compute in polynomial time the marginal probability of a given genotype, theorem  <dig> implies the following:

corollary  <dig> mgp is np-hard.

posterior decoding algorithm
we next present an mgp heuristic similar to the posterior decoding algorithm for hmms. specifically, the algorithm selects for each snp locus i the genotype ĝi with maximum posterior probability given the read data r. note that, unlike the single snp genotype calling method, where we condition only on the set ri of reads overlapping locus i, in the posterior decoding algorithm we take into account the entire set of reads:

posterior decoding algorithm

step  <dig>  for each i =  <dig>  … , n, ĝi ← argmaxgip

step  <dig>  returnĝ = 

below we detail an o implementation of the posterior decoding algorithm. since p ∝ p, for implementing the maximization in step  <dig> it suffices to compute marginal probabilities p for every i =  <dig>  … , n and gi ∈ { <dig> ,2}. for each snp locus i and each pair of founders  we let the forward probability be  and the backward probability be  respectively. using these forward and the backward probabilities, the marginal probability p can be written as  

where  is given by:  

thus all probabilities p can be computed in o once the forward and backward probabilities  and  are available.

the forward probabilities can be computed using the recurrence:      

for every  and i =  <dig>  … , n, where   

the inner sum in equation  is independent of fi, and so its repeated computation can be avoided by replacing  with:      

a similar optimization can be applied when computing the backward probabilities, resulting in the following recurrence:         

forward and backward probabilities can thus be computed in o by using recurrences , , and , respectively , , and , resulting in an overall runtime of o, where m is the number of reads, n is the number of snps, and k is a user selected parameter denoting the number of founders in the hmm models of haplotype diversity in the parental populations .

RESULTS
datasets
we evaluated the hmm-based posterior decoding algorithm on shotgun sequencing datasets generated using three different sequencing technologies, as follows:

 <dig>  watson 454: a set of  <dig>  million reads downloaded from the ncbi sra database . the reads, with an average length of ~ <dig> bp, were generated using the roche  <dig> flx platform as part of james watson’s personal genome project. this is a subset of the  <dig>  million  <dig> reads analyzed in  <cit> . unless noted otherwise, the haplotype panel used to train identical hmm models for the maternal and paternal populations was obtained by phasing ceu trio genotypes from hapmap r23a  <cit>  using the ent algorithm of  <cit>  and retaining parent haplotypes from each trio. as in  <cit> , genotype calling accuracy was assessed using the snp genotypes determined using duplicate hybridization experiments with affymetrix 500k microarrays .

 <dig>  na <dig> illumina: a set of  <dig> million paired-end reads downloaded from the ncbi sra database . these 36bp reads, which were generated using the illumina genome analyzer from a hapmap yoruban individual identified as na <dig>  are a subset of the dataset analyzed in  <cit> . for the analysis of this dataset the hmm models for maternal and paternal populations were trained using yri haplotypes from hapmap r <dig>  excluding the haplotypes of the yri trio that contains na <dig>  as gold standard we used the genotypes published as part of hapmap r <dig> for individual na <dig> 

 <dig>  na <dig> solid: a set of  <dig> million single abi solid reads generated from hapmap individual na <dig> was kindly provided by the authors of  <cit> . reads varied in length between  <dig> and  <dig> bp, and were already mapped to the reference genome. corresponding raw reads are available for download from the ncbi sra database . hmm models and gold standard genotypes were determined in the same way as for the na <dig> illumina dataset.

read mapping
we mapped  <dig> reads on build  <dig>  of the reference human genome using the nucmer tool of the mummer package  <cit>  with default parameters. we discarded alignments matching less than 90% of the reference or with  <dig> or more errors . we then discarded surviving reads with multiple matching positions. we mapped the illumina reads using maq version  <dig>   <cit>  with default parameters. we discarded alignments with mapping probability less than  <dig>  or with sum of quality scores of mismatching bases higher than  <dig> . solid reads were mapped using the solid system analysis pipeline tool  as described in  <cit> . table  <dig> shows for each dataset the numbers of test snps, initial and mapped reads, and the average coverage per snp after mapping.

genotyping accuracy
to evaluate the effects of read coverage on genotype calling for each dataset of m mapped reads we created four subsets of sizes m/ <dig>  m/ <dig>  m/ <dig> and m/ <dig> by picking reads at random. for each subset we called genotypes using the hmm-based posterior decoding algorithm, the binomial test of  <cit>  , and the single snp posterior probability described under methods. we also included in the comparison genotype calls obtained by soapsnp  <cit>  and maq  <cit> , two widely used ld-oblivious bayesian methods implemented in the samtools package  <cit> . unfortunately we could not compare our method with similar tools developed as part of the  <dig> genomes project  <cit> , which have only become publicly available when this article was in press. we measured the accuracy of each genotype calling method by computing the percentage of snp genotype calls that match the gold standard available for each dataset. as in previous papers  <cit> , we separately report accuracy for homozygous and heterozygous snps.

fig.  <dig> shows genotype calling accuracy of the compared methods for varying average mapped read coverage on the na <dig> illumina dataset; similar results were obtained on the other two datasets. for both homozygous and heterozygous snps, the posterior decoding algorithm has the highest accuracy of the compared methods at every considered coverage. the improvement in accuracy is most pronounced for heterozygous snps and at low average coverage. this is not surprising since, as previously noted in  <cit> , at low average coverage there is an increasingly high probability of leaving uncovered at least one of the alleles of a heterozygous snp, and a minimum coverage of each called allele is required by the binomial test, soapsnp, and maq. for example, the binomial test used in  <cit>  requires that each allele be covered at least twice; in all our results we used the more relaxed requirement of covering each allele at least once. in contrast, the single-snp posterior and the hmm-based posterior decoding algorithm do not have a minimum coverage requirement. by leveraging population allele frequencies estimated from the reference panel, the single-snp posterior method already outperforms the binomial test, soapsnp, and maq at low average coverage. the hmm posterior decoding algorithm further improves accuracy by capturing ld information between neighboring snps.

fig.  <dig> shows the accuracy achieved by the hmm posterior decoding algorithm when varying the average mapped read coverage for all three datasets. genotyping accuracy achieved on the na <dig> illumina reads matches that observed on watson  <dig> reads for homozygous snps, and is only slightly lower for heterozygous snps. the accuracy achieved on the na <dig> solid reads is consistently lower than that achieved for the other two datasets over the tested range of average coverages. we found that this difference is due to a bias towards the reference allele during color-to-base translation for reads mapped with corona lite. this bias is likely to induce incorrect heterozygous calls for some homozygous non-reference snps and homozygous reference calls for some heterozygous snps. the presence of this bias can be observed in fig.  <dig>  which shows the distribution of reference allele coverage ratios  for heterozygous snps in the watson  <dig>  na <dig> illumina, and na <dig> solid datasets. in the absence of allele call biases, the average of reference allele coverage ratios over heterozygous snps should be close to 50%. we found that this was indeed the case for both the watson  <dig> and na <dig> illumina datasets  but not for the na <dig> solid dataset . fig.  <dig> shows the concordance of genotypes called by hmm posterior decoding on the na <dig> illumina dataset for groups of snps with varying rates of local recombination, respectively minor allele frequency, both estimated from the yri panel of hapmap. the percentage of snps in each group is also plotted using dashed lines. for both homozygous and heterozygous snps concordance is relatively stable over the entire range of local recombination rates ), dropping below 96% only for heterozygous snps in regions with local recombination rate of over  <dig> cm/mb. the effect of minor allele frequency is more pronounced ), with heterozygous snps concordance dropping to 83% for snps with minor allele frequency below  <dig> . however, the overall accuracy is not affected too much since only 2% of heterozygous snps of na <dig> have an estimated allele frequency in this range.

to assess the effect of the size of the reference panel on genotyping accuracy, we conducted additional experiments on the watson  <dig> reads using n =  <dig> ceu haplotypes available in hapmap <dig>  similar to experiments with varying read coverage, we generated subsets of approximately n/ <dig>  n/ <dig>  n/ <dig>  and n/ <dig> randomly selected reference haplotypes, and compared the accuracy achieved by running the hmm posterior algorithm using these subsets to that obtained using all n reference haplotypes. fig.  <dig> gives the genotype call concordance obtained for different panel sizes. the results suggest that no significant improvement is achieved by increasing the reference panel size beyond 60- <dig>  thus – in contrast to methods for imputing untyped snps, which continue to benefit from increasing the panel size to several hundreds of haplotypes  <cit>  – highly accurate genotype calling from sequencing data is possible with relatively small reference panels.

since our algorithm computes a posterior probability for each snp genotype, further increases in calling accuracy can be obtained at the expense of leaving uncalled a small percentage of snp genotypes with low posterior probability. such “no-calls” are commonly used in microarray-based genotyping for snps for which hybridization signals are ambiguous. fig.  <dig> shows the tradeoffs achievable between the concordance and call rate when running the hmm posterior decoding algorithm on the full set of watson  <dig> reads. over all snps, concordance with the duplicate affymetrix genotypes reaches  <dig> % at a no-call rate of only 6%.

CONCLUSIONS
in this paper we introduced a statistical model for multi-locus genotyping that integrates shotgun sequencing data with ld information extracted from a reference panel. although finding the multi-locus genotype with maximum posterior probability under the integrated model is np-hard, experimental results suggest that a simple posterior decoding algorithm produces highly accurate genotype calls even from low-coverage sequencing data. compared to current ld-oblivious genotype calling methods, our method allows researchers to achieve a desired accuracy target with reduced sequencing costs. for example, genotype calling accuracy achieved at 5-6× average coverage by a previously proposed binomial test is matched by the hmm-based posterior decoding algorithm using less than 1/ <dig> of the reads. while a full comparison of sequencing and microarray based genotyping in the context of gwas is beyond the scope of this paper, experimental results on three publicly available datasets generated using the  <dig>  illumina, and abi solid sequencing platforms suggest that at a mapped coverage depth of 5-6× our algorithm achieves an accuracy that is comparable to that of microarray platforms. concordance rates reported for microarrays often exceed  <dig> % , and are even higher for methods that integrate hybridization signals with ld information  <cit> . however, due to cost constraints, microarrays typically assay only a fraction of the snps represented in reference panels. for example, the next generation of illumina microarrays is expected to assay only  <dig> million of the estimated  <dig> million snps generated by the  <dig> genomes project  <cit> . genotypes for the untyped snps would have to be inferred based solely on ld information, and even the best imputation methods have error rates of 5-6%  <cit> , or 2-3% when leaving 10% of snps uncalled. since the majority of snps must be imputed, this results in an overall accuracy below that achieved by the hmm posterior algorithm on the watson  <dig> dataset.

in ongoing work we are exploring efficient algorithms for ld-based haplotype reconstruction from paired shotgun sequencing reads. we also plan to empirically compare our method with similar tools developed as part of the  <dig> genomes project  <cit> .

authors contributions
iim and yw conceived the study. jd, jk, sd, and yh implemented the methods and conducted the experiments. jd and iim drafted the manuscript. all authors participated in the development of the methods, data analysis, and manuscript revision. all authors have read and approved the final manuscript.

competing interests
the authors declare that they have no competing interests.

acknowledgments
jd, jk, and iim were supported in part by nsf awards iis- <dig>  iis- <dig>  and dbi- <dig>  yw was supported in part by nsf award iis- <dig>  sd and yh were supported in part by nsf award ccf- <dig> 

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2011: selected articles from the ninth asia pacific bioinformatics conference . the full contents of the supplement are available online at http://www.biomedcentral.com/1471-2105/12?issue=s <dig> 
