BACKGROUND
protein-protein interaction  plays a central role in many biological processes. information on ppis can hint at potential functions for uncharacterized proteins  <cit> . on a broader scale, ppi networks allow for a systems-level understanding of molecular processes underpinning life  <cit> . powered by high-throughput techniques, yeast two-hybrid screens have been applied on a genomic scale to several organisms for a systematic identification of ppis  <cit> . related techniques have also been developed, allowing researchers to address different aspects of ppis than yeast two-hybrid screens  <cit> . on the other hand, ppis in protein complexes have been investigated by affinity purification followed by mass spectrometry analysis  <cit> .

concurrently, there have been intensive efforts to develop computational methods for predicting ppis. early approaches tried to mine patterns from genomic data that are a priori expected for ppis such as gene neighborhoods and gene order  <cit> , the existence of fusion genes  <cit> , the co-evolution of interaction partners  <cit> , phylogenetic profiles  <cit>  and similarity of phylogenetic trees  <cit> . some of these ideas have recently been explored again in a refined manner  <cit> . since domain-domain interactions underlie many ppis, they have also been intensively studied  <cit> . more generalized concepts than protein domains, such as linear sequence motifs or sets of discontinuous sequence motifs defined on the basis of protein structures, have also been explored  <cit> . approaches combining different types of data in a self-consistent manner have been put forward  <cit> . in addition, microarray gene expression data have been explored as a potential source for predicting ppis  <cit> .

recently, a unique category of sequence-based prediction methods has been put forward - unique in the sense that it does not require homologous protein sequences  <cit> . this enables it to be universally applicable to all protein sequences unlike many of previous sequence-based prediction methods. for example, domain-based methods do not work for query protein pairs without domain information, and the rosetta-stone methods  <cit>  and the co-evolution-based methods  <cit>  can not be applied to proteins without homologous protein sequences. the new sequence-based, universally applicable prediction methods would have far-reaching utilities in many fields of biology research, if effective as claimed. upon close survey, however, i realized that many of them were not properly benchmarked, e.g., tested on ill-sized data sets often fraught with homologous proteins. moreover, newer methods were often published without performance comparison with previously proposed ones. thus, it is not clear how good they are and whether there are significant performance differences among them. these are important issues to investigate for both a true advancement of this research field and maximizing the benefits of computational predictions for the general research community. in this work, i have implemented and thoroughly tested four different methods using large-scale, non-redundant data sets to address these issues.

RESULTS
four methods for comparative benchmarking
in this study, i tested  <dig> different methods. the selection criteria were 1) the original purpose of the method was to predict physical binary ppis, 2) the method is sequence-based, yet does not require homologous protein sequences and 3) either trainable versions of the software are available or the description in the original report is specific enough for me to confidently implement it on my own. the four methods are as follows.

• m1: the signature product-based method proposed by martin and co-workers  <cit> . in this method, the sequence information for a protein pair is encoded by a product of signatures, which is then classified by a support vector classifier   <cit> . for individual proteins, signatures are defined to be a culled set of subsequences. i used their "sym" kernel since preliminary analysis showed that it worked slightly better than their gaussian kernel, i.e., exp,) - 2×sym,) + sym,)]), where sym,) is the "sym" kernel for a pair of protein pairs a-b and c-d, and sym,) and sym,) are analogously defined. for the details, please refer to the original paper  <cit> .

• m2: the method developed by pitre and coworkers, also known as pipe  <cit> . for a pair of proteins, pipe looks for the co-occurrences of their subsequences in protein pairs that are known to interact.

• m3: the method introduced by shen and coworkers  <cit> . in this method, a protein sequence is represented by a reduced set of amino acids. then, each protein sequence is encoded by a feature vector that represents the frequencies of  <dig> amino acid-long subsequences. the feature vectors are then concatenated for a pair of proteins and classified by an svc.

• m4: the method developed by guo and coworkers  <cit> . a feature vector for a protein sequence comprises its auto-correlation values of  <dig> different physicochemical scales. the feature vectors are then concatenated for a protein pair and classified by an svc.

cross-validation on the yeast and the human data
i first estimated their performance on the yeast and the human data in 4-fold cross-validation . the following points are apparent in table  <dig>  first, m <dig> significantly excels the others in terms of the area under the receiver-operating characteristic  curve  across both the yeast and the human data: see the additional file  <dig> for detailed p values. second, m <dig> significantly outperforms the others in terms of recall-precision across both the yeast and the human data. third, m <dig> is least effective regardless of which performance measure to use for comparison. the dominance order among the four methods is the same for both the yeast and the human data, in spite of the fact that each data set is uniquely biased . moreover, these three points are repeatedly observed in other analyses presented below. thus, the analysis in fig.  <dig> and table  <dig> appears to unravel genuine performance differences.

1evaluation using a negative subset of size 10n randomly chosen from the 100n negative set, where n is the size of the positive set.

2precision values at 20% recall

another point worth discussing is the use of two complementary performance measures in the above analysis. aucs are a widely used figure for assessing the performance of computational prediction methods. since aucs are solely based on ranks of positives relative to those of negatives, aucs are to a large extent insensitive to absolute numbers of false positives. this may be a significant drawback. for example, for experimental biologists who want to use prediction results for prioritizing candidates for in-depth experimental follow-ups, the absolute number of false positives may equally matter. thus, estimation of prediction performance by aucs alone can be misleading if absolute numbers of false positives become as relevant. in this regard, recall-precision analysis is complementary to aucs because it is sensitive to absolute numbers of false positives. for a clear demonstration of this point, prediction performance for each method was re-estimated using the original positive set  and a negative subset of size 10n randomly chosen from the original 100n negative set. by reducing the negative set size from 100n to 10n, we effectively reduced the number of potential false positives by  <dig> fold. as shown in table  <dig>  aucs change little between the 10n and the 100n sets for all four methods. yet, the p20r values  dramatically improve for all four methods for the 10n set compared to the 100n set. similar improvements are also obvious in recall-precision plots . improvements coming from the use of the 10n set instead of the 100n set are, of course, not real: they are just artefacts coming from the use of ill-sized negative data. the number of potential protein-protein pairings is expected to be >  <dig> times the number of ppis in the cell. in this sense, negative sets of size 10n are grossly ill-sized, let alone 1n sets that were used for benchmarking for some of the four methods in the original reports. even the 100n set may not still be large enough. however, prohibitively high computational expenses made it very difficult to use significantly larger ones. taken together, table  <dig> illustrates the importance of complementary performance measures along with data sets right-sized in a physiological sense for meaningful performance estimation of prediction methods. given the importance of right-sized negative data sets for meaningful benchmark tests, all the results reported hereafter are based on negative data sets of size 100n, unless otherwise stated.

as noted above, m <dig> dominates in terms of auc while m <dig> excels in terms of recall-precision. this dominance reversal between auc and recall-precision may be inferred by the cross between the roc plot of m <dig> and that of m <dig> in fig.  <dig>  m <dig> is based on counting how frequently pairs of subsequences in the query protein pair occur in protein pairs known to interact. when the count is low, its prediction outcome is no interaction. since the count is based on similarity of  <dig> amino acid-long segments, it is more often low than high. this conservative prediction behavior is thought to underlie its good performance in terms of recall-precision. this core idea of m <dig> has been successfully exploited in one form or another by other related prediction methods  <cit> .

the performance of m <dig> reported here appears not to be as good as that reported in fig.  <dig> of the original paper  <cit> . a very likely reason for this is that the two studies adopt different definitions for true positives: the current study defines a true positive as a pair of proteins known to interact and predicted to interact, whereas the source code for m <dig> that i downloaded from the original authors' website defines a true positive as a pair of proteins assumed not to interact and predicted not to interact.

insight into the performance difference between m <dig> and m3
the performance contrast between m <dig> and m <dig> is interesting, given that their approaches stem from overall similar ideas. methodological differences between them can be decomposed into 1) feature representation of individual proteins and 2) how to combine the features of individual proteins to represent protein pairs. we investigated the effects of the second factor on prediction performance because this is a recurring issue whenever it is necessary to encode protein pairs rather than individual proteins. m <dig> computes the outer product of individual feature vectors  while m <dig> concatenates them. specifically, we wanted to investigate which of the two approaches - computing the outer product of individual feature vectors as in m <dig> and concatenating them as in m <dig> - leads to better prediction performance. to this end, we modified m <dig> such that the outer product of individual feature vectors is replaced by their concatenation, and the modified m <dig> was tested on the yeast and the human data as in table  <dig>  table  <dig> summarizes the results. a comparison of m1's performance in tables  <dig> and  <dig> indicates that the two approaches lead to similar prediction performance, even though the performance of m <dig> in table  <dig> is significantly better than that of m <dig> in table  <dig> . this suggests that the outer product approach for encoding protein pairs is not a critical factor for the success of m <dig>  conversely, this suggests that the poor performance of m <dig> is mostly attributable to its less effective feature representation of individual proteins. at first glance, this may seem odd because the feature encoding system of m <dig> may look similar to that of m <dig>  the feature encoding system of m <dig> is, however, much more sophisticated than that of m <dig>  m1's feature vectors are culled sets of  <dig> amino acid-long subsequences that are based on  <dig> naturally occurring amino acid types whereas m3's feature vectors are full sets of  <dig> amino acid-long subsequences that are based on a reduced set of  <dig> "amino acid" types. for efficient handling of large feature vectors, m <dig> was implemented using special data structures  <cit> . apparently, these seemingly small differences led to considerable performance differences. in this regard, it is also to be noted that a previous study has shown that feature vector encoding systems like that of m <dig> do not work well for ppi predictions  <cit> . the respectable performance of m <dig> suggests that protein pairs that interact do display some physicochemical properties that not all potential protein pairs share.

cross-species benchmarking
in the above analyses, prediction methods were trained and tested on the same species data in 4-fold cross-validation. what about training prediction methods on the yeast data and testing them on the human data or vice versa? this is a relevant question to ask because many prediction servers have been trained on one species' data and yet predict also for other species' protein pairs. although it is not fully clear whether ppis taking place in yeast are of a fundamentally different nature than those taking place in human, yeast ppi data that are typically used for training prediction methods are certainly expected to contain distinct biases from human ppi data. as such, it is not clear, for example, whether prediction methods trained with the human data work as well on the yeast data as when trained with the yeast data.

in table  <dig> and fig.  <dig>  we trained prediction methods with the human data and tested them on the yeast data and vice versa. comparison of table  <dig> with table  <dig> reveals that prediction methods are much more effective on the yeast data when trained with the yeast data than when trained with the human data. this is in spite of the fact that much more data points were used during training with the human data  than during training with the yeast data . this strongly suggests that data sets typically used for training prediction methods contain peculiar biases that limit the general applicability of prediction methods trained with them. likewise, prediction methods are more effective on the human data when trained with the human data than when trained with the yeast data. however, in this case, the asymmetric numbers of data points used for the two trainings might also have affected the results. in sum, this analysis indicates that prediction methods trained only with particular ppi data sets are likely to have greater generalization errors than those suggested by cross-validation with such particular sets - a point overlooked by many of the four methods in their original benchmarks.

1"a - b" signifies training with the a data and testing on the b data.

in this table, prediction methods were trained with all the data from one species and tested on all the data from another species .

combined set benchmarking
the above analysis suggests that one straightforward way of developing generally applicable prediction methods is to use diverse training data so that they learn only features common to diverse data. to test this idea, i trained the four methods on the data that combines the yeast and the human data . then, their prediction performance was evaluated for three different sets  in 4-fold cross-validation. fig.  <dig> and table  <dig> summarize the results. first, the inclusion of the yeast data did not significantly affect the prediction performance of all four methods on the human data. this may be due to the fact that the size of the human data is ~ <dig>  times larger than that of the yeast data, dominating the combined set. second, the inclusion of the human data slightly degraded the performance of some methods  on the yeast data, although the results in table  <dig> are much better than those in table  <dig> 

consensus approach
having carried out a thorough comparative analysis for the four methods, a naturally arising question is how good their performance is. another formulation of this question would be "would it be easy to develop another method that consistently outperforms the four methods in terms of both auc and recall-precision?" since the primary interest in this work is not to develop a novel method that surpasses existing ones, i touched on this issue simply by designing a consensus approach and asking how it compares with the four methods. as described in the methods section, i tried an svc with a linear kernel as a simple consensus approach, with all its parameters set to default values. in this case, the feature vector consisted of classification scores generated by the four methods.

tables  <dig>   <dig> and  <dig> and figs.  <dig>   <dig> and  <dig> summarize the results . the consensus approach consistently outperforms all four methods in terms of both auc and recall-precision, and this is even without any serious attempts to optimize svc parameters. these results strongly suggest that there is still ample room for further developments. the use of the linear kernel in the consensus methods makes it possible to look into how much each method contributes to them. table  <dig> lists the mean coefficients of each method for each data set. the mean coefficients were normalized by dividing by their sum. the large contributions of m <dig> and m <dig> to the consensus methods are consistent with the results presented above, as is the least contribution of m <dig>  however, since the four methods are not "orthogonal" to each other, other drastically different linear combinations of the four methods could lead to separating hyperplanes as optimal as the one with the coefficients in table  <dig>  in other words, the redundancy of the four methods makes it difficult to infer, from the magnitudes of the linear svc coefficients, how useful each method is in forming the consensus methods.

one potential way of evaluating the usefulness of the four methods while overcoming the redundancy is to form consensus methods that selectively include component methods  and compare their performance with that of full consensus methods that incorporate all four. table  <dig> shows the results for all possible combinations of  <dig> or  <dig> methods, revealing the following points. first, methods that combine m <dig> and m <dig> favourably rival full consensus methods in terms of both auc and recall-precision. this is rather surprising because m <dig> and m <dig> tended to be much worse than m <dig> in terms of recall-precision in the above analyses. for this reason, it was expected that consensus methods should incorporate m <dig> in order to be good in terms of recall-precision. apparently, the simple linear svc could learn how to combine m <dig> and m <dig> in such a way that the combined predictions are now good not only in terms of auc but also in terms of recall-precision, even without m <dig>  second, as expected, it is consistently observed that exclusion of m <dig> leads to decrease in auc values. this is also true for m <dig> to some extent. third, the presence of m <dig> does not necessarily lead to good performance in terms of recall-precision. in sum, m <dig> and m <dig> appear to be sufficient to fully account for the success of the full consensus methods.

1"a - b" signifies training with the a data and testing on the b data.

analysis of prediction results by protein types
would there be any protein types that could be better predicted by the prediction methods tested in this study? could it be that some methods significantly outperform others for special categories of proteins, even though their overall performance as shown above is not as good as that of others? to address these issues in a systematic way, i analyzed the prediction results by the gene ontology  slims  <cit> . the go slim annotations for the yeast and the human proteins were downloaded from the go project website. altogether  <dig> go terms were considered. for each combination of a data set  and an evaluation scheme , table  <dig> lists five go terms for which best performance was achieved. the complete results are available in additional file  <dig>  a first obvious point in table  <dig> is that the consensus method is the best-performing method in terms of auc. in terms of p20r, it is either the consensus method or m <dig> that is most effective. this effectiveness of m <dig> in terms of p20r is consistent with the analysis shown above. another obvious point in table  <dig> is that the go terms for which best performance was achieved in the yeast cross-validation do not overlap those for which best performance was achieved in the human cross-validation. this appears to reflect the distinct biases in the yeast and the human data sets, as shown above in the cross-species benchmark tests. finally, go terms for which good performance was achieved in terms of auc tend to overlap those for which good performance was achieved in terms of p20r. specifically, the spearman's rank correlation coefficients between the ranking according to auc and that according to p20r are  <dig>  ,  <dig>   and  <dig>   for the yeast, the human and the combined data, respectively. this indicates that a selective use of prediction methods for proteins with such go terms may yield more fruitful results. it is to be noted that the prerequisite for this is just either protein having such go annotations because the analysis in table  <dig> was based on go terms applying to either protein in protein pairs.

1c: the consensus method that integrates the four methods m <dig> through m <dig> 

for each combination of a data set  and an evaluation scheme , five go terms are listed for which best performance was achieved. for each go term, the number of protein-protein pairs in the data set is shown in the third column for which either protein in the pair is annotated with that go term. also shown are the best-performing method  and its performance .

CONCLUSIONS
in this work, i have implemented and thoroughly tested four different sequence-based ppi prediction methods that do not require homologous protein sequence. it revealed 1) significant performance differences among them and 2) ample room for further developments. in addition, it illustrated the importance of complementary performance measures along with right-sized data sets for meaningful benchmark tests. thus, the current work provides a firm ground for future endeavors in computational prediction of protein-protein interactions. regarding practical use of predicted ppis in experimental biological research, ppi prediction results may be best used in conjunction with other types of biological data.

