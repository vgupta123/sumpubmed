BACKGROUND
a major challenge in computational biology is to reveal the cis-regulatory logics of gene expression through analysis of high-throughput genomic data, for example, genomic sequences and microarray gene expression data. a common practice is to first identify putatively co-regulated genes by clustering gene expression patterns  <cit> , and then search for common motifs from the promoter sequences of these genes  <cit> . however, motif finding methods are often sensitive to noises and usually do not consider combinatorial nature of cis-regulation. furthermore, these methods by themselves do not reveal the actual transcription factors  that bind to particular sequence motifs.

recently, many researchers attempted to build quantitative or qualitative models to associate a gene's expression level with regulatory motifs on its promoter sequence. pilpel et al.  <cit>  explicitly analyzed the combinatorial effects of motif pairs on gene expression profiles and identified many significant motif combinations. bussemaker et al.  <cit>  and others  <cit>  modeled the expression levels of genes as a linear regression of putative binding motifs, and applied feature selection techniques to find the most significant motifs. hu et al.  <cit>  used decision trees to find motif combinations that best separate two sets of genes. phuong et al.  <cit>  applied multivariate regression trees to model the transcriptional regulation of gene expressions over several time points simultaneously. middendorf et al.  <cit>  used an ensemble of decision trees to model gene expression levels by combining putative binding motifs and the expression levels of putative tfs. simonis et al.  <cit>  combined a string-based motif finding method and linear discriminant analysis to identify motif combinations that can separate true regulons from false ones. segal et al.  <cit>  and beer and tavazoie  <cit>  built probabilistic graphical models, e.g., bayesian networks, to explain gene expression patterns from motifs. in these models, the predictors  are the matching scores of promoter sequences to putative binding motifs, and the predictions  can be continuous or discrete gene expression levels or categorical cluster labels.

the features used in these models generally come from one of the following sources. first, one can use computer programs to automatically find motifs from the promoters of the genes to be modeled  <cit> . second, predefined motifs can be obtained independently from sources such as databases of experimentally verified or putative motifs  <cit> . third, one can enumerate all words up to a certain length as features  <cit> . in addition, tf binding data derived from chromatin immunoprecipitation  assays  <cit>  have been used as a substitution of motif scores. for example, banerjee and zhang  <cit>  directly applied the method of pilpel et al.  <cit>  to chip-chip data to identify tf combinations; gao et al.  <cit>  replaced the variables in the linear model of bussemaker et al.  <cit>  with chip-chip data and identified significant regulators for many experimental conditions. we recently applied a decision tree method to s. cerevisiae chip-chip data and identified all known tfs and many interesting tf combinations for yeast cell cycle  <cit> .

each type of the features discussed above  has its advantages and disadvantages in modeling gene transcriptional regulations. as to our knowledge, no comparison has been made to evaluate their relative merits. modeling accuracy is largely affected by the type of features considered in model construction. if all relevant features are included correctly, many modeling algorithms may have equally high accuracies. on the other hand, if most significant features are omitted, no model can achieve satisfactory accuracy. furthermore, the inclusion of many irrelevant features may significantly decrease modeling accuracy. therefore, a comparative study can identify limitations of these feature types, and provide some guidelines and justifications.

although many classification tools are publicly available , most of them are not designed specifically for modeling transcriptional regulation, and are not convenient for biological applications. the only related software is a web server called reduce  <cit> , which combines linear regression and feature selection methods to identify significant motifs for specific biological events. it uses enumerated words up to a certain length as features, but does not allow other types of features such as position specific weight matrices  <cit>  or chip-chip data to be used. moreover, the linear model used in reduce assumes that each motif contributes linearly to gene expressions, and therefore is unable to represent complex cis-regulatory logics such as and and or relations  <cit> .

in this study, we apply a well-studied classification method, decision tree  <cit> , to model significantly up-or down-regulated genes in each of  <dig> microarray experiments of s. cerevisiae. the utilization of decision trees in modeling transcriptional regulation has been explored previously by others  <cit>  and in our own research  <cit> . here we focus on analyzing the extent to which the expression of these genes can be predicted using different features. we compare the cross-validation accuracies of the models built with different features or feature combinations. we also compare the robustness of these models by introducing noises into training data. furthermore, we analyze the enrichment of functional categories of the genes that can pass model tests comparing to those fail the tests, and show that decision tree models can be used to detect true regulons. finally, we present the design and implementation of a user-friendly web interface that combines multiple information sources for automated analysis of gene transcriptional regulations using decision trees. as an example, we also present a case study on the transcriptional regulation of genes in arabidopsis thaliana in response to abscisic acid  treatment.

RESULTS
modeling gene transcriptional regulation with decision trees
here we briefly introduce the modeling of gene transcriptional regulation with decision trees. for a detailed treatment of decision trees, the reader is referred to related literature  <cit> . suppose that there are n genes , each of which is represented by a feature vector f = f <dig>  f <dig> ..., fm and has a class label c, where fi is a real number and c is a category. a decision tree is built as follows. initially, the tree has only one node, the root, which contains all the genes. then for each node that has no child node,

 <dig>  examine every possible binary split of the genes in the node based on each feature i, such that all genes in one subset have fi <x and those in the other subset have fi ≥ x.

 <dig>  select the best split, and create two child nodes that contain the two subsets of genes respectively.

steps  <dig> and  <dig> are then recursively applied to each of the child nodes until no split is possible, or until all genes in the current node have the same label. finally, some branches of the tree may be pruned to prevent over-fitting. nodes with or without child node are called internal nodes or leaf nodes, respectively. for examples and biological interpretations of decision trees, see figure  <dig> and figure  <dig> 

each entry fi in the feature vector of a gene corresponds to the matching score of the gene's promoter to the ith binding motif, or the binding data of the ith tf to the gene's promoter, depending on the type of features used. a split is equivalent to a test for a gene in the form of, for example, "is the matching score of the gene's promoter to motif a greater than x?" or "is the binding affinity of the gene's promoter to tf b greater than y?" the exact split point x or y is determined by maximizing an objective function that reflects the purity of the child nodes. information gains and gain ratios are two frequently used objective functions  <cit> . here we used information gains .

the class label of a gene represents a property of the gene that we want to model. for example, one can cluster genes according to expression patterns, and then assign the same label to genes in the same group. labels can also be derived from other sources such as functional annotations. in this work, we assign labels to genes according to the change of their expressions under certain conditions relative to some reference state , and focus our attention on the comparison of different features. this modeling approach is based on the assumption that co-regulated genes very often share common regulatory elements on their promoters. this approach, on the other hand, will not capture post-transcriptional modifications, and will ignore genes that share no regulatory elements with other genes. note that the underlying assumption may not always be met, since not all co-expressed genes are co-regulated. moreover, genes may be mislabeled due to noises in their expression data. the purpose is, therefore, to identify rules of thumb for the regulation of the majority genes, while tolerating to some extent the failure in modeling particular genes. as we will see later, decision tree models can indeed be used to detect the true regulons from putatively co-regulated genes.

experimental setup
we collected data for  <dig> microarray experiments on yeast s. cerevisiae, of which  <dig> were for cell cycle  <cit>  and  <dig> were for responses to various stress conditions  <cit> . we built decision trees for each condition with two classes of instances: positive genes that are differentially expressed  with respect to the reference state, negative genes that are neither up- nor down-regulated. for each experiment, we selected up to  <dig> up- or down-regulated genes as positive instances and sampled negative instances from non-differentially expressed genes. . once the genes were selected, we modeled the regulation of up- and down-regulated genes separately. there may be common regulatory motifs shared by up- and down-regulated genes, which may not be revealed if they were modeled together.

since most genes are not differentially expressed, the number of negative instances is far greater than the number of positive instances. previous researches have shown that class distribution is an important factor for successful modeling  <cit> . in general, a skewed class distribution will lead to a degraded modeling accuracy. therefore, for a set of n positive instances, we randomly sampled μn instances from all possible negative instances to obtain a desired class distribution. the sampling was repeated  <dig> times, and each set of sampled negative instances was combined with the set of positive instances to build a decision tree. the accuracy of each model was estimated with a ten-fold cross-validation and measured by the kappa statistic . as shown in figure 1a, the highest accuracy was achieved when μ =  <dig>  which is consistent with the results of simonis et al.  <cit> . therefore, we used μ =  <dig> in all subsequent analysis.

we considered three types of features. the first type contained  <dig> known and putative motifs compiled by pilpel et al.  <cit>  . of the  <dig> motifs,  <dig> were obtained from literature, and the rest were discovered from the promoters of genes sharing similar mips functional categories  <cit> . the second type of features included motifs identified from the promoter sequences of positive genes by the alignace program  <cit>  . the third type of features was derived from the in vivo binding data of  <dig> transcription factors  <cit>  . for the first two types of features, each motif was represented as a position specific weight matrix. a promoter was scanned with scanace  <cit>  for all motifs in the feature set, and the highest matching score for each motif was used. for the third type of features, the binding affinity of each tf  to a promoter sequence was used.

in general, the inclusion of a large number of irrelevant features in training data decreases the accuracy of most classification algorithms. therefore, feature selection methods are usually applied to reduce the number of features. most feature selection methods can be categorized as wrappers  <cit>  or filters  <cit> . a wrapper method searches for a subset of features that maximize the cross-validation accuracy of a given classification algorithm. this strategy is guaranteed to improve the classification accuracy if the same algorithm is used in feature selection and model training. however, it may over-fit to the specific classification algorithm. furthermore, the method is computationally expensive since many iterations of the classification algorithm need to be executed. in a filter method, features are selected independently of any classification algorithm. individual features or feature subsets are ranked according to certain scoring functions, and the top ones are selected. this approach is efficient in removing a large number of irrelevant features, but may sometimes eliminate low-ranked, nevertheless important, features. in this study, we used a filter method because of its efficiency in computation. the method ranks individual features according to their information gains and selects the top d features . as shown in figure 1b, the best kappa was achieved with as few as  <dig> features. this agrees with the fact that a transcriptional regulation only involves a few transcription factors in general. careful inspections on individual decision trees show that with  <dig> features, the performance of some trees may be worse than those with more features, due to the loss of some significant features. with  <dig> features, the modeling accuracies were almost never worse than those with more features. therefore we used d =  <dig> in all subsequent analysis. the accuracy of each classification model was estimated using a ten-fold cross-validation procedure. first, a training set was randomly divided into ten equal-sized subsets. each subset was then used in turn as a validation set to test the accuracy of the model built with the other nine subsets. we calculated kappa  <cit>  to measure model accuracies . the kappa statistic, written κ, measures the agreement between the class labels and the predictions made by the classifier, corrected by the amount of agreement that may be achieved by chance. therefore, it reflects the extent to which the differential expression between positive and negative genes can truly be explained by the classification model. for example, given a data set containing  <dig> positive and  <dig> negative genes, a model that simply guesses all genes as negative agrees with the true labels on 80% of cases, as does another model that makes five mistakes in positive and  <dig> in negative genes. taking into account the amount of agreement that we would expect by chance, the value of κ is  <dig>  for the former model, while  <dig>  for the latter.

it is known that κ depends on the class distribution and the number of categories in the test data  <cit> . this, however, was not a problem in our case, since the models in our test all had binary classes and the same class distributions. another difficulty associated with κ is its lack of interpretability, although some relations between κ and model quality have been suggested  <cit> . therefore, in addition to κ, we calculated sensitivity  and specificity  for each model . ss is the proportion of positive genes that are correctly predicted by the model, i.e., the proportion of up- or down-regulated genes that can be explained by the regulatory elements identified. sp is the proportion of negative genes that are correctly predicted by the model, and  <dig> - sp represents the proportion of negative genes that cannot be separated from the positive genes based on the regulatory elements.

methods for identifying deg candidates
microarray data are noisy and often measured with limited or no replication, which makes the identification of differentially expressed genes  difficult. in most early microarray analysis, a fixed fold-change threshold  was used to identify degs, while more sophisticated methods have emerged recently  <cit> . although it is not the focus of this paper, we considered and compared several different deg identification methods to show that our conclusions on the classification models are unlikely to be affected by the specific deg identification method used.

for the first method , we downloaded the transformed and normalized log ratios for the  <dig> microarray experiments. the data set had been corrected for background noises, and globally normalized by constant factors such that the mean log <dig> value is zero within each slide  <cit> . for expression data in cell cycle conditions, the log ratios were further normalized such that the mean log ratio for each gene across all cell cycle conditions is zero  <cit> . several rules were also applied to remove spurious data points  <cit> . for each column  of this data set, we selected the genes with log <dig> ≥  <dig>  as up-regulated genes. in cases there were more than  <dig> up-regulated genes, we selected the top  <dig> with the highest fold changes, or until ties were broken. likewise, down-regulated genes with log <dig> ≤ -  <dig> were selected. genes with |log2| ≤  <dig>   were considered as non-degs and were used to sample negative instances. note that we intentionally used two different thresholds for degs and non-degs, in order to exclude genes whose labels may be ambiguous.

for the second to fifth methods, we downloaded the raw intensity data. however, we only found raw data for  <dig> of the  <dig> conditions, and it was sometimes unclear how to match the name of a raw data file with a column in the log ratio data. the intensity data were background corrected, without any other normalization or transformation. we removed low quality data points that were annotated by the authors with failed status or non-zero flags.

the second approach  was similar to the vanilla approach, except that no per-gene normalization was made. the third approach  was similar to the second approach, except that within-slide normalization factors were intensity dependent, obtained through a locally weighted regression approach  <cit> . the fourth method  transformed the intensities with a generalized logarithm function, in order to stabilize the variances which were originally intensity dependent  <cit> . we applied the same thresholds as in the vanilla approach to the transformed data. the fifth method  quantified the heteroscedasticity as a function of intensity and then taking it into account to identify degs  <cit> . the edge method assigned each gene a p-value based on its distance from the line of equivalence , corrected for multiple tests. we ranked genes according to their corrected p-values, and selected up to  <dig> up-regulated or down-regulated genes with false discovery rate  <  <dig>   <cit> . the fdr threshold was used to ensure that the number of dags selected by edge was approximately equal to those chosen by the other approaches. it had no impact for most experiments, where all top  <dig> genes had fdrs less than  <dig> . genes with fdr >  <dig>  were considered as non-degs. the programs for vsn and edge were obtained from their original authors.

we used each of the five methods to select degs and non-degs for each microarray. deg sets with less than  <dig> genes were not used. table  <dig> lists the average group size and the number of deg sets identified by each method. the accession numbers for the genes in each set can be viewed on the supplementary website  <cit> .

for each set of positive genes , we randomly sampled threefold negative genes from the corresponding non-degs to construct a decision tree and performed a ten-fold cross validation. the random sampling was repeated for ten times for each deg set. the cross-validation accuracies for all models are included in supplementary table  <dig> . figure  <dig> shows the values of κ, ss and  <dig> - sp averaged across all gene sets obtained by each method. the five different methods showed similar accuracies in all three measures. although two of the methods  seemed to have slightly better ss and kappa, the difference is not significant. we therefore restricted our subsequent analysis on the degs identified using the vanilla method, which resulted in the largest number of deg groups.

a comparison of the prediction power of different features
we compared the cross-validation accuracies of the models built with three types of features that we discussed early: chip-chip data, predefined motifs and auto motifs. the combination of chip-chip data with predefined motifs was also tested. for each type of features or feature combinations,  <dig> ×  <dig> =  <dig> decision tree models were built . we randomly exchanged the labels for positive and negative genes to serve as controls. note that we carried out two types of cross-validations for models built with auto motifs. in the first method, promoter sequences of genes in both training data and test data were combined to find motifs. in other words, motifs were identified from all positive genes, and the same set of motifs was used to train models for each fold in a cross-validation. in the second method, genes were first divided into ten subsets without constructing the actual feature vectors. a subset was chosen for testing, and the other nine subsets were used for motif finding. in other words, motifs were identified from only the training genes, and a different set of motifs was used to train models for each fold in a cross-validation. the second method provided a more stringent estimation of the generalization accuracy of a model, since it completely hided the test data from the learning algorithm until they were tested. the first method, however, was used in several previous studies  <cit> , probably because it is simple to implement and convenient to test. here we analyzed the results of both cross-validation methods to compare auto motifs with other feature types. in the next two subsections, we used only the first method to show other aspects of the models based on auto motifs.

a complete list of the cross-validation accuracies of models for each microarray experiment is included in supplementary table  <dig> . the mean cross-validation accuracies of models for genes in cell cycle and stress conditions are shown in figure  <dig> 

as shown in figure 3a, when the first cross-validation method is used, the models using auto motifs have the highest kappa values  among the three individual feature types. however, it is important to note that these models also have the highest kappa values on randomly selected genes .

furthermore, the accuracies measured by the second cross-validation method are much lower: the average kappa values are  <dig>  for models in cell cycle and  <dig>  for models in stress response experiments, and are approximately zero for models of randomly selected genes. therefore, the first method considerably over-estimates the accuracies of the models built with auto motifs. this is because that, with the first cross-validation method, the feature set contains some information about the test instances, even though the models are built only on training instances. consequently, although the results reported in previous studies utilizing automatically identified motifs  <cit>  may still be valid qualitatively, the exact accuracies may need to be re-evaluated. nevertheless, an apparent advantage of using automatically identified motifs is that it may be able to discover new features not included in predefined motifs and chip data.

in cell cycle experiments, the models using chip data or predefined motifs have similar kappa values . in contrast, in stress response experiments, the models using chip data alone have very low kappa values than that using predefined motifs . the chip data used in this study were measured under normal cell growth conditions. however, it is known that tf binding may change with environmental conditions  <cit> . while the cell cycle expression data were measured under conditions relatively similar to normal cell growth conditions, stress treatment dramatically changes the environmental conditions and thereby alters the binding of tfs. it is thus expected to observe lower prediction accuracies in stress response experiments than in cell cycle experiments when using chip data alone.

in cell cycle experiments, the models built with a combination of predefined motifs and chip data have substantially better kappa values than those with chip data or predefined motifs alone . the p-value is 10- <dig> in a paired t-test for results of chip data  and combined features , and 10- <dig> for predefined motifs  and combined features . in stress experiments, the kappa values for models based on combined features  are only marginally better than that for predefined motifs , due to limited usage of chip data as pointed out above. nevertheless, the models using combined features perform significantly better  in  <dig> cases, while the models using predefined motifs are never better by more than  <dig>  in kappa . a paired t-test yields a p-value 10- <dig>  which is still statistically significant. putative binding motifs and chip data represent two distinct and complementary sources of evidence of regulation. therefore, a combination of them can provide a better discriminative power than either of them does.

since the role of decision tree models is exploratory, there is no need to be restricted to any specific type of features. indeed, one should try a variety of them to identify the most relevant features for a particular set of genes. a good strategy in choosing feature types is probably as follows: first use a combination of tf binding data and predefined motifs for modeling; if a model with good cross-validation accuracy can not be found, then consider using automatically identified motifs. obviously when predefined motifs or tf binding data are unavailable or insufficient, using automatically identified motifs as features is the only option.

stability of models
to analyze the stability of decision tree models, we introduced some noises into positive training data and tested whether the models can separate the true positives from the noises. for each microarray experiment we randomly selected  <dig> to  <dig> negative genes and deliberately mislabeled them as positive. the original data and the additional fake positive instances were then combined to build a decision tree model. we compared the results of the new models to the results of the original models in ten-fold cross-validations and counted the numbers of losses, rescues and false positives . according to  <cit> , a loss is a positive instance that is mis-classified in the noisy data but correctly classified in the original data. a rescue is a positive instance that is correctly classified in the noisy data but mis-classified originally. an fp corresponds to a newly added noise gene that is classified as a  positive gene.

as shown in table  <dig>  the models built with predefined motifs are more robust than the models built with auto motifs. even at 100% noise level , almost 90% of the introduced noises  can be correctly filtered out by the models built with predefined motifs. in comparison, the models built with auto motifs can only filter out ≈ 75% of the noises. this is because the motif finding program was distracted by the wrongly labeled genes so that the discovered motifs became less effective to discriminate the true positives from false ones.

furthermore, the predictions made by the models built with predefined motifs are more stable, as reflected by the smaller values of loss + rescue in table  <dig>  the addition of a small amount of noises may result in, dramatic change to the predictions by the models built with auto motifs. when as few as  <dig> noisy instance were added, the models based on auto motif changed their predictions by  ≈ 58%, while the models based on predefined motif changed their predictions by only  ≈ 30%.

functional enrichment in correctly classified positive genes
as mentioned early, there may be errors in the labels of training instances, i.e., some genes assigned with the same label may actually not be co-regulated. here we test decision tree models' capabilities of identifying "true" regulons from such genes. given a set of putatively co-regulated genes as positive instances and randomly sampled genes as negative instances, we used a leave-one-out strategy to predict which of the positive genes are indeed co-regulated. to this end, a positive instance was removed from the training data, and tested on the decision tree model built without it. this was repeated for each positive gene. consequently, the positive genes were categorized into two groups: those that were predicted as true positives and those as negatives, which we refer to as gp and gn, respectively. we hypothesized that the genes in gp are more functionally coherent than the genes in gn, since according to the decision tree model, the genes in gp share some common regulatory elements. to test this hypothesis, we counted the number of gene ontology  functional categories  <cit>  that are statistically enriched in each group with a false discovery rate <  <dig>  . the above procedure was applied to the up- and down-regulated genes in each of the  <dig> microarray experiments and the average results were calculated. as shown in table  <dig>  the models built with predefined motifs and with auto motifs both succeed in retaining functionally related genes and filtering out unrelated genes. for example, in the models built with predefined motifs for up-regulated genes in cell cycle, there are in average  <dig> enriched go categories in  <dig> gp genes, while there are only  <dig> enriched go categories in  <dig> gn genes. a similar trend can be observed for down-regulated genes and for the models built with auto motifs. a paired t-test between  and  combining all cases yields a p-value 10- <dig> 

furthermore, we tested whether a similar degree of functional enrichment can be achieved without decision tree models. suppose a decision tree model predicted  <dig> out of  <dig> positive genes as true positives, and go analysis showed that these  <dig> genes were functionally more coherent than the remaining  <dig> genes. we want to know whether there is another way to select  <dig> genes that have higher degree of functional enrichment than those predicted by decision trees. for example, we may simply pick genes that are top ranked according to their expressions. we used the following procedure to test this hypothesis. for each set of up-or down-regulated genes, a, which has p predicted true positive genes, we selected p top ranked genes from a based on the absolute log ratios of their expressions. we denoted this set of genes as gp', which has the same number of genes as gp, and counted the number of enriched go categories in it. the average results over all microarray experiments are shown in the  column of table  <dig>  as shown, the genes in gp contain more enriched functional categories than genes in gp'(). a paired t-test between  and  combining all cases has a p-value 10- <dig>  therefore, we can conclude that both models built with auto motifs and with predefined motifs are more effective in selecting functionally related genes than the naive differential expression model.

cager web server
several previous studies have shown that decision tree is a valuable tool in analyzing transcriptional regulation of gene expressions  <cit> . although there are many publicly available software packages for building decision trees , they are not specifically designed for biological applications, and are not convenient for biologists to use. therefore, to make a good use of the results from this study, we designed and implemented a user-friendly web server and interface for building decision trees to analyze transcriptional regulation. the server integrates several software components that allow the user to select from different types of features and to interact with the constructed models.

the interface for user inputs is shown in figure 4a. to submit a job to cager, the user is first asked to provide positive and negative genes as either orf identifies for one of the supported organisms, which currently includes yeast s. cerevisiae and arabidopsis thaliana, or promoter sequences in fasta format. these can be copy-pasted to the web form or uploaded from files in the user's local computer. given orf identifiers, the promoter sequences in a supported genome are retrieved automatically from a local database. second, the user specifies some feature sets, which may be chip-chip data for yeast s. cerevisiae  <cit> , predefined motifs from pilpel et al.  <cit> , motifs automatically identified from the promoter sequences by alignace  <cit> , or a combination of them. the user can also specify whether features should be identified from negative instances as well as from positive instances, whether feature filters should be used, and the minimum number of instances per node. finally, the user fills in his or her email address and submits the job. after a job is completed, the user will be notified by email for instructions about how to access the results.

on the output page, a decision tree is displayed as a portable network graph , along with related statistics for the tree in training and cross-validation processes . the text inside an internal node of the tree gives the name of a feature, and the text inside a leaf node shows the predicted label for genes inside the node, as well as the number of supporting and counter-instances for the prediction. each node of the decision tree can be clicked to show some details. for example, if an internal node contains a feature derived from chip-chip data for a tf in yeast, clicking on it leads the user to sgd  <cit>  for detailed information about the tf. if the feature is a binding motif, a click opens a new window to display the sequence logo  <cit>  and the position specific weight matrix of the motif. a click on a leaf node brings up a window for displaying the identifiers of the positive and negative genes in the leaf.

application to aba-responsive genes in arabidopsis
here we show an example of using the web server to study the regulation of genes expressed in response to abscisic acid  in arabidopsis. aba is a phytohormone that plays important roles in many stages of plants, such as seed development and stress responses . seki et al.  <cit>  identified about  <dig> genes in arabidopsis that are induced by at least 5-fold after aba treatment. since arabidopsis is one of the supported organisms in our current server, its promoter sequences are available in our database.

therefore, we provided as positive instances the list of orf names corresponding to the up-regulated genes, and as negative instances a list of randomly selected genes that are not up-regulated. promoter sequences were retrieved for  <dig> of the positive genes. we used auto motifs identified from these promoters as features. the decision tree and the sequence logos for the most interesting motifs are shown in figure  <dig>  alignace identified a total of  <dig> motifs with default parameters, five of which were selected by the decision tree . three motifs, ace_m <dig>  ace_m <dig>  and ace_ <dig>  together correctly classified  <dig>  positive genes , while as many as  <dig> positive genes were classified as negative. this may be due to the fact that aba triggers a lot of down-stream responsive genes, many of which are not co-regulated with direct targets of aba. the motif ace_m <dig> has a conserved cacgtg core, which is very close to the known aba responsive elements  identified in many other plants  <cit> . it is known that an abre often functions together with a coupling element , but the consensus sequence of ce in arabidopsis is elusive. here, the decision tree suggests that ace_m <dig> and ace_m <dig> may be two possible ces. motif ace_m <dig> has a cgtgtg core which partially resembles the ce in rice osem gene   <cit> , and ce <dig> in barley hva <dig> gene   <cit> . note that ace_m <dig> has a weak second copy of the gtgtg core, whicl may be important for enhanced binding activity. motif ace_m <dig> is also remotely similar to ce <dig> in maize rab <dig> gene   <cit> , although in maize the cgtgtg core is replaced by cgcgcc. motif ace_m <dig> is a weak but significant motif that consists of a series of g's separated by one or two a's. this motif is not similar to any known motif in the database of plant cis-acting regulatory dna elements   <cit> , and therefore may be a new motif for arabidopsis.

CONCLUSIONS
in this research, we compared the effect of using different features to study transcriptional regulation of gene expressions by classification methods. we considered features based on chip-chip data, predefined motifs, automatically identified motifs, and their combinations. we found that tf binding data from chip assays are effective in modeling gene expressions only under the same conditions where chip-chip experiments were conducted. our results also indicate that many previous studies may have over-estimal the cross-validation accuracies of models built with automatically identified motifs. furthermore, the models built with automatically identified motifs are not robust with respect to noises, comparing to those built with predefined motifs. a combination of chip-chip data with predefined motifs seems to be superior to either one of them applied separately.

we also showed that the positive genes correctly predicted by decision tree models are more functionally related than those that are not correctly predicted. therefore, decision tree models can be used to refine putative regulons and detect new genes of a regulon. simonis et al.  <cit>  have showed this by testing on known regulons, while we confirmed this through analyzing the functional enrichment of predicted regulons. we presented a web service that integrates motif finding and decision tree learning for analyzing transcriptional regulation of gene expressions. its usefulness was illustrated with an example of studying the regulation of aba-responsive genes in arabidopsis. we identified two motifs that are similar to known aba-responsive elements  and coupling elements , and suggested a new ce, which may deserve further studies. as demonstrated by the example, the web interface combines a number of software components and hides most specific parameters from the user, while still allows some flexibilities. the graphical representation of a decision tree makes it easy to visualize and extract significant regulatory rules. we believe that it can significantly reduce the learning curve for those who are interested in applying classification methods to analyzing transcriptional regulation, and will be a useful tool to facilitate the discovery of transcriptional regulatory networks by combining multiple information sources.

