BACKGROUND
with the rapid development of high-throughput technologies, large-scale experiments nowadays frequently adopt more complex designs, further complicating the issue of multiple testing. in designs where a single hypothesis is tested for each feature , we need to consider the adjustment of multiplicity across a large number of features. as experiments become more complicated, it is often the case that multiple hypotheses need to be tested for each feature. this creates two dimensions of multiplicity - one dimension comes from the multiple features , while another dimension comes from the multiple hypotheses associated with each feature. in dealing with these multi-dimensional multiple testing problems, it is crucial to understand the underlying structure and adjust for multiplicity accordingly.

as an example of such problems, we consider gene expression studies over ordered categories. in these experiments, researchers are often interested in genes that are possibly differentially expressed across a number of time points or dose levels. in this case, multiple tests of differential expression are conducted for each gene. an easy way of adjusting for multiplicity would be to pool all the tests from all the genes together, and simply apply multiple testing procedures such as the benjamini and hochberg procedure   <cit> , controlling for the false discovery rate . however, this approach ignores the fact that the two dimensions of multiplicity are not equivalent. a suitable approach should take into account the fact that the key goal in these experiments is to identify important genes, and that the false discoveries should be controlled at the gene level.

in recent years, many proposals have addressed these new issues in multiplicity arising in microarray time-course or dose-response experiments. sun and wei  <cit>  considered the problem of multiple testing for pattern identification in these types of studies. they considered this a “set-wise” multiple testing problem, where each gene corresponds to a “set”. since they focused on pattern identification, their methods test for specific patterns across time for each gene, instead of making multiple individual inferences of differential expression between the time points. guo, sarkar and peddada  <cit>  looked into the problem of controlling false discoveries when making multiple directional decisions for each gene, also for time-course and dose-response experiments. they considered individual inferences for each time point and proposed controlling a quantity called the mixed directional false discovery rate . we will later show that the main procedure introduced by guo et al.  <cit>  falls under the general framework of this paper. on the other hand, building upon our framework, we are able to easily come up with procedures that are more powerful than that proposed by guo et al.  <cit> .

our approach is to consider the multiple hypotheses for each gene as belonging to a hypothesis set associated with that gene. we aim at controlling false discoveries on the hypothesis set level, but we also enable inferences on the individual hypotheses. inspired by a procedure in heller et al.  <cit>  for testing differentially expressed gene sets, we discuss a general two-step procedure to first identify significant hypothesis sets, and to then make further individual tests on each of the hypotheses within the significant sets. the procedure adjusts for multiplicity in both steps by adopting the benjamini-hochberg procedure in the first step and family-wise error rate controlling procedures in the second step. to measure false discoveries on the set level, we adopt the concept of the overall false discovery rate , which was introduced by benjamini and heller  <cit>  in the context of screening for partial conjunction hypothesis and further discussed in heller et al.  <cit> . the ofdr is a straightforward extension of the fdr to hypothesis sets. the general two-step procedure we discuss is proved to control the ofdr under independence between the hypothesis sets, which follows from a similar result in the paper by heller et al.  <cit> . in addition, we extend the general procedure to incorporate the cases of making directional decisions for two-sided alternatives, and discuss the control of the mixed-directional fdr in this case.

we applied this framework to gene expression data on ordered categories and developed three procedures for the problem of identifying genes that are differentially expressed between categories, as well as making directional decisions for each significant expression change. we conducted a simulation study to show that all three proposed procedures maintain control of the ofdr and mdfdr at the desired level under independence between genes, as well as positive correlations across genes. simulation results show that two of our new procedures perform better in terms of power compared to the procedure in guo et al.  <cit> . the proposed methodology is also applied to a microarray dose-response experiment by coser et al.  <cit>  which studied  <dig> β-estradiol  sensitivity of genes in breast cancer cells. we identified genes that are induced at low concentrations of e <dig>  and compared the results across the different procedures. our results confirmed and complemented the original findings.

methods
a framework for multiple hypothesis set testing and a general two-step procedure
we first present a general framework for multiple hypothesis set testing.

suppose we want to test for m sets of hypotheses h,…,h simultaneously. in each set of hypotheses h, there is a screening hypothesis, denoted by h <dig>  that will be tested first. the rest of the hypotheses in the set h <dig> …,h
n, which we will refer to as the individual hypotheses, will be tested simultaneously if and only if h <dig> is rejected. in general, the number of individual hypotheses in each set need not be the same. note that all the hypotheses referred to here are by default null hypotheses.

in this formulation of multiple testing of hypothesis sets, we wish to control the proportion of false rejections on the level of the hypothesis sets. so instead of the usual false discovery rate, we consider the overall false discovery rate   <cit> , which is a similar concept but defined in terms of the hypothesis sets. it is defined as the expected proportion of falsely rejected hypothesis sets out of all the rejected hypothesis sets. we define a hypothesis set to be rejected if the screening hypothesis in the set is rejected; and we define a hypothesis set to be falsely rejected if at least one true null hypothesis in the set  were incorrectly rejected. the formal definition of ofdr is given below.

definition 1
a hypothesis set h  is said to be rejected if the screening hypothesis h <dig> is rejected. a hypothesis set h is said to be falsely rejected if it is rejected and at least one hypothesis in the set h <dig> h <dig> …,h
n is falsely rejected. the overall false discovery rate  is defined as

 ofdr=evr∨ <dig>  

where r∨1=max, r is the total number of hypothesis sets rejected out of m, and v is the total number of hypothesis sets that are falsely rejected out of m.

heller et al.  <cit>  proposed a two-step procedure for testing differentially expressed gene sets that controls the ofdr of the gene sets. here we formally discuss a general two-step hierarchical testing procedure for the multiple hypothesis set testing framework. the general procedure proceeds as follows. let p
j
 be the unadjusted p-value for individually testing the jth hypothesis in the ith set, where i= <dig> …,m and j= <dig> ,…n.

procedure 1:

•apply the benjamini-hochberg procedure at level α to the m p-values corresponding to the screening hypotheses p <dig> …,p <dig>  let r be the number of rejected screening hypotheses.

•for each rejected hypothesis set h, test for the individual hypotheses h <dig> …,h
n simultaneously, applying a p-value adjusting procedure on p <dig> …,p
n such that the family-wise error rate  of these n tests are controlled at level rα/m.

procedure  <dig> enables two levels of inferences. we are able to identify the significant hypothesis sets by testing the screening hypotheses for each set. at the same time, for each significant hypothesis set, we are able to identify the significant individual hypotheses within the set. on the other hand, the false discovery rate is administered only on the set level. procedure  <dig> controls the ofdr of testing the m hypothesis sets at level α, under the condition that the p-values of the individual hypotheses in each hypothesis set are independent from all other screening hypothesis p-values. the proof follows directly from the proof in  <cit>  of a similar claim on their procedure. we state the theorem formally below.

theorem  <dig> 
procedure  <dig> controls the overall false discovery rate  at level α assuming that for each hypothesis set h, the p-values p <dig> p <dig> …,p
n are independent of all the other screening p-values, p <dig> …,p <dig> excluding p <dig> 

though theorem  <dig> only states the case of independence between the hypothesis sets, in practice, the framework can be applied to more general cases where certain positive dependency structures exist between the test statistics from different hypothesis sets. intuitively, this is because procedure  <dig> relies on the b-h procedure. the conditions on dependence such that the fdr is controlled are given in  <cit> . on the other hand, we will later present simulation studies that cover the situation where positive correlation exists across the hypothesis sets, and the results demonstrate control of ofdr in these cases

the multiple hypothesis set testing framework and the general two-step procedure have very broad applicability. they provide a general platform for dealing with practical problems in large scale experiments where simultaneous inference is needed on two or more dimensions. take microarray experiments as a general example. one dimension of multiplicity would be the genes, while another dimension would represent the multiple inferences for each gene that the researcher is interested in. we now give some examples: 1) in time-course experiments, the second dimension could reflect hypotheses on/between the different time points; in dose-response experiments, the second dimension could reflect hypotheses on/between the different dose levels; 2) in experiments with multiple treatment groups, the second dimension could reflect a number of possible pairwise comparisons between treatments. in all of these cases, the multiple hypotheses for each gene would make up the hypothesis set for that gene. thus each gene would correspond to a hypothesis set. under this context, intuitively, we would want to control the false discoveries on the gene level, despite the multiple inferences made for each gene. this makes the ofdr a reasonable quantity to control, compared to the usual fdr. in general, our framework and procedure can be reasonably adapted to any multi-dimensional multiple testing problem that has a hierarchical structure where it makes sense to define hypothesis sets.

incorporating directional decisions
in many practical settings, following the rejection of a hypothesis, researchers are interested in making additional claims. in the case of two-sided alternatives, directional decisions are often made. this is especially common in differential expression analysis of genomic data, where it is important to claim the direction of expression change after finding a difference. in these situations, in addition to the traditional type i error, there is also a chance of making directional errors  <cit> . directional errors occur when a two-sided test is correctly rejected, but the choice of the alternative  is incorrect. if directional decisions are desired, it is important to take into account directional errors  in additional to type i errors.

guo et al.  <cit>  discussed the idea of mixed-directional fdr , which is similar in concept to the ofdr, but with the addition of directional errors. we give the formal definition of mdfdr below.

definition  <dig> 
the mixed-directional false discovery rate  is defined as

 mdfdr=ev+sr∨ <dig>  

where r∨1= max, r is the total number of hypothesis sets rejected out of m, v is the total number of hypothesis sets that are falsely rejected out of m, and s is the total number of hypothesis sets that are correctly rejected but for which at least one directional error was made when making directional decisions for the individual hypotheses.

it is apparent that ofdr≤mdfdr. thus while the general procedure  <dig> guarantees the control of the ofdr under independence conditions , it does not automatically guarantee the control of the mdfdr. however, we can easily extend the proof of theorem  <dig> to obtain the following results.

lemma  <dig> 
under the assumptions of theorem  <dig>  procedure  <dig> controls the mixed-directional fdr  at level α if the family-wise error rate controlling procedure used in step  maintains control of both type-i and directional errors.

although lemma  <dig> is just a direct extension of theorem  <dig>  it provides great practical benefits. this is because many commonly used family-wise error rate controlling procedures have been shown to maintain control of directional errors under certain conditions  <cit> . for instance, finner  <cit>  showed that the bonferroni procedure, holm’s procedure, as well as hochberg’s procedure are all able to control both type i and directional errors family-wise, for multiple two-sided tests involving independent t-statistics. this covers the most common two-sided tests as well as some of the most common family-wise error rate controlling procedures. thus lemma  <dig> allows us to extend procedure  <dig> to many situations where directional decisions are needed, and ensures control of the mdfdr in addition to the ofdr

procedures for testing gene expression differences on ordered categories
now we shall introduce methods for testing differential expression for microarray experiments on ordered categories, while controlling for the ofdr/mdfdr on the gene level. the procedures we are proposing are based on the hypothesis set testing framework and the general procedure  <dig> described previously.

in microarray experiments on ordered categories, such as time-course or dose-response experiments, depending on the study design, some of the common research interests include discovering:  genes that are differentially expressed between two treatment groups at certain time points or dose levels;  genes that are differentially expressed between successive time points or dose levels; or  genes that are differentially expressed at certain time points or dose levels compared to a starting time or baseline dose level. regardless of the specific case, the commonality is that we are interested in testing multiple hypotheses simultaneously for each gene, and that a gene would be considered interesting if at least one of its associated hypotheses is significant.

the cases described above are problems of multiple hypothesis set testing, where each gene corresponds to a hypothesis set. the individual hypotheses of each hypothesis set are the multiple hypotheses that are tested for each gene. on the other hand, the screening hypothesis for each hypothesis set would test an overall hypothesis of whether the gene is differentially expressed at all. for the case of time-course and dose-response experiments, it would be reasonable to set up the screening hypothesis such that it tests for the conjunction of the individual hypotheses. that is, for each hypothesis set, the screening hypothesis tests for whether at least one of the individual null hypotheses can be rejected.

assume that we test the same set of q individual hypotheses for each gene, i.e. n=q for i= <dig> …,m. let h <dig> …,h
q
 denote the individual null hypotheses for gene i, i= <dig> …,m. the screening null hypotheses for gene i is h0=∩k=1qhk, which is the conjunction of the individual hypotheses. let p <dig> …,p
q
 denote the p-values for testing h <dig> …,h
q
 individually. there are many possible methods for testing the conjunction of hypotheses in order to obtain p <dig> for the screening hypothesis h <dig>  including more conservative family-wise error rate controlling methods such as the bonferroni method, or commonly used meta-analysis methods such as fisher’s combined probability test. in this case though, referring to procedure  <dig>  since we ultimately need to make inference on each of the individual hypothesis in the second step, it makes sense to use methods for testing h <dig> such that the rejection of h <dig> leads to at least one rejection out of h <dig> …,h
q
. thus meta-analysis methods such as the fisher’s combined probability test that do not have corresponding procedures for making inference on the individual hypotheses are not suitable in this case. on the other hand, multiple testing procedures such as the bonferroni method, holm’s step-down procedure  <cit>  or hochberg’s step-up procedure  <cit> , can be used to test for the conjunction of hypotheses and at the same time test for the individual hypotheses while controlling the family-wise error rate. based on procedure  <dig> and the three family-wise error rate controlling methods mentioned, we propose the following three procedures for making inference on gene expression data on ordered categories. let p≤⋯≤p be the ordered versions of p
j
, j= <dig> …,q, for a fixed i.

procedure 2:

•based on bonferroni’s method, let the screening p-value p0=qp for i= <dig> …,m. apply the benjamini-hochberg procedure at level α to p <dig> …,p <dig> for testing h <dig> …,h <dig> simultaneously. let r be the number of rejected screening hypotheses.

•for every j= <dig> …,q and i= <dig> …,m with p
j
≤rα/, reject the corresponding h
j
. if desired, the directions of expression changes can be declared according to the signs of the test statistics.

procedure 3:

•based on holm’s method, let the screening p-value p0=qp for i= <dig> …,m. apply the benjamini-hochberg procedure at level α to p <dig> …,p <dig> for testing h <dig> …,h <dig> simultaneously. let r be the number of rejected screening hypotheses.

•for every i= <dig> …,m, let r
i
= max{1≤j≤q: p≤rα{m}− <dig>  for l= <dig> …,j}, if the maximum exists; otherwise r
i
= <dig>  for every i and j with p
j
≤rα{m}− <dig> ≤p), reject the corresponding h
j
. if desired, the directions of the expression changes can be declared according to the signs of the test statistics.

procedure 4:

•based on hochberg’s method, let the screening p-value p0= min1≤j≤q{p} for i= <dig> …,m. apply the benjamini-hochberg procedure at level α to p <dig> …,p <dig> for testing h <dig> …,h <dig> simultaneously. let r be the number of rejected screening hypotheses.

•for every i= <dig> …,m, let r
i
= max{1≤j≤q: p≤rα{m}−1}, if the maximum exists; otherwise r
i
= <dig>  for every i and j with p
j
≤rα{m}− <dig> ≤p), reject the corresponding h
j
. if desired, the directions of expression changes can be declared according to the signs of the test statistics.

by theorem  <dig>  procedures  <dig>   <dig> and  <dig> control the ofdr of the genes under independence between genes and other conditions required for bonferroni’s, holm’s and hochberg’s methods to control the family-wise error rate. in addition, by lemma  <dig>  procedures  <dig>   <dig> and  <dig> also maintain control of the mdfdr of the genes under independence between the genes and the test statistics for the individual hypotheses for each gene, as well as the conditions required for bonferroni’s, holm’s and hochberg’s methods to control the family-wise error rate. in fact, bonferroni’s method and holm’s method control the family-wise error rate without any restrictions on the individual hypotheses. hochberg’s method does require either independence between the individual hypotheses or certain positive dependence structures . on the other hand, since hochberg’s method is uniformly more powerful than holm’s method, which is uniformly more powerful than bonferroni’s method, procedure  <dig> is more powerful than procedure  <dig>  which in turn is more powerful than procedure  <dig>  notice though that the screening p-values for procedure  <dig> and  <dig> are the same, so that they would reject the same genes in step one, but procedure  <dig> would potentially find more significant individual hypotheses in step two compared to procedure  <dig> 

interestingly, the main procedure proposed by guo et al.  <cit>  for making multi-dimensional directional decisions is essentially the same as procedure  <dig> above. in an attempt to increase power, guo et al.  <cit>  also proposed another procedure similar in structure but using the simes method  <cit>  instead of the bonferroni method. however, as discussed in  <cit> , the procedure based on the simes method, though potentially more powerful, does not guarantee control of the mdfdr. under our proposed framework, it is easy to see that the problem lies within the fact that the simes method does not guarantee control of the family-wise error rate, which is a required property of the method used in the second step, as seen in the general procedure  <dig>  with this observation in mind, the key to improving power over the procedure in guo et al.  <cit> , is to use family-wise error rate controlling methods that are more powerful than bonferroni’s method, naturally leading to procedures  <dig> and  <dig> 

RESULTS
a simulation study
we conducted a simulation study to illustrate the control of the ofdr and mdfdr of procedures  <dig>   <dig> and  <dig>  as well as compare their performances on power. we shall set up the simulation study exactly following the paper by guo et al.  <cit> . since procedure  <dig> is essentially the same as the procedure proposed in  <cit> , this allows us to directly compare the performances of our new procedures  <dig> and  <dig> with their procedure.

following  <cit> , we simulate the setting of a time-course experiment with m= <dig> genes, and  <dig> time points. we are interested in differential expression between successive time points, which leads to q= <dig> hypotheses for each gene. the gene expression vectors 
z

j
  for the  <dig> time points are simulated from independent m-dimensional multivariate normal distributions, where z
j
i
∼n  and have a common correlation ρ. ρ is set to be  <dig>   <dig> ,  <dig>  or  <dig>  for four separate simulations respectively. let the vector of expression differences between successive time points for each gene i be 
δ

i
, where each component δij=/ <dig> for j= <dig> …, <dig>  out of the m
δ

i
’s, m <dig> were set to a zero vector, and the δ
i
j
’s in 50%, 25% and 25% of the remaining m−m0
δ

i
’s were randomly generated  from the intervals ,  and  respectively. the null hypothesis tested is δ
i
j
= <dig> for all i and j. the test statistic for testing each δ
i
j
 is tij=/ <dig> and the corresponding p-value is computed by p
i
j
=2{1−Φ}, where Φ is the standard normal cdf. here p
i
j
 are the p-values for the individual hypotheses for each gene i - corresponding to the notation of p
j
 used in the methods section. this simulation set up, as well as the parameter values, strictly follow that of  <cit> . simulation results are averaged across  <dig> replications. the level α is set to be  <dig> . notice that even though theory on all the procedures were developed under independence between genes, we also investigate the cases where genes are positively correlated in the simulation study.

we consider procedures  <dig>   <dig> and  <dig> in our simulation study. as a comparison to these two-step procedures, we also consider what we call the simple b-h procedure, which is basically a one-step procedure that simply tests for the mq individual hypotheses simultaneously by directly applying the benjamini-hochberg procedure. by construction, the simple b-h method would control the fdr of the mq individual hypotheses, but it would be interesting to see how it performs with respect to the gene-wise ofdr or mdfdr. the simple b-h method does not conduct tests on the hypothesis set level, but in order to compare it with the two-step procedures, we can define a hypothesis set  to be rejected if any of its individual hypotheses are rejected by the simple b-h method, and define the ofdr/mdfdr correspondingly.

in this simulation, evaluating the mdfdr would be more appropriate, since we do care about the direction of change across the time points. figure  <dig> shows the evaluation of the mdfdr for the different methods and correlation settings. results for the ofdr are very similar to those of the mdfdr in our simulations. we do not provide separate plots for the ofdr, but note that since ofdr≤mdfdr, the ofdr is controlled whenever the mdfdr is controlled. the first plot in figure  <dig> shows the control of the mdfdr  by procedures  <dig>   <dig> and  <dig>  these three procedures have almost exactly identical results for mdfdr, thus only one set of results are reflected in the plot. notice that the mdfdr is not only controlled under independence between genes , which is proved by theory, but it is also controlled under the three positive correlation settings . in fact, it seems that stronger positive correlation results in even lower mdfdr. the plot also shows that the mdfdr decreases as the number of false null hypotheses increases. more precisely, the x-axis is the number of genes  for which at least one null hypotheses is false. for these genes, which we shall call “false null genes”, the screening null hypothesis associated with it would be false. notice that as the number of false null genes reaches  <dig> , the mdfdr does not decrease to  <dig>  in this case, even though there would be no probability of making false discoveries with regard to the screening hypotheses , there is still a positive probability of making false discoveries, especially false directional decisions for the individual hypotheses. the second plot in figure  <dig> shows the average mdfdr for the simple b-h method. as we can see, the simple b-h method fails to control the mdfdr at α= <dig> . this illustrates the fact that the fdr with respect to the m×q individual hypotheses and the ofdr/mdfdr with respect to the m hypothesis sets are distinct concepts. it can be shown that the simple b-h method always rejects at least as many genes as procedure  <dig>  however, the rejections by simple b-h method are on the basis of the individual hypotheses - not considering each gene as an entity. in this case, if the interest is in controlling the false discoveries of the genes, then simply applying an fdr controlling procedure to all the tests does not guarantee the control of the desired ofdr/mdfdr.

next, we shall look at the performances on power for the different procedures. we first need to define power in the context of multiple hypothesis set testing. in general multiple testing problems, we evaluate power by looking at the proportion of false null hypotheses that are correctly rejected by a method. we can adopt this definition of power for our problem as well, if we put aside the hypothesis sets for a moment, and directly look at all the m×q individual hypotheses. we shall name this “power ”. on the other hand, we can define power with respect to the hypothesis sets, by looking at the proportion of false null genes that are correctly rejected. here, false null genes refer to the genes for which at least one null hypotheses is false, as mentioned previously. further, we say that a false null gene is correctly rejected, if and only if a correct decision is made for every single null hypothesis for that gene - i.e., we need to correctly reject every false null hypothesis for that gene, and at the same time not reject any true null hypothesis for that gene. the power defined this way is with respect to the hypothesis sets and we shall name it “power ”.

in summary, results from the simulation study show that procedures  <dig>   <dig> and  <dig> do indeed control the ofdr and mdfdr under independence between genes, as well as positive correlation between genes. the three procedures perform almost identically with regards to the mdfdr/ofdr. on the other hand, our new procedures  <dig> and  <dig> show considerable gains in power compared to procedure  <dig> . by comparing the two-step procedures with the simple b-h method, we also gain some insight into the differences between treating a problem as a simple multiple testing problem versus a multiple hypothesis set testing problem.

an application to a microarray dose-response experiment
coser et al.  <cit>  studied the effect of estrogen on gene expression in breast cancer cells. in particular, they are interested in characterizing the effect of low concentrations of  <dig> β-estradiol  on the transcriptome profile of mcf7/bus human breast cancer cells. according to  <cit> , the e <dig> dose-dependent growth curve of these cells saturate with  <dig> pm e <dig>  which is a concentration unlikely to be maintained in vivo. thus it is important to study the effects of lower, unsaturated concentrations of e <dig>  varying low concentrations of e <dig> are investigated in this study through a microarray dose-response experiment using affymetrix u-133a chips. gene expressions are evaluated at  <dig> different levels of concentration of e2:  <dig>   <dig>   <dig>   <dig> and  <dig> pm. five replicates are used for each concentration. gene expressions are evaluated for a total of  <dig> genes. the gene expression dataset from this study can be found in the ncbi geo public database under the record number gds <dig> 

we apply the methodology we proposed in this article to the dose-response gene expression data from  <cit>  to identify genes that are significantly induced or suppressed at various low concentrations of e <dig>  more specifically, we test four individual hypotheses for each gene, to detect differential expression at  <dig>   <dig>   <dig> and  <dig> pm compared to  <dig> pm respectively. the screening hypothesis for each gene tests for whether the gene is differentially expressed at all at any of the four levels of concentration of e <dig> compared to absence of e <dig>  the ability of our procedure to make directional decisions is utilized to decide whether the significantly differentially expressed genes are induced or suppressed.

we tried all three procedures on the data: procedure  <dig> , which corresponds to that of  <cit> , and procedures  <dig>  and  <dig> . theoretically, in order to control the ofdr, procedure  <dig>  requires that the tests between the multiple dose levels and  <dig> pm be independent or satisfy certain positive dependence criteria. it seems reasonable to assume that these tests within each gene are positively correlated, therefore we think it is appropriate to apply procedure  <dig> here in practice.

with the overall false discovery rate controlled at level  <dig> , procedures  <dig> and  <dig> identified  <dig> genes that are differentially expressed at some level of e <dig> , while procedure  <dig> identified  <dig> genes . note that in this application, the significant individual hypotheses within a gene always display consistent direction of change, regardless of which procedure was used, thus enabling us to declare each significant gene as induced or suppressed. recall that procedures  <dig> and  <dig> will always reject the same hypothesis sets, but may not reject the same individual hypotheses subsequently. with regards to the individual hypotheses, the number of individual hypotheses deemed significant by procedures  <dig>   <dig> and  <dig> are  <dig>   <dig> and  <dig> respectively. notice that our new procedures were able to detect a considerably larger number of significant individual hypotheses.

the implications of the fact that procedures  <dig> and  <dig> reject the same genes but that procedure  <dig> rejects more individual hypotheses is that, for the same genes identified by both procedures, procedure  <dig> is more likely to detect significant differential expression for a lower concentration level of e <dig>  thus better characterizing the sensitivity of the genes. table  <dig> summarizes the distribution of the number of e <dig> concentration levels that the identified genes are found to be differentially expressed in, for the three procedures respectively. as we can see, out of the  <dig> genes identified by both procedures  <dig> and  <dig>  only one gene was found to be differentially expressed at all four concentrations of e <dig> by procedure  <dig>  while nine of them were identified by procedure  <dig> to be differentially expressed at all four concentration levels. on the other hand,  <dig> genes were found to be differentially expressed at only one concentration of e <dig>  according to procedure  <dig>  however,  <dig> of them were found to be also differentially expressed at other concentration levels by procedure  <dig>  to further illustrate this point, we compare the genes that are identified by the three procedures as having very high e <dig> sensitivity . procedures  <dig> and  <dig> detected  <dig> and  <dig> genes respectively that are induced at  <dig> pm e <dig>  while procedure  <dig> only detected  <dig> of them. in particular, progesterone receptor gene pgr, one of the genes found to have very high sensitivity by  <cit> , was identified by procedures  <dig> and  <dig>  but not by procedure  <dig>  at the same time, procedures  <dig> and  <dig> detected  <dig> and  <dig> genes suppressed at  <dig> pm e <dig>  while procedure  <dig> detected only  <dig>  again, one of the genes found to be e2-suppressible by  <cit> , apolipoprotein d gene apod, was only detected by procedures  <dig> and  <dig> but not by procedure  <dig>  these results show that our new procedures are better options for this problem compared to that of  <cit> .

the direct comparison of the lists of genes found by our procedures and those in  <cit>  is not straightforward, partly due to the fact that  <cit>  considered both the p-values and the fold-changes in determining significance, but without making any explicit adjustments to multiple testing. however, to compare the pathways associated with the gene lists, we performed functional annotation clustering analysis using david, which is available at http://david.abcc.ncifcrf.gov/home.jsp. the analysis was performed on lists of genes with high e <dig> sensitivity that were induced at concentrations  <dig> pm or  <dig> pm. we compare the results from procedures  <dig> and  <dig>  we did not include procedure  <dig> because its gene list is rather similar to that of procedure  <dig>  the top five groups of functions associated with each genes lists are summarized in table  <dig> along with corresponding enrichment scores. the top functions identified by the three gene lists are fairly similar, showing a consistency in findings, especially compared to that of  <cit> . on the other hand, the enrichment scores associated with the results produced by procedure  <dig> are the highest among the three. this indicates that the evidence gathered by procedure  <dig> for the top functions is stronger.

CONCLUSIONS
in large-scale experiments, such as microarray gene expression studies, as the problem and the designs become more complicated, new issues in multiple testing arise. for instance, in microarray time-course or dose-response experiments, in addition to considering tens of thousands of genes simultaneously, multiple hypotheses are often being tested for each gene. as a result, the problem of multiplicity becomes multi-dimensional. traditional concepts of type i error control and methods for large-scale multiple testing  can still be used, but may not be optimal for these more complex designs. hence, it is important to consider new measures of type i error and develop statistical methods for these multi-dimensional multiple testing problems.

the methodology in this article provides one way of approaching these problems. we have formulated certain types of multi-dimensional multiple testing problems as multiple hypothesis set testing. in the case of microarray time-course/dose-response experiments, we consider each gene to be associated with a hypothesis set, where the multiple individual hypotheses in the set test for differential expression among a number of different time points or dose levels. we have adopted the concept of the overall fdr, which is a measure of the fdr on the hypothesis set level. by doing so, we aim at controlling the false discoveries on the gene level, which increases the interpretability of the results, compared to focusing on the fdr of all the individual hypotheses. we discussed a general two-step hierarchical testing procedure for multiple hypothesis set testing, which is proved to control the ofdr under independence across the hypothesis sets. we also extended the general procedure to enable directional decisions for two-sided tests and discussed the control of the mdfdr under certain conditions. we then suggested three specific procedures for microarray time-course/dose-response experiments. these procedures not only allow us to test for differential expression across multiple time points or dose levels, but are also capable of identifying the direction of expression change, while still maintaining control of the ofdr and mdfdr. we evaluated the performance of the proposed procedures under both independence and dependence between genes and compared the power with previous methods. finally, the methodology is applied to analyze data from a microarray dose-response study to identify genes that are differentially expressed at low concentrations of estrogen in breast cancer cells.

the key point in the hypothesis set testing framework is that the two-dimensional multiplicity is transformed into a hierarchical structure. hypotheses are tested in the unit of sets in the first step. this is realized by the formulation of a screening hypothesis for each set. the first step of our procedures deals with the hypothesis sets much like dealing with a traditional multiple testing problem. by applying the benjamini-hochberg procedure to the screening hypotheses, we are able to adjust for part of the multiplicity on the hypothesis set level. additional type i errors  that can potentially occur while making inference for the individual hypotheses in each set are controlled in the second step by applying family-wise error rate controlling procedures. together, the ofdr  is controlled at the hypothesis set level.

although our focus was on applications to gene expression data over ordered categories, the proposed methodology is widely applicable. the framework of multiple hypothesis set testing is very flexible and can be easily adapted to many large-scale multiple testing problems with complex designs. for example, the methodology can be applied to microarray studies with anova designs that require follow-up pairwise comparisons. in this case, each gene would still be associated with a hypothesis set, where the individual hypotheses in the set are the multiple pairwise comparisons between the number of treatments. on the other hand, it would be interesting to develop more powerful procedures for each specific type of problem. for example, if a large proportion of individual hypotheses are expected to be significant given the significance of the hypothesis set, then we can potentially improve power by incorporating adaptive multiple testing methods into the procedure. much future work can be done on adapting the hierarchical hypothesis set testing framework and procedures to different multi-dimensional multiple testing problems.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
yl developed the procedures, carried out the simulation studies and data analysis, and drafted the manuscript. dg supervised and contributed important ideas throughout the research process and revised the manuscript. both authors read and approved the final manuscript.

acknowledgments
we acknowledge the support of the nsf grant abi- <dig> 
