BACKGROUND
the exponential growth in high-throughput sequencing exceeds the pace of speed increase in computer hardware. therefore, advancements in software and algorithms for read analysis have been required in order to analyze the tremendous amount of data obtained from sequencing.

most of the existing programs for read alignment are based on two classes of algorithms: a) prefix-trees  and b) hash-tables . reviews of the main algorithms and software packages developed for read alignment are available in  <cit> .

software packages released in recent years use these approaches very efficiently. when the reference is not very large and not very repetitive, when the number of reads is not large, and when it is possible to "mask" large parts of the reference, existing algorithms and tools provide a computationally inexpensive solution. however, as the throughput continues to grow and new applications emerge, a new approach to read alignment may be useful for many applications.

in this paper, we introduce a random-permutations-based approach to read alignment. the approach is conceptually related to the use of random projections in randomized nearest neighbors algorithms . an outline for a random-permutations-based algorithm for string searches has been presented by charikar  <cit> . we formulate the read alignment problem as a special nearest neighbors search problem and propose a practical search algorithm based on the random permutations approach.

the applicability of the algorithm is demonstrated by comparing an implementation of the algorithm to existing fast read alignment programs.

problem definition
in this subsection we formulate the problem as a "nearest neighbors search" problem.

in the study of the genome, the sequences of nucleotides that form dna molecules are represented as strings composed of the characters a, c, g and t. we investigate the following scenario: we are given a long reference string  and a large number of short strings, called "reads." for each of the reads, we would like to find the most similar substring of the reference.

we assume that all our reads are strings of the same length. this assumption often holds in practice, and the approach can be extended to non-uniform lengths. we denote the length of the reads by m. a typical value can be m ≈  <dig> 

we denote the long reference string, which represents the entire reference genome, by w. in the human genome, the length of this string is in the order of n ≈  <dig> ×  <dig> 

instead of considering w as one long string, we examine its contiguous substrings of length m. there are n - m +  <dig> such substrings, each of them starts at a different location in w. we denote each of these substrings by its location in w, so xi is the substring that begins at the ith character of w .

we can now phrase our alignment problem as follows: given a read y , find the most "similar" string xi in the reference library. the measure for similarity is based on the number of mismatches, or the "hamming distance" between strings; the smaller the distance, the higher the similarity.

this type of search problems  is known as "nearest neighbors search."

in this discussion, we describe an algorithm for finding a single, unique, "true nearest neighbor". we assume that no two reference strings are identical. we also assume that there is a unique "true nearest neighbor" for every read, so no other reference string has the same hamming distance to the read as the "true nearest neighbor." these assumptions simplify the definitions and the analysis, but the approach is applicable when these assumptions do not hold.

extended frameworks
the principles discussed in this limited framework and under these assumptions can be extended. for more general search problems, we consider a two-step framework for read alignment: a search step and a refinement step. in the first step, we use a search algorithm to recover candidate alignments and apply a coarse filter to obtain a "small" list of final candidates. in the second step, a more refined method is used to process the list of candidates. this step may include scores  and thresholds, but may also include cross-referencing of the information recovered from different reads as well as additional searches. this framework is appropriate for permutations-based-algorithms which automatically enumerate many possible candidates.

the prototype presented in the results section implements a version of the algorithm which preforms the first approximate search step and returns a small number of candidates, rather than a single "best" match.

in most of this paper, we restrict our attention to mismatch-type variations and errors. although considering mismatches is sufficient for some applications, there are other important variations: insertions and deletions  of characters that change the relative positions of other characters. the implementation in the results section demonstrates one of the extensions for fast and accurate alignment in the presence of indels. a comprehensive discussion of the extensions for indels is beyond the scope of this paper.

observations
in the description of the algorithm, we discuss arrays of strings which we sort lexicographically, like words in a dictionary. in particular, we discuss lexicographically sorted libraries containing versions of the strings in the reference library. in this subsection, we describe several properties of lexicographically sorted libraries and properties of strings comparison.

definition  <dig> if a string is present in the lexicographically sorted array, we define its "lexicographical position" in the array as its position in the array. if a string is not present in the lexicographically sorted array, we define its "lexicographical position" in the array as the position where it would have been inserted if we had added it to the array.

observation  <dig> there are search algorithms, such as "binary search"  <cit> , that allow us to find the lexicographical position of reads in sorted libraries of reference strings in o) strings comparison operations. furthermore, when the reference library contains a perfect match for the read, these search algorithms find the perfect match.

this operation is very similar to looking up a word in a dictionary.

observation  <dig> suppose that all the mismatches in some read with respect to its true nearest neighbor are known to occur "late enough" in the read, so that the lexicographical position of the read in the sorted array is within k positions from the position of the true nearest neighbor. then we can find the true nearest neighbor in o + k) strings comparison operations.

this can be done by first finding the lexicographical position of the read, and then considering the "neighborhood" of ~ 2k strings around it. this operation is analogous to finding the correct page in a dictionary and then examining all the words on that page.

observation  <dig> if the same permutation is applied to two strings, the hamming distance between the permuted strings is equal to the hamming distance between the original strings.

a permutation of a string reorders the characters in the string. therefore, the same mismatches still occur in the permuted versions, only the positions where they occur are changed by the permutations.

methods
an informal description of the algorithm
in our search problem, we have some library of reference strings and a read. suppose that our read y and its true nearest neighbor xi have p mismatches. based on observation  <dig>  if we apply the same permutation π to our read and all the reference strings, the hamming distance between the permuted version of our read and each permuted reference string is the same as the distance between the original read and the corresponding original reference string. in particular, the number of mismatches between the permuted read y and the permuted version of the true nearest neighbor xi is still p, and the permuted version of the true nearest neighbors is the true nearest neighbor of the permuted read. if we are "lucky" enough, we happen to move the p mismatches to positions that are "far enough" from the beginning of the string. based on observation  <dig>  if the positions are "far enough," the search for the lexicographical position of the read leads us to the "neighborhood" of the "true nearest neighbor." formal definitions of "neighborhoods" are presented below.

we do not know in advance which characters to "push" to the end of the string and we cannot expect to always be "lucky" enough to permute the correct characters away from the beginning. instead, for each read that we receive, we repeat the procedure described above several times, using a different random permutation each time. consequently, we have a high probability of finding the true nearest neighbor in at least one of the repetitions.

this procedure uses sorted arrays of permuted strings to define and search for "neighborhoods." different versions of the algorithm use other data structures, such as prefix-trees of permuted strings.

to illustrate what permutations do, we generated a random "reference genome" of length n =  <dig>  and built a library of all substrings of length  <dig>  in this example, we consider the read y = cttgccaaagccatg, which should be mapped to the location  <dig>  where x <dig> = ctcgccaaagccatg.

we attempt to look for a match to y in the sorted library. since the mismatch occurred "early" in the read, our search takes us to a distant position in the sorted array and we do not find x <dig> there. the correct neighborhood of x <dig> is presented in table  <dig> 

if we permute y using the code π: , the mismatch in position  <dig> is permuted to the 13th position: y = π = ctaaaggcccgttac. when we look for y, we find the permuted version of x <dig>  which is x <dig> = π  = ctaaaggcccgtcac. the lexicographical neighborhood of π  is presented in table  <dig> 

if we use the same permutation and the mismatch occurs in a different position, we may not find x <dig>  in fact, if the mismatch occurs in position  <dig>  it becomes a mismatch in the first character of the permuted string. therefore, we use several randomly chosen permutations to reduce the probability of failure. when we use long strings and random permutations, the probability of error drops rapidly as the number of iterations grows.

a more formal description of the algorithm
we now describe the algorithm more formally. first, we describe an indexing procedure . then we describe the search for candidate neighbors . finally, we describe an approach to filtering the proposed neighbors and finding the best one .

part 1: indexes
create a collection of random permutation schemes {π}.

for each permutation π:

use π to permute all the original reference strings.

build a sorted array ar of the permuted reference strings.

store permutation π and index ar for use in part  <dig> 

end for.

part 2: lists of candidates
for each read y :

initialize candidates = ∅.

randomly choose j of the random permutations.

for each chosen permutation:

calculate y = π, the permuted version of y .

find the lexicographical position of y in ar.

add the lexicographical neighborhood of y to candidates.

end for.

end for.

part 3: filter
for each read y :

for every candidate )

calculate the hamming distance between xi and y .

keep track of the candidate string most similar to the read.

end for.

report the most similar string as the alignment of y .

end for.

"neighborhoods" of strings
in this subsection we give one of the possible definitions for a "neighborhood." we also define the terms "prefix neighborhood" and "resolution length," which we use in the analysis.

we define a neighborhood size k > <dig>  which is an order of magnitude of the number of strings that we compare to the read in each iteration.

suppose that we are looking for the string y in a sorted array of reference strings.

definition  <dig> if k is the lexicographical position of the string y in a sorted array of strings, then the "neighborhood" of y is defined as the list of strings in positions k - k to k + k in the sorted array.

definition  <dig> the "prefix neighborhood of length l" of the string y is the list of all strings that have the same l-long prefix as the string y .

definition  <dig> given a string x, we define the "resolution length"  as the smallest value such that the l-long prefix of x is the prefix of no more than k strings in the library.

analysis
in this subsection, we discuss the probability of obtaining the "true nearest neighbor" for a read. we denote the number of mismatches between the read and the true nearest neighbor by p.

we assume a constant value of "resolution length" for the true nearest neighbor across the different permutations used. we denote it by l. different reads may have different true nearest neighbors with different values of l. this assumption can be relaxed in more detailed analyses of the algorithm. we assume that p <.

there are m! possible permutations for a string of m characters. the permutations that we use are chosen randomly from these m! possibilities with equal probabilities.

we begin by considering a single permutation and a single iteration of part  <dig> of the algorithm. by definition, if there are no mismatches in the first l characters of the permuted string, then the true nearest neighbor is in the "neighborhood" and it is added to the list of candidates in this iteration. since the "neighborhood" examined in part  <dig> of the algorithm is larger than the "prefix neighborhood of length l," some additional reference strings are added to the list of candidates. there are !! ways to place p mismatches in the  positions at the end of the string, which are not part of the l-long prefix. there are ! ways to place the  characters that have no mismatches. therefore, there are !!! "lucky" permutations, that permute the p mismatches away from the prefix. we assumed that our permutations are chosen from among all m! permutations with equal probabilities, so each of the "lucky" permutations is chosen with probability 1/m!.

therefore, the probability of "being lucky" in a single iteration, and adding the true nearest neighbor to the list of candidates is at least:

  prgoodperm=!!!m!. 

the probability for being "unlucky" in any one experiment is at most 1-prgoodperm. the permutations are chosen at random, and they are independent. therefore, the probability that at least one of the lists contains the true nearest neighbor is:

  prsuccess≥1-)j. 

in part  <dig> of the algorithm, we check all the candidates directly, so if the true nearest neighbor is in the list, we are guaranteed to report it as the the best match for the read. so, prsuccess is also the probability of reporting the correct search result.

each read has its own true nearest neighbor, therefore the value of l and the number of mismatches  varies between reads. given a distribution of l for the different reads and their "true nearest neighbors," a distribution of the number of mismatches and criteria for the desired probability of success in different cases, we set appropriate values of k and j. our experiments suggest that in practice, low values of k and j, which allow fast computation, can produce good alignment results in a wide range of scenarios.

complexity
the indexing of the reference in part  <dig> of the algorithm is a simple sorting operation which requires o) strings comparison operations for each of the indexes.

based on observations  <dig> and  <dig>  the number of strings comparison operations required by parts  <dig> and  <dig> of the algorithm is o + k)) per read.

filtration and reporting multiple possible alignments
since the algorithm evaluates multiple candidates in part  <dig>  some degree of multiple alignments analysis is a byproduct of the algorithm and the algorithm can be extended to report multiple possible alignments. this property allows us to extend the algorithm to perform the fast search required in the first step of the extended alignment framework.

an improved filtration component, the "hit-count" filter, can be used to generate a small list of candidates  and also to accelerate the algorithm. a version of the algorithm that uses "hit-counts" stores the number of times each candidate appeared in the searches in part  <dig> of the algorithm . in part  <dig> of this version, the algorithm evaluates and reports only candidates that appeared in several searches in different indexes .

memory considerations and practical indexes
large reference genomes may require multiple large indexes. it is enough to store the original reference string and the permutation rules, and it is not necessary to store all the permuted strings explicitly in the sorted arrays. it is also not necessary to store all the indexes in the ram at the same time; one can load an index, perform one iteration of part  <dig> of the algorithm for a batch of reads, and then load another index.

furthermore, each single index can be used almost as if it were multiple indexes with different permutations. to achieve this, we use a sliding window to take contiguous substrings of the reads. we permute each of these substrings and search for it in the sorted array of permuted reference strings.

RESULTS
basic alignment
we implemented a version of the algorithm in c . our permutations-based prototype implementation was used in the same three modes in all the experiments.

for the comparison presented here, we chose some of the popular programs which preform the fastest alignment to a human reference genome. we used bowtie  <cit>  as the main benchmark for performance evaluation because it is one of the fastest aligners  <cit> . we also compared the performance to bwa  <cit>  and the more recent bowtie <dig>  <cit> .

the purpose of the comparison is to demonstrate the applicability of the algorithm to a large-scale problem like aligning to a full human genome. this is not meant to be a complete comparison to all programs in all scenarios.

all the real reads were obtained from the  <dig> genomes project  <cit> . all the simulated reads were produced using wgsim  <cit> . the human genome grch <dig>  <cit>   was used as the reference. some large regions were masked with "n"s in the original reference, but other repetitive regions were not masked.

the comparison was performed on a cluster node with  e <dig> cpus and  <dig> gb ram. similar experiments of alignment to the full human genome, using low-cost  desktops with  <dig> gb and  <dig> gb ram, produced similar results. all the programs were used in single thread mode. bowtie requires about  <dig>  gb of ram, bowtie <dig> requires about  <dig>  gb and bwa requires about  <dig>  gb. the permutations-based prototype implementation requires about  <dig> gb of ram for the full human genome .

in figure  <dig> we compare the best alignments obtained by bowtie and the permutations-based prototype. in certain settings, bowtie found alignments with fewer mismatches for some reads. for example, "bowtie -v 3" found alignments with up to  <dig> mismatches for about  <dig> % more reads . the permutations-based prototype found more alignments for reads with a large number of mismatches than all the modes which we tested in this experiment , and found more alignments with a low number of mismatches than some modes of bowtie .

in table  <dig> we compare the search times of bowtie, bowtie <dig>  bwa and the permutations-based prototype in alignment of real reads. the different programs have different criteria for reporting, and the permutations-based prototype usually generates more possible alignments, so the number of alignments would be misleading and it is not reported in the tables.

each dataset contained  <dig> reads from the fastq files obtained from the " <dig> genomes" project.

we also simulated reads to measure how many of the reads are aligned to the "correct original location in the genome." in some cases, there may be several equally probable alignments and in some cases the "best" alignment with the fewest mismatches may be different than the "correct location." ideally, the alignment program should report both the "best" alignment and other possibilities that could be the "correct" alignment. the results of this experiment are presented in figure  <dig> and table  <dig>  in most cases, the permutations-based prototype was faster than bowtie, bowtie <dig> and bwa and produced more correct alignments to the correct "original location" than all other programs.

bowtie
bowtie
bowtie
bowtie
bowtie
bowtie2
bowtie2
bowtie2
bowtie2
bowtie2
bwa
bwa
permutations-based
permutations-based
permutations-based
each dataset contained  <dig> reads. mutation rate:  <dig> %, indel ratio: 15%.

we report the search time  and the percent of the reads which were aligned to the correct position in the genome.

in some cases and in some settings, the programs may report several possible alignments for some reads. when needed, additional filtering can be added to aligners in order to eliminate some of the results, as appropriate for specific applications. in the experiment, the programs reported < <dig> alignments/read , with 0- <dig> alignments for the majority of reads. in this table, when the program produces multiple possible alignments, it is enough that one of the reported alignments corresponds to the correct location in order to consider the alignment correct.

alignment of paired-end reads, in the presence of indels
one common variation in the alignment scenario we described is the use of a different type of distance: "edit distance." strings may be close in "edit distance" even in the presence of indels, although the indels are likely to make the strings far apart in hamming distance.

another common variation in the scenario is the availability of "paired-end reads": reads are presented in pairs, in which both reads are known to have originated from nearby areas in the genome. in this case, we are required to find nearest neighbors for both strings, subject to some constraint on the distance between the locations in the reference genome.

a modified version of our prototype performs paired-end alignment in the presence of indels. we first align each of the reads in the pair separately. then, for each "reasonable" candidate found for one of the reads, we restrict our attention to the area of the reference genome around that candidate, and attempt to align substrings of the other read to that area.

since bowtie does not allow indels, we used bowtie <dig>  <cit>  and bwa  <cit>  as benchmarks. all the programs were used in single thread mode. this version of the prototype requires about  <dig> gb of ram for the alignment of paired-end reads to a human genome. bowtie requires about  <dig>  gb of ram, bowtie <dig> requires about  <dig>  gb and bwa requires about  <dig>  gb.

in table  <dig> we compare the search times of bowtie, bowtie <dig>  bwa and the permutations-based prototype implementation in paired-end alignment of real reads.

each dataset contained  <dig> pairs of reads from the fastq files obtained from the " <dig> genomes" website. search times are reported.

in figure  <dig> and table  <dig> we present the results of aligning simulated pairs of reads with indels. the permutations-based prototype was faster than the other programs and usually produced more correct alignments when there were few indels. the permutations-based prototype was also able to align reads with higher indel rates almost as well as the best performing benchmark program, but significantly faster.

bowtie
bowtie
bowtie
bowtie
bowtie
bowtie2
bowtie2
bowtie2
bowtie2
bwa
bwa
permutations-based
permutations-based
the "low indel probability" datasets were generated with mutation rate:  <dig> %, and indel ratio: 15%. the "high indel probability" datasets were generated with mutation rate:  <dig> % and indel ratio: 100%. each of the datasets contains  <dig> pairs of  <dig> character-long reads.

for each dataset and each program, we report the search time  and the percent of the reads which were aligned to the correct position in the genome.

in some cases and in some settings, the programs may report several possible alignments for some reads. when needed, additional filtering can be added to aligners in order to eliminate some of the results, as appropriate for specific applications. in the experiment, the programs reported < <dig> alignments/read , with 0- <dig> alignments for the majority of reads. in this table, when the program produces multiple possible alignments, it is enough that one of the reported alignments corresponds to the correct location in order to consider the alignment correct.

CONCLUSIONS
an algorithm has been constructed for the fast alignment of dna reads to a reference genome. the algorithm handles mismatches by design, and it has been demonstrated that it can be extended to allow some inserts and deletions in some cases of practical interest.

the algorithm has been implemented and compared to existing programs. our experiments indicate that the algorithm can produce alignments comparable to those generated by existing fast alignment algorithms, often aligning more reads with a significant speed increase. future implementations of the algorithm are expected to be faster and more efficient, sensitive and accurate.

the permutations-based prototype implementation requires  <dig> gb of ram for the alignment of reads to a human genome . some existing programs require significantly less memory. however, the amount of memory required by this implementation is available in low cost computers, and other versions of the algorithm utilize memory more efficiently.

our current implementation of the algorithm is not a complete software package and does not replace existing software packages. this prototype implementation demonstrates how the proposed algorithm can be used to enhance existing software packages and to build new software packages.

the scope of this discussion is limited to the basic problem of fast alignment to large genomes. separate work on this class of algorithms indicates that the algorithms can also be used for very fast alignment of long  <dig> and ion torrent reads which may have many indels. other work indicates that these algorithms can be used for other applications, such as assembly. additional preliminary results and technical reports are available at http://alignment.commons.yale.edu.

competing interests
the author developed patent-pending methods for processing in sequencing.

