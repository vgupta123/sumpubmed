BACKGROUND
gene ontology in annotation and analysis
the abundance of genome-scale data across the many species and biological contexts of interest to modern molecular biology and genetics has created substantial problems for data interoperation and integrated analysis, particularly when the creation and analysis of these data is highly distributed. likewise, the rate of discovery in molecular genetics has accelerated rapidly, due in no small measure to new high-throughput genome-scale technologies and automation. capturing new knowledge as annotation, and making it easily accessible to other research groups and to computational methods, will remain challenging so long as the primary storehouse of biological knowledge is natural-language statements collected in peer-reviewed scientific literature. an important way forward is through the adoption of controlled vocabularies that can be used to annotate collections of biological entities with statements that reflect the current state of biological knowledge about those entities. controlled vocabularies, or ontologies, establish precise, agreed-upon definitions for terms, and establish the context in which those terms may be used. in this way ontologies facilitate the reuse and exchange of knowledge by researchers, and enable the broader application of computational methods over a vocabulary vastly reduced from that of natural language.

the most widely adopted of these controlled vocabularies is the gene ontology   <cit> . go covers knowledge about the molecular function of gene products, the biological processes in which they are active, and the cellular component in which they function or reside. by coupling go terms with gene-product identifiers, the annotation process associates biological information with identifiers in formally defined machine-readable formats and thus enables the exchange, analysis and re-use of biological knowledge.

the gene ontology consortium, which is responsible for the ongoing development of go, draws its members from a number of organism-specific databases including flybase  <cit> , mouse genome database  <cit> , wormbase  <cit> , the arabidopsis information resource  <cit> , and the zebrafish information network  <cit> . these consortium members, and others such as the gene ontology annotation database  <cit> , produce go annotations for public use. this community structure has contributed to the broad acceptance and adoption of go as the primary controlled vocabulary for molecular genetics and genomics.

go is commonly represented as a tree-like hierarchy of terms, in which each term can have child terms that are more-specific subclasses of the parent class. in fact, the go hierarchy is a directed acyclic graph  rather than a tree, as a go term can have multiple parents. indeed, because go covers three domains of knowledge and relationships are defined only within each knowledge type, go is in fact three distinct, non-overlapping dags identified by their respective namespaces: biological_process , molecular_function , and cellular_component .

information about the cellular biological context of a gene product  is extremely valuable, and go annotations are used in a wide variety of domains and applications. for example, go terms are commonly used to identify biological processes or molecular functions over- or under-expressed in different cell types, developmental states or disease conditions  <cit> , identify likely false positives  <cit> , evaluate predictive methods  <cit> , and examine whether genes of like function are clustered along the genome  <cit> . the success of go in these and many other contexts relies on the quality and currency of its annotation, and considerable resources must be invested by researchers and communities into its ongoing manual development and curation. even with substantial coordination across these activities, equivalent parts of the go graph end up being developed to very different degrees of resolution and detail.

the wide adoption of go has contributed to the proliferation of terms within it, and as of april  <dig> go contained  <dig> terms for biological processes,  <dig> for molecular functions and  <dig> for cellular components, excluding obsoletes. its size contributes to its broad applicability, but makes it difficult for users to select go terms for annotation, or to compare and analyse data annotated with go terms. the hierarchical structure of go establishes transitive relationships between terms: for any gene product annotated with a term, annotation with all the parents of that term, back to the root, must also be biologically sound. this property has been exploited to create smaller, more-manageable subsets of go, called go slims, that focus on terms relevant to a specific problem or data set. these go slims can then be used to generate higher-level annotation more robust to tests of statistical significance  <cit> .

a number of projects have created go slims, seven of which are currently maintained by the go consortium http://www.geneontology.org/go.slims.shtml. two of these are general go slims  go slim  <cit> ), while four are domain-specific  and one is specific to the protein information resource http://pir.georgetown.edu/. other go subsets that have been archived but are not maintained include organism-specific slims for the honey bee apis mellifera, the fruit fly drosophila melanogaster, the malarial parasite plasmodium falciparum and rice oryza sativa. tools exist for mapping between go-slim sets and full go annotation, such as the map2slim application http://search.cpan.org/~cmungall/go-perl/ for which several web-based implementations exist .

efforts have been made to automate or semi-automate the creation of go subsets. the obo edit application provides a graphical browser that can be used to mark terms for inclusion in a go slim and check that complete paths exist between the selected terms and the root term of each graph. a taxonomy-based method has been developed to create species-specific subsets of go  <cit> , although it is not extensible to slim creation in general. to the best of our knowledge, however, no automated tool support currently exists for the creation of go slims. in this paper we introduce a general approach, based on ontology management principles, graph theory and information theory, for the automated generation of ontology slims based on information obtained from both annotations and the ontology structure, and we illustrate the application of this method to the generation of high-quality go slims at a series of information content thresholds. this framework also includes annotation management and semantic synchronisation features that reduce information lost as data lose currency and terms become obsolete.

graph and information theory as applied to go
while go may be thought of as a hierarchically ordered controlled vocabulary, it is topologically a directed acyclic graph . go terms form the nodes  in this graph, and relationships between terms form the edges. directionality on the edges is established by the is_a and part_of relations that are transitive in nature, and establish more-specific terms as sub-classes of more-general terms, and progressively group information up the hierarchy to the root term of each graph: biological_process , cellular_component , and molecular_function  respectively. of the two relationship types, is_a relationships establish conceptual subclass-superclass relationships between terms, while part_of relationships establish a subset-superset relationship. this information is contained in the graph structure itself, while additional information is contained in the gene-product annotations.

the creation of go slims, therefore, must carefully reduce the information loss, from the perspectives of both graph structure and gene-product annotation. information content can be computed from the distribution of go terms in annotated datasets, from the structured relationships between go terms in the ontology itself, or from both sources in combination. for example, wang et al.  <cit>  used semantic similarities of go terms to find functional similarities of genes by introducing weights for the different relations, while tao et al.  <cit>  introduced semantic similarity for gene-function prediction based on the node's location and semantic relationships  <cit> . other approaches have also been based on topological measures of similarity, such as the shortest path between terms, to determine similarity between go terms  <cit> .

resnik  <cit>  developed an information theoretic measure of similarity based on the probabilities of co-occurring terms in a set of instance data , in order to avoid the unreliability of topology alone in calculating term similarity. similarly, using information available from annotated gene product datasets, del pozo and colleagues  <cit>  introduced a go similarity measure based on the simultaneous occurrence of go terms in a curated dataset from interpro  <cit> .

thus although both graph theory and information theory have been explored to gain biological insight from datasets annotated using go, and a number of go slims have been created and are being maintained for use by research communities, to the best of our knowledge no tool support currently exists for the automatic generation of go slims. here we introduce such a method that can generate customised go slims for specific annotated datasets. our method finds an optimal reduced go graph by penalising graph complexity, while at the same time minimising information loss  by retaining terms with high information-content values. we compute the information content of a term based both on its position in the go dag and on the gene-product annotations associated with it in a given annotated dataset, while taking into account the information lost if the term is removed. in this our method differs from classical information-theoretic approaches that compute information content without reference to graph structure  <cit> .

RESULTS
go slim for yeast
here we analyse a set of go slims generated across a range of information content thresholds on the yeast go annotation contained in the sgd database  <cit> , and compare them with the manually created yeast go slim maintained by the yeast community. we examine the composition of slims created by our method over a range of information thresholds, and finally we examine the improvements in statistical power that result from conducting functional enrichment analysis based on go slim terms compared with full go annotation.

as expected, when examining go slims generated at a range of thresholds, we observe that progressively raising the information content threshold yields slim ontologies of reduced complexity, with fewer terms included in the slim subset . selection of an optimal threshold for creating a slim will depend on the intended use of that slim, and on the level of resolution desired in the resulting go slim file. the frequency of information content values i obtained for the input terms can provide some guide to selecting an appropriate value for the threshold, τ. for example, figure  <dig> shows the frequency distribution of i for the go cc terms in the yeast dataset. most have values between  <dig>  and  <dig> , while table  <dig> shows that the number of terms selected becomes relatively stable for values over  <dig>  because few terms hold values of i over this threshold.

ic threshold
above thresholds of  <dig> , the size of the go slim subset changes little.

in additional files  <dig>   <dig> and  <dig>  we provide full mappings between annotation terms and selected slim terms for three values of τ:  <dig> ,  <dig>  and  <dig> . to illustrate the performance of the method at these thresholds, here we examine in detail the mapping of terms within the top level of the bp namespace ), focusing on the descendents of response to stimulus  at each threshold . this example highlights the trade-off between reducing the complexity of the go slim graph, and maintaining detail in the associated annotation.

it is noteworthy that using our approach and scripts, slims are automatically generated for the yeast dataset in less than a minute on a standard system , 2x  <dig> mhz vcpus, 1gb ram). with this speed of execution, researchers can easily experiment with a range of τ values to achieve their desired level of resolution and conceptual depth.

response to stimulus has  <dig> descendents in the go slim generated using τ =  <dig>  , nine descendents at τ =  <dig>  , and five at τ =  <dig>  . the descendent count for response to stimulus then remains stable between  <dig> - <dig>  as child term dna repair has a information content of  <dig> . gene products annotated with specific terms not included in the slim are collapsed upward to the most-specific terms retained. thus a term originally annotated with go: <dig>  would retain this annotation if mapped to a slim generated at τ =  <dig> , would be collapsed to the term go: <dig>  at τ =  <dig> , and would be collapsed to go: <dig>  at τ =  <dig> - <dig> .

biological process, which has  <dig> immediate children in the full ontology, has  <dig> immediate children at τ =  <dig>  ,  <dig> at τ =  <dig>  , and  <dig> at τ =  <dig>   and five at τ =  <dig> . progressive loss of immediate children of biological_process results in an increasing number of terms being mapped back to the root node: while only  <dig> terms are collapsed non-specifically to the root node at the lower threshold,  <dig> terms are collapsed to the root node at τ =  <dig> , and  <dig> at τ =  <dig>  . this illustrates the loss of resolution inherent in creation of small, high-level go subsets. while gene products whose go annotations are collapsed to the root node lose their detailed annotation, annotation with the root node label at least retains the association of the gene product with a known  biological process. the extent of collapse can be prioritised on the basis of an information-content calculation and is therefore an objective, rather than subjective, process. finally, the outcome is repeatable, not dependent on the vagaries of individual or collective human decisions.

comparison of results with manually produced go slim
we compared the go slims generated by applying our automated method on the sgd protein annotations to the one produced manually by curators associated with the sgd database, to explore the extent to which our process retrieves terms considered important by human experts. the sgd yeast go slim  is made available to the community through the gene ontology consortium website as one of the set of go slims maintained at http://cvsweb.geneontology.org/cgi-bin/cvsweb.cgi/go/go_slims/ and includes  <dig> terms. our slims range in size from  <dig> to  <dig> terms . we present the results of this comparison over a range of information content thresholds in figure  <dig> 

the maximum overlap between the subsets is found at the lowest threshold value , where all but one goslim_yeast term is included. the missing term, spindle envelope , is not included in our subset because it is not used to annotate any gene product in the set of yeast proteins from sgd. at progressively higher values of τ fewer overlapping terms are observed; the proportion of overlapping terms, computed as a proportion of total terms in our go slim, peaks at ~22% at τ =  <dig> .

while our automatically generated go slims never achieve full overlap with the manually created subset, we contend that this is due to bias in the selection of terms by human curators. for example, no term exists in the sgd yeast go slim corresponding to the cc concept integral to membrane  despite the fact that around one quarter of all yeast proteins are likely to be integral to a membrane  <cit> , and >  <dig> sgd proteins are annotated with this term. integral to membrane has functional implications distinct from those of the parent term membrane , which is included in both slims. likewise, the molecular function term atp binding  is used to annotate >  <dig> yeast proteins, but is absent from the yeast slim. terms such as protein complex biogenesis , cellular component morphogenesis  and generation of precursor metabolites and energy  that are present in the yeast_slim, but are either not used to annotate gene products, or used only once, will not appear in our objectively defined slims, or will appear  only at the most permissive of thresholds.

case study: functional enrichment analysis
to evaluate how effectively our method improves the clarity of functional enrichment analysis, we use the hypergeometric test as previously applied  <cit>  to identify go terms significantly enriched in a set of differentially expressed genes identified through microarray profiling of yeast sporulation  <cit> . the sgd expression connection interface was used to retrieve  <dig> genes with greater than a five-fold increase in expression during yeast sporulation. the genes were mapped to sgd accession numbers, and  <dig> unambiguously mapped genes and associated gene ontology annotations are available in additional file  <dig> 

because many go terms occur in the gene lists and each term is tested individually, multiple hypothesis testing  correction methods such as the bonferroni method  <cit>  or benjamini-hochberg false discovery rate  correction  <cit>  should be applied. here we compare the results of the hypergeometric test before and after mapping genes in the list to a go slim generated at τ =  <dig>  for that experiment. in this sporulation experiment,  <dig> genes have go annotations of biological process, as do  <dig> of the  <dig> genes identified in our expression connection search. while  <dig> go bp terms were used to annotate the full set of yeast gene products, after mapping to the τ =  <dig>  go slim, only  <dig> go bp terms are required.

the p-values for equivalently ranked go terms are presented in table  <dig>  and demonstrate the benefit of reducing the number of hypotheses  tested.

rank order according
these results demonstrate that application of our method at τ =  <dig>  decreases the bonferroni correction by nearly ten-fold: using the full go annotation set, p-values are multiplied by  <dig>  while using our go slim, p-values are multiplied by only  <dig>  with the more-permissive benjamini-hochberg correction, only the first  <dig> terms  from the full go annotation tests retain significance after correction, compared with  <dig> terms from the go slim. balanced against this increased statistical power is the reduced detail available from the terms that remain. in this example, terms covering mitotic spindle elongation and mitotic sister chromatid segregation were found to be significant in the full annotation set, but were collapsed to mitotic cell cycle in the go slim.

availability
this method has been implemented as a computational pipeline and is available for download from the tools and data page at http://bioinformatics.org.au. example data and a user's guide are included with this download.

discussion
we have introduced a method, based on graph and information theory, for the automatic generation of ontology subsets . given an ontology and a particular set of annotations generated using that ontology, ontology slims optimally matched to those terms can be generated at any permissible threshold of information content. our method has potential to supplement, or indeed replace, the laborious, error-prone and sometimes idiosyncratic manual creation and curation of ontology slims for specific species, problems or research areas.

our method maximises the information content available in the resulting slim, while minimising its size. our node information content metric, in, incorporates information from both the graph structure and the annotated data. existing methods are unsuited for calculating information content relevant to ontology-subset selection; shannon's mutual information, for example, considers conditional dependency of nodes but not graph complexity. it was our intention to construct slims that concomitantly minimise both information loss  and the number of terms used. likewise, methods that calculate the information of terms based only on graph structure neglect the context-specific information contributed by specific sets of annotated gene products, and as such are unsuitable for creating ontology subsets specific to a given biological dataset.

our approach begins with an annotation processing phase in which we update the annotation file by identifying and resolving inconsistencies between the annotation and the current version of the go. inconsistent terms that can be clearly mapped to a new term in the ontology are updated, while annotations using terms entirely removed from the ontology, or without clear successors, are removed to a separate file for manual resolution. this process ensures that information contributed by old annotations is preserved and updated, and removed only if corresponding concepts no longer have equivalents in the current go. these pre-processing methods are of broader applicability, for example in updating historical annotation datasets, or automatically preserving currency in existing annotated datasets.

our method for creating go slims is automatic and fast, generating slims that are complete , well-formed , and objectively constituted . these desirable properties are not necessarily shared by manually curated slims, as illustrated by our analysis of goslim_yeast. our information-content metric takes into account both graph structure and annotation, and as a consequence annotation is preserved at hierarchical levels such that information content is maximised across the entire annotation set. all gene products are guaranteed to map to a term in the slim, although in the worst  case this may be the root term of a namespace. these properties enable users to balance generality against specificity, tuning the slim to a granularity appropriate for each individual problem or application.

using this approach, small groups or individuals can create and maintain high-quality customised ontology slims, and keep these slims up to date with respect to emerging gene-product datasets and the most recent version of go. presently, the lack of tool support available for go slim construction means that the process of creating and maintaining a go slim is arduous, and while many slims are created, fewer are maintained . these custom slims preserve relationship types , and can be flexibly tailored to storage or computational resources. like other slims, our custom slims offer greater statistical power than full ontologies, as a reduction in the number of hypotheses lessens the impact of mht correction.

although here we illustrate our method only in application to go, it is directly applicable to any ontology presented in the open biomedical ontology  format. many ontologies are available in this format, covering such areas as organismal anatomy, taxonomy, mass spectrometry and chemical entities. a list of obo ontologies is available at http://www.obofoundry.org/. our method is more-generally applicable to any ontology with a dag structure, and for which the relations between terms are transitive and a corresponding annotated dataset exists. the speed of the method over go also indicates that our approach will support the generation of slims from ontologies much larger than go.

CONCLUSIONS
our ontology-engineering method enables researchers to create and maintain an automatically generated go slim for a specific dataset of interest. to select informative terms objectively, we have developed a new information contents metric that combines information contained in the go structure with that obtained from annotated datasets. by removing the time consuming and subjective ontology editing procedure previously required for the creation of a go slim , a significant barrier to the use of engineered go subsets is removed.

