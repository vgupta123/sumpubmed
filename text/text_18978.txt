BACKGROUND
sequencing platforms such as the  <dig> life sciences gs-flx  <cit>  and illumina  <cit>  are providing a previously unprecedented insight into the extent of pathogen variation  <cit> . this is due to the depth of coverage that can be obtained across individual genes or genomes  <cit> , as well as the ability to analyze large numbers of samples simultaneously  <cit> . within chronic viral infections, such as hiv- <dig> and hcv, the study of variation is important as it has been directly associated with both disease progression and the outcome of treatment  <cit> . these sequencing platforms have the potential to accurately quantify the variation within viral populations  <cit> , including those sampled through time  <cit> , and from differing compartments within the host  <cit> , thus, providing a more complete picture of viral evolution. this has applications for the development of treatment strategies that are both reactive and predictive. reactive in that the information derived from individual hosts can be incorporated into the optimization of current drug treatment regimes  <cit> . predictive in that the likelihood of the emergence of resistant variants can be calculated and incorporated into strategies such as the algorithmic design of therapeutic vaccines  <cit> .

however, prior to the practical and routine application of current sequencing technologies to the characterization of patterns of variation, a number of non-trivial challenges need to be overcome  <cit> . primarily this involves the detection of error introduced during sequencing  <cit> , and the separation of this from real genetic variation. this issue is particularly acute for rna viruses within an individual host for which the degree of genetic variation may be on the same order as the error rate. the extent and nature of sequencing error varies between platforms  <cit> . for example, the  <dig> technology utilizes a sequencing by-synthesis method during which the incorporation of cyclically delivered nucleotides into the growing dna strand, via pyrophosphate liberation, is measured  <cit> . in regions where the complement strand contains a homopolymeric stretch, the strength of the signal is proportional to the number of bases incorporated. ambiguities in signal intensity are most frequently manifested as under- and over-calls on the length of these stretches  <cit> . an overall error rate of about 1% has been observed  <cit>  which has been partitioned into insertion , deletion  and mismatch error . unlike the  <dig> platform, sequences generated on the illumina platform are extended one base at a time  <cit> , thus, under- and over-calls are uncommon. mismatch error, however, has been observed  <cit> , and, because of the high coverage that is achievable, the quantification of the rate at which this error occurs is particularly relevant when attempting to identify low frequency genetic variants.

the development of an accurate, dynamic picture of viral evolution within the host has also been hampered by the logistics of data management. the many mapping, assembly and analysis programs available  <cit>  primarily have the goal of obtaining an accurate estimate of a genomic sequence or detecting variation at the allelic level. other commercially available packages such as geneius  <cit>  and clc genomics workbench http://www.clcbio.com/, that do offer tools to analyze sequence variability, have limited capacity to account for temporally sampled viral data. at the time of writing no freely available, generally applicable software exists that addresses the task of detecting and characterizing the high levels of genetic variation encountered within rapidly evolving viral populations using data that has either been temporally or compartmentally sampled. prior to our current work we presented a framework, for the mapping of the short sequence segments  generated on the  <dig> platform, which was applied to the detection of clusters of low frequency drug resistant forms  <cit> . here we extend this framework so that it  is applicable to viral data generated on the illumina platform ,  outputs a range of metrics for characterizing variability including base, indel and codon frequencies, coverage and quality scores and  allows for multiple data sets to be managed within a project permitting comparative analysis. to demonstrate the usefulness of our software we assess platform-induced variation present within reads derived from  <dig> influenza a h1n1/ <dig> infected individuals. for each individual, because the same sample was used for read amplification on both the  <dig> and illumina platforms, any variation associated solely with a single platform can be considered as potential sequencing error. h1n <dig> genomes are particularly useful for characterizing insertion and deletion error that has been introduced by the sequencing platform because indels are rare in this data  <cit> .

implementation
implemented in java the software, segminator ii, along with the source code, is available from http://www.bioinf.manchester.ac.uk/segminator/. a graphical user interface  resides on top of an underlying data management framework providing convenient access to the main features of the software. components of the framework can be incorporated within automated bioinformatics pipelines through direct use of the core package . within the framework individual reads are stored post-mapping as lists of polymorphisms in relation to a user-defined reference sequence . as a consequence the majority of characters that are identical to the template, representing redundant information, do not need to be stored. selection of a reference sequence that is proximal to the data set is, therefore, important not only for improved mapping  <cit> , but also for the reduction in the quantity of information that needs to be stored. the storage of polymorphic characters in this manner allows for the efficient extraction of data from the assembly. for example, reads themselves spanning a particular location of the template can be quickly reconstructed either  with all insertions in relation to the template removed, thus, maintaining site compatibility between reads or  in its original format, where the read start location is maintained but inter-read compatibility between individual sites is not guaranteed. an immediate application of the former is the 'treedar' feature of the user interface  which uses pairwise distances between reads that have been aligned to the template in order to generate a rough, but dynamically generated, phylogenetic tree as the user scrolls along the virus genome. this tree can be used to rapidly identify regions of the genome with divergent portions of sequence space prior to the localized application of full phylogenetic reconstruction techniques. additionally access to information pertaining to the classification of variation at individual sites , along with associated quality scores, is made possible without the need to reconstruct complete alignments.

prior to read storage and variant detection individual reads in fastq format, are required to be mapped to the template sequence. this is performed using a combination of k-mer matching and pairwise alignment . through the user interface multiple data sets may be linked to the same template sequence. setting up a project with its associated template sequence does this as subsequent data sets added to the project are then mapped to the associated template. if the user is concerned about failing to map reads because of divergence from the template, which is especially relevant to rapidly evolving viral genomes such as hiv- <dig>  <cit> , there is a parameter  that when set to true, will take a consensus at each site of the template after the first mapping and then remap reads to this consensus sequence. a full description of the features of the user interface, as well as the parameters used, is available on the website. to demonstrate the usage of our framework we have applied it in a case study to  <dig> h1n <dig> data sets derived from samples sequenced on both the  <dig> and illumina platforms.

case study: data sets
nasal swabs were taken from individuals within the uk presenting with pandemic h1n1/ <dig>  virus genome rna was extracted from these swabs using standard methods. influenza genomes were rt-pcr amplified using the method based on  <cit> . reactions were performed in a volume of  <dig> μl under an overlay of  <dig> μl vapor-lock , and contained  <dig>  μl of rna isolated from clinical material, and final concentrations of 1× superscript® iii one-step rt-pcr reaction buffer,  <dig>  μm each primer and  <dig>  μl superscript® iii rt/platinum® taq high fidelity enzyme mix. thermal cycling conditions were: reverse transcription at 42°c for  <dig> minutes, 55°c for  <dig> minutes, 60°c for  <dig> minutes; initial denaturation/enzyme activation of 94°c for  <dig> minutes; five cycles of 94°c for  <dig> seconds, 45°c for  <dig> seconds, slow ramp  to 68°c, 68°c for  <dig> minutes;  <dig> cycles 94°c for  <dig> seconds, 57°c for  <dig> seconds, 68°c for  <dig> minutes; and final extension of 68°c for  <dig> min. rt-pcr products were used to generated multiplex identifier  tagged libraries for  <dig>  or illumina  sequencing, according to the manufacturers' instructions.  <dig> sequencing was performed on the genome sequencer flx system. illumina sequencing was performed on the genome analyzer i system with  <dig> bp paired-end reads. in total there were  <dig> data sets,  <dig> from each platform. the number of reads available for each data set prior to mapping ranged from  <dig>  to  <dig> , <dig> for the illumina platform, and from  <dig>  to  <dig>  for the  <dig> platform . these are available in fastq format from our website.

unmapped and mapped reads

case study: template creation, mapping and alignment
to construct a reference sequence, for each genomic segment of the h1n <dig> genome, a sample of data-all available full length us sequences-were downloaded from genbank http://www.ncbi.nlm.nih.gov/genbank/, aligned using muscle  <cit>  and a consensus sequence generated. the number of sequences included for each gene was: pb2:  <dig>  pb1:  <dig>  pa:  <dig>  ha:  <dig>  np:  <dig>  na:  <dig>  mp:  <dig> and ns:  <dig>  consensus sequences from each were concatenated together to produce a genome length template of length  <dig>  nucleotides. at each concatenation point, a string of ns was incorporated in order to separate the segments for visualization purposes; these were ignored in the read mapping. for each of the  <dig> samples, reads from both platforms were separately mapped to the template using our framework , following which a data set specific consensus sequence was generated by maintaining the most frequent residue present at each site. reads were then remapped and aligned to the consensus sequence, which resulted in the final assemblies used in downstream analysis. the parameters for the k-mer matching step were k-mer length, k-mer density  and k-mer skip ; the values set for these were  <dig>   <dig> and  <dig>  respectively. note, for conserved data the speed of the mapping can be increased using the skip parameter as searching every k-mer to find the approximate location of a read leads to redundancy. for the pairwise alignment step the parameters were: match, gap open and gap extension scores as well as the value for transversions and transitions with the values:  <dig>  - <dig>  - <dig> ,  <dig> and  <dig>  respectively.

case study: 
RESULTS
the number of successfully mapped reads from each sample is presented in table  <dig>  for each data set, following pooling of the data by platform, genomic coverage was calculated . the median length of the reads within the combined  <dig> data sets was  <dig> nucleotides , which varied only slightly within individual data sets . reads from the illumina platform were all of length  <dig> nucleotides. to characterize the general diversity present within our  <dig> samples the per-site entropy was calculated across data pooled according to platform using the standard shannon entropy measure. for comparison, per-site entropy was also calculated within the sample of genbank data used during the generation of the reference sequences. for both platforms the entropy present  was observed to be higher than that within the database data  , thus, highlighting the need to characterize platform dependent variation within the read data. note, the same pattern of mutations was seen when samples were analysed individually.

the ratio between the frequency of minority variants and the population consensus at each genomic site was calculated using data sets pooled according to platform. here pooling was performed, as we were interested in characterizing differences occurring between platforms, not the explicit detection of variants within each sample. in order to identify platform-induced variation these ratios, after normalization for differences in coverage, were subtracted at each genomic site . because the same samples had been used for sequencing on both platforms, differences that deviate from zero are indicative of platform specific variation, with positive values indicating variation unique to the  <dig> platform and vice versa. when ratios obtained from each platform are compared, the extent of platform dependent variation is highlighted . the median for insertions and deletions within the data generated on the  <dig> platform, at  <dig>  and  <dig> , respectively, were significantly higher  than those from insertions and deletions within the data generated on the illumina platform . for mismatches, the median rate obtained on the  <dig> platform, at  <dig> , was very similar to that observed with the illumina data . when sites are divided into two categories:  those that are part of a homopolymeric stretch of length three or more  and  those that are outside of these regions , the  <dig> platform shows significantly higher variation occurring within the hps+ category . for insertions, deletions and mismatches the median within the hps+ sites were  <dig> ,  <dig>  and  <dig> , respectively, while outside of these regions the medians were  <dig> ,  <dig>  and  <dig> , respectively. despite the far higher coverage, data from the illumina platform contained very few insertions and deletions, and no difference between hps+ and hps- was observed.

on mapping change from a consensus to a minority variant at sites on the template to locations on the underlying reads it was observed that within the  <dig> data, with the exception of the very start of the reads, there is a relatively uniform distribution across the read length, following a random expectation . for deletions the single peak, at location  <dig>   was attributed to a homopolymeric run of five cytosine's at position  <dig> of the mp segment and another of four adenine's at the same position of the pa segment. when sites on the template were limited to those that were outside of hps+ regions of length four or more this peak was removed . given that genome defined hps+ regions explains the majority of platform-induced variation this uniform trend is not unusual. if this trend was not present it would suggest that read location plays a significant role in the introduction of variation, but, after taking the hps+ regions into account, there is little variation left to explain. for the illumina data there is a non-linear relationship between read location and observed variability . here however it should be noted that for insertions and deletions the overall rates are two orders of magnitude less than in their  <dig> counterparts, again, reflecting the robustness of the illumina platform to the introduction of erroneous indels.

the proportion of nucleotide sites across each patient that contain differences to the consensus was calculated . although the underlying rates for mismatches are similar between both platforms the illumina data contains far more sites harboring low-level variation. this is a result of the characteristically much higher levels of coverage obtained from this platform. the proportion of sites across the template that contained variability unique to one of the platforms was then plotted against a range of threshold values that defined the extent of variation allowed between platforms before a site was considered to be in disagreement . threshold values were based on percentiles across the distribution of rate differences . for example, at the threshold value of  <dig> any values between  <dig> plus or minus the 30th percentile value of rate differences was considered to be in agreement, and any value outside of this range was not in agreement. intuitively as the threshold is increased the proportion of sites in agreement between both platforms is observed to increase. for the  <dig> data at low threshold levels, the proportion of sites harboring mismatches not confirmed on the illumina platform, at  <dig> , is low. however, on the illumina platform, at the same low threshold levels, the proportion of sites harboring low-level variation, not confirmed on the  <dig> platform, is  <dig> . it is only at threshold levels above the 60th percentile that both platforms start to agree with each other consistently.

both frequency and base quality are usually used as an indication of the reliability of the observed variation. to visualize the relationship between  the percent of non-consensus nucleotides at a site,  the quality of nucleotide calls, and  the number of sites verified within each individual sample on both platforms, percentiles were used to select incrementing minimum threshold values for quality and variation. for each parameter set, the number of sites across all patients with variation and quality greater than or equal to the values used for both platforms could be identified . for example, if the ith site within the data from an individual patient obtained from the  <dig> platform had both variation and quality above the selected percentile value for that platform, but the corresponding site within the illumina data fell below one or both of the illumina percentile values, the site would not be counted. alternatively if the ith site on the illumina platform also had variation and quality greater than or equal to the illumina selected percentile values then the site would be counted. thus, this provides a method of identifying variable sites containing a minimum level of variation, associated with a minimum quality, that has been cross-validated on both platforms. three examples of such site identification are depicted . an interesting feature of this topology is between the 55th and 56th quality score percentile, there is a marked decrease in the number of sites identified across all non-consensus values. on the  <dig> platform the quality values at these percentiles was  <dig> and  <dig>  respectively, while on the illumina platform the corresponding quality values were  <dig> and  <dig>  if variable sites are not validated using the illumina platform the number of sites identified within each of the  <dig> samples is consistently higher . across all  <dig> parameter pairs queried the median number of variable sites identified is  <dig>  just under three times higher than when cross-platform validation was performed  . if data from the illumina platform was used without validation from the  <dig> platform, the number of variable sites obtained is consistently higher than both previous searches since the number of sites containing low-level variation exceeds that within the  <dig> data.

discussion
here we have developed a framework for the comparison of next generation data derived from multiple sources. we have applied the framework to the comparison of platform dependent error rates present within data generated on both the  <dig> life sciences and illumina platforms. other applications include the comparison of temporally sampled data or data derived from different tissues within the host. given that novel next generation sequencing platforms and chemistries are being developed, ease of comparison of data from different sources is timely. our software permits the efficient analysis of multiple such data sets within one integrated framework. we demonstrate its usage by comparing extremely large data sets of influenza h1n <dig> samples sequenced on both the  <dig> life sciences and illumina platforms. previously we have demonstrated how phylogenetic trees can be inferred from combined time points of viral data, permitting the tracking of the emergence of distinct viral lineages associated with hiv- <dig> drug resistance forms  <cit> .

to determine the importance of characterizing the extent of platform induced variation in this study we compared the entropy present within the read data derived from the  <dig> h1n1/ <dig> samples to that of a sample of data from genbank . we observed that the median entropies obtained from reads pooled according to platform were higher than those obtained from the genbank data, thus, highlighting the importance of quantifying how much of this variation was caused by platform error, prior to the detection of genuine variants. in order to quantify this we considered any differences in variation between the data from each of the platforms as being platform dependent . following the calculation of the per site ratios between variant and consensus frequencies, it was observed that for insertions and deletions the ratios within the  <dig> data were significantly higher than their illumina counterparts . the higher ratios were strongly associated with hps+ regions , a characteristic that has been previously observed, for example, within a study designed to characterize platform error using the reverse transcriptase gene of hiv- <dig>  <cit> . this result highlights the suitability of the illumina technology for viral data sets, which is often prone to high levels of biologically relevant indels.

while mapping of low frequency variation at sites on the template to locations within the underlying reads it was observed that within the  <dig> data, with the exception of the read starts, the frequencies follow a random expectation . this is unsurprising given the observation that the majority of platform-induced variation is dependent on the location of sites in relation to hps+ regions , as defined by the genome. since these regions are located randomly in relation to the read, platform dependent variation would be expected to appear randomly with respect to read length. the major implication of this is that that error occurring at particular positions on a genome may be replicated across multiple independent samples, as has been previously observed  <cit> . it also suggests, that within the  <dig> data the genomic positioning of hps+ sites can be used to accurately predict where this error is likely to occur, and that steps can be taken to reduce its effects on data analysis, such as the removal of insertions within reads that fall with hps+ regions and that are associated with low quality scores. conversely within the data obtained from the illumina platform the distributions of indel error in relation to read location does not fall consistently within the random expectation . for this data hps+ regions were not observed to influence location. combined, this suggests that read location plays an influential role in the introduction of such error, although the levels present, especially given the far higher coverage, are extremely low.

for mismatches, ratios between consensus and variant frequencies were observed to be relatively similar on both platforms, although as a result of higher coverage many more sites within the illumina data harbored low-level change . to demonstrate the applicability of our software to data sets derived from different sources the topology generated by the number of variable sites cross-validated using both platforms, in relation to the quality of the nucleotides present was plotted . the topology follows the general trend of high non-consensus and quality score values lead to few polymorphic sites, low non-consensus and quality score thresholds lead to many polymorphic sites. of particular interest, however, is that between the 55th and 56th quality percentiles there is a consistent decrease in the number of variable sites identified, suggesting a possible cutoff value for this parameter. interestingly, quality alone does not appear to be sufficient for accurately identifying the presence of low-level biological variation as, without cross-validation using the illumina platform, the number of sites identified within each sample is consistently higher . in the latter the median number of variable sites across all  <dig> samples is  <dig>  which is almost three times higher than when cross-platform validation is performed. reflecting this uncertainty is the development of many probabilistic methods that attempt to improve the reliability of identifying low-level variation at sites within data obtained from a single platform  <cit> . our frameworks ability to store temporally sampled data provides an opportunity to derive a set of priors characterizing the expected variation within that individual. combined with the error rates described here and in conjunction with read quality scores this forms the bases for our first future update which involves filtering platform dependent variation from temporally sampled read data using a bayesian approach.

CONCLUSIONS
we have provided software, segminator ii, which can be used for the processing of temporally, spatially or otherwise linked viral data obtained from next generation sequencing platforms. in a demonstration of the usability of our software we have also quantified the amount of platform dependent error that is present within data generated on both the  <dig> and illumina platforms and, thus, highlighted the need for care when calling low frequency variants using a single platform. given that next generation data is increasingly important in the analysis of drug-resistance and vaccine trials, this software will be useful to the retroviral research community.

availability and requirements
project name: segminator ii

project home page: http://www.bioinf.manchester.ac.uk/segminator/

operating system: e.g. platform independent

programming language: java

other requirements: java  <dig>  or higher

license: gnu lesser gpl

any restrictions to use by non-academics: license needed

competing interests
the authors declare that they have no competing interests.

authors' contributions
conceived and designed the project: dlr, ar and ja. performed the sequencing: pk, gb and sw. analyzed the data: ja, dlr and ar. implemented the software: ja. wrote the paper: ja, with input from dlr, ar and pk. all authors commented on and approved the final version of the manuscript.

