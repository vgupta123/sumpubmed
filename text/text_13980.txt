BACKGROUND
in genome-wide association studies , it is generally accepted that multilocus methods can obtain better power than single-locus approaches that test only one single-nucleotide polymorphism  at a time  <cit> . among a large number of mathematical and statistical approaches considering many predictors simultaneously, scan statistics  <cit>  serve as a useful multilocus analytical means for combining genetic information on multiple contiguous snps. in this method, the whole genome is scanned by a sliding window with estimated size, and the moving sum for each window is computed as the sum of suitable single-locus statistics. then the scan statistic, defined as the largest moving sum, is calculated and its associated empirical p-value is evaluated by permutation tests.

despite its remarkable advantages, the scan statistics method has two drawbacks that can restrict its practical use:  linkage disequilibrium  within local genomic regions is not taken into account, which can result in an inflated type i error rate;  all contiguous snps within a genomic region  are selected simultaneously, which can bring excess noise and increase the false discovery rate .

during the last decade, various advances based on the framework of scan statistics have been developed. zaykin et al.  <cit> , dudbridge et al.  <cit> , and yang et al.  <cit>  proposed more effective and powerful test statistics within each sliding window and improved the sensitivity of scan statistics; sun et al.  <cit>  took into account the complex distribution of human genomic variation in the detection of causal chromosomal regions; browning  <cit>  and li et al.  <cit>  proposed a variable-sized sliding-window method based on markov chain and regularized regression analysis. in their method, there is no need to specify a window size for haplotype tests, which makes it particularly useful in the investigation of association studies.

in this study, we propose a novel sliding window-based multilocus method for identifying a subset of susceptibility snps based on forward variable selection, using generalized ridge logistic regression  for model fitness at each step. as a broader and generalized form of ridge logistic regression, grlr can take advantage of prior information between any pair of snps and impose proper shrinkage penalty on each snp within the genomic region of interest. our method can automatically combine genetic information within local regions and select a subset of snps that best predict disease status, whose associated empirical significance level is assessed by permutation tests. we demonstrate by simulations and analysis of two published datasets that our method is highly informative and promising.

methods
generalized ridge logistic regression
logistic regression  is a common statistical method for looking into the dependency of a binomial response on a number of variables , whose general form is:

 logpi1-pi=β0+xitβ <dig> i= <dig> ,…,n, 

where the m-dimensional vector xi represents the ith observation and pi is the probability of observing the ith outcome yi =  <dig>  the regression coefficients parameter β=β <dig> β1tt can be estimated by maximizing the following log likelihood:

 llr=∑i=1n[yilog+log. 

although logistic regression is very popular in case-control association analysis, it suffers from several shortcomings. if the number of snps in the regression model is larger than the number of observations, this method fails  <cit> . moreover, with a large number of snps in the regression model, predictors can be highly correlated , which can lead to further degradation of the model  <cit> . with the use of quadratic  penalization, ridge logistic regression   <cit>  can overcome these disadvantages of logistic regression and increase the stability of model fitness. this method has recently been applied successfully in several biological investigations including accommodating linkage disequilibrium  <cit>  and uncovering gene-gene interactions  <cit> .

for the analysis discussed below, we consider generalized ridge logistic regression , a broader and generalized form of ridge logistic regression, which amounts to maximizing the following penalized log likelihood:

 lgrlr=∑i=1n−12λβ1tpβ <dig>  

where p is a nonnegative definite penalty matrix and λ is a positive scale constant, that is, a tuning parameter, which can be specified by cross-validation. the regression coefficients in the model are estimated using the newton-raphson iterative algorithm. the effective degrees of freedom and the variance of the coefficients can be approximated by estimators introduced in  <cit> . then the wald test can be applied to assign p-values to the regression coefficients.

due to the feature of quadratic penalization that none of the coefficient estimators would be equal to zero in the shrinkage, grlr cannot serve as an independent tool for model selection; however, the traditional forward selection procedure can be utilized, with the use of grlr for model fitness in each round. in forward variable selection, we start with no predictor in the model and then add the one variable that leads to the best score. we continue adding variables one at a time until the score stops improving. in this study, we choose the aic   <cit>  as the scoring method in the variable selection procedure, which measures goodness of fit of a statistical model.

as a proof of concept, we assume a sample of m individuals genotyped at n snps. for each individual, the three genotypes aa, ab, and bb on any given snp are denoted by  <dig>   <dig>  and  <dig>  respectively, where the b allele is the minor allele, and an additive model is assumed. for the phenotype, the disease-affected status is denoted by  <dig>  while the disease-unaffected status is denoted by  <dig>  let x be an n × m matrix containing the sample genotypes, where n is the number of snps and m is the number of individuals. let y be an m-dimensional vector representing sample phenotypes. the procedure of our method is described below, and an intuitive flowchart is displayed in figure  <dig> 

initially, we compute the p-values p <dig>  p <dig>  ..., pn for all the n snps, using logistic regression. for the ith snp, where i =  <dig>   <dig>  ..., n, we construct a search region with that snp being in the center of the region. let u and v denote the sizes  before and after this snp, where u and v are always equal as long as the search region is entirely located in a chromosome. the constructed search region with the ith snp as the central snp is denoted by:

 gi={i−u,i−u+ <dig>  …,i,…,i+v− <dig> i+v}. 

to define the penalty matrix p in the grlr model, we use the physical position information between pairs of snps in the search region, in order to impose different weights on different snps based on their distances to the center. the larger the distance between a snp and the center, the more penalties would be placed on it. other weighting functions for pairwise snps can also be implemented, such as the ld measurements d or r <dig>  in this study, we only consider physical position information. assume that the positions  of snps in the region gi are denoted by wi = {di-u, di - u +  <dig>  ..., di, ..., di + v +  <dig>  di + v}. then the nonnegative definite penalty matrix p is defined by:

 p={diag}   /∑j=i−ui+νdj−di. 

to avoid introducing excess noise, we do not use the information from all snps in each search region, because those with single-locus p-values too large  may contribute little to the power. to do this, we denote t as the p-value truncation threshold, and those snps with single-locus p-values larger than t will be excluded from the search region. in practical applications, the threshold t may be set somewhere from  <dig>  to  <dig> . after the truncation on gi, the adjusted search region is denoted by ti.

with the above configuration, we apply forward selection to each search region ti, using grlr for model fitting in each step. denote bi as the current best subset of snps for each step of the model selection procedure, which is empty at the beginning. we start by fitting the grlr model using the central snp  as the only predictor, and calculating the corresponding aic. then we remove the central snp from the search region, ti, and add it to bi. next, the remaining snps in ti are entered into the grlr model one by one, along with the snps in bi as predictors. we select the one snp which can reduce the original aic most. then we add it to bi, remove it from ti, and update the current aic. we repeat this procedure until none of the remaining snps in ti can decrease the current aic. finally we investigate the last model and calculate the corresponding p-value p{ei} for the model fitness, where the subset ei stands for the selected snps in this search region.

considering all the search regions over the whole genome, our test statistic is defined as the minimum of all p{ei}s. to assign a global empirical p-value for the selected subset of snps, we use l permutations by randomly switching the case-control labels in the observed dataset. considering the computational burden, we can construct search regions of interest using the top s snps whose p-values are smallest among all the p-values computed by the logistic regression. an alternative is to pre-define another truncation threshold and exclude the snps whose p-values exceed the threshold.

simulations
we apply our method to simulated data and compare its performance with that of five other methods in current use. for each replication, we generate a susceptibility genomic region with  <dig> snps  under two scenarios. in scenario , two snps within the region are disease-causing, while in scenario , three snps are disease-causing. in both scenarios, one causal snp is located at the center of genomic region while other causal snps are randomly located. we generate  <dig> independent individuals , using the following logistic regression model:

 logpi1-pi=β0+ a^1xi1+…+ a^kxik,i= <dig> ,…,n. 

in this model, the predictor xij refers to the genotype of the ith individual at the jth causal snp, where genotypes aa, ab, and bb are coded by  <dig>   <dig>  and  <dig>  respectively, assuming the b allele is the minor allele. in scenario , k  equals  <dig>  while in scenario , k equals  <dig>  the intercept βo is determined by requiring a disease prevalence of  <dig> ; other regression coefficients βj are set to  <dig> .

assume that each snp within the region is derived from a multivariate normal distribution, and the variance-covariance matrix Σ is defined by: Σpq =  <dig>  when p = q; Σpq = r, when |p - q| ≤ 5; Σpq =  <dig>  otherwise. the correlation coefficient r can be varied in simulations. for each snp, we determine its genotype by its corresponding value generated from a multivariate normal distribution. if the value falls into the interval 2)), the genotype of this snp is set to aa; if the value falls into the interval , + ∞), the genotype of this snp is set to bb; otherwise, the genotype of this snp is set to ab. here, f is the frequency of the b allele  and the function "qnorm" computes the quartile of standard normal distribution.

RESULTS
power calculations
we compare the performance of our method  with that of logistic regression , fisher product method   <cit> , truncated product method   <cit> , lasso logistic regression   <cit>  and elastic net   <cit> . fpm uses a sliding window with fixed size to scan the genomic region, and for each window, it computes the sum of the logarithm of each p-value. then the test statistic is defined as the minimum value over all windows. tpm is similar to fpm but it focuses on the p-values that are no more than a pre-fixed truncation threshold. in this simulation study, the truncation threshold for tpm method is set to  <dig>  and the window size is set to  <dig> in both fpm and tpm methods. for the lasso and enet methods, all snps in the search region are entered into regression models and subsets of snps are selected. the tuning parameters in both methods are determined by cross-validation. for the grlr method, the truncation threshold is also set to  <dig>  and the tuning parameter λ is set to  <dig>  we mimic the physical distances between different snps by constructing a simple mapping function that the position of the bth snp in the genomic region is set to b.

for each combination of these parameters, with minor allele frequencies f =  <dig> ,  <dig> , or  <dig>  and correlation coefficients r =  <dig> , or  <dig> , we carry out  <dig> replications and assess the power of various methods under both scenarios. to ensure that the type i error rate of each method is equal to  <dig> , we utilize the following control procedure: for the fpm, tpm, and grlr methods,  <dig> permutations are applied in each simulated replication. for the lasso and enet methods, since they often include extra terms and tend to have a high type i error rate  <cit> , we apply  <dig> times ten-fold cross-validations for each generated replication. for each selected snp in the observed data, its consistency is defined as the number of times that it occurs in  <dig> sub-datasets that contain  <dig> percent of observations. the consistency thresholds are determined under the null hypothesis to ensure the normal type i error rates.

for power considerations, the testing "success" can be defined by different strategies:

scenario  
• strategy i: at least one of the two snps is detected

• strategy ii: both snps are detected

scenario  
• strategy i: at least one of the three snps is detected

• strategy ii: at least two of the three snps are detected

• strategy iii: all three snps are detected

tables  <dig> and  <dig> show the results of power simulations for the six methods under the conditions of scenario  and scenario , respectively. considering all  <dig> conditions in the results, the averaged power for the six methods lr, fpm, tpm, lasso, enet, and grlr, are equal to  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig> , and  <dig> , respectively. our grlr method is the overall winner and enet is second, being slightly less powerful than our method. lasso performs worse than grlr and enet, but clearly outperforms the remaining three methods. fpm and tpm have quite similar power results, and lr ranks last. it is interesting to note that our grlr method works very well under strategies ii and iii, which indicates that our method is especially powerful in uncovering all causal snps within a given genomic region.


                                 strategy
                                 corr
                                 maf
                                 method
                                 lr
                                 fpm
                                 tpm
                                 lasso
                                 enet
                                 grlr
results of power simulations for six methods under scenario  . two definitions of testing success, strategy i  and strategy ii , are applied in comparisons; the number of replication runs is  <dig> for all the simulations. corr = correlation coefficient; maf = minor allele frequency.


                                 strategy
                                 corr
                                 maf
                                 method
                                 lr
                                 fpm
                                 tpm
                                 lasso
                                 enet
                                 grlr
results of power simulations for six methods under scenario  . three definitions of testing success, strategy i , strategy ii , and strategy iii , are applied in comparisons; the number of replication runs is  <dig> for all the simulations. corr = correlation coefficient; maf = minor allele frequency.

in our grlr method, arbitrary choices of the truncation threshold and the size of the sliding window may become a potential problem. thus we investigate the impact of different truncation thresholds t =  <dig>  or  <dig> , and different sizes of regions  <dig>   <dig>  or  <dig> . we focus on scenario  , and set the minor allele frequency to  <dig> . results are shown in figure  <dig>  where we can see that the power fluctuation caused by different choices of the two parameters is not large. it indicates that our method is not very sensitive to the choice of truncation threshold and the size of the sliding window.

we conducted additional simulations to test the performance of our method conditional on various choices of the tuning parameter λ. we consider scenario   and apply two definitions of testing success, strategy i  and strategy ii . the correlation coefficient and the minor allele frequency are set to  <dig>  and  <dig> , respectively. the number of replication runs is  <dig> for all simulations. results show that, when the tuning parameter λ equals  <dig> ,  <dig> ,  <dig> ,  <dig>  and  <dig>  the power of our proposed method under strategy i equals  <dig> ,  <dig> ,  <dig> ,  <dig> , and  <dig> , respectively, while the power under strategy ii equals  <dig> ,  <dig> ,  <dig> ,  <dig> , and  <dig> , respectively. we can see that the power fluctuation caused by different values of λ is not large. it indicates that our method is not very sensitive to the selection of the tuning parameter, although it is unknown which selection can lead to the best result.

we further compared the performance of single-locus logistic regression and our proposed method by increasing the total number of snps in each simulated window to  <dig> and the number of causal snps to  <dig>  for ease of calculation, only  <dig> permutations were applied in each of  <dig> replication runs. simulation results show that, for logistic regression method, the proportion of times that it can successfully detect at least one causal snp is  <dig> , while the proportion of times that it can detect at least two causal snps is only  <dig> ; for our grlr method, the proportion of times that it can successfully detect at least one causal snp is  <dig> , while the proportion of times that it can detect at least two casual snps is  <dig> . these results indicate that our method is more powerful in discovering multiple disease variants.

analyzing published data
to further demonstrate our grlr method and evaluate its practical applications in real dataset analysis, we apply it to two published genome-wide datasets:  a case-control dataset for heroin addiction  <cit>  with approximately  <dig>  snps and  <dig> individuals , and  a case-control dataset for age-related macular degeneration  collected in hong kong  <cit>  with approximately  <dig>  snps and  <dig> individuals .

for the heroin addiction data, we initially apply logistic regression on all the snps using the whole-genome data analysis toolset plink  <cit> . table  <dig> shows the original p-values of the top  <dig> snps, as well as the adjusted p-values after applying the bonferroni correction and  <dig> permutations. from the result, none of the snps are statistically significant at threshold α =  <dig>  after multiple test correction. to apply our grlr method to the dataset, we construct genomic search regions based on the snps whose single-locus p-values are no larger than  <dig> ; the truncation threshold within each search region is also set to  <dig> ; the size on each side of the central snp is set to 10; the tuning parameter λ in the grlr model is set to  <dig> . we use  <dig> permutations to assign empirical p-values for the selected subset of snps. a summary of the analysis results is shown in table  <dig>  where the identified subset {rs <dig>  rs965972} is statistically significant with a global empirical p-value of  <dig> . it is interesting to note that using logistic regression or other single-locus methods, p-values for the two snps are  <dig>  × 10- <dig> and  <dig>  × 10- <dig>  neither of which is statistically significant at α =  <dig>  after multiple testing corrections. in contrast, our method automatically combines the association information of the two snps and leads to a significant result.


                              rank
                              chr
                              snp rs#
                              bp position
                              odds ratio
                              original p-value
                              bonferroni correction
                              empirical p-value
analysis results for the published dataset on heroin addiction using logistic regression. odds ratios, original p-values, p-values after bonferroni correction, and empirical p-values  of the top  <dig> snps are listed.


                              dataset
                              chr
                              selected subset of snps
                              test statistic
                              empirical p-value
analysis results for two published datasets using our grlr method. genomic search regions are constructed based on the snps whose single-locus p-values are no larger than a fixed threshold  <dig>  for the heroin addiction data, and  <dig>  for the amd hong kong data; the truncation threshold within each search region is set to  <dig> ; the maximal length on each side of the central snp is set to 10; the tuning parameter λ in grlr model is set to  <dig> . empirical p-values are derived from  <dig> permutations.

for the amd hong kong data, after applying logistic regression, only the snp rs <dig> is statistically significant, whose functional significance had been established experimentally  <cit> . table  <dig> shows the original p-values of the top  <dig> snps, as well as adjusted p-values for multiple testing corrections. for our grlr method, we construct search regions based on the snps whose single-locus p-values are no larger than  <dig> . other parameter configurations are the same as those applied in the first dataset. a summary of the results is shown in table  <dig>  our method shows that the identified subset {rs <dig>  rs <dig>  rs763720} is statistically significant with an empirical p-value of  <dig> . based on this estimate, the 95% confidence interval for p extends from  <dig> through  <dig> , which is considerably smaller than the published p-value of  <dig>  .


                              rank
                              chr
                              snp rs#
                              bp position
                              odds ratio
                              original p-value
                              bonferroni correction
                              empirical p-value
analysis results for the published dataset on amd hong kong using logistic regression. odds ratios, original p-values, p-values after bonferroni correction, and empirical p-values  of the top  <dig> snps are listed.

discussion
our method has the following advantages:  grlr automatically combines association information of snps within each sliding window, and by truncating snps with low marginal effects and penalizing snps with a large distance from the center, our method can exclude excess noise and allow for linkage disequilibrium in local genomic regions;  we apply a forward model selection framework and fit the grlr model at each step, since grlr cannot serve as a means for variable selection. the results of power simulation and real datasets analysis indicate that this procedure works very well;  the global empirical p-value for the selected subset of snps is evaluated by permutation analysis, which properly handles the multiple testing problem and furnishes a valid type i error rate.

there are still some aspects in our grlr method that can be improved in future work:  we do not consider the selection of the tuning parameter λ in this study. cross-validation is an important tool for determining the tuning parameters in penalized regression approaches. it would be reasonable to determine λ by cross-validation, although it would introduce a higher computational burden;  the choices of window size and the truncation threshold in our method are arbitrary, which may reduce the stability of our method. although simulation results show that the impact of these parameters on power is not large, a variable-size sliding-window procedure could be a better choice. another way is to allow for the free variability of these parameters and then determine the best ones by permutations;  the lasso and enet methods can perform better than our proposed method in high-dimensional model selection, since they can deal with multiple variables simultaneously. in this case, the introduction of a truncation threshold is not quite necessary for the applications of these two methods. for power comparisons, however, we wanted to apply the same preselection procedure and the same truncation threshold to the lasso and enet methods. it is of our interest to investigate this further in future work;  it is ideal to apply our region construction procedure to all snps. in this study, the search regions are constructed based on the snps whose marginal p-values do not exceed some pre-defined threshold;  it is of our interest to use the ld measurements or the combination of the ld and the physical distance information in constructing the weights for snps.

CONCLUSIONS
in this study, we propose a new sliding window-based multilocus approach for detecting causal snps, which is based on forward model selection using generalized ridge logistic regression  for model fitness at each step. our method can overcome some defects of the scan statistics approach and provides a powerful procedure for identifying causal genomic region and mapping susceptibility genes in routine case-control association studies. in particular, because of its capability of automatically combining association information of multiple snps and its advantage on variable selection, our method can be a useful technique in the analyses of human complex diseases. our software  is written in r  <cit> , with the use of the design package  <cit>  and glmnet package  <cit> .

competing interests
the authors declare that they have no competing interests.

authors' contributions
zl and ys participated in the study design and the programming. jo contributed to the overall organization, reviewing and editing the manuscript. all authors read and approved the final manuscript.

