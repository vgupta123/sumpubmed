BACKGROUND
proteins are the fundamental functional units in living systems. protein tertiary  structures at the molecular level are necessary to understand the functions of proteins. however, due to the significant cost of experimentally determining the tertiary structures of proteins, the number of known 3d protein structures is about  <dig> times smaller than the number of known protein sequences  <cit> . therefore, it is important to develop computational methods to predict protein structures from protein sequences  <cit> . recognizing a known structure that is similar to the unknown structure  is an important step of the template-based protein structure modeling approach that uses the known structure as a template to construct a structural model for the target protein  <cit> .

since the number of unique protein structures appears to be limited  according to the structural analysis on all the tertiary protein structures in the protein data bank   <cit> , it is possible to identify one correct template structure  for a large portion of target proteins. this is particularly the case if a target protein has a significant sequence identity with one of template proteins with a known tertiary structure. fold recognition becomes very challenging when the sequence identity of the target protein and template proteins is low, i.e., in the twilight zone. numerous research endeavors have been devoted to developing sensitive methods to improve fold recognition in the twilight zone. machine learning methods have been used to tackle the problem effectively by casting the fold recognition as a binary classification problem to decide whether or not a target protein shares the same structural fold with a template protein in a protein structure library  <cit> .

given a number of features describing the pairwise similarity between two proteins , the objective of the classification is to predict if the two proteins share a similar tertiary structure . the problem can often be divided into three difficulty levels that range from the easiest family level , to the superfamily level, and to the hardest fold level. this roughly corresponds to the decrease in sequence identity between two proteins. proteins sharing similar structures have a relatively high sequence similarity if they are in the same family, moderate or little sequence similarity if in the same superfamily, and almost no sequence similarity if in the same fold.

random forest is one of the most powerful machine learning methods known for its good interpretability and its efficiency in handling very large training datasets  <cit> . random forest grows a large number of decision trees based on a subset of randomly selected features and a fraction of randomly selected training data points. all the trained trees are applied to a new data point to make prediction. the majority vote of the ensemble of trained decision trees is used as the final prediction for the data point. the average decision based on a large number of decision trees makes random forest robust against noisy data, irrelevant features, and unbalanced class distribution. random forest has delivered an excellent performance in broad classification tasks that compares favorably with other ensemble classifiers such as adaboost  <cit> , and its performance is generally comparable to other state-of-the-art classifiers such as support vector machine  as well  <cit> . random forest has been used extensively in a wide variety of domains  <cit>  including protein fold classification  <cit> , which is related to, but different than protein fold recognition. the fold recognition problem addressed in this paper is to recognize proteins that have similar tertiary structures to target proteins, while the protein classification  <cit> , and  <cit>  is to classify a single protein sequence into a number of structural folds. on contrary, we applied random forest to classify if a pair of proteins  shares the same structure. the classification scores are then used to rank template proteins based on their structural relevance  with a target protein. many methods have been developed to improve the accuracy of recognizing structurally similar folds when there is little sequence similarity between a target and a template protein, such as psi-blast  <cit> , hmmer  <cit> , sam-t <dig>  <cit> , sshmm  <cit> ,threader  <cit> , fugue  <cit> , sparks  <cit> , sp <dig>  <cit> , hhpred  <cit> , foldpro  <cit> , sp <dig>  <cit> , sp <dig>  <cit> , raptor  <cit> , sparks-x  <cit> , and boostthreader  <cit> .

in this work, we applied the random forest method  to address the fold recognition problem and evaluated its performance on the standard lindahl's dataset  <cit> , on which many previously established methods had been benchmarked. in comparison with  <dig> existing methods, rf-fold's performance was comparable to that of the state-of-the art methods, demonstrating the effectiveness of the random forest method in protein fold recognition.

methods
random forest method for protein fold recognition
the decision tree method for classification had been widely used in many domains due to its simplicity and good interpretability after leo breiman et al. introduced it in  <dig>  <cit> . however, the accuracy of a single decision tree is often lower than more advanced classification methods such as support vector machines or neural networks, which limits its application in accuracy-critical domains. the more recent development of the decision tree methodology found that using an ensemble of decision trees constructed from randomly selected features and training data not only often yielded significantly higher accuracy than a single decision  <cit> , but also often surpassed the accuracy of other most advanced machine learning methods. this new approach is called random forest. random forest is a meta-learning algorithm for classification, which consists of a bag of separately trained decision trees. therefore, it inherits the advantages of decision tree methods such as easy training, fast prediction, and good interpretability. because random forest selects a random subset of input features to construct each decision tree, the average prediction of a sufficient number of decision trees is robust against the existence of irrelevant features, which partially contributes to its good accuracy. furthermore, the random selection of a subset of training data to train each tree also leads to an ensemble of decision trees that are resistant to noise and disproportional class distribution in the training data.

in our study, each decision tree in the random forest was trained to predict if two proteins share a similar structural fold or not from a list of input features describing similarity between the two proteins . a number of features used to construct each decision tree were randomly selected from the total  <dig> features. the random forest method was implemented by using the randomforest r package  <cit> . the decision trees were trained by the standard decision tree training algorithm that maximized the information gain in selecting a feature to partition the training data. after training, each tree  was able to predict the probability of each class  given an input feature vector representing a protein pair . the average probability predicted by these trees was calculated and the class with higher predicted probability was the prediction. figure  <dig> illustrates how the random forest makes a prediction. the trained random forest is used to predict if a target protein has the similar fold with each template protein in the test data set through cross-validation. the top one or five templates with the higher predicted probability to share a fold with the target protein were obtained for evaluation.

data set and features
we trained and tested rf-fold on the foldpro dataset  <cit> . the foldpro dataset used the proteins in lindahl's benchmark dataset  <cit>  derived from the scop  <cit>  database . the lindahl's dataset includes  <dig> proteins, among which  <dig> proteins have at least one positive match with other proteins at the family level,  <dig> proteins at the super family level, and  <dig> proteins at the fold level. the pairwise sequence identity of any pair in the dataset is <= 40%. in the foldpro dataset,  <dig> features were extracted for each of all  <dig> Ã—  <dig> distinct protein pairs in order to classify if a pair of proteins  share the same structure at the family, superfamily, or fold level. the features were extracted using existing, general-purpose alignment tools as well as protein structure prediction programs in five categories, including sequence/family information, sequence-sequence alignment, sequence-profile alignment, profile-profile alignment, and structural information. for the features of sequence/family information, the compositions of a single amino acid  and an ordered pair of amino acid  were computed and transformed into similarity scores using the cosine, correlation, and gaussian kernel functions. for sequence-sequence alignment features, palign  <cit>  and clustalw  <cit>  were used to extract pairwise features associated with sequence alignment scores of a pair of proteins. for sequence-profile alignment features, psi-blast, hmmer-hhmsearch  <cit>  and impala  <cit>  were used to extract profile-sequence alignment features between the target profile and the template sequence. for profile-profile alignment features, five profile-profile alignment tools clustalw, coach of lobster  <cit> , compass  <cit> , hhsearch  <cit>  and prc  were used to align target and template profiles to obtain profile-profile alignment scores. for structural features, based on the global profile-profile alignments obtained with lobster, structural features of query proteins predicted using the scratch suite  <cit>  were compared with that of template proteins to obtain structural compatibility scores.

the small portion of pairs belonging to the same protein family, superfamily, or fold was labelled as positive examples because they shared the same structural folds. the vast majority of protein pairs that did not have structural similarities were labelled as negative examples.

training and benchmarking
we divided all protein pairs into  <dig> equal-size subsets for 10-fold cross validation purposes. we put all the target-template pairs associated with the same target protein into the same subset. nine subsets were used for training and the remaining subset was used for validation. we removed all the pairs in the training dataset that used targets in the test dataset as templates. this procedure was repeated  <dig> times and the sensitivity and specificity of fold recognition were computed across the  <dig> trials. we also compared rf-fold with  <dig> other methods by fold recognition rates for top-one ranked templates and for top-five ranked templates as in  <cit> . using the same evaluation procedure as in  <cit> , we calculated the sensitivity by taking as predictions the top-one or the top-five template proteins ranked for each target protein by classification scores. here the sensitivity was defined by the percentage of target proteins  having at least one correct template ranked 1st, or within the top  <dig>  <cit> .

RESULTS
comparison of random forest with a single decision tree
we compared the random forest consisting of  <dig> decision trees to a single decision tree in terms of the error rate . the error rate of the random forest classification was  <dig> %, which was lower than  <dig> % of a single tree . it is worth noting that the error rate is very low because the dataset with only a small fraction of positive examples is highly imbalanced.

effects of data imbalance on random forest
it is difficult to train a classifier on a highly imbalanced dataset in which one or more classes are extremely under-represented. the significant drawback of using training data with the imbalanced distribution of classes has been reported in  <cit> . the foldpro dataset is a very imbalanced dataset, which has  <dig>  positive examples versus  <dig>  negative examples. the ratio between the majority class and the minority class is 128: <dig>  training on such a dataset is difficult for most machine learning methods in general.

in order to assess how well the random forest approach handled imbalanced data, we trained the random forest classifier on  <dig> datasets, which had a ratio of negatives to positives of 128: <dig>  100: <dig>  75: <dig>  50: <dig>  and 25: <dig>  table  <dig> shows how the numbers of correctly selected templates were at the family, superfamily, or fold level change with respect to the ratios in the10-fold cross validation. except for the case with a 1: <dig> ratio, it appeared that the performance of random forest method was steady with different ratios of negative and positive examples.

effect of the number of features
the number of features used for training affects the performance of machine learning methods. we evaluated how the performance of the random forest changed with respect to the number of features used in training, which ranged from  <dig> to  <dig>  figure  <dig> shows the plots of the sensitivity of fold recognition of rf-fold against the number of features at the family, super family, and fold levels for both top-one ranked templates and top-five ranked templates. the sensitivity for top-one  ranked templates is defined as the percentage of target proteins having at least one correct template ranked no.  <dig>   <cit>  by rf-fold. the results showed that the performance of the random forest improved or stabilized as more features were used in training. however, it appeared to plateau out after  <dig> features at the family level, and after  <dig> features at the superfamily and fold level.

comparing rf-fold with existing fold recognition methods
the bold font denotes the highest sensitivity in their respective categories of prediction. the results of other methods are taken from  <cit> 

rf-fold performed better than most of methods in table  <dig> and comparably to raptor, sparks-x, and boostthreader. compared with raptor, in most situations, rf-fold shows some improvement of accuracy, while it performed worse than raptor at top- <dig> family level and top- <dig> fold level. compared with sparks-x, rf-fold was less accurate at the fold level, but more accurate at the other two levels. compared with boostthreader, rf-fold was less accurate in top-one at three levels, but more accurate in top-five at all three levels.

availability of rf-fold software and source code
in order to facilitate the reuse and implementation of rf-fold method, the online web service for fold recognition, the source code of the programs of random forest learning and classification, the scripts of generating pairwise features for a pair of proteins, the scripts of evaluating the fold recognition results, and the training and test datasets are released at http://calla.rnet.missouri.edu/rf-fold/. the readme .txt file describes how to train and test the random forest method for fold recognition , how to evaluate the performance on the benchmark data set , the datasets used to do cross-validation, and the scripts used to generate  <dig> pairwise features for a pair of proteins . based on the document and programs, any user can create his/her own training and test datasets and train / test his/her own random forest classifier for protein fold recognition from scratch. the software, source code and data are released under the gnu general public license. anyone can freely reuse the software and source code for any purpose . any technical problems may be addressed to the email box of the corresponding authors. based on users' feedback, additional documents, utility programs, test examples, and data will be added in order to facilitate the development of random forest methods for protein fold recognition.

CONCLUSIONS
in this study, we developed a random forest method  to recognize protein folds. the method was systematically validated by varying the input features and the class distribution of training datasets on a standard fold recognition dataset. the random forest consisting of  <dig> decision trees yielded a low error rate than a single decision tree on a highly imbalanced dataset. the random forest also delivered a good, steady performance regardless of the different ratios of negative and positive examples. compared with  <dig> other different fold recognition methods, the performance of the rf-fold is generally comparable to the best performance. the results achieved by the rf-fold demonstrated the effectiveness of using the random forest algorithm in protein fold recognition. in the future, we plan to further evaluate the performance of rf-fold on a standard protein homology detection dataset  <cit> , independent casp datasets  <cit> , and to build a protein tertiary structure prediction web server based on rf-fold for the community to use. furthermore, the sensitivity of rf-fold for the hardest fold recognition problem at the fold level is still relatively low , which is one of the major bottlenecks of template-based protein structure modeling. we will incorporate more informative features into rf-fold to address this problem in the future.

competing interests
the authors declare that they have no competing interests.

authors' contributions
tj implemented the algorithms and carried out the experiments. tj and jc analyzed the data, wrote and edited the manuscript. tj and jc approved the manuscript.

