BACKGROUND
biosurveillance is a necessary task to monitor food for human consumption and pharmaceutical drugs, subsumed as “biologicals”, which typically consist of complex mixtures of processed biological material. since the species origin of such products is often unclear, there is a concern about fraud, health risks and violation of ethical/religious principles, as best illustrated by the  <dig> european horse meat case . therefore, food and drug legislation demands producers to provide a proper declaration of ingredients, e.g. by naming species components of food products  <cit> . to ensure correct declaration, accurate and efficient analytical methods of foodstuff analysis have been developed, mostly based on the detection of species on the dna level by pcr  <cit> . such dna-based tests are considered superior to protein-based methods, when processed material has to be analyzed  <cit> . real-time pcr assays, often based on fast-evolving gene regions from the abundant mitochondrial genome, now facilitate a multiplex detection of many bird, fish and mammalian taxa . such assays sometimes even allow for discrimination of taxa as closely related as cow and water buffalo  <cit> . the main shortcoming of pcr-based detection methods is, however, that they inherently target only dna from species to which the pcr primers bind efficiently. this caveat also holds true in principle for barcoding methods that rely on the pcr amplification and subsequent massively parallel next-generation sequencing of amplicons from variable genomic or cell organelle dna regions . barcoding methods have been shown to very efficiently identify taxa within environmental or food-derived metagenomic samples in a qualitative way , but require separate assays to address the different domains of life. in addition, quantification of components by barcode sequencing has proven problematic due to taxonomic biases induced by the varying primer binding efficiencies across taxa . species quantification by sequencing of organellar pcr amplicons is also critical, as the absolute number of mitochondrial genomes per cell is highly fluctuating already between different tissues . in contrast, sequence analysis of total genomic dna isolated from food offers in principle the possibility to detect species in a totally unbiased way, enabling e.g. the detection of fraud through admixture of undeclared ‘exotic’ taxa or the presence of health risks by microbial contamination  <cit> . in the field of gene expression analysis, ngs sequencing facilitates a robust quantitative analysis of rna molecules through digitally counting sequence reads obtained from the cdna population of a tissue  <cit> . the sensitivity and dynamic range of read counting equals or supersedes other quantitative dna analytical methods like microarrays or sage  <cit> . from a technical perspective, species identification based on the whole-genome sequencing should also be feasible since the large, non-protein-coding part of eucaryotic genomes evolves rather quickly and strongly conserved gene exons constitute only a minor proportion, e.g. roughly  <dig> % of a mammalian genome  <cit> . therefore, even closely related food-relevant taxa such as goat and sheep or turkey and chicken should be distinguishable in a total genomic comparison. intraspecific polymorphism in foodstuff species ranges between  <dig>  to  <dig> nucleotides per  <dig>  bp in horse, swine and chicken, respectively , which should not substantially affect species discrimination.

here we show that deep sequencing of total dna derived from foodstuff material can readily identify and quantify species components with high accuracy by a single experimental assay. sequence reads are assigned to species by mapping  <cit>  to publicly available reference genome sequences, which steadily grow in number, as exemplified by the genome10k project . at the same time, reads of “unexpected” species origin are readily detected by a metagenomic analysis based on dna sequence database searching.

methods
the bioinformatics pipeline
sequence reads of 100 bp, either obtained by simulation  or by illumina sequencing of dna from sausage meat , were initially mapped against reference genomes using the algorithms bwa  or cushaw  <cit>  resulting in a sam file for each mapping. reference genomes in our pilot analysis comprised the species bos taurus, bubalus bubalis, equus caballus, escherichia coli, gallus gallus, glycine max, homo sapiens, listeria seeligeri, meleagris gallopavo, mus musculus, neisseria gonorrhoeae, oryctolagus cuniculus, oryza sativa, ovis aries, rattus norvegicus, shigella boydii, sus scrofa, triticum aestivum and zea mays . reference genome taxa were mostly chosen either because of their foodstuff relevance or matches obtained in the metagenomic analyses step of our pipeline. others  were primarily included to serve as negative controls to judge the extent of false positive read assignments. it is clear that for a broader screening many more reference genomes could have been used. the practical upper limit for the number of reference genomes clearly depends on computer power and scales linearly with time. the bwa mappings were executed by allowing  <dig>   <dig>   <dig> or  <dig> mismatches, depending on the respective approach . for the downstream analysis of the mapping results we utilized samtools  and a set of self-implemented perl scripts.after the mapping step, we identified three sets of sequence reads . the first set contained reads mapping to just one genome . assigning these reads to a genome and quantifying them by counting was a straightforward task. more challenging were reads, which covered conserved sequence regions within genomes and therefore simultaneously hit at least two different genomes , even under conditions of the highest mapping stringency. since these conserved reads cannot be assigned with any certainty to one specific genome, we distributed them to the respective candidate genomes in the proportion previously calculated from the unique reads. by this means, the multi-mapped reads could additively be used to improve the values of the quantitative analysis.figure  <dig> 
outline of the afs pipeline.




a 3rd category, so-called “unmapped reads”, were collected and forwarded to up to three further rounds of mapping, each of which allows one more mismatch than the previous round . we then calculated the proportions of species material from all reads, which were unambiguously assigned at this step. to account for the different quality  of the reference genomes, as indicated by different numbers of positions denoted by ns in the genome drafts, our initial quantitative estimates were corrected by a genome quality factor f = /c, where n is the number of ambiguous nucleotides and c is the total number of nucleotides in the reference genome. further normalization should in principle be necessary to adjust for largely different genome sizes, e.g. when comparing birds and mammals which differ roughly 3-fold in dna content  <cit> . however, our quantification of a sample containing avian material  indicated that such normalization might be unnecessary, possibly due to the correlation of smaller genome size with a smaller nucleus and cell size  <cit>  leading to a compensatory denser packaging of cells per gram avian tissue.

in our pipeline, we subsequently tried to identify the origin of still unmapped reads by blastn  database searching  <cit>  against the ncbi nucleotide database . since our query sequences were short 100 bp reads, we used a word size of  <dig>  set the blast e-value to  <dig> according to megan’s “how to use blast” tutorial  <cit> , and accepted the best three hits for further analysis. furthermore, we set blast’s “–i” option to add the gi number to the default blast output files. otherwise, default blastn settings were used. blastn results were then visualized by the metagenomic analysis tool megan <dig> . this tool parses blast output files and assigns the results to species or, if this is not possible, taxonomic groups of higher rank according to the ncbi taxonomy database. to filter out false-positives, caused by low complexity repeats  or highly conserved regions, we set megan’s lca parameters to min complexity =  <dig> , min score =  <dig> , top percent =  <dig>  and turned on the percent identity filter. to limit the analysis to the most relevant results, taxa were somewhat arbitrarily only accepted for visualization in our pilot study, if more than  <dig> reads were assigned to this taxon. blast results were then visualized as a phylogenetic tree and quantified using excel. for species attracting more than a threshold number of the unmapped reads in the blast step, a return to the read mapping procedure would be reasonable to infer more exactly the proportion of this taxon. this, of course, requires the availability of the respective reference genome, the list of which is gradually increasing.

dataset simulation and calculation
as a proof of principle, we simulated records of illumina sequence data by randomly extracting 100 bp long sequences from downloaded genome sequences, which were subsequently tagged by their origin . random errors were introduced into the simulated reads at a 1% rate. next, we compiled mixed datasets for testing the read-mapping pipeline, by randomly sampling subsets of these simulated sequence reads. for simplicity at this testing stage, we did not perform iterative mapping at different stringencies, but allowed only one mismatch in the mapping process. we also did not apply the genome quality factor.

illumina sequencing of dna from a sausage calibration sample
total genomic dna was extracted from 200 mg of the homogenized calibration sausages “kald”   <cit>  and “klyoa”   <cit>  by the wizard plus miniprep dna purification system . dna was eluted in 50 μl elution buffer according to the supplier's manual. illumina sequencing library preparation was conducted on  <dig>  μg of total dna by starseq  using the truseq dna sample preparation kit v. <dig> . sequencing was performed on an illumina hiseq  <dig> instrument  for kald and on a miseq instrument  for klyoa. we used the fastx toolkit  for adapter clipping and quality filtering. reads shorter than 50 bp  or 20 bp  were discarded.

hardware for bioinformatical analyses
for the sake of speed, mappings using bwa were preferentially performed on one node  of the mogon linux-cluster at university of mainz. each iterative mapping  with  <dig> mio paired-end reads took about 45 minutes. mapping on a standard pc  consumed 3 hrs of time using  <dig> reference genomes  and  <dig>  reads. the blast steps of the pipeline were run on the university of mainz central computing linux-cluster lc <dig> . blast requests  were split up to  <dig> separate jobs, which reduced runtime to less than 2 hours for  <dig>  queries. the megan program was subsequently run on a standard personal computer  with 8 gb ram and windows os.

RESULTS
read mapping facilitates exact quantification of dna from diverse species
to test if high-throughput genomic dna sequencing was able to accurately determine the proportions of foodstuff components, we initially simulated two sets of sequencing records . the simulated sequence data was based on randomly sampled sub-sequences of public available genomes with randomly introduced errors.table  <dig> 
mapping results from simulated datasets



cattle

horse

human

pig

rat

sheep
simulated quantification of sequence reads obtained from six different genomes using the afs pipeline. “difference abs.” shows the difference between the proportions of reads, as determined by afs , relative to the expected amounts existing in the sample . “difference rel.” is calculated by dividing “difference abs.” by the expected proportion value.
effect of reference genome choice



cattle

e.coli

pig

sheep
simulation demonstrates the effect of choosing the adequate genomes for quantification by afs. initially, the e. coli reference genome was omitted in the mapping step. after observing e. coli reads in the metagenomic analysis, its genome was added to the mapping procedure, and the species proportions were now recovered with much higher accuracy.



dataset  <dig> consists of one million reads derived from six mammalian species . after running our pipeline on this dataset, the proportions of reads assigned to the respective reference genomes mirrored the sample compounds with high accuracy. the artificial dataset contained sequences present in rather high quantities  and low amounts  indicating that the method worked over a broad range of proportions. we achieved absolute differences between assigned reads and input read numbers of  <dig> to  <dig> % . the maximum relative difference  was  <dig> %. we also checked the accuracy of the mapping process by tracing the identity of the uniquely mapped reads . the mapping accuracy turned out to be better than  <dig> % .

simulation dataset  <dig> comprises 850 k reads, mixed at uneven proportions from three mammalian species  and the bacterium e. coli . this dataset was created to check if the method was able to detect signals of “unexpected” species, which would possibly not have a reference genome included in the initial mapping step. the sample was therefore initially run through the pipeline without mapping against bacterial genomes. as a result, all e. coli reads were passed on to the metagenomic blast/megan step. by this database searching routine,  <dig>  of  <dig>  unmapped reads  were identified as possible e. coli signals. according to our pipeline rationale, the strong e. coli signal prompted us to add the e. coli genome to the mapping process and to run the pipeline again to achieve a better quantitative estimate of the bacterial reads. in fact, the proportion of e. coli reads was now determined at high accuracy with only  <dig> % deviation from the real input value . meanwhile, the correct assignment of the e. coli reads improved the overall quantitative estimates for all the other species components.

these  results of our simulation study proved the general feasibility of quantitative species identification through deep sequence analysis of total genomic dna. quantification was most exact for the read mapping process implemented in afs, which however requires the availability of a reference genome. given that vertebrate  species will soon be sequenced by the thousands, this requirement will not set a limiting condition on the method itself.

for identifying unexpected species, the application of a less stringent metagenomic search tool, based on a blast database search followed by visualization via megan, also proved successful. however, our results for dataset  <dig> suggested that the mere evaluation of blast/megan results would not facilitate an accurate quantitative measurement of read numbers, which is only possible via the more stringently working read mapping algorithms. it should also be stressed that the results of the metagenomic working step entirely depend on the completeness of the sequence database chosen for searching and on the representation of a particular species within a database partition. in addition, one should be cautious of erroneous annotations within public databases  <cit> .

however promising the results of the simulation data analysis appeared, they clearly represented an idealized situation, since we obviously obtained the simulated reads from the very same genomes to which they were mapped thereafter. hence, we conducted an analysis using real data.

illumina sequencing of a dna sample from calibration sausage material
illumina sequencing was performed on dna obtained from sausage material, which previously had been designed and produced as calibration sample for qpcr-based approaches to species identification . the sample kald, on which we focused our most detailed analysis, contained material from four mammalian species . these mammalian taxa feature a minimal interspecific nucleotide divergence at the level of synonymous sites within genes of 7% , which is most probably exceeded by neutral non-genic sites. in addition, the sausage sample contained admixtures of  <dig> different plant allergens at varying amounts .

after quality filtering, we obtained  <dig> ×  <dig> million 100 bp paired-end reads. encouraged by the previous simulations, subsets of only  <dig> × 500 k  randomly selected paired-end reads were used for further analysis. to account for a possible trade-off between the specificity of taxon identification and a maximally exact quantification of reads, we devised two different mapping strategies. when maximum specificity was the prime goal , we did not allow any mismatches during read mapping, and thus performed only a single mapping step with the highest stringency. in addition, we disabled the smith-waterman alignment option in bwa because it lowers the mapping stringency for a paired-end read when rescuing a read from its aligned mate. the second strategy  aimed at best quantitative results. to this end, we performed an iterative read-mapping starting with a stringency of  <dig> and ending with  <dig> mismatches.

for both strategies, the n =  <dig> repetitions produced highly similar results, as evidenced by low standard deviations . the afs-quant approach delivered a highly accurate quantification of meat components in sausage kald, as exemplified by the value of  <dig> % dna versus 55%  meat for sheep . absolute differences between the dna proportions and the meat proportions ranged from  <dig>  to  <dig> %, showing that species quantification can be achieved at the 1% discrimination level. the highest divergence  was observed for pig and can be explained by the use of lard tissue  <cit> , which presumably contains less cells and thus dna than e.g. muscle tissue. in this respect, afs behaves in the same well-known matrix-dependent way as other dna-based detection methods  <cit> , and the definition of normalization values for typical ingredients and production recipes should alleviate this problem also for afs.table  <dig> 
mapping results for the reference sausage kald



cattle

horse

pig

sheep

waterbuffalo
quantitative species analysis obtained by illumina sequencing of dna from the “kald” reference sausage  <cit> . the afs-quant and afs-spec approaches  were compared. each dataset tested contained  <dig> mio of paired-end sequence reads, randomly selected from a larger dataset. three different sub-datasets  were analyzed and mean values plus standard deviations are displayed. “difference abs.” shows the difference between the proportion of reads as determined by afs  relative to the expected amounts existing in the sample . “difference rel.” is calculated by dividing “difference abs.” by the expected proportion value.



to infer the specificity of the mapping procedure we included the reference genome sequence of water buffalo, which belongs to the same subfamily  as cattle. afs-quant detected a false-positive proportion of  <dig> % dna reads in the buffalo genome , which probably represent sequences strongly conserved between the two bovines. the more stringent afs-spec approach was able to reduce the false-positive rate of “buffalo reads” substantially to  <dig> %, but only at the expense of a markedly diminished accuracy for quantification of the real meat components . to demonstrate the broader applicability of the afs-quant approach we sequenced and quantified the main ingredients of the klyoa sausage sample, which contains  <dig> % chicken and  <dig> % turkey on a background of pig and cattle meat . the avian components were determined as accurate as the mammalian ones.

we conclude that the afs-quant strategy delivers the most accurate quantitative species determination. we note that the afs quantification results are equal to or sometimes even better than species analyses performed by quantitative pcr on the same sausage material  <cit> . afs still contains a very low risk of obtaining false-positive matches to closely related species. clearly, further case studies with other species pairs like horse-donkey, which diverged only  <dig>  million years ago  <cit> , have to be conducted to generalize our conclusions. as a screening procedure, afs performance is only limited by the number of reference genomes available. offering both, a qualitative and quantitative result, deep sequencing of total genomic dna appears as an excellent alternative to microarray-based screening methods for species identification  <cit>  or sequencing of pcr-based barcode amplicons  <cit> .

detection of “unexpected” species via metagenomic analysis
dna reads which do not map to the selection of reference genomes will be passed over to the blast/megan annotation procedure in afs. the one-million-read datasets obtained from the kald sausage each produced more than 200 k of unmapped reads . roughly half of these reads could successfully be assigned to a species or higher ranked taxon. the other half was represented by two classes:  low-complexity repetitive dna  which is present in almost all genomes and thus cannot be assigned unequivocally; and  un-assignable reads which either did not match an entry in the chosen database or did not meet the stringent megan criteria applied. clearly, the choice of different specialized databases and perhaps less stringent match criteria has the potential of reducing this portion.figure  <dig> 
metagenomic analysis of unmapped reads. results of the metagenomic analysis of sequence reads obtained from the kald reference sausage. the global result of the blast/megan step is shown in the box . a more detailed classification of matches is displayed for mammals, viruses, bacteria and plants.



the ca. 100 k reads that were taxonomically assigned by blast/megan originated in their vast majority  from mammals . of those mammalian hits, 96% were annotated as cattle, sheep, pig and horse . close inspection of these sequences revealed that they predominantly represented centromeric satellite dna. this sequence class is usually not represented in genome reference sequences, explaining that the corresponding reads could not be assigned in the mapping step. the observed species proportions of the satellite dna reads somewhat surprisingly did not match the meat proportions for cattle and sheep. a reason could be that centromeric dna, which is an inherently unstable component of eucaryotic genomes  <cit> , is present in different amounts in the heterochromatin of sheep and cattle chromosomes, making its use for quantification purposes problematic.

among the reads of mammalian origins, we further recorded hits to several bovine-related taxa like the muntjac, goat or whales , which separated from bovines  <dig>   <dig> and  <dig> million years ago, respectively . we could show by an analysis using the tool repeatmasker  that these reads most often belonged to transposable elements  which show sequence conservation across this clade. surprisingly, we also found ~ <dig> matches to human, cercopithecan primates and mouse. inspection of these blast hits revealed that they also contained interspersed repeats. however, in humans and monkeys, none of those reads corresponded to the primate-specific alu element family. we are thus rather sure that neither goat or whale nor traces of human, monkey or mouse dna are present in the sample. at the same time, this issue demonstrates that expert interpretation of blast results is required, which is by no means a simple task.

beyond mammalia, blast/megan suggested the presence of viral, bacterial and plant sequences in the sausage dna . viral dna, all belonging to bacteriophage phix <dig>  was easily explained since this dna is usually applied for technical reasons as a calibrator in illumina sequencing . several hundred bacterial reads were detected, mostly originating from the human-pathogenic species neisseria gonorrhoeae  or from pseudomonadales , with pseudomonas fluorescens as an often annotated species . the latter is notably present e.g. in deteriorating milk and meat products  <cit> . while the small numbers of p. fluorescens reads can be taken as an indicator of beginning food spoilage, the finding of neisseria reads tells a very important cautionary tale in metagenomic analysis. after adding the respective genome  <cit>  to the mapping process, presumed n. gonorrhoaea dna was detected at an amount of  <dig> %. knowing that there should not be any n. gonorrhoeae material in the sample, we investigated this result further. by mapping all  <dig> million reads of our initial dataset to the n. gonorrhoeae genome, we obtained matches exclusively located in ten genomic regions, each shorter than  <dig> bp, where read coverage was extremely high . these regions were extracted from the n. gonorrhoeae genome and analyzed by blast against the ncbi nucleotide database, thereby revealing strong homology of these parts to ruminant sequence entries . in addition, mapping the sausage reads to other available n. gonorrhoeae genomes sequences did not produce any matches. we thus question the quality of the n. gonorrhoeae strain tcdc-ng <dig> genome and recommend using it with high caution. in general, this points out that the annotation quality of database entries is of prime importance to species diagnosis.

since meat products often contain plant material, the metagenomic analysis on the plant spectrum is of special interest. in fact, the sausage contained admixtures of  <dig> plant species  to enable its use in the development of allergen detection methods. the most prominent spiked-in ingredients were lupine , walnut , hazelnut  and mustard . we detected  <dig> plant hits, which were assigned to a total of  <dig> plant families. amongst those families, brassicaceae  dominated with  <dig> hits, followed by fabaceae  with  <dig> hits . all other plant ingredients received only from  <dig> to  <dig> blast hits. these numbers of database matches did not correlate with the amount of spiked-in plant material, illustrating that the current blast/megan routine is by no means quantitative. a probable reason is the unbalanced representation of sequence entries for the different taxa in the database . this can be overcome in future by the production of reference genomes for all major food- and allergenicity-relevant species. in addition, as expected for a dna-based method, the quantification result will heavily depend on the efficiency of dna recovery from the food matrix. of all plant allergens tested, only the genome of soy  is publicly available and was thus included in the afs read mapping step. we detected a stable proportion of  <dig> % soy dna in the sample, while the proportion of spiked-in soy material in the sausage was  <dig> %, suggesting a matrix-dependent underestimation by a factor of  <dig>  we point out, however, that qualitative detection may be the prime goal in allergen analysis  <cit> . the limits of afs for allergen detection clearly have to be investigated further.

technical considerations and further improvements
next-generation sequencing methods represent the fastest growing technology worldwide, with ever decreasing cost per analysis . applying novel 96-well format multiplex methods for illumina library preparation  and a personal sequencer  we calculate current sequencing cost  at roughly 150– <dig> euro per sample, which may already now be interesting and feasible for routine screening purposes. although we produced 100 bp paired-end reads for the kald sample, the initial results on klyoa suggest that cost-saving 50 bp single-end reads will probably perform equally well in read mapping. however, shorter reads may pose more problems in database searches, unless the blast version is optimized for short query sequences.

an additional cost saving can possibly be achieved by optimizing the numbers of sequence reads necessary to obtain stable quantification results. to this end, we mapped different numbers of reads, starting with 50 k and multiples thereof up to  <dig> mio reads, and calculated the sum of deviations  of the observed from the expected species proportions . deviations decreased with increasing dataset size, but were already close to the optimum at  <dig> mio reads. even at  <dig> or 100 k reads, the sum of deviations was rather moderate, opening the perspective that even very small datasets will still guarantee a reasonable quantification result for the main sample ingredients.figure  <dig> 
determination of the optimal number of sequence reads necessary to obtain accurate quantification results for species components. the number of sequence reads used in the mapping  was plotted against the values of mapping accuracy , calculated as the cumulated absolute deviation in% of mapping results versus expected species proportions.



throughput of samples in time will improve, especially when using the miseq® instrument, running only 6 hrs for 50 bp reads. dna size requirements  and input amounts needed  for the nextera xt® protocol  <cit>  are routinely obtained in current pcr-based foodstuff analytics . the slight chance for a wrong allocation of multiplexed samples, which may e.g. be due to erroneous bioinformatic sorting of multiplexing tags, will be substantially reduced by the use of two such tags per sample in the nextera protocol  <cit> . another practical problem which has to be adequately addressed is the possible run-to-run carry-over of dna molecules e.g. due to incomplete removal of residual dna washing from the sequencing device. illumina’s technical notes say that this detrimental effect is typically below  <dig> %  and must be controlled by dedicated device maintenance procedures.

on the bioinformatic side, the read-mapping process can already be carried out on standard pcs with 4 gb of ram using commercial software tools, but is still time-consuming when many reference genomes are inspected. new developments in software programming offer the use of fast and affordable graphics processing units  to analyze massive sequence data in reasonable time. to test if such compute unified device architecture -based programs will speed up our pipeline, we compared the novel mapping tool cushaw  <cit>  to the standard tool bwa for the time needed for analyze the species proportions of the sausage sample. while the accuracy using cushaw appeared somewhat lower than bwa possibly due to algorithmic differences , time improvement using cushaw was substantial with a  <dig>  to  <dig> -fold speed-up, depending on the number of threads  bwa was allowed to use. cushaw thus could cut the time needed for read mapping on a pc roughly by half.

the biggest limitation in our pipeline in terms of time and costs was set by the massive blast routines  necessary for the metagenomic step. our adhoc calculations suggest that additional costs  have to be considered, if access to a commercial computing facility is needed. the cautionary tale of the wrongly assembled/annotated neisseria reference genome in our metagenomic step illustrates that the correct interpretation of the blast/megan results still requires substantial biological and bioinformatical knowledge. the use of curated sequence database information and/or the application of dedicated repositories containing validated species-specific sequence data  will greatly simplify this step for non-specialists on the food control side. we wish to point out that a number of highly innovative approaches for the identification  of species have recently been established in the field of bacterial metagenomics, making use of curated taxon-specific sequence databases , ultrafast algorithms for sequence pattern recognition  or a probabilistic framework for read assignment to very closely related genomes . integration of these tools is a promising option for further improvement of afs.

CONCLUSIONS
afs has the potential to be a valuable method for routine testing of food material and other biosurveillance applications, offering an attractive combination of unbiased screening for all types of ingredients and the possibility of simultaneously obtaining quantifiable results. since deep dna sequencing has already revolutionized biological and medical research, it may find its way into routine diagnostics soon. afs implementation currently requires elaborate knowledge of genomes and bioinformatics, but several strategies are conceivable to further simplify and standardize the approach.

electronic supplementary material
additional file 1: table s1: reference genomes used in afs. 

 additional file 2: table s2: mapping results for the reference sausage klyoa. 

 additional file 3: table s3: plant components: spiked in proportions and respective blast-hits. 

 abbreviations
afsall food sequencing

kaldkalibrator d

klyoakalibrator lyoner a

gpusgraphics processing units

ngsnext-generation sequencing.

competing interests

the authors declare that they have no competing interests.

authors’ contributions

th, fr, fk, mw and rk conceived the study. fr, fk, as and mw evaluated datasets. yl and bs improved afs routines and benchmarked datasets. rk contributed dna material and unpublished food-related data. th, fr and fk drafted the manuscript. yl, bs, rk and mw revised the manuscript. all authors approved the paper in its final version.

