BACKGROUND
until fairly recently, little research has concentrated on design and quality issues in microarray studies. instead, most research has been devoted to developing methods for analysis. indeed this is understandable as the final endpoint of any study is to answer the biological questions of interest. however, the importance of experimental design and quality control cannot be over-emphasised, as experiments that have not been designed based on sound principles are more likely to produce poor quality data, which in turn affects all downstream processes  and thus lead to unreliable or misleading results. work by researchers such as  <cit> , etc. have attempted to address the deficit in the area of experimental design. however, far fewer researchers have tackled the issue of quality control, some exceptions being the work done by  <cit> .

in microarray studies, researchers are often interested in comparing two or more mrna samples either to determine which genes are differentially expressed or to detect different subtypes  <cit> . the approach adopted in analysing the data depends not only on the question of interest, but also on the quality of the microarray data. statistical methods such as cluster analysis may be quite sensitive to the process of filtering out poor quality expression data , whilst other methods such as principal component analysis and singular value decomposition cannot be used when missing data are present in the matrix of gene expressions  <cit> .

missing data in microarray experiments occur for a number of different reasons, including the quality of the clone preparation and of the mrna, image corruption, the printing process, the presence of dust or scratches on the array, saturation, incomplete hybridization etc. in the pre-processing of the raw intensity data , quality assessment of individual spots plays an integral part. poor quality spots, either flagged up manually or through quality measures provided by the image extraction software or developed in the literature, are usually filtered out so as to prevent bias in results. additionally, negative background-corrected intensities become undefined if a logarithmic transformation of the data is used, and must be removed. thus this filtering process may potentially lead to a substantial amount of missing data, in particular for cdna experiments when a relative measure of gene expression is of interest and therefore valid intensity measurements in both the red  and green  channels are required. consequently, compared to the situation when there is complete data, the efficiency and power of any analysis performed on the filtered data may be substantially reduced.

furthermore, if data "missingness" is due to the removal of less reactive spots or intensities below some pre-defined  limit of detection, then any analysis performed on the incomplete data set may be subject to unwanted bias. the incomplete data set may not be representative of the complete data set, as the filtering process may be highly selective in the types of genes affected. thus the missingness is informative, and ways of appropriately addressing the missingness are required to obtain more relevant and meaningful results. in particular, replacing undefined logarithmic data with zeros or shifting the data by a positive constant, although common approaches, may not be valid.

it is generally agreed that experimental replication  and repeated measurements  are fundamental requirements in the experimental design of microarray experiments, as they are critical for reliably distinguishing noise from other sources of variation , thereby increasing the reliability and consistency of results obtained  <cit> . furthermore, as we will show, replication may serve the additional purpose of allowing a more thorough determination of spot quality and open the way to handling poor quality spots through imputation or weighting. in this paper we describe a modelling approach to "repair" microarray data sets that, by the filtering of poor quality or negative intensities, have missing data.

RESULTS
example
we apply our method  to background uncorrected intensity data obtained from an experiment performed to observe gene expression changes with  <dig> hr paclitaxel  treatment on a human cervical cancer derived cell line . in this experiment the cells were treated with l <dig> nm paclitaxel at 50% confluency and left for  <dig> hours prior to rna extraction. six independent rna biological replicates  were created for treated samples. these were compared using identically configured  <dig>  k human cdna microarrays  with a common reference dmso-treated sample used as control. each array had  <dig> probes spotted.

to calibrate and stabilize the variance of the background uncorrected intensity data, the inverse hyperbolic sine  transformation of  <cit>  was applied using the "vsn" package in r . the ri  plots  of the transformed data for the six arrays showed that the transformation stabilized the variance reasonably well for most of them. however, array  <dig> had rather different scale and offset parameters than the other five arrays. this may be indicative of a "problem" with array  <dig>  although not necessarily, as the arsinh transformation may have corrected for any systematic differences between the six arrays. however, as will be seen later, array  <dig> was observed to have the largest proportion of spots identified as being of poor quality amongst the six arrays.

the results of fitting the mixture model described in the methods section to our data are presented in the tables below. the parameters α and ε were set to  <dig> and  <dig>  respectively. estimates of some of the location parameters, the variances and the component probabilities are shown in table  <dig>  the automated approach estimated that approximately 81% of the intensities in channel f <dig>  were of good quality, whilst 98% of the intensities in channel f <dig>  were estimated to be of good quality. table  <dig> displays the number and proportion of poor quality  spots identified by our proposed method under stochastic flagging. we observe that there are significantly more poor quality data predicted for the f <dig> channel than the f <dig> channel. further, we observe that array  <dig> has the highest proportion of failures in both channels amongst the six arrays , thus confirming our earlier observation. this array is partly responsible for only 81% of the intensities overall in f <dig> being of good quality. when array  <dig> is removed and the quality assessment is repeated the failure proportions for each channel are more evenly spread across the five remaining arrays  and the percentage of good quality intensities in channel f <dig> improves to 90%, whilst in channel f <dig> it becomes 97%. interestingly, of the double failures occurring in array  <dig> through to array  <dig>  the percentage of unreliably low poor quality spots in both channels were approximately 5%, 83%, 60%, 33% and 87% respectively.

it was reassuring that the majority of spots identified by eye as of poor quality  prior to undertaking the automatic quality assessment analysis were also identified through the proposed method.

an example of the type of spots clearly identified by eye and also identified through use of the model as being of poor quality is shown in figure  <dig>  here dust on the slide at this spot position has caused an obvious saturated flash in both channels of array  <dig>  by imputation under stochastic flagging, we have replaced these poor intensities with more reasonable intensity measurements that are comparable to the same spot on the other five arrays. in addition to identifying these clear "outlier" spots, note that more subtle differences between replicates that could not be picked up manually by "eyeing" the data are easily detected with the automated approach.

the resulting bivariate scatter plot of the transformed data using our model  to predict the quality labels is shown in figure  <dig>  most of the data fall in the middle box, whilst the majority of data are in the upper right four panels. this indicates that most of the poor quality data were of the unreliably high variety. note the strong positive correlation between yik <dig> and yik <dig> in each cell of figure  <dig>  this clearly reflects underlying correlations in the μ1k <dig> and μ1k <dig>  for example. note that this does not conflict with the conditional independence assumption for our model, which as stated in the methods section, concerns the residuals rik <dig> and rik <dig> note also that overlap in intensity measurements across panels is allowable, as each spot intensity measurement for a particular probe is made relative to the replicate spot intensities for that probe across arrays.

here the strong positive correlations that were observed in figure  <dig> is now only apparent in the middle panel and the lower left-hand panel. we have experimented with more elaborate models that take account of this dependence, but the results were not substantially changed. we therefore prefer to stay with the model described in the methods section, as it is simpler.

in the microarray literature, a number of approaches have been developed for missing value estimation or imputation. these approaches range from the simple "replace missing entries with zeroes" and row-average approaches to k-nearest neighbourhood  approach and its variants such as the sequential knn  approach  <cit> , to singular value decomposition  and bayesian principal component analysis  methods  <cit> , to least square, regression and maximum likelihood approaches  <cit> . the most popular of these is the knn approach, which was shown by  <cit>  to outperform the row-average and svd approaches. however, in terms of root mean square error , it was shown not to perform as well as the more complex and time consuming approaches  <cit>  that have been recently proposed or its variant sknn approach, which was shown to have improved accuracy in estimation of missing data with high computational speed. additionally, an imputation approach using gaussian mixture clustering  <cit>  has been developed and found to be more accurate than the svd and knn approaches. this imputation method is similar in spirit to our mixture modelling approach.

we have compared the imputation part of our approach with the knn and sknn approaches for missing data estimation. we assume that the imputed data set constructed from our example above is a "true" data set. from this true data set, we randomly select  <dig> spots, and perturb their f <dig>  intensities by any independent gaussian random variable with mean ±  <dig> and variance  <dig>  these probes may then indicate possible "high" or "low" poor quality spots depending on how extreme the applied perturbations. from this newly pertubated data set, we apply our method to flag poor quality spots. of the  <dig> pertubed spots, those flagged were then filtered and the knn and sknn methods were applied to repair the data for these spots. the root mean square errors  of the knn and sknn methods were then calculated for these flagged spots and compared to the rmse obtained from our mixture model assuming that the flagged intensity data were replaced by the appropriate "good quality" spots' mean parameters. we repeated the above ten times and the average root mean square errors were calculated for the three imputation approaches.

it was found that on average  <dig> of the  <dig> randomly chosen spots were flagged by the quality assessment step of our method. the rmse for our mixture model approach was  <dig> , which was substantially smaller than the rmses for the knn and sknn approaches, which were  <dig>  and  <dig>  respectively.

discussion
we have demonstrated an alternative approach to assessing the spot quality in cdna microarray experimentation. the method requires replicate arrays in order to assess whether a spot signal is a true signal or not. its strength lies in the use of information found within and, also importantly, between arrays. thus we are able to separate different components of variability found in microarray experiments. this then allows us to be able to identify subtle problems that cannot be detected by considering each array separately, as well as the more obvious problems such as dust and comet tails. data that appear to be good when assessed within an array, need not be reliable when assessed against corresponding data from replicate arrays. thus replication increases the power of detecting poor and good quality spots and therefore reduce the false positive and false negative rates.

the data from replicate arrays, in its raw or background corrected form, may in general not be comparable because of the need for separate calibration and normalization of the arrays. we chose to use the inverse hyperbolic sine transformation of  <cit>  to do the necessary calibration and normalization. this transformation was shown to be very effective and robust when compared to alternative transformations discussed in the literature.

our approach has the additional advantage of not filtering out data but instead imputing new data to replace the spots  identified as being unreliable. of course, it is necessary to acknowledge that these imputed data are not real data and therefore suitable measures must be taken to account for the resulting uncertainty in further analyses using these repaired data. we advocate the use of multiple imputation as a way to avoid spuriously precise results. furthermore our method performed favourably to the knn and sknn missing data/imputation approaches, with the added generality/advantage that it not only repairs poor quality spots but identifies them.

alternatively instead of imputing new data, our approach can be used to assign weights to each spot. these quality weights can then be used under various strategies to down-weight spots thought to be of uncertain quality in downstream microarray processes, such as normalization and statistical analyses. some researchers have advocated filtering of unreliable spots to avoid biasing results. we believe that the filtering of spots does not necessarily remove biases, but may actually introduce bias if the data filtering process is informative. that is, for example, if the filtering process is highly selective in removing certain types of genes and therefore the resulting filtered data set will not be representative of the true data. as our approach is dependent on having replicates, it is natural to ask how many replicates are required. however, the number of replicates required depends on a number of factors, such as the type of microarray experiment to be performed , the reliability of the experimental system used , the cost, etc. in the example above, five or six replicates appeared to be a reasonable number. however in other types of experiments a larger number of replicates may be required.  <cit>  provide a useful discussion regarding this question.

CONCLUSIONS
as the quality of microarray experiments affect downstream processes, it is essential to have a reliable and automatic method of flagging and then repairing poor quality spots. we have proposed a mixture model method to accomplish this two-step process of identification and imputation, and thereby producing a repaired/complete data set which is less biased than before.

