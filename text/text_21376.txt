BACKGROUND
introduction
ultraconserved elements  are perfectly conserved regions of genomes shared among evolutionary distant taxa. usually it is assumed that these regions are identical in closely related species and have minor differences in relatively distant ones, which substantially limits the phylogenetic distances. generally these are untranslated regions. uces were first described in mammals, where several hundreds of identical regions more than 200 bp in length have been reported  <cit> . knockouts of certain uce loci in mice resulted in viable fertile offspring suggesting a cryptic role of uces in genome biology  <cit> .

then, uces were found in other vertebrates as well as in invertebrates and plants. for example, hundreds of conserved noncoding sequences were detected in four dicotyledonous plant species: arabidopsis thaliana, carica papaya, populus trichocarpa, and vitis vinifera  <cit> .

makunin et al.  <cit>  used preliminarily generated multiple alignments of insect genomes with the genome of drosophila melanogaster as well as the genomes of vertebrates with the human genome; a 100-bp sliding window was used to find identical uces in drosophilids and vertebrates, and the number of uces in insects proved to be much lower compared to vertebrates. as an alternative, uces can be identified using the method described by kent et al.  <cit>  based on pairwise alignments of complete genomes generated by blastz  <cit> .

a number of studies such as  do not rely on genome alignments for the identification of uces, which seems generally advantageous. thus, reneker and shyu  <cit>  proposed an algorithm for the identification of short conserved dna regions based on a hash table mapping all short words represented in the chromosome. it was used to search conserved sites and repetitive sequences in different prokaryotic and eukaryotic species. later reneker et al.  <cit>  used this method with 8-bp words to identify and analyze uces of at least 100 bp in plants and to expand the uce sets in vertebrates.

christley et al.  <cit>  offered a public domain software embedded into the biococoa library. it is based on a combinatorial algorithm that considers pairs of genomes using suffix arrays, after which the intersection is taken for all pairs; no alignments are involved. the method is claimed to be much faster than blast and is comparable in speed to the algorithms based on suffix trees. uces were identified in  <dig> genomes of vertebrates.

identical uces are available in regularly updated databases and online resources such as ucbase  <cit>  for humans and ucnebase  <cit>  for vertebrates from human to zebrafish.

uces can be used in phylogenetic studies. this relies on a phylogenetic signal that can be embedded in uce flanks; their variation increases with the distance from the conserved core  <cit> . the conserved region allows easy alignment across widely divergent taxa, while variation in the flanks is useful for comparative analyses  <cit> . in this case, uce-containing loci are sequenced in fairly closely related species. in particular, this method was applied to reconstruct the phylogeny of  <dig> avian species including pavo and five co-distributed neotropical rainforest bird species  <cit> . similar studies were conducted on the phylogeny of birds in neoaves  <cit> , all major reptile lineages including tuatara  <cit> , and fish  <cit> . mccormack et al.  <cit>  used identical uces of reptiles  to design  <dig> in silico probes, which were aligned with the available mammalian genomes, after which the flanks of the resulting regions were also aligned. the data obtained suggested the phylogeny of amniotes. glazov et al.  <cit>  have found all identical matches longer than 50 bp between the genomes of the mosquito anopheles gambiae and two fruitflies drosophila melanogaster and d. pseudoobscura, all of which belong to the order diptera.

the average similarity between regions from uce decreases as more distant taxa are included, which gave rise to the term highly conserved elements . the identification of hces is also considered in numerous publications, many of which rely on alignments and percent identity-based methods .

after the identification of hces in placental mammals, the evolution was investigated by extending these hces to opossum, chicken, frog, and fugu  <cit> . the identified hces demonstrate minor differences in the corresponding regions, while their number substantially increased, to  <dig>  this work was further extended to elephant shark using the same approach  <cit> .

the database ancora provides non-exonic regions of high similarity between genome sequences from distantly related metazoan organisms: human, mouse, dog, horse, chicken, zebrafish, tetraodon, drosophila , caenorhabditis , aspergillus oryzae , and dictyostelium discoideum   <cit> . these hces were identified by scanning pairwise whole-genome alignments obtained with blastz for regions with identity of 70-100 % depending on the evolutionary distance.

faircloth et al.  <cit>  used pairwise alignments of the genomes of honeybee and nasonia vitripennis to identify about  <dig> of identical uces with the length of at least 40 bp, which were confined to hces with at least 80 % identity to their counterparts in two other insect genomes with a lower coverage . target sequencing of the selected hces in  <dig> species from different hymenopterans made it possible to refine the phylogeny of this taxon. the lastz program  <cit> , an improved version of blastz, was used in this analysis.

siepel et al.  <cit>  presented an approach to hce identification based on multiple genome alignments. in this case, a comprehensive search was conducted separately in four groups of organisms: five vertebrate species , four insect species , two species of caenorhabditis, and seven species of saccharomyces. the elements were identified in multiple alignments using the phastcons program, which is based on a two-state phylogenetic hidden markov model. multiple alignments for each species group were prepared using multiz, which builds a multiple alignment from local pairwise alignments of a designated reference genome with all other genomes in the group of interest  <cit> , pairwise alignments were obtained by blastz. as a result, from  <dig> thousand to  <dig>  million hces with the length up to  <dig> kbp were predicted, and these hces are more phylogenetically justified and rich in secondary rna structures.

thus, ample data are available on the identification of both uces and hces for phylogenetic reconstructions of plants, fungi, and animals. however, little is known about uces and hces in protists.

summary
in contrast to the special case of identification of uces, sets of identical words in not too distant genomes, for which fast algorithms are available, the identification of hces, sets of notably different words in more evolutionary distant genomes, is a rather complex computational problem. to our knowledge, no fast algorithm is available for it. a number of studies performed hce identification using pre-identified uces, which were supplemented by similar words from new genomes. other studies relied on time-consuming generation of alignments rather than on pre-identified uces. in contrast to these approaches, the proposed algorithm identifies hces from scratch relying on neither known uces nor alignments, and it seems faster than other methods.

the standard methods based on the comparison of gene coding regions have been widely used to generate taxonomies and reconstruct species evolution over a long period of time. later, the coding regions were supplemented by the primary and secondary structures of the regulatory regions of genomes  as well as uces and hces. all these different approaches to taxonomy and evolution favor their better understanding. it bears repeating that hce identification in distant species is a nontrivial computational problem. this particularly applies to apicomplexans due to different rates of their evolution as well as the rate of evolution in apicomplexans relative to that in better known animals and plants. clearly, the hce-based approach can only be used to supplement more traditional approaches to taxonomy and evolution. comparisons of results obtained using hce identification by the method proposed and those obtained using traditional methods are sampled below in the results and discussion . specifically, the comparisons apply to the superphylum alveolata and, in our next work, to mitochondria of ciliates .

mathematical aspect
mathematically, the identification of hces might be reduced to building and clustering a graph with nucleotide sequences assigned to its vertices. the edge weight usually reflects the similarity between the sequences at the edge ends. the weight is often computed from a global alignment using the needleman–wunsch algorithm or from a local alignment using blast.

the majority of clustering methods utilize various strategies to construct “heavily connected components,” i.e., the clusters that include only vertices mainly connected by high-weight edges. various clustering approaches were proposed, from specifically organized partitioning of the spanning tree of the initial graph  <cit>  to time estimation of random walk on a graph . in the latter algorithm based on markov chains, a walk within a cluster should be long and jumps between clusters should be rare  <cit> . the description of orthomcl implicitly states that its convergence is difficult to discuss even hypothetically. a single cluster can be found by the meme algorithm  <cit> , which seems to be well suited for general graphs not divided into parts.

let us recall that a multipartite graph has a vertex partition into disjoint subsets . it does not have edges connecting vertices inside any part. a subgraph of the multipartite graph is called m-dense if each its vertex is connected to vertices from at least  different parts. clearly, an m-clique  in a multipartite graph is an m-dense subgraph. notice that there exist 3-dense 3-partite graphs that contain no 3-cliques. it is important to identify m-dense subgraphs with a high total weight that include not many vertices from the same part, e.g. subgraphs which contain no more than γ vertices from each part; the preferred γ value is  <dig> or very small. the m, γ and edge weight parameters should be given in advance. the identified m-dense subgraphs in a given multipartite graph can be screened one by one for cliques of cardinality m or less. any m-dense subgraph with small value of parameter γ may be called a cluster. worth mentioning is the clustering method that we used previously. when the size  of a cluster is known in advance, e.g., in multicomponent systems where the length of the orthologous series is known for one component, the most dense cluster of this size is constructed using the algorithm described in  <cit> . closely related methods are described in .

due to the heuristic nature of these procedures, the comparison of the algorithms is hard to formalize, especially in the absence of standard benchmarking data.

here we propose a novel universally applicable and freely available software package for hce identification  <cit> . our software does not rely on known uces, nor hces, which makes it applicable to unstudied taxonomic groups. the package includes original algorithms for the graph generation and clustering, which allow the identification of hces that consist of not only similar regions but also relatively dissimilar regions from distant species. specifically, the algorithms rely on the generation of a sparse multipartite graph  from pairs of similar regions, compaction of it into the so-called initial graph, and massively parallel identification of dense subgraphs in the latter graph, which are considered as hces.

species analyzed by the method
many of apicomplexan species considered below are agents of protozoal infections: perkinsus marinus, in mollusks; ichthyophthirius multifiliis, in fish; many apicomplexans, in birds and mammals; and the full list of their hosts is much wider. the evolutionary distance between apicomplexans can be very high, in particular, due to the positive selection pressure on them; there are many relevant publications putting forward similar claims, e.g.  <cit> . this complicates the identification of highly conserved elements in alveolates, which is overcome by our algorithm.

alveolates include four major lineages: ciliates, dinoflagellates, chromerids, and apicomplexans  <cit> . chromerids are phylogenetically related to apicomplexan parasites and contain photosynthetic plastids, while apicomplexans have a non-photosynthetic plastid called the apicoplast  <cit> . the coral-endosymbiotic algae chromera velia and vitrella brassicaformis share a common ancestry with apicomplexan parasites  <cit> . plastids are also found in the dinoflagellates lepidodinium chlorophorum  <cit> , durinskia baltica, and kryptoperidinium foliaceum  <cit> .

neither cryptosporidium parvum  <cit>  nor gregarina niphandrodes  <cit>  have plastids. gregarines are early diverging apicomplexans. thus, it is not clear whether the common ancestor of apicomplexans had plastids.

the protozoan parasite perkinsus marinus is a facultative intracellular parasite of mollusks. its close relationship with the apicomplexa was initially proposed based on the ultrastructural analysis of the zoospore, which revealed the presence of organelles resembling an apical complex  <cit> . the transcriptome analysis of p. marinus suggests the presence of a relict plastid. furthermore, p. marinus sequences display significant similarity to those from both apicomplexans and dinoflagellates  <cit> .

tetrahymena thermophila is a model ciliate species. it exhibits between non-coding rna–genome interactions leading to the removal of one third of the genome in developing somatic nuclei  <cit> . let us recall that the micronucleus and the macronucleus are separated inside the same cell, but they have a common genetic source. in vegetative life, the micronucleus is transcriptionally inert.

finally, this work proposes a novel universally applicable and freely available software for hce identification. analysis of hces found with the help of it provided essential information on the phylogeny in the superphylum alveolata.

methods
following the data subsection, we describe our major result, the method for highly conserved element identification.

data
all genomes analyzed are available either in the eukaryotic pathogen database resources  <cit>  or in genbank  <cit> . see table  <dig> for details.table  <dig> all used species and their genome accession numbers

 
cyclospora cayetanensis strain chn_hen01
 
eimeria falciformis bayer haberkorn 1970
 
hammondia hammondi strain h.h.34
 
neospora caninum liverpool
 
sarcocystis neurona sn3
 
toxoplasma gondii me49
 
plasmodium berghei anka
 
plasmodium chabaudi chabaudi
 
plasmodium falciparum 3d7
 
plasmodium yoelii yoelii ym
 
babesia bovis strain t2bo
 
babesia microti strain ri
 
theileria annulata strain ankara
 
theileria equi strain wa
 
theileria orientalis strain shintoku
 
theileria parva strain muguga
 
cryptosporidium baileyi tamu-09q1
 
cryptosporidium hominis tu502
 
cryptosporidium meleagridis ukmel1
 
cryptosporidium muris rn66
 
cryptosporidium parvum iowa ii
 
gregarina niphandrodes
 
ascogregarina taiwanensis
 
chromera velia ccmp2878
 
vitrella brassicaformis ccmp3155
 
perkinsus marinus atcc 50983
 
tetrahymena thermophila sb210
 
paramecium tetraurelia strain d4-2
 
ichthyophthirius multifiliis strain g5
 
stylonychia lemnae 2x8/2


unfortunately, the genome data contains many short contigs due to incomplete assembly. nuclear chromosomes have been assembled for a few apicomplexan species: babesia bovis  <cit> , theileria parva  <cit> , theileria annulata, neospora caninum, toxoplasma gondii, plasmodium spp., and cryptosporidium spp.

also, we used genomes of ichthyophthirius multifiliis, paramecium tetraurelia, stylonychia lemnae, and tetrahymena thermophila from the phylum ciliophora  as well as perkinsus marinus from the phylum perkinsozoa.

an overview of the method
conceptually, the method performs a fast search for pairs of words  of maximum length with the difference below the specified edit distance. such pair defines an edge whose weight equals the maximum  length of words assigned to its ends. the graph composed of these edges is then compacted by merging some of its edges and vertices. the dense subgraphs are identified by a cellular automaton-like algorithm; each subgraph defines a cluster composed of similar inextensible words from different genomes. almost all clusters are considered as predicted highly conserved elements.

technically, the method consists of the three following stages: a source graph is built from source data, this graph is used to construct an initial graph whose vertices and edges are generated by merging the vertices and edges of the source graph. the latter graph is used to construct the final graph containing only a fraction of vertices and edges of the initial graph. in the final graph the connected components are identified, which is the result of our method. these components are also called clusters. sometimes, one of the clusters includes the great majority of vertices; such cluster is referred to as a giant cluster. a giant cluster is our method’s limitation; other clusters are considered as predicted hces. figure  <dig> shows the main stages of the method.fig.  <dig> stages and algorithms of the method



an arbitrary region of sequence a between positions i and j  will be referred to as a word a. the edit distance λ is defined for a pair of words  <cit> , which depends on fixed costs δi, δd, and δs of edit operations for character insertion, deletion, and substitution; they are subject to the usual constraints: all substitution costs are the same and δi = δd . the insertion/deletion cost is often set greater than that for substitution; below we assume all costs equal to  <dig> for simplicity. the edit distance equals the minimum number of operations transforming one word into another. our software allows arbitrary costs; in this case the edit distance equals the minimum total cost of the series of operations. an arbitrary word w = 〈w1w2 … wl〉 occurs in sequence a = 〈a1a2 … an〉, if there are positions 1 ≤ i ≤ j ≤ n in it, for which the edit distance λ  ≤ ε, where ε is a given threshold . this relationship will be referred to as w ≈ a. the threshold ε is usually not high; e.g.,  <dig> character substitutions, insertions, and deletions for the word length l =  <dig> 

thus, we are given m genomes each of which is represented by a set of sequences using the same alphabet. each set contains sequences with the total length not exceeding n. good data correspond to well-assembled genomes ; in this case, the number of sequences in a set is relatively small. the problem is to find all words with length l ≪ n that occur in at least m ≤ m sequences from different genomes and to specify their positions in the sequences. here l and m are parameters of the problem.

let us make a remark on the algorithm memory and time complexities. if each genome consists of a single sequence a = 〈a1a2 … an〉 of length n, the algorithm consumes the largest amount of memory, because it works with each pair of the top level sequences from each two genomes. the longer first sequence of the pair, the more memory is required. if the necessary amount of memory is not available, the sequence a may be split into parts with a small overlap. however, this requires the identified clusters to be analyzed for duplicated words occurring at the cuts. the time complexity depends on the total length of genomes irrespective of the number of sequences in those genomes.

parameters of the method
let us list all parameters. two of them reflect the dimension of the problem: the number of genomes m and the greatest total length of all sequences that belong to one of the genomes n. next, there are two main parameters, the minimum allowable length of words to search l and the maximum edit distance between them ε. since hce characteristics are not known in advance, l and ε make it possible to control the trade-off between the prediction completeness and computation time. the value of ε is associated with the costs of replacement δs and insertion/deletion δid operations in our procedure of semilocal alignment  of sequence regions; these three parameters are concordantly specified by the user based on the desired difference between words. the parameter d is the minimum length of overlapping between words in each group of words  that belong to the same sequence; this parameter modulates the integrity of clusters. specifically, clusters are fragmented and merged as d increases and decreases, respectively. the values of l and ε uniquely determine the key length k and the maximum number of deletions d for lack of insertions in the same word, or vice versa  in the stage  <dig> section and additional file 1). the values of k and d can be independently varied by the user to accelerate calculations, although it can sometimes cause underpredictions. the parameter m specifies the lower bound of the number of species  represented in hces; it is common to vary the m value. accessory parameters include t  and r ; these parameters can accelerate the algorithm by excluding low-complexity words from the search.

the main complication is the dimension of the problem to solve: the total sequence length n in each given set can be very high , and the number of sets m can be in the hundreds or more. the brute-force approach has a quadratic complexity with o comparison operations and the total memory of o. this does not allow this problem to be solved even using current supercomputers. the known fast algorithms for the word search in a sequence  are inapplicable here since they only find exactly matching words.

an efficient method based on our fast algorithms 1– <dig> and tailored to parallel computation is presented below, in three stages . these stages differ in scalability, so different number of processors or even distinct supercomputer can be appropriate for each of them.

stage 1: identification of candidate words in two sequences
the three following notes explain what underlies the high performance of our method.

 a straightforward quadratic algorithm checks the presence of each word from sequence b in the given sequence a. instead of that we use indexing the sequence a, which is performed once and then reused many times.

 highly conserved elements are identified so that the distance between words is low, i.e., the words become identical in no more than ε insertion, deletion, and substitution operations. thus, target words a priori include exactly matching subwords of length k that can be used as search keys. for instance, the key length k ≈  <dig> for the above parameters ε =  <dig> and l =  <dig> 

 after matching keys are identified, each key in each of such pairs is extended in both directions as long as the distance between words  does not exceed ε, their total length is the longest, and each word is not shorter than l.

the distance between words is usually evaluated using the needleman–wunsch global alignment algorithm  <cit>  with the complexity of o. but this algorithm assumes that the ends of words are fixed, while in our case only the beginning or end of a word is invariable depending on the extension direction. the application of local alignment algorithms  is excessive here since one of the word extremities is fixed . because of that, we use an original variant of the needleman–wunsch algorithm called semilocal alignment. since this variant makes allowance for the threshold ε and uses a limit d of the number of deletions, its spatial and temporal complexity is o, as shown in additional file  <dig>  thus, semilocal alignment algorithm is linear in l as against the conventional quadratic algorithm.

based on the above three notes, the algorithm  <dig> explained below is applied to each unordered pair of sequences 〈a, b〉 from different genomes .fig.  <dig> the flowchart of algorithm 1



first, sequence a is indexed according to note  as follows. let k be the key length set according to note  above. a hash table ha is filled with all available keys, i.e., words of length k in sequence a along with their starting position in the sequence: ha=hai≡ka,jj|ka,j=aj..j+k− <dig> i=hashka,j, 

where hash is a hash function mapping the key to the table slot number. collisions appearing as the hash table is generated decrease the algorithm efficiency. they stem from the imperfect hash function and duplications of the same word of length k in the source sequence. the rate of the former collisions can be reduced by selecting a different hash function and/or by decreasing the load factor of the table . the latter collisions cannot be avoided, although their rate decreases with k. table  <dig> illustrates the rate of such collisions for real data . here, such collisions at k =  <dig> appear in more than 20 % of cases; however, their rate decreases below 4 % as the key length increases to  <dig>  repetitive keys usually belong to genome regions of low complexity that are discarded here ; we use the occurrence threshold t for a key in the considered sequence, and keys that occur more than t times are discarded. since the collisions are inevitable , we have chosen a hash table with separate chaining. the hash table size depends primarily on the length of sequence a and chosen load factor. considering that sequence b is not involved here, the index is generated once for all sequences a in parallel and then repeatedly used for all b sequences in accordance with the note .table  <dig> the number of repeating keys of length k in the long sequence of the complete genome of sarcocystis neurona


k = 16
k = 24
k = 32
k = 48


after the hash table ha is built, the following steps 1– <dig> of the algorithm  <dig> are applied to one or more sequences b.for each position j of sequence b, use the word kb,j = b as the key for the hash table.

check if the key occurs in ha; if not, loop to step  <dig> using the next position j.

if there exists s such that ha = , a new pair of candidates has been found starting at positions i and j in sequences a and b, respectively. if the element ha contains a chain of positions j due to multiple occurrences of the key, all  pairs are checked. however, we skip the pairs with a different key which can occur as a hash function limitation.

the identified pair of candidates is tested for key extension to approximately matching words of interest; if successful, the words are stored. the extension algorithm relies on the note ; it is detailed in additional file  <dig>  where it has a complexity of o.

loop to step  <dig> with the next position j in sequence b until the end of the sequence.

repeat steps 1– <dig> for the sequence reverse-complementary to sequence b.



if collisions are neglected, algorithm  <dig> has a complexity of o ⋅ o, i.e., it is linear in the sequence length on average. the memory used, o, is also linear, although the corresponding constant can cause problems for very large n. in the case of a short alphabet, memory requirements can be reduced by compressing keys in the hash table ha: hashed keys ka,j should be transcoded using a smaller number of bits per character and stored compressed in a smaller number of bytes; this does not affect key search in the table if candidate words are transcoded in the same way. since the problem in question applies to sequences using a four-letter alphabet, memory requirements for storing keys in the hash table can be reduced fourfold; it is also convenient to select quadruple k.

to summarize, the overall complexity of the first stage of our method is o for a single pair of sequences. for all unordered pairs, the complexity is multiplied by the number of them to become in the order of o; however, sequence pairs can be processed in parallel as specified below.

let us consider three more points relevant to stage  <dig>  let us recall that hce is considered as a set of words assigned to vertices of an m-dense subgraph . we wish different hces to have the property designated as inextensibility: all words of one hce are not subwords of words of another hce taken from the same sequence locations. naturally, the inextensibility requirement is limited to the set of all identified m-dense subgraphs. in order to meet this requirement, the key extension with the maximum total length of words is chosen at step  <dig> of algorithm  <dig> 

only words of sufficient complexity are of interest. complete genomes include long regions composed of one or two symbols repeated many thousand times, e.g., at-repeats. hces containing words from such regions are ignored. the exclusion of simple highly repetitive words also decreases memory usage and accelerates our algorithm. this is realized also at step  <dig> by the ziv–lempel compression algorithm  <cit>  implemented in the gnu gzip utility  <cit>  with the threshold r empirically defined for the compression ratio.

in the presence of m/ <dig> or more processors, stage  <dig> is executed in parallel for each unordered pair of genomes independent of other pairs. the algorithm is most efficient when a sequence a of one genome is compared with all sequences b of other genomes in the separate process, in which case algorithm  <dig> operates in parallel on m −  <dig> processors . intermediate options with different numbers of parallel processes can be used to balance the computational burden between processors; we have considered this problem elsewhere  <cit> .

the result of the first stage is a huge set of isolated edges; taken together they constitute the source graph with low vertex degrees. from our experience, the number of edges in it is typically closer to the number of vertices rather than to the squared number of vertices; the graph usually consists of many disjoint components. this is an edge-weighted graph; the edge weight is the maximum length of words assigned to its ends. the weight is evaluated at this stage and remains unaltered later. sometimes it is more convenient to use a monotonic function of length of these words instead of their maximum length. a graph part is defined as all words of the source graph which belong to sequences of the same genome. there are no edges within a part. thus, we get an m-partite graph that is further processed.

stage 2: compaction of the source graph
the properly extended keys are assigned to the ends of the edge defined by this pair of words in the source graph. since edges are built at the first stage irrespective of the other edges, certain edges can have vertices corresponding to roughly the same location in a sequence but with different word ends, fig.  <dig>  at this stage, algorithm  <dig> merges overlapping vertices along with incident edges, thus compacting the source graph. specifically, algorithm  <dig> checks words of each sequence in ascending order of their middle position. the maximum set  of consecutive words from the same sequence that overlap by at least d characters forms a new vertex. if this requirement is not satisfied, the current word initiates a new group. thus, each new vertex corresponds to its own group of consecutive words from the same sequence, and these groups are disjoint. this compaction of the source graph is done separately for each sequence, maybe in parallel.fig.  <dig> the compaction of the source graph by algorithm 2: a three word pairs identified in three sequences and the corresponding edges of the source graph; b union of words at new vertices, the intersections are marked by a darker color; edges x and y merged into edge z




during merging, old edges are first transferred to new vertices; however, if multiple edges emerge between two new vertices, the edge with the highest weight is kept. each new vertex is assigned a union of all words of the corresponding group. the intersection of these words is also stored. such unions and intersections are useful for the analysis of future hces. each new vertex specifies an approximate position of an hce word in the corresponding genome.

thus, at the second stage the source graph is compacted by merging all vertices with corresponding words overlapping at a length of d or greater, thus producing so-called initial graph. the complexity of this stage is linear in the number of vertices in the initial graph and is naturally parallelized over the number of sequences.

stage 3: identification of dense subgraphs
at this stage, algorithm  <dig> recognizes the m-dense subgraphs of the initial graph, primarily, with the highest total edge weight . the set of identified m-dense subgraphs makes up the solution of the original problem. the resulting graph of this stage is referred to as final.

algorithm  <dig> features deep internal parallelism and is similar in design to a cellular automaton with graph vertices as cells and incident vertices as neighboring cells. an independent process is initiated at step  <dig> shown below at each graph vertex. the processes at all vertices are synchronized after each step  <dig> or  <dig> so that a next step of any process starts only after the previous step was completed at all vertices.

the two steps of algorithm  <dig> are as follows .fig.  <dig> the flowchart of algorithm 3



 <dig>  if a vertex is connected by edges to less than  graph parts, this vertex and all edges incident to it are removed.

if a vertex is connected to a part by a single edge, such edge is labeled; labeled edges may be deleted only together with one of its ends.

if step  <dig> of the algorithm modified the graph, step  <dig> is executed again at all graph vertices.

otherwise, step  <dig> is executed once at all graph vertices.

 <dig>  if an edge incident to the vertex is unlabeled and its weight is strictly less than those of all other unlabeled incident edges , such edge is removed.

if step  <dig> modified the graph, step  <dig> is executed again at all vertices; otherwise the algorithm terminates. the result is the final graph. each of its connected components is the desired m-dense subgraph.

the algorithm  <dig> offers flexible scaling possibilities for the number of processors up to the number of graph vertices and can be implemented on distributed memory systems. if the number of available processors is less than the number of vertices, they are evenly distributed among the available processors, each of which executes the current step of the process at all allocated vertices one by one. the efficiency of parallel computation can be increased by allocating vertices connected by low-weight edges to the same processes and, vice versa, by allocating nonadjacent vertices or vertices connected by high-weight edges to different processes. the optimization of graph vertex allocation among processors is an independent problem. it is hard to evaluate the algorithm complexity analytically; however, it is not practicable since sample calculations of large data volumes demonstrated that the third stage of our method is executed much faster and requires a less powerful supercomputer than the first two ones.

a serious limitation of the method is the emergence of a connected component in the final graph including the majority of graph vertices when improper parameters are used to build the source and/or initial graphs; we referred to it as a giant cluster. the absence of such a component as well as the presence of m-dense subgraphs for m greater than the half of graph parts  indicates a success. our experiments demonstrated that the risk and size of the giant cluster can be decreased by removing all edges with the weight below a certain threshold, the choice of which is an independent problem. the presence of a giant cluster in the final graph not necessarily interferes with the identification of m-dense subgraphs with a smaller number of vertices for relatively high m values.

the substantial result of our method is a set of connected components of the final graph excluding the giant cluster, which are considered as predicted hces. certainly, the definition of the giant cluster depends on the corresponding threshold.

thus, we have developed a parallel algorithm that reduces the initial graph to the final graph composed of only m-dense subgraphs. computer experiments on real data demonstrated that algorithm  <dig> completes the task in a small number of such steps  even for very large graphs . it also features flexible scalability for any number of available processors in a wide range.

RESULTS
as mentioned above, our major result is the method for hce identification set forth in the methods section. the phylogeny of alveolata section below discusses the results obtained by this method for biological data on the superphylum alveolata.

all computing was made using the following parameters: m =  <dig>  n =  <dig>  ⋅  <dig>  l =  <dig>  k =  <dig>  t =  <dig>  δs =  <dig>  δid =  <dig> , ε =  <dig> , d =  <dig>  r =  <dig> , d =  <dig>  and m =  <dig> 

comparison with lastz program
the first stage of our method has much the same goal as the pairwise alignment of genomes in many papers cited in the background section. we used protists data to compare the results of our first stage with those of lastz with default parameters. the comparison was conducted in uniprocessor mode on a 2 ghz linux workstation. specifically, the longest  chromosome of neospora caninum was collated in turn with three well-assembled full genomes: babesia microti of  <dig> chromosomes , cryptosporidium parvum of  <dig> chromosomes , and plasmodium falciparum of  <dig> chromosomes . it took respectively 2 m 16 s, 11 m 35 s, and 30 h 47 m for lastz to process these three data sets. our algorithm  <dig> worked for 1 m 9 s, 1 m 30 s, and 20 m 26 s, respectively. it is arguable that our algorithm is faster and its complexity grows with input data volume not nearly as rapid as for lastz. the memory consumption was 130–204 mb for lastz and 620–645 mb for our algorithm. for the first data set, the number of pairs of similar words  was  <dig>  and  <dig> . however, among of  <dig> alignments found by lastz, at least  <dig> were of low complexity regions; while our algorithm rejected such words. remaining  <dig> alignments included less than a half  of word pairs found by our algorithm. this can be attributed to essentially different functionals used by the two approaches. our algorithm looks for pairs of words that have the maximum length and the edit distance below the threshold, which results in words with the length of 61–109 bp  and 72-85 %  of identity . lastz finds longer alignments , but with a lower identity . the alignments identified by lastz included only  <dig> ones with the identity greater than 70 %, which is less than our algorithm has found. a similar situation is observed for two other data sets: lastz and our algorithm have found  <dig> vs  <dig> word pairs for the second set and  <dig>  million vs  <dig> thousand word pairs for the third set, respectively.

the second and third stages of our method transit from a pairwise genome analysis towards building hces for a set of genomes. the authors are not aware of freely available counterparts of these tools. generally speaking, they may not be necessary when hces are identified using a multiple alignment of genomes; each element becomes evident in many genomes  <cit> . in case of uces, the search using pairwise genome alignments can be based on intersections of pairwise elements  <cit> . in the general case, synthenic chains of elements in orthologous parts of genomes can be selected  <cit> .

the phylogeny of alveolata
the species tree predicted using the derived hce data  is shown in fig.  <dig> and discussed below. the phylum ciliophora was used as an outgroup to root the tree.table  <dig> predicted hces

fig.  <dig> the tree predicted for  <dig> alveolata species using their hces identified by our algorithm



comparison of the complete genomes from table  <dig> and generation of the source graph  were conducted on supercomputers mvs-100 k and mvs-10p in the joint supercomputer center of the russian academy of sciences  <cit> , which required about 200 h on up to  <dig> processors. the subsequent compaction of the graph and identification of dense subgraphs  was conducted on a 32-core server with 256 gb ram and required less than 20 h.

the source graph contained  <dig> , <dig> vertices and  <dig> , <dig> edges. merging of properly overlapped vertices and removing duplicated edges yielded the initial graph with  <dig> , <dig> vertices and  <dig> , <dig> edges. after  <dig> steps of the algorithm for dense subgraph identification, the final graph included  <dig> , <dig> vertices and  <dig> , <dig> edges, which formed  <dig> connected components. the giant cluster included  <dig>  % vertices. it has not been analyzed in detail; however, some preliminary investigation demonstrated that many words in it contain low complexity regions. complexity evaluation of individual regions in a word with overall allowable complexity is another problem not considered here. the remaining  <dig> clusters included  <dig> vertices. detailed data on the obtained clusters including their words and summary data on clusters are available in additional files  <dig> and  <dig>  respectively.

all found words from hces were further analyzed using the following two resources.

 <dig>  genome annotations available in genbank ; it was tested if a word of interest overlaps with the regions of a gene and its coding sequence . if both conditions are satisfied, the word corresponds to a protein ; if only the first condition is satisfied, the word belongs to a gene untranslated region such as an intron .

 <dig>  rfam database  <cit> ; it was tested if the word is a fragment of a known non-protein-coding rna. in this case, additional file  <dig> specifies the rna name and other data.

additional file  <dig> summarizes the data on each cluster including the hce type. specifically,  if any of cluster words was found in rfam, the cluster corresponds to a known rna such as trna, snrna, etc. and is labeled as this rna;  otherwise if any of cluster words overlaps with a cds, it corresponds to a protein  and is labeled as “protein”;  otherwise if any of cluster words overlaps with a gene, it corresponds to an intron or other untranslated region and is labeled as “intron”;  otherwise the cluster describes an unknown hce .

table  <dig> demonstrates that more than 90 % of identified hces correspond to proteins or known rnas. nevertheless, no data were found for  <dig> elements of unknown function as well as for  <dig> elements corresponding to non-coding gene regions. although many of the latter genes are known or were reliably predicted, hces lie in their untranslated regions rather than exons . many of such clusters include only a single word annotated as a presumable gene. these can be errors of automatic annotation. anyway, these  <dig> hces deserve a thorough consideration together with those for which no data are available.

the above  <dig> clusters are largely small, i.e., the corresponding elements are conserved in a small number of species . the number of clusters with  <dig>   <dig>   <dig>   <dig>  and  <dig> species is  <dig>   <dig>   <dig>   <dig>  and  <dig>  respectively.

raxml v.  <dig> . <dig>  <cit>  generated a tree  using a matrix with  <dig> rows and  <dig> columns corresponding to the number of nuclear genomes  specified in table  <dig> and hces identified by our algorithm listed in table  <dig>  cell value of  <dig> and  <dig> in the matrix indicates the presence or absence in a genome of an hce-representing word, respectively. branch lengths have standard meaning of estimated average number of substitutions  per site . thus, maximum likelihood search followed by rapid bootstrapping was performed in raxml using binary substitution model with maximum likelihood estimate for the base frequencies. frequency-based criterion was satisfied after  <dig> bootstrap replicates. all other raxml parameters were left in default setting.

for all genera of apicomplexan parasites, their species group together in the tree. the only exception is babesia spp. a separate position of babesia microti relative to other species of the order piroplasmida in the hce-based tree is in agreement with its isolated position in the plastid tree  <cit> . at the same time, b. orientalis is closely related to other piroplasmida species in agreement with  <cit> .

the genus cryptosporidium is not included in the class coccidia in agreement with  <cit> . it is closely related to the genus plasmodium.

two coral-endosymbiotic phototrophic algae chromera velia and vitrella brassicaformis are closely related, which agrees with  <cit> . species from the subclass coccidia have many common hces with phototrophic algae as well as with perkinsus marinus. here our result is in agreement with  <cit>  as well as with an early observation by levine  <cit> .

two species gregarina niphandrodes and ascogregarina taiwanensis are also closely related and compose an early diverged branch of the group of apicomplexa.

according to our hce-based tree, we can propose that the common ancestor of all the apicomplexans had no plastids. thus, plastids could appear after the gregarinasina isolation, while early apicomplexans with plastids were photosynthetic algae. later these plastids were lost in cryptosporidium spp.

note a good agreement between the trees based on hces and all proteins encoded in the plastids of apicomplexa and chromerida species  <cit>  as well as with chromosomal structures  <cit> .

the isolated position of coccidians agrees with the results of comparative analysis of apicoplast-targeted proteins  <cit> .

CONCLUSIONS
we presented a novel algorithm to identify highly conserved dna elements; it was applied to the superphylum alveolata. the multitude of identified elements was used to infer the phylogeny of alveolata which turned out to be in agreement with other available data. the described method for the identification of highly conserved elements is applicable to other fields where any texts are compared including natural language analysis targeted to identify the author, style, borrowings, etc.  <cit> .

additional files
additional file 1: contains the details of step  <dig> of algorithm  <dig> including auxiliary algorithms of semilocal sequence alignment and optimal key extension. 

additional file 2: presents in detail all clusters found in the final graph by our algorithm. the clusters are ordered by their numbers in column a; the first cluster is a giant one . the first line of each cluster is marked with fixed numbers in columns c–d; it contains the number of vertices  of that cluster in column e. each of the subsequent lines corresponds to a word and contains the following data in columns a–j: the cluster number , the number of species in the cluster , the vertex degree , the vertex density, i.e., the number of graph parts this vertex is connected to , the species name , the sequence name , start position of the word in the sequence , the word length , dna strand indicator , and the word itself . a part of the word shown in capital letters corresponds to the intersection of all words merged at this vertex ; lowercase letters correspond to the union of those words. if the word overlaps with regions of a gene and its coding sequence  according to the genome annotation available in genbank, this word corresponds to a protein. in such cases, the gene data including the protein description is shown in columns k–o; and cds data, in columns p–r. if only the first condition is satisfied, the word belongs to a gene untranslated region such as an intron; in this case, only the data on the gene are shown. if a word is a fragment of a known non-protein-coding rna according to rfam database, columns s–ab contain the rna name and other data. the clusters that correspond to untranslated regions or unknown hces are highlighted in gold or blue, respectively, in column a. 

additional file 3: presents summary data on the clusters. the resume sheet provides some information on the algorithm results with different parameters. the variant with the threshold length 65 bp, which is discussed in the main paper, is highlighted in pink. in lines 15– <dig>  the number of m-dense clusters and their vertices are shown for m values from  <dig> to  <dig>  for example :  <dig> clusters were found containing words from all  <dig> genomes; these clusters comprise a total of  <dig> vertices, i.e.  <dig> words per genome on average. another example :  <dig> clusters were found containing words from  <dig> genomes;  <dig>  words per genome on average. on the clusters sheet, each line starting from the sixth one corresponds to a cluster. column a contains the cluster number highlighted in the case of untranslated or unknown uce . the hce type is shown in column b as follows: if any of cluster words was found in rfam, the cluster corresponds to a known rna such as trna, snrna, etc.; the column contains this rna label; if any of cluster words overlaps with a cds, it corresponds to a protein  and is labeled as a protein; if any of cluster words overlaps with a gene, it corresponds to an intron or other untranslated region and is labeled as an intron; otherwise the cluster describes an unknown hce . column c shows the total number of words in the cluster; column d, the total number of species containing these words; and columns e–ah, the number of words from each species. 



abbreviations
hcehighly conserved element

uceultraconserved element

