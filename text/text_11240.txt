BACKGROUND
high density arrays evaluate dna, rna and protein levels at the genome and proteome scale. these high throughput experiments enable the identification of some biomarkers associated with disease. for example, classification of gene expression profiles has the potential to help diagnosis, prognosis, to suggest targeted treatment and to predict response to treatment. from the machine learning point of view, it is well known that high throughput array data suffers from the curse of dimensionality where a relatively small number of samples  compared to the number of genes , so that we face over-fitting. over-fitting occurs when a supervised learning algorithm adapts too well to the training data and ends up performing well on training data but not on testing data. feature selection is one of the ways to counter over-fitting.

the goal of feature selection is to find genes  that best distinguish groups of instances  to reduce the dimensionality of the dataset. several univariate statistical methods  including t-test, significance analysis of microarrays   <cit> , and analysis of variance  have been applied to select features from microarray data. in classification experiments, feature selection methods generally aim to identify relevant gene subsets to construct a classifier with good performance  <cit> . features are considered to be relevant when they can predict the class: the strongly relevant features are indispensable to prediction and the weakly relevant features may only sometimes contribute to prediction.

filter methods evaluate feature subsets regardless of the specific learning algorithm used. these methods ignore the fact that there may be redundant features  and so do not seek to find a set of features which could perform similarly with fewer variables while retaining the same predictive power  <cit> . for this reason multivariate methods are more appropriate. wrappers belong to the family of multivariate methods that consider the learning algorithm as a black-box and use prediction accuracy to evaluate feature subsets  <cit> . wrappers are more direct than filter methods but depend on the particular learning algorithm used. several search algorithms can be used such as forward selection  or backward elimination . from the classification standpoint, the simple naïve bayes classifier  <cit>  has been shown to perform at least comparably to decision trees  <cit> . a naïve bayes classifier contains a directed edge between the class variable and every other node and no edges between the other nodes. in other words, in naïve bayes classifiers, the following assumptions hold: all variables are relevant to classification and other variables than the class are independent of each other.

these assumptions are often violated in many application domains and several research directions have been developed to relax either of those assumptions. one of these research direction is to allow the addition of directed edges between attributes such as tree augmented naïve bayes  <cit> , bayesian network augmented naïve bayes or general bayesian network augmented naïve bayes  <cit> . another way to leverage the naïve bayes assumption is selective naïve bayes  <cit> , where the idea is to use only a subset of features by ignoring features that reduce classification accuracy.

within the selective naïve bayes approaches, a maximum a posteriori  method was recently presented by  <cit>  to select the most probable subset of variables compliant with the naïve bayes assumption. this method introduces a compromise between the number of variables and the performance of the classifier. our work is closely related to the approach presented by  <cit>  but different in that we penalize for the correlation between variables in the model. we argue that this is important for high density array datasets due to their highly correlated nature, as it is well-known that genes act together in pathways  <cit> . we performed an extensive simulation study in order to evaluate the performance of our algorithm and then applied our approach on real cancer datasets. our results show that we obtain either similar or better performance than other competing methods with a smaller number of genes.

methods
the problem we face is the following: given k variables  and a class variable y , we aim to select m variables that predict the response y. in the microarray literature, this set of m variables is called the gene signature. in this paper, we propose a two-step approach to refining gene signatures. specifically, our work consists of a bayesian method for feature selection with regularization which penalizes correlation between the variables selected. the method is developed in the context of microarray data, but can be applied to any array data , where the variables  are continuous. first, from the thousands of genes present in an array, we select the few  of those associated with the class variable using some known feature selection methods, or by using some existing gene signatures. from these pre-selected genes, we then use a forward selection algorithm with a beam search in order to find the smallest and least correlated subset of variables. this search is done using a cost function derived from the posterior likelihood of a naïve bayes classifier, including the probability of selecting a model as a prior which penalizes models containing highly correlated variables.

model
let  be the set of k gene expressions  available for each of the n biological samples , such that xk = . let y =  be the class variable one wants to predict, taking values in { <dig>  2}, assuming that y <dig> ,..., yn are independent. we also note ℳm the set of all possible sets of m gene expression variables chosen without replacement among the k gene expression variables available. finally, we note  the set of all possible combinations of m variables chosen among k variables.

in the naive bayes classifier setting, we note p  the conditional density distribution of xk given y = y and we assume that x <dig> ..., xk are all independent conditionally to the class variable y.

for a given set of variables m ∈ ℳ, the posterior probability of y is  

we shall assume a prior distribution on the set of variables m included in the model. specifically, if model m is of size m , we set  

where p  represents the probability to choose a set of variables of size m chosen among all the possible models of any size.

in this work, we wish to weigh each probability p  according to the amount of correlation among the variables present in m. in other words, if the variables from m are highly correlated, the probability to select this particular set of variables is low, and vice versa. specifically, we set the probability of selecting a model m as an inverse function of cormax, the maximum of all the pairwise correlations among the variables of m :   

in this paper, we do not claim to model the correlation structure of a signature although we acknowledge it would be interesting to do that. note that we only measure the magnitude of the correlations, and the cormax statistics was designed to answer this objective.

to compute the denominator of equation , it is clear that enumerating all the possible models containing the edge with maximum correlation would be computationally prohibitive. instead, we can notice that the number of models of size m with maximum correlation among all pairs of variables in the model can be easily computed using the binomial coefficients from pascal's triangle. first, let ρij be the correlation measure between , with i =  <dig> ..., k, j =  <dig>  ..., k and i ≠ j. we also note the corresponding ordered correlations ρ ≥ ρ ≥ .... ≥ρ/2). now, consider a pascal triangle with  rows  and let us note pqr the entry of the triangle corresponding to row q and column r, which corresponds to the combination . we now define the vector z of size k/ <dig> such that we repeat the triangle coefficients of column j in reverse order by shifting one position each time:  

then, we have  

where zl is the lth element of z. a simple example of the calculation above is presented in the appendix. now that we have set the probability of selecting a particular model of size m, we can define the prior probability of selecting a model containing m variables:   

where variables are chosen with replacement according to the same argument as described in  <cit> .

however, one can notice that the above probability is a monotonic function increasing with the model size m. this implies that one would tend to prefer models with a large number of variables. in order to penalize for large models, we choose the following instead of    

noting that  and  are symmetric. in the bayesian framework, the posterior probability of a model m is evaluated as the product of the prior and the likelihood. the log-posterior probability of a model m is then  

the middle part of this posterior probability penalizes for the correlation among variables in the model, whereas the last part penalizes for the size of the model. this means that the posterior probability of a model m decreases with the amount of correlation among variables in m and decreases with the number of variables in m . in cases where data are highly correlated, as it is the case in microarray data, one may want to give more weight to the correlation penalty, and by including a weight lambda, the penalty terms become:  

RESULTS
in order to evaluate our approach, we first performed an extensive simulation study  and then applied our approach on real datasets . the goal of the simulation is to evaluate the performance of our method in the general context of feature selection with correlated variables, where we simulate data such that only a subset of the variables predicts the class. for fair comparison, we compared our approach with two other methods based on a naïve bayes classifier: a naïve bayes wrapper  <cit>  and the  <cit>  method . note that the wrapper searches for feature subsets by optimizing the classification accuracy and it is known as a very powerful multivariate approach. for each method, we identified whether we could successfully retrieve the original subset of variables that was simulated to predict the class. in such a way, we are able to evaluate our approach and we shall show later that we can most often recover the correct subset of genes that predict the class, even when accuracy and subset size remain the same. the weka machine learning tool  <cit>  was used in all the experiments described below.

simulations
our simulation study was designed such that only a subset of the variables simulated predicts the class outcome. our aim is to address the following questions: i) can we select the relevant features; ii) can we remove redundant features; iii) can we handle noisy data; iv) how does the number of features and instances affect the results; v) what is the impact of the penalty weight on the feature selection results. for the simulations, we supposed that a subset of variables predicts the class according to a logistic model and that other variables can be correlated with them. we simulated correlations among variables using a network representation, as shown in figure  <dig>  nodes without parents were simulated according to a standardized normal distribution with mean  <dig>  children of those nodes were simulated using a linear regression model containing their parents with coefficients uniformly randomly chosen between  <dig> and  <dig>  finally, the class outcome y in the network was simulated according to a logistic model containing only the parents of y . we varied the connectivity in the networks from sparse, full or half connection  for  <dig> sets of  <dig> and  <dig> variables respectively . in each of these  <dig> cases, we generated datasets varying sizes for training  and  <dig> instances for testing. we repeated this simulation over  <dig> iterations in each of the  <dig> situations. on each training dataset, we performed a  <dig> fold cross-validation. we also compared the performance of our approach with varying penalty weight lambda  <dig> and  <dig>  denoted corr <dig> and corr <dig> respectively) with boullé's method and the wrapper approach. over the  <dig> iterations, we computed the number of times the correct subset of variables was found.

can we select the relevant features?
first, consider the simple case of finding  <dig> variables out of  <dig> from the dataset a100-sparse. all methods seem to perform similarly in terms of training accuracy , testing accuracy  and number of selected variables . however our approach finds the correct variables more often than the other methods .

can we remove redundant features?
when varying the connectivity with the network of  <dig> variables, our approach always outperforms the others in terms of finding the correct variables. increasing the penalty weight lambda improves the performance . similarly, when varying the connectivity with the network of  <dig> variables , we see that it is more difficult with the small training set size to recover the correct variables  but increasing the number of instances in training improves the performance of our approach .

can we handle noisy data?
we added noise to the training sets by randomly flipping the values of  <dig>   <dig> and 20% of the class variable. our approach outperforms the others but we note that the wrapper approach is fairly tolerant to noise .

how does the number of features and instances affect the results?
by comparing tables  <dig> and  <dig>  we can see that the number of features correlated with the subset of interest greatly affects the methods ability to recover the correct subset of variables. this is true for every method. however, with increasing number of instances, our approach can find the correct subset even though the other compared methods did not.

what is the impact of the penalty weight λ on the feature selection results?
we performed the same experiments as previously with varying penalty weight λ  and found that increasing λ generally improves the results. however, increasing λ over  <dig> doesn't seem to make any difference in terms of the number of correct subsets recovered .

real datasets
we also applied the proposed method to real cancer datasets. in this case, gene expressions are usually measured from biopsies collected on patients affected by a given type of cancer. for each real dataset, the data we used was normalized according to the methods in the papers describing the datasets.

the class variable y may represent the cancer prognostic, for example. note that in this case, we do not know the true set of prediction variables but can only measure classification performance. it is important to note that accuracy  is not the best measurement for model evaluation  <cit> . this is why we also computed the area under the receiver operating curve   <cit> , as there is often a trade-off between misclassifications in terms of true positives  or false positives . we remind that the receiver-operator characteristic  curve compares sensitivity and specificity directly by plotting the tp rate vs. fp rate . computing the area under this curve  reduces the roc performance to a single scalar value and it represents the probability that the classifier will rank a randomly chosen positive instance higher than a randomly chosen negative instance. we also measured sensitivity , specificity , positive predictive value , which is the proportion of true positives  over all the predicted positives, and negative predictive value , which is the proportion of true negatives  over all the predicted negatives. since models must be evaluated carefully to prevent selection bias  <cit> , we used a  <dig> fold cross-validation  strategy for feature selection. it is important to apply cv not only on the creation of the prediction rule but also on the feature selection otherwise a bias is introduced in the estimated error rates resulting in over-optimistic classification accuracy  <cit> . as a consequence, results from many studies are controversial due to methodological flaws  <cit> . therefore, models must be evaluated carefully to prevent selection bias  <cit> . nested cv is recommended, with an inner cv loop to perform the tuning of the parameters and an outer cv to compute an estimate of the error  <cit> . it is important to note that using nested cv, a different feature subset of variables is selected at each iteration. to look at the stability of the feature subsets selected at each fold, we could use the stability index proposed by  <cit> . however, this index is defined only to compare subsets of the same size, which is not applicable in our case. in a similar spirit, we suggest instead to look at the stability of the feature subsets by considering the number of folds where each variable was selected.

van't veer dataset
we first ran our algorithm on the  <dig> genes signature from the van't veer breast cancer dataset  <cit> . van't veer and colleagues investigated the problem of molecular classification of breast cancer and found a  <dig> genes profile also known as the amsterdam signature to predict breast cancer prognosis. from the key observation that  <dig> to 80% of patients receiving chemotherapy would have survived without it,  <cit>  identify a  <dig> genes signature to classify good prognosis  and poor prognosis . the van't veer training set contains  <dig> patient samples of which  <dig> have poor prognosis and  <dig> have good prognosis. in a follow-up study by  <cit> , tumors of primary invasive breast carcinoma less than  <dig> cm in diameter from  <dig> women were examined for validation. the cohort of  <dig> patients studied includes  <dig> of the  <dig> patients from the previous study  <cit> . the amsterdam signature assigns a given instance to good prognosis if this instance has correlation coefficient greater than  <dig>  with the  <dig> genes profile, and assigns the instance to poor prognosis otherwise. for training, we used  <dig> samples instead of the original  <dig> as one sample had  <dig> % missing value.

note that we used preprocessed data for both van't veer and van de vijver datasets where the fluorescence intensities were quantified, corrected for background noise and normalized  <cit> .

first, we evaluated the performance of each approach with a nested  <dig> fold cv looking at the classification performance . we also looked at the genes selected in each fold to evaluate the consistency of the nested cv. figure  <dig> shows the frequency of the genes found over the folds. it shows that our approach is more stable than the others.

we also evaluated the performance of the different methods on the independent test set from the van de vijver dataset  <cit> . we considered only the  <dig> new tumor samples from the van de vijver dataset  as the independent test set. our approach finds  <dig> genes with at least 50% confidence in nested  <dig> fold cv . even though the wrapper and boullé methods produce less number of genes, their sensitivity is significantly lower than with our approach . furthermore, our accuracy on the independent test set is not significantly different than the  <dig> genes in the amsterdam signature  but used  <dig> genes instead of  <dig> 

the average number of genes represents the average over the nested  <dig> fold cv.

pomeroy medulloblastoma outcome dataset
 <cit>  investigated the response to treatment of medulloblastomas with gene expression profiles from biopsies of  <dig> similarly treated patients and found a  <dig> genes signature.

note that we used the preprocessed pomeroy medulloblastoma dataset after thresholding, filtering and rescaling as described in  <cit> . we applied our algorithm to the pomeroy medulloblastoma training dataset of  <dig> samples  to predict clinical outcome and evaluated the classification performance using a  <dig> fold nested cv using the original  <dig> genes signature. in general our prediction is slightly better than the prediction obtained using pomeroy's  <dig> genes but used only  <dig> genes  instead of  <dig> . varying the penalty weight lambda did not alter the results. as we did before, we also looked at the stability of the subset of genes selected in each fold and found that our approach is more stable compared to others .

the average number of genes represents the average over the nested  <dig> fold cv.

ramaswamy metastases dataset
 <cit>  explored the gene expression profiles of human primary tumours and metastases. they found a  <dig> genes signature that best distinguish primary and metastatic carcinomas.

note that we used the preprocessed ramaswamy metastases dataset after rescaling as described in  <cit> . we applied our algorithm to the ramaswamy training dataset  of  <dig> samples  to predict metastases and evaluated the classification performance using  <dig> fold nested cv . our prediction is similar to the prediction obtained using ramaswamy's  <dig> genes but used only  <dig> genes  instead of  <dig>  the results did not change when increasing the penalty weight lambda past  <dig> 

we also looked at the genes selected in each fold and found that our method is more stable compared to others .

discussion and 
CONCLUSIONS
the main question we explore in this paper is how many genes and which genes should be selected for class prediction? we presented a bayesian approach for feature selection with regularization to penalize for the correlation among the variables in the model. we performed an extensive simulation study where we simulated variables to predict the class in order to address the issues of redundancy, noise and scalability in terms of number of features and number of instances. in such a way we were able to evaluate the performance of our approach. we found that we can most often recover the correct genes even when the accuracy and subset size is the same than compared to boullè's method and a wrapper approach. one of the limitations however is that small sample size can severely affect the frequency of correct subsets found highlighting the small sample size problem especially when the genes are highly correlated, as it is the case in microarray data. this finding agrees with other reports including the comparison of the removal of irrelevant and redundant features to binning  <cit> . it is worth noting that with enough data, unlike other methods, our approach could recover correct subsets even in fully connected networks. for the choice of the penalty weight, we tried various penalty weights and observed that the larger the penalty weight, the better the performance. however, the performance of the method did not seem to change after λ =  <dig>  we then applied our method on real cancer datasets  and showed that we can refine gene signatures with a smaller number of genes and similar or better classification performance. we also showed that the results obtained were not very sensitive to the tuning parameter λ .

from the biological standpoint, it is important to note that genes are known to interact with each other in pathways that bring about a particular phenotype. genes that act together in a pathway undergo gene regulation and often have correlated expressions. if one wants to model gene interactions and infer relationships between the genes, network-based approaches are currently developing into a fruitful area of investigation. nevertheless, the objective of our paper is not to reconstruct gene pathways derived from their correlation structure. instead, we penalize the gene correlations in order to identify the smallest set of least correlated genes that can predict a given phenotype such as disease outcome. in this work, we ask whether we can identify crucial genes that can predict a phenotype. the interest of finding a minimal set of genes to predict the class by refining gene signatures is mainly to improve prediction with cost reduction of screening tests for diagnosis, prognosis or treatment response of future new patients in the pharmaceutical industry.

in the particular application to microarrays, how to estimate the true correlations between variables is unclear. it is known  <cit>  that normalization procedures destroy the correlation structure of the genes on the array, and that we cannot estimate the true value of correlations between gene expressions. however, as qiu and colleagues  mentioned in their paper: "when analyzing real world biological data sets, normalization procedures are unable to completely remove correlation between the test statistics. the long-range correlation structure also persists in normalized data". in this work, we do not claim to find a unique set of genes to predict the class but that our algorithm can find one such set with least mathematically correlated genes.

in future work, we aim to extend this idea to bayesian networks which relax the assumption of variable independence of naïve bayes. in a bayesian network, the markov blanket of a class variable y is the minimal set of variables such that y is independent of all other variables given its markov blanket. the markov blanket of y therefore probabilistically shields off y from the rest of the network and would provide a network approach towards the predictive modeling of cancer pathways.

finally, note that a user-friendly software implementation of the method proposed in this paper is available at http://www.medicine.mcgill.ca/epidemiology/labbe/publications.html.

authors' contributions
ad and al conceived of the study and wrote the manuscript. ad devised, implemented and tested the algorithms and evaluated the results. al contributed to the experimental design and also to the statistical analysis of the results. both authors read and approved the final manuscript.

appendix
we provide here an example of how to compute the denominator of equation  in section  <dig>  when k =  <dig> and m =  <dig>  i.e:   

this is equivalent to compute the sum over all possible models of size  <dig>  of the maximum of the pairwise correlations in each model. we denote the  <dig> variables { <dig>   <dig>   <dig>   <dig>  5} and assume without loss of generality that the ordered correlations are ρ <dig> ≥ ρ <dig> ≥ ρ <dig> ≥ρ  <dig> ≥ ρ <dig> ≥ ρ <dig> ≥ ρ <dig> ≥ ρ <dig> ≥ ρ <dig> ≥ ρ <dig>  if one could list all possible models of size  <dig> chosen among  <dig> variables, equation  could be written as:  

to compute the formula above, we first construct a pascal triangle with k -  <dig> =  <dig> rows:  

by looking at the  = 1st column of the triangle , we define  

then, equation  is equal to:  

