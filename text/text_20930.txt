BACKGROUND
recent advances in molecular genetics have led to a widespread use of molecular markers in genetic research for both animals and plants  <cit> . particularly, microsatellite genotyping  <cit>  and sanger sequencing  <cit>  are being widely used for different objectives in small-to-medium sized labs for biodiversity studies. dna sequencing and microsatellite genotyping experiments often go through several major steps such as sample collection, dna extraction, pcr amplification, electrophoresis and result analysis. fundamental principles for conducting experiments are given in textbooks or technical documentation. normally, lab users develop their own procedures, which they describe in lab protocols, to carry out lab work at each step. in other words, protocols provide essential information, such as how to prepare samples, what materials are needed, how to setup the machine, and what information to collect for workflow support, etc. for the completion of lab work. although different labs may perform similar steps, the data processing operations at each step are not necessarily the same. moreover, the demand for storage, use and management of data varies lab by lab. therefore, identifying data items for data storage is essential. for the development of integrated information systems applicable to a wide range of labs, a general data model must be designed in the first phase. this data model must meet all requirements of different labs without additional programming or modification. in the second phase, the required functionality must be implemented resulting in a general software package.

we have previously developed a formalized workflow  <cit>  and a data framework to concretely describe pipelined data processes and data items generated at each step which serves as the basis for the database design in the first phase. accordingly, in these contributions, the term "workflow" specifies the flow of operations  relevant to data, not actual lab work steps. in other words, we only focus on the workflow for capturing and handling data. at each step of the workflow, we use a "data integration table"  to represent data items required in labs. each dit is a table with n rows and m columns where the values in the columns of each row specify names, data types, data sources and requirements of surveyed labs, respectively. the collection of these dits forms a data framework which helps us to construct the general data model for developing molabis. the details, which focus on the construction of dits as well as the methodology for building the formalized data framework, will be presented in another contribution.

data handling in molecular biology labs
the challenges that small-to-medium sized labs face can be classified into five major issues. first, searching and keeping track of data is often inefficient, since heterogeneous data, possibly from different sequencers, is stored and managed in a non-standard way. each scientist has her or his own way to handle data. often, there is no naming convention among scientists for data objects such as individuals or samples. second, it is difficult to share and merge data generated by different persons, because data is isolated among scientists and projects. in practice, data is often scattered and stored in inconvenient formats. some information may be stored in paper lab books, whereas other data are kept in file systems. third, due to the lack of a centralized database, making reports becomes difficult for project managers, because too much time has to be spent on combining data sets from various sources and locations. fourth, sometimes data cannot be found and is thus lost. this problem is most prominent in labs with short term lab users like master or doctoral students. typically, they come to the lab with their samples and leave the lab with their data. fifth, scientists often spend much time on manually preparing and converting data. in order to start lab work such as pcr amplification or electrophoresis, a scientist has to know the availability and physical location of samples. this information is often found in a paper lab book, which may be difficult to retrieve. in addition, conversion and compilation of data for further analyses is carried out manually, which is, both time consuming and prone to error. most of these challenges are often prominent in labs conducting biodiversity experiments, since sharing and synthesis of data among projects are regular incidents.

requirements
to address the above challenges, we developed a proper information system for long-term data storage. it comprises essential tools to handle, retrieve, report and convert data effectively with a focus on biodiversity experiments. such an information system must meet specific requirements as follows:

r1: the information system stores and manages sequence and microsatellite data of different projects in small-to-medium sized labs conducting sanger sequencing and microsatellite genotyping experiments.

r2: it supports the management of individuals from which samples were derived, including their classification into species and breeds or varieties.

r3: sample management is provided to keep track of all kinds of material  from different projects collected by different users. the sample storage scheme is suitable for any physical storage location of samples in different labs.

r4: the information system provides functionality for managing the workflow and the traceability of samples in lab procedures. it allows tracing lab work such as dna extraction, polymerase chain reaction , pcr validation, and electrophoresis to capture all original data from possibly different machines.

r5: the information system supports basic functionality  and the import of large amounts of samples, sequences and microsatellites from external files. raw data received from different architectures of sequencers can be stored and retrieved in a uniform way.

r6: ready-to-print reports can be generated easily to provide data and statistics of a certain project or an entire database.

r7: sequences and microsatellites  can be converted to various data formats for further analyses.

r8: the information system is a multi-user system which supports security and access control.

r9: the software package runs on different platforms  with a simple installation procedure which allows users with no experience in programming and database management to setup and use the system. the software is freely available to be used, distributed, and modified without restrictions. therefore, open-source software, e.g. under the gpl license, is preferred.

r10: migration of data from previous projects is supported by the software package.

existing information systems
in recent years, biologists, bioinformaticians and computer scientists have spent much effort to confront the challenges of storing and managing heterogeneous data in a uniform way  <cit> . therefore, a whole class of software systems has been developed to support lab work, appropriately called lab information management systems or lims. it has to be noted that there are many types of labs with different requirements for data storage and management. accordingly, lims developed for a chemistry lab will support very different work than a lims required in a molecular genetic lab. in the latter class, a number of lims developments have been reported. most of them focused on the storage and management of processed data including microarray  <cit>  and proteomics data  <cit> . wendl et al.  <cit>  developed an information system to keep track of sequencing workflows, but it does not support collecting information on individuals and microsatellite data. in  <dig>  a group of researchers developed agl-lims  <cit> , an open source information system for genotyping workflows which meets some of our requirements. as it focuses on microsatellite data in plants, sequencing is not supported. further, the management of individuals, original samples along with the physical storage places are not considered. recently, some database applications were devoted to the management of both single nucleotide polymorphisms  genotype data and phenotype data  <cit> . additionally, weiÎ²ensteiner et al. extended their system developed in  <dig>  <cit>  to enable the import and storage of mtdna and str  data  <cit> . in  <dig>  ducan et al. also provided an open source web application to enable researchers to store, organize and retrieve their sequence data  <cit> .

in general, the common objective of these information systems is to provide means for lab users to keep their data in-house and extract data for further analyses. however, they often aim to capture raw data from a specific platform  <cit> , or import only final data, while ignoring raw data  <cit> . most of them do not support the management of individuals and traceability of samples in lab procedures. some systems  <cit>  do not provide a solution for documenting lab data.

since available information systems are designed in a specific context of a lab, installation and use in other labs is usually a challenge. to the best of our knowledge, there is no lims available, which meets all requirements stated above. we have therefore designed a general data model for labs conducting sanger sequencing and microsatellite genotyping. in this paper, we present the design, implementation and features of molabis, an integrated information system for storing and managing sequence and microsatellite data in molecular genetics labs with a focus on biodiversity experiments.

implementation
database design
the first step in database design is the definition of a data model. in order to build such a data model, we need to know  differences in data streams in labs,  data types spawned from those data streams,  what data items should be stored at each step, and  how lab users use and retrieve their data. figure  <dig> shows the conceptual database structure of molabis in form of the entity-relationship diagram   <cit>  using crow's foot notation. specifically, the database structure could be divided into three groups of closely linked relations . the first group consists of five tables  which are used to store initial data, information on lab users and experimental protocols. the codes table keeps the references of foreign keys in the information system. instead of using many tables to store foreign keys of different types, we grouped them together in one table. a column called "class" in the table codes stores classes of foreign keys such as species, or breed. table  <dig> lists  <dig> such classes used in molabis. typically, each class is a drop-down list in the data entry forms of molabis. each value in the class  is a data item from the drop-down list. therefore, whenever a user wants to choose a data item, which is not available in such drop-down lists , he or she should insert a new code for the corresponding class. two tables unit and contacts manage all contacts stored in the database. by storing the content of files as binary large objects , all lab protocols are managed in the database via two tables protocols an blobs.

the codes table provides fourteen classes to keep the references of foreign keys. each class has many different values. the values are used to make drop-down lists in the data entry forms.

the second group with five tables  manages data on individuals, samples and dna. the combination of two tables organisms and transfer allows us to store the detail of all individuals of any species and breed or variety. it also helps to accept any external identification system of animals or plants. tracking of samples is conducted with the triplet of samples, storage, and storage-samples. sample storage is managed by a five level hierarchy, creating a storage tree , in which each location has a single parent  and many children . in relational databases, this data structure is organized in a single table with three columns "storage-id", "storage-name", and "parent-id" as in the storage table.

the last group consists of several tables which, deal with tracking the workflow. the collection of samples and the extraction of dna are managed in tables sample-collection and dna-extraction, respectively. in addition to storing information on dna, the dna-extraction also saves the traces of the original samples extracted. the details of pcr amplification and electrophoresis are recorded in the tables pcr-amplification, pcr-markers, amplified-samples and electrophoresis. two tables validation and gel-images are used to store the information on the validation of dna or pcr products and the content of gel images. final data is stored in the two tables sequences and microsatellites.

in order to derive a general data model, two important points have been considered. first, the data model allows for storage of different data types of original data regardless of the hardware variations of sequencers. the database was designed on an abstract level to accept any type of raw files, for instance, gel images of a gel electrophoresis, or chromatogram files of capillary electrophoresis. instead of using many different tables to serve different data types, all raw data files are stored as blobs in a single table. second, the data model only comprises elements which are at least in principle available for every species, sample type, and lab. other more specific elements can be stored in text blocks and blobs. as a result, the data model can be applied without customization to capture data of any species, breed , biological material type and hierarchical sample storage scheme.

application architecture
molabis is an integrated information system which is developed on the basis of apiis  <cit> , a framework for developing adaptable platform independent information systems. it is a web application based on a three-tier client/server architecture . on the client side, end-users from any computer in the local area network  can interact with the system to carry out all activities via a standard web browser  on any operating system. no additional software packages or programs need to be installed on the client machine. the incorporation of web  <dig>  technologies such as ajax  <cit>  makes web interactions simpler and more effective. the menu bar helps end-users to easily navigate all web forms. web layouts and dynamic interactions are controlled by javascript, css  and prototype   <cit>  to create an easy-to-use graphical user interface .

at the data tier, postgres  <cit> , an open source database management system , is used to store application data and handle all data transactions. the application tier requires an apache web server  <cit>  running under the linux operating system. on the top of apiis  <cit> , the molabis controller is central to the application tier to process user requests and to communicate with other components. the application source code is written mainly in the perl programming language  <cit> . many perl modules, which are available on cpan  <cit> , are used to implement different functionalities in the system. the apiis meta layer between the web server and the database server controls data transactions and error handling. many open source software packages are integrated in molabis. particularly, html::templates  <cit>  and cgi::ajax  <cit>  are two perl modules used to produce and handle dynamic web forms. since our objective is to have a uniform layout, form templates are all designed in the same manner. they are compiled by the molabis controller to create web pages, which are sent to the web browsers. the labels of form elements in each form template are variables translated from a text file in ascii format, allowing easy changes of labels on the forms. the forms are designed so that a large number of data records  can be entered, imported and processed. because of its dynamic length, the form has to be broken down into smaller units called sub forms. a data buffer is implemented on the server to ensure the temporary storage of data of sub forms before they are submitted to the database.

as an apiis application, the database of molabis is created from a xml   <cit>  schema called "model file". the model file also defines a set of business rules for each table in the database. these business rules are checked at the meta layer in the apiis framework to guarantee atomicity and consistency  <cit> .

we selected an automatic report generation solution in jasperreports  <cit> , an open source reporting library written in java, to make ready-to-print reports in pdf format. it is integrated into the molabis controller with the assistance of the inline::java package  <cit> . jasperreports templates in xml were designed under ireport  <cit> , an intuitive and visual report editor for jasperreports. these templates can be customized and checked independently without affecting the application code. further, bioperl  <cit>  was used to support converting sequence data to a number of specific formats.

security
the information system must provide mechanisms for user authentication to protect data from unauthorized accesses, according to the design requirements. since users may play different roles in the system, they should accordingly be granted different rights for the utilization of the system and its data. the system controls the access of a user to functionality and data once he or she logged in successfully through "user roles". each role is a definition of a group of access rights to determine which part of the program is hidden or shown. they also define which part of the database can be accessed and modified by the end-user. in our application, user roles are considered on both levels of system and database to assign proper tasks. therefore, after a user account is created it has to be granted one "user role on the system tasks"  and one "user role on the database tasks" .

there are four srs corresponding to four kinds of users. each sr in this case is assigned a given number of system tasks depicted in table  <dig>  while the management of srs handles access rights for different functions or modules of the application, the management of drs is responsible for checking all activities related to the content of the database. table  <dig> lists five drs along with expected data access rights.

each row defines access rights to seven functional blocks . user administrators can add users to or remove users from the system. they can update the data and grant new roles to existing users. lab managers can use most of the functions in the system except data entry via the workflow. scientists can deal with the workflow for data entry and use other functions of the system except the administration of common data in the lab. visitors can use some functions such as viewing data, generating reports, converting data and reading helps. however, they are limited to work with the workflow and the administration.

defining user roles on database tasks.

sample tracking and management
often sampling individuals  is the first phase of molecular genetics projects. here we use the term "sample" to imply biological material, such as blood, semen, oocytes, embryos, somatic cells, or tissue from which dna is extracted. sample management allows recording three blocks of information: origin of sample, sample information, and the storage location of the sample.

the first block records data of individuals from which the samples are collected. here, samples from any species and breed  are accepted. the second block specifies the sample itself. a sample is collected from a certain type of biological material on a given date by a given person. different types of biological material result in different types of vessels and different storage units . the final block describes when and where the samples are stored.

sample storage is based on the storage facility and infrastructure of each lab. therefore, our storage management system is designed to handle physical storage in a general way by providing a five level hierarchy. this flexible storage scheme is also used to manage the location of samples in national genebanks  <cit>  and is also used for storing dna in molabis. normally, the highest level  is used for the storage location . the lower levels could define various storage facilities , while the lowest is the sample storage level in which the samples can be located by sequential search. figure  <dig> is an example for defining the sample storage in a small lab, where all sample containers are kept in one place. it is a storage tree where each node at each level can have multiple sub-nodes in the lower level. each leaf node is associated to either a box of vessels or a single vessel. in such labs, we may need only four storage levels  to keep track of samples since there is only one node as the root of the tree in the first level. this scenario can be extended easily for large labs where samples are physically stored in different places.

since relational databases are not well suitable to store hierarchical data, we used a tree structure to model the storage of samples in a single table . technically, this helps us to take advantages of tree search algorithms for easily implementing the functionality of sample retrieval such as searching a certain sample, listing samples in a level, printing a single path of storage places.

data migration
one of the challenges for setting up a new information system lies in transferring large amounts of historical data collected and stored over the years to the database, prior to loading the new data into the database. data migration is the process of transferring data from external data sources to a new database. this work can be done in either a visual loading mode or a batch loading mode. in the visual loading mode the user can employ a graphical interface to browse data from file systems, select proper data, enter related details and load everything to the database. this mode is provided in most of the information systems, and here molabis is not an exception, allowing this process to be carried out under the workflow. however, for large sets of data, this is time consuming, because data entry must be done manually step by step. in this case, the batch mode is more efficient. instead of having many separated loads done manually in the visual loading mode, a big load can automatically be executed in the batch loading mode. this feature sets molabis apart from other information systems.

RESULTS
molabis has been implemented as a web database application, written in approximately  <dig>  lines of source code . the main graphical user interface provides five different modules  which can be accessed from the navigation menu. all functionality has been developed to meet the requirements listed above. it provides essential tools for collecting data effiectively, searching and retrieving results easily, and making reports and extracting data quickly. the following list demonstrates the major features of molabis.

data capture and storage
data of very different formats  from the primary, final and descriptive data is stored in the central database, resulting in a transparent data handling independent of the data types. instead of keeping files uploaded from the web browsers in the file system located in the web server all files are stored in a relational database as blobs. this approach avoids broken file links and storing many backup copies of data files. molabis allows lab users to store complete data sets of their projects: it captures both raw data and final data, as well as details of data operations and stores everything in a central database in a compact, coherent and uniform way. figure  <dig> shows the data flows of the two methods supported in molabis for collecting data efficiently.

workflow
supporting the lab workflow is an important feature, as it allows users to easily keep track of their lab work and update their data in the database. under the workflow , a scientist starts a project and then, step by step, interacts with the system to update the data until the project is finished. it is worth noting that data can be pipelined from one step to the next in the workflow. for example, samples exported in the step "prepare samples" in a spreadsheet format can be imported in the following step "extract dna" of the workflow. at each step, users are provided a web form or a sequence of sub-forms, for data entry. forms are optimized for filling in data quickly .

batch loading of historical data
in order to support data migration, "mloader", an automation tool for bulk loading of historical data from previous projects has been developed. mloader is a command line script written in perl. it can be invoked at the back-end to import large datasets into a molabis database. all historical data must be available in electronic form to be accessed by the script . in order to execute the script, a user must supply parameters and data spreadsheets. all parameters are indicated in a configuration file which is made up of file records . it means that the user needs to declare what kind of data should be imported into the database. mloader provides different options for loading part of or all data of a project . to prepare data spreadsheets, a user may fill in empty templates, which are predefined in a given format. the spreadsheets can be supplied in xls, csv, or ods format.

data management
molabis not only keeps track of the workflow to capture and store different data types but also provides structured data handling capability i.e. it allows users to search for data across all projects, get back both raw and final data and modify any type of data stored in the database.

search
search functions are applied in the same manner for all web forms found under "manage data" and "administration" in the main interface . a criteria based search mechanism is used, which allows the user to specify the criteria to be used in the search. therefore, the search results can be extended or narrowed easily. search results can be sorted according to any given field.

data retrieval
in molabis, data objects are stored in a coherent manner, making data tracking much easier. the samples are considered the central entry point in the tracking model. through the relationships among associated data objects as depicted in figure  <dig> the system can locate related data. for instance, using the sample id the user can retrieve information such as details on the sample itself, information on the individual from which the sample was collected, the storage location of the sample, details on the dna extracted from the sample, raw data relevant to the sample, and final sequences obtained.

data modification
molabis allows unrestricted data modification; lab managers can change any data field for codes, contacts, protocols, markers, storage places of samples in the lab. scientists can update or delete all data objects stored in the database including individuals, samples, dna, pcr amplifications, electrophoresis, sequence and microsatellite data of a project.

generating reports
molabis creates ready-to-print reports in pdf format based on user specified parameters. with a few mouse clicks, users can download pdf files to their computers. thirteen predefined types of reports have been developed in molabis . the system can provide lists of projects, contacts and individuals. it can make reports about information on samples or dna, along with storage locations for a given project. besides, statistical reports for sequences and microsatellites can be done for a particular marker, a certain project, or the whole lab. molabis also allows users to generate a report to sum up the data volume in the entire lab or make a chart of sample distribution of a project. since the reports are based on templates, developers can easily modify the predefined types of reports.

exporting data
a further important feature of molabis is the export and conversion of final data to various formats required as input files for subsequent analyses, which is particularly useful for molecular labs working in the analysis of biodiversity.

converting sequence data
different analysis tools expect different data formats. this requires scientists to convert sequences from a given format to another. molabis offers a tool to extract sequences stored in the database and to automatically convert them to various formats. the current version of molabis supports conversion of sequences to seven data formats: fasta, nexus, phylip, mega, msf, psi-blas and pfam . furthermore, the system can export sequences collected from different projects into a single file, which is available for download as required for instance in phylogenetic analyses. as an additional service, users can have their uploaded sequences in fasta format converted to other formats by molabis.

converting microsatellite data
microsatellite data is frequently stored as a matrix in which rows represent samples and columns markers. many of bioinformatics tools such as microsatellite toolkit  <cit>   require diploid or haploid microsatellite data as input files. preparation of these input files may be tedious. here, molabis helps by extracting microsatellite data of samples from different projects and by exporting all to a single file. it allows the user to select one of three types of data formats  for exporting. in addition, the user can choose excel or csv  as the file format of the output. this process is depicted in figure  <dig> 

performance and scalability
by using postgres, molabis obviously meets the requirements regarding time and space complexity mentioned in  <cit> . it can store large amounts of data and is only limited by the hardware configuration of the server. the software has been tested to ensure that it can be used by multiple users at the same time in a lan, as well as the internet. molabis runs without performance issues even when used by  <dig> simultaneous users.

to evaluate the performance and scalability of molabis, we have done three tests on three databases but with different sizes . the tests were conducted on a computer with an intel core i <dig>  <dig> Ã  <dig>  ghz processor and  <dig> gb of ram, running kubuntu  <dig>  and using postgres  <dig> . all tests used the same test cases, which are typical queries in a production mode. for each test, a test case was executed and benchmarked ten times at the front-end to calculate the mean response time. the results are reported in table  <dig> showing response times in the order of seconds, thereby allowing the users to rapidly interact with the system. as expected, the response times are independent of the size of the database indicating that molabis scales well. indeed, the differences in the response time among tests are insignificant .

the response time is measured in seconds at the front-end of a client machine in a lan. for each test case, the mean response time and standard deviation is calculated from the response times of ten runs. the databases consist of approximately  <dig> ,  <dig>  and  <dig>  samples for the three tests, respectively.

discussion
molabis was developed to overcome the challenges of molecular genetics labs in the context of data management as defined in the requirement section. in the following, we summarize how molabis addresses the requirements listed in the section "background".

r1: while other information systems are often designed to collect data of either dna sequencing projects or microsatellites genotyping projects, molabis is the only system to support both.

r2: molabis can manage information on individuals in plants and animals from any species and breed.

this feature is not supported in other information systems.

r3: the functionality of sample management in molabis is considered a complete software package for the storage and management of samples. molabis allows to track a large number of samples of different types. it provides a five-level hierarchical storage scheme ensuring the flexibility in the representation of physical storage locations of samples and dna in different labs. the lab manager can define a new location, update and delete existing ones at any storage level.

r4: the workflow, one important feature in molabis, supports the experimental workflow in the wet lab efficiently and organizes the data entry accordingly. data is pipelined from one step to the next in the workflow. at each step in the workflow, the details of lab work such as pcr amplification, pcr validation, and electrophoresis are recorded. this feature also highlights the difference between molabis and other systems, which only support importing final data.

r5: all data operations can be performed via a standard web browser including internet explorer 7+, firefox  <dig> + and safari 3+ running under a variety of operating systems. the ajax technology used in molabis allows to create an interactive user interface, which has the quality of desktop applications. the users can search, view, update, and delete their data in a single form without switching screens. raw data  is stored independent of architectures of the sequencers. therefore, molabis can manage all electrophoresis products, which can be obtained from different sequencers, in a uniform way. the import functionality of molabis has considerably enhanced the process of data entry. the details of samples and dna can be imported in various file formats, such as .xls, .ods, or .csv. moreover, sequence and microsatellite data can be imported into the database. additionally, every data entry form can store additional information in a comment block thereby allowing molabis to function as a filing cabinet.

r6: jasperreports, an embeddable open source java reporting library, is integrated in molabis to provide an effective reporting solution. the report templates are compiled with parameters specified by the user to extract data from the current database and generate the report. although the system currently supports generating reports in pdf format, the report templates can easily be extended to other formats.

r7: molabis supports the retrieval of final data, as well as original files of raw data of any project. in addition, final sequences and microsatellites can be converted to various formats.

r8: developed as a web application, molabis can be installed and used in a lan or internet, thus allowing many users to access the system simultaneously. under the access rights control of molabis, data is used and shared in a secure manner. molabis is well-suited for localization. the text, labels, and context help in all web forms are read from an ascii file  which can be edited by any text editor.

r9: we used virtualization technology to package and deploy the application. hence, the molabis appliance can be installed on different platforms . the installation process itself amounts to downloading the appliance file, installing the virtual player and running the appliance under the virtual player without any knowledge about its operating system or other software components. under the gnu general public license, molabis can be downloaded, installed and used free of charge. this contrasts the traditional installation which starts with the installation and configuration of dbms, web server, application framework and software components, thus requiring it experts, who usually are not present in most labs.

r10: loading data from previous projects can be carried out in a batch loading mode. the mloader can be used to load large amounts of data collected and stored over the years. it executes a sophisticated system of foreign key loading and rollbacks. this facilitates the detection of similarly spelt keys and the restoration of origin data for wrong data loading.

the above list indicates that the requirements, as stated in the first section of this paper, have been met. our software package was tested by third parties who are independent of the development of the application. thorough testing has been carried out, in order to check for both technical bugs and missing functionality. moreover, a user guide is available and released along with the software.

CONCLUSIONS
the development of molabis has solved the problems described in the first part of this paper. molabis is a web-based integrated information system which can be used to store, manage and handle data of dna sequencing and microsatellite genotyping workflows. all operations can be done via a standard web browser running on any operating system. developed as an open source software package, molabis takes advantage of other open source components. it brings benefits to both researchers and lab managers. for researchers, their data is stored safely with high reliability. in collaborative projects, the data can be shared in a secure manner. the system helps to reduce the workload and the time needed for searching and preparing data for subsequent lab work steps. the conversion of data formats is performed easily, thus saving time and avoiding human errors. for lab managers, molabis ensures long-term data storage and monitors the progress of different projects carried out by various lab members. in fact, molabis supports full documentation of genotyping and sequencing experiments, even with short term lab users  and different genotyping platforms. with its general data model, molabis meets common requirements of various molecular genetics labs working in biodiversity. released under the gnu general public license, molabis can be downloaded, modified and used freely. molabis is distributed as an appliance in which all components and services are installed and pre-configured. being a ready-to-use appliance, it can be run on different platforms by using a free player such as vmware player or virtualbox with minimal installation effort.

rapid advances in molecular genetic technology have led to a quick adaption of high throughput genotyping for snp and nextgen sequencing. future releases of molabis will have to address this development, possibly also adding support for other molecular markers like aflps, which are still being used in many small labs, especially in developing countries. to accommodate these changes, the data model will have to be expanded, while preserving the core part of the sample management and all current functionality.

availability and requirements
the source code, user guide and appliance of molabis are freely available at the project homepage http://www.molabis.org. we also provide a live demo for users who want to evaluate molabis without installation. release notes and other information will be also updated on the project homepage.

project name: molabis

project homepage: http://www.molabis.org

operating system: platform independent

programming language: perl database: postgres

license: gnu gpl

authors' contributions
ct designed the data model, implemented the software, and wrote the manuscript. lg evaluated and enhanced the usability of the software and wrote the user's guide. eg initiated and supervised the project. bm co-supervised the project and revised the manuscript. all authors edited, read and approved the final manuscript.

supplementary material
additional file 1
source code of molabis. the source code of molabis is provided as a zip file.

click here for file

 acknowledgements
this study was funded by the german federal ministry of research and education  through the project molabis . the authors are grateful to zhivko duchev for his helpful suggestions, detlef schulze for testing the software. we also thank the surveyed labs for data supports.
