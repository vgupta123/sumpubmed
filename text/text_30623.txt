BACKGROUND
protein families frequently can be divided into subfamilies of similar but distinct function. the study of these subfamilies and the residues which control the functional specificity is an important step in the analysis of these families.

many previous studies have focused on the question of how to find the functional residues for a given protein family when proteins already have been assigned to subfamilies. these methods include approaches based on information-theoretical measures such as relative entropy  <cit>  or mutual information  <cit> , template-based similarity scores to known functional residues  <cit> , approaches which contrast position-specific conservation in orthologues and paralogues  <cit>  or superfamilies  <cit>  and comparisons to known reference 3d structures to find discriminatory surface residues  <cit> . the opposite of this so called supervised problem, is the unsupervised setup, where subfamily assignments are unknown and have to be inferred from the data. in the unsupervised case, clustering approaches for protein data can be applied to obtain subfamilies from set of protein sequences. for protein subfamily clustering most methods rely on the construction of a phylogenetic tree. these methods can be further subdivided into pure clustering methods  <cit>  and approaches which include functional residue prediction  <cit> . tree-based methods perform well in the presence of abundant data but might suffer from instability in the inferred topology for small data sets with strongly divergent sequences. for this type of data sets a stable phylogeny often cannot be inferred. in the worst case, a substrate specificity evolved multiple times independently leading to functional clusters which are not monophyletic. here, any tree-based approach is assured to fail. such data sets for instance arise from detailed molecular studies, where individual proteins are examined for their substrate specificity  <cit>  and each experiment requires considerable effort. for such data sets a method, which is not based on a phylogenetic tree is advantageous. in a typical biological scenario, one is usually in between the supervised and unsupervised setting. a few members of a family have been characterized experimentally, but no functional information is known for the majority of the domain family. in these partially-supervised learning problems the classification error can be greatly reduced by making use of the annotated  proteins, even when only a small number of high quality labels is available  <cit> . in addition, the integration of a limited amount of expert knowledge can help to focus the clustering on subfamilies which are of relevance for a particular research question. in  <cit> , we presented a method based on the context-specific independence  mixture framework for clustering of protein sequences and simultaneous prediction of functional residues.

the novel contribution of this work is as follows. first, the method has been extended and augmented with a partially-supervised learning setup, which allows the integration of prior knowledge into the clustering procedure. this extension allows the integration of experimental data for a few characterized proteins mimicking closely the typical biological scenario. secondly, we simultaneously discover subfamilies and predict functional residues in four data sets of protein domain families. the results not only underline the relevance of our method but also allow insights into the sequence level basis of different ligand specificities. thirdly, we contrast the clustering performance of our method with state-of-the-art tree-based approaches.

methods
mixture models
the general problem addressed in this work is visualized in fig.  <dig>  given a multiple sequence alignment  of protein sequences , we discover subfamilies of sequences with different functional specificities  and simultaneously predict residue positions which are causal for these functional differences. this is indicated by the differently colored columns . generally speaking, there is an increased subfamily-specific sequence conservation at positions which are relevant with respect to the distinct functions of the subfamilies. these positions are highly informative for the characterization of the clusters. conversely, positions which are not relevant for the functional characterization of the subfamilies may show very little variability between subfamilies. such positions are very weakly informative for the clustering and are best modeled by the same set of parameters in all subfamilies, instead of separate sets of parameters for each cluster. this notion of adaptation of model complexity to the position-specific degree of sequence variability observed in the data is formalized in the csi mixture models, which are defined as follows:

let x <dig>  ..., xp be discrete random variables over the  <dig> amino acids and a gap symbol representing rows of a multiple sequence alignment  with p positions. for a given data set with n samples d = x <dig>  ..., xn, a conventional mixture model is defined as

   

where π =  are the non-negative mixture weights which sum to one, . that is, the data is modeled as a convex combination of k component distributions. as component distributions we employ a product distribution over the p features of the data set, the well known naive bayes model  <cit> ,

   

the complete set of parameters of the mixture m is then given by Θ = . this adoption of the naive bayes model as component distributions implies the assumption of conditional independence between features given the mixture component. moreover the standard assumption of independence between samples is made, which means that the probability of d under the mixture p decomposes into the product over the probabilities of the individual samples,

   

the context-specific independence  extension to the conventional mixture framework is based on the observation, that in the latter, a separate set of parameters has to be estimated from the data for each component and each feature. this situation is visualized in the left matrix in fig.  <dig>  the example shows a five component mixture c <dig>  ...,c <dig> over four features x <dig>  ..., x <dig>  each cell in the matrix represents a separate set of parameters θkj in the mixture. now, the csi framework is based on the insight that for many data sets it will be unnecessary to have a separate θkj for all components in each feature. rather, components should share parameters based on the feature-specific degree of variability observed in the data. an example of a csi structure is shown on the right in fig.  <dig>  again each cell of the matrix represents a set of parameters, and cells spanning multiple rows represent shared sets of parameters between components. for instance, components c <dig> and c <dig> share a parameterization for feature x <dig> and all components share parameters for feature x <dig> 

in the following we introduce the csi mixture model formally. given the set of k component indexes c = { <dig>  ..., k} and random variables  x <dig>  ..., xp let g = {gj} be the csi structure of the model m. then gj =  where zj gives the number of subgroups for xj and each gjr, r =  <dig>  ..., zj is a subset of component indexes from . therefore, each gj is a partition of  into disjunct subsets, such that each gjr represents a subgroup of components with the same distribution for xj. the csi mixture distribution is then obtained by replacing fkj with fkjj) in  where gj = r such that k ∈ gjr. accordingly,  is the full model parameterization and  denotes the different parameter sets in the structure for feature j. the complete csi model m is then given by m = .

finally, the ranking of positions in the msa for prediction of functional residues was carried out using the relative entropy score based on the csi structure and the model parameters described in  <cit> . essentially, this score contrasts the amino acid distribution within a subgroup with the distribution observed for all other subgroups. it can be seen as an extension of the score applied in  <cit>  to the soft subgroup assignments inherent to the probabilistic mixture framework.

partially supervised learning
when clustering a given data set d, we need to infer the mixture parameters Θ and the csi structure g. the standard technique for arriving at estimates for Θ is the expectation maximization  algorithm  <cit> . the structure learning of g is carried out by applying the structural em framework  <cit> . the central quantity of both of these algorithms is the posterior distribution of component membership

   

here τki gives the probability that a sample xi was generated by component k. this posterior not only gives the solution to the conditional expectation of the hidden data  in the em framework, it also gives rise to the expected sufficient statistics required for the structural em algorithm .

a different interpretation of the component membership posterior is as the uncertainty in the cluster assignment of a sample. in fact, the entropy of this posterior can be used to identify samples where no clear classification is possible . in the partially-supervised setting, the component assignment of the labeled samples is known a priori. this means that for a labeled sample xi with label l, τki =  <dig> for k = l and τki =  <dig> for all k ≠ l. therefore, all samples with the same labels are constrained to be assigned to the same cluster, and therefore to different clusters if the labels are different. fig.  <dig> shows an example for the constraints implicit in the labeling of data samples. red edges between points represent must-link constraints, where each red edge stands for a different label, blue dashed edges must-not-link constraints. this setup can also be thought of as a point in the continuum between supervised  and unsupervised  learning tasks. for the former, the assignment of samples to components is known . for the latter, the assignment of samples to components is unknown and the em algorithm needs to be used to arrive at estimates for Θ. the partially supervised approach, then, is a situation, where there is complete data for a subset of samples in the data set. the same modification to the posterior for the labeled samples that defines the partially supervised em, also gives the adaption of the csi structure learning for the partially supervised setting.

structure learning
the structural em algorithm allows the efficient evaluation of candidate csi structures. in order to score the different structures we adopt a bayesian approach and compute the model posterior given by

  

where p is the probability of the data set d under the mixture m given by

  

where p is eq.  <dig> evaluated for the maximum a posteriori parameters . p() is a dirichlet mixture prior  based on nine basic chemical properties of the amino acids introduced in  <cit> . the prior p() regularizes the structure learning by introducing a notion of amino acid similarity into the objective function p. that is, a dmp p() is given by

   

where in this case g =  <dig> and each of the components represents one of nine basic chemical property of amino acids . the parameters of the dmp component distributions αg and mixture weights qg are chosen according to the heuristic described in  <cit> .

finally, p is a prior over the model structure given by the simple factored form

   

where p = γk is the prior over the number of components and  is the prior over model structure. γ <  <dig> and α <  <dig> are hyper parameters which determine the strength of the bias for a less complex model expressed in p. the values of α and γ were chosen by use of the heuristic introduced in  <cit>  with a prior strength of δ =  <dig> .

improvement of the structure learning algorithm
the model posterior p defines a scoring function over the space of csi structures. however, exhaustive enumeration of all possible structures is infeasible in practice, since the number of possible structures is increasing exponentially with the number of mixture components. the number of possible structures for a given model can be computed by the bell numbers  <cit> . for instance for a single feature and ten components there are already  <dig>  possible structures to be evaluated. so, in order to arrive at structure estimates we applied an iterative, greedy procedure starting from the full structure matrix . moreover, we optimized the computations by making use of redundant terms between the current model and the candidate models. in each step of the structure learning procedure, all pair-wise merges of groups in the current structure have to be scored and the one which maximizes the posterior is accepted. an example of this is shown in fig. 4a). each of the four nodes represents a component of the mixture and each pair of components gives rise to a merge parameter θgjr based on the expected sufficient statistics of the merge, which in turn allows the evaluation of the model posterior p. this means that in each step o() candidate merges have to be computed, where zj is the current number of groups, starting with zj = k in the first step. an important observation that can be made, is that the merge parameters θgjr of disjunct merges are independent in the sense that the respective computations have no terms in common. this is because the merge parameters are computed from the element-wise addition of the component membership posteriors τk = {τki}i =  <dig> ...,n of the components that are part of the merge. an example is θ <dig>  and θ <dig>  in fig. 4a). the former is based on τ <dig>  = τ <dig> + τ <dig>  whereas the latter arises from τ <dig>  = τ <dig> + τ <dig>  if we were to accept the merge of  <dig> and  <dig> in the first step, the second step ) would necessitate the re-computation of only the merge parameters θ <dig> , <dig> and θ <dig> , <dig> , whereas θ <dig>  would remain unchanged from the previous step and need not be computed again. therefore, by caching the merge parameters in each step, the number of merge parameters to be re-evaluated in each step after the first drops from o() to o. this greatly increases the speed of the structure learning, especially for models with a large number of components.

RESULTS
we applied our mixture modeling to four protein sequence data sets. these were chosen as representatives of specific challenges for subclass discovery. in the case of the phosphatases, catalytic active members should be distinguished from inactive ones. the focus in this example is the automatic identification of sites important for the catalytic reaction. the second dataset, pyridoxal-5'-phosphate dependent decarboxylases was chosen to test whether our algorithm is able to identify substrate specific groups even if they were not monophyletic. in this case, one substrate specificity was evolved independently in archaea and plants. thus, no tree based approach will correctly predict the two classes of substrate specificity. furthermore, this protein family is highly divergent, with median pairwise identities below 20%. this also holds true for the remaining two datasets, ww and sh <dig> domains . additionally, these domains are comparably small, leaving few conserved positions for classification. finally, they are functionally divergent and genetically mobile, that is they can be found in many otherwise non-homologous proteins. finally, as part of the comparison of clustering performance and in order to assess the impact of the clustering quality on the functional residue prediction, we also revisit a data set of malate/lactate dehydrogenase sequences previously analyzed in  <cit> . all the alignments are available from the authors upon request. the general properties of all data sets are summarized in table  <dig> 

the number of sequences, length of alignment and length of alignment after filtering  are given.

in order to assess the impact of the partially-supervised setup, models were trained with and without labels. the labeled samples were chosen at random. for each data set we trained models with a number of components in a range of one to ten and the normalized entropy criterion   <cit>  was used to perform model selection.

in practice, it seems reasonable to expect that the number of labeled data points available for a given data set is fairly limited. therefore, the main question we were interested in with regards to the partially-supervised learning was in how much different amounts of randomly chosen labels would impact on the clustering performance.

following the approach in  <cit> , alignment columns with more than 33% gaps were filtered prior to clustering in order to reduce the noise level in the data sets. the clustering quality was evaluated by the standard measure of accuracy , where for the cluster labels and the true class labels, tp gives the number of pairs of samples where the true class labels and the cluster labels are the same. the remaining quantities are calculated accordingly, i.e. fp , tn  and fn .

receptor tyrosine phosphatases
together with protein kinases, protein phosphatases are the key players of signal transduction cascades. here, we analyzed a specific subfamily, the receptor tyrosine phosphatases. intracellularly, receptor tyrosine phosphatases contain two phosphatase domains. whereas the membrane proximal domain is catalytic active, the distal domain has lost its activity and is assumed to be involved in regulation. searching for differences in site specific evolutionary rates, a second functional region, opposing the catalytic center, was proposed  <cit> . using this dataset, we asked two questions:  is our algorithm capable to recover a classification which is based on phylogenetic trees  <cit>  and  can the algorithm identify known functional sites.

therefore, the  <dig> phospho-tyrosine phosphatase domains  of all proteins with two ptpc domains in the human genome were extracted from smart  <cit> . an alignment was obtained using muscle  <cit> .

when performing the clustering, a clear separation of the two classes became apparent. the nec model selection chose two clusters as optimal and the resulting model separated the classes with perfect accuracy. this result was confirmed in  <dig> repetitions and unsurprisingly remained unchanged when adding prior knowledge in form of labeled samples.

fig.  <dig> shows the ranking of alignment positions by score. positions with a score of zero have been marked as uninformative for the clustering by the csi structure learning. this is the case for the majority of positions. when considering the top ranked positions, we found two positions  which are part of a loop surrounding the active site  or involved in inter domain hydrogen binding . to illustrate the kind of regularities in the alignment revealed by the position ranking, the top ten ranked positions in the phosphatase data are shown in fig.  <dig>  the two experimentally confirmed sites are highlighted in yellow and green, respectively. indeed, the method picked up positions which showed patterns of subgroup-specific conservation.

pyridoxal-dependent decarboxylase
the pyridoxal-5'-phosphate dependent amino acid decarboxylases comprise a large protein family of four evolutionary unrelated families  <cit> . these are classified according to their substrates. here, we focused on two enzymatic classes of group ii decarboxylases. the first catalyses the decarboxylation of tyrosine , whereas glutamate is the substrate of the second group . the data set was constructed by selecting all sequences of the pfam family pyridoxal_dec which had an unique annotation for the substrate specificity in the catalytic activity field of the corresponding swissprot entries. this resulted in  <dig> sequences with glutamate specificity and  <dig> sequences with specificity for tyrosine. an alignment of these  <dig> sequences was obtained using clustalw  <cit> . subsequently, a phylogenetic tree was calculated using proml  <cit> , which showed that the studied tyrosine decarboxylases are not monophyletic. whereas the position of the sequences within the groups were frequently only poorly supported, the relation of the four groups to each other was revealed in all of the  <dig> bootstraps . thus, the catalytic specificity for tyrosine arose independently in archaea  and plants . no tree based method will be able to identify the two groups with the differing substrate specificity. we used this dataset to test if our method was able to dig out the small signal of substrate binding differences covered by a strong phylogenetic signal.

while the nec assigned two clusters, the separation of the glutamate and tyrosine subclasses proved to be very challenging without labels. the average performance over  <dig> repetitions was an accuracy of 51% . when adding the power of the partially supervised framework to the clustering by randomly selecting different numbers of labels for the two subclasses a different picture emerged. the average accuracies based on  <dig> repetitions for different amounts of randomly selected labels per class are shown in fig.  <dig>  the average clustering accuracy increased monotonously with the number of labeled samples. while the average accuracy improved significantly in the range of 5%-16% labeled samples, the variance also increased. this is most likely an effect of the random selection of labels. indeed, the quality of the labeling is crucial for the performance of partially-supervised approaches  <cit> . when outliers of a class were labeled, the labeling could even have a negative impact on the clustering performance. this issue is increasingly receiving attention in the machine learning community  <cit> . for about 22% labels the variance decreased again and models with perfect accuracy and zero variance  were obtained for more than 22% labels.

the unsupervised clusterings returned a very low-variance, highly robust clustering of the sequences. these clusterings did not reflect the tyrosine/glutamate subfamilies and so the question was whether they represent some other biological context. upon examination it became clear that the unsupervised clustering split the data set based on phylogenetic divergence. one cluster contained predominantly archaeal and bacterial sequences, the other metazoa and viridiplantae . based on this taxonomic classification of the sequences, the clusterings had an average accuracy of about 82%. this means that for the unsupervised setup, the clustering picked up a decomposition of the sequences which, while being biologically meaningful in itself, did not reflect the specific question we were interested in. this problem was overcome by including prior knowledge in form of sequence labels. these results illustrated nicely how the partially supervised approach improved the parameter estimation and structure learning by guiding it away from clusterings which were not consistent with the biological question under consideration. however, the high variance for moderate amounts of labeled samples again underlined the importance of the label selection procedure.

in order to quantify the impact of label selection, we split the results shown in fig.  <dig> in cases where the phylogenetically divergent groups with glutamate specificity tydc/mfna were linked by the labeling  and cases where there was no link. the average accuracies for the two cases are shown in fig.  <dig>  accuracies of the cases where tydc/mfna were linked are shown in red, other cases in blue. the average accuracies of labelings with tydc/mfna were higher. for  <dig> labels , the average accuracy improved from 69% to 90% for the cases where tydc and mfna were linked. it is also noteworthy that the variances of the average accuracies were still large. these results showed how the integration of additional biological prior knowledge  could improve the clustering.

ww domain family
the ww domain is a small protein module of about  <dig> amino acids, which forms a triple stranded anti-parallel β-sheet. it is involved in protein-protein interactions and its target sequences are usually proline rich or contain phosphorylated serine/threonine sites. based on the sequence of their ligands, ww domains have been grouped into three functionally different classes   <cit> . using protein arrays, the ligand preferences for  <dig> human ww domains of the two most populated classes, i and ii/iii were determined  <cit> . here, we asked the question, whether the ligand based classification can be recovered using only the domain sequences. the nec model selection gave a two cluster model as optimal. the domains were correctly classified with accuracy 96% with this model. this result was highly robust,  <dig> repetitions of the clustering gave an average accuracy of 96% . when performing the same setup in a partially-supervised manner with randomly selected labels, the same results were obtained for any number of labels.

based on the optimal unsupervised clustering according to the nec, the positions of the alignment were ranked by their information for separating the clusters . the main structural difference between members of group i and of group ii/iii is the existence of an additional binding site, the xp <dig> groove in the latter. of three residues which form the xp <dig> groove  <cit> , two were identified within the five top ranking positions . thus, our method was not only able to identify the correct clustering of this domain, it also identified the sites responsible for the functional difference without prior knowledge.

sh <dig> domain family
similar to the ww domain, the src homology domain  <dig>  is a protein interaction module binding to polyproline regions. its preferred binding partners are characterized by a structural motive, the polyproline type ii helix. two types of binding mode can be distinguished based on the direction of the helix in the binding groove  <cit> . in contrast to the ww domain, these different binding preferences are not caused by two different binding patches on the domain, rather it is one site responsible for these interactions. this makes an automated classification and identification of specificity inducing sites even more challenging than in the case of the ww domain.

we analyzed data from a large scale interaction study on  <dig> yeast sh <dig> domains  <cit>  which classified each domain into one of three groups  based solely on their ligands. some of the domains showed interactions with both types of polyproline helices, indicating that even biologically there is no clear separation between these groups. out of the twenty sh <dig> domains in the data set, eight fell unequivocally into class i, four into class ii, five showed binding for both classes  and three showed an unique, unusual binding pattern. for the partially-supervised clusterings 1- <dig> labeled samples from each of the classes i and ii were selected at random. this corresponds to 10%-60% labeled samples out of the  <dig> sequences in the data set. the structure of the sh <dig> domain of pex <dig>  was used as reference.

for the the models trained with two labels per class, nec model selection picked two components as optimal and the clustering gave a clear separation of class i  and classes ii and i/ii . the separation was complete except for two misclassifications, one for classes i and ii each. with respect to the i vs.  class separation, this amounted to an accuracy of 78%. to quantify the robustness of this result and the performance for larger number of labels, average accuracies over thirty repetitions were computed fig.  <dig>  thirty repetitions of the two label setup had an average accuracy of around 65% . in the unsupervised approach we observed average accuracies of 80%  for  <dig> repetitions. thus, the partially-supervised setup had a detrimental effect on clustering performance with up to four labels per class. probably the main reason was again the random selection of labels for the partially supervised parameter training. although the average accuracy was better, the optimal unsupervised model chosen by nec had one misclassification more than the one from the partially-supervised clusterings with two labels per class .

as the clustering results revealed a sufficient overlap with the ligand based classification, the next question was, whether the sites of highest importance for the clustering are indeed involved in the ligand binding. one interesting aspect of the csi structure learned for the sh <dig> data was, that there were almost no completely uninformative positions in the alignment . this showed the high heterogeneity of the sequences involved, where each position carried at least some information about cluster separation. in order to evaluate the ranking, the highest scoring sites were mapped on the structure of the pex13p sh <dig> domain. this domain contains a second interaction site, which we did not consider, as it is not present in other members of this group. we found that of the  <dig> highest scoring residues  <dig> are directly involved in ligand interaction, i.e. "their accessible surface area dropped by more than 50% or their backbone amides were shifted considerably after binding of the ligand"  <cit>  . the alignment of the ten best scoring positions is shown in fig.  <dig>  the previously reported functional residues are marked in yellow.

interestingly, other sites directly involved in the interaction yielded low scores. the sh <dig> domain of sla <dig>  contains five primary binding interface positions, tyr <dig>  phe <dig>  trp <dig>  pro <dig> and phe <dig>  these positions were listed at the very end of the ranking, within the last nine positions, and were found to be uninformative for the clustering. thus, our method identified those sites, which are responsible for differences in binding between the family members. complementary, it rejected those, which are of importance in all family members.

comparison with other methods
the general principle underlying most methods for the prediction of functional residues, independent of the specific metric used, is to contrast the amino acid composition in the alignment between different clusters. as such, the quality of the clustering is crucial for the subsequent prediction of functional residues. therefore, in the following we evaluate the clustering performance of the csi mixtures.

in order to assess the performance of our method in comparison to other state-of-the-art procedures, we computed clusterings for all the data sets using five different methods. the cluss  <dig>   <cit>  algorithm is a tree-based clustering method which does not rely on an alignment. in the original papers cluss has been compared with favorable results to a variety of protein clustering methods. the clusterings were performed using the cluss server at . additionally we applied four methods which combine clustering and functional residue prediction. the proteinkeys algorithm  <cit>  finds subgroups and putative functional residues by combinatorial entropy optimization . the treedet  <cit>  server  offers two different methods for clustering and functional residue prediction: the treedet-s is a tree-based method which tries to find optimal tree cuts and treedet-s3det is based on dimensionality reduction by multiple correspondence analysis. all methods were run on the respective servers with default parameters.

in addition to domains described in detail above, we revisited a previously analyzed data set  <cit> . the alignment of the malate/lactate dehydrogenase  family  is a benign test case for clustering and functional residue prediction. the data set is small  and there is a single experimentally verified specificity-determining position  with very strong  subgroup specific conservation. for details on the csi mixture clustering on this data, refer to  <cit> .

generally the csi mixtures performed favorably. in the dehydrogenase data, there is a strong correlation between the clustering accuracy and the presence of the true specificity inducing residue in the predicted functional residues. for those methods with good clustering performance  arg <dig> was correctly predicted to be functional, whereas the other method  did not . this underlined the importance of a high quality clustering as a necessary condition for the prediction of biologically valid functional residues.

the proteinkeys method achieved rather mediocre clustering accuracies. the main reason was the inflated number of clusters returned by the method. this suggests that the proteinkeys method has the implicit assumption that the data contains a larger number of functional subgroups, which makes it less suited for the small, highly diverse data sets which are the focus of this work.

to test whether this result was exemplary for other tree based methods, we calculated phylogenetic trees for the four analyzed domain families. starting with the multiple alignments of the families,  <dig> bootstrap replicates were generated with the seqboot program  <cit> . finally, trees were calculated using proml and a consensus tree was generated by consense  <cit> . the decarboxylase tree captured the phylogenetic partitioning as described above. as expected for the phosphatases, the inactive and the active members were separated with a bootstrap support of  <dig>  this was in contrast with the other two data sets where the resulting tree did not show reliable bootstrap values . the average bootstrap values per data set were  <dig>   for the sh <dig> data and  <dig>   for the ww domains. from the high standard deviation it can be seen, that beside some edges with decent support, there were also edges with almost no support in the bootstrap samples. with the usually accepted bootstrap cutoff of  <dig>  the usefulness of the tree was highly dubious. in contrast, our method gave reliable results even in the challenging cases of short and extremely divergent domains , which were intractable for tree based methods. for all four data sets the median identity was at or below  the so called protein twilight zone.

discussion & 
CONCLUSIONS
domains are the structural, evolutionary and functional building blocks of proteins. a domain based analysis is a fundamental step in predicting the function of a protein. still, this step is hampered by the fact that different members of the same domain family can perform vastly differing functions. here, we used a csi mixture clustering method augmented with partially-supervised learning to assign domains to a functional subclasses. additionally, our method predicts residues relevant for the specific function of a subclass. this information can directly be used in the experimental characterization of the protein. the application of our method to four domain families revealed a good classification and identified known functional residues even for the selected, highly challenging families .

it is interesting to contrast the different effects of the extension to partially-supervised learning on these four data sets. for the ww and phosphatase domain data, the unsupervised clustering already yielded a very high quality clustering and as such it is not unsurprising that a minimal number of labels did not have a significant effect on the results.

for the yeast sh <dig> domain data set, the addition of random labels actually caused more noise in the clustering than compared to the unsupervised case. there are a number of possible explanations for the apparent disadvantage the partially-supervised framework had on the sh <dig> data. first of all, the labels used for the  <dig> repetitions of the partially-supervised setup were chosen at random and therefore it is likely that samples which are outliers within their class were labeled. this can overemphasize these outliers in the characterization of the cluster center, especially if only few labels are available, as was the case in our setup. this effect of low quality labels having a detrimental effect on clustering performance has been described previously  <cit> . from this perspective, the results on the sh <dig> data can be seen as a cautionary tale to take proper care that the chosen labels chosen are of high quality. it is also noteworthy that even though the average performance of the partially-supervised method decreased, the best model chosen according to nec was one misclassification better than the model obtained from the unsupervised setup. finally, for the decarboxylase data the integration of prior knowledge greatly increased the quality of the clustering solution with respect to a subgrouping of the data that was informative for the biological classification we were studying. at the same time, just as with the sh <dig> data, the high variance observed for the labeled data sets underlined the importance of the choice of labels. bearing that in mind, if the labeled samples are known to be of high quality, the partially-supervised approach can greatly improve the clustering setup.

in addition to the functional grouping, our method also provides a ranking of sites important for each group. as exemplified by the sh <dig> domain, the method is able to distinguish 'core' position, which are functional in all family members, from those which are responsible for the sub-group specific function. this information could guide the further experimental characterization of the domain family.

the software we developed to carry out this analysis pymix - the python mixture package is freely available from . for future work it would be interesting to investigate additional data sets, especially protein sequences which arose from the kind of high-detail studies which yield data sets that do not lend themselves to study with tree-based methods. on the theoretical side it would be interesting to extend the framework with more complex notions of partial-supervision such as pair-wise positive and negative constraints between samples. finally, we intend to devise additional improvements to the running time of the structure learning to optimize performance for the analysis of large scale data sets.

authors' contributions
bg implemented the method and carried out the computations. js assembled the data sets and performed the biological analyses. as conceived the study and participated in its design and coordination. all authors wrote the manuscript and approved the final version.

supplementary material
additional file 1
supplementary figures. figures of bootstrap trees for the various data sets.

click here for file
