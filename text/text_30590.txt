BACKGROUND
the concept of a direct, one-to-one association between a sensory stimulus and a motor response has been strongly influential in neuroscience  <cit> . such associations may be quite complex; for instance, monkeys can learn visuomotor mappings based on arbitrary rules  <cit> . but from a mechanistic point of view, it is their flexibility which is remarkable. humans and other mammals react to a given stimulus in drastically different ways depending on the context  <cit> . what is the neural basis for this? how do current goals, recent events, and other environmental circumstances gate or route immediate sensory signals to generate an adequate action?

gain control is a common mechanism by which neurons integrate information from multiple modalities or sources  <cit> . gain-modulated neurons typically have a sensory receptive field, but in addition, their overall excitability depends on some other modulatory parameter. a classic example are the neurons in parietal area 7a, whose activity can be described by the product of a gain factor, which is a function of the gaze angle, and the response profile of the visual receptive field  <cit> . that is, gaze direction determines the amplitude of their stimulus-dependent responses. according to theoretical studies, gain-modulated responses are useful for performing a class of mathematical operations known as coordinate transformations  <cit> . for example, by combining multiple eye-centered inputs that are gain modulated by gaze direction, a downstream neuron can generate a response that depends on the location of a stimulus relative to the body  <cit> . experimental studies have reported gain changes due to a wide range of proprioceptive signals, such as gaze direction  <cit> , eye and head velocity  <cit>  and arm position  <cit> . modulations relevant to attention-centered  <cit>  or object-centered representations  <cit>  have also been documented.

interestingly, all of these examples deal with the same problem – spatial localization – but the computations that can be effectively carried out through gain-modulated responses are much more general  <cit> . in particular, here i show that modulating the activity of a population of neurons is equivalent to turning on and off different subsets of neurons. thus, the modulation can be thought of as a switch that can activate one of many possible sensory networks, each instantiating a different sensory-motor map. crucially, the modulatory signal itself does not have to provide any spatial information; it can be a recent instruction or some other aspect of the current behavioral context. examples of choices between multiple sensory-motor maps determined in a context-dependent manner include speaking in one language or another, and the ability of musicians to interpret a musical score depending on the clef and key signature at the beginning of each stave. but the same principles also apply in more simplified settings, such as behavioral tasks where a given stimulus is arbitrarily associated with two or more motor responses, depending on a separate instruction  <cit> . for instance, the shape of a fixation point may be used to indicate whether the correct movement should be a saccade toward a spot of light or an antisaccade away from it  <cit> . what all of these cases have in common is a functional reconnection between visual and motor networks that must occur very quickly and without explicit spatial guidance from the context information.

using theoretical and computer-simulation methods, i show that this type of functional switching can be achieved through contextual modulation regardless of how the context is encoded – whether continuously or discontinuously – and independently of the discriminability of the stimuli. the results are presented using neural network models of hypothetical behavioral tasks similar to those used in experiments with awake monkeys. a report with a different example was published previously  <cit> .

RESULTS
all model networks discussed below have the same general, two-layer architecture  <cit> . a first layer of gain-modulated  neurons drives a second layer of output or motor neurons through a set of feedforward connections, with each gm unit projecting to all output units. in each trial of a task, the gm neurons are activated by the sensory and context signals, and a motor response is generated by the output neurons . each model proceeds in three steps. first, the gm and the desired output responses are specified according to the task. then, synaptic weights are found that, across all stimulus and context combinations, make the driven output responses as close as possible to the desired ones. finally, the network is tested in multiple trials in which the gm neurons drive the output units. model performance is measured by comparing the resulting, driven pattern of motor activity in each trial with the desired, pre-specified one. the first task, with only two contexts, serves to illustrate the analogy between gain modulation and a switch.

switching between saccades and antisaccades
in the antisaccade task, a stimulus appears briefly at position x along the horizontal and the subject responds by making an eye movement . there are two possible contexts or conditions. in the first one, the movement should be to the location where the stimulus appeared, x; in the second one, the movement should be to the mirror-symmetric point, -x. both condition and stimulus location vary across trials. the color of the fixation spot  may serve to indicate which condition applies in each trial  <cit> .

examples of model gm responses chosen for this task are shown in fig.  <dig>  these neurons simply respond to visual stimuli presented at different locations; however, they are also sensitive to the context. each graph shows the mean firing rate of one unit as a function of x, with one curve for each of the conditions . these tuning curves are bell-shaped because gaussian functions were used to define them . because context affects the gain of the responses, for any given cell, the two curves differ only in their amplitudes. the context that produces the highest gain is the preferred one. the maximum and minimum gains for each neuron are model parameters that can be between  <dig> and  <dig>  the four gm units in fig.  <dig> illustrate various degrees of modulation. the case of full modulation  depicted in fig. 2a corresponds to a neuron that is switched on and off by context: in its preferred condition it is highly active, whereas in its non-preferred condition it is fully suppressed.

first consider what happens if the first layer of a model network is composed of two populations of such switching neurons. one population is active in context  <dig> and the other in context  <dig>  this is illustrated in fig. 3a. the rectangle encloses the responses of all model neurons  in a single trial of the antisaccade task. the firing rates of the gm neurons are in color. the two populations  have opposite context preferences but identical sets of sensory tuning functions. the black dots are the responses of the driven output neurons. their center of mass , which in this case is the same as the location of the peak, is interpreted as the target location for an impending saccade. the network performs accurately in the four trials shown in the column, since the encoded movement location is equal to x for saccades  and to -x for antisaccades . it is easy to see why such a network can implement two entirely independent sensory-motor maps: each population has its own set of synaptic connections driving the downstream motor neurons, and the maps are kept separate because the two populations are never active at the same time.

the model correctly produces saccades in context  <dig> and antisaccades in context  <dig>  furthermore, this scheme for switching sensory-motor maps as a function of context would also work for any two maps driven by the two populations. this model switches maps successfully because the gm neurons are themselves switched on and off by context, so this case is trivial. however, the main result in this section is that a network of partially modulated gm neurons has exactly the same functionality. the more rigorous statement is this: for a discrete number of contexts and everything else being equal, a network of partially modulated neurons can generate the same mean downstream responses as a network of switching neurons. figure  <dig> illustrates this equivalence: identical output activity profiles are generated when all gm neurons are fully suppressed in their non-preferred context , when all are partially modulated by the same amount , and when the modulation varies randomly across cells . these three cases require different sets of synaptic connections between gm and output layers, but this is simply because the gm responses vary across cases. in particular, note the dark blue diagonal bands in figs. 3e,3f, compared to fig. 3d. they correspond to negative weights needed to subtract out activity that is irrelevant to a particular context. for instance, in the direct saccade trials of fig. 3b, the responses of the antisaccade-preferring neurons should be cancelled, and viceversa. the new negative weights combined with larger positive weights achieve this.

the key point is that, under relatively mild conditions, partial and full modulation lead to the exact same repertoire of switchable sensory-motor maps . the formal proof is presented in appendix a. this result is interesting because it provides an intuitive interpretation of gain modulated activity: modulations that may seem small at the single-unit level may produce drastically different output responses due to their collective effects, the result being as if different sensory populations had been turned on and off.

partial versus maximum gain modulation
the equivalence between networks of neurons that switch across contexts and networks with partial modulation is subject to an important condition and a qualification.

the key condition is that the modulation factors that determine the gain of all the neurons with similar stimulus selectivities must be linearly independent across contexts . in practice, one way to achieve this is to include all relevant combinations of sensory and contextual preferences. for instance, if there are two neurons that respond maximally when x =  <dig>  the condition is fulfilled for that pair if one neuron prefers context  <dig> and the other context  <dig>  as long as this independence constraint is satisfied, there is great flexibility in the actual amount of modulation; it does not need to be 100%, as with a full switch.

the qualification, however, is also critical, because a network of partially modulated gm neurons is not exactly the same as one composed of switching neurons: in most functionally relevant cases, partially modulated neurons are effectively noisier. in general, variability plays an important role in the performance of these networks. no fluctuations were included in the simulations of fig.  <dig>  so performance was virtually perfect. but the magnitude of the error between correct and encoded movement directions increases depending on the amount of noise that is added to the gm responses, and as the difference between the minimum and maximum gains diminishes, the impact of noise typically goes up. this is shown analytically in appendix c and is illustrated in fig.  <dig> 

two measures of noise sensitivity are plotted in fig.  <dig>  the first one is the standard deviation of a single output response across trials with identical stimulus and context. this number, σr, quantifies the variability of single neurons. figure 4a plots σr as a function of γ, which is the minimum gain of the gm neurons . when γ =  <dig>  the gm neurons are fully suppressed in their non-preferred context; when γ =  <dig>  the gm responses are identical in both contexts. the three curves are for three levels of noise. their order shows that, as expected, higher noise in the input layer always produces higher variability in the output. for each data point, the synaptic weights were set so that the average firing rates of the output neurons, as functions of stimulus location and context, were always the same . thus, for all γ values, the average profile of motor responses for x = - <dig> and x =  <dig> looked exactly like those in fig.  <dig>  the monotonically increasing curves in fig. 4a indicate that the variability of the output rates goes up with γ, as predicted theoretically .

the second measure of noise sensitivity is σcm, which estimates the error between the desired movement location and the center of mass of the output population, which is considered the encoded movement location . thus, σcm quantifies the variability of the network. figure 4b shows that σcm also increases with γ, reaching a saturation level. this error saturates because, in contrast to the individual neuron responses, the encoded movement location is restricted to a limited range of values, so its variance cannot grow above a certain limit.

figures 4c and 4d show the same measures of variability but when the synaptic weights are computed using the standard, optimal algorithm . for each value of γ, the optimal algorithm considers both the mean and the variance of the output responses  <cit> , striking a balance between them that, overall, minimizes the average squared difference between the driven and the desired output rates . therefore, in figs. 4c,4d, the mean output responses are not quite the same for all data points; in particular, for x = - <dig> and x =  <dig> there are small differences compared to the curves in fig.  <dig> . this method markedly reduces the variability of the individual output neurons relative to the case where only the mean values are considered. it also produces a modest decrease in σcm . however, it does not change the main effect: the error in the encoded location still grows monotonically with γ.

note that, as explained in appendix c, γ >  <dig> does not always produce higher variance in the output, compared to γ =  <dig>  for instance, if the sensory-motor maps in the two contexts are the same, the optimal strategy is to activate both populations of gm neurons simultaneously, i.e., to use γ =  <dig>  this is simply because the average of two noisy responses with equal means is better than either of them. in general, however, switching is relevant precisely when the sensory-motor maps are different, as in figs.  <dig> and  <dig>  in which case weaker modulation  results in higher output variability.

in conclusion, as the modulation becomes weaker, the performance of the network typically becomes less accurate, even though the average output responses may be close or identical to those obtained with maximum modulation. in fig.  <dig>  this becomes more of a problem when the minimum gain γ is above  <dig>  or so, at which point σcm is about twice that observed with full modulation. these results were obtained using the same γ for all gm neurons, but almost identical curves were produced when γ varied randomly across cells and the results were plotted against its average value.

continuous vs discontinuous context representations
the possible contexts encountered by an organism could be numerous and diverse, so it is not clear how the brain might encode them. there are at least two distinct ways: as separate, discrete states, or as points along a smooth, continuous space. what would be the difference in terms of the functionality of the remapping networks studied here? this is investigated next, using a generalization of the antisaccade task referred to as the scaling task.

the scaling task is very much like the antisaccade task, except with more contexts. the subject's response should be an eye movement toward a location determined by the position of the stimulus, x, and a scale factor, y; the movement should be toward the point xy. when y =  <dig>  the movement is simply a saccade toward x; when y = - <dig>  the movement is an antisaccade toward -x; when y =  <dig> , the movement should be to a point halfway between fixation and the location of the stimulus, and so on. to begin with, five possible conditions are considered, corresponding to scales of - <dig>  - <dig> ,  <dig>   <dig>  and  <dig> 

differences between these two coding strategies can be observed in fig.  <dig>  this figure shows the performance of two versions of the network model, each with  <dig> gm cells, in four trials of the scaling task. in the first version, illustrated in figs. 6a-6d, context is encoded discontinuously, as in figs. 5a,5b. the gm firing rates are color-coded, ordered according to their preferred stimulus locations  and preferred scales . in each trial, the gm rates form a band of activity centered on the location of the stimulus. the most intense responses are somewhat clustered, although high firing rates are scattered throughout the band. the band occurs because the responses vary smoothly as functions of stimulus location, and the scatter in the y-direction is due to the random order in which each neuron prefers the contexts; such scatter would be present even without noise. the output neurons have profiles of activity  with the highest peak located near the intended movement target. the small wiggles and secondary bumps are due to noise. the performance of the network is accurate, however: the encoded movement is close to the intended one for all combinations of stimulus location and scale factor . the second version of the model, illustrated in figs. 6e-6h, is almost identical to the first, except that context is encoded continuously, as in figs. 5c,5d. now the the activation pattern that emerges is clearly localized, centered on the current stimulus and context values. performance is similar for the two networks, both having σcm ≈  <dig> .

figures 7a,7b evaluate the performance of these two models across a wider range of parameters. the graphs show σcm as a function of the number of gm neurons for three levels of noise. in all cases, the error decreases approximately as  – a sign that noise is what limits the accuracy of the system. this is consistent with the virtually perfect performance obtained with zero noise. with the five selected contexts, results are almost identical for the continuous and discontinous cases.

robustness and generalization
there are two aspects of these networks that could vary depending on how context is encoded. the first is their robustness. in addition to random variations in the gm responses, there could be fluctuations in other elements of the circuits, in particular, the synaptic connections. thus, a key question is how finely-tuned these connections need to be in order to obtain accurate performance. the answer: not very much. the networks tolerate considerable alterations in synaptic connectivity. this is illustrated in figs. 7c,7d, which show σcm as a function of the number of gm neurons in networks in which the connections were corrupted. for these plots, the connections were first set to their optimal values, as in the standard simulations, but then 25% of them, chosen randomly, were set to zero. to generate the same range of output firing rates, all remaining connections were divided by  <dig> , but no further adjustments were made. performance was then tested. compared to the results with unaltered weights , performance is evidently worse, but the disruption is not catastrophic; in particular, the error still goes down with network size. the increase in error is most evident when the noise is relatively low. random weight deletion was used for these simulations because it is a rather extreme form of weight corruption, but other manipulations generated similar results.

the second important issue about these networks is their capacity to generalize. so far, the models have been tested with the same stimuli and contexts used to set the connections, but what happens when new stimuli or contexts are presented? this is where partial modulation and a smooth organization of response properties make a difference. first consider the model in which scale is encoded discontinuously. its performance in generalization is shown in fig. 7e. for this graph, only  <dig> stimulus locations, in combination with the  <dig> possible scales, were used to calculate the synaptic weights. that is, only  <dig> evenly-distributed values of x were used in equation  <dig>  giving a total of  <dig> combinations of stimulus and context. however, the network was tested with all  <dig> combinations of  <dig> stimulus locations  and  <dig> scales. accuracy is practically the same as in the original simulations , where the  <dig> stimuli and  <dig> scales were used both for setting the connections and evaluating performance. the same scales had to be used in both cases because, given the discontinuous encoding, the gain factors for other scales could not be interpolated or inferred.

in contrast, in the continuous case, generalization can be tested in both the sensory and modulatory dimensions; the gm responses can be obtained for any combination of stimulus location and scale, because both quantities are defined analytically . results are shown in fig. 7f. for this graph,  <dig> stimulus locations and  <dig> scale factors were used to set the connections. the network was then tested on  <dig> stimulus locations and  <dig> scales within their respective ranges. performance is slightly better than in the standard condition in which identical combinations of  <dig> stimulus locations and  <dig> scales were used throughout .

in summary, this task requires somewhat more complex gm neurons than the antisaccade task, because there are more contexts. in the discontinuous case, the basic intuition for why the model works is the same as in the previous task: with the proviso that they are effectively noisier, partially modulated neurons are equivalent to switching neurons, which can trivially establish independent sensory-motor maps. however, the key advantage of a continuous neural representation of context over a discontinuous one is that it allows a network to perform accurately on combinations of stimulus and context that have not been explicitly encountered before. by its very definition, such continuous encoding requires partial modulation. therefore, although partial modulation is typically detrimental for switching between discrete contexts , it is highly advantageous when context is parameterized by a continuous variable, because it serves to generalize.

remapping based on ambiguous stimuli
in the scaling task, all stimuli and contexts are unambiguous, but in many real-life situations and experimental paradigms, motor actions are preceded by perceptual processes that involve the interpretation or analysis of sensory information. that is, specific actions  are often based on ambiguous information . in theory, switching between maps should be independent of the perceptual component of a task .

to investigate this, consider the orientation discrimination task illustrated in fig.  <dig>  in each trial, a bar is presented and the subject must determine whether it is tilted to the left or to the right. the judgement is indicated by making an eye movement either to a left or a right target. discrimination difficulty varies depending on orientation angle x. the task is most difficult when x is near 0° and the bar is nearly vertical, but it becomes easier as x approaches ± 45°. this is also a remapping task because the association between bar orientation and correct target is not unique: the color of the fixation spot determines whether left and right targets correspond to bars tilted to the left  and to the right , respectively, or viceversa. there is also a no-go condition, which gives a total of three.

the gm cells in this case are tuned to stimulus orientation. the response curves are not shown, but have a single peak, as in figs. 5a,5b – the difference is that the sensory variable is orientation, which varies from -90° to +90°, and that there are only three conditions, three values of y . the order in which each gm cell prefers the three contexts is set randomly, so context is encoded discontinuously.

the responses of the model output units are shown in figs. 9a-9h. in no-go trials , all neurons fire near their baseline rates, as prescribed . thus, in this condition the network ignores the stimuli. in go trials, however, the profile of output responses has peaks at - <dig> and + <dig>  which are the only two target locations in this task. in contrast to the activity profiles seen in previous tasks, here there never is a unique peak, even with zero noise . instead, the relative amplitude of the two peaks varies as a function of bar orientation. the difference in the amplitudes of the two hills of activity decreases as the bar becomes more vertical, thus reflecting the difficulty of the task. without any noise, the largest peak is always located at the correct target, but with noise the amplitudes vary across trials and errors are produced .

to quantify the performance of the network in this case, the generated movement was set equal to the location of the tallest hill of activity. this always corresponded to one or the other target location, + <dig> or - <dig>  so each trial could be scored as either correct or incorrect. the assumption here is that a profile of activity with two peaks, as in figs. 9c,9d, can be converted into a profile with a single peak, such that the smaller hill of activity is erased. networks with recurrent connections organized in a center-surround fashion can do just that  <cit> . so, if such lateral interactions were added to the output layer of the network, only the largest hill of activity would remain. equivalently, the responses of the output neurons could serve as inputs to an additional, third layer that performed the single-target selection  <cit> . either way, given that this is a plausible operation, it is reasonable to simply consider the location of the largest peak to determine the evoked movement.

based on this criterion, the performance of the network is shown in figs. 9i,9j, which plot the probability or fraction of movements to the target on the right as a function of stimulus orientation x. these are essentially neurometric curves – psychometric curves computed from neuronal responses – and indeed have the sigmoidal shape that is characteristic of many psychophysical measurements. figure 9i shows the results for condition  <dig>  in which bars with x >  <dig> correspond to movements to the right; fig. 9j shows the results for condition  <dig>  in which the association is reversed and bars with x >  <dig> correspond to movements to the left. the gray curves are best fits to the simulation data points. the fits have two parameters, the center point, or bias , and a second parameter that determines the steepness at the center point and is inversely proportional to the discrimination threshold . without noise, performance is virtually perfect , in which case the bias and threshold are zero and the neurometric curve becomes a step function. however, both quantities increase in magnitude as noise is increased, producing the observed sigmoidal curves.

the presence of a bias might be surprising, given the symmetry of the network. however, the bias depends on the number of trials used to estimate the probabilities. if each orientation were tested an infinite number of times, the data points in figs. 9i,9j would line up perfectly along continuous curves. the discrimination thresholds of those curves would not be significantly different from those shown, but their biases would be zero. with finite samples, a bias in the neurometric curve is inevitable.

figures 10a,10b show the bias and discrimination threshold as functions of network size for three levels of noise. both quantities decrease with network size, so in this sense, the network is just as effective as that for the scaling task. because large numbers of trials were used, the bias is about an order of magnitude smaller than the threshold. figures 10c,10d plot the results when the synaptic connections in the network are corrupted by deleting 25% of them at random, as in figs. 7c,7d. this manipulation leaves the discrimination threshold virtually unchanged, but increases the bias by about an order of magnitude, making it comparable to the threshold. this bias is a true limitation of the network; it does not decrease with more trials. figures 10e,10f show performance during generalization, as in fig. 7e. in this case, only the two extreme orientations, -8° and +8°, were used to set the connections . the network was then tested on the standard set of  <dig> orientations. a true bias also appears in this case. it stays lower than the threshold, which remains essentially unchanged.

in summary, although the ambiguity of the sensory information is reflected in the motor responses, it does not interfere with the context-dependent selection mechanism.

discussion
gain modulation as a switch
the above results demonstrate that contextual modulation could serve to select one of many associations or maps between sensory stimuli and motor responses. indeed, a key insight is that modulating the gain of a neural population is, in a sense, equivalent to flipping a switch that turns on or off specific subpopulations of neurons. this explains why networks of gm neurons can generate large changes in downstream responses – even all-or-none changes, as in go vs no-go conditions  – although their own activity may vary rather subtly. in this framework there is a distinction between the selection process and the sensory representations. the capacity to switch depends on the collection of gain factors, whereas the space of possible functions of the stimulus that can be computed downstream is determined primarily by the sensory tuning curves . a weaker modulation typically increases the sensitivity to noise of the resulting motor responses , but otherwise, partial modulation can achieve the same sensory-motor map selection as maximal, all-or-none modulation. this is why the mechanism works across a large variety of tasks and representations that involve some type of switch.

in a landmark paper, pouget and sejnowski  <cit>  studied the capacity of gm networks for coordinate transformations using the concept of basis functions. a group of functions of x form a basis set when any arbitrary function of x can be computed as a linear superposition of those functions in the group; sines and cosines of are a well known example. the function of x typically associated with a neuron's response is its tuning curve – its firing rate measured as a function of x. pouget and sejnowski showed that, starting with two networks that form separate basis sets for x and y, a network of gm neurons comprising all possible combinations  of those two sets would form a basis set for functions that depend simultaneously on x and y. this means that any function of x and y can be computed from the resulting gm responses. this was a crucial result, because it provided a rationale for generating such a combined representation. however, it assumed that both the sensory and modulatory variables are continuous and that, taken independently, the sets of x- and y-dependent tuning curves both form true basis sets.

the present results relax some of these assumptions and provide a complementary point of view. when the modulatory quantity y varies discretely, each of its values corresponds to computing a different function of the stimulus x. furthermore, the x- dependent tuning curves determine what functions of x or sensory-motor maps can be computed downstream, but there is no requirement for them to form a strict basis set. as mentioned, the discontinuous case fits better with the idea of switching between various possible maps, as if separate populations of neurons were turned on and off. this approach also highlights two important characteristics of these networks, that the modulation factors need to be nonlinear functions of context , and that the sensitivity to noise depends on the magnitude of the modulation .

relation to other models
an important property of networks of gm neurons is that the output units read out the correct maps using a simple procedure, a weighted sum  <cit> . as a consequence, the overall strategy of these networks can be described as follows: the input data are first projected onto a high-dimensional space, and the responses in this space are then combined through much simpler downstream units that compute the final result – in the present case, x and y are the inputs and the high-dimensional space is composed of the gm responses. interestingly, such expansion into an appropriate set of basis functions  <cit>  is the central idea of many other, apparently unrelated models. for instance, this scheme is a powerful technique for tackling difficult classification and regression problems using connectionist models  <cit> . it also works for calculating non-trivial functions of time using spiking neurons  <cit> . this strategy might constitute a general principle for neural computation  <cit> . in addition, these networks are capable of generalizing to new stimuli and are quite resistant to changes in the connectivity matrix, so they don't require exceedingly precise fine-tuning.

the problem of high dimensionality
a crucial requirement for the above scheme of projecting the data onto a suitable set of basis responses is to cover all relevant combinations of sensory stimuli and modulatory signals in the gm array  <cit> . it is the potentially large number of such stimulus-context combinations that may pose a challenge for these networks, a problem sometimes referred to as the curse of dimensionality  <cit> . in terms of the antisaccade task, for example, the context could be signaled by the shape or color of the fixation spot, the background illumination of the screen, a sound, or simply by past events, as would happen if the experiment ran in blocks of saccade and antisaccade trials. each one of these potential cues would need to have a similar modulatory effect on the sensory responses, and it is not clear how the brain could establish all the necessary connections for this. part of the problem is that we don't know how many independent dimensions there are – independence being the crucial property. for instance, the model for the antisaccade task has two contexts and requires two populations of switching neurons. more neurons are needed to deal with the version of the task that has five scales or contexts, but the number of necessary neurons does not keep growing endlessly; if the modulatory terms are chosen appropriately, a relatively small number of neurons can generalize to any scale, in effect generating an infinite number of sensory-motor maps. of course, the key is that these are not independent, so the network can generalize. thus, the scheme might work with realistic numbers of neurons if the number of independent context dimensions is not exceedingly large, but estimating this number is challenging.

another possibility is to have a relatively small number of available gain modulation patterns controlled by an additional preprocessing mechanism that would link them to the current relevant cue , a sort of intermediate switchboard between possible contexts and possible gain changes. attention has some features that fit this description – it can select or favor one stimulus over another, it can act across modalities, and it can produce changes in gain  <cit> . no specific proposals in this direction have been outlined yet, neither theoretically nor experimentally, but this speculative idea deserves further investigation.

is exact multiplication needed?
a key ingredient of the general, two-layer model is that the gm neurons must combine sensory and modulatory dependencies, f and g, nonlinearly  <cit> . results of two manipulations elaborate on this. first, when f and g were added  instead of multiplied, all transformations failed completely, as expected  <cit> . second, when the sensory- and context-dependent terms were combined using other nonlinear functions , accuracy remained approximately the same in all tasks. results are shown in table  <dig>  which compares the performance of networks that implemented different types of stimulus-context interactions but were otherwise identical. this shows that the exact form of the nonlinearity used to combine f and g is not crucial for these models.

however, in some cases a multiplication allows the synaptic connections to be learned through simple hebbian mechanisms  <cit> , so it may be advantageous for learning. at least under some conditions, neurons combine their inputs in a way that is very nearly multiplicative  <cit> . perhaps they do so when multiplication provides a specific computational advantage.

mixed sensory-motor activity
in the model for the orientation discrimination task, the level of activity of the output neurons reflects not only the evoked movement but also the difficulty of the sensory process. this is consistent with the observation that, during sensory discrimination tasks, neuronal responses in many motor areas carry information about the stimulus  <cit> . this activity is often interpreted as related to a decision-making process. in the discrimination model, the responses of the neurons encoding the movement toward one of the targets increased in proportion to the strength of the sensory signal linked with that target , as observed experimentally  <cit> . the model was not designed to do this. it simply could not generate single, separate peaks of activity for two nearby orientations on the basis of a single feedforward step; an additional layer or additional lateral connections would be required for that. nevertheless, when such selection mechanism is assumed to operate, remapping proceeds accurately, even when the strength of the sensory signal varies. according to the model, sensory and motor information should be expected to be mixed together when distinct, non-overlapping responses  are generated on the basis of small changes in a stimulus feature that varies continuously, as orientation did in this task.

responses that depend on multiple cues
in the present framework, if sensory responses were modulated by multiple environmental cues, the responses of downstream neurons could be made conditional on highly specific contextual situations . therefore, this mechanism may also explain the capability of some neurons to drastically change their response properties in a context-dependent way. two prominent examples are hippocampal place cells, whose place fields can be fully reconfigured depending on multiple cues  <cit> , and parietal visual neurons, which become selective for color only when behavioral context dictates that color is relevant  <cit> .

in many tasks, two or more inputs are combined into conditional statements – 'if x and y then z'. the switching property of gm networks is useful in these situations as well. the study of abstract rule representation by wallis and miller  <cit>  is a good example. in their paradigm, the decision to hold or release a lever depends on an initial cue and on two pictures. the cue indicates which of two rules, 'same' or 'different', is applied to the pictures. if the rule is 'same', the lever is released when the two pictures are identical but not when they are different; if the rule is 'different' the situation reverses, the lever is released when the two pictures are different but not when they are identical. to execute the proper motor action, two conditions must be checked. with the framework presented here, it is straightforward to build a model for that task; all it requires is a neural population that encodes the similarity of the pictures  and is gain modulated by the rule. although the exact form of the modulation, for instance, whether it is close to multiplicative, is hard to infer from their data, the findings of wallis and miller  <cit>  are generally consistent with the types of responses predicted by the model.

experimental predictions
other experimental studies also include results that are consistent with gain interactions between multiple sensory cues  <cit>  or with gain changes due to expected reward  <cit> . interpreting these data is problematic, however, because those experiments were not designed to test whether changes in context generate changes in gain. the tasks described here, or similar paradigms, may be simplified to eight or so stimuli and two or three conditions, generating stimulus sets that would be within the range of current neurophysiological techniques with awake monkeys. the key is to be able to construct full response curves , so that neuronal activity across contexts can be compared for several stimuli – not only for two, as is often done. this is because the models make three basic predictions that can only be tested with multiple stimuli and conditions: the responses should have mixed dependencies on stimulus and context, the mixing should be nonlinear, and the neurons should behave approximately as a basis-function set, in the sense that a weighted sum of their responses should approximate an arbitrary function of stimulus and context extremely well  <cit> .

ideally, the nonlinear mixture will show up through multiplicative changes in gain, as in figs.  <dig> and  <dig>  where the context-dependent variations in firing intensity respect stimulus selectivity. this could certainly happen  <cit> , especially for some individual neurons, but other nonlinearities are possible  <cit>  and might work equally well. a key observation is that context can include widely different types of circumstancial information, such as expected reward, motivation, fear or social environment  <cit> . therefore, given the versatility of the models discussed here, a broader implication of the present work is the possibility that, as a basis for adaptive behavior, the brain systematically creates sensory responses that are nonlinearly mixed with numerous types of contextual signals.

CONCLUSIONS
the framework discussed here demonstrates how to make a neural network adaptable to various environmental contingencies, labeled here simply as context. to achieve this flexibility, context must influence the ongoing sensory activity in a nonlinear way. this strategy was illustrated with tasks akin to those used in neurophysiological experiments with awake monkeys, but is generally applicable to the problem of executing a sensory-evoked action only when a specific set of conditions are satisfied. the mechanism works because changing the gain of multiple neurons is, in a sense, equivalent to flipping a switch that turns on and off different groups of neurons. its main disadvantage is that all relevant combinations of stimulus and context must be covered, which may require a large number of units. on the upside, however, the switching functionality is insensitive to the quality or content of the sensory signals, is robust to changes in connectivity, and places minimal restrictions on how context is encoded. future experiments should better characterize how cortical neurons integrate sensory and contextual information.

