BACKGROUND
with recent advances in the efficiency of high-throughput snp genotyping technology, genome-wide association studies are now routinely undertaken with hundreds of thousands of snps genotyped on sample sizes necessary to detect the modest genetic effects we expect for complex diseases  <cit> . there is now a clear demand for efficient tools that allow processing of the data generated by these studies, including qc, statistical analysis and subsequent evaluation, visualization and interpretation of results. to meet these demands, we have developed goldsurfer <dig> , a new integrated software package for gwa analysis, developed from the goldsurfer tool  <cit> . the main feature of the original version of the goldsurfer program was its 3d visualisation of ld patterns. while this functionality is still available and has been further developed in gs <dig>  the focus of program has been shifted towards performing and evaluating genetic association testing. the main improvements from the previous version of goldsurfer are the ability to work on a genomewide scale, performance and feature wise, and added methods for statistical analysis and visualization of results.

the two single most important factors leading to the current surge in gwa studies are the advances in chip-based genotyping technologies  <cit>  and the available data from the hapmap project, in which a large number of common genetic variations were characterized and genotyped for a panel of four different human population samples  <cit> . the application of chip-based technology allows cheap, quick and readily available measurement of a large subset of the snps characterised by the hapmap. standard analysis is now being routinely undertaken using up to  <dig> markers and is even cheaper than customized analysis of a smaller number of markers. a chip containing  <dig> million snps is now under development and likely to be available soon. although chip-based technology has been used for quite some time for measuring gene expression, measurement of genotypes generates different analytical challenges. studies of gene expression normally measure a relatively low number of samples, however gwa studies can easily involve many thousands of samples to provide sufficient statistical power of the analysis. this leads to new analytical challenges, as the dimensionality of data sets increase.

another distinguishing feature of snp analysis compared to gene expression analysis is that mrna transcripts have mostly been experimentally verified to be expressed in various tissues and many will have a known biological role. by contrast, most snps have no defined functional role and can be located in coding as well as non-coding regions of the genome. to make biological sense of the findings from gwa studies it is crucial to link results to available biological annotation, for example by comparing the location of snps relative to genes and biological features such as cpg islands and recombination hotspots. it may be particularly important to dissect the functional role of a snp in the full context of the surrounding genomic sequence, for example if it is found in or near a gene, in an intron, exon or regulatory element. further analysis of candidate genes may involve looking at regulatory pathways, studying expression profiles, and the biological role, cellular location and molecular function based on annotation using the controlled vocabulary of gene ontology   <cit> .

before defining useful candidate markers and genes a gwa project will involve many nontrivial steps. to optimise a study in terms of power and to avoid confounding factors it is crucial to have a well-designed experiment with a large enough sample size number and a well-characterised phenotype. with the new large-scale high throughput technologies the problem has moved from generating the data itself to actually making sense of the wealth of information hidden behind a background of type i error caused by multiple testing. with the large datasets it is even difficult to store and to get an overview of the data since it is impractical to use simple text editors and that the dimensions of datasets exceed the maximum limits of data manipulation tools like microsoft excel. specialised software solutions and/or database systems needs to be used to analyse the data, which demand specific data analytical and computing skills from researchers.

the statistical methods currently applied in association studies are highly sensitive to poorly conditioned data and can easily give spurious associations so it is important to perform initial quality control. problems with the quality of the data can also be caused by the genotyping technology, including difficulties in the calling of genotypes from the raw intensities. the detection of real genetic effects can also be confounded when a marker does not conform to expectations of mendelian inheritance, for example in the case of copy number variation. most gwa studies are typically enriched with common genotypes as they are generally based on the markers identified by the hapmap project, a survey of common variation  <cit> .

the variables normally used in quality control include the failure rate of genotyping for markers and samples, minor allele frequencies, differential call rates for cases and controls, skewed heterozygosity distributions and deviation from hardy weinberg equilibrium  <cit> . snp genotype data can be said to be pseudo-binary involving a step where the original intensities are analysed using clustering algorithms. unfortunately the calling of the genotypes using different clustering algorithms are far from perfect which means that, for example, obviously monomorphic snps can be erroneously assessed to have multiple genotypes, while potentially interesting candidates may be wrongly excluded as missing values.

various methods are used for obtaining a statistical measurement of the association between a snp represented by alleles or genotypes and a phenotype of which most are based on simple chi <dig> statistics from genotype-by-disease tables, using tests such as the cochran armitage trend test. examples of other popular methods include fisher's exact test and logistic regression  <cit> . hits are often ranked by their statistical significance in terms of bayes factors or p-values. although association with snps with low p-values are theoretically less likely to be observed by chance, when  <dig> k markers are tested, we can expect a very large number of preliminary associations, the vast majority of which are likely to be false. high density gwa analysis accentuates the need for new approaches to follow up preliminary results to find candidates that are more likely to be true positives. one common way of raising the significance threshold is to apply bonferrroni correction but this may be overly conservative and could lead to discarding real hits. another approach to obtain significance limits is to perform permutation testing which is less conservative but more computationally demanding.

genetically associated markers often show a high degree of correlation with each other. neighbouring markers often do not vary independently from each other, which are referred to as linkage disequilibrium . analysing ld patterns can be useful for disentangling the underlying mechanism of an association. a suggested significant marker is not necessarily the causative variant but can be in ld with an ungenotyped functional variant. by comparing findings to the ld structure in the hapmap, studies can easily be expanded to find snps outside the genotyped subset. another interesting way of interpreting ld is to compare patterns between different populations or different classes of samples such as cases and controls. looking at ld patterns and comparing with genomic annotation features in candidate regions can be interesting for unravelling the functional explanation of a potential finding.

as previously mentioned there is a great need for specialised software for gwa studies. most available software for performing statistical analysis of genotype-phenotype datasets are mainly command line based and do not tend to be very user friendly for inexperienced computer users although the area is improving with some recent products, haploview  <cit>  and plink  <cit> . also the scale of the data makes its representation as plots and tables far from straightforward or even impossible. another problem with currently available tools is that a large number of different tools are needed to perform genotype qc, statistical analysis and downstream interpretation. genomizer  <cit>  is another tool that is similar to gs <dig> in that it is implemented in java and that it can be used for data import, statistical analysis and evaluation of results. it focuses on importing genotyping calls from affymetrix genechip arrays and employs a different approach to plotting the results by opening generated image files in an external browser.

one of the main workloads for analysis in statistical genetics and bioinformatics is the frequent formatting of data for export and import of very large data files. this procedure involves writing and running new programs and scripts that are often time consuming in both implementation and execution, creating numerous opportunities for the introduction of errors due to the data manipulation. in general there is a need for a single efficient and user-friendly platform that can accommodate multiple steps of the data analysis process from data management to evaluation of results using biologically relevant information and interactive plotting facilities.

implementation
gs <dig> is implemented as a platform independent java  <dig>  application that can be used locally on the machine on which it is installed. the program is run by downloading the application or by using java start. no additional libraries besides those that come with the installation need to be downloaded. to link to and retrieve genome annotation information from external sources such as the ucsc database  <cit>  users need to provide path and connection information to a suitable mirror of it. the installation also comes with precompiled flatfiles containing basic biological annotation and more updated and complete versions of these will be available to download from the project webpage.

the design of gs <dig> is based around an interactive graphical user interface . a central part of the design is the arrangement of data in a project based tree structure. this allows for organising data by splitting up it into different categories such as the chromosomal origin, ethnic origin or affection status while still obtaining an overview of the dataset. the progress of the data analysis can easily be saved by storing subsets of data based on performed selections and exclusions/inclusions of snps and samples after different steps of quality control. in projects with complex data analysis processes involving many collaborating researchers it is a big risk that the analysis gets out of control due to problems with version control. we have built in functionality to keep track of the data analysis flow by automatically creating and saving timestamps when performing actions such as saving projects and formatting data. the implementation of gs <dig> is optimised for analysis of very large datasets with thousands of samples and more than  <dig>  markers. following import of tab delimited files in standard or custom formats, gs <dig> internally creates marker objects and sample objects in which imported and calculated values such as properties and statistics are stored in local data structures. genotype data is written to temporary swap files that are accessed when performing subsequent calculations and are internally purged to free memory after these have been performed. for speeding up this procedure tasks are multithreaded which means that on a multi core system all processors are used for calculations. gs <dig> is able to compress gigabyte-sized text data sets into megabyte-sized binary files by saving genotypes into low-level binary data format and to save this together with calculated and imported values into project files.

a range of standard methods for quality control of data and association testing have been implemented but new features such as additional statistical methods can easily be added to gs <dig> through its dynamic design. there is a steady stream of novel methods developed in both industry and academia for statistical analysis of genetic data. the most long-lived and useful software will be the ones that are designed to easily accommodate new methods. of central importance for the gui are the interactive plots that can be used for showing all information about markers and samples and for performing selections for further analysis.

program overview
in order to exemplify the features of gs <dig> we will review the typical steps that may be taken during the analysis of a whole genome association project.

importing data
genotypes can for example be imported from flatfiles in the standard ped format  <cit>  and binary bed format  <cit> . hapmap genotype files can also be downloaded from the official hapmap webpage  <cit>  and imported into gs <dig>  compressed genotypes together with associated calculated and imported information can also be loaded from a previously saved gs <dig> project. as mentioned there are a wealth of formats available and it will be impossible to cover all specifications. for flexible import of data to gs <dig> a preview function allows the user to specify how data is formatted and how it should be imported, for example to set if samples or markers are represented in rows or columns respectively and to identify columns with for example affection status. import and analysis of multi-allelic markers and micro satellites is currently not supported. built in, there is functionality for importing genotyping calls exported from the affymetrix platform and importing data from other main genotyping platforms can easily be added due to flexible implementation of gs <dig>  additional formats not currently supported have to be transformed into one of the standard formats that are currently supported by gs <dig>  ie traditional "ped" format and the recent binary ped or "bed" format developed and popularized by plink. results from gwa studies in the form of plink output files or in publicly available summary files such as those of the wellcome trust case control consortium project   <cit>  can be imported into gs <dig> without loading genotyping calls.

loaded datasets are organized in a hierarchical tree structure with each dataset populating the tree as an individual sub node with associated plots and tables visible in the main window . after importing the genotypes additional information for markers and samples can easily be added to the project. examples of added sample information are quantitative data, binary affection status and covariates. for the markers, examples include importing statistical data that has been calculated using external server based programs or importing precompiled annotation data. all imported and calculated data can be visualised, used for interactive selections and used as arguments for statistical methods.

summary
• store and arrange projects in hierarchical tree structure

• import projects saved in compressed .gs <dig> format

• import genotype data from different file formats

◦ ped, bed or hapmap

◦ preview function lets user specify import-format by specifying datatypes in columns and rows

• import statistical results from gwa studies

◦ plink and flatfile formats for publicly available output files

• by not storing data in memory, very large datasets can be imported and analysed

• import additional information for both markers and samples

performing calculations
gs <dig> has a flexible and customizable design facilitating the expansion of functionality by adding new statistical methods to it. a number of methods for calculating statistics for snps have already been implemented in gs <dig>  the basic methods include calculating allele and genotype frequencies, minor allele frequency , heterozygozity frequencies, failure rate and the hardy-weinberg exact test   <cit> . these calculations are automatically performed for all samples and subsets of samples such as cases and controls. another category of methods uses the affection status of samples for calculating tests for genetic association. the currently implemented method in this category is the cochran armitage trend test. for quantitative trait analysis standard linear regression has been implemented. a series of transformations have also been implemented, in which p-values, inverse chi <dig> and genomic control  <cit>  can be compared. all calculations can be done for multiple affection status categories. the rationale behind splitting up the calculations into different categories is to make it easy to combine different methods to get specific solutions. as an example, a quantile quantile plot  is created by calculating chi <dig> statistics with the cochran armitage test, calculating the p-value for the result and subsequently calculating the inverse chi <dig> value for the p-value and plotting these values against each other.

to give an overview of the ld profile in a dataset, an average value for each marker can be calculated using a sliding value approach. it is also possible to find markers in a second dataset, for example imported hapmap genotypes that are in ld with a selection of markers. data can be filtered by removing redundant markers with a pairwise ld exceeding a user specified threshold, e.g, r <dig> =  <dig> to remove identical markers.

to investigate the effects of population stratification, principal component analysis   <cit>  has been implemented. pca models are calculated on genotypes as represented  <dig>   <dig> and  <dig>  plotting the clustering of samples for the first components can reveal how the different populations relate to each other, if there are outliers in the data or if samples have been misclassified.

summary
• a selection of methods for quality control, association analysis and analysis of linkage disequilibrium has been implemented

◦ allele and genotype frequencies including minor allele frequencies and marker heterozygosity.

◦ hardy-weinberg exact test

◦ cohran armitage trend test

◦ linear regression

◦ p-value calculations

◦ average and pairwise calculation of ld

◦ principal component analysis for studying stratification

• perform calculations separately for sample classes such as cases and controls

• a flexible design makes it easy to add new methods

• calculations are multithreaded to make use of all processors in multi core systems

using plots and tables
for each dataset all imported and calculated data are summarised in a central interactive table and selection of plots . markers and samples can easily be selected from any of these. the table can be used for showing values for cases and controls, respectively representing data by coloured bars giving both an overview and making it easy to spot differences between different samples categories. for example, it is easy to observe variations in allele and genotype frequencies between cases and controls. plots include general 2d scatter plots, histograms with the option to show mean values for another variable for each of the bins.

among the specialised plots is a 3d view of ld patterns , sample relationship by identity by state and a genome view  for showing marker values and annotation information as tracks such as genes, recombination hotspots and cpg islands imported from the ucsc database or local flatfile. the latter plot can be extensively zoomed both vertically and horizontally. further information about genes and snps can be obtained by automatically linking to information available on the internet. by plotting inverse against original chi2values from the cochran armitage trend test a qq plot can easily be created to identify snps with unusually high association values. the 3d ld plot has been further developed from the original goldsurfer publication. with this plot the contour and colouring of the plot can be used to represent different measurement of ld and different parts of the plot can show calculated values for cases and controls respectively. in the diagonal calculated variables such as association p-values or maf and annotation categories can be visualised as columns or ribbons. it is also possible to plot the original intensities on which the genotyping calls are based . genotyping data is typically read in traditional discrete representation and the intensities for the raw genotype type calls have to be separately imported. plotting the intensities addresses the difficulty that a significant number of markers could have been wrongfully removed due to being called as missing values. this plot can similarly to the other plots be used to show values from for example cases and controls separately. a good approach for final quality control is to manually go through a list of the highest ranked candidates for association.

all plots can be saved as images in most common format such as tiff, jpg and png.

summary
• interactive plots

◦ 2d scatter plots

◦ histograms

◦ genome view

▪ view biological features such as genes with introns and exons

▪ 2d view of ld

▪ line plots for calculated variables

◦ 3d view of ld

◦ plot intensities for raw genotype calls

▪ use different color schemes for different sample classes such as cases and control

• interactive tables

◦ for easy overview of data, variables and genotype frequencies can be represented as bars in the table.

◦ multiple sorting of markers and samples

removing data failing qc
manipulating data is a two-step process involving first selecting objects in any of the interactive plots or tables or by using the filtering tool. with the filtering tool markers and samples can be selected randomly, by entering a list of regular expressions or by setting limits for values or selecting specific classes. after the selection either inclusion or exclusion of data is performed to obtain a cleaned up version of the data.

summary
• select markers or samples using interactive plots, tables or by setting selection intervals for imported or calculated variables.

selecting candidate markers
markers can be selected based on any annotation information, imported values or calculated values or by using gene ontology terms . based on keywords genes can be selected by attributes such as name, molecular function, cellular location or biological role with markers close to these genes automatically selected.

summary
• automatically select markers close to genes selected by different annotation terms such as keywords and gene ontology.

manipulating data structures
the hierarchical tree structure can be used for a structured analysis process or by splitting up data into different categories by descriptions such as chromosomal origin for markers or ethnic origin for samples. after excluding markers failing qc a new dataset can be created containing only included markers or markers in biologically interesting regions. there are many functions for manipulating the structure such as cloning, splitting and merging data. this is useful in many situations for example when samples such as cases and controls or different populations are stored in different datasets and need to be combined together. similarly the same functionality is useful when markers are stored in separate files for example by chromosome. using the different functions for manipulating data is useful for updating datasets after additional markers or samples have been analysed and need to be added to the previous analysis. the functions are accessed from the menu bar and the actions are applied on datasets selected in the tree structure.

summary
• use the hierarchical tree structure to keep track of the progress of the data analysis process.

saving project and exporting data
the progress of the current analysis process can be saved in binary format taking considerably less space on disk compared to the original text files and keeping the structure of the project intact. another advantage is that it takes much less time to load a saved gs <dig> project compared to the initial parsing of the text files. data can also be exported in a variety of different format such as .ped, .bed, phase to be used for subsequent analysis or just for sharing your cleaned up data.

summary
• save project in binary .gs <dig> file format keeping project settings, imported information and genotypes.

• export genotypes and additional data into various formats

• use version tracking system to keep control of actions performed in the analysis process.

RESULTS
to give a flavour on how gs <dig> can be used in some of the important steps of genome wide association studies a couple of brief examples are presented in the sections below. for more comprehensive examples please refer to the tutorials on the project webpage.

investigating results from publicly available studies
publicly available results such as those from the wtccc can be downloaded and directly imported into gs <dig>  gs <dig> can also import results from statistical calculations performed using plink. it can plot interactively and query imported results such as p-values. for in-depth functional investigations, one can plot marker values together with annotated gene structures and query their functional annotation to generate summarised functional reports. to extract association p-values, a list of favourite genes can be pasted into the program to find all markers located within these target genes.

stratification analysis using pca
different genotyped populations can be batch imported from separate files. files can be merged into a new dataset consisting of a subset of markers genotyped in all populations. this allows investigation of population stratification via pca, after which the clustering of samples on the first components can be plotted for visual inspection. if this analysis suggests strong deleterious effects of stratification, it is not recommended to perform association testing further without accounting for the stratification.

association testing for genotype data
a number of procedures can be conducted for basic genotyping data. initially, the user will import genotype data using from standard formats using built in functions and then exclude markers and samples based on quality control thresholds. a new dataset can be created with all remaining objects. association using cochran armitage trend test can be done internally on these data, or externally using plink with subsequent importing of results. new sub nodes in the tree structure can then be constructed by separating markers according to chromosome. it is useful at this stage to sort markers based on the lowest association p values or largest test statistics. for qc checks of the most significant results, one can then import the raw genotyping intensities for each chromosome and plot the calls for all significant markers. for those with no obvious genotyping error the ld structure can be plotted using interactive 2d and 3d plots. these patterns can be annotated by importing hapmap data, using built-in methods for finding new markers to genotype in the more densely genotyped hapmap panel. at this stage one can import gene information, query their annotation and plot their structure and position. finally, one can export a list with the most interesting markers and save the analysis as a gs <dig> project file.

CONCLUSIONS
gs <dig> can efficiently be used on a standard laptop or desktop computer to analyse the latest generated gwa datasets, containing  <dig> markers or more and as many as  <dig> samples.

loading  <dig> markers and  <dig> samples and performing association testing calculating the p-values for the cochran armitage trend test takes roughly  <dig> mb of memory and can be done in 15– <dig> minutes on a standard dual core laptop.

availability and requirements
project name: goldsurfer2

project homepage: 

operating system: platform independent

programming language: java

manual: comes with download and can also be separately downloaded from project homepage

authors' contributions
lrc and mrb initiated and coordinated the project. apm supervised the project. fp wrote all of the code, designed the interface and wrote the manuscript. all authors read and contributed to revising the manuscript for intellectual content and approved the final manuscript.

