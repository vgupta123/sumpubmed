BACKGROUND
biologists rely heavily on a variety of publications  to discover prior knowledge about organisms of interest. scientific names are the primary identifiers for organisms used within these information resources. due to different taxonomic perspectives of authors through time, scientific names and their associated descriptions in these works are not static but represent taxonomic concepts  <cit> . this continuous change in taxonomic concepts thus brings into question the validity of using scientific names alone as a basis of comparison. however, taxonomic works often contain detailed morphological, distributional, and other evidence that can assist with analyzing the evolution in taxonomic concepts over time.

this morphological evidence can be managed in taxon-character matrices, a research tool widely used in biological research, ranging from taxonomy to phylogenetic studies. traditionally, these matrices are created manually by biologists within their taxonomic area of expertise. it is a tedious and laborious process because the matrix author must manually select relevant character information from published literature and/or other sources and populate the matrix with their associated character states or values. by far the most common method of making taxon-character matrices is using a spreadsheet, although other software tools, for example macclade  <cit>  and mesquite  <cit> , have been also used to make the matrix creation process more efficient. more recently morphobank has made a web-based matrix editor available for researchers to collaboratively develop large matrices  <cit> .

the challenge of efficiently extracting character information from systematics publications into a structured format, such as taxon-character matrices, remains open. the phenoscape knowledgebase and a number of model organism databases employ human curators to convert natural language phenotype character descriptions into a machine-readable form by using phenex  <cit>  or other web-based platforms . these manual approaches effectively capture high quality character data. however, they are time consuming and expensive.

automated extraction of factual information from text remains an active research area after decades of research. it was previously called message understanding in the eighties, but is now better known as information extraction, and sometimes also semantic role labelling, semantic parsing, or more generally text mining. algorithms and software have been developed for general domains , for specific domains , for different extraction targets , and for text in different human languages. currently, the dominant overall approach is using various machine learning methods  with text syntactic analyses, various knowledge resources , and when available, large corpus of unlabelled data, as well .

portability, the ability of a natural language processing system to perform equally well in a domain different from the one for which it was trained/developed, remains the greatest challenge  <cit> . in-domain vs. out-domain performance differences were consistently found in all systems participated in the semantic role labelling shared tasks of conll  <dig> and  <dig>  <cit> . this is because texts in different domains contain different features that computers need to learn. this explains the need to develop various information extraction systems for different domains and different tasks, see for example, the shared tasks offered by conll for general domain , biocreative for biomedical domains , and bionlp shared tasks  for biodiversity domains.

extracting morphological characters from taxonomic descriptions received relatively little attention, but it has made significant progress in the past decades. taylor  <cit>  used grammar rules and a lexicon to extract plant characters from several floras. the performance was not scientifically evaluated but estimated at 60–80% recall. taylor noted also that different parsers  may be needed to parse characters for other taxon groups, suggesting variations within biodiversity. diedrich, foruner, & milton’s terminator  <cit>  was an interactive system that used fuzzy keyword matching, a set of heuristic rules, and a handcrafted dictionary of structures, characters and character states. the system was evaluated with one random description, which showed that 55% of the time a perfect structure-character-state triple was among the first five candidates extracted by the system. this work suggests that morphological descriptions are not as structured as many had expected. wood et al.,  <cit>  sampled  <dig> descriptions from five plant species and their genera described in six different floras in english. they lumped all non-numerical characters, such as color and shape into one plant feature character. evaluated on  <dig> descriptions, the system showed 66/74% recall/precision in character extraction. the first system that used a machine learning method to process plant descriptions was cui  <cit>  but she only parsed the text at the sentence level. tang and heidorn  <cit>  subsequently advanced the research to the character level. they adapted soderland’s supervised learning system, whisk  <cit> , to extract leaf characters and fruit/nut shapes from  <dig> flora of north america  species descriptions. the system scored 33–80% in recall and 75–100% in precision depending on the characters. the lower recall indicates the training examples used may not have covered the characters in the test descriptions well, suggesting a weakness in the supervised learning approach for this task. cui, boufford, & selden  <cit>  showed that an unsupervised learning algorithm was able to learn 50–93% of the structure and character state terms directly from text morphological descriptions without any training examples. at the same time, cui  <cit>  showed that linguistic resources – machine-readable lexicons, glossaries, or ontologies – for extracting biodiversity characters were lacking. she examined three linguistic resources for plant domain and one for biology overall, and found that they lacked coverage of domain terms, an issue that still exists today: the phenotype quality ontology  <cit>  currently contains 2300+ terms, roughly the same size as fna categorical glossary  <cit> . in contrast, huang et al.  <cit>  used charaparser  <cit>  and extracted over  <dig> unique phenotype terms from  <dig> volumes of fna and flora of china alone. these resources also lack agreement in their term categorizations . the four glossaries/ontologies agreed only 19% of the time on a set of  <dig> core character terms extracted from two plant description resources. research further shows there is a high likelihood of an unlimited number of character terms needed to describe the entire scope of the biodiversity domains  <cit> . this suggests a supervised learning approach may not be the best choice for extracting morphological characters  <cit> . at the same time, learning and growing consensus-based linguistic/knowledge resources for phenotype characters of biodiversity are relatively urgent tasks.

charaparser  <cit>  was developed to address these issues. it uses an unsupervised learning algorithm  <cit>  to learn domain terms and the mature general-purpose parser, stanford parser  <cit> , to analyze sentence structures. the learned domain terms inform stanford parser what the part of speech tags for the domain terms are to help it adapt to the domain of morphological descriptions. evaluated on fna and invertebrate treatises, the system performed at  <dig> to over 90% precision and recall on character extraction, when provided with a comprehensive glossary.

charaparser semi-automatically extracts character information from taxonomic descriptions of various taxon groups and in the process involves biologists in categorizing domain terms . the categorized terms are saved in a glossary and can be used in current and future character extraction processes. similar to other automated information extraction systems, software that extracts character information requires external knowledge to extract target information. this external knowledge may come from training examples  as employed in tang and heidorn  <cit> , extraction rules defined by users, such as for paleodeepdive  <cit> , or the application of glossaries or ontologies  <cit> . charaparser was designed to extract character information and build domain glossaries simultaneously. being domain experts, users are familiar with term usages and are capable of categorizing the terms with confidence, especially when source sentences and other contextual information are made available to them. furthermore, categorical glossaries are reusable knowledge that will benefit other natural language processing applications in the biodiversity domain and are valuable resources for constructing phenotype ontologies. in contrast, the utility of training examples and extraction rules are often limited to the taxon groups or description collections for which they were created  <cit> . charaparser also differs from other information extraction systems in that it comprehensively extracts all characters found in a description, not just a predefined set of characters, making it more suitable for generating taxon-character matrices from morphological descriptions.

other biodiversity information extraction systems, including those extracting taxon names, are reviewed in thessen, cui, and mozzherin  <cit> . information extraction systems for biomedical domains that extract gene mentions, protein-protein interactions, etc. are reported and reviewed by the biocreative workshops . work on information extraction from medical records is also fruitful, for example, in  <cit> . related work in computer vision and image processing algorithms has extracted characters from high resolution images of organisms, for example, in  <cit> . while automatic identification of taxa has been called for  <cit> , training computers to score characters from images is challenging as algorithms have to be crafted to extract different types of characters and the target characters may be clustered with other characters in images.

in this paper, we introduce the explorer of taxon concepts  toolkit, which has been developed in the exploring taxon concepts project to offer a suite of web-based software tools for morphological character extraction, taxon-character matrix building, interactive taxonomic key generation, and taxonomic concept analyses. the tools attempt to work towards a number of challenges, especially on open, computable data, and advance understanding of the evolution of taxonomic names. the toolkit currently consists of text capture , ontology building , matrix generation, key generation, and taxonomy comparison  tools, in addition to supporting functionalities for input file creation, file management, task management, and user account management. the tools expect input in english. the tools can be used individually or collectively as a pipeline. we share the belief of hardisty and roberts  <cit>  for projects to “release their service early and update often, in response to user feedback”. the etc tools are made available when implemented and are updated frequently with new or improved features. the etc toolkit is currently in beta test and publicly available at http://etc.cs.umb.edu/etcsite/. a different development site is used internally to test new functions and conduct evaluation experiments, including the one reported in this paper.

taxon-character matrices produced by etc tools are raw matrices as the character states  are extracted from taxonomic descriptions without being refined  or scored. some phylogenetic analysis software  <cit>  requires that character states be scored, that is, to convert the raw values to symbols such as  <dig>   <dig>  and  <dig>  where 0 = small, 1 = medium, and 2 = large, for example. matrix converter  <cit> , an open source program software, can be used to score etc raw matrices to phylogenetic matrices. etc matrix generation allows characters described at a higher rank  to be automatically propagated to lower ranks  when the characters are missing at the lower ranks. it also supports inferred presence and absence characters for structures  similar to  <cit> .

etc is the first set of tools, to our knowledge, that converts morphological descriptions to taxon-character matrices. the main differences between this tool and other information extraction systems are:it does not have a set of pre-defined target characters to be extracted; rather, it is designed to parse and discover all characters described in input descriptions. given the variety of biodiversity descriptions, the system cannot predict the characters it may encounter.

it targets organism morphological descriptions, but is not limited to any taxon groups.

it takes an unsupervised learning approach to extract characters so its extraction targets are not limited to those included in the training examples and the users do not need to provide training examples.

it consolidates extracted characters to a taxon-character matrix, allowing character inheritance from higher to lower taxa and absence/presence character reasoning.

because of , it also outputs reusable knowledge entities such, as categorical glossaries/ontologies .




although still under continued enhancement, etc text capture and matrix generation tools are used by a small number of biologists to generate matrices or compare taxonomic concepts for systematics and evolutionary research  <cit> . in this paper, we introduce these two tools through a case study, in which body part measurements from spider taxonomic descriptions are extracted and consolidated as a taxon-character matrix. we compare matrices generated from original and normalized inputs to a hand-curated gold standard matrix. the spider work is an appropriate case study for three reasons. first, the gold standard matrix has been manually curated by experts from the same set of descriptions prior to this study and is used in actual biological research . second, the spider work provides a relatively straightforward numerical measurement extraction task that allows us to focus the discussion on a set of common issues with automated character extraction, leaving the challenges of matrix making with categorical characters for a future paper. third, the spider case study permits a comparison experiment design that illustrates significant improvements normalized descriptions could bring to the resulting matrix. it also provides an opportunity to discuss steps that authors of taxonomic descriptions can take to prevent some extraction issues.

the paper is organized as follows: etc tools used in this case study are first described, followed by the experimental design, material preparation, matrix generation procedure, and evaluation metrics in the methods section. we report the comparison results in the results section and analyze the differences in the discussion section, where we also discuss sources of errors and potential solutions. the paper concludes with future development plans.

etc tools for matrix generation
the etc toolkit site  hosts a set of five tools: text capture, ontology building, matrix generation, key generation, and taxonomy comparison. these tools are supported by utilities including task manager, file manager, and user account settings. the site menu, along with login/out, get started, and help functions, is always available at the top of the screen regardless of the user’s current location. hovering the mouse over the menu will provide access to all functions and tools provided by the site.fig.  <dig> etc site homepage with expanded menu




etc toolkit users can utilize the text capture and matrix generation tools to create taxon-character matrices from taxonomic descriptions. a high level logic flow of the matrix generation pipeline is displayed in fig.  <dig> fig.  <dig> etc logic flow for generating matrix




input creation
since etc text capture is only concerned with morphological descriptions, it does not directly accept full articles as input. the descriptions to be processed should be manually selected by the user from source publications, and the input files for text capture may then be created in the file manager before starting the tool or within the first step  of running the tool, using the single-file creation  or the batch creation  tab. either tab provides users with a form to enter bibliographic information and paste in plain text taxonomic descriptions, but in batch creation, users can format multiple descriptions according to the instructions and paste them into the taxonomic treatment area section to generate multiple input files .fig.  <dig> batch file creation function




the input creation function wraps bibliographic information and descriptions with xml  tags  <cit>  required by the text capture tool. input files are saved in the file manager, where the content of a file may be viewed/edited, as shown in fig.  <dig> fig.  <dig> an example input file for the text capture tool




text capture tool
the text capture tool employs seven steps to process taxonomic descriptions: create input , define task, and preprocess are the preparation steps; learn, review, and parse are processing steps; and output is the last step . the learn and parse steps are computationally intensive , while the review step is where the user interacts with the system to review and categorize character-related terms for the system. these categorizations are reusable for future tasks. in a description, the text capture tool annotates structures , characters, character values, and relationships among structures. figure  <dig> shows an example of an output file with detailed annotations in xml, conforming to the etc output schema  <cit> . these annotations are used by the matrix generation tool to produce a matrix. by comparing the xml input  and the output , one can see the text capture tool breaks down the text descriptions into a series of characters marked up in xml .

users start a text capture task by generating input files  and then define the task by assigning it a name and selecting appropriate settings . the task name is used to name output folders and track the progress of the task. tasks may be performed asynchronously and users are notified via email or in the task manager when the task is completed . the task manager can also be used to delete a task or share a task with other registered users. when a task is shared with other users, these users can access the shared task as well as its input and output files. for example, users with a shared text capture task can categorize the same set of terms in the review step and share their expertise with the task owner.fig.  <dig> the define task step in the text capture tool


fig.  <dig> etc task manager. shown five tasks with their names , task start time , how the tasks are shared , type of tasks , and task progress/current step . the green spinning wheel indicates the task is currently running at a specific step




a task is defined with its name, input folder, and the taxon group most closely related to the task . the taxon group information allows the system to select an appropriate categorical glossary to use to process the task. currently, there are glossaries for algae, cnidaria, fossil, gastropods, hymenoptera, plant, porifera, and spiders , reflecting the taxon groups that have been processed with etc. using existing glossaries reduces user effort during the review step. if etc does not have a needed glossary, the use empty glossary option will make text capture learn the terminology from scratch. with the user’s permission, categorizations are exported to oto   <cit> , reviewed by multiple domain experts, integrated into etc categorical glossaries, and made publicly available at the etc glossary git repository  <cit> . the user’s ownership of the terms set and its categorizations is acknowledged in oto and in the final glossary. the linkage of the etc text capture tool to oto allows the collective and incremental building of consensus-based domain controlled vocabularies from source descriptions.

the preprocess step checks for editing errors in the input description text for the user to correct . in the learn step, the tool analyzes input descriptions and categorizes terms as structures, characters/states, and other terms. with the built-in categorical glossary, it further categorizes character/state terms  to specific categories, such as shape and size. users are then presented with a screen in the review step to examine system categorizations and categorize remaining terms . numerical values are handled automatically by the software and are not presented for review.fig.  <dig> the review step in the text capture tool




in the review interface , terms to be categorized appear in the pane on the left, while categorized terms are in the category boxes on the right. to categorize a term, the user can drag and drop the term on the heading of its proper category, or use the dropdown menu invoked by right-clicking on the term. the user can indicate two terms are synonyms by dropping one on top of the other, making the latter a primary term . this signals the software to replace occurrences of the synonyms with the primary term in the output, making the matrix result cleaner and less sparse. terms that are neither structures nor characters/states should be left uncategorized in the left pane. the categories are used in text capture tool as a flat list of categories without hierarchical relationships. several user-friendly features are provided: users can add/remove/merge categories, multiple terms can be selected and categorized to one category as a batch, missing terms can be added, misspelled terms can be corrected, terms can be marked as “not useful” and grayed out, and comments can be left on a term. the term information pane located at the lower portion of the screen provides useful information about a term. clicking on a term displays its current categories in the location tab, its source sentences in the context tab, and its matching entries from user selected ontologies in the ontologies tab. the user can make their ontology selections from ncbo bioportal  <cit>  using the ontologies menu. the file menu allows users to download their categorization results or upload a set of categorized terms to the system .fig.  <dig> importing term categorizations in the text capture review step




the review stage is the only step where substantial user input is needed. term categorizations affect the formulation of characters in the final matrix. for example, if long is categorized as a shape, the matrix will contain characters such as “leg shape: long”, as opposed to long as a size, which results in “leg size: long”. in the spider case study presented in this paper, our focus was on numerical measurements; numerical values do not need to be categorized by users, thus, the importance of the review step is minimized in this particular case.

after the review step, the system parses the descriptions and produces valid xml files  with structure and character information finely marked up according to the etc output schema  <cit> . this schema was developed because existing xml schemas, such as taxpub  <cit>  or nexml  <cit>  cannot accommodate the fine-grained markup produced by text capture. furthermore, the xml schemas used in etc are intended for internal use only, not for data exchange among different systems.fig.  <dig> example output file of the text capture tool




matrix generation tool
the output xml files from text capture are used as input for the matrix generation tool, which consolidates the annotated character information into a taxon-character matrix for users to review and edit . the matrix output is a csv  file .

matrix generation consists of five steps: select input, define task, generate, review, and output, with generate being the key processing step.

the select input and define tasks steps  serve similar functions as the first two steps in text capture. the inherit values enables automatic propagation of characters from a higher taxon to lower taxon members. the infer absent/present states option enables the software to infer the presence or absence of organs and other anatomical parts, aside from what is stated explicitly within the descriptions. for example, if a leg cusple is present, then the leg must be present, as the spider ontology  <cit>  indicates leg cusple is part of some leg article and leg article is part of some leg.fig.  <dig> the define task step in the matrix generation tool




the generate step extracts character information from xml files and assembles them into a taxon-character matrix. the matrix will contain more characters/states than those explicitly stated in the descriptions when the inherit and/or infer option is selected.

after the matrix is produced, users proceed to the review step, which has two views: the preview and selection view and spreadsheet view. the preview and selection view provides an overview of the taxa and characters produced and allows users to select a set to upload and review . the spreadsheet view presents the selected taxa and characters in a matrix format with taxa displayed as rows and characters as columns .fig.  <dig> the preview and selection view at the matrix review step


fig.  <dig> the spreadsheet view at the matrix review step. two highlighted characters are candidates for a merge




web browsers cannot handle large spreadsheets efficiently, therefore it is recommended to review in sections matrices larger than  <dig> taxa and  <dig> characters. the selection feature is also useful when the user is interested in only a portion of extracted characters, for example, numerical characters in the spider case study. in the preview and selection view , users are presented with an interface where the left half of the screen is dedicated to information about taxa and the right half to character information. the leftmost panel allows users to select taxa of interest. by right-clicking on each taxon, users may add, modify, remove, or change the order of taxa, or query google images to retrieve images of the selected taxon. the taxon details panel provides information about the selected taxon, including publication information and the original description. characters are selected from the characters panel . in the characters panel, organs and characters are organized in a tree format, with characters listed under their respective organs. similar to the functions for taxa, users may add, modify, and remove characters or change the order by right-clicking on a character. details about characters are presented in the upper right panel and character values are displayed in the lower right. the annotation menu supports user comment and color setting configuration for better data management. users can associate different colors with different meanings and use colors to track characters that are reviewed, questionable, or require additional research, etc.

multiple taxa and characters can be selected by pressing the “shift” key or “ctrl” key  and load to the spreadsheet view . this view provides rich functions that are invoked by hovering the cursor over the right-end of a cell and clicking on the small triangle icon that appears. functions affecting both taxa and characters are invoked in the first cell of the spreadsheet, taxon-related functions are invoked in any taxon cell , and character related functions  are invoked in any character cell .fig.  <dig> character-related functions for the first column of the spreadsheet




in addition to the add, delete, edit, sort, color, and comment functions, the user can lock taxa or characters to prevent edits, bring up an original source description, control what values are acceptable for certain characters, or merge two selected characters. because synonyms or quasi-synonyms are often used, some characters could be merged to consolidate the taxa-character matrix. for example, in fig. 12
the length of whole-organism and length of body characters both represent the total length of a spider. the merge function put the values of the two characters in the column the user chooses. after an edit operation is performed, the matrix is refreshed automatically and affected cells are indicated with small red triangles on a corner. users can save their progress and return to it at a later time via task manager. the matrix can also be downloaded from the matrix menu at any time. when proceeding to the output step, the matrix is saved as a csv file  in the file manager.fig.  <dig> example output  file of the matrix generation tool




it is important to note that the basic principle for designing text capture and matrix generation tools is to stay true to the original descriptions. taxonomic descriptions are highly technical and present levels of sophistication and subtleties that only taxon experts can fully interpret. the interpretation may also depend on the intended use of the character data. the etc tools are intended to extract characters as they are expressed in taxon descriptions but leave the customization and refinement of the results to the experts, which may be accomplished by using the functions provided at the view step. in addition, since parsing characters and generating matrices are automated using various algorithms, the results are not error free. the rest of the paper evaluates the performance of the etc matrix generation pipeline using the spider body part measurement as a case study.

methods
experimental design
the experiment was designed as a comparison study. the same etc tools and same settings were applied to the set of original input descriptions and the normalized set, then machine-generated matrices were compared to a gold standard matrix. both versions of the input descriptions were generated from the same source publications on spiders . the hypothesis was that the normalized input would result in a taxon-character matrix that is more similar to the gold standard than when using the original input. the original input and the normalized input used in the experiment are included in the additional file  <dig> as original input and additional file  <dig> as normalized input.

the gold standard matrix was built by the three spider systematists who co-authored the paper. the building of the gold standard matrix was blind to all the other co-authors. two other co-authors normalized the text, and one of them generated the matrices using etc tools.

materials
the gold standard matrix was derived from a matrix initially composed in ramírez  <cit>  and successively enriched/used in aisen and ramírez  <cit>  and labarque et al.  <cit> . this expert-curated matrix contained  <dig> descriptions of exemplars  of  <dig> species  and  <dig> characters. to create the gold standard matrix for this study,  <dig> species with no descriptions or with non-english descriptions and three redundant characters were removed from the expert matrix. in addition, character names in the expert matrix were standardized to the character of structure style , making them comparable to machine-generated character names. when this matrix was used to evaluate the machine-generated matrices, a handful of incorrect states/values were found and subsequently corrected. the final gold standard matrix consisted of  <dig> exemplars of  <dig> species,  <dig> characters and  <dig> character states. the gold standard matrix is included in the additional file  <dig> as gold standard matrix.

all  <dig> terms representing anatomical parts in the spider ontology  <cit>  and  <dig> terms representing character/character states from the plant glossary  <cit>  were used to create a new categorical glossary for spiders. although the character/character state terms from the plant glossary do not affect the machine-generated numerical measurement matrices, they were included to reduce the number of terms for review/categorization in text capture. the spider glossary files, one for term categorization and the other for synonyms, can be found at: https://github.com/biosemantics/glossaries/tree/master/spider.

two versions of the input descriptions, original and normalized, were generated from the source publications provided by the spider systematist co-authors. content of male and female exemplar descriptions of the spider species were manually copied from pdf  files and formatted as required by the etc input creation utility. errors in pasted text were manually corrected , and different characters appearing as hyphens  were converted to standard ascii  hyphens. the resulting clean text descriptions were considered as the original input. a normalized version was formed by adding omitted measurement units  and the omitted word “leg” to the original input. for example, an original statement “tibia/metatarsus: i,  <dig> / <dig> ” was normalized to “tibia/metatarsus:leg i,  <dig> / <dig>  mm”. two of the co-authors created the normalized input programmatically and independently cross-validated the results. while normalization is a typical step in text processing, the specific normalization step taken in this experiment was meant to put the missing information  back to the text to make the descriptions more self-contained. in the results we examine the different performance results from using the self-contained  vs. the original descriptions. the automatic modification of text method used in  <cit>   achieved the same goal of making the text self-contained.

generation of the matrices using software tools
the input creation, text capture, and matrix generation tools on the etc-development site were used as a pipeline to generate a matrix for each of the two input texts. for the text capture tool, the “spider” glossary was used . terms pertaining to structures were mostly categorized correctly by the software while some structure terms, such as “coxae” and “membrane”, were manually categorized . because this study was primarily concerned with the numerical measurements of morphological structures, categorical character terms  were placed in an arbitrary category  and essentially ignored. no synonyms were made in the review step. term categorizations made in this experiment is included in the additional file  <dig> as term categorization. in the matrix generation tool, the inherit values and infer absent/present states options were not selected  because they were not relevant for this case study. after morphological characters were extracted by the matrix generation tool, body part characters with numerical measurements were manually selected in the preview and selection view to form the final output matrix .

comparing etc matrices to the gold standard matrix
to evaluate the effectiveness of the matrix generation workflow, we measured the accuracy of the extracted characters, the effort needed to edit the matrices, and the similarity of the edited matrices to the gold standard matrix.

accuracy measures the correctness of extracted data items. an extracted data item is correct if it is consistent with the original description. a data item may be considered correct while not matching the gold standard as the latter represents the expert’s consolidation and refinement of original characters present in the descriptions. for example, if the system extracts length of ii =  <dig>  mm from the description i, ii, iii, iv length:  <dig> ,  <dig> ,  <dig> ,  <dig>  mm, it will be considered correct, even though the gold standard may have length of leg ii =  <dig>  mm. however, if the system extracts size of ii =  <dig>  mm, length of ii =  <dig> , or length of ii =  <dig>  mm, it would be considered wrong. accuracy=correctdataitems/extracteddataitems 


edit effort is the minimal number of column-based merge, rename, and deletion operations needed to make a machine-generated matrix as similar as possible to the gold standard matrix. specifically, character columns mostly containing incorrect values  are deleted; and character columns mostly containing correct values are either merged into a valid column/character  or renamed with a valid column/character name. although merge operations place character values under a different character name, they are not counted again as rename operations. we also note that some characters extracted by the machine need splitting to match the gold standard, for example, length of tibia/metatarsus =  <dig> / <dig>  mm needs to be split into length of tibia =  <dig>  mm and length of metatarsus =  <dig>  mm. since a split character feature has not been implemented in the matrix review step, in this study, split operations were counted separately from edit effort. edit efforts were counted manually. edits made on machine-generated matrices are documented in matrix edits in the additional file  <dig> 

the similarity of an edited matrix to the gold standard is evaluated via precision, recall, and f <dig> metrics that are routinely used in the evaluation of information retrieval and information extraction systems. precision is the proportion of machine-generated data items that match the gold standard. recall is the proportion of gold standard data items that are extracted by the machine. in other words, precision measures the soundness of machine-generated items, while recall measures the exhaustiveness of the machine results as compared to the gold standard. both metrics result in a value between  <dig> and  <dig>  if the machine-generated matrix is identical to the gold standard, both precision and recall will have a value of  <dig>  the f <dig> score is the harmonic mean of precision and recall, meaning it puts equal weights to precision and recall. to summarize:precision = |matched data items| / |data items output by the software, excluding null values|

recall = |matched data items| / |data items in the gold standard matrix, including null values|

f <dig> score =  <dig> * precision * recall / 




note that accuracy is based on the correctness of the extracted characters as compared to the input text, while precision is based on the “matchness” of the extracted characters to the gold standard.

RESULTS
table  <dig> describes the matrices generated from the original and normalized inputs, before and after the edits. for all matrices, the number of rows is  <dig>  consistent with the input exemplars. the matrix from the original input initially had  <dig> characters and  <dig> non-empty data items, making the matrix  <dig> % populated, while the matrix from the normalized input initially had  <dig> characters and  <dig> non-empty data items, or  <dig> % populated. after the edits, both matrices were better populated at approximately 85%.table  <dig> summary of the matrices generated from the original and the normalized inputs




table  <dig> below summarizes the accuracy, edit effort, and precision/recall-based similarity scores for the matrices generated from the original input and the normalized input. the pre-edit accuracy of the matrix from the original input is  <dig> %, and after  <dig> column-based edits, its precision, recall, and f <dig> scores were  <dig> ,  <dig> , and  <dig> % respectively. the pre-edit accuracy of the matrix from the normalized input was  <dig> %, and after  <dig> edits, its precision, recall, and f <dig> scores were  <dig> ,  <dig> , and  <dig> %, respectively. the pre-edit accuracy of normalized input matrix was  <dig> times better than that of the original input matrix, and normalized input matrix required 39% less edit effort.table  <dig> accuracy, edit effort, and precision/recall/f1-based similarity scores of the matrices generated from the original and normalized inputs




table  <dig> summarizes the edits made to the two matrices. details are included in tables  <dig> and  <dig>  for the matrix resulting from the original input, eight of the  <dig> characters were first split because they contained data items with combined character values. after that,  <dig> edits  deleted +  <dig> characters renamed +  <dig> characters merged) were made on the matrix. these edits affected  <dig> values in the matrix. three characters out of the original  <dig> were retained without edits.table  <dig> summary of edit efforts made to the original and normalized input matrices


the numbers in “” indicate the number of values affected by an edit operation. characters indicated with an “*” were retained without edits


the numbers in “” indicate the number of values affected by an edit operation. the  <dig> characters in the gold standard were all included in the machine-generated matrix. the characters superscripted with “$n” are considered equivalent to a corresponding character in the gold standard, either by their semantic equivalence , or by the experts’ decisions 




for the matrix generated from the normalized input, three of the  <dig> initial characters were split at first, and then  <dig> edits were made , with a total of  <dig> values affected by the edits.

precision, recall, and f <dig> scores of the edited matrices as compared to the gold standard are shown in tables  <dig>   <dig>   <dig> and  <dig>  tables  <dig> and  <dig> display the exemplar-based and character-based precision and recall scores of the matrix generated from the original input, while tables  <dig> and  <dig> show the scores of the matrix generated from the normalized input. the scores are very similar between the two matrices. in table  <dig>  the precision/recall scores of all data items in post-edit matrices from the original and normalized inputs are  <dig> %/ <dig> % and  <dig> %/ <dig> %, respectively. it indicates that  <dig> % and  <dig> % of the data items in these two matrices are incorrect, respectively, and  <dig> % and  <dig> % of the data items in the gold matrix were missing from these matrices, respectively.table  <dig> exemplar-based precision, recall, and f <dig> scores of the matrix generated from the original input







discussion
domain conventions and automated character extraction
the accuracy scores of the original input and normalized input matrices were dramatically different,  <dig> % vs.  <dig> %, respectively . the lower accuracy of the data items extracted from the original input can almost be exclusively attributed to its omitting units in measurements . measurement units and other indicators, such as “long”, “length”, and “wide”, are among the clues the software uses to identify measurement characters. when measurement indicators are absent, the software labels the character with a more general label  in place of a more specific label of “length” or “width”. when both units and measurement indicator clues are absent, as was the case for the majority of the numerical values in the original input, the software could only name the character with the most general label . these quantity characters account for the difference in accuracy scores, which is also reflected in the rename and merge edits for the matrix .

adding the word “leg” in front of roman numerals “i”, “ii”, “iii”, or “iv” in the original input did not affect the accuracy score because other cues in the text can be used in its place . one can take this as a sign of the system’s robustness, but it should be noted that omitting “leg” made character names for the leg measurements less understandable for the user , and introduced term categorizations that are domain specific . we would recommend that future description authors not omit the word “leg”, or other structure terms  under similar circumstances.

the performance differences between normalized and original descriptions in terms of accuracy and edit efforts shows less self-contained morphological descriptions present a challenge for automated character extraction. it may be argued that software can be made for users to provide missing information during data processing. this approach is not viable in our task for at least three reasons:  it is infeasible to collect all special conventions used in describing biodiversity and new conventions may continue to be introduced ;  accommodating a large number of special conventions useful only for specific domains harms the usability of the software for all users -- it requires all users to be aware of conventions used in other domains to discern the ones that are applicable to the task at hand;  it also makes the software difficult to develop or maintain in the long run, especially in the presence of conflicting conventions. to assist with automated character extraction and reduce human effort, we encourage systematics authors to write more self-contained morphological descriptions  <cit> .

although not included in this experiment, we would like to note that descriptions codified according to certain conventions are difficult to parse automatically for the same reason -- the needed information on how to interpret them is not in the description text. for example, “spines: leg i, femur d 1-1- <dig>  p d1ap; tibia v 2-2- <dig> , p 1-1- <dig> or 1-0- <dig>  r 1-0-1; metatarsus v 2-0- <dig>  p d1-d1-0- <dig>  r 0-1- <dig>  d 0-p1- <dig> ”

matrix generation pipeline performance
although both machine generated matrices had become very similar to the gold standard matrix after editing , the matrix from the original input needed nine deletions,  <dig> renames, and  <dig> merges while the matrix from the normalized input needed much fewer edits . the latter edits affected fewer values : it was often the case a few values were merged to a correct character already present, suggesting the matrix generated from the normalized input was already quite similar to the gold standard. the merges were sometimes needed for characters that were correctly extracted. for example, length of abdomen and length of opisthosoma were distinct characters correctly extracted from the original description, but for the specific use of the matrix in , the spider experts considered them as equivalent characters . this phenomenon confirms our design rationale for the merge operation in the matrix review interface. in addition, the character distance of epigastrium-epigastrium  was also correct according to the original descriptions, but the experts identified it as a typo in the original publication .

etc provides functions to control equivalent character issues, for example, synonymizing terms or importing synonyms in the review step of text capture , and the etc ontology building tool that is being implemented. true synonyms can be included in the ontology, while terms that need to be treated as synonyms for a certain task may be synonymized in the review step. making use of these tools could reduce the effort of merging characters during the matrix review step.

the precision and recall scores  of the exemplar-based and character-based evaluation of edited matrices indicate that character values were extracted from the descriptions correctly  and not many were missed , even after deletions of some characters. character/column-based editing seems to be effective in bringing machine-generated matrices close to the gold standard matrix. the low standard deviations of precision and recall scores in tables  <dig> and  <dig> suggest that the software performs consistently on each exemplar and across all characters, as shown by the similar precision and recall scores for each of the characters in tables  <dig> and  <dig> 

error analyses
incorrect decisions in character markup made by text capture  propagate into the matrices generated. in this section, we discuss the errors and their causes, which include one caused by a typo in the original source pdf file where “width” was misspelled as “with”.

issue i: there were several mistakes that led to a number of merge operations . if analyzed carefully, it can be seen the description sentences were ambiguously written. three such examples are given below:
carapace globose, thoracic groove on depressed area, length  <dig>  mm, width  <dig>  mm.


carapace very wide in front, ocular area slightly protruding, length  <dig>  mm, width  <dig>  mm.


abdomen extremely elongate, legs very long, including leg iii. total length  <dig>  mm.




in each example, the length/width measurements could be associated with any structure shown in bold . this type of ambiguity is difficult to resolve, even by a non-expert human reader. these sentences can be simply revised as below to remove the ambiguity. carapace globose, length  <dig>  mm, width  <dig>  mm, thoracic groove on depressed area.

 carapace very wide in front, length  <dig>  mm, width  <dig>  mm, ocular area slightly protruding.

 total length  <dig>  mm. abdomen extremely elongate, legs very long, including leg iii.





semantic ambiguity in taxonomic descriptions is a widespread issue, as we have seen it in all taxon groups we have processed. sometimes a domain expert is not able to interpret a descriptive statement with certainty, however, it is not always easy for description authors to notice the ambiguity.

issue ii: another error was caused by the software’s inability to translate the following sentence to “distance of spiracle-epigastrium” . <dig>  epigastric furrow  <dig>  mm from tracheal spiracle.




this translation requires several approximations: epigastric furrow approximates epigastrium, and tracheal spiracle approximates spiracle. as indicated before, such approximations are purposefully excluded from the design goals of the system; however, the software did recognize that some distance is expressed in the sentence.

issue iii: text capture needs to be improved in its ability to accurately generate individual characters from compound expressions similar to those included in sentences  <dig> and  <dig> below. the problem was alleviated to some extent by the normalizations, reducing the number of splits by over 50% . <dig>  length of tibia/metatarsus: leg i,  <dig> / <dig>  mm; leg ii,  <dig> / <dig>  mm; leg iii,  <dig>  mm; leg iv,  <dig> / <dig>  mm.

 <dig>  tibial lengths and indices: leg i missing; leg ii <dig>  mm, 7; leg iii <dig>  mm, 13; leg iv <dig>  mm,  <dig> 




sentences  <dig> and  <dig> are challenging because the characters  and their values  are separated by other elements and they require information external to the text itself for accurate interpretation, for example, knowing the tibia and metatarsus are parts of each leg, knowing the correspondence of multiple characters  to their listed values, and knowing how to deal with exceptions, such as missing values . while specific rules can be programmed to parse the sentences seen in this experiment, the applicability of the rules to other descriptions is highly questionable, as they could have their own special conventions.

error identification
one practical question is how to quickly identify errors, whether in character names or in values, at the matrix review step. the names of the characters themselves are good clues, for example quantity of leg would seem suspicious to a spider expert. in addition, the review interface supports different ways of sorting characters. assuming erroneous characters would have values in fewer taxa, sort by character coverage  can help identify bad characters. the original descriptions can also be brought up from the matrix review interface, allowing the user to check the original descriptions. an upcoming feature will highlight characters in the original text to facilitate scanning of text by the user.

other types of characters
issues discussed here are also applicable to extracting and matricizing categorical characters. we know that a character consists of a structure name , a character name  and a character value . issue i discussed in error analysis will affect whether a correct structure name is identified, regardless of types of characters. issue ii and iii are similarly applicable to categorical characters.

a major challenge specific to categorical characters is with the determination of the character names. descriptions often state character values without explicitly mention character names. for example, in ocular area slightly protruding , protruding is the character value, but what is its character? does protruding describe the size, orientation, prominence, or relief of the ocular area? character names are important because they determine how the characters will be named in the matrix . since a standard character dictionary does not exist, the system has to ask the user to indicate what character name protruding refers to in the term review step . in fact, term review could be the most time consuming step when dealing with categorical characters because the user will need to categorize the terms that are not in the system’s glossary. synonymizing structure/organ names at this step is also critical for producing high quality matrices to avoid the same characters being scattered in multiple columns.

cardinal characters, such as counts or quantities, are often easier to extract. our experience suggests that their extraction accuracy from taxonomic descriptions can be expected at the same level as the numerical measurements reported here. however, when the cardinal characters are not expressed in numbers, but in phrases, such as few, many, and numerous, the semantics of the character values will need human interpretation. while the systematics community has discouraged this practice, it still exists in descriptions.

CONCLUSIONS
in this paper, we introduced the etc matrix generation pipeline, input creation -text capture - matrix generation, for semi-automatic production of raw taxon-character matrices from morphological descriptions of various taxon groups. this is to our knowledge the first pipeline that produces taxon-character matrices from morphological descriptions. we reported a case study where the tools were used to generate two measurement matrices from the original and normalized descriptions of  <dig> spider exemplars. the quality of the machine-generated matrices were compared to the hand-curated gold standard matrices, in terms of data extraction accuracy, efforts required to edit a matrix, and the similarity of an edited matrix to the gold standard.

as demonstrated in the paper, etc matrix generation pipeline is a low-barrier workflow, in that it does not require training examples or user-crafted extraction rules. the inputs required are the minimal necessary requirements to perform the task -- clean text descriptions and domain knowledge in the form of term categorization. as shown in  <cit>  and confirmed in this case study, the character extraction works well on fact-rich, self-contained morphological descriptions with relatively simple syntactic structures. besides generating taxon-character matrices, evidence from this case study suggests other benefits of using the tools:  helping to identify errors in the source descriptions ,  helping to identify errors in the human-curated matrix , and  checking for parallelism in the descriptions. these errors can be corrected and the can be data re-harvested using tools/infrastructure such as the one described in  <cit> .

the spider body part measurement experiment provided quantitative support for several findings that we argue are not limited to this case study but are generalizable across character information extraction in biodiversity domains:with full respect for any domain conventions, we showed the conventions that make taxonomic descriptions less self-contained have negative impacts on machine-processed results. the accuracy of the data items  extracted was improved from  <dig> % using the original input to  <dig> % using the normalized input .

semantic ambiguity exists in morphological descriptions . it is often not easy for description authors to see the ambiguity. we plan to adapt the charaparser algorithm to highlight the potential semantic ambiguities in the descriptions for the authors.

we also showed that accurately extracted data items may not match exactly with the independently-created gold standard, the ideal result desired by biologists. the matrix from the normalized input contained  <dig> % accurate data items, but it still required  <dig> edits to be 99% similar to the gold standard . the analyses of the experimental results revealed two reasons for this:  the differences between character expressions used in the original descriptions and the form of characters the user desires in the matrix, and  less-parallel descriptions or user/use preferences sometimes lead to the synonymization of an original character to something close. in addition, as elaborated in  <cit> , selecting and constructing characters for certain biological research is a nontrivial task even for domain experts.




in addition, the case study showed that character/column-based edits were sufficient to bring the matrices 99% similar to the gold matrix. although this result confirms our experience, additional empirical studies are needed to verify this result.

future work will further improve the character extraction performance and improve the robustness of the system for various inputs. we also hope to enhance the input functionality by taking html, doc, or pdf files as input. pdf is a challenging format for text processing, but promising software is being developed and tested  <cit> . this experiment suggested that editing facilities are needed for users to identify, select, merge, split, rename, or delete machine-generated characters. the etc matrix review interface already provided a suite of features in this regard, but additional improvement is needed. some of the features can be easily added, for example, support for quick splitting of a compound character, or color-coding the original text to visualize the machine-identified characters. other features will need additional research, for example, suggest potentially problematic characters for the user to review.

additional files

additional file 1: original input. the original input used in the experiment. 


additional file 2: normalized input. the normalized input used in the experiment. 


additional file 3: gold standard matrix. the expert hand-curated matrix used as the ground truth to evaluate the etc generated matrices. 


additional file 4: term categorization. this text file shows how the terms were categorized in the review step of etc text capture in the experiment. 


additional file 5: matrix edits. list all the edits made in the etc generated matrices. 




abbreviations
asciiamerican standard code for information interchange

csvcomma separated values

etcexplorer of taxon concepts

otoontology term organizer

pdfportable document format

xmlextensible markup language

