BACKGROUND
over recent years, advances in technology have allowed an acceleration of new genomes sequencing  <cit> , evidencing the increasing demand for data analysis automation and for improving procedures previously used  <cit> . this has encouraged studying and implementing several computational techniques and creating new tools to enable processing of large amounts of genomic data.

one of the first steps for functional genomic annotation is promoter identification. promoters are regions responsible for signaling and controlling the exact position where the transcription mechanism initiates, called tss . the capability for detecting them in their different forms will make it possible to understand how, where and when transcription occurs, in addition to providing clarification on the interaction network and regulation of the transcription mechanism  <cit> .

the identification of promoter sequences in genomes can be seen as a classification problem, where, given the features of a genomic sequence, it would be classified as promoter or non-promoter. therefore, several computational approaches to predict promoters have been proposed using different classification techniques and different types of information extracted from sequences. nevertheless, further progress is needed to improve them  <cit> .

much of the complexity of promoter prediction problem is due to their diverse nature, which makes it difficult to identify them  <cit> . the selection of inappropriate features to predict promoters can result in a high number of false-positives. therefore, a crucial step for prediction success is to discover features of promoter sequences that are relevant to differentiate them from non-promoter sequences.

in the search for relevant features to distinguish between promoter and non-promoter sequences, several properties of sequences have been tested for their predictive capability. according to  <cit> , a prediction strategy can use three types of features: structural, based on signs and based on context. several studies have shown that in order to build accurate models to predict or describe genomic processes, the structural properties of the dna molecules must be considered  <cit> . thus, the structural properties have been widely used in recent years  <cit>  and have also been adopted for this work.

despite the large amount of work involving promoter prediction  <cit> , to the best of our knowledge, none of them have verified in a systematic way the relation between the length of sequences used for training classification models and their predictive performance.

the importance of this evaluation is due to the fact that, considering the structural properties, the longer the sequences used to compose datasets used for training classifiers, the greater the amount of attributes. the problem is that high-dimensional datasets, that is, with great number of attributes, make the classification a more complex process, and the result may be an increase in classifiers training time and a reduction of their predictive performance.

in our preliminary work  <cit> , the effect of sequence length for distinguishing between promoters and nonpromoters was briefly evaluated using two classification techniques. in this work, in order to extend this analysis, an additional classifier, the random forest, was evaluated using the same datasets adopted in  <cit> . statistical tests were also applied aiming at assessing the differences among the classification performances obtained from each evaluated dataset. classifiers' performances for each class were included as well. finally, results of an experiment carried out to evaluate the impact of increasing the number of dataset instances on classifiers predictive accuracy were also added.

due to the amount of data available and the attention it has received from the scientific community in recent decades  <cit> , the genome chosen to be studied in this work was homo sapiens. the experiments were conducted using a well-known and reliable promoter database which is publicly available on the web.

methods
consolidation of datasets
for the studies conducted in this work, promoter and non-promoter sequences derived from human genome were used for datasets construction.

promoters were obtained from a set of sequences available in the dbtss database  <cit>  , which has already been used in several other works  <cit> , and is a set of approximately  <dig>  experimentally validated promoter sequences with active tss, where each sequence has  <dig> bp .

non-promoters correspond to several genomic sequences that were extracted randomly from intergenic regions and from introns and exons  <cit> . the criteria for obtaining these sequences require that the region is at a minimum distance of  <dig> nucleotides from the positions demarcated on cage database, indicating transcription regions, and at a minimum distance of  <dig> nucleotides from the positions demarcated on refseq database, that has informations denoting the beginning and ending positions of genes. thus, the selection of false non-promoter sequences is avoided. cage and refseq databases were obtained from pppbenchmark tool  <cit>  website http://bioinformatics.psb.ugent.be/webtools/pppbenchmark/.

due to computational cost to process a sequence dataset, only part of the sequences available at dbtss database were used for composing datasets for the first part of this study. thus, a total of  <dig>  different promoter sequences were chosen randomly, avoiding the inclusion of noisy sequences. in addition, other  <dig>  non-promoter sequences completed the datasets. therefore, these datasets are composed of the same  <dig>  sequences.

however, the length of sequences varies from one dataset to another. for example, the dataset called 250- <dig> consists of sequences represented by  <dig> nucleotides. for promoter sequences, this size is the sum of the number of nucleotides positioned upstream and downstream from tss , that is, in the example there are  <dig> nucleotides upstream and  <dig> nucleotides downstream from tss. therefore, for the same dataset, tss is always located at the same position in all promoter sequences. since nonpromoter sequences do not have tss, their length is simply given by their number of nucleotides. thus, in 250- <dig> dataset, non-promoter sequences are also composed of  <dig> nucleotides.

in addition to these datasets consisting of  <dig>  sequences, which were used to evaluate the impact of sequence length variation on the predictive performance of classifiers, datasets comprised of a higher or greater number of sequences  were built in order to verify the impact of an increased number of training instances on the predictive capacity of classification models. using the same procedures previously presented for generating datasets, a random selection of  <dig>  promoter sequences from the dbtss database allowed the construction of additional datasets containing  <dig> ,  <dig>  and  <dig>  promoter sequences. it is worth noting that the same amount of non-promoter sequences completes each of these datasets, maintaining the ratio of 50% of promoter sequences and 50% of non-promoter sequences.

each dataset sequence is characterized by a set consisting of  <dig> structural properties  <cit> , named: a-philicity, base stack energy, b-dna, bendability, dna-bending stiffness, disrupt energy, dna denaturation, free energy, nucleosome positioning, propeller twist, protein deformation, protein-dna twist and z-dna. these properties, which have already been subject of other studies in literature  <cit> , are physicochemical and conformational properties.

since the structural properties may be determined by local interactions among neighboring nucleotides in a sequence  <cit> , they are represented by tables where each possible nucleotide combination is associated with a value that represents its contribution to a particular structural property. as an example, table  <dig> presents the mapped values of oligonucleotides for the stacking energy structural property.

using these  <dig> structural properties, each nucleotide sequence  is converted into a numerical vector that characterizes it. figure  <dig> illustrates the conversion of a sequence into two structural properties . as it can be observed, the numerical vector of each property  is obtained from scanning the sequence of nucleotides where, depending on the structural property, each vector value is obtained considering sequences of dinucleotides  or trinucleotides .

considering the conversion schema previously mentioned, in order to show the capability of the structural properties to distinguish promoter from non-promoter sequences, figure  <dig> illustrates, for all structural properties considered in this work, the average structural profile of promoter and non-promoter sequences of the 250- <dig> dataset. the structural profiles were plotted according to the average value on each position. in this figure, tss is located at the  <dig> position.

the complete characterization of a sequence is given by a single numerical vector resulting from the junction of the vectors representing each of the  <dig> structural properties considered in this work. the size of the resultant vector of these junctions corresponds to the number of predictor attributes of the datasets used for classifiers training. figure  <dig> illustrates this process of generating dataset instances. in addition to these predictor attributes, each sequence has a value for the class attribute, which indicates whether that sequence is promoter or non-promoter. as an example, the largest dataset used in our experiments, the 250- <dig> one, results in a set of  <dig> predictor attributes. table  <dig> shows the number of predictor attributes for each dataset used in this work.

as it can be observed in table  <dig> the length of sequences used to compose the dataset defines the amount of their attributes. several studies in literature have addressed the problem of promoter prediction using datasets containing sequences of  <dig> nucleotides or more  <cit> . although a limited amount of features is being used in characterization of sequences, high-dimensional datasets are generated for classifiers training.

the problem with high-dimensional datasets, that is, with high number of attributes, is that they make classification a more complex process, often consuming an infeasible time for training classifiers and degrading their predictive performance.

therefore, to predict promoters by training classifiers from datasets with a reduced number of attributes, it is essential to obtain good predictive performance with low computational cost. this way, the objective of the first set of experiments conducted in this work is to evaluate the impact of the sequence length variation on classifiers performance. after that, considering a limited sequence length , additional experiments were carried out aiming at verifying the impact of an increased number of training instances on predictive performance of classifiers.

classifiers and experimental setup
svm   <cit> , random forest  <cit>  and k-nn   <cit>  classifiers, usually adopted in data mining works, were chosen to evaluate the impact of the sequence length variation and training dataset size  on the performance of predictive models. experiments were conducted using the caret package  in r  <cit> , which is a programming language and an environment widely used in statistical and graphics computation for data analysis.

k-nn classifier's idea is very simple. each dataset instance is described by an n-dimensional vector, where n corresponds to the number of predictor attributes. to classify a new instance , the classifier uses distance metrics to determine the k training instances that are more similar to the instance to be classified. then, the most frequent class among the k similar instances is attributed to the new instance. in k-nn, the k value is an input parameter.

considering each dataset instance as a point in n-dimensional space, the basic idea of svm is to find a hyperplane with maximum margin of separation, i.e., one that provides the separation of training instances, with maximum margin, in two portions in n-dimensional space. once the optimal hyperplane is found, the classification of a new instance is made by determining its position in relation to the separation hyperplane. although this method was originally proposed for binary classification problems, several extensions have been proposed in literature to make it suitable for multi-class classification problems.

random forest  is a classification method that operates building decision trees and performing classification by combining their results. through the bagging process, multiple datasets are derived from the original one and, from each derived dataset, a new decision tree is generated. the construction of these trees is made by using a subset of attributes randomly selected from the original dataset. the random nature of the process ensures low processing cost and diversity of generated decision trees.

in order to set the algorithms parameters for the datasets used in this study, experiments were conducted by varying the parameters values c  and gamma, for svm , mtry , where p is the number of predictive attributes of the dataset, for random forest  and k  for k-nn. table  <dig> presents the best parameter values obtained for each dataset and therefore used in our experiments to obtain the results presented here. all experiments were carried out on a core i7- <dig> @  <dig> ghz pc with  <dig> gbytes of ram.

k
ntree
mtry
c
sigma
the classifiers predictive performance was measured using ten-fold cross validation method  <cit>  and fmeasure metric. furthermore, an agreement statistic, named kappa measure, was also adopted aiming at evaluating the classifiers for datasets composed of different number of sequences. since this measure do not take into account the correct classification as a result of a mere coincidental concordance between the classifier output and the actual class of each instance to be classified, it is a reliable metric for assessing the performance of classifiers. for each dataset, the same test partitions were used in the evaluation of classifiers.

RESULTS
impact of the variation of sequences length
the results obtained from the experiments to verify the impact of the sequence length variation on the classifiers performance are shown in the figure  <dig> 

the graph of figure  <dig> shows the predictive performance, in terms of average f-measure, of the svm, rf and k-nn classifiers for each of the  <dig> evaluated datasets. as it can be seen in this graph, the svm and rf classifiers have obtained better predictive performance than the k-nn one for all datasets evaluated.

yet, the most important thing to observe in figure  <dig> graph is that, for all classifiers, the decrease in the length of sequences used in the datasets did not necessarily imply a reduction in their predictive performance. svm and rf performance remained relatively stable for datasets composed of sequences ranging in length from  <dig>  to  <dig>  nucleotides, presenting some degradation in performance only for sequences containing less than  <dig> nucleotides. k-nn achieved its best performance with the 50- <dig> dataset and, even for the dataset composed of shorter sequences , presented superior predictive performance compared with larger datasets .

in order to determine if there is a statistically significant difference among the f-measures of the evaluated datasets for each classifier, we have used friedman test  <cit> . after that, if the differences in the datasets' performances were statistically significant, the nemenyi post-hoc test  <cit>  was applied to find which datasets actually differ. these statistical tests were applied with 95% of confidence level.

p-value
aiming at verifying in which pairs of datasets the differences in performance were statistically significant, the nemenyi post-hoc test was applied and its results are shown in tables  <dig>   <dig> and  <dig> for svm, rf and k-nn, respectively. in these tables, the result contained in each intersection of a row and a column indicates if the performances of datasets related to this row and to this column are significantly different  or not .

for the svm classifier, based on the results shown in table  <dig> it can be noted that the dataset, composed of smaller sequences, that does not present a statistically significant difference in classification performance when compared with any other datasets comprising longer sequences, is the 10- <dig> 

the results presented in table  <dig> show that, for rf classifier, the classification performance of the dataset composed of sequences of  <dig> nucleotides  is not statistically inferior to any dataset comprising sequences longer than  <dig> nucleotides.

similarly to what happened to the svm and rf classifiers, the results displayed in table  <dig> for k-nn show a dataset composed of short sequences  that achieved no worse classification performance  than those obtained by datasets composed of longer sequences.

the results presented so far show that, for the evaluated classifiers, datasets consisting of sequences represented by  <dig> or less nucleotides allow the construction of classification models that are as accurate as those obtained from datasets composed of longer sequences, commonly adopted in literature for promoter prediction purpose.

the importance of this result is due to the fact that the size of the sequences used for training classifiers can make the process very complex, often degrading their predictive performance or consuming unfeasible processing time and computational resources.

the average f-measure results presented so far have been computed considering test instances of both classes, promoter and non-promoter. although all datasets used in the experiments are balanced in the class distribution, classifiers performances for each class are not necessarily similar. then, the graphs in figure  <dig> represent the f-measure value of each class for all three classifiers and for the  <dig> evaluated datasets. these graphs show that all classifiers had a better predictive performance for non-promoter class for all datasets. it is also worth noting that, for all classifiers, the performance difference between the classes is always smaller for datasets composed of shorter sequences. this outcome reinforces the importance of training classifiers from datasets consisting of sequences represented by fewer nucleotides.

impact of increasing the number of instances
as previously mentioned, due to the computational cost for processing a dataset of sequences, only part of the promoter sequences obtained from the dbtss database was considered for composing datasets used in the experiments involving the evaluation of the length variation on predictive performance of classifiers. from these experiments, it was found that datasets consisting of sequences represented by few nucleotides  resulted in predictive models equivalent to those obtained from datasets formed by longer sequences.

since the length reduction of sequences used in datasets can substantially reduce the processing time  and the amount of memory consumed in classification process, using sequences represented by only  <dig> nucleotides , additional experiments were conducted in order to answer the following question: could the predictive performance of classifiers be improved by increasing the number of instances  in datasets?

so that we could answer the previous question, datasets containing  <dig> ,  <dig>  and  <dig>  instances were built and evaluated. each dataset was composed by 50% of promoter sequences and 50% of non-promoter sequences. the averages f-measure reached by the same classifiers adopted in the previous experiments are shown in figure  <dig> graph. in addition, for each classifier, the kappa statistic is presented in order to show its relative improvement over a random predictor.

in order to permit a more detailed examination of results reached by rf for the dataset containing  <dig>  sequences, its confusion matrix is shown in figure  <dig> 

in a similar way, kappa statistic improved for all classifiers after increasing the number of instances in the dataset . the kappa statistic measures the agreement of prediction with the actual class, assuming its maximum value of  <dig> only when there is a complete agreement. there is not a standardized interpretation of the kappa statistic, but according to  <cit> , values of kappa from  <dig> to  <dig>  are considered slight,  <dig>  to  <dig>  fair,  <dig>  to  <dig>  moderate,

 <dig>  to  <dig>  substantial, and  <dig>  to  <dig> as almost perfect. hence, in spite of the results are regarded as fair for all evaluated classifiers considering the dataset containing  <dig>  instances, from  <dig>  instances, while k-nn and svm predictive performances are considered moderate, the rf classifier achieved an almost perfect agreement .

regarding the time spent for processing the datasets, figure  <dig> graph shows that it grows roughly linearly as the number of instances in the dataset increases. another relevant fact is that the rf, classifier that achieves the best predictive performance, is not the one that consumes more processing time.

CONCLUSIONS
promoter prediction is a fundamental step for genome functional annotation and, therefore, several computational approaches have been proposed using different classification techniques. however, to the best of our knowledge, none of them verified in a systematic way the relation between the length of sequences used for training classification models and their predictive performance. this way, experiments were conducted to analyze the impact of the sequence length variation on the classifiers performance.

in order to perform the analysis previously mentioned,  <dig> datasets composed of different sized sequences were generated and evaluated using the svm, rf and k-nn classifiers. the experimental results show that a decrease in the length of sequences used in the composition of the datasets did not necessarily result in a reduction of classifiers predictive performance. in addition, several datasets composed of shorter sequences achieved superior predictive performance compared with datasets composed of longer sequences and consumed a significantly shorter processing time. the results show that sequences represented by fewer nucleotides  are good enough for human promoters prediction.

from the conclusion obtained in this first experiment, using sequences composed of only  <dig> nucleotides, datasets with many more instances could be processed to generate new classification models. this way, it was possible to evaluate if larger sets of instances for training classifiers could provide an improvement in their predictive performances. the results have shown that all classifiers achieved better predictive performance after increasing the number of instances in the dataset. the highlight result of this experiment was the rf performance for datasets containing  <dig>  sequences or more, which reached f-measure equal to 97%.

aiming at confirming the predictive power of classifiers, the kappa measure was also considered in the experimental evaluation. again, for datasets containing from  <dig>  sequences composed of  <dig> nucleotides, according to interpretation of the kappa statistic presented in  <cit> , while k-nn and svm achieved a moderate predictive performance, rf reached an outstanding performance .

as future work, we plan to apply techniques for selecting attributes in datasets generated in this study aiming at reducing the datasets number of attributes and improving classifiers predictive performance.

competing interests
the authors declare that they have no competing interests.

authors' contributions
sgc, rgs and lhcm conceived the study and designed the experiments. sgc performed the experiments. sgc and lhcm analysed the data and wrote the manuscript. all authors read and approved the manuscript.

