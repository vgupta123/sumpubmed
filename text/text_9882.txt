BACKGROUND
new large scale techniques in biology have produced a rapidly increasing range of publically available data. a number of centralized database resources are available that aim to integrate this data, such as entrez  <cit> , interpro  <cit> , msd  <cit> , and ensembl  <cit> . databases that integrate huge datasets are faced with problems regarding scaleability of their storage facilities, how to manage frequent updates and how to exchange the data with the community. rather than building bigger centralized repositories, an alternative strategy is to encourage individual data providers to offer their results in standard formats, then provide users with tools which can find and communicate with these distributed repositories, and build integrated views on demand. the distributed annotation system  is a widely used system for biological sequence annotation that follows this latter approach  <cit> . das is frequently used for

 <dig>  integration of personal data into major bioinformatics portals like ensembl  <cit> .

 <dig>  integration of the annotations from external sources into local applications.

 <dig>  access to the most recent versions of biological databases without the need for local installations.

reference and annotation servers
das is a simple client-server network protocol. das clients make requests by fetching a defined url from a das server, and receive simple xml responses. it is a web service, in the sense that all requests are made using the hypertext transfer protocol . this also allows to use existing web proxy infrastructure for accessing remote servers through firewalls. an important part of the request url is the das command, which specifies the type of information that the client is requesting, and thus the response format which it expects to receive. key commands in the das  <dig>  protocol are sequence, which returns all or part of a dna or protein sequence, and features, which returns a set of annotated regions on a sequence, such as genes or protein domains. see  <cit>  for the full specification of the das  <dig>  protocol.

central to the das system is the idea of reference objects. these are biological data objects with stable identifiers which are targets for annotation. in the original das protocol, the reference objects are always biological sequences: chromosomes, scaffold sequences from genome assemblies or protein sequences. when a das client starts, its first action is to connect to an appropriate reference server and retrieve the reference sequence. once a reference object has been loaded, the das client will contact one or more annotation servers to obtain the data provided for the reference objects. typical annotations might include sets of predicted exons on a genome sequence, or matches to a protein domain model on a protein sequence. it is the client's responsibility to collect all relevant annotations and display them in a user-friendly manner. genomic sequences are generally much longer than protein sequences, in terms of number of nucleotides and amino acids, so it is possible to restrict das requests to sub-ranges of the data. biological sequence data is dynamic: sequences change as new sequence data becomes available. thus it is important that das clients are able to check that the annotation they have received match the available reference sequence. the ideal solution is a version number for each sequence, administered by whatever authority assigns identifiers for sequences that is incremented each time the sequence changes. not all biological databases provide such a version number though, so the members of the biosapiens project  <cit>  have agreed to use the md <dig> digest of the sequences for both the reference objects and the annotations as part of the version attribute in the das responses.

RESULTS
new das commands
the original das specification was rather genome and sequence centric. das mediated data exchange and visualisation today is heavily used in the popular genome browsers like ensembl , wormbase  <cit> , and gbrowse  <cit> . several protein sequence das clients are available like dasty  <cit> , proview  <cit>  or the cbs das viewer  <cit> . the multiple sequence alignment viewer jalview has recently been extended to support accessing features through das  <cit> . cargo is a flexible system for visualization and analysis of biological information which among several different sources of data can use das  <cit> .

to generalize the system and enable the development of new applications, we have extended the specification and added several new commands. the new das commands are:

 <dig>  alignment – request an alignment or mapping between two or more reference objects. the alignment format is quite general, and can specify pairwise and multiple alignments between protein sequences, structures and chromosomes.

 <dig>  structure – request coordinate data for three dimensional reference objects such as protein structures.

 <dig>  sources – request and query meta information about available das sources.

implementation
the guiding principle for the design of the new das commands was to provide a reference object for three dimensional information, similar to the sequence command. the alignment command should be rather generic and support multiple alignments of objects of the same data type. in connection with the coordinate systems introduced below, it can also provide mappings between objects of different data types, like mappings between protein sequence and structure residue positions or alignments of chromosomes. similar to the original das commands, data should be pre-computed. for serving structure alignments, the actual calculation of the superimposition should be done on the server side, so the client can be independent from the actual implementations of structure alignment algorithms and support any of the number of available methods, for example  <cit> .

we have extended the two das server implementations proserver, which is written in perl  <cit>  and its java counterpart, dazzle  <cit>  to support the new commands. for a detailed documentation on the specification of the new das commands please see  <cit> .

publishing and discovery of das sources
das is now a widely-accepted communication protocol. with a growing number of people offering data via das, it has become increasingly difficult to keep track of the different servers and the functionality and data they offer. originally there was no specification for a registration mechanism and if a user wanted to add a new das source to a client, they were expected to discover the server's url outside of the das system, perhaps by reading web pages or papers, then manually enter the url into their das client. moreover, with the extensions presented here das becomes applicable to new data types, which adds another level of complexity. we believe a registration system is essential to support the continued development and usage of das.

in order to address this problem we have developed a das extension for communicating with registry servers, the sources command. registry entries include the base url for communicating with a server, a human-readable description of the data it provides, and also some machine-readable meta information which helps clients to automatically decide which sources might be relevant to a given reference object. see figure  <dig> for an example how a das source is being described with this meta information.

multiple data types
das is used to annotate many different kinds of biological entities. genome sequences, gene loci, protein sequences, and molecular structures are currently the most common targets for das annotation. the das registration system therefore needs to be able to deal with the different data types. a das client on the other side usually will only support a certain set of these types, for example, a particular view of the human genome will not necessarily be able to display data that has been annotated on the chimpanzee genome. to allow data integration, the das clients must be able to find all the das annotation sources which can be used with a particular reference object. one of the goals of the das registration service is to provide a description of these sets of data types. it is called coordinate system, and can also be thought of as a "namespace" for reference objects.

there are several parts to the definition of a coordinate system:

• the authority or name of a data set. this usually is the name of an institution or organization that defines identifiers or accession codes. for example, uniprot is an authority to assign protein sequence accession codes.

• the type of object refers to the physical entity being used. currently supported are chromosome, clone, contig, gene_id, nt_contig, protein sequence, protein structure, and scaffold.

• the organism from which the data was derived. this field can be empty in the case of multi-species databases like uniprot, but is important for genome assemblies.

• some resources, especially genome assemblies, have a versioning scheme which applies to the entire collection of sequences rather than to a single sequence. in this case, the optional version field can represent this, and allows data sources annotating several different versions of a given genome to co-exist in the same registration server.

implementation of a das registry
based on the concepts of the sources meta description of das sources, we have established a central das registry which implements this protocol and fulfils the following roles:

 <dig>  it allows discovery of available das sources via a web page, or as machine-readable xml which can be used directly by das client programs.

 <dig>  it automatically validates registered das sources to ensure that they return well formed das xml.

 <dig>  it periodically tests das sources and notifies their administrators if they are unavailable.

 <dig>  it can group the registered das sources according to the coordinate systems of their data.

 <dig>  it can also communicate bi-directionally with das clients and activate or highlight das sources in clients.

the das registration server is available at  <cit> . currently it contains a listing of more than  <dig> das servers provided by about  <dig> groups in  <dig> countries. to obtain a listing of meta information about all registered das servers, the new sources das command is provided at  <cit> . the same command can be used to batch-upload das servers, for example ensembl provides a listing of das sources via  <cit> . the registry automatically obtains this listing and updates the meta information for these servers.

the das registry is backed by a mysql relational database, and can be accessed in several different ways. as well as the das-style sources interface, a html front-end is provided which allows manual interaction with the registry  <cit> . a soap style webservice can be accessed from  <cit> .

two tools that the das registry offers are validation and auto-activation of das sources in das clients.

validation
there are a number of different das server programs available. frequently used server libraries include dazzle  <cit> , proserver  <cit> , ldas  <cit>  or gbrowse  <cit> . due to the simplicity of das, sometimes individually implemented cgi scripts are used as well, thus it is important to ensure that a correct response is given regardless of the implementation. to do this the das registry employs a validation mechanism such that only servers providing well formed das-xml can get registered. for this validation a test code is required, which is an accession code that identifies a reference object for which features are provided. to ensure that the listing within the das registry is current, the servers are periodically validated to ensure that the server is still available and the xml response is well formed. successful attempts are logged, and a graphical summary of the availability of a das source is provided via the registry's web interface. if the das source can not be validated for more than two days, a watchdog can optionally inform the server's administrator by email. if a server is down for a longer period of time, the server administrator can be contacted to inquire about the status of the server. if the server remains unavailable for an extended period, it will be removed from the listing.

auto-activation
users can browse and search through the das registry website. if they find an interesting das source it can be conveniently be enabled or highlighted in their favorite das client, if this client supports this. the listing of each das server in the registry's web interface contains specially formatted links to the clients. when selected, these links not only launch the das client, but highlight or turn on that particular das source, which we have termed auto-activation. at present, the clients that support the registry directed auto-activation are ensembl  <cit> , spice  <cit> , and dasty  <cit> . the registry also provides a send to friend mechanism to share auto-activation links by email.

positional and non-positional features and plots of data
the das protocol provides the features command to share annotations that have a start and stop position. this convention does not deal well with special cases where annotation can not be assigned to a defined region, or where the feature has a size of one. for data that is non-positional, such as literature references, the working convention has been adopted of providing  <dig> as the start and stop positions.

some data sets, such as hydropathicity plots or signal peptide prediction scores, can be transmitted via das by providing a different score for each feature position. the das  <dig>  specification provides the stylesheet command which allows to specify how a das client should visualize data. we developed a convention how to configure different types of plots for ensembl and spice  <cit>  and implemented support for this in the two das clients .

applications
the new das extensions presented here are actively being used by several web sites and applications. this section highlights a couple of these as examples.

pfam
the pfam database  <cit>  now makes a large proportion of its data available via das. in addition to the classical das-feature command that is used to provide domain annotations of individual protein sequences, the pfam multiple sequence alignments are also made available via das . one of the options in the specification allows the retrieval of one or more ranges from the requested query alignment. this option is of particular use when trying to view the very big pfam alignments. for example, the pkinase  full alignment contains  <dig> sequences  making it, at best, very slow to visualise the alignment when loaded as a single file. by requesting ranges, the alignment visualisation is much faster. however, most alignment visualisation tools utilise some kind of colouring scheme to highlight regions of conservation based on the properties of the whole alignment. therefore, to enable a region of an alignment to be placed in context of the whole alignment, pfam also provides the alignment consensus via a das-feature request. the data from these two requests can be combined such that requested alignment regions can be coloured according to similarity .

mapping of genome features on protein structures
we have set up alignment das server that provide mappings from the ensembl peptide sequences to uniprot, and from uniprot to pdb. the das client spice, is a browser of protein structures, sequences, and their annotations  <cit> . based on the alignment data sources we extended spice, which now can easily show the location of genomic features, like snps or intron/exon boundaries mapped onto the three dimensional structure.

multiple structure alignments
the alignment commands can be utilized to export pairwise and multiple protein structure alignments, a feature which has been used by the sisyphus database. sisyphus is a collection of proteins with non-trivial structural relationships and their alignments  <cit> . it provides a large amount of the data via das. the sisyphus multiple structure alignments can now be visualized using spice which has been recently extended to view multiple protein structure alignments .

another application of the new das structure and alignment commands was the casp experiment  <cit> , which has the goal to independently assess protein structure predictions. to do so, information about structures that have not been released to the public is passed to the structure prediction teams. these teams then provide models of the "unknown" structure.

to make evaluation and assessment of the predictions easier and more open, alignments of the predictions against the target were made available using das and visualized using spice. the different structures can be compared with each other and it is possible to switch between sequence dependent and independent alignment servers  <cit> .

discussion
das is an important system for exchanging and viewing biological data. the simple, but powerful original design of the das specification allowed scope for extension of the protocol. here we presented several extensions to the core das specification that allow to manage, publish and discover the ever growing number of das sources and to deal with alignments and protein structure data, hence allowing new types of applications built on das. we envisage further extensions to the das protocol in the future. a new extension for electron microscopy data has recently been published by macías et al.  <cit> . das has also received attention beyond the biological community and now even serves as a model in astrophysics  <cit> . das has many similarities to webservices that are provided using the simple object access protocol . soap based services have been made available by a number of institutions, e.g.  <cit> . they use xml requests and responses for the transport of information. in contrast to das there is no default definition how the transported information should look like, although there are approaches to provide standards for some data types  <cit> . biomoby is a system for interoperability between data providers, analysis services providers, and client implementations which is using soap as an envelope  <cit> .

in contrast to soap based web services, das follows the paradigm of rest, the representational state transfer  <cit> . the basic difference is that das does not have an xml envelope for its messages, but uses well defined urls for the das commands. the das responses are transported as xml documents. soap is frequently used to request remote calculation of data. in contrast the data provided with das is most of the time pre-calculated or can be computed quickly. together with the taverna project  <cit>  we agreed on the addition of a "come back later" response for das which will allow to perform longer lasting computations triggered by das requests. this can be used to establish a bridge between das and taverna workflows. a prototype implementation for this is available via the dasobert java library.

a concept sometimes used in connection with soap based webservice is the service oriented architecture . a soa consists of three components. a service provider, a consumer and a service registry. this concept can also be applied to das, with das servers being the service providers and das clients the consumers. by providing a registration server, we have extended das to become a full soa.

communication with the registry has been integrated into several web sites and applications. ensembl, pfam, dasty, jalview and spice now all can talk to the registry and users can access the registered das servers through different configuration interfaces.

currently the version  <dig>  of das specification is emerging  <cit> . we are actively participating in this development process. the sources specification for describing das services has been adopted as part of the core das/ <dig> specification. das/ <dig> is being defined with extensibility in mind and will allow the addition of protocols for sharing structure and alignment information.

CONCLUSIONS
the distributed annotation system is becoming widely accepted demonstrated by the fact that support for it is being built into more and more web sites and applications. here we have presented several extensions that help the das system to scale, add support for new data types, and allow the development of new applications. using these new das commands it has become possible to seamlessly walk from the genome level to the protein structure level and to share sequence and structure alignments.

availability and requirements
• project home page: 

• operating system: platform independent

• programming language: java, perl

• other requirements: internet browser

• license: lgpl

• any restrictions to use by non-academics: none

authors' contributions
ap implemented spice and the das registration server, extended the dazzle server and wrote the paper. td contributed several libraries, was involved in the design and planning of this project, is main author of the dazzle server and helped with writing the paper. ek extended the ensembl code base with new das functionality. rf is responsible for the pfam website, for extending proserver to support the new das commands and contributed some paragraphs to the paper. ap, td, rf, th designed the das extensions. ap, td, rf, ek, ak set up and maintain various das servers. th provided substantial advice and guidance during all phases of the project. all authors read and approved the final manuscript.

