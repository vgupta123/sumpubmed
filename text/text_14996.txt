BACKGROUND
genome-wide protein-dna interactions including transcription factor binding and epigenomic modifications play a crucial role in the programming of cell specific gene expression. therefore, their genome-wide mapping with the chip-seq  technology can significantly advance our ability to understand biology and human diseases. as a result, chip-seq is now routinely used in many applications, e.g.,  <cit> .

in a chip-seq experiment, the dna fragments from binding sites of a target protein or from sites of specific histone modifications are enriched through immunoprecipitation. these sites can be sharp point sources in transcription factor binding, or long and diffused regions in some histone modifications, or combination of both in rna polymerase-dna interactions  <cit> . then sequenced ends  of millions dna fragments are aligned to a reference genome to identify enrichment sites with over-abundance of reads. in chip samples, there are large number of fragments generated from non-specific “background” regions throughout the genome. thus, the reads in a chip sample can be considered as a mixture of enrichment signal reads and background noise reads  <cit> .

early studies without the use of control samples have assumed uniform background read distribution when assessing the significance of enrichment sites  <cit> . however, regions with high read counts do not necessarily contain enrichment sites. many follow-up studies have shown that the distribution of reads is far from uniform and is affected by many factors, including gc content  <cit> , mappability  <cit> , chromatin structure and copy number variation  <cit> , among others. the most effective approach to account for these known and other unknown biases is to include a matching control sample that is generated either from input dna or by using non-specific antibody.

the chip and control samples usually are sequenced at different depths . a common strategy for making the samples “comparable” is to linearly scale according to the sequencing depth ratio. because of the mixture nature of chip sample, it is reasonable to align/normalize only the background reads of the chip sample with respect to the control sample. hence, an appropriate normalization involves the estimation of the background reads proportion  among chip sample reads and the corresponding chip/control normalization factor. the proper estimation of the normalization factor is important for finding weak enrichment sites, especially for those sites whose enrichment ratio is between the sequencing depth ratio and the true normalization factor. the existence of weak enrichment sites has been experimentally validated and shown to be biologically meaningful  <cit> .

the normalization factor is a critical parameter of most chip-seq data analysis programs that can utilize control samples. for example, cisgenome  <cit>  and peakseq  <cit>  explicitly use the normalization factor to estimate p-values under binomial distribution. macs  <cit> , spp  <cit> , and useq  <cit> , among many others, use the normalization factor to linearly scale the control sample for comparison with the chip sample. furthermore, many programs  estimate false discovery rate  using a sample-swapping method as follows. after computing an enrichment statistic for each non-overlapping region, the fdr can be estimated as ri /rc , where ri  and rc  are the numbers of enriched regions called on the control sample and the chip sample, respectively, using the same threshold s on the enrichment statistics. to make the statistics in chip and control samples comparable, a normalization factor is implicitly used in the fdr estimation. therefore, the normalization factor is a crucial parameter of enrichment site detection and error rate control in chip-seq data analysis.

last but not least, the estimation of background reads proportion Π <dig> is of scientific interest itself. Π <dig> can be viewed as an overall quality indicator which is related to the specificity of the antibody used in an experiment, experimental design, and other experimental protocols. we have observed that Π <dig> can vary from  <dig>  to close to  <dig> in many chip-seq datasets. unless the number of truly enriched regions is small, Π <dig> close to  <dig> indicates the scarcity of enrichment reads and the need for better antibody or protocol, or both.

many chip-seq data analysis programs  have proposed methods for estimating the normalization factor; however, their performances under diverse set of settings have not been studied. most of the above methods are intuitively appealing; but many rely on ad-hoc tuning parameters.

in this paper, we develop a novel normalization method and compare it with existing methods through data-driven simulations. we further demonstrate that our method leads to better estimation accuracy, fdr control, and power than other methods.

methods
empirical studies show that the background  parts of the chip sample and the control sample exhibit a  linear relationship  <cit> . we further demonstrate such linear relationship in human, worm c.elegans and yeast s.cerevisiae chip-seq datasets in . we begin our exposition by reviewing existing normalization strategies that are well documented in the published journal articles and then present our method.

existing methods for estimating chip to control normalization factor
suppose there are n <dig> and n <dig> uniquely aligned reads for the chip and the control samples, respectively. according to the signal-noise model proposed by  <cit> , the reads in the chip sample can be decomposed into Π0n <dig> background and n <dig> enriched signal reads. then the correct chip/control ratio should be r=Π0n1n <dig>  we will refer to r as the normalization factor in the rest of the paper.

to estimate the normalization factor, the commonly used set-up is to divide reference genome into non-overlapping bins of width w, numbered from  <dig> to m. let n1i and n2i denote the total number of reads in the ith bin in the chip sample and the control sample, respectively, and ni = n1i + n2i denote the total number of chip and control reads for bin i. if the knowledge of which bins are within background regions were given to us by an oracle, then a natural estimator of the chip/control ratio would be 

  r^=∑i∈bn1i∑i∈bn2i, 

where b represents the index set of the background bins provided by the oracle. each existing normalization factor estimation method employs a different approach for estimating b. given that enrichment sites tend to have high read counts, bins with small total counts are more likely to belong to background. cisgenome sets bin-width w =  <dig> bp and uses the bins with low total counts as background. specifically, bw  ={i:ni ≤ t} and the total threshold t is set to  <dig>  as implied by this definition, bw  depends on the choice of w and t. another idea, similar in spirit but operating on the opposite direction, is to exclude bins with high read counts. spp estimates the background regions by excluding highly “enriched” regions with a small p-value either in the chip sample or the control sample under uniformity assumption on the reads. specifically, spp sets w =  <dig> kbp and b = {i:min > c}, where p1iand p2i are the poisson p-values for testing whether the ith chip and control bin read counts are generated from an uniform background read distribution, and the threshold c is set to 10− <dig> 

ccat estimates b and the normalization factor in an iterative fashion where b is estimated based on reads from the positive strand and r is updated using reads from the negative strand through . more specifically, in the jth iteration, b={i:n1i+<r^n2i+}, where r^ is the current estimate of the normalization factor which is initialized at the sequencing depth ratio and n1i +  and n2i +  are chip and control positive strand read counts in bin i with bin-width w =  <dig> kbp. the algorithm iterates till convergence.

a related method, peakseq, first defines enriched regions by using a certain threshold of fdr on the height of the chip sample read profile. instead of using , peakseq then excludes a proportion  of bins that overlap with putative enrichment sites defined in the first step and utilizes the slope of linear regression of chip against control bin counts  as the normalization factor.

all the above methods attempt to approximate the background region in some intuitive way; however they rely on tuning parameters which are set in an ad-hoc fashion. the suggested bin-width w ranges from  <dig> bp to  <dig> kbp. utilized definitions of the background regions b depend on arbitrary thresholds on an array of parameters, e.g., total count, p-value, and fdr. the same procedure with different tuning parameters may lead to drastically different estimates. in an application of peakseq  <cit> , the estimates of the normalization factor changes from  <dig>  to  <dig>  when the exclusion proportion pf changes from  <dig> to  <dig>  furthermore, there aren’t any established guidelines for optimally setting the tuning parameters.

two other methods  have adopted similar mixture-regression approaches by modeling chip counts in background and signal regions as functions of multiple covariates . however, their regression coefficients of the control read count are unlikely to be suitable for estimating normalization factor. this is because their regression functions are usually more complicated than a simple linear relationship between chip and control read counts. in mosaics, the linear regression is on some power of the control read count; whereas in zinba, there can be interaction terms involving control read count.

estimating normalization factor: ncis
we propose a new method named as ncis . our method extends cisgenome’s estimator by choosing the optimal value of bin-width w and the threshold of total read counts t in a data-adaptive manner. in general, the smaller the total count threshold t, the more likely that bins with small total counts, i.e., ni ≤ t, are from background regions, and thus, the normalization factor estimated from  by treating these bins as background tends to have smaller bias . cisgenome sets t to  <dig>  the smallest possible non-zero total count, so that bias can be minimized. on the other hand, using larger t will increase the size of bw  and reduce variance . statistically, the choice of t represents the trade-off between bias and variance.

we now motivate our method through a real chip-seq study. figure 1a shows the marginal chip/control ratio =∑i:ni=tn1i/∑i:ni=tn2i) against the total count  with w =  <dig> bp for a c.elegans chip-seq dataset of transcription factor pha- <dig>  <cit> . on the left half of the figure where t is small, the ratio estimates fall around a horizontal line, and the variability increases as t becomes small. this observation illustrates that the reads from the bins with small total counts are mostly from background regions and their marginal chip/control ratios are similar. on the right half of figure 1a, there is a strong ascent of marginal ratios which indicates the significant infusion of enrichment signal reads into the chip reads.

our method takes into account the above observations and operates as follows. first, all reads will be shifted towards their 3’ end by l/ <dig>  where l is the average dna fragment length available either through experimental protocol or computational estimation . because it is sufficient to use only nonempty bins, we filter out bins with zero total count . for any fixed bin-width w, define r^w=∑i∈bwn1i/∑i∈bwn2i as in  and bw  ={i:ni ≤ t} as in the previous subsection. we search for a total threshold t instead fixing it at a pre-specified constant. in most chip experiments, it is reasonable to believe that the vast majority of the genomic landscape are background regions. therefore, to avoid large variation in estimating r^w when t and size of bw are small, we start searching for t at the upper quartile of the non-zero total counts. specifically, our estimate of the normalization factor with a fixed bin-width w is r^w=r^w where tw∗=min{t:r^w≥r^w,|bw|≥ <dig> mw} and mw is the total number of bins. that is, r^w is the first r^w estimate that is larger than or equal to its previous one and is based on more than three quarters of the bins. for example, the vertical dash line in figure 1a marks the tw∗ selected by ncis; it separates the background regions on the left from the signal regions on the right.

it is reasonable to set the other tuning parameter, bin-width w, close to the width of the enrichment site so that there are clear contrasts between the read counts of the chip and the control samples when the bins coincide with enrichment sites. however, without knowledge of the exact locations of enrichment sites and also in the settings where the lengths of enrichment sites vary, it is not possible to put the bin boundaries tightly around enrichment sites. as a result, enriched sites are likely to be split into two or more bins, and it is advantageous to use small bin-width to gain resolution if the sequencing depth is high enough. hence, we search over a grid of bin-width {w <dig> w <dig> …,wn} such that w1< w <dig> < … < wn and stop at the first bin-width that satisfies r^wi+1≥r^wi and use r^wi as our final estimate r^. that is, r^=r^wi∗ where i∗=min{i:r^wi+1≥r^wi}. note that the values of r^wi are bound to increase because the normalization factor equals to sequencing depth ratio  when w equals to the total genome size. as an example, the normalization constant estimates  of the c.elegans data are plotted in figure 1b as a function of bin-width , and the vertical dash line indicates the bin-width that reaches the minimum of the r^w values. the default values for bin-width grid values are set at { <dig>   <dig>   <dig>  1k, 2k, 5k, 10k} to cover the range of bin-width used by existing methods.

RESULTS
a comparison of statistical properties of normalization factor estimators
in this section, we used the yeast chip-seq study of  <cit>  to generate data in our data-driven simulations. a parallel simulation study that is based on a c.elegans dataset is presented in the . we selected the yeast dataset because it is one of the deepest sequenced publicly available chip-seq datasets in terms of genome coverage. the yeast genome is about  <dig> times smaller than that of the human such that high coverage can be easily achieved on yeast with relatively small number of reads. the control sample of segregant  <dig>  has more than  <dig> m uniquely aligned reads and is one of the deepest sequenced control samples in the study. with an average fragment length of  <dig> bp,  <dig> m fragments amount to about 70x coverage on the yeast genome. as a comparison, 20m reads  for a human sample is equal to about 1x coverage. we randomly split the seg <dig> control sample into two halves and subsampled 1/d of each, where d is a subsampling divisor parameter. one of the subsamples was treated as control, and the other half was mixed in with simulated reads from p enriched sites and treated as a chip sample. using a high coverage yeast dataset and a subsampling strategy, we can investigate the performance of methods under a spectrum of coverage. for example, the coverage achieved by 20m reads on a human sample is roughly equal to the coverage on a simulated yeast control sample with d =  <dig>  as the cost of sequencing decreases rapidly, we can look into the “future” of chip-seq on large mammalian genomes by studying the performances of methods at small values of d.

we simulated reads for enriched regions in three different scenarios. setting  <dig> mimics chip-seq data of transcription factors where enrichment reads concentrate in sharp peaks. our set-up is similar to the simulation setting of  <cit> . more specifically, reads for enrichment sites were simulated from n with μi randomly assigned along the genome and σ <dig> =  <dig>  the number of reads of each site followed an exponential distribution with mean c·n2/pso that, on average, we spiked-in c times the total number of control sample reads . parameter c, which represents the proportion of signal reads relative to the background was set to  <dig> ,  <dig>  and  <dig> to represent weak to strong overall binding signal strength. the value of p was set to  <dig>  based on the results of  <cit>  which identified about  <dig> binding sites for the transcription factor ste <dig> in various strains of yeast. the subsampling divisor, d, took values in { <dig> , <dig> , <dig> ,100} to represent different depths of coverage. the simulation was repeated  <dig> times for each combination of c and d.

in this simulation study, we compare our estimator  with estimators proposed in cisgenome, spp, ccat, and peakseq. the exclusion proportion parameter pf  in peakseq was set at  <dig> to simplify its computation. left panel of figure  <dig> displays the log  of mean squared error  for setting  <dig>  with c =  <dig>  we chose mse as our comparison metric because it considers both the bias and the variance of the estimators compared to true normalization factor. overall, our ncis estimator has the smallest mse among all the methods. peakseq estimator is the worst in estimation precision, followed by spp. cisgenome estimator has second best mse when sequencing depth is low; however its performance deteriorates when sequencing depth is high. the performances of all the estimators except peakseq and cisgenome improve with the increase of sequencing depth. the rest of the results  for setting  <dig> are similar and are provided in .

in setting  <dig>  we study the impact of artifacts on normalization constant estimation. high-throughput sequencing experiments, including chip-seq experiments, are complex biochemical and computational processes, and it is common that the sequencing data contain various artifacts. some examples of artifact regions where the control sample has significantly higher read count than the chip sample are displayed and discussed in . we first simulated reads as in setting  <dig>  then we generated artifacts according the patterns observed in the above examples. more specifically, we randomly chose  <dig> locations along the genome and generated artifact reads on these locations in the control sample such that the total number of artifact reads is a small percentage  of the original control sample sequencing depth. figure  <dig>  illustrates that most methods are not affected significantly by the presence of artifacts. however, the performance of ccat is much worse than in setting  <dig>  indicating its lack of robustness with respect to these artifacts.

in setting  <dig>  we simulated the enrichment reads to resemble histone modifications and polymerase binding where enrichment reads are spread out on large regions. we allocated enriched reads uniformly on p =  <dig> regions. the length of each region was generated uniformly between 5– <dig> kbp. the distribution of the number of reads of each region, signal/background proportion c and subsampling divisor d were the same as in above transcription factor set-up. right panel of figure  <dig> displays the results for c =  <dig> while the results for c =  <dig>  and  <dig>  are provided in . our method remains the best in terms of mse.

we also simulated various levels of the true normalization factor  by using different subsampling divisors on split halves. the results are similar to those presented here for the true normalization factor of  <dig> and hence are not reported. in term of estimation precision, the order of the methods  is: ncis, ccat, cisgenome, spp, and peakseq.

fdr control and power
we evaluate the impact of using different normalization factor estimators on fdr control and power with simulated data similar to the previous setting  <dig> with the same split-subsampling procedure and the addition of artifacts. however, we generated the binding site locations and signal strength differently. we first called peaks using spp at fdr level  <dig>  and obtained  <dig> putative binding locations from the seg <dig> yeast data. then the signal strength at each site was estimated as its chip count minus its corresponding  control count. at each iteration, we randomly sample  <dig> sites from the total  <dig> and let the number of reads at each site follows a poisson distribution with mean equal to the estimated signal strength. because the binding site locations and signal strengths are obtained from a real chip data, a more realistic power result can be achieved.

fdr control is achieved through the sample-swapping method as discussed in the background section. to obtain putative binding site locations , we employed a simple two-stage search strategy. in the first stage, we partitioned the yeast genome into  <dig> bp non-overlapping bins and retained only bins with binomial p-value smaller than or equal to some liberal threshold, for example,  <dig> . then in the second stage, we merged nearby retained bins into putative regions and searched each region to locate the  <dig> bp bin with the highest chip bin count and used the center of this bin as our prediction of the putative binding site. for each binding site, we extended  <dig> bp from the site location to both directions and formed a binding region. then we used the chip and control read counts in the binding region to compute a binomial p-value as the enrichment statistic for the binding site. more specifically, for each normalization factor estimator, the binomial probability p when comparing the chip sample to the control sample is computed as r^/, where r^ is their respective estimate of normalization factor. further details for computing binomial p-value can be found in  <cit> . this peak-calling procedure was first performed with the chip sample versus the control sample to obtain a list of putative binding sites and their statistics, and repeated one more time with the control sample versus the chip sample to obtain a list of control binding sites and their statistics. then a number of putative binding sites were declared as true binding sites such that the empirical fdr  did not exceed certain nominal level  using the same p-value threshold. a site was classified as false positive if the predicted location was  <dig> bp away from its closest true binding site. note that there were few declared binding sites located between  <dig> bp to  <dig> bp away from true binding sites, so any choice between  <dig> bp and  <dig> bp would yield similar results.

simulations for fdr estimation of the sample-swapping method have been performed in  <cit> , and our simulation differs from theirs in two major ways. first, simulations in  <cit>  only evaluated the fdr estimation over a range of nominal fdr levels with a fixed sequencing depth, while our simulations evaluate fdr control over varying sequencing depths. second, fdrs computed in  <cit>  are on the basis of  <dig> kbp non-overlapping regions, while we classified predicted binding sites by their distance to their closest true binding sites. our false positive criteria is more accurate and relevant because a single  <dig> kbp region can hold multiple binding sites and one or more these sites can be close to the boundary of two adjacent regions such that both regions would be regarded as true binding regions.

as a comparison, we also performed peak calling when the normalization factor is set to its true value of  <dig> and refer to this method as the oracle. fdr is controlled at the target level of  <dig> , and figure 3a displays the means of the realized fdr for various methods. the fdr values of the oracle are close to the nominal value of  <dig>  . for display purpose, the oracle fdr values are plotted at the expected value of  <dig> , and other methods are adjusted accordingly. cisgenome and ccat fail to control fdr at various sequencing depths, especially when the sequencing depth is high. cisgenome’s fdr values can be drastically larger than nominal level at high sequencing depths because its normalization estimate becomes unreliable and highly variable. ccat’s failure to control fdr is due to the negative bias resulting from the artifacts. among all the methods, the fdr values of ncis are the closest to the oracle. figure 3b shows the power  of all methods against different subsampling divisors/sequencing depths. among all methods that can control fdr at the nominal level , ncis is the most powerful method and is indistinguishable from the oracle. on average, ncis is about 6% more powerful than the second best  across different sequencing depths.

application
yeast ste <dig> data
we applied our method on the chip-seq data of yeast strain seg <dig> in  <cit>  and estimated Π <dig>  the background proportion in chip sample, to be  <dig> . the original analysis was performed by macs, which assumes the sequencing depth ratio as the normalization factor. to make results comparable with the original analysis, we modified the latest stable version of macs  such that it can utilize user specified normalization factors through an additional input parameter. the estimated normalization factor , background proportion  and number of detected binding sites under two different criterion are listed in table  <dig>  the first criteria “#peaks by p-value” refers to the number of peaks detected by macs with its default p-value threshold of 1e- <dig>  and the second criteria “#peaks by fdr” refers to the number of peaks detected by macs with fdr controlled at  <dig>  level. the other parameters of macs were set to be the same as in the original analysis. using different normalization factors has a dramatic impact on the power to detect binding sites and the estimation of fdr. this is because it is difficult to call peaks in chip sample but relatively easy to do so in control sample with a conservative normalization constant such as the sequencing depth ratio. for example, macs only declared  <dig> significant binding region at fdr level  <dig>  in contrast to  <dig> significant binding regions with ncis estimate at the same fdr threshold. on the other hand, macs estimated the fdr for the most significant  <dig> peaks to be  <dig> , while the fdr for the top  <dig> peaks was estimated as  <dig>  using the ncis estimate. the roughly  <dig> fold difference in the estimated fdr was caused by a relative small change in the normalization factor estimates. this example illustrates the importance of the normalization factor estimator. a recent paper  <cit>  also pointed out that macs overestimated fdr  <dig>  fold in their study, and that it is highly likely that the incorrect normalization factor is the major contributing factor. cisgenome’s estimate of normalization factor is very conservative. this is because the seg <dig> strain was deeply sequenced and as a result, there are only  <dig> bins whose chip and control read count total equal to  <dig>  hence, cisgenome’s estimate is expected to be highly variable due to the small sample size to estimate normalization factor when sequencing depth is high. this is consistent with our observation in figure  <dig> and the simulation results.

the fourth column contains the numbers of detected peaks with p-value ≤  <dig> e- <dig>  the fifth column contains the numbers of detected peaks at fdr level  <dig> .

to further illustrate the differences between different normalization factors, we plotted the chip versus the control bin counts with bin-width w =  <dig> bp in figure  <dig>  in this plot, different colors indicate different densities of bins which are annotated at the right-hand side. there are many bins with relatively high chip counts due to the enrichment signal. the slope of the upper black line is the sequencing depth ratio, and majority of bins  appear below this line. we should expect less than 50% of bins to appear below the normalization factor line because binding regions have smaller than  <dig>  probability to exhibit a chip count/control count ratio below the normalization factor. the ncis normalization factor is represented by the lower blue line, which passes right through the densest area of bins and has  <dig> % of bins below the line.

human nfκb data
we next compared different normalization estimators on a human nfκb chip-seq dataset in  <cit> , where the genome-wide binding of transcription factor nfκb was extensively studied on multiple cell lines. as one of the deepest sequenced cell lines among the data collected, cell line gm <dig> has  <dig>  and  <dig>  million uniquely mapped reads in the chip and the control samples, respectively. table  <dig> shows estimates of normalization factor from different methods.

the sequencing depth ratio is  <dig> .

software
r package  for ncis is available in .

discussion
as the sequencing technology improves rapidly over time, deeply sequenced data sets will become more common. we demonstrated in our simulation and application studies that cisgenome estimator’s performance deteriorates when sequencing depth increases. in one unpublished and deeply sequenced e.coli dataset , we observed that cisgenome estimator was not applicable because every mappable bin had more than one read. although we studied the fdr in a balanced  simulation setting, our analytical results also support fdr control for unbalanced data in the .

CONCLUSIONS
in this study, we systematically evaluated the available chip-seq normalization factor estimators through data-based simulations. all existing estimators rely on some ad-hoc tuning parameters, which may be crucial to the final estimate. our ncis method is data-adaptive and has better estimation precision  than existing methods over a wide range of sequencing depths, and for both sharp and diffused chip signals. given the importance of normalization factor in evaluating protein-dna binding efficiency and the power of detecting protein-dna binding sites while achieving proper error control, we expect our method to contribute significantly to the chip-seq research and applications.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
kl designed the study, wrote the ncis package, conducted statistical analyses, and drafted the manuscript. sk designed the study and drafted the manuscript. both authors read and approved the final manuscript.

supplementary material
additional file 1
section  <dig>  illustration of linearity between chip and control samples. section  <dig>  simulation results for the normalization factor estimators at different settings with yeast data. section  <dig>  simulation results for the normalization factor estimators with c.elegans data. section  <dig>  fdr control for unbalanced data,  <cit> .

click here for file

 additional file 2
ncis r package.

click here for file

 acknowledgements
this work was supported by nih-ro1hg <dig>  hg <dig> , and de-fg02-04er <dig> grants. the authors are grateful to professor kiley  for sharing her deeply sequenced e.coli chip-seq dataset to test and evaluate our method.
