BACKGROUND
in recent years, a rise in the number of genome sequencing projects around the world has led to an increase in the number of protein sequences with unknown structures. protein structure prediction aims to bridge the gap between the number of such sequences and the number of sequences with experimentally determined structures. one advantage of computational protein structure prediction is that accurate in silico protein modelling can help guide the more expensive experimental efforts in protein structure determination. ultimately, the goal is to understand protein function through its 3d structure and sequence and to further increase our biological insights of the behaviour and interactions of these macromolecules in ways that would be beneficial to mankind.

since  <dig>  the casp experiments  <cit>  have provided a useful platform for structure prediction groups to apply their methods to a common set of target sequences, thereby providing the means of direct comparison between these methods. if a target sequence has templates in the structure databases, comparative modelling and fold recognition methods are used to select the templates. in the event of a sequence having an unknown fold, in the case of the template free category, fragment assembly methods such as fragfold  <cit>  and rosetta  <cit>  are used to build plausible models. typically, large numbers of candidate models, also known as decoys, are built in order to sample as large a 3d conformational space as possible. the subsequent challenge is to select the lowest rmsd structure among these decoys to represent as the prediction. this is referred to as the decoy discrimination problem. common approaches to decoy discrimination include the use of statistical potentials  <cit> , structural clustering of decoy structures  <cit> , as well as the application of model quality assessment programs  such as modcheck  <cit>  and victor/frst  <cit> .

in this work, we present a novel method of decoy discrimination using machine learning, more specifically using neural networks. decoy discrimination is represented as a machine learning problem, where neural networks are used to learn the native-like features of protein structures using a set of positive and negative training examples. a set of native protein structures forms the positive training examples, while a set of simulated decoy structures makes up the negative training examples. various features are extracted from the training dataset of positive and negative examples and used as inputs to the neural networks.

for the purpose of providing negative training examples, the method of generating a decoy structure  by retaining the physical structure and changing only the sequence ensures that we are using good structural features, as opposed to having overly compact generated structures with steric clashes or non-compact generated structures with obvious non-protein like features. each of these generated structures with reversed sequences retains native-like structural features, such as native shape and packing density but sequence-related features such as the distributions of pairwise distances of particular residue pairs would be different. for example, the distribution of alanine-alanine pairs in native structures  <dig> residues apart would have a peak at about 11Å typical of helices, but no such peak exists in the distribution in generated structures with reversed sequences. it is hoped that neural network training can be used to capture the differences in these distributions of pairwise distances among the  <dig> possible residue pair types, and that the final neural network can be used to judge or discriminate decoys with near-native features from poorer quality decoys.

it is also an option to generate near-native decoy structures from native structures and then use the generated structures as negative training examples. in this case, structural features such as the pairwise distances would be different, and the distributions of pairwise distances from such decoy structures would be dissimilar to those of native structures too. in this paper, we have decided to leave this method for future work, and concentrate solely on the sequence reversal method for the generation of negative training examples, and test this sequence reversal method to see if it is effective in the context of neural networks. the other main alternative would be to use decoy datasets as negative training examples, but that would render the decoy datasets unavailable for testing, and most publicly available decoy sets are very limited e.g. in terms of protein sizes or types.

although machine learning has been used for model quality assessment before  <cit> , it has generally used to optimally combine component features such as solvation energy and secondary structure similarity into a single model quality score. in this case we use machine learning to learn features which are the equivalent of basic pairwise and solvation potential terms to discriminate native folds from decoys. the intended advantage of this approach is that a wide range of input features can be directly incorporated into a single scoring function and combined implicitly. for example, close interactions between positively charged and negatively charged amino acid side chains are rare when the side chains are buried. nevertheless such salt-bridge interactions do occur, and these can be highly discriminatory features when present in the native structure. the rarity of these features, however, makes it hard for traditional statistical pair potential functions to correctly recognize them. if the evolutionary conservation of the charged amino acids is taken into account, then it is straightforward to identify the rare occasions on which a salt-bridge should be considered, as buried salt-bridges are generally seen to be highly conserved across a family of related proteins.

in this work we start out by using neural networks to replace standard pair and solvation potentials. this novel paradigm of using neural networks to perform decoy discrimination is then extended to include evolutionary information. the benefits of using psi-blast  <cit>  profiles with neural networks has previously been demonstrated for secondary structure prediction  and here we demonstrate the use of such information for tertiary structure prediction. dong and co-workers  <cit>  have also tried to use profile information to develop a better mean force potential for discriminating native structures from sets of decoys, but in their case they simply threshold the sequence profile scores to render a binary decision as to whether a residue is conserved or not conserved. in this paper, we demonstrate that by using neural networks to represent the scoring function, evolutionary information can be encoded as continuous input features to improve the decoy discrimination process. our intention is to demonstrate the promise of using neural networks with evolutionary information to perform effective coarse decoy discrimination as an initial step, and to provide a platform for future higher resolution decoy discrimination. to provide a rigorous test of these neural network methods, high resolution decoy datasets such as the baker dataset  <cit> , as well as lower resolution decoy datasets, are used for the comparison of results to that obtained from existing in-house pairwise potential methods  <cit> .

RESULTS
a set of  <dig> protein domains are selected from the scop database  <cit>   and divided into training, validation and preliminary test datasets, of size 60%, 20% and 20% respectively. the number of protein domains in each dataset and the percentages of secondary structure content are shown in table  <dig>  the training and validation datasets are used for neural network training. the preliminary test dataset is used as a basic test for the neural networks in their ability to distinguish native structures from random decoys. random decoys are generated by randomizing the sequence of each structure in the preliminary test dataset.

while random decoys provide a basic test, ultimately the neural networks need to be tested on the discrimination of near-native decoys in real decoy datasets. several decoy datasets are used, and these are shown in table  <dig>  in the discussion of results, the baker dataset  <cit>  is discussed in greater detail because it has the highest quality of decoys, compared to other datasets .

several input features of the training datasets are extracted and used for neural network training . the various types of neural networks and their input features are shown in table  <dig> . for example, the nn-dist method trains neural networks that code for residue pair identities and pairwise distances, as well as having one neural network for each sequence separation k. due to the large size of training data, each discrete value of the sequence separation k has to be represented as one neural network. such a representation means that the various sequence separations k have to be combined in meaningful ways. in this work, for the sake of comparison with the in-house pairwise potentials method  <cit>  which has proven competitive in recent casp experiments,  <dig> methods of combinations of results are attempted. these are the short-range  combination which sums up the average scores from the k =  <dig> to k =  <dig> networks; the short-and-medium  combination which sums up the average scores from the k =  <dig> to k =  <dig> networks; the short-medium-long  combination which sums up the average scores from the k =  <dig> to k =  <dig>  as well as k >  <dig>  networks .

besides using the in-house pairwise potentials method  <cit>  as a basis for effective comparison, the k nearest neighbours method, a basic machine learning method, is also used for comparison to the various types of neural networks. the measures used for evaluating the different methods are the z-score and the enrichment score  <cit> . the z score measures the extent to which a method can select the native structure from among the decoys; the enrichment score  <cit>  is an indication of the degree to which the method succeeds in identifying the lowest rmsd near-native structures.

the ability of any two decoy discrimination methods can be compared by looking at the difference in the quality of the top-ranked models produced by each method  <cit> . here,  <dig> structural similarity measures for assessing the quality of a decoy model are used, namely tm-score  <cit> , gdt-ts  <cit>  and maxsub  <cit> . the one-tailed wilcoxon sign-rank test is used to test, at a 5% significance level, the differences between any two methods. the null hypothesis is the zero median of the distribution of differences in a given structural similarity score, e.g. tm-score  <cit> , of the respective top-ranked models. similarly, apart from looking only at the top-ranked model, the ability of any two methods to effectively rank the decoys from highest to lowest quality are also assessed in the form of the spearman rank correlation coefficient. here another one-tailed wilcoxon sign-rank test is used to test the difference between any two methods in their ability to rank the decoys from highest to lowest quality. the null hypothesis is the zero median of the distribution of differences in spearman correlation coefficients produced by the two methods.

results produced from neural networks which use evolutionary features extracted from the training datasets are also discussed. table  <dig> shows the various types of neural networks that use evolutionary features. a complete description of each method can be found in the section methods, inclusion of evolutionary information.

preliminary test dataset
for each of the  <dig> proteins in the preliminary test dataset in table  <dig>   <dig> random decoy structures are generated by shuffling the sequence in the native structure.

it is important to point out here that the randomization of sequences in native structures is done only to provide sets of  <dig> random decoys each for the first-level test, while the reversal of sequences is done on native structures in the training dataset to provide the neural networks with a number of native-like negative training examples equal in size and number to the native structures, which are the positive training examples. it is previously mentioned in the case of generated structures of reversed sequences that structural features such as pairwise distances are retained, and sequence-related features such as the distance distributions of pairwise residues have been altered. the same applies to generated structures with randomized sequences, except that the distributions of pairwise distances of such structures would be more different to those of native structures. this is because in the case of generated structures with reversed sequences, information regarding the proximity between certain residues along the sequence is retained. for example, an alanine pair of  <dig> residues apart which can be found in a helix in the native structure would still be  <dig> residues apart in the reversed structure but they may be part of a beta strand or loop. this type of information would be lost in the randomized structures.

the purpose of preliminary testing is to test the viability of the idea of using neural networks in the current context for decoy discrimination, which includes the paradigm of using structures with reversed sequences as negative training examples, and the separation of native from random decoy structures as a quick first-level test. using the nn-dist method and the s combination of network results,  <dig> out of  <dig> native structures are correctly ranked with the highest network scores. this means that for the  <dig> native structures in the preliminary test dataset and the  <dig> corresponding random decoys for each native structure, the s combination of the nn-dist method is able to assign the highest network score to the native structure for  <dig> cases. the average z score of these  <dig> proteins is  <dig> . the remaining  <dig> cases have their native structures ranked 2nd, 3rd, 8th and 23rd out of  <dig> structures . apart from the worst performing native structure, 1vps:a, the native structures of the other  <dig> cases have comparatively high ranks, even though they do not have the highest rank. the protein domain 1vps:a has  <dig> other similar domains, and forms part of a beta sandwich architecture, and the poor z score of its native structure could be due to the fact that  <dig> generated structures with randomized sequences have, due to pure chance, distributions of pairwise distances similar to that of native distributions.

results of methods with no evolutionary information
results of different combinations of scores
it can be seen from figure  <dig> that there is little difference between the different combinations of network scores for the nn-solvpair method. for the nn-solvpairndist method, the k =  <dig> single mean score is better than the other combinations. for the nn-dist method, there is more variability between the different combinations, with the sm and sml combinations yielding negative z scores. figure  <dig> also shows that the nn-solvpairndist method performs better than the other two methods across all different combinations of scores.

due to the fact that the nn-dist method does well for the s combination, and the rest of the methods perform rather consistently across the different combinations, the s combination is used for benchmarking for all decoy datasets in the remaining results presented in this work. although the k =  <dig> single mean score yields the highest z score for the nn-solvpairndist and nn-dist methods on the baker dataset  <cit> , it is poorer than the s combination in most of the other decoy datasets .

results on baker dataset
because the baker dataset  <cit>  has  <dig> proteins, it is possible to see how the various methods, including the pairwise potentials  <cit>  and the k nearest neighbours method, perform on different secondary structural classes of proteins. figure  <dig> shows the z scores produced by the s combination of the various neural network and k nearest neighbours methods on the different secondary structural classes of proteins in the baker dataset  <cit> .

it can be seen from figure  <dig> that for the s combination, the nn-solvpairndist and nn-solvpair methods do not perform well for α-only proteins in the baker decoy dataset  <cit> , compared to the rest of the methods. the reverse is true for αβ proteins where the nn-solvpairndist and nn-solvpair methods have higher z scores than the nn-dist method and the k nearest neighbours methods. in all cases, the pairwise potentials method  <cit>  has the highest z score and it is interesting to note that the nn-solvpairndist method has a z score which is only marginally lower than that of the pairwise potentials method  <cit>  for αβ proteins.

the nn-dist method and the k nearest neighbours methods  perform well for α-only and β-only proteins, but has low z scores for αβ proteins. the k =  <dig> method performs slightly better than the k =  <dig> method for all classes.

on average, across all proteins, the pairwise potentials method  <cit>  has the highest z score. the nn-solvpairndist method performs slightly better than the nn-dist method, while the k nearest neighbours method  has an overall z score which is slightly higher than the nn-solvpairndist method.

results on all datasets
in general, although the pairwise potentials method  <cit>  has the highest overall z score, it does not have the highest z score for each individual dataset. for the fisa  <cit> , lmds  <cit>  and semfold  <cit>  datasets, the nn-solvpairndist method has the highest z score instead. the nn-solvpairndist method also has the second highest z score after the pairwise potentials method  <cit>  in the 4state_reduced  <cit> , lattice_ssfit  <cit>  and fisa_casp <dig>  <cit>  datasets. this suggests that the nn-solvpairndist method shows some promise in matching the performance of the pairwise potentials method  <cit> , if it can be further augmented with additional information.

in all but one case , the nn-solvpairndist method has a higher z score than the nn-dist method. for all but  <dig> decoy datasets , the  <dig> k-nn methods have lower z scores than the nn-solvpairndist method, although they are comparable to the nn-dist method in terms of z score. the nn-solvpair method also performs better than the nn-dist method in all but two cases, namely the baker decoy dataset  <cit>  and lmds_v <dig>  <cit> . the nn-solvpairndist method always has higher z scores than the nn-solvpair method, which suggests that the additional distance information of the nn-solvpairndist method contributes to the discrimination of native structures.

it also seems that there is no significant improvement of the enrichment score  <cit>  for the nn-solvpairndist method over the nn-dist method.

results of methods using evolutionary information
in this section, the results of the sequence profile methods and homologue threading methods are presented. because the semfold  <cit>  dataset has about  <dig> decoys per protein, and there is a lack of computational resources during the application of the homologue threading methods for the threading of such a large number of decoy structures, the semfold  <cit>  dataset is left out in this section. the k nearest neighbours methods are also left out to increase the clarity of the graphs.

it can also be observed that the homologue threading methods has higher z scores than the non evolutionary counterparts across all classes, except β-only, of proteins. this suggests that there is a small but noticeable reduction in noise in the discrimination of native structures when the averaging of network output scores of sequence homologues is used.

in figure  <dig>  for the sp-nn-solvpairndist method, the performance on the enrichment score  <cit>  for the s combination is less pronounced than that of the z score. the sp-nn-solvpairndist method ranks best in the baker decoy dataset  <cit> , 4state_reduced  <cit> , and fisa  <cit>  datasets.

in figure  <dig>  for the ht-nn-dist, ht-nn-solvpair and ht-nn-solvpairndist methods, apart from the 4state_reduced  <cit>  dataset, it can be seen that the averaging of sequence homologues do yield a slight increase of z score for each ht-nn method over its corresponding basic nn counterpart method. this suggests that a modest increase in the performance of the discrimination of native structures can be achieved using averaging the scores of sequence homologues that are threaded to each structure in the decoy dataset. table  <dig> shows the number of homologous sequences produced by psi-blast  <cit>  for the native proteins in the various decoy datasets.

for the enrichment score  <cit> , the ht-nn methods show little improvement over the basic counterpart methods. all the  <dig> homologue threading methods show improvements over the basic nn methods in only  <dig> datasets, namely the baker dataset  <cit> , 4state_reduced  <cit>  and the lattice_ssfit  <cit>  datasets.

one conclusion that can be drawn is that the sp-nn-solvpairndist method, which uses profile information in conjunction with pairwise distance and relative solvent accessibility information of residue pairs, has the best performance in terms of the discrimination of native structures for all decoy datasets  among the various neural network methods and the pairwise potentials method  <cit> . in terms of selecting the low rmsd decoys , it slightly outperforms the rest of the methods for a number of decoy datasets.

results of statistical tests
this section discusses the results of two statistical tests, the first of which evaluates the difference between two decoy discrimination methods in the ability to select the top ranked model of highest quality. the assessment of the quality of the top ranked model itself is done using different structural similarity measures, namely tm-score  <cit> , gdt-ts  <cit>  and maxsub  <cit> . the one-tailed wilcoxon sign-rank test is used here to test, at a 5% significance level, the null hypothesis of zero median in the distribution of differences in structural similarity scores of the respective top ranked models produced by the two methods.

the second statistical test compares the differences between the ability of the two decoy discrimination methods to assign high scores to better quality models and low scores to poorer quality models. the spearman rank correlation coefficient is used here to measure the correlation between the output scores of each method and the structural similarity  score of the decoy structures. the one-tailed wilcoxon sign-rank test is then used in the assessment of the difference, if any, in the distributions of the spearman rank correlation coefficients produced by both methods.

in table  <dig>  the comparison of the sp-nn-solvpairndist method with the nn-solvpairndist method is shown to have p-values ≤  <dig>  for the α-only set of proteins for all structural similarity measures, and hence the null hypotheses can be rejected in these cases. this suggests that evolutionary information, in the context of the neural network that uses relative solvent accessibilities and pairwise distance, can yield better quality top ranked models in α-only proteins.

in table  <dig>  the comparison of the sp-nn-solvpairndist method with the nn-solvpairndist method is shown to have p-values ≤  <dig>  for the combined dataset of proteins, as well as the α-only, β-only, αβ classes of proteins, for all structural similarity measures. the same can be said of the comparison between the sp-nn-solvpair and nn-solvpair methods too. hence the null hypotheses can be rejected in these cases. this suggests that additional evolutionary information, in the context of the sp-nn-solvpair and sp-nn-solvpairndist methods, can produce better spearman correlation coefficients between the quality of the models and the output scores.

comparison with dong's profile-based statistical potentials
one existing method that uses evolutionary information for discriminating native structures from decoy datasets is developed by dong and co-workers  <cit>  in the form of profile-based statistical potentials. in their work, they extend the traditional paradigm of residue identity in pairwise potentials  <cit>  to that of frequency profiles, which represent the probabilities of amino acids occurring in specific positions of protein sequences. these frequency profiles are converted to binary profiles via probability thresholds. a variety of profile level statistical potentials, including distance-dependent, contact, dihedral angle and accessible surface potentials, are created and tested on various decoy datasets. in this paper, we compare the z scores of our most promising method, sp-nn-solvpairndist, to that of the most successful method, the distance profile method, of dong and co-workers <cit> . table  <dig> shows the z scores applied to the various decoy datasets. the number of protein decoy datasets used in our method and dong's method differs for the baker decoy dataset <cit> , the 4state_reduced  <cit>  and fisa_casp <dig> <cit>  datasets. for example, we use only the  <dig> non-obsolete x-ray structures in the baker dataset <cit> , while dong and co-workers used the whole set of  <dig> structures. similarly, for the 4state_reduced <cit>  dataset, we use  <dig> non-obsolete protein decoy datasets instead of  <dig> and dong used  <dig> instead of  <dig> protein decoy datasets in fisa_casp <dig> <cit> .

for the baker decoy dataset  <cit> , dong's statistical profile potentials has a higher z score than the sp-nn-solvpairndist method, but the z score is derived over additional low-resolution nmr native structures in the baker dataset <cit>  for the former method. for the 4state_reduced <cit>  and lattice_ssfit <cit>  datasets, dong's distance profile method has higher z scores than the sp-nn-solvpairndist method, although the 4state_reduced <cit>  dataset used by dong and co-workers include one additional obsolete structure. however, our sp-nn-solvpairndist method has higher z scores than dong's distance profile method for identical number of proteins in the lmds <cit>  and fisa <cit>  datasets, as well as for the fisa_casp <dig> <cit>  dataset, where the number of protein decoy datasets differ.

discussion
in this paper, we introduce the idea of replacing sets of mean force potentials by a small number of neural networks to perform discrimination of native structures from decoys. different combinations of input features were tried, with the most useful features being pairwise distance between residue pairs, solvent accessibility values of the residues, and/or evolutionary information encoded in the form of profiles.

positive training examples are extracted from a set of native protein structures, and negative training examples are simulated using the sequence reversal method on the same set of protein structures. testing is done on several publicly available decoy datasets, and results are compared to that obtained using the in-house traditional pairwise potentials method  <cit> .

results show that as far as the discrimination of the native structure is concerned, neural networks without evolutionary information do not perform as well as statistical potentials across the various datasets . the best neural network has a z score of  <dig>  compared to the pairwise potentials method <cit> 's z score of  <dig> . however, the neural network with the input combination of pairwise distance and solvent accessibilities does as well for the αβ class of proteins in the baker dataset <cit>  , with a z score of  <dig>  compared to the z score of  <dig>  produced by the pairwise potentials method  <cit> . for the enrichment score  <cit> , the best neural network without evolutionary information has a score of  <dig> , compared to the pairwise potentials method's enrichment score  <cit>  of  <dig>  .

however, addition of evolutionary information helps improve the discrimination of the native structure considerably, as measured by the z score, compared to statistical pairwise potentials <cit>  . the best neural network, which comprises a combination of all input features, has a z score of  <dig>  compared to the pairwise potentials method's z score of  <dig>  . for the different classes of proteins in the baker dataset  <cit> , the same neural network outperforms the pairwise potentials method <cit>  for the β-only and αβ classes, but not the α-only class of proteins. the enrichment score  <cit>  of the best network utilizing evolutionary information is  <dig> , a marginal improvement over the statistical pairwise potentials' score of  <dig>  .

it is mentioned in the work of park and co-workers <cit>  that different decoy discrimination functions work well in some datasets, but not in others due to the differences in the construction of decoy datasets. from figure  <dig>  the best neural network, sp-nn-solvpairndist, appears to have similar levels of performance for the various decoy datasets, apart from the baker dataset  <cit>  which is highest in quality. figure  <dig> however shows that the sp-nn-solvpairndist neural network performs better with β-only and αβ classes of proteins, as compared to the α-only class of proteins. this suggests that this neural network can be used in conjunction with the in-house pairwise potentials method  <cit> , which performs well for α-only proteins, for decoy discrimination, depending on the predicted secondary structural content of the target sequence.

the use of neural networks in decoy discrimination yield mixed results, with much better results achieved from those neural networks that use evolutionary information. this suggests that the sequence reversal method of generating negative training examples is, on the whole, feasible and works better in those neural networks that utilise evolutionary information. this is not surprising because evolutionary information in the form of psi-blast  <cit>  profiles encode information regarding the affinity of all possible residue types to occupy two particular positions in the sequence. for the native structures that represent positive training examples, such information represented by the multi-dimensional distributions of features such as the pairwise distance can be effectively encoded by the neural networks. similarly, for the generated structures with reversed sequences that represent the negative training examples, the distributions representing the affinities of residue types to any two "false" positions, brought about by the reversal of sequence, have a stronger negative signal compared to that of the non-evolutionary information, and this can be effectively encoded by the neural networks in the training phase.

CONCLUSIONS
in this paper, we have demonstrated the viability of using machine learning, more specifically neural networks, to perform decoy discrimination.

the method of simulating the decoy structures using the sequence reversal method appears to provide an adequate representation of negative training examples in neural network learning. a combination of input features of the identities of the residue pairs, pairwise distance, and relative solvent accessibility information proves promising in the discrimination of native structures. we also show that evolutionary information can be used to further improve the discrimination process.

the best neural network method  has input features comprising of the position-specific sequence profile information of residue pairs, together with the relative solvent accessibility of the residues and the pairwise distance between these residues. the sp-nn-solvpairndist method is the best among all the methods tested in discriminating native structures from the corresponding set of decoy structures, as demonstrated by the highest z scores it has in all the decoy datasets in figure  <dig>  as for the enrichment  <cit>  in figure  <dig>  the sp-nn-solvpairndist method is the best in approximately half of the decoy datasets tested.

statistical tests have shown at a 5% significance level that, for α-only proteins, the sp-nn-solvpairndist method can select a top model of better quality, using structural similarity measures of tm-score <cit> , gdt-ts <cit>  or maxsub  <cit> , than the corresponding nn-solvpairndist method. this suggests that evolutionary information can help to increase the quality of top model selection.

at a 5% significance level, for the combined dataset and the various secondary structural classes of proteins, there is an increase in the spearman correlation coefficients of the structural similarity measures of decoy models with the output scores of the sp-nn-solvpairndist and sp-nn-solvpair methods, when compared to the spearman correlation coefficients of the structural similarity measures with the output scores of the corresponding basic nn-solvpairndist and nn-solvpair methods respectively. this again suggests that evolutionary information helps to better correlate the quality of the decoy models with the output scores of the proposed decoy discrimination method.

in conclusion, the idea of applying machine learning for the decoy discrimination problem, in context of using neural networks and the proposed way of representing the required training examples, is indeed feasible, as demonstrated in this paper. furthermore, decoy discrimination, in particular the identification of the native structure, can be greatly improved by using evolutionary information in the form of including psi-blast  <cit>  profiles in the training of the neural networks.

a major advantage of this approach to evaluating protein models is that any number of relevant features can be directly taken account of in the formulation. here we have looked primarily at evolutionary information, but information from experimental sources  could also be incorporated.

further improvements to decoy discrimination can be expected through the use of better simulated decoy structures. rather than using crude reversed sequence threading models, a large ensemble of refined de novo models could be used, or perhaps decoy structures specifically tuned to particular sizes of proteins or folding types, for example.

a future variation of this idea will be to extend this machine learning paradigm to high resolution modelling which involves the discrimination of close-to-native decoys from native structures. although the idea of using reversed sequences to provide negative training examples works reasonably well for presently available low-resolution decoy datasets, it cannot be applied to the discrimination of native structures from close-to-native decoys. in this case, suitable models for the negative training examples could be taken from sets of comparative models built from templates of closely related structures <cit> .

