BACKGROUND
rather than considering a single species in pure culture, metagenomics goes beyond and focuses on the exploration of entire microbial communities  <cit> . this focus is possible only because of the recent improvements in sequencing technology. as is typical of new concepts, the emergence of this new paradigm has brought up some new challenges. among them, the manipulation and analysis of short reads deserves special attention.

in some cases, the phylogenetic diversity of a microbial community is not well covered and, as a consequence, only a few reads can be assembled  <cit> . hence, one of the first steps of a large-scale metagenomic analysis is to estimate the phylogenetic distribution of the sample. one approach to perform this task is the taxonomic classification of the reads, which is the assignment of these reads into phylogenetic categories  <cit> .

essentially, there are three approaches to classifying sequences into taxonomic categories. one possibility is to focus on conserved gene markers  to identify the source organism of the read. because rrna is well conserved, this approach produces an accurate taxonomic classification of the reads. nevertheless, because only a small fraction of the sequences contain these gene markers, most of the reads of a metagenomic sample cannot be classified using this approach  <cit> .

taxonomic classification can also be based on sequence similarity, that is, the alignment of metagenomic reads to a reference dataset . this approach is an accurate method, as long as a similar sequence is present in the database--which is not always true for metagenomic projects  <cit> . some examples of off-the-shelf software for metagenomic analysis based on sequence similarity are carma  <cit>  and megan  <cit> .

yet another way to perform the taxonomic classification is to rely on a set of features that is induced by the sequences of nucleotides, producing the so-called composition-based classification  <cit> . some features employed in this case are: codon usage, gc content, and oligonucleotide frequency . the latter is usually considered to be a good choice, because the n-mer frequencies carry phylogenetic signals that are useful for extracting common patterns between organisms at different taxonomic levels  <cit> . the following are some examples of software for taxonomic classification based on n-mer frequencies: phylopythia  <cit>  implements a support vector machine for classifying sequences that are larger than  <dig> kbp, phymm  <cit>  uses interpolated markov modes  to classify reads with at least  <dig> bp, tacoa  <cit>  merges the k-nearest-neighbor  algorithm with kernelized learning strategies to handle sequences from  <dig> bp to  <dig> kbp, and treephyler  <cit>  uses hidden markov models  to classify reads of  <dig> bp.

this work focuses on composition-based classification using n-mer frequencies to encode genomic sequences. such an approach involves a series of decisions, regardless of the specific classifier chosen to perform the task. usually, these decisions are based on a set of preliminary experiments that account for one particular type of classifier  <cit> . these studies provide valuable information regarding the performance of a given category of classifier; however, because they are biased by the peculiarities of the classifier of choice, they provide little insight about the characteristics of the classification problem itself. this paper presents a general framework for the empirical assessment of the impact that several decisions have on the degree of separability of taxonomic classes. thus, instead of focusing on any classifier in particular, we focus our study on the classification problem.

here we refer to a specific configuration of the classification problem as the setting induced by the following three features:  the length of the n-mer word used to encode the dna sequences;  the similarity measure adopted to compare the sequences; and  the strategy used to assign sequences to taxonomic classes, which can be the conventional approach, in which the sequences are considered independently, or the hierarchical approach, in which the taxonomic context of each dna fragment is accounted for. the goal of the current work is to serve as a guideline for the development of composition-based metagenomic classifiers by providing some intuition as to how the difficulty of the taxonomic classification problem changes with respect to the variation in the features described above.

methods
acquisition of datasets
we used two types of data:  complete genomes; and  synthetic metagenomic fragments. these datasets are described in the following sections.

complete genomes
the genomes were obtained from genbank, the ncbi database of genetic sequences  <cit> . we used only microbial sequences, because the majority of metagenomic studies are focused on this type of organism  <cit> . we considered all  <dig>   <dig> microbial genomes sequenced until january,  <dig>  among these,  <dig> sequences had to be removed because they had incomplete taxonomic lineage or undefined nucleotides. hence, the actual number of genomes used was  <dig>  which encompassed the domains bacteria and archaea.

synthetic metagenomic fragments
the synthetic fragments were generated by the program metasim  <cit>  using the genomes described above. metasim is a metagenomic sequence simulator that can be used to create sets of synthetic fragments reflecting the taxonomic composition of typical metagenomic scenarios. a total of  <dig>   <dig> fragments with ~ 400bp was generated under the sequencing conditions of roche's  <dig> pyrosequencer  <cit> .

preprocessing of datasets
we now describe how we preprocessed the data to perform our analysis.

calculating n-mer frequencies
to encode the nucleotide sequences we calculated the n-mer frequencies in each genomic sequence. to do so, we counted the number of occurrences of all possible n-mers in a given sequence, considering an overlap of n -  <dig> nucleotides . this strategy gives rise to a 4n-dimensional vector whose elements represent the number of occurrence of each possible n-mer. we then divided the elements of such a vector by the total number of n-mers contained in the sequence. for the experiments with kullback-leibler  divergence we used a slightly different approach to count the n-mers, because the strategy above could lead to a division by zero . in particular, we assumed that each n-mer had occurred at least once, a method usually referred to in the literature as "add-one smoothing"  <cit> . in the end, each sequence is represented by a vector of n-mer frequencies . we will sometimes refer to a vector of frequencies as simply a "sequence" when there is no risk of misinterpretation. figure  <dig> illustrates the process described above.

determining taxonomic lineage
to associate the sequence with its corresponding taxonomic lineage we used the information available at ncbi taxonomy and bioperl, a toolkit for the manipulation of genomic data  <cit> . the result of this process was a vector comprising seven positions that were filled out with ncbi taxids  corresponding to each one of the seven taxa: domain, phylum, class, order, family, genus, and species.

score functions
the next step is implementing a score function, which provides, under a specific configuration, a score for the degree of separability of the taxonomic classes. to formally define this function, we will adopt the following notation. d = {g, f} is the dataset, in which g represents the genomic sequences and f is the metagenomic synthetic fragments. t = {do, ph, cl, or, fa, ge, sp} is the taxon set, which represents the sequence's taxonomic lineage. n = { <dig>   <dig>  . . . , 10} is the set of lengths of n-mers and s = { <dig>   <dig>  ∞, kl} represents the set of similarity measures, where  <dig> is the 1-norm distance ,  <dig> represents the 2-norm  distance , and ∞ is the ∞-norm distance ; kl is the kullback-leibler divergence .

  s1= ∑i=14n|xi-yi|, 

  s2=∑i=14n|xi-yi|21/ <dig>  

  s∞=maxi= <dig> ,...,4n|xi-yi|, 

  skl= ∑i=14nxilnxiyi. 

a ={c, h} is the set of score measures. the element c represents the conventional score measure, in which the configuration is scored considering the sequence separately, and the element h is the hierarchical score measure, in which the configuration is scored with respect to the sequence's taxonomic context . considering this notation the score function is defined as follows:

  f:d×t×n×s×a→ <cit> . 

thus, f  = y represents a score y to the dataset d, considering the taxon t, using a n-mer length of n to encode the sequences and the similarity measure s to check how similar the sequences are and, finally, using the score measure a. in other words, the score y is a measure of the degree of separability of the taxonomic classes in d at level t under the specific configuration induced by n, s, and a.

we now describe how we defined the score measures that were used to evaluate the classification problem.

conventional score measure
we want to assess the "separability" of the taxonomic classes under a given configuration. a straightforward way to do so would be to choose a specific type of classifier and then measure its classification accuracy for each possible combination of values for  . note that in this case we would be measuring the difficulty of the problem under the assumptions made by that specific classifier. for example, if we adopted a linear model such as the naive bayes classifier, then we would be measuring how well classes can be separated by a hyperplane  <cit> . therefore, if we want to make no assumptions regarding the "shape" of the classes, the correct approach would be to use a nonlinear model capable of representing any boundary between the classes . however, such an approach would require an expensive cross-validation process to determine the correct level of complexity of the model under each configuration .

we want a measure of the separability of the classes that can be efficiently computed and at the same time makes no strong assumptions regarding the shapes of the classes. a possible way of solving this problem is to base our measure on this simple observation: given a set of objects that belong to different classes, the level of separability of the classes can be assessed by the fraction of objects whose closest neighbor belongs to the same class. note that, under this criterion, if the boundaries between the classes are well defined, then the set of objects will usually be considered to be separable, regardless of the shape of the classes. therefore, this simple measure is an efficient way of assessing the degree of overlap between classes.

algorithm  <dig> presents a detailed description of the computation of the proposed separability measure. given a configuration , for each sequence in d, we calculate its nearest neighbor  and check whether both sequences belong to the same class at the taxonomic level t. if so, then we add  <dig> to the configuration score. the result is then normalized to fall in the interval  <cit> . we call this approach the conventional score measure.

algorithm 1: conventional_score

/* computes the conventional score for a given set of dna sequences */

input: d ∈ d, t ∈ t, n ∈ n, s ∈ s

output: conventional score

 <dig> score ← 0

2m ← 0

3foreach sequence di ∈ d do

 <dig> if di is not the only representative of its class in d at level t then

 <dig> m ← m + 1

 <dig> dj ← nn ;/* nearest neighbor of di in d using n-mers and measure s */

 <dig> if class = class at taxonomic level t then score ← score + 1

 <dig> return score/m

note that, if a genome is the only representative of its taxonomic group, then its nearest neighbor will necessarily belong to another class, which biases downwards the score measure shown in algorithm  <dig>  for this reason, we classify a genome only if it is not the unique example of its taxonomic class . in the dataset used in our experiments, classes with a single member occur only at the taxonomic level of species. specifically, out of  <dig> genomes used in the experiments,  <dig> were the unique representatives of their species.

as shown in algorithm  <dig>  the conventional score is the percentage of sequences that have the same lineage as their nearest-neighbors at a given taxonomic level. incidentally, this approach is similar to using the k-nearest-neighbor  classifier with k =  <dig>   <cit> . this approach is in accordance with our objective of focusing our analysis on the classification problem, because the 1-nn classifier does not make strong assumptions regarding the shape of the classes  <cit> .

hierarchical score measure
given the hierarchical structure of the taxonomic classification task, one might wonder whether it is a good strategy to decompose the problem into simpler sub-problems that are defined at each taxonomic level. more specifically, instead of using a single classifier, one would have a hierarchy of classifiers that are organized according to the taxonomic tree. in this case, a given dna sequence would be classified as follows: first, a classifier at the highest hierarchical level would determine the domain to which the sequence belongs. then, the dna sequence would be classified at the next hierarchical level, the phylum, with the particular classifier used to do so determined by the domain the sequence was assigned to at one level above. following the same reasoning, the sequence would then be passed on to the classifier that is responsible for the specific phylum that it was assigned to, and so on, until the desired taxonomic level had been reached. this classification strategy has been used before in the literature  <cit> .

note that, to compare the hierarchical scoring measure with the conventional measure, we cannot simply apply algorithm  <dig> at each taxonomic level, because the nearest neighbor of a given sequence defines its classification at all of the taxonomic levels . since we do not want to introduce any bias in our analysis, we must define a score measure that is compatible with our strategy of measuring the separability between classes. this goal can be accomplished as follows. suppose that a given sequence di has been correctly classified at taxonomic level t. then, to classify it one level below in the taxonomic tree, t +  <dig>  we can eliminate all of the

sequences that do not belong to the same class as di at level t. this procedure corresponds to selecting a specific classifier in the hierarchical scheme described above. next, if we remove our initial assumption that di was correctly classified at level t, it is clear that, by eliminating the appropriate sequences of the dataset, an incorrect classification at level t can be followed by a correct classification at level t +  <dig>  this strategy is precisely what allows us to evaluate the hierarchical classification using nothing but the nearest neighbor of each dna sequence.

observe that eliminating the sequences that do not belong to the same class as di at level t corresponds to assuming that di was correctly classified at that level. of course, to have an accurate score function at level t +  <dig>  we must account for the possibility that the sequence was incorrectly classified at level t. clearly, a straightforward way to estimate the probability of a misclassification at level t is to use the score function at that level. therefore, we define the hierarchical score measure recursively: roughly speaking, the hierarchical score at level t corresponds to the product between the conventional score at the same level and the hierarchical score one level above. algorithm  <dig> provides a step-by-step description of how to compute the proposed hierarchical score measure.

algorithm 2: hierarchical_score

/* computes the hierarchical score for a given set of dna sequences */

input: d ∈ d, t ∈ t, n ∈ n, s ∈ s

output: hierarchical score

 <dig> if t =  <dig> then return conventional_score ;/* i.e., if t is "domain" */

2else

3score ← 0

4m ← 0

5foreach sequence di ∈ d do

6d' ← d with only sequences dk which belong to the same class as di at level t - 1

7if |d'| >  <dig> and di is not the only representative of its class at level t then

8m ← m + 1

9dj ← nn

10if class = class at taxonomic level t then score ← score + 1

11return score/m * hierarchical_score

using algorithm  <dig>  one can assess the degree of separability of taxonomic classes under a hierarchical classification scheme without making any strong assumptions regarding the shape of the classes. therefore, the result of such an analysis applies to any set of classifiers, including a heterogeneous hierarchy composed of classifiers of different types.

RESULTS
as described above, in this work we assume that a given configuration of the taxonomic classification problem is defined by:  n, the length of n-mers used to encode the sequences;  s, the similarity measure used; and  a, the score measure, which can be the conventional measure or the hierarchical measure . to provide an empirical basis for the development of composition-based metagenomic classifiers, we analyzed the separability of taxonomic classes under different configurations of the classification task.

we performed  <dig> *  <dig> *  <dig> =  <dig> experiments with the genomic dataset and  <dig> *  <dig> *  <dig> =  <dig> experiments with the synthetic metagenomic fragments data ). in total, we performed  <dig> +  <dig> =  <dig> experiments. our analysis addresses the impact of parameters n, s, and a over the configuration scores. although we also discuss other taxonomic levels, we focus our analysis on the classification problem at the taxon species.

complete genomes
the genomic dataset comprises  <dig> genomes encompassing  <dig> different species. considering the conventional score measure, the configuration scores for this type of data at the level of species varied from f  =  <dig> , for the worst configuration, to f  =  <dig> , for the best configuration. the hierarchical scores varied between f  =  <dig>  and f  =  <dig> .

observe also that from n =  <dig> to n =  <dig> the scores decrease slightly. this decrease is a consequence of the fact that, when n ≥  <dig>  the number of possible n-mer sequences is very large, which results in sparse frequency vectors with a low discriminative power. for example, if the similar sequences di = aaatggta and dj = agatggta are encoded with n =  <dig>  the result is two vectors with  <dig>   <dig> positions filled with zeros in all but one position, which would contain a "1" representing the words di and dj. hence, we have two extremely similar sequences represented by two different frequency vectors, which clearly disrupts the score function f.

concerning the two score measures, the hierarchical approach presented slightly better performance than the conventional score, as shown in figures  <dig> and  <dig>  this relationship suggests that decomposing the classification task into smaller sub-problems does indeed make the problem easier.

synthetic metagenomic fragments
the synthetic dataset comprises  <dig>   <dig> fragments with approximately 400bp. as mentioned previously, these sequences were generated with the sequences simulator metasim  <cit>  under the sequencing conditions of the  <dig> pyrosequencer. the configuration scores at the level of species varied between f =  <dig>  and f =  <dig>  for the conventional score function, and between f =  <dig>  and f =  <dig>  when the hierarchical measure was considered.

again, changing the similarity measure s did not have a significant impact on the scores. note, however, that with metagenomic fragments the use of s = ∞ has a degenerating impact over the scores which is more noticeable than the trend observed in the case of complete genomes . figure  <dig> shows the conventional and hierarchical scores as a function of n when the kl divergence is adopted as the similarity measure. here we observe curves similar to the curves shown in figure  <dig>  with the peak of each curve shifted slightly to the left. this change makes sense, because with shorter sequences the "sparsification" of frequency vectors discussed in the previous section occurs at smaller values of n. additionally, note how the conventional scores of the metagenomic dataset are low at the taxonomic level of order and below. this trend suggests that using a single classifier in this case might not be the best alternative. such an observation could be particularly helpful in the future development of composition-based classifiers, because one of the major problems with real metagenomic projects is the difficulty of obtaining accurate classification at lower taxonomic levels  <cit> .

in summary, we observed that the scores associated with metagenomic data are in general smaller than the scores generated with genomic data, and using a hierarchical classification approach in this case appears to be even more beneficial. moreover, the value of n that generated the best results decreased from n ≈  <dig> to n ≈  <dig>  which indicates that, when dealing with metagenomic fragments with approximately 400bp, there is no point in using frequency vectors that have a dimension much higher than  <dig> 

discussion
in this section we summarize the results presented in the previous sections and provide an overview of our analysis. to accomplish those goals, we show in figure  <dig> the scores that were generated with the genomic data at the level of species as a function of n and s, and in figure  <dig> we show the same information for the scores generated with the metagenomic dataset. from examining these figures, we arrive at the following conclusions:

• the scores are an approximately concave function of n with a maximum value that is between  <dig> and 7; the "optimal" value of n is smaller for the metagenomic dataset.

• changing the similarity measure s does not have a strong effect on the scores.

• the hierarchical classification scheme appears to be a better alternative for both genomic and metagenomic data; however, in the latter case, its advantage over the conventional classification approach is more evident.

• in general the scores that are associated with the metagenomic data are smaller than the scores that are associated with the genomic data, but the difference is more significant under the conventional classification scheme.

in conclusion, we show in table  <dig> the configurations that produced the best results in both datasets. the values shown in table  <dig> can serve as a starting point in the development of composition-based metagenomic classifiers.

n
s
score
n
s
score
the scores were produced considering both score measures and both datasets, at the species taxonomic level.

CONCLUSIONS
taxonomic classification is an essential step within a metagenomic study, since this is the first step of a metagenomic analysis and its result is used as a basis to posterior investigations. usually, composition-based metagenomic classifiers are configured based on preliminary experiments that account for a specific type of classifier. in this work we proposed to shift the focus of the analysis to the classification task itself. to make this shift, we presented a general framework that can be used to study the impact of several decisions on the difficulty of the classification problem .

in this work we focused the analysis on the impact of three factors in particular:  the length of the n-mers used to encode the dna sequences;  the similarity measure used to compare frequency vectors; and  the underlying classification scheme . the results presented provide some intuition on how the difficulty of the classification problem changes as a function of the features above. because our analysis does not assume any structure of the classification problem, it can be used as a guideline for the development of composition-based metagenomic classifiers of any type. moreover, the framework presented in this work can be used for the analysis of the impact of other factors over the taxonomic classification task.

competing interests
the authors declare that they have no competing interests.

authors' contributions
sh performed the experiments, helped in the interpretation of the results, and wrote the manuscript. amsb analyzed and interpreted the results, and helped in writing the manuscript. mec helped in the experiments, and reviewed the manuscript. atrv reviewed the manuscript, and conceived the project. all of the authors have approved the final version to be published.

