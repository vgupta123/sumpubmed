BACKGROUND
exploring the interactions between proteins and rnas can help us to understand the mechanisms of life, such as the protein translation process , gene expression  <cit> , rna post-transcriptional modification , cellular regulation  <cit> .

a lot of effort has been put on the identification of pris using traditional experimental methods and post-experimental methods. as experimental methods consume more time and money than post-experimental methods, the latter is gaining more and more attention. there are mainly two categories of post-experimental methods: 1)structural & chemical-based methods and 2)computational methods.

the first category of methods attempted to analyze the interacting mechanism of protein and rna at structural and chemical levels. for example, jones et al.  <cit>  focused on analyzing protein-rna complexes, and obtained the physical-chemical properties of rna-binding residues and the distribution of atom-atom within the complexes. with protein-rna experimental data, ellis et al.  <cit>  presented a statistics on properties of binding residues bounding to functional various rnas. besides, some function-based works  <cit>  also discussed the protein-rna interactions.

as for computation-based methods, several machine learning techniques have been employed on identifying pris, such as random forest , naive bayes  and support vector machine . pancaldi et al.  <cit>  used rf and svm for identifying pris by considering more than  <dig> properties of rnas and proteins. instead, muppirala et al.  <cit>  used only protein and rna sequence information for predicting interactions. similarly, wang et al.  <cit>  improved the naive bayes  classifiers for predicting pris with only sequence data. recently, we also proposed learning method  <cit>  with only positive and unlabeled samples on pris prediction.

compared with structural & chemical-based methods, computational methods are more efficient and effective. however, the performance of computational methods heavily depends on the quality of training datasets, which usually consist of positive samples and negative samples. here, positive samples are not the problem. the difficulty lies in that we do not have experimentally-validated negative samples. current works  <cit>  addressed this problem by randomly pairing rnas and proteins and then removing these pairs included in the positive set. in this paper, we call this method random method or traditional method. obviously, random negative samples must not be real negative samples. so the quality of random negative sets cannot be guaranteed. this will unavoidably impact prediction performance of classifiers trained on datasets with random negative samples.

this paper addresses how to select highly reliable negative samples to improve pri prediction. to this end, we present an effective method fire — the abbreviation of finding reliable negative samples). the basic idea of our method is like this: given a known pri of protein i and rna j, for a protein k, the more difference between protein i and protein k, the less possibility that protein k interacts rna j.

we first construct positive sets using known pris. given a positive set, we establish two negative sets: one is by random method and the other by our method. and the positive set is combined with each of the two negative sets to form a dataset for model training and performance evaluation. in such a way, we construct  <dig> datasets of different species and different ratios of negative samples to positive samples. then, we extract the features of each pair of protein and rna. here, each feature is composed of a conjoint triad of vicinal amino acids and a k nucleotide acids. to cutoff computational cost, a filter-based feature selection method is employed to reduce the dimensionality of feature vectors. finally, we conduct extensive experiments to evaluate the proposed method by training and testing svm, rf and nb classifier on the  <dig> datasets. the experimental results show that these classifiers perform much better using the negative samples generated by our method than using random negative samples.

methods
we collected non-redundant known pris as positive samples, and generated  <dig> datasets based on our method and the random method, which were used to evaluate the performance of pri prediction by svm, rf and nb classifiers. figure  <dig> is the procedure of our method, which contains five steps: 1) generating negative datasets by using our method fire and the random method; 2) constructing feature vectors for each pair of protein-rna; 3) reducing the dimension of feature vectors; 4) training classifiers; 5) performance evaluation.
fig.  <dig> the framework of this work. here, rectangles are executive modules, and parallelograms are data modules




datasets
we constructed  <dig> non-redundant positive pri sets from pridb  <cit> , npinter  <cit> ,  <dig> reliable negative sets based on the positive sets and the string  <cit>  database by our method, and  <dig> random negative sets with the random method. the procedure for negative sample construction will be detailed later. each positive set is merged with a negative set to construct a pri dataset, consequently  <dig> pri datasets in total are constructed. pridb is a database of protein-rna interfaces calculated from protein-rna complexes in pdb  <cit> . npinter is a complete database covering eight-category functional interactions between proteins and noncoding rnas of six model organisms, including caenorhabditis elegans, drosophila melanogaster, escherichia coli, homo sapiens, mus musculus and saccharomyces cerevisiae. string is an updated online database resource search tool for the retrieval of interacting genes, it provides uniquely comprehensive coverage and ease of access to both experimental and predicted protein-protein interaction  information.

the  <dig> datasets are divided to  <dig> groups. the first group of datasets  contain  <dig> experimental-validated pris that are used as positive samples, which are related to the six organisms above and constructed from the npinter and string databases. this group consists of six sub-datasets  as follows: 
the first sub-dataset  contains  <dig> positive samples and  <dig> reliable negative samples generated by our method, the ratio of positives to negatives is 1:1;

the second sub-dataset  contains  <dig> positive samples and  <dig> reliable negative samples, the ratio is 2:1;

the third sub-dataset  contains  <dig> positive samples and  <dig> reliable negative samples, the ratio is 1:2;

the fourth sub-dataset  contains  <dig> positive samples and  <dig> random negative samples generated by the random method, and the ratio of positives to negatives is 1:1;

the fifth sub-dataset  contains  <dig> positive samples and  <dig> random negative samples, the ratio is 2:1;

the last sub-dataset  contains  <dig> positive samples and  <dig> random negative samples, the ratio is 1: <dig> 




the second group of datasets  includes  <dig> experimental-validated homo species pris used as positive samples, which are extracted from the pridb and string databases, it also consists of six sub-datasets. following the nomenclature of the first group of datasets, these pri datasets are named as homo_reliable
1: <dig>  homo_reliable
2: <dig>  h
o
m
o _reliable
1: <dig>  homo_random
1: <dig>  homo_random
2: <dig> homo_random
1: <dig> 

the third group of datasets  has  <dig> experimental-validated mouse pris as positive samples, which also consists of six sub-datasets: mus_reliable
1: <dig>  mus_reliable
2: <dig>  mus_reliable
1: <dig>  mus_random
1: <dig>  mus_random
2: <dig>  mus_random
1: <dig> 
table  <dig> the  <dig> pri datatsets used in this paper


so_reliable
1:1

so_reliable
2:1

so_reliable
1:2

so_random
1:1

so_random
2:1

so_random
1:2

homo_reliable
1:1

homo_reliable
2:1

homo_reliable
1:2

homo_random
1:1

homo_random
2:1

homo_random
1:2

mus_reliable
1:1

mus_reliable
2:1

mus_reliable
1:2

mus_random
1:1

mus_random
2:1

mus_random
1:2



construction of random negative samples
previous works  <cit>  randomly select negative samples, the underlying hypothesis is: if there is no validated interaction between a protein and a rna, then the protein and the rna constitute a negative sample. obviously, the hypothesis is not completely reasonable. the flowchart for generating random negative samples is shown in fig.  <dig> 
fig.  <dig> the flowchart of constructing random negative samples




in fig.  <dig>  the major steps of the random method are as follows: 
each pri extracted from pridb and npinter is included in the positive set. from the positive set, we can get a set p of proteins and a set r of rnas, each protein/rna in p/r is involved in at least a positive pri.

for each protein p in p and each rna r in r, there is a corresponding protein-rna pair .

if  is not included in the positive set, it is a negative sample.

the positives and negatives are merged to a pri dataset.




construction of reliable negative samples
the basic idea of our method is like this: for an experimentally-validated pri of protein p and rna r, r is highly possible to interact with any protein p
′ similar to p. on the contrary, if protein p
′ is dissimilar to p, there is low possibility that p
′ interacts r. based on this idea, we propose the method fire to construct reliable negative pris. the flowchart of fire is shown in fig.  <dig>  concretely, for each positive pri , we try to find any protein p
′ that is as much dissimilar as possible to p. if  is not an experimentally-validated pri, then it is selected as a negative pri.
fig.  <dig> the flowchart of constructing reliable negative samples




we first compute the similarity between each pair of proteins based on three different data sources, then we combine these similarity scores as a final score to measure the similarity between the two proteins. detail is delayed to “protein-protein similarity computation” section.

the procedure of our method fire is as follows: 
construct the positive set ps of pris based on the pridb and npinter databases, and compute the similarity matrix sp of proteins involved in ps as in “protein-protein similarity computation” section.

for protein p
i and rna r
j that do not form a positive pri in ps, i.e.,  ∉ps, compute a score between p
i and r
j as follows: 
if protein p
k  and r
j forms a pri in the positive pri set ps, then the score spr
ijk indicating the confidence of  being a positive pri via protein p
k can be evaluated via sp
ik, which is the similarity between p
i and p
k.

as there may be multiple  positive pris involving r
j in ps, we aggregate the scores spr
ijk over all positive pris   as follows: 
  <dig> sprij=∑k=1nsprijk=∑k=1nδ×spik, 



spr
ij indicates the confidence of  being a positive pri, δ= <dig> if  is a positive pri, otherwise  <dig> 




as  ∉ps, it is a potential negative pri. sorting all generated potential pris  via their scores spr
ij in increasing order, the top-m protein-rna pairs in the sorted list are taken as negative pris if m negative pris are to be generated.




protein-protein similarity computation
we compute the similarity between any two proteins involved in the positive set based on three types of data sources: sequence information, functional annotations and protein domains, these computed similarities are called sequence similarity, functional annotation semantic similarity and protein domain similarity, which are merged to get the final similarity of the two proteins.


sequence similarity . protein sequences are obtained from the uniprot database  <cit> . we compute sequence similarity between two proteins using a normalized version of smith-waterman score  <cit> . the normalized smith-waterman score between two proteins p
i and p
j is nsw=sw/swsw where sw means the original smith-waterman score. by applying this operation to protein pair p
i and p
j, we can obtain their sequence similarity ss= + nsw)/ <dig> 


functional annotation semantic similarity . go annotations are downloaded from the go database  <cit> . semantic similarity between each pair of proteins is calculated based on the overlap of the go terms associated with the two proteins  <cit> . all three types of go are used in the computation as similar rnas are expected to interact with proteins that act in similar biological processes, or have similar molecular functions or reside in similar cell compartments. we compute the jaccard value  <cit>  with respect to the go terms of each pair of proteins as their similarity. the jaccard score between term sets t
i and t
j of proteins p
i and p
j is defined as |t
i∩t
j|/|t
i∪t
j|, which is the ratio of the number of common terms between proteins p
i and p
j to the total number of terms of p
i and p
j, which is used as the functional annotation semantic similarity fs of proteins p
i and p
j.


protein domain similarity . protein domains are extracted from pfam database  <cit> . each protein is represented by a domain fingerprint  whose elements encode the presence or absence of each retained pfam domain by  <dig> or  <dig>  respectively. we compute the jaccard value of any two proteins p
i and p
j with their domain fingerprints as their similarity ds.

for proteins p
i and p
j, we compute the aggregated similarity  by merging the three different similarity measures above as follows: 
  <dig> as=+fs+ds)/ <dig>  


pri feature vectors
existing works  found that properties of amino acids are effective in protein classification. to reduce the dimensionality of protein representation, shen et al.  <cit>  classified the  <dig> amino acid residues as seven classes according to their physicochemical properties, meanwhile the concept of conjoint triads were also proposed to represent the protein properties. wang et al.  <cit>  further reduced the dimension of feature vector by encoding the  <dig> amino acids residues into four classes: {de}, {hrk}, {cgnqsty}, and {afilmpvw}. in this work, we use the same strategy for encoding protein sequences.

feature construction
to compute protein feature vectors, we used conjoint triads as protein properties as in  <cit> .  <dig> continuous amino acids constitute a conjoint triad, we can get  <dig>  classes of conjoin triads. note that two triads are treated as the same class if their residues in the corresponding positions belong to the same class. for rna sequences, we used k-nucleotide acids  as properties. a k-nas refers to a unit of k continuous nucleotide acids. k-nas of size  <dig>  are called “uninas”, size  <dig>  are called “binas”, size  <dig>  are called “trinas”, size  <dig> or more  are simply called “k-nas”. because rna sequences contain only the four bases a, u, c, g, we have  <dig> unique uninas,  <dig> unique binas and  <dig> unique trinas. finally, by pairing the k-nas  and triads, we can get at most  <dig>  4-mers,  <dig>  5-mers and  <dig>  6-mers, each of which is composed of a conjoint triad and a unina, bina and trina respectively. in the sequel, we also call 4-mers, 5-mers, 6-mers as type  <dig>   <dig>   <dig> -mers.
table  <dig> an example of feature extraction for a pair of protein and rna sequences

d
p
p
v
p
p
p
p
p
v
c
c
u
c
u



feature value computation
in order to discriminate the significance of different types of features in a feature vector, we introduce the concept of concentration of different features. denote the number of unique -mers of type i as n
i. the concentration of type i is the ratio of n
i to the total number of unique -mers, that is, 
  <dig> ci=ni∑j=13nj,i= <dig> , <dig>  


for example, the number of unique 6-mers is 64× <dig>  the total number of unique -mers used in this study is  <dig>  therefore the concentration of 6-mers is c
3=4096/5376= <dig> . then, the elements of a feature vector are calculated by 
  <dig> fj=tj×ci,1≤j≤ <dig> 


above, t
j is the occurrence frequency of a certain unique -mer of type i. a feature vector contains  <dig> dimensions, each of which corresponds to a unique -mer of a certain type i . within a vector, the dimensions are arranged in the order of 6-mers, 5-mers and 4-mers. then f
i is further normalized to ff
i as follows: 
  <dig> ffj=fj−fminfmax−fmin 


where f
max and f
min denote the maximum and the minimum of all f
j , respectively.

feature reduction
in order to reduce the computational cost, we employed a filter-based method for cutting down the dimension of feature vectors.

for the i-th feature ff
j of the j-th vector, let fp and fn denote its occurrence frequency in the positive and negative sample set respectively, which are calculated by 
  <dig> fp=∑j=1nffj,vectorj∈thepositiveset, 



  <dig> fn=∑j=1mffj,vectorj∈thenegativeset, 


where n and m are the numbers of positives and negatives in the dataset.


fp and fn are further normalized to ffp and ffn as in eq. , and then the final score of each feature is defined as follows: 
  <dig> fscore=ffpffn,i= <dig> ,…, <dig>  


our objective is to choose those discriminative features that either frequently occur in the positive set but seldom occur in the negative set, or frequently occur in the negative set but rarely occur in the positive set. in such a way, we choose the features that help us to distinguish positive samples from negative samples.

as fscore measures the relative enrichment of the i-th feature in the positives over the negatives, it can be regarded as an indicator of the usefulness of the i-th feature. based on the calculated fscore values, the most “useful” features that have the largest or smallest fscore values are selected to represent the pri pairs. suppose that we reduce the pri vectors to k dimensions, we select the k <dig> features with the largest fscore values and the k <dig> features with the smallest fscore values to represent the k-dimension pri vectors. in our work, k is set to  <dig> 

the classifiers and performance metrics
as several studies have successfully used random forest , naive bayes  and support vector machine  to predict pris , we also use them to evaluate our method by 10-fold cross validation.

four widely-used performance metrics, sensitivity , specificity , accuracy  and geometric mean  are used in this paper. gm is commonly used for class-imbalance learning  <cit>  because it can give a more accurate evaluation on imbalanced data. therefore, for the imbalance datasets, we pay more attention to gm rather than acc. these metrics are evaluated as follows: 
  <dig> se=tptp+fn, 



  <dig> sp=tntn+fp, 



  <dig> gm=se×sp, 



  <dig> acc=tp+tntp+fn+tn+fp, 


where tp is the number of true positives, tn is the number of true negatives, fp is the number of false positives, and fn is the number of false negatives.

in addition, we also use auc  curve) to evaluate prediction performance in some experiments. auc falls between  <dig> and  <dig>  the maximum value  <dig> means a perfect prediction. for a random guess, the value of auc is close to  <dig> .

RESULTS
in our experiments, eighteen pri datasets are used, these datasets either contain pri data of different species or have different ratios of positive pris to negative pris. for each dataset, 10-cross validation is performed on svm, rf and nb classifiers respectively, and the performance metrics of se, sp, gm and acc as well as auc are used.

in the sequel, for the simplicity of notation, we denote the ratio of positive samples to negative samples as pnr, and remove the words “reliable” and “random” from the dataset names in table  <dig>  for example, both so_reliable
1: <dig> and so_random
1: <dig> are simplified to so
1: <dig>  in other words, so
1: <dig> represents both so_reliable
1: <dig> and so_random
1: <dig> 

performance comparison
figures  <dig>   <dig> and  <dig> respectively show the performance comparison between using our reliable negative samples and using random negative samples on the so datasets, homo datasets and mus datasets.
fig.  <dig> experimental results on so datasets. a–d are the se, sp, gm and acc values of svm classifiers; – are the se, sp, gm and acc values of rf classifiers; and – are the se, sp, gm and acc values of nb classifiers


fig.  <dig> experimental results on homo datasets. a–d are the se, sp, gm and acc values of svm classifiers; – are the se, sp, gm and acc values of rf classifiers; and – are the se, sp, gm and acc values of nb classifiers


fig.  <dig> experimental results on mus datasets. a–d are the se, sp, gm and acc values of svm classifiers; – are the se, sp, gm and acc values of rf classifiers; and – are the se, sp, gm and acc values of nb classifiers




to more clearly evaluate the advantage of reliable negative samples over random negative samples, we define the performance improvement ratio  of using our reliable negatives over using random negatives as follows: 
  <dig> ir=resultreliable−resultrandmresultrandom×100%, 


where result
reliable and result
random denote the performance measure  of using our reliable negatives and using random negatives, respectively. a positive ir means using our reliable negatives achieves better performance than using random negatives. table  <dig> shows the ir values calculated based on the results in figs.  <dig>   <dig> and  <dig> 
se
sp
gm
acc
se
sp
gm
acc
se
sp
gm
acc

so
1:1

so
1:2

so
2:1

homo
1:1

homo
1:2

homo
2:1

mus
1:1

mus
1:2

mus
2:1



from table  <dig>  we can see that out of the  <dig> ir values, only  <dig> irs are negative, one is  <dig>  the other  <dig>  values are positive. as gm and acc are more comprehensive than se and sp in measuring classification performance, we check their ir values more carefully. of the  <dig> ir values for ge and acc,  <dig>  values are positive. therefore, in most cases performance measure of our method is better than the random method. the largest ir is  <dig> %, which is achieved for se by svm on dataset mus
1: <dig>  we can also see that svm and rf perform better than nb on these datasets.

the results above show that using the reliable negative samples selected by our method indeed boosts the performance of pri prediction, and our method can serve as a practical and effective method for computationally predicting pris.

the effect of score threshold
to select negative samples, we have to set a score threshold, and require that all candidate negative samples  have scores ) no larger than the threshold. so the value of threshold will impact the quality of selected negative samples, and will subsequently impact the prediction performance. the smaller the threshold, the higher the quality of selected negatives, and the smaller the number of negatives that can be selected. so there is a tradeoff between the quality and the number of selected negatives. in this part, we check the impact of score threshold on prediction performance and thus suggest proper values for the threshold. here, we use auc to evaluate prediction performance.

we randomly select  <dig> nonredundant positive pris of homo sapiens from pridb and npinter, then construct an equal number of negative samples by our method with different score threshold values. concretely, we generate negative samples like this: give a threshold value st , we select  <dig> protein-rna pairs whose scores are closest to st. thus, we construct five pri datasets. finally, we evaluate the auc values of three classifiers rf, svm and nb on the five constructed datasets by 10-fold cross validation. figure  <dig> shows the results. as we can see, for all the three classifiers, with the increase of threshold value, the auc value shows a decreasing trend, which conforms to our expectation. and when the score threshold is less than  <dig> , the prediction performance is stable.
fig.  <dig> auc vs. score threshold 




capability of finding new positive pris
in this paper, we define a score ) to measure the relationship between each protein and each rna. the smaller the score, the more possible this protein-rna pair is a negative pri. otherwise, the more possible it is a pri. so the merits of our method are two-fold. on the one hand, we can use it to select highly credible negative pris; on the other hand, it can be used to directly predict positive pris.

we randomly select  <dig> nonredundant positive pris of homo sapiens from pridb and npinter, and compute the score of any protein-rna pair not included in the positive set by our method. among the screened protein-rna pairs, for each rna we extract the top  <dig> protein-rna pairs in terms of the aggregated score as defined in eq.  and requiring as> <dig>  then we get  <dig> protein-rna pairs involving  <dig> unique rnas and  <dig> unique proteins. we search each protein-rna pair against the npinter and pridb datasets, and find that  <dig> pairs have been validated by biological experiments.

furthermore, from the  <dig> protein-rna pairs gotten above, we filter out those pairs whose proteins appear in pris of the npinter and pridb datasets, and get  <dig> protein-rna pairs involving  <dig> unique rnas and  <dig> unique proteins. then we annotate manually the  <dig> proteins in the  <dig> protein-rna pairs by the gene ontology database, and we find that  <dig>  proteins have rna binding, chromatin binding or nucleotide binding functions, which play important roles in positive or negative regulation of transcription, gene expression and rna processing.
fig.  <dig> the pri network constructed by true pris and predicted ones by our method.  <dig> predicted pris consist of  <dig> unique proteins and  <dig> unique rnas. the yellow ellipses and purple diamonds represent proteins and rnas, respectively. the solid and dotted lines are the true and predicted pris




CONCLUSIONS
in this paper, we present a novel method fire for boosting the performance of protein-rna interaction prediction by selecting high-quality negative protein-rna pairs to construct high-performance classifiers. experiments over  <dig> pri datasets show that the three compared classifiers, including svm, rf and nb all achieve better performance on the negative sets selected by our method than on the random negative sets. this means that our method can screen highly-credible negative pris, and thus can improve pri prediction performance. as for future work, we will further explore the interacting mechanism between protein and rna, and propose new and more effective methods to select reliable negative samples.

not applicable.

declarations
this article has been published as part of bmc systems biology volume  <dig> supplement  <dig>   <dig>  selected articles from the 15th asia pacific bioinformatics conference : systems biology. the full contents of the supplement are available online https://bmcsystbiol.biomedcentral.com/articles/supplements/volume-11-supplement- <dig> 

funding
national natural science foundation of china   for the design of the study, data generation and analysis, manuscript writing, and publication cost; the national key research and development program of china  for data collection and analysis; nsfc  and the program of shanghai subject chief scientist  for data interpretation and manuscript writing.

availability of data and materials
the datasets used and/or analysed during the current study available from the corresponding author on reasonable request.

authors’ contributions
sz conceived and supervised the research, and revised the manuscript. zc implemented the proposed method, carried out the experiments, did most data analysis, and drafted the manuscript. kh did some data analysis. yw prepared datasets and implemented some compared methods. hl and jg participated discussions and manuscript revision. all authors read and approved the final manuscript.

competing interests
the authors declare that they have no competing interests.

consent for publication
not applicable.

ethics approval and consent to participate
not applicable.
