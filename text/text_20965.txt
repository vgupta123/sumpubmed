BACKGROUND
physical systems are constrained to operate according to the fundamental laws of thermodynamics. the conservation of mass and energy and the production of entropy  dictate that certain events are physically impossible. a broken glass, for example, will not spontaneously reassemble, and a bar of gold will not fortuitously appear from thin air. not all physical constraints imposed by thermodynamics are intuitively obvious. as a matter of fact, thermodynamic constraints imposed on biochemical reaction systems are routinely overlooked in the literature, either due to ignorance of their existence or difficulties in understanding the implications of modern non-equilibrium thermodynamics. there is an increasing consensus, however, that care must be taken to ensure that the kinetic parameters of a biochemical reaction system meet these thermodynamic constraints  <cit> .

there are many publications discussing the problem of estimating the kinetic parameters of a biochemical reaction system from experimental data of molecular concentrations, when the underlying stoichiometry is known  <cit> . essentially, all approaches to this problem, which is often referred to as model calibration, are based on deriving a cost function and choosing an optimization algorithm to minimize that function  <cit> . the cost function provides a measure of 'goodness of fit' of the estimated biochemical reaction system dynamics to available observations, and may be designed by a variety of statistical inference techniques, such as maximum likelihood, bayesian inference, etc., or by simply employing an appropriate distance metric, such as least-squares. the optimization procedure used must be characterized by superior performance for finding global minima, due to the highly non-convex and multi-modal nature of the cost function  <cit> . the vast majority of published model calibration methods, however, produce biochemical reaction systems that may not be physically realizable, since they do not take into account the fact that the underlying kinetic parameters may be constrained by the fundamental laws of thermodynamics.

recently, there have been several attempts to address the issue of thermodynamic constraints in chemical kinetics  <cit> . among proposed methods, the thermodynamic-kinetic modeling  approach  <cit>  enjoys some benefits over other techniques. however, we have previously noted in  <cit>  that this approach is unnecessarily complicated and can be cumbersome, especially when dealing with molecular perturbations  or when merging estimated tkm models  <cit> .

to address these problems, we have recently proposed two techniques for estimating the kinetic parameters of closed biochemical reaction systems from available observations of molecular concentrations in a thermodynamically consistent fashion  <cit> . in  <cit> , we model biochemical reaction systems by mass-action kinetics, use maximum-likelihood estimation, and employ a projection step that allows us to appropriately choose kinetic parameter values so that the final system is thermodynamically feasible. in  <cit> , we employ a bayesian inference approach, eliminate the projection step, and derive a biophysically based cost function over parameters that can be chosen independently without violating the underlying thermodynamic constraints. unfortunately, both methods are limited, being applied to closed biochemical reaction systems using standard mass action kinetics.

in this paper, we propose a method for calibrating the kinetic parameters of biochemical reaction models of cellular function so that the resulting systems are thermodynamically feasible. the method, which we refer to as thermodynamically consistent model calibration , works with any iterative parameter estimation algorithm of choice and can be applied to open biochemical reaction systems, which, in problems of systems biology, are more realistic than the closed systems we considered previously. furthermore, tcmc is capable of handling any kinetic rate laws in ideal mixtures, such as non-mass action rate laws commonly used to describe complex enzymatic reaction schemes.

we exemplify practical aspects of the proposed technique by recalculating the kinetic parameters of a well-known model of the egf/erk signaling cascade  <cit> , which is thermodynamically infeasible. this allows us to propose a thermodynamically feasible model for this important signaling pathway that is physically realizable and better matches available densitometric data. computer simulations reveal a number of qualitative and quantitative differences of possible biological significance between the thermodynamically feasible and the thermodynamically infeasible published model, which need to be validated experimentally. moreover, we discuss a number of important advantages gained by tcmc over estimating the kinetic parameters using a collective fitting approach that does not consider the underlying thermodynamic constraints. besides producing physically realizable and thermodynamically consistent models, tcmc may result in dimensionality reduction, better estimation performance, and lower computational complexity. matlab software, using the systems biology toolbox  <dig>  http://www.sbtoolbox <dig> org, can be accessed from http://www.cis.jhu.edu/~goutsias/csslab/software.html. an sbml file containing the thermodynamically feasible egf/erk signaling cascade model can be found in the biomodels database http://www.ebi.ac.uk/biomodels-main.

we believe that tcmc can be effectively used to recalculate the parameter values of any existing thermodynamically infeasible biochemical reaction model of cellular function, as well as to estimate the parameters of new biochemical reaction models from available experimental data, thus producing physically plausible versions of these models compatible with the fundamental laws of thermodynamics. finally, as more chemical species or reactions are discovered, tcmc can be used to easily extend existing models of cellular activity in a thermodynamically consistent and computationally efficient fashion.

RESULTS
biochemical reaction systems
most biological processes of interest to systems biology are modeled by means of open biochemical reaction systems; i.e., systems that exchange mass with their surroundings  <cit> . living cells, for example, are open systems maintaining themselves by exchanging materials with their environment. mass exchange is modeled either explicitly or implicitly. examples of explicit modeling include: clamped species, reactions with null species as reactants or products, and irreversible reactions  <cit> . clamped species are chemicals whose concentrations are held fixed. they are often used to model molecular species whose concentrations are affected by unknown reactions. it is apparent that these chemicals must be supplied or removed from the system at appropriate rates to ensure that their concentrations do not deviate from their fixed values. on the other hand, reactions with null reactants or products model mass transfer in and out of the system, respectively. finally, the use of an irreversible reaction is based on the assumption that the concentration of at least one of its products is clamped to zero , which implies mass transfer as well. an example of implicitly modeling mass exchange is a reaction with reactants or products not modeled by the system. a common case would be the phosphorylation of a protein without explicitly modeling conversion of atp to adp  <cit> .

an open biochemical reaction system is comprised of n molecular species x <dig>  x <dig> ..., xn that interact through m coupled reactions, given by  

where , ℳ: = { <dig>   <dig> ..., m}, and νnm,  are the stoichiometries of the reactants and products. we can characterize an open biochemical reaction system at time t ≥  <dig> by the concentrations  of all molecular species at t. clamped molecular species  have concentrations that do not vary with time, whereas, the concentrations of the remaining 'dynamic' species  evolve as a function of time. we will assume that the system characterizes reactions in an ideal and well-stirred  mixture at constant temperature and volume and that the concentrations  vary continuously in time. in this case, we can describe the dynamic evolution of the molecular concentrations in the system by the following chemical kinetic equations:   

initialized by setting xn = qn, , for some initial concentrations qn, , where ϕm is the net flux of the mth reaction,  is the net stoichiometry coefficient of the nth molecular species associated with the mth reaction,  is an observation time window of interest, and k is a vector of kinetic parameters , where . the parameters k characterize the biochemical reaction system at hand and are independent of the molecular concentrations . moreover, we assume that these parameters do not vary with time.

by appropriately pruning and modifying an open biochemical reaction system, we can derive a closed subsystem  that lends itself to thermodynamic analysis since external or unknown thermodynamic forces no longer exist. to do so, we first remove all null and irreversible reactions, as well as partially modeled reactions . next, we remove clamping of molecular species involved in reversible reactions. subsequently, we keep only reactions that are thermodynamically independent. thermodynamic independence among reactions means that a reaction is only driven by its own thermodynamic force, which implies that the affinity of the reaction will be zero if and only if there is no change in its degree of advancement. this condition is usually fulfilled if we keep only elementary reactions . as a consequence, we obtain a closed reaction set ℳ <dig> ⊆ ℳ. finally, we remove all species that are no longer involved with any of the reactions in ℳ <dig>  leaving only the molecular species  associated with the closed subsystem.

the main rationale behind the second step is that the kinetic parameters k considered in this paper are assumed to be independent of the molecular concentrations. as a consequence, the values of these parameters will not change if the concentrations of the clamped species are allowed to vary. therefore, we can construct a  situation in which the concentrations of the clamped species vary as if they were dynamic species. because our goal in creating the closed subsystem is to discover and enforce thermodynamic constraints on the kinetic parameters, we must include the clamped species in our model. this is contrary to simply removing all clamped species and the associated reactions, since this approach will not allow us to determine thermodynamically feasible values for the kinetic parameters of the removed reactions.

the third step is due to a simplification imposed on us by the current state of non-equilibrium thermodynamics. thermodynamically dependent reactions influence each other, since the thermodynamic force of one reaction may drive the other reaction and vice versa. unfortunately, it is not clear at this point how to deal with thermodynamically coupled reactions. future research may be necessary to address this issue.

the resulting closed biochemical reaction subsystem is comprised of n <dig> molecular species  that interact through m <dig> coupled reversible reactions. the dynamic evolution of the molecular concentrations in this system is governed by:   

initialized by xn = qn, for . we will characterize all reactions in ℳ <dig> by the generalized mass-action rate law  <cit> . in this case, the net fluxes are given by   

for m ∈ ℳ <dig>  where r2m- <dig>  r2m are the  rate constants of the mth forward and reverse reactions, respectively. the quantity fm can be any positive and finite function of the concentrations x and may depend on a set of kinetic parameters π. for usual mass action kinetics, fm =  <dig>  however, for more complex schemes, this function usually takes a rational or polynomial form. it is known that all reversible reaction rate laws in ideal mixtures  can be described by   <cit> . note that k includes the kinetic parameters π as well as the rate constants {r2m- <dig>  r2m, m ℳ0}. it also includes the kinetic parameters of all reactions in ℳ∈ℳ <dig> 

it is a direct consequence of thermodynamic analysis that a closed biochemical reaction system will asymptotically reach a unique non-zero state  of chemical equilibrium at which all concentrations become stationary , satisfying the following detailed balance equations:   

as a consequence,   

these constraints must be satisfied by the rate constants in order for the closed biochemical reaction system to be thermodynamically feasible.

the constraints implied by  correspond to the reaction 'cycles' in the system. a reaction cycle is comprised of those reactions corresponding to the nonzero elements of a vector in the null space null () of the stoichiometry matrix  of the closed system. clearly,  will be at a fixed point whenever the net fluxes of the underlying reactions are set equal to the corresponding elements of a vector in null (). if we denote by s the n <dig> ×  <dig> vector whose nth element is the log steady-state concentration ln  and by z the m <dig> ×  <dig> vector whose mth element is the log equilibrium constant zm = ln, then we can write  in a matrix-vector form as . now, if b is a vector in the null space of , then  and , or   

which are the well-known wegscheider conditions  <cit> . these conditions express necessary and sufficient constraints on the reaction rate constants of a closed biochemical reaction system to be thermodynamically feasible. thus, if we denote the set of all thermodynamically feasible parameters k by , then any  satisfies  and, likewise, any k that satisfies  is a member of .

we want to emphasize that, in open biochemical reaction systems, the rate constants of the reversible reactions must also be constrained by the wegscheider conditions, even if the system is far from equilibrium. to identify these constraints, we need to prune an open biochemical reaction system into a closed subsystem, by employing the technique discussed previously, and use the resulting stoichiometry matrix  to calculate the constraints given by .

an equally important observation is that the rate constants of the reactions pruned from an open system are not constrained by the wegscheider conditions, since  must only be satisfied by the reactions in the closed subsystem. furthermore, if a reaction m in a closed system is not part of a cycle, then bm =  <dig>  for every b ∈ null (), and its forward and reverse rate constants will not be thermodynamically constrained, since these constants trivially satisfy .

it can be shown  that the entropy production rate of an open biochemical reaction system at chemical equilibrium in which the net fluxes of the reactions in ℳ <dig> equal to the elements of a vector in the null space of the stoichiometry matrix , is given by   

where a =  <dig>  × 1023mol- <dig> is the avogadro number, v is the system volume, and kb =  <dig>  × 10-23jk- <dig> is the boltzmann constant. according to the second law of thermodynamics, the entropy production rate must always be greater than or equal to zero, with equality if and only if the system is at thermodynamic equilibrium. it is therefore clear from  that the wegscheider conditions imply that the entropy production rate must be zero in this case . as a consequence, the chemical motive force  and the heat dissipation rate must also be zero. this makes intuitive sense, since a reaction cycle leaves all molecular concentrations unchanged and, therefore, there is no change in internal energy or mass flow through the system boundary. clearly, we can think of the wegscheider conditions as being a direct consequence of the thermodynamic requirement that σ  =  <dig>  for every b ∈ null ().

linear constraints
unfortunately,  imposes a possibly infinite number of non-linear constraints on the rate constants of a closed biochemical reaction system. however, it is sufficient to satisfy  for m <dig> = m <dig> - m <dig> basis vectors {b, i =  <dig>   <dig> ..., m2} of the null space of , where m <dig> is the number of reactions and m <dig> = rank () . by using this observation and by taking logarithms on both sides of , we obtain the following linear constraints on the log-rate constants :   

where  is the mth component of the ith basis vector b. in additional file  <dig> we derive an analytical formula for the basis vectors of the null space of  . as a consequence, the possibly infinite non-linear wegscheider conditions given by  are equivalent to much more manageable finite linear constraints on the log-values of the parameters of the closed subsystem, given by   

where κ := ln and  is an m <dig> × j matrix that can be easily constructed from knowledge of  using . hence,  if and only if  ln =  <dig> 

we should note that there might be additional linear constraints that we may wish to impose on the logarithms of the kinetic parameters of a biochemical reaction system. here are some examples:

• by using an appropriate experimental procedure, we may be able to accurately measure the equilibrium constant rm of the mth reversible reaction. for a  mass-action reaction, we have rm := r2m-1/r2m and thus we obtain a linear constraint  on the log rate constants of the mth reaction, where  is the log value of the measured equilibrium constant.

• for a reversible michaelis-menten reaction, the haldane relationship implies a linear constraint between the logarithms of the kinetic parameters of a reversible michaelis-menten reaction and  <cit> .

• by using experimental techniques, such as plasmon resonance or atomic force microscopy, it may be possible to obtain a highly accurate measurement  of an individual kinetic parameter kj. in this case, we must impose the  constraint , where ej is the jth column of the j × j identity matrix.

• to reduce the dimensionality of parameter estimation, we may employ a sensitivity analysis approach, such as the one proposed in  <cit> , to identify parameters that do not appreciably influence the cost of estimation. determining accurate values for these parameters is inconsequential to the behavior of the biochemical reaction system at hand. therefore, we can fix these parameters to some nominal values  throughout model calibration, resulting again in linear constraints of the form .

• we may want to expand an existing  thermodynamically feasible model to include additional reactions and molecular species. we can do this by fixing the parameters of the existing model using linear constraints , where  is the jth parameter value of the existing model. then estimation takes place only on the parameters associated with the new reactions.

for a given biochemical reaction system, we can combine all possible linear constraints on the logarithms κ of the kinetic parameters k into a single matrix equation of the form:   

where  is an appropriately constructed l × j matrix and c is an l ×  <dig> vector of known values determined by the constraints, with l being the number of constraints. note that if there are no constraints other than the wegscheider conditions, we would simply have  and c =  <dig> 

model calibration
we will now assume that we have obtained noisy measurements  of the concentration dynamics of selected molecular species  in an open biochemical reaction system of known stoichiometry, obtained by a set of distinct experiments  at discrete time points, within the observation time window . the problem of model calibration we consider in this paper is to determine thermodynamically consistent values for the kinetic parameters , so that the concentration dynamics  produced by the estimated system match y in some well-defined sense. note that, for a given , the dynamics  are computed via  using initial conditions  that correspond to the pth experimental condition. data y may be obtained by appropriately designed in vivo or in vitro experiments, or by simulating an established and experimentally validated biochemical reaction model whose kinetic parameters are thermodynamically infeasible. instead of focusing on the quality of the estimated values of the kinetic parameters, it has been argued in  <cit>  that matching predicted and experimental observations of molecular concentrations is the right thing to do due to the 'sloppiness' of biochemical reaction systems .

there are many estimation techniques we can use to address the previous problem, such as maximum likelihood or bayesian inference. the final product of these techniques is a cost function c used to quantify the overall error between the predicted concentration measurements x, obtained by simulating the biochemical reaction system with kinetic parameter values k = exp{κ}, and the noisy observations y. in an effort to reduce the typically large dynamic range of kinetic parameter values, it is customary to estimate the log values κ instead of k. as a consequence, the problem of interest here is to compute an estimate  of the log kinetic parameters κ, so that   

where  is the set of all κ's satisfying the linear constraints given by ; i.e.,. for simplicity, we consider in this paper the least-squares error cost criterion, given by   

this error criterion is a consequence of a maximum likelihood approach to parameter estimation under the assumption of normally distributed observation errors. note that the cost c depends on the log kinetic parameters κ through the molecular concentrations .

in this paper, we refer to the constrained optimization problem given by  as thermodynamically consistent model calibration . the importance of tcmc lies on the formulation of the model calibration problem as one of constrained optimization via , with constraints that ensure at least the thermodynamic feasibility of the resulting model. a useful observation is that tcmc is agnostic to the choice of the cost function used and the algorithm employed for optimization. moreover, we can easily transform the constrained optimization problem given by  to a standard unconstrained problem. indeed, a well known result of linear algebra implies that , where , κ <dig> is a j ×  <dig> vector that satisfies  is a j × d matrix whose columns form a basis for the null space of matrix , and ℜd is the space of all d ×  <dig> real valued vectors. thus, if we can find a particular solution κ <dig> to the constraints , we can reformulate the constrained optimization problem given by  as the following lower dimensional unconstrained problem:   

where   

note that we assume here that there is more than one solution to . if only one solution exists, optimization is not necessary, since this solution will be our parameter estimate. on the other hand, if  has no solution, then we cannot find a κ that will simultaneously satisfy all necessary constraints, indicating that we must reformulate the problem.

the objective function c <dig> is non-convex with possibly many local minima. as a consequence, a gradient-based optimization algorithm for solving  may prematurely terminate at a local minimum with much larger cost than the globally minimum cost. to ameliorate this problem, we have decided in this paper to use a stochastic optimization algorithm, namely simulated annealing   <cit> . stochastic optimization algorithms can move away from premature local minima, thus resulting in better solutions to optimization problems than when using deterministic techniques. although many choices exist for optimization, such as the simultaneous perturbation stochastic approximation  method employed in our previous work  <cit>  and genetic algorithms, sa is a stochastic search optimization algorithm that enjoys several advantages over other algorithms. in particular, the most important features of sa are ease of implementation and the ability to avoid premature convergence by jumping away from local minima en route to finding a global minimum. in sa, a new value of v is proposed nearby the current value. the proposed value becomes the new value with a certain probability based on cost improvement. if the proposed value is not accepted, then the current value is used. the proposed value is usually drawn from an appropriately chosen probability distribution around the current value . see additional file  <dig> for a detailed description of the sa algorithm used.

a natural question that arises here is whether different choices for κ <dig> and  affect the final result of optimization. if we had an algorithm that could always find the global solution to a non-convex optimization problem, then the choice of κ <dig> and  would have no effect on the solution. since however global minima are difficult to find, we expect that different choices for κ <dig> and  will have some impact on the final solution. note that it would be advantageous to choose κ <dig> as close as possible to the globally optimal solution. we attempt to do so in our subsequent example by taking κ <dig> to be a solution to  that is closest  to published values. on the other hand, we expect that the choice of  will have only a minor effect on optimization, since different matrices  amount to scaling or rotating the axes of the parameter space being searched. good optimization algorithms, such as sa, are expected to be robust to such alterations.

example
we now demonstrate the proposed tcmc method by re-estimating the kinetic parameters of a classical model of the egf/erk signaling cascade  <cit> . this model consists of three compartments , n =  <dig> biochemical species, and m =  <dig> reactions. moreover, it is characterized by  <dig> different kinetic parameter values, a number that is smaller than the total number of individual reactions, due to the fact that some reactions share the same kinetic parameters, whereas, other reactions are not associated with any parameters.

although the schoeberl model has provided valuable insights into the biological mechanisms underlying egf/erk signaling, the values of the kinetic parameters published in the literature are thermodynamically infeasible. as a consequence, the concentration dynamics produced by the published model are physically impossible and could not occur in nature. by using tcmc to recompute thermodynamically feasible values for the kinetic parameters, we can construct a physically realizable model whose dynamics are expected to reflect the true behavior of egf/erk signaling more accurately than the dynamics produced by the published model.

we use the version of the schoeberl model published in the biomodels database  <cit> . moreover, we employ the same experimental time series data of erk-pp activity used for creating the original model  <cit> . to simplify implementation of tcmc, we assume here that the schoeberl model is characterized by j = 2m =  <dig> kinetic parameters . for an irreversible reaction, we constrain the rate constant of the reverse reaction to be equal to zero. for those reactions not associated with any kinetic parameters, we assign two artificial parameters  and constrain both their values to be zero.

we implement the following tcmc procedure to re-estimate the values of the kinetic parameters in a thermodynamically consistent manner. first, we find the closed subsystem of the schoeberl model . this subsystem consists of n <dig> =  <dig> molecular species and m <dig> =  <dig> reversible elementary  reactions. then, we determine the thermodynamic constraints by using the  <dig> ×  <dig> stoichiometry matrix  of the closed subsystem. it turns out that the rank of the stoichiometry matrix  is  <dig>  as a consequence, the closed subsystem contains m <dig> =  <dig> -  <dig> =  <dig> independent reaction cycles, determined by the columns of matrix , given by equation  of additional file  <dig> . therefore, the rate constants of the closed subsystem must satisfy  <dig> independent wegscheider conditions. it turns out that the published schoeberl model satisfies only  <dig> of these conditions. as a matter of fact, the entropy reaction rates, given by , associated with  <dig> independent reaction cycles are negative, in direct violation of the second law of thermodynamics, whereas, the entropy reaction rates of  <dig> reaction cycles are positive, with the remaining being equal to zero .

next, we construct matrix  and vector c by combining the  <dig> thermodynamic constraints with  <dig> linear equality constraints originally built into the model that relate various parameters across reactions , thus producing the linear constraints . in this case,  is a  <dig> ×  <dig> matrix, whereas, c is a  <dig> ×  <dig> vector with elements  <dig> or -∞ . it turns out that rank () =  <dig>  which implies that the dimension of the null space of  is d =  <dig>  subsequently, we find a basis for the null space of  and form the  <dig> ×  <dig> matrix . moreover, we find a particular solution κ <dig> of  that is closest, in the least-squares sense, among all other solutions to the published thermodynamically infeasible parameter values. we accomplish this by using a well-known approach for solving constrained least-squares problems  <cit> . finally, by using  on the aforementioned experimental time series data and sa, we calculate the  <dig> ×  <dig> vector  by minimizing the cost function c <dig>  given by , and set .

we take the thermodynamically feasible log kinetic parameter values κ <dig> to be close to the published kinetic parameter values, since the published values already produce a good match between the experimentally available and predicted molecular dynamics. in this case, tcmc provides a thermodynamically consistent correction of κ <dig>  by means of , that reduces the cost of estimation, thus further improving the match between the experimentally obtained and predicted dynamics.

in figure  <dig>  we depict the concentration dynamics of erk-pp obtained by the published model , for two different input egf concentrations, namely  <dig> ng/ml and  <dig> ng/ml, whereas, in figure s <dig> of additional file  <dig> we depict the concentration dynamics of erk-pp obtained by the published model for three additional concentrations of input egf, namely  <dig>  ng/ml,  <dig>  ng/ml, and  <dig>  ng/ml. clearly, the resulting dynamics match the available densitometric data  rather poorly.

we should note here that the erk-pp dynamics originally published in  <cit>  seem to match the available data pretty well - see figure 2f in  <cit> . however, the model detailed in the original publication cannot be used to reproduce the results. on the other hand, the model available in the biomodels database does not reproduce the results published in the schoeberl paper but produces dynamics that are very similar to the ones reported in that paper.

the solid curves in figure  <dig> and figure s <dig> of additional file  <dig> depict the erk-pp concentration dynamics estimated by tcmc. tcmc results in a thermodynamically consistent model of the egf/erk signalling cascade that produces erk-pp concentration dynamics which match the available experimental data noticeably better than the dynamics produced by the published model. as a matter of fact, model fit between predicted and experimentally measured erk-pp concentration dynamics, quantified by the least-squares error given by , is reduced by 69%. tcmc simultaneously adjusts the values of the kinetic parameters in order to minimize the cost of fitting the erk-pp response to the available densitometric data. this 'collective fitting' strategy has been recognized in the literature  <cit>  as being more desirable than constructing a biochemical reaction system model from individual parameter estimates in a piecewise fashion, which is the case with the published schoeberl model.

to separate the effect of collective fitting versus imposing the underlying thermodynamic constraints on the kinetic parameters, we use the same simulated annealing algorithm employed by tcmc to estimate the kinetic parameters without including the thermodynamic constraints. the resulting  estimated dynamics are depicted by the dashed curves in figure  <dig> and figure s <dig> of additional file  <dig>  as expected, these dynamics fit the densitometric data better than the dynamics obtained by the published model. as a matter of fact, model fit between predicted and experimentally measured erk-pp concentration dynamics is reduced by 70% in this case, which is slightly better than the one obtained by tcmc. it will shortly become clear however that the solution obtained without imposing the thermodynamic constraints leads to unrealistic system behavior. in the following, we discuss a number of advantages gained by tcmc over estimating the kinetic parameters using a collective fitting approach that does not consider the underlying thermodynamic constraints.

discussion
qualitative/quantitative value of thermodynamic consistency
due to lack of thermodynamic consistency in the parameter values of the published schoeberl model, the molecular dynamics produced by this model cannot possibly occur in nature. because the values estimated by the proposed tcmc method satisfy all necessary thermodynamic constraints, it is expected that the resulting tcmc model will provide a more accurate representation of egf/erk signaling than the published schoeberl model.

to provide an example of a potentially important difference between the published model and the tcmc model calculated in this paper, we consider the integrated response of erk-pp activity . it has been argued in the literature that the integrated response provides an appropriate metric for quantifying dependence of dna synthesis on erk activation in certain cells  <cit> . as a consequence, this feature of the erk-pp concentration dynamics can influence a number of diverse biologically outcomes, such as cell cycle progression, cell proliferation, and cell differentiation.

in view of the fact that differences in the integrated response of erk-pp activity may cause distinct biological outcomes, it is reasonable to believe that a key objective of egf/erk signaling is to maintain robust integrated response to changes in input egf concentration while producing a quick and sharp 'switch-like' transition between states of differing biological outcomes. in figure  <dig>  we provide a log-log plot of the integrated response of erk-pp activity predicted by the published  and tcmc  models, for a wide range of input egf concentrations. although the integrated response predicted by both models is indeed robust for input egf concentrations larger than 10- <dig> ng/ml, when the egf concentration decreases below 10- <dig> ng/ml, the integrated response of erk-pp activity predicted by the tcmc model exhibits a sharper transition from large to small values than the one predicted by the published model. as a matter of fact, the tcmc model predicts seven orders of magnitude decrease in the integrated response, when the input egf concentration decreases from 10- <dig> ng/ml to 10- <dig> ng/ml, whereas, the published model predicts only four orders of magnitude decrease. by considering the discussion in  <cit> , we believe that this behavior by the tcmc model may turn out to be a biologically important property of the egf/erk signaling pathway that cannot be effectively captured by the published model.

we will now show that the tcmc model may result in a biologically plausible prediction of erk-pp activity that can also be different than the one produced by the estimated thermodynamically infeasible model using collective fitting. in figure  <dig>  we show the long-term behavior of the estimated thermodynamically infeasible model. under certain normal biological conditions , erk-pp activity is expected to decay to zero at steady-state  <cit> . however, one can see from figure  <dig> that, even after  <dig> hours, the concentration of erk-pp predicted by the estimated thermodynamically infeasible model is steadily increasing - possibly being driven by the chemical perpetuum mobiles that occur when the wegscheider conditions are violated. this unrealistic behavior appears despite the fact that the transient dynamics, depicted in the inset of figure  <dig> by the dashed curves, fit the data better than the tcmc dynamics, denoted by the solid curves. such a sustained and long lasting response may lead to different biological outcomes than the ones resulting from erk-pp activity that decays to zero at steady-state  <cit> . thus, the estimated thermodynamically infeasible model can lead to erroneous biological predictions, despite its reasonable fit to the available densitometric data.

our previous examples show that thermodynamic consistency may result in model behavior that is different than the one predicted by thermodynamically infeasible models of cellular function. however, more research is needed to experimentally validate observed differences and demonstrate that lack of thermodynamic consistency may indeed result in inaccurate  biological predictions.

flux analysis
flux-based analysis of biochemical reaction systems is a widely used method for understanding the principles underlying the production and regulation of mass flow in cellular systems, such as signaling or metabolic pathways. it turns-out that the wegscheider conditions, given by , constrain the reaction fluxes. if flux analysis does not take into account these constraints, then it may lead to inaccurate or misleading conclusions about the behavior and properties of mass flow in biochemical reaction systems.

if {b, i =  <dig>   <dig> ..., m2} is a set of basis vectors of the null space of the stoichiometry matrix  of the closed subsystem, and  are respectively the forward and reverse fluxes of the mth reaction at time t, then    

where  is the mth element of the basis vector b. note that this equation must be satisfied at each time point , even far away from equilibrium. moreover, it is satisfied for any vector b in the null space of .

since tcmc always leads to a thermodynamically feasible biochemical reaction system with parameters satisfying the wegscheider conditions, the flux constraints imposed by  are satisfied as well. thus, thermodynamically consistent flux analysis can be performed on the resulting system without any additional considerations, and the behavior of the system is always physically realizable.

bias-variance tradeoff and overfitting
in addition to the previous advantages, there is an important statistical benefit for thermodynamically constraining the parameters of a biochemical reaction system. by searching for kinetic parameter values within a thermodynamically consistent subset of the parameter space, we may reduce the variance of estimation and thus lower the estimation error through the well-known bias-variance tradeoff.

the mean-square error   in cost, where  is an estimator of the 'true' parameters κtrue, satisfies:  

generally speaking, imposing constraints on the parameters may increase the bias term but decrease the variance. however, since the true parameter values must satisfy the thermodynamic constraints, we expect a decrease in variance without an increase in bias. as a consequence, searching for parameter values within the thermodynamically consistent subspace of the parameter space may lead to a lower mean square error in cost due to smaller variance. since the volume of a search space grows exponentially in the dimension of the space, gains in variance  are expected to be large.

a related statistical notion in estimation problems is data overfitting. overfitting refers to situations where model complexity  is high and the amount and quality of available data is comparatively low. in this case, it is often possible that we match the data so well that, in addition to matching the underlying physical phenomena of interest, the model fits the measurement noise as well. this situation reduces the predictive power of the estimated model. the relationship of overfitting to the bias-variance tradeoff is clear: complex models are characterized by low bias and are able to describe a wide range of phenomena but suffer from high variance in parameter estimation .

most often, the behavior of biochemical reaction systems is only influenced by a small number of parameters . this reduces the actual number of parameters that must be estimated with precision. moreover, the thermodynamic constraints further reduce the number of parameters to be estimated, alleviating some overfitting concerns. imposing additional parameter constraints, such as the ones employed by the schoeberl model, may further be used to combat this issue. unfortunately, model complexity is much higher than the amount and quality of available data in most problems of systems biology and overfitting remains a major concern even when using tcmc. in the example considered in this paper, time series data is only available for one crucial chemical species. as a consequence, it is natural to expect that the dynamics produced by the tcmc model overfit the available data to a certain extent. thus, when more experimental data become available, tcmc must be rerun in order to produce a better calibration of the model, with a new cost function that includes the additional data.

in light of these concerns, some may argue that collective fitting of model parameters is not the correct approach, and that a reductionist approach is more appropriate . unfortunately, the reductionist approach is time consuming, extremely expensive, and, in most cases, impossible with current experimental techniques. moreover, incorrect implementation of a reductionist approach may lead to a thermodynamically infeasible model calibration. this is clearly the case with the schoeberl model .

tcmc is a collective fitting procedure, but offers a pragmatic compromise to the reductionist approach. in light of the fact that some parameters may be measured individually with extreme precision, tcmc allows for these parameters to be fixed to their measured values using matrix . in addition, a more advanced bayesian cost function can be used  to factor in prior experimental knowledge when parameters have been previously estimated with less precise experimental techniques.

computational advantages
according to the 'curse of dimensionality,' which refers to an exponential increase in the volume of the parameter space as its dimension grows, estimation becomes substantially harder in high dimensional spaces. a 'naïve' search of that space, in an effort to find the 'true' parameter values of a biochemical reaction system , is hopeless. as a matter of fact, the probability of obtaining parameter values that satisfy the wegscheider conditions and other underlying log-linear constraints by uniformly sampling the entire parameter space  is zero. as a consequence, the constraints must be explicitly considered by the optimization problem at hand to have any hope of successfully solving the problem of model calibration.

as a matter of fact, since the feasible manifold is of lower dimension than the entire parameter space, methods that do not consider the underlying thermodynamic and non-thermodynamic constraints will spend most time searching the immense infeasible portions of the parameter space. the imposition of constraints among the kinetic parameters of a biochemical reaction system reduces the dimensionality of the parameter space to a smaller feasible region and make parameter estimation computationally easier. tcmc makes this explicit, by performing optimization over a lower dimensional space, spanned by the lower dimensional vectors v, instead of the entire parameter space, spanned by the higher dimensional vectors κ.

CONCLUSIONS
for a biochemical reaction system to be physically realizable, it is required that the underlying kinetic parameters satisfy certain thermodynamic constraints, known as wegscheider conditions. this issue has been largely ignored in the literature, as evidenced by the fact that many published models violate these constraints. the model calibration method we have proposed in this paper can be effectively used to determine thermodynamically consistent values for the kinetic parameters of any set of reactions in an ideal homogeneous mixture at constant temperature and volume. our method is simple to understand and implement. moreover, it can be easily incorporated into any existing or newly proposed calibration technique in order to make sure that the resulting model satisfies the fundamental laws of thermodynamics as well as other desirable conditions and constraints.

there are two major issues associated with calibrating biochemical reaction systems:

 <dig>  the quality and quantity of available data are inadequate to allow sufficient estimation of all underlying parameter values.

 <dig>  biochemical reaction models contain many parameters whose numbers dramatically increase with model size and detail. as a consequence, the curse of dimensionality seriously hampers estimation algorithms.

the first issue is primarily associated with current limitations of experimental methods and approaches. to address this issue, we need substantial improvements in experimental equipment and methodologies. however, tcmc scales well with future improvements in data quality and quantity. matrix  can handle arbitrary parameter measurements . moreover, tcmc can employ any cost function of choice, so additional concentration data can be incorporated seamlessly therein.

the second issue is the largest obstacle facing model calibration techniques. to reduce dimensionality, we must attempt to exploit mathematical structure particular to the biological problem at hand. tcmc attempts to address this problem in two ways:

• first, tcmc uses the fact that there are fundamental physical principles underlying biochemical reaction systems that may constrain the set of possible kinetic parameter values. as a consequence of the fundamental laws of thermodynamics, most complex biochemical networks contain reaction cycles that constrain the kinetic parameters according to . these constraints allow tcmc to reduce dimensionality by restricting the estimation problem on a smaller thermodynamically feasible subset of the parameter space.

• second, experimental data and mathematical analysis can often provide other forms of constraints on the underlying parameters . in particular, sensitivity analysis may reveal non-influential kinetic parameters that can be set to some nominal values without appreciably affecting system behavior. all these additional constraints can be accounted for by the  matrix in , further reducing the dimensionality of the ensuing parameter estimation problem.

as we mentioned before, dimensionality reduction is made explicit by tcmc, since optimization takes place over a smaller dimensional vector v, instead of the higher dimensional vector κ specified by the model. as a consequence, tcmc does not entirely rely on finding the globally optimal parameter values that best fit available dynamic data of molecular concentration. imposing thermodynamic  constraints allows tcmc to restrict its search for appropriate parameter values over a smaller subspace of the entire parameter space in order to reach a compromise between optimal data fit and biophysical feasibility. it has been recently pointed out in the literature that this approach to parameter estimation should be considered as an important part of determining the parameter values of complex biological models  <cit> .

recently, a method has been proposed in the literature for inferring a complete and consistent set of kinetic parameter values from incomplete and inconsistent data  <cit> . this method, known as 'parameter balancing,' employs a bayesian estimation approach based entirely on published data pertaining the values of the underlying kinetic parameters. although parameter balancing can be used to provide thermodynamically consistent values for the kinetic parameters of a biochemical reaction system, the method does not include quantitative dynamic measurements of molecular concentrations. as a consequence, parameter balancing may result in a thermodynamically feasible biochemical reaction model that does not adequately predict experimental observations of dynamic system behavior. future research may focus on combining tcmc with parameter balancing to utilize published parameter sets as well as dynamic experimental data.

a problem that we have not addressed in this paper is the influence of ions, such as k+, and ca2+, and certain environmental factors, such as the temperature and ph, on the thermodynamic behavior of a biochemical reaction system  <cit> . our objective in this paper is not to address biochemical reaction systems with this level of complexity, but to focus on the widely reported simpler models of cellular function that consider only interactions among biochemical reactants in a fixed environment. note, however, that temperature and ph dependence of parameters has been accounted for in  <cit>  via parameter balancing using log-linear equations between biochemical parameters. since arbitrary log-linear constraints between parameters can be enforced by tcmc via , we suspect that tcmc can be used directly or appropriately modified to handle additional biochemical complexities that have not been addressed in this paper.

another problem that we have not addressed here is constructing new biochemical reaction models of cellular function. since, in this paper, we only address the model calibration problem, we take  as given and proceed to determine the parameter vector k from data. in general, determining the structure  of a biochemical reaction network is an extremely laborious task. preliminary work indicates that thermodynamics can also play a key role in estimating the structural complexity of biochemical reaction systems  <cit> . future scientific investigations are necessary to further examine this open problem.

authors' contributions
gj developed the general methodology and coded a substantial portion of the software. jg derived many theoretical results and ideas and wrote substantial portions of the final document. gj and jg both interpreted the obtained computational results and approved the final version of the paper.

supplementary material
additional file 1
in this document, we provide supplementary mathematical and computational details required to fully understand the material presented in the main text.

click here for file

 acknowledgements
this research was supported in part by dod, high performance computing modernization program, national defense science and engineering graduate  fellowship,  <dig> cfr 168a, and in part by the national science foundation , grant ccf- <dig> 
