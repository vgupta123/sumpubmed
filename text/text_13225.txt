BACKGROUND
illumina bead arrays  <cit>  are a popular choice for array-based genome profiling studies. although next generation sequencing technology is on the rise, microarray-based gene expression profiling is still widely utilized due to its ease of use, robust performance, reproducibility, and low per-sample cost. furthermore, open data repositories  contain a vast amount of microarray experiments, which are often re-analyzed, integrated, or combined with newly generated data in the context of modern integrated systems biology research. this process is facilitated by easy access to streamlined processing. to extract biologically meaningful information from genome profiling experiments, generated data first needs to be quality checked, filtered, pre-processed and statistically analyzed. having these basic analysis steps at a user’s disposal is essential for an effective and iterative research process. as gene expression profiling experiments are typically designed, performed, and interpreted by biological domain experts rather than bioinformaticians, it is important to enable these researchers to independently operate basic analysis pipelines. pipelines with a user interface that provides immediate and intuitive feedback are of great interest for increasing efficiency and effectiveness of the research process. besides proprietary vendor-provided software  and open-source software illuminaio  <cit> , several pre-processing and quality control  methods for illumina bead arrays are available . however, utilization of these methods requires extensive bioinformatics skills and therefore they are not readily accessible for a broad researchers community. to extend utility of analysis workflows for illumina bead arrays also to non-bioinformaticians, we have created an open-source, user-friendly workflow, accessible via the web interface of arrayanalysis.org, that combines functionality of bioconductor packages for essential quality control and pre-processing, with statistical functions and downstream analysis  <cit> .

the relevance of analysis workflows for illumina bead arrays that are friendly to a wide range of researchers has been recognized by several other bioinformatics developers, resulting in availability of tools and pipelines related to our work . nevertheless, our module for arrayanalysis.org provides a significant contribution to the research community as it provides an easily accessible alternative that does not require local installs. for instance, chipster provides similar functionality but requires local software installation and availability of specific java versions; madmax is not open source and requires login credentials to be provided by the developers; and illuminagui requires a local install of r and its support has been discontinued. therefore, our web interface-based workflow is a convenient resource for free, fast and user-friendly analysis of illumina bead arrays by a broad community of researches - regardless of their bioinformatics skill level or research budget.

implementation
the illumina qc and pre-processing module was developed to complement and link to previously created modules for analysis of microarrays, available at www.arrayanalysis.org  <cit> . the illumina module has been implemented as a wizard guiding the users through the different steps and is connected in an arrayanalysis workflow to downstream modules for statistics and pathway analysis. figure  <dig> shows an overview of the steps of the illumina module and its use together with other modules and software.fig.  <dig> schematic representation of the different steps in the data workflow for illumina bead arrays. steps 1– <dig> are part of the newly added illumina qc and pre-processing module.  import the input data text files;  enter sample annotation and experimental grouping, by either uploading a description file or completing the form ;  summary of the array type, species and number of arrays found in the data set and whether data has been background corrected, with an option to enter an email address for notification when the workflow has finished;  select a pre-processing method and the plots and tables to be computed on the raw and pre-processed data;  obtain the normalized data table and diagnostic images to check the data quality. illustrative examples of such tables and images are shown . optionally, steps  <dig> to  <dig> of the pre-processing procedure may be repeated after exclusion of low quality arrays. the output files can be further used to perform statistical analyses through the statistics module and pathway analysis through the pathway analysis module, or to proceed with downstream analyses in external tools



the module was implemented using r and bioconductor packages for illumina analysis lumi  <cit>  and limma  <cit>  to provide the user with the most commonly used analysis options. using the lumi package, we implemented various types of background correction , variance stabilization , ‘log2’, ‘cubicroot’) and normalization. additionally, the neqc method from the limma package has been included, which performs a background correction using a normal-exponential-modeling approach  <cit>  followed by a quantile normalization of all regular and control probes together, and a log2-transformation on the dataset. after normalization, probes with intensities below detection level can be removed to speed up the processing and to reduce false positives.

five types of quality control  plots are implemented:  density plots and  boxplots of the log-intensity distributions of all arrays on a single graph, facilitating comparison of signals between arrays and identification of arrays with deviating distributions;  a correlation coefficient plot, representing correlations between all pairs of arrays in the dataset as a colored matrix;  a principal component analysis  plot, providing another view of the correlations of expression between arrays: the data are projected on several axes  that explain the largest amounts of variance;  a hierarchical clustering plot that can be generated using various distance metrics  and clustering methods , and is used to inspect the groupings of the samples. all plots use consistent colors for arrays and experimental groups and can be generated for both raw and pre-processed data, which helps to assess whether the pre-processing step corrects possible aberrations.

the illumina identifiers are converted to equivalent nucleotide universal identifiers   <cit>  based on their probe sequence. after quality control and pre-processing, the nuids are used to add additional annotation  to the processed result tables.

RESULTS
when running the illumina workflow, the user is guided through the different analysis steps via a web based user interface. at the first step, the user is prompted to upload a summarized probe-level data file and optionally a control probe data file, the output of illumina’s beadstudio/genomestudio software. the user may choose to perform all pre-processing steps within our workflow , or to provide already background-subtracted data. both summarized probe-level and summarized gene-level input data are supported. summarized probe-level data is recommended as input, as this will eliminate the occurrence of improper combinations of the expression values of different probes into a single-gene value  <cit> .

in the second step, the user can annotate the imported samples by entering custom sample names and experimental group names by either uploading a sample description file or entering the sample description information manually via the web based interface.

the third step summarizes the information about the uploaded data and provides the user with the option to enter an email address for notification when the workflow has finished.

the fourth step will perform background correction and normalization of the user’s data. this encompasses the removal of per-array technical effects, which ensures that the values being further analyzed reflect underlying biology. three actions are typically performed to achieve the following  <cit> :  background correction,  between-array normalization and  data transformation . the user may choose between two popular pre-processing approaches that implement these actions for illumina data:  lumiexpresso from the lumi bioconductor package  <cit> , or  neqc, from the limma package  <cit> . also, the user can choose the types of plots that are to be created and whether filtering probes with intensities below detection level is to be performed.

upon completion of the run, the user receives a link to download a zip archive of results either at the web-interface or by email. if the qc diagnostic plots show arrays of insufficient quality, the pre-processing procedure may be repeated after exclusion of those arrays. otherwise, the user can immediately proceed with the next module of the workflow to perform statistical analysis. via a web interface, the existing statistics module prompts the user to specify which experimental groups are to be compared  or to define any custom comparison of interest. after submitting the choices, this module runs limma model fitting to compute a table of relevant statistics, including estimated coefficients  and their significances  <cit> . results from the statistics module can then be used for further pathway analysis processing in a downstream module that makes automated calls to pathvisio  <cit>  or they can be downloaded for processing in other software.

running time of an analysis is very much dependent on the size of the input file, the number of arrays, the specific user settings, and the modules used, and will range from minutes to hours in the extremes. performance of arrayanalysis servers is being monitored to make sure they effectively deal with the workload, and extra capacity can be allocated in future if needed. when not surpassing a dozen concurrent runs, running times will not increase much. additionally, users can download the r scripts to run on their own systems if desired, for example in case of many projected runs or very large data sets that would not be convenient to process over the internet. the scripts have been designed for ease-of-use, providing a separate initiation script to specify user settings , which automatically calls the other scripts.

the addition of the currently introduced illumina module complements arrayanalysis.org with functionality to pre-process data from experiments run on the widely used illumina bead array platform. it provides users of this platform or those processing existing data not only with an easy to use data quality control and pre-processing web module, but also with a direct connection to further modules offering downstream statistical and pathway analysis functionalities. as a whole, arrayanalysis.org is continuously being improved, evolving into a one-step solution for pre-processing, statistical analysis, and biological interpretation of data from multiple technological platforms. being an open source project, developers within the user community can contribute by adding modules or improving functionality of existing ones, and source code can be downloaded for local deployment.

CONCLUSIONS
the developed illumina bead array analysis workflow provides an easy, fast, and intuitive way for quality control, pre-processing, statistical, and pathway analysis of illumina gene expression arrays for a broad range of researchers. the workflow provides immediate feedback on quality and basic statistics outcomes of generated data, increasing the speed and iterative capacity of intuitive research pipelines. this enables researchers to effectively resolve the first steps in data analysis and focus on their primary interest: extracting biologically meaningful information out of their gene expression data. the workflow can therefore be used as a starting point facilitating a broad range of applications in life sciences research.

availability and requirements
project name: arrayanalysis.org illumina pre-processing and qc module

project home page: http://www.arrayanalysis.org

operating system: platform independent 

programming language: implemented in r, php

other requirements: none

license: apache version  <dig> 

any restrictions to use by non-academics: no restrictions

user guide: additional file  <dig> 

tutorial: additional file  <dig> 

source code: https://github.com/bigcat-um/ilmnqc_module  and additional file  <dig> 



additional files
the additional files are given for reference, most recent versions are available from http://www.arrayanalysis.org and https://github.com/bigcat-um/ilmnqc_module.additional file 1: 
user guide.


additional file 2: 
tutorial demonstrating analysis of a publicly available example dataset from arrayexpress.


additional file 3: 
r scripts.




abbreviations
qcquality control

limmalinear models for microarray data

pcaprincipal component analysis

nuidnucleotide universal identifier

competing interests

the author declare that they have no competing interests.

authors’ contributions

mr, ce, conceived the research. vg, le, tk, ma, implemented the software. mr, le, vg, wrote the manuscript. tk, ce, ma, critically reviewed the manuscript. all authors read and approved the final manuscript.

