BACKGROUND
with the improvements in biosensors and high-throughput image acquisition technologies, life science laboratories are able to perform an increasing number of experiments that involve the generation of a large amount of images at different imaging modalities/scales: from atomic resolution for macromolecules , to subcellular locations , up to human body organs or regions .

in cell biology, the analysis of results of imaging experiments may provide biologists with new insights for a better understanding of all cellular components and behaviors  <cit> . however, visual classification  of images into several classes with some shared characteristics  is tedious. indeed, manual classification of such an amount of images is time-consuming, repetitive, and is not always reliable, due to experimental conditions, variable image quality, and human subjectivity or tiredness that lead to considerable interobserver variations and misclassifications. in other words, manual examination could be a source of bias and would cause a bottleneck for high-throughput experiments, thus systems that automate image classification tasks would greatly help biologists. ideally these systems should proceed faster than human in most cases, with the same accuracy , and widely reduce the number of images that require human inspection .

in the computer vision community, image classification is a very active field. given a set of training images labelled into a finite number of classes by an expert, the goal of an automatic image classification method is to build a model that will be able to predict accurately the class of new, unseen images. such techniques have been applied to various problems where the goal is to identify a specific object , and current researches aim at developing generic methods for the categorization, detection and segmentation of classes of objects or scenes with shared characteristics in terms of their shapes, colors, and/or textures   <cit> .

in the context of biomedical studies and cell biology, such automatic methods could for example help to study the phenotypic effects of drugs in human  cells  <cit>  where a class could denote the shape of a cell . in various cytopathology studies, one may want to automatically recognize various cellular types to quantify their distributions in a certain state . another promising example is the automatic identification of subcellular location patterns , using fluorescent tagging and fluorescence microscopy, as an essential first step to understand the function of various proteins  <cit> . other recent examples of biological studies that can be formulated as image classification problems include the recognition of the different phases of the cell division cycle  by measuring nucleus shape and intensity changes in time-lapse microscopy image data  <cit> , the microscopic analysis of urine particles   <cit> , the study of protein distributions following a retinal detachment from confocal microscopy images  <cit> , the annotation of fruitfly gene expression patterns over the entire course of embryogenesis obtained by in situ mrna hybridization  <cit> , etc.

related work
global feature extraction
till recently, image classification systems usually rely on a pre-processing step, specific to the particular problem and application domain, which aims at computing a certain number of numerical features from the initially huge number of pixels in images. such features could for instance correspond to statistics of pixel intensities , or compute various measures from preliminary segmented objects or "blobs" , etc. this reduced set is then used as new input variables  for traditional learning algorithms , possibly tuned for the specific application. the learning algorithm then tries to build from the data a model that associates features with predefined classes. the limitation of this approach is clear: a given set of features is suitable only for certain specific applications, but unsuitable for others, and the choice of which set of features to use for a given application is not obvious. thus, when considering a new application or, more dramatically, when new image classes are of interest, it is often necessary to manually adapt the pre-processing step by taking into account the specific characteristics of the new task. recently, several works tried to overcome this limitation and consider combining several different types of features that describe different aspects of an image, and applying feature selection techniques. in  <cit>  several hundreds image features are extracted corresponding to texture descriptions, pixel intensity distributions, edges, responses to various filters, etc. however, these approaches that use global features may not work properly with cluttered and partially occluded images and they may not be robust to various image transformations , that may appear in many applications. meanwhile, it has been shown recently that generic methods developed by the object recognition community perform very well on medical images even though they were not tuned for such tasks  <cit> .

local appearance models
many recent object recognition methods rely on a "local features" scheme  <cit> . first, interest points or image regions are detected  whose neighbourhood has high informational content and which are thought to be robustly detectable in images under varying conditions  <cit> .

then, the appearance of the interest points or regions is encoded by a feature vector of numerical values computed in their neighbourhood  <cit> . such descriptors are often designed to be discriminative, concise and insensitive to various transformations that global feature methods are generally not able to cope with. these descriptors are sometimes compressed by dimensionality reduction techniques  because local regions contain too much data for the traditional learning methods that are not able to deal with very high numbers of variables. these local feature vectors are then stored in a database for use during the recognition step.

to predict the class of a new image, each feature vector computed from the image is classified using a nearest-neighbor algorithm against the feature vectors in the database. the majority class among the classes assigned to local feature vectors is then assigned to the image.

our work
in  <cit> , we have proposed a generic approach for image classification that largely follows the aforementioned scheme but distinguishes from other methods by several notable points. first, the method uses a large set of randomly extracted image subwindows  and describes those by high-dimensional feature vectors composed by raw pixel values. then, the method uses ensemble of extremely randomized decision trees  <cit>  to build a subwindow classification model. to predict the class of a new image, the method aggregates subwindow class predictions given by the decision trees and it uses majority voting to assign a class to the image. details about the method and its rationale are given in the methods section.

our approach was evaluated on various image classification datasets involving the classification of digits, faces, objects, buildings, photographs, etc. moreover, in  <cit> , we successfully applied it on a  <dig> x-ray image database with classification results very close to the best ones  <cit> .

in this paper, we evaluate the potential of our image classification method in cell biology by evaluating its performances on four datasets of images related to protein distributions or subcellular locations and  cells. the application of our method is straightforward  and we compare its results with human classification  and automated methods designed specifically for a given task. we discuss properties of the method such as attractive computational efficiency and possible interpretation.

RESULTS
the performance of our method is given for four image classification tasks: two of them correspond to sub-cellular protein localizations, the third one to red-blood cell shapes, and the last one to protein distributions in retina cells and layers. details about these datasets are given in the methods section.

basically we measure the accuracy of the models to correctly predict the class of unseen images. in all experiments, we build t =  <dig> trees using the default filtering parameter value  except for the rbc task where we observed that its maximum value  achieved better accuracy. the number of extracted subwindows is given for each problem. details about our method and its parameters are given in the methods section.

lifedb
random guessing on this dataset would provide an error rate of  <dig> %. straightforward application of our method  yields a leave-one-out prediction error equal to  <dig> %. examples of random subwindows extracted from these images are given in figure  <dig> 

since for this experiment there are no results available from the literature, we applied a nearest neighbor classifier with euclidian distance and an extra-tree classifier on resized versions  of the global images  to provide some baseline for comparison. with these methods, we obtained error rates of  <dig> % and  <dig> %  respectively, which shows that the nearest neighbor classifier is here not able to deal with the high-dimensional feature vectors and the small number of images. on the other hand, the significant improvement of our method with respect to the extra-tree classifier confirms the interest of the subwindows sampling and voting scheme of our method.

hela cells
random guessing on this dataset would give about 90% error rate, while the human classification error rate on this task is of 17%, as reported in  <cit> . we obtain with our method an error rate of  <dig> % Â±  <dig>  .

we can compare these results with those of  <cit>   which range between 25% downto  <dig> % depending on the number of features used and the parameters of the learning algorithm . subsequently , k. huang and r.f. murphy have improved these results downto  <dig> % by using an unweighted majority-voting ensemble model of all possible combinations of eight classifiers, with several parameters optimized on this specific dataset.

in terms of types of classification errors, let us notice that like the method presented in  <cit> , our approach is more effective in distinguishing the two patterns of golgi proteins  than human observers. on the other hand, errors of our approach are mostly due to misclassifications for the endosome and mitochondria classes. these results are further illustrated in figure  <dig> which shows the confusion matrix of our method for one of the ten protocol executions , as well as the prediction confidence for one golgi gpp image .

red blood cells 
in the literature, error rates on this dataset range from 31% to  <dig> %  <cit> , while the error rate of human experts is estimated to be above 20%  <cit> . on the other hand, with the protocol we used and due to the unbalanced number of images in each of the three classes, a method always guessing the most frequent class would achieve an  <dig> % error rate. with our method, we obtained the best results by constraining the random subwindow sizes between 80% and 100% of the image size instead of the full range of sizes, with a mean error rate over all subsets of  <dig> % Â±  <dig>  with  <dig> subwindows extracted from each image.

notice that the method that obtains the best results on this dataset  <cit>  also uses a local appearance approach, but with a distance measure between patches that incorporates invariances with respect to transformations that are known a priori: cell border line thickness, six affine transformations, and additive image brightness.

retinal detachment
in  <cit> , authors proposed a method that computes different sets of mpeg- <dig> features within fixed-size square tiles, applies independant component analysis to the feature vectors, and uses a support vector machine classifier. their results range from  <dig> % downto  <dig> % classification error rate on a dataset of  <dig> retinal images labelled into  <dig> classes. we obtain a 10% leave-one-out error rate using  <dig> subwindows extracted from each image with subwindow random sizes inferior to 10% of the image size. our  <dig> misclassification errors are confusions between "normal" and " <dig> day" conditions, and between " <dig> day" and " <dig> day" conditions. our accuracy results are not directly comparable to those in  <cit>  because the number of images and classes are not equivalent. however, they illustrate the ability of our method to capture the characteristics of these  <dig> classes using only a dozen images per class, hence its potential for this type of imaging experiments. a more in depth validation of our method on this type of problem would require a larger set of images representing additional experimental conditions .

also, in order to be useful in practice, the image classification method should provide biologically meaningful information that can be interpreted by physicians, like for example the one used in  <cit> . as a first illustration of the possibility to gather such meaningful information with our method, figure  <dig> shows the most discriminative subwindows of a particular image from each class, i.e. those subwindows that receive exactly t votes for that class . figure  <dig> shows for one image all the correctly classified subwindows and the most discriminative ones, with the corresponding confidence maps. the confidence maps are given in grey level images and show for each pixel the number of votes assigned to  subwindows which contain the pixel. one can observe that the most discriminative regions of the image are identified by the confidence maps as those which indeed seem specific to the particular class. we believe that in specific studies, this kind of qualitative information could be quite useful for interpretation by domain experts.

discussion
we think our method is attractive for cell biology studies in view of its properties that we summarize hereafter.

first, without integrating any domain knowledge neither complex pre-processing techniques, our experiments show that our generic method obtains quite good results on average on four problems with images of different quality and representing various patterns. as one could have expected, these results are however not as good as the best results published in the literature obtained either with tailored methods for one specific dataset and/or after important research efforts .

interestingly, our method is competitive with respect to classification by human experts on the hela cells and rbc tasks. in biological studies where the number of images to classify is so large, and where the perfect classification of molecules or cells is not required , the method would thus be quite useful. indeed it is directly applicable to any image classification problem, it is reasonably fast, it can run on regular computers, and it would be easily possible to take advantage of parallel architectures, if available.

in the case of particular applications that require better prediction results than the ones obtained with the default settings of our method, its enhancement or tailoring is conceivable. integration of domain knowledge would be possible. for example, in the case of protein subcellular localizations, the combination of the image classification and the classification of the amino acid sequence of the protein with a similar approach  <cit>  might improve results. domain knowledge could also be incorporated implicitly through the description of the subwindows with domain specific features, and also the exploitation of more generic image classification features  may be useful. generation of synthetic versions of the subwindows  <cit>  might be another way to improve robustness  by providing the learning method a richer training set to generalize from.

beyond misclassification error rates, the method could highlight discriminative subwindows in images, hence it could be used as an exploratory tool for further biological interpretation. preliminary results were given on the retinal dataset. for a specific study, this function should be applied on larger sets of images and corroborated by domain experts to assess its pratical usefulness.

CONCLUSIONS
we illustrated the potential of our generic image classification method on different kinds of problems in cell biology. thanks to its computational efficiency and competitive accuracy results on average with respect to human classification and tailored methods, we foresee the use of this automatic approach as a baseline method and a first try on various biological image classification problems where a manual approach could be a source of bias and would cause a bottleneck for high-throughput experiments. moreover, preliminary results show that minor parameter tuning could possibly improve the default results on specific problems. extension of this approach to image sequence classification and segmentation also deserves to be studied.

