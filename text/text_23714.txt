BACKGROUND
de novo assembly using next-generation sequencing short read sequences have been successful in producing draft genome sequences  <cit> . however, complete and fully automated assembly of genomes remains elusive, especially for prohibitively sized genomes such as human. problems generally reside in areas of low-coverage or highly repetitive sequences. even in cases where the overall long-range sequence structure can be disambiguated, on shorter scales there may be ambiguous or undetermined bases, producing regions of ns or “gaps” in assembly scaffolds. the need for gap closure is made more evident for large  genomes, such as in h. sapiens, where there are higher occurrences of complex genomic features. in fact, as the cost of dna sequencing decreases faster than the cost of computer hardware, more raw sequencing data will be generated while computational resources will remain mostly the same  <cit> . thus it is critical to develop tools that can scale up to these large datasets while using minimal computing resources. projects such as the  <dig> genomes project  <cit> , the cancer genome atlas , and clinical uses of whole-genome sequencing  <cit>  highlight the trend of processing gbp-scale datasets.

even though these projects are about re-sequencing human genomes and transcriptomes, it was demonstrated that de novo assembly of the raw reads provides valuable information on structural variations . thus these initiatives would benefit from a gap-closing tool that can improve the quality of human draft assemblies, while having low runtime and memory usage as it would help reduce the cost of analysis  <cit> .

obviously, gap-closing algorithms are also valuable in de novo sequencing projects, with some of the contemporary studies using the concept to improve assembly contiguity  <cit> . when the closed gaps refine the sequence content in or near genic or regulatory regions, they provide information for the downstream annotation work, and enable biological insights.

hence, several tools have been designed to close gapped regions with sequence reads, including baseclear gapfiller  <cit>  and soapdenovo gapcloser  <cit> . the former implements a method that seeks read pairs with one pair aligning within a contig and its mate partially located in a region identified as a gap. these partially aligned reads are used to close the gap through sequence overlap. with gapcloser, a stand-alone tool in the soapdenovo package, reads are aligned to contig positions, and a base extension algorithm is performed. although both of these tools have been shown to successfully close gaps in mega-bp scale datasets such as in s. cerevisiae  and human chromosome  <dig>  genomes, they have difficulties to process larger datasets, such as the entire h. sapiens genome.

to address this need, we developed sealer, a resource-efficient gap-filling software. sealer uses an assembly utility within the abyss package, called konnector  <cit>  as its engine to close intra-scaffold gaps. we demonstrate the scalability of sealer on the white spruce  draft genome  <cit> , which it processes under 27 h using 40 gb ram – resources that can be found in contemporary commodity desktop computers. we evaluate sealer by running tests on experimental datasets, comparing runtime, memory usage, and gap-closing success rate against state-of-the-art gap-filling applications. we expect sealer to find a wide application for finishing small and large genomes alike.

implementation
algorithm overview
sealer performs three sequential functions . first, regions with ns are identified from an input scaffold file, and nucleotides flanking each gap are extracted. then, flanking sequence pairs are used as input to konnector along with a set of reads with a high level of coverage redundancy. typically, the reads represent the original dataset from which the draft assembly is generated, or may be reads from further whole genome shotgun  sequencing data generated from the same sample. the konnector utility is run with a range of k-mer lengths to connect the flanking sequences. finally, successfully connected sequences are inserted into the gaps of the original scaffolds, and a new gap-filled scaffold file is generated. sealer ignores size discrepancies between gaps and newly introduced sequences, since gap sizes are often estimated from fragment library distributions and assemblers do not generally provide confidence intervals for every region of ns. despite this, large expansions of the assembly are unlikely due to decreasing gap-closing yield of konnector as the gap size increases  <cit> . below are further details on these three steps.step 1: extracting sequences flanking gaps. sealer identifies regions of ns in an input assembly. it then searches for flanking sequences that do not contain ns, and are at least -l nucleotides long . the start position and scaffold id of each gap are recorded for downstream processing.

step 2: konnector assembly. the underlying engine for sealer is konnector, a tool to generate pseudo long reads from paired-end sequencing data by filling the unknown sequence between read pairs using the redundancy in sequence coverage. given a k-mer length and a read set, konnector builds a bloom filters to represent all k-mers in the reads, and retains k-mers that are observed with a certain threshold multiplicity or higher . it uses this data structure as an implicit de bruijn graph  <cit>  to perform a depth-limited, bidirectional, breadth-first graph search for a path that connects the flanking reads. in sealer, gap-flanking sequence pairs are used in lieu of read pairs.



sealer invokes konnector with a range of k-mer lengths. the advantage of this “k sweep” strategy is, gaps with low coverage have an increased chance of being closed by shorter k-mer lengths, while gaps with highly repetitive sequences are more likely to be closed by larger k-mer values. at each k-mer instance, all possible traversals within the depth limit are identified between each flanking sequence pairs. unique traversals, and traversals with path multiplicity less than or equal to a user-specified threshold  are reported as successful connections. consensus sequences are produced for multiple paths, reporting iupac ambiguity codes  <cit>  for mismatched bases. sealer records these generated sequences for subsequent insertion into a given scaffold.

to minimize peak memory usage, sealer performs these local assembly runs serially, such that there is only one bloom filter loaded at a given time. this implementation is beneficial for processing large genomes, such as p. glauca for which each bloom filter instance requires 40gb ram. further, it allows a subtractive procedure, where we eliminate successfully closed sequence gaps from the input of subsequent iterations, minimizing cpu run time.step 3: updating the draft assembly. the scaffold ids and gap start positions recorded during step  <dig> are used to match the new sequences to the corresponding gaps. however, the size of a gap and the length of a filled sequence may disagree, potentially shifting gap coordinates as sealer closes them. to avoid this issue, sealer processes gaps from 3′ to 5′, attempting to close the right-most gap first, moving left, making its way gap by gap towards the 5′ end of a scaffold. when a gap and new sequence are matched correctly, sealer removes the n bases and the flanking nucleotides in the selected window, and replaces them by the newly assembled sequence. the flanking nucleotides are also replaced since the assembly process may have modified portions of these sequences, correcting micro-misassemblies near the end of the flanking sequence by adjusting them so that they are concordant with the underlying read set. this may also occur if there are alternative solutions to the original assembly problem, as in the case of polyploid genomes with allelic variations.



experimental data
we used five datasets representing genomes of varying size  and complexity  to assess the scalability and performance of sealer over a range of conditions . all draft assemblies were generated using abyss using optimized assembly parameters. specifically, we downloaded e. coli k- <dig> substr. dh10b  illumina hiseq  <dig> paired-end reads from the sequence read archive  . we used the reference genome  from ncbi to assess the accuracy of the filled gaps. we closed gaps in this draft assembly with sealer using seven k-mer lengths , and using the konnector parameters -b  <dig> -f  <dig> -p  <dig>  we obtained experimental s. cerevisiae s288c  data from the european nucleotide archive. the corresponding reference was downloaded from ncbi . gaps were closed with sealer using the same seven k-mer lengths as for e. coli and the konnector parameters -b  <dig> -f  <dig> -p  <dig>  experimental c. elegans  paired-end reads were obtained from the sra. the latest version of the reference genome was acquired from wormbase . sealer closed gaps in the draft assembly using 64 k-mer lengths  and the konnector parameters -b  <dig> -b 1200 m -f  <dig> -p  <dig>  sequence reads for h. sapiens  individual na <dig> from the  <dig> genomes project were obtained from the sra, and the human genome reference grch <dig> obtained from genome reference consortium. gaps were closed with sealer using 31 k-mers , and the parameters for konnector were -b  <dig> -f  <dig> -p <dig>  p. glauca  v <dig> draft assembly  was downloaded from ncbi [genbank:gca_ <dig> ). we ran sealer on this dataset using two k-mer lengths  while using the konnector parameters -b  <dig> -f  <dig> -p  <dig> table  <dig> sequence read datasets used

e. coli
s. cerevisiae
c. elegans
h. sapiens
p. glauca



comparison to other gap-closing tools
sealer was compared to two similar tools: gapfiller   <cit>  and gapcloser , the latter in the soapdenovo <dig> package  <cit> . default settings were used for both tools in our tests, maximizing the number of compute threads, when needed . smaller datasets  were included in the assessment of sealer to accommodate gapcloser and gapfiller, which have high memory and runtime requirements, respectively.

the two were also tested on the 3-gigabase h. sapiens draft assembly, but gapfiller was manually stopped after running for over 350 h  without completion or output. neither one of the tools were used on p. glauca, based on their compute resource requirements on the high-coverage  h. sapiens data.

machine specifications
all sealer runs were benchmarked on a 12-core computer running centos  <dig>  with two intel xeon x <dig> cpus @  <dig>  ghz and 48 gb ram. all gapfiller and gapcloser runs were performed on a machine using centos  <dig>  with  <dig> cores @  <dig> ghz, 125 gb ram with the exception of the gapcloser run on the h. sapiens data. for that we used a machine running centos  <dig>  with  <dig> cores @  <dig>  ghz and 236 gb ram to accommodate the high memory requirement of gapcloser.

assessment of performance
to ensure consistent reporting of gap statistics, a script was developed that counts the number of regions with n bases in an assembly. this script was used to calculate the number of gaps before and after processing a draft assembly. a gap was defined as having one or a contiguous group of n bases. we used exonerate   <cit>  to analyze the accuracy of each tool. sequence alignments were used to calculate the average sequence similarities . inserted sequences of closed gaps, rather than entire assembly scaffolds, were aligned to the corresponding reference . with sealer, this was a straightforward process because of the comprehensive output it provides. along with the new draft assembly and a log file describing specific results of each k run, sealer also outputs a fasta-formatted file of all the newly generated sequences , which includes the original scaffold id and gap position. in addition, there is an option to output a fasta file of gap-flanking nucleotide sequence pairs . in contrast, neither gapcloser nor gapfiller output a file of newly inserted sequences. therefore, we had to develop a pipeline to identify and extract these novel bases for assessment and benchmarking the performance between all three tools. the pipeline begins by generating a file of all gap-flanking sequence pairs  found in the original assembly. it performs an exonerate alignment using these flanking sequence pairs and a gap-filled assembly as query and target, respectively. this returns the coordinates of flanking sequence pairs within the gap-filled assembly. using this information, the assessment pipeline extracts the bases found between each flanking sequence pair, and aligns them to the reference genome to determine sequence similarity. this pipeline was used on all three tools to maintain consistency in our analyses. we measured the runtime of sealer using the unix command ‘time’. we used the python script memusg  to benchmark peak memory usage. in addition to these analysis scripts, gap-closed assemblies of e. coli were manually inspected. using parts of the sequence assessment pipeline described above, newly generated sequences and their flanking sequences were extracted from gap-closed assemblies. these sequences were aligned to the reference using exonerate . the alignments of sequences produced by sealer were compared with the alignments of sequences generated by the other two tools. indels , mismatches and ambiguity codes were noted. we further analyzed the quality of the new draft assemblies using quast  <cit> . additionally, gene annotations , allowed us to determine whether the gaps closed by each tool spanned genic regions.

RESULTS
we benchmarked sealer, gapfiller  <cit>  and gapcloser  <cit>  on five datasets across a broad spectrum of genome assembly sizes . the comparators were chosen based on overall performance and resource requirements, as recently evaluated  <cit> . these studies considered several other tools that we did not include in our comparisons. image  <cit>  was not considered based on its prohibitively high processing time  <cit> .

gap-closing capability was similar between gapfiller and sealer , with sealer outperforming the former in two out of three small draft genomes . gapcloser never achieved a full gap closing success rate above 50 % in any of the datasets tested. we note that gapfiller and gapcloser both have the ability to resolve some of the unambiguous bases within a gap, even when the gap is not completely closed. in contrast, sealer produces an all-or-none gap closing output. a summary of the comparison results are presented in table  <dig> fig.  <dig> gap-closing success rates. results of gap closure of the tools tested on a broad-size genome data spectrum . baseclear gapfiller could not complete its run on h. sapiens. both gapfiller and gapcloser were not attempted on the p. glauca, due to their high resources requirements


e. coli

s. cerevisiae

c. elegans

h. sapiens

p. glauca


we took advantage of the small size of e. coli to manually inspect every sequence produced by sealer, gapcloser and gapfiller. we aligned these sequences to the reference genome to determine percent similarities. as shown in additional file 2: table s <dig>  sealer closed  <dig> of the  <dig> gaps while gapcloser and gapfiller fully closed  <dig> and  <dig> gaps, respectively. out of the  <dig> new sequences output by sealer,  <dig> had 100 % similarity to the reference genome. gapcloser also had 100 % similarity, but only from its two fully closed sequences. gapfiller performed similarly to sealer, obtaining 100 % similarity for all but  <dig> gaps. the gaps commonly closed by all  <dig> tools  comprised the same base sequence. furthermore, the sequences of commonly closed gaps between sealer and gapfiller were the same, with the exception of two gaps. three sequences produced by sealer contained ambiguity codes, consistent with the ability of konnector to report alternate bases when multiple assembly paths are possible.

for s. cerevisiae, of the  <dig> commonly closed gaps , percent similarities to the reference genome are  <dig>  %,  <dig>  % and  <dig>  % for sealer, gapcloser and gapfiller respectively. sealer successfully closed  <dig> of the  <dig> gaps in this dataset, outperforming the other tools.

for c. elegans,  <dig> gaps were detected as commonly closed. sequence similarities were reported as  <dig>  %,  <dig>  % and  <dig>  % for sealer, gapcloser and gapfiller respectively. these findings  show that the accuracy of the gaps closed by the three tools are comparable, while the success rate of sealer is the highest in all but one experiment.fig.  <dig> identity of closed gaps by sealer and two leading gap-filling applications. venn diagrams depict the overlap of gaps closed between each tool for the a) e. coli, b) s. cerevisiae and c) c. elegans datasets. the sizes of individual circles represent the number of gaps closed relative to the other tools. overlapping closed gaps were approximated using the assessment pipeline described in section  <dig>  and depicted using the online venndiagram.tk tool 



we note that the peak memory usage of gapcloser is up to one hundred times higher compared to sealer , and memory requirements are similar between sealer and gapfiller. for smaller genomes, gapcloser had the fastest run times, but consistently closed less gaps compared to the other two tools. gapfiller had the slowest run time for all the experiments. when closing gaps in the h. sapiens draft assembly, gapfiller was left running for over 353 h  before we manually killed the process. gapcloser was able to complete this dataset in three and a half days using  <dig>  gb ram, while gapfiller was still processing 19 % of the paired-end reads at the time of its termination, with no partial assembly output. sealer closed  <dig>  of the  <dig>  human draft assembly gaps, a success rate of  <dig>  %, in less than 30 h  compute time. compared to gapfiller, sealer used ~ <dig> times less memory to close marginally more gaps. likewise, sealer processed the colossal white spruce  <dig> gbp draft assembly in  <dig>  h using bloom filters for two values of k, and achieved a gap-closing success rate of  <dig>  %, closing  <dig>  of the  <dig> , <dig> gaps in the ncbi v <dig> draft assembly.

the results reported by quast  further supports the ability of sealer to produce quality draft assemblies. with the exception of the c. elegans assemblies, the resulting sealer gap-filled assemblies are contiguous, even when factoring mis-assemblies, as the nga <dig> length metric suggests. this indicates that the mis-assemblies in the sealer e. coli and s. cerevisiae assemblies tend to be on shorter scaffolds. in all genomes under study, sealer was marginally superior in its ability to close gaps located within genes compared to the other tools. average additional number of complete genes recovered by sealer compared to other applications for e. coli, s. cerevisiae and c. elegans is  <dig>  +/−  <dig> ,  <dig>  +/−  <dig>  and  <dig>  +/−  <dig>  in that order. we speculate that, when measuring number of ns per  <dig> kbp, quast is counting ambiguity codes as well, since no n bases exist in the contig files submitted to the analysis tool.

leading gap-filling applications, namely gapfiller and soapdenovo’s gapcloser resolve gaps by short read sequence alignments. current implementations of this paradigm have similar gap-filling efficiencies on small bacterial genomes  <cit> , which is comparable to that of sealer. they however, have difficulty scaling to larger genomes such as the whole human genome and sizes beyond. this will become increasingly more important as the data throughput from sequencing instruments continues to swell, and researchers undertake more de novo sequencing projects of large genomes. for such projects, even though it is possible to process assembly scaffolds in smaller batches on a compute farm, doing so would result in an overhead that is often impractical and requires specialized hardware and bioinformatics know-how. while our manuscript was in review we became aware of a promising, but not yet scalable, graph-based gap filling algorithm  <cit> , which was reported at the time to close 28 % more gaps in bacterial genome assemblies when compared to gapfiller and gapcloser.

sealer uses a light-weight bloom filter de bruijn graph assembler as its core assembly algorithm. this gives sealer a few advantages over alternative tools. 1) the entire  <dig>  tbp p. glauca read set  <cit>  easily fits on a 48 gb ram computer, a system that is now accessible to most labs. 2) the de novo assembly method sealer uses has the advantage of generating multiple paths through a k-mer graph, which could be used to effectively capture allelic differences and sequence variants, both key features to genetics and cancer studies. in contrast, gapcloser and gapfiller use coverage information and a threshold score to determine which consensus base is used in the case of a discrepancy, effectively stripping that information. 3) the fast bi-directional de bruijn graph assembly strategy, specifically allows one to exhaustively assemble k-mers across gaps using a comprehensive range of k values. we applied this strategy to the c. elegans dataset, testing  <dig> different k values . although this impacted its run time, sealer was still four times faster than gapfiller while closing above 70 % of the gaps, a yield comparable to that obtained by the latter. further, because the sealer run time is low and its memory footprint is relatively small, one could envision building bloom filters with additional data from the same sample, or even third-party data from same-species, to produce a mosaic assembly in a manner similar to the human genome reference.

when running individual sealer runs at unique values of k on 250 bp human experimental wgs read data, we find that k =  <dig> is more successful at closing gaps. when considering the entire k spectrum, being more permissive on the maximum number of assembly paths  increases gap closure by  <dig>  % overall . generally speaking, k-mers varying in size from  <dig> to 220 bp were all suited to close gaps in the human draft assembly, and gaps of equivalent sizes tend to close in a k-independent manner, with a slight constriction of gap length distribution with decreasing k . this is not surprising since konnector achieves maximum efficiency on fragments <  <dig> kbp  <cit> . on a practical note we recommend, whenever possible, exploring a wide range of k, typically from the read length l to k =  <dig>  which is the practical lower limit of k for konnector. for human, we ran sealer iteratively by exploring 31 k-mers from  <dig> to  <dig> nucleotides, and still completed the run in less than half the time compared to the next best application . when working with de bruijn graphs, shorter k-mers yield more tangled graphs but are useful when read coverage is inadequately low. on the flip side, the use of longer k-mers help disambiguate repeats and tangles in the graph when the coverage is sufficient, and are expected to help resolve gaps that arise due to repeats  <cit> . we find that, when used iteratively, both large and short k-mers close a similar number of gaps in the human data set . a combination of k-mers used in iterative cascading runs is thus warranted since, clearly, lower k values close more than half of the gaps that were not successful at larger values of k. also, larger k-mer values tend to close larger gaps and overlaps. generally, the first k-mer utilized closes the most gaps in iterative runs , which is why running sealer first with large k values that can more readily resolve repeats is recommended. we profiled the repeat content in gaps  <cit>  that were uniquely closed at a specific k-value during the iterative sealer run on the human assembly. we observe that gaps with sines are preferentially closed at a shorter k while those comprised of simple repeats, lines and satellites are preferentially closed with larger k-mers, which is intuitive. overall, we do not find many gaps harboring low complexity regions, small rna, and unclassified repeats, suggesting that we may have limited success in closing gaps comprising these features . we have randomly sampled  <dig> gaps that we could not close after the sealer iterative k runs on the human assembly draft. we observe that  <dig>  % +/−  <dig>  % of those are due to repeats in the hg <dig> reference human genome, as indicated by the corresponding regions harboring lower case bases in the reference genome. the +/−  <dig>  % interval refers to the 95 % confidence interval of this estimated rate.

gapcloser and gapfiller will resolve base ambiguities as they iterate through a subset of sequences even when they cannot fully close a gap. sealer on the other hand provides an all-or-nothing output, not reporting partially filled gaps when the number of possible reconstructions between flanking gap sequences exceed a user-defined threshold or when assembly paths are obscured. as a result, gapcloser and gapfiller results may have fewer ns per  <dig> kbp . however, we note that remaining gaps still require design and execution of finishing experiments, and arguably fewer gaps would be desirable over more but slightly shorter gaps. also, because gapcloser and gapfiller do not report their partially closed gaps, we were not able to test their accuracy.

CONCLUSIONS
finishing genomes has been relevant since sequencing h. influenzae, the first shotgun genome assembly  <cit>  and, more than ten years after publishing of the first human genome draft, we still do not have a complete assembly  <cit> . there have been few reasons for that, including difficulty in cloning, sequencing and assembling heterochromatin, as well as the lengthy, tedious nature of finishing work. but the prohibitive analysis cost is one of the main reasons why we do not completely finish genomes today. with dna sequencing affordability on the rise  <cit> , shotgun assembly of large genomes  is increasingly becoming routine in research laboratories, and widespread uptake in the clinic is anticipated. consequently, obtaining better draft genomes is a common goal of all de novo sequencing projects. further, de novo assembly and sequence finishing is also finding applications in many re-sequencing projects, especially in oncogenomics projects where comprehensive sequencing and nucleotide-level resolution informs clinical intervention  <cit> . sealer is a scalable gap-filling software expected to be an indispensable addition to the genome finishing toolkit, and with broad application to on-going finishing efforts.

whereas obtaining 100 % completion is unlikely without at least some computer-assisted manual finishing and labour-intensive pcr work, sealer brings human genome finishing and finishing of colossal genomes such as that of the  <dig> gbp white spruce one-step closer.

availability and requirements
project name: sealer

project home page:https://github.com/bcgsc/abyss/tree/sealer-release

operating system: unix

programming language: c++

other requirements: boost c++ library  and google sparsehash library

license: gnu gpl

any restrictions to use by non-academics: license needed

additional files
additional file 1: figure s <dig>  sealer gap-closing pipeline. pdf file depicting the steps to gap-filling genome draft assemblies with sealer. 

additional file 2: table s <dig>  table of gaps closed in the e. coli k- <dig> genome. pdf file presenting an in-depth gap sequence analysis in e. coli. 

additional file 3: figure s <dig>  compute resource required. pdf file showing benchmarking results of sealer, soapdenovo gapcloser and gapfiller for closing gaps in draft genome assemblies. 

additional file 4: table s <dig>  table detailing a quality assessment of gap-filled assemblies. pdf file reporting a quast analysis of gap-closed e. coli, s. cerevisiae and c. elegans draft genome assemblies. 

additional file 5: figure s <dig> individual sealer h. sapiens runs at unique values of -k and –p. 


additional file 6: table s <dig> closing gaps in a human genome draft assembly using sealer with different k value ranges. 

additional file 7: figure s <dig>  closing gaps iteratively in a cascading fashion at various values of k in the e. coli, s. cerevisiae, c. elegans, h. sapiens and p. glauca draft genomes. 



abbreviations
abyssassembly by short sequences

wgswhole genome shotgun

iupacinternational union of pure and applied chemistry

ramrandom access memory

gbpgiga base pairs

cpucentral processing unit

daniel paulino and rené l. warren contributed equally to this work.

competing interests

the authors declare that they have no competing interests.

authors’ contributions

r.l.w. and i.b. designed the research; r.l.w. and d.p. prototyped the application; d.p., b.p.v., t.r. and s.j. developed the software. d.p. and r.l.w. analyzed the data and made the figures; d.p., r.l.w. and i.b. wrote the manuscript. all authors discussed the results and commented on the manuscript. all authors read and approved the final manuscript.

