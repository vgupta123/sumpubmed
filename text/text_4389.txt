BACKGROUND
graphs or networks provide an excellent organizing framework for representing data from high-throughput experiments that measure interactomes, or genome-scale biological interactions: physical interactions between proteins; genetic interactions or specific phenotypes such as synthetic lethality between genes; gene regulation interactions between transcription factors and genes; and metabolic connections between enzymes and metabolites. in these networks, vertices represent genes, proteins, or other molecules, and edges represent specific interaction types  <cit> .

an important current challenge is to develop methods to analyze these and other networks, such as social networks  <cit> . one challenge is to infer network structure by identifying subgroups of related vertices, which in the biological domain may be inferred to have similar functions. a second challenge is to predict links that might exist but which are not represented in the data. missing links are prevalent in biological interactomes, where over half the true interactions may be absent from current data sets, and where spurious interactions may overwhelm true interactions in raw data  <cit> . even most ambitious physical interaction mapping technique was limited to ~ 20% of the total possible interaction space  <cit> . models based only on degree distribution have been unable to predict missing interactions  <cit> .

stochastic block models, in which vertices belong to groups and vertex-vertex interactions are determined by group membership, have shown promising results for network clustering in terms of probabilistic mixtures  <cit>   and admixtures  <cit>   of communities. typically these models assume a flat structure of k top-level groups, which has the technical drawback of requiring a pre-specified value or a search over a pre-specifed range. a more serious problem, however, is a “resolution limit” in which the existence of large groups fundamentally prevents the discovery of small groups  <cit> .

a recent hierarchical network model  <cit>  proposed by clauset, moore, and newman  provides a principled method for investigating structure at all levels by defining a probability distribution over network structures. this model avoids the resolution limit problem. it is also flexible in describing both assortative and disassortative networks. unfortunately, it requires lengthy markov chain monte carlo  simulation to sample over network structures. more fundamentally, this model imposes an exhaustive hierarchical structure at both the top level  and the bottom level  of a network.

here we describe a new algorithm, hierarchical agglomerative clustering , that provides a fast, deterministic approximation for optimizing a network probability motivated by cmn. a key observation exploited by newman and leicht  <cit>  is interactions with vertices outside a group often provide more information than within-group interactions. methods that focus on within-cluster interactions, such as bayesian hierarchical clustering  <cit> , modularity scores  <cit> , and even spectral methods  <cit>  often miss this information. we use this information to drive accurate bottom-up clustering using a novel model selection strategy to identify groups to merge and to detect when a subtree should be collapsed into a single cluster, similar to power graph  <cit>  but with a firm statistical foundation. a similar bayesian model selection step determines when clustering should be terminated, yielding a set of top-level clusters lacking evidence for further hierarchical structure.

we then show that hac achieves better accuracy in predicting missing links than other state-of-the-art algorithms. moreover, the automated detection of structure at both the top and bottom level is shown to be expressive and flexible when applied to physical and genetic interactomes.

methods
preliminary definitions
notation
a graph g is defined by a set of vertices v and edges e that connect pairs of vertices. this work considers undirected, unweighted edges with no self edges. extensions to directed, weighted, and self-edges are possible but are not discussed here.

a “flat” model. a model m defines how vertices are collected into groups. these groups are denoted c <dig>  c <dig>  …, ck for a model with k groups. each vertex is assigned to one of the k groups, and the groups are disjoint. this model can be summarized as m
= {ck : k ∈  <dig>  …, k}. subscripts u, v typically refer to individual vertices, and subscripts i, j, k refer to groups.

edge counts between groups can be summarized as  for i ≠ j, and  the binary variable euv =  <dig> for a u ~ v edge and  <dig> for the lack of an edge, or a hole. total pair counts are defined as tij = ninj for i ≠ j, and tii= ni/ <dig>  where ni is the number of vertices within group i. summary counts for holes are hij = tij — eij. for a given pair of groups i and j, the eij edges are modeled as the result of tij independent bernoulli trials with parameter θij. the probability of the observed edges, conditioned on θij, is   

the maximum likelihood value  is obtained by setting θij to its maximum likelihood estimate with a uniform prior, . a fully bayesian probability  is obtained by integrating out the nuisance parameter θij, again with a uniform prior:   

where beta is the standard beta function and xx =  <dig> for x =  <dig> 

for a flat model, with k/ <dig> parameters, the likelihood and fully bayesian probability are   

generalization to a hierarchical model
we can extend the notion of a model m to a hierarchical random graph  based on a model that successively merges pairs of groups  <cit> . this original model generates a binary dendrogram t. each node r in this dendrogram represents the joining of graph vertices l underneath the left sub-tree and vertices r underneath the right sub-tree. with the same bernoulli probability model  as a building block, er and hr are defined as the total number of edges and holes crossing between the left and right sub-trees. we generalize this model for the case of multiple top-level nodes, which merge together into a flat structure using a full block model. we also generalize for tree structures that are not completely branching, yielding tree nodes that collect multiple graph vertices into a single group. similar to eq. <dig>  letting m ≡ t, the likelihood l of a hierarchical model t and the corresponding probability p of the graph given the model are   

top-level terms  and  depend on the edges err′ and holes hrr′ crossing between the top-level groups r and r′, with trr′=err′+hrr′. for all tree nodes,  and . for branching nodes , the edges er holes hr refer to those crossing between the left and right sub-trees; for non-branching terminals, er and hr refer to the edges and holes for vertices within the terminal groups.

sampling trees with mcmc provides excellent results for predicting missing links by accumulating  values for link probabilities between left and right sub-trees  <cit> . we have found that extending the mcmc approach to genome-scale networks is computationally burdensome. approximation methods, such as a variational bayes approach  <cit> , can reduce computational costs, but still require a good initial estimate of tree structure. here we consider agglomerative approaches for finding trees t that optimize the objective function l and its fully bayesian counterpart p.


agglomerative clustering
maximum likelihood guide tree
suppose currently there are k top-level clusters numbered  <dig> … k within the r total tree nodes. this model, m, has k/ <dig> + r total parameters. merging two of the top-level nodes  gives a model with /2+  parameters, a reduction of k —  <dig> parameters. without loss of generality suppose we merge clusters  <dig> and  <dig> into a new cluster 1′, defining a new model m′. the model likelihood ratio is   

there is a subtle but crucial difference between this agglomerative algorithm, which assumes a full block model for the top-level nodes, and the more standard approach with a star-like structure at the top with a single parameter governing the interactions between all pairs of top-level nodes. a starlike model with k top-level and r total nodes has r+ <dig> parameters, and merging two groups increases the number of parameters by  <dig>  the increase in parameters at each step, coupled with a maximum likelihood model, is liable to over-fit the group structure. a further problem is the model likelihood ratio for the star model,   

where  and similarly hb = tb - eb count the edges and holes between all pairs of top-level groups before merging  <dig> and  <dig>  and e <dig> and h <dig> count the edges and holes just between groups  <dig> and  <dig>  under the star model, any two groups with the same values of e <dig> and t <dig> will have identical ratios . at the initial step, every pair of vertices will have one of two merging scores, depending on whether e <dig> =  <dig> or  <dig>  additional criteria are then required to avoid bad merges at the start of clustering. in contrast,  gathers information from shared patterns of connectivity with other grops. in particular, at the initial step when each group is a single vertex, , where the number of mismatches is 

greedy agglomerative algorithm
the likelihood ratio  leads to an agglomerative algorithm that successively merges the two clusters have the largest value.

initialize top-level clusters as {{v} : v∈v}

initialize k ← v

whilek >  <dig> do

find top-level clusters i,j with largest 

add top-level cluster r; l = i and r = j

remove clusters i and j from the top level

k ← k – 1

end while

we call this method hac-ml. the time complexity of a naϊve implementation scales as o, but using a priority queue, restricting possible merging pairs to clusters that share at least one common neighbor, and lazy evaluation of λ reduce the complexity to o, where e is the total number of edges and j is the average vertex degree.

bayesian model selection for top-level and terminal clusters
a natural stopping criteria at the top level is obtained by augmenting , eq.  <dig> with its fully bayesian equivalent ,   

a reasonable stopping criterion is  for the best merge  <cit> . while there are k/ <dig> possible merges, we do not include this factor in the stopping criterion.

our previous work introduced a similar criterion for collapsing bottom-level clusters comparing a model with separate left and right sub-trees with a model all vertices collected in a single group  <cit> . clusters with a single vertex are considered collapsed. during the merging process, if clusters  <dig> and  <dig> are selected for merging and are both collapsed, the probability ratio   

is calculated, where the subscripts indicate edges and holes within and between groups. the merged cluster is collapsed if . clusters of two vertices are always merged because λc =  <dig>  while there are  ways for the reverse process of splitting a cluster into two non-empty groups of sizes n <dig> and n <dig>  we do not include this factor in the model selection.

extension to multiple edge types
the hac-ml algorithm is directly applicable to networks with multiple edge types. rather than merging the edges into a single superimposed network, each edge type α defines its own likelihood l and probability p for a particular model m
. the full likelihood and full probability are then obtained as products over the edge types, l = ∏αl and p = ∏α p.

performance evaluation
data preparation
experimental evidence codes listed in biogrid database  provide a way to distinguish physical versus genetic interaction pairs. we built a physical network collecting all physically binding or interacting pairs and a genetic network restricted to negative interactions comprising to empirical evidence codes negative genetic, synthetic growth defect, synthetic haploin-sufficiency, and synthetic lethality. we ignored redundant pairs within each type of network such that resulting graphs were undirected and unweighted. we then iteratively removed isolated or degree- <dig> vertices, as these provide scant information for clustering. for other non-biogrid genetic interaction datasets we filtered out positively weighted pairs and applied the same iterative removal. in joint-network analysis, we restricted attention to the common intersection of genes.

other methods
we compared hac-ml with other deterministic methods: fast modularity , variational bayes modularity . cnm is an efficient algorithm that directly optimizes newman modularity  <cit> . vbm simplifies network data to one intra- and one inter-community probability distribution. for gdk by discriminating between even-length and odd-length paths, qi et al.
 <cit>  improved link prediction performance, particularly for disassorative  networks. we used the odd parity kernel with the recommended damping parameter set to  <dig> .

different merging scores
in addition, we also considered agglomerative clustering based on heuristic merging scores:  edge density, ρe;  combined edge density and shared neighbor density, ρe + ρs; and  decomposed newman modularity q from cnm  <cit> . the edge and shared neighbor densities for merging clusters  <dig> and  <dig> are      

the summations in ρs runs over all vertices u not in groups  <dig> or  <dig>  and the logical functions evaluate to  <dig> and  <dig>  the newman modularity for merging groups  <dig> and  <dig> is   

where du and dv are vertex degrees and e is the total number of edges. this algorithm is essentially cnm, but retains the hierarchical structure defined by the merge order for link prediction . replacing  with ρe, ρe + ρs, and q yields algorithms hac-e, hac-es, and hac-q.

link prediction
we assessed correctness of a model in the framework of link prediction as presented in henderson et al.
 <cit> . starting with a real-world network, training networks are generated by deleting a specified fraction of edges. a test set is defined by the held-out edges and a random choice of an equal number of holes. we then ran all methods on the training data set. the trained group structure provides maximum likelihood estimates for edges within and between clusters . for vbm and cnm, we estimated edge densities between all pairs of clusters and within all clusters. for hierarchical models, we estimated densities between all left and right clusters at all tree levels. for gdk, each pair’s diffusion was directly used to rank pairs. finally we assessed precision and recall of pairs in the test set ranked by link probability or gdk score. the counts of true positives , false positives , and false negatives  as function of the number of predictions define the precision, tp/, and the recall, tp/. the f-score is the maximum value of harmonic mean of precision and recall. this test set definition is suitable for assessment, but overstates practical performance by reducing the number of negative test examples for a sparse network. note that for large real-world networks, group assignments are generally unknown, making it difficult to assess group assignments directly.

implementation
algorithms were implemented in c++ and are available under an open source bsd license as supplementary material and from http://www.baderzone.org.

RESULTS
data preparation
interaction data was taken from biogrid  <cit>   for physical interactions within s.cerevisiae, a. thaliana, c. elegans, d. melanogaster, and h. sapiens. synthetic lethal and synthetic fitness defect genetic interactions were taken for s. cerevisiae. additional genetic interaction data sets were collected from genome-wide synthetic gene array   <cit>  and diploid-based synthetic lethality analysis on microarray   <cit> . the largest network in this study contains roughly  <dig> vertices and up to  <dig>  interactions .

symbols: v, number of vertices ; e, number of edges ;  , average degree. data sources:  biogrid  <dig> . <dig>  <cit> ;  we selectively included “negative genetic”, “synthetic growth defect”, “synthetic haploinsufficiency”, “synthetic lethality” experiments;  supp. data s <dig>  intermediate cutoff, of costanzo et al.  <cit> ;  supp. table s <dig> of pan et al.  <cit> .


empirical evaluation
summary results for link prediction demonstrate overall superior performance by hac-ml . of the  <dig> real-world networks, hac-ml is top or tied for top in link prediction  <dig> times, followed by gdk for  <dig>  cnm for  <dig>  and vbm for  <dig>  these summary results are for  <dig> % of known edges held out, and supplemented with an equivalent number of holes selected at random as an 85/ <dig> cross-validation set.


first numbers indicate an average f <dig> score of multiple experiments and second numbers following ± sign are standard deviations of last-digit .


more detailed results are provided for two of the largest networks, yeast-ppi physical interactions  and yeast-gen genetic interactions . the hac-ml method dominates along the precision-recall curve, and also generally performs best over many fractions of left-out edges . the high-precision region of the hac-ml prediction generally extends further than the other methods .

among top-ranked pairs, the flat models cnm and vbm perform worse than the hierarchical models. the performance of cnm is improved to nearly the performance of hac-ml by using hac-q to determine the merge order. the poor performance of cnm and vbm in the high-precision region may reflect the inherent resolution limit of a flat model  <cit>  that hierarchical models do not appear to be limited.

methods that consider shared neighbors, including hac-ml and gdk, also perform better than methods that ignore this information, such as hac-e. shared neighbors are strong predictors of missing links in networks of protein interactions  <cit>  and genetic interactions  <cit> . methods that consider shared neighbors, as opposed to just modularity or density, perform better for disassortative networks such as yeast-gen. the vbm method, which assumes homogeneous groups, may also work incorrectly when applied to networks with a mix of assortative and disassortative group structures.

multi-resolution views of a physical interaction network
bayesian model selection provides criteria for collapsing homogenous bottom-level clusters and for identifying top-level clusters that should not be merged. the size distributions for top-level and bottom-level clusters have long tailed distributions . power-law fits for maximum likelihood  <cit>  yield exponents close to  <dig>  albeit over only a decade of sizes.

edge densities within top-level clusters and bottom-level clusters have bimodal distributions, including edge densities of both  <dig> and  <dig> . clusters with density  <dig> can be generated when unconnected vertices share one or more interaction partners, a frequent pattern in both physical and genetic interaction networks. standard algorithms for identifying densely connected subnetworks  <cit>  perform poorly in these cases, whereas algorithms based on shared neighbors can still perform well  <cit> .

a representative example of a top-level cluster with bottom-level structure is the protein transport complex discovered in the yeast-ppi network . this cluster, with  <dig> vertices, has a hierarchical structure with  <dig> layers branching down to over  <dig> bottom-level clusters. the bottom-level clusters include examples both of cliques  and proteins that do not interact with each other but share common neighbors, including neighbors in other top-level groups.

visual inspection indicates that the bottom-level clusters are subsets of known go annotation categories, and may provide greater resolution than existing bottom-level go categories. these results also indicate connections between go categories learned from high-throughput data. an example is process of autophagy, which starts by forming a membrane-bound component that engulfs excess cytosolic proteins and make degraded in lysosome or other vacuoles  <cit> . therefore “vecicle fusion” and “vesicle-mediated transport” are its mechanistic processes; a proper “protein localization” and targeting is required. connections with plasma membrane proteins have become recently known, suggesting that plasma membrane is the source of autophagosome and autophagy is initiated by de novo assembly of proteins and lipids  <cit> . as autophagy is a response to starvation  <cit>  to re-use available intracellular resources. we find that disjoint low-level clusters correspond to “autophagy” and “golgi to plasma membrane transport”, suggesting that different proteins are responsible for transport in each direction. moreover seemingly distant relationship to “exocytosis” is under investigation  <cit> .

synergy in mixed networks
the extension to multiple edge types was used to compare link prediction for single yeast networks to link prediction from simultaneous analysis of physical and genetic interaction data . little evidence for synergy is apparent: predictions for a specific network are not improved by adding data from a second or third network. this behavior has been observed before for joint analysis of physical and genetic interactions  <cit> .


evaluation scheme was 85/ <dig> cross-validation. first numbers indicate an average f <dig> score of multiple experiments and second numbers following ± sign are standard deviations of last-digit .


this lack of synergy may arise from high-throughput studies exploring different subsets of genes and proteins. moreover our joint analysis assumes different types of edges are generated under a common group structure, but this pattern might be disrupted by a large fraction of false positive interactions, or some edge types might conflict with others. in presence of prevalent false positive interactions, physical and genetic interactions might not be directly complementary or orthogonal to each other in contrary to kelley et al.
 <cit> . in our simulation study, where orthogonality is well-preserved, hac-ml trained by multiple data sources significantly outperformed . to resolve this issue, a kernel-based method used by the previous studies  <cit>  can be beneficial, but this is an open research problem.

CONCLUSIONS
the hierarchical agglomerative clustering methods hac-ml is effective at discovering structure in real-world networks, with the ability to resolve both top-level and bottom-level groups. it provides superior performance for link prediction when applied to real-world networks, with a good tradeoff between efficiency and accuracy.

a general weakness of deterministic optimization heuristics is the possibly of becoming trapped in a local minimum. a more fundamental weakness is that different aspects of cross-cutting network structure may be reflected by multiple pertinent local minima. even so, the group structure generated by hac-ml can be used as a starting point for mcmc sampling over tree structures, which can provide better results than any single tree  <cit> .

unlike many agglomerative algorithms which effectively introduce a new parameter every time two groups are merged, hac-ml starts from a full model and removes parameters at each step. this approach gathers information from shared interaction patterns in building a guide tree, and then uses bayesian model selection to collapse the bottom level of the tree and terminate the clustering at the top level. extensions to joint analysis of multiple networks are provided, and extensions to more complex networks with weighted, directed, and time-varying edges are easily envisioned within the same probabilistic framework.

competing interests
the authors declare that they have no competing interests.

authors' contributions
yp and jsb developed the methods, analyzed the results, and wrote the manuscript. yp implemented the methods and performed the calculations.

