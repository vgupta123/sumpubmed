BACKGROUND
statistical potentials are widely used tools for protein structure analysis, modeling and quality assessment. many different aspects and properties of these potentials have been explored during the last few decades including the different theoretical foundations to derive them, the representation of interaction centers and types of interactions, and the various models for defining the reference state. combinations of various types and flavors of potentials are often used together in order to boost their performance. initially, statistical potentials were based on statistical mechanics  <cit> , however knowledge-based potentials now employ many other ideas, including the use of conditional probabilities to observe particular atom or residue distributions in specific conditions  <cit> , linear programming techniques  <cit> , linear and quadratic programming on various decoy sets  <cit> , or information theory  <cit> .

despite the seemingly similar formalism to derive statistical potentials in general, the alternative definitions may result in very different performances. the majority of statistical potentials are pairwise potentials. in addition, single body potentials, like the ones accounting for solvent accessibility  <cit> , were reported, as well as multibody potentials  <cit> . although pairwise potentials are frequently used in combination with other types of potentials to improve their performance, multibody potentials are much less used, apparently due to the high computational cost to apply them. in the present work we focus on pairwise potentials.

the majority of statistical potentials employ the boltzmann law to convert the observed frequencies of interactions into potentials. these potentials are obtained as the ratio of observed and expected frequencies, where the expected frequencies are derived from a hypothetical reference state when no interactions occur. while the observed interactions can be counted in experimentally solved structures, hypothetical protein models without interactions, which serve as reference states, are solely imaginary. therefore depending on their actual design they are potential sources of great variability in the performance of statistical potentials.

quasi-chemical approximation, a popular model for defining the reference state  <cit> , uses molar fractions of the corresponding interacting centers to calculate the expected frequency of their pairs in the system without interactions and otherwise does not provide any other assumptions regarding their spatial distribution. this approach implies a homogeneous, infinite system, which of course is not true for proteins. an interesting attempt to account for the finite size of proteins was to substitute the corresponding dissipation of the atom density with a reduced effective dimensionality of the space  <cit> . "isotropic" reference state, which is based on the occurrence of interacting pairs of any type at the given condition , appears natural and was also widely used  <cit> . however, it also approximates the system as infinite and homogeneous. a reference state that is free of these limitations was recently developed on a basis of shuffled systems  <cit>  and a similar approach was suggested in the dope  <cit>  potential. the reference state in the dope potential was defined as a homogeneous ensemble of non-interacting atoms in a sphere with the radius equal to the radius of gyration of a sample native structure, whereas our shuffled reference state model preserved spatial positions of the interacting centers in proteins, while their identities were shuffled. further improvements to dope potential have been reported later  <cit> . some other definitions of reference state, such as the use of decoys  <cit> , were also suggested.

different representations of interaction centers were explored in statistical potentials. two major classes of explored representations are residue level or atomic. the residue level representations use cα, cβ atoms or side chain centroids and are usually based on the  <dig> naturally occurring amino acids  <cit> , although both reduced  <cit>  and extended  <cit>  amino acid alphabets were explored, where the extended alphabet further classifies each residue according to the possible secondary structure types. another representation of interaction centers utilizes profile-based representation of amino acids residues  <cit> . for each protein a psi-blast  <cit>  generated alignment is used to create a position specific scoring matrix, which is converted into a set of evolutionary allowed amino acid residues for each position in the protein. then these sets are used to derive potentials in a similar way to methods published by melo  <cit>  and sippl  <cit> . side-chain-to-backbone and side-chain to side-chain residue level potentials were also described  <cit> . all-heavy-atom representations based on reduced  <cit>  and detailed all-atom protein representations were suggested  <cit> . more elaborate modifications of atomic alphabets consist of reduced set of atom types grouped by their chemical types and substitution states  <cit> . micro-environments of atoms were distinguished by their chemical nature and by the counts of surrounding atoms. a potential function based on two interaction centers per residue  <cit>  was also reported . these two centers were cα atoms and the side chain center of masses .

various models of interactions were explored during the developments of statistical potentials. the most widely used ones are the distant-dependent potentials, which either treat all contacts uniformly within a cutoff distance  <cit> , or account for their radial distribution  <cit> . similar to the distance-dependent potentials are the contact area  <cit>  and packing density potentials proposed by li and liang, . another frequently used interaction model is based on angular dependence. distributions of backbone ϕ, ψ torsion angles  <cit>  as well as virtual κ, α angles  <cit>  were explored. promising combination of these degrees of freedom depends on both distance and orientation, which became more widely used recently  <cit> .

comparative analysis of contact potentials demonstrated that majority of them can be approximated by simple sum of amino acid hydrophobicities, while the rest depends on the hydrophobicities as well as on electrostatic properties  <cit> .

in addition to the variety of ways to derive potentials, some additional techniques to improve their accuracy have been proposed. a trivial source of errors in statistical potentials is sparse statistics. two major workarounds were developed: the use of pseudo-counts  <cit>  and a weighting scheme suggested by sippl  <cit> . pseudo-counts simply add a unity to every count to avoid a division by zero when calculating fractions and do not try to normalize potential values in the case of empty counts, which could result in arbitrarily high positive values in certain cases. the weighting scheme assigns the average of all interaction types to the potential in the case of an empty count.

composite potentials combine various terms, which may include solvation, residue-level pairwise, atomic level pairwise, hydrogen bonding, steric, torsion or secondary structure packing. one such example is the rosetta scoring function  <cit> . another, more recent example for a composite scoring function is qmean  <cit> , which consists of six different terms: a torsion angle potential, secondary structure-specific, distance-dependent residue and all-atom pairwise potentials, a solvation potential as well as terms accounting for agreement of predicted and calculated secondary structure and solvent accessibility. a combination of mean force potentials, which account for distributions of pseudo-bonds, pseudo-angles, pseudo-dihedrals and distances between centers of interactions was studied  <cit> . another composite potential, utilizing both residue-level   <cit>  and its all-atom version  <cit>  combines energy terms for distance-dependent pairwise interactions with orientation preference, hydrogen bonding, short-range interactions, packing, tri-peptide packing, three-body interactions, and solvation terms. zhang and colleagues proposed a composite residue-level potential that consists of contact and local energy terms and employs a reduced alphabet of amino acids and a mapping of protein structures into a discrete state model  <cit> . the potential was generated by optimizing its components in order to guarantee a minimum energy gap between the native and decoy structures in a training set.

in the present work we perform a systematic comparison of many of the above listed scoring functions using a large and diverse decoy set that is based on models collected during various casp experiments  <cit> . we analyze the differences in their performances of ranking protein models as a function of various flavors of scoring functions. partially based on these results, we developed a novel residue level statistical potential that takes advantage of our earlier developed shuffled reference state definition  <cit>  but utilizes orientation-dependent accounting for residue interactions. we demonstrate that this novel potential is highly competitive with other scoring functions.

RESULTS
benchmarking potential functions
evaluating the performance of various statistical potentials using protein-like decoys is not a trivial problem. decoys must present a balanced range of difficulty or be specific for a particular task or property  <cit> . some scoring functions identify the native structure easily among a set of decoys but perform very poorly when it comes to identifying the most accurate model from the rest of the decoys in the absence of the native structure. this can happen because of overtraining on native structures or because of significant structural differences between the decoys and the native structure. as a consequence, benchmarks that include the native structure in the decoy set may not be informative or challenging enough for most scoring functions. on the other hand, a decoy set without a native structure has its own limitations because it is not guaranteed that a decoy with the highest geometrical similarity to the native structure  is also the one with the lowest energy. the model that is most similar to the native structure might have a higher energy due to some locally unfavorable features. nevertheless, this approach seems more practical because scoring functions are typically used in scenarios when the native structure is not known and only a variety of possible alternative models are available.

another problem arises when only one method or a limited number of methods is used to generate decoys, which is often the case for other available decoy sets  <cit> . in these cases a scoring function might be specific to implicit features of the decoy generation procedure but perform significantly worse if used to score decoys of different origin. these potential problems can be avoided with the use of a large number of targets in a decoy set and by a careful selection of decoy properties, such as using standardized similarity to the native structure and using a diversity of methods to generate decoy models.

in the present work, we tested scoring functions on decoys with and without the native structure, emphasizing on the latter set. "global distance test - total score" / <dig>  where gdt_pn denotes percent of residues under distance cutoff ≤ nÅ) values  <cit>  were used to assess structural similarity of decoy models to the corresponding experimental solution structure of the target. scores were binned in  <dig>  gdt_ts units , and bin numbers were used as rank values starting from the highest gdt_ts value. this scheme makes sets of decoys of different quality comparable to one another. although the choice of  <dig>  gdt_ts units for binning is subjective, any other value would be subjective to the same extent. meanwhile this value provides enough granularity for a statistical survey, while groups together essentially indistinguishable models. however, when native structure is included in a decoy set, this approach may over-penalize mispredictions. the gdt_ts score of a native structure is  <dig> by definition and, according to the selection process, the closest model can be as low as  <dig> . therefore, if the native structure is included in the test set, it may be separated from the most accurate decoy model by a significant accuracy gap, up to  <dig> bins. consequently, misrecognition of the native model, when it is included in the set, is heavily penalized. to overcome this effect, we always assign the rank of  <dig> to the first non-native structure, if the native one is present, regardless of the number of empty bins separating them.

impact of different protein representations on performance
according the representation of interaction centers used scoring functions evaluated in this study can be classified in three major groups:  atom-based, i.e. all-heavy-atom or reduced set of atom types, namely "qmean-all_atom"  <cit> , "opus_psp"  <cit> , "dope"  <cit> , "dfire"  <cit> , "shortle2006"  <cit> , vscore-pair  <cit> , anolea-like   <cit> , our "rf_ha", "rf_ha_srs"  <cit> , and "liang-geometric" potentials,  residue-based: "qmean-pairwise", "qmean-sse_agree", "qmean-acc_agree", "qmean-torsion", "qmean-solvation"  <cit> , "floudas-ca"  <cit> , "floudas-cm"  <cit> , "dong-pair"  <cit>  potentials, as well as potentials proposed in this work, "rf_cb_srs_od", "rf_cb_od", "rf_cb_srs", "rf_cb", and  composite potentials: "prosa-pair", "prosa-combined"  <cit> , "rosetta"  <cit> , "shortle2005"  <cit> , "qmean6"  <cit> , "opus_ca"  <cit> , "vscore-combined"  <cit> , and "pc2ca"  <cit> . composite potential functions most often are defined as a linear combination of residue-based long-range potentials with different kinds of local potentials, which are in most cases residue-based as well. in addition to the knowledge based scoring functions, a molecular mechanics potential, charmm  <cit> , as implemented in the namd  <cit>  package, was also evaluated. in terms of protein representation charmm can be categorized as a composite all-atom potential. models were evaluated after subjecting them to one or  <dig> relaxation steps, indicated as "namd 1" and "namd 1000", respectively.

the results of the benchmarking survey of the scoring functions are shown in table  <dig>  data are sorted by the average rank of the lowest energy decoy structure in the absence of the native structure. it is noticeable that the performance of different potentials varies significantly depending on the presence or absence of the native structure. in the presence of a native structure all-atom potentials are usually more sensitive . meanwhile, no interaction type preference is observed if the native structure is absent from the test set: residue or atom based or composite potentials all perform competitively. in addition, potentials with good performances in the presence of the native structure often exhibit rather mediocre performance if the native structure is removed from the decoy set. for instance rf_ha_srs, our all-atom potential with shuffled reference state definition  <cit> , is the best performing potential recognizing the native structure correctly in  <dig> out of  <dig> decoy sets but ranks only as the 6th best when tested on a set without the native structure . similarly the shortle <dig> potential, which is the second best recognizing the native structure among decoys ranks only 23rd among potentials when the native structure is removed. this may indicate that atomistic potentials are often over-trained to recognize native structures or, alternatively, it may indicate that side-chain placement by current modeling methods is not accurate enough. indirect support for the former hypothesis is the observation that reduction in number of atom types by joining chemically equivalent but distinct by pdb nomenclature types like phe-cd <dig> and phe-cd <dig> atoms into one phe-cd type results in the loss of potential performance .

a the average rank  in the absence of native structures.

b the number of sets when the best model was ranked as first, in the absence of native structures.

c the average rank when native structures are present.

d the average rank when native structures are present, calculated without compensation for the gap in ranking between experimental structure and first model .

e the number of sets when the best model was ranked as first when native structures are present.

¶expected random values were generated by picking a wining model from the decoy sets randomly. average values over  <dig> random trials are shown.

influence of different properties of scoring functions in test cases where the native structures are absent from the set of decoys is not as straightforward as it is in the case when the native structures are present. there is not a specific group of potentials that outperform others. the composite potential qmean <dig>  with its individually evaluated all-atom term and components accounting for secondary structure and solvent accessibility agreement, is among the best performing potentials. the residue level rf_cb_srs_od potential proposed in the present work compares competitively in this test. however, qmean "agreement-based" terms perform rather modestly in the presence of the native structure, and all other functions discussed here  underperform some other all-atom potentials , as mentioned above.

assessing statistical significance of performance differences
an important question in benchmarking various potentials is the assessment of the statistical significance of differences of their performances. we performed pairwise one-tailed wilcoxon tests on results obtained in the absence of the native structure . potentials are sorted in the same order as in table  <dig>  only p-values higher than  <dig>  are shown, pointing out pairs of scoring functions that are not significantly different from one another. we employed the wilcoxon test because the distributions of the calculated ranks of decoys that scored as best are highly different from normal. in this test the null hypothesis is that the ranks calculated by two methods under comparison share the same distribution and the one-sided alternative is that the ranks obtained with the method listed in the row of the fig.  <dig> are lower than ones obtained with the method listed in the column.

the importance of reference state definition
a large group of various potentials, specifically qmean residue-based pairwise and accessibility agreement terms , our atomic level potentials with shuffled  and classic  reference states, our residue-level potentials with and without orientation dependence and shuffled reference state , rosetta++ scoring function , both pairwise  and composite  versions of vscore potential, prosa <dig> composite scoring function , as well as profile based distance-dependent potential from dong group  and opus_psp potentials do not demonstrate statistically significant difference to one another . however, one can speculate that p-values obtained for the residue-level regular  and orientation dependent  potentials, both of which utilize a recently introduced shuffled reference state definition  <cit> , are superior to , which is a potential based on a classic reference state definition . orientation dependence is another important factor, which contributes significantly to the potential performance, resulting in statistically significant superiority the  potential over classic reference state potential . it is also interesting to mention that the distribution of ranks obtained with opus_ca scoring function is located significantly lower on the rank scale than most other potentials in this group, whereas the average rank value calculated with this potential is in the middle of this group. this fact can be explained by the observation that opus_ca is able to score decoys with the highest gdt_ts values as the best ones in many more cases than other potentials in this group . however, the relatively low average rank for this potential is because it exhibits a drastically high error in cases in which it fails to find the best structure.

the performance of the molecular mechanics based charmm potential depends on the number of steps of structure relaxation. the performance of the charmm is close to random after one and even after  <dig> steps of relaxation. a further 10-fold increase in the energy minimization steps brings charmm performance to the middle of the group of similarly performing potentials, discussed above . however, the exceedingly high computational cost makes the use of such long minimizations impractical.

effect of accounting for microenvironments on the performance
it is interesting to survey the common features among the best performing potentials. as we noted above, the choice of the type of interaction center  does not correlate with the performance. indeed, one can see, from the color coding of interaction center types in raw titles , that potentials of every kind can be found over the entire range of performances. the very small number of residue level potentials that are based on interaction centers other than cβ atoms  does not allow us to draw a conclusion about their performance. meanwhile, some conclusions can be drawn from the effect of certain other features of scoring functions, such as the use of solvent accessibility, torsion angle, accounting for secondary structure and consideration of orientation dependence. the aforementioned features are color-coded in the column titles of fig.  <dig>  the secondary structure dependent functions  perform better than average, whereas torsion angle dependent functions  perform worse than average. potentials using information on solvent accessibility  and orientation dependence  do not show a clear advantage.

it is interesting to see if the performance of various scoring functions varies with the quality of the best available model for a given target. this dependence is plotted in fig.  <dig>  panels   and  display the accuracy dependence of composite, all-atom and residue-based potentials, respectively. one can observe a general trend in the case of composite  and especially of all-atom potentials , according to which the performance improves with the improvement of the quality of the best available model. noticeable exceptions are composite vscore and prosa potentials, which perform visibly worse for the highest accuracy groups, when the best model has gdt_ts  <dig>  or higher. these two potentials include solvent accessibility term in addition to their distance dependent terms. solvent accessibility term may have limited benefit at this high accuracy level, when solvent accessibility of alternative models is essentially identical. another example of such "reversed" dependence is opus_psp, which is the best in the group of targets in the bin of  <dig> , but its performance decreases as higher quality models become available. the group of residue-based potentials  does not show the above trends. instead, this group collectively shows inferior performance for targets in  <dig>  bin as compared to the  <dig>  bin, as well as for targets in  <dig>  bin as compared to  <dig>  bin. an interesting exception is the performance of qmean-sse_agree  and qmean-acc_agree  potentials. both are among the best ones for sets of targets with lower quality , qmean-sse_agree keeps its leading position up to  <dig>  gdt_ts target group but looses its sensitivity as nearly perfect models of gdt_ts  <dig>  or higher become available. this observation together with the outstanding performance of the qmean-all_atom potential, which is also a secondary structure dependent one, confirms the previous observations about the general benefit of incorporating secondary structure information in the potential function. however, the qmean-acc_agree potential with solvent accessibility term loses its sensitivity much earlier. this behavior of the qmean-acc_agree potential is in agreement with earlier discussed behavior of composite vscore and prosa potentials, which also dependent on solvent accessibility.

we also reviewed the performance of the scoring functions as a function of various structural classes. because only  <dig> out of  <dig> targets are currently classified in the scop database  <cit> , the significance of such analysis is limited. we could not find a significant correlation between particular scoring function features and the fold classes . in general, all scoring functions show a better performance in case of α/β proteins, an average performance can be observed for all-α proteins and α+β proteins, while the worst performance is detected for all-β proteins.

CONCLUSIONS
in summary, the correct definition of the reference state used in statistical potentials is critical. in addition, there seems to be a benefit of including information on various protein microenvironments. an effective reference state definition should be free of systematic errors, as it is in our srs model, and actual interactions should be a function of amino acid frequency variations caused by local microenvironments such as different secondary structure preferences, and other deviations of local characteristics from the average.

