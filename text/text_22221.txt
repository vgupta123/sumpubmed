BACKGROUND
the goal for many real-time quantitative pcr  assays with clinical, forensic, or environmental applications is to develop a standardized method that can be implemented on an inter-laboratory scale. real-time qpcr assays are ideal for such applications due to high levels of precision, specificity, and sensitivity. real-time pcr allows for the continuous monitoring of pcr product production as the reaction occurs. under ideal conditions these products accumulate exponentially in the reactions, i.e. their quantities double with each thermal cycle. thus, real-time qpcr can be applied to determine a fixed threshold where the accumulation of pcr product is first significantly detectable over a real-time measurement background signal . the fractional cycle number where pcr product accumulation passes this fixed threshold is called the threshold cycle   <cit> . qpcr is based on the theoretical premise that there is a log-linear relationship between the starting amount of dna target in the reaction and the ct value that is obtained. the ct value can then be used to estimate the initial concentration of a dna target from an unknown sample.

relative and absolute quantification with real-time qpcr
two general strategies are often used to estimate dna concentration from ct values including relative and absolute approaches  <cit> . a relative quantification approach measures the change in target dna concentration relative to another reference sample. this approach is ideal in gene expression studies where the goal is to measure the regulation of a gene in response to a particular treatment. however, a relative approach can be limiting for qpcr applications designed to quantify dna targets with no clear connections to a reference target such as assays where the dna target is from an uncharacterized microorganism. relative quantification based qpcr methods can also be difficult to apply on an inter-laboratory scale for the enumeration of dna targets from highly variable, complex, and poorly described sample matrices such as gastrointestinal and environmental samples  <cit> .

absolute quantification is another widely used strategy. absolute quantification is achieved by using a standard curve, constructed by amplifying known amounts of target dna in a parallel set of reactions  <cit> . absolute quantification requires that the exact quantity of a standard is determined by independent means using spectrophotometry or an intercalating dye such as picogreen®  <cit> . for bacterial dna targets, genomic dna from pure cell cultures is preferred. cultivated bacterial cells can be isolated and counted to provide a conversion factor between mass of genomic dna, copies of target dna, and number of cells. however, this practice imposes a substantial restriction on the development of real-time qpcr methods targeting bacterial genes because an estimated 99% of the microbial diversity on the planet has not been cultivated  <cit> . when a dna target originates from an uncultivated microorganism, plasmid dna standards are often used. plasmid preparations are advantageous because these preparations generate high quality, pure, and concentrated standards that can be independently quantified and converted to number of copies of target dna. for absolute quantification approaches, an assumption must be made that plasmid and genomic dna amplify with the same efficiency. factors such as dna stability, base composition, secondary structure, and presence of complex mixtures of non-target dna could significantly alter amplification performance. a limited number of strategies have been used in an attempt to equilibrate these two types of dna for real-time qpcr applications such as treating genomic dna with a cocktail of restriction enzymes and dna ultrasonication  <cit> . however, many studies simply assume that there are no differences.

in addition to the uncertainty associated with amplification of plasmid versus genomic dna targets, there are a number of other sources of variability to consider when generating a calibration curve from absolute standards. uncertainty can arise within and between experiments from numerous sources such as inconsistencies in quality of reagents, pipet calibration, as well as dilution preparation and storage of standards. any of these factors could significantly alter ct measurements from experiment to experiment. therefore, estimation of uncertainty becomes critical to account for sources of variability and make reasonable estimates of calibration curve parameters.

estimating dna concentrations from ct values and propagation of uncertainty
simple linear regression is commonly used to estimate dna concentration from an unknown sample where the standard calibration model is developed with a dna concentration  and associated ct measurements. typically four to five known dna concentrations are selected and then triplicate ct measurements are taken at each dna concentration to fit a calibration curve. the fitted curve is then used to estimate the mean dna concentrations of unknown samples.

widely used standard methods for generating calibration curves from absolute standards and estimating dna concentration include the classical and inverse approaches. the classical approach assumes dna concentration as the independent variable and ct measurement as the dependent variable. usually each experiment is repeated three to four times, with three replicates within each experiment. even though triplicate ct measurements are taken at each dna concentration of each experiment, the average of the ct measurements is commonly used to fit the calibration curve  <cit> . the corresponding regression model is given by:

  yi~n,μi=α+β∗log⁡ <dig> i= <dig> ,...,n 

where, n is the total number of dna concentrations, yi is the average of the ct measurements at the ith dna concentration, xi is the corresponding dna concentration, α and β are regression coefficients and σ <dig> is the random error variance. for an unknown mean value of log <dig>  say log <dig>  a y value, say y <dig> is observed. the classical method uses y <dig> to estimate log <dig> by:

  log⁡10=y0−β^α^ 

where, α^ and β^ are least squares estimates of α and β, respectively. finding the standard deviation of log <dig> is not a simple statistical problem as it is a non-linear function of the estimated intercept and slope parameters. thus for given x, a 100% confidence interval is constructed for y^) first, as it is a linear function of intercept and slope parameters. the formula for this interval is given by:

  y^±tn−22∑]2)⋅∑2n− <dig> 

where zi = log <dig>  then the corresponding fiducial interval is reported as the confidence interval for x .

another approach in practice is to estimate the unknown dna concentration using triplicate ct measurements from one experiment to obtain the calibration curve  <cit> . the corresponding regression model for replicated data is then given by:

  yij~n,μij=α+β∗log⁡ <dig> i= <dig> ,...,n; j= <dig> , <dig> 

where, yij is the jth ct measurement of ith dna concentration. except for more data points, the above regression model is same as the model given by equation . the same least squares method is used to estimate the model parameters and then equation  is used to estimate unknown concentrations.

the inverse method to estimate the unknown dna concentration assumes a simple linear regression of x on y on the same replicated data given by equation  in the classical method  <cit> . the inverse regression model is given by:

  log⁡10~n,δij=δ0+δ1∗yij,i= <dig> ..n; j= <dig> , <dig> 

the inverse estimator of x <dig> is given by:

  log⁡10=δ^0+δ^1⋅y <dig> 

where, δ^ <dig> and δ^ <dig> are respectively the least squares estimates of δ <dig> and δ <dig>  an approximate 100% confidence interval is given by :

  log⁡10±tn−22∑2)⋅∑2n− <dig> 

an alternative approach to the classical and the inverse approaches is a bayesian method using a monte carlo markov chain  simulation technique. a detailed description of this method to generate a master calibration curve is discussed in the results and discussion section. bayesian approaches have been employed in many molecular applications and have been particularly useful for microarray data analyses to account for multiple sources of uncertainty arising from experimental variation, background noise, and the use of multiple hybridization probes with different lengths and base pair compositions  <cit> . bayesian principles have also been used to model pcr amplification curves  <cit>  and characterize the relationship between fluorescence chemistry and determination of ct values during real-time detection  <cit> .

here we report the use of a bayesian approach to generate calibration curves for the enumeration of target dna from genomic dna samples using absolute plasmid dna standards. calibration curves were generated from three independent real-time qpcr assays  using both genomic and plasmid dna standards to test the assumption that both dna types generate similar calibration curves. finally, a calibration curve was generated for an additional real-time qpcr assay  where only a plasmid absolute standard was available. to account for potential differences in amplification performance between the plasmid standards and genomic dna target from unknown samples, mcmc simulations were used to estimate the mean difference in slope and intercept from fitted curve equations for plasmid and genomic dna produced from assays btheta, entero <dig>  and entero <dig>  using the same mcmc approach, these differences were applied to the plasmid dna derived calibration curve for hf <dig>  the modified calibration curve was then used to estimate dna concentration from several unknown samples. the mcmc approach was ideal because it not only accounted for observed mean differences in plasmid and genomic dna standards, but also propagated intra- and inter-assay variation.

RESULTS
bayesian simulation method
the bayesian approach to statistical modeling is based on the premise that the uncertainty about unknown quantities, such as the parameters in a model, is described by a probability distribution; more precisely by a conditional probability distribution given all that is known, including the data as it becomes available. initially, i.e., prior to obtaining the data, the uncertainty about the parameters are described by what is known as the prior distribution of the parameters, which probabilistically summarizes any available prior information about the parameters. once the data is obtained and a suitable model for the observed data is chosen, the likelihood function of the parameters summarizing the information in the data can be mathematically expressed. the prior distribution is then combined with the likelihood via bayes theorem, to obtain what is known as the posterior distribution of the parameters. the posterior distribution is a probabilistic expression of the  uncertainty about the parameters, after incorporating the available prior information and the information contained in the data. it is therefore the posterior distribution that forms the basis for bayesian inference about the unknown parameters.

typically, summaries of the posterior distribution such as the mean and the percentiles are used as point and interval estimates of an unknown parameter. in this paper, we use the term bayesian credible interval  to refer to the interval with equal tail probability on either side under the posterior distribution. closed form solutions for these quantities are usually not available, but, in most cases, mcmc methods  <cit>  can be used to numerically compute the desired summaries of the posterior distribution. mcmc methods first use an iterative algorithm to generate a sequence of draws from a suitable markov chain. drawing a sufficiently long sequence, referred to as the burn-in phase, typically ensures convergence. convergence is needed for the estimates of unknown model parameters. examining the trace plots of the sample values of a model parameter provides evidence of when the simulation appears to have stabilized. subsequent draws, after the burn-in phase, is a  sample from the posterior distribution, which can be used to calculate desired summaries of the posterior distribution.

the mcmc calculations in this study were done using the publicly available software winbugs  <cit> . often, prior information about an unknown parameter may not be available. in such cases, standard non-informative prior distributions, i.e., probability distributions which contain little or no information about the parameters, are used, resulting in posterior distributions that are dominated by the likelihood. some of the advantages of the bayesian approach via mcmc are that it is capable of fitting models accounting for different sources of variability, and it allows for the appropriate processing of uncertainty when inference about complex functions of the model parameters are of interest. in such cases, the traditional methods tend to use approximations based on the basic summary values, i.e., estimates of model parameters and their standard errors, to obtain the inference, whereas the bayesian approach via mcmc accurately evaluates the inference using the joint posterior distribution of the parameters. the bayesian approach, however, also requires the specification of distributions of additional quantities in the models, as well as extensive simulation to fit them.

developing a calibration curve from a single qpcr experiment
a bayesian approach was used to estimate the calibration curve parameters. to estimate x <dig>  we use all the triplicate ct measurements from a single experiment to fit the calibration curve. the simple linear regression model given by the equation  was used here to fit the data. as no prior information is assumed for the model parameters α, β and σ <dig>  the following diffused prior distributions are used to estimate these model parameters:

 α, β ~ n  

 σ <dig> ~ inv. gamma. 

these are essentially flat priors , and hence would lead to posteriors dominated by likelihood. according to bayes theorem, the posterior distribution of the model parameters, α, β and σ <dig>  given the data y <dig>  ..., yn, is proportional to the likelihood, and the probability density of the prior distribution of α, β and σ <dig>  the mcmc method is employed using the winbugs software to obtain the required summaries of the posterior distributions of α, β and σ <dig>  for given y <dig>  the posterior distribution of

  log⁡10=y0−αβ, 

can be easily used to obtain summary statistics, such as mean, median and 95% bci, for the unknown dna concentration log <dig> .

developing a master calibration curve from multiple qpcr experiments
calibration curves from several independent runs are pooled together to obtain a master calibration curve. a hierarchical bayesian model is used to allow for run to run variability in estimating a master calibration curve. as several calibration curves are produced in this study, the slope and intercept parameters of the calibration curves are allowed to vary from run to run in developing a master calibration curve. equation  is modified to allow for run to run variability in the intercept and slope parameters. the general form of the regression model is given by:

  yijk~n,μij=αi+βi∗log⁡ <dig> αi~n,βi~n,k= <dig> ,..nij,i= <dig> ...n;j= <dig> ,..m; 

where, yijk is the kth ct measurement of jth copy number and ith run, xij is the jth copy number for ith run, αi and βi are regression coefficients for ith run, σi <dig> is the random error variance of the ith calibration curve, α¯ and β¯ are the overall regression coefficients, combining information from all runs. the following diffused prior distributions are used to estimate the model parameters:

 α¯,β¯~nσa <dig> σb <dig> σi2~inv. gammai= <dig> ...n. 

we also used the prior distribution recommended by dumouchel for σa and σb, which is based on the harmonic mean of the estimated variances of the intercepts and slopes of individual calibration curves  <cit> . dumouchel priors for σa and σb are given by:

  σa~u)/nσb~u)/n 

where, u stands for the standard uniform distribution u and var and var are respectively the estimated variances of the least squares estimates of αi and βi. the results obtained using the dumouchel and gamma priors for σa and σb are very similar. a mcmc simulation method was used to estimate the model parameters via winbugs software. convergence diagnostics of markov chain draws from the posterior distributions of the parameters were checked using trace plots, auto-correlation plots, and gelman and rubin diagnostics  <cit> , and found to be satisfactory .

for given y <dig>  by requesting the posterior distribution of

  log⁡10=y0−α¯β¯ 

from the winbugs program, one can easily obtain summary statistics, such as mean, median and 95% credible interval for the mean of log <dig> . replacing α¯ by αi and β¯ by βi in equation , we get the posterior distribution for the ith run . the estimated mean copy number corresponding to different ct measurements are plotted in figure  <dig> for entero <dig> genomic type . notice that the 95% upper and lower credible bounds and the fitted curve are for the copy number  in figure  <dig>  for comparison purposes, the averaged concentration data is used to obtain a fitted master curve and 95% bci, for mean dna concentration, and these are given in figure  <dig> along with the corresponding 95% bci using the raw data. it is better to use the raw data  as it allows accounting for the within and between run variations in constructing credible interval for dna concentration. allowing for these  variations would lead to more realistic and wider confidence intervals. consequently, the 95% bci is wider for the raw data than for the averaged data.

fitting a genomic dna calibration curve using three independent qpcr assays
in real time qpcr studies using absolute standards, usually a calibration curve is developed to estimate an unknown dna concentration. typically, either plasmid or genome type calibration curves can be developed for a given assay. but, there are instances where pcr assays designed to target genomic dna sequences must rely on plasmid derived absolute dna standards to generate calibration curves such as pcr assays targeting genes from uncultivated microorganisms. qpcr assays that rely on plasmid absolute dna standards to estimate genomic dna concentrations from unknown samples must either assume that there is no difference in the amplification efficiencies between these two dna types or estimate differences and account for this uncertainty in respective calibration curve statistics. a simulation method to estimate the genomic dna type calibration curve for the assay hf <dig> using both plasmid and genomic dna type curves of btheta, entero <dig> and entero <dig> assays is discussed in this section.

the model described in equation  was applied to all four assays with an additional suffix. in the following model, this suffix is set to  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig>  and  <dig> .

  yijkl~n,μijl=αil+βil∗log⁡ <dig> αil~n,βil~n,k= <dig> ,..nijl,i= <dig> ...n;j= <dig> ,..m;l= <dig> ,.. <dig>  

the following priors are used to estimate the model parameters:

 α¯l,β¯l~nσal,σbl~dumouchell= <dig> ...7σil2~inv. gamma,i= <dig> ...n;l= <dig> .. <dig>  

where the dumouchel priors for σa <dig> and σb <dig> are based on the least square estimates of αil and βil, respectively ).

to test for potential differences between genomic and plasmid dna standard curves, overall fitted curves representing seven to eight independent runs for genomic dna standards with a 6fam labeled probe and plasmid dna standards with a tet labeled probe for three fib assays  were compared using analysis of covariance  test. a significant difference between genomic and plasmid dna type approaches was observed in slopes for btheta  and entero <dig>  assays. thus the assumption that there are no differences between respective genomic and plasmid dna types held for only one of the three assays. for btheta, entero <dig>  and entero <dig>  the difference between the genomic dna type calibration curve intercept and the plasmid dna type calibration curve intercept are respectively α¯2−α¯ <dig> α¯4−α¯ <dig> and α¯6−α¯ <dig>  the respective differences between the slopes are β¯2−β¯ <dig> β¯4−β¯ <dig> and β¯6−β¯ <dig>  the fitted genomic and plasmid dna calibration curves indicated the least variability in posterior mean slope and intercept differences for entero <dig> and the most for entero <dig>  suggesting that differences between plasmid and genomic dna curves can vary from one pcr assay to another. as the genomic dna calibration curve is not available for hf <dig>  we used all three fib assays to modify the plasmid dna curve of hf <dig> to estimate variation between the known plasmid dna curve and the uncharacterized genomic dna curve. the intercept and slope of hf <dig> genome type calibration curve was estimated by adding the corresponding mean differences from the plasmid and genome type calibration curves of btheta, entero <dig>  and entero <dig> to the plasmid type curve of hf <dig>  thus, the intercept α¯ <dig> and slope β¯ <dig> of hf <dig> genome type calibration curve are given by:

  α¯8=α¯7+/3β¯8=β¯7+/ <dig> 

by utilizing the posterior distributions of α¯ <dig> and β¯ <dig> from the winbugs program, one can estimate the slope and intercept parameters of the genomic type calibration curve for entero <dig> . figure  <dig> gives the fitted plasmid and simulated genome master calibration curves for hf <dig> with a 95% bci.

estimating dna concentration from a modified master calibration curve
the modified master calibration curve for hf <dig> with intercept and slope parameters α¯ <dig> and β¯ <dig> was used to obtain estimate dna concentrations from recreational water samples . for given y, the posterior distribution of log <dig>  where

  log⁡10=/β¯8=y−{α¯7+/3}β¯7+/ <dig> 

was used to estimate the mean, standard deviation and 95% credible intervals for unknown dna concentration. estimates for four unknown samples are given in the output section of appendix b . even though log <dig> is a non-linear function of the parameters α¯ <dig> ...α¯7;β¯ <dig> ...β¯ <dig>  the bayesian mcmc simulation method can be easily applied to estimate x <dig>  to evaluate the impact of prior distributions, uniform prior was used for each of σa1and σb <dig> . no apparent difference was seen in the resulting mean, median or 95% bci of the two posterior distributions of any of the model parameters .

CONCLUSIONS
we employed a bayesian approach for the estimation of dna concentrations from environmental samples using absolute standard curves generated by real-time qpcr. our approach allowed us to account for uncertainty from multiple sources such as experiment-to-experiment variation, variability between replicate measurements, as well as uncertainty introduced when employing calibration curves generated from absolute plasmid dna standards. the bayesian approach also allowed for the estimation of model parameters from multiple models simultaneously unlike stepwise progression of estimates typically used in real-time pcr calibration calculations. the flexible modeling capability of the bayesian approach was ideal for real-time qpcr assays that rely on absolute plasmid dna standards for quantification and this method should be applicable over a wide range of study designs.

