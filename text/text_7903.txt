BACKGROUND
the inference of homologies among dna sequences, that is, positions in multiple genomes that share a common evolutionary origin, is a crucial, yet difficult task facing biologists. its computational counterpart is known as the multiple sequence alignment problem. there are various criteria and methods available to perform multiple sequence alignments . among these, given a distance function, to minimize the overall cost of the alignment on a phylogenetic tree is known in combinatorial optimization as the tree alignment problem   <cit> . the tap typically occurs as a subproblem of the generalized tree alignment problem  which looks for the tree with the lowest alignment cost among all possible trees  <cit> . the gtap is equivalent to the maximum parsimony problem when the input sequences are not aligned, that is, when phylogeny and alignments are simultaneously inferred.

an important element in sequence alignment and phylogenetic inference is the selection of the edit function, and in particular, the cost g of a sequence of k consecutive insertions or deletions, generically called indels  in the sequence aa could create the sequence attta. the same operation in the opposite direction would be a deletion. the sequence alignment implied would be a- - -a/attta, where - represents an indel). g can have a significant impact in the overall analysis  <cit> . there are four plausible indel cost functions described in the literature: g=bk   <cit> , g=a + bk   <cit> , g=a + blog k   <cit> , and g=a + bk + clog k  <cit> . simulations and theoretical work have found evidence that affine-logarithmic yields the most satisfactory results, but provides marginal benefits over the affine function, while its time complexity is much greater  <cit> . for this reason, many biologists adopt the affine indel cost function. 

for large data sets, a popular heuristic is direct optimization   <cit> . do provides a good tradeoff between speed, scalability, and competitive scores, and is implemented in the computer program poy  <cit> . for example, the alignment for the sankoff et al. data set  <cit>  produced by do has cost  <dig> , matching that of gestalt  <cit>  and salsa  <cit> . using an approximate iterative version of do that has the same time complexity, poy finds a solution of cost  <dig> , close to the best known cost of prodali   <cit> . all other  algorithms have greater time complexities compared to do . an important limitation of do, however, is that it was not defined for affine edit distance functions.

the properties of do and the gtap  for phylogenetic analysis were experimentally evaluated in  <cit> . the main conclusion of that study is that do+gtap could lead to phylogenies and alignments less accurate than those of the traditional methods . the initial work of ogden and rosenberg  <cit>  raised a number of important questions: do the conclusions hold if a better fit heuristic is used for the tree search in the gtap? what would be the effect of using an affine edit distance function? how do the hypothesis scores compare among the different methods? these questions have since been answered in various followup papers.

in  <cit> , the author found that the opposite conclusion can be drawn when a better fit heuristic for the gtap is used. that is, when the resulting tree is closer to the optimal solution, do+gtap is a superior method. moreover, a good fit heuristic is a fundamental aspect in phylogenetic analysis that cannot be overlooked.

although  <cit>  performed simulations under affine gap costs, the study used the non-affine distance functions described for do at the time of publication. whether or not a different distance function could yield different conclusions was tackled in  <cit> . the authors found that when using the gtap as phylogenetic analysis criterion under the affine gap cost function, the resulting phylogenies are competitive with the most accurate method for simulated studies   <cit> . it is important to note that  <cit>  used an early implementation of the algorithms presented in this paper .

a comparison of the tree scores of various methods was recently performed in  <cit>  and is implicit in some of the conclusions of  <cit> . the authors concluded that when using a heuristic fit for the gtap, the hypotheses have scores better than those produced by other methods. therefore, without hindsight , biologists would prefer the hypotheses generated under the gtap.

in this paper, we introduce and present experiments for a new algorithm affine-do. affine-do has the same time complexity of do, but is correctly suited for the affine gap edit distance. we show its performance experimentally, as implemented in poy version  <dig>  with more than  <dig>  experimental tests. these experiments show that the solutions of affine-do are close to the lower bound inferred from an linear programming  solution. moreover, iterating over a solution produced using affine-do has very little impact in the overall solution, a positive sign of the algorithm’s performance.

although we build affine-do on top of the successful aspects of do, do has never been formally described, nor have its basic properties been demonstrated. to describe affine-do, we first formally define do and demonstrate some of its properties.

related work
the tap is known to be np-hard  <cit> . due to its difficulty, a number of heuristic methods are applied to produce reasonable  solutions. the first heuristic techniques  <cit>  consist of iteratively improving the assignment of each interior vertex as a median between the sequences assigned to its three neighbors. this method can be applied to any initial assignment of sequences and adjust them to improve the overall tree cost. in recent work, yue et al. <cit>  used this algorithm in their computer program msam for the tree alignment problem, using as initial assignment the median computed between the  <dig> closest leaves to the interior vertex .

hein  <cit> , designed a second heuristic solution which is implemented in the treealign program. in treealign, sets of sequences are represented by alignment graphs, which hold all possible alignments between a pair of sequences. the complete assignment can be performed in a post-order traversal of a rooted tree, where each vertex is assigned an alignment graph of the two closest sequences in the alignment graph of its two children vertices. the final assignment can be performed during a backtrack on the tree. although this method is powerful, it is not scalable . moreover, the treealign program does not allow the user to fully specify the distance function. this algorithm was later improved by schwikowski and vingron, producing the best tree alignment known for the sankoff data set  <cit> .

the most important theoretical results for the tap are several  <dig> approximation algorithms, and a polynomial time approximation scheme   <cit> . these algorithms solve the tap from a theoretical perspective, but the execution time of the ptas renders it of no practical use. on the other hand, the 2-approximation algorithms have shown very poor performance when compared to heuristic methods such as that of treealign.

direct optimization   <cit>  is a heuristic implemented in the computer program poy  <cit> , which yields good execution times and competitive alignment costs. given that dna sequences have a small alphabet , do represents a large number of sequences in a compact way by using an extended alphabet . in the spirit of the treealign method, do heuristically assigns to each vertex, during a post order traversal, a set of sequences in an edit path connecting two of the closest sequences assigned to the child vertices. subsequently, in a pre-order backtrack, a unique sequence is assigned to the interior vertices to produce the solution.

do can be implemented with a time complexity of o, where n is the length of the longest sequences, and v  is the vertex set of the tree. for larger alphabets the total time complexity is o, where |Σ|≪n is the alphabet.

schwikowski and vignon  <cit>  published the best heuristic algorithm for the tap, as implemented in the prodali software. although powerful, this algorithm has a potentially exponential time and memory complexity, which in turn makes it non-scalable and difficult to use for the gtap. moreover, prodali is not publicly available. it is for these reasons that do is the algorithm of choice for the gtap, yielding slightly weaker tree cost approximations when compared to those of prodali, but suitable for better performance on larger data sets.

RESULTS
direct optimization
direct optimization  has only been described informally in the literature  <cit> , and to build on it, we must first fill this gap. at the core of the algorithm is the use of an extended alphabet to represent sets of sequences. we begin by exploring the connection of this method with those using a tree alignment graph.

in treealign and prodali, the set of optimal alignments between sequences are represented in an alignment graph. these graphs are aligned at each vertex in the tree to find their closest sequences. an alignment graph is then computed between these sequences, and assigned to a vertex of the tree. the alignment between a pair of such graphs, however, is an expensive computation, both algorithmically ), and in its implementation. prodali is more expensive in practice, as it not only stores the set of optimal, but also suboptimal alignments.

in do, not all the possible alignments are stored, but only one. however, it stores all the possible sequences that can be produced from this alignment. we will call such set of sequences a reduced alignment graph . thanks to their simplicity, do use a more compact representation of a rag, to permit greater scalability than that of treealign or prodali. do represents them as sequences in an extended alphabet by which we can then represent a complete rag with an array.

it is then possible to align rag’s, find the closest sequences contained in them, and compute their rag with time complexity o. the following section formalizes these ideas.

sets of sequences, edition distance, and medians
the first goal is to find a compact representation of sets of sequences produced in a pairwise alignment. for example, the alignment attga--c is represented in an alignment graph shown in figure  <dig>  such graph can then be extended to include intermediate sequences such as atg or atc .

the same information can be efficiently stored by using an extended alphabet Σp=p∖{∅} that includes all the subsets of Σ with the exception the empty set, as follows 

 {a}{t,indel}{t,indel}{g,c}. 

 we call such representation a reduced alignment graph . notice that all the intermediate sequences can be produced by selecting an element from each set in the rag, and removing all the indels from the resulting sequence. if a sequence can be generated by following this procedure, then we say that the sequence is included in the rag. the example then includes the sequences attg, attc, atc, atg, ac, and ag.

observation 1
let a∈Σp∗ be a rag. then there are ∏x∈a|x| sequences contained in a.

in the original problem definition, we are given a distance d between the elements in Σ. let dp=mina∈a,b∈bd, be the distance between elements in Σp. the following observation is by definition:

observation 2
for all a,b∈Σp, there exists an a∈aand b∈bsuch that dp=d.

define the rag edit distance by setting d=dpin equation  <dig> 

the sequence edit distance can be computed using dynamic programming  <cit> , following the recursive function: 

  e=mine+de+de+d 

with base cases e= <dig>  and e=e=∑1≤i≤|a|d. the affine case is more elaborate but possesses the same spirit and time complexity  <cit> .

we will show that we can find efficiently the closest sequences in a pair of rags, as well as their edit distance. thanks to these properties, a rag is used instead of an alignment graph, to bound the cost of a tree with lower time complexity.

lemma 1
for all rags a, b, there exists sequences u, v such that u is contained in a, v is contained in b, and e=e.

proof
we define a procedure to produce u and v . start with an empty u and v , and follow the backtrack of equation  <dig>  for each case, prepend the following to u and v : 

case  <dig> select an element x∈xithat holds observation  <dig> and prepend it to u. then find an element y∈ykthat is closest to x and prepend it to v. from observation  <dig> we know that d=dp.

case  <dig> select an element x∈xiclosest to indel and prepend x to u and indel to v. again from observation  <dig> we know that d=dp.

case  <dig> symmetric to case  <dig> 

□

observe that the overall time complexity remains o as in the original needleman-wunsch algorithm  <cit> .

the do algorithm
do, direct optimization
do , direct optimization) estimates the cost of a tree by proceeding in a post-order traversal on a rooted tree, starting at the root ρ, and assigning a rag to each interior vertex. 

data: a binary tree t with root ρ

data: an assignment χ:l→Σof sequences to the leaves l of t

data: s holds a set of sequences for vertex v, initially empty for every vertex

result: cost holds an upper bound of the cost of t,χ

begin

cost←0

foreachlevel of t, with the bottom level firstdo

foreachnode v at the leveldo

ifv is a leaf  then

s←〈ai,ai={χi}〉

else

data: v has children u and w

cost←cost + ep,s;

u,w← the alignment of s and s) respectively;

s←mp;

end

end

returncost

end

end

we have not defined yet mp to compute each rag. let mm be the set of elements in x and y  that realize the distance dp. let the rag between two aligned rags a,b∈Σp∗,|a|=|b|=n be 

 mp=〈xi=m〉. 

 without loss of generality, assume from now on that for all x∈Σ∖{indel}, d=b for some constant b.

lemma 2
let c=mp. then for all x included in c, there exists y and z included in a and b respectively, such that ep=e=e + e.moreover, y and z are  the closest sequences to c that are contained in a and b respectively.

proof
follows directly from the median definition and lemma  <dig>  □

lemma  <dig> is important for the correctness of the do algorithm. it shows that for every sequence contained in c, there are corresponding sequences in a and b of edit distance equal to ep. this lemma can then be used in the do algorithm to delay the selection of a sequence from each rag, and use ep directly to calculate the overall cost of the tree. without it, epcannot be used for this purpose directly.

definition 1
compatible assignments two assignments χ:v→Σ∗and χ′:v→Σ∗are compatible if both assign the same sequences to corresponding leaves, that is, for all v∈l, χ=χ′.

the following theorem shows that the tree cost computed by do is feasible:

theorem 1
there exists an assignment of sequences χ′compatible with χsuch that 

 do=∑∈ee,χ′). 

proof
let t have root vertex ρ. call χ′the final assignment of sequences to the vertices of t. select any x included in s and set χ′←x. then for each other vertex v with parent p, following a pre-order traversal starting at ρ, let χ←xwhere x∈Σ∗is included in s and is closest to χ′. from lemma  <dig>  we know that for any selection at p there exists a selection in its children that would yield the additional cost computed at p during the do algorithm. moreover, at each pre-order traversal step, we assign to each vertex v the closest sequence to χ′ included in s. again from lemma  <dig>  we know that the total cost of the two edges connecting p with its children must be greater than or equal to the additional cost computed for vertex p in the do algorithm. therefore, do≥∑∈ee,χ′). □

do is weaker than the alignment graph algorithms  <cit> , as the later techniques maintain the set optimal edit paths between sequences, or a superset including it. however, in these algorithms the overall execution time and memory consumption requirements could grow exponentially  <cit> . in contrast, do maintains a polynomial memory and execution time, making it more scalable, with competitive tree scores. moreover, do can be efficiently implemented thanks to the simplicity of the data structures involved.

the affine gap cost case
in practice, biologists use do because of its scalability and competitive costs. however, the do algorithm was defined for the non-affine distance functions =bk), and does not work correctly for the popular affine indel cost model  <cit>  =a + bk). under many parameter sets, do could produce worse tree cost estimations than those of the lifted assignment if used under the affine gap cost model . the fundamental reason for this problem is that lemma  <dig> does not hold for the affine gap cost , and therefore, ep cannot be directly used to correctly bound the cost of a tree.

to overcome this problem, we extend gotoh’s algorithm  <cit>  to compute distances heuristically for sequences in Σp∗, and define a new median sequence. with these tools, we modify do so that lemma  <dig> still holds to compute tree cost bounds.

heuristic pairwise rag alignment
let a and b be a pair of rag’s to be aligned. define the affine edit distance function, analogous to ep, using  <dig> auxiliary matrices , as 

 eaffp=min{g,d,v,h}. 

the matrices g,d,v, and h will be filled recursively. before defining them formally, the basic intuition of the procedure is that g is the cost of an alignment where ai and bj align elements other than an indel. d is the cost of an alignment using indel elements in aiand bj. v is the cost of an alignment where we use a “vertical” indel block by aligning bj with an indel. finally, h is the cost of an alignment where we use a “horizontal” indel block by aligning ai with an indel.

to compute these values, we define a number of accessory functions. the cost of a pure substitution subst=dp. symmetric to the substitution cost, we need the cost of extending a gap when indel∈a,b⊆Σ: 

 diag=0ifindel∈xandindel∈y∞otherwise. 

there are three remaining accessory functions required to compute the matrices g,h,v, and d. each function handles various cases where a or b needs to be added. the first function, go evaluates whether or not it is necessary to add a gap opening value when aligning ai with a gap: 

 go=0ifi=1andindel∈ai0ifi>1andindel∉ai−1andindel∈aiaotherwise. 

the second function go′ calculates the extra cost incurred when not selecting an indel in one of the sequences means splitting an indel block: 

 go′=subst+0ifindel∉xaotherwise. 

the third, and final accessory function, computes what would be the extra cost of extending an indel, that is: 

 ge=0ifindel∈xbotherwise. 

finally, the recursive functions for the cost matrices is defined as: 

  g=ming+substd+subst+go+gov+go′h+go′, 

  h=minh+ged+ge+go, 

  v=minv+ged+ge+go, 

  d=diag+ 

  mindg+go+go, 

with base cases g <cit> = <dig> d <cit> =∞,v <cit> =go, h <cit>  = go,g == d= v =∞,h= h + ge,1≤i≤|b|,v=v + ge, and g=d=h=∞,1≤j≤|a|.

the following theorem shows that if we align a pair of sequences in a,b, then we can bound the cost of the closest pair of sequences included in them.

theorem 2
there exists a sequence x contained in a and a sequence y contained in b such that eaffp≥eaff.

proof
we are going to create a pair of sequences x and y  contained in a and b respectively that have edit cost at most eaffp. to do so, follow the backtrack that yields eaffp, and at each position i and j in the aligned a and b assign xkand yk, where k is the alignment position corresponding to the aligned xiand yjas follows: 

 <dig>  g is the cost of aligning a1…iand b1…jwhen a non-indel element of aiand bjis aligned. if the backtrack uses g then assign to xiand yjthe closest elements in ai∖indeland bj∖indel. observe that all the cases in equation  <dig> align a non-indel element from aiand bj, and add a cost that is always greater than or equal to subst=d.

 <dig>  h is the cost of extending an indel in the horizontal direction. therefore, select xk=indel, and 

 yk=indelifindel∈bjy,y∈bjotherwise. 

if yk=indel, then the alignment of xkand ykcauses no additional cost in the particular alignment being built between x and y. otherwise, then there is an extra cost, of at least the b parameter, which both cases of equation  <dig> account for. additionally, if the previous pair of aligned elements are a pair of indels , then an extra indel opening cost is added.

 <dig>  v is the cost of extending an indel block in the vertical direction. the treatment is symmetric to that of h, with yk=indeland 

 xk=indelifindel∈aix,x∈aiotherwise. 

 <dig>  d is the cost of extending an indel in the diagonal direction, that is, when both a and b hold indels, and those indels are being selected during the backtrack. equation  <dig> ensures that this choice is only possible by assigning ∞ whenever at least one of aior bjdoes not contain an indel. otherwise, if this option is selected, then simply assign indel to both xk and ykwith no extra cost for the alignment of x and y.

□

the main algorithm: affine-do
we will now use eaffp to bound the cost of a tree using a post-order traversal, in the same way we did with do , direct optimization). in order to do so a rag to be assigned on each step must be defined , direct optimization). to create the rag m , do as follows in each of the  <dig> items described in the proof of theorem 2: 

 <dig>  if we selected two indels in xkand yk, don’t change m.

 <dig>  if xk=indeland yk≠indel, then prepend {indel}∪bj to m.

 <dig>  if xk≠indeland yk=indel, then prepend {indel}∪ai to m.

 <dig>  if xk≠indeland yk≠indel, then prepend {x∈ai,for some y∈bj,d=d} + {y∈bj,for some x∈ai,d=d} to m.

 <dig>  once the complete m′is created, remove all the elements mi={indel} to create the indel-less rag m. we call m the rag produced by maffp.

definition 2
affine-do affine-do is algorithm do, direct optimization, modified by replacing mpwith maffp, and epwith eaffp.

it is now possible to use the affine-do algorithm to bound heuristically the cost of an instance of the tap.

theorem 3
given a rooted tree t with root ρ, and an affine-do assignment s:v→Σp∗, there exists an assignment χ′:v→Σ∗such that x=χ′ and the cost computed by affine-do equals that implied by χ′.

proof
if there are no indels involved in the tree alignment, then the arguments of theorem  <dig> would suffice. hence, we now concentrate on the cases that involve indels.

to prove those remaining cases, we will use induction on the vertices of the tree. to do so, we will count the credits that each vertex adds to the subtree it roots as added by the affine-do algorithm. the credits represent the maximum total cost of the indels involved in a particular subtree; we will compare them with the debits incurred by a set of indels, and verify that the credits are always greater than or equal to the debits. to simplify the description, we will call type a subsequences of maximal size holding only indels, and type b subsequences of maximal size holding sets that include, but are not limited to, indels, and type c maximal subsequences holding sets with no indel. we will count without loss of generality the credits and debits within those subsequences. in figures  <dig> and  <dig>  type a is represented as a line, type b as a box with a center line, and type c as an empty box.

for the inductive step, consider the leaves of the tree. by definition, for all v∈l, s can contain subsequences of neither type a nor b, as there are no indels allowed. therefore, the theorem holds true, with a credits=debits= <dig> 

consider now the interior vertex v, with children u and v. in figure  <dig>  all the simple cases where the limits of the subsequences in s and s match those of s. it is straightforward to see that in all those cases credits=debits.

consider now the more difficult case when the blocks do not have exact limits. assume without loss of generality that s and s have a segment of type b, and s has in the corresponding segment a series of blocks of type a and c .  aligned with those of type b in s and s as maffp does not allow it.)
.

the total credit granted by equation  <dig> is c≥2ma+2b∑i=1msi. we can transfer c/ <dig> to u , so that in one edge rooted by u , a series of insertions corresponding to the subsequences s <dig> s <dig> …,smcan occur , while the other branch supports a single deletion of length l−∑i=1msi . the total debit of these events now rooted in u would be 

  a+b∑i=1msi+b≤c/2+a+bl. 

by the inductive hypothesis, the subtree rooted by u  has credits≥debits, and from equation  <dig> we also have that credits>debitsin p, therefore the theorem holds, and the overall tree rooted by p has a sequence assignment of cost at most that computed by the affine-do algorithm. □

theorem 4
if Σis small, then affine-do has time complexity o time, otherwise the time complexity is o.

proof
if the alphabet is small, then maffp and dpcan be pre-computed in a lookup table for constant time comparison of the sets. for large alphabets the maximum size of the sets contained in Σpcan be made constant. otherwise, a binary tree representation of the sets would be necessary, adding a |Σ| factor to the set comparison. each heuristic alignment can be performed using dynamic programming, with time complexity o where n is the maximum sequence length . each alignment must be repeated for |v| vertices during the post-order traversal, yielding the claimed time complexity. □

experimental evaluation
in this section, we describe the methods used to generate the instance problems, assess the solutions generated by each algorithm, and compare the algorithms. this allows the assessment of the performance of each algorithm, affine-do in greater detail, and an evaluation of affine-do using exact solutions for trees with only  <dig> leaves.

data sets
to generate the instance problems, we simulated a number of sequences using dawg  <dig> . <dig>  <cit>  with insertions and deletions following a power law distribution. the simulations followed random binary trees of  <dig> leaves comprising all the combinations of the parameters listed in table  <dig>  these produced a total of  <dig>  independent simulations. for each data set, we collected the true sequence assignment. this information allows the comparison of the cost calculated by affine-do with the cost implied by the true sequence of events. our expectation was to produce costs lower than those using the true sequence assignment.

all combinations of parameters were employed to generate the test data sets. the branch length variation equals the average branch length.

solution assessment
the sequences assigned by the simulation can be far from the optimal solution. to evaluate affine-do, we used two algorithms: the standard fixed states algorithm, which is known to be a 2-approximation, and the cost calculated by the solution of an lp instance of the problem. a good heuristic solution should always be located between these two bounds. as a comparison measure for each solution, the ratio between the solution cost and the lp bound was computed. the closer the ratio to  <dig> , the better is the solution.

this form of evaluation has the main advantage , of being overly pessimistic. most likely, the lp solution is unachievable, and therefore, the approximation ratio inferred for the solution produced by affine-do will most likely be an overestimate. to assess how over-negative the lp bound is, we produced  <dig> random sequences divided in triplets of lengths between  <dig> and  <dig>  for each triplet, the affine-do, the lp bound, and the exact solution were computed. these three solutions were compared to provide an experimental overview of the potential performance of our algorithm. we selected random sequences because preliminary experiments showed evidence that these produce the most difficult instances for affine-do.

algorithms compared
we implemented a number of algorithms to approximate the tree alignment problem. our implementation can be divided in two groups: initial assignment, and iterative improvement.

initial assignment
includes the fixed states , direct optimization  <cit> , and affine-do. each of these algorithms starts with a function χ and creates a χ′ compatible with χwhich is an instance solution. do and affine-do have already been described. the fixed states  <cit>  is a simple algorithm were the interior vertices are optimally assigned one of the leaf sequences of the input tree, yielding a 2-approximation solution  <cit> .

iterative improvement
modifies an existing χ′by readjusting each interior vertex using its three neighbors. this procedure is repeated iteratively, until a  maximum number of iterations is reached, or no further tree cost improvements can be achieved. the adjustment itself can be done using an approximated or an exact three dimensional alignment, which we call the approximate iterative and exact iterative algorithms. approximate iterative , uses do or affine-do  to solve the tap on the three possible rooted trees formed by the three neighbors of the vertex used as leaves. the assignment yielding the best cost is selected as the new center. the exact three dimensional alignment has time complexity o  <cit> . our implementation uses the low memory algorithms implemented by powell  <cit> , though they can be improved to o memory consumption  <cit> .

we compared msam  <cit> , affine-do, approximate iterative, exact iterative, and fixed states, using a lower bound computed with an lp solution. we do not include do in the comparisons because it could not solve this problem <cit> . it is therefore impossible to compare it directly with our algorithm. gestalt, salsa, and prodali were unavailable, and so, could not be used in our comparative evaluation. treealign did not produce a solution for the simulations within  <dig> hours of execution time, and therefore, was not included in the comparisons.

in total, more than  <dig>  solutions were evaluated. we only present those results that show significant differences, and represent the overall patterns detected. the exact iterative algorithm was only evaluated for the short sequences , due to the tremendous execution time it requires. fixed states followed by iterative improvement is not included because its execution time is prohibitive for this number of tests . nevertheless, preliminary analyses showed that this combination of algorithms produce results in between fixed states and affine-do, but not competitive with affine-do.

algorithm comparison
the most important patterns observed between the evaluated algorithms are presented in figure  <dig> and table  <dig>  in general, affine-do yields a better approximation than fixed states. according to the density histograms , the expected approximation ratio of  <dig>   in the best parameter combination, and  <dig>   for the worst. iterative improvement  has a small overall impact in the approximation ratio . in all cases, affine-do found better solutions than the simulations .

each individual indel has cost  <dig> 

although the combination of affine-do and iterative improvement produces better solutions, its execution time is dramatically higher. in the current implementation, running on a  <dig>  ghz,  <dig> bit intel xeon  <dig> cpu with  <dig> gb of ram, affine-do evaluates each tree in less than  <dig> second in the worst case, while affine-do + iterative improvement may take more than  <dig> hour per tree. for this reason, affine-do is well suited for heuristics that require a very large number of tree evaluations such as the gtap, where millions of trees are evaluated during a heuristic search.

approximation of affine-do
typically, the larger the sequence divergence, the larger is the approximation degree of affine-do. the same pattern is observed for larger a. to test an extreme case, were the branch length is maximal, we evaluated the behavior of random sequences in the same set of trees. figure  <dig> shows the results of this experiment.

the worst case is observed with an average approximation slightly over  <dig> . this variation, however, could have been caused by a more relaxed lp bound, which could be producing an overly pessimistic evaluation of the algorithm. to assess the importance of this factor, we evaluated its tightness experimentally.

comparison with an exact solution
to assess affine-do and the tightness of the lp bound, we computed the exact solution for  <dig> unrooted trees consisting of  <dig> leaves with random sequences assigned to their leaves, under all the parameter sets tested. figure  <dig> shows the density histograms for the results obtained.

note that the lp-inferred bound is overly negative even for these small test data sets, with the inferred approximation expected at around  <dig> , while in reality affine-do finds solutions that are expected to approximate within  <dig>  of the optimal solution, a 10% difference for trees consisting of only  <dig> sequences.

CONCLUSIONS
we have presented a novel algorithm that we have called affine-do for the tap under affine gap costs. our experimental evaluation, the largest performed for this kind of problem, shows that affine-do performs better than fixed states. however, we observed that the lp bound is too pessimistic, producing unfeasible solutions 10% worse, even for the smallest non-trivial tree consisting of  <dig> leaves. based on these observations, we believe that affine-do is producing near-optimal solutions, with approximations within 10% for sequences with small divergence, and within 30% for random sequences, for which affine-do produced the worst solutions.

affine-do is well suited for the gtap under affine sequence edit distances, and yields significantly better results when augmented with iterative methods. the main open question is whether or not there exists a guaranteed bound for do or affine-do. then, if the answer is positive, whether or not it is possible to improve the ptas using these ideas. additionally, many of these ideas can be applied for true simultaneous tree and alignment estimation under other optimality criteria such as ml and map. their use under these different optimality criteria remains to be explored.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
ww defined the fixed states and do algorithms. av developed affine-do and performed all analyses under supervision of ww. av and ww wrote and revised the manuscript. both authors read and approved the final manuscript for publication.

