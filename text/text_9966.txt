BACKGROUND
a voiced speech signal such as a vowel is created in the human sound production system through phonation and articulation  <cit> . in normal phonation, the vibrating vocal folds produce a periodic excitation, termed the glottal flow. due to this inherent periodicity, the spectra of vowels produced by normal phonation are characterized by a harmonic comb structure, i.e., distribution of energy at the fundamental frequency  and its harmonic integer multiples  located regularly in frequency  <cit> . this comb structure is then locally weighted in frequency by the resonances caused by the vocal tract. these resonances, termed the formants , determine the vowel category. changing the shape and the length of the vocal tract results in different formant frequency settings and, consequently, in variations of the perceived phoneme category. the f <dig> and its harmonics are the primary acoustical cues underlying pitch perception and the lowest two formants are regarded as the major cues in vowel categorization  <cit> .

the auditory n <dig> response of the electro- and magnetoencephalography , generated in the auditory cortices of the left and right hemisphere, reflects the acoustic properties of auditory stimuli : its amplitude is largely determined by stimulus onset characteristics and stimulus intensity and its latency varies according to both stimulus intensity and frequency. an increase in stimulus intensity decreases the latency of the n1m and, in the  <dig> –  <dig> hz range, the n1m is elicited at a roughly invariant latency. interestingly, in the frequency range of speech f <dig>  sinusoidal stimuli result in longer-latency n <dig> responses and this latency delay increases monotonically as stimulus frequency is lowered  <cit> .

with respect to phonation, the latency delay of the n1m is observable both when the f <dig> is present  <cit>  and absent  <cit> ; in the latter case, provided that the harmonic structure of the high-frequency components is intact, the result is the virtual perception of the fundamental frequency . with regard to articulation, the categorization of vowels might be based on temporal encoding of the formant frequencies  <cit> . for instance, the vowel /u/, which has relatively low f <dig> and f <dig> values , elicits the n <dig> at a longer latency than the vowel /a/, which has higher f <dig> and f <dig> values . previous studies have related these effects either to the f <dig>  <cit>  or f <dig> and f <dig> values  <cit>  of these vowels.

these latency effects of the n1m elicited by vowels have been documented to occur symmetrically in the two hemispheres  <cit> . this symmetry appears rather interesting when considering that speech stimuli comprising consonants  <cit>  have been found to elicit asymmetric n1m response behavior. however, given that vowels are the core phonemes of speech utterances  <cit> , and that they comprise spectral energy preferred by either the left or the right hemisphere , one would expect that isolated vowel sounds should result in hemispheric asymmetries as indexed by the auditory n1m response. hemispheric specificity of speech processing notwithstanding, no consensus has been reached on whether cerebral asymmetries are brought about only by attentional top-down modulation of cortical activity  <cit>  or whether they might be found already in the passive recording condition when the subject is not engaged in the attentive processing of vowel stimuli.

to summarize, the effects of voice excitation and articulation on cortical activity elicited by vowels have been studied extensively – but, more often than not, in isolation. this, obviously, might be considered a shortcoming in cognitive brain research, further emphasized by the fact that the two issues are inseparable in real speech communication. in addition, studies addressing the combined effects of phonation and articulation have typically used a much too narrow perspective in characterizing voice excitation; it is often quantified in terms of f <dig> alone while the role of the type of the excitation, and thereby also the set of underlying spectral cues, is ignored. this limited perspective, again, can be criticized from the point of view of natural speech communication: as an example, two representatives of the vowel /a/ can be created with equal f0s but with greatly different types of the voice excitation waveform. this results in two speech sounds, both perceived as the phoneme /a/ and, importantly, of the same pitch. however, their voice quality can be clearly different due to differences in the type of the excitation waveform. it is, for example, possible that the one /a/ sounds breathy due to use of a soft pulseform in the glottal excitation whereas the voice quality of the other /a/ is perceived as pressed resulting from the use of a sharper shape in the glottal excitation pulseform  <cit> .

besides the above-mentioned, restricted view on the role of the voice excitation type, we hasten to emphasize another, equally overlooked an issue in studies of speech production and perception: because of the wide range of their f <dig> and f <dig> values, vowels are also fundamentally different in terms of the distribution of energy over frequency. for instance, due to its high f <dig> and f <dig>  the sound energy in the vowel /a/ is distributed across a wide, 0– <dig> khz range of high-energy harmonics. however, in the case of, say, vowel /u/, the low positions of f <dig> and f <dig> strongly attenuate the higher harmonics and most of the sound energy is actually allocated at frequencies below  <dig> khz. this, then, results in variations in the perceived loudness of the stimuli, despite attempts to adjust the intensity of the stimuli using objective measures such as the sound pressure level .

recent studies conducted in the passive recording condition indicate that the overall harmonic structure of vowels should perhaps not be overlooked in descriptions of speech-evoked cortical activity. for one, the amplitude of the n1m is already modulated by the presence of periodic glottal excitation in vowel sounds: a vowel with this kind of excitation elicits larger-amplitude n1m responses than the same vowel with an aperiodic, intensity-matched noise excitation  <cit> . further, the amplitude of the n1m reflects temporal changes in the harmonic structure of speech created by glides in f <dig> while corresponding glides in pure tones do not affect the n1m amplitude  <cit> . contrasting these observations, both the amplitude and latency of the n1m are unaffected by the identity of loudness-matched vowels   <cit>  and by the lack of phonetic f <dig> f2-content in natural, periodically excited vowels  <cit> . regardless of the formant frequencies, the latency of the n1m elicited by speech sounds with different f0-values appears to be invariant and shorter than the latency of the n1m elicited by pure tones whose frequencies are adjusted to match the f <dig> of the speech sounds  <cit> . thus, these findings tentatively suggest that the presence of periodic glottal excitation in auditory stimulation might be an important prerequisite for the elicitation of speech-specific cortical activity.

given the lack of data on the combined effects of phonation and articulation, the present study was designed to investigate how different combinations of voice excitation  and formant frequencies  are reflected in the cortical processing of vowels as indexed by the auditory n1m response. to investigate the effects of phonation, we used the periodic glottal excitation extracted from a natural utterance and contrasted its effects with those of an aperiodic noise waveform and a tonal excitation represented by two sinusoids. the effects of articulation, in turn, were analyzed by introducing two natural-sounding vowels with an intact harmonic structure  and located in the opposite corners of the f <dig> f2-space. hence, as illustrated in fig.  <dig>  the study comprised two phonemes with known formant values, but created by three substantially different variants of excitation. the spectra of the vowels excited by aperiodic noise  were similar to their periodic counterparts, both in terms of the formant frequencies and the overall spectral envelope structure but, importantly, they lacked the comb structure of natural speech. further impoverishing the stimulation, we also utilized two-tone complexes /a/tone and /u/tone, where the sound energy was concentrated at two distinct frequency peaks corresponding to the f <dig> and f <dig> of /a/ and /u/.

perceptually, the vowels /a/per and /u/per were of normal voice quality while their aperiodic, noise-excited counterparts matched for intensity resembled whispered speech. both had a rich spectral structure and were recognizable as speech. in contrast, the tonal stimuli had an extremely sparse spectral structure not perceivable as speech. based on previous research  <cit> , we hypothesized that the type of phonation  should be reflected in latency variations of the n1m response. with regard to articulation, we expected that the different sound energy distributions of the vowels /a/ and /u/, caused by the different articulatory settings as explained above, should result in variations in the amplitude of the n1m. with regard to amplitude, latency, and source localization of the n1m, we were specifically interested to see whether asymmetries in the left- vs. right-hemispheric brain activity might arise already in the passive recording condition. finally, in line with the tentative findings reported in  <cit> , the experimental design allowed us to study whether human speech consisting of an intact, natural harmonic structure leads to a different spatial distribution of cortical activation than unnatural utterances.

RESULTS
as illustrated in figures  <dig> and  <dig>  the temporal dynamics of cortical activation as indexed by the latency of the n1m varied asymmetrically in the right and left hemispheres according to vowel category and type of excitation. this observation was confirmed by statistical analysis which showed a significant hemisphere by vowel by excitation type-interaction  =  <dig> , p <  <dig> ): in the right hemisphere, the periodic, aperiodic, and tonal variants of /a/ elicited the n1m at an invariant latency , and, interestingly, some  <dig> ms earlier than the three variants of /u/ . there were significant differences in all comparisons of the latency of the n1m elicited by the vowels /a/ and /u/ .

in the left hemisphere, the three variants of /u/ elicited the n1m at comparable latencies , although the n1m tended to peak earlier as stimulus complexity was increased . variations in the type of voice excitation had a marked effect on the latency of the n1m elicited by the vowel /a/: both the periodic and the aperiodic vowel elicited the n1m at a significantly longer latency than the two-tone complex . the 4-ms latency difference between the n1m responses to /a/per and /u/per was statistically non-significant, whereas the responses to /a/aper and /a/tone were faster than those to /u/aper and /u/tone .

with regard to response amplitude, the right-hemispheric n1m responses were more prominent than the left-hemispheric ones  =  <dig> , p <  <dig> ). in both hemispheres, the amplitude of the n1m varied according to both vowel category  =  <dig> , p <  <dig> ; hemisphere-vowel-interaction  =  <dig> , p = n.s.) and excitation type  =  <dig> , p <  <dig> ; hemisphere-type of excitation – interaction  =  <dig> , p = n.s.): as depicted in fig.  <dig>  the vowel /a/ elicited larger n1m responses than the vowel /u/ . furthermore, the vowels with periodic excitation elicited larger-amplitude n1m responses  than the vowels with aperiodic  or tonal excitation . the vowels with aperiodic and tonal excitation, however, resulted in equally large n1m responses .

corroborating previous observations  <cit> , the sources of the n1m were confined to a restricted area in both hemispheres , and the right-hemispheric ecd locations were more anterior than the left-hemispheric ones . the n1m responses to stimuli with natural, periodic structure were anterior to those elicited by stimuli with impoverished stimulus structure. in both hemispheres, the ecds for the periodic vowels  were roughly  <dig> mm anterior to those for the aperiodic vowels  =  <dig> , p <  <dig>  & f =  <dig> , p <  <dig>  for the left and right hemispheres, respectively). the ecds for the two-tone complexes  were located between those for the periodic and aperiodic vowels, differing statistically from neither. also, there were no differences between the ecd locations either along the medio-lateral or the superior-inferior-dimension.

discussion
here we studied the combined effects of phonation  and articulation  on cortical activity elicited by vowels with carefully controlled acoustic properties. brain activity elicited by natural, periodic speech sounds was contrasted with that elicited by the deficient harmonic structure of aperiodic speech sounds and two-tone complexes. both the type of excitation of the vowels and their formant settings resulted in hemispheric asymmetries with regard to the latency behavior of the auditory n1m response, suggesting that the left and right auditory areas of the human brain employ different strategies for extracting information from speech signals. further, given that the data revealing cortical asymmetries were derived in the passive recording condition, it appears that these extraction processes takes place without requiring, for example, top-down attentional engagement.

firstly, we were able to establish that vowels comprising the periodic glottal excitation elicited distinctly different time courses of the auditory n1m in the left and right hemisphere: the vowel /a/ activated the right-hemispheric auditory cortex some  <dig> ms earlier than the vowel /u/, whereas both of these vowels activated the left-hemispheric auditory cortex at the same latency. this indicates that the right hemisphere treats differentially vowels with different formant settings and may therefore be involved in the processing of articulatory cues. the right-hemispheric 10-ms latency difference occurred regardless of the type of voice excitation and is compatible with previous observations  <cit>  which have shown that the latency of the n1m is determined by the f <dig> and/or f <dig> frequency of the vowels, with the low-formant vowel /u/ eliciting a longer-latency n1m than the high-formant vowel /a/.

this latency effect of the n1m was complemented by modifications in the n1m amplitude according to both phonation and articulation. phonation had a straightforward effect, with the natural periodic stimulation always resulting in more prominent brain activity than aperiodic or tonal stimulation. with regard to articulation, however, matters become more complicated because it appears that the n1m amplitude depends on both the locations of formant frequencies and the overall spectral distribution of the stimulus energy. here, intensity matching was used to objectively normalize the overall energy  to the same value for all the stimuli. this procedure is typically used in laboratory settings to ensure that different stimuli represent the same sound pressure level. thus, using two clearly different articulatory settings, we were able to study the behavior of n1m evoked by speech sounds of equal phonation and overall energy but with different sound energy spectral distributions and established that the high-frequency periodic vowel /a/ elicits a larger-amplitude n1m than the periodic vowel /u/. the present data suggests that this could be attributed to differences in sound energy distributions: the periodic vowel /u/per, endowed with much lower frequency values of f <dig> and f <dig>  has sound energy mainly at these frequencies, thus resulting in amplitude-diminished n1m response compared to the periodic vowel /a/per which has sound energy distributed across a wider range of high-energy harmonics. this interpretation gains further support if one considers the n1m amplitudes in figure 4: the n1m amplitudes to the periodic vowel /u/ and the two-tone complexes, which have relatively similar distributions of spectral energy, are quite close to each other, whereas the large difference in n1m amplitudes elicited by the periodic vowel /a/ vs. the other five stimuli might reflect their large spectral discrepancy. understanding the effects of sound energy distribution on the behavior of n1m obviously requires further experimentation and this could be done, for instance, by studying the processing of speech sounds representing the same phoneme, such as /a/, but excited by different shapes of the periodic glottal excitation. the present observations already indicate that the amplitude of the n1m is sensitive to the energy distribution of the stimulus which can be affected, importantly, both by changes in phonation and in articulation, and any violation in the natural structure of speech sounds is carried over to n1m amplitude and latency dynamics.

the present observations also suggest that the processing of periodic vowels with different spectral energy distributions results in latency changes in the right hemisphere whereas the left hemisphere responds to these vowels at an invariant latency. therefore, we propose that the left-hemispheric constant-latency brain process in response to vowels with periodic glottal excitation is related to the ability to correctly categorize vowel identity irrespective of the considerable variations in their acoustic structure. this conclusion gains further support from a recent study  <cit>  showing that the periodic vowel /a/ elicits the n1m at a constant latency regardless of whether the voice pitch is that of a male, a female, or a child. here, the origin of speech-specific invariance in the left hemisphere is further narrowed down to the effects introduced by phonation, that is, the presence of the natural glottal excitation in stimulation: when the spectral comb structure provided by the periodic glottal excitation is replaced by an aperiodic one, the vowel with high-frequency f <dig> and f <dig> activate the auditory cortex at a significantly shorter latency than the vowel with low-frequency f <dig> and f <dig>  when the spectral structure of the excitation is further impoverished, this latency difference becomes even more pronounced: the two-tone complex /a/tone activates the auditory cortex at a very short latency, characteristic of high-frequency tonal stimulation  <cit> .

finally, it appears that stimuli with a periodic spectral structure are processed in slightly different brain areas than stimuli with an aperiodic structure, there being shifts in the ecd locations in the anterior-posterior direction. although the present observations provide corroborating evidence that the effect, despite being only of the order of 2– <dig> mm, is a reliable one  <cit> , we are still lacking a proper explanation of the underlying neuronal mechanisms. tentatively, one might suggest that stimuli with a natural harmonic structure evoke activity across larger neuronal populations than stimuli with an impoverished structure. consequent changes in the centre of gravity of the activated cortical areas would show up as shifts in the ecd location as well as in larger response amplitudes for natural sounds. alternatively, the more anterior activation for natural sounds might reflect the processing of speaker identity  which has been suggested to take place in anterior auditory areas .

CONCLUSIONS
the present study suggests that in human auditory cortex, categorization of speech sounds takes place irrespective of attentional engagement and is based on cues provided by both phonation  and articulation  which, consequently, lead to hemispheric asymmetries as indexed by the auditory n1m response. more specifically, the effect of the locations of the f <dig> f <dig> frequencies on the amplitude composition of the harmonics plays a major role in the categorical perception of vowels: the amplitude of the n1m in both hemispheres probably reflects the distribution of sound energy at different frequencies, and varies according to vowel category and the type of voice excitation. the latency variations of the right-hemispheric n1m appear to be attributable to the spectral energy distribution of the speech sound, while the invariant latency of the left-hemispheric n1m might be related to the ability of humans to categorize vowels irrespective of variations in pitch and loudness. the present study indicates that the simultaneous presence of the natural glottal excitation and formant frequencies is a prerequisite for the emergence of the speech-specific cortical activation as reflected in the auditory n1m response. therefore, based on the above, we propose that speech-specificity should be understood as specificity to the acoustic structure of natural speech.

