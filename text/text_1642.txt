BACKGROUND
the extensive collection of protein sequence and structure information has resulted in the creation of numerous classification resources for organizing proteins  <cit> . two main structure-based classification databases, scop  <cit>  and cath  <cit> , combine sequence, structural, and functional information to provide a hierarchical classification of known protein structures in the protein data bank   <cit> . in the scop database, for example, proteins are organized into a four-level hierarchy: class, fold, super-family, and family. members of the same family group share a clear common evolutionary origin, supported either by significant sequence similarity or significant structural and functional similarity. the families are grouped into super-families based on structural or functional similarity that suggest a probable common evolutionary origin. the fold level groups proteins based on the arrangement of major secondary structure elements. and finally the class level groups proteins according to their secondary structure element content: mainly α, mainly β, mixed α and β, or small structures.

classification hierarchy levels that group evolutionarily related or structurally similar proteins provide important insight into the evolution and functional relation between proteins; therefore the development of fast automatic methods for reliable relationship detection at these levels is an active area of research. due to the absence of significant sequence similarity, relationships between distant homologs  and analogs  are the most difficult to detect. despite recent advances in sequence-based approaches, these relationships can still only be detected by protein structure comparison methods.

in the past few decades numerous protein structure comparison methods have been proposed  <cit> . because of the inherent difficulty of structural alignment, accurate residue-based alignment methods remain computationally expensive. to allow high-throughput protein structure comparison and classification, a number of less accurate but very fast protein structure comparison methods have been developed  <cit> . these methods fall into two basic categories. one group of methods  <cit>  first identifies potentially equivalent structural elements and then finds a maximal consistent set of such elements using either dynamic programming or graph theoretical methods. a second, more recently pursued, class of methods  <cit>  first maps a protein structure into a high-dimensional vector space. once the mapping is done, the structure comparison is reduced to a distance computation between corresponding vectors, as shown in figure  <dig>  and therefore is extremely fast and simple. we refer to this class of methods as projection methods.

even though projection methods do not produce a structural alignment as the result of comparison, there are two key applications in high-throughput comparative structure analysis, screening and classification, that may benefit from the ability of projection methods to perform fast and simple protein structure comparison. protein structure alignment servers are routinely used to compare a query protein structure against a large database of structures such as the pdb. in the screening application, a projection method can be used to rank the structures in the database, allowing the more computationally expensive residue-based structure alignment method to be applied only to the highest ranked  fraction of the database. in the classification application a query structure has to be assigned to one of the groups of structures in the database . furthermore, a vector representation of protein structure produced by a projection approach can be combined with machine learning techniques to provide powerful classification schemes. therefore improving the performance of projection methods and understanding the limits of these techniques is particularly important.

the central question in projection methods' approach to protein structure comparison is how to devise a mapping that is able to capture all the salient features of protein structure. over the past few years three projection methods have been proposed that employ very different approaches to the mapping construction. in pride <dig>  <cit> , gaspari et al. compute all pairwise distances between the central carbon atoms k residues apart , and use the distance distributions as a descriptor of protein structure. in sgm  <cit> , rogen et al. map a polygonal line passing through the cα atoms of protein backbone into r <dig> using geometric invariants borrowed from knot theory. in lff  <cit> , choi et al. apply an idea common to diverse application areas, such as text mining  <cit>  and classification of biological networks  <cit> , in which a complex object is represented as a high-dimensional vector of counts or footprint of its small size motifs. in the case of protein structure, such motifs correspond to structural fragments. choi et al. use pairs of backbone segments of size ten as structural fragments. since the space of all such fragments is not discrete, a finite set of representative structural fragments or models is selected. given a protein structure, its structural footprint is computed by making each structural fragment in the structure contribute a count of one to the closest  model. in this work we propose a novel projection method, sse footprint , that utilizes the structural footprinting paradigm and secondary structure information. even though many protein structure comparison methods use secondary structure information to speed up the computation  <cit>   and some of them use pairs  of secondary structure elements  <cit> , we are not aware of any method that uses triplets of secondary structure elements as structural fragments to produce a vector representation of the protein structure as a whole. we argue in the next paragraph that triplets of secondary structures are particularly suitable for producing such a representation.

as projection methods approximate structural similarity by distance between corresponding vectors, the success of such methods depends critically on the choice of the mapping function. in particular, the mapping function should be able to tolerate a certain amount of variability in the less conserved regions of distantly related structures. it has been established that secondary structure elements are more conserved than loop regions, regions of the backbone in between the secondary structure elements. therefore we reasoned that the mapping best suited for our purpose should capture the arrangement of secondary structure elements. towards this end we chose a set of models that represents a large variety of possible conformations of triplets of secondary structure elements. furthermore, we note that if, as in the lff method, each structural fragment contributes only to the closest model, then the footprint is indeed a vector of counts with each dimension being the number of appearances of the corresponding model in the structure. although this approach has an intuitive interpretation, it may be unstable when a structural fragment is almost equidistant from several models. to solve this problem, we allow a structural fragment to contribute to several models, with the most similar models getting the biggest contribution.

to evaluate our projection approach we perform a comprehensive comparison of our method with all currently known projection methods: lff  <cit> , sgm  <cit> , and pride <dig>  <cit> . the objective of our evaluation is to find out how well the methods perform in the context of two proposed application areas, screening and classification, and to understand what structural information is important for good performance. the later is possible as the methods evaluated use very different approaches to project a protein structure into a high-dimensional vector space. finally we measure the running time of the methods on a massive all-against-all structure comparison. we conclude the paper by discussing a potential connection between the type of structural information captured by the mapping and the performance of each projection method.

RESULTS
sse footprint method
there are three main components in the general framework that underpins structural footprinting: selecting a type of structural fragment, selecting a representative set of structural fragments as models, and computing the footprint. the type of structural fragment that is chosen to model protein structure and its representation may affect greatly the ability of the mapping to be effective in detecting pairs of similar structures, especially distantly related structures. in our method we use a triplet of secondary structure elements as a structural fragment. we approximate each secondary structure by a positional vector in 3d  and represent the spatial conformation of an sse triplet by a robust descriptor that captures the relative orientation of the corresponding sse vectors.

we select a set of p spatial conformations as models via a clustering technique applied to sse triplets extracted from a representative set of protein structures, in our case a set of fold representatives from every fold in the scop  <dig>  classification database. once the models are selected, each protein domain is mapped to a vector in rp, where each dimension corresponds to a particular model and records the "weighted" number of times the model is observed in the structure of the domain .

comprehensive evaluation of projection methods
for the results shown below we used the scop classification database version  <dig>  . we repeated all the experiments with the latest versions of the scop version  <dig>   and the cath version  <dig>   databases. in all performance evaluation tests we took a set of non-redundant proteins extracted either at 40% sequence identity  or at 35% sequence identity  as a set of database proteins.

performance in the screening application
in the screening application the set of similar protein domains depends not only on the query and the database, but also to some extent on the protein structure alignment method that is being sped up. to decouple our evaluation procedure from a particular protein structure alignment method and to evaluate the method's performance as a stand-alone application, we turn to the gold standard, the scop classification database  <cit> , for the definition of structurally similar protein domains or true relationships . in this work we use three scop classification levels to define true relationships. to measure a method's ability to detect structural similarity between closely related domains we use scop family level, i.e., we say that a pair of domains is related if they belong to the same scop family group and unrelated otherwise. to measure the method's ability to detect structural similarity between distantly related protein domains, on the other hand, we use scop super-family and fold levels.

to measure how well a projection method performs in the screening application we use a variation of widely used roc curves. given a projection method and a database of protein domains, each query protein domain defines a curve, which plots coverage  against the number of errors . to obtain one curve per projection method that shows the method's performance for queries from different classification groups, the individual curves were averaged, first across different queries in the same classification group and then across different classification groups .

the coverage versus error plots for scop family, super-family and fold classification levels are shown in figure 3–. even though each false positive result is an overhead for the structural alignment method being sped up with the screening, it is reasonable to assume that a few such errors can be tolerated as long as most of the related  domains are retrieved. thus, it is interesting to compare the coverage of different projection methods when the nth error is encountered. here we show the coverage up to the 300th error, where  <dig> is about 5%  of the total number of unrelated domains in the database; the coverage for different methods when the 300th error is encountered is given in figure  <dig>  for example at the scop super-family level, the ssef, lff, sgm, and pride methods retrieve  <dig> %,  <dig> %,  <dig> %, and  <dig> % of related domains respectively.

as expected, structural similarity between distantly related domains is more difficult to detect than structural similarity between close homologs for all four methods. thus, at the scop family level, the three best methods achieve 83% – 90% coverage at the 300th false positive and only 66% – 76% at the scop fold level. while the ssef method has better performance at all classification levels, the difference is most profound at the scop super-family and fold levels. the sgm and lff methods have comparable performance at the lower error levels, but at the higher error levels the lff gains about 4% in coverage over the sgm. the pride <dig> method has worse performance than the other three methods.

performance in the classification application
to evaluate the performance in the classification application, we reproduce the scop classification hierarchy using a nearest neighbor classification strategy. this classification scheme assigns a protein domain to the group of its nearest neighbor in the database . we compute two numbers per projection method and per classification level in the scop database. the first number  is the percentage of domains that are classified correctly, i.e., the fraction of domains whose nearest neighbor belongs to the same classification group as the domain itself. the second number  is an attempt to remove the bias towards large classification groups. to obtain this number we first compute the fraction of correctly classified domains within each group and then average across the groups.

the classification accuracies for the methods are given in table  <dig>  comparison of "% accuracy" and "% accuracy over groups" numbers shows that the nearest neighbor classification strategy is biased towards large groups. but the difference in performance between methods is consistent; the ssef method has the best accuracy at the super-family and fold levels while the lff method has the best accuracy at the family level.

the best classification accuracies ,  <dig> % at the family level ,  <dig> % at the super-family level , and  <dig> % at the fold level , indicate that there is room for improvement. manual inspection of accuracies of different groups revealed that some groups are hard to classify for some projection methods and easy for others. for example, the lff method classifies both members of the g.  <dig>  group  while the ssef has 0% accuracy for this group. the roles are reversed for the a.  <dig>   <dig> group ; the ssef method classifies both members correctly and the lff none.

running time
to compare the efficiency of the projection methods evaluated in this study we analyze for each method the running time needed to performall-against-all structure comparison of  <dig>  domains in the scop 40%-id dataset. all programs were run on a linux machine with an intel xeon cpu  <dig>  ghz and the results are shown in table  <dig> 

for any projection method the all-against-all structure comparison involves two steps: the first step is the pre-processing step where the structures are projected into vectors, and the second step is the pairwise distance computation between the set of vectors. if there are n structures in the dataset then the total running time is n × prep + n2
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaadawcaaqaaiabd6gaujabcicaoiabd6gaujabgkhitiabigdaxiabcmcapaqaaiabikdayaaaaaa@3407@ × eval, where prep is the average pre-processing time per structure and eval is the average time to compare a pair of structures. it should be noted that we use the pre-processing to denote the mapping of each structure into a vector, i.e., no pairwise computations are done during this step.

for applications of screening and classifications, we can assume that the pre-processing step is done once for the database proteins and therefore the running time spent on in this step is amortized as the number of queries against the database grows. even though the pre-processing step does not affect directly the effectiveness of a projection method, it may be indicative of the "amount of information" that is used during projection computation. for example, the lff method computes a very detailed description of the structural fragments it uses to generate the mapping; each pair of backbone segments of length ten is described by  <dig> ×  <dig> inter-atomic distance matrix between the cα atoms.

the running time spent on distance computations is mainly affected by the dimension of the projection, p. our method uses p =  <dig>  and takes about  <dig> times longer to compute the distances than the lff  and sgm  methods. but even the  <dig>  seconds to perform  <dig>  * / <dig> =  <dig> ,  <dig> protein structure comparisons is almost negligible compared to the time it would take dali  <cit>  to perform the same number of comparisons. we have used the dalilite program  <cit>  and estimated that one query against the same database of  <dig>   <dig> domains takes on average  <dig>  seconds or  <dig>  hours. therefore, unless a screening method is applied,the entire all-against-all comparison would take about  <dig>  hours or  <dig>  months to compute.

CONCLUSIONS
in this work we described a novel projection method for protein structure comparison. our method is different from other projection methods in that it uses the relative orientation of triplets of secondary structure elements in the projection computation. an extensive comparison to other currently known projection methods indicates that the projection technique used by our method better captures features of protein structure important for detecting structural similarity at all levels: from the structural similarity characteristic of closely related structures to the structural similarity characteristic of distantly related protein domains. moreover, the performance of our method is stable with respect to the secondary structure assignment algorithm used to define the sses. in the early stages of our work we used the secondary structure assignment from the mmdb database  <cit>  and found that the performance of our method does not depend on the actual secondary structure assignment, i.e., both the mmdb and the dssp  assignment schemes result in very similar performance.

our evaluation procedure concentrated on performance in two application areas uniquely suited for projection methods: screening and classification. the difference in performance between the methods is consistent across application areas and also across different classification databases , which allows us to speculate about the appropriateness of different projection techniques for protein structure comparison. based on our evaluation it seems that interaction patterns between atoms at most thirty residues apart do not carry a strong enough signal and the projection technique that uses this structural information alone did not perform well in our tests. we have been experimenting with the geometric invariants used by the sgm method, and they appear to emphasize local spatial interactions between line segments connecting neighboring cα atoms. as the lff method puts a 20°a threshold on the maximum distance between cα atoms, both the lff and the sgm methods capture local spatial interactions between residues and good  performance of both methods suggests these interactions are enough to capture structural similarity. finally, as indicated by the performance of ssef method, information about spatial conformation of triplets of secondary structure elements gives an edge, especially in detecting structural similarity between distantly related domains.

as projection methods produce a representation of protein structure in a vector form, they open the door to the application of machine learning techniques, such as support vector machines, to the task of protein structure classification. in this work we have used a simple classification scheme, the nearest neighbor classification, in the classification experiments. in our future work we plan to combine the ssef method with more powerful classification strategies to improve the classification accuracy. another direction for improvement stems from the fact that difficult-to-classify groups are not uniform across the methods. therefore, we also plan to investigate how classification decisions produced from different methods can be combined to obtain better classification accuracy.

