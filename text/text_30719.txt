BACKGROUND
the advent of rna-seq  <cit>  and dramatic decrease in next-generation sequencing costs have led to numerous rna-seq studies in recent years. this revolutionary technique has enabled digital transcriptome profiling at unprecedented resolution that avoids many of the limitations inherent to the analog nature of microarray technology  <cit> . however, despite numerous publications and the fact that rna-seq studies have supplanted microarrays as the gold standard for transcriptome analysis, it is not without its own inherent limitations.

early concerns regarding library preparation, sequencing error, read mapping, and gene expression quantification have been resolved by a number of studies; however, there is no standardized approach for quality control and data adjustment of rna-seq data after the generation of gene expression estimates. without an appropriate approach to data analysis, reproducibility of these studies remains limited  <cit> . further, the unique designs of sequencing studies suggest that a single black box approach is unlikely to be uniformly optimal across all experiments. thus, we propose an approach to address data cleaning, normalization, and adjustment in rna-seq data analysis . this pipeline is informed by best practices that we and others have developed for genome-wide association studies   <cit> , which also suffered from similar sources of error prior to the development of optimized methods.

we demonstrate the applicability of our approach in  <dig> autism-affected and control brain samples. specifically, our outlier detection method is based on utilizing the rna-seq gene expression estimates as well as dna and rna genotypes obtained from the same individual. further, expression quantitative trait loci  are biologically meaningful loci at which gene expression is modified by genotype. accordingly, we utilize replication of cis-eqtl data from two recently published brain studies  <cit>  as a means to assess the integrity of sequencing data and appropriateness of data handling procedures. we replicate the findings from this eqtl analysis in an independently-generated rna-seq data set of  <dig> blood samples from the genotype-tissue expression  project  <cit> . within the context of eqtl replication, we particularly highlight the need to identify and remove outlier samples in rna-seq experiments and further corroborate the necessity of accounting for unknown sources of variation in high-throughput data  <cit> . while a number of publications have presented methods by which one can analyze rna-seq data  and account for unknown covariates  <cit> , the steps we present herein ultimately provide a straightforward approach that allows for more accurate approximation of gene expression values that can be confidently used in downstream disease-based comparisons.

RESULTS
data normalization in rna-seq
brain rna-seq data were generated from post-mortem cortical samples collected from brodmann area  <dig>  in  <dig> control and  <dig> autism-affected cases . after estimating gene expression from the sequencing reads, two methods for data normalization were assessed: exploratory data analysis and normalization for rna-seq   <cit>  and conditional quantile normalization   <cit> . the normalized gene expression values from each algorithm demonstrated method-specific biases. examining p-values from our covariate adjusted case–control analysis, we note that normalization by cqn leads to a marked increase in the test statistics for shorter and low gc content genes , a problem not observed with edaseq . on the other hand, genes with both lower gene expression estimates and the assignment of zero values by edaseq led to an increase in outliers on a per-gene basis in our eqtl analyses , whereas cqn did a better job handling these genes . further comparison by eqtl replication to assess the biologic reproducibility  of these two normalization methods was performed with cqn slightly outperforming edaseq . while one unified approach that directly addresses the limitations of each approach more effectively would improve results, we selected cqn for downstream analyses due to its slight improvement in eqtl replication. nonetheless, we recommend that, until the presented issues are directly addressed, both methods be considered as part of an analysis pipeline.

identifying outliers in rna-seq data
in large sequencing studies, specific samples, for technical or biological reasons, can be recognized as outliers and should be removed from the study  <cit> . to identify outlier samples, whose global gene expression pattern is not explained by known covariates, we used principal component analysis , investigating the first six principal components, which together explain ~60% of the variance in the brain data. samples greater than three standard deviations  from the mean in any of the first six principal components were deemed outliers and removed from analysis  .

after sample-based outlier removal described above, it was apparent that, on a gene-by-gene basis, there were samples whose expression estimates differed greatly from the rest of the samples for that particular gene . using a cut-off of three sd from the mean,  <dig> %  <cit>  of genes tested for differential expression between cases and controls had at least one sample flagged as an outlier for gene expression level. as these sample outliers are gene-specific, they suggest a clear artifactual origin, as opposed to a problem with the sample as a whole. comparing the  <dig> most significantly differentially expressed genes between cases and controls before and after outlier removal, the lists differ at 60%  <cit>  of the genes present , demonstrating that inaccurate results would be reported if gene-by gene outliers were not removed. to further ensure that this was indeed biologically sound, we assessed the validity of this approach using our eqtl analysis .

after flagging outlier samples for removal in the brain data set, we obtained genotypes from both dna and rna. as a check on our data, we verified sample identity by comparing each rna-seq sample against all dna samples. pair-wise identity by state  distances  were calculated in plink with the expectation that dna and rna genotypes generated from the same individual should have a dst value approaching  <dig> . in all samples, dna genotypes best matched their corresponding rna genotypes with a dst >  <dig> , indicating that our dna and rna samples were, in fact, from the same individual.

despite correct identification of sample identity by ibs, three samples had borderline dst values , warranting further investigation. these samples demonstrated an unexpected genotyping comparison profile such that all three showed an increased number of genotype calls deemed homozygous by dna genotyping but called heterozygous at the rna level. as dna genotyping by affymetrix array has proven to be extremely accurate  <cit> , an excess of sites where the dna genotype indicates homozygosity but heterozygous calls are present at the rna level indicates possible contamination. we quantify these occurrences in each sample using a metric we refer to as the discordance ratio . for the majority of our samples, for which there is no suspected contamination, the dr approaches zero, with a value less than  <dig>  indicating rna-seq data of sufficient quality for further analysis. the three samples in question had elevated drs , suggestive of sample cross-contamination .

to address the possibility of contamination, we conducted a mixing experiment where we combined high quality rna-seq samples  in controlled ratios. we carried out variant calling on these intentionally contaminated samples as had been previously carried out in the rna-seq data and calculated the dr for each. this ratio was then compared between the rna-seq samples in question and those from which mixing had been simulated. this comparison suggests that, for the three sample libraries in question, 30-70% of the rna-seq reads originated from a different sample . as reads from a foreign sample would lead to inaccurate gene expression estimates, we removed these samples from downstream analysis, resulting in a final data set of  <dig> samples, comprising  <dig> controls and  <dig> cases.

reported brain eqtls are reproducible in rna-seq data
previously, surrogate measures of rna quality  have been used in an attempt to predict biologic validity, but none has been uniformly successful. using published sets of brain eqtls – regulatory genomic loci at which gene expression levels in the brain differ by genotype – we looked to recapitulate a number of the previously reported brain eqtls in our gene expression data. we postulated that if we could replicate these eqtls in our data, this would indicate that the use of post-mortem brain tissue may be representative of physiological conditions. we used a list of  <dig> cis-eqtls generated from two recent studies that detected brain eqtls in multiple disease populations across a number of brain regions  <cit>  . despite a smaller sample size and only one brain region under interrogation, we replicate  <dig> %  <cit>  of the tested associations  when age, sex, site and principal components are included as covariates .

monitoring eqtl replication to gauge quality control measures
we posit that if we are appropriately handling our data, known brain eqtls should demonstrate improved association after each data correction step as well as an overall increase in the number of previously reported eqtls that replicate. we have measured the ability to replicate known cis-eqtls associations using three metrics:  the percentage of known eqtls that replicate at p <  <dig>  after adjusting for genome-wide inflation   π <dig>  a statistic that estimates of the proportion of significant tests  <cit> , and  the percentage of known eqtls that replicate at q <  <dig> . when taken together, these three metrics offer a profile of the validity of each data handling step.

as part of the initial quality control, seven of the  <dig> samples  were flagged as pca outliers or contaminated samples, and removed. to assess the effect of sample removal, we compared eqtl replication in three data sets:  prior to outlier removal ,  after dropping pc outliers , and  after dropping likely contaminated samples . sample outlier removal allows for the detection of  <dig> % more known eqtls p <  <dig>  and  <dig> % more eqtls q <  <dig> . similarly, π <dig> estimates a dramatic increase in the proportion of replicating eqtls from  <dig>  to  <dig> . these data indicate the necessity of removing suspect samples in these data .

we further utilized eqtl replication to determine the most appropriate model for gene annotation. there is evidence that suggests expression levels estimated from rna-seq data at the coding sequence  alone correspond better with qrt-pcr measurements than rna-seq estimates that include both the cds and its untranslated regions . however, recent rna-seq analyses have generally included gene annotation from the whole gene – that is the cds and its utrs – under the argument that gene annotation gains accuracy upon utr inclusion  <cit> . to address this discrepancy in the literature, we compared these two gene annotation approaches by eqtl replication. the whole gene annotation clearly replicates known eqtls better than the cds alone  detecting 5% more known eqtls at p <  <dig>  and  <dig> % more at q <  <dig> . replication, as measured by π <dig> demonstrates an increase in this test statistic as well . this improvement in eqtl detection offers support for the use of utr inclusion in gene annotation in these data.

similarly, eqtl replication was used to compare normalization methods. we note that when considering the overall number of known eqtls detected, cqn replicates  <dig> % more eqtls  than does edaseq , further supporting its use in analyzing gene expression in this data set.

disease-based comparisons are frequently adjusted for known covariates . however, comparative studies are also frequently plagued by unknown covariates, or confounders within the data that are not easily attributable to any recorded measurement  <cit> . these unknown covariates can be approximated through various data decomposition methods. we initially considered using pca to accomplish this goal but observed that the first pc was correlated with both collection site  and disease status, which often occurs whenever different sites have differing fractions of cases and controls. as this could be a likely issue in many case–control studies, limiting the utility of pcs in downstream analyses, we also considered surrogate variable analysis   <cit>  and independent surrogate variable analysis   <cit> , as these approaches allow for disease status to be protected during their generation. lastly, we also considered utilizing peer  <cit>  to account for unknown covariates, as this method has been used and performed well in previous eqtl analyses  <cit> . in eqtl replication analyses, performance was comparable with isvs, svs, peer and pcs detecting  <dig> ,  <dig> ,  <dig>  and  <dig>  percent of the previously reported eqtls, respectively  . ultimately, however, to address the case–control confounding issue, we had to decide between isv and sv usage. to do so, we tested both methods by assessing q-q plots generated for disease-based comparisons. as the inclusion of svs, but not isvs, demonstrated inflated p-values in these analyses , we decided to move forward with isvs to account for unknown covariates.

finally, regarding covariate inclusion, we note that certain metrics for technical artifacts of sequencing  were correlated with specific isvs , suggesting that the unknown covariates detected by isva may simply be accounting for known technical artifacts of sequencing. we tested this possibility and demonstrate that, while including technical artifacts as covariates does improve eqtl detection over known covariates alone , both pcs and isvs perform even better, demonstrating a  <dig> % and  <dig> % increase at p <  <dig> , respectively, when compared to no covariate inclusion . these data ultimately support the inclusion of covariates, as captured by data decomposition methods, in downstream analyses suggesting that such methods are either  accounting for unknown covariates beyond technical sequencing artifacts or  appropriately weighting the effects of the technical artifacts amongst the isvs/pcs generated.

as noted above, sample outliers were also identified on a per-gene basis and removed from analysis. to ensure that removing these outliers was biologically sound and that these outliers did not represent true measures of differential expression, we tested data sets where sample outliers were removed at each gene using our eqtl replication approach. while per gene outlier removal did not demonstrate a marked increase or decrease in eqtls detected , the presence of outlier samples leads to a lack of robustness in the case–control analysis where single samples dramatically skewed the results . as per-gene outlier removal helped to stabilize the case–control analyses and did not hinder our ability to detect known eqtls, we support its inclusion in rna-seq data analysis.

independent rna-seq data set supports use of eqtl gold standards
to bolster the results of our brain rna-seq data set, we set out to replicate the main findings of our initial analysis in an independent rna-seq data set generated from a distinct tissue source. to do this, we used  <dig> blood samples from the gtex project  <cit> , for whom we had dna genotypes as well as raw count data from rna-seq. in these data, four samples  were identified as pc outliers, using the same criteria as was used in the brain data. sample outlier removal led to a slight decrease in the number of eqtls detected ; however, there was an increase in π <dig>  . normalizing using cqn again led to an overall increase in eqtls detected  . in assessing covariate addition, a pattern similar to what was seen in the brain data was observed. while known covariates  in the brain data did not improve the eqtl detection, there was a similar improvement seen upon the addition of pcs to account for unknown covariates  . again, per gene outlier removal does not hamper the ability to detect known eqtls .

discussion
just as it took more than ten years for the field to reach a consensus on the analysis of microarray data, rna-seq analysis has been undergoing a similar struggle since the first rna-seq publication. since then, accurate library preparation, appropriate mapping of short sequencing reads, and correct estimation of gene expression values have been the primary focus. while many of the original experimental and data analysis hurdles have been addressed, a framework in which one can assess the quality control and data adjustment measures taken after obtaining accurate gene expression estimates was lacking. for experiments with rna-seq data, dna genotypes and a list of tissue-appropriate eqtls, we demonstrate that our approach can be easily employed to generate a clean set of expression estimates for downstream analyses . specifically, we propose using the ability to replicate eqtls as a biologically meaningful check on the integrity of the data and to help ensure that the data is being handled appropriately at each quality control and data adjustment step.

we demonstrate that upon generating normalized gene expression estimates, pca can be utilized to identify global gene expression sample outliers and that dna and rna genotypes can be employed to verify sample identity and check for sample contamination. using the replication of known eqtls, we also demonstrate the importance of including both known and unknown covariates in downstream analyses. this result is consistent with expectation  <cit> , illustrating the utility of eqtl replication as a simple approach to assess data handling measures and offering credence to its usage in additional comparisons. this eqtl replication approach was further employed to demonstrate that isvs are not simply explaining known technical artifacts of next-generation sequencing, that gene annotation best replicates known biology when utrs are included in gene annotation, and that we do not overtly lose power to detect known eqtls when reducing the sample size by removing suspect samples.

of the data cleaning steps employed, we highlight the importance of removing individuals on a per-gene basis, as this is not a standard quality control step. indeed, either due to low coverage  or undetected pcr duplication , a sample may exhibit gene expression values vastly different than the rest of the samples, and as a result, should be removed from analysis at that particular gene prior to isv/pc generation. we note that this process is more important when using edaseq than when cqn is used for normalization, as quantile normalization produces fewer outlier values. in the brain data set, when edaseq was employed,  <dig> % of genes had at least one sample flagged as an outlier , whereas the nature of quantile normalization produced outliers in only  <dig> % of genes tested. nevertheless, with both methods, the differential gene expression analysis becomes more robust upon the removal of individual samples present in the data skewing the results . while these sample-specific outlier genes could certainly reflect an insertion-deletion event or another genetic variation in these individual samples, our goal is to maximize one’s ability to find eqtls and assess overall data handling measures, and as such, these individuals should be removed from analysis. given that our ability to detect eqtls is not hampered and that differential gene expression analysis demonstrates improved robustness upon per-gene outlier removal, we argue that this novel outlier identification approach be incorporated in future rna-seq expression studies.

the utilization of two distinct rna-seq data sets – one generated from brain  and another independently generated from blood  – helps to demonstrate the main findings of this work. in both brain and blood data sets, eqtl replication was improved with the use of cqn for data normalization and further improved upon the addition of pcs as covariates. further, in both data sets, removing per-gene outliers did not hamper the ability to detect known eqtls. however, there are data handling measures imposed on the data that were more important in the brain data set than in the blood data set, likely reflecting the fact that the brain data was plagued by a smaller sample size and that the sequencing data was generally of overall lower quality due to degradation of the starting material. reflecting the sample size difference, overall replication was higher across the board in the blood data set. further, the degraded nature of the starting brain rna-seq material was reflected in the need for extensive processing of the sequencing reads due to poor library quality. accordingly, sample outlier removal proved essential in the brain data set, but did not make a meaningful difference in the blood data. while the blood data set was less sensitive to the presence of outliers, this work demonstrates that despite the use of a degraded starting product, biologically meaningful data was still generated from the brain data and that careful data analysis can augment the information garnered from a limited data set. these distinctions between the two independent data sets furthers the point that each rna-seq experiment is unique and carries its own limitations, but eqtl replication can be used to guide one’s analysis pipeline.

finally, it is important to note that our eqtl approach was more helpful in some comparisons than others. while this approach can greatly help to guide one’s analysis, there will be cases where the choice is not so obvious and further steps will need to be taken to assess one’s data processing. for example, when comparing the three data decomposition methods  , the answer was unclear, as all methods do a similar job accounting for the unknown covariates. thus, the choice between the methods was based on additional criteria with pcs being excluded due to confounding within the first pc between sample collection site and disease status and svs due to their overinflated p-values in differential gene expression analysis . additionally, we note that there are several caveats to the use of data decomposition methods. first, when dealing with small sample sizes, including a large number of covariates can lead to overfitting of the data. second, data decomposition will minimize the ability to detect global differences in gene expression, which may be correlated with one or more of the eigenvectors .

in addition to this approach not being applicable for all comparisons, we note that rna-seq remains an imperfect measure of gene expression. technical and analytical limitations remain. cell type heterogeneity and the need for cdna generation currently result in unavoidable biases in data generation. while single cell rna-seq and direct rna sequencing methods will address these issues, any improvement that further reduces bias in library construction will lead to more accurate gene estimate values, allowing for further protocol improvement. additionally, improvements in mapping algorithms, normalization procedures, and gene estimate quantification will also aid in reproducibility.

CONCLUSIONS
in recent years, rna-sequencing  experiments have moved to the forefront of the transcriptomics field becoming the gold standard approach for the study of genome-wide gene expression. while this period has led to protocols that aim to optimize library preparation and computational methods that aid in improved mapping and accurate gene expression estimation, a method to assess downstream data handling approaches was lacking. here, we offer a framework that utilizes dna genotypes and rna-seq data along with previously published eqtls to assess possible sample contamination and assess the biologic validity of each data analysis step to ultimately enable confident downstream analyses.

