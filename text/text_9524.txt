BACKGROUND
the identification of conserved dna sequences by comparative genome sequence analysis has been widely used to annotate both protein-coding and gene regulatory elements in a wide variety of taxa  <cit> . while searching for these "phylogenetic footprints"  <cit>  is a powerful technique, traditional methods often make predictions from a single dna sequence alignment. by ignoring the possibility of alignment uncertainty, these predictions are highly sensitive to both alignment errors and regions where alternate alignments may describe the true evolutionary history. a dependence on a single alignment may be particularly harmful when searching for regulatory motifs, such as transcription factor binding sites , which are difficult to align reliably due to their short lengths  and tolerance of degenerate nucleotides  <cit> . recent studies have noted that single-alignment phylogenetic footprinting approaches often produce inaccurate or inconsistent results depending on the alignment method used, and have called for new techniques capable of controlling for alignment error and uncertainty  <cit> .

"statistical alignment"  <cit>  methods provide a framework for performing comparative genomic analyses while considering a probability-weighted distribution of alignments. probabilistic models of evolutionary events  are used to calculate the likelihoods of different evolutionary histories and a probability-weighted distribution of sequence alignments. these models vary in complexity, ranging from the treatment of insertion and deletion events  as single-nucleotide events  <cit>  to the modeling of complex length distributions for indels  <cit> , but all allow for evolutionary inference without assuming a single alignment. incorporating alignment uncertainty information using statistical alignment can improve not only the accuracy of sequence alignment, but also the estimation of the parameters specifying the length and frequency of evolutionary events as well as the estimation of phylogenetic relationships between species  <cit> .

statistical alignment models can be modified to simultaneously align sequences and detect functional elements. by doubling the number of states in a hidden markov model  aligner in order to model both quickly evolving  and slowly evolving  elements, we recently introduced sapf , a software package which analyzes a probability-weighted distribution of alignments in order to identify sequence elements that are evolving at a reduced rate  <cit> . results on both simulated datasets and drosophila cis-regulatory modules demonstrate how removing the traditional dependence on a single alignment increases the accuracy of functional element predictions. the improvement was most prominent when there was alignment ambiguity in functional regions due to binding sites that were not highly conserved. while sapf is used to discover new motifs, the morph software package modifies a simple probabilistic aligner to detect and align instances of known motifs that have been previously characterized as position state weight matrices  <cit> . here too, the authors report higher accuracy when examining all alignments between two species.

while these studies present strong evidence for the benefits of using statistical alignment to detect regulatory elements, they are limited in the amount of sequence data they can analyze. both sapf and morph use standard hmm algorithms  <cit>  to compute likelihoods and posterior probabilities, and as the number of sequences under analysis increases, the number of states in the hmm increases exponentially. as a result, morph is restricted to pairwise alignments and sapf can analyze only up to four sequences. while the potential benefit of adding more sequence data is highly dependent on the evolutionary distances between species in the dataset, recent simulation studies have demonstrated how greater numbers of species can increase the sensitivity and specificity of functional element recognition  <cit> . additionally,  <cit>  proposed the simple rule that for a given evolutionary distance, the number of genomes required to detect functional elements scales inversely with element length. therefore, while two genomes may be sufficient for detecting long conserved exons, three to fifteen genomes may be needed to detect tfbs. the inability to analyze more than four sequences puts sapf at a disadvantage relative to phastcons, the single-alignment based phylogenetic footprinter used to create the 28-genome conservation track in the university of california at santa-cruz  genome browser  <cit> .

markov chain monte carlo sampling techniques  <cit> have been successfully applied to statistical alignment methods in order to expand the numbers of sequences that can be analyzed  <cit> . the statalign package - a markov chain monte carlo  sampler implemented in java - samples alignment parameters, sequence alignments, tree branch lengths and tree topologies in order to infer both the alignment and the phylogenetic tree relating the input sequences  <cit> . the sampler places a statistical alignment model on each branch of the tree, and represents internal node sequences as a collection of gaps and felsenstein wildcards  <cit> . to create bigfoot, we extend this package to perform phylogenetic footprinting as well. we alter the alignment framework to model both quickly and slowly evolving regions, and develop new mcmc transition kernels to infer the breakpoints between the slowly and quickly evolving regions.

RESULTS
algorithm
model summary
while traditional alignment algorithms assume identical mutation rates throughout the sequence, we introduce an alternative evolutionary model allowing for rate heterogeneity by modeling the evolution of both quickly and slowly evolving regions. in our model, a two-state hmm emits a sequence of conserved  and non-conserved  states at the root of the tree. this defines an alternating series of conserved and non-conserved segments, allowing our model to represent both neutral sequences expected to exhibit higher mutation rates and functional sequences undergoing purifying selection. each segment evolves independently along a phylogenetic tree according to a pairwise alignment model which allows for insertions, deletions, and substitutions on each branch of the tree. while the statalign package jointly estimates both the tree and the alignment, we condition the analysis on a user-inputted phylogenetic tree in order to estimate the alignment and locations of quickly and slowly evolving regions more efficiently.

our model is a reformulation of the sapf multiple hmm with two main differences. as in  <cit> , we model the difference between fast and slow states by scaling down the branch lengths of the phylogenetic tree in slow states, reducing the evolutionary time - and thus the expected divergence - in these regions. while sapf models slow states by modifying the rate parameters of the mutation models, bigfoot uses a branch scaling approach in order to support multiple substitution models with different numbers of parameters. two different scaling factors, both of which are model parameters endowed with user-defined priors and constrained to be less than one, are used for substitution and indel events.

another minor difference is that the bigfoot model does not allow for insertions at the exact boundaries of functional regions. this modification was necessary to create unambigious and reversible mcmc proposals, and is a biologically relevant modification since an insertion event in one sequence should not define the beginning  of a conserved region.

modeling molecular evolution
our alignment model is expressed as a pairwise hmm transducer  <cit> , a conditionally normalized hmm representing the evolution of an ancestral sequence into a descendent sequence, and is similar to the transducer model in  <cit> . more complete details describing the transducer are presented in the methods section and supplementary sections s <dig>  and s <dig>  .

we base our transducer on the  <dig> approach of thorne, kishino, and felstenstein   <cit> . tkf <dig> models the birth and death of fragments with geometrically-distributed lengths in order to represent long indel events. our model can be viewed as an extension of the tkf <dig> approach, allowing these fragments to exist in either quickly or slowly evolving regions. in our fast states, as in the tkf <dig> model, the length of indel fragments is modeled by a geometric distribution with the same expected length as a fragment of matched bases, resulting in an expectation of long indel events. in annotated functional regions, however, we noticed that most indel events were very short . to represent this, we create a separate parameter to specify the expected lengths of indel events. thus, we not only expect functional regions to have fewer indel events, we also predict that these events will be shorter.

we place a pairwise transducer on each branch of the phylogenetic tree in order to model the evolution from each ancestor to each descendent. transducer theory  <cit>  shows how the concatenation of these transducers results in a multiple hmm describing the evolution from the ancestral root node to all leaves in the tree. we place a separate hmm on the root sequence, allowing it to switch between emitting slow-evolving characters and fast-evolving characters with specific probabilities. this models fast and slow regions with geometric distributed lengths, set by model parameters.

one limitation of our approach is that our model does not allow for the creation or deletion of conserved regions along the tree. since the annotation of fast or slow characters emitted by the root is conserved in the descendent sequences, the model cannot detect the loss or gain of binding sites. for this reason, when testing bigfoot we discarded sequences with long deletions from analysis.

the full likelihood of a tree is equivalent to the full emission probability of the multiple-hmm. unfortunately, this likelihood cannot be calculated quickly, as the time complexity of the forward algorithm for a multiple hmm grows exponentially with the number of sequences. instead of direct computation via dynamic programming, we apply a bayesian mcmc method with data augmentation.

bayesian mcmc
all model parameter densities are estimated using mcmc sampling. exponential priors with expectation  <dig> have been used as priors for insertion-deletion parameters in the alignment transducer and for all free parameters in substitution models provided with the software package. for parameters responsible for annotation , we allow the user to input either beta or uniform priors on these parameters. this allows the user to tailor the analysis to their specific needs. for example, the user can set an informative prior to search for longer weakly conserved regions, or for very short and highly conserved regions. alternatively, the user can set uninformative priors and allow the mcmc to estimate parameter distributions freely.

the joint posterior distribution of alignments, trees and evolutionary parameters forms a high dimensional and complex distribution from which efficient direct sampling is most likely impossible. therefore, we applied markov chain monte carlo to converge to this prescribed distribution. after convergence, samples from the markov chain provide correlated samples from the posterior distribution.

the likelihood of a tree under the multiple hmm can only be easily calculated when we augment the tree with additional data known as extended alignments. this data contains information on how the observed sequences are aligned to ancestral sequences associated with internal nodes of the tree. we represent the unobserved ancestral sequences as a collection of gaps and felsenstein wildcards in order to sum over all possible nucleotide values when calculating the total likelihood.

our mcmc walks on the joint distribution of the extended alignments, locations of fast and slow regions, and model parameters. the random walk comprises the following components:

• changing model parameters

• changing extended alignment

• shifting the boundary of an existing fast or slow region

• creating a new  fast or slow region

the first two types of moves are described in  <cit> , and the last two are described in the methods section. in each mcmc iteration, we apply a metropolis-hastings move to alter one of these components, and select moves with fixed probabilities that were chosen to enhance mixing.

postprocessing the samples from the markov chain
the markov chain provides correlated samples from the posterior distribution of alignments, locations of fast and slow regions, and evolutionary parameters. to report posterior probabilities for phylogenetic footprinting predictions we take the approach of  <cit> , collapsing our predictions onto one axis and reporting posterior probabilities for a single species. our results thus represent the posterior probability of each nucleotide having been generated from a slow state. these probabilities are simply the proportion of samples in which each nucleotide appears inside the boundaries of a slow region.

multiple sequence alignment samples can be summarized in several ways. unlike other authors  <cit> , we found the map  alignment estimation drawn from mcmc samples to be very unstable, especially when there is autocorrelation between samples from the chain. we chose instead to estimate the mpd  alignment  <cit> , which maximizes the product of alignment column posterior probabilities. we found this estimation to be more stable as it allows the uncertainty in each alignment column to be assessed independently. we present a complete algorithm for calculating the mpd alignment in supplementary section s <dig>  .

testing
as a first test of the accuracy of the mcmc results, we ran bigfoot on a relatively small dataset to compare the results with the exact dynamic programming predictions of sapf. the two methods were expected to return similar, though not identical, results. this is because sapf and bigfoot use slightly different alignment hmms on each tree branch. we analyzed a cis-regulatory module in four drosophila species: d. melanogaster, d. erecta, d. pseudoobscura, and d. willistoni. this  <dig> base pair region has been found to regulate the expression of the homeodomain encoding protein eve in the second stripe of the developing drosophila embryonic blastoderm  <cit> . the redfly database provided the sequence coordinates of the biologically verified regulatory module in the d. melanogaster sequence  <cit> , and the flyreg database provided locations for  <dig> experimentally discovered binding sites  <cit> . figure  <dig> exhibits the close agreement between the mcmc and dynamic programming predictions, with the locations of the known binding sites displayed above the posterior probabilities, and provides strong evidence that bigfoot is sampling from and converging to the true joint distribution. both programs identify  <dig> of the  <dig> binding known binding sites with high posterior probabilities. of the remaining five sites, none have homologous instances in either d. melanogaster or d. pseudoobscura. four were biologically characterized as "weak-affinity" binding sites  <cit>  which could indicate reduced functionality and a loss of evolutionary pressure, and the last was postulated to be recently evolved in d. melanogaster due to an absence of orthologous sequence in both closely and distantly related drosophila species  <cit> .

the drosophila  <dig> genome consortium has completed the sequencing of  <dig> drosophila genome sequences exhibiting a large range of evolutionary distances  <cit> . for example, the evolutionary distance separating d. melanogaster and d. grimshawi is greater than that between any pair of mammals when generation time is taken into account  <cit> , while other sequence pairs are very closely related. the large number of sequenced genomes and the diversity in their evolutionary distances make this an ideal dataset for implementing phylogenetic footprinting techniques. we tested the eve stripe  <dig> enhancer region using ten of the  <dig> genomes in this dataset. we chose to remove two species, d. mojavensis and d. virilis, as both sequences contained numerous long deletions and were thus too divergent to be informative. sequence data for all species were obtained from a set of pre-computed whole-genome alignments  <cit> .

• higher sensitivity to verified binding sites. while figure  <dig> exhibits a close agreement between the two sets of analyses for many of the experimentally verified binding sites, the addition of more species does improve the conservation signal in some tfbs. in particular, peaks corresponding to a kruppel binding site , a bicoid binding site , and a joint site  are all more strongly identified as evolving slowly when ten species are analyzed. additionally, one kruppel binding site  is only detected, albeit weakly, when using the larger dataset. this demonstrates that while imperfectly conserved regions may be reasonably likely to occur by chance in neutral sequence when only a few species are analyzed, additional sequences may provide stronger evidence of purifying selection. heightened sensitivity is also observed at previously unannotated peaks from bases 137- <dig> and 227- <dig>  both regions are adjacent to a verified tfbs and have a high posterior probability of being emitted from a slow state, and thus should be candidate regions for future experimental study. this heightened sensitivity does not result in a general loss of specificity, as low probability peaks  in previously un-annotated regions disappear when using the larger dataset.

• finer nucleotide resolution for tfbs start/stop positions. when analyzing a small number of species, it may be difficult to identify the boundaries between quickly and slowly evolving regions, especially in a region where tfbs may be grouped close together. the results shown in figure  <dig> demonstrate how adding additional sequence data can result in a clearer signal at the boundaries of binding sites. in the kruppel site kr <dig>  the distance in bases from the limits of the predicted conserved region  to the limits of the laboratory-identified regulatory element decreases by  <dig> bp when additional sequences are analyzed. though this difference is small, it corresponds to 27% of the  <dig> bp binding site. a similar effect is observed in the kruppel site kr <dig>  for which additional sequence data decreases the boundary error by  <dig> bp.

additionally, in a closely spaced group of functional elements  separated only by a small number of neutral bases, the small dips in posterior probability correspond more closely to the neutral regions when more sequences are added to the analysis. while the agreement is not perfect, these results are consistent with previous findings showing an increase in nucleotide resolution as more species are analyzed  <cit> .

in order to quantify the predictive accuracy of our results, we calculated receiver operating characteristic  curves for both sets of bigfoot results. the area under the curve , which has a maximum value of 100%, is a summary statistic that accounts for both the sensitivity and the specificity of the predictions. a value of 50% implies that the predictions are no better than random guessing. the methodology used for creating the roc curves is described in  <cit> . the curves are displayed in figure  <dig>  which exhibits the small but noticeable predictive improvement when additional sequences are added to the dataset.

to demonstrate that bigfoot can be applied to sequence data from vertebrates, we analyzed a  <dig> base pair region previously identified as the major regulatory element of human α-globin   <cit> . this region was sequenced in  <dig> species, analyzed with the transfac database, and found to contain seven tfbs. these tfbs range from 8- <dig> bp in length, and include recognition elements for the maf protein and gata- <dig>  both important in globin gene regulation  <cit> .

to analyze this region, we downloaded the multiz28way alignment of the region from the ucsc genome browser  <cit> . this alignment provided sequence information for  <dig> vertebrate species, three of which  contained long deletions and were therefore removed from the analysis. the results of the analysis are shown in figure  <dig>  where we display the results of two independent mcmc runs initialized at independent starting points. the first run was started using the ucsc alignment to initialize the markov chain, while the second was initialized with a random alignment proposed by bigfoot. both runs were also initialized with independent and randomly selected evolutionary parameters. despite these differences, figure  <dig> exhibits that there is extremely close agreement - in many regions near exact correspondence - between the two sets of results, demonstrating the mixing and convergence of the mcmc sampling.

when analyzing the  <dig> vertebrate species, bigfoot detects six of the seven known binding sites with posterior probabilities of greater than 95%. however, the seventh binding site, notated in figure  <dig> as bs <dig>  is poorly conserved and the binding site peak probabilities do not exceed 50%. in fact, this region was only detected due to the presence of a previously unannotated and weakly conserved adjacent region, notated as bsalt, which is incorrectly aligned in the multiz <dig> way alignment. bigfoot corrects this alignment error and annotates this region with a peak exceeding 80% posterior probability. this example demonstrates the importance of calculating and correcting for alignment ambiguity and error. by doing this, bigfoot not only discovers a previously undetected conserved region in a well-annotated regulatory module, but also enables the detection of a weakly conserved but previously identified regulatory element.

comparison with phastcons
one of the most widely used alignment-based phylogenetic footprinting tools is the phastcons program, used to create the conservation track in the university of california at santa-cruz  genome browser  <cit> . the conservation track makes predictions from a single multiz alignment and does not incorporate indel information. this puts the method at a significant disadvantage to bigfoot, as indel information has been shown to be extremely valuable in the detection of functional elements  <cit> . indeed, we observed that predictions from the ucsc conservation track had significantly lower specificity and sensitivity when compared to the bigfoot results in both the drosophila and the αmre datasets.

in the command-line version of phastcons, however, it is possible to set an option for the program to incorporate indel information  <cit> . we set this option and ran phastcons on the bigfoot test datasets, using the ucsc alignment as input. the two programs returned almost identical results for the majority of the binding sites, since the majority of the binding sites are well conserved and thus perfectly aligned in the multiz alignments. in these cases there is little alignment uncertainty, so bigfoot and phastcons are expected to return similar results. however, in shorter binding sites exhibiting weaker conservation, bigfoot outperforms the single-alignment method. the most drastic example is the kruppel site kr <dig> in the eve stripe  <dig> enhancer. the core of the tfbs is very well conserved and bigfoot predicts the site with high probability, but there are substitutions towards the edges and short indels in some species, and the multiz alignment incorrectly aligns the binding site. as a result, phastcons detects all nucleotides in the tfbs with less than 5% probability. the roc curve for the phastcons predictions is displayed alongside the bigfoot roc curves in figure  <dig>  comparing the auc values demonstrates how the increase in predictive accuracy caused by adding more sequence data is less than the corresponding increase caused by analyzing a distribution of alignments instead of a single alignment.

a similar error in the multiz alignment of the αmre enhancer results in phastcons failing to annotate any nucleotide the weakly conserved region discussed in the previous section  with greater than 5% probability. while we cannot know if this region is a functional tfbs without further experimental analysis, examining a distribution of alignments ensures that this region is not incorrectly passed over during the conservation analysis.

since phastcons analyzes only one single alignment, the computational time to analyze a single region, around  <dig> seconds on a  <dig> ghz macbook computer, was substantially less than the 12- <dig> hours needed to analyze a single region with bigfoot. as a result, phastcons can be used to compute functional element predictions for the entire genome, while bigfoot can only be used to analyze individual regions of interest. however, for users who have identified specific genomic regions to study in detail, the benefit of controlling for alignment error and uncertainty by using bigfoot may justify the additional computational time needed for the analysis.

implementation
the algorithms have been implemented in java  <dig> , and are part of the bigfoot software package available at: 

user input
bigfoot requires the user to input a set of homologous dna sequences  and an evolutionary tree  describing the phylogenetic relationships between the inputted species. bigfoot can construct an initial alignment of the sequences, or if the user has a previously computed starting alignment in fasta format, they can set it as the starting alignment in the markov chain. the user can also place either beta or uniform priors on parameters modeling the difference between fast and slow states.

substitution models
our aim was to build a software package for an insertion-deletion model that can be coupled with an arbitrary substitution model. therefore we would like to give users the option to implement their own substitution models. in the software help file, we describe how users can extend this class to create their own substitution models. we currently provide a large selection of eight nucleotide substitution models including the jukes-cantor model  <cit> , the kimura three parameter model  <cit> , and the hky <dig> model  <cit> .

postprocessing
our program provides random samples from a markov chain whose stationary distribution is the joint bayesian distribution of sequence alignments, locations of fast and slow regions, and model parameters. this high dimensional joint distribution can be analyzed in several ways, ranging from an analysis of the posterior distribution of a single rate parameter to an investigation of markov chain convergence using a log-likelihood trace or a separate multidimensional autocorrelation analysis. we implemented a set of postprocess plugins which analyze data from the markov chain and display in the graphical interface. in the software help file, we also describe how the user can implement their own postprocess plugin by extending the abstract class.

we implemented the following plugins, each of which represents a tab in the graphical interface:

• log-likelihood trace this plugin plots the log-likelihood trace and writes the log-likelihood values into a text file when the analysis is complete.

• current alignment this plugin shows the multiple sequence alignment in the current state of the markov chain, along with the locations of slow and fast regions. capital letters in the alignment represent slowly evolving regions in the current state of the chain, while lower case letters represent quickly evolving regions.

• mpd alignment this plugin calculates and performs running updates of the maximum posterior decoding alignment based on all previous samples of the markov chain. figure  <dig> pictures this alignment display, along with two curves overlaying the sequence information. the blue curve represents the posterior probability of each alignment column: higher values indicate greater confidence in the alignment. the red curve represents the phylogenetic footprinting results: higher values indicate a greater posterior probability of purifying selection. the final mpd alignment, and all footprinting results, are written into a text file after the analysis is complete.

• current tree this plugin graphically displays the tree inputted by the user.

computational power
we initially assessed convergence using a log-likelihood trace, and verified convergence using independent mcmc runs. we found that 106- <dig> steps were required for convergence, depending on the number of sequences and their lengths. to remove the effects of autocorrelated samples, we took a sample of the chain after every  <dig> iterations of the mcmc. for all examples, total computational time did not exceed  <dig> hours on a  <dig> ghz macbook computer. datasets larger than  <dig> species can also be analyzed, but may take longer to achieve convergence.

CONCLUSIONS
we have presented and tested an algorithm for co-sampling multiple sequence alignments, locations of quickly and slowly evolving regions, and a set of evolutionary parameters. our likelihood engine evaluates an hmm transducer switching between fast and slow states, where the evolutionary models in the slow states indicate a reduced rate of mutation as a consequence of purifying selection. we also present a new mcmc transition kernel enabling the combination of sequence alignment and phylogenetic footprinting. we have demonstrated the accuracy of our method by comparing the results with a dynamic programming solution, and we have presented strong evidence for the convergence of our sampling distribution by running independent mcmc runs from different starting points and obtaining essentially identical results.

we tested bigfoot on the eve stripe  <dig> gene in drosophila. our results exhibit two major potential benefits for analyzing additional sequences in comparative genomics approaches. augmenting our dataset from four to ten sequences resulted in higher sensitivity towards experimentally verified binding sites and finer nucleotide resolution when detecting the exact boundaries for tfbs. the ability to analyze larger datasets was the primary motivation for extending the sapf dynamic programming approach into bigfoot, and these results show that it is important for existing tools to have the capacity to analyze multiple sequence datasets.

by simultaneously estimating multiple sequence alignments and phylogenetic footprinting predictions, bigfoot correctly incorporates alignment uncertainty information into functional element predictions, and ensures that alignment error or ambiguity will not prevent the software from identifying slowly evolving regions. however, there is an additional benefit to our joint model. in some weakly conserved regions there is a highly conserved core of 3- <dig> bp, but conservation drops off slightly towards the edges of the site. in these cases, a simple aligner will often correctly align only the binding site core while misaligning the outer regions, or misalign the entire binding site. our combined model, however, recognizes that a conserved core may indicate the presence of a slowly evolving region, and thus could be surrounded by other conserved nucleotides. in these cases, the model will push weakly conserved positions together to align the full binding site. as a result, bigfoot not only detects the binding site, but also increases the accuracy of the posterior alignment distribution. the two best examples of this phenomenon are the two conserved regions  that were misaligned in the multiz alignments. while both these regions contained small indel events and multiple nucleotide degenerate sites, resulting in multiple plausible evolutionary histories, the posterior alignment distribution from bigfoot exhibited how our joint model reliably aligned all instances of the binding site together.

while there are binding sites for which analyzing a distribution of alignments improves the accuracy of bigfoot's predictions, for many other binding sites, analyzing a single alignment may return very similar results. the latter case is particularly true when binding sites are highly or perfectly conserved in which case the bulk of the probability mass in the alignment distribution rests on a single alignment. thus, if all binding sites in a region are highly conserved, the approximation of a single alignment is adequate and bigfoot may not significantly improve upon traditional methods. when roughly analyzing large genomic regions or large numbers of regulatory modules, traditional methods like phastcons may correctly predict the majority of binding sites. the additional computational time and complexity required to calculate the alignment distribution may reduce bigfoot's practicality for these datasets. however, during detailed analysis of individual regions, such as identifying specific sites for further laboratory analysis, the potential for bigfoot to correct for alignment error and uncertainty may justify the neccessary additional computational time. we are currently exploring different techniques for drastically reducing bigfoot's computational requirements. for example, approximating the multiple alignment distribution by analyzing the set of all pairwise alignments instead of using mcmc could allow for the analysis of large genomic regions.

another particularly useful improvement to our model would be to relax the constraint fixing the phylogenetic footprinting annotation of all species in an alignment column. this would allow us to appropriately model the gain and loss of functional regions in parts of the tree. we are currently pursuing this improvement, hoping that it will not only improve our ability to detect weakly conserved binding sites but will also allow us to make statistical predictions about the evolution of regulatory elements in a species or clade.

