BACKGROUND
mass spectrometry proteomics
the field of proteomics has made remarkable advances in analytical hardware and software which have provided increasingly sensitive and robust analyses on platforms capable of detecting low abundance proteins from complex mixtures, such as serum and cell lysates. the nanoscale liquid chromatography and mass spectrometry  proteomic technology, which has become the state-of-the-art for differential expression proteomic studies in most major laboratories around the world, typically uses a ‘bottom-up’ approach, where the samples are subjected to a total proteolytic digestion, and the peptide ‘surrogates’ of the protein are quantified and identified using tandem mass spectrometry. there are two general approaches used for bottom-up differential expression proteomics via lc-ms, those based on the use of stable isotope labeling or tagging of the peptides, and the so-called label-free methods   <cit> . advances in both approaches have occurred in recent years such that currently both relative and absolute quantitation of proteins is possible from complex mixtures by either labeled or label-free methodologies  <cit> .

although a specific advantage of the labeling approaches is the ability to heavily fractionate the samples to “dig deeper” into the proteome while maintaining quantitative capabilities, extensive fractionation of the sample is often impractical in the context of a clinical study with tens or even hundreds of samples. the proteomics community has seen a significant increase in the use of the label free approach due to increased instrument stability and software sophistication, and it is emerging as the method of choice for larger clinically-based studies where use of the labeling strategies is impossible or impractical. in particular, an advantage of label-free strategies which measure area-under-the-curve  of the lc-ms peak is that any of a number of commercial or open-source software packages can be used to extract ion intensities from each individual analysis, and statistical analysis on the relative abundance of these ions can be performed even in the absence of a peptide identification. the ability to precisely and reproducibly quantify thousands of proteolytic peptides using the label-free method was demonstrated by wang, et al. and has been since employed and reproduced in a number of laboratories  <cit> .

techniques for aggregating peptides into larger units generally revolve around protein identifications. a variety of approaches exist to combine individual peak areas to generate a relative or absolute aggregate expression levels. once peptides are assigned to their parent proteins, using an algorithm such as proteinprophet, either the peptide frequency of observation  or ms intensity is used to estimate protein abundance  <cit> . the spectral counting approaches have gained a fairly large degree of use in the community due to their ease of implementation, however they generally suffer from a limited dynamic range and they are insensitive to small changes in expression level due to the large number of species which have peptides observed only 1– <dig> times  <cit> . label-free auc approaches generally overcome these limitations by locating a peak in the retention-time and accurate-mass matrix using sophisticated software, and extracting the area under the lc-ms peak. an important characteristic of auc label-free studies is that they need to be performed on high resolution instruments for the best results, which limits the application of this approach to more expensive qtof, ft-icr, or orbitrap instruments.

analysis of shotgun proteomics
error in protein-level quantitation can first occur due to incorrect peptide identifications. even at a relatively low peptide false-discovery rate , the fraction of proteins detected that contain at least one false peptide identification is much higher because multiple peptides match back to the same protein. if a false-positive peptide is included in the protein level quantitation it can cause increased error in the protein-level quantitation. this can be partially overcome utilizing only the highest-quality or best-ionizing peptides for protein quantitation, however in current implementations of “top 3” quantitation, the individual peptide confidence is not utilized as an inclusion parameter  <cit> . a second type of error in protein quantitation occurs when many homologues share a common peptide. in this situation the protein grouping algorithm, such as proteinprophet, makes an informed decision about which parent sequence a peptide belongs to and typically associates all of the peptide intensity to that parent sequence. this can deliver erroneous protein quantitation results when multiple homologues are present. a final challenge is with protein isoforms, post-translationally modified or proteolytically processed peptides, which may show a biologically relevant and different expression pattern than the proteotypic peptides. in these cases, they should not be grouped together with the other peptides for the purposes of modeling expression.

this paper describes a statistical model which is designed to allow the inclusion and modeling of correlation structure for the problem of differential expression in mass spectrometry proteomics. there are a number of different approaches designed for protein level quantitation. the simplest of these use direct summarization of all features/isotope groups/peptides that are identified for each protein, such as averaging or robust summarization based on quantiles  <cit> , or averaging only the most abundant three peptides from a protein  <cit> . in addition to these algorithms, there are anova approaches for protein quantitation  <cit>  and differential expression  <cit> . these are regression models that variously include or exclude fixed effects for experimental group and random effects to handle repeated measurements of the same sample . all of these approaches rely on protein identifications and none make explicit use of correlations between isotope groups. while we do not consider the introduction of fixed effects for biological phenotypes or the introduction of random effects for cases in which we have replicate measurements from the same sample, the factor model we describe is a regression model. therefore, one might introduce these features in a relatively straightforward way.

we present here a metaprotein classification approach which demonstrates the use of coexpression in addition to identification of peptides to assist in grouping with similarly-quantified peptides. we note here the specific use of the term metaprotein. this is because, while many metaproteins obtained from fitting our model are dominated by peptides from a single protein, it is entirely possible that a “metaprotein” is not representative of a single protein at all. rather, a metaprotein may contain peptides from multiple proteins. in such a case, the metaprotein is representative of the activity of a pathway. the extent to which the model is able to distinguish individual proteins within a pathway will depend on the sample size of the data set, however, even for very large sample sizes this may be impossible for proteins that have highly correlated expression. we would argue that distinguishing these is somewhatacademic in this case, and that noting that they are highly correlated, which is a feature of our approach, offers advantages in terms of higher power in subsequent hypothesis testing and model fitting . our approach has the following features, some of which are shared by the models described above:

· allows for the subtraction of large scale correlation structure between proteins that likely arise from technical rather than biological variability .

· appropriately models both identified and unidentified features of the lc-ms output

· utilizes feature identifications from ms/ms spectra, but allows for the probability that some of those identifications will be incorrect

· produces a full posterior distribution on the model parameters, which leads to the quantification of uncertainty in the results.

· admits the possibility that sections of a protein will be post-translationally modified and therefore may not be representative of the expression pattern of the protein as a whole.

· makes use of correlation structure across samples, which provides significant information about feature relationships that is unused in many other approaches.

· can be used in the creation of predictive models based on multiple proteins, rather than just the enumeration of proteins associated with a particular outcome.

we recognize that there are many excellent approaches to modeling label-free proteomic data that share some of these properties, however our proposed model is unique in its ability to concurrently model all of them.

in addition to advances in statistical modeling of label-free, unbiased proteomics data, this paper presents a novel pre-clinical predictor of response to therapy in patients with hepatitis c. finally, we demonstrate the validation of that predictor in two separate cohorts. first, we show that the approach generates a predictor that is reproducible between two different labs that are utilizing entirely different mass spectrometry technologies. second, we show that the predictor is able to accurately differentiate clinical responders from non-responders in a novel cohort of pediatric patients with hepatitis c. in both cases, the predictor is based on unbiased, label-free mass spectrometry data. we are aware of one previous example of the validation of shotgun proteomics findings with further shotgun proteomics experiments  <cit> , in which a number of individual peptides were validated as markers of central nervous system lymphoma. standard practice is to validate using a targetted platform such as selected reaction monitoring . to the best of our knowledge, ours is the first example of the validation of a full predictor. finally, we verify some of the key elements of the predictor in our original cohort using srm.

RESULTS
metaprotein factor model
in order to estimate metaprotein abundance, we build our model from pre-processed data with intensity estimates aggregated to the isotope group level. in our modeling approach, we allow the possibility that an isotope group will be incorrectly identified, or be correctly identified, but have a pattern of expression that is distinct from the bulk of peptides from the corresponding protein. in practice, this new grouping approach often leads to metaproteins which may be dominated by isotope groups from a particular protein, but which contain isotope groups from other proteins as well.

let x be a p × n-dimensional matrix consisting of measurements on p isotope groups across n samples. we utilize a modification of the latent factor model outlined previously in  <cit> .

  x=μ1n+aΛ′+ϵ 

the p-dimensional vector μ has elements μi representing the mean expression of isotope group i and 1n is a column vector of ones. the n × k-dimensional matrix Λ represents latent factors which will be learned from the data and a is a p × k-dimensional matrix of factor loadings with elements ai,k. the random variable ϵ is a p × n matrix of idiosyncratic noise.

our goal is to estimate relative protein concentration from this model using the latent factors in Λ. recall that we have identifications for some subset of the isotope groups. with this in mind, suppose we identify each column of a and the corresponding column of Λ with one identified protein. if we set ai,k =  <dig> when isotope group i is from a peptide identified as coming from protein k and ai,k =  <dig> otherwise, then our model is describing the expression pattern of each isotope group as a noisy approximation of the expression pattern of the protein, where the protein is known.

retaining, for the time being, the idea of fixing ai,k in this way, we wish to handle the possibility of changing sensitivity and changing protein concentration from sample to sample. to account for this, we introduce an additional set of latent factors into equation  <dig> 

  x=μ1n+bh′+aΛ′+ϵ 

we now introduce latent factors h and factor loadings b= where j=1⋯j which we use to account for systematic structure in the data that is sample specific. because these features will span almost all peptides, we utilize a generic gaussian prior for the elements of b.

  bi,j∼n 

this distribution represents our belief that these effects span all isotope groups, but with varying effect sizes. this prior also minimizes identifiability issues between b, which is not sparse, and a which is very sparse with informative priors.

rather than assigning isotope groups to factors based purely on identification, we want to utilize a prior on a that allows for possible post-translational modifications and misidentifications. with this in mind, we want to relax our strict assignment of zeros and ones in the loadings matrix a. instead, our prior distribution for ai,k will reflect our level of certainty that we know which factor should represent the expression of this peptide. when we have an identification for peptide i and have mapped that peptide to protein k, our prior distribution will reflect an increased certainty that ai,k≠ <dig> 

we introduce a p-dimensional vector of latent variables  which identifies the non-zero column of a for each isotope group. when we have an identification that suggests that isotope group i comes from protein k, our prior distribution for zi is

  zi∼multinomialqi∼dir 

where αk is substantially larger than α <dig> to reflect our prior belief that zi=k. we default to αk=500⋅α <dig>  but have tried values from  <dig> through  <dig> and these lead to only minor shifts in metaprotein membership. as the weight of this prior decreases we are decreasing the importance of identification information and placing progressively more importance on correlation structure. we find, for the hepatitis application below, that the association of metaproteins with outcome doesn’t substantially change until we increase the weight of the identification data to very high levels. we find that using α0= <dig> leads to interpretable metaproteins without loss of association with the outcomes. for peptides which do not have identifications, we utilize an unbiased prior zi∼dir. because different peptides showing similar expression patterns may, nonetheless, show a different magnitude of expression of that pattern due to the relative sensitivity of the mass spectrometer for the peptide, we model each of the non-zero elements of a independently, such that ai,k∼n when zi=k and ai,k= <dig> otherwise.

there is not a specific threshold for determining the grouping of isotope groups into metaproteins. instead, the assignment of an isotope group to a particular metaprotein is a function of the variance associated with that isotope group, the number of isotope groups already assigned to each metaprotein and the level of agreement between the expression pattern of the isotope group and that of the metaprotein. all of these things are estimated using mcmc within the context of the model fitting.

we note that, in the limit as αk→∞ we obtain an anova model in which there is no uncertainty about which metaprotein each isotope group belongs to. this is a fixed effects model with feature-specific variance similar to clough et al.  <cit> . that limiting model implies that identifications are assumed to be accurate and assumes that post-translational modifications are of minor importance. clough et al. correctly point out that, by collecting features one obtains higher power for detecting associations versus simple tests of association with individual isotope groups. that model, as well as the one we present here, may be expanded with additional design vectors identifying experimental groups or particular interventions if so desired. these may be included as columns in h which are simply not updated in the mcmc .

to complete the model specification, we assume a conjugate, row specific inverse gamma prior for the variance of ϵ. this is similar to the protein level aggregation model of  <cit> , and allows differing variance estimates for each isotope group. because we are working with a relatively large number of samples , we use a prior with mean  <dig> and variance  <dig>  we also assume that the individual columns of Λ arise from a uniform distribution on the n-dimensional sphere of radius n. the model is fit via mcmc and the result of this fit is a set of draws from the posterior distribution of all of the model parameters. all prior distributions are conjugate, and therefore we may use gibbs sampling to update the model parameters at each step of the mcmc. the data sets we are modeling have been aggregated at the isotope group level, and as such they have between  <dig> and  <dig> thousand measurements per sample. while our sampling scheme is able to fit this data in just a few hours on a desktop, we expect that some sort of parallel processing will be desirable for data that is aggregated at the feature level. we have tested our model on multiple simulated data sets of various sizes  to verify the accuracy of the parameter recovery even in the presence of intentionally mislabeled isotope groups.

overlapping peaks
by our assumption that each row of a have only one non-zero entry, we have restricted our peptides to belong to just one metaprotein. as an alternative, one might allow more than one non-zero element in each row of a. this is equivalent to assuming that more than one metaprotein is responsible for the expression pattern seen in a single peptide. this might occur in cases where multiple isotope groups have highly overlapping peaks or where multiple proteins have homologous regions that can give rise to the same peptide. although the extent to which we see multiple isotope groups in a single peak is unclear, this type of structure can be accounted for with relaxed priors on a. if ai,k is an element of a, then a point mass mixture prior accomplishes our goals.

  ai,k∼δ0+qkn 

where δ <dig> is the distribution describing a point mass at  <dig>  this distribution represents the prior belief that some, but not all, metaproteins will be required to describe the expression pattern of each isotope group. the normal distribution allows the magnitude of the effect to vary. for each of the metaproteins, we estimate the number of associated isotope groups by our prior distribution on the mixing probability qk:

  qk∼be 

this approach allows for the restriction on isotope group association with just one metaprotein to be relaxed. however, as the resolution of mass spectrometry increases, and as fractionation in multiple dimensions  makes the distinction between polypeptides clearer, this modification to the model will become less and less important. further, experience suggests that the vast majority of measured peaks are single species. because of this, the addition of features to deal with overlapping peaks can introduce more noise than it removes, particularly when the number of samples in the experiment  is limited.

features of the factor model
one of the strengths of our approach is the ability to collect isotope groups based not only on identifications, but also on their coexpression across samples. perhaps the most common method for visualizing correlation structure in high-dimensional data is hierarchical clustering. however, this is most typically used as a visualization strategy and does not, by default, provide quantitative estimates of aggregate behavior. while it is possible to generate models based on what is visualized from hierarchical clustering, nearest centroids for example, these have not to our knowledge been published for proteomic data. in addition, there are questions surrounding how one might combine peptide identifications and correlation structure in a principaled way to jointly model all of the available information.

one can identify collections of coexpressed isotope groups as well as an approximation of the expression patterns of each group from our model based on posterior distributions of the model parameters. the posterior parameters of greatest interest will depend on the specific application, but often we will be most interested in the vector of factor memberships, z, which describes which peptides group together most often. in data sets intended for the generation of predictive models in clinical/translational studies , we will be interested in Λ. the columns of this matrix define our estimates of the expression patterns of the metaproteins across our samples. these can be used to estimate fold change, or can be treated as independent variables in any type of model that is appropriate for the study.

associated with meta-protein i is a column of factor scores, Λi, representing the expression of that meta-protein. in addition, there is a collection of isotope groups which make up that meta-protein, the isotope groups jfor which zj=i. figure  <dig> shows a heatmap of all of the peptides from the dataset that are identified as belonging to the protein apo e. note that, while the majority of those peptides share a common expression pattern, three .show a very different, conflicting pattern. our meta-protein model automatically groups the co-expressing peptides into the same factor while assigning the peptides with conflicting patterns to other meta-proteins that more closely match their expressionpatterns.

inconsistent expression of peptides from the same protein
we define a “dominant metaprotein” for a protein to be the metaprotein with more than half of its identified isotope groups contributed by that protein. we note that, because there are many metaproteins it is possible for a dominant metaprotein to consist largely  of peptides from one protein, but not contain all  of the isotope groups from that protein. one of the features we have observed from studying posterior parameters from our model is that there are manyexamples in which an identified isotope group  does not follow the expression pattern of its corresponding dominant metaprotein. that is to say, for any given protein there is often a “consensus” expression pattern that many of the isotope groups from that protein follow, but that there is also a large minority of isotope groups which do not follow that expression pattern. we fit our model to all  <dig> proteins which have more than  <dig> identified peptide in the data set. heatmaps similar to figure  <dig> for each of these proteins are available in additional file  <dig>  examination of these figures shows that the presence of peptides that show expression patterns significantly different from their corresponding dominant metaprotein is the rule, rather than the exception.

there are a few reasonable explanations for this. the most obvious possible explanation is that the poorly conforming peptides are those with the lowest overall intensity, and therefore subject to smaller signal to noise ratios. however, examination of heatmaps showing the exact same peptides, but now sorted by mean intensity across the samples rather than by meta-protein membership demonstrates that there is not a strong predominance of low intensity peptides among those that do not coexpress with the other peptides from the protein. all  <dig> of those heatmaps are available in the additional file  <dig>  we tested, using a non-parametric kruskal-wallis test, for association between meta-protein membership and mean signal intensity for each ofthe metaproteins, and found that, of the  <dig> proteins tested, only  <dig> showed significant association .

another possible explanation for the presence of poorly co-expressing peptides within a single protein is misalignment between runblocks. the data set was analyzed in three runblocks, one of which occurred months after the original two, and aligned according to the algorithm described in the methods section. there are sometimes shifts in retention time between runblocks which may lead to misalignment, however, we expect misalignment to be a rare occurrence. additionally, if peptides are misaligned, we would expect to see a peptide that coexpresses with its dominant metaprotein well in two run blocks but is mismatched in the third, and this is not generally the case. we are able to find some examples that fit this pattern, however, it is almost always the case that when a peptide does not share an expression pattern with its dominant metaprotein one runblock, it also does not share that pattern in the other run blocks.

a third explanation for peptides that are uncorrelated is mis-identification. however, we are using identification algorithms with parameter settings that lead to very low  false identifications. we expect around  <dig> such misidentifications, assuming that identification is correct 99% of the time . in fact, examining the list of peptides that do not belong to their dominant metaprotein, we see that more than half fall into this category . this is true despite our prior distribution assigning a 500x greater likelihood of a peptide belonging to its dominant meta-protein than to a different metaprotein.

post-translational modification of proteins is a well known process, but it is unclear how extensive these modifications are. if proteins are extensively and dynamically modified after translation, then we should expect many of them to exhibit expression patterns that do not match the bulk of peptides from that same protein. also, if peptide modification is a significant contributor to observed patterns of expression, then we also expect to find peptides that have targets for post-translational modification to be more likely to be found outside their dominant meta-protein. we examined the probability of peptides containing glutamine and asparagine, which are known sites of deamidation, to belong to their dominant metaproteins. correcting for the number of peptides inside and outside their dominant metaproteins, we find that peptides containing glutamine are approximately  <dig>  times more likely to not follow the dominant expression pattern for any given protein, and that this is a statistically significant difference . in addition, peptides with asparagine are  <dig>  times more likely to fail to coexpress with the dominant group of peptides from a protein . in addition to these two sites ofpost-translational modification, we examined the motif nxs/t, which is a known site of n-linked glycosylation. for these two motifs,  <dig> of the  <dig> peptides which contain the “nxt” motif and  <dig> of the  <dig> peptides which contain the “nxs” motif follow expression patterns that are different from their dominant metaproteins . additionally, both serine and threonine are known to be sites of o-linked glycosylationas well as phosphorylation. we find that both threonine and serine are also more likely to show odd expression patterns . we tested proline  and histidine  as negative controls.

we note that we are not directly detecting the post-translationally modified peptides. instead, we suspect that we are detecting changes in the expression levels of the unmodified peptides due to post translational modification. thus, peptides with any of these post-translational modification motifs are significantly less likely to follow the dominant expression pattern for the protein from which they are derived. it is possible that post-translational modification is a pervasive feature of plasma proteomics, and that protein level quantitation is likely to either introduce errors by summing across uncorrelated parts of a protein  or to miss critical post-translational modifications . it is important to note, however, that inconsistent expression of peptides from the same protein is likely due to multiple different causes, including protein isoforms, increased noise in low abundance peptides, misalignment, mis-identification, peptide modification, and sample to sample variation in ion suppression from variable coelution in the lc separation. regardless of the root cause, the statistical model we propose will identify isotope groups that show this characteristic and treat them appropriately.

analysis of spike-in data: relabeling of misidentified peptides
we obtained a publically available spike-in data set from  <cit>  which consists of three replicate measurements of each of six conditions. the base solution is solid-phase n-glycocapture from human serum, and each of six different non-human proteins were spiked in at each of six different concentrations in a latin square design. after fitting our model to this data, we find that there is strong evidence for a significant increase in the total number of isotope groups that could be identified as coming from the known six spiked in proteins . estimated fold-change for each protein was also calculated for each experimental group and each spiked in protein. we find that, while the estimation works well for the highest four groups for each spiked in protein, the lowest two groups are typically underestimated due to the significant level of missing data.

in order to test the ability of our model to identify and correct inaccurate identifications, we randomly permuted 10% of the identifications in this data and refit our model. this experiment was repeated  <dig> times. additional file  <dig> shows the results of this experiment for the ‘myg_horse’ metaprotein for one such permutation. note that there are  <dig> isotope groups that are correctly assigned to the myg_horse metaprotein even though the original identification would have placed them in other proteins. this experiment was repeated  <dig> times, and of the  <dig> total reassigned identifications across those experiments,  <dig> were correctly reassigned to their original protein. of the remainder, the peptide was fit to a noise factor  <dig> times and fit to some other protein  <dig> times. none were assigned to the protein associated with the incorrect relabel.

comparison with protein level quantitation
while there are similarities between our meta-protein model and various techniques for protein level quantitation, the ability to group peptides based on co-expression across all samples, and therefore identify peptides that show evidence of post-translational modification is a critical difference that is shared by no protein level quantitation method that we are aware of. nonetheless, it is interesting to compare our model to protein level quantitation algorithms. for this purpose, we will examine two such algorithms. the summation algorithm estimates protein level quantitation by summing total expression across all peptides from a protein. this algorithm automatically gives peptides with high intensity measurements a larger effect on the estimated protein level quantitation. a second algorithm, top  <dig>  estimates the protein level expression as the mean of the three peptides with the highest intensity . these two algorithms typically give similar results, however, because peptides from the same protein do not always show consistent expression patterns, these approaches can lead to protein level quantitation that is unnecessarily noisy.

in general, we find that the correlation between our metaprotein model and protein level quantitation for estimation is high when there are a large number of peptides from the given protein. for example, one of the most abundant proteins in this data set is apolipoprotein b , and correlation between estimated expression from our factor model and from summation of all apo b identified peptides is  <dig> . however, when there are fewer peptides available or if there are many misidentifications or modifications, we find evidence that our factor model gives improved estimation of protein level expression patterns. for example, pregnancy zone protein, which has only three associated isotope groups in the data set, is known to be over expressed in women compared to men. while both the metaprotein model and the summation algorithm show differential expression for this protein, the factor model gives a p-value of  <dig> e- <dig>  as compared to a p-value of . <dig> for estimation by summation over identified peptides .

of the  <dig> subjects in this study, we have available antibody assay mesurements of both apo b and apo e on  <dig>  we compared the two protein level quantitation algorithms and our metaprotein model to the antibody assay “gold standard”. correlationsare all generally high and examination of figure  <dig> shows that the three techniques are generally in agreement, even on outliers. the top three isotope groups identified as coming from apo b show a high level of correlation, and all of these peptides are members of the main apo b metaprotein. also, a large majority of the apo b peptides show this same expression pattern and are assigned to the same metaprotein, thus agreement between the three methods on apo b is not surprising.

however, examination of the top three isotope groups from apo e  shows a different picture. the second most abundant isotope group from apo e is in a different metaprotein because it shows a substantially different expression pattern from the bulk of the apo e isotope groups. in addition, if we delete the two outliers from the data , the correlations between the three top apo e isotope groups and the antibody assay of apo e activity are. <dig>  . <dig> and . <dig> respectively . thus, this second most abundant isotope group should be adding noise to the top  <dig> protein level estimate of apo e. interestingly, the correlation between the top  <dig> estimate and the antibody assay is . <dig>  this is higher than any of the three separately, which suggests that the antibody assay is in fact measuring an aggregation of two different forms of apo e.

metaprotein expression in a hepatitis c cohort
in addition to the analysis of a publically available latin square data set , we obtained pre-treatment serum samples from  <dig> patients with hepatitis c who have a known response or non-response to the standard of care treatment with interferon and ribavirin  <cit> . serum from the patients was measured with open platform lc-ms/ms. the overall goal of the study was to predict who among the study subjects will respond to therapy and who will not. we are also interested in estimating which proteins and peptides are potential markers of response, allowing for future, targeted assay development.

analysis of this data set proceeds in two steps. first, the model described above is fit to the proteomic data without regard to the phenotype of interest. there were a total of  <dig>  peptides in the data set with either positive identifications or with average expression levels greater than the mean. of these  <dig> had identifications. these were matched with  <dig> different proteins of which  <dig> had two or more associated, identified peptides.

prediction of outcome
as with the computation of protein level expression, our  <dig> metaproteins may be used in any context as independent predictor variables. additionally, we may assess the level of association between metaproteins and other biological phenotypes in either case.

our first step in the analysis of the posterior distribution involves comparing the mean metaprotein expression patterns for all metaproteins to the “response to therapy” phenotype. we find three such metaproteins to be significantly associated  even after correction for multiple hypothesis testing . protein level quantitation by summation yields only  <dig> and protein quantitation by top  <dig> yields zero. furthermore, the relevant expression pattern is far clearer for the metaprotein analysis. figure  <dig> shows the most predictive “protein” , as computed by the summation protein quantitation algorithm. examination of the metaprotein with the most peptides from za2g, built from our model, shows that za2g is indeed identified as predictive by the metaprotein model as well. however, our metaprotein model identifies only those peptides from za2g that are highly correlated with each other, and it additionally identifies a number of other peptides from other proteins that share the same expression pattern across the samples . the result is better separation between responders and non-responders.

in addition to strong associations for three metaproteins, we find that there are a total of  <dig> metaproteins with p-values less than . <dig> . thus there is clear evidence of the presence of blood-borne markers of response to therapy in hepatitis c.

identification of candidate peptides
we would like to identify a set of candidate peptides for use in future targeted studies such as selected reaction monitoring  or antibody studies. from the analysis of associations between averaged metaproteins and the phenotype, we are confident that there are markers of interest. in order to identify the most relevant isotope groups, we propose to obtain draws from the mcmc chain, and for each draw build a predictor and observe which peptides are included in that predictor. in this way, the values of Λ are computed directly from the peptides included in the corresponding metaprotein. additionally, by keeping track of which peptides are most often included in the predictors, we obtain a list of candidate biomarkers for future study.

because we have  <dig> metaproteins but only  <dig> samples, direct regression is not possible in this context. we instead use variable selection with model averaging. variable selection allows regression with a small subset of the total number of predictors, while model averaging allows us to properly account for uncertainty in which models are correct. in this context, model averaging has been shown to outperform the single best model for predictive accuracy on hold out data sets  <cit> . we use a publicly available implementation of variable selection and model averaging called shotgun stochastic search  <cit> .

as mentioned above, our analysis consists of two steps. the first is the generation of a factor model to explain the variation seen in the peptide concentration data. this step is unsupervised; it does not take into account any phenotype data in any way. in this step we are seeking only to describe correlation structure in the isotope groups. in principal, if there were another large open platform plasma proteomics data set available this step could be performed on a different data set entirely. prediction of the phenotype from the metaprotein expression through the use of variable selection and model averaging in a binary regression model constitutes the second, supervised step. results from this analysis will vary slightly at each step of the mcmc chain. this allows us to estimate both the accuracy of predictors generated by this model as well as the uncertainty in that accuracy. figure  <dig> shows receiver operating curves  of the model for  <dig> steps of the mcmc, and compares this to the same roc’s from predicting randomly generated phenotypes with the same number of cases and controls. we see that the accuracy is significantly better than chance for all  <dig> draws from the markov chain. the collection of most used isotope groups in this modeling approach are shown in figure  <dig>  we show the locations of the associated peptides  in their respective proteins.

validation of a predictor discovered in an unbiased, label-free data set
there are two significant challenges facing users of label-free, unbiased, mass spectrometry proteomics. first, there are a number of different mass spectrometry machines, and some utilize different physical principals in order to measure mass-to-charge ratio. differences in these machines and differences in protocols between laboratories can make reproducing the same results at different labs difficult—even when the samples used are exactly the same. second, validation of findings in new samples can be difficult, particularly when the validation approach involves the use of different sample preparation or different techniques for measuring the peptides or proteins. it is quite common to see two phase experimental designs in which candidate peptides/proteins are identified by shotgun mass spectrometry then those candidates are validated on a much larger group of samples, but using antibody assays or srm mass spectrometry. these approaches introduce additional variables in the sample preparation or measurement, and in cases where validation fails the explanation for that failure becomes uncertain—it may have failed because the peptides/proteins are not good candidates or because of the changes in the way they were measured.

we validated our results on the predictor of response to therapy by both testing the consistency of the predictor when measured in different labs and also when testing the accuracy of the predictor in a new set of samples. in each case, we are attempting to validate our predictor through the use of an additional unbiased, label-free data set. because of difficulties with alignment between data sets, this approach is challenging and is usually not taken. the approach to this type of validation undertaken successfully by  <cit>  involved the validation of multiple individual makers of disease. that approach produces a set of putative biomarkers, some of which validate in the follow-up data and some of which do not. it leads to a more highly filtered, and therefore more likely to succeed, list of biomarkers, but it does not lead to a validated predictor. validation of a such a predictor must take into account uncertainties associated with alignment and false discovery. the advantage of our approach for this purpose is in the use of factors as predictors rather than individual isotope groups. by aggregating multiple isotope groups and using the aggregated expression pattern, the metaprotein model produces predictions that are robust to misalignments or false discovery associated with individual analytes.

we reanalyzed  <dig> of our original samples in an independent laboratory on a different mass spectrometry machine using a different technology . those samples were analyzed using the protocols of the independent lab without modification. in addition to this,  <dig> additional samples were obtained from a pediatric cohort  <cit> , and the predictor was evaluated on this cohort. all data sets were aligned to each other , and a predictor was built using our original data . this predictor was then tested for accuracy in each of the two additional data sets. figure  <dig> shows that in both the independent laboratory measurement and the independent validation were successful. the area under the receiver operating characteristic  curve for the new, untrained pediatric patients was . <dig> and the predictor was significantly different between patients with a sustained viral response compared to those who did not respond to therapy . these two results represent a validation of a clinically relevant predictor of disease state from label-free, unbiased mass spectrometry by further label-free, unbiased mass spectrometry.

verification of differential expression for individual peptides
in order to verify our findings, we identified  <dig> peptides which were subsequently targeted for quantitation with selected reaction monitoring  without the addition of stable-labeled peptides, similar to the lf srm method described in  <cit> . of the samples that were measured with the shotgun proteomics approach,  <dig> from the first two run blocks  were measured as well as  <dig> from the third run block . in order to test whether we can generate predictors of response to therapy in patients with hepatitis c, we trained a regression model on the  <dig> and validated on the remaining  <dig>  all samples were used in the selection of peptides to target with srm, therefore this does not constitute a true validation of an srm based predictor. however figure  <dig> shows that our predictive accuracy on the held out samples is quite good. this verifies, on the same samples and for a subset of the peptides, that our initial findings in the open platform can be reproduced by measurements of individual peptides. because we utilized the shotgun proteomics results from all samples to select isotope groups for srm, this does not address the question of out of sample accuracy, however, we have addressed this issue separately in patel et al.  <cit> .

in addition to biomarker verification, we sought to validate some examples of isotope groups which were determined not to follow their dominant metaprotein during the analysis of the original shotgun proteomics assay. an example is shown in figure  <dig>  the polypeptide “ttppttatpir” from the protein finc, which is known to be potentially o-glycoslyated at two residues  <cit> , has a consistently-measured expression pattern on both srm and qtof platforms . this peptide exemplifies the type of peptide the metaprotein approach would not group into the dominant metaprotein for finc, since it does not correlate with the expression pattern of other finc peptides  or the finc metaprotein . intensity data from the srm experiment is available in additional file  <dig> 

CONCLUSIONS
to date, the algorithms and models for aggregating mass spectrometry features in larger groups than peptides have relied on protein identifications and do not use correlations across samples in any way. the model we have described makes use of these correlations to identify peptides that do indeed show consistent expression in addition to agreement in identification. this paper describes both a novel statistical approach for the analysis of label-free, unbiased mass spectrometry proteomics and an approach for the validation of discoveries on that platform by further experiments on the same platform. furthermore, we have demonstrated the application of this approach in the context of the treatment of hepatitis c, which is a disease causing significant morbidity and mortality worldwide. the predictor of response to therapy described in this paper has the potential to significantly affect therapeutic decision making.

the model offers an approach to aggregation of mass spectrometry proteomics data that differs from protein level quantitation, and that in some situations, offers significant advantages over previous approaches. the critical difference between protein level quantitation and our metaprotein model is the inclusion of correlation structure in the metaprotein model. we should note that the inclusion of correlation structure may offer only minimal advantage low sample size situations. additionally, in cases where there is an overwhelming biological effect, that effect can dominate the observed correlations and drown out what would otherwise be differing expression patterns. however, we have demonstrated the utility of the approach for validation studies and for potential clinical applications.

our model is particularly well suited to situations in which we have a relatively large number of samples  with a high degree of biological variability. we have shown that it can be used to gain insights into translational studies, and have exemplified its use with a study of response to therapy in patients with hepatitis c. the model is appropriate for any high-quality quantitative  proteomics data. this is not limited to data-independent acquisitions, rather the approach can be utilized on any label-free quantitative data which is based on precursor intensity for the quantitation and collects enough points across the peak to accurately define the peak area.

