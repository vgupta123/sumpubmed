BACKGROUND
identifying microarray target concentration changes in response to developmental and environmental cues is one of the most common end points of microarray data analysis. however, diverse and numerous sources of variation are known to affect the accuracy and reliability of such results  <cit> . large community-wide efforts including the microarray quality control  project  <cit>  and the external rna controls consortium   <cit>  have been initiated to further identify sources of variation, establish reliable assessment metrics, and improve the accuracy of the interpretation of microarray data. normalization is an important analytical step to correct systematic noise inherent in microarray technology. to make arrays comparable current normalization techniques rely on knowledge or assumptions about genes expected to have low variation. we present a novel microarray normalization method that avoids the need to know or hypothesize about genes with low variation and thereby provide a more robust procedure.

not all sources of variation that are known to have an impact on data normalization performance are noise. biological sources of variation , namely, differential gene expression, are frequently observed in microarray data. in raw measurements, it is difficult to distinguish between biological sources of variation and the variation due to limited sampling, differences in array production batches, hybridization and washing conditions, scanning power, etc. when arrays under comparison are generated from different tissues or developmental stages, the total impact of biological variation and the percentage of genes containing gene effects are expected to be significantly large. this presents a challenge to microarray data normalization, which is an important step for removing experimental noise. a salient question with respect to normalization is how to deconvolute two sources of variation so that the associated experimental noise can be accurately assessed and removed by normalization. with proper normalization, the underlying biological variation across experimental groups becomes quantifiable.

frequent observation of nonlinear systematic noise in both affymetrix chip data and cdna microarrays has led to the development of several normalization methods for correcting nonlinear experimental differences between arrays. among them, quantile normalization in rma  <cit> , lowess  <cit> , and invariant set method  <cit>  are well adopted for analyzing affymetrix chip data. to prevent the perturbation caused by the presence of gene effects or other sources of outliers, lowess provides a built-in robust regression option in the method . designed for the same purpose, the invariant set method selects expression invariant probes whose rank difference is proportionally small between two chips prior to nonlinear curve fitting via either lowess  <cit>  or median-based procedures  <cit> . these approaches provide robustness against small gene effects.

however, they require that a critical assumption hold: any gene effects that exist are small or symmetric over the entire intensity range  <cit> . therefore, dchip recommends users to provide a known set of housekeeping genes which are assumed to have low variability across experimental groups when normalizing arrays from different tissues. to relax the statistical assumption, fan et al. proposed a semilinear in-slide model to iteratively assess two sources of variation  <cit>  and thereby directly address the issue of gene effects. variations of the semilinear models have also been proposed  <cit> . these methods often impose the requirement that sufficient numbers of replicated genes are present over the entire intensity range. with all these methods, there is a demand for a set of known low-variability genes over the intensity range.

performance of various normalization methods have been evaluated and compared in many studies. most evaluation does not involve data with significantly large numbers of gene effects, due to a lack of suitable experimental microarrays. recently, fujita et al compared several nonlinear normalization methods including lowess using an artificial dataset containing up to 40% outliers  <cit> . their results indicate various degrees of robustness to outliers with respect to normalization choices. when the percentage of outliers increases from 5% up to about 40%, all methods incur increasing amounts of normalization errors. to overcome the lack of experimental microarrays of known large gene effects, choe et al generated a spike-in array dataset  containing approximately 34% gene effects  <cit> . as expected, normalization based on only unchanged genes clearly performs better than normalization on both unchanged genes and differentially expressed genes , indicating that the deleterious impacts of incorrect assumptions about which genes have no gene effects are present in all normalization methods studied. in light of this study, irizarry et al. stress the need for new normalization methods when processing microarray datasets that are quite different  <cit> .

in our current study, we propose a two-dimensional nonparametric modeling approach named nonparametric variable selection and approximation  for normalizing affymetrix arrays in experiments that may have significantly large numbers of gene effects. nvsa identifies genes exhibiting no differential expression, and uses them as the basis for normalization. using benchmark evaluation procedures, we demonstrate the following: 1) nvsa prevents interference by gene effects and results in higher accuracy and higher precision normalization under conditions where the performance of alternative approaches are affected; 2) the variable selection component of nvsa can be used to improve the performance of alternative methods; and 3) nvsa analysis generates statistically consistent data whether all genes or only housekeeping genes are used for normalization. taken together, our data indicates that nvsa may be a useful utility for data normalization analysis in any experiment, and especially in experiments currently known or expected to be difficult to analyze such as those containing samples from different tissues or development stages.

RESULTS
the nvsa methodology
let xi, yi, i =  <dig>   <dig> ... n be the measured log <dig> baseline and sample array intensity at the ith gene, or probe, respectively. following the ma convention  <cit> , we thus have

  mi = yi - xi = δi + f + εi 

where δi denotes gene effect, ai =  <dig> * , f is the intensity effect and εi is random error. to estimate the intensity and gene effect levels independently, we first fixed f by segmentation or binning. to provide sufficient degrees of freedom to estimate f, the data were binned into q fixed-width intervals by a. when the width is sufficiently small, the awithin an interval will be similar, thus the corresponding f is approximately constant. then for the interval j centered at aj,  is rewritten as

  mj = δj + f + εj 

where aj ∈ j, j =  <dig>   <dig> ...,m. this equation indicates that only when the gene effect δ =  <dig>  can the intensity effect f be solved independently from the gene effect. three classes of gene effect may exist: no gene-regulation , up-regulation , and down-regulation . therefore, the density distribution of {mj} may be skewed, as well as multimodal, depending on the relative proportions of these three gene effect classes.

let rj = mj, f be the density of r with k numbers of distinct classes or modes, k >=  <dig>  we approximate f via one-dimensional gaussian kernel density estimation  <cit> :

  f^=1mh∑j=1mk 

  k=12πe−u2/ <dig> 

where k is a gaussian with zero mean and standard deviation of  <dig> and h is the fixed width smoothing window . the boundaries of each mode  are identified via gradient search:

  grad))≥ <dig> 

where grad) ≥  <dig> . the expected value of each class ∏i, i =  <dig>   <dig> ...,k is computed by averaging the top 80% of the peak area of the class to prevent convolution between classes. we are primarily interested in identifying the invariant class ∏iv, which is enabled by following the two priors: 1) predominance rule: the area in ∏iv is the largest when invariant genes are dominant, and 2) intensity effect f  is slowly changing  <cit>  along a, as does the expected value of the invariant class ). let ∏l be the class with largest area, wl be the ratio of the largest class to the total area in all classes within an interval. we compute the central moving standard deviation  on wl data and moving coefficient of variation  on e data, respectively, across intervals with window size of  <dig>  the initial seed invariant classes were selected once relative homogeneity in predominant classes occurs . the invariant classes for the remaining intervals are determined sequentially from the seed to the left boundary and then from the seed to the right, employing the slow-changing rule:

  arg min {|f'|} ∩ arg min {|f"|} 

where f′=e−e, f′= <dig> ×−e+f′), f" = f' - f', - <dig>  - <dig> denote the preceding two intervals, respectively. if none of the classes in the interval to be evaluated meets the condition specified in equation  <cit> , the interval will be skipped. the intra-bin intensity effect is then derived by f = e, according to  <cit> . to compute the fitted intensity effects {f^}, q numbers of bin-conditioned intensity effects {f are smoothed on intensities {aj} by a weighted smoothing spline  <cit> , where weight is defined as:

  w=n−nmin⁡nmax⁡−nmin⁡×+τb 

where n is the logarithm to the base  <dig> of the number of data points in an interval, τa, τb are tolerance factors of a smoothing spline, and τa ≤ τb . the final normalized log <dig> intensity is given by, y′i=yi−f^. the nvsa was written in matlab  <cit>  and is available free of charge for academic purposes upon request.

normalization accuracy and precision under conditions of gene effects
to evaluate whether our nvsa method would be sufficiently robust against the impact of gene effects, we constructed simulated data based on a simple multiplicative error model with the ground truth data generated from real microarray data . three intensity effects, three gene regulation modes, and  <dig> various percentages of gene effects are simulated alone or in combinations. data series labeled d <dig>  d <dig> , and dnl represent linear intensity effects of  <dig> and  <dig> , respectively, and nl denotes nonlinear intensity effects . gene regulation modes are up-regulation only, down-regulation only, and mixed up- and down-regulation  known as a globally symmetric gene effect.

six alternative normalization procedures, quantile, lowess, robust lowess, invariant set, cross-correlation , and global median were chosen to be compared with nvsa due to their availability. cross-correlation is a novel peak-matching algorithm to address unbalanced shifts in transcripts levels  <cit> . all datasets were normalized to the ground truth data under default conditions. figure 1b, c shows a typical scatter plot of intensities before and after nvsa normalization, illustrating that nonlinearity is removed by nvsa normalization.

we then used accuracy and precision measurements to quantify the performance of each normalization procedure. accuracy here refers to closeness to the true value, computed as the mean relative error in the estimated normalization factors: average of |/true|. a highly accurate method incurs low error. the precision benchmark, an indication of reproducibility, refers to how near the values of repeated measurements are to each other. the array-averaged coefficient of variation  was used to evaluate the precision between the normalized dnl and their gene effect and regulation mode matched d <dig> array intensities .

the accuracy results show that all nonlinear normalization procedures perform equally well in conditions where there is a zero percentage of deg . however, the accuracy of the quantile, lowess and invariant set are progressively affected by an increase in the percentage of gene effects. robust lowess, on the other hand, appears to provide protection against gene effects ranging up to 15%. among alternative methods, cross-correlation is most robust, exhibiting a similar low error rate until 30% gene effects. among all methods evaluated, the errors in the nvsa-normalized data were found to be the lowest and do not appear to be significantly affected up to 50% deg. this indicates that under gene effect conditions, nvsa is the most accurate method and is the most resistant to the presence of deg. the accuracy results with the linear d <dig>  dataset also show similar pattern , indicating that the performance difference in normalization is not due to the ability to remove the data nonlinearity itself, but owing to each method's robustness against gene effects.

consistent with the differences in the data modeling strategies, the invariant set and robust lowess approaches are more robust against gene effects when compared to quantile and lowess. the improved accuracy in nvsa over the quantile and lowess is statistically significant under all  <dig> non-zero gene effect conditions , likewise, the larger normalization errors in invariant set, robust loess, and cross-correlation methods than the errors in nvsa are statistically significant under  <dig>   <dig>  and  <dig> out of a total of  <dig> non-zero gene effects conditions, respectively.

the precision of the normalization was measured by the array-averaged coefficient of variation  between the normalized dnl and their gene-effect matched d <dig> array intensities . the results  show a similar pattern to the accuracy assessment: 1) all six nonlinear normalization approaches perform equally well under zero gene effects, 2) the precision of nvsa normalization does not appear to be negatively affected by gene effects, but the precision of quantile, and lowess methods worsens when the gene effect increases, and 3) the cross-correlation, invariant set, and robust lowess approaches generally perform better than quantile and lowess under nonzero gene effect conditions. taken together, our studies indicate that under our test conditions, nvsa normalization is of high-accuracy and high-precision regardless of the extent of the gene effects.

nvsa improves the robustness of alternative methods against gene effects
we postulate that the key difference in these normalization methods lies in the effectiveness of the method to distinguish invariant genes from the ones that have altered expression. therefore, nvsa's unique invariant gene selection approach may be useful for improving the robustness of alternative methods.

using the nvsa method, we filtered out the genes whose log <dig> expression ratios  are outside of the invariant gene modes . the percentage of genes that have been filtered out correlates well with the percentage of gene effects . normalization by lowess, quantile, and cross-correlation on the remaining data are subsequently carried out under the same default conditions as used previously. it should be noted that the nvsa filtering plus lowess analysis is equivalent to replacing the rank invariant step of the invariant set method with the nvsa variable selection procedure. thus, normalization by the curve-fitting component  of the invariant set method was not necessary and was not performed. to prevent errors caused by extrapolation, only the normalization errors on the invariant genes were estimated. as expected, the accuracy of normalization has been substantially improved with the introduction of nvsa analysis prior to data normalization , as compared to the one without, for all of the alternative methods tested. in most cases, nvsa-assisted alternative methods perform as well as the full nvsa application. the results indicate that the performance gain observed in figure  <dig> is largely due to the variable selection step of nvsa, and nvsa is most effective for identifying a set of invariant genes that can be used to produce an accurate normalization procedure.

gene effects result in skewed distributions
normalization methods assuming symmetric gene effects are expected to be sensitive to skewed ler distributions, a condition that can occur when there is an over abundance of up- or down-regulated genes within a small range of intensities in a dataset. using the simulation data, we measured the extent of the skewed ler distribution within each bin according to the ag method in the dnl data series  <cit> . the studies reveal that the percentage of genes in skewed distributions increases concurrently with an increased percentage of gene effects . studies of actual local deg percentages reveal uneven distribution of up- and down-regulated genes locally, when these two populations are balanced globally . thus, both globally- symmetric and asymmetric gene effects cause a local skewing of the ler distributions and these observations are consistent with our performance assessment results.

agreement of normalization regardless of gene effects
normalization methods that are robust to gene effects are expected to output similar normalization curves from data including or excluding genes containing gene effects. we therefore use this criterion to compare the performance of normalization methods on experimental microarrays where the true normalization factors are unknown but the genes that are differentially expressed are known. the golden spike data set, developed by choe et al.  <cit> , is unique in that the relative concentrations of all  <dig>  gene transcripts between control  and spike-in  samples are defined:  <dig>  have identical concentrations between s and c samples;  <dig>  have increased concentration in s over c samples at a fold-change level ranging from  <dig>  ~  <dig> folds. thus, the dataset has approximately 34% gene effects between c and s samples yet 0% gene effects between replicate arrays. this allows us to study the agreement of normalization under the conditions of large gene effects versus no gene effects, as well as between the analyses from all genes versus non-deg only.

therefore under our test conditions, nvsa is most robust for normalizing experimental microarrays containing significantly large and asymmetric gene effects. the performance characteristics associated with nvsa could be important since it removes the requirement for a priori knowledge of or assumptions about housekeeping genes in experiments involving multiple tissues or stages of development in which it is reasonable to assume the existence of a large number of deg.

discussion
in the current study, we describe a novel two-dimensional nonparametric normalization method to address the problem of significant gene effects in affymetrix microarrays. this problem is significant in experiments involving multiple tissues or developmental stages since knowledge of and assumptions about gene expression, including those of housekeeping genes are tenuous. we demonstrate the high performance characteristics of our new analysis method in dealing with the influence of gene effects during normalization.

we show that the nvsa approach maintains high accuracy and high precision during the normalization of data containing  <dig> to 50% simulated gene effects. normalization by alternative approaches, however, becomes increasingly compromised when the extent of gene effects increases. the analysis on experimental microarrays confirms that nvsa performs better than alternatives when gene effects are large. these performance characteristics are consistent with the difference in model assumptions and method approaches. nvsa is nonparametric for both the intensity and ler dimensions, as opposed to the quantile, lowess, and invariant set methods that are nonparametric in one dimension . nonparametric versus parametric assumptions of ler distribution is the key distinction between nvsa and the available alternatives in model assumptions. nonparametric assumptions of ler distribution means that the algorithm does not assume the symmetry, modality of ler distributions. when ler is symmetrically distributed, all methods are expected to perform well and our results confirm this. when ler is asymmetrically distributed, nonparametric treatment of ler distribution for identifying the center of invariant genes is expected to be superior to parametric methods, since nvsa characterizes ler distributions rather than assuming them. the variable approximation process of nvsa is functionally similar to other nonlinear normalization methods including lowess. however, the dimensions of the input data  are dramatically reduced , resulting in a faster implementation .

although both nvsa and the invariant set methods specifically aim to identify invariant genes, the variable selection process of nvsa takes a more sophisticated approach to achieve two aims: 1) to segregate gene and intensity effects in mutually independent ways using a two-dimensional nonparametric approach, and 2) to identify invariant genes even when they are not in the predominant classes using a rule-based global optimization approach. our study demonstrates that nvsa provides superior performance to the invariant set method under many common and important experimental conditions.

cross-correlation is a newly developed normalization to address the issue of asymmetric gene effects. the method accumulates significant amounts normalization error starting from 30% gene effects in simulation data and produces statistically significant disagreement between results of normalization on all genes and those on only invariant genes in the majority of golden spike data containing ~34% gene effects. we speculate that the cross-correlation method may be dependent on an assumption that the local invariant genes are present as a predominant class. we have generated a ma plot for dnl data containing 30% up-regulated genes, which shows that in four intensity bins, invariant genes are not the predominant classes . consistent with this notion, erroneous normalization by cross-correlation occurs in one of the regions where invariant genes are not dominant . we have further plotted the number of non-dominant invariant gene classes along with all gene effects conditions . visual comparison of fig. 7c to fig. 2a suggests that the conditions where the cross-correlation method fails are generally the conditions where the number of non-dominant invariant classes is greater than  <dig>  a higher number of non-dominant invariant class correlates with a larger normalization errors in this method. these analyses results support our hypothesis that the cross-correlation method requires an implicit assumption that may be violated in simulation data sets.

our current results confirm the hypothesis that significant gene effects cause skewed ler distributions, the conditions under which the critical assumptions made by other approaches break down and cause the methods to produce errors. interestingly, the percentages of genes in skewed distributions are higher in up- than in down-regulated genes. skewed distributions have also been found in data simulated with globally balanced gene effects. we reason that it is the result of combinations of asymmetric intensity distributions and boundary effects. it is known that the intensity distribution in a typical microarray is non-normal, with a long tail skewed to the right and denser distribution on the left side. the magnitude of negative fold-changes is thus more likely to be subdued by a scanner's low detection limit than the magnitude of positive fold-changes to be tempered by the upper detection limit; positive fold-changes are thus likely to increase the percentage of local deg more than negative fold-changes do due to the asymmetric intensity distribution.

when the extent of gene effects is locally greater than 50%, invariant genes are not in the largest peak of local ler distribution. this may cause nvsa to mistake the variant genes as invariants, which may influence the accuracy of seed invariant class selection. when this does occur, nvsa is expected to break and incur large errors. to estimate exactly when the performance of nvsa breaks, we have generated dnl or d <dig>  data containing  <dig> to 95% gene effects in a 5% increment, and then  <dig> to  <dig> percent in a 1% increment. for dnl data, the nvsa normalization has maintained similar small error rates as seen in fig.  <dig> and then start to break when data contains 100% up-, 90% down-, and 85% up/down-regulated genes, respectively . correspondingly, large normalization errors start to be observed in nvsa-normalized d <dig>  data containing 95% up-, 75% down-, and 80% up/down-regulated genes, respectively. in all theses cases, the performance break-down is due to the miss-selection of seed invariant classes. this error may be corrected by manually typing the correct corresponding intensity interval of the seed invariant class if the class is visually definable. another factor that may influence nvsa performance is the choice of bin width, which can cause overfitting or underfitting of the data. however, some local overfitting or underfitting errors can be mitigated by the following spline smoothing procedure. we set our default bin width at  <dig> . our limited study indicates that small variations in the choice of bin-width do not affect nvsa performance as long as there are sufficient numbers of data points in the bin. when the whole array data points are much smaller than a typical affymetrix array, a coarse binning may be more appropriate. as with most normalization methods, the performance of nvsa may also be affected by the accuracy of background subtraction. for example, nonzero intensities from large amounts of empty cells may convolute the distribution of invariant genes and thus interfere with the estimation of intensity effects. in addition, various forms of experimental noise may influence the choice and performance of normalization methods. for any given experimental microarray, it is beneficial to validate with statistical tests  <cit>  whether a normalization method is needed and which normalization method is most suitable.

CONCLUSIONS
our analyses revealed that a high percentage of gene effects, whether they are globally balanced or not, causes local asymmetric distributions of ler. the skewed ler distributions increasingly interfere with the performances of several normalization methods that are widely used today. we presented a novel normalization method nvsa that implements a unique integrated approach for selecting invariant genes. the accuracy in invariant gene selection was achieved using a two-dimensional nonparametric approach for peak identification and a rule-based global optimization method for peak selection. we validated the high performance of the new method on simulated and experimental data sets containing up to 50% gene effects. our analysis results indicated that the new method may be a useful tool for data normalization analysis in any experiment, and especially in experiments containing samples from different tissues or development stages in which it is reasonable to assume the existence of a high percentage of gene effects.

