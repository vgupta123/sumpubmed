BACKGROUND
parameter estimation of dynamic biological models described by nonlinear ordinary differential equations  poses a critical challenge. a special feature of biological models is that they usually contain a large number of parameters among which correlations exist  <cit> . in general, the quality of estimation results depends on the quality of data acquisition, the quality of the fitting method, and the quality of the model. good experiment design can lead to highly informative data which will enhance the accuracy and identifiability of model parameters. therefore, the task of parameter estimation demands an interactive endeavour of experiment and computation  <cit> .

to fit parameters to measured data a numerical method for solving an optimization problem is required. available methods for carrying out this task can be classified into deterministic approaches  and stochastic approaches . using these approaches, model parameters can be well fitted to measured time courses provided from either experiment  or simulation , i.e. high quality fits with minimal residual values can be obtained by global optimization methods.

however, even such a good fitting cannot guarantee unique parameter estimation, due to correlations among the parameters. the correlation phenomenon can be explained by the biological background, e.g. genes or proteins which are expressed in a correlated manner, correlations of expression levels between cells. as a consequence, certain regions in the parameter space correspond to good model predictions. it means that the residual value  remains low even if the parameters vary in certain regions. by testing  <dig> biological models, gutenkunst et al.  <cit>  concluded that collective fits to large amounts of ideal time-series data lead to the fact that some eigenvectors are orders of magnitudes better constrained than others.

correlated parameters are non-identifiable. if the non-identifiability does not change for any data, these parameters are called structurally non-identifiable. on the contrary, if the non-identifiability can be remedied by data improvement, they are practically non-identifiable  <cit> . identifiability analysis represents an important ongoing topic in the literature which can be in general categorized into two major groups: a priori and a posteriori methods  <cit> . without any requirement of measurement data, global  identifiability can be determined by a priori methods  <cit> . since these methods are normally based on differential algebra, their application to high dimensional complex models can be limited.

the a posteriori methods reveal practical identifiability properties based on results from fitting parameters to available data sets. in most studies, correlations are detected by analysing the sensitivity matrix and the fisher information matrix   <cit> , from which local confidence regions of parameter solutions can be obtained. sensitivity analysis is well suitable to linear models but will have limitations for highly nonlinear models  <cit> .

recently, raue et al.  <cit>  proposed to use profile likelihood to detect non-identifiability for partially observable models. the parameter space is explored for each parameter by repeatedly fitting the model to a given data set, which then provides a likelihood-based confidence region for each parameter. results from this method show that the number of practically non-identifiable parameters will decrease when more data sets are used  <cit> .

an aim of identifiability analysis is to determine if the parameters of a model are identifiable or not, i.e. whether its parameters can be uniquely estimated. the profile likelihood approach can also offer information on the correlated relations among the parameters  <cit> . the information on parameter correlations  is important for experimental design, so that a series of experimental runs with determined conditions can be carried out to acquire proper measurement data sets for improving the quality of parameter estimation.

very few studies have been made to investigate parameter correlations in biological models. yao et al.  <cit>  used the rank of the sensitivity matrix to determine the number of estimable parameters. however, the subsets of correlated parameters cannot be identified based on this result. chu and hahn  <cit>  proposed to check the parallel columns in the sensitivity matrix to determine parameter subsets in which the parameters are pairwise correlated. quaiser and mönnigmann  <cit>  proposed a method to rank the parameters from least estimable to most estimable. these methods, however, cannot identify parameter groups in which more than two parameters are correlated together but not in pairwise, i.e. the corresponding columns in the sensitivity matrix are linearly dependent but not parallel. such correlations are called higher order interrelationships among parameters  <cit> .

in this paper, “parameter correlations” means a group of parameters in the model equations which are mathematically related to each other through some implicit functions, i.e. among the parameters there is a functional relationship  <cit> . correlated parameters will be structurally non-identifiable, if the functional relationship does not depend on the control variables which determine experimental conditions and thus measured data. on the other hand, they will be practically non-identifiable, if the functional relationship depends on the control variables.

in this paper, we present an approach which is able to identify both pairwise and higher order parameter correlations. our approach is based on analysis of linear dependences of the first order partial derivative functions of model equations. in a given model there may be a number of groups with different number of correlated parameters. we propose to identify these groups by analysing the correlations of the columns of the state sensitivity matrix which can be derived directly from the right-hand side of the odes. therefore, the method proposed in this paper is a priori in nature, which means that the parameter correlations considered in this paper are not from the results of data-based estimation. a geometric interpretation of parameter correlations is also presented. using this approach, groups of correlated parameters and the types of correlations can be identified and, hence, the parameter identifiability issue can be addressed. moreover, the relationship between parameter correlations and the control inputs can be derived. as a result, both structural and practical non-identifiabilities can be identified by the proposed approach.

in the case of practical non-identifiability, the parameter correlations can be relieved by specifying the values of control inputs for experimental design. based on the correlation analysis, the maximum number of parameters among the correlation groups can be determined, which corresponds to the minimum number of data sets with different inputs required for uniquely estimating the parameters of the model under consideration. numerical results of parameter estimation of a three-step-pathway model clearly demonstrate the efficacy of the proposed approach.

methods
identification of parameter correlations
we consider nonlinear model systems described by

  x˙t=fxt,ut,p 

  yt=hxt,ut,q 

where x ∈ rn is the state vector, u ∈ rm the control vector, and y ∈ rr the output vector, respectively. in this study, two different sets of parameters, i.e. p ∈ rnp in the state equations and q ∈ rnq in the output equations, are considered. in most cases the number of parameters in the state equations is much larger than that in the output equations. since the correlations of the parameters in the output equation  are easier to identify, we concentrate on the analysis and identification of correlations of the parameters in the state equation .

the equation of the state sensitivity matrix can be derived by taking the first order partial derivative of eq.  with respect to parameters p

  s˙=∂f∂xs+∂f∂p 

where s=∂x∂p is the state sensitivity matrix. by solving this equation  the state sensitivity matrix can be written as

  s=∫t0tvτ∂f∂pdτ 

where v is a matrix computed at time τ. it means that s has a linear integral relation with the matrix ∂f∂p from t <dig> to t. if at any time ∂f∂p has the same linearly dependent columns, the corresponding columns in s will also be linearly dependent, i.e. the corresponding parameters are correlated. therefore, we can identify parameter correlations by checking the linear dependences of the column in the matrix ∂f∂p which is composed of the first order partial derivatives of the right-hand side of the odes. based on eq. , the output sensitivity matrices are, respectively, given by

  ∂y∂p=∂h∂x∂x∂p=−∂h∂x∂f∂x−1∂f∂p 

  ∂y∂q=∂h∂q 

to ensure unique estimation of the parameters , based on the measured data of y, it is necessary that the columns in the output sensitivity matrices ∂y∂p,∂y∂q are linearly independent. from eq. , relations of the columns in ∂y∂q can be easily detected. the difficulty comes from eq. , since the sensitivity functions in ∂y∂p cannot be analytically expressed. however, from eq. , the output sensitivity matrix is a linear transformation of ∂f∂p. consequently, there will be linearly dependent columns in ∂y∂p, if there are linearly dependent columns in ∂f∂p. it means the necessary condition for unique estimation of p is that, at least, the matrix ∂f∂p must have a full rank. based on eq. , ∂f∂p is expressed as vectors of the first order partial derivative functions

  ∂f∂p=∂f∂p <dig> ∂f∂p <dig> ⋯,∂f∂pnp 

now we analyse relations between the partial derivative functions in eq. . if there is no correlation among the parameters, the columns in eq.  will be linearly independent, i.e. if

  α1∂f∂p1+α2∂f∂p2+⋯+αnp∂f∂pnp= <dig> 

there must be αi =  <dig>  i =  <dig>  ⋯, np. otherwise, there will be some groups of vectors in ∂f∂p which lead to the following cases of linear dependences due to parameter correlations. let us consider a subset of the parameters with k correlated parameters denoted as psub = t with s + k ≤ np.

case 1:

  α1∂f∂ps+1=α2∂f∂ps+2=⋯=αk∂f∂ps+k 

where αi ≠  <dig>  i =  <dig>  ⋯, k. notice that the coefficient αi may be a function of the parameters ) and/or of control inputs , p)). it should be also noted that the control inputs u are considered as constants in these coefficients, since they will be specified in experimental design. the linear dependences described by eq.  lead to pairwise correlations among the k parameters, i.e. any pair of the parameters in psub are correlated. moreover, the correlations mean a functional relationship between the parameters, i.e. the relationship between the parameters can be expressed by an algebraic equation

  ϕsubγps+ <dig> ps+ <dig> ⋯,ps+k= <dig> 

where γ denotes a function of the parameters with one set of pairwise correlated parameters. the parameters in this function are compensated each other in an algebraic relationship, e.g. γ or γ. eq.  describes the functional relationship between the parameters, e.g. ϕsub) = 1 + γ − )2 =  <dig>  due to the complexity of biological models, an explicit expression of this equation is not available in most cases.

if the coefficients in eq.  are functions of only the parameters, i.e. αi, the parameters are structurally non-identifiable. in this case, the correlation relations in eq.  will remain unchanged by specifying any values of control inputs. it means that the non-identifiability cannot be remedied through experimental design.

if the coefficients in eq.  are functions of both the parameters and control inputs, i.e. αi, the parameters are practically non-identifiable. different values for u can be specified which lead to different αi, such that eq.  will not hold and therefore the parameter correlations will be relieved. since k parameters are correlated, k different values of the control inputs u,  are required, such that the matrix

  ∂f∂psub=∂f1∂ps+1∂f1∂ps+2⋯∂f1∂ps+k∂f2∂ps+1∂f2∂ps+2⋯∂f2∂ps+k⋮⋮⋯⋮∂fk∂ps+1∂fk∂ps+2⋯∂fk∂ps+k 

has a full rank. notice that the columns in eq.  are only linearly dependent for the same input, but the columns of the whole matrix are linearly independent. in this way, the non-identifiability is remedied. moreover, a suggestion for experimental design is provided for the specification of u,  to obtain k distinct data sets which will be used for parameter estimation.

if all state variables are measurable, according to eq. , this subset of parameters can be uniquely estimated based on the k data sets. if the outputs y are measured and used for the parameter estimation, it can be concluded from eq.  that at least k data sets are required for unique parameter estimation.

case 2:

  α1∂f∂ps+1=⋯=αs+l1∂f∂ps+l <dig> ⋯,αs+ld−1+1∂f∂ps+ld−1+1=⋯=αs+k∂f∂ps+k 

and

  αs+k+1∂f∂ps+1+αs+k+2∂f∂ps+l1+1+⋯+αs+k+d∂f∂ps+ld−1+1= <dig> 

where αi ≠  <dig>  i =  <dig>  ⋯, s + k + d. similarly, the coefficients may be functions of the parameters and/or of the control inputs. in this case, there are d sets of pairwise correlated parameters ). a set is not correlated with another set, but all sets are correlated together ). the functional relationship in this case can be expressed by

  ϕsubγ1ps+ <dig> ⋯,ps+l <dig> ⋯,γdps+ld−1+ <dig> ⋯,ps+k= <dig> 

based on eq. , the group with the maximum number of parameters max  is of importance for data acquisition. from eq. , in the case of practical non-identifiability, data for at least d different inputs is required. the combination of eqs.  and  leads to the conclusion that we need a number of max  data sets with different inputs to eliminate parameter correlations in this case.

case 3:

  α1∂f∂ps+1+α2∂f∂ps+2+α3∂f∂ps+3+⋯+αk∂f∂ps+k= <dig> 

where αi ≠  <dig>  i =  <dig>  ⋯, k. in this case, all k parameters are not pairwise correlated but they are correlated together in one group. the correlation equation in this case is expressed by

  ϕsps+ <dig> ps+ <dig> ⋯,ps+k= <dig> 

which means there is no set of correlated parameters in this case. the approach described above is able to identify pairwise and higher order parameter correlations in the state equations ). in the same way, correlations among parameters in q in the output equations ) can also be detected based on the first order partial derivative functions in eq. .

from the results of this correlation analysis, the maximum number of correlated parameters of the correlation groups can be detected. this corresponds to the minimum number of data sets required for unique estimation of all parameters in the model. furthermore, it is noted that the initial state of the model has no impact on the parameter correlations, which means that any initial state can be used for the experimental runs for the data acquisition.

for complex models, the correlation equations , , ) cannot be analytically expressed. a numerical method has to be used to illustrate the relationships of correlated parameters of a given model, which is discussed in the next section.

interpretation of parameter correlations
here we give an interpretation of parameter correlations in a biological model. geometrically, for np parameters, i.e. p = t, the estimation task can be considered as searching for true parameter values p* in the np-dimensional parameter space. to do this, we need np linearly independent surfaces in the parameter space which should pass through p*. mathematically, such surfaces are described by linearly independent equations with the unknown parameters. we define such equations based on the results of fitting model equations  to a data set  by minimizing the following cost function

  minpfjp=∑l=1m∑i=1nwi,lxi,ljp−x^i,lj <dig> 

where m is the number of sampling points, n is the number of state variables and x^ denotes the measured data while x the state variables predicted by the model. wi,l are weighting factors. the fitting results will depend on the data set resulted from the control inputs u, the values of wi,l, and the noise level of the measured data. for a geometric interpretation of parameter correlations, we assume to use idealized measurement data, i.e. data without any noises. based on this assumption, the residual function  should be zero, when the true parameter set p* is applied, i.e.

  xi,ljp*−x^i,lj= <dig> i= <dig> ⋯,n,l= <dig> ⋯,m 

it is noted that eq.  is true for any noise-free data set employed for the fitting and independent of wi,q,. now we define a zero residual equation  as

  φi,ljp=xi,ljp−x^i,lj= <dig> 

this equation contains the parameters as unknowns and corresponds to a zero residual surface passing through the true parameter point p*. it means that a zero residual surface is built by parameter values which lead to a zero residual value. this suggests that we can find p* by solving np linearly independent zres. from the first order taylor expansion of eq. , the linear dependences of zres can be detected by the columns in the following matrix

  ∂xj∂p=∂xj∂p <dig> ∂xj∂p <dig> ⋯,∂xj∂pnp 

where x = t. eq.  is exactly the state sensitivity matrix calculated by fitting to the given data set . this means, under the idealized data assumption, a zero residual value delivered after the fitting is associated to surfaces passing through the true parameter point. when there are no parameter correlations, the number of linearly independent zres will be greater than np and thus the true parameter point can be found by fitting the current data set.

if there are parameter correlations, the fitting will lead to zero residual surfaces in the subspace of the correlated parameters. for instance, for a group of k correlated parameters, the zero residual surfaces ) will be reduced to a single zre represented by eq. , eq. , or eq. . therefore, in the case of practical non-identifiability, k data sets are needed to generate k linearly independent zres so that the k parameters can be uniquely estimated. in the case of structural non-identifiability, the correlated relations are independent of data sets. it means fitting different data sets will lead to the same zre and thus the same surfaces in the parameter subspace.

if the measured data are with noises, the fitting results will lead to a nonzero residual value and nonzero residual surfaces, i.e.

  φi,ljp=xi,ljp−x^i,lj=ϵi,l 

where ϵi,l ≠  <dig>  thus the nonzero residual surfaces will not pass through the true parameter point. however, based on eq.  and eq.  the first order partial derivatives remain unchanged. it means that parameter correlations do not depend on the quality of the measured data. moreover, it can be seen from eq.  and eq.  that the zero residual surfaces and the nonzero residual surfaces will be parallel in the subspace of the correlated parameters.

RESULTS
we consider a three-step pathway modelled by  <dig> nonlinear ordinary differential equations  containing  <dig> metabolic concentrations  and  <dig> parameters  <cit> , as given in eqs. . the p and s values in the odes are considered as two control inputs specified by experimental design. no output equations were considered for this model in the previous studies.

  x˙1=p11+pp2p3+p4sp5−p6x <dig> 

  x˙2=p71+pp8p9+p10x7p11−p12x <dig> 

  x˙3=p131+pp14p15+p16x8p17−p18x <dig> 

  x˙4=p19x1p20+x1−p21x <dig> 

  x˙5=p22x2p23+x2−p24x <dig> 

  x˙6=p25x3p26+x3−p27x <dig> 

  x˙7=p28x4s−x7p291+sp29+x7p30−p31x5x7−x8p321+x7p32+x8p <dig> 

  x˙8=p31x5x7−x8p321+x7p32+x8p33−p34x6x8−pp351+x8p35+pp <dig> 

this pathway model was studied by moles et al.  <cit>  using  <dig> noise-free data sets and rodriguez-fernandez et al.  <cit>  using  <dig> both noise-free and noisy data sets, respectively. they showed some strong parameter correlations in several groups. accurate parameter values were identified in  <cit> . however, a clear correlation analysis of the parameters and the relationship between the parameter correlations and the numbers of data sets with different inputs required for the parameter estimation were not given in the previous studies.

identification of correlations
now we identify parameter correlations in this model using our approach. given the model represented by eqs. , the first order partial derivative functions can be readily derived leading to the following linear dependences .

from eq. ,

  α1∂f1∂p1=α2∂f1∂p2=⋯=α5∂f1∂p <dig> 

from eq. ,

  α6∂f2∂p8=∂f2∂p9andα7∂f2∂p7+α8∂f2∂p10=∂f2∂p <dig> 

from eq. ,

  α9∂f3∂p14=∂f3∂p15andα10∂f3∂p13+α11∂f3∂p16=∂f3∂p <dig> 

from eq. ,

  α12∂f7∂p28+α13∂f7∂p29=∂f7∂p <dig> 

from eq. ,

  α14∂f8∂p35=∂f8∂p <dig> 

the coefficients in eqs.  – , αi, , are functions of the corresponding parameters and controls in the individual state equations . based on these results, correlated parameters in this model can be described in  <dig> groups:

group 1: g <dig>  among which any pair of parameters are pairwise correlated;

group 2: g <dig>  among which p <dig>  p <dig> are pairwise correlated and p <dig>  p <dig>  p <dig> as well as p <dig>  p <dig>  p <dig> are correlated, respectively.

group 3: g <dig>  among which p <dig>  p <dig> are pairwise correlated and p <dig>  p <dig>  p <dig> as well as p <dig>  p <dig>  p <dig> are correlated, respectively.

group 4: g <dig>  the parameters are correlated together but not pairwise;

group 5: g <dig>  they are pairwise correlated.

since the coefficients are functions of both of the parameters and the control inputs, these correlated parameters are practically non-identifiable for a single set of data. it is noted that, in g <dig> and g <dig>  the maximum number of correlated parameters is three. among the  <dig> correlated parameter groups the maximum number of correlated parameters is  <dig> . it means at least  <dig> data sets with different control values are required to uniquely estimate the  <dig> parameters of this model.

verification of the correlations by fitting the model
to verify the proposed approach and check the correlations in this model, we carried out numerical experiments by fitting the parameters to a certain number of simulated data sets with different inputs. the fitting method used is a modified sequential approach suitable for handling multiple data sets  <cit> .

we used the nominal parameter values given in  <cit> , initial state values as well as p and s values  given in  <cit>  to generate  <dig> noise-free data sets with different inputs containing the time courses of the  <dig> state variables. for each data set  <dig> data points were taken with 1 minute as sampling time.

for fitting the parameters we used random values for all  <dig> parameters to initialize the computation and all weights in eqn.  were set to  <dig> . the results were taken by a threshold of the total residual value in the order of 10- <dig> when using noise-free data sets .

*

+
++
+…+
+…+
+…+

p* are the nominal  values, p the values based on the 1st data set, p+ based on the 1st, 2nd data sets together, p++ based on the 1st, 2nd, and 3rd data sets, p+…+ based on the 1st to 4th data sets, and p+…+ based on the  <dig> data sets, respectively.  means results from 10% noises on the data. correlated parameter groups are highlighted separately.

figure 1a  shows the angles between the columns of the state sensitivity matrix by fitting to the 1st data set. the zero angles  mean that the corresponding columns are pairwise parallel. according to figure 1a,  <dig> pairwise correlated parameter groups , , , ) can be detected. however, these are not the same results as identified by the analysis of the model equations. this is because a dendrogram only shows pairwise correlations; it cannot detect higher order interrelationships among the parameters.

to illustrate the geometric interpretation, we first take the group of g <dig> as an example to construct zres, i.e. to plot the correlated relations between p <dig> and p <dig>  this was done by repeatedly fitting the model to the  <dig> individual data sets with different inputs, respectively, with fixed values of p <dig>  the resulting  <dig> zero residual surfaces  in the subspace of p <dig> and p <dig> are shown in figure 2a. as expected, the zero residual surfaces resulted from different data sets cross indeed at the true parameter point in the parameter subspace. figure 2b shows the relations between p <dig> and p <dig> by fitting the parameters separately to the same  <dig> data sets on which a gaussian distributed error of 10% was added. it can be seen that, due to the measurement noises, the crossing points of the nonzero residual surfaces are at different positions but near the true parameter point. moreover, by comparing the lines in figure 2a with figure 2b, it can be seen that the corresponding zero residual surfaces and nonzero residual surfaces are indeed parallel, when fitting the same data set without noises or with noises, respectively.

figure  <dig> shows the residual surfaces based on fitting to  <dig> individual noise-free data sets  and to the same  <dig> data sets together . it is shown from figure 3a that, due to the correlation, two hyperbolic cylinders are built by separately fitting to individual data sets. the bottom minimum lines of the two cylinders corresponding to the zero residual value cross at the true parameter point. fitting to the two data sets together leads to an elliptic paraboloid  which has only one minimum point with the zero residual value. this point is the true parameter point, which means the remedy of the correlation between p <dig> and p <dig> 

since the maximum number of parameters among the correlation groups is  <dig>  according to our approach, at least  <dig> data sets with different inputs are needed to uniquely determine the parameter set. the last column in table  <dig> +…+) shows the parameter values from fitting the model to the  <dig> data sets together. it can be seen that all of the  <dig> parameter values fitted are almost at their true values. according our geometric interpretation, this means that the  <dig> zero residual surfaces expanded by together fitting to the  <dig> data sets cross at the true parameter point in the parameter subspace. figure 1b  shows these correlated relations indeed disappear based on the results of fitting to the  <dig> data sets together.

moreover, it is shown in table  <dig> +) that the correlation between p <dig> and p <dig> can be remedied by fitting two data sets together. as expected, it can be seen that in p+ the parameters in g <dig> are not well fitted . it is also interesting to see in p+ the parameter values in g <dig>  g <dig> and g <dig> are also not well estimated. this is because the degree of freedom of g <dig>  g <dig>  and g <dig> is  <dig>  indeed, as shown in table  <dig> ++), these parameters are exactly determined based on fitting the model to  <dig> data sets together. however, it is shown in table  <dig> from the parameter values of p++ and p+…+ that a number of data sets less than  <dig> is not enough to remedy the correlations of the parameters in g <dig> 

to test the sensitivity of the parameter results to measurement errors, we also fitted the model to the same  <dig> data sets with different inputs and with 10% noise level together. as shown in the last column in table  <dig> +…+), to some extent, the parameter values identified are deviated from the true values due to an increased residual value. but the overall parameter quality is quite good. it means the crossing points of the  <dig> nonzero residual surfaces expanded by the  <dig> noisy data sets are quite close to the true parameter point.

figure  <dig> shows profiles of all parameters as a function of p <dig>  based on different number of data sets used for fitting. it is seen from figure 4a that only p <dig> is correlated with p <dig> . moreover, it can be seen that, by fitting to one data set, the other parameters which have higher order interrelationships in other groups cannot be well determined. as shown in figure 4b, the correlation between p <dig> and p <dig> is remedied by fitting to two data sets together and, moreover, the parameters tend to approach their true values . finally, all parameters are uniquely determined , when  <dig> data sets were used together for fitting the model, as shown in figure 4c.

these results clearly demonstrate the scope of our approach to identifying parameter correlations. moreover, it is clearly seen that adding more data sets with different inputs can remedy the parameter non-identifiability problem in some complex models, but a necessary number of data sets with different inputs  is enough.

to illustrate a higher order interrelationship among parameters, estimations were made by separately fitting the model to  <dig> individual data sets to plot the relations of the parameters in g <dig>  as shown in figure  <dig>  it can be seen that the three zero residual surfaces  resulted from the three individual data sets cross exactly at the true parameter point in the subspace of the  <dig> parameters. this demonstrates our geometric interpretation of parameter correlations, i.e. to estimate a group of three correlated parameters at least three distinct data sets with different inputs are needed.

since parameter correlations determined from the proposed approach are based on the structure of the state equations, our result provides a minimum number of different data sets with different inputs necessary for unique parameter estimation . this is definitely true, if all state variables  are measurable and included in the  <dig> data sets.

the results shown above are from the solutions of the parameter estimation problem based on the data sets composed of all  <dig> state variables. it is demonstrated that at least  <dig> data sets with different inputs will be needed to uniquely estimate the  <dig> parameters. however, our method does not give information on how many state variables which may be fewer than  <dig> but sufficient to identify the  <dig> parameters. to achieve this information, we tried to estimate the parameters based on the generated  <dig> data sets which include fewer measured state variables . we checked the identifiability when the  <dig> data sets consist of data profiles of only a part of the state variables. computational tests were carried out based on different combinations of the state variables included in the data sets. table  <dig> shows the minimum sets of state variables which should be included in the data sets so as to achieve a successful fitting. it can be seen, for instance, the  <dig> parameters can be uniquely estimated in the case that only the first three state variables  are included in the  <dig> data sets. moreover, the generated data profiles of x <dig> and x <dig> are also enough for identifying the  <dig> parameters. due to insufficient data, estimation runs with fewer numbers of the state variables than listed in table  <dig> could not converge, i.e. the parameters will be non-identifiable.

different sets of state variables were used as measurable output variables included in the  <dig> data sets, respectively. this table shows the groups of a minimum number of state variables used as outputs for the parameter estimation which leads to the convergence to the true parameter point.

CONCLUSIONS
it is well recognized that parameters in many biological models are correlated. finding the true parameter point remains as a challenge since it is hidden in these correlated relations. in many cases, a direct analysis of parameter correlations based on the output sensitivity matrix depends on experimental design, and the analytical relationship cannot be seen. instead, we presented a method to analyse parameter correlations based on the matrix of the first order partial derivative functions of state equations which can be analytically derived. in this way, pairwise correlations and higher order interrelationships among the parameters can be detected. the result gives the information about parameter correlations and thus about the identifiability of parameters when all state variables are measurable for fitting the parameters. since the output sensitivity matrix is a linear transformation of the matrix of first order partial derivative functions, our correlation analysis approach provides a necessary  condition of parameter identifiability. that is, if there exist parameter correlations, the corresponding parameters are non-identifiable.

in addition, we introduced residual surfaces in the parameter subspace to interpret parameter correlations. any point on a zero residual surface will result in a zero residual value. the crossing point of multiple zero residual surfaces leads to the true parameter point. zero residual surfaces correspond to zres resulted from noise-free data sets used for fitting the parameters. if the zres are linearly independent , the model parameters are identifiable, and otherwise they are non-identifiable. if more linearly independent zres can be constructed by adding new data sets with different inputs, the parameters are practically non-identifiable, otherwise they are structurally non-identifiable. in the case of practical non-identifiability the true parameter values can be found by together fitting the model to a necessary number of data sets which is the maximum number of parameters among the correlation groups. if the available measured data are from output variables, this should be regarded as the minimum number of data sets with different inputs required for unique parameter estimation. the results of the case study demonstrate the feasibility of our approach.

moreover, an interesting result of our approach is that parameter correlations are not affected by the initial state. this means that, experimental runs can be conducted with any initial state to obtain the required data sets with different inputs. more interestingly, according to this result, different data sets with different inputs can be gained in one experimental run by changing the values of the control inputs. it is noted that the proposed approach does not address the identifiability issue of the initial states which would be a future research aspect.

the result of identifiable parameters determined by the proposed approach is theoretical. this means that the quality of the available data  has an important impact on the identifiability issue. parameters which are theoretically identifiable may not be identifiable by an estimator due to low quality of the data. non-identifiability issues caused by relative data are not considered in this paper. in addition, the identification of parameter correlations based on the output equations is not considered in this paper.

competing interests
the authors declare that they have no competing interests.

author’s contributions
pl developed the methodology, wrote the manuscript and supervised the study. qdv wrote the software and designed the study. both authors read and approved the final manuscript.

supplementary material
additional file 1
derivation of the sensitivity matrix, partial derivative functions of the case study, and the values of control inputs for generating data sets in the case study.

click here for file

 acknowledgements
we thank m. bartl, c. kaleta, r. guthke and h. m. la for carefully reading the manuscript and their suggestions for improving the description. this work has been supported by the phd scholarship from vietnamese government to qdv. in addition, we thank the anonymous reviewers for their comments that improved the manuscript.
