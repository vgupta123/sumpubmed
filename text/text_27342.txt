BACKGROUND
sample classification based on gene expression data is usually based on small numbers of samples and very large numbers of genes. selecting those genes that are truly biologically important remains a problem in these types of studies.

many methods to address these types of problems have been described  <cit> , and they can be divided into two main categories: those that rely on filtering methods and the model-based or so-called wrapper approaches  <cit> . pan  <cit>  has reported a comparison of different filtering methods, highlighting similarities and differences between three main methods. the filtering methods, although faster than the wrapper approaches, are not particularly appropriate for establishing rankings among significant genes, as each gene is examined individually and correlations among the genes are not taken into account. although wrapper methods appear to be more accurate, filtering methods are presently more frequently applied to data analysis than wrapper methods  <cit> .

guyon et. al.  <cit>  compared the usefulness of rfe  for svm against the "naïve" ranking on a subset of genes. the naïve ranking is just the first iteration of rfe to obtain ranks for each gene. they found that svm-rfe is superior to svm without rfe and also to other multivariate linear discriminant methods, such as linear discriminant analysis  and mean-squared-error  with recursive feature elimination.

li and yang  <cit>  also compared the performance of support vector machine to other algorithms ) for classifying gene expression datasets and also examined the contribution of recursive procedures to the classification accuracy. they show that the way in which the classifier penalizes redundant features in the recursive process has a strong influence on its success. ridge regression was superior in the datasets they examined.

literature data mining has been used to construct networks of interacting genes and the way they form pathways to complete various biological tasks e.g., metabolic, transcriptional, signaling or differentiation and developmental programs. many gene network models are constructed entirely from experimental studies described in the scientific literature and make up the content of databases such as kegg, david, and ingenuity.

however, a variety of computational methods have also been considered for reconstructing gene networks from gene expression data including, for example, linear models described in eugene et al  <cit> . genent  <cit>  is a computational tool that groups functionally related genes into tight clusters despite their expression dissimilarities. bonneau and co-workers  <cit> devised a pair of programs which first bicluster genes and conditions, and then infer regulatory relationships among the genes. at present, this pair of programs has only been applied to prokaryotes. chen et. al.  <cit>  present a novel structure-learning method for gene network discovery from gene expression data. the method is based on information theory and a greedy search algorithm in bayesian network  learning. the results show that the proposed method can identify networks that are close to the optimal structures when the constructed networks are compared to the original networks. srinivasan et. al.  <cit>  described recent progress in network research. they briefly survey available datasets in functional genomics, review methods for data integration and network alignment, and describe recent work on using network models to guide experimental validation. djebbari and quackenbush  <cit>  suggest using preliminary networks derived from the literature and/or protein-protein interaction data as seeds for a bayesian network analysis of microarray datasets. they claim that the seeded bayesian networks have the ability to identify high-confidence gene-gene interactions that have been validated by comparison to other sources of gene networks and pathway data.

recently we have developed a new approach for selecting significant genes in comparative gene expression studies. this method, which we refer to as svm-rce <cit> , combines k-means, a clustering method, to identify correlated gene clusters and support vector machines to identify and weight  those gene clusters. recursive cluster elimination  is applied to remove those clusters of genes that contribute the least to the classification performance. we have now extended this approach by selecting as initial clusters, groups of genes which a network algorithm has determined to be linked. in applying this approach one thousand genes selected by t-test from a training set are first filtered so that the only genes that map to the gene networks database remain. the gene expression network analysis tool  is applied to these genes to form n clusters of genes that are highly connected in the network. linear svm is used to classify the samples using these network clusters, and a weight is assigned to each cluster based on its importance to the classification. the least informative clusters are removed while retaining the remainder for the next step. this process is repeated until an optimal classification is obtained.

RESULTS
algorithm
svm-rne uses the gene expression network analysis tool  <cit> , a clustering method, to identify correlated gene clusters, and support vector machines to identify and  those gene networks  for accuracy of classification. after scoring by svm the lowest scoring clusters are removed. the remaining clusters are merged, and the process is repeated . nacu et al  <cit>  developed gxna as an improvement on the method of ideker at el  <cit>  who propose a statistical method for scoring sub-networks and a search algorithm to determine sub-networks with high scores. gxna is based on gene expression and prior biological information to suggest differentially expressed pathways or gene networks.

we assume a dataset d with s genes. the data is partitioned into two parts, one for training  and the other  for testing.

let x denote a two-class training dataset consisting of ℓ samples and s genes. we define a score measurement for any list s of genes as the ability to differentiate the two classes of samples by applying linear svm. to calculate this score we carry out a random partition of the training set x of samples into f non-overlapping subsets of equal sizes . linear svm is trained over f- <dig> subsets and the remaining subset is used to calculate the performance. this procedure is repeated r times to take into account different possible partitioning. we define score, f, r) as the average accuracy of the linear svm over the data x represented by the s genes computed as f-fold cross validation repeated r times. we set f to  <dig> and r to  <dig> as default values. moreover, if the s genes are clustered into sub-clusters of genes s <dig>  s <dig>  ..., sn then we define the score , f, r) for each sub-cluster while x is the data x represented by the genes of si.

the central algorithm of the svm-rce method is described as a flowchart in figure  <dig>  it consists of three main steps applied on the training part of the data: building gene networks using the gxna tool, the svm scoring step for computing the score ), f, r) of each cluster of genes and the rne step to remove clusters with low score, as follows:

algorithm svm-rne 
x = the training dataset

s = genes list  or top n_g genes by t-test

n = initial number of clusters

m = final number of clusters

d = the reduction parameter

while  do

 <dig>  build gene networks from s genes into n networks s <dig>  s <dig>  ..., sn using gxna . gxna determines the value of n.

 <dig>  for each network i =  <dig> . n calculate its score, f, r) 

 <dig>  remove the d% networks with lowest score 

 <dig>  merge surviving genes again into one pool s

 <dig>  test these genes on the 10% of the samples held out

 <dig>  decrease n by d%.

the basic approach of svm-rne is to first group the gene expression profiles into n gene interaction networks, using gxna. we have used the default parameters of gxna. a score: score, f, r) is assigned to each of the networks by linear svm, indicating its success at separating samples in the classification task. the d% networks  with the lowest scores are then removed from the analysis. steps  <dig> to step  <dig> are repeated until the number n of networks is decreased to m.

let z denote the testing dataset. at step  <dig> an svm classifier is built from the training dataset using the surviving genes s. this classifier is then tested on z to estimate the performance .

for the current version, the choice of n is determined by the gxna tool while m is determined by the investigator. in this implementation, the default value of m is  <dig>  indicating that the method is required to capture the top  <dig> significant networks  of genes. however, accuracy is determined after each round of network elimination and a higher number of networks could be more accurate than the final two.

testing data used for assessment of classification accuracy
we tested the svm-rfe, svm-rce and svm-rne methods, with several datasets. the following is a brief description of these datasets.

ctcl datasets  and 
cutaneous t-cell lymphoma  refers to a heterogeneous group of non-hodgkin lymphomas. ctcl includes  <dig> patients and  <dig> controls  <cit>  while ctcl consist of  <dig> patients and  <dig> controls . for more information about the data and preprocessing refer to  <cit> .

lymphocyte data is from the gxna study  <cit> . this data set is related to the role of the immune system in cancer. it is derived from blood samples of  <dig> healthy and  <dig> melanoma patients. lymphocytes were sorted according to their type into b-cells, cd <dig> t-cells, cd <dig> t-cells and nk  cells. gene expression data was obtained using  <dig> agilent human 1a version  <dig> microarrays. after removing saturated genes, there were  <dig> genes left  <cit> 

airway epithelial gene expression
we also re-analyzed the airway epithelial gene expression of spira et al.  <cit>  using svm-rne. the data set consists of  <dig> samples,  <dig> smokers with lung cancer and  <dig> smokers without lung cancer. the gene expression data was obtained using affymetrix hg-u133a microarrays obtained from bronchial brushings. the analysis of the training set  identified an 80-gene biomarker by selecting the most frequently  <dig> up-regulated and  <dig> down-regulated selected by internal cross-validation. the 80-gene biomarker identified using a weighted-voting algorithm achieved an accuracy of 83% .

classification accuracies for the three algorithms on three datasets are presented at representative steps in the course of recursive feature elimination. the number of clusters  and the total number of genes in the clusters  are shown for the steps which are presented in reverse order, i.e. the last elimination step is shown first in the table. no clusters are shown for svm-rfe since the genes are eliminated without clustering.

svm-rce and svm-rne were applied to the airway epithelium data with 10-fold cross validation repeated  <dig> times . an accuracy of 84% with  <dig> genes was obtained . it took about  <dig>  hours to complete one experiment  on airway epithelium data 

discussion
various methods have been used for classification studies to find the optimal subset of genes that gives the highest accuracy  <cit>  in distinguishing members of different sample classes. with svm-rne, one can think of this process as a search in the gene-networks space for the m networks, of interacting genes, that give the highest classification accuracy. in the simplest case, the search is reduced to the identification of one or two networks that define the class differences. these might include the important up-regulated and the important down-regulated genes. while svm-rne and svm-rfe are related, in that they both assess the relative contributions of the genes to the classifier, svm-rne assesses the contributions of groups of interacting genes instead of individual genes . additionally, although both methods remove the least important genes at each step, svm-rne scores and removes clusters of genes, while svm-rfe scores and removes a single or small numbers of genes at each round of the algorithm. the difference between svm-rce and svm-rne is in the way the genes are grouped: svm-rce uses k-means clustering, while svm-rne uses a network construction algorithm.

CONCLUSIONS
in addition to providing biomarkers for distinguishing classes, an additional aim of most classification studies is to determine the biological basis for the class differences. if the expression levels of several genes on a single pathway are found to be altered, confidence in classification is increased and an understanding of the biology underlying the class differences may be enhanced. using network fragments as units of information should make significant pathway identification easier than trying to assemble single genes into a pathway after their selection, since most genes will belong to numerous pathways.

the success of the svm-rne in classification studies suggests that a pathway based metric or other biological metrics to may be used to group the genes useful for classification studies and provide an alternative approach to single gene studies. the exploration of the way other factors can contribute to the classification and to the characterization of new sub-classes will be the subject of future studies  <cit> .

competing interests
the authors declare that they have no competing interests.

authors' contributions
my, ls and ms equally contributed to the development of the algorithm svm-rne while mk wrote the matlab code for the svm-rne method and measured the statistical significance of the method. lm has contributed to the development of the computational method. all authors approved the manuscript.

