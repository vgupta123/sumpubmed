BACKGROUND
reconstructing the recombinational history of a dna fragment has proved to be a difficult problem and can only be achieved at small scales. nonetheless the reconstruction of the history of long fragments, is of great interest to geneticists. although the mutational history of adjacent fragments is independent, this is not true for recombinational history: thus merging adjoining networks add a new level of richness in complexity in terms of the suite of recombination events that shape variations within and across populations .

this paper explores the combinatorics involved in incorporating recombination events into the topology. while it is possible to give loose bounds on the number of recombination events using some convenient and clever variation of the four gamete rule  <cit> , the actual enumeration of the recombinations by a careful exploration of the underlying combinatorics will tighten this bound, as well as give additional information such as participating lineages, time-ordering of the recombination events and so on. however, it is important to note that the corresponding combinatorial optimization problem cannot be solved exactly unless p = np  <cit> . nevertheless, there have been various efforts to give a good estimate of a bound on this number .

in this paper, we address the problem of computing a consensus a pair of phylogenetic networks g <dig> and g <dig> to give g <dig> with a minimum number of new recombination events to jointly explain g <dig> and g <dig>  such a network g <dig> satisfies certain characteristics due to the very nature of its genesis: this is called a compatible network  <cit> . in this paper we presented a topology-based methodology to understand genetic variations in human haplotype data: we first cluster  haplotypes that display no evidence of recombinations and a representative haplotype of each cluster is extracted for the next phase. then exploiting the coherence seen in such data, each haplotype is recoded using patterns of snps . finally, a network is constructed from the recoded representative haplotypes. using a divide-and-conquer paradigm, the haplotype is segmented to give simple structures and then these individual structures are merged to give a unified topology using a dsr scheme . clearly, each stage is algorithmically non-trivial, however optimizing the number of recombination events in the merging phase is a critical component. this is our focus in this paper. the interested reader is directed to  <cit>  for other details including the rationale of the model.

in this paper, we analyze the performance of the dsr scheme in two ways. firstly, we give a mathematical evaluation of the algorithm. in other words, how far are we from the optimal number of new recombinations that explain the data? we show that the greedy polynomial time dsr based algorithm guarantees that the number of computed new recombination events is within ϵ = sz  of the optimal number of recombinations. to date, this is the best known result for a network consensus problem. note that the computation of consensus trees  is a very battered problem in literature. thus, although our model is derived from the special setting discussed above, the problem and its solution is of interest in a general context involving reticulation events. see for example  <cit> . the ideas in pair-wise consensus is easily extendible to k-wise consensus.

secondly, we examine how well the algorithm performs on real data. we apply the method on  <dig> kb segment of high snp density in the recombining part of the x chromosome. with our preliminary analysis from a phylogeographic viewpoint, we are able to infer ancient recombinations, population-specific recombinations and more  which also support the widely accepted 'out of africa' model. these results are consistent with established mutation-based methods: thus this can be taken as an indirect validation of our analysis and the methodology.

methods
here we discuss the underlying mathematical model. we are given h units or extant individuals, each of which has f features. each feature is a snp  and a unit is a haplotype. to keep the paper self-contained in this section we reproduce the notation used in  <cit> . a network g is a directed acyclic graph  and is defined as follows: it has three kinds of nodes. a node with no incoming edge is a root node and g may have multiple root nodes. a node with no outgoing edges is a leaf node. each leaf node is labeled with nonempty sets haplotype labels. every other node is an internal node. a node has at most two incoming edges. when a node has exactly one incoming edge, it is called a mutation node and the incoming edge is called a mutation edge. when the node has two incoming edges, the node is called a recombination or a hybrid or a reticulation node and the incoming edges are called recombination or reticulation edges. the direction of the edges is always towards the leaf nodes which in the figures in this paper is downwards. to avoid clutter, only the recombination edges display the direction as arrows.

associated with a network g is a segmentation s. the segmentation s is a partition of the f features into some k  subsets. when the features are ordered say as f <dig>  f <dig>  f <dig> ..., ff, they can be simply written as the closed interval , and the segmentation is a collection of non-overlapping intervals. for example, if f =  <dig>  a possible segmentation of interval  <cit>  is: s = { <cit> ,  <cit> ,  <cit> }. the three individual segments are s <dig> =  <cit> , s <dig> =  <cit>  and s <dig> =  <cit>  with s = {s <dig>  s <dig>  s3}. for convenience, the three segments are denoted simply by the consecutive integer labels  <dig>   <dig> and  <dig> and to keep clarity of exposition, s is written simply as s = { <dig>   <dig>  3}. then each feature f is written as s: f where s is the segment label that the feature f belongs to.

for a segmentation s, the labeling of the edges of g are as follows:  mutation edge: every mutation edge e incident on a node v, has a non-empty label, lbl. each member, s: f, of the label is interpreted as feature f in segment s.  further, each element appears at most once in an edge label in g.  recombination edge: the two recombination edges, e <dig> and e <dig>  incident on a recombination node v are labeled by sets of segment labels lbl <dig> and lbl <dig> with lbl1≠ lbl <dig>  for example lbl <dig> = { <dig>  3} denoting that e <dig> is labeled with the segment labels  <dig> and  <dig> 

for a segment s ∈ s, restricted is the network obtained by doing the following two operations: removing all recombination edges in g that do not have the element s in the true edge label lbl'.  from each mutation edge label in g, removing the elements of the form s: f, for any f, from the edge label. for a concrete example see figures  <dig> and  <dig>  this definition is easily extended to multiple segments as restricted, where s' ⊆ s.

g is always associated with a segmentation s of the f features, hence written as . note that g cannot be any arbitrary network. it must satisfy the following: for each s ∈ s, restricted is devoid of recombinations. such a network is termed compatible. the consensus compatible network problem is defined as follows  <cit> : given two compatible networks  and  with no common features , the task is to compute a compatible network  with the minimum number of additional recombination nodes such that  is isomorphic to restricted and  to restricted.

in the remainder of the paper, we refer to  simply as g, and segmentation s will be clear from context.

the dominant subdominant recombinant  framework
the dsr scheme to solve the problem and its proof of correctness was presented in  <cit> . the method is an iterative, bottom-up working at one level of g <dig> and g <dig> at a time. the level of a node is defined as the maximum distance to a leafnode.

the same level is also associated with any edge e incident on the node written as level. a leaf is at level  <dig>  the method gets its name from the need to give one of three possible assignments, dominant  or subdominant  or recombinant , to nodes at each iteration, which is central to this scheme.

matrix xl
let g have t roots. for root vi introduce an incoming edge ei,  <dig> ≤ i ≤ t. then the height of g is defined as max⁡i=1t ). let lmax  be the maximum  of the heights of g <dig> and g <dig>  for a fixed level l, let , eil = {e is an edge in gi | level = l}. then intersection nl × ml matrix xl is defined as xl=e1l×e2l and an example is shown in fig  <dig>  in the algorithm the intersection matrix, xl had dimensions  ×  as this extra last row  with header '-ϕ-' is required to take care of elements that are not covered by the rest of the columns . an empty entry is shown as '∅'. in x <dig> the exact entries can be computed and for xl, l >  <dig> and the non-empty entries are identified by '{·}'. further, let xl be the number of non-empty entries in xl. see figure  <dig> for an example.

dsr assignment rules
the non-empty entries of xl are given a dsr assignment. note that at least two conditions are required for a viable compatible network g <dig>  : each row  in matrix xl has at most one dominant. if the row  has no dominant, then it has at most one subdominant. : a non-recombinant element can have another non-recombinant in its row or its column but not both. as a result of the dsr assignments to the entries on xl, the rows and columns also get implicitly assigned as follows. a row  that has a dominant entry is assigned dominant. a row  that is not assigned dominant but has a subdominant in the row  gets assigned subdominant. a row  that has only recombinants in the row  is assigned recombinant. note that only dominant rows  contribute to entries in xl', l' > l. figures  <dig> and  <dig> give two different assignments giving the two different networks in figure  <dig>  and  respectively. using a simple greedy optimization approach, we include a third rule. : minimize the number of recombinants in xl. complete examples are worked out in figures  <dig>   <dig>   <dig> and  <dig> for the interested reader.

approximation factor of the greedy dsr scheme
in this section, we compute the approximation factor  <cit>  of the greedy version of the dsr scheme. let the number of new recombination events produced by the dsr algorithm in g <dig> be ndsr. let the optimal number of new recombinations be nopt. we use the following definition of the true approximation factor:

  approxtrue=ndsr−noptnopt. 

for given graphs g <dig> and g <dig> let zl = max where nl >  <dig> and ml >  <dig> are the number of nodes at level l in g <dig> and g <dig> respectively. further, let z be the sum of all zl over all the levels . let lv be all the leafnodes  reachable from node v in g. for each level, l >  <dig>  i.e. excluding the leafnodes, consider lvi ,  <dig> ≤ i ≤ nl, where each vi is at level l in g <dig>  similarly consider lui ,  <dig> ≤ i ≤ ml, where each ui is at level l in g <dig>  let xl be the number of non-empty intersections between the two collection of sets and let y be the sum of xl over all the levels . note that if g <dig> and g <dig> are the same  graphs then y = z and nopt =  <dig> 

theorem 1
  approxtrue≤zmax⁡. 

proof: let nmax  be the maximum  number of new recombinations produced by the dsr scheme over all possible dsr assignments. then we first show the following:

  nmin≤ nopt≤ ndsr≤ nmax. 

clearly nopt≤ nmax holds . next we have to show that nmin ≤ nopt holds as well. for this we need a few more characterizations of the network.

recombination node descriptor f1|f2
let y be the set all given haplotypes . a split or bipartition is written as z1|z <dig> where z <dig> and z <dig> are nonoverlapping subsets of y with y = z1∪ z <dig>  a tripartition z1|z2|z <dig> is defined similarly. in earlier works  a mutation event has been associated with a bipartition of y and a recombination event with a tripartition. however, the latter requires certain restrictions in the form of network g, i.e., a recombination node cannot be a direct descendent of another recombination node. here we define recombination nodes as a bipartition of an appropriate subset of features.

for a fixed segment s, let s-path be a path in the graph with mutation edge and recombinant edge with s in its label. for any v, note that there is a unique s-path from a root to v. further, let v be a recombination node and lbl <dig> and lbl <dig> be the labels of the two incoming  edges u1v and u2v respectively. for s <dig> ∈ lbl <dig> but s <dig> ∉ lbl <dig>  let feature f <dig> be such that s <dig> : f <dig> is in the label of the closest mutation edge on the s1-path from v. then f <dig> is the set of all such features. f <dig> is defined similarly. for example in g <dig> of figure  <dig>  consider the recombination leafnode labeled with haplotype a. here lbl <dig> = {2}, lbl <dig> = {3} and the descriptor for this node is f1|f <dig> = {2:4}|{3:5}. for the recombination node labeled 'r', lbl <dig> = {4}, lbl <dig> = { <dig>  3} and the descriptor is f1|f <dig> = {4:7} | {2: <dig>  3:8}.

isomorphism )
let lv be all the leafnodes  reachable from node v. let s: f be in the label of the unique incoming edge on mutation node v and then let ls: f  be the same as lv. two compatible networks g <dig> and g <dig> on the same segmentation s are isomorphic , written as g <dig> ≡ g <dig>  if the following two conditions hold:  for each element s: f in g <dig>  ls: f  = ls: f  and viceversa, and,  for each recombination node v in g <dig> with descriptor f1|f <dig>  there exists a recombination node in g <dig> with the same descriptor and viceversa.

canonical form
it is possible to bubble up or down an element in the mutation edge label to obtain g' such that g' ≡ g. our convention will be to bubble down the element of the mutation edge label, towards a leafnode. a network g is in the canonical form  if no node has only one outgoing edge and  if no element of any mutation edge label can be bubbled down to obtain g' with g' ≡ g. for example see figure  <dig>  since the levels of nodes in a canonical network are unique, the following can be readily verified .

lemma  <dig> let g <dig> be the consensus of g <dig> and g <dig> which are in canonical forms, with lmax  as the maximum  of the heights of g <dig> and g <dig>  then there exist some x-matrices, x <dig>  x <dig> ..., xlmax⁡whose dsr assignments produce g <dig>  this is written as g <dig> ≅ x <dig>  x <dig>  ...,xlmax⁡.

back to the proof: we have to show that nmin ≤ nopt holds. assume the contrary, i.e., nopt <nmin. in other words, the optimal number of new recombinations is even lower than the minimum produced by the algorithm over all possible choices. then consider this network g′ <dig> with nopt new recombinations. then by lemma  <dig>  there exist a sequence of x-matrices g′ <dig> ≅ x <dig>  x <dig>  ..., xlmax⁡ with some dsr assignments for each xl. thus by these choices of the algorithm nmin ≤ nopt must hold, again leading to a contradiction.

hence nopt ≮ nmin. here ends the proof of correctness of eqn  <dig>  next, we give a few characterizations of

the dsr assignment to facilitate the counting of the new recombinations.

type i & ii  recombination events
let v be a recombination node in g <dig> with labels lbl <dig> and lbl <dig> on the two incoming edges and descriptor f1|f <dig>  the recombination event is new if, without loss of generality, lbl1⊆ s <dig> and lbl2⊆ s <dig>  in other words, this recombination node is a result of the consensus of g <dig> and g <dig> . a new recombination node v is of two types: let e <dig>  be a mutation edge in g <dig>  with a label in f <dig> . without loss of generality, let level = l. then the recombination is of type i at level l if level = l and is of type ii at level l if level > l. further, let the number of  entries assigned dominant be nld, subdominant be nls and recombinant be nlr in an x-matrix xl. then the following can be verified.

lemma  <dig> the number of type i recombination events at level l in g <dig> is nlr. the number of type ii recombination events at level l in g <dig> is ≤ nld+nls. also, the number of recombination events in a network is bounded below  by the number of type i recombination events and above  by the sum of the number of type i and type ii recombination events.

islands in x
we now give tighter bounds on nld, nls and nlr for our analysis. consider a bipartite graph b with v partitioned into  nl nodes, corresponding to the rows and  ml nodes corresponding to the columns of xl. the adjacency matrix x′l is obtained from xl where an empty set entry is replaced with  <dig> and a non-empty set entry with  <dig>  let the number of connected components  <cit>  of graph b be cl. each connected component corresponds to an island in xl which is a collection of rows and columns of xl. thus xl is fragmented into cl islands, xl,i, written as: xl = xl, <dig> + xl, <dig> + ... + xl,cl. see figure  <dig> for an example. note that this fragmentation is for analysis purposes only. further, ∑l=1lbnd∑i=1clyl,i, for any yl,i, will be written simply as ∑l,ilbndyl,i. let island xl,i have xl,i non-empty entries and let the number of entries assigned y  in xl,i be nl,iy. within an island the number of non-recombinants cannot exceed max by rules  <dig> and  <dig> 

lemma  <dig> for each island xl,i:

  nl,id+nl,is=max⁡, 

  nl,ir=xl,i−max⁡. 

eqn  <dig> follows from using rule  <dig> in island xl,i and eqn  <dig> from xl,i=nl,id+nl,is+nl,ir.

back to the proof: next, let nc max and nc min be some computable functions of the input . using lemmas  <dig> and  <dig>  we define appropriate  nc maxand nc minas follows:

  nmax⁡≤∑llmin⁡xl=ncmax⁡ 

  nmin⁡=∑l,ilmin⁡nl,ir=∑l,ilmin⁡)≥∑llmin⁡xl−∑llmin⁡max⁡=ncmin⁡ 

note that the greedy rule  <dig> encourages fragmentation of xl, l >  <dig>  into islands and under the best case scenario we get nld+nls=∑llmin⁡max⁡, which is used in eqn  <dig> above. finally, using eqn  <dig>  we have

  approxtrue=ndsr−noptnopt≤ncmax⁡−ncmin⁡ncmin⁡≈ncmax⁡−ncmin⁡max⁡ 

the correctness of eqn  <dig> is established by setting z=∑l,ilmin⁡max⁡ and y=∑llmin⁡xl. here ends the proof.

experimental 
RESULTS
in the last section we gave a mathematical proof of the tightness of the number of recombinations estimated by the model to explain the data. also, in our earlier work we had presented results on simulation data with a general analysis of false positive and false negative errors. in this section, we discuss results on a segment of chromosome x data and the plausibility of the results is verified independently by using traditional manual analysis. due to the manual component in the verification process, here we use only small data sets.

chromosome x snp data
we used a  <dig> kb segment of high snp density in the recombining part of the x chromosome, starting at genomic position  <dig> , <dig> . in hapmap ii  <cit> , this segment contains  <dig> sites, of which only  <dig> are polymorphic in at least one population. recombination rate is ≈  <dig>  cm/mb, slightly below the ≈  <dig> cm/mb genomewide average. we chose this segment for two reasons.  it does not contain any genes. thus variation in this region is less likely to have been shaped by natural selection and is more likely to reflect purely genomic processes.  the segment does not contain copy number variations or segmental duplications. these could induce genotyping errors possibly producing ectopic recombination events, which is not accounted for in the downstream analysis.

further, we used only the haplotypes in the hemizygous males to avoid any phasing errors. these errors would manifest as phantom recombination events. the populations used were yorubans from nigeria , europeans , and a pooled sample of chinese and japanese .

statistical analysis 
as a preprocessing step, exploiting the coherence seen in the data, each haplotype is recoded using blocks of g snps. based on the combinatorial model, a network is constructed from the recoded representative haplotypes. recall that first the haplotype is segmented to give simple structures and then these individual structures are merged with a small number of recombinations to give a unified topology. here we discuss the choice of the value of g in our experiments. let l be the number of distinct patterns of the g snps across the samples. using this as a proxy for the extent of ld in this block, we estimate the p-value of the number l. loosely speaking, when these g snps are in linkage equilibrium , l should be much larger than when they are in ld.

let the number of samples be h and let the number of snps be f. further, let v be a column vector of size h. since the snps are assumed to be bi-allelic, v which represents the value of a snp in the h samples is binary. we use two schemes, based on the mode of definition of the f vectors, to estimates the p-value. the range of values of l seen in our data is  <dig> ≤ l <  <dig> and we study the p-value estimates in this range using two schemes.

randv
in this scheme, v <dig>  v <dig>  ..., vf are defined randomly. in other words, each entry of each v is picked independently and uniformly from a set of two alleles. we use  <dig> replicates and the distribution of the number of g-sized patterns is shown in fig  <dig>  the p-values estimated based on this scheme is shown in the table below. the p-values are ≈  <dig>  for every value of l.

permv
while the randv scheme is not incorrect, we make some domain-dependent modifications to design another scheme. in the permv scheme we  mimic the allele frequencies seen in the input data and  use the population distribution, by ethnicity, of the screened samples in the chromosomal region. the individual v vectors are plucked from the x-chromosome of the database  and any untyped snp  in the vector is given a value in agreement with the allele frequency of that column. further, we use only those v 's that have maf ≥  <dig> . we again use  <dig> replicates and for each replicate, we randomly permute the f vectors. the distribution of the number of g-sized patterns is shown in fig  <dig> 

if for a block, l has an insignificant p-value, then the subsequent analysis risks becoming unreliable. we then reduce the grain size. an alternative is to discard the offending snps of the block, thus fragmenting the region. in our experiments we used a grain size g =  <dig> and the p-values obtained for this on all the regions were acceptable. the haplotypes are re-coded as sequence of these snp patterns for the combinatorial analysis discussed in the methods section.

result analysis
we show a sample network of a short segment of the chosen region in figure  <dig>  here we summarize our observations from a phylogeographic viewpoint and answer only questions raised traditionally in this area. table  <dig> shows the number of detected recombination events and how they are shared across populations. the observations  are as follows: we discovered a total of  <dig> recombinations in the data. seventeen recombinations are population-specific, and can be used to infer the recombinational diversity within a population. assuming recombination rate is constant across populations, this is a function of the effective population size of each population. four recombinations are shared among pairs of populations, and can be used as indicators of shared population ancestry. in this particular case, both europeans and asians share events with the african population, which is more recombinationally diverse. ten recombinations are shared among all three populations, and they are presumably ancient events that occurred before the split of the three populations.
ceu & asn & yri: 10

mutation-based studies of genetic diversity have shown exactly the same pattern: a larger diversity in africans, and variation outside of africa that is partially a subset of that in africa. our recombination-based results follow the same pattern, and, as the mutation data, fit the the "out of africa" model  <cit>  for the origin of anatomically modern humans. consistency with mutation data can be taken as an indirect validation of our analysis and the methodology. in our future work, we plan to investigate  more non-traditional questions.

CONCLUSIONS
we have addressed the problem of studying recombinational variations in human populations. one of the contributions of this work is a guaranteed upper bound on the approximation factor  in a greedy polynomial time algorithm to construct a consensus network. such an assurance is of significance when dealing with data where there are no other reasonable means of cross-checking results. to date, this bound is the best known result for this problem. we use this scheme to study recombinational imprints in an appropriate segment of x chromosome from three populations. while the upper bound on the approximation is our theoretical contribution, our second contribution is the results on this data: with our preliminary analysis, we are able to infer ancient recombinations, population-specific recombinations and more, which also support the widely accepted 'out of africa' model. the agreement with mutation-based analysis can be viewed as an indirect validation of our results and the methodology. in our future work, we plan to investigate more non-traditional questions via the networks computed by our methodology.

competing interests
the authors declare that they have no competing interests.

authors' contributions
the work is a result of the synergistic efforts of all the authors. however, the brunt of each author's involvement is as follows. design and analysis of the mathematical models: lp. design and implementation of the algorithms: aj. design and implementation of the experiments: mm, fc and jb. further, lp and jb were involved in conceiving and planning the recombinations project.

