BACKGROUND
the emergence and widespread adoption of massively parallel next-generation sequencing technologies has given rise to the explosive increase in dna sequencing throughput at a substantially lower unit cost of data, compared to conventional sanger capillary-based technologies. however, these technologies introduce some new challenges to the assembly of large genomes due to two factors:  short read length and  high throughput. this poses a challenge to the bioinformatics community to devise assembly software that can deal with a massive amount of short reads in reasonable time using modest and accessible compute resources.

consequently, several assemblers for high-throughput short reads have been recently developed. they can be classified into two approaches: contig extension and de bruijn graph. the contig extension approach is based on the base-by-base extension at the 3' end of a contig sequence by finding overlaps between the prefixes of reads and the suffixes of the contig. ssake  <cit> , vcake  <cit> , sharcgs  <cit> , taipan  <cit> , and pe-assembler  <cit>  are example assemblers using this approach. the de bruijn graph approach to assembly was first introduced in pevzner et al.  <cit> , and several short read assemblers based on de bruijn graphs have been developed. prominent examples include allpaths  <cit> , velvet  <cit> , abyss  <cit>  and soapdenovo  <cit> . due to the enormous cost in terms of both memory and execution time, allpaths was initially constrained to the assembly of small genomes and recently has been extended to support large genomes  <cit> . velvet employs a bi-directed simplified de bruijn graph data structure, which requires accommodating the entire genome in the graph, resulting in a large amount of memory consumption for large genomes. furthermore, when joining contigs into scaffolds using paired-end data, velvet stores the read mapping locations and paired-end information along with the graph, making it infeasible for assembling large genomes. abyss employs a distributed de bruijn graph data structure. it is implemented using the message passing interface , and produces contigs in parallel on a distributed-memory compute cluster without the use of paired-end information. soapdenovo employs a de brujin graph data structure similar to that of velvet, but uses a multi-threaded design to parallelize compute-intensive portions on shared-memory architectures. besides those algorithms that use directed de brujin graphs, yaga  <cit>  employs a bi-directed string graph, represented by a set of edges, and produces contigs through path walking using a variation of the classic parallel list ranking problem. this algorithm shows good parallel scalability for small microbial genomes. however, to assemble the e.coli dataset , its execution time  using  <dig> cpus of a blue gene/l system is longer than pasha  on a single cpu core .

in this paper, we present pasha, a parallelized short read assembler for large genomes based on de bruijn graphs. some of the concepts adopted in pasha are inspired by velvet and abyss. the primary contribution of our algorithm is the usage of hybrid parallelism consisting of small-scale shared-memory multi-threading on multi-core cpus and large-scale distributed-memory parallelism on compute clusters to overcome memory constraints and to achieve high speed for large genome assembly. furthermore, we incorporate several techniques  in the typical assembly pipeline to facilitate the improvement of assembly quality. evaluation using three small-scale real paired-end datasets indicates that pasha produces higher-quality assemblies than velvet, abyss and soapdenovo in less time. to demonstrate the capability of assembling large genomes, we assembled  <dig>  billion paired-end short reads from the whole-genome sequencing of a yoruban male individual  from bentley et al.  <cit> , and obtained an ng <dig> contig size of  <dig>  with the longest correct contig size of  <dig> , and an ng <dig> scaffold size of  <dig> .

the size of the assembly problem severely impacts on the assembly algorithm. the pasha and abyss assemblers are implemented using mpi and are able to run on both shared-memory and distributed memory computer clusters. soapdenovo is designed using multi-threading and thus is only suitable for shared-memory computers. because soapdenovo requires a computer system with a large amount of shared memory , we are not able to execute it to assemble the yoruban male individual genome on the hardware resources available to us  and thus exclude it from the comparison. for the complete assembly, pasha took about  <dig> hours using only modest computing resources, achieving competitive assembly quality with faster execution speed, compared to abyss.

methods
even though de bruijn graph-based assemblers successfully alleviate the pressure on memory space and execution speed by substituting reads with k-mers  as nodes, compared to the conventional overlap-layout-consensus approaches, the memory consumption and execution time is still prohibitive for large genomes. for example, for the genomic data of a yoruban male individual, the total number of nodes in the preliminary de bruijn graph  is about  <dig>  billion. this motivates us to design a scalable assembler for large genomes that is workable on modest and commonly used high-performance computing resources.

pasha is a parallelized algorithm for large genome assembly, which overcomes the memory and execution speed constraints by using hybrid computing architectures consisting of shared-memory multi-core cpus and distributed-memory compute clusters. figure  <dig> illustrates the pipeline of our assembler. the pipeline comprises four stages:  generating and distributing k-mers,  constructing and simplifying the distributed preliminary de bruijn graph,  merging bubbles and generating contigs after constructing a velvet-like de bruijn graph, and  scaffolding to join contigs into scaffolds. we have implemented stages  and , which are suitable for parallelization and the most memory-intensive, using mpi. this makes our program compatible with both shared-memory and distributed-memory computing systems. each mpi process pi comprises two threads t <dig> and t <dig>  t <dig> performs computations for the assembly pipeline, and t <dig> performs communications between different processes  and  in figure 1), as well as file i/o operations. by employing two threads in a single process, we intend to gain faster speed by overlapping the local computation and remote communications with processes . by distributing the de bruijn graph over a network of computers, we get a partition of the graph with each part stored in a different computer. hence, we do not need a large amount of memory in a single computer, making our algorithm workable even on a compute cluster comprised of commonplace workstations or personal computers. since the size of a message is very small, sending messages one-by-one to remote processes will incur large communication overheads. thus, for the messages that are not time-critical, we combine them into packets to improve the communication efficiency. t <dig> and t <dig> are connected through a bi-directional message queue. the maximal number of messages in the queue is controlled by a maximal capability threshold. any thread, which tries to append a new message to the queue, will be blocked if the queue reaches the threshold, and will be resumed once the queue has spaces available. any thread that tries to retrieve a message from an empty queue will be blocked until there is at least one message available. for stages  and , which exhibit limited parallelism and are less memory-intensive, we use a multi-threaded design, only compatible with shared-memory systems.

in our proof-of-concept implementation , we have used parts of the source code from velvet for stages  and  with some algorithmic and data structure modifications. the use of existing open-source code significantly reduces the development time for prototyping our algorithm, and more importantly, our modifications make the two stages feasible and practical to execute on a workstation with limited system memory , as well as providing better assembly qualities. pasha supports the standard fasta and fastq input formats for single-end and paired-end short reads with different insert sizes. while some other assemblers require users to tune a number of parameters to gain the best assembly, pasha only needs a single parameter "-k" , making it relatively user friendly.

before describing pasha in details, we firstly define some terms to facilitate our discussion. given a sequence s of length l, we define s as the i-th base in the sequence, s¯ as the complement of s, si as the k-mer starting at position i  of s, si¯ as the reverse complement of si, and sic as the canonical k-mer that is the lexicographically smaller of si and si¯. a k-molecule of si is a pair of complementary k-mer strands consisting of the canonical k-mer of si  and the non-canonical k-mer of si .

k-mer generation and distribution
in a de bruijn graph, a node corresponds to a k-mer and an edge between two nodes is created if and only if their corresponding k-mers have a suffix-prefix overlap of k- <dig> bases. hence, pasha starts the construction of its preliminary de bruijn graph from the generation of all k-mers from the input read data.

as mentioned above, pasha employs an mpi-based approach to k-mer generation and distributes them among the processes. this distribution requires that the location of any k-mer is deterministic and can be efficiently computed from the k-mer itself. since a k-molecule is a pair of complementary strands, the location of a k-mer and its reverse complement must be the same. before calculating the location of si and si¯, pasha first transforms si and si¯ to their corresponding base- <dig> representation by assigning numerical value { <dig>   <dig>   <dig>  3} to bases {a, c, g, t}. to determine the location of si, unlike abyss , pasha computes the location from the canonical k-mer. since the base- <dig> representation of a k-mer is stored in a 64-bit integer , the comparison can be theoretically completed in one clock cycle on a 64-bit computing system. a balanced distribution of k-mers among processes is critical to the performance of our algorithm in terms of both execution time and memory space. an unbalanced distribution would cause some processes to consume much more memory for k-mer storage, thus resulting in a system failure due to memory limitations on some compute nodes. in pasha, we first calculate a hash value ik using a linear congruential hash function from the base- <dig> presentation of the canonical k-mer. then, the id of the process that owns this k-mer is computed as ik % np, where np is the number of processes. from our experiments, our location determination method is able to  balance the distribution of k-mers .

to achieve memory efficiency, we use the sparse_hash_set template class in the google sparse hash library  to distinguish and store k-mers. in pasha, each process holds a local sparse hash-set to store its k-mers. for each process, thread t <dig> loads the reads from disk and transfers the reads to thread t <dig> through the message queue, where the short reads are arranged into batches and a message contains a batch of reads. t <dig> receives batches of reads from the queue, calculates the hash values of all k-mers, and stores some of them in its local sparse hash-set depending on the hash values. the cooperation of the two threads overlaps the computation and the file i/o operations, thus reducing the execution time. since a k-mer and its reverse complement are considered equivalent in a k-molecule, we only need to store the canonical k-mer into the sparse hash-set to represent the k-molecule.

for any read containing non-a/c/g/t bases, pasha converts those non-a/c/g/t bases to the base "a" , not simply discarding the whole read as abyss does  <cit> . after completing the generation of k-mers, each process writes its local k-mers to disk for future use when constructing the preliminary de bruijn graph. our distributed k-mer generation implementation can also be used  by other tools, such as cuda_ec  <cit>  and quake  <cit>  to generate and count the occurrences of k-mers in genomic data.

distributed de bruijn graph construction
the preceding stage only generates k-mers, and does not record any graph-related information for a k-mer. however, to construct a de bruijn graph, we need not only the k-mers themselves, but also multiplicity and linkage information. a common approach is to use a hash-map implementation, using k-mers as keys, to provide fast access to the graph-related information. however, this approach will result in a large memory overhead. conway and bromage  <cit>  suggested a sparse bitmap data structure to represent the de bruijn graph, achieving memory efficiency at the cost of execution time. however, their proof-of-concept assembler  and  ) takes about  <dig> hours and yields a highly fragmented assembly, with an n <dig> contig size of only  <dig>  for the yoruban male genome. hence, we exclude it from the following assessments. in pasha, we instead use a sorted vector data structure to store the k-mers and their graph-related information. each process loads its local k-mers from disk and stores them in a sorted vector. the sorted vector is sorted using the k-mers as keys.

we use the same approach as abyss to represent the linkage information between nodes; i.e., the linkages are compacted into  <dig> bits with each bit representing the presence or absence of each of the eight edges in the two directions. however, to build the linkages between nodes, pasha employs a different approach. for each k-mer , abyss checks the existence of all possible neighbours by doing all possible base extensions in each direction. if a neighbour exists, it sets its corresponding bit to represent the existence of the linkage. this approach is effective but has a probability of introducing spurious edges, which connect k-mers that are not adjacent in any read. hence, pasha builds linkages directly from the adjacency information of k-mers in the input reads, i.e., a linkage between two k-mers is created if and only if the two k-mers are adjacent in at least one read.

while building linkages, for each process, thread t <dig> loads batches of reads from disk and transfers them to t <dig> as the previous stage does. for each read s, t <dig> iterates over each k-mer si and identifies its location after calculating the base- <dig> representation of its canonical k-mer. if the k-mer belongs to it, t <dig> sets the corresponding linkage bits calculated from the bases s and s, which are the extension bases in the left and the right directions of si. when the index is out of the range, the corresponding extension base  is an invalid base Ø, indicating that no linkage is created in that direction. figure  <dig> shows all four cases of the linkage construction between two adjacent k-mers in a read. because each process iterates all k-mers in all input reads, no communication between processes is required during the construction process. while constructing the linkages, we compute the multiplicity of each k-mer at the same time. in pasha, two bytes are used to represent the multiplicity of a k-mer. after completing the linkage construction, we will get a distributed preliminary de bruijn graph with each node corresponding to a k-mer.

graph simplification
the preliminary de bruijn graph contains many linear chains of nodes that can be merged to simplify the graph without loss of information. we start the simplification from the removal of spurious linkages. generally, there are three major kinds of spurious linkages: tips, low-coverage paths and bubbles. a tip is a short and low-coverage dead end, which is likely to be caused by sequence errors at the beginning or the end of reads. a low-coverage path only covers one or a few reads and is likely to be a chimeric connection. bubbles are redundant paths with minor differences, which might be due to heterozygosity, internal read errors or nearby tips connecting. at this stage, we only remove tips and low-coverage paths, leaving the removal of bubbles to the following stage.

prior to the removal of longer tips, we first remove low-frequency dead-end individual k-mers. this removal relies on the assumption that the majority of true k-mers should occur in several reads, i.e. the multiplicity of a true k-mer is supposed to be above a minimum multiplicity threshold m, which is automatically estimated from the multiplicities of all k-mers. this removal work is conducted round-by-round until no dead-end k-mers meet the removal conditions. for each process, t <dig> identifies the k-mers, which are dead-end and have a multiplicity less than m, in its local collection of k-mers, and then removes the k-mers and their linkages in the graph. when removing linkages to k-mers in another process, t <dig> packs a request message and lets t <dig> forward to the remote process. t <dig> forwards the request from t <dig> to other processes, and handles the requests on the removal of the specific linkages to its local k-mers, from the other processes.

in pasha, we simply remove tips that are shorter than 2k. for each process, t <dig> generates the current linear chain of k-mers, starting from a dead-end k-mer, by extending the chain in the left or right directions base-by-base. if the chain is longer than 2k, the chain is released; and otherwise, the k-mers in the chain will be removed as well as their linkages. if, during the extension of a chain, a linked k-mer exists locally, t <dig> gets the graph-related information of the k-mer directly from its local sorted vector. otherwise, t <dig> packs a request message and lets t <dig> forward it to the remote process. t <dig> will be blocked until receiving the response, forwarded back by t <dig>  from the remote process.

after completing the removal of tips, the graph is split into different linear chains of nodes. all processes cooperate in parallel to generate the sequences corresponding to the linear chains. the linear chains are generated using two steps. the first step generates linear chains starting from dead-end k-mers, where a chain is extended in only one direction. the second step starts from an arbitrary k-mer, where a chain must be extended in two directions. in the first step each process pi extends a linear chain from each active local dead-end k-mer until another dead-end k-mer is met. in this case, pi checks the location process pj of the dead-end k-mer to avoid duplicates because pj  might be generating this linear chain at the same time. in our algorithm, pi keeps this linear chain only if pi ≤ pj, and releases it, otherwise. this process will be conducted iteratively until there are no local dead-end k-mers in each process. the second step is completed by assigning processes one-by-one to generate linear chains. at any time, only one process pi is allowed to generate linear chains and the other processes have to wait and process requests from pi. pi starts the two-directional extension from each local k-mer until a loop or a dead-end k-mer is found. in this case, the loop is simply broken up and output as a linear chain. for each sequence, the coverage is calculated by dividing the sum of multiplicities of the k-mers in its corresponding chain by the sequence length. if the coverage is lower than the minimum coverage threshold, the sequence should be given up since it is likely to be generated from linear chains containing spurious connections. the remaining sequences are written to disk for the use in the next stage.

bubble merging and contig generation
this stage consists of three steps. first, a velvet-like de bruijn graph is constructed from the sequences produced from the previous stage. to build the velvet-like graph, we form a node, as well as its twin node, from a sequence and create linkages between nodes by aligning reads to nodes. if two adjacent k-mers in a read belong to two different nodes, we create an edge connecting them if there is no edge between them, and otherwise, update the information of the existing edge. while aligning reads to nodes, we do not record any mapping information about the reads. we employ a multi-threaded implementation to accelerate the alignment of reads to nodes on multi-core cpus, where a single read is aligned to the graph nodes by a thread and locks are carefully employed to guarantee the mutual exclusive access to critical sections .

secondly, we detect and merge bubbles in the graph. the "tour-bus" method in velvet is employed to detect bubbles. the detected bubbles are merged into a single path if the sequences of the parallel paths meet the user-specified similarity requirement. in pasha, we directly use the source code of the "tour-bus" method, but modified the conditions to merge the two paths. two paths are merged if they have at most a two-base-pair difference in length with ≥ 90% identity.

finally, we simplify the graph after further removal of short tips and low-coverage nodes, and then generate contigs from nodes.

scaffolding
the scaffolding work aims to find the correct ordering of the assembled contigs, and then joins them into scaffolds. the determination of the ordering of contigs relies on the mapping information of paired-end reads onto the contigs, and then the mapping information is transferred to scaffolding linkages between contigs.

in pasha, the scaffolding work starts from the construction of a velvet-like de bruijn graph from the assembled contigs. while aligning paired-end reads to the graph nodes , the mapping information of a read pair, such as mapping locations and node identifiers, is recorded into an in-disk database if the two reads successfully map onto the graph. a similar multi-threaded design, as in the previous stage, is employed to accelerate the graph construction on multi-core cpus.

having completed the read mapping, the median insert size, as well as its standard deviation, for each library is estimated from the mapping information of paired-end reads whose two reads map onto the same nodes. we employ a modified pebble algorithm  <cit>  to do the scaffolding work. the scaffolding linkages are built from the mapping information of paired-end reads in the in-disk database. velvet constructs linkages from the mapping information of reads and read pairs. for a single read, if it overlaps with more than one node, linkages will be created between these nodes. for a read pair, both of which have overlaps with nodes, a linkage is created between two nodes that respectively have overlaps with the two reads. in pasha, we only use the mapping information of read pairs to construct linkages, where a linkage is considered reliable if we have at least three read pairs to form the linkage.

speed optimizations
in the representation of the preliminary de bruijn graph, pasha employs a sorted vector data structure, instead of a hash-map, to store k-mers and their graph-related information. while reducing memory overhead, a sorted vector causes an increase in the average search time of k-mers. given n k-mers stored in a sorted vector, the average search time is about logn, generally longer than the  constant search time of a hash-map. in this case, we build an acceleration table using the most significant r bits  of a k-mer to speed up the search. this acceleration table only results in a memory increase of 2r times the size of type integer bytes, but is expected to reduce the average search time to log.

for stages  and , each mpi process has two threads t <dig> and t1: one for communication and the other for local computation. this mechanism is expected to improve the execution speed by overlapping communication and computation. however, when the two threads communicate frequently, along with memory allocations and de-allocations at the same time, the overhead incurred by system calls on memory operations may offset the performance obtained from the overlapping. thus, we use the tbb_allocator template class in the intel threading building blocks library to manage the memory allocation and de-allocation for the communication between t <dig> and t <dig>  the tbb_allocator template class does improve the execution speed through its smart management of user memory allocation and de-allocation.

RESULTS
experimental data
to assess pasha, we use four paired-end short read datasets from four different genomes to conduct experiments . the first three datasets: bacillus, bordetella and e.coli have accession numbers drr <dig>  err <dig> and srr <dig> in the ncbi sequence read archive , respectively. the reference genome of the bacillus dataset is bacillus subtilis subsp. subtilis str.  <dig> with accession number nc_ <dig> in genbank; the reference genome of the bordetella dataset is bordetella pertussis tohama i with accession number nc_002929; and the reference genome of the e.coli dataset is escherichia coli str. k- <dig> substr. mg <dig> with accession number nc_ <dig>  the yoruban male dataset has the accession number sra <dig> in ncbi sra, which contains six sub-datasets with accession numbers srx <dig>  srx <dig>  srx <dig>  srx <dig>  srx <dig> and srx <dig>  respectively. the first four sub-datasets come from the same library ct <dig> and the last two sub-datasets from library ct <dig>  we have used the six sub-datasets  to produce contigs and used the first four sub-datasets to create scaffolds . the use of these short read datasets is consistent for both pasha and abyss to produce contigs or scaffolds.

* uses an estimated insert size from assembly due to the unavailability of the real library insert size; ** uses the total length of all scaffolds in the grch37/hg <dig> build human reference sequence.

assembly quality assessment
we have assessed the assembly quality of pasha by comparing it to three leading assemblers: velvet , abyss  and soapdenovo  using the datasets in table  <dig>  all the tests are conducted on a workstation with two quad-core  <dig>  ghz cpus and  <dig> gb memory, and on a compute cluster with  <dig> compute nodes connected by a high-speed infiniband switch. each node of the cluster consists of two quad-core  <dig>  ghz cpus and  <dig> gb memory, running the linux operating system.

the assembly quality of all assemblers is compared in terms of ng <dig>  ng <dig> and maximum contig or scaffold sizes. the ng <dig>  contig or scaffold size is calculated by ordering all assembled sequences by their lengths, and then adding the lengths from the largest to the smallest until the summed length exceeds 50%  of the reference genome size. in this paper, for each dataset, we use the same reference genome size  to calculate the ng <dig>  contig or scaffold size for all assemblers. this is different from the calculation used in the abyss and soapdenovo papers, where they consider the total length of all assembled sequences by each assembler as the reference genome size. for the calculation of scaffold sizes, the intra-scaffold gaps are included. for the calculation of genome coverage, we split the scaffolds into their constituent contigs at the position of gaps that are filled by a series of "n" bases. the genome coverage and the number of incorrect contigs are computed from the results obtained from aligning contigs to their reference genomes using blat version  <dig>  <cit> . a contig is considered correct if it has a full length alignment to the reference genome with a minimum identity of 95%  and a maximal error rate of 5%. the alignment length is calculated by summing up the number of matches, the number of mismatches, and the number of insertions in the query and the target. the error rate is calculated by dividing the sum of the number of mismatches and the number of insertions in the query and the target by the alignment length.

we first use the three small paired-end datasets  to evaluate the different assemblers in terms of assembly quality and execution speed on a single cpu core of the workstation. the parameters of all the assemblers have been carefully tuned with the intention to gain the highest assembly quality for each dataset, where each assembler chooses the k-mer size that produces the largest ng <dig> scaffold size. table  <dig>   <dig> and  <dig> show the assembly results of all four assemblers, where we only consider scaffolds of length ≥  <dig> bps. the tables show that for all the three datasets, pasha is able to produce more contiguous assemblies with comparable genome coverage and mis-assembly rates in terms of all measures relating to scaffolds. moreover, pasha achieves the fastest execution speed on a single cpu core. pasha uses a single mpi process  for the first two stages of the pipeline, and a single thread for the last two stages. however, due to the small sizes of datasets, thread t <dig> contributes little to the actual execution time by overlapping file i/o operations with t <dig> 

pasha uses the parameters "k = 29", velvet uses "k =  <dig>  -exp_cov = auto, -cov_cutoff = auto", abyss uses "k =  <dig>  n = 10" and soapdenvo uses "k =  <dig>  insert_length = 160".

pasha uses the parameters "k = 31", velvet uses "k =  <dig>  -exp_cov = auto, -cov_cutoff = auto", abyss uses "k =  <dig>  n = 10" and soapdenvo uses "k =  <dig>  insert_length = 198".

pasha uses the parameters "k = 31", velvet uses "k =  <dig>  -exp_cov = auto, -cov_cutoff = auto", abyss uses "k =  <dig>  n = 10" and soapdenvo uses "k =  <dig>  insert_length = 215".

to demonstrate the capability of pasha to handle large genomes, we have further assembled the genome of a yoruban male individual using the above compute resources. the first two stages of pasha are computed on the 8-node cluster, and the last two stages run on the 8-core workstation. the contig generation of abyss is computed on the 8-node cluster and the scaffolding is performed on the 8-core workstation. both pahsa and abyss use a k-mer size of  <dig> for the assembly. tables  <dig> and  <dig> show the pasha and abyss assembly results both with, and without, scaffolding between pasha and abyss, where we only consider contigs and scaffolds of lengths ≥ 100bps. without scaffolding, pasha produces an ng <dig> contig size of  <dig> with a largest contig length of  <dig>  and abyss gives an ng <dig> contig size of  <dig> with a largest contig length  <dig> . as for genome coverage, pasha correctly aligned  <dig> % of the contigs, covering about  <dig> % of the human genome, and abyss correctly aligned  <dig> % of the contigs, covering about  <dig> % of the human genome. the longest correct contig has a length of  <dig>  for pasha, indicating that the largest contig failed to be aligned to the human genome, and a length of  <dig>  for abyss. with scaffolding, pasha yields an ng <dig> scaffold size of  <dig>  and a largest scaffold length of  <dig> , giving a genome coverage of about  <dig> %. abyss gives an ng <dig> scaffold size of  <dig>  and a largest scaffold length of  <dig> , giving a genome coverage of about  <dig> %. overall, pasha demonstrates competitive assembly quality with abyss in terms of contigs and scaffolds.

in terms of execution speed, pasha takes about  <dig> hours to complete the whole assembly, running on  <dig> cores  in the 8-node cluster with  <dig> gb per node  and on the 8-core workstation with  <dig> gb memory . using the same compute resources, abyss takes about  <dig>  hours, about  <dig> × slower than pasha. hence, we may say that pasha has a higher performance-cost ratio than abyss for the assembly of genomes as large as the human genome.

scalability
to evaluate the scalability of pasha, we have carried out the assemblies of the three small datasets on a different number of cpu cores. the first two stages of pasha are executed on the compute cluster using different numbers of cpu cores, and the last two stages on a single node using four threads. since pasha uses two threads for one mpi process, we start the evaluation from two cpu cores.

CONCLUSIONS
in this paper, we have presented pasha, a parallelized short read assembler for large genomes using de bruijn graphs. taking advantage of both shared-memory multi-core cpus and distributed-memory compute clusters, pasha has demonstrated its potential to perform high-quality de-novo assembly of large genomes in reasonable time with modest compute resources.

our evaluation using three small real paired-end datasets shows that pasha is able to produce better assemblies with comparable genome coverage and mis-assembly rates compared to three leading assemblers: velvet, abyss and soapdenovo. moreover, pasha achieves the fastest speed for all three datasets on a single cpu. for the yoruban male genome, pasha is able to complete the assembly in about  <dig> hours with modest compute resources, which is about  <dig> × faster than abyss running on the same compute resources. without scaffolding, pasha yields an ng <dig> contig size of  <dig> with the longest correct contig length of  <dig> , and with scaffolding, it produces an ng <dig> scaffold size of  <dig> . pasha achieves competitive assembly quality with abyss, but takes less execution time using the same compute resources. for scalability, pasha is able to reduce the execution time as the number of cpu cores increases, and is about  <dig> × faster on average than abyss running on the same number of cpu cores.

abbreviations
cpu: central processing unit; mpi: message passing interface; sra: sequence read archive

authors' contributions
yl conceptualized the study, carried out the design and implementation of the algorithm, performed benchmark tests, analyzed the results and drafted the manuscript; bs conceptualized the study, participated in the algorithm optimization and analysis of the results and contributed to the revising of the manuscript; dlm conceptualized the study, participated in the analysis of the results, and contributed to the revising of the manuscript. all authors read and approved the final manuscript.

