BACKGROUND
the olfactory system
the structure of olfactory systems is similar between insect species. as an example, we provide numbers for the honeybee apis mellifera. on the antenna, approximately  <dig>  odour receptor neurons interact physically with the odour molecules. these  <dig>  neurons converge onto  <dig> glomeruli in the al, where each glomerulus collects input from receptor neurons of one type. the glomeruli are bundles of synapses and appear as spherical structures with a diameter between  <dig> and  <dig> µm. at the al stage, each odour is represented by an activity pattern across the  <dig> glomeruli. further upstream, this compact representation is widened again, as the projection neurons project from the glomeruli to approximately  <dig>  kenyon cells, a stage where odours are represented by sparser, high-dimensional patterns.  <cit>  while implementation details differ between species, the combinatorial coding of odours by activity patterns across glomeruli, in the insect al or in the vertebrate olfactory bulb, is a common feature of olfactory systems and can also be found in humans  <cit> .

odour responses in the al
calcium imaging using calcium-sensitive fluorescent dyes grants us access to the odour response patterns in the al of the honeybee apis mellifera  <cit> . these odour response patterns reflect the response properties of the odour receptor neurons, as well as additional processing that takes place in the al. interneurons connecting the glomeruli perform further computations such as contrast enhancement  <cit> .

for an example of odour response patterns in the honeybee al, see figure  <dig>  the activity pattern of glomeruli  fluctuates at a low amplitude when no odour is present. after stimulation with an odour , glomeruli exhibit individual responses to the odour. as a result, the activity pattern across glomeruli changes in way that is characteristic for the odour. the same odour elicits a similar pattern in different bees  <cit> .

there is evidence that not only the identity of a particular odour is encoded by the corresponding glomerular response pattern, but that also chemical  <cit>  and perceptual  <cit>  similarity are reflected by the similarity of response patterns, suggesting that response pattern space is a rather faithful representation of chemical space.

odour responses on the antenna
glomerular response patterns, as measured in the honeybee recordings from this work, are the output signal of the al, i.e. they are the result of integrating all receptor neurons of one type and of further processing that occurs in the al network of interneurons. while odour coding is improved after this processing  <cit> , the results of this paper suggest that chemical identity and similarity can already be inferred from receptor neuron signals recorded on the antenna, the earliest stage in the olfactory processing pipeline where response patterns are easily accessible without dissecting the brain.

in this work, antenna data was recorded in the fruit fly drosophila melanogaster. the genetic tools that are available for drosophila make it possible to express a calcium reporter directly in the receptor neurons on the antenna. instead of expressing the reporter in cells of one type, as has been done before  <cit> , the approach pursued here is to measure signals from a large set of different receptor cells that all express the general olfactory co-receptor orco that these cells bear in addition to a specific odour receptor. this allows us to measure broad odour response patterns across many receptors. the segmentation approach presented in this paper is then used to to extract individual response units from the imaging movie based on their differential responses to a series of  <dig> different odours.

related work
computational approaches to analysing imaging data can be classified as being either synthetic or analytic. in a synthetic approach, similar to common procedures for analysing fmri data, stetter et al.  <cit>  have set up non-linear functions that they fitted to the individual  time series of the imaging movie. these functions can account e.g. for dye bleaching over time and for different neural signal components. rather than performing bottom-up synthetic reconstruction of the imaging movie, analytic approaches decompose  the movie into factors. these are matrix factorisation or decomposition methods that exist in many different flavours, e.g. the well-known principal component analysis . in particular independent component analysis  has found widespread application on imaging data  <cit> . while ica can be seen as a matrix decomposition method, the motivating paradigm for ica is source separation. under the assumption that there are underlying source signals that are statistically independent , ica algorithms  aim at recovering or separating these source signals on sample data where the sources appear in mixed form, e.g. neural signals mixed with measurement artifacts.

a recent convex analysis approach  <cit>  , performs a factorisation of the movie matrix based on extremal column vectors from the boundary of the convex/conical hull of the data. under the assumption that pure signal sources are present in the data, finding the extremal column vectors identifies these pure signal sources.

traditionally, calcium imaging data from the insect al has been processed by semi-automatic methods that perform e.g. image smoothing, but that still require human interaction to select regions of interest  <cit> . from the methods listed above, those that require human interaction appear less suited for real-time processing on a movie stream. so far, no real-time implementations of the computational approaches exist, the software implementations from  <cit>  being only suited for offline data analysis.

methods
biological methods
imaging the honeybee al
for honeybees, it has been shown that projection neuron firing rate correlates with changes in intracellular calcium  <cit> . staining with calcium-sensitive fluorescent dyes and excitation of the dyes with uv-light thus leads to a good proxy signal for brain activity  <cit> .

calcium imaging with forager honeyebees  was performed as described in  <cit> . projection neurons in the l-apt and m-apt  were stained with fura2-dextran , a calcium-sensitive, fluorescent dye. activity of the projection neurons, that depart from the glomeruli in the al, could be recorded using the experimental setup displayed in figure  <dig>  a fluorescence microscope  was equipped with a water immersion objective . a light source  provided excitation light at  <dig> and  <dig> nm, and fluorescence was recorded with a ccd camera . the input signal for data processing was computed as the ratio between consecutive images recorded at  <dig> and  <dig> nm, a standard procedure for fura2-dextran  <cit> .

imaging the drosophila antenna
animals
animals used for the experiments were female drosophila melanogaster that were reared at  <dig> °c in a 12/ <dig> light/dark cycle. flies were of genotype w; p; pattp <dig>  expressing the calcium reporter g-camp <dig>  <cit>  in all orco  bearing cells .

odorant preparation
odorants were purchased from sigma-aldrich in the highest purity available. pure substances were diluted in  <dig> ml mineral oil  to a concentration of 10- <dig> vol/vol. odours were prepared in  <dig> ml headspace vials, covered with nitrogen and sealed with a teflon septum . odorants used were: 2-propylphenol , alpha-ionone , alpha-bisabolol , trans-caryophyllene , -carvone , -carvone , beta-citronellol , 4-allyl- <dig> -dimethoxybenzene , ethyl 3-hydroxyhexanoate , ethyl -3-hydroxybutanoate , eugenol , e, e-farnesol , geraniol , heptyl acetate , hexyl acetate , hexyl butyrate , isoamyl tiglate , iso-eugenol , 4-isopropylbenzaldehyde , linalool , methyl 3-hydroxy hexanoate , 4-methoxybenzaldehyde , methyl jasmonate , -myrtenal , nonanal , nonanone , octyl acetate , phenylacetaldehyde , 4-hydroxy-3-methoxybenzaldehyde , gamma-propyl-gamma-butyrolactone , alpha-terpineol  and alpha-thujone .

stimulus application
a computer-controlled autosampler  was used for automatic odour application.  <dig> ml of headspace was injected in two  <dig> ml portions at timepoints  <dig> s and  <dig> s with an injection speed of  <dig> ml/s into a continuous flow of purified air flowing at  <dig> ml/min. the stimulus was directed to the antenna of the animal via a teflon tube .

the interstimulus interval was approximately  <dig> min. solvent control and reference odorants  were measured after every five stimuli . the autosampler syringe was flushed with purified air for  <dig> s after each injection and washed with pentane  automatically after each block of stimuli.

calcium imaging
calcium imaging was performed with a fluorescence microscope  equipped with a 50x air lens . a ccd camera  was mounted on the microscope, recording with 4x <dig> pixel on-chip binning, resulting in 160x <dig> pixel sized images. for each stimulus, recordings of  <dig> s at a rate of  <dig> hz were performed using till vision .

a monochromator  produced excitation light of  <dig> nm wavelength which was directed onto the antenna via a  <dig> nm low-pass filter and a  <dig> nm dichroic mirror. emission light was filtered through a  <dig> nm high-pass emission filter.

flies were mounted in custom-made holders, placed with their neck into a slit. the head was fixed to the holder with a drop of low-melting wax. a half electron microscopy grid was placed on top of the head, stabilising the antenna by touching the 2nd, but not the 3rd antennal segment.

matrix factorisation framework
we first describe the general matrix factorisation framework for imaging movies. the framework is illustrated in figure  <dig>  an imaging movie can be cast into matrix form by flatting the two-dimensional images with n pixels into row vectors of length n. the movie matrix am × n has m time points and n pixels. the rows of the movie matrix, a, contain images or time points. the columns, a, contain pixels or time series.

we consider a factorisation of a into a matrix tm × k of k time series and a matrix sk × n of k images, where k≪n,m. this provides a low-rank approximation ak to the original matrix a:

  am×n:ak=tm×ksk×n=∑r=1ktirsrj 

in imaging movies, all pixels that report the signal of the same glomerulus are correlated with each other , which causes redundancy in a. it is thus possible to construct a good approximation with small k, such that ∥a-ts∥ is small.

the optimal rank-k approximation with respect to the aforementioned norm difference can be computed with principal component analysis   <cit> . however, the images in s computed by pca are not sparse, with almost all pixels being different from zero  <cit> . the images in s, and the corresponding time series in t, can thus hardly be interpreted as the boundaries or the signal, respectively, of a particular neural unit. by definition, principal components need to be orthogonal to each other, which often prevents them from closely fitting the underlying source signals.

ideally, as in the example from figure  <dig>  the images in s should be sparse, with only few pixels being different from zero. the k time series in t should be selected from k different glomeruli with the corresponding rows in the sparse s marking positions and boundaries of the glomeruli. we have shown in  <cit>  that there is a method, the convex cone algorithm, that can achieve a factorisation with such favourable properties on imaging data.

convex cone algorithm
in this section, we review the convex cone algorithm from  <cit> . it is based on a non-negative mixture model for imaging data:

  a=ts0++n 

the movie matrix a can be described by basis time series in t that are combined by coefficients in the non-negative matrix s0+. residual noise is accounted for by n.

we assume that the columns a of the movie matrix contain either pure glomerulus signals or mixed signals, i.e. linear combinations  of the pure signals. at the fringes of a glomerulus, close to the neighbour glomeruli, such mixed signals can occur when a glomerulus signal is contaminated with additive light scatter from one or more neighbour glomeruli. even if a glomerulus does not respond to an odour, light scatter can give the impression of a signal. in the middle of the glomeruli, that are rather large, circular objects, light scatter from the  pixels of the neighbour glomeruli is less likely, and we assume that here the pixels contain pure signals.

for the matrix factorisation framework from figure  <dig>  we would like to select one pure signal from each glomerulus into t. mixtures can then be modelled by s0+. while s0+ can be computed easily given a and t, the challenging part is the selection of time series from the glomeruli into t.

geometrically, the columns in t span a convex cone  <cit>  that contains a part of the data points in a. data points that lie within the cone can be reconstructed exactly by linear combination  of the columns in t . data points that lie outside of the cone can be approximated by projecting them to the boundary of the cone, where the approximation error depends on the distance to the boundary.

from convex analysis we know that the set of extreme vectors of a is the minimal generator of the convex cone that contains the entire a  <cit> . with the extreme vectors we can span a volume that contains all data points of a and that thereby reduces the approximation error to zero. for imaging movies, the extreme columns vectors are also the columns with the pure signals from the middle of the glomeruli, whereas the mixed signal columns, that can be combined from the extreme, pure signal columns, lie within the cone.

following this motivation, the convex cone algorithm  <cit>  makes locally optimal choices for the next extreme column vector. with each new vector selected by the algorithm, the columns in t span a larger  volume.

the convex cone algorithm starts with matrix a{1} := a, selecting the column with index p that has the largest euclidean norm: arg maxp||a{1}|| this column becomes the first column of t,t:=a{1}. then, a matching s:=a{1}tt is computed . the movie matrix is downdated as a{2}:=a{1}-ts. in the new matrix a{2} at iteration  <dig>  the influence of the first column t is removed. we then select the column that is farthest away from the boundary of the cone, i.e. the column with the largest norm in a{2}. this is an estimate for the next extreme column vector, and we fill this column into t.

we repeat the process until c columns are selected. in the following, we reserve c for the  number of columns selected by the convex cone algorithm, and k for the number of principal components in the pca step that is performed before the convex cone algorithm.

working on a movie stream
there are two motivations for performing pca as a preprocessing prior to the convex cone algorithm. first, keeping only the top-k principal components reduces noise, which can make selection of extreme columns more robust. second, we can utilise pca to reduce computation time. for the real-time application, the movie matrix a grows by one row at each time point. the complexity of the convex cone algorithm is in the order o if run once on the complete matrix a. for a growing movie matrix this would quickly accumulate a large overhead, the cost of performing the convex cone algorithm at each time point being o.

if we utilise pca to keep, at all times, a compact summary matrix of constant size, we can remove the dependency on the growing time dimension. we propose to use an incremental pca  approach that computes the matrix vk of the top-k principal components at each time point, where vk is updated at low cost given the old version of vk and the current image received from the movie stream. the convex cone algorithm is then no longer performed directly on a, but on vk. as vk is the minimiser of ||a-vk||, moderate values for k are sufficient in practice.

several publications have treated ipca algorithms  <cit> . here, we rely on the ccipca algorithm by weng et al.  <cit> . several successful applications of ccipca can be demonstrated  <cit> . in these cases, ccipca was also used to incrementalise another algorithm by providing an updated version of matrix vk at each time point. ccipca costs a constant o operations per update, which amounts to o for processing the entire movie once.

here, we outline the basic principle behind ccipca. the first principal component is approximated as the mean of the images received so far. the second principal component is approximated as the mean of the images from which the projection onto the first pc has been subtracted, etc. this approach allows for incremental updates, and it completely avoids the time-consuming construction of a large n × n covariance matrix, which would be required by standard pca approaches that compute the eigenvectors of the covariance matrix. in the following, we briefly outline the ccipca iteration. for further details on ccipca, see  <cit> . a convergence proof is given in  <cit> .

we assume that the movie matrix grows by one image, a, at time point i. the r = <dig>  ..., k rows of the principal component matrix v = vk are initialised with k arbitrary, orthogonal vectors. then, v is upated at each time point using the current image a, where principal component v at time point i is denoted v{i}:

  v{i}:=i-1iv{i-1}+1iaatv{i-1}∥v{i-1}∥ 

then, image a is downdated by subtracting the projection onto v{i}:

  a:=a-atv{i}∥v{i}∥v{i}∥v{i}∥ 

after updating the rth principal component in this way, we can return to equation  to update v .

algorithm 1: v{i} = update_ipca , k , i)

for all r ∈  do

 v{i}:=i-1iv{i-1}+1iaatv{i-1}∥v{i-1}∥ 

 a:=a-atv{i}vr{i}v{i}v{i} 

end for

cone_updating: visualisation in real time
combining ccipca  and the convex cone algorithm leads to the algorithm at the core of the real-time imaging system: cone_updating . each image a at time point i is first preprocessed by pixel-wise z-score normalisation: subtract µ, the mean, and divide by σ, the standard deviation. both, µ and σ of a pixel, can be updated as the movie stream proceeds.

after normalisation, the matrix v of the top-k principal components is updated with the current image: v{i} := update_ipca, k, i). finally, the convex_cone_algorithm  is applied to select c pixels  from the current version of v.

as the movie matrix a grows, the incremental estimates for µ, σ and v improve. as a consequence, the c columns selected by the convex cone algorithm are better estimates of the extreme column vectors of a, the vectors that contain the pure glomerulus signals. in the matrix factorisation framework, these are are the columns for matrix t, and the corresponding s indicates glomerulus position .

visualisations of brain activity, such as in figure  <dig>  can be achieved by low-rank approximation, using matrices t and s: ak = ts. at time point i we do not yet know the final t and s, and therefore we obtain the approximation a^ asa^:=as{i}s{i}, where s{i} is the current version of s.

for offline data visualisation, the colour scale can be adjusted to the maximum and minimum value of a. for real-time display, using one colour scale for the entire movie, maximum and minimum have to be updated incrementally. to avoid level changes, e.g. by long-term photobleaching of the calcium dye, data was high-pass filtered  before display in a false-colour scale .

algorithm  <dig> : s = cone_updating , c, k)

  initialise v{1}

  for all i ∈  do

    a := z_score_normalise )

    if i >  <dig> then

      v{i}:= update_ipca, k, i)

      s{i} := convex_cone_algorithm 

      
a^:=as{i}s{i}// low-rank approximation to image a

    end if

  end for

implementations
we consider three implementations of the convex cone algorithm. two implementations were written in java, java_offline, the reference implementation from  <cit> , and java_online. java_offline performs exact offline pca, followed by the convex cone algorithm, whereas java_online  uses incremental pca instead. both java implementations were performed in knime  <cit>  , a data pipelining environment.

finally, we implemented the incremental online variant  using gpgpu: gpgpu_online. z-score normalisation and the time-consuming pca were implemented for the gpu with the nvidia cuda  <cit>  basic linear algebra subroutines   and the cuda linear algebra library  . the actual convex cone algorithm was run on the cpu.

till photonics live acquisition  software  <dig>   <cit>  was employed to control experimental hardware and excitation light intensity. gpgpu_online accessed the movie stream directly from the camera using a custom-built software interface kindly provided by till photonics.

RESULTS
this sections starts with a technical evaluation of the proposed algorithm and a comparison of different implementations. we then demonstrate practical applicability in an experiment with honeybees and show how the techniques developed in this work can be utilised to turn the insect antenna into a living chemosensor. we conclude with a discussion regarding the impact that real-time processing of neural activity can have.

performance measures
computing time
the motivations for adapting the matrix factorisation framework to the datastream domain were the ability to perform incremental updates upon arrival of new data, and of course the ability to process data with minimal time delay. for evaluation, we performed computation time measurements on a reference dataset. measurements were carried out using an intel core i <dig>  <dig>  cpu and a nvidia.

geforce gtx  <dig>  gpu. the java_offline and java_online implementations were run in knime  workflows, and, for comparability with the c-implementation gpgpu_online, time measurements do only include the actual computation time and not the time for data transfer between nodes in the knime workflow.

the dataset consisted of  <dig> imaging movies of the honeybee al  with ≈  <dig> ×  <dig> pixels and ≈  <dig> time points each. the average length was about  <dig> minutes per movie. table  <dig> reports overall computation time  for the entire dataset and computation time per frame, averaged over all  <dig> movies. both the incremental approximation to pca and the gpgpu implementation contributed to the speedup. java_online, that uses incremental pca, achieved an approximately  <dig> -fold speedup over java_offline that is based on exact, conventional pca. gpgpu_online achieved an additional 2-fold speedup over java_online by using the gpu instead of the cpu. the parallelisation abilities of the gpu ensure scalability to future increases in data size, i.e. higher speedups are expected for data with higher resolution.

we report average computation time per frame and overall computation time for the entire dataset.

with the fastest implementation, gpgpu_online, a single image from the movie can be processed in  <dig> ms , which is sufficient for calcium imaging in honeybees and drosophila with typical recording frequencies below  <dig> hz.

approximation quality
the fastest implementation, gpgpu_online, achieves a significant speedup over the offline reference implementation. we next evaluated the quality of the results computed with gpgpu_online. there is an algorithmic approximation involved, and gpu computations are performed with float precision instead of double precision. in the online setting, incremental z-score normalisation was imperfect whenever there were mean shifts during the course of the experiment. how does this affect the quality of the results? for visualisation, we constructed maps of the glomeruli in the al by overlaying all images from the rows of matrix s, the images that show the positions and boundaries of the glomeruli . such glomerular maps reveal the anatomy of the al and can be matched between bees  <cit> . using the reference results from  <cit> , we compared glomerulus maps computed by java_offline and gpgpu_online on the same movie. parameters were k =  <dig> principal components, c =  <dig> . figure 4a shows glomerulus maps constructed by the two implementations. clearly, both implementations reveal the same anatomy, but there is no perfect correspondence between the maps.

apart from visual inspection of glomerulus maps, where cluster size has a strong impact, we also analysed how robust signal  selection was against incremental approximation. the convex cone algorithm selects extreme column vectors into matrix t that correspond to the pure signal sources. matrix s is computed given a and t , and the rows of s reflect the distribution of similarity with the corresponding signal sources in t . this gives rise to the clusters of similar pixels in s and on the glomerulus map. preprocessing, such as incremental z-score normalisation and incremental pca, and a postprocessing step employed in  <cit>  to remove the residual noise n  all have an impact on signal similarity and thus influence cluster size. this affects especially clusters that correspond to e.g. areas of similarly strong background staining, illumination artifacts etc. that do not have such clearly distinct signals as the glomeruli.

to evaluate signal selection independent of cluster size, we visualised the positions of the columns selected by the offline reference implementation java_offline, along with the positions of the columns selected by gpgpu_online. for the reference implementation, we included only glomerular signals, i.e. those that could be identified by matching glomerulus maps to the anatomical honeybee al atlas  <cit> . figure 4b shows that the positions of signals selected by gpgpu_online  are in good correspondence with the glomerulus "targets" provided by java_offline . we conclude that selection of relevant signals, i.e. glomerular signals, is robust against incremental approximation in the online setting.

documentation of a real-time experiment in the honeybee al
to demonstrate practical applicability, we performed a real-time experiment with honeybees. we used the experimental setup from figure  <dig> and gpgpu_online, the software implementation that proved fastest in the evaluation. for a screenshot, see figure  <dig>  during the experiment, three windows were constantly updated: the raw fluorescence signal, shown as the ratio between consecutive measurements with  <dig> nm and  <dig> nm excitation light , a map of the glomeruli in the al, and the low-rank approximation to the current image. movie documentations of the real-time experiment  are available online.

the glomerulus map is a segmentation of the image plane into regions with correlated activity over time. with the growing movie stream, more and more information about correlations between pixels becomes available. figure  <dig> shows the gradual development of a glomerulus map during the course of the experiment. while at early time points many of the c basis signals were still influenced by the initialisation of the  incremental pca , they quickly moved to the positions of the glomeruli as more information arrived from the stream. already after 400- <dig> time points, the map was almost complete. if needed, such an incremental computation of the glomerulus map could also be used to adapt to changes: for example, shifts between images caused by animal movement could be corrected for by giving higher weights to more recent time points.
. development of a glomerulus map during a real-time experiment. the images show incremental updates of the map at different time points. parameters: k =  <dig> , c =  <dig>  as preprocessing, images were spatially filtered .
. spontaneous background activity of glomeruli in the honeybee al, visualised by low-rank approximation. top: fluorescence images recorded at  <dig> hz. each image is the ratio of consecutive images recorded with  <dig> nm and with  <dig> nm excitation light . bottom: the same images after processing with the real-time software.

the insect antenna as a chemosensor
functional segmentation of the antenna
while recording glomerular activity in the honeybee al can help to answer neurobiological questions, the experimental procedure is technically demanding and time-consuming as it requires to dissect the brain and to fill in a calcium-dye into the projection neurons the day before the experiment. working with the model organism drosophila melanogaster, we could omit the manual staining step, genetically expressing the calcium-sensitive dye g-camp  <cit>  in the receptor neurons that are accessible without dissecting the brain .

this experimental design allows us to employ a drosophila antenna as an easy-to-handle chemosensor. similar to the situation in the honeybee al, stimulating the antenna with a series of odour presentations elicits differential responses in the receptors that can then be distinguished based on their activity over time. we can thus utilise the real-time software to construct a map of the drosophila antenna and to observe odour responses.

we employed a series of  <dig> different odour stimulations, two of which were control odours that were applied multiple times. this stimulation protocol elicited sufficiently diverse responses to allow for functional segmentation . for figure  <dig>  we computed a map of the antenna consisting of c =  <dig> response units. the antenna map is shown in 8a, and figure 8b contains a single image from the calcium imaging movie.

in drosophila, olfactory receptor neurons are anisotropically spatially scattered over the surface of the antenna, so that odour response patterns form spatio-temporal maps. however, sources could be overlapping, creating a situation that is more complex than with the image of well segregated olfactory glomeruli in the antennal lobe.

data analysis
we thus investigated whether the response units had indeed biologically or chemically meaningful signals. after processing the entire movie stream, we analysed the response unit time series in matrix t . for each odour stimulation, we computed a feature vector, where the feature was the maximum value of the response unit after presentation of the respective odour : figure 9a.

clustering these feature vectors  shows that feature vectors for repeated applications of the same odour, e.g. nonanone, cluster together. the odourless control measurements  appear clearly separated from the odourous substances, and chemically similar odours end up in the same cluster . this serves as a proof of concept, demonstrating that the real-time imaging system can, in principle, both recognise known odours and estimate the identity of unknown odours by their similarity to reference odours.

while distances between odour molecules are in part well reflected by response pattern distances, this is not always the case. for example, iso-eugenol does not fit into the heptyl acetate cluster, and 2-propylphenol lacks clear responses and therefore ends up in the  oil/air cluster. further experiments are needed to evaluate whether representation of chemical identity can be optimised by recording more or different response units, e.g. in a different focal plane.

it also needs to be tested whether the observed odour responses are stereotypical across many individuals. as a first approach, we replicated the experiment from figure  <dig>  finding a high correlation  between the odour × odour euclidean distance matrices  from both experiments, indicating that the relative dissimilarity of odours could be conserved between individuals.

how can the system be applied?
artificial chemosenors, so-called electronic noses  <cit>  are important tools for environmental monitoring, healthcare or security applications. they do, however, not yet reach the efficiency and sensitivity of biological olfactory systems. the real-time software can extract features from calcium imaging recordings, directly accessing the drosophila antenna as a biological chemosensor. such feature vectors  can be used to visualise molecular identity, or they can be subject to further processing, e.g. by classifiers, aiming to determine the identity of an unknown chemical substance. there are two points to making the biological chemosensor practical: 1) working with non-invasive biological techniques that allow for easy handling of the flies, 2) software that can process the continuous stream of odour plumes encountered in a real-world application.

impact of real-time processing
going beyond the specific example of the chemosensor application, real-time processing has a wider range of applicability that involves any kind of interactive experimentation. this belongs to future work that is made possible with the real-time technology.

motivating examples
it is increasingly clear that perception is influenced by both the stimulus and the prior state of the brain. for example, brain oscillations during the pre-stimulus interval influence how a human subject perceives an auditory stimulus in an experimental setup targeted at multimodal sensory integration  <cit> . sensory experience without external stimulation, stemming only from the current state of the brain, is known from medical phenomena such as tinnitus  <cit> .

for honeybees, there is first evidence in the direction that spontaneous background activity of the glomeruli in the al carries information about odours that have been encountered recently: glomerular activity patterns similar to a particular odour response pattern reverberate minutes after the actual response has been elicited by odour stimulation  <cit> .

considering the growing interest in ongoing brain activity, it is increasingly important to develop experimental strategies that allow stimulus presentations to be conditional on ongoing brain activity states. with the real-time methods presented in this work, glomeruli can be targeted because of their responses to odours or because they are part of reverberating patterns in spontaneous background activity.

real-time processing is necessary to answer fundamental questions regarding the role of ongoing brain activity: is it a side-effect that simply occurs as a consequence of neuron and network properties? are patterns in spontaneous activity actually read out for further processing in the brain? in conditioning experiments  <cit> , bees learn to associate an odour with a sugar reward. can rewarding a pattern in spontaneous activity have the same effect as rewarding the actual odour?

added value by real-time processing
from a biological perspective, the added value provided by the real-time software is that brain activity can be interpreted based on processed information. only milliseconds after the activity occurs, we can regard not only raw pixel values, but anatomically distinct and identifiable units, the olfactory glomeruli in our case.

while analysis of neural data is often is performed pixel-wise , the brain encodes odours in patterns across glomeruli. being able to work on a glomerulus level allows us to match the odour response patterns we observe with known response patterns from a database, which can reveal the chemical identity of the stimulus molecule. for spontaneous background activity, we can analyse the distribution of glomerular patterns that informs us about the state the antennal lobe network is in, i.e. the prior state that is relevant for how the stimulus will be perceived.

how fast is fast enough?
closed loop experiments, where measured brain activity controls experimental settings, require that data processing is faster than recording speed. in calcium imaging experiments, images are often recorded at frequencies of  <dig> hz or slower. thus, any processing of  <dig> ms/frame or faster is appropriate. recordings with voltage-sensitive dyes, for example, are generally useful at  <dig> hz or faster: the fastest neuronal processes, the action potentials, have a duration of 1- <dig> ms, so recordings at  <dig> hz would be ideal. the current speed of  <dig> ms/frame  is already getting close to the  <dig> hz value, but it is still far from the ideal  <dig> hz.

for many experiments, fast processing is a requirement, e.g. if we wish to follow and react to fluctuations in spontaneous activity. for the chemosensor task, the advantage lies in the fact that we can directly query a biological chemosensor instead of waiting for results from post-hoc data analysis. fast processing reduces the delay of the chemical analysis and allows for high-throughput assays.

CONCLUSIONS
in the brain, odours are represented as activity patterns across many neurons. calcium imaging is a technique that lends itself to extracting such activity patterns, as it allows to record many units simultaneously. so far, software for calcium imaging data has focussed on offline data processing  <cit> . the algorithms and software presented in this work process calcium imaging movies online, making the neural representations of odours accessible directly when they occur.

algorithmically, we rely on a matrix factorisation that is updated with every new image that arrives from the movie stream. a low-rank approximation to the movie matrix serves as a compact representation of the calcium imaging movie, discarding noise and highlighting neural signals. this serves as the basis for further visualisations, such as functional maps of the glomeruli in the al: glomerulus borders are not defined by anatomy, but by function, i.e. activity  of pixels over time. this eliminates the need for registration of imaging data to anatomical stainings.

such maps and the visualisation obtained by low-rank approximation reveal the "looks of an odour", the initial odour response pattern on the antenna, or, after data integration and processing has taken place, the glomerular response pattern in the al.

both odour representations have applications that profit from real-time processing. the role of the al network in shaping the odour response patterns can now be investigated using closed-loop experiments, where prior system states influence current experimental parameters. staining an array of receptor neurons with a single genetic construct, accompanied by online processing, provides easy access to odour response patterns, making real-time chemosensing with a biological sensor practical.

visualising the neural representation of odours serves also to map perceptional spaces. distances between odour response patterns are an estimate for perceptional similarity between odours  <cit>  throughout different stages of odour information processing in the same individual, and also between individuals and even species, leading to species-specific odour perception spaces.

for such and further applications, the algorithmic and visualisation framework developed here enables fully automatic processing of odour response data without the need for human interaction to define e.g. regions of interest.

availability
source code is available in additional file  <dig> 

competing interests
the authors declare that they have no competing interests.

authors' contributions
ms developed computational methods. ms wrote the manuscript with contributions from ps, dmü and mpb. cm  and ms  programmed software. cm, mpb and ms performed practical implementation and testing of the real-time imaging system. biological experiments were performed by dmü and tl , and by ps . cgg  and dm  supervised the project. od, cgg and dm revised the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
video documentation, part  <dig>  experimental setup for honeybee brain imaging.

click here for file

 additional file 2
video documentation, part  <dig>  screen capture from a honeybee brain imaging experiment.

click here for file

 additional file 3
source code. archive containing source code for the software presented in this work. note that till photonics la  <dig>   <cit>  is required for configuring experimental hardware.

click here for file

 acknowledgements
we are grateful to till photonics gmbh  for providing a software interface for their imaging system. we would like to thank julia rein for the honeybee reference data, and jacob stierle for assistance with handling and preparing bees.

declarations
this publication was funded by the ieee symposium on biological data visualization  as a supplement of highlights.

the articles in this supplement have undergone the journal's standard peer review process for supplements. the supplement editors declare that they have no competing interests.

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2013: highlights from the 2nd ieee symposium on biological data visualization. the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/14/s <dig> 
