BACKGROUND
the number of generalized hidden markov model  gene finders reported in the literature has increased fairly dramatically of late  <cit> , and the community is now contemplating various ways to extend this attractive framework in order to incorporate homology information, with a handful of such systems having already been built . ghmms offer a number of clear advantages which would seem to explain this growth in popularity. chief among these is the fact that the ghmm framework, being  purely probabilistic, allows for principled approaches to constructing, utilizing, and extending models for accurate prediction of gene structures.

while the decoding problem for ghmm gene finders is arguably well understood, being a relatively straightforward extension of the same problem for traditional hmms and amenable to a viterbi-like solution , methods for optimally training a ghmm gene finder have received scant attention in the gene-finding literature to date. what information is available  seems to indicate that the common practice is to optimize the submodels of the ghmm independently, without regard for the optimality of the composite model.

the training of hmms and ghmms has traditionally been carried out using some form of maximum likelihood estimation . baum-welch training  <cit> , which is an instance of the well-known expectation maximization  procedure, is itself a form of mle  <cit> . in the case of ghmm gene finders, one typically applies some form of mle to each of the submodels  in the ghmm so as to render training features of each type  maximally likely under the induced model; i.e., maximizing:



for state q and for si a feature of length di from the state-q-specific training set t. the submodels are then merged into a composite model  by observing transition probabilities between features in the training data corresponding to each of the ghmm states.

for example, an exon state in a ghmm can be trained by collecting n-gram statistics  from known exon sequences and normalizing these into transition probabilities for an th-order markov chain  <cit> . similarly, intron, intergenic, and untranslated region  states can be modeled by collecting appropriate statistics from corresponding sample features and using these to train individual content-scoring models, such as markov chains, neural networks, decision trees, etc. signal sensors for donor and acceptor splice sites and start and stop codons can be trained by aligning known signals of the appropriate type and counting nucleotide frequencies at each position within a fixed window around the signal; converting these counts to relative frequencies produces probability estimates for use in a weight matrix or similar type of model. transition and duration probabilities can likewise be estimated by observing appropriate frequencies in training data. all of these estimation activities can be performed independently, resulting in a ghmm consisting of distinct subsets of maximum likelihood parameters.

such an approach does not, however, attend to the global optimality of the ghmm as a whole. ideally, one would like to maximize the expected accuracy of the gene finder on unseen data. a reasonable approximation to this ideal would be to maximize the average probability of the gene parses in the training set:



where the collection of model parameters making up the ghmm is denoted θ and the elements  of the training set t comprise pairs of sequences s and their known parses φ. this argmax gives us the parameterization  under which the full gene parses  in the training set will be maximally likely . decomposing each parse φ into a series of  pairs, for state qi and state duration  di, we get:



where pe, pt, and pd represent the emission, transition, and duration probabilities of the ghmm, respectively. whereas the common mle training procedure for ghmms as described above optimizes the individual terms in the numerator of equation  <dig> independently, the argmax above calls instead for these terms to be jointly tuned so as to optimize the entire ratio in parentheses. intuitively, one can think of this alternate formulation as attempting to account for the process in the viterbi algorithm  whereby the individual submodels "compete" for nucleotides . our hope is that by addressing the issue of submodel competition explicitly during parameter estimation, we will thereby empower the gene finder to better discriminate at a global sequence level between the features modeled by individual submodels in the ghmm, thereby producing more accurate gene predictions.

a similar optimization problem occurs in the field of speech recognition, in which systems of interacting acoustic models and language models are employed to optimally parse an audio stream into a series of discrete words. interestingly, the trend in that field, starting with bahl et al. in  <dig>  <cit> , has increasingly been away from the sole use of mle and toward an alternative approach very similar to that prescribed by equation  <dig> known as global discriminative training  <cit>  or conditional maximum likelihood  <cit> . the problem also appears in a slightly different form in the related field of statistical natural language parsing, in which it has been suggested that global methods for optimizing competing stochastic grammar models may improve the accuracy of systems at the level of whole-sentence parses  <cit> . maximum discrimination hmms have already been applied successfully to problems in the realm of biological sequence analysis  <cit> , though their use in gene finding has apparently not yet seen widespread adoption. to our knowledge, the only gene finder reported to use discriminative training is hmmgene  <cit> , a gene finder based on a non-generalized hmm.

in light of these considerations, it is worth contemplating the possible gains in gene finder accuracy that might be obtained through the use of some form of discriminative training applied to a ghmm – that is, training aimed more directly at optimizing the ability of the gene finder to discriminate between exons and non-exons, thereby improving the expected accuracy of the gene finder's predictions. anecdotal evidence already suggests that investigation of such methods may indeed be fruitful, as the process of manual tuning of ghmm parameters  after mle training is commonly acknowledged by those with experience training ghmm-based gene finders . the practice of performing such tuning on the training set, especially when done iteratively, can be viewed as a manual form of gradient ascent optimization using the percentages of correctly predicted nucleotides, exons, and whole genes as surrogates for the Σ∈t p term in equation  <dig> 

we therefore decided to investigate the use of a simple form of global discriminative training for gene-finding. we did this by building a rudimentary gradient ascent optimizer and applying it to a subset of the model parameters for our ghmm-based gene finder, tigrscan, as described in the methods.

RESULTS
maximum likelihood versus discriminative training
results for arabidopsis thaliana are shown in table  <dig> and those for aspergillus fumigatus are shown in table  <dig>  the two methods being compared are maximum likelihood estimation  versus maximum likelihood followed by gradient ascent parameter estimation .

grape = gradient ascent parameter estimation, mle = maximum likelihood estimation only. cv=cross validation, t = training set, h = 1000-gene hold-out  set. cv in the train column means training on  <dig> genes from t. cv in test column means testing on  <dig> genes from t. in rows with a cv in either column, numbers are averages from  <dig> runs. nucacc = nucleotide accuracy, exonf = exon f score, genesn = gene sensitivity. f = 2snsp/ for sn = sensitivity and sp = specificity. cv averages are reported ± sd.

see table  <dig> for legend.

the train column indicates whether training  was performed on the entire training set  or on separate 800-gene cross-validation partitions . the test column indicates whether accuracy was measured on the full training set , on one-fifth of the training set , or on the unseen data . we will consider the evaluation on h to be the most reliable measure of gene finder accuracy. for any row containing a cv, we report the average of five runs, where each run used a different 800-gene subset of the training data for parameter estimation.

both tables give compelling evidence for the value of gradient ascent training, as shown in figure  <dig>  in arabidopsis, gradient ascent applied to the full training set improved over the mle method from 71% to 81% at the level of exons and 33% to 48% at the level of whole genes. in aspergillus the improvement was even more dramatic: 30% to 51% at the exon level and 18% to 31% for whole genes. a gain of 4% nucleotide accuracy was measured for both organisms.

data partitioning and cross validation
a tangible improvement was still seen when a cross-validation design was used to split the training set so as to separate the data used for maximum likelihood estimation  and subsequent gradient ascent . however, results from both organisms suggest that this separation did not improve the accuracy of the gene finder, as shown in figure  <dig>  indeed, on arabidopsis, gradient ascent training produced greater gains in accuracy when performed on the entire training set rather than using the cross-validation structure, while on aspergillus the improvement due to using a cross-validation structure was either small , zero , or negative . thus, the recommended training protocol would be to apply mle to the entire training set followed by gradient ascent on the full training set as well.

although use of a cross-validation structure to split the training set for the twin purposes of maximum likelihood estimation of ~ <dig>  parameters and gradient ascent refinement of  <dig> parameters is therefore not justified , cross-validation does seem to have some value in terms of predicting how well the gene finder will perform on unseen data, as suggested by figure  <dig> 

on both genomes and at all levels , accuracy measurements obtained through cross-validation were closer to the accuracy measured on unseen data than were the measurements taken from the full training set, as we expected. this was true both with and without gradient ascent, though when gradient ascent was applied, even the cross-validation results were slightly inflated. the latter observation is presumably attributable to the "peeking" that was permitted , whereby the gradient ascent procedure received feedback from the  <dig> evaluation genes held out from the training set, t. this suggests that estimating even small numbers of parameters  from the test set can artificially inflate accuracy measurements on that set.

discussion
the results presented above provide a clear demonstration that independent maximum likelihood estimation of submodel parameters is sufficiently neglectful of global ghmm behavior as to compromise gene finder accuracy. even such a crude method as our 29-parameter gradient ascent procedure proved to be effective at significantly improving accuracy over that achievable by simple mle training. the potential for more sophisticated global discriminative training methods to produce even greater improvements is surely worthy of investigation.

it is interesting to observe that the natural language processing and speech recognition communities, from whom hmm-based methods were originally borrowed for use in bioinformatics, have been moving toward global discriminative training methods for some time. the two most popular forms of discriminative training for speech recognition are maximum mutual information  and minimum classification error . both methods can be implemented using an iterative gradient ascent/descent algorithm. our approach is most similar in spirit to that of mce.

in the case of "pure"  hmms, expectation-maximization  update formulas have been derived for both mmi and mce. these formulas allow model parameters to be updated in an axis-oblique  manner; i.e., multiple parameters can be adjusted simultaneously, so that the optimizer is less constrained in following the direction of steepest gradient in parameter space. this may reduce the number of steps required for convergence. indeed, more rapid convergence  has been cited as a concrete advantage of these em-style formulations over more generalized gradient ascent methods  <cit> . however, em-style approaches to the discriminative training problem for hmms have typically involved a number of simplifying assumptions and/or heuristics, thereby voiding formal assurances of optimality . furthermore, as with more generalized gradient ascent procedures, em often tends to find only a local optimum rather than a global one  <cit> .

in the case of ghmm-based gene finders, the advantages of em over a generalized gradient ascent procedure may indeed be rather slim. the very flexibility which we find attractive in ghmms can be expected to complicate the derivation of such em-like update formulas for arbitrary ghmm-based gene finders, likely requiring additional assumptions and approximations that would further compromise the optimality of the em procedure. it was for this reason that we decided to employ a more generalized gradient ascent method for the present study. a rudimentary gradient ascent optimizer is simple to implement, and the use of prediction accuracy as an objective function affords great convenience in approximating Σ∈tp. although p can be more directly computed using a modified forward algorithm  <cit> , to do so would in theory be no more efficient than running the full gene finder, since the asymptotic run times of the forward and viterbi algorithms for ghmms are equivalent. nevertheless, inasmuch as the forward algorithm provides a more direct approximation of p, its use for this purpose is worthy of investigation.

there are a number of other variations and enhancements which we are at present contemplating for our discriminative trainer. one of these involves the joint training of pairs of submodels in the ghmm using a maximum discrimination criterion rather than the usual one based on maximum likelihood. although such an approach would not in itself directly attend to the global optimality of the ghmm , it would at least seem to offer a promising direction for improving our existing optimizer and may be feasible without increasing the computational cost beyond what is practical.

for the present, we feel confident in making the recommendation that others tasked with the training of ghmm gene finders consider applying an automated gradient ascent procedure like that described here as a more systematic alternative to manual tuning of parameters following maximum likelihood training of individual submodels. beyond the obvious advantage of likely improving gene finder accuracy, such an automated method may offer some degree of reproducibility  and uniformity for the purposes of comparing gene finders and gene finding algorithms. in addition, we urge those practicing manual tuning on their final "test" set to consider that their reported accuracy results may well be inflated as a result of "peeking" at the test set before the final evaluation – a practice that has been criticized in the field of machine learning . that significant inflation was seen in our studies as a result of tuning only  <dig> of the ~ <dig>  ghmm parameters on the 200-gene "test" set suggests that the phenomenon may conceivably occur to some degree even when an automated procedure is not employed.

finally, we would like to make note of an unfortunate consequence of discriminative training of hmms for biological sequence analysis, namely, that while the resulting models may possess improved ability for discrimination and therefore greater utility for specific tasks such as gene prediction, their suitability as representative models of biological knowledge  may well be reduced relative to models induced with simple mle techniques. indeed, some authors in the field of speech recognition  have noted that more accurate discrimination can sometimes be obtained by relaxing sum-to-one constraints for probability distributions, thereby permitting the gradient ascent procedure to automatically discover appropriate weightings between states or inputs. this is reminiscent of the exon "optimism" parameter which we employ and which seems to have no principled justification . thus, despite the apparent value of discriminative training in improving gene finder accuracy, our ability to extract biological knowledge by inspecting the parameters of a gene finder trained in this way may be somewhat hindered. for the present, this does not seem to be of great practical significance, but it is a consideration worthy at least of mention.

CONCLUSIONS
we have shown that discriminative training for ghmm-based gene finders is feasible using a rudimentary gradient ascent approach, and have briefly explored the relation between this method and the em-like techniques which have been proposed in the field of speech recognition. our experiments show that the gradient ascent method can result in a gene finder with substantially greater prediction accuracy. it is our hope that even greater gains in accuracy will result from extension and refinement of discriminative training techniques applied to ghmm-based gene finders.

