BACKGROUND
one important goal in genomics is to determine the genetic differences among individuals and to understand their relationships to the phenotypic differences within a species, such as human beings. these variations consist of single nucleotide polymorphisms  and structural variations  including short insertions/deletions  and other more complex ones such as duplications and translocations. because of the efficiency of genotyping methods and the central role they play in the genome-wide association studies, snps are currently the best catalogued and studied human genetic variations. ubiquitous 1-bp indels, expansions of simple repeats and chromosomal anomalies have long been observed and acknowledged as the genetic bases for some human diseases  <cit> . except for these old discoveries, however, indels and svs have been much less studied due to their wide size range, the multitude in their types, and the lack of an efficient genotyping method. after several recent studies, however, their genetic significance starts to be appreciated: not only do they exist in large numbers in the human populations, they may also have a more significant impact on phenotypic variation than snps  <cit> .

the microarray technology, array cgh, has been widely used to detect copy number variants , a type of sv, with kilo-bases resolutions  <cit> . the advancement in high throughput sequencing technologies has enabled a new set of comparative approaches for cnv calling, such as the read-depth analysis  <cit> , which computes the read coverage of different genomic regions, the read pair analysis, which focuses on cases where the distance between the two ends of a reads deviates more than expected when they are mapped back to the reference  <cit> . accompanying the advancement of these experimental approaches, different computational methods for sv detection and their breakpoint refinement have also been developed  <cit> .

because indels/svs come in various sizes, there is an additional aspect--the size coverage--to their detection. the aforementioned methods only partially address all the requirements of indel/sv detection to various degrees. for sequence insertions and deletions, indels/svs are conventionally defined as micro-svs of 1- <dig> bp and large ones over  <dig> kb, respectively. in the following text, wherever the context is clear we use sv as the encompassing term, subsuming small indels. due to methodological limitations, svs of middle lengths have only been minimally, if not at all, studied. indeed, over the full spectrum of the sv size, only several small size spans are covered by current methods . moreover, sv detection approaches described above  cannot accurately locate the breakpoints of the sv events, nor can they reveal the actual sequence content of insertions. such information can only be gained via the direct analysis of the read sequences, instead of based on the statistics of the mappings of such reads.

here we report the split-read analysis, a sequence-based method that detects svs through direct analysis of the mapping information of how high-throughput sequencing reads are aligned to the reference genome. using alignment of read sequences to reference genomes with gaps, the method allows the precise identification of svs covered by such reads. building our method directly upon blat, a well-established sequence alignment program, we take advantage of the speed and the sensitivity of this popular sequence-to-genome alignment tool. however, more importantly, by considering both the sequencing and mapping errors in our assessment strategy to score each initial sv call, our method also takes into account the sequencing error model , and distinguishes the different confidence levels in detecting different svs based on the characteristics of supporting reads. compared with the read-depth and the read-pair analyses, our sequence-based method can not only pinpoint the breakpoints of sv events, but also reveal the actual sequence content of insertions. the split-read analysis has another advantage--it can cover the whole size spectrum for deletions . we expect our method to be more useful in the future as the sequence reads become longer.

due to both experimental and computational limitations, there are biases on multiple levels in the call sets generated by all current sv identification methods. in addition to their significantly more restricted size range of identifiable insertions than that of deletions, all current sv identification methods are sensitive to svs of different length , and as a result studies using them have reported different numbers of svs. one study using the read-pair method reported  <dig> svs over  <dig> kb in a sampled genome  <cit> , while another using the same approach but with a different molecular construct reported  <dig> and  <dig> svs over  <dig> kb in two tested genomes  <cit> . in a study of whole-genome sequencing and assembly,  <dig>  indels were identified in a diploid human genome  <cit> . currently it is not known how many svs, small or large, are in an individual human genome. using empirical error models estimated from sequencing experiments to simulate high-throughput sequencing reads, we could not only parameterize our split-read method, but also, more importantly, quantify both false positive and false negative rates. knowing these error rates enables us to estimate the total number of svs of a given length in a human genome.

RESULTS
we have developed the split-read identification, calibrated , a sequence-based method for detecting structural variants . it maps reads to the reference genome with gapped alignment and scores these mappings with consideration for sequencing and alignment errors. sric pinpoints exact sv breakpoints, reveals the sequence content of insertions, and covers the whole size spectrum for deletions. simulation is used to calibrate sric, allowing unbiased estimation of the sensitivity and proportion of svs across different length-scales.

analysis of the simulated sequence data
for sequencing simulations, instead of using the whole human genome, we use the diploid human chromosome  <dig> , which counts for 1% of the human genome but has a repeat content and a gene density both representative of the whole genome, to save computational processing time. to keep the local sequence environment of indels as found in a genome, we use indels identified in venter's genome  <cit>  in our sequencing simulation .

determining thresholds used in the analysis
three thresholds are used in our split-read analysis: tr, the threshold on the ratio of the score of the best alignment to that of the second best as a measure of the uniqueness of the read, tn, the threshold on the number of supportive reads for 1-bp svs, and tc, the threshold on the maximum centeredness  for large svs.

to determine the score ratio threshold tr for the alignment preprocessing, we simulate ~5× sequence coverage that gives ~ <dig>  million  <dig> single-end 400-bp reads and then identify svs using different values for the score ratio threshold tr  while keeping the other two parameters fixed . the percentage of true positives, false negatives, and false positives of deletions and insertions identified at different tr values are plotted in figure 2a-b. there is a small decrease in the number of identified svs when tr is increased from  <dig>  to  <dig> . the further increases in tr from  <dig>  to  <dig>  only cause negligible changes to the sv identification results. over all, the sr method is not very sensitive to tr when it is in the range of  <dig>  and  <dig> . this insensitivity is a result of unique mapping to the reference genome of most  <dig> reads, which are much longer than those produced by other next-generation sequencing technologies.

two thresholds, tn and tc, are used for the initial sv calls . we vary the value of one of these two thresholds while fix the other to determine how they affect the accuracy and the sensitivity of the split-read method. using the simulated sequence set with the ~5× coverage, we make sv calls with tn =  <dig>   <dig>  ...,  <dig> while tc =  <dig>  and tc =  <dig> ,  <dig> , ...,  <dig>  while tn =  <dig>  count the true positive and the false positive calls, and calculate the percentage of true positives, false negatives, and false positives at each threshold combination. the results of this performance analysis as depicted in figure 2c-f make it clear the effects that theses two thresholds have on the sv identification show a dichotomous dependency on the sv length. while tn affects the identification of short svs, tc biases that of longer ones. in practice, we use the sequencing depth for tn  and set tc to  <dig> . it is also clear that the method has different sensitivities in the size range of indels that it can detect: it is less sensitive to 1-bp indels because  <dig> sequencing is prone to over- or under-call bases in homopolymers and thus more a stringent threshold is needed to lower the number of 1-bp false positives.

assessing how the read length affects the performance
we first assess how the read length affects the sv identification by simulating single-end reads of  <dig>   <dig>   <dig>   <dig>  and  <dig> bp long. for each read length, we generate sequences with ~5× coverage and analyze five sequence sets with the same set of method parameters . we compare the true svs and the ones that we identified using the split-read analysis. the numbers of true and false positives of deletions and insertions identified using reads of different lengths are plotted in figure 3a-b.

the general trend, which is expected and depicted in the figure, is that the sv identification is improved with longer reads. with 50-bp reads, the sv identification is the worst with low sensitivity for both short and long deletions. because the length of discoverable insertions is capped by the read length, it is not surprising that at this read length none of the insertions of 20-bp and longer are found. when the read length is increased to  <dig> bp and longer, the sensitivity and the positive predictive value almost double for longer svs. for deletions, 200-, 400-, and 800-bp reads seems to give comparable performance, and longer reads only bring marginal improvements to the results. the choice of read length for insertions identification is, however, a rather open-end question, as longer reads will always enable better identification of longer insertions.

assessing the effects of sequence coverage on sv calls
we first simulate ~20× sequence coverage that gives ~ <dig>  million  <dig> single-end 400-bp reads. to assess how the sequencing depth affects the sv calls by the split-read analysis, we also simulate ~1×, 5×, 10×, and 15× sequencing coverage by down-sampling the 20× sequence set with appropriate numbers of reads . we then identify svs using default parameters . the numbers of true and false positives of deletions and insertions identified at different sequencing coverage are plotted in figure 3c-d. the general trend is that sv identification is improved with higher coverage but with diminishing returns. comparing to the low coverage at 1×, there is a marked improvement to sv identification at higher coverage.

notes:

 <dig>  we use  <dig> , <dig> bp as the size of human chromosome  <dig> for calculating the sequence coverage.

 <dig>  for 1~15× target sequence coverage, we sample from the used sequences in the 20×-coverage dataset.

to assess how sequencing coverage affects the sensitivity of our method, we determine the maximum sensitivity achievable in each simulated sequence set. the number of 'seeable' true svs is affected by several factors, including the sequencing depth, the read mapping quality/uniqueness, and the minimum number of supportive reads required for an sv call. after the initial alignment processing to remove the mapping ambiguity, we count the number of supportive reads for the true svs of different lengths and plot the number of true svs with one and two or more supportive reads at different sequencing depth .

the sequencing depth has the most significant effect on short svs. at 1× coverage, ~ <dig>  of true 1-bp deletions and insertions are supported by at least one read. when the coverage is increased to 2×, these numbers almost are doubled. as the coverage increases, the percentage of supported true svs also increases but with a diminishing pace. 80~90% true svs are supported by at least one read at 5× to 20× coverage. one supportive read is the absolutely minimum requirement for an sv call. to reduce the false positives, we require at least two supportive reads for every sv call. this global threshold has a much more significant effect on the low-coverage sequence set than on the high-coverage one: while the percentage of true deletions with two or more supportive reads is about the same as that of true deletions with one supportive read at 1× coverage, there are very few true svs with only one supportive read at 10× or higher coverage.

performance assessment
several different approaches have been used to extensively evaluate the performance of our sric method . first, we compare sric with pindel, the only published method that can detect sv breakpoints on the nucleotide level. the comparison between the numbers of svs that these two methods can find in simulated datasets with the same sv placements shows sric has a significantly higher sensitivity than pindel at every length simulated, whether it is of deletions or insertions . second, we apply our split-read analysis to  <dig> genomic reads generated for two individuals  and calculate the positive predictive values at different thresholds on the number of supportive reads after validating deletion calls using two experimental methods, respectively--array capture followed by sequencing and trio-array comparative genomic hybridization . the experimental result shows for the type of svs under consideration sric can achieve 70-80% call accuracy .

notes:

 <dig>   <dig> ×  <dig> reads for a ceu individual  from the  <dig> genomes project are used to make the sr deletion calls.

 <dig>  only deletions longer than  <dig> bp are selected for array capture validation.

 <dig>  tn, is threshold on the number of supportive reads.

 <dig>  positive predictive value = true positive/positive.

notes:

 <dig>  only deletions longer than  <dig> bp called for an yri individual  from the  <dig> genomes project are selected  for the trio-array cgh validation. due to the data usage restriction, only validation results for deletions in chromosome  <dig> are used.

 <dig>  not every validation test yields definite result. inconclusive results are excluded from this table.

 <dig>  tn, threshold on the number of supportive reads.

 <dig>  positive predictive value = true positive/positive.

analysis of the  <dig> genomes project data
a major sequencing project, the  <dig> genomes project, has been launched to resequence the genomes of at least a thousand people from around the world using the new sequencing technologies to produce the most detailed map of human genetic variation for disease studies. as a proof of concept, we apply our split-read analysis to a set of  <dig> sequence reads generated by the  <dig> genomes project for one individual.

the genome of an individual  from the yoruba in ibadan, nigeria has been sequenced using the  <dig> single-end method to ~5× sequence coverage. the sequencing generated ~ <dig> million sequence reads, of ~ <dig> × <dig> bp in total. mapping of the sequence reads  took ~ <dig> hours of the wall time with exclusive access to  <dig> dell poweredge  <dig> nodes  of a linux cluster. applying our sr method, we identify  <dig>  deletions ranging from  <dig> bp to ~ <dig> kb and  <dig>  insertions ranging from  <dig> bp to  <dig> bp on the chromosome  <dig>  compared with  <dig> validated insertions in chromosome  <dig> from dbsnp ,  <dig> in both sets are at exactly the same genomic locations, which indicates a sensitivity of ~60% for validated insertions in dbsnp. this defines a lower bound on sensitivity as different genomic dna sources are involved. the simulation used to compare the numbers of insertion and deletion calls  enables us to determine the positive predictive values and the sensitivities of our sr method for indels identified in a sequence set at 5× coverage and subsequently estimate using equation  the total numbers of deletions and insertions of lengths in continuous ranges separately on chromosome  <dig> . we estimate there are  <dig>  svs in chromosome  <dig> and extrapolate to  <dig>  svs in the whole genome of this individual.

notes:

 <dig>  the true number of large svs will be underestimated. however, this will have only a marginal effect the magnitude of the estimation of the total number of svs in a large chromosome or in the whole genome.

 <dig>  the true number of svs in the whole genome is estimated by extrapolation of the corrected number of svs in chromosome  <dig> by the fold increase in size from chromosome  <dig> to the whole genome.

discussion
mapping reads to the reference genome
the size of the deletions covered by the split-reads can range up to tens of thousands of bases, and this makes blat well suited for mapping such reads back to the genome, since it not only allows small gaps and mismatches within the alignment like many other alignment tools, but also takes into account large gaps due to its initial purpose to handle introns in rna/dna alignments  <cit> . in short, unlike the alignment results from tools such as blast which will generate two distinct partial alignments for a split-read covering a large deletion event, the alignment results of blat can directly reveal the deletion event and its up- and down-stream alignments at the same time. recently a new algorithm, burrows-wheeler aligner's smith-waterman alignment , has been designed and implemented to align with gaps long reads such as  <dig> reads  to the reference genome with higher accuracy and a faster speed than blat  <cit> . however, blat should be used to align  <dig> paired-end reads, because currently the average  <dig> read length is less than  <dig> bp and thus, the majority of sequences on both ends will be shorter than  <dig> bp.

for the non-split reads, however, using blat would be unnecessarily time-consuming, because their alignment results would usually only contain  a small number of mismatches. bowtie, a recently developed alignment tool, incorporates the burrows-wheeler transform technique to index and search the genome in a fast and memory-efficient manner, and is an immediate candidate for processing such reads  <cit> .

the two-tiered alignment cascade is used to expedite the step of aligning reads to the reference genome. the first assortment step effectively fractions the sequence reads into two subsets: ones that can be uniquely mapped and ones that cannot. by limiting the gapped alignment of the reads in the former subset to their associated chromosomes, the tiered mapping approach removes the unnecessary mapping attempts and thus speeds up the alignment step. the speed gain is clearly related to the size ratio of the two read subsets: the more uniquely mappable reads, the bigger the speed gain. because it is assessed by their 35-bp end tags, the genomic uniqueness of the reads is limited to the unique mappability of the 35-mers to the human genome. it has been estimated that  <dig> % of the genome is uniquely mappable using 30-bp sequence tags. since the human genome consists of  <dig> chromosomes, it is natural to use them as the bins for end tag assortment. it is, however, conceivable to fraction the human genome into large  fragments with small  overlaps and use them as the assortment bins to further restrict the search space of the subsequent blat genomic mapping of the reads whose end tags are uniquely mapped.

parameterization of the split-read analysis
five parameters are intrinsic to our split-read analysis alone: the alignment score ratio threshold tr, the threshold on the number of supportive reads for 1-bp svs tn, the threshold on the maximum centeredness for large svs tc, the minimum number of supportive reads for every sv identification nmin, and the exponential decay parameter λ. for sequence reads that are mapped to multiple genomic locations, we use tr to control on what level of distinctiveness such reads can be used for the sv identification. a higher value of tr lowers the overall mapping ambiguity and thus reduces the number of false positives. this will, however, disqualify more correct alignments and in turn increase the number of false negatives. small and large false sv calls have different origins: the former result from sequencing errors that under- or over-call bases while the later are mostly generated by misalignments. to count for such distinct error origins, two different threshold functions, separately parameterized with tn and tc using the same exponential base function, are used to make sv calls. λ controls how fast the threshold changes between 1-bp and large svs and it is set to  <dig> in all of our split-read analyses. we require that there should be at least two supportive reads for every sv identified regardless of its length. this global threshold  dramatically reduces the false positive sv calls.

CONCLUSIONS
directly building our method upon blat, we take advantage of the speed and the sensitivity of this popular sequence-to-genome alignment tool. however, more importantly, we designed an assessment strategy to score each initial indel/sv call that takes into account both the sequencing and mapping errors. compared with the existing read-depth and read-pair analyses, our sequence-based method can pinpoint the exact breakpoints of indel/sv events, reveal the actual sequence content of insertions, and cover the whole size spectrum for deletions. we thoroughly benchmarked and validated our sric method against the best available methods for detecting structural variants at relevant resolutions by using several different approaches to extensively evaluate the performance of our method. we illustrate the characteristics of our split-read method by applying it to both synthetic and experimental data sets. with the advent of the third-generation sequencing technologies that produce longer reads, we believe the split-read approach presented here can make a significant contribution to the study of indels/svs.

