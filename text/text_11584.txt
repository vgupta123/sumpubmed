BACKGROUND
humans are diploid, inheriting a pair of each chromosome, one from each parent. the two copies of each chromosome are highly homologous to each other. with most current technologies, heterozygous sites are sampled independently from both chromosomes, and the data appears as a collection of heterozygous sites. see figure 1b. the goal of haplotype phasing is to separate the maternal and paternal chromosomes, by linking alleles at heterozygous sites.

haplotyping is an important component of genetic analysis. it improves the power of genetic association, and is useful in inferring evolutionary scenarios, historical recombination events, and detecting cis-regulatory events  <cit> . given the importance of the problem, a variety of computational and experimental techniques have been developed to phase chromosomes, and we discuss a few here to put our work in context. population-based inference exploits linkage disequilibrium to identify likely phasings. consider a population of individuals sampled at the first two sites in figure  <dig>  if a large number of individuals carry the homozygous genotypes , then we infer that the haplotype at is common in the population, and the phasing . however, historical recombination events can reduce or eliminate this linkage, and reliable phasing can only be achieved over short regions, 3050kb on the average  <cit> . while phasing is difficult with populations, it is almost trivial if parental information is known  <cit> . in family-based haplotyping, if the mother and the father of the individual in figure  <dig> had genotypes  and , then the individual shows  only by inheriting at from the mother and ca from the father. given that only a few crossovers occur per meiosis on each chromosome, a small sampling of homozygous alleles in the parents is sufficient to phase entire chromosomes. while family-based haplotyping is powerful, it is not always feasible and requires additional genotyping or sequencing of parents. also, family-based techniques will not work for haplotyping in a more general context, where it can also refer to separating strains of microbes and pooled samples from other organisms. recently, chromosome micro-dissection techniques have also been developed to amplify genomic dna from single molecule templates. the principle is as follows: micro-dissect and dilute dna, so that each sample contains only one chromosomal fragment; perform whole genome amplification, followed by genotyping/sequencing. homozygous sequenced alleles originate from a single chromosome and can be linked  <cit> . while this method works for connecting distal heterozygous sites, current techniques provide only a very sparse phasing-about 24k heterozygous snps in ma et al.,  <dig>  <cit> . the approach must be used in conjunction with other techniques to get meaningful results.

the method we discuss here, haplotype assembly, is very attractive given the proliferation of inexpensive sequencing techniques  <cit>  that have the throughput to sequencing entire human genomes.see figure 1a-b. each sequenced fragment is sampled from one of the chromosomes and mapped to the reference sequence. multiple alleles sampled by one fragment must all be from the same chromosome. therefore, the fragment -a-c- links allele a  with allele c . if a sufficiently large number of informative fragments  are available, long haplotypes can be generated by chaining the links together. haplotype assembly was proposed some time ago  <cit> , but the data for individual genomes is only now becoming available. the first sequence of a genomic individual, j. craig venter,  was produced using sanger sequencing. the sequencing was paired-end, and we modify notation slightly to say that sanger sequencing generated ~ <dig> bp per read, with two subreads linked 2kbp-150kbp apart, and each base sampled an average of 6×. this change of notation allows us to discuss strobe sequencing later, where each read can have arbitrary k ≥  <dig> subreads. the phasing was quite effective, with a ‘median’ haplotype  of length 270kbp  <cit> . specialized error correction algorithms were used to generate highly accurate haplotypes  <cit> . sanger sequencing provides long and accurate reads but lower throughput and expensive library preparation making it less cost-effective. by contrast, newer technologies allow for massively parallel sequencing, but have much shorter reads, and are more error prone. while there has been ongoing work on haplotype assembly  <cit> , much of it has focused on one aspect of the problem, as explained below.

we begin by formalizing the problem. aligned fragments define a snp-graph in the individual, as shown in figure 1b. each heterozygous location corresponds to a node. when a fragment overlaps two sites, we add an edge to the corresponding nodes. it is easy to see that two sites can be phased if and only if they are connected in the snp-graph. therefore the length of the haplotypes depend upon the size of connected components, while the accuracy of haplotypes depends upon the error in sequencing, depth of coverage, and computational algorithms for error correction. the quality of a haplotype is measured by metrics for length and accuracy.

metrics for haplotype length
given the snp-graph, we use three different metrics  to measure the median length of assembled haplotypes: s <dig>  n <dig>  and an <dig>  related to the size , span , and adjusted span of the contigs respectively. see figure 1d. recall that the haplotyping is limited to connected components in the snp-graph. the length of a haplotype can be described in terms of its size , or span . as the connected components can interleave, we define the adjusted-span of a component as the span times the fraction of sites that lie in the contig. in figure 1d, we observed connected components of size  <dig> and  <dig> with spans 12kbp, and 11kbp, respectively. the adjusted spans are given by, , and .

we define s <dig>  to be the size  such that 50% of all sites are in contigs of size  s <dig> , or greater. as snps display a ‘clumping’ property, s <dig> might inflate the haplotype size. on the other hand, n <dig> tends to inflate the haplotype size when there are contigs that span a long distance, but do not phase many snps. the an <dig>  or adjusted n <dig> metric considers both span, and size. it is defined as the adjusted span s.t. 50% of the snps are in contigs with an adjusted span an <dig> or larger. we will primarily use the an <dig> metric. however, our results and trends remain the same for any metric.

metrics for haplotype accuracy
erroneous base-calls corrupt the accuracy of assembled haplotypes. in simulations, where the reference is known, we can measure the accuracy of the reconstructed haplotype as the haplotype edit rate , equal to the fraction of incorrectly called alleles. a second reason for incorrect haplotyping is that weak links might cause a ‘switch’, a crossover from one true haplotype to the other. this could potentially cause her to be large, even though a single crossover can correct the haplotypes. see additional file  <dig>  therefore, we define another metric switch error rate  which is the number of crossovers  in the assembled haplotypes to match the correct haplotype.

strobe sequencing and haplotype assembly
much of the current computational research on haplotype assembly focuses on improving haplotype accuracy  <cit> . until now, the length of the haplotypes depended upon the specific technological parameters, and was assumed to be determined by the technology. with recent developments in sequencing, the user has the ability to select different parameters for an experiment. our paper investigates the relationship of sequencing parameters on the haplotype length.

of particular relevance is the upcoming technology of strobe sequencing, available from pacific bio-sciences  <cit> . in this technology, a genomic fragment is sequenced in a strobed fashion with sub-reads of pre-determined lengths separated by user-determined intervals . in figure 1a, we see a number of fragments with k =  <dig> strobes, and one with  <dig> strobes. paired-end sequencing is analogous to strobe sequencing with k =  <dig>  however it differs in that the sequenced reads must be from terminal portions of an insert which leads to reduced flexibility in selecting advance lengths. a key result of our analysis is that the choice of advance lengths can change the haplotype length by an order of magnitude for the same amount of sequencing. in fact, the best results are obtained by a complex distribution f on advance lengths. besides k and f we also study the impact of other parameters on haplotype length. these include  l, the number of bp sequenced per fragment; l = ∑ili, where li is the length of the i-th subread;  n: number of fragments sequenced;  a, the maximum insert size allowed. note that because we usually fix l, the advance lengths are related to a. for example, the maximum advance length for k =  <dig> strobes is a – l. in addition, we usually work with coverage c = nl/g, which gives the number of times each bp is sampled, on average. to obtain our results, we developed a simulator that generates reads according to specific technological parameters, and constructs connected components of the snp-graph. the software is available upon request from the authors.

while the focus of our analysis is on designing experiments for haplotype length, we also touch upon haplotype accuracy. we use a simulator provided by pacific biosciences to generate strobe sequence data based on an error model having high rates  of insertions and deletions relative to miscall errors  <cit> . we use our previously designed tools to phase in the presence of error. our results indicate that long and accurate haplotyping is feasible even with technology having such high error rates.

RESULTS
singleton strobes
assuming that the cost is proportional to the number of nucleotides sequenced, we compare all designs after fixing coverage c. a back-of-the-envelope calculation suggests that with long read lengths , we should be able to link all snps together, given that the average pair of snps is 1kbp apart. the intuition is wrong because  a poisson process for snps implies an exponential distribution of inter-snp distance in a population- hence a long tail; and,  a single individual is heterozygous at only a subset of the snps. indeed, the distribution of inter-snp distances in huref is more consistent with the power-law  with a long tail of large inter-snp distances . therefore, we only reach an an50=48kbp even with l = 5kbp and c = 20× . similar results can be obtained with mate pair sequencing  at much lower coverage. the linking together of distant snps through subread probes is indeed the most significant parameter determining haplotype length.

advance lengths for paired end sequencing 
we fixed the read-length l = 900bp as it is within the current mean length distribution reported by pacific biosciences  <cit> . for l = 900bp, c = 20×, and k =  <dig> subreads, choosing fixed insert sizes a <dig> = 3kbp, a <dig> = 9kbp results in low an <dig> values  <dig> kbp and  <dig> kbp, respectively. however, a simple 50- <dig> mix of the two increases this by an order of magnitude an50=54kbp. clearly, variation in insert size, and thus advance length, is important. however, it is not immediately obvious what distribution of advance lengths will give the highest an <dig>  for example, we could consider uniformly varying advances from a minimum to a maximum length, or follow the library mix used for sequence assembly dominated by smaller advance lengths to form contigs, mixed with a smaller number of large advances to create scaffolds. to search efficiently over a large space of distributions, we used the 2-parameter β-distribution. for parameters , and maximum insert size a, define the p.d.f as   

where the denominator is a normalizing constant. different choices of α, β provide a large range of distributions for f  <cit> . for example, larger α values correspond to a negative skew , while larger β correspond to a more positive skew. when α = β, the distribution is symmetric. we systematically explored all α, β values in the interval  to identify the optimal choice of parameters.

surprisingly, the distributions with the highest an <dig> had α ∈  and β ∈ , and skewed heavily toward the longer clones. for c = 20×, l = 900bp, a = 9kbp,  = , we achieve an an50≃ 151kbp . even more surprising, distributions skewed toward smaller clone lengths  =  had the worst performance . uniform  = , and other symmetric distributions  show an intermediate performance. the bias is maintained at different values of coverage, maximum insert size, and other parameters. while there is a heavy bias towards longer clones, variation is important as well. for example, the distribution given by  =  shows an extreme skew towards longer clone lengths so that it almost mimics a delta function at 9kbp and gives an an <dig> of 45kbp. the trends do not change with a choice of other metrics s <dig>  n <dig> .

wasted reads: note that popular designs for sequence assembly emphasize short inserts  mixed with a few large clones for scaffolding. by contrast, haplotype assembly is improved by focusing on larger inserts and higher variation. figure 4a provides an illustration of the impact of different distributions of advance lengths on the connectivity of the snp-graph. a connected component with k vertices and m edges has m – k +  <dig> ‘waste’ edges, as only k –  <dig> ‘useful’ edges are needed to maintain connectivity. due to the clustering of snps, a design with larger number of short advances has more wasted edges compared to a design with long advances. as each useful edge connects two previously unconnected components, it has a large impact on haplotype lengths. we computed the number of useful edges for the two designs, fixing c = 20× and varying maximum insert, a. we observe that the number of useful edges is always larger in designs with a bias towards long advance lengths . for a = 5kbp, we see a 13% difference in useful edges between the two distributions.

the erdós-renyi theory describes the evolution of a random graph from isolated components to a single component, with increasing number of edges  <cit> . in our case, the edge probability in snp-graphs is not initially uniform due to the clustering of snps . by choosing designs with a bias towards longer advance lengths, we are essentially leveling out the probability of linking snp pairs irrespective of their distance, leading to improved connectivity.

other parameters
maximum insert size,a: in figure 5a, we plot maximum achieved an <dig>  maximum theoretical an <dig>  as a function of a. the achieved an <dig> increases with increasing a for the same amount of sequencing , indicating that the largest possible value of a should be chosen. interestingly, the sa optimized parameters  remain similar as a is increased .

coverage, c: the effect of coverage on an <dig> is analogous to increasing the edge probability, and we expect to see an increase in connectivity until saturation is reached. the plot in figure 5b shows this for a = 9000bp, l = 900bp, and sa optimized .

read length, l: once a, c are fixed the impact of read-length l is minimal. here, we assume that the subread is of minimal size  to permit accurate mapping. initial improvement is seen with increasing l as the same subread captures proximal snps. however, the effect saturates quickly.  values. again, the β-distribution stays similar with changes in l. 

number of strobes, k
besides flexibility in advance lengths, strobe sequencing allows the possibility of multiple strobes k. figure 1a provides a cartoon of strobe sequencing for k =  <dig> and k =  <dig>  to compare designs with different number of strobes, we fixed the subread lengths for each k to lk = l/k, keeping the total read-length constant. we also fixed the maximum insert size, a. recall from the paired-end results that longer sub-read lengths help cover the relatively high proportion of snps that are clustered close together. therefore, increasing number of strobes helps increase the variation in advance lengths against the penalty of smaller subreads.

optimal advance distribution for higher k
for a simulation with k strobes, we compute an optimal collection of  for  <dig> <i <k iteratively. thus, for k =  <dig>  a <dig> is randomly generated with , and a <dig> is randomly generated with . the strobed read is arranged as in figure 1a with a <dig> as the advance length between the subread <dig> and subread <dig>  and a <dig> as the advance length between subread <dig> and subread <dig>  a similar pattern is used for higher k. while we see an improvement for k =  <dig> and k =  <dig>  higher values of k do not help .

the optimal distribution always skewed towards longer advance lengths. the skew towards longer advance lengths was extremely strong, and consistent among the very first set of ’s chosen, corresponding to the advance length between to two furthest strobes. for the other set of ’s, there was still a skew towards the longer advance lengths; however, the skew was not as strong and the degree of the skew was much more varied. we conclude that for the shorter advance lengths among multiple strobes, the exact distribution does not have a strong effect, as long as it is skewed towards longer advance lengths.

regions with a high snp density
haplotype assembly is often applied to phase specific regions of interest. often, these regions are gene-rich, and have a high snp density. the hla region on chromosome  <dig>  contains genes encoding cell surface antigen presenting genes and many other genes involved in the immune system. diversity in this region is important for host defense against pathogens, and it has been implicated in susceptibility to diseases including diabetes, cancer, and various autoimmune disorders  <cit> . phasing of coding snps could provide critical structural information, motivating the development of haplotyping techniques specifically targeted to this region  <cit> . we specifically looked at the region from position chr6: <dig>  652k- <dig> k, using huref data. while increased coverage provides modest improvement, high gains in an <dig> are obtained by increasing a . at c = 10×, l = 900bp, a = 20kbp we span 80% of the region with  <dig> haplotypes.

a short note on haplotype accuracy
while our focus is on the feasibility of generating long haplotypes, accuracy is also an important consideration with next generation technologies that may have undesirable raw read error rates. we used our previously developed tools, hash, and hapcut  <cit>  to phase haplotypes while accounting for error. the pacific biosciences simulator was used to generate reads under realistic error models. the simulator takes a single parameter ε as input, reflective of the overall error rate. we chose ε ∈ { <dig> ,  <dig> ,  <dig> }. as our subreads are long, we assumed correct alignment of all reads .

many homozygous sites appear heterozygous due to missed base calls. for example, we observe 202k heterozygous sites at ε =  <dig>  in a region with  <dig> known snps. using a statistical test for filtering, only  <dig> of the erroneous sites remain, and none of the ‘true’ snps is eliminated. table  <dig> summarizes the false negative and false positive rates for ε ∈ { <dig> , <dig> , <dig> }, and c ∈ {10×, 15×}.

this table shows false positive rates  and false negative rates  when sites are filtered using the likelihood ratio with a cutoff at - <dig> 

for c = 10×, ε ∈ { <dig> ,  <dig> }, we were able to perfectly assemble the haplotypes. even with ε =  <dig> , we were able to assemble haplotypes with her=  <dig> %, ser= <dig> %. increasing coverage to c = 15×, we achieved her= <dig> %, ser= <dig> %. as more data becomes available, we will exploit the error characteristics and related base level quality values to further improve haplotyping accuracy.

CONCLUSIONS
in spite of a long history and success with sanger sequencing, the feasibility of assembling meaningful haplotypes with next generation sequencing has been questioned. here, we demonstrate that with a judicious choice of parameters and strobe sequencing, long  haplotypes can be effectively generated. the most important parameter appears to be the flexibility in choosing advance lengths, available with strobe sequencing. even with only k =  <dig> strobes, and coverage c = 10×, we can achieve long haplotypes. on the target hla region, we covered 80% of the region with  <dig> haplotypes.

surprisingly, the optimal design for haplotyping heavily favors longer advances, and the trend does not change with higher values of a, l, c, or number of strobes. here, we only provide a partial explanation, suggesting that the longer advances level the probability of all edges. a rigorous explanation based on extending the erdós renyi theory to the interval-like snp-graphs will be the focus of future efforts. other parameters influence haplotype lengths as well, and our results help determine the optimal values.

here, we use the ‘number of bp sequenced ’ as the “cost” of the design, and optimized parameters after fixing coverage. however, other cost factors might be reasonable. for example, it may be more expensive to generate reads with longer inserts. also, more biological sample is needed  with longer inserts, and that can be a limitation when sample is limited . our simulated annealing software for optimizing parameters can easily be modified to deal with a custom cost function.

finally, while haplotype assembly can generate long haplotypes, it is not yet capable of separating entire chromosomes. however, other techniques such as chromosome dissection and amplification can generate long scaffolds connecting distal sites. used in conjunction with haplotype assembly on strobe sequences, chromosome level haplotyping is indeed feasible, even without familial information.

