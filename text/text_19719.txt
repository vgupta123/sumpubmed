BACKGROUND
today's, and tomorrow's even greater, availability of sequence data provides unprecedented opportunities to understand evolutionary relations; however, the increasing wealth of data also poses challenges to computational methods for data analysis and, thereby also, to algorithm design. the number of sequences involved in an analysis may be very large, since a large number of species or a large gene family may be considered – some species harbor hundreds of members of some gene families. the ultimate goal in species tree construction is to obtain the tree of life, to the extent it exists. as the size of the phylogenies being reconstructed grows, the demand for long sequences increases, which often is satisfied by concatenation of genes. in other applications many trees have to be reconstructed. for instance, comparative genomics studies often involves constructing gene trees for all gene families in a number of genomes, i.e., often thousands of families. also bootstrapping, which commonly is used to obtain significance values for a single family, requires many reconstructions.

there are two major approaches to phylogenetic tree reconstruction; distance methods and character based methods . although this paper is concerned with tree reconstruction through distance methods, character based methods are many times the preferred approach. however, since most distance methods are several orders of magnitude faster than character based methods, distance methods are preferred when it comes to extensive evolutionary analysis.

in general, distance methods first estimate pairwise evolutionary distances of the species, represent them using a distance matrix, and, then, compute the tree, or attempt to compute the tree, that realizes the given distance matrix as well as possible. the neighbor joining algorithm   <cit>  is a distance method, running in time Θ, where n is the number of sequences, which due to its accuracy and speed has been embraced by the phylogenetic community. however, prior to running the distance method the distance matrix has to be computed from the sequences. although the distance matrix in theory can be computed in time o, where l is the sequence length, see  <cit> , the only practical algorithms require time Ω. therefore, the overall running time of tree reconstruction with nj is Ω. since the sequence length often is larger than the number of taxa, computing the distance matrix is the bottleneck. in this paper, we remove this bottleneck by presenting an algorithm which in practice has running time comparable to n.j.

there are various markov models of sequence evolution describing how sites evolve, typically, independently and identically from the root down toward the leaves. for example, kimura's two-parameter model   <cit>  distinguishes between two types of events: transitions which are changes within the purine  and pyrimidine  groups and transversions which are changes between the groups. the aim in distance estimation is to find the most likely  estimate of the actual number of mutational events given the number of observed events. for the kimura two-parameter model, this is done by counting the number of transitions and transversions between each pair of sequences and thereafter optimizing the likelihood function, using a closed formula, to attain the corrected distances. the straightforward way of counting the number of observed events between two sequences of length l takes Ω time. therefore, the straightforward algorithm of computing all pairwise distances between n sequences has running time Θ.

in this paper, a novel divide and conquer algorithm for computing the number of observed events is presented. the algorithm computes the same function and has the same asymptotic running time as the straightforward algorithm. in practice, however, it is significantly faster than phylip  <cit>  and paup  <cit> . we show on both simulated and real biological data how our algorithm speeds up the reconstruction using nj from a matter of many minutes and even hours to a matter of seconds. it is important to note that, since the computation of the distance matrix is a prerequisite for all distance methods, our algorithm provides an increase in speed for all distance methods, i.e., not only nj.

in addition, we present two new methods for handling, so called, ambiguity symbols, i.e., bases of uncertain identity. such symbols occur naturally in the form of single nucleotide polymorphisms  and also as a result of failure to resolve bases during sequencing. ambiguity symbols complicates matters in distance estimation and it is not obvious how to include them in the likelihood computations. we show on simulated data that our new methods for ambiguity symbols are significantly more accurate than earlier methods. this is, to the best of our knowledge, the first work which evaluates the accuracy of different ambiguity approaches.

RESULTS
a novel algorithm for computing the number of mutational events
in distance estimation, a specific model of sequence evolution is used to derive an estimate of the true mutational distance between two sequences from the number of observed mutational events. once the observed mutational events have been counted, the ml estimate of the true mutational distance is computed in constant time, either by using a closed correction formula or by using an iterative method for optimizing the likelihood function. our novel algorithm takes two dna sequences as input and counts the number of purine-transitions, pyrimidine-transitions, and transversions. these events are sufficient for computing the estimates with respect to the four most common models of sequence evolution: the jukes-cantor model  <cit> , kimura's two-parameter model  <cit> , the felsenstein- <dig> model  <cit> , and the tamura-nei model  <cit> .

our algorithm is based on an elaborate divide and conquer and bit-fiddling strategy, i.e., the problem is divided into subproblems which are solved and the solutions are combined using the bitwise representation and low-level tricks. it is important to note that our algorithm computes the number of observed events exactly. in other words, it solves the same computational problem, i.e., it computes exactly the same value as previous algorithms for computing the distance estimators; however, it does so significantly faster. in the remainder of this section, we show using both simulated and real biological data, that the speed of our algorithm, fastdist, outshines that of the distance estimation implemented in both phylip  <cit> and paup  <cit> . although this implies that fastdist is a useful tool it does not exclude the possibility that other implementations of the naive approach can be faster. we therefore implemented our own optimized version of the naive approach and compared also its running time with fastdist.

running time on simulated data – the hidden factor
the computational complexity of our distance estimation algorithm is o, where n is the number of species and l the sequence length. this is the same complexity as that of the algorithm in the phylip package and that of our implementation of the naive approach. however, the differences between the hidden constant in the big-o expressions of the methods are very significant. to estimate the ratio between the hidden constants, we ran the programs ,  <dig>  ghz,  <dig> mb cache per chip,  <dig> gb dual channel ram,  <dig> mhz front side bus.) on datasets of  <dig> taxa and varied the sequences length. the test results, which are displayed in table  <dig>  show that fastdist is a factor  <dig> – <dig>  times faster than our implementation of the naive approach and a factor 180– <dig> times faster than phylip, depending on whether reading the sequences is included in the comparison. with respect to paup our algorithm is about  <dig> times faster on sequences of length  <dig> , about  <dig> times faster on sequences of length  <dig> , and more than  <dig> times faster on sequences of length l million. it turns out that paup adopts a preprocessing that has runtime complexity o . also notice that our own implementation of the naive algorithm is significantly faster than both phylip and paup.

comparing the running time o phylip s dnadist, paup, our optimized implementation of the naive approach, and the new algorithm fastdist. the test's are run on simulated data with  <dig> species. it should be noted that phylip could not be run on sequences of length  <dig> , <dig>  except for paup which uses the analytic formula, the programs computed the k2p distance with a globally fixed transition transversion ratio of  <dig>  reconstructing a tree of  <dig> taxa using nj takes no more than  <dig>  seconds. moreover, simply reading a file containing  <dig> sequences of length one million with the wc unix utility takes  <dig>  seconds.

running neighbor joining on a distance matrix of  <dig> taxa takes no more than  <dig>  seconds. therefore, even when a fairly moderate sequence length of  <dig>  nucleotides is considered, overall, it takes  <dig>  seconds to reconstruct the tree using fastdist+nj,  <dig>  seconds using phylip+nj, and  <dig>  seconds with paup+nj.

running time on real biological data
above we reported experiments on large simulated datasets. at present there are, however, no real biological datasets available of such sizes. we have selected two large datasets from the literature; one containing  <dig> rna sequences of length  <dig> from the hepatitis c virus  <cit>  and one containing  <dig> copies of a nuclear gene in birds with a sequence length of  <dig>  <cit> . we decided to perform  <dig> bootstrap evaluations for both datasets. as can be seen in table  <dig>  our new algorithm is significantly faster than phylip on both datasets. the reader should notice that fastdist+nj performs the task in a matter of seconds while phylip+nj takes many minutes or even hours. also notice that although our own implementation of the naive algorithm is slower than fastdist it is still much faster than phylip.

comparing the running time of phylip's dnadist, our optimized implementation of the naive approach, and the new algorithm fastdist  on real world biological datasets when  <dig> bootstrap evaluations were performed. the nj column describes the time it takes to reconstruct the  <dig> trees using the implementation of  <cit> . the dataset birds  <cit>  contains  <dig> copies of a nuclear gene in birds with a sequence length of  <dig>  the dataset hepatitis c  <cit>  contains  <dig> rna sequences of length  <dig> from the hepatitis c virus. using the wc unix utility for reading the file containing  <dig> bootstrapped datasets of  <cit>  takes  <dig>  seconds and reading the datasets of  <cit>  takes  <dig>  seconds.

unfortunately, it is not possible to run paup on a file containing multiple datasets. however, it seems reasonable to assume, considering its performance on simulated datasets, that paup should have approximately half the running time of phylip.

a novel method of handling ambiguity symbols
ambiguity symbols, i.e., bases of uncertain identity, complicates matters in sequence comparison. such symbols occur naturally in the form of single nucleotide polymorphisms  and also as a result of failure to resolve bases during sequencing. even though ambiguity symbols are rare they are usually not omitted from the analysis but instead treated in one of two ways, either as swofford  <cit>  or as felsenstein  <cit> . we suggest two novel methods for handling ambiguity symbols: one general method for estimating pairwise distances and one method for adjusting the probability distribution of the resolutions in each ambiguity. the default in our program fastdist is to combine these two methods.

we evaluated the accuracy of the four methods: swofford  <cit> , felsenstein  <cit> , our general method, and the default in fastdist. as detailed in the methods section, we first generated sequence data without ambiguities and thereafter we inserted ambiguity symbols at random. the accuracy was then measured by computing matrix norms  between the ml estimate of the data without ambiguities and the matrices computed by the four different methods on the data with ambiguities.

as can be seen in figure  <dig>  the fastdist default, denoted fastdist in the figure, is significantly more accurate than the other three methods. our general method, denoted noresolve, and swofford's method have almost identical accuracy. felsenstein's method, denoted phylip, is slightly less accurate than swofford's and our general method. although swofford's approach and our general method have similar accuracy our method requires less information and time to be computed. in particular, our method for handling ambiguities can be used together with our divide and conquer algorithm for fast computation of observed mutational events.

CONCLUSIONS
reconstruction of phylogenies with distance methods, such as nj, is done by first computing a distance matrix and thereafter applying the distance method. while nj and other distance methods are fast, the computation of the distance matrix is slow. in this paper, we provide a very fast algorithm for computing the distance matrix. this algorithm provides a valuable tool in tree reconstruction by improving the overall running time of distance methods by a huge factor; compared to both phylip and paup. we also present two novel methods for handling ambiguity symbols which, when combined together, provide significantly more accurate estimation than earlier methods.

the improvement our new algorithm gives is especially apparent in genome wide applications or when performing significance testing through bootstrapping. using our algorithm it is possible to perform extensive bootstrapping in a matter of seconds, even for very large datasets. this facilitates extensive bootstrapping in other applications, e.g., for computing initial guesses for other types of reconstruction algorithms, such as likelihood heuristics.

