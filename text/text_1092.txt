BACKGROUND
the microarray has become an important platform for a variety of bioscience and medical research areas. it allows researchers to detect the expression of thousands of genes simultaneously and to identify the differentially expressed genes  based on statistical analysis of sample comparisons. however, due to the large number of tests that are performed, there are anticipated errors in identification of degs, and it is important to compute the error rate. this information aids in the initial evaluation of the discovery and also reduces the cost of validation experiments.

to date, many different multiple test methods that detect overall type i error rates have been used to interpret microarray experiments  <cit> . the original multiple test methods were created for comparisons that were carried out many times simultaneously. for example, to test a drug's effects on several groups of subjects  <cit> , one wants to report the probability of at least one null hypothesis  in the side effects of this drug. fwer  is derived from the total number  of p-values at the significance level , e.g. α* =  <dig> - m  <cit> . all tests are subjectively dependent, i.e. all p-values are related as a whole or as a single subject, for example the side effects. all test p-values must be used in this multiple test method. in microarray experiments, p-values are generated for tens of thousands of genes. each p-value has no meaning with regard to other p-values, and all p-values are not related as a whole or to a single subject even though subgroups of genes exhibit biological dependency to some extent. therefore the rationale of an fwer derived from the total gene number would need further evaluation in microarray experiments. for example, it may not matter if one is certain  that a gene list contains one or two false positives, i.e. fwer is  <dig> . the common criticism of fwer is that it is too stringent and that it lacks power because fwer increases exponentially with the number of tested hypotheses  <cit> .

a commonly used multiple test alternative to fwer, false discovery rate  is defined  <cit>  as the expectation  of false positive genes  among selected genes , i.e. fdr = e. while fdr is conceptually appealing, there is no way to identify the number of actual false positives v. multiple test procedures thus estimate the proportion  of null hypothesis genes and multiply it by the total gene number and a false cutoff   <cit> : v = p <dig> m. α. there are several variations of fdr methods  <cit> , but the main difference is in the method of estimating this p <dig>  thus, all of these fdr methods are still constrained by the total gene number on the array, similar to the use of an fwer. the permutation approach for fdr counts the times that occur at a lower p-value than the actual p-value  <cit> . an ideal fdr method should present the false discovery rate within a given gene list. it is apparent, however, that permutation deduction does not directly reflect the false rate within the genes selected. also, it possesses low power for microarray experiments that have a small number of sample replicates. the bayesian model-based algorithm for fdr relies on a prior probability calculation  <cit> , however, in real cases, this prior determination is biased.

previously reported multiple test methods are constrained by the total gene number used. problems arise when an experiment uncovers only a few degs among a large number of total genes. these few but real positive genes result in a very high fdr and therefore could be eliminated from the resultant deg list. because of this problem, reduction of the total gene number by gene filtering was reported to increase the power of the multiple testing  <cit> . this approach is questionable because one could eventually reach a lower fdr with continued filtering. the total gene list should not be filtered except for reasons of poor quality or violation of the multiplicity concept.

researchers are often confused by the availability of so many different multiple test procedures. thus they typically try several procedures at the same time and only report the most satisfying one, or they try to filter genes until they reach a satisfying result. it is apparent that with these approaches, the results from different research reports may not be comparable. here we contrast parallel multiplicity to the traditional simultaneousness concept, and propose a new multiple test called the error discovery rate  for microarray experiments. this method overcomes the common problem of previous multiple test procedures where the type i error rate detection has low power when the total gene number used is large and provides an alternative or standard type i error rate method.

RESULTS
null hypothesis distribution and false discovery rate 
in a microarray experiment, one simultaneously conducts tens of thousands of individual gene hypothesis tests ,

 hi:μi=0  

where m is the total number of genes targeted on an array and μi is the mean log ratio of expression levels for the ith gene. these tests produce p-values  for all genes m. at a certain significance level α, one can define all genes into two groups: one is called "rejected null hypotheses"  with p-values equal to or less than α and containing the significantly changed genes or positive genes we actually observed; and the other group is called "accepted hypotheses"  with p-values higher than α and encompasses the non-significant genes or negative genes we actually observed.

if the p-value densities are plotted , typically the negative gene p-values  are under a flat curve indicating that the null tests follow a uniform distribution. the positive gene p-values  close to a p-value of zero is higher than the flat region of negative gene p-values .

in these hypothesis tests, we are interested in the type i error rate in the resultant positive genes r. however, only m, r, and n can be seen among all other parameters  in these tests. the ideal way to find the errors  within r is by using experimental validation such as quantitative rt-pcr to determine the false positives. however, such an experimental approach is impractical for hundreds or thousands of r genes. indeed, some studies randomly choose a few degs for qrt-pcr and report the ratio of number of confirmed degs to number of examined degs as fdr. statistically, it can be assumed that the null distribution provides the desired control under the true or alternative distribution  <cit> . therefore, the known parameter n or m can be statistically used for v approximation.

in the simultaneous multiplicity model, the proportion of unchanged genes  among all genes  is estimated in order to deduce the total null genes . thus, a natural estimate of fdr  when all null hypotheses are rejected with pi ≤ t is

  fdr=m0tr 

the key is that simultaneous multiple tests use the total unchanged genes  for the error estimate. to date, much effort has been undertaken for the m <dig> determination. storey  <dig>  <cit>  applied a tuning parameter, λ ∈ [ <dig> ), for the m <dig> estimate ). other methods, including nonparametric and parametric methods, have also been proposed to estimate m <dig>  including the beta-uniform model  <cit> , the spacing loess histogram  <cit> , the lowest slope estimator  <cit> , the smoother  <cit> , the bootstrap least squares estimate  <cit> , the successive elimination procedure  <cit> , the moment generating function  <cit> , and the poisson regression approach  <cit> , among others. all of these fdr methods estimate null hypotheses  by applying various parameters on p-values of the total number of genes m.

parallel multiplicity and error v estimate
a new idea for multiplicity is proposed here that tens of thousands of genes can be tested in parallel in the microarray experiment. this "parallel" approach is different from the many "simultaneous" approaches that occur in the literature  <cit>  and that introduce multiple tests into microarray experiments. parallel multiplicity is composed of two complicities of the microarray: the normalization and the controls. data normalization places all genes to be objectively or observationally related. the unchanged genes as negative controls influence the reliability of error detection. for example, assuming that the p-value reflects the error probability of a gene that is claimed as a positive gene, if a gene has  <dig>  of error , the context of this error would be different  when there are many negatives as controls in parallel versus when there are no controls in parallel. we prove how these negatives that parallel the positives can be used in error estimation.

lemma 1
the error estimation  by using the number of null tests  that have p-value 1-t and above is close to the real error  at the same significance level of t.

proof
let φ be the error rate in a selected gene list r, and the real error v = r. φ. let v be the error estimated at pi ≤ t using m <dig>  then v = m <dig> t. let v be the error estimated at pi ≤ t using parallel negatives that have p-value 1- t and above, then v = n'.t.

assume that m <dig> >>r . under this normalization assumption, we assume that n' ~ r and φ ~ t. then

 v−v=m <dig> t−r.φ>> <dig> 

 v−v=n'.t−r.φ≈ <dig> 

for those null tests  that have any p-value interval bins less than 1-t, the number of x may be the same as n' since the null p-values are of uniform distribution  <cit> . for example, the number of p-values between  <dig> and 1-t is the same as the number of p-values between 1-t and 1-2t. however, the context of these null tests is different. the null tests having higher p-values have higher probability of being true nulls, and the largest p-values are most likely to come from the true null, uniformly distributed p-values  <cit> . for example, a gene with p-value of  <dig>  will have a 90% chance to be a true null test. the parallel idea uses the strongest contrastingly related  gene sets to control the type i errors even though other portion of null tests might also be used.

error discovery rate 
in this parallel multiplicity idea, the parallel negatives  at a certain significance level  are used to determine the error v. therefore the error discovery rate  in a selected gene list  is defined as

  edr=n'.tr 

it can be seen that the contrast of edr to fdr is that fdr uses total unchanged gene m <dig> but edr uses the parallel negative genes n' to approximate error rate. since the expression of most genes in microarray experiments is unchanged , the m <dig> is close to m. in cases where the m is large and r is small, the fdr in equation  would pose a problem, i.e. the small number of real degs could be eliminated because it results in a high fdr. that is the reason for the use of the gene filtering approach to decrease the total gene number m in order to increase the detection power. however, in the edr method, the positives  and negatives  are sampled at each significance level   from all genes  and the distribution of the p-values. it can be seen in equation  that edr would not pose a problem even when there is a large m and a small r, hence no gene filtering is needed for edr.

the edr in equation  is not an estimate of the probability of a deg to be discovered in error. it is generally lower than the latter because it is computed using all the genes that have lower p-values than gene i . it is apparent that a gene whose p-value is near the threshold t does not have the same probability to be differentially expressed as a gene whose p-value is close to zero. the edr gives too optimistic a view of the probability for the gene to be an error. thus, an edr attached to each gene i that has p-value  was defined by removing the denominator r

  edr'i=n'.pi 

this is similar to the local fdr proposed by aubert et al.  <cit>  that is derived from the q-value estimation

  fdr¯=m <dig> 

the difference between equation  and  is that local edr replaces m <dig> and  of local fdr by using n' and pi, respectively. as noted above, n' is different from the m <dig> . compared to , pi retains more of the original test statistics of gene i.

further, a reality error parameter σ is applied to the edr model. let σi=1xi, where xi is the ratio of the maximum group mean of gene i with the median value of genes of all groups. fi is the fold change between groups of gene expression i. for example, each group of genes gives an expression mean value, and a maximum mean value is given from these group means. xi produces a reliability factor of the gene expression values. the fold change is log transformed for both up-regulated and down-regulated fold changes. when fi is equal to  <dig> , there is no change in this gene expression between groups. clearly, a small xi with small fi would lift the error. applying these reliability factors to adjust the error rate is especially important in cases where only a few sample replicates are used because of the unstable variance that arises when sample size is small.

the final error discovery rate of gene i, i = , is derived from the number of negative genes  that parallel to gene i at a p-value of pi:

  edri=n'piσi 

the edr method can be implemented for two-group statistic tests  or multiple-group anova tests with gene expression matrix file, in which the fi is the fold change between the group with highest expression and the group with lowest expression of gene expression i. the edr method can also be implemented with only p-values available as in equation .

case studies
in order to explore the problems or behaviors of multiple testing methods in real experiments, we chose three real case data sets that typically represent three situations: one contains a small number of degs, one has a moderate number of degs, and one presents a large number of degs.

hyperinsulinemic data
this data set was used to compare the method powers in the real case that the proportion  of differentially expressed genes is extremely low. this hyperinsulinemic data set was reported in a study to examine the effects of insulin on gene expression in healthy humans  <cit> . the original studies only reported three degs . the edr method found five degs among the  <dig> genes that passed the raw p-value cutoff at the significance level of α =  <dig> ; while other fwer, fdr, sam, and bayes methods could not find any positive genes at the same significance level  including the previously reported gos <dig> gene that has a very low raw p-value  and a high fold change . the five degs detected by edr  include gos <dig>  but not txnip and bcl <dig> that were in the original report  <cit> . this may result from a different data preprocess as these two genes, txnip and bcl <dig>  have raw p-values of  <dig>  and  <dig>  from the two-tailed t-test, respectively. the evidence that the ddx <dig> gene is differentially expressed in diabetic mice  <cit>  suggests that ddx <dig> detected by edr in this study may be a true deg.

the raw cel files of these three data sets  <cit>  were downloaded from the ncbi geo database  and were preprocessed by the gc-rma method. two groups in each data set were tested by two-tailed t test assuming equal variance. all multiple tests and raw p-values were applied at the same significance level of α =  <dig> .

edr detection of the hyperinsulinemic data set. the edr of gene i is the expectation of raw-p of this gene  multiplied by the number of negative gene controls  at p-value equal to or greater than 1- pi, divided by the ratio of the maximum group mean of this gene with the median value of all genes  and by the fold changes  minus  <dig> 

mirna knockout data
this data set  <cit>  was used to compare the methods in the real case that s <dig> is in the moderate range . specifically, this mirna knockout data set was reported from an examination of the effects of mirna on gene expression in mouse heart tissue using the mirna knockout model  <cit> . this mirna deficiency would induce quite a number of gene expression differences  <cit>  even though this study only focused on  <dig> protein-coding genes differentially expressed in mir-1-2-null hearts. in this data set, the edr method caught more positive genes than any other multiple tests except pcer. the pcer method identified more genes, but its gene number is even higher than the number found by the raw p-value cutoff .

colorectal cancer data
the data set examined  <cit>  was used to compare the methods in a real case with a large s <dig> . this data set of colorectal cancers was reported from a systematic search for genes differentially expressed in early-onset colorectal cancers using the genechip u133-plus  <dig>  that contains  <dig> probe sets on array  <cit> . in the original study,  <dig> probe sets were found to be differentially expressed between patients and healthy controls according to two-tailed t-test analyses with p <  <dig> . when the data set contains a large proportion of degs, edr still detected more degs than fwer and by but becomes slightly more stringent than other fdr methods such as sam and bayes . this appears sensible in real microarray experiments where, when there are so many positives, one strives for more stringent selection.

in these three real case data tests, it was found that the fwer and fdr methods were unable to detect degs at a significance level of  <dig>  when only a small number of degs exist because of the high error rates that resulted. at the same significance level, the edr method not only detected degs when only a few degs existed, but also caught more degs than fdr and fwer methods when there existed a moderate number of degs. interestingly, edr becomes more stringent when there are a large number of degs. however, since the degs were not validated in these experiments, we cannot determine whether the increase in the number of degs is due to an increase in power or an increase number of false degs. hence, the specificity and sensitivity of these methods were further evaluated.

specificity and sensitivity
in order to evaluate specificity and sensitivity, one needs to know the "true" degs and "false" degs. as such, a published microarray expression data set  <cit>  complemented with cdna sequence digital expression confirmation was used to test the specificity and sensitivity of edr and other multiple test procedures. the same rna samples from mexican axolotl animals were examined by ambystoma genechip and  <dig> cdna sequencing. degs between  <dig> and  <dig> days post amputation of denervated  forelimb tissues were detected by microarray analysis at different significance levels. the resultant degs were compared to the true degs  that were found to be differentially expressed via cdna sequence digital expression analysis, the false degs  that were not found differentially expressed via direct cdna sequencing, and the true negatives  that were not differentially expressed in both platform detections.

the true positive rate  and false positive rate  of edr and other methods at the significance of  <dig>  are shown in table  <dig>  it can be seen that the tpr and the fpr levels are a trade-off. for example, edr had better tpr  than bonferroni  and by , but higher fpr  than bonferroni  and by . however, when tpr and fpr were plotted on the receiver operator characteristic  curve, the edr curve was plotted above all other methods, and approached the left-top corner where the highest tpr and the lowest fpr exist . this indicates that edr had an overall better accuracy in performance over other methods. the area under the curve  of edr was the highest .

the expression data set was downloaded from http://www.ambystoma.org and was preprocessed by the rma method  <cit> . differentially expressed genes  were detected at the significance level of  <dig>  by the edr method and the other methods from the multtest package  <cit> . the resultant degs were compared with the true degs  measured by digital expression. false positives  are those degs that are not found to be differential in digital expression analysis. true negatives  are those genes that are not differential in both platforms.

it should be noted that in this microarray data set, the total number of gene probe sets on the array was small , and it has a moderate number of degs . this is an optimal case for simultaneous multiplicity model methods. even in this case, edr exhibited slightly improved performance over other methods. therefore it may be speculated that the superior performance of edr would likely be most evident in cases with large numbers of genes on the array and fewer degs.

simulation study
to test the above speculation that edr would have a better performance over other methods when a small number degs exist among a large number of genes on the array, existing mouse genechip data  <cit>  was simulated with a different proportion  of changed genes  and the powers of all multiple test methods were compared at different situations varying in deg number. the power is defined as the expected proportion of true degs that are declared as degs  <cit> . the simulated degs were assumed as the true degs for power estimation  <cit> . as expected, only when a higher proportion of genes are differentially expressed  can all fdr tests increase power . all fwer methods have low powers and their powers do not increase as s <dig> increases. even though the powers of sam and bayes increase when s <dig> increases, they still hold the lowest powers. however, at the same significance level of α =  <dig> , edr detected all simulated positive genes when s <dig> is  <dig> %. when s <dig> is less than or equal to  <dig> %, edr had more power than the commonly used fdr methods by and bh. when s <dig> became larger, edr caught slightly fewer degs but still retained consistently high power. this is particularly useful when there are so many 'degs' that a more stringent selection is needed.

the power of edr is derived from the error estimate from n'. as shown in figure  <dig>  without the reality factor, the edr_n  of equation  had more power than the commonly used method hy and by when the deg number is small. after applying this reality factor, the edr  power of equation  was further improved.

it can also be seen that at the significance level of  <dig> , the raw p-value, pcer, as well as the edr-i of the equation  ) detected all simulated degs. their powers reached the maximum of  <dig>  or more at different s <dig> points. obviously, examining only power cannot determine the performance of these methods because these methods may have included many false degs as well.

since these simulation data sets contain a large number of non-degs , the roc curve would be skewed to the very low false positive rate  side. we calculated the precision-recall  curve instead. while the pr and the roc are equivalent, the pr curve is more informative when dealing with highly skewed data sets  <cit> . when there is a small r  and big m , the edr family exhibited better performance than bonferroni and by, but had a similar auc size to bh and rawp methods . because the error rates of all multiple test methods are derived from raw p-value and the lower raw p-value is equivalent to an fdr or edr, it is not surprising that the rawp has a large auc among all three data sets . however, a closer examination of the rawp curve in additional file 3a showed that several cutoffs of rawp give very low precision, indicating false degs were contained in the detected degs. the significance level of  <dig>  is commonly chosen for statistics and for power evaluation  <cit> . at this significance level, edr had a better precision  than bh and other methods . even though the edr-i and rawp caught more simulated true degs, i.e. a higher power as showed in figure  <dig>  their precisions were relatively low. when there were several hundred degs , edr exhibited better performance than bonferroni and by, but lower than bh . when the simulated true degs go up further , edr became more stringent than other methods except bonferroni.

discussion
there are many research papers and reviews on multiple testing for microarray experiments  <cit> . most of the literature discusses how to apply various multiple tests in microarray experiments, but the theory of multiplicity for the microarray has not been depicted. general statements are found where "as a typical microarray experiment measures expression levels for thousands of genes simultaneously, large multiplicity problems are generated"  <cit> . the parallel multiplicity concept proposed here stands in contrast to the traditional "simultaneous" multiplicity. parallel multiple tests use only the negative genes that parallel the positive genes to control the error rate while simultaneous multiple tests use the total unchanged gene number for error estimation even though both the negative gene number and the total unchanged gene number depend on the total gene number and the distribution of the p-values. the edr method based on parallel multiple tests exhibits improved performance over simultaneous multiple test methods in specificity and sensitivity. since parallel multiple tests use only the negative genes that parallel the positive genes, not the total unchanged genes, the edr method overcomes the common problem found in previous simultaneous multiple test procedures where the type i error rate detection power is low when the total gene number used is large and the deg number is small. it is a robust method for a variety of statistical p-value distributions  <cit> . edr retains the power for various data sets without requiring gene filtering as well.

specificity and sensitivity are crucial criteria for method comparison, and the true and false positives need to be known for these tests. however, there is no gold standard to determine true or false positives. there are three levels for the definition of "true": true hybridization signal changes, true mrna transcript changes, and true functional changes. true hybridization signals can infer mrna transcript levels , but may not necessarily represent the true mrna transcripts, and the true mrna transcript changes may not cause the gene functional changes within an organism. here we focus only on the expression level, i.e. the mrna transcript level. to date, many microarray multiple test studies use simulation data or case data to evaluate the power  and specificity  <cit> . those microarray data sets with very few qrt-pcr validations are not useful for evaluating the specificities of multiple tests. in this study, a mexican axolotl animal microarray data set with cdna sequence digital expression validation  <cit>  was found to be useful. this data set possesses a relatively large number of "true" and "false" positives determined at mrna transcript levels. even though  <dig> sequencing also has a certain level of false positives, the comparison using this same data set for edr and comparison of other methods is compatible. in testing this data set, the edr method exhibited slightly improved performance over other methods in specificity and sensitivity. this improved performance is not as remarkable as in other cases, because this data set, with a low number of genes on array and a moderate number of degs, is an optimal case for simultaneous multiple test methods. the consistent superior performance of the use of edr was further supported by testing the simulation data and three real case data sets that vary in the proportion of unchanged genes.

many reports use real microarray case data sets for multiple tests evaluations. for example, the acute lymphoblastic leukemia  data set was intensively used for such a purpose  <cit>  even though there was no validation for the real degs in this data set. other real case microarray data sets were also used for multiple test performance evaluation, including a breast cancer data set  <cit> , a colon cancer expression data set  <cit> , a wheat data set  <cit> , a diabetes data set  <cit> , and a smoking data set  <cit> . not all of these data sets were validated for real degs. three real case data sets were chosen for this study because they represent three typical cases: low, moderate, and high levels of degs. it is difficult to evaluate the individual method by unvalidated data, but these data sets are still helpful in comparing the behaviors or performance of different methods under the same circumstance.

the edr model is different from the per-family error rate  and the per-comparison error rate  that simply adds individual p-values together or averages p-values  <cit> . it is distinct from fwer and fdr in that edr utilizes cross-gene information in the parallel concept but is not constrained by the total gene number. it varies from permutation-based fdr in that edr directly reflects the errors of the given genes and edr operates for small sample sizes. also, edr is appealing because it attaches the error to each gene, and the genes do not need to be ranked by raw p-values as is the case for all other multiple tests. other multiple test comparisons sequentially compute the error rate based on the ranked raw p-values; thus the error rates are the same as the lower p-values. this is not true in microarray multiplicity because at times lower p-values possess higher error potential than some higher p-values. edr recognizes this reality . there are indeed reports for how to rank and select genes  <cit> , but they do not address the error rate issue.

a false positive or the rejection of a true null hypothesis is a gene that is called as differentially expressed when it is not. the falsehood or error can be a systematic error or random error. the systematic error can be corrected by background subtraction or dye normalization, while the random error cannot be captured but can be modeled by statistical analysis. the p-value of each gene is a measure of how much evidence we have against the null hypothesis. it is rational that all multiple tests use this raw p-value or marginal p-value as a base error rate of that gene  <cit> . even though the p-value has inherently accounted for the fold change, an extremely small standard deviation  could drive a small p-value with a small fold change. almost all microarray studies apply a fold change cutoff for the final gene list to be reported. the reason that we only keep the genes whose fold changes are higher than a defined value, for example, a 2-fold change, is that it is still not certain that those low fold-changes in hybridization signals are real positives at the level of the mrna transcript. after these uncertain genes are removed, the error rate in the final gene list would undoubtedly decrease. also, some genes have very low intensity signals. for example, among the gene expression values ranging from  <dig>  to  <dig> , a 10-fold increase deduced from  <dig>  divided by  <dig>  is reasonable from a statistical point of view. however, biologists often remove this gene even though it has a very small p-value because this low expression level is close to background expression levels and therefore may be not reliable. thus, an ideal multiple test procedure would incorporate into the raw p-values the unreliability factors that result from low intensity and low fold-change in the error calculation in order to reflect the error or false reality. in the edr method, xi uses the maximum group mean and the median expression value to control the gene expression values, and uses fi to control the fold changes.

different multiple test procedures were recommended for different experiments based on the sample size, the magnitude expectations, and the p-value distribution  <cit> . however, there may exist a large variation in judging these multiple parameters. therefore the same type of experiments may produce different results depending on the method of preference among different researchers. there is not a comparable standard multiple test method that can be applied to a variety of data sets. it is interesting to note that the edr method had a similar performance pattern in all three different case data sets . this pattern was not affected by the proportion  of degs of the data. also, this performance pattern presents a deep slope in all three data types. this deep slope forms a boundary useful for significance cutoff value selection. other methods could not form this boundary in all data types. the performance patterns of other methods change vigorously depending on the s <dig> . for example, the bh performance curve did not show up in the low-s <dig> data set. it has lower power than pfcr in the median-s <dig> data set but was capable of much higher power than pfcr in the high-s0data set. this suggests that the edr method exhibits consistent performance in various data sets. this consistency is further supported by the use of simulation data. the edr method works for different data sets and would therefore provide a standard method for type i error rate calculations in microarray experiments. for example, we can say that with an edr cutoff of  <dig>  we found  <dig> differentially expressed genes between disease and normal samples. however, if we use other fdr methods, this may not be the case because some studies may find more genes using the same fdr cutoff in the same data set but by filtering genes or filtering in different ways, or they may use different fdr methods for data sets that vary in the proportion of unchanged genes.

it is difficult to test if the edr method works for dependent tests in microarray experiments. the multiple-endpoint in clinical trials  <cit>  is an example for fdr to control dependence in multiple tests. in this example, we know all tests are dependent. this knowledge is not deduced from p-values but instead by the experiment itself. in a microarray experiment, all p-values do not relate to one single subject, i.e. they are independent. only the genes in subgroups may be dependent because they usually work in a collaborative fashion to fulfill certain cell functions or pathways. the fdr methods claim to be able to control the error rate of the dependent p-values, and simulated dependent data was used to test this claim  <cit> . clumpy dependence was simulated in the sense that blocks of genes have dependent expression and therefore dependent p-values in p-value bins. however, this simulated dependence is quite different from the real microarray experiment. in a microarray experiment, the "correlated" p-values may not necessarily reveal true biological dependence, and true biological dependence may not exhibit dependence on p-value levels. for example, minor differential expression of some genes may play a remarkable regulatory function in a particular pathway, and the p-values of these genes may not be correlated to those of other genes in this same pathway. further studies are needed to examine genes in the same pathways and then to adjust the error rate based on the same pathway groups.

CONCLUSIONS
microarrays are extensively used today to examine changes in gene expression. however, biologists have difficulty in both the understanding and use of multiple tests in microarray studies. a new system of parallel multiple tests is proposed here. parallel multiple tests use the negative genes that parallel the positive genes to control the type i error discovery rate  in the microarray experiment. the edr method exhibits consistently improved specificity and sensitivity  over other methods in testing diverse data sets that vary in the number of null hypotheses. this method provides an alternative to standard type i error rate methods. parallel multiplicity is a new proposition and worth further enhancement in statistics and algorithm development.

materials and methods
hyperinsulinemic data and preprocessing
this data set was reported in a study to examine the effects of insulin on gene expression in human health  <cit> . six nondiabetic volunteers were given a 3-h hyperinsulinemic  euglycemic clamp test. a variable infusion of glucose  was used to maintain euglycemia during insulin infusion. the gene expression profiles of skeletal muscle biopsies from these six subjects pre- versus post-clamp were compared using the affymetrix genechip hu <dig> containing  <dig> probe sets. only three genes were reported to be regulated by insulin in human muscle cell using a wilcoxon signed rank test after filtering removed  <dig> probe sets.

the raw cel files were downloaded from the ncbi geo database  containing data that are miame compliant as detailed on the mged society website http://www.mged.org/workgroups/miame/miame.html the gc-rma algorithm was used for probe level signal condensation, background subtraction, and normalization. the gc-rma values were log-transformed for robust use in statistics tests since the log values are more compliant with the data normal distribution assumption than the raw data. but the fold and ratio calculations used the raw expression values. the raw expression values were truncated into  <dig> % and  <dig> % percentile ranges in order to avoid the extreme large and extreme small values in the fold and ratio calculations. with this data set, the edr method was compared with  <dig> other multiple test procedures  at the same significance level of α =  <dig>  .

mirna knockout data and preprocessing
this data set was reported to examine the effects of mirna on gene expression in mouse heart tissue  <cit> . heart tissue samples from three wild type and three mir-1- <dig> knockout mice at postnatal days  <dig> were compared for gene expression levels using affymetrix mouse genome  <dig>  <dig>  array that contains  <dig> probe sets. the raw cel files were downloaded from the ncbi geo database  and were preprocessed by gc-rma algorithm. with this data set, the edr method was compared with  <dig> other multiple test procedures  at the same significance level of α =  <dig>  .

colorectal cancers data and preprocessing
this data set was reported to systematically search for genes differentially expressed in early-onset colorectal cancers using the genechip u133-plus  <dig>  array  <cit> . twelve tumor specimens and ten adjacent grossly normal-appearing tissues from at least  <dig> cm away were collected for rna extraction. the raw cel files were downloaded from the ncbi geo database  and were preprocessed by gc-rma algorithm. with this data set, the edr method was compared with the other  <dig> multiple test procedures  at the same significance level of α =  <dig>  .

transcriptional validated data set
the data set used was reported in a study of transcription during nerve-dependent limb regeneration  <cit> . the same rna samples were detected by ambystoma genechip and  <dig> cdna sequencing. there are total  <dig> probe sets  on this genechip array.

the raw cel files were downloaded from the public ambystoma microarray database  <cit> . detailed information of these data files and the degs confirmation by  <dig> cdna sequencing were described in the original study  <cit> . the rma algorithm  <cit>  was used for probe level signal condensation, background subtraction, and normalization. the rma values were log transformed for robust use in statistics tests since the log values are more compliant with the data normal distribution assumption than the raw data. but the fold and ratio calculations used the raw expression values. raw expression values were truncated into  <dig> % and  <dig> % percentile ranges in order to avoid the extreme large and extreme small values in the fold and ratio calculations. the two-tailed t test was used to calculate the raw p-values.

of the degs detected among five group comparisons by microarray analysis,  <dig> degs were confirmed in mrna levels by using  <dig> cdna sequencing. in this evaluation, only two groups of raw data files, zero and five days post amputation of denervated  forelimb tissues, were used. among the total  <dig> true degs,  <dig> genes were true degs between dl <dig> and dl <dig> and possessed  <dig> -fold or greater changes in normalized digital expression levels. at each significance level, the true positive degs  were the portion of these  <dig> genes discovered by microarray analysis. the false positive degs  were those total degs detected by microarray analysis  subtracted by tp. the false negative degs  were calculated by subtracting tp from  <dig>  the true negative degs  were the tgs subtracted by tdegs. since  <dig> cdna sequencing presumably covered all cdnas or genes including all probe sets on the genechip, the portion of genes that were not detected by both platforms were tn.

simulation data
in order to calculate the statistical power of method, we simulated microarray data with different proportions  of true positive gene numbers. the power was calculated as the proportion of true positives that were detected at the same significance level of α =  <dig> .

the simulation parameters for gene group means  and gene group variances  were replicated on the real mirna knockout data set  <cit>  and preprocessed by gc-rma  <cit> . the simulated data matrix was created by  <dig> groups of  <dig> sample columns  and  <dig> rows of genes  .

each gene expression value is generated within the normal distribution of mean mi and standard deviation sdi. mi is the gene group mean that is uniformly distributed within the minimum and maximum values of the whole mirna knockout data set. sdi is the standard deviation of a gene group that is uniformly distributed within the minimum sd and maximum sd of all gene group sds of the whole real data set. the non-degs were guaranteed to have the normal distribution of the sdi and equal mi. also. in addition, the two group means are close to equal because if they fall into the normal distribution with an equal mean, they still may have large fold changes. this ensures they are non-degs in a statistical sense. the different s <dig>  data sets were simulated by adding different proportions of degs. the normal distribution of gene expressions of degs in each group samples was simulated using mean and sds vectors. the mean vectors have folds uniformly distributed between  <dig> - to 3-fold changes and the sds vector has uniformly distribution of one-fifth of the means . for each simulation data set, two-group t-tests assuming equal variance were performed, and edr and other multiple test methods were applied.

receiver operating characteristic  and precision-recall  curves
for the transcriptional validated data set, the roc curve of edr method was compared with other multiple test procedures . the aucs of roc curves based on tpr and fpr were used to compare the overall performances of edr and other methods. the curve approaching the left-top corner represents the highest tpr and lowest fpr.

for the false positive rate  skewed simulation data sets, pr curve was used instead for method performance comparison.

 tpr, recall=tptp+fn 

 fpr=fpfp+tn 

 precision=tptp+fp 

multiple tests
the multiple tests for type i error rates were categorized into several groups  <cit> : pcer, pfer, fwer, and fdr. the following tests are defined according to figure 1d and used in this study.

pcer  <cit> 
the per-comparison error rate is defined as the expected value of the number of type i errors divided by the number of hypotheses, that is,

 pcer=e/m=a1+...+amm 

pfer  <cit> 
the per-family error rate is defined as the expected total number of type i errors, that is, pfer = e = a <dig> + ... + am

fwer
the family-wise error rate is defined as the probability of at least one type i error , that is, fwer = pr. the bioconductor multtest package  <cit>  was used for following pwer procedures: bonferroni, holm, hochberg, and sidaksd.

bonferroni  <cit> , pi=αim

holm  <cit> , pi = pi=αim−i+1

hochberg  <cit> , pi = pi=αim−i+1

sidaksd  <cit> , pi=1−1−αm−i+1

fdr
bioconductor multtest, qvalue, and sam packages  <cit>  were used for the following fdr detection : bh, by, qvalue, sam, and empirical bayes.

bh  <cit> , pƒi=pimi

by  <cit> , pƒi=pim∑1/ii

qvalue  <cit> , pƒi=pimπ^0i, where π^ <dig> is the proportion estimation of unchanged genes.

sam  <cit> , pƒi=∑bbnpb>pib, where b is the number of permutations.

empirical bayes  <cit> , p=απ0απ0+, where p is the fdr, α is the significance level, π <dig> is proportion of null hypothesis, and  is the test power.

authors' contributions
wx proposed the idea, performed the tests, and wrote the manuscript. cc contributed to the revision.

supplementary material
additional file 1
r source code for edr method. the edr method was implemented for two group comparison experiments either with p-values provided or without p-values.

click here for file

 additional file 2
simulation and parameters. existing mouse genechip data  <cit>  was simulated with a different proportion  of differentially expressed genes.

click here for file

 additional file 3
precision-recall  curves. precision-recall  curves of multiple test methods on simulation data sets with different proportions of degs . upper panel: pr curves; middle panel: the area under the curve ; lower panel: simulated true degs  contained within all detected degs of each method were at or below the significance level of  <dig> .

click here for file

 acknowledgements
the authors thank nathan springer for helpful comments and rui kuang for valuable discussion on this manuscript. the authors also thank yung-tsi bolon and tracey bartlett for reading and editing this manuscript. the authors would like to thank hackstadt amber j. for kindly providing a portion of simulation source code. the authors would also like to thank the anonymous reviewers for their constructive comments.
