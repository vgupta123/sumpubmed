BACKGROUND
microarray technology has provided biologists with the ability to measure the expression levels of thousands of genes in a single experiment. the vast amount of raw gene expression data leads to statistical and analytical challenges including the classification of the dataset into correct classes. the goal of classification is to identify the differentially expressed genes that may be used to predict class membership for new samples. the central diffculties in microarray classification are the availability of a very small number of samples in comparison with the number of genes in the sample, and the experimental variation in measured gene expression levels. while very effective methods for binary classification  are known, these methods do not necessarily perform as well in the multi-class case  <cit> . this paper addresses the multi-class classification of microarray data, and the evaluation issues that arise in determining the validity of the performance measures.

the classification of gene expression data samples involves feature selection and classifier design. feature selection identifies the subset of differentially-expressed genes that are potentially relevant for distinguishing the classes of samples. the aim is to reduce the initial gene pool from  <dig> – <dig>  to 100– <dig>  several gene selection methods based on statistical analysis have been developed to select these predictive genes, they include t-statistics, information gain, twoing rule, the ratio of between-groups to within-groups sum of squares  and principal component analysis  <cit> . in this study we explore the alternative methods provided by the rankgene software  <cit>  for the initial feature selection task.

both supervised and unsupervised classifiers have been used to build classification models from microarray data. this study addresses the supervised classification task where data samples belong to a known class. many classifiers have been used for this task such as fisher linear discrimination analysis, maximum likelihood discriminant rules, classification tree, support vector machine , k nearest neighbour , and aggregated classifiers  <cit> . in this study we adopt the knn classifier. knn classification is based on a distance function such as the euclidean distance or pearson's correlation that is computed for pairs of samples in n-dimensional space. each sample is classified according to the class memberships of its k nearest neighbours, as determined by the distance function. knn has the advantages of simple calculation and the ability to perform well on data sets that are not linearly separable, often giving better performance than more complex methods in many applications . the aim of this study is to evaluate an evolutionary algorithm for multiclass classification of microarray samples by assessing its classification accuracy on microarray samples. we also investigate the feature selection step that is a necessary precursor to classification. these objectives require an appropriate evaluation method to determine the final figures for accuracy. once the appropriate parameters for the evolutionary algorithm are determined, its performance is evaluated again using the . <dig> bootstrap estimation method to obtain a low-variance measure. two published microarray datasets are used to test the performance of the algorithms, namely, the leukemia and nci <dig> datasets. the contributions of this paper are: a comprehensive evaluation of an evolutionary classifier; an investigation of feature selection in learning classifiers; an analysis of frequently selected genes, and a comparison of gene rankings across several previous studies of the leukemia data.

systems and methodology
evolutionary algorithm
evolutionary algorithms have been applied to microarray classification in order to search for the optimal or near-optimal set of predictive genes on complex and large spaces of possible gene sets. evolutionary algorithms are stochastic search and optimisation techniques that have been developed over the last  <dig> years. these algorithms are based on the same principles of evolution found in the biological world involving natural selection, and survival of the fittest. evolutionary algorithms differ from other traditional optimisation techniques in that they involve a parallel search through a population of solutions.

the evolutionary algorithm we employ maintains a population of predictors whose effectiveness as a classifier can be determined by using them as features in a knn classifier. the size of the population and the number of features in a predictor are parameters that we shall explore experimentally in the following section.

we assume that an initial gene pool of informative genes has been identified . the initial predictors in the population are randomly constructed from the initial gene pool as indicated in figure  <dig>  a predictor contains between  <dig> and  <dig> genes and so defines a subset of the features  that are identified in the initial feature selection step.

each predictor is scored according to its ability to classify the training data based on a leave-one-out cross validation  analysis. the scoring function s in steps 3b and 3c in figure  <dig> is the sum of the training samples that are correctly classified in the loocv. that is, one of the samples is left out to be a pseudo test data, the classifier is built based on all but the left out sample, and the score incremented if the sample is correctly classified. the score is incremented by an additional amount proportional to the minimum separation of the clusters. the replication of a particular predictor depends on how the mutation effects the scoring function. the selection process uses a statistical replication algorithm. the predictors which have a higher score after mutation survive in the next generation. the termination condition is met when the all predictors give similar score over a specific number of generations. the most successful predictor is the one giving the fewest errors on the training samples. to measure the performance of the algorithm, the best predictor is evaluated again using test samples.

the parameters of the evolutionary algorithm are fixed as follows: the probability that a predictor will be mutated is set to  <dig> . the probability of adding a new gene to the predictor and the probability to delete a gene from any random position in predictor are set to  <dig> . this makes adding a gene and deleting a gene equally probable. the knn classifier uses the euclidean distance measure. when surveying the performance for the population size and feature size parameters we report the average of the accuracy rate over  <dig> trials.

the selection and evolution process is a modification of the statistical replication algorithm described in deutsch  <cit> . the termination criteria is defined using both the maximum number of generations and the criteria of no improvement of maximum fitness value of the population. the predictor with highest fitness will be the one that contains the best subset of genes for the classification task.

genetic algorithm
in order to confirm the conclusions drawn from the experimental analysis, we repeat the classification task using a different search algorithm – a standard genetic algorithm  – in combination with a k-nearest neighbour classifier. the ga encodes a weight for each feature in a chromosome, and maintains a population of chromosomes which are combined using crossover, and modified by mutation operators in a standard manner  <cit> . the ga explores the space of weights for each feature using a  <dig> bit representation, where the feature is assigned a weight of  <dig> or  <dig>  in this configuration, the ga+knn classifier performs feature selection and hence is directly comparable to the evolutionary algorithm. the ga was configured to have  <dig> chromosomes and was run for  <dig> generations in each trial.

methodology
to investigate the initial feature selection step, and its effect on classifier learning, we apply six of the feature selection methods supported in the rankgene  <cit>  software. these techniques have been widely used either in machine learning  or in statistical learning theory . they quantify the effectiveness of a feature by evaluating the strength of class predictability when the prediction is made by splitting the full range of expression of a given gene into two regions, the high region and the low region. the split point is chosen to optimise the corresponding measure. feature selection is performed using only the samples in the training data set.

the evolutionary algorithm that we shall evaluate learns the optimal subset of features that classify the data, based on the initial set of selected features. in the trials reported here, the evolutionary algorithm will stop when the score of all predictors in the population give a standard deviation of less than  <dig>  for ten consecutive generations, or the evolutionary algorithm reaches the maximum number of generations .

many evaluation methods has been investigated for small-sample error estimation. typically, a microarray experiment provides a dataset of small size, and as a result the most commonly used method for error estimation is leave-one-out cross validation . the loocv error rate estimator is a straightforward technique and gives an almost unbiased estimator.

a comparison of various error estimation methods is presented in  <cit> , these include the resubstitution estimator, k-fold cross-validation, leave-one-out estimation, and bootstrap methodology. these methods were tested with many classifiers: linear discriminant analysis, 3-nearest-neighbour, and decision trees. for over all performance, the . <dig> bootstrap proved to be the best estimator in their simulations, but the drawback of this method is the computational cost in comparison to loocv. as loocv is almost unbiased and is fast, it is acceptable to use it for parameter analysis.

we investigate the performance of the feature selection methods and evolutionary algorithm as follows:

• the evolutionary classifier is tested on the leukemia dataset without the use of any feature selection method.

• the rankgene methods are employed, and performance compared against the baseline and against each other for the leukemia data.

• the ga-based classifier is evaluated on the leukemia data to validate these results.

• the evolutionary classifier is tested on the leukemia and nci <dig> datasets.

• a ranking of frequently selected genes by z-score is obtained, and the performance of the top ranked genes as a classifier is measured.

• the . <dig> bootstrap error estimator is applied using the optimal parameters for all datasets.

RESULTS
we begin by demonstrating that the performance of the population of predictors improves on each iteration of the evolutionary algorithm. figure  <dig> shows the average scores in each iteration from several trials. the graph shows that the average score increases more rapidly over the first few generations in comparison with the final generations. the evolutionary algorithm typically converges and terminates in less than  <dig> generations. the runs terminate on different iterations depending upon when the termination condition is met.

in the baseline test, the evolutionary algorithm is run on the entire set of genes  in order to obtain a baseline measure of performance.

the baseline system is evaluated on the  <dig>  genes of the leukemia dataset. the initial predictors in population are built by randomly selecting  <dig> genes to be an initial feature of the predictors. this means the evolutionary algorithm has to search for  <dig> optimal predictive genes set from the  possible subsets. performance of the predictors is evaluated using knn classifier to determine the loocv on training samples. after the best predictor is found in each generation, it will be tested again on test samples to give the performance based on an out-of-sample estimation. the knn classifier classifies each sample in the test data using a database of all training samples.

building an informative initial gene pool by the rankgene software
we determine the best choice for the number of initial features, i.e. the initial gene pool, to be  <dig> by experiment . based on this result, the performance of the following six ranking methods for a range of population and feature sizes is investigated: r <dig>  information gain; r <dig>  twoing rule; r <dig>  gini index; r <dig>  sum minority; r <dig>  max minority; r <dig>  sum of variances. the details of each method can be found at .

leukemia dataset
the parameters of the evolutionary classifier are evaluated on the set of  <dig> training samples and the  <dig> test samples of the leukemia data – as described in the original work. we explore: population size { <dig>   <dig>  50} feature size { <dig>  50} and initial gene pool  <dig> 

the classification results are summarised in table  <dig>  when a predictor with 100% accuracy is learned in one or more of the test runs we indicate this by . average accuracy over ten trials lies in the range 92–98%. using feature selection, the accuracy on the test data is more than 19% greater than that of the baseline system. for a given feature selection method, the prediction accuracy on the test samples varies up to 3% across the range of parameter settings surveyed. the choice of feature selection method contributes up to 5% for a given set of algorithm parameters. information gain consistently gives the best performance on the leukemia dataset.

abbreviations: r <dig>  information gain; r <dig>  twoing rule; r <dig>  gini index; r <dig>  sum minority; r <dig>  max minority; r <dig>  sum of variances.

the results of the confirmation study are shown in table  <dig>  where feature selection improves accuracy by at least 27%: the accuracy on the training data in the baseline system  is  <dig> % which is significantly greater than the test accuracy of  <dig> %. a variation of  <dig> % is observed in average accuracy across the rankgene methods. the best rankgene method is information gain. in comparison with feature selection by information gain, all other methods have a significantly lower accuracy on the testing data than information gain, while there are no differences in performance on the training data across the other rankgene methods.

nci <dig> dataset
the aim of this investigation is to find the best parameters and ranking method for the evolutionary classifier when applied to the nci <dig> data. the same range of parameters is surveyed as for the leukemia data, and again the performance of six feature selection methods is evaluated.

due to the very small sample size of the nci <dig> dataset, it is not possible to divide the data into training and testing sets. thus, the accuracy of predictors in table  <dig> is given by using the loocv error rate estimation on the whole dataset. to get a more reliable performance of the evolutionary algorithm on the nci <dig> dataset, the . <dig> bootstrap estimator will be used.

the best classification score on the nci <dig> data is  <dig> %, and was obtained using information gain, with a population and feature size of  <dig>  no predictor learned in any run of the system was able to classify all data 100% correctly.

discrimination method
the frequency of selection of the genes that are members of the best predictor across  <dig> independent trials is assessed in order to determine the reproducibility of the results. if a gene is consistently preferentially chosen as a member of a predictive set it would suggest that the gene selection operation is reproducible – despite the random initialisation.

z-score analysis is one means to determine the significance of the observed frequency of an event against that which might have occurred by chance. this calculation normalises the frequency with which each of the initial genes was selected in all predictors that classify the training and test data perfectly  <cit> . the z score can be calculated using equation .



where si denotes the number of times genes i was selected, e is the expected number of times for gene i being selected, and σ denotes the square root of the variance. the calculation of e is as follows: let a number of perfect predictors found in the experiment, pi =  / . then, e = pi * a.

the evolutionary classifier was run  <dig> times on the leukemia dataset using the best set of parameters:  <dig> initial genes constructed by the information gain and feature size =  <dig>  there are  <dig> predictors  that classify all training and test data correctly. figure  <dig> shows a plot of z-score applied to the top ranked genes that are most frequently selected. the top  <dig> genes have a similar z-score and the top  <dig> have a positive z-score. in this case, it seems reasonable to choose the  <dig> top-ranked gene as the most discriminative genes.

to confirm the predictive power of the  <dig> top-ranked genes we constructed a classifier using these genes as features. as before, we measure the accuracy on the test set using the training set as a case-base. an accuracy of 100% is obtained.

additional file:  <dig> shows the  <dig> top-ranked genes, their frequency of occurrence in the  <dig> best predictors and the z-score value. this set of genes will be used in the further evaluation using . <dig> bootstrap estimator.

the z-score analysis was repeated on the nci <dig> data and these results are shownin figure  <dig>  it can be seen that the z-score of the 8th ranked gene is half that of the top ranked gene and that the top  <dig> genes have a positive z-score. additional file  <dig> lists the top  <dig> genes. a classifier constructed using these genes has an accuracy of  <dig> % by loocv, and  <dig> % by a bootstrap estimate.

. <dig> bootstrap estimates
the . <dig> bootstrap method involves sampling the original dataset  to obtain a new resampled set on which the classification error δ is measured  <cit> . the accuracy ε on the samples omitted from the resampled set is also determined. the bootstrap estimator ab <dig> for a dataset of n samples requires n resampled datasets to be constructed and the classification error calculated according to equation . the final bootstrap estimate is the average value of ab <dig> over b iterations of the procedure .



on the leukemia data, the . <dig> bootstrap estimate for the accuracy of the evolutionary algorithm with population size  <dig> and feature size  <dig> is  <dig> %. the . <dig> estimate for a classifier based on a fixed set of  <dig> top-ranked genes is  <dig> %.

on the nci <dig> data, the . <dig> bootstrap estimate for the accuracy of the evolutionary algorithm with population size  <dig> and feature size  <dig>  is  <dig> %. the . <dig> estimate for a classifier based on  <dig> top-ranked genes is  <dig> %.

discussion
on the data sets studied, we find that the evolutionary algorithm performs robustly over the space of parameters surveyed. optimal values for population size and feature size are obtained, but the approach is not overly sensitive to these choices. this is a promising result as stochastic algorithms and techniques such as neural nets can be sensitive to parameter settings  <cit> .

despite showing approximately 97% accuracy on the leukemia data, the evolutionary algorithm does not perform as well on the nci <dig> dataset. the . <dig> bootstrap estimate of 59% for the nci <dig> data is significantly less than the 76% obtained by loocv. if we accept that the bootstrap method is appropriate, then we must conclude that the loocv estimates typically reported may be considerable overestimates. the loocv estimate we obtain is greater than the averages for the nci <dig> data reported in  <cit> , but less than the best error rate reported in  <cit> . the bootstrap estimate is comparable with the results of  <cit> .

gene selection
the value of the rankgene methods for feature selection is shown by the improvement in accuracy over the baseline results. without feature selection, the evolutionary algorithm can discover predictors that give 100% accuracy on the training set, but perform poorly on the test set. a similar finding is obtained using a ga-based search with a knn classifier. this indicates that the classes can be distinguished by any of a large set genes that are indicative of a category, but that these genes are not necessarily informative in the sense that they are activated in a comparable way across both the training and the testing sets. by allowing uninformative genes into the feature set we observe a degree of overfitting.

the correct choice of rankgene method can improve classification by 5% for a given population size and feature size on the leukemia data . the confirmation study reproduced this finding also. in comparison, the selection of population and feature sizes can influence performance by up to 3% . thus, feature selection has a significant influence on the classifier learning task.

the optimal predictor
several researchers have tried to find the optimal predictive gene set. it has been suggested that for the leukemia dataset the number of predictive genes included in a predictor should be less than  <dig>  <cit> . this conclusion was based on a z-score analysis. deutsch  <cit>  found an average of  <dig> predictors was sufficient to classify the leukemia data perfectly, with some runs reducing the number to  <dig>  we find  <dig> genes are not sufficient, and that that up to  <dig> genes are required, but have not attempted to identify a lower bound.

gene ranking
for comparison, the rankings of selected genes found to be significant in previous analyses  <cit>  of the leukemia data are listed in table  <dig> along with those ranked highly by our methods. the ranking of ben-dor  <cit>  is of genes that discriminate between aml and all, while thomas  <cit>  ranks the  <dig> genes more highly differentially expressed genes in aml than in all, and provides a similar ranking for the genes differentially expressed in all.

only four of the top  <dig> genes we identify are found in the  <dig> genes listed as having highest relative differential expression for aml/all respectively. in contrast,  <dig> of the top  <dig> genes of ben-dor  <cit>  are in this list . this difference can be accounted for by the fact that we address the 3-class problem while ben-dor solve the 2-class problem. thus it appears that the differential expression of genes can be exploited in classifying samples but, even in the 2-class case will, not lead to optimal classification as it ignores the relationships between the expression levels in a predictive set of genes.

five of the genes we rank in the top  <dig>  also lie in the equivalent range  in  <cit> . further, the human cd <dig> antigen gene m <dig> and t-cell surface glycoproteins xo <dig> and j <dig> which are ranked in the top  <dig> in our study do not appear in the top  <dig> genes in ben-dor  <cit>  or in thomas  <cit> . cd <dig> is known to indicate b-lineage and cd <dig> to indicate t-lineage  <cit>  this study confirms that significantly different sets of genes are found to be most discriminatory as the sample classes are refined.

CONCLUSIONS
the evolutionary methods we have developed for microarray data classification perform robustly and accurately on the data sets examined. the results are in accord with clinical knowledge as demonstrated by a z-score analysis of the genes most frequently selected for inclusion in a classifier: genes known to discriminate between aml and pre-t all leukemia are identified. this study also concludes that there are notable dependencies between the way in which the classification problem is formulated and the resulting rankings of discriminatory genes.

