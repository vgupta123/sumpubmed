BACKGROUND
most machine-learning classifiers output predictions for new instances without indicating how reliable the predictions are. the application of these classifiers is limited in the domains where incorrect predictions have serious consequences. medical practitioners need a reliable assessment of risk of error for individual cases  <cit> . thus, given the prediction tailed with a corresponding confidence value, a system can decide whether it is safe to classify. the recently introduced conformal predictor   <cit>  is a promising framework that produces prediction coupled with confidence estimation. the exploiters advanced a welcome preference for formal relationship among kolmogorov complexity, universal turing machines and strict minimum message length . they assumed the transductive prediction as a randomness test which returns nonconformity scores closely associated with the property of the iid distribution  governing all of the examples. when classifying a new instance, cp assigns a p-value for each given artificial label to approximate the confidence level of prediction. cp is more than a reliable classifier of which the most novel and valuable feature is hedging prediction, i.e., the performance can be set prior to classification and the prediction is well-calibrated that the accurate rate is exactly equal to the predefined confidence level. it is impressive to see its superiority over the bayesian approach which often relies on strong underlying assumptions. in this paper, we use a random forest outlier measure to design the nonconformity score and develop a modified random forest classifier.

since reports from both academia and practice indicate that the default assumption of equal misclassification costs is most likely violated  <cit> , the natural desiderata is extending cp to label-wise cp, which takes into account different costs for misclassification errors of different class and allows different confidence level to be specified for different classification of an instance. in this paper, we investigate the method to extend cp to label-conditional cp, which can solve the non-uniform costs of errors in classification.

consider a classification problem e: the reality outputs examples z = {,..., } ∈ x × y and an unlabeled test instance xn, where x denotes a measurable space of possible instances xi∈ x, i =  <dig>   <dig> ... n -  <dig> ...; y denotes a measurable space of possible labels, yi∈ y, i =  <dig> ,... n -  <dig> ...; the example space is represented as z = x × y. we assume that each instance is generated by the same unknown probability distribution p over z, which satisfies the exchangeability assumption.

conformal predictor 
cp is designed to introduce confidence estimation to the machine learning algorithms. it generalizes its framework from the iid assumption to exchangeability which omits the information about examples order.

to construct a prediction set for an unlabeled instance xn, cp operates in a transductive manner and online setting. each possible label is tried as a label for xn. in each try we form an artificial sequence ,..., , then we measure how likely it is that the resulting sequence is generated by the unknown distribution p and how nonconforming xn is with respect to other available examples.

given the classification problem e, the function an: z × zn → r is a nonconformity measure if, for any n ∈ n,

 αi := an 

 i =  <dig> ..., n -  <dig> 

  αn := an 

where  is a "bag" in which the elements are irrelevant according to their order. the symbol α denotes sample nonconformity score: the larger αi is, the stranger zi is corresponding to the distribution. in short, a nonconformity measure is characterized as a measurable kernel that maps z to r while the value of αi is irrelevant with the order of zi in sequence.

for confidence level  <dig> - ε  and any n ∈ n, a conformal predictor is defined as:

  Γε={y∈y:py=|{i= <dig> ...,n:αi≥αn}|n>ε} 

a smoothed conformal predictor  is defined as:

  Γε,τn={y∈y:py=|{i= <dig> ...,n:αi>αn}|+τn|{i= <dig> ...,n:α1=αn}|n>ε} 

where y is a possible label for xn; py is called p value, which is the randomness level of zn =  and also the confidence level of y being the true label; τn, n ∈ n is a random variables that distributed uniformly in  <cit> . smoothed cp is a power version of cp, which benefits from p distributing uniformly in  <cit> .

let Γε = {y ∈ y: py > ε}, and the true label of xn is denoted as yn,

if |Γε| =  <dig>  we define it as a certain prediction.

if |Γε| >  <dig>  it is an uncertain prediction.

if |Γε| = ∅ , it is an empty prediction.

if yn ∈ Γε, we define it as a corrective prediction with confidence level  <dig> - ε. otherwise, it is defined as an error.

when it comes to forced point prediction, cp selects the label with maximum p value as the prediction.

cp is originally proposed for online learning and vovk  <cit>  offered the theoretical proof that in the online setting in the long run the prediction set Γ contains the true label with probability  <dig> - ε and the rate of wrong prediction is bounded by ε. especially the smoothed cp is exactly valid, i.e., the rate of wrong prediction is exactly equal to ε. this is summarized as the proposition of well-calibrated.

  limn→∞sup⁡n=ε 

with errnε the number of error predictions at the confidence level  <dig> - ε . extensive experiments demonstrated that cp is also applicable to offline learning, which enlarge its applications.

different nonconformity measures have been developed from existing algorithms, such as svm, knn and so on  <cit> . all the cps have the calibration property, but the efficiency of cp largely depends on the designing of nonconformity measure  <cit> . efficiency means the certain and empty prediction ratio in all predictions. certain prediction is favourable because it is more informative than uncertain predictions. cp is successfully employed to hedge these popular machine learning methods, and this paper shows that cp-rf is more efficient than others.

random forest 
breiman's random forest applies bagging  <cit>  and randomization  <cit>  technique to grow many classification trees with the largest extent possible without pruning. random forest is especially attractive in the following cases  <cit> :

 first, the real world data is noisy and contains many missing values, some of the attributes are categorical, or semi-continuous.

 furthermore, there are needs to integrate different data sources which face the issue of weighting them.

 rf show high predictive accuracy and are applicable in high-dimensional problems with highly correlated features, especially in the situation which often occurs in bioinformatics, like medical diagnosis.

in this paper, the random forest outlier measure is used to design a nonconformity measure in order to incorporate random forest into the cp and label conditional cp scheme. our method can be used in both online and offline settings.

cost-sensitive learning problem
in medical diagnosis, the default assumption of equal misclassification costs underlying machine learning techniques is most likely violated. a false negative prediction may have more serious consequences than a false positive prediction. to address this problem, cost-sensitive classification is developed, which considers the varying costs of different misclassification types  <cit> . usually a cost matrix is defined or learned to reflect the penalty of classifying samples from one class as another. a cost-sensitive classification method takes a cost matrix into consideration during the model building process    <cit> . however, how to get a proper cost matrix remains an open question  <cit> . the definition or learning of a cost matrix is quite subjective. in this paper, we extend our method to label conditional cp to address the cost sensitive problem, and the risk of misclassification of each class is well controlled.

RESULTS
experiments setup
the experiments are divided into two parts: first, to show the calibration property and efficiency of our method, we demonstrate our method cp-rf on  <dig> benchmark datasets and a real-world gene expression dataset. second, to cope with the cost-sensitive problem, we extend cp-rf to label conditional cp-rf, and test its performance on two public application datasets.

part i performance of cp-rf
we employ  <dig> uci datasets  <cit> , including satellite, isolet, soybean, and covertype, etc. some details are included in table  <dig>  which contains information of the number of instances , number of class , number of attributes , and number of numeric  and nominal .

we perform cp-rf in a 10-fold cross validation in an online fashion and report the average performance and compare it with tcm-svm and tcm-knn. we use the following key indices at each predefined significance level:  percentage of certain predictions.  percentage of uncertain predictions.  percentage of empty predictions.  percentage of corrective predictions. these terms distinguish with traditional accuracy rate given by rf, svm and other traditional classifiers.

given a significance level ε, the calibration and efficiency can be laid out. let the number of trees  equal to  <dig> and the number of variables to split on at each node  be the default value a . in figures  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>  we demonstrate performance curves according with the significance level ε ranging from  <dig>  to  <dig>  and show the average experimental results on pima , soybean , covertype  and liver , etc.

figures  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> show that the empirical error line is well-calibrated with neglectable statistical fluctuations. it allows controlling the number of errors prior to classification. percentages of corrective predictions with a predefined level of confidence illustrate the calibration of the new algorithm. figures  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> also show high accuracy with series of significance level and some interest points are extracted in table  <dig> for impressive purpose.

the percentage of certain predictions reflects the efficiency of prediction. notice that the percentage of uncertain predictions monotonically decreases with higher significance levels. how fast this decline goes to zero depends on the performance of the classifier plugged into the cp framework. figures  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> show that cp-rf performs significantly well, and it is applicable at the significance levels of  <dig> ,  <dig> ,  <dig> , and  <dig> . for the convenience of comparison, we apply standard tcm-knn and tcm-svm algorithm provided by gammerman and vovk. the ratios of certain predictions on the  <dig> datasets are given for comparison in table  <dig> and we can find that the efficiency of cp-rf is much better than the others, which indicates its superiority. then we compare their performance in the occasion of forced point prediction in table  <dig> 

it is clear that cp-rf performs well at most of the datasets, especially on the datasets with categorical and mixed variable. cp-rf especially outperforms tcm-knn for high-dimension dataset , and outperforms tcm-svm for noisy data .

to compare with the most popular machine learning methods, we consider acute lymphoblastic leukemia  data which was previously analyzed with traditional machine learning methods. we choose an all dataset from  <cit>  for comparison . there are  <dig> cases with attributes of  <dig> genes. the data has been divided into six diagnostic groups and one that contains diagnostic samples that did not fit into any one of the above groups . each group of samples has been randomized into training and testing parts.

we report results using cp-rf without discriminating gene selections, i.e. using all of the genes. in order to compare with traditional machine learning method, we apply cp-rf in an offline fashion, and use results of forced prediction. table  <dig> demonstrates the detailed classification performance per class in confusion matrix, and it shows that cp-rf makes only  <dig> misclassifications. the comparison with a fine-tuned support vector machine is laid out in table  <dig> 

*the results of svm are cited from  <cit> 

tables  <dig> and  <dig> show cp-rf outperforms svm in subgroup  <dig>   <dig> and  <dig>  and they are well-matched in subgroup  <dig> and  <dig>  all of the two misclassifications happen in subgroup  <dig>  because this subgroup only has six cases, the error rate seems very large.

due to the low sample size, the reliability of classification is not guaranteed <cit> . we show the distinct advantage of cp-rf with two measures, corrective predictions and certain predictions under  <dig> confidence levels in table  <dig>  the results show that our method is well-calibrated and make reliable predictions, even in an offline fashion.

part ii: performance of label conditional cp-rf
in this part, we choose two multi-class and unbalanced real-world data sets as examples for cost sensitive learning. the objective is to control risk of misclassification within each class for different misclassifications may have different penalty in medical diagnostics. the first data set is the thyroid disease records  <cit> , and the problem is to determine whether a patient referred to the clinic is hypothyroid. each record has  <dig> attributes in total  corresponding to various symptoms and measurements taken from each patient. the data set contains  <dig> examples in total and is highly unbalanced in its representation of the  <dig> possible classes corresponding to diagnoses. some details are included in table  <dig>  which contains information on the name, index and size of each class.

another dataset is the chronic gastritis dataset  <cit> , which is a common disease of the digestive system with gastric inflammation being its notable features. compare to western medicine, chinese medicine have many advantages in its treatment  <cit> . according to "diagnostic criteria for the diagnosis of chronic gastritis combining traditional and western medicine" set by the integrated traditional and western medicine digest special committee, chronic gastritis is divided into five subtypes . in our application, we collected  <dig> cases from the digestion outpatient department of the affiliated shuguang hospital during february and october,  <dig>  all cases are inspected by both gastroscopy and pathology. each case is correlated with  <dig> kinds of symptoms listed in table  <dig> 

when constructing rf, we let the number of trees equal to  <dig> and the number of variables to split on at each node be ⌊55⌋ . for experiments on thyroid disease dataset, the original dataset is randomly divided into a training set  and a test set . for chronic gastritis dataset, we perform our method in a 10-fold cross validation. average performances are reported.

we are interested in performances comparison of the label conditional cp-rf with the cp-rf. limited by space, we only show parts of results: figures  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> show experiment results on two classes with relatively small samples of thyroid and chronic gastritis datasets. figure  <dig> shows that the cp-rf is not well-calibrated at most of confidence levels within class "primary hyperthyroid" on thyroid, and meanwhile figure  <dig> shows that the efficiency of cp-rf is very low with confidences levels ranging from  <dig>  to  <dig>  in contrast, as is shown in figure  <dig>  label conditional cp-rf is well-calibrated up to neglectable statistical fluctuations and the empirical corrective prediction line can hardly be distinguished from the exact calibration line. aside from the property of calibration, label conditional cp-rf show improvements on predictive efficiency in figure  <dig>  compared with cp-rf. these contrasts can also be observed in experiments on class "deficiency of spleen and stomach "of chronic gastritis datasets .

it is noticeable that the percentage of certain predictions and certain & correct ratios monotonically increase with significance levels. how fast the decline of uncertain prediction goes to zero also depends on the superiority of calculation of p value.

some interest points are extracted in tables  <dig> and  <dig>  it demonstrates that label conditional cp-rf can be used to control the risk of misclassification within each class, so that it can be considered as an alternative approach for cost sensitive learning for unbalanced data.

discussion
part i: cp-rf
parameter sensitivity analysis
a common way to validate an approach is to ensure robustness, that is, the approach must produce consistent results independent of the initial parameter settings. empirical studies show the parameters adjustments have great impacts on cps. normalization of examples affects tcm-knn greatly. as for tcm-svm, not only the normalization but the type and parameters of kernel functions are important. thus, the empirical and non-theoretically alteration hints a potential instability.

to demonstrate the parameter insensitivity of cp-rf, we set up different parameters for cp-rf, with ntrees =  <dig> , <dig> and ntry =  <dig> ..., a. mean and standard deviation of forced accuracy on sonar are reported.

for tcm-knn, we compare the fluctuation of forced accuracy with or without normalization; for tcm-svm, the affection of different types of kernel are illustrated. the results on sonar are summed up in table  <dig>  cp-rf shows a comparatively trivial fluctuation with the change of parameter settings. the advantage comes from the nature of rf and will benefit medical diagnosis.

feature selection
the problem of feature selection is an open question in many applications. in our method, there is no feature selection. take gene expression analysis for example, gene selection is a crucial study and remains unsolved. in yeoh's study, gene expression profiling can accurately identify the known prognostically important leukemia subtypes, by the means of classification using svm, knn, and ann when various selected genes were used. unfortunately, classifications were performed following a process of discriminating gene selections by a correlation-based feature selection. this process is also labor intensive and requiring experiential knowledge. it is better that automated classification should be made with a level of confidence. moreover, due to the low sample size, although their research has yielded high predictive accuracies that are comparable with or better than traditional clinical techniques, it remains uncertain how well the selected genes results will extrapolate to practice in the future  <cit> . cp-rf is especially suitable for this situation, without discriminating gene selections, i.e. using all of the genes, and this may meet the need of an automated classification. moreover, no selection bias is introduced.

part ii: label conditional cp-rf
from experiments in part i, we can see that though cp-rf is well calibrated globally, i.e. the error predictions equal to the predefined confidence level on the whole test data, it cannot guarantee the reliability of classification for each class especially for unbalanced datasets. different from cp-rf, label conditional cp-rf is label-wise well calibrated while the former may not satisfy the calibration property in some classes. because the latter uses only partial information from the whole data set, so the computational efficiency is better.

CONCLUSIONS
most of state-of-the-art machine learning algorithms cannot provide a reliable measure of their classifications and predictions. this paper addresses the importance of reliability and confidence for classification, and presents a novel method based on a combination of random forest, and conformal predictor. the new algorithm hedges the predictions of rf and gives a well-calibrated region prediction by using the proximity matrix generated with rf as a nonconformity measure of examples. for medical diagnosis, the most important advantage of cp-rf is its calibration: the risk of error can be well controlled. the new method takes advantage of rf and possesses a more precise and stable nonconformity measure. it can deal with redundant and noisy data with mixed types of variables, and is less sensitive to parameter settings. furthermore, we extend cp-rf to a label conditional version, so that it can control the risk of prediction for each class independently rather than globally. this modified version can provide an alternative way for cost sensitive learning. experiments on benchmark datasets and real world applications show the usability and superiority of our method.

