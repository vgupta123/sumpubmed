BACKGROUND
the primary purpose of this paper is to introduce two new external indices for measuring the performance of a clustering algorithm for the specific purpose of grouping genes using their expression profiles.

clustering of genes on the basis of expression profiles is a frequently, if not always, performed operation in analyzing the results of a microarray or sage study. often times it is taken as a first step in understanding how a class of genes act in consort during a biological process. statistics and machine learning literature provide a huge choice of clustering tools for such unsupervised learning operations. not only do multiple algorithms exist, but even a single algorithm may rely on various user selectable tuning parameters such as desired number of clusters, or threshold values for forming a new cluster, initial values etc. naturally, the results may be quite varied . although, the hierarchical clustering method upgma  <cit>  is used most often with microarray data sets , the following algorithms are also generally considered to be solid performers in the clustering world and are freely available through various r  <cit>  libraries: a partition method called k-means  <cit> , a divisive clustering method diana  <cit> , a fuzzy logic based method fanny  <cit> , neural network based methods som  and sota  and a normal mixture model based clustering  <cit> .

past evaluations of clustering algorithms have been of general  nature. for example, a good clustering algorithm ideally should produce groups with distinct non-overlapping boundaries, although a perfect separation can not typically be achieved in practice. figure of merit measures   <cit>  such as the silhouette width  <cit>  or the homogeneity index  <cit>  can be used to evaluate the  separation of groups obtained from a clustering algorithm. the concept of stability of a clustering algorithm was taken into consideration in  <cit>  . a resampling based validity scheme was proposed in  <cit> .

although popular statistical clustering algorithms  have often been reported to successfully produce clusters of functionally similar genes, it is important to make that requirement a part of the evaluation strategy in selecting one from a list of competing clustering algorithms. some attempts in this direction have been made in recent years . these papers propose scoring a clustering algorithm based on the biological similarity of the resulting clusters in some fashion, although all of them ignore the stability issue. the index proposed in  <cit>  is based on the idea of mutual information content between statistical clusters and biological attributes. the entropy is taken as a measure of information content and a filtered collection of all go terms is used as attributes.  <cit>  used an anova based test of equality of means amongst the cluster members to define their validation index. one potential difficulty with this approach is that a quantitative conversion of biological attributes is needed .  <cit>  used an information content technique proposed by  <cit>  to compute their validation index. there also exists another set of papers  where the main objective is that of biological interpretation of the clusters produced by a clustering algorithm.

in this paper, we introduce two performance measures for evaluating the results of a clustering algorithm in its ability to produce biologically meaningful clusters. the first measure is a biological homogeneity index . as the name suggests, it is a measure of how biologically homogeneous the clusters are. this can be used to quantify the performance of a given clustering algorithm such as upgma in grouping genes for a particular data set and also for comparing the performances of a number of competing clustering algorithms applied to the same data set. the second performance measure is called a biological stability index . for a given clustering algorithm and an expression data set, it measures the consistency of the clustering algorithm's ability to produce biologically meaningful clusters when applied repeatedly to similar data sets. a good clustering algorithm should have high bhi and moderate to high bsi. we also provide an r-code with some simple illustrations for computing these indices . we evaluated the performance of ten well known clustering algorithms using this dual measures approach on two gene expression data sets and identified the optimal algorithm in each case.

we use publicly available go  <cit>  tools and databases to obtain the functional information in our illustrative real data examples. they are used to produce a reference collection of functional classes with respect to which a clustering algorithm was judged for homogeneity and stability. in particular, it has no relations to the idea of co-clustering which uses statistical clustering within each go term.

RESULTS
we first consider the breast cancer data. this data set consisted of expression profiles of  <dig> significant genes based on their eleven dimensional expression profiles over four normal and seven dcis samples. based on the size of the data set we judge that a cluster size between four and ten might be appropriate. thus, both the biological homogeneity index  and the biological stability index  was computed for each clustering algorithm in this range of cluster numbers. as described in the methods section, we used eleven functional classes for this study. figure  <dig> shows the plots of bhi for the ten clustering strategies along with the results for random clustering. the thick black piecewise linear curve denotes the 95-th percentiles of the bhi values obtained by random clustering â€“ these are computed by a monte carlo scheme as described in the methods section based on  <dig> iterates. thus, the probability of obtaining a value of bhi as high as that just by chance is estimated to be less than 5%. therefore, any score higher than the thick black curve by a clustering algorithm will be judged to be "statistically significant".

three of the seven clustering algorithms were used with two choices of dissimilarity measures. these are indicated by the line types with solid lines corresponding to one-minus the pearson's correlation coefficient as a dissimilarity measure and dashed lines corresponding to euclidean distance, respectively. in the rest of the paper, the term correlation refers to the pearson's correlation coefficient. the plot of bhi reveals that upgma with the correlation measure happens to produce most homogeneous biological clusters based on this data set and the results are statistically significant when the number of clusters are between six and ten. we also computed p-values under a non-uniform resampling which maintains the same cluster sizes  as produced by a given clustering algorithm. this is easily accomplished by drawing a random sample with probability proportional to the original cluster sizes instead of a simple random sample in step  <dig> of the statistical scoring algorithm. note that it is computationally expensive however, since separate resampling needs to be done for each k and clustering algorithm combination. upgma with correlation and k between six and nine remains significant at 5% based on the non-uniform resampling as well . interestingly, the performance of most other clustering algorithms was not significantly better than random clustering except for fanny with cluster size k =  <dig>  and diana  with k =  <dig> 

the biological stability index  is plotted in figure  <dig>  the 95th percentile bsi values under random clustering were all nearly zero and are not plotted further. we can say that all the clustering algorithms have produced significantly more consistent answers as compared to random clustering which is perhaps not too surprising. the fuzzy logic based clustering fanny seems to be the least stable and upgma , along with diana , seems to be the most stable in their capabilities of producing clusters using reduced data sets that are biologically alike. considering both indices, we would say that upgma , which also has decent stability, is the best choice for this data set provided investigators select six to nine clusters where seven seems to be the optimal number of clusters to maximize the biological homogeneity. diana  will be a worthwhile consideration if ten clusters are desired.

next we report the results for the sporulation data set. as stated in the methods section, we have used two different sets of functional classes for biological validations. for the details, we refer to figures  <dig> and  <dig> which show the biological homogeneity index  and figures  <dig> and  <dig> which show the biological stability index  under the two functional schemes. a range of six to twelve was selected for the number of clusters. the plots of bhi show that for this data set, under both sets of functional classes, fanny, diana , k-means and sota are doing well whereas upgma and som are not. model based and diana  perform well under the funcat classes but not with respect to the fatigo classes.

model based selected only six clusters even if a larger maximum number of clusters was specified. the biological stability index, on the other hand was high for upgma and fanny  but low for k-means and fanny . thus, considering everything, fanny  seems to be the optimal algorithm for the yeast data set. other overall good performers were diana  and sota.

discussions and 
CONCLUSIONS
historically, validation measures for clustering algorithms are based on the data themselves. they measure the extent of a clustering algorithms's ability in finding similarity structures hidden in the data. however, for clustering biological data such as the gene expression profiles, it would be reasonable to consider external measures that employ the existing biological knowledge . as argued by  <cit> , internal measures by themselves may not be suitable for biological data which are often subject to many sources of noise .

the two indices introduced here are useful in quantifying the results of an unsupervised clustering in grouping genes with similar biological functions given a reference collection of relevant functional classes. these indices will be preferable over internal indices when there is a substantive existing biological knowledge about the genome under consideration .

as mentioned in the background section, the stability aspect was absent in existing external indices based on biological information. in our earlier work  <cit> , diana  was recommended based on our internal stability measures and an external fom measure called "distance from model profiles". it should be noted, however, that diana  was not included for benchmarking in  <cit> . based on the new external fom, the biological homogeneity index bhi, both diana  and  look good; however based on the new external stability measure bsi, diana  is preferable over diana .

past studies have often concluded that clustering of the gene expression profiles  show that functionally similar genes are grouped together. this is often concluded by inspecting a handful of handpicked genes. such conclusions are inherently incomplete unless one can quantify the agreement between the clusters produced via the expression profiles and the biological classes because it is likely that many biologically unrelated genes will be grouped together as well.

the proposed indices are easy to interpret and easy to implement. they are also useful in identifying the optimal clustering algorithm for a given data set in its ability to cluster biologically similar genes. as illustrated in this paper, no single clustering algorithm is likely to be the winner in all data sets. the approach introduced here will be even more useful as the gene ontology databases grow with time.

as shown with the illustrated data sets, the biological indices can also guide us to determine the number of clusters to be used in a clustering routine. once an optimal algorithm is determined one may choose k that maximizes bhi for that algorithm in the given range. this approach would indicate that seven and eleven, respectively, are the optimal number of clusters to be used for the breast cancer data and the sporulation data.

