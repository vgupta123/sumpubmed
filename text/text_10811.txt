BACKGROUND
reconstructing the evolutionary relationships among species based on their genetic information is one of the primary objectives in phylogenetic analysis. in recent years, numerous heuristics to reconstruct phylogenies for large data sets have been proposed  <cit> . in addition, parallel tree-reconstruction programs have been implemented  <cit> .

to date, distance-based methods introduced by cavalli-sforza and edwards  <cit>  and by fitch and margoliash  <cit>  appear most appropriate to reconstruct phylogenies based on thousands of sequences. these methods are a compromise between computational speed and topological accuracy  <cit>  and run typically in o time for n sequences  <cit>  or in o for recently suggested approaches  <cit> . clustering algorithms form a major class of distance-based methods  <cit> . they do not have an explicit objective function that needs to be optimized. they rather group sequences  iteratively to reconstruct a distance-based phylogenetic tree. upgma is a popular method to infer phylogenies with the constraint that a molecular clock is imposed on the evolutionary process. other clustering approaches have been proposed to relax the molecular clock assumption  <cit> .

an attempt to boost the accuracy and to reduce the computational burden is the introduction of k-representative set concepts  <cit> . k-representative sets consist of at most k elements but retain the most important information from whole sets. in this paper, we extend our original approach  <cit>  by introducing a more natural k-representative set concept. in a nutshell, representative sets are regarded as components to construct shortest triplets, each of which comprises three closely related sequences from three k-representative sets. the collection of shortest triplets serves as building block for a new distance-based clustering method called shortest triplet clustering algorithm .

RESULTS
simulations were run on a pc cluster with  <dig> nodes. each node has two  <dig>  ghz processors and  <dig> gb ram. seq-gen  <cit>  was used to evolve sequences along trees using the kimura two-parameter model  <cit>  with a transition/transversion ratio of  <dig> . we generated  <dig> simulated data sets of  <dig> sequences each with sequence lengths  <dig>   <dig> and  <dig> nucleotides , respectively. as one model tree, we used the rbcl gene tree with diameter  <dig>  substitutions per site as inferred from an alignment of  <dig> rbcl-genes  <cit> . we call this the rbcl-simulation.

in a second experiment, the so-called large simulation, tree topologies were drawn from the yule-harding distribution  <cit> , and edge lengths were drawn from an exponential distribution and subsequently rescaled such that the mean diameter of the tree was either  <dig> ,  <dig> ,  <dig> , or  <dig> . for each value of the diameter we generated  <dig> trees with  <dig> sequences and  <dig> trees with  <dig> sequences. thus, a total of  <dig> trees were used.

finally, we tested the accuracy and runtime of the stc and compared it with six other commonly used distance-based methods. more specifically, we investigate the performance of the neighbor-joining method   <cit>  implemented in paup*  <dig>   <cit> , bionj  <cit> , weighbor  <dig>   <cit> , harmony greedy triplet and four point condition   <cit>  as well as greedy minimum evolution  and balanced minimum evolution   <cit> . unfortunately, no distance-based program is available for the disc-covering method  <cit> . all methods were combined with dnadist version  <dig>   <cit>  and pairwise distances were corrected for multiple hits according to the model used in the simulation. moreover, we examined the performance of all methods when the balanced nearest neighbor interchange   <cit>  is used as a post-processing step.

further, to illustrate the performance of stc we re-analyzed the 96-taxon alignments of sequence length  <dig> nt, that were analyzed in  <cit>  and available at . the  <dig> trees were split into three groups called "slow" , "moderate"  and "fast" . we call this the re-analyzed simulation.

the accuracy of a tree reconstruction method for a simulated data set is measured by the robinson and foulds  distance  <cit>  between the inferred tree and the model tree used to generate the data set. the rf distance between two trees is the number of bi-partitions present in one of the two trees but not the other, divided by the number of possible bi-partitions. thus, the smaller the rf distance between two trees the closer are their topologies. in other words, the smaller the rf distance is between the inferred tree and the model tree the higher is the topological accuracy of the tree reconstruction method.

in the following we discuss the results of the rbcl-simulation, and the large simulation and the re-analyzed simulation.

rbcl-simulation
large simulation
due to the increase in runtime, weighbor could not be tested. table  <dig> and  <dig> show that stc gives better results than the other methods independent of the diameter. all methods display a decrease in accuracy when the number of sequences changes from  <dig> to  <dig>  as shown in table  <dig> and  <dig>  bnni boosts the accuracy of all methods including stc. all methods give similar results when being used together with bnni.

re-analyzed simulation
except for stc, the accuracies for the other methods displayed in table  <dig> and  <dig> were taken from  <cit> . table  <dig> shows that stc outperforms the other methods in terms of topological accuracy with the exception that weighbor is slightly better than stc with respect to the slow simulation group. if bnni is applied, all methods exhibit an almost identical performance .

another look at the performance
instead of looking at the average rf distance, we suggest to take a closer look at the simulated data. for each simulated data set, that is subjected to the stc and six other tree reconstruction methods mentioned above, we compute the rf distance between the reconstructed tree and the model tree for all methods. figure  <dig> illustrates the results for the large simulation when comparing stc with nj  and stc with the second best method bme . in each diagram specified by the number of taxa and reconstruction methods,  <dig> points are displayed, that resulted from  <dig> simulations for each of the tree-diameters . although four tree-diameters were studied only two clouds of points are discernible, where the cloud in the north-east corner of each diagram represents the simulations with the tree-diameter  <dig> . the remaining  <dig> points gather in the south-west cloud because the rf-distances from trees with diameter  <dig> ,  <dig> ,  <dig>  are not substantially different from each other . more precisely, the horizontal and vertical axes indicate the rf distances of stc and nj , respectively. each point in the graph presents the rf distance for a simulated data set. points above the dotted line are examples where the rf distance of the stc-tree is less than the rf distance of the nj-tree or bme-tree. thus, the stc gives higher topological accuracy than nj or bme with respect to the simulated data set. for example, figure 1a illustrates the comparison between stc and nj with respect to  <dig> taxa data sets.  <dig> out of  <dig> points are above the diagonal, thus, stc gives better results than nj in about 95% of the simulations. for the remaining  <dig> alignments , two methods showed the same rf distance. finally, we found  <dig> points below the diagonal in which case nj outperforms stc. for the large simulation , nj is worse than stc in all cases. however, the second best method bme is better than stc in 11% and 5% of the cases with respect to  <dig> and  <dig> sequence data sets.

similar results hold for the other methods. these results are summarized in table  <dig> where we show the percentage of simulations in which stc is at least as good as the other methods.

again, if bnni is applied we observe that no substantial difference among the various approaches. the accuracy of the methods is mostly determined by bnni .

CONCLUSIONS
we are presenting k-representative sets which allow us to design a fast and accurate method to reconstruct phylogenies from large data sets with  <dig> or more taxa. simulations show that stc gives better results than other tested methods in terms of topological accuracy. however, if bnni is introduced as a subsequent optimization step, the differences in the performance disappear. all methods show more or less the same accuracy. thus, one should apply bnni to improve the topological accuracy.

the time to reconstruct a tree of up to  <dig> sequences is not really an issue for all tested distance-based methods, with the exception of weighbor. weighbor needed about  <dig> minutes to reconstruct a tree with  <dig> sequences, thus it is only applicable to data sets with up to some hundred sequences. for data sets with up to  <dig> sequences, the remaining methods needed less than one minute to output a tree, thus the difference between methods in terms of runtime is not significant. for data sets with  <dig> sequences, stc  with bnni took about  <dig>   minutes to reconstruct a tree. nj  with bnni were slower and consumed approximately six minutes to output a tree. in short, the combination of stc and bnni efficiently reconstruct trees for large data sets in both terms of topological accuracy and runtime.

finally, we did not systematically evaluate the impact of the number of representatives k. we present some preliminary results for k =  <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig>   <dig> and  <dig>  figure  <dig> shows that the rf distance of stc decreases when k grows from  <dig> to  <dig>  this proves our intuition that a too small number of triplets leads to an inaccurate estimate of path lengths and edge lengths. when k ranges from  <dig> to  <dig>  the rf distance remains more or less unchanged. for k ≥  <dig>  the rf distance increases steadily indicating a loss of accuracy. the decrease in accuracy is explained by the inclusion of triplets with large distances which include noise and disturb the reconstruction. thus, we chose k =  <dig> as a good compromise between the accuracy and computational complexity for all data sets. that is, the practical complexity of the stc algorithm is only o.

