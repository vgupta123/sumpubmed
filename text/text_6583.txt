BACKGROUND
metazoan cells have the ability to adopt an extraordinarily diverse spectrum of cell shapes. for example, the cuboidal, polarized morphology of epithelial cells differs markedly from that of neuronal cells, which extend long, thin, and highly-branched projections. the shape of an individual cell is the result of a complex interplay between the activity of thousands of genes and the cell's environment. understanding this interplay is a fundamental challenge in developmental and cell biology. currently, there are two key aspects to deciphering cellular morphogenesis on genome-scale. the first is determining the individual functional contributions of every gene towards the regulation of cell shape, and the second is to describe how complex relationships between cell shape genes affect morphology. with the advent of high-throughput rna interference  screening technologies, particularly in model systems such as drosophila melanogaster  <cit> , it is now possible to systematically query the involvement of genes in the regulation of different cellular processes and functions. typically, rnai-based genetic screens involve the acquisition of relatively low-content, single-dimensional data which is easily analyzed using conventional and unbiased means and thus feasible to perform on genome, or multi-genome scales  <cit> . in order to facilitate similar analysis of image-based screens, we and other researchers have recently developed novel image segmentation algorithms to rapidly quantitate hundreds of different parameters at a single-cell level in an automated fashion  <cit> , and we have demonstrated that such image segmentation algorithms can be used in the context of genetic screens  <cit> . notably however, this and other similar screens  <cit>  have been 50– <dig> fold smaller in scale than typical low-dimensional screens and are not yet genome-scale. the reduced scale of these screens is due, largely in part, to the fact that the expert opinion of cell biologists is still an essential and rate-limiting aspect in the analysis of many image-based datasets. although human intervention is not required in screens where the potential phenotypic outcomes are few or binary in number , such intervention is currently necessary in order to identify novel/subtle phenotypes in image-based datasets of genetic or chemical perturbations where the dynamic range of cellular phenotypes cannot be predicted before the data is collected. for example, in genome-scale screens for regulators of cell shape, it is impossible to predict a priori the diversity of morphologies that will ultimately be present in the dataset. the failure to accurately measure this phenotypic variation will lead to concomitant classification errors, especially false negatives, and misleading results. current methodologies usually employ a two-step procedure to maximize the amount of variation that is captured in a particular image-based analysis. first, 100– <dig> phenotypic features are measured on a single-cell level , and second, supervised techniques assisted by biologists are used to both reduce dimensionality of feature space and carrying out classification on the images. the biologist has to at least perform preliminary qualitative visual scoring of a small part of the dataset in order to gain a crude assessment of the phenotypic variance that is present in this subset. unfortunately, it is impossible to perform such analysis in the course of screens where millions of images are acquired, thus the ability of these screens to identify new phenotypes is greatly limited. the issues of defining meaningful phenotypes and describing them using informative feature subsets are closely related. automated feature space reduction schemes have been implemented in the context of high content screen, including feature extraction methods examined in  <cit> , factor analysis in  <cit>  and svm-rfe method in  <cit> . these methods allow more effective modelling of existing phenotypes, and also prompt the necessity of updating informative feature sets so that they can not only model the existing, but also discover the novel.

cluster analysis is widely used to reveal the structure of unlabeled datasets. specifically, there are a number of methods that have been developed in order to estimate cluster numbers from a dataset such as using a series of internal indices  <cit> , jump methods  <cit> , and weighted gap statistics  <cit> . moreover, supervised approaches to cluster validation such as using re-sampling strategy  <cit> , prediction strength  <cit> , methods based on mixture models and inference of bayesian factors <cit> , or strategies which are application-specific  <cit>  have also been previously implemented. nevertheless, most existing methods are subject to certain hypothesis on a fixed dataset, and cannot be directly used for online phenotype discovery where new images continuously extend the dataset and millions of cells are involved. improper assumptions on data structure may cause incorrect division or merging of biologically meaningful phenotypes. to avoid this problem, such methods combine each new image with the whole existing dataset  and frequently re-run from the very beginning.

methods for online phenotype discovery should be sensitive and flexible to various phenotypes and avoid frequent re-modelling involving complete existing datasets. as a kernel machine based novelty detection method, one-class svm is used for "off-line" phenotype discovery  <cit> . however, two major points limit its application to high-throughput image-based screens, especially for screens of cell shape regulators. first, in one-class svm all the test samples are classified into two classes, "novel" and "known", however many high-throughput rnai datasets may potentially contain multiple diverse and unique novel phenotypes which should not necessarily be grouped together. subsequent cluster analysis would be needed to identify and model different novel phenotypes following the use of one-class svm. second, each time a novel phenotype is discovered using one-class svm, the support vectors need to be modified so that the newly discovered phenotype are included as "known" in the following loops, otherwise it will continuously be identified as novel in future. as mentioned earlier, in a typical rnai screen on  <dig> – <dig> s genes with dozens of images for each rnai and 100s of cells in each image, such updating would involve millions of cells and is intractable.

here we describe the development of an online phenotype discovery pipeline that we implemented in the context of a high-throughput image-based rnai screen for regulators of cell shape. a simplified scheme of online phenotype discovery is shown in figure  <dig>  online phenotype discovery demands adaptively identifying various novel phenotypes based on multiple existing phenotypes , being sensitive and flexible to various new phenotypes and avoiding frequent re-modelling using large existing dataset. our method includes two key components: phenotype modelling and iterative cluster merging. first, a gaussian mixture model  is estimated for each existing phenotype following  <cit> . second, iterative cluster merging are performed based on gap statistics. when a new image is incorporated, we sample the gmm of each existing phenotypes and start a series of merging loops. in each loop, the image is combined with sample set for one existing phenotype and we estimate cluster number in such combined dataset using gap statistics and use gmm of existing phenotype as part of the reference distributions. if some cells in the new image are clustered together with samples from the existing phenotype, they are merged into the existing phenotype, i.e. they are included into the dataset of existing phenotype and deleted from the new image. the iterations continue until sample set from each existing phenotype has been combined with the new image and has merged with its counterpart . upon completion of all loops, the remaining cell groups in the new image are identified as the candidate of new phenotypes. by sampling reference dataset from new image and existing phenotype separately, utilizing the gmm for existing phenotypes as  reference distribution and involving existing clusters one by one, our method improves the ideas in  <cit>  and becomes more effective. experimental results show that the proposed method is robust and efficient for online phenotype modelling and discovery in the context of diverse image-based screens, especially rnai screens on drosophila.

RESULTS
synthetic dataset
overcoming large sample size difference between two clusters
difference between sample numbers of distinct clusters could bias cluster number estimation. we propose to tackle this problem by using gmms as reference distributions for existing phenotypes in gap statistics and validate our method using simulation.

each simulated dataset consists of observations from two populations ℙ <dig> and ℙ <dig>  each population are sampled from a two dimensional gaussian distribution with means  for ℙ <dig> and  for ℙ <dig>  and an identity covariance for both groups. gap statistics  <cit>  are used to estimate number of clusters from the experiment dataset ℙ <dig> ⋃ ℙ <dig>  this method uniformly samples different reference datasets from the support of ℙ <dig> ⋃ ℙ <dig>  and here the number of reference datasets is set to  <dig>  then the experiment dataset ℙ <dig> ⋃ ℙ <dig> and the  <dig> reference datasets are clustered into candidate cluster numbers k =  <dig> .. k, and we set k =  <dig>  for each clustering result, we measure the compactness of obtained clusters using "within cluster dispersion". for each cluster number k, such dispersion are measured separately on experiment dataset and each reference dataset, and gap statistic for k, denoted as gap, is defined as the average value of difference between the dispersion on experiment dataset and that on each reference dataset, meanwhile we obtained standard deviation of such difference across  <dig> reference dataset, and denoted as sk.

some typical gap statistic curves are summarized in figure  <dig> to illustrate the problem and validate our method. x axis in figure  <dig> indicates candidate cluster number i, and each data point denote gap while the error bar indicating sk. larger value of gap means better compactness when the dataset is clustered into k clusters , then a increase from gap  to gap  means the clustering performance is improved from k- <dig> to k. we take sk into consideration when estimating cluster numbers following  <cit> , and take the estimated cluster number as the first k with gap>gap-sk+ <dig> . details of gap statistics method are discussed in methods section.

when samples from ℙ <dig> and ℙ <dig> have identical number of  <dig>  gap statistics can correctly judge sample number as  <dig>  then we set sample number from ℙ <dig> as  <dig>   <dig>   <dig>   <dig>   <dig> and  <dig>  and sample number from ℙ <dig> are fixed as  <dig>  figure  <dig>  left and figure  <dig>  middle show that when number difference is over six-fold, gap statistics does not work correctly.

a ten-fold difference of cell numbers between existing phenotypes and new images is not the worst situation we would face in online phenotype discovery. based on the results given in figure  <dig>  middle, samples from two obviously different populations would be merged together. we propose to solve this bias through fitting a gmm model for existing phenotypes, as well as using gmm as reference distribution for each existing cluster in gap statistics.

next, we consider ℙ <dig> as existing cluster with known distribution model. if we use gaussian model for ℙ <dig> as reference dataset for gap statistics, it gives the correct result in  <dig> % occasions across  <dig> experiments even with ten-fold difference in sample number. figure  <dig>  right shows one gap curve with ten-fold difference, where gap--s2) = - <dig> , meanwhile gap>gap-s <dig>  thus, the estimated cluster number is  <dig> rather than  <dig> >gap), because data point for k =  <dig> is higher than the bottom of error bar for k =  <dig> 

the results are summarized in table  <dig>  generally speaking, when two distinct clusters have ten-fold difference in sample numbers, original gap statistics method using uniform reference fails to estimate cluster number correctly, while our method of using accurate model as reference distribution can overcome this issue and give a correct estimation of cluster number.

simulating typical cells using seven types of polygons
seven types of polygons are defined based on the fluorescent cell image from a real genome wide rnai screen , and a simulation dataset is constructed based on these different types of polygons. information about these seven polygons is shown in figure  <dig> and some details on generating these polygons are introduced in .

 <dig> polygons from each of seven types were generated and used as training dataset, i.e. the set of existing phenotypes, and another  <dig> polygons were generated for each type to as testing dataset. in each experiment, we started from a certain set of existing phenotypes and built gmm from training samples, meanwhile, we iteratively chose two of seven polygon types and selected  <dig> polygons apiece from the testing dataset to form a synthetic test image, altogether  <dig> images can be formed for one experiment. using the model estimated from the training set, we can identify existing and novel type of polygons from these synthetic images, and observe the performance of our method under different number of novel phenotypes and order of image input.

performance under different sets of existing phenotypes
box and whisker plots for performance under different conditions
as indicated earlier, the test datasets always consist of seven phenotypes, we can then change the conditions of experiments  and observe the performance for certain phenotype to test the robustness of our method. across experiments with different input order of images and composition of existing phenotypes, the performance on certain phenotypes are ranked, and such distribution of performance are illustrated using box and whisker plot. we show the box plots for ellipses and 16-point stars in figure  <dig> and explain the meaning of such plots in its caption. we observed that larger variation of accuracy values correlates with lower number of existing phenotypes, which is because the models of novel phenotypes are estimated from test samples input in the earlier stage of experiment and updated as new images are included. thus, the accuracy has a larger variance across different image input order when the number of existing phenotypes is low. this issue indicates the importance of more robust strategy of model updating. however, the overall performance of our method is robust regarding to different condition of experiments.

performance comparison with svm based methods
one-class svm  <cit>  tackles the novelty detection problem of differentiating novel phenotypes from known ones by estimating a distribution from the core structure of existing dataset and model such distribution using a series of support vectors. it then labels each testing samples as "known" or "novel" using the model built upon support vectors. compared with svm used in classification, a parameter ν ∈   is involved in one-class svm. this parameter is used to define the core structure of the existing dataset, and it has two roles, i.e. the asymptotic upper bound of training data which are labelled as outliers and the lower bound of the fraction support vectors in training samples. however, one-class svm itself cannot be used to handle problems such as the restoration of multiple existing phenotypes. we modify one-class svm to fit it into the scenario of online phenotype discovery. each new image is combined with the support vectors trained from the existing samples and novelty detection is carried out using one class svm with gaussian kernels of width  <dig>  and various parameters ν to define the scale of support vectors and outliers. after novelty detection, each test sample labelled as "known" is subject to multiple linear svm classifiers  and assigned into one of multiple existing phenotypes according to majority vote among classifiers. we detailed one-class svm and our modification in .

we compared our method and svm based method and figure  <dig> shows the comparison results in two occasions. four sets of parameters are used for one-class svm. figure 6left shows the performance when ellipses are considered as novel phenotype while the other six phenotypes serve as the set of existing dataset; and figure 6right shows the performance when 16-point stars are the only novel phenotype. accuracies for all seven phenotypes were measured and averaged across  <dig> experiments with different orders of image input. in both cases, when ν =  <dig> , svm based method merged most of the new samples into existing phenotypes and gave best performance on existing phenotypes , while svm with ν =  <dig>  left out most of the new samples as outliers and gave the best accuracy for the novel phenotype, meanwhile, the difference between best and worst accuracy in one experiment could be as large as 25%; our method outperformed most svm based method on the accuracies for at least  <dig> of  <dig> phenotypes and the difference between best and worst accuracy across seven types are never greater than 10%.

cell culture, image segmentation, morphological feature extraction and selection
cell culture and image acquisition
as a next step, we implemented our methods in the context of a high-throughput image-based screen. in particular, we focused on a novel dataset of images acquired in the course of a genome-scale rnai screen for regulators of drosophila kc <dig> cell shape that have hemocyte-like properties . by using dsrna to target and inhibit the activity of specific genes/proteins, the role of individual genes in regulating morphology can be systematically determined. briefly, kc <dig> cells are bathed in the presence of individual dsrnas targeting all known drosophila protein kinases and phosphatases in 384-well plates . following a 5-day incubation period, the cells are fixed and stained with reagents in order to visualize the nuclear dna , polymerized f-actin , and α-tubulin . for each well, sixteen images from each of the three channels  were acquired in an automated fashion using an evotec spinning-disk confocal with a 60× water objective. auto-focusing is performed in a two-step fashion by first focusing on the bottom well at each individual site, and then moving the objective by the same z-distance  at each site. the images were captured at a binning of  <dig> and have a resolution of 661* <dig> pixels.

image segmentation
to analyze the morphology of single cells, it is necessary to first delineate the boundaries of individual cells. direct segmentation of the cell bodies in the f-actin and α-tubulin channels is difficult due to the complex morphology of cellular boundaries. segmentation of nuclei in the dna channel is relatively easier, and its segmentation results provide the rough position information of the cell bodies. herein, we utilize a two-step segmentation procedure  <cit>  including nuclei segmentation on dna channel, and cell body segmentation of images derived by combining images from the dna, f-actin and α-tubulin channels.

in nuclei segmentation, the nuclei are first separated from the background by using a background correction based adaptive thresholding method  <cit> . however, the clustered nuclei cannot be separated by the adaptive thresholding method. to separate the clustered nuclei, the centres of the nuclei are first detected using a gradient vector field  based detection method  <cit> . specifically, we filter the nuclei image using a gaussian filter, which suppresses the noise and generate local maxima inside cells, and these local maxima correspond to the nuclei centres. however, there are still some local maxima due to noise. to further eliminate the noisy local maxima, we detect the true cell centres using gvf method. it is a well-known fact that in an electric field, the electric field lines point to the positive electrodes, and the free negative electrons move along the electric field lines and stop at these electrodes. in gvf, the gradient-vector lines also point to the local maxima. analogous to the electron moving inside the electron field, we put one particle on each detected cell pixel and pushed it along the gradient vector lines. consequently, these particles stop at these local maxima. since no or very few particles stop at non-maxima and noisy local maxima, the true cell centres can be identified by choosing the points that have many particles  <cit> . after the centres of nuclei are detected, the nuclei are segmented using the marker-controlled watershed algorithm.

to use both f-actin and α-tubulin channels information, we combine the two channels' signal as i = / <dig>  where i, if-actin and iα-tubulin denote the combined image, f-actin channel image and iα-tubulin channel image respectively. we then segment the cell bodies using the combined image. first the cell bodies are separated from the background using the aforementioned adaptive thresholding algorithm. the nuclei segmentation results facilitate the segmentation of cell bodies by providing the rough position information of cell bodies. herein, we employ the marker-controlled watershed and the nuclei segmentation results to segment the individual cell bodies. to reduce the over-segmentation of cell bodies a feedback system proposed in  <cit>  is employed. three scoring models, which measure the morphological appearance, gradient and edge intensity of cell pairs respectively, are built to identify the over-segmented cell bodies, and guide the merging procedure  <cit> . detailed shape and boundary information of nuclei and cell bodies is obtained after the two-step segmentation procedure.

morphological feature extraction and feature selection
cellular phenotype identification depends on choosing a rich set of descriptive features, which is one of the most critical steps for pattern recognition problems. to capture the geometric and appearance properties,  <dig> morphology features belonging to five categories are extracted following  <cit> . the selected features include a total of  <dig> wavelet features ,  <dig> geometric region features describing the shape and texture characteristics of cells  <cit> ,  <dig> zernike moments features with selected order of  <dig>  <cit> ,  <dig> haralick texture features  <cit>  and a total of  <dig> phenotype shape descriptor features   <cit> . a feature selection procedure is necessary to de-noise the dataset and describe it in the most informative way. as the datasets and phenotype models are being updated adaptively, an unsupervised feature selection without relying on phenotype labels is used to supply a stable feature subset. it is based on iterative feature elimination using k nearest neighbour features following  <cit> . in this study, an informative subset of fifteen features is selected to quantify the segmented cells.

online phenotypes discovery in the context of rnai high-throughput screenings
fitting gmm model for existing phenotypes
we first performed a visual examination on a subset of dataset in order to define images and cellular morphologies of typical normal cells, as well as cells in three distinct cellular phenotypes. we termed these quantitative categories "long punctuate actin ", "cell cycle arrest " and "rho <dig> ", collected images in these categories and combined them with images of  <dig> normal cells, to form our cell database of existing phenotypes. we estimated a gmm for each existing phenotype using em algorithms. a uni-modality model is obtained for normal and lpa phenotypes, and cca and rho phenotypes end up with  <dig> and  <dig> gaussian terms respectively and the covariance matrices are set to be diagonal. a brief introduction of each existing phenotype is shown in figure  <dig> 

case 1: merging cells in existing phenotypes
to validate our method's ability of restoring three existing phenotypes: normal, lpa and cca, we carried out  <dig> times of five-fold cross validation. in each experiment, 20% of cells from each existing phenotypes were taken out and combined to form a flow of new images, these cells were divided into seven groups, simulating seven new images. we defined merging accuracy for each phenotype as the proportion of test samples merged into its original phenotype. the mean and standard deviation of accuracies across  <dig> experiments was shown in table  <dig> 

our method can identify and merge cells into original phenotypes well. in the third column of table  <dig>  we list the typical mistakes made during the merging loops. some cells with normal and lpa phenotypes are not merged correctly, and such mistakes suggest the existence of previously undefined phenotypes in such images.

case 2: discovering new phenotypes: cross validation based on known phenotypes
to validate our method's ability of discovering new phenotypes, we performed the following experiments after the a priori identification of four existing phenotypes  by biologists. in each experiment, three of four phenotypes were considered as existing phenotypes, and cells in the other phenotype were divided into groups with  <dig> cells. these cell groups represent an incoming dataset of new images containing "novel phenotypes". given only one phenotype in the testing images, ideally in each experiment, our method would identify the first of such cell groups as a new phenotype, model this phenotype, assign all the other testing images to this "novel phenotype", and no testing cells would be merged by any of the other three phenotypes. fifty experiments were performed to identify each phenotype,  <dig> cells served as "novel group" for normal and lpa phenotypes while  <dig> cells were used for cca and rho <dig> phenotypes. the experiment results are summarized in table  <dig>  "accuracy" is defined as the ratio between the number of testing cells assigned to a single cluster and the total number of testing cells, and such accuracy is calculated after all three merging loops for each experiment.

case  <dig> shows our method's ability of identifying novel phenotypes. we hypothesize that the relatively low accuracy for cca and rho phenotypes can be attributed to the small number of samples and incomplete understanding of which phenotypes is the biological representative for the entire treatment class. high classification accuracies for normal cells in both case  <dig> and case  <dig> provide strong validation of the ability of our methods to identify wild-type cells. while the overlap of normal and lpa serves as a starting point for novel phenotypes discovery.

case 3: identifying multiple novel phenotypes from online image input and performance comparison with svm based methods
in this case, we still used the test dataset in case  <dig>  which included a total of  <dig>  cells from four phenotypes. in each group of experiments we started from the models  of two existing phenotypes, and all  <dig>  test cells were divided into  <dig> images with cells from two phenotypes in one image, and all images were input with  <dig> different orders. altogether, three groups of experiments were carried out, and in each experiment, normal phenotype were paired with one of the other three phenotypes, to serve as sets of ''existing phenotypes''. both our method and svm based methods were used in each experiment, and we can thus validate our method's ability to deal with multiple novel phenotypes well as the performance under different order of image input.

having multiple phenotypes in a single image is a challenge in the analysis of image based high-throughput screens. our method successfully tackle such cases and identify multiple phenotypes from online image input, and can therefore provide a better perspective for further quantification of the whole image, en route to the identification for the role of each gene.

identifying "rl/tear-drop" phenotype in the context of drosophila genome-scale rnai screen
typically, a new image which is incorporated into the dataset may have less than fifty cells, which can severely impact the ability to quantitatively determine and distinguish novel phenotypes. but such images can still be incorporated into our analysis by discarding images with cell numbers < <dig>  and putting together cells from multiple new images to make a combined dataset having at least  <dig> cells. we collected cells from four existing phenotypes, assembled them as training dataset, modelled existing phenotypes and used such phenotype models to analyze images acquired as part of a drosophila genome-scale rnai screen. implementation of our method revealed a phenotype that was undetected by visual inspection which we termed as "rl/tear-drop". these cells are small in size and having smooth boundaries and non-round shape. figure  <dig> supplies some information and typical images for this phenotype. such phenotype was initially discovered in wells where cells had been incubated in the presence of rl rnai. drosophila rl, or rolled is the homolog of mammalian erk kinase and is a central regulator of a host of cellular processes  <cit> . importantly, the rl/tear-drop phenotype was not scored during human inspection of the images. the detection of cells with the rl/tear-drop phenotypes in an image or well often correlates with detection of cells with an lpa phenotype, and we hypothesize that rl/tear-drop represents a phenotypes that occur as cells transition from normal to lpa. we collected more than  <dig> cells with the rl/tear-drop phenotype through analysis of replicate experiments, modelled this phenotype with gmm, and used it to analyze cells from the new images. our method detects rl/tear-drop cells in experiments where cg <dig>  cg <dig>  nipped-a and pten have been targeted by rnai. although the nature of the relationship among these genes needs further investigation, we have previously identified nipped-a and pten as regulators of erk activity following insulin stimulation  <cit> , suggesting a relevant relationship between these genes. altogether, these results demonstrate that our online phenotype discovery methods can be used to provide unexpected and novel biological insight.

we also tested our method using two published dataset from drosophila rnai screen  <cit>  and hela cell cycle phase detection , compared its performance with svm based methods and validated our method's ability of handling dataset from various organisms. these experiments are described in , the results on drosophila dataset from  <cit>  are reported in  and results on hela dataset are reported in .

all other functions are developed in matlab  <dig>  and ran in pc with intel® core™  <dig> t <dig>  <dig>  ghz cpu and  <dig>  gb of ram. starting from four existing phenotypes, the average running time for our method based on improved gap statistics is  <dig>  seconds on a group of  <dig> segmented cells,  <dig>  seconds on a group of  <dig> cells and  <dig>  seconds on a group of  <dig> cells. considering the fact that cell number in each image is seldom over  <dig> in the reported high content screen, our method is suitable for online application.

discussion
online identification and validation of novel morphological phenotypes are major challenges in specific high-throughput image-based screens. manual phenotype labelling of high-throughput image-based data is a laborious and inordinately time-consuming process, while available automatic identification methods usually classify cells into a limited set of predefined phenotypes which may be determined through biased means and will not be updated according to the online image input. as millions of images are now generated during the course of a comprehensive genome-scale screen, new methods are needed to effectively identify novel phenotypes in such massive databases. here we report the development of an online phenotype discovery method which models existing phenotypes, compares cells in new images with existing phenotype models through cluster analysis, assigns some new cells to existing phenotypes, and finally identifies and validates novel phenotypes online.

gmm is used for modelling existing phenotypes and gap statistics, with gmm as reference distribution for existing phenotype, plays a key role in cluster analysis and merging. we built gmm for existing phenotypes, sampled datasets from the model and used them as reference distribution in gap statistics method, following this pipeline we can cover the complete properties of phenotypes more efficiently. furthermore, gap statistics are dealing with only one existing phenotype plus a part of the new image in each merging loop, and the content of new image is iteratively updated with the merging procedure. we present additional file  <dig> to validate the idea of modeling existing phenotype using gmm, the detailed information of gmm estimated from four existing phenotype in our real dataset are reported along with histograms for some typical feature. 

for analysis of high content screen data, many researchers choose to summarize the information of single cells or objects to supply a normalized signature for higher level concepts . thus it is critical to identify different phenotypes related to a same treatment condition. our method can be used in identifying multiple phenotypes in single well and supply detailed insight into related questions. the performance of our methods relies on the quality of image processing, feature selection, phenotype modelling, and cluster analysis methods. using iterative cluster merging, our future goals are to build more reliable phenotype models and to construct complete pipelines of cluster analysis with detailed validation procedures to obtain more reliable definition of clusters.

CONCLUSIONS
we propose an online phenotype discovery method for high-throughput rnai screen, which can be used in the course of many image-based screens. this method is based on adaptive phenotype modelling and iterative cluster merging using improved gap statistics. given datasets for existing phenotypes, the method can build a model of each existing phenotype, identify novel phenotypes in images obtained from ongoing screening and assign newly obtained cell images into different phenotypes. compared with traditional novelty detection techniques, our approach avoids frequent re-modelling involving the huge existing dataset and can handle multiple existing phenotypes in a flexible manner. implementation of our methods in the analysis of images acquired during a genetic screen for regulators of drosophila cell morphology demonstrates the power of these computational tools in efficiently discovering meaningful new phenotypes.

