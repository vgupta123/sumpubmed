BACKGROUND
genes related to causing some diseases are called disease-causing genes or disease genes. a pertinent role for bioinformatics research exists in the analysis of biological data for disease gene discovery. most current efforts at disease-gene identification involving linkage analysis and association studies result in a genomic interval of  <dig> - <dig> centi morgen containing up to  <dig> genes  <cit> . these candidate genes need to be further investigated to identify disease causing genes. but identifying the real disease genes from the large amount of candidate genes by biological experiment is time consuming and labor-extensive. to address the challenge, computational prediction of good candidate genes before experimental analysis is quite necessary, which will save both time and effort. the main strategy is to prioritize candidate genes by their similarity to known disease genes, which is called candidate gene prioritization.

with the advent of high-throughput technologies, huge amount of genomic data have been generated. therefore, there are many ways to define 'functional similarity' between genes. a number of methods have been proposed to prioritize candidate genes based on different kinds of genomic data, such as sequence-based features  <cit> , functional annotation data  <cit>  and protein interaction data  <cit> . however, most of these data sources are noisy and incomplete, which downgrades the prioritization algorithms. how to effectively integrate heterogeneous data sources to improve prediction is a major challenge. notably, there are two combination algorithms. on is endeavour, proposed by aerts et al.  <cit> . they integrated nine data sources, e.g. sequence data, gene annotation data, etc. there are two stages in the framework of endeavour. in the first stage, a rank list of candidate genes is calculated according to their similarity to known disease genes based on each data source. in the subsequent stage, these rank lists were integrated into one rank list using n-dimensional order statistics   <cit> . another combination algorithm is multiple kernels learning , proposed by de bie et al.  <cit> . for each data source, a kernel matrix was used to measure the similarity between genes. they used one-class svm trained on the combined kernel to prioritize candidate genes. they compared mkl with endeavour on  <dig> diseases, and found that mkl works better than endeavour. in our previous work, we improved the first stage of endeavour, the ranking algorithm, and achieved higher auc values than mkl  <cit> . in this paper, we combined protein protein interaction  data and gene ontology  data to prioritize candidate genes. we follow the framework of endeavour and did improvements on both stages, the ranking algorithm and the combination algorithm.

rank lists of candidate genes were obtained using random walk with restart  algorithm  <cit> . firstly, each data source is transformed into a network . protein-protein interaction data is directly transformed into a network as the node and edge information are available. three k-nearest neighbor  graph were derived from gene ontology annotation, corresponding to three sub-ontologies, 'biological process', 'cellular components' and 'molecular function'. we found the sub-ontology 'biological process' was the most effective in prioritizing candidate genes among four data source used.

to combine these rank lists, we proposed a new algorithm, called discounted rating system . it is inspired by discounted cumulated gain  score, which is widely used to evaluate the ranking results of document retrieval  <cit> . similar to ndos, our algorithm starts from several rank lists of candidate genes. the rank lists are transformed into discounted rating lists through the discounted rating system. then, candidate genes are ranked based on the mean value of discounted rating scores corresponding to each data source. the performance is evaluated by area under roc curve  value using leave one out cross validation. in comparison with ndos, drs achieved comparable auc values for most of the disease families. but drs works much faster than ndos, especially when there are a large number of data sources. when there are  <dig> candidate genes and  <dig> data sources, drs works more than  <dig> times faster than ndos. in addition, we propose to give different weights for different data sources. the auc values for the weighted drs were statistically significant higher than ndos.

the rest of this paper is organized as follows. we begin with the description of the data sets used in this work, and then introduce the related algorithms and our proposed drs. we evaluate its performance on  <dig> disease families and compare it with ndos. the last section concludes the paper with a brief summary.

methods
in this section, we firstly introduce the data used in this work: disease genes, protein-protein interaction  data and gene ontology   <cit> . then, we introduce the ranking algorithm based on random walk and the combination algorithm n-dimensional order statistics  used in endeavour  <cit> . finally, we describe our newly proposed combination algorithm discounted rating system .

disease genes
disease gene data set was collected by  <cit> , which was defined on the basis of entries in the online mendelian inheritance in man  database  <cit> . there were  <dig> disease gene families; the largest family contained  <dig> genes and the smallest only three genes. in this work, we choose  <dig> disease families, each of which includes at least  <dig> genes. these disease families include genetically heterogeneous disorders in which mutations in distinct genes are associated with similar or even indistinguishable phenotypes; cancer syndromes comprising genes associated with hereditary cancer, increased risk, or somatic mutation in a given cancer type; and complex  disorders known to be influenced by variation in multiple genes.

protein-protein interaction network
the ppi data were derived from human protein reference database   <cit>  and biogrid  <cit> . hprd contains manually curated scientific information pertaining to the biology of most human proteins. all the interactions in hprd are extracted manually from literatures by expert biologists who read, interpret and analyze the published data. the biogrid is also a curated database for protein-protein interaction. it is compiled by in-house large scale curation efforts. it contains both physical interaction data and genetic interaction data. in total, there are  <dig>  unique interactions between  <dig>  proteins in these two databases. the interaction data can be used to construct a network, in which nodes are proteins and edges are interactions.

gene ontology and gene functional similarity network
gene ontology
the gene ontology  provides a controlled vocabulary to describe gene and gene product attributes  <cit> . it is comprised of three independent sub-ontologies, 'biological process' , 'cellular component'  and 'molecular function' . bp refers to a biological objective to which the gene or gene product contributes. it often involves a chemical or physical transformation. examples of general  biological process terms are 'metabolism' or 'signal transduction'. examples of more specific  process terms are 'pyrimidine metabolism' and 'camp biosynthesis'. cc refers to the place in the cell where a gene product is active. it includes terms such as 'nuclear membrane' or 'golgi apparatus'. mf is defined as the biochemical activity  of a gene product. this definition also applies to the capability that a gene product  carries as a potential. it describes only what is done without specifying where or when the event actually occurs. examples of broad functional terms are 'enzyme', 'transporter' or 'ligand'. examples of narrower functional terms are 'adenylate cyclase' or 'toll receptor ligand'.

the functional similarity between two genes can be measured by the semantic similarity between their go annotation terms  <cit> . since there are three independent sub-ontologies, the functional similarity can be defined considering three different aspects. therefore, we constructed three gene similarity networks, according to three sub-ontologies. in this work, the similarity between two genes is measured by their overlap annotation terms  <cit> , because of its computational efficiency.

gene functional similarity network
before constructing knn graphs, a gene-term annotation matrix was compiled for the corresponding sub-ontology. each column in the matrix represents the annotation vector of a gene. the annotation vector is binary valued, with '1' representing the presence of the go term in the gene's annotation and '0' representing its absence. the functional similarity between two genes can be calculated by the dot product between the corresponding annotation vectors, which is the number of co-annotated terms. intuitively, genes sharing specific term 'pyrimidine metabolism' are expected to be more functionally similar than genes sharing general term 'metabolism'. therefore, the '1' values in the annotation vector are replaced by the information content  of the corresponding go term. the information content of a term is related to how often the term is associated to genes in the database, such that rarely used terms are assigned with higher ic. the calculation of ic is described as follows:   

where n is the total number of genes in the sub-ontology and nt is the number of genes annotated with term t.

the functional similarity between two genes are calculated by dot product between corresponding weighted annotation vectors   

where gi and gj are gene i and gene j, and xi and xj are the corresponding annotation vectors, weighted by ic values.

for each gene, we calculate the functional similarity between this gene and any other gene in the sub-ontology using eq., and find k most similar genes of it, called k-nearest neighbors. then the gene is connected with its k-nearest neighbors, weighted by the similarity measure calculated by eq.. the network  constructed by this method is called the k-nearest neighbor  graph. in this work we use 5-nn graph.

ranking algorithm based on random walk with restart
let g be a graph, where v is the set of nodes and e is the set of edges. random walk  <cit>  method simulates a random walker that starts on a source node . at each step, the walker chooses randomly among its immediate neighbors . the transition probability from node i to node j is   

where a is the adjacency matrix of the graph, d is the sum of the ith column in a. the transition matrix m of random walk processes can be written in a matrix form as   

where d is the diagonal matrix of the degrees  and dij =  <dig> for i = j).

let ps be a vector in which the ith element holds the probability of finding the random walker at node i at step s. the probability at step s +  <dig> can be given by   

the initial probability vector p <dig> is constructed such that equal probabilities are assigned to all the source nodes with the sum of the probabilities equal to  <dig>  this is equivalent to letting the random walker begin from each of the source nodes with equal probability.

random walk with restart  is a variant of the random walk. at each step, the random walker moves to its immediate neighbor or goes back to source nodes with probability γ. formally, the random walk with restart is defined as:   

after certain steps, the probability will reach a steady state. this was obtained by performing the iteration until the difference between ps and ps+ <dig>  fell below 10- <dig>  the steady state probability p∞ gives a measure of proximity to source nodes. if p∞  >p∞ , then node i is more proximate to source nodes than node j. rwr algorithm has been used on ppi network to prioritize candidate genes, with nodes representing known disease genes as source nodes. the hypothesis is that disease genes of a particular disease are located in same 'modules'  <cit> .

n-dimensional order statistics used in endeavour
n-dimensional order statistics  used as comparison in this paper was proposed by  <cit> . it has been used in endeavour to combine multiple data source and prioritize disease genes  <cit> . before using ndos, they generate a rank list for candidate genes based on each individual data source. therefore, each candidate gene yields n rank positions r <dig>  r <dig>  ..., rn, where n is the number of data sources used. then, n ranking positions from the separate data sources are combined into a q value using ndos, which is calculated by the following recursive formula:   

with r <dig> =  <dig>  finally, all the genes are ranked by corresponding q values. thereafter, the combined rank list was derived from the separate rank list. the computational complexity is o, and endeavour  <cit>  implemented a faster alternative formula with complexity o.

discounted rating system
similar to endeavour, in the begining, we obtain a rank list for the candidate genes based on each individual data source. here, we propose a new strategy, discounted rating system  to combine these rank lists into one. figure  <dig> shows the input of drs, rank list of  <dig> candidate genes obtained by using rwr based on each individual data source. and the output of drs is shown in figure  <dig>  four steps of drs are described below.

1) firstly, we transform the rank lists into rating lists. candidate genes are categorized into five equal-size ratings based on their rank positions in the rank list. the higher the rating, the more relevant is the gene to the disease.

2) in the second step, the rating and ranking of each gene is combined into one value called discounted rating . the discounted rating of a gene based on data source i is calculated as follows:   

where ratingi is the rating of the investigated candidate gene based on data source i and ri is its rank position. the discounting function log <dig> reduces the gene's rating as its rank increases. the calculation of discounted ratings is inspired by dcg  score, which is widely used to evaluate the ranking results of document retrieval  <cit> . the higher position ranks have more influence than the lower position ranks. our assumption is that disease genes are ranked somewhere in the top of the rank lists according to some data sources.

3) in the next step, the mean value of discounted ratings is calculated as the combined score for the investigated gene.   

where n is the number of data sources used.

4) finally, the candidate genes are ranked according to this score.

considering  <dig> candidate genes, the whole procedure of drs is illustrated in figure  <dig>  for example, the rank positions of the 8th gene, g <dig>  obtained by rwr based on bp, cc, mf and ppi, is given by  <dig>   <dig>   <dig> and  <dig>  respectively. that is, for g <dig>  r <dig> =  <dig>  r <dig> =  <dig>  r <dig> =  <dig> and r <dig> =  <dig>  after transformed into ratings, they are all  <dig>  in the next step, their dr values are  <dig> ,  <dig> ,  <dig> , and  <dig> , respectively. the combined score for g <dig> is  <dig> . finally, each candidate gene has a combined score, based on which, all the candidate genes are ranked as the combined rank list. the most likely real disease is g <dig>  because it is finally ranked 1st. in the combined rank list, g <dig> and g <dig> are ranked 2nd and 3rd, they may also be real disease genes.

weighted discounted rating system
discounted rating system can be thought as a kind of ensemble strategy. different data source should be given different weights in the decision of the combined ranking, since different data sources differ in their usefulness and suitability to rank candidate genes for a certain disease family. the weighted drs  is calculated as follows:   

where μi is the weight for data source i. in this work, weights are obtained by using cross validation as described in the next section.

cross validation
to assess the performance of these prioritization methods, we use leave one out strategy proposed in  <cit> , which is illustrated in figure  <dig>  firstly, for each disease gene, we retrieve the  <dig> nearest genes form the up-stream and down-stream genetic interval of the disease gene. for the investigated disease family, in each validation run, we hold out one gene from the set of disease genes. the held-out gene and  <dig> genes are called test set. and the remaining disease genes for the investigated disease family are called training set and used as source nodes of random walk algorithm to prioritize test genes. ideally, the held-out gene should be on the top of the test genes' rank list.

therefore, for each disease gene, we obtain a rank list of test genes, that is, prioritizations of  <dig> genes. suppose there are  <dig> disease genes in the investigated disease family, after cross validation, we obtain  <dig> rank lists, each with  <dig> prioritizations. then, from these  <dig> prioritizations, we calculate sensitivity and specificity values of the investigated disease family at varying thresholds. sensitivity refers to the percentage of disease genes that were ranked above a particular threshold. specificity refers to the percentage of non-disease genes ranked below this threshold. for instance, a sensitivity/specificity value of 70/ <dig> would indicate that the correct disease gene is ranked among the best-scoring 10% of genes in 70% of the prioritizations. we plot receiver operating characteristic  curves and use the area under this curve  as a standard measure of the performance. for instance, an auc value of 100% indicates that every held-out gene is ranked first.

RESULTS
in this section, we first compared ndos and drs in detail, taking esophageal carcinoma as an example. then, the performance of ndos and drs on all  <dig> disease families was compared. after that, we investigated the effect of parameter γ in rwr. finally, we compared ndos and drs on larger number of simulated data sources.

case study of esophageal carcinoma
esophageal carcinoma is a kind of cancer, which have a high incidence in china, india, japan and united kingdom. there were  <dig> disease genes for the disease of esophageal carcinoma  <cit> . we used the leave one out cross validation to evaluate the performance of our algorithm. in each validation run, one known disease gene and  <dig> nearest genes were treated as test set. the rest known disease genes of esophageal carcinoma were treated as training set and used as source nodes for rwr algorithm.

the rank position of the held-out disease gene is shown in table  <dig>  since most of the data sources are incomplete, some genes may not be included in all the data sources. ndos and drs solve this problem by adjusting n in eq.  <dig> and eq.  <dig>  respectively. as can be seen from table  <dig>  for most of the disease genes, the ranks of both methods are comparable. the ranks of dec <dig> and dlec <dig> by drs is better than ndos, because they were ranked near to the top by at least one data source and in drs the combined ranks were dominated by top rank positions. the last row in the table shows the auc scores corresponding to the data sources or combination algorithms. for each data source, the auc value is calculated on available disease genes in this data source. in the case of esophageal carcinoma, the auc value of drs  is higher than that of ndos .

as can be seen from table  <dig>  for different data source, the predictive ability is different. therefore, when calculating the combined score for candidate genes, we gave weight for each data source based on its auc value.   

where auci is the auc value corresponding to data source i. then, μi was plunged into eq. to calculate swdr the combined score of weighted drs. more effective data sources were given higher weights and were able to play more important role in the decision of the combined score swdr, and thereafter the gene's rank position. the data sources with auc below  <dig>  are filtered out, since the weight of which are set zero. we choose  <dig>  to ensure the predictive data sources are highlighted and not to filter out much data sources. in the case of esophageal carcinoma, the data source of ppi and bp dominate the final ranks of disease genes.

performance on all  <dig> disease families
we applied drs on  <dig> disease families. auc values of the leave one out cross validation for each disease family are shown in table  <dig>  for most of the disease families, the auc values for drs and ndos are comparable. and the auc values for wdrs are higher than drs and ndos. to make it more clear, we performed wilcoxon signed-rank test between auc values of wdrs and ndos, and found that wdrs was significantly better than ndos . similarly, the permeance of weighted drs was much better than non-weighted version .

there are  <dig> disease genes in all the  <dig> disease families. as shown in figure  <dig>  for each disease gene, we obtained a rank list of  <dig> test genes. we put all  <dig> rank lists together and constructed a roc curve, which is shown in the left panel of figure  <dig>  it is clear that the roc curve for wdrs is above drs and wdrs, therefore the auc value of wdrs is larger than drs and ndos.

as described in the section of cross validation, the sensitivity value at  <dig> - specificity = 10% means the proportion of real disease genes in the top 10% ranked genes of  <dig> rank lists. the right panel is the zoom-in roc plot of top 10% candidate genes. the drs algorithm selected out more disease genes in the top 10% ranked genes of  <dig> rank lists. in the wet-lab experiments, biologists pay more attention to the top ranked genes. the drs algorithm gives better guidance for wet-lab experiments than ndos. and the weighted drs performs even better.

the performance of individual data source were calculated based on the disease genes available in this data sources. as shown in table  <dig>  among four data sources, bp ontology achieved the highest auc value , which was higher than the result of combined algorithms. but  <dig> of the  <dig> disease genes can not be prioritized by bp data source. the coverage of ppi network was even smaller,  <dig> of  <dig> disease genes were absent in the ppi network. as described in the section of cross validation,  <dig> sets of test genes were retrieved from the corresponding artificial linkage. for a data source, a large number of genes were absent. the median numbers of test genes are shown in table  <dig> 

ranking algorithm based on individual data set can not prioritize genes not presented in the data source, while the combined algorithm can increase the scope of application. if one gene is listed in any data source, it can be prioritized.

the numbers of ratings
in the second step of drs, we classify candidate genes into  <dig> ratings. to investigate whether or not the number of ratings has effect on the performance of drs, we set the number of ratings at  <dig> and  <dig> and calculated the auc values of leave one out cross validation. as can be seen from table  <dig>  the scale of rating did not effect the results significantly.

stable performance of rwr algorithm
in the base ranker, rwr algorithm, there is one parameter, the restart probability γ . to investigate the effect of this parameter, we set γ at  <dig> ,  <dig> ,  <dig>  and  <dig> , and did leave one out cross validation for both ndos and drs. we calculated auc value for each disease family, and performed pair-wise t-test between two lists of auc values, as we did in the previous section. results are shown in table  <dig>  for each γ value, performance of drs was significantly better than ndos. we also calculated the overall auc values based on all the  <dig> disease genes. for both ndos and drs, the auc values did not change much with γ value changing.


                              γ
comparison of ndos and drs with the number of data sources increasing
in this work, there were  <dig> candidate genes and  <dig> data sources. on a desktop with a  <dig>  ghz intel processor and  <dig> gb ram, the computational time of cross validation using drs and ndos were found to be  <dig> s and  <dig> s, respectively. both drs and ndos were implemented in matlab.

in the latest version of endeavour  <cit> , there are  <dig> data sources available for h. sapiens. we tried to compare the performance of ndos and drs, with the number of data sources increasing. we did not add more real data sources, but simulated the data as described subsequently. for the real data source, in each run of cross validation, one known disease gene and  <dig> genes in the nearest genetic interval are test genes, and a rank list of these test genes is generated using rwr, as shown in figure  <dig>  for the newly added data source, we simulate the prioritization result of  <dig> test genes. we suppose there are m test genes available in data new source, m is chosen from the last column of table  <dig>  we randomly select m genes from the  <dig> test genes. the prioritization result of selected test genes is simulated as a random permutation of integers from  <dig> to m. to make the simulation more reliable, the rank position of known disease gene was randomly selected from distribution of ranking positions of  <dig> known disease genes based on real data source. in brief, for each known disease genes,  <dig> real rank lists were calculated and several simulated rank lists were generated. then, simulated rank lists and four real rank lists were put together and fed into drs and ndos algorithm respectively, as shown in figure  <dig>  and the corresponding combined rank list was generated. finally,  <dig> combined rankings were generated, based on which auc value was calculated.

as shown in table  <dig>  when the number of data sources increasing, the computational time for ndos was dramatically increased, while it for drs did not change much. when the number of data sources increased to  <dig>  drs was more than  <dig> times faster than ndos used in endeavour. since there are a large number of missing values in the real data sources and simulated data sources, the n value in eq.  <dig> is much smaller than the number of data sources and compute much faster than complete data. but the incompleteness of the data have little effect on the computation time on drs. if there are no missing values in the  <dig> data sources, the computation time of ndos is around 300s. therefore, drs performs more than  <dig> times faster than ndos. with the complexness of genomic data, the merit of drs will become more significant. on the other hand, for both ndos and drs, the auc value increased when the number of data sources increasing. when the number of data source came to  <dig>  drs achieved higher overall auc value than ndos.

CONCLUSIONS
in this work, we integrated gene ontology data and ppi data to prioritize candidate genes. the ppi data were presented by the ppi network, and then random walk with restart  algorithm was directly used on the network. for gene ontology data, three knn graphs were generated corresponding to three sub-ontologies, bp, cc and mf and rwr algorithm was used on the graphs to prioritize candidate genes. results showed that, bp ontology was the most informative data source for candidate genes prioritization.  due to the incompleteness of each individual data source, some genes can not be prioritized, while the combined method can make use of all the data available.

we proposed a new strategy called discounted rating system  to combine the rank lists of candidate genes obtained by using rwr algorithm. in comparison with ndos  <cit>  algorithm used in endeavor  <cit> , drs performed much faster and achieved higher auc values on most of the disease families. another merit of drs algorithm is flexibility to give weights for different data source. especially, when the number of data sources increases to  <dig>  drs works more than  <dig> times faster than ndos. the framework of drs is flexible to give weights on different data sources. given proper weights the drs will works better. results of leave one out cross validation showed that weighted drs achieved higher auc values than ndos and non-weighted drs.

competing interests
the authors declare that they have no competing interests.

authors' contributions
yj li designed the algorithm and drafted the initial manuscript. jc patra provided counseling on issues related to data processing and analysis, and supervised the project's development. both authors read and approved the final manuscript.

