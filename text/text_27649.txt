BACKGROUND
due to the continued growth of biomedical publications, it has become very difficult for scientists to keep up with the new findings reported in the literature. as a consequence, we have observed an increase in the effort spent on automatically extracting information from research literature and developing biomedical text mining tools.

this paper aims to address the relation extraction task, which identifies selected types of relationships among entities  reported in text.

approaches to the relation extraction task can be categorized into two major classes:  machine learning-based approaches and  pattern-based approaches. machine learning-based approaches are data-driven and can derive models from a set of annotated data . the use of machine learning methods can be quite effective, but the performance of resulting systems depends on the quality and the amount of annotated data. for example, large annotated corpora become available for the protein-protein interaction relation task, reflecting a general community-wide interest  <cit> . but this situation does not always hold for relations of different scientific interest, because preparing annotated corpora is generally time consuming and expensive and it also requires domain expertise and significant effort to ensure accuracy and consistency. in contrast, pattern-based approaches do not require annotated data to train a system. however, they do require domain experts to be closely involved in the design and implementation of the system to capture the patterns used for extracting the necessary information. some systems rely on extraction patterns defined at the surface textual level or based on outputs from a shallow parser . others use deep parsers with hand-crafted patterns . as found in opendmap  <cit> , a semantic grammar may be utilized with text literals, syntactic constituents, semantic types of entities, and hyponomy. in all cases, rigid extraction patterns are manually encoded in the systems. owing to rigid patterns, pattern-based approaches usually achieve a high precision but are often cited for low recall. while it is feasible to manually identify and implement high quality patterns to achieve a good precision, it is often impractical to exhaustively encode all the patterns necessary for a high recall in this manner.

our work enables the fast development of pattern-based systems, while mitigating some of these concerns. we aim to reduce the involvement of domain experts and their manual annotation, and to attain high precision and recall.

our approach starts by identifying a list of trigger words for the target relation  and their corresponding trigger specifications . given this information, we make use of linguistic principles to derive variations of lexico-syntactic patterns in a systematic manner. these patterns are matched with the input text in order to extract target relations.

to improve the applicability of the generated patterns, we incorporate two additional design features. the first is the use of text simplification. this allows us to design a small set of lexico-syntactic patterns to match simple sentence constructs, rather than try to account for all complex syntactic constructs by generating an exhaustively large amount of patterns. second, the framework exploits referential relations. with this method, two phrases referring to the same entity  or in a particular relation  are detected in text, and links are established between them. these links can be used when seeking the most appropriate phrase referring to the target entity and, hence, allow for extraction of target entities beyond lexico-syntactic patterns.

the proposed approach is based on the property of the language, rather than task-specific knowledge. therefore, it is generalizable for different trigger words and potentially applicable to many different types of information targeted in biomedical relation extraction tasks.

we acknowledge several studies underlying our proposed framework. the automated pattern generation employed in this study shares the fundamental assumptions of certain linguistic theories, such as lexicalized tree adjoining grammar   <cit> , head-driven phrase structure grammar  <cit> , and lexical functional grammar  <cit> . in particular, we believe that the concept underlying our method is similar to that of ltag. the paradigm of inferring patterns exploited in our method shares the ideas with , but we focus on a specific set of patterns pertaining to the expression of biomedical relations.

simplifying a sentence as a prerequisite for biomedical information extraction was studied in the past . the use of meronymy and its opposite holonymy, among other relationships found in the biomedical ontology, was discussed in  <cit> . some of these relations were later considered in biomedical information extraction systems in order to improve their performance . these relations and paradigms are in conjunction with our own two additional referential relationships: coreference and hyponymy. we integrate them in our framework and examine their utility for biomedical relation extraction.

to evaluate the framework, we test it by producing an extraction system for six relations that were part of the bionlp-st  <dig> and  <dig> ge tasks. we show that by just taking the specification of trigger words , we produce a relation extraction system with results that compare favorably with state-of-the-art results on this corpus. we further show that we can achieve good precision and recall with the patterns generated from the trigger, and that simplification and referential relation linking can increase the recall without compromising the precision.

methods
a. architecture overview
the architecture of our framework has several components , as summarized below and detailed in sections b-f. the framework consists of four system modules  and two external modules .figure  <dig> 
framework architecture. the framework consists of four modules: pattern generation, pattern matching, sentence simplification, and referential relation linking. there are two external modules: parsing and entity typing. the framework requires trigger specifications and pre-defined pattern templates to generate patterns. then it extracts relations from text using the generated patterns.



it also requires trigger specifications and associated pattern templates to locate the relations of interest. an example trigger specification is shown below:
  

in the above example, line  <dig> shows the trigger word, “phosphorylate” in this case. line  <dig> indicates that it is the trigger for the relation “phosphorylation”. line  <dig> specifies that the trigger syntactically chooses two noun phrases, designated as np  <dig> and np  <dig>  lines 4– <dig> add selectional restrictions, by requiring np  <dig> to be a gene or gene product  and np  <dig> to be either a ggp or a protein part. lines 6– <dig> show that if np  <dig> and np  <dig> can be extracted, and if both np  <dig> and np  <dig> meet the above constraints, then the framework will assign their semantic roles of agent and theme, respectively.

now consider the following example sentence: the c-jun amino-terminal kinase phosphorylatesnfat <dig> 



from , we will extract “the c-jun amino-terminal kinase” as the agent and “nfat4” as the theme of the phosphorylation relation. this extraction is the result of matching the text fragment with a pattern that is partly derived from the trigger specification. this pattern should not only capture the general syntactic form of a clause involving a transitive verb in an active voice, but also capture the selection restrictions imposed by the word “phosphorylates” and the arguments. thus, this pattern contains information described in two places:  lexical trigger that specifies the arguments, the selection restrictions on the argument, and the role they play, and  the syntactic constraints corresponding to different constructs . we call the former “trigger specification”, and the latter “pattern templates”. actual lexico-syntactic patterns are obtained by merging the trigger specifications and pattern templates. as we shall see later , the combination of these two is mediated by the frame that is mentioned in the trigger specification.

we now briefly discuss four modules of the system framework: pattern generation, pattern matching, sentence simplification, and referential relation linking .

the pattern generation  module uses trigger specifications and predefined pattern templates to derive lexico-syntactic patterns for each trigger word. the pattern matching  module then matches fragments of text with lexico-syntactic patterns, and extracts the textual expressions in the trigger and argument positions. in order to more effectively match with the patterns, the sentence simplification  module is used to preprocess the input text. it aims to ensure that the lexico-syntactic patterns generated in the previous step are able to be matched even in complex sentences. finally, the referential relation linking  module links arguments identified by the pattern matching module with the target entities they refer to, where applicable. this step enables the system to find relations between more appropriate entities than the ones referred by textual expressions in the argument position.

in addition to the above four system modules, there are two external modules. one is the parsing module, which is used by the pattern matching step. the other is the entity typing module, which assigns semantic types or categories to noun phrases. both are found to be useful to enhance the precision of the relation extraction task  <cit> .

b. trigger specification
trigger specifications are used to locate triggers and arguments in text for target relations. to make it easier to specify triggers, we ask users to provide the trigger’s root, which is the primary lexical unit of a word. from the root morpheme, we can derive other forms of triggers using our previous work  <cit> . for example, from “phosphorylate” we derive “phosphorylates”, “phosphorylated”, “phosphorylation”, etc. in general, we generate different possible forms of triggers and confirm whether they are used in the literature. in a few cases, we ask the users for this confirmation. this generation is based on well-known english inflection rules, and this can be used to match to the appropriate trigger template.

next, we show two example trigger specifications for the same root morpheme, “express”, but with different semantic types for the argument, gene and rna.
  

although these two specifications share the same trigger word, they represent different types of relations: gene expression and transcription. the gene expression relation requires its theme  to be a gene, whereas the transcription relation requires its theme  to be an rna. these examples show that argument types in the trigger specification are essential to the framework to achieve a high precision, because they emphasize the selection restrictions on arguments.

c. pattern generation
provided with a trigger specification, we use the “frame” to associate a trigger with a set of pattern templates to derive lexico-syntactic patterns. in the following subsections, we will define frames and pattern templates, and then discuss how they can be combined to generate lexico-syntactic patterns.

c. <dig> frames
a frame is a set of pattern templates sharing the same syntactic nature of the constituents that are likely to be associated with the trigger. it specifies the arguments of the trigger. we found that the most frequent frame in biomedical documents is: frame:np0/np1



we distinguish np  <dig> and np  <dig>  because semantically they play different roles and have different types in the trigger specification, and syntactically they represent different grammatical constituents. the above frame may be realized by the standard active form “np  <dig> v np 1”, where v is a verb, and np  <dig> and np  <dig> appear at the left and right of the verb, respectively.

relations can be semantically “directional” or “non-directional”. for example, phosphorylation is a directional relation, but binding is non-directional. this is because “a binds b” and “b binds a” may be used to specify the same relation between “a” and “b”, but “a phosphorylates b” and “b phosphorylates a” represent two different relations. if a relation is directional , we would expect that all triggers for that relation have the property as well. in our framework, we use an additional binary constraint “ 〈direction〉= directional/non-directional” in the trigger specification to distinguish non-directional relations from the other, because currently it is the only place where users interact with the framework. to generate appropriate patterns, this directionality constraint in the trigger specification will cause an appropriate defined frame to be chosen: the non-directional frame differs from the directional one by allowing for the swapping of the agent and the theme.

c. <dig> pattern templates
a pattern template is specified by a sequence of words or phrases β <dig> …,βn, followed by a set of constraints. each constraint assigns a value for one of the βi features.

to reduce the number of pattern templates, we limit pattern templates to capture one argument at a time. so the pattern templates will capture pairs <trigger, npi >. after templates are instantiated and arguments are extracted, we combine pairs if they have the same trigger. thus we can extract relations with multiple arguments. we believe that considering one argument at a time is more flexible and manageable, because such pairs can be applied independently, while constraints on combinations can cover many different relations.

we further categorize pattern templates into two groups: one with explicit argument, and one with null argument. we will discuss pattern templates for argument realization in the next section, and then introduce methods to generate lexico-syntactic patterns. lastly, we will discuss pattern templates with null argument.

c. <dig> pattern templates for argument realization
argument realization, which is at the heart of the area of linguistics, is the study of the possible syntactic expressions of the arguments of a verb  <cit> . in this study, we extend argument realization to nominal and adjectival triggers derived from verbs as well.

verbal triggers
below are examples of pattern templates for verbal predicate vtr in active voice:
  

an example template for a verbal predicate vtr in passive voice is:
  

we use np <dig> in pattern templates  and  in contrast to np <dig> in template , because their roles are different. for example, in trigger specification of , np <dig> is always the agent and np <dig> is always the theme. furthermore, in combination with the constraints expressed within the trigger specification, the use of template  will succeed only if np <dig> is ggp, whereas the use of template  will succeed even if np <dig> is a protein part.

nominal triggers
in addition to the standard pattern templates that are based on verbal forms of the trigger, we also consider cases where the trigger verb is nominalized . for example, “transcribe” can be nominalized into “transcription” or “transcript”. nominalization of verbs can be divided into two classes. the first class is where resulting nouns denote actions, states, and processes. their suffixes are typically “-ion”, “-age”, and “-ance” . the second class is where resulting nouns refer to entities . because our primary interest is processes pertaining to genes or proteins, we currently focus on the first class. typical pattern templates for nominal triggers are:
  

besides the theme, the agent can be incorporated via a “by” phrase. a pattern template for such instances is:
  

as for non-directional relations we discussed earlier, we have additional templates, which are exemplified by the following:
  

adjectival triggers
english has a general morphological process of adjective conversion , which enables verbs to be used as adjectives. the pattern template for adjective triggers is
  

in this framework, adjectival derivations can be the present participle , the past participle , and the adjectivization  of a verb.
  

c. <dig> generation of patterns
the pattern generation module automatically creates lexico-syntactic patterns given a list of trigger specifications and frames.

to associate pattern templates with frames, verb type information is used. for example, one constraint in english is that only transitive verbs can be passivized. therefore frame:np0/np <dig> contains template , , and , but frame:np <dig> contains template  only. given the trigger specification of  for “phosphorylate” having frame:np0/np <dig>  we will automatically generate lexico-syntactic patterns like “np <dig> phosphorylates”, “np <dig> is phosphorylated”, etc..

the automatic generation procedure is similar to the concept of ltag. in ltag, a tree family associates a verb lexeme with a given subcategorization. the subcategorization includes a set of grammatical structures that represent all the possible lexico-syntactic variations for that verb lexeme. so grammatical structures can be obtained by combining lexical rules and syntactic transformations. compared with ltag, the “frame” in our approach is essential but not exactly a subcategorization in ltag. the trigger specifications are similar to tree families in ltag, which associate a trigger lexeme with a given frame. in addition, we also consider verb nominalization and adjectivization.

c. <dig> pattern templates with null argument
there are cases when the writing style does not follow the common trigger-argument association. when the argument is omitted, but implied, we call them “elliptical construction”. following are some examples of  elliptical constructions, and  how they would be written if the trigger-argument association would be required.
  

both  and  are grammatically correct and express the same underlying idea in  and , but we tend to write  rather than  as a shorthand. such null argument structure is similar to the null complement anaphora  in a modern syntactic theory  <cit>  and the implicit argument in a semantic theory  <cit> . for the relation extraction task, we observe that the elided argument may be found as its antecedent and determined by another trigger that selects it. our framework recovers them as part of the relation extraction process, by applying for the null argument pattern templates. it should be noted that such elliptical constructions can appear in various positions of a sentence, e.g., at the beginning  or at the end . these templates always rely on the whole sentence construct, therefore are too cumbersome to express. we designed some pattern templates to match sentences like  and . whether there exists a more general and clearer way to express these types of pattern templates needs to be further explored.

d. pattern matching
consider the text fragment where “jnk” and “nfat4” have already been tagged as gene or gene product. jnk phosphorylates nfat4



this fragment is captured by the generated lexico-syntactic patterns derived from frame:np0/np <dig> and the trigger specification “phosphorylate” in . the next step is to extract the actual agent and theme. specifically, pattern template  matches the “phosphorylates” word as a trigger, and “nfat4” as np <dig>  the trigger specification  checks np1’s type, which is ggp, and assigns its role for a theme. therefore, we get <phosphorylatestrigger, nfat4theme >. similarly, by using pattern template  we can extract <phosphorylatestrigger, jnkagent >.

for pattern matching, we would like to mention two issues. first, as illustrated above, the pattern matching engine must be able to check the types of nps are consistent with those mentioned in the trigger specifications. for this purpose, any method that assigns types to noun phrases or named entities, such as bionex  <cit>  or genia tagger  <cit>  can be employed. in our evaluation, we have used the bionex tool.

secondly, in order to match a broader range of phrases, we skip verbal auxiliaries and adjuncts for pattern matching. by auxiliary verbs, we mean verbs used to express tense, aspect, modality, etc. by adjuncts, we mean the optional phrases that do not affect the main meaning of a sentence. first, consider the following examples having auxiliary verbs:
  

the above examples belong to pattern templates  and , respectively. however, none of them can be directly matched because of the complex way in which the predicates are expressed. this construction of consecutive verb groups makes basic pattern matching extremely laborious, because of the many variations they can introduce. in this framework, we would like to avoid constructing complex pattern templates, thereby reducing the burden of system development. we notice that  syntactically, such consecutive verb groups form a dependent-auxiliary construction: dependent-auxiliary + main-verb, and  semantically, the “agent” and “theme” are always related to the last main-verb, rather than the auxiliary. thus, we match the consecutive verb group as a whole, then choose the last verb as the head of the whole sequence.

second, let us look at adjuncts in the following sentences:
  

the most frequent adjuncts that are likely to be skipped are the adverbial adjuncts, e.g. “abundantly” and “in the granulocyte fraction of human peripheral blood cells” in . in addition, adjective-nominal adjuncts are also skipped, e.g “abundant” and “in human peripheral granurocytes” in .

e. sentence simplification
so far, we have discussed how arguments can be extracted by matching patterns. but even with a large number of patterns automatically generated in the proposed manner, the recall of the resulting system is still low because sentence constructions and writing styles vary considerably in actual text, and the number of variations to be considered is overwhelmingly high. for example, consider sentence : active raf-1phosphorylates and activates the mitogen-activated protein  kinase/extracellular signal-regulated kinase kinase  <dig> , which in turn phosphorylates and activates the map kinases/ extracellular signal regulated kinases, erk <dig> and erk <dig>  



it is difficult to extract phosphorylation relation <phosphorylatestrigger, erk1theme > and <phosphorylatestrigger, erk2theme > from  by preconceiving complex patterns required and exhaustively encoding them along with all possible variations. on the other hand, if we can simplify the syntactic structure of  and obtain the following sentences, the automatically generated patterns can easily match the simple sentences:
  

this and many other instances that we observed in biomedical research articles motivated us to separate the various structures of a sentence first, and then match patterns to the simplified sentences.

complex constructs, e.g., coordinations and relative clauses, pose a challenge for state-of-the-art full parsers. however, even if these constructs can be detected correctly using full parsers, new patterns are still needed to skip parts of a construct . when using a dependency parser, more collapsed rules involving prepositions, conjuncts, as well as information about the referent of relative clauses are used to get direct dependencies between content words  <cit> . both cases will increase the complexity of patterns and, thus, increase the pattern encoding effort.

alternatively in this framework, we introduce sentence simplification as a preprocessing module. given an input sentence, this module outputs a set of generated simplified sentences, thus conceals the syntactic complexity from the pattern matching step.

e. <dig> complex constructs for simplification
in this section, we will describe syntactic constructs that the preprocessing module simplifies. for further details of our sentence simplifier, isimp, we refer to  <cit> .

coordinations are syntactic structures that link two or more items  of syntactically equal status  <cit> . these conjuncts are linked by coordinating conjunctions . our primary concerns are coordinations of nouns , noun phrases , verbs , and verb phrases .
  

for a coordination, the original sentence can be split into multiple ones, each containing one conjunct.

relative clauses are clauses that modify noun phrases. for example,
  

there are two types of relative clauses that frequently appear in biomedical text: full relative clauses and reduced relative clauses. full relative clauses  are introduced by relative pronouns, such as “which”, “who”, and “that”. reduced relative clauses  and  start with a gerund or past participle and have no overt subject. a sentence containing a relative clause can be simplified into two sentences: the original sentence without the relative clause and the other that consists of referred noun phrase as a subject and the relative clause.

appositions are constructs of two noun phrases next to each other, typically separated by comma and referring to the same entity. for example,
  

appositions can be detected by searching for two noun phrases separated by a comma, when they are not part of a coordination. in addition, because one noun phrase  normally renames or describes the other, it usually begins with a determiner or a number . appositions can be simplified into two sentences: one with the referred noun phrase and the other with the appositive.

parenthesized elements are any words enclosed within “()”, “”, and “{}”. they usually refer to or describe preceding noun phrases.
  

when simplifying parenthesized elements, an additional sentence is created only with the parenthesized elements without the preceding nouns phrase.

e. <dig> dealing with attachment ambiguities
attachment of phrases poses one of the well-known problems in syntactic ambiguity.
  

examples in  refer to relative clause attachment ambiguities, where there is a complex np of the type “np1prep np2” followed by a relative clause. in such cases, it is unclear whether to attach the relative clause to the first noun phrase  or the second one . other kinds of attachment ambiguity include pp-attachment, e.g., “np <dig> and np <dig> pp” , and the attachment involving coordination, e.g., “adj np <dig> and np2” . solving the attachment problem is important in sentence simplification, but we believe it is not a purely syntactic problem  <cit> . semantic information is also necessary to make a decision. therefore, in this study, we produce alternative attachments as candidates while simplifying sentences, and leave the decision to the pattern matching module where type information is available.

f. referential relation linking
by using patterns and sentence simplification, the system can detect textual expressions in the argument position. sometimes, the referred entity is mentioned somewhere else in the text. consider example . the system can extract binding relation <dimerizedtrigger, the proteintheme > from , but the actual target entity is “c-fox”. to link these phrases, we developed patterns to extract referential relations. the stability of c-fox was decreased when the proteinwas dimerized with phosphorylated c-jun.



f. <dig> referential relations
referential relation patterns are designed to extract the relationship of one nominal phrase to another, when one provides the necessary information to interpret the other  <cit> . by utilizing referential relations, an extraction system is able to identify an actual target entity beyond the initially extracted arguments.

co-referential relations  occur when multiple expressions refer to the same referent. for instance, in the previous example, “the protein” and “c-fox” both refer to the same object. in a co-referential relation, the anaphoric reference can be a pronoun or definite noun phrase, and its antecedent can be the actual name of protein or gene. in this study, co-referential relations are not extracted, except for the case of a relative pronoun, because we consider their detection as a separate and independent task from pattern-based extraction.

part-whole relations are useful when an argument extracted for a trigger comprises a part of the target entity. for example: both eomes and runx <dig> bind at the prf1locus.



for biomedical information extraction, this framework focuses on relations between protein parts and a protein, e.g., a residue in a protein. such part-whole relations in example  can be captured by patterns like “npwholecontains nppart” or by the existence of keywords like “locus”, “promoter”, and “domain”.

member-collection relations are useful in linking a generic reference to a group of entities that are specified in other places in text. for example: expression of adhesion moleculesincludingintegrin alpha, l-selectin, icam- <dig>  and h-cam



the above example illustrates that the generic reference “adhesion molecules” can be extracted as an argument of the trigger “expression”. meanwhile, specific referred entities include “integrin alpha”, “l-selectin”, “icam-3” and “h-cam”. we consider patterns like “np, such as np *” to identify this type of relations.

hyponymy relations are used when argument x is a hyponym of argument y, if x is a subtype of y, or when an instance of x refers to a concept y. thus, in , “cd14” is said to be a hyponym of “membrane glycoprotein”, and in , “p <dig> crk-associated substrate ” is a hyponym of “protein”. when linked, the system extracts <expressedtrigger, cd14theme > and <phosphorylatedtrigger, castheme >, respectively.
  

to achieve this goal, we identify the fragments having keywords such as “acts as” or “is identified as”, which are similar to the ones in  <cit>  and  <cit> . moreover, the apposition construct can also hold a hyponymy relation between the appositive and the referred noun phrase.

f. <dig> linking entities through referential relations
we will use the example in figure  <dig> to illustrate integrating basic patterns and linking relations.figure  <dig> 
an example of the referential relation linking. the pattern will extract “the earliest genes” as the theme first. then with the member-collection and hyponymy relations linking, the framework can identify “tumor necrosis factor alpha” as the actual theme of “transcribed”.



this example contains one transcription relation. our goal is to extract its trigger and argument, namely <transcribedtrigger, tumor necrosis factor alphatheme > which are highlighted in the sentence. we assume “tumor necrosis factor alpha” is typed as a gene.

given the trigger “transcribe” and using pattern template  as discussed earlier, we can extract <transcribedtrigger, the earliest genestheme >. but “the earliest genes” is not a named entity . in addition, we extract one member-collection relation <onemember, the earliest genescollection > and one hyponymy relation <tumor necrosis factor alphahyponym, onehypernym >. the first relation enables us to infer <transcribedtrigger, onetheme >, since the collection of genes  are “transcribed” and, then, one of its members can be “transcribed” as well. then, the latter relation allows us to state “tumor necrosis factor alpha” is the “one” in this context and hence to conclude <transcribedtrigger, tumor necrosis factor alphatheme >.

the algorithm for the linking is as follows. first we collect all referential relations in the document. then we use the patterns to get instances for a trigger. if the instance’s argument is not an informative reference, we recursively search for all of its references in the detected referential relations. if an appropriate reference of an entity is found, we link it to the trigger, by creating a new pair <trigger, referred entity >. this search procedure ends when we exhaust all possibilities. as a result, more than one pair may be created and all pairs are proposed.

g. evaluation design
our framework is designed to extract a variety of relations. for the evaluation of our framework, we need test sets containing different types of relations. furthermore, the data set should include trigger annotations needed to automatically generate patterns. we chose to use the corpora of bionlp-st   <dig> and  <dig> ge tasks, which included several event extraction subtasks  <cit> .

g. <dig> bionlp-st ge task
the bionlp-st ge task series aim to extract various events from biomedical text. the first shared task workshop was held in  <dig>  and the most recent one in  <dig>  in this study, both  <dig> and  <dig> corpora are used for the evaluation. we will refer to them as “ge 2011” and “ge 2013” hereafter.

in ge  <dig> task, evaluation results were reported on hole, bstract, and ull paper collections, respectively. the abstract collection contains paper abstracts, the full text collection contains full papers, and the whole collection contains both abstracts and full text. following the same setting, we also report our results on w, a, and f. ge  <dig> corpus covers nine types of events: gene_expression, transcription, localization, protein_catabolism, phosphorylation, binding, regulation, positive_regulation, and negative_regulation. among these, we focused on events with simple entities as themes. thus, regulation and its subtypes were removed because their themes could be other events with other triggers. as a result, only the first  <dig> types of events were evaluated. the first five events were called “simple event” collectively. in the ge  <dig> corpora, we consider the same events as well.

g. <dig> trigger selection
since our approach requires a list of triggers, we used the triggers annotated in the corpus. to effectively evaluate our framework, we further decided to focus on a selected group of triggers. among triggers in ge corpus, we chose only the triggers that are based on verbs  and their nominal and adjective forms  as discussed before. we did not use the triggers that are pure nouns  or adjectives . additionally, we eliminated verb triggers like “find” and “form” because they are not specific to particular biomedical events.table  <dig> 
selected triggers


see above
see above
see above
 <dig>  this predication is always used together with “mrna”.

 <dig>  this predication is always used together with “surface”.

the derivation column shows affix used to derive other forms of triggers. singular, past tense, and gerund forms are not shown.



g. <dig> evaluation measurement
the evaluation was carried out by comparing the predicted annotation with the gold standard. we used the approximate recursive matching decomposition mode as in the ge task  <cit> , which requires extracting equality between the two events as follows: the event types are the same;

the triggers are the same; and

the arguments are the same.



same triggers and arguments means that “the given text span is equivalent to a gold span if it is entirely contained within an extension of the gold span by one word both to the left and to the right.” for example, if  is the given span and  is the gold span, they are the same iff a1≥a <dig> and b1≤b <dig> 

g. <dig> system implementation
this section describes one implementation of the framework.

the raw text was parsed by charniak-johnson parser using david mcclosky’s biomedical model  <cit> . we chose charniak-johnson parser because it was convenient in comparing the evaluation with existing systems  <cit> . but other constituent parsers would also work with little integration effort.

we consider the typing as a critical component of the framework. for example,  for relations like phosphorylation, the theme needs to be a noun phrase of type protein or protein part;  for triggers like “associate”, the binding relation should not be extracted if its themes’ are not proteins or protein parts; and  for triggers like “express” and “detect”, the themes’ type must be gene or mrna, and the relation is either gene expression or transcription, respectively. this implementation of the framework uses a modified version of bionex, which was developed based on ideas from  <cit>  and used in rlims-p  <cit> . bionex can detect semantic types of entities referred by nouns or noun phrases, such as protein, gene, chemical or their part. the type detection is based on considering the head nouns and their suffixes, and comparing them with a predefined list for each type.

patterns were generated and matched from the parse tree using the tree regular expression  <cit> . thus pattern templates were designed using tree regular expression as well.  <dig> pattern templates were created. to extract the predicate in a consecutive verb group, , we looked at the verb phrase subtree and searched for its rightmost children. when the last verb phrase in the group was found, we picked its head.

for the simplification task, we used isimp, which is a sentence simplifier specifically created for biomedical text  <cit> . currently, isimp can detect six types of simplification constructs: coordination, relative clause, apposition, introductory phrase, subordinate clause, and parenthetical element. it uses shallow parsing and state transition networks to detect all forms of simplifications. the detection of various simplification constructs is based on the chunks , and from these, isimp generates simplified sentences. isimp also handles nested constructs. for an in-depth description of this process, we refer the reader to  <cit> .

for anaphora resolution, we used javarap, which is based on the algorithm of  <cit>  and implemented by  <cit> . other referential relation patterns were defined using tree regular expressions.

the discussion above describes an implementation of the framework. in order to evaluate the framework using the bionlp-st ge data, we implemented a relation extraction system for the six events in these data sets. the relation extraction system is obtained from this implementation by specifying the triggers, which were chosen by considering a subset of the trigger words marked in the training set for the six events in the ge  <dig> training set. in particular, we chose only frequently occurring verbal trigger words. note the trigger specifications require only the base form of these verbal triggers . because this set of triggers are limited in the subcategorization variety, they fall into a handful set of predefined trigger specifications. as a result, we are able to quickly complete the trigger specification for these words.

this relation extraction system implementation is available as a web service accessible: http://research.bioinformatics.udel.edu/ixtractr. unlike the evaluations conducted in this paper, the web service does not have gene mentions marked in the text as the input. instead, we integrated an in-house module to detect gene mentions. because this module only accepts pmids as the input rather than full text, the current web service only supports pmid input as well.

RESULTS
a. results on ge  <dig> corpus
after trigger selection, events related to the selected triggers were found to be very frequent in the corpus, covering  <dig> % and  <dig> % of all events in the training and development sets of the ge  <dig> corpus, respectively . this intrinsic limitation, however, led to an upper bound of  <dig> % and  <dig> % in the f-score of our system.table  <dig> 
statistics of the data sets after modification



total
statistics of events with selected triggers on bionlp-st  <dig> st ge task. if an event’s argument is within an equivalence relation with n members, this event will be counted n times. % = events with selected triggers/all events.


evaluation results on the whole, abstract, and full paper collections from the training set of bionlp-st  <dig> ge task



whole set
 total

subset with selected triggers
 total
performance is reported in terms of recision/ecall/-score.


evaluation results on the whole, abstract, and full paper collections from the development set of bionlp-st  <dig> ge task



whole set
 total

subset with selected triggers
 total
performance is reported in terms of recision/ecall/-score.


comparative results of subset events with selected triggers on the whole, abstract, and full paper collections from the training set of bionlp-st  <dig> ge task



basic patterns
 total

using simplification
 total

using simplification and referential relations
 total
performance is reported in terms of recision/ecall/-score. the third part is reproduced from the second part of table  <dig>  “basic patterns” = using pattern templates for argument realization and pattern templates with null argument to generate patterns.
comparative results of subset events with selected triggers on the whole, abstract, and full paper collections from the development set of bionlp-st  <dig> ge task



basic patterns
 total

using sentence simplification
 total

using sentence simplification and referential relations
 total
performance is reported in terms of recision/ecall/-score. the third part is reproduced from the second part of table  <dig>  “basic patterns” = using pattern templates for argument realization and pattern templates with null argument to generate patterns.


results on the hole, bstract, and ull paper collections from the testing set of bionlp-st  <dig> ge task 1



total
performance is reported in terms of recision/ecall/-score.



we would like to note that although table  <dig>   <dig>   <dig>   <dig>  and  <dig> show the results on different partitions of the  <dig> data sets, the system remains unchanged because the trigger word list  remains the same.

b. analysis of false positives and negatives on ge  <dig> corpus
we randomly chose  <dig> false positive  cases and  <dig> false negative  cases with  <dig> for each event type from the training set of ge  <dig> corpora in order to analyze reasons for failure. we identified two major types of errors.

b. <dig> parsing errors
a large proportion of failure was due to errors made by the parser. since the patterns rely on the parser output, the system failed to recognize a true positive in these cases. some of the parsing errors were due to noun phrase coordinations. although the parser detected the coordination, the resulting trees could have been shallow or deep. figure  <dig> shows two different parse trees of noun phrase coordinations:  is correctly parsed, but  is not. flattening the coordination and applying relaxed matching rules could have fixed most of these problems. for coordination simplifications in particular, we could apply noun phrase and verb group similarity rules to detect coordination boundary and transform the subtree from  to   <cit> .figure  <dig> 
two parse trees of coordinations.  parsing tree of the fragment “fgf <dig> signaling and nf-kappab activation”.  parsing tree of the fragment “adhesion molecule and hsp expression”.



parsing errors also cause simplification errors. figure  <dig> shows the parsing subtree of the fragment “the physical interaction we detected between foxp <dig> and p300”. if the parse tree were correct, we could remove the relative clause “we detected” in the simplification step and extract the binding relation between “foxp3” and “p300”, but the incorrect parse tree failed the system. as can be seen, errors in sentence simplification can propagate and cause errors in subsequent processing. most of the simplification errors are due to incorrect coordination detection. however, overall the number of simplification errors are few, and as can be seen from table  <dig>  the boost in recall is significantly more than the drop in precision.figure  <dig> 
two parse trees of the fragment “the physical interaction we detected between foxp <dig> and p300”. parse tree of the fragment “the physical interaction we detected between foxp <dig> and p300”, with target relation <interaction
trigger, foxp <dig> theme > highlighted.  is the incorrect parse tree generated by the parser.  is the correct parse tree.



b. <dig> missing pattern templates
another case of false negatives is due to the trigger word being a noun but not the head of the noun phrase. for example, our pattern templates could be applied for fragments “transcription of np” and “expression of np” but could not be applied for fragments “ of np2” or “ of np2”. we impose such a constraint in order to maintain a high precision. the analysis showed, however, that we could generalize the constraints in the future with some effort, especially in deciding on the words that can head the nps.

similarly, we need to generalize null argument structures further. for example, consider the fragment targets c-fos fordegradation



we have a pattern template using “via” but not “for”. there are a few other cases, where null argument pattern templates could have been applied, but these new templates need to be further checked.

c. results and analysis on ge  <dig> corpusevaluation results from the training, development, and testing sets of bionlp-st  <dig> ge task 1



training set
 total

development set
 total

testing set
 total
performance is reported in terms of recision/ecall/-score.



the system achieves f-scores of  <dig> % for the simple event and  <dig> % for the binding event on the ge  <dig> test set with an overall f-scores of  <dig> % on the  <dig> ge task. these scores compare favorably with the top-ranking systems in the  <dig> ge taska <cit> . our system achieves the highest scores for simple event and overall. however there are two participated systems , which have better scores for binding event. in comparison with these systems, our system’s strength lies in its precision, achieving  <dig> %, whereas, the precision of these systems ranges from  <dig> % to  <dig> %.

the testing set of the ge  <dig> task is not available to the public, hence we cannot directly examine the results. instead, we conducted experiments on the training and development sets. although the results on these two sets are consistent with the corresponding results on  <dig> corpora, we noticed some differences between the ge  <dig> and  <dig> corpora: the former is completely comprised of full-length articles, whereas the latter is mostly made up of abstracts. we also observed that in the full-length articles, certain information is repeatedly mentioned within a single section, therefore there is significant use of ellipses in such sections. for instance, consider the example from the ge  <dig> development corpus in figure  <dig> figure  <dig> 
sample use of ellipses in the paragraph. for the trigger “phosphorylation” in the third sentence, the author neglected to mention the theme because it can be inferred from the context:  the previous sentence also mentions this “bmp- <dig> induced phosphorylation”, but its theme has a general term “smad”, and  the actual proteins “smad1/5/8” are clearly specified in the first sentence.



for the trigger “phosphorylation” in the third sentence, the author neglected to mention the theme because it can be inferred from the context:  the previous sentence also mentions this “bmp- <dig> induced phosphorylation”, but its theme has a general term “smad”, and  the actual proteins “smad1/5/8” are clearly specified in the first sentence. as a result, to infer the theme of the trigger “phosphorylation” in the third sentence, we not only need the syntax information, but also the discourse-level processing.

note that the system used in this evaluation remains the same as the one that was used on the ge  <dig> task. no changes were made to accommodate any differences between the ge  <dig> and  <dig> corpora. the focus in this framework is on the patterns and hence almost all processing is syntax-based. while some of our earlier work on relation extraction has integrated discourse-level processing with syntax-based patterns  <cit> , the integration of such discourse-level processing is beyond the scope of this work. however, examples as above suggest that the need for discourse-level processing may be important for full-length based extraction. we intend to investigate incorporating the generalized discourse-level processing into our framework in the future, so that it can be useful for full-text based extraction.

CONCLUSIONS
in this work, we have designed a framework for development of biomedical relation extraction systems. the framework requires as input only a list of triggers and their specifications to retrieve relations of interest. it utilizes linguistic generalizations that help speed up the development process by proposing various lexico-syntactic patterns as well as improve the performance, particularly the recall, by making use of sentence simplification and referential relations.

to evaluate the framework, we developed a relation extraction system, which was produced using general resources and the only aspect specific to the evaluation was the selection of trigger words that appear in the corpus. except for the specification of triggers, other aspects  are general purpose systems that already existed. the fact that only the specification of the triggers is required from domain experts, together with the fact that no training set is required, meets our goals for developing the framework: ability to create effective relation extraction systems for new relations where resources  are not publicly available.

we evaluate the performance of the system by producing a relation extraction system and evaluating it on the bionlp-st  <dig> and  <dig> ge tasks. the system achieved f-scores of  <dig> % on the ge  <dig> test set, and  <dig> % on the ge  <dig> test set. our analysis shows that we can achieve high precision and good recall with the range of patterns automatically generated from triggers and that simplification and referential relation linking serve to increase the recall while maintaining the precision.

in the future, we would like to extend the framework in two ways. so far, we only considered the triggers that are verbs and their derived forms. next, we would like to account for triggers that are primarily nouns or adjectives. also, we would like to extend the framework to take complex entities  as arguments rather than just simple entities .

we are developing systems for additional relations. in general, it is a challenging task to identify all the triggers for the relation and to complete their specifications. this study demonstrates a generalizable relation extraction framework that can be quickly implemented for new relations, initially focusing on a few triggers that appear frequently. while not accounting for a long tail of less frequent triggers, our framework allows additional trigger specifications to be added with little impact on the existing trigger list. thus as new triggers are found, they can be integrated in the system. using the framework and this approach, we have developed a system for mirna-target extraction. preliminary evaluation based on an in-house corpus of  <dig> abstracts shows an f-score of the system over 90% . we would like to use the experience in developing this and other relation extraction to design a process involving user interaction in generating trigger specifications for new relations. in general, the specification of a trigger needs both domain knowledge as well as linguistic knowledge. the domain expert will be able to suggest the trigger words for a relation, whereas linguistic knowledge will be more useful in preparing the trigger specifications of sub-categorization, thematic roles, etc.

in our framework, we already have a predefined set of subcategorization frames and thematic roles that can be utilized in the specifications. this can be used to engage the user in the interactive process. at the beginning, the users who are domain experts will provide a list of trigger words. then the process will derive various forms of triggers using the linguistic knowledge and ask users to choose. if necessary, the process will use these triggers to generate simple examples for the users to confirm which predefined specification should be associated to the trigger. the whole process will communicate with users in an interactive way, which we expect is able to further speed up the development of new relation extraction systems.

endnote
a simple event includes phosphorylation as well, same as in the bionlp-st  <dig> ge task  <dig> 

competing interests

the authors declare that they have no competing interests.

authors’ contributions

yp carried out the framework studies described here, conducted the experiments, and drafted the manuscript. mt participated in the design of the study and has been involved in drafting the manuscript. cw coordinated the study, and has been involved in revising the manuscript critically for important intellectual content. kv conceived the study, and participated in its design and coordination and helped in drafting the manuscript. all authors read and approved the final manuscript.

