BACKGROUND
the stanley neuropathology consortium  <cit>  recently made a large  data set publicly available on gene expression in the brains of deceased individuals with bipolar disorder or schizophrenia, as well as controls. in addition the data contains limited demographic and clinical history information, including gender and history of smoking, alcohol and drug use. this paper presents a retrospective statistical study on this data set, in which we address the following three questions:

q <dig>  can either bipolar disorder or schizophrenia be distinguished from control purely on the basis of gene expression profile?

q <dig>  does addition of the demographic and clinical history data further improve the ability to distinguish bipolar disorder or schizophrenia from control?

q <dig>  is there a significant difference between the abilities of different widely-used data analysis algorithms to make these distinctions?

we show that bipolar disorder and schizophrenia each can be distinguished from control, based on gene expression alone, significantly better than chance – in fact with areas under the receiver operating characteristic  curve  of  <dig>   and  <dig>  . while area under the roc curve indicates how well one can distinguish across a range of specificities , it is also worth noting that for each task, a sensitivity of  <dig>  can be achieved when operating at a specificity of  <dig> . moreover, by taking demographic information and clinical history into account , performance improves to an auc of  <dig>  for schizophrenia vs. control and to an auc of  <dig>  for bipolar disorder vs. control. to our knowledge, this is the first statistical comparison of the efficacy of using a combination of gene expression data and clinical history data against using gene expression data alone. with regard to question q <dig>  the paper shows that support vector machines  significantly outperform the other most widely used algorithms for statistical classification and machine learning for these tasks.

this table lists the distribution  of the demographic features in the three classes . because most classification techniques are restricted to numerical features only, we reencode each nominal feature as a numeric feature. the numerical encoding is listed between parentheses after each nominal feature value.

furthermore, we found that some variables in this data set, such as alcohol and drug use, are strongly associated to the diseases. given that these variables may affect gene expression, they may make it more difficult to identify genes that are directly associated to the diseases.  we have investigated if post-stratification can correct for such variables, but we found that it significantly reduces the predictive accuracy of the statistical methods.

data
the expression data set was obtained from the stanley neuropathology consortium  <cit> . the records utilized in this study are a subset of the entire collection of data. the data set contains  <dig> schizophrenia patients,  <dig> patients with bipolar disorder and  <dig> controls. for each subject, it includes annotated gene expression data and demographic and clinical information. all data was analyzed un-blinded. diagnosis and criteria have been described previously by torrey and colleagues  <cit> . as described in the same report by torrey and colleagues, the recreational or prescription status of drugs for each of the donors was largely unknown, because the researchers relied on post-mortem urine toxicology screens that are not always conducted.

the expression data was obtained using affymetrix human genome u133a genechip oligonucleotide arrays containing  <dig>  probe sets . probe level data was summarized using the gc content adjusted robust multi-array average  method  <cit> . the data set includes the gc-rma value of each probe set as a numerical feature.

the data set records, besides expression data, also demographic and clinical information about the subjects. table  <dig> lists the recorded demographic and clinical features with their distribution in the three classes. for numeric features, it lists the mean and standard deviation, and for nominal features, the class-wise count of each feature value.

algorithms
we define two binary classification tasks on the data set: schizophrenia versus control and bipolar versus control. for each task, we compare the following six classification techniques: support vector machines, nearest shrunken centroids, decision trees, ensemble of voters, naïve bayes, and nearest neighbor. we briefly describe each technique. the section "methods" lists the software packages that we use and explains how the parameters of the different algorithms are set.

support vector machines
support vector machines  belong to the family of generalized linear models. we employ linear svms, which exhibit good classification performance on gene expression data  <cit> . a linear svm is essentially an -dimensional hyper-plane that separates the instances of the two classes in the n-dimensional feature space. figure 1a illustrates this for the two dimensional case: the hyper-plane reduces here to a line, which separates the empty  and filled  circles. the hyper-plane maximizes the margin with the closest training instances. these instances are called the "support vectors" because they fix the position and orientation of the hyper-plane. linear svms assume that the training data is linearly separable. if this is not the case, then svms rely instead on the concept of a soft margin  <cit> . in the evaluation, we use a soft margin svm, which minimizes, in addition to the margin, also the sum of the distances to the training instances that are incorrectly classified by the hyper-plane .

nearest shrunken centroids
nearest shrunken centroids  is a technique designed for classifying gene expression data. nsc represents each class by its centroid  and classifies new instances by assigning them the class of the closest centroid. nsc shrinks the class centroids  in the direction of the overall data centroid. this has the effect that components of a class centroid that after shrinkage are equal to the corresponding components of the overall centroid become irrelevant to the classification process. this occurs for the horizontal component of the class centroids in figure 1b. as a result, nsc implicitly performs a kind of feature selection.

decision trees
decision trees  are tree-shaped symbolic models with tests on the feature values in the internal nodes, and class labels in the leaves . dts classify a new instance by sorting it down the tree, according to the tests in the nodes, until it reaches a leaf; the label of the leaf becomes the predicted class of the new instance. c <dig>   <cit>  is a well-known algorithm for constructing decision trees. c <dig>  builds a dt top-down, by recursively partitioning the data at each step by a test comparing a feature to a value. at each node, the algorithm selects the test that maximizes a heuristic function called information gain ratio. the better a test is able to separate the instances of the two classes, the higher its information gain ratio. then, it partitions the training instances based on the selected test, and finally it recursively repeats the same procedure to construct a sub-tree for each subset in the partition. c <dig>  creates a leaf if all remaining instances belong to the same class or if there are fewer instances than a user defined threshold. the label of the leaf is the majority class of the instances it covers. after building the tree, c <dig>  prunes back some parts to reduce the expected error on new instances.

ensemble of voters
ensemble of voters  is a simple ensemble method. an eov model is a set of decision stumps. decision stumps are decision trees that consist of precisely one test node with two leaves. the eov model includes one decision stump for each of the top n feature value tests ranked by the information gain score  <cit> . to obtain a prediction for a new instance, the model combines the predictions of the stumps by means of majority voting: the predicted class is the class predicted by more than n/ <dig> stumps.

naïve bayes
naïve bayes  is a statistical classifier based on bayes rule. its name comes from the strong  statistical independence assumptions that it makes. in spite of these strong assumptions, it often works remarkably well in practice. nb predicts a class with the rule: class=arg⁡max⁡c∈classesp∏ip. it estimates p and p from the training data. note that nb assumes nominal features, which means that numerical features must be discretized prior to running nb.

nearest neighbor
k-nearest neighbor  classifies a new instance as the majority class of its k closest training instances in the feature space. for example, 3nn in figure 1d assigns the class "black" to the new instance .

evaluation
we evaluate the performance of the different classification techniques by means of receiver operating characteristic  curves. roc analysis allows us to simultaneously compare classifiers for different misclassification costs and class distributions  <cit> . it is based on the notions of "true positive rate"  and "false positive rate" . given two classes "positive" and "negative", tp rate is the proportion of correctly predicted positive examples, and fp rate is the proportion of negative examples that are incorrectly predicted positive. the vertical axis of a roc diagram represents tp rate, and the horizontal axis fp rate. each classifier corresponds to a point on this diagram. the closer the point is to the upper-left corner , the better the classifier.

most classifiers provide confidence scores for their predictions. for such classifiers, a roc curve can be constructed. we present such a curve for each classifier and report the corresponding "area under curve" , which is defined as the area between the roc curve and the horizontal axis. to obtain a measure for the predictive performance of the models, we estimate the roc curves using a 10-fold cross validation procedure. details about this evaluation procedure can be found in the section "methods". we use a t-test to assess if the auc difference between two classifiers is significant and report the corresponding p-value.

RESULTS
classifier performance
we compare the six classification techniques in the context of two classification tasks: schizophrenia versus control and bipolar versus control. in a first set of experiments, the data consist of only the gene expression features , and in a second batch, the data include both demographic and clinical features as well as gene expression .

we also present experiments on data for male subjects only  and for female subjects only , to assess if the diseases can be better predicted if data of only one sex is used. the svm result auc =  <dig>  on the combined data of figure  <dig> for schizophrenia versus control is, however, not significantly different from the result for male subjects  or that for female subjects . the same holds for the bipolar versus control task. we hypothesize that this is because the data sets with subjects of one sex only are much smaller than the combined data, so that there is less training data for each model. even if classification is easier for such data, this is offset by the smaller data size.

figures  <dig>   <dig>   <dig>   <dig>   <dig>   <dig> present a similar set of experiments for the data set that includes demographic and clinical data in addition to the gene expression data. adding demographic and clinical information improves classification performance. svm, for example, performs better on the schizophrenia versus control task with demographic information  than without such additional information . the same holds for the other classification techniques and for the bipolar versus control task .

we again present experiments for male and female subjects separately , this time with the demographic and clinical data included. the conclusion from this set of experiments is similar to the previous conclusion: separating the subjects by sex does not significantly improve the classification performance for svms.

the superior performance of svms when compared to the other classification algorithms can be understood based on the properties of gene expression data. gene expression data is typically characterized by a high dimension combined with a relatively low number of samples. for example, the present data set records the expression level of  <dig>  probe sets for a number of samples that is two orders of magnitude smaller. many classification algorithms are known to perform poorly on such high dimensional data. svms, on the other hand, are well suited to this setting because their classification performance can be independent of the dimensionality of the feature set  <cit> : their performance rather depends on the margin with which they separate the samples . this explains the good performance of svms on high dimensional data. additional empirical evidence is that svms are known to perform well on text classification problems   <cit> . previous studies on gene expression data also illustrate the good performance of svms  <cit> .

note that the above discussion does not imply that svms will always outperform other algorithms on gene expression data. for example, nsc, which implicitly performs dimensionality reduction , has also been shown to work well on gene expression data  <cit> . therefore, it is common practice in machine learning to evaluate different classification algorithms on a new data set and based on this evaluation select the one that works best. this is also the approach that we follow in this work.

most relevant features
to asses which features are most relevant to each of the classification tasks, we apply two techniques:  ranking the features by their p-value, and  ranking the features by their svm weight. the first technique performs, for each feature, a two-sided t-test comparing the feature's values in the two classes. it then ranks the features by their t-test's p-value. besides the p-values, we also report q-values  <cit> . q-values measure significance in terms of the false discovery rate. for example, if all features with a q-value ≤ 5% are called significant, then 5% of these features may be false discoveries, that is, their mean value in the two classes may be actually identical. we use the software qvalue developed by storey  <cit>  to compute the q-values. the second technique ranks the features by the weight that the svm classifier assigns to each feature in the linear equation of its classification hyper-plane. the larger the absolute value of the svm weight, the more important the feature is to the classification task.

the qvalue software computes, in addition to the q-values, also an estimate of the proportion π <dig> of truly null features. for each of the schizophrenia versus control tasks it estimates π <dig> to be  <dig> , that is, no significant features; for the bipolar versus control tasks, π <dig> ranges from  <dig>  to  <dig> . note that the estimate for schizophrenia versus control is conservative . qvalue makes certain assumptions about the p-value distribution of the data, which do not hold in this case . it is interesting that, even though qvalue estimates that there are no significant individual features, it is still possible to build classification models that are highly accurate on previously unseen data.  this is partly because the qvalue estimate is conservative. but it also is partly because classification techniques do not rely on a single feature, but exploit the combined effect of the set of most relevant features. therefore, obtaining an accurate classifier is possible even if there are no individual significant features.

comparing  the rankings for expression data only  to  the rankings for expression and demographic data  shows that similar features appear in  and . for example, all probe sets that appear in  also appear in  for table  <dig>  all subjects. in addition,  also includes a number of highly ranked demographic and clinical features. table  <dig> shows, for example, that drug use and alcohol use are ranked high for the all and male subjects cases. this indicates that some of the demographic and clinical features are important to the classification tasks. note that we also observed this while comparing classification models: the models with demographic and clinical features are more accurate.

when comparing the features that appear in the different tables, we observe that for the schizophrenia versus control task , the rankings for all subjects and male subjects have  <dig> features in common: lbh , mt1x , mt1x , tnfsf <dig> , abcg <dig> , mt1e , sst , crhbp , emx <dig> , npy , mt2a , mt1h/p <dig> , sox <dig> , s100a <dig> .

on the other hand, the rankings for all subjects and female subjects have only one feature  in common. for the bipolar versus control task  all subjects and male subjects share  <dig> features , and all subjects and female subjects also share  <dig> features . for both diseases, there is no overlap between the ranking for the female subjects and that for the male subjects. possibly of higher interest are the features relevant to both the schizophrenia versus control and bipolar versus control tasks. comparing the rankings  shows that there are  <dig> common features: lbh , tnfsf <dig> , sst , and npy . these are relevant to both diseases.

biological relevance
of the top  <dig> genes identified using the p-value ranking,  <dig> have been previously implicated in schizophrenia in at least one study. these genes include: nr4a <dig>   <cit> , sst   <cit> , npy   <cit> , s100a <dig>   <cit> , crh   <cit> , gad <dig>   <cit> , fos   <cit> , jun   <cit> , dnajb <dig>   <cit> , slc16a <dig>   <cit> , and egr <dig>   <cit> .

overlap with the current literature occurs for bipolar disorder as well, although overlap is not as large primarily because of the relative immaturity of the field and concomitant smaller number of literature results. of the top  <dig> genes identified using svm weight or p-value,  <dig> genes have been implicated previously in bipolar disorder. interestingly, multiple probes for the same gene are in the top  <dig> for dusp <dig>   <cit>  and hla-dra   <cit> . single probes previously implicated in bipolar disorder include: sst   <cit> , hla-a   <cit> , npy   <cit> , hla-drb <dig>   <cit> , and dnajb <dig>   <cit> .

interestingly, most of the remaining genes in the list are known to interact with the genes that have a documented association with either bipolar disorder or schizophrenia. these interactions were determined using ingenuity systems software.  <dig> of the  <dig> genes in the schizophrenia sample are involved in the same biological pathway . by combining the two networks generated by the software package via  <dig> overlapping genes,  <dig> of the  <dig> genes are in a single biological network. similarly,  <dig> of the  <dig> genes are in a single pathway for bipolar disorder . by combining two of the  <dig> generated pathways through  <dig> overlapping genes, this biological network represents  <dig> of the  <dig> genes on the list.

one of the more remarkable features of this analysis is the difference in gene expression patterns between males and females. much speculation has surrounded the role of gender in psychiatric disorders based on morphological and clinical comparisons between affected males and affected females. this analysis may provide further evidence to support and broaden this hypothesis. the most prevalent gender-based differences associated with mental disorders are in the structural abnormalities that have long been known in schizophrenia  <cit> . these have been validated using ct and mri scans, demonstrating differences in ventricle size in males and females with schizophrenia; specifically the left ventricles of males are known to be enlarged relative to both their healthy counterparts and affected females  <cit> . another structure showing a difference in affected males and females is the corpus calosum  <cit> . the temporal lobe appears smaller in affected men than women  <cit> . specifically, the superior temporal gyri  <cit> , the posterior superior temporal gyrus  <cit> , and herschel's gyri  <cit>  have all been shown in one or more studies to be reduced in affected males when compared to their unaffected male counterparts or affected females. volume reductions have also been observed in the amygdale-hipocampal complex  <cit> . reduced asymmetry of the planum temporale has been observed in females in both mri and post mortem studies  <cit> . in this study we provide additional evidence to further bolster the claim of gender differences, but this new evidence is in the form of molecular differences between affected males and females in both schizophrenia and bipolar disorder. this may all provide evidence that gender may have confounded the results of past molecular analyses into these disorders.

the ranking based on the svm weights does not produce a significant number of genes previously implicated in schizophrenia or bipolar disorder. this does not necessarily mean this measure does not provide as much biological insight as the ranking based on p-value. the smaller overlap may instead be because the svm-based method is more different from previous studies than is the method based on p-values. whereas previous studies sought individual genes, much as the ranking by p-value does, the ranking by svm weight seeks genes that are predictive in the context of other genes. therefore it seems likely that this more global look at bipolar disorder and schizophrenia is producing genes missed in previous analyses of microarray data on brain tissue.

impact of alcohol and drug use
consider the schizophrenia versus control classification task. feature rankings by p-value, such as table  <dig>  may include alcohol use  and drug use  associated genes, and some of these may not be associated to schizophrenia. au and du are known to alter gene expression, that is, there are genes that are differently expressed in heavy au/du subjects and in low au/du subjects. such au/du associated genes will also be differently expressed in the schizophrenia and control classes, simply because there are more high au/du subjects in the schizophrenia class, and more low au/du subjects in the control class . therefore, au/du associated genes may appear in the feature rankings .

identical reasoning applies to the bipolar disorder versus control task, which exhibits a similar difference in au/du distribution between the two classes. this should be kept in mind when analyzing the rankings. note that these differences in distribution are already present in the population and therefore difficult to avoid in the samples.

post-stratification can potentially be used to remove the confounding effects of variables such as au and du. essentially, post-stratification computes a subset of the data such that the subset's au/du distribution is identical in each class. we have applied post-stratification. a detailed description of the method that we used together with its results is available in additional files  <dig> and  <dig>  in these results however, post-stratification proved ineffective because it significantly reduced the amount of data, and therefore also the power of the statistical methods, resulting in unacceptably high false discovery rates. we briefly quantify this in the following paragraph.

consider the p-value ranking for the schizophrenia versus control task, expression data only, all subjects . reporting all top  <dig> features as being significant results in a false discovery rate of  <dig> %, that is, fewer than one feature is a false discovery. however, if we compute a similar ranking on the stratified data, which contains only  <dig> of the  <dig> samples in the original data , then reporting only the four top-ranked features as significant already yields a false discovery rate of  <dig> %, that is, more than two of these four may be false discoveries. because of this high false discovery rate, we decided not to use stratification in the paper and to accept the possibility of au/du associated genes in the rankings. further analysis, possibly using more data, is required to identify such genes.

note that this problem is partially mitigated by use of the svm-based ranking instead, when using demographic features in addition to gene expression. if a gene's correlation with disease is only because of its correlations with au/du, then the svm will prefer to place most/all of the weight on au and du rather than on this gene. the gene will receive high weight only if it provides additional predictive ability for disease beyond its association with au/du. as a result, the ranking will mostly include genes that are truly associated to the disease, which may explain the difference between the svm and p-value rankings. the extent of this mitigation requires further study to quantify, which is difficult because we do not have a ground truth to compare to, that is, it would require that we know which genes are directly associated with au/du and are not associated with the diseases.

CONCLUSIONS
this paper demonstrates that both bipolar disorder and schizophrenia induce substantial changes in gene expression within the brain – substantial enough that each can be distinguished from normal control with an area under the roc curve of over  <dig> . the paper also demonstrates the utility of combining gene expression and clinical data. to our knowledge, this is the first time such a combination has been employed on this scale. finally, the paper demonstrates the significant advantage of support vector machines for this task over other widely used algorithms from statistical classification and machine learning.

using these classification schemes we have shown an overlap with the current literature when ranking the genes according to p-value. in fact, nearly the entire schizophrenia and the entire bipolar disorder list are either indicated in the literature or are involved in a biological network with a previously implicated gene. however, when ranking the genes based on svm weight only  <dig> or  <dig> genes out of  <dig> on each list overlapped with the current literature. this does not necessarily imply that these methods are not viable but rather that these may be previously unidentified candidates that have risen to the top due to the large sample size of this analysis and the application of alternative classification algorithms for microarray data analysis.

this paper also discussed the possible impact of variables such as alcohol and drug use on the presented gene rankings. post-stratification can correct for such variables, but it significantly reduces the power of the statistical methods. therefore, data for more controls with high values for these variables is required so that the au/du distributions in the different classes become more similar. it should also be kept in mind that this is a retrospective study on a given data set and that all results will require further clinical validation. samples in the collection were matched during the collection process for as many parameters as possible. while there may be some confounding effects from pre-mortem consumption of alcohol and other non-prescription medication, this analysis is our best attempt to account for differences in the factors through analytical means . since, these samples are not derived from controlled animals models we will have to rely on these analytical means to aid our efforts in dissecting the root causes of complex diseases.

