BACKGROUND
in recent years, single nucleotide polymorphisms  have become the preferred marker for association studies of genetic diseases or traits. a set of linked snps on one chromosome is called a haplotype. recent studies have shown that the patterns of linkage disequilibrium  observed in human populations have a block-like structure  <cit> . the chromosome recombination only takes place at some low ld regions called recombination hotspots. the high ld region between these hotspots is often referred to as a "haplotype block." within a haplotype block, there is little or even no recombination occurred, and the snps in the block tend to be inherited together. due to the low haplotype diversity within a block, the information carried by these snps is highly redundant. thus, a small subset of snps  is sufficient to distinguish each pair of patterns in the block  <cit> . haplotype blocks with corresponding tag snps are quite useful and cost-effective for association studies as it does not require genotyping all snps. many studies have tried to find the minimum set of tag snps in a haplotype block. in a large-scale study of human chromosome  <dig>  patil et al.  <cit>  developed a greedy algorithm to partition the haplotypes into  <dig>  blocks with  <dig>  tag snps. zhang et al.  <cit>  used a dynamic programming approach to reduce the numbers of blocks and tag snps to  <dig>  and  <dig> , respectively. bafna et al.  <cit>  showed that the problem of minimizing tag snps is np-hard and gave efficient algorithms for special cases of this problem. 

in reality, a snp may not be genotyped and considered to be missing data  if it does not pass the threshold of data quality  <cit> . these missing data may cause ambiguity when using the minimum set of tag snps to distinguish an unknown haplotype sample. figure  <dig> illustrates the influence of missing data when identifying haplotype samples. in this figure, a haplotype block ) defined by  <dig> snps and  <dig> haplotype patterns is presented . we follow the same assumption as previous studies that all snps are diallelic   <cit> . suppose we select snps s <dig> and s <dig> as tag snps. the haplotype sample h <dig> is identified as haplotype pattern p <dig> unambiguously ). consider haplotype samples h <dig> and h <dig> with one missing tag snp ). h <dig> can be identified as haplotype patterns p <dig> or p <dig>  and h <dig> can be identified as p <dig> or p <dig>  as a result, these missing tag snps result in ambiguity when distinguishing unknown haplotype samples.

although we can not avoid the occurrence of missing data, the remaining snps within the haplotype block may provide abundant information to resolve the ambiguity. for example, if we re-genotype an additional snp s <dig> for h <dig> ), h <dig> is identified as haplotype pattern p <dig> unambiguously. on the other hand, if snp s <dig> is re-genotyped ), h <dig> is also identified unambiguously. these additional snps are referred to as "auxiliary tag snps," which can be found from the remaining snps in the block and are able to resolve the ambiguity caused by missing data.

alternatively, instead of re-genotyping auxiliary tag snps whenever encountering missing data, we work on a set of snps which is not affected by the occurrence of missing data. figure  <dig> illustrates a set of snps which can tolerate one missing snp. suppose we select snps s <dig>  s <dig>  s <dig>  and s <dig> to be genotyped. note that no matter which snp is missing, each of the  <dig> missing patterns can be distinguished by the remaining three snps. therefore, all haplotype samples with one missing snp can still be identified unambiguously. we refer to these snps as "robust tag snps," which are able to tolerate a number of missing data. the important feature of robust tag snps is that although they consume more snps than the "tag snps" defined in previous studies, they guarantee that all haplotype samples with a number of missing data can be distinguished unambiguously. when the occurrence of missing data is frequent, the cost of re-genotyping processes can be reduced by robust tag snps.

this paper focuses on the problem of finding robust tag snps to tolerate a number of missing data. throughout this paper, we denote m as the maximum number of missing snps to be tolerated, which corresponds to different missing rates in different genotyping experiments. and we wish to find a minimum set of robust tag snps which can distinguish each pair of haplotypes even when up to m snps are missing. we assume that the haplotype phases and block partition are available as the input. numerous methods have been developed to infer haplotypes from genotype data  <cit> . several algorithms have also been proposed to find the block partition  <cit> . the problem of finding minimum robust tag snps is shown to be np-hard . to find robust tag snps efficiently, we propose two greedy algorithms and one linear programming  relaxation algorithm. the proposed algorithms have been implemented and tested on a variety of simulated and empirical data. we also analyze the efficiency and solutions of these algorithms. an algorithm for finding auxiliary tag snps is described assuming robust tag snps have been computed in advance.

RESULTS
we propose two greedy algorithms which select the robust tag snps one by one in different greedy manners. in addition, we reformulate this problem as an integer programming problem and design an lp-relaxation algorithm to solve this problem. the greedy and lp-relaxation algorithms are able to find solutions within factors of  lnk2
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqacigacagaaeqabaqabegadaaakeaacqqgsbabcqqgubgbdawcaaqaaiabduealjabcicaoiabduealjabgkhitiabigdaxiabcmcapaqaaiabikdayaaaaaa@363f@, lnk2)
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqacigacagaaeqabaqabegadaaakeaacqqgsbabcqqgubgbcqqgoaakcqqgoaakcqwgtbqbcqghrawkcqaixaqmcqggpaqkdawcaaqaaiabduealjabcicaoiabduealjabgkhitiabigdaxiabcmcapaqaaiabikdayaaacqggpaqkaaa@3cd6@, and o of the optimal solution respectively, where m is the maximum number of missing snps allowed and k is the number of haplotype patterns in the block.

we have implemented the first and second greedy algorithms in java . the lp-relaxation algorithm has been implemented in perl , where the lp problem is solved via a program called "lp_solve"  <cit> . the lp-relaxation algorithm is a randomized method. thus, this program is repeated for  <dig> times to explore different solutions and the best solution among them is chosen as the output.

in order to evaluate the solutions and efficiency of our algorithms, we also implement a program in java  which uses a brute force method to find the optimal solution. for a given data set of n snps, the opt program examines all possible solutions 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqacigacagaaeqabaqabegadaaakeaadaqadaqaauaabeqaceaaaeaacqwgobgtaeaacqaixaqmaaaacagloagaayzkaaaaaa@3059@, 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqacigacagaaeqabaqabegadaaakeaadaqadaqaauaabeqaceaaaeaacqwgobgtaeaacqaiyagmaaaacagloagaayzkaaaaaa@305b@, ..., and 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqacigacagaaeqabaqabegadaaakeaadaqadaqaauaabeqaceaaaeaacqwgobgtaeaacqwgobgtaaaacagloagaayzkaaaaaa@308e@). the minimum subset of snps that can tolerate m missing snps is chosen as the output. due to the np-hardness of this problem, the opt program fails to output the optimal solution within a reasonable period of time in many data sets. as a consequence, we skip some impossible solution space to speed up this program by the following two observations:  the solutions with less than or equal to m snps are the impossible ones since m snps might be missing; and  for a data set containing k haplotype patterns, the minimum number of snps required to distinguish each of them is at least log k . as a result, we can examine the possible solutions only for subsets of 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqacigacagaaeqabaqabegadaaakeaadaqadaqaauaabeqaceaaaeaacqwgobgtaeaacqwgtbqbcqghrawkcyggsbabcqggvbwbcqggnbwzcaamc8uaagpavlabduealbaaaiaawicacaglpaaaaaa@3a01@, 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqacigacagaaeqabaqabegadaaakeaadaqadaqaauaabeqaceaaaeaacqwgobgtaeaacqwgtbqbcqghrawkcyggsbabcqggvbwbcqggnbwzcaamc8uaagpavlabduealjabgucariabigdaxaaaaiaawicacaglpaaaaaa@3bd3@ ..., and 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqacigacagaaeqabaqabegadaaakeaadaqadaqaauaabeqaceaaaeaacqwgobgtaeaacqwgobgtaaaacagloagaayzkaaaaaa@308e@. by searching possible solutions from small subsets to large ones, the opt program can stop and output the optimal solution immediately when a subset that can tolerate m missing snps is found.

results on simulated data
theoretically, all snps will reach complete linkage equilibrium after sufficient chromosome recombination takes place. we first generate  <dig> data sets containing short haplotypes which simulate this bottleneck model  <cit> . each data set consists of  <dig> haplotypes with  <dig> snps. these haplotypes are created by randomly assigning the major or minor alleles at each snp locus. let m be the number of missing snps allowed and sa be the average number of robust tag snps over  <dig> data sets. figure  <dig>  plots sa with respect to m . when m =  <dig>  all programs find the same number of snps as the optimal solution. the iterative lp-relaxation algorithm slightly outperforms the others as m increases. when m >  <dig>  more than  <dig> snps are required to tolerate missing data. thus, no data sets contain enough snps for solutions.

we then generate  <dig> data sets containing long haplotypes. each data set is composed of  <dig> haplotypes with  <dig> snps. figure  <dig>  illustrates the experimental results on these long data sets . the optimal solutions for m >  <dig> can not be found by the opt program within a reasonable period of time  and are not shown in this figure. it is because the possible solutions in long data sets are too large to enumerate. on the other hand, both greedy and iterative lp-relaxation algorithms run in polynomial time and always output a solution efficiently. in this experiment, both greedy algorithms slightly outperforms the iterative lp-relaxation algorithm. in addition, the number of missing snps allowed is larger than those in short data sets. for example, to tolerate  <dig> missing snps , all programs output less than  <dig> snps. the remaining snps in each data set are still sufficient to tolerate more missing snps.

hudson   <cit>  provides a program which can simulate a set of haplotypes under the assumption of neutral evolution and uniformly distributed recombination rate using the coalescent model. we use hudson's program to generate  <dig> short data sets with  <dig> haplotypes and  <dig> snps and  <dig> long data sets with  <dig> haplotypes and  <dig> snps. figure  <dig>  shows the experimental results on hudson's short data sets . the number of missing snps allowed are less than that of random data. it is because hudson's program generates coalescent haplotypes which are similar to each other. as a result, many snps can not be used to distinguish haplotypes and the amount of tag snps is inadequate to tolerate larger missing snps. in this experiment, we observe that the iterative lp-relaxation algorithm finds solutions quite close to the optimal solutions and slightly outperforms the other two algorithms.

results on real data
we also test these programs on two real data sets:  public haplotype data of human chromosome  <dig> released by patil et al.  <cit> ; and  a  <dig> kb region on human chromosome 5q <dig> which may contain a genetic variant related to the crohn disease by daly et al.  <cit> . patil's data include  <dig> haplotypes of  <dig>  snps spanning over about  <dig>  mb, which are partitioned into  <dig>  haplotype blocks. by genotyping  <dig> snps with minor allele frequency at least 5%, daly et al. partition the  <dig> kb region into  <dig> haplotype blocks. each haplotype block in these real data sets contains different numbers of snps and haplotypes . when m increases, some short blocks may not contain enough snps for tolerating missing data . as a consequence, sa here stands for the average number of robust tag snps over those blocks still containing solutions.

f: fail to contain enough snps for tolerating m missing snps

discussion
in terms of efficiency, the first and second greedy algorithms are faster than the lp-relaxation algorithm. the greedy algorithms usually returns a solution in seconds and the lp-relaxation algorithm requires about half minute for a solution. it is because the running time of lp-relaxation algorithm is bounded by the time of solving the lp problem. furthermore, this lp-relaxation algorithm is repeated for  <dig> times to explore  <dig> different solutions. the opt program for searching the optimal solution is apparently slower than the others. the optimal solution usually can not be found within a reasonable period of time if the size of the block becomes large. ¿from our empirical study, the optimal solution can be found in reasonable time by the opt program if the block contains less than  <dig> snps . but for those large data sets with more than  <dig> snps, the opt program is significantly outperformed by the approximation algorithms .

assuming no missing data , we compare the solutions found by each algorithm with the optimal solution. table  <dig> lists the numbers of total tag snps found by each algorithm in previous experiments. in the experiments on random and daly's data, the solution found by each algorithm is as good as the optimal solution. in the experiments on hudson's and patil's data, these algorithms still find solutions quite close to the optimal solution. for example, the approximation ratios of these algorithms are only 472443≈ <dig> 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqacigacagaaeqabaqabegadaaakeaadawcaaqaaiabisda0iabieda3iabikdayaqaaiabisda0iabisda0iabiodazaaacqghijyucqaixaqmcqgguaglcqaiwaamcqai3awnaaa@37f1@ and 46574595≈ <dig> 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqacigacagaaeqabaqabegadaaakeaadawcaaqaaiabisda0iabiada2iabiwda1iabieda3aqaaiabisda0iabiwda1iabimda5iabiwda1aaacqghijyucqaixaqmcqgguaglcqaiwaamcqaixaqmaaa@39eb@, respectively.

we then analyze the genotyping cost that can be saved by using tag snps. in table  <dig>  the percentage of tag snps in each data set is shown in parentheses. the experimental results indicate that the cost of genotyping tag snps is significantly reduced in comparison with genotyping all snps in a block. for example, in patil's data, we only need to genotype about 19% of tag snps in each block, which saves about 81% genotyping cost.

the tradeoffs between the number of additional tag snps required and the number of missing snps allowed are discussed in the following. in practice, missing data in the genotyping experiment are usually limited to certain missing rate. we transform the maximum number of missing snps allowed into maximum missing rates allowed by calculating the percentage of m with respect to the number of robust tag snps. table  <dig> lists the results of the first greedy algorithm applied on random and hudson's long data sets. the number of additional tag snps grows with respect to m linearly. however, we observe that the maximum missing rate allowed grows slowly as m becomes large. this is because more additional tag snps are required in order to tolerate more missing snps. but under the same snp missing rate, genotyping these additional tag snps may also increase the number of missing snps, which reduces the power of robust tag snps. on the positive side, when m is small, the corresponding maximum missing rate allowed is sufficient for most genotyping experiments since their missing rates are usually less than 10%. for example, the robust tag snps with m =  <dig> are sufficient to tolerate 10% missing snps, and they only requires at most  <dig> additional snps. as a result, genotyping additional tag snps for tolerating missing data is cost-effective under the current genotyping environment.

in reality, not all haplotypes are of equal importance or confidence. when selecting robust tag snps, it might be desirable to weight them according to their population frequency. to incorporate the frequency of haplotypes into this problem, there are two possible ways:

 <dig>  it can be easily done by discarding the rare haplotypes and retain the common haplotypes as the input of our algorithms. this approach would not require modification to our algorithms. but the retained common haplotypes will be processed as equally weighted.

 <dig>  our algorithms try to find a set of snps such that each pair of haplotypes are distinguished by a threshold of at least  snps. a simplest way to weight the haplotypes is choosing different thresholds for each pair of haplotypes according to their population frequency. the haplotype pairs with higher frequency can then be assigned with more tag snps than the lower ones by our algorithms.

CONCLUSIONS
in this paper, we show there exists a set of robust tag snps which is able to tolerate a number of missing data. our study indicates that genotyping robust tag snps is more practical than genotyping minimum tag snps for association studies if we can not avoid the occurrence of missing data. we describe two greedy and one lp-relaxation approximation algorithms for finding robust tag snps. our experimental results and theoretical analysis show that these algorithms are not only efficient but the solutions found are also close to the optimal solution. in terms of genotyping cost, we observe that the genotyping cost saved by using robust tag snps is significant, and genotyping additional tag snps to tolerate missing data is still cost-effective. one future direction is to assign weights to different types of snps , and design algorithms for the selection of weighted tag snps.

software availability
project name: efficient algorithms for utilizing snp information.

project home page: 

operating system: the implemented greedy algorithms are platform independent, and the implemented lp-relaxation algorithm runs on the windows operating system.

programming language: the greedy algorithms are implemented in java, and the lp-relaxation algorithm is implemented in perl.

