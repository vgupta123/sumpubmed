BACKGROUND
motifs, or sequence motifs, are patterns of nucleotides or amino acids. motifs are often related to primer selection, transcription factor binding sites, mrna processing, transcription termination, etc. sequence motifs of proteins are typically involved in functions such as binding to a target protein, protein trafficking, post-translational modifications, and so on. motif search problem has been studied extensively due to its pivotal biological significance. several types of algorithms have been proposed for motif search. in one such class of methods, putative motifs in an input biological query sequence are predicted based on a database of known motifs. examples include  <cit> . in another class of methods, motifs are assumed to appear frequently in a set of sequences, like the same protein sequence from different species. here the problem of motif search is reduced to that of finding subsequences that occur in many of the input sequences. planted motif search is one such formulation.

numerous algorithms have been proposed to solve the pms problem. the winnower algorithm uses a graph to transform this problem into one of finding large cliques in the graph  <cit> . the patternbranching algorithm introduces a scoring technique for all the motif candidates  <cit> . the projection algorithm repeatedly picks several random positions and uses a hash table with a threshold to limit the motif candidates  <cit> . bailey  <dig>  <cit>  employs expectation maximization algorithms while gibbs sampling is used in  <cit> . multiprofiler  <cit> , meme  <cit> , and consensus  <cit>  are also known pms algorithms.

an exact pms algorithm always outputs all the motifs present in a given set of sequences. mitra employs a mismatch tree structure to generate the motif candidates efficiently  <cit> . risotto constructs a suffix tree to compare sequences  <cit> . pms <dig>  <cit>  considers all the motif candidates and evaluates them using sorting. voting uses a hash table to locate the motifs  <cit> . pms <dig> is based on pms <dig> and it extends smaller motifs to get longer motifs, and pms <dig> forms a motif of a desired length using two smaller motifs  <cit> . pmsprune introduces a tree structure for the motif candidates and uses a branch-and-bound algorithm to reduce the search space  <cit> . pms <dig> is a speed-up technique that finds a superset of the motifs using a subset of the input sequences and validates those candidates  <cit> . pms <dig> employs an integer linear programming as the branch-bound algorithm for a speedup  <cit> . pms <dig> uses the solutions of such ilps to generate motif candidates  <cit> .

most of the work on exact algorithms for pms has focussed on dna or rna sequences where |Σ|= <dig>  little work has been done on larger alphabet sizes, such as on proteins. a recent work focusses on protein sequences  <cit> . however, the stemming algorithm proposed in this paper does not solve the pms problem. in particular, it does not find motifs but rather motif stems. a motif stem can be thought of as an l-mer with some wild cards present in it. as a result, a stem stands for a set of motifs. a stemming algorithm generates stems to represent motifs for large-alphabet inputs  <cit> . the stemming algorithm of  <cit>  generates a very large set of stems . in this paper we propose two algorithms for motif stems search, mss <dig> and mss <dig>  which outperform the stemming algorithm of  <cit> . the new algorithms generate a much smaller set of stems. the stems generated by the algorithm of  <cit>  as well as mss <dig> and mss <dig> are guaranteed to be supersets of all the motifs present in a given set of input sequences.

methods
motif search on large alphabets
in this section we provide some definitions pertinent to pms and mss problems.

definition 1
a sequence x=x on Σ is an l-mer.

definition 2
given two l-mers x and y, the hamming distance between two l-mer is defined as:

 hd={i|x≠y,1≤i≤l} 

definition 3
given an l mer x and a sequence s of length m, the hamming distance between x and s is defined as

 hd=min1≤i≤m−l+1{hd}. 

definition 4
problem). let s be a set of n sequences of length m each on an alphabet Σ. specifically, let s={si||si|=m, 1≤i≤n}. the planted motif search problem or motif search problem takes as input s and two integers l and d, and finds every string x of length l such that for every si, the hamming distance between x and si is no more than d. in particular, we want to compute the following set:

 {x|x=l,hd≤d,for1≤i≤n}. 

any such x is called an -motif. any l-mer of si that is at a hamming distance of ≤d from x is called an occurrence or instance of x.

definition 5
given an l-mer x, the d-neighbors of x is defined to be {y : |y|=l and hd≤d}. the d-neighbors of x in any sequence s is defined to be the intersection of the d-neighbors of x and the set of l-mers in s.

observation 1
if the hamming distance between two l-mers x <dig> and x <dig> is larger than 2d ≥2d)then no l-mer x <dig> exists such that hd≤d and hd≤d.

pms algorithms are typically tested on random data with n= <dig> and m= <dig>  each input string is randomly generated such that each symbol in each string is equally likely to be any character from the alphabet. a motif is generated randomly. randomly mutated versions of this motif are planted in the input strings . for a given value of l, we call the pair a challenging instance if d is the smallest value for which the number of -motifs occurring in the input strings by random chance is ≥ <dig>  some of the challenging instances are: , , , , , , and so on. one of the performance measures of interest for any exact algorithm is the largest challenging instance that it can solve. mitra can solve the instance of  <cit> , and risotto  <cit>  and voting  <cit>  successfully run on . pmsprune solves up to  <cit> . pms <dig>  <cit>  and pms <dig>  <cit>  can handle . these statistics are based on dna sequences where |Σ|= <dig> 

the time complexities of exact algorithms typically depend exponentially on the size of Σ. pms <dig> takes o time, and pms <dig> costs o time where w is the word length of the computer  <cit> . it needs o time for risotto  <cit> , o for voting  <cit> , and o for pmsprune  <cit> .

when the size of the alphabet is large , the above exact algorithms will take a very long time. kuksa and pavlovic have introduced a new version of the motif search problem and proposed an efficient algorithm to solve it on large alphabets. a motif stem is an l-mer with wildcards. thus a stem represents a set of l-mers without wildcards. for example, if g ∗ acc is a dna stem, it represents the following 5-mers without wildcards: ggaac,gcaac,gtaac, and gaaac. given a set of strings from some alphabet, the problem of finding motif stems in them is known as the motif stem search  problem. we focus on mss in this paper.

definition 6
motif stem search problem. input are n sequences and two integers l and d. the problem is to find a set of stems such that the set of l-mers represented by these stems is a superset of all the -motifs present in the n sequences.

as stated above, there are many possible solutions to the mss problem. the challenge then is to come up with a superset as small as possible which covers all the -motifs. in other words, we want the number of l-mers represented by the stems to be as small as possible.

mss <dig> - a basic algorithm
based on observation  <dig>  if the hamming distance between an l-mer x and a sequence s is larger than 2d, then no l-mer x’ exists such that hd≤d and hd≤d. this leads us to the following observation.

observation 2
given an l-mer x, if ∃si such that hd>2d, then none of x’s d-neighbors can be a motif.

the stemming algorithm of  <cit>  works as follows. it makes use of observation  <dig> crucially. observation  <dig> states that an l-mer x in any input string cannot be an instance of an -motif if there exists at least one input string s such that hd>2d. the algorithm of  <cit>  first identifies a set i of possible motif instances. an l-mer x in any input string s will be included in i if and only if hd≤2d for every input string s’. having found such a set i, the algorithm then uses i to generate stems. the stems are found as follows: for every x,y∈i, the algorithm generates the common d-neighbors of x and y as stems. the union of all such stems will constitute candidate motif stems. this union is a superset of the motif stems. finally, for each candidate stem, the algorithm checks if this is a correct answer or not. all valid stems that pass this test are output.

in algorithm  <dig> and algorithm  <dig> we present a faster algorithm for generating motif stems. in algorithm  <dig> we present an algorithm for generating the set i. the cardinality of i that we generate is a much smaller subset of the i generated in the stemming algorithm of  <cit> . for any pair of l-mers in the set i, we begin with x and replace some characters in x with wildcards to generate mss candidates. the positions in which x and x’ match are referred to as the matching region and the positions in which x and x’ differ are referred to as the non-matching region. the wildcards can be placed in the matching region and/or the non-matching region. any stem t is generated by placing wildcards in x. therefore, wildcards in the generated stem t are always treated as mismatches between t and x, independent of whether they are in the matching or the non-matching region. however, for x’, in the non-matching region, wildcards in the generated stem t are assumed to be matches between t and x’ while in the matching region they are still treated as mismatches between t and x’. the number of wildcards is dependent on the hamming distance between x and x’ and d. let hd=dx. table  <dig> shows how many wildcards should be placed in different cases.

assume that i wildcards are placed in the non-matching region of x to form t, resulting in i mismatches between t and x and mismatches between t and x’. we consider the following two cases: 

 <dig>  dx≤d: the number of wildcards i can vary from  <dig> to the size of the non-matching region. to make the total number of mismatches against x smaller than d, at most d−i wildcards can be placed in the matching region of x. similarly, to make the total number of mismatches against x’ smaller than d, at most d−wildcards can be placed in the matching region of x’.

 <dig>  dx>d: at least dx−d wildcards have to be placed in the non-matching region to eliminate the mismatches. similar to case  <dig>  in the matching region, at most d− maxwildcards can be placed.

algorithm  <dig> mss1
in the matching region, d− maxis an upper bound on the number of wildcards. however, it is not necessary to enumerate all the cases from  <dig> to d− max. similarly, it is not necessary to repeat stems generation for all pairs in i. for any x let x1i,x2i,…,xji∈i be x’s 2d-neighbors in sequence si and let oi be the set of motif instances in si. then, clearly, oi⊂ii. the motifs form a subset of stems that can be obtained between x and each of oi. the motif stems we generate are stems that can be obtained from l-mer pairs of ,,…,). to minimize the number of stems generated from i, we have to use the sequence with the smallest j.

observation 3
for any l-mer x, let its 2d-neighbors in sequence si be ii=x1i,x2i,…,xji . then, the -motifs are included in the stems set, which is generated from the pairs ,,…,.

the detailed mss <dig> algorithm is given in algorithm  <dig> and algorithm  <dig> 

in lines 2- <dig> we find the sequence in which x has the minimum number of 2d-neighbors. also, if one sequence has no 2d-neighbor, the current l-mer x is skipped . the stems are generated by placing wildcards in each pair of x×imin, as shown in algorithm  <dig> 

hamming distance is called m2n times. therefore, excluding wildcards placement, algorithm  <dig> takes otime.

wildcards placement procedure is called times and each time |imin|=m−l+ <dig> in the worst case. therefore, in this case, wildcards placement in algorithm  <dig> is run otimes. the number of wildcards is no more than d. so line 4– <dig> takes old time in the worst case. as a result, wildcards placement in mss <dig> takes o time. in the best case, wildcards placement procedure is only called once when all other l-mers in s <dig> have no 2d-neigbhors, and imin= <dig>  the best case for line 4– <dig> is when dx=2d and it takes o2dd time .

in summary, mss <dig> takes otime, where |stems| is the total number of stems generated.

algorithm  <dig> placewildcards
mss <dig> - a speedup algorithm
the computation of the 2d-neighbors of x from s <dig> in a certain sequence si can be thought of as the calculation of a distance matrix between all l-mers in s <dig> against those in si as shown in figure 1b. a straight forward algorithm takes otime. when i ranges from  <dig> to n, the total time will be o. in this section we show how to reduce this total time from oto o.

assume that we have computed the hamming distance between x <dig> in s <dig> and xj′ in si. let this be hd=d <dig>  then, hd can be obtained by comparing: 1)the first characters of x <dig> and xj; and 2)the last characters of x <dig> and xj+ <dig>  observe that the -length prefix of x <dig> is the -length suffix of x <dig>  and xj′ and xj+1′ also share the same -mer.

if the first characters of x <dig> and xj match, then the d <dig> mismatches happen in the remaining -long suffixes of x <dig> and xj. in this case, hd=d <dig> if the last characters of x <dig> and xj+ <dig> match; otherwise hd=d1+ <dig>  similarly, if the first characters of x <dig> and xj do not match, then there are mismatches in the remaining -long suffixes of x <dig> and xj. in this case, hd=d1− <dig> if the last characters of x <dig> and xj+ <dig> match; otherwise hd=d <dig>  this observation is also mentioned in  <cit> .

observation 4
given hd=d <dig> where x <dig> and xj′ are two l-mers in s <dig> and si, the hamming distance between the next two l-mers of s <dig> and si, hd, can be calculated in otime as in :

  hd=d1−1ifx <dig> <cit> ≠xj′ <cit> ,x2=xj+1′d1ifx <dig> <cit> ≠xj′ <cit> ,x2≠xj+1′d1ifx <dig> <cit> =xj′ <cit> ,x2=xj+1′d1+1ifx <dig> <cit> =xj′ <cit> ,x2≠xj+1′ 

however, hd where p>q is left out when observation  <dig> is used repeatedly and reaches the end of si. we simply append a copy of si to si to cover all the pairwise alignments . then, by calculating the hamming distance only once and applying observation  <dig> repeatedly, each diagonal in the matrix of figure 1b can be computed in otime.

we do the above for m diagonals from cell  to  in figure 1b. then the first and last rows are used to form a complete ×matrix. the l rows in the middle were eliminated since they are the extra rows caused by appending a copy of si. therefore, the computation of the 2d-neighbors of x from s <dig> in any sequence si can be computed in o)=otime. the computation for all the sequences from s <dig> to sn takes a total of otime.

the pseudocode is given in algorithm  <dig>  in lines 6– <dig>  the hamming distance is calculated for the alignment of s <dig> with the jth position of si. each of the remaining hamming distances in this alignment is obtained in constant time by observation  <dig> . instead of appending a copy of si, the mod operation is used. mss2

n2d keeps the 2d-neighbors of the kthl-mer in s <dig> in the ith sequence si. to build the matrix of 2d-neighbors of all the l-mers of s <dig> , it takes otime . lines 29– <dig> search the 2d-neighbors of each l-mer of s <dig>  if some sequence sj has no 2d-neighbors, the current ithl-mer of s <dig> is skipped . otherwise, the 2d-neighbors in the sequence with the smallest size, imin, are used and the wildcards are placed.

mss <dig> takes otime.

optionally, a post-process phase is used following both mss <dig> and mss <dig> algorithms to refine the output stems. in the post-process phase, a stem is retained only if this stem has at least one neighbor in each sequence at a distance of ≤d. this phase takes a total of otime.

an estimation on the number of stems
we can compute the expected number of stems generated by our algorithms as follows. let q be any l-mer in s <dig>  what can we say about |imin| corresponding to q? consider any sequence s other than s <dig>  let q be any l-mer of s. the probability p that hd ≤2d is ∑i=02dliσ−1σi1σl−i where σ=|Σ|. this implies that the expected number of such q’s is mp. when Σ increases, p decreases drastically, as examples are shown in table  <dig> for σ= <dig> and σ= <dig>  in all the previous works , analyses have been done assuming that all the l-mers in any sequence are independent. if we assume this, then we can apply chernoff bounds and show that the number of such q’s is owith high probability. this in turn will imply that |imin|=owith high probability. nstems, the number of stems generated between any two l-mers with the hamming distance dhm, is given in , which is crudely bounded by o. as a result, it follows that the expected number of stems generated by our algorithms is o.

  nstems=∑i=0dhmlild−max{i,dx−i}0≤dhm≤d∑i=dhm−ddlild−max{i,dx−i}d≤dhm≤2d 

algorithm  <dig> mss2
challenging instances
consider a pms instance with n sequences of length m each. for a given value l, let d be the smallest integer such that the expected number of motifs that occur by random chance is ≥ <dig>  we refer to as a challenging instance. we can compute challenging instances as follows. let the alphabet under concern be Σ with |Σ|=σ. the probability that two random characters in this alphabet match is 1/|σ|. then assuming an iid background, the probability that the hamming distance between two l-mers is no more than d is p=∑i=0dliσ−1σi1σl−i. for each sequence, the probability that a random l-mer has at least one d-neighbor in this sequence is p=1−m−l+ <dig>  this means that the expected number of randomly occurring motifs in the n sequences is σlpn. from this we can calculate the challenging instances. for σ= <dig>  the challenging instances are ,, etc. when σ= <dig>  the challenging instances are ,, etc. because of observation  <dig>  in our tests of challenging instances of protein sequences, we have used the cases of ,, and .

RESULTS
we have evaluated our algorithms on the standard benchmark where n= <dig>  m= <dig>  let |Σ|= <dig> . we have used values starting from going up to .

the testing data was generated as follows: 1) <dig> sequences of length  <dig> each were generated such that each character in each sequence is equally likely to be one of the characters from the alphabet; 2)a motif of length l was generated randomly; 3)a random number of mismatch positions which is smaller than or equal to d was selected and the characters in these positions were replaced by other amino acids randomly to form a motif instance; 4)step 3)was done  <dig> times to generate  <dig> such instances and these were planted in the  <dig> sequences .

we have implemented and compared our algorithms with risotto  <cit>  and the stemming algorithm of  <cit> . please note that we have implemented the algorithm of  <cit>  since we have no access to a running version of the corresponding program. both the running time and the number of stems generated were used as performance measures. the machine used had an intel core i7-2760qm  <dig> ghz processor with a memory size of 4gb, as shown in table  <dig> and table  <dig>  in these tables "-" indicates that the algorithm took too long to finish. these tables show that mss <dig> and mss <dig> run faster than risotto  <cit>  and stemming  <cit> . since the set of stems is a superset of the true motifs, the stems set contains true motifs and false motifs . a smaller number of stems indicates less false predictions. the proposed algorithms generate a much smaller subset of the stems generated by the stemming algorithm  <cit> . since instances such as ,,,etc. are commonly used in dna sequences, we have also tested the algorithms on more challenging cases such as ,, and as shown in table  <dig>  in addition to the case of σ= <dig>  we have also tried different alphabet sizes:  <dig>   <dig>   <dig>  and  <dig>  table  <dig> displays the running time for various alphabet sizes. the fact that the rune times are nearly the same for different alphabet sizes indicates that the running time of all the algorithms are independent of the alphabet size. the post-processing phase takes longer time as the alphabet size increases since the number of stems increases.

due to better performance, we have used mss <dig> in real biological protein data. in minimotif miner  <dig>  database  <cit> , we randomly sampled  <dig> protein motifs. each of these motifs has multiple source proteins. comparison of mss, risotto, and stemming is shown in table  <dig> 

finally, we have compared the mss <dig> algorithm with pmsprune, a well-known plant motif search algorithm on dna sequences  <cit> . as is clear from table  <dig>  mss <dig> is not as fast as pmsprune. on dna sequences, the number of spurious motifs is very large. therefore, the motif stems search algorithms, which are efficient for large alphabets are not as efficient for small alphabets.

discussion and 
CONCLUSIONS
the analysis in  <cit>  shows that, assuming iid background, the expected number of the -motifs depends highly on the alphabet size |Σ|. therefore, when |Σ| is large, the expected number of 2d-neighbors in the nm-length sequences is very small in comparison with the total number of l-mers ).

the proposed algorithms consider an even smaller size of candidates by introducing imin. in particular, for any given l-mer x, we focus on the sequence that has the smallest number of 2d-neighbors for x. the expected size of imin is 1n times the total number of 2d-neighbors of x in all the sequences. please note that we do not miss any of the valid motifs.

on the other hand, when generating the stems, as shown in table  <dig>  once i wildcards in the non-matching region are placed, it is known that the upper bound of wildcards in the matching region is d− max. however, it is not necessary to enumerate all the cases from  <dig> to d− maxin the matching region. as long as the case of )wildcards cannot be eliminated,  <dig> to −1)wildcards are contained in the )wildcards placement. therefore, the proposed algorithms do not enumerate  <dig> to −1)wildcards placements in the output.

in the computation of the 2d-neighbors, mss <dig> takes otime and ospace. mss <dig> takes otime and ospace. the stemming algorithm of  <cit>  uses sorting to compute the set i.

the proposed algorithms mss <dig> and mss <dig> provide an efficient way to solve the motif stems search problem in terms of both time and space. also, the stems generated by mss <dig> and mss <dig> form a much smaller subset, with less false predictions, of the stems generated by the algorithm of  <cit> .

competing interests
the authors declare that they have no competing interests.

authors’ contributions
tm contributed to the implementation of the algorithms, manuscript preparation, algorithms development, and performance analysis. sr contributed to algorithms development, analysis of the results, performance analysis, and manuscript preparation. both authors read and approved the final manuscript.

