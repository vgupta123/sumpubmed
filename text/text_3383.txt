BACKGROUND
transcriptional profiling studies can produce data in the form of abundance measurements for genes in samples assigned to one of two classes. a recent exemplar employed cdna microarrays to assay  <dig> clones from normal liver and liver cancer  tissues  <cit> . given such two-class high-dimensional data, one analytical task is identifying a "small" subset of features able to discriminate between the classes. tools that solve this problem would accelerate development of novel and/or improved molecular targets for diagnosis, prognosis, and therapy  <cit> . for example, enunciating genes able to distinguish liver cancer from normal samples could assist investigations into the etiology and treatment of liver cancer.

existing classification and feature selection techniques can be employed to ascertain the cardinality of a feature subset yielding a classifier that generalizes well, i.e., one which makes zero  errors in assigning the class of an unseen data point. frequently, application of these approaches to a data set results in the definition of one discriminatory subset with tens to hundreds of features and requiring similar numbers of free parameters. this work focuses on subsets smaller than those produced by existing algorithms: all subsets of one-, two-,  features that can be separated by a linear surface without error. a multiplicity of error-free linear classifiers constructed from few features could facilitate the creation of cost-effective clinical tests and guide further basic research.

here, an m-feature classifier is defined as a decision surface for m-dimensional data points where the m features are a subset of p a priori features, m ≪ p. the potential number of these classifiers is equivalent to choosing m items out p, i.e., . this number increases when different types of decision boundaries are permissible for each value of m. the scope of the problem can be reduced and simplified if only m-feature linear classifiers  are considered. this restriction of neglecting non-linear decision surfaces is reasonable because hyperplanes can be calculated efficiently, and support vector machines with linear kernels are sufficient for classification problems associated with profiling data . recent work by bo  <cit>  and kim  <cit>  demonstrate the utility of looking for small feature sets. bo and jonassen surveyed a number of classifier discovery methods including linear hyperplanes. they showed that accurate two-gene classifiers exist in real world data sets and that they perform well. they only analyzed  <dig> data sets, did not report computer runtimes nor consider single genes or gene triples in their analysis. kim et al employed a heuristic, monte carlo-based strategy to discover 2- and 3-lcs for a real-world, 3226-dimensional, two-class transcriptional profiling data set  <cit> . this sophisticated method computes noise tolerant hyperplanes using an analytic spherical model. however,  <dig> hours on a supercomputer cluster were required to identify at least  <dig> pairs of genes, each of which separates the data. thus, although brute force exhaustive search provides a comprehensive and systematic method for finding all small discriminatory feature subsets, the strategy is expensive computationally and largely untenable for m ≥  <dig> . the high dimensionality of transcriptional profiles and the logistical issues associated with exhaustive enumeration of all 1-, 2- and 3-lcs have lead to the prevailing assumption that such searches are both too expensive and unlikely to be informative. thus, while some recent studies have made use of kim's method  <cit> , most profiling studies neither consider nor report small sized discriminatory feature subsets.

here, a relatively inexpensive method for calculating maximal margin hyperplanes, liknon  <cit> , is utilized to rapidly find error-free m-lcs in ten published transcriptional profiling data sets that assayed samples from liver, human breast, ovary, lung, skin, gastrointestinal tract, bone marrow, brain, and prostate. the number of free parameters in this method is m +  <dig>  hence is very small relative to the size of the data, greatly reducing the problem of over-fitting to the training data . it seems plausible that the existence of single genes and gene pairs with the ability to form perfect linear classifiers may be a widespread phenomenon. to demonstrate the biological utility of the strategy, the gene pairs and triples discovered in the aforementioned livercancer data set were examined and found to yield new and unanticipated scientific insights. overall, the results indicate the importance of ascertaining, as a matter of routine, the presence  of small distinguishing feature subsets.

RESULTS
all results are available through the web site  <cit> .

the  <dig> published cancer data sets examined here are listed in table  <dig>  they range in size from small  to large , using a variety of microarray technologies. for each data set, all single and pairs of genes were tested  using the liknon technique. all gene sets that formed zero training error classifiers were saved and are available via the web site. table  <dig> lists the number of such gene sets. many data sets have single genes or pairs that form such perfect linear classifiers which is interesting as most original reports did not note their presence. computer runtimes are given in table  <dig>  a rough time estimate is  <dig> second per million pairs per sample. evaluating all pairs requires checking about  <dig>  * n <dig> pairs . so a  <dig> gene,  <dig> sample set would need about  seconds.

as expected, small data sets are found to have many thousands of gene pairs while large data sets have few. the gene sets discovered in the two large data sets  are likely biologically relevant and are discussed later. the thousands of pairs found on small data sets are mostly due to the small sample size of the data, and would likely not maintain their perfect classification upon addition of further patient samples. generalization performance was estimated with a loo methodology  and is often reasonably good.

however, even gene sets found in small data sets can be interesting depending on the end use. for use in a medical diagnostic it is desirable that the gene set be highly accurate on large number of patient samples so the test result error rate is low. if used to guide basic research, even a poor error rate could indicate a productive research direction.

the results are easily visualized for single and pairs of genes by a scatter plot. for each sample the expression values for the gene set the x-y position and the point is labeled with the sample class as shown in the example plot figure  <dig>  the separating plane is drawn between the two clouds of points and one can see the amount of separation between the two classes  a particular set of genes pair yields. a larger margin means the data are more well separated hence is more resilient to noise and more likely biologically relevant.

discussion
many of the genes sets found accurately classify the data with large separation between the classes. it is exciting to consider the possibilities for medical diagnostics if some small gene set is found to accurately and reproducibly indicate a disease state. while general machine learning principles suggest that having more features  is desirable in order to make more noise resistant classifiers, this is data dependent and gene pairs with a training error rate of 1/ <dig> as found in the livercancer data could be perfectly acceptable. small gene sets, even if not accurate enough for medical purposes, can indicate fruitful new research directions. like other classification methods that produce large numbers of genes, considering the corpus of all genes found can provide insight to the underlying biology.

experimental design and construction of a data set profoundly influences the presence of small sized classifiers. for example, the brca sets are labeled according to their known brca1/brca <dig> mutation status. if some of the measured genes reflect this mutation status we would apriori expect to find some  small feature sets, and not finding any could indicate errors in the class labels .

in data where the class sizes are small, most of the small gene sets will prove sensitive to noise. thus they are not likely to perform well as predictors on new samples, or in different experiment setups. classifiers made from large data sets are more likely to be reproducible and perform well in other situations. classifiers with large margin and zero loo error are more likely to indicate real biological effects that would hold true on new patient samples.

the gist and breastbrca experiments are examples of both of the above conditions, and both lead to very large numbers of pairs. both have small class sizes and have pre-disposed differences between the classes. the gist experiment compares cancers from different tissue types which means there will be a very strong signal from just the tissue differences rather than just the cancers alone. the breastbrca experiment has the pre-disposition of being split along brca status lines. in both cases the number of patient samples and class sizes is small and  <dig> + pairs are found. we suspect there are some biologically real pairs hidden in the large background noise due to small sample sizes. random data tests  indicate that 30+ samples with more even class sizes are needed in order to reduce the random chance noise to a very small level .

gene sets that perform well across independent experimental data sets also likely indicate real biological effects. however, cross-experiment array comparisons are difficult and would be much easier and more broad if experimenters used more common clones and references.

is the cost of such computation worth it? certainly it is for single genes and pairs. modern computers are powerful enough to solve these size problems in a few minutes. triples needs tens to hundreds of hours on a single computer, which is still tractable. quadruples are beyond single computer tractability. however, this type of algorithm is trivially parallelized over a standard network of computers leading to linear speed up. each computer would be instructed to examine a given part of the search space and thereafter be independent from all the rest. a super computer or dedicated computer cluster is not required. it seems possible that the occurrence of such small sized classifiers is a common characteristic of microarray data, thus making the effort of searching for small gene sets worth the computational cost. the technique is not restricted to rna/dna transcript microarray data as used here. it can be applied to protein microarray, mass-spectra, or any data with similar characteristics.

data set discussion
we can't discuss all the gene sets found in all data sets: there are too many. here we discuss results from the  <dig> large data sets that we think produce highly biologically relevant results. the supplement  contains further discussion and the web site  <cit>  provides access to all the results and plots.

liver cancer
the large liver cancer data set contains  <dig> classes  with  <dig> patient samples and measurements for  <dig> genes. we examined this data set in more detail than the others as it is large and any results found are likely to be biologically relevant. the original data  <cit>  was re-normalized using the intensity/local then spatial/local methods as implemented in the bioconductor r package  <cit>  . with the original data example labelings , there are no pairs found. however, normal liknon  <cit>  discovers a  <dig> gene classifier with  <dig> of the tumor examples strongly mis-classified . this suggests these  <dig> samples might have some sort of problem with them  or are simply mislabeled. relabeling these  <dig> tumor samples to be normal results in  <dig> gene pairs being found. going further we wished to look for gene triples, yet using all  <dig> genes would lead to excessive runtimes, so we applied a variation filter to reduce the number of genes. this variation filter  reduced the number of genes examined from  <dig> down to  <dig>  which yielded  <dig> gene triples  and  <dig> gene triples . only  <dig> of these triples were saved for further analysis. all  <dig> gene pairs,  <dig> of the  <dig> and  <dig> of the  <dig> triples include the recently annotated gene plac <dig>  a "placenta specific gene of unknown function".

the  <dig> genes in pairs with plac <dig> are

• image: <dig> glcci <dig> glucocorticoid induced transcript 1

• image: <dig> adcy <dig> adenylate cyclase 6

• image: <dig> transcribed sequence with moderate similarity to protein sp:p <dig> 

• image: <dig> bcat <dig> branched chain aminotransferase  <dig>  mitochondrial

• image: <dig> mt1e metallothionein 1e  hs74170

• image: <dig> arhe ras homolog gene family, member e hs6838

• image: <dig> gpc <dig> glypican  <dig> hs119651

and is shown in figure  <dig>  gpc <dig> is a recently noted hcc cancer marker  <cit> , where it was elevated in  <dig> out of  <dig> patient samples. here this gene triple makes no errors on all  <dig> patient samples. the top triple using the relabeled examples is

• image: <dig> rnahp rna helicase-related protein hs8765

• image: <dig> plac8

• image: <dig> phlda <dig> pleckstrin homology-like domain, family a, member  <dig> hs82101

in all, the  <dig> triples make use of  <dig> of the genes. the fact that triples exist when using the original labelings argues that the "outlier" examples are correctly labeled as tumor, albeit maybe a different type of tumor . that these small gene sets exist in such a large data set argues that they are biologically relevant. these  <dig> gene pairs only make  <dig> errors out of the  <dig> patient samples , which is an error rate of 2/ <dig> = l/ <dig>  the triples found with the original labelings make no errors. based on such data, one can imagine a simple few-gene diagnostic test based on these pairs and triples.

it is perhaps not surprising that a placental gene is associated with liver cancer. both are blood organs, and cancers often recapitulate early development stages, of which the fast growing placenta might be an example. in addition, mitochondria related genes have been associated with cancer progression.

for this data, normal liknon was a useful aid in identifying outlying data examples. the two outlying tumor samples in this data set could represent a rare tumor type or development state. using such aids during the experiments would allow such samples to be identified in a timely manner for further investigation.

modeling of plac8
plac <dig> is noted to have a match to the pfam model pfam <dig>  duf <dig>  a search of the pdb database using a sam hmm model  <cit>  created from the pfam alignment finds a hit to 1p <dig>  which is a non-covalent endonuclease iii-dna complex from bacillus stearothermophilus. the pfam model locates to the c terminus of the 1p <dig> crystal structure. the sequence of 1p <dig> is some  <dig> amino acids longer than plac <dig>  and the alignment hit aligns the last  <dig> amino acids or so. visualizing the 3d structure of 1p <dig> with the alignment hit in plac <dig> colored silver in the rasmol tool , shows that this hit forms a distinct mostly helical domain at the c terminus.

yeohall
the yeohall data set is a large multi-class pediatric acute lymphoblastic leukemia cancer set. the original data contains  <dig> classes, we use only  <dig> of them . for each of the  <dig> classes we compare each class against all others combined, thus asking the question can each class be distinguished from all the others. there are  <dig> patient samples and the  <dig> classes are t, e2a, bcr, tel, mll and hyperdiploid >  <dig>  both the t vs the rest and e2a vs the rest splittings have single genes that perfectly separate t or e2a from the others. five out of the  <dig> splittings have gene pairs, only hyperdiploid vs the rest does not have any small gene sets. we applied a variation filter to reduce the original  <dig> affymetrix probes down to  <dig> genes . we only discuss the top results for the t and e2a splittings here, see the supplement  for more details. our results reinforce many of the findings in yeoh's work that there are single genes that accurately classify the t and e2a leukemia subtypes and extends it by identifying accurate  <dig> gene classifiers.

t vs the rest
the only single gene separating t vs the rest is the same one identified by yeoh, "38319_at cd3d antigen, delta polypeptide  hs95327". this gene has a high value in t and a low value otherwise  and clearly separates the data. there are  <dig> pairs making use of  <dig> different genes, the top pair is "37039_at hla-dra major histocompatibility complex, class ii, dr alpha hs409805", and "1105_s_at m <dig> humtcbyy human t-cell receptor active beta-chain mrna" . in t, humtcbyy is generally high and hla-dra is low. these and many other of the genes in the top pairs are identified by yeoh as being significantly differentially expressed in t. however they did not identify any gene pairs as accurate classifiers.

e2a vs the rest
the  <dig> single probe sets for e2a are

• "33355_at pbx <dig> pre-b-cell leukemia transcription factor  <dig> hs408222"

• "1287_at adprt adp-ribosyltransferase  polymerase) hs177766"

• "430_at np nucleoside phosphorylase hs75514"

• "32063_at pbx <dig> pre-b-cell leukemia transcription factor  <dig> hs408222"

 all of these are high in e2a and lower in the rest. probe 33355_at for pbx <dig> is shown in figure  <dig> where it clearly separates the classes and was the only single gene identified in yeoh's original work. the other  <dig> probes barely separate the data and likely failed yeoh's stringent cross-validation criteria. these  <dig> probes are in yeoh's significantly differentially expressed list.

there are  <dig> pairs, the best pair is "35125_at rps <dig> ribosomal protein s <dig> hs408073" and "35974_at lrmp lymphoid-restricted membrane protein hs124922". figure  <dig> shows that this pair separates the data well. lrmp is identified in yeoh's lists , as are many of the genes in the other top pairs. these and the other top pairs often highly separate the data indicating they might be biologically relevant and resilient to noise. these and all the rest of the results are available through the web site.

CONCLUSIONS
small sets of genes  able to accurately classify two-class microarray data occur in many real-world data sets. these small sets could portend simple medical diagnostics and point to important research targets. the many small sized gene sets found here were not noted previously in the literature, and seemingly went unnoticed. many members of the pairs discovered here have known associations with cancer and indicate the possibility of simple, accurate medical diagnostic tests based on such results.

exhaustively examining all pairs in thousand gene size datasets is easily tractable on modern computer hardware. all triples is harder, needing a few days, but this is only computer time, and powerful computers are cheap and plentiful. given that the compute time is small enough and the results possibly important, we conclude that examining microarray data for single genes, gene pairs and maybe gene triples should be done routinely. when performed along with acquiring the biological data, the results can be used as a quality check on the experimental process.

the gene of unknown function, plac <dig> appears to have a role in liver cancer, and based on our hmm modeling might have a domain similar to part of the crystal structure of 1p <dig>  we find that there are  <dig> genes that when paired with plac <dig> form a classifier with the low error rate of 1/ <dig>  in addition there are many gene triples, often including plac <dig>  that form zero error classifiers and might be good biomarkers. we find the previously identified hcc biomarker gene, glypican  <dig> , is part of an accurate gene triple involving mt1e and arhe. we also find small gene sets able to accurately distinguish leukemia subtypes in the large pediatric acute lymphoblastic leukemia cancer set of yeoh et al.

