BACKGROUND
data-driven inference of intracellular regulatory networks, in particular of those involved in gene regulation, remains to be one key challenge of computational and systems biology.

many methods for this daunting task have been proposed and new methods are appearing at a high rate
 <cit> . the different inference methodologies can be categorized based on the model formalism and the principle used for deriving interactions in a regulatory network: sparse regression
 <cit> , correlation-based approaches
 <cit> , z-score
 <cit> , mutual information
 <cit> , anova-based analysis
 <cit> , bayesian networks
 <cit> , gaussian graphical models
 <cit> , random forest
 <cit> , differential equations
 <cit> , reaction networks
 <cit>  and boolean networks
 <cit> . one final output of all these approaches is the reconstructed network topology, typically given as a  graph. recent efforts have shown that combining several of the aforementioned methods often outperform all single approaches
 <cit> .

it is of utmost importance to rigorously evaluate and compare the large number of methods before one can put confidence in the results of their application. the need for the verification of computational systems biology methods is now recognized worldwide. notably, the dialogue on reverse engineering assessment and methods  project organizes international gene regulatory network inference challenges and evaluates the solutions submitted by participating research groups in a transparent manner
 <cit> . this way a “collaborative-competition” is established in which complicated problems are addressed as a community rather than individual laboratories
 <cit> . recently, it was demonstrated that such community effort was fruitful for the inference of an improved gene regulatory network of escherichia coli and the inference of a novel gene regulatory network for the bacterium staphylococcus aureus <cit> .

verification of inference methods requires benchmark datasets
 <cit> . benchmarking on real biological data is challenging as true biological networks are largely unknown
 <cit> . the availability of realistically simulated datasets is therefore of utmost importance for the verification of these methods. only for simulated data can we be certain about the true complex system underlying the data. simulated data has been used to validate methods, but typically the data was generated with small networks 
 <cit>  and with the same models as used by the inference
 <cit> . a step to more realistic benchmark data was made in 2003
 <cit> , generating simulated gene expression data using equations based on enzyme kinetics . as regulatory network inference methods are typically applied to genome-wide data, a necessary next step is to perform evaluations also on genome-scale.

in this paper we revisit two related gene network inference methods: down-ranking of feed-forward loops  and transitive reduction for weighted signed digraphs . both approaches were successfully employed  in the dream <dig> in silico network  <dig> nodes challenge. in this challenge, the task was to reverse engineer gene networks from  steady-state and time-series data. dr-ffl and transwesd share a common core as they both try to infer a minimal regulatory graph that can explain the gene expression changes observed in perturbation experiments. in particular, both methods apply the principle of transitive reduction to identify and eliminate edges reflecting indirect effects. since both dr-ffl and transwesd were ranked high, their underlying inference strategy could provide a generally promising approach for gene network inference.

network reconstruction based on transitive reduction usually involves three steps of which the last can be seen as optional: 

step  <dig> : a perturbation graphgp is generated from the perturbation data, i.e., a directed edge from a node i to a node j  is included in
gp if a perturbation in i changed the level of j significantly . sometimes, the edges are also labeled by a sign and might also get a weight indicating their confidence or likelihood.

step  <dig> : as an edge in the perturbation graph may reflect a direct but also an indirect effect between two nodes, the goal of the second step – the transitive reduction – is to identify and eliminate indirect effects in
gp yielding the final reconstructed graph
gt. as a general rule for transitive reduction, an edge introduced due to indirect effects is detected by searching for alternative paths in
gp which could induce the same net effect as this edge. we say that such a path explains the edge and the latter is then removed.

step  <dig> : normally one would consider all edges contained in
gt as the true edges. in an optional third step, all edges of the reconstructed graph
gt are ranked in a list according to a given confidence score for each edge. for certain applications it might be useful to augment this list also by “edges”  not contained in
gt . in this way we get an ordered list of all potential pairwise interactions according to their confidence score.

these three steps are common to all approaches using transitive reduction  but different variants may arise  by using different approaches to derive the perturbation graph  in step  <dig> or  by considering different criteria a path must fulfill in order to explain a given edge in step  <dig>  or  by different edge sorting schemes to be used in step  <dig>  for example, dr-ffl
 <cit>  uses a z-score-based strategy to generate the pg and does not consider edge signs in the tr step when searching for valid paths that can explain certain edges. in contrast, transwesd
 <cit>  generates the pg by selecting edges that satisfy two related but distinct statistical conditions whereas the actual tr procedure accounts for edge signs and also edge weights when searching for suitable paths that can explain a given edge.

in the present study, we propose and test novel variants for each of the three steps mentioned above, i.e., for pg generation, for tr, and for edge sorting. as one major outcome, we present particular combinations of pg generation and tr strategies which yielded superior results in diverse benchmark tests outperforming by far the two original approaches. as benchmarks we used not only the dream <dig> in silico network challenge but also a novel and unprecedented synthetic compendium consisting of several realistic 5000-gene networks simulated with varying biological and measurement error variances resulting in a total of  <dig> datasets. in both benchmarks we focus on perturbations induced by single gene knockouts. such experiments can be carried out at genome-scale at least in some model organisms . as a realistic application scenario we used our framework for inferring gene interactions in yeast saccharomyces cerevisiae based on a library of gene expression data measured in mutants with single knockouts of transcription factors
 <cit> . the reconstructed network shows a significant enrichment of known interactions, especially within the  edges identified with highest confidence.

the results of the benchmarks demonstrate the relative performance of the different approaches, moreover, they also enable us to draw some general conclusions. for example, it turns out that when pruning the pg by tr, it is often sufficient or sometimes even favorable to restrict the search on paths having a length of only two. we also demonstrate that edge weights are highly beneficial for tr whereas edge signs are of minor importance . we give an explanation for these observations from a graph-theoretical perspective.

methods
we start with a brief description of the original tr methods dr-ffl and transwesd which inspired the novel inference algorithms presented herein. afterwards we introduce the new variants for pg generation, tr, and edge sorting. for the pg generation algorithms, we assume that we are given the following input variables : 

• a 1 × n row vector gwt containing the  wild-type gene expression data

• the n × n matrix gko containing the  measured steady-state gene expression levels after perturbing/knocking-out each single gene. the element
gi,jko stores the gene expression level of gene j after perturbing gene i.

these input variables directly correspond to the datasets provided in the dream <dig> challenge and in our novel compendium of simulated large-scale networks .

down-ranking of feed-forward loops 
the dr-ffl algorithm described in
 <cit>  used the following strategies for the three steps:

step  <dig> 
in a preprocessing step, a confidence weight is assigned to each possible edge i → j of the network by computing the absolute value of the standard z-score zij. the latter quantifies the difference between the expression
gi,jko of gene j under knockout/perturbation of gene i and its mean μj, normalized by the standard deviation σj:

  zij=gi,jko−μjσj. 

mean μj and standard deviation σj are computed on all available expression measurements of gene j, including the wild-type
gjwt. then, the pg
gp is obtained by selecting all those edges whose |zij| is larger than a given threshold β. we then denote the pg generated by the original dr-ffl method by pg <dig> 

step  <dig> 
dr-ffl circumvents possible problems arising in tr of cyclic graphs by allowing only those edges to be removed that connect nodes from different strongly connected components . dr-ffl uses unsigned and unweighted tr, i.e., an edge i → j is removed from
gp if i and j are from different components and if there is an alternative path connecting i and j without using edge i → j.

step  <dig> 
the confidence weights |zij| of the remaining edges in the graph
gt obtained after tr are increased by a constant offset such that all edges in
gt are ranked higher than all other potential edges . the latter are listed below the edges of
gt according to their confidence weight computed in step  <dig> .

transwesd
transwesd  was introduced in
 <cit>  with the goal to generalize and improve previous tr approaches
 <cit>  to make it amenable for the reconstruction of large biological networks.

step  <dig> 
transwesd constructs the pg
gp via two thresholds: an edge i → j is introduced in
gp if  a measure similar to the z-score |zij| used by dr-ffl exceeds a given threshold β and  if the absolute change of the state of node j when perturbing i exceeds a certain minimal deviation γ, i.e. if
|gjwt−gijko|>γ. each edge i → j gets a sign
sij=signgjwt−gijko indicating whether the changes in i and j have the same direction  or not . in addition, a weight wij is assigned to each edge i → j quantifying its uncertainty or behavioral distance . accordingly, transwesd uses wij = 1 − |cij| with cij being the conditional correlation coefficient between genes i and j which is computed from all experiments except those where gene i was directly perturbed. more specifically, herein we define the conditional correlation coefficient cij as the pearson correlation coefficient computed from all measurements of nodes i and j  except in the experiments where j was knocked-out. the pg generated by the original transwesd procedure is denoted by pg <dig> 

step  <dig> 
a particular feature of transwesd is that it can deal with signed and weighted pgs and that cycles are allowed. the tr rule is as follows: an edge i → j with sign sij and weight wij is removed if there is an alternative path pij  which connects i and j and fulfills the following requirements:  pij is simple, i.e., it does not contain a cycle;  pij does not involve edge i → j;  the overall sign of pij  is the same as sij; and  the maximum weight of all edges on path pij ) fulfills

  wmax<α·wij. 

the confidence factor α is typically chosen close to  unity; the default value used by klamt et al.
 <cit>  is  <dig> . with α <  <dig> it is ensured that all edges in the path pij have a higher confidence than the edge i → j. however, in some cases it can nevertheless be advantageous to use also α >  <dig>  if a path pij with the four required properties exists in the pg, then the observed effect of i upon j is considered to be explained  by path pij. all edges i → j in the pg fulfilling these conditions are considered to be  removable and are collected in a set r. if the graph is acyclic, tr is simple and unique and all potentially removable edges in r can be deleted immediately. the situation is more complicated in cyclic graphs: the result of tr can become non-unique, depending on the order of edge removals. transwesd uses a reasonable rule to resolve non-uniqueness: it removes the edges of r iteratively starting with the highest weight  first. as a second problem in cyclic graphs, it may then happen that a formerly removable edge in r becomes non-removable because certain paths may have been interrupted by preceding deletions of other removable edges. even worse, an edge might still potentially be removable but its elimination would lead to the interruption of a path that was required to explain an edge already removed in a previous iteration . it is therefore necessary to explicitly test, in each iteration, whether upon removal of the next edge of r all edges originally contained in the pg
gp are still explainable by the remaining graph . this may require extensive shortest path calculations.

therefore, to reduce the computational effort in large-scale cyclic graphs, transwesd provides two parameters  to allow for the  use of approximate solutions which may drastically reduce the required computation time. since computing the shortest path of a given sign in cyclic signed digraphs is an np-complete  problem, starting transwesd with path_exact= <dig> enforces the use of approximate path calculation algorithms which have been shown to produce no or only few errors in large-scale biological networks
 <cit> . the full_check= <dig> option can be used to suppress recomputation of shortest path lengths after deleting an edge . to our experience from numerous tests, there are usually only minor effects on the reconstruction quality when using this simplification. as we deal herein only with large-scale networks, we used path_exact=full_check= <dig> in all calculations.

we illustrate the approach with the example shown in figure
 <dig>  the graph on the left-hand side displays a hypothetical cyclic pg with its edge weights and signs. using the standard confidence factor of α =  <dig> , in principle, three edges could be identified as indirect effects as for each of them a suitable explaining path would exist. this concerns the edge a → c , the edge a → b  and the edge d → b . these three edges form the set r of potentially removable edges. according to the rules, transwesd removes first edge a → c as it has the largest weight . in the second iteration, a → b can be safely removed. now the algorithm has to stop even though the edge d → b is still explainable by the path given above. if we removed this edge, no positive path from a to b and from a to c would remain in the graph, i.e., the originally observed influence of a on b and c would not be captured anymore. this example shows that transwesd may keep an edge in the graph, even if there is an explaining path for it. the resulting graph
gt for this example is shown on the right-hand side of figure
 <dig>   removed in addition to the others whereas path_exact= <dig> had no effect).

step  <dig> 
transwesd ranks the edges according to their weights computed in step  <dig> : edges with highest confidence  are placed first. edges retained in
gt are put first followed by edges that were contained in the pg
gp . the last group comprises all other pairwise interactions; their order is also determined by the conditional correlation coefficient cij.

novel variants
dr-ffl and transwesd were successfully applied and highly ranked in the dream <dig> network reconstruction challenge. however, when we compared and mixed both methods  of transwesd with step  <dig>  of dr-ffl) we realized that even better approaches, in particular for step  <dig>   and step  <dig>  , might exist. in the following we describe several new variants focusing on those which in the benchmarks performed significantly better than the original dr-ffl and transwesd versions .

perturbation graph
the novel pg generation procedure delivers: 

• the signed and directed pg
gp itself.

• a matrix wt containing the weights of the edges in
gp to be used by the transitive reduction algorithm. the element wt contains the weight of the edge i → j in
gp; it is set to ∞ if the edge was not included in the pg.

• a matrix wr containing the confidence weights for all possible interactions  to be used in the edge ranking procedure in step  <dig>  in contrast to wt, this matrix contains a weight for all pairs  , even if i → j is not contained in
gp.

a key difference of the novel pg algorithms compared to the strategies used by dr-ffl and transwesd is that different edge weights are used for tr and for edge sorting. moreover, the selection of candidate edges and the calculation of edge weights are based on  correlation and z-score measures. in detail, the following calculations are performed: 

 <dig>  compute the n × n conditional correlation matrix c from the expression measurements gwt and gko.

 <dig>  use gko to compute the n × n z-score matrix z comprising the z-score values of all  edges.

 <dig>  compute the n × n matrix zc as the z-score calculated on the absolute value of the entries of the conditional correlation matrix c, and add a  offset to obtain positive values: zc >  <dig> 

 <dig>  build the pg by defining the following set of edges: 

•
s <dig> comprises all node pairs  for which |zi,j| > β.

•
s <dig> comprises all node pairs  for which |ci,j| > γ.

•
s <dig> is the set of all node pairs  whose z-score and correlation values have opposite sign: ci,j · zi,j <  <dig> 

•
b=s1∩s2∩s <dig> is the set of node pairs  satisfying the three previous conditions.

•
zp is the set of node pairs  with positive z-score value.

•
zn is the set of node pairs  with negative z-score value.

•
ep=zn∩b is the set of positive edges of the pg.

•
en=zp∩b is the set of negative edges of the pg.

•
gp=ep∪en=b yields the pg.

 <dig>  compute the ranking weight matrix by normalizing wr = |z| + zc between  <dig> and  <dig> 

 <dig>  compute the weight matrix wt to be used for transitive reduction in transwesd as wt = 1 − zc.

using this scheme, the pg is built by selecting all edges where  the z-score exceeds a given threshold β,  the conditional correlation exceeds another threshold γ, and  the signs of z-score and conditional correlation are opposite. the latter condition is justified because a positive z-score for the edge  is computed when the deletion/decrease of i  yields an increase in the activity of j which should corresponds to a negative correlation between i and j. the same correspondence exists between negative z-score and positive correlation. obviously, measurement noise may invalidate the truth of these statements, thus we only keep edges that are consistent with respect to this sign rule. with the rule described above, the positive edges contained in
ep stem from a negative z-score and the negative edges contained in
en from a positive z-score. in the following we denote the pg generated by the above procedure pgnew.

the weights
wi,jr used for edge ranking take equally-weighted into account  the absolute value of the standard z-score ) of the deviations induced by the perturbation in i and  the z-score of the deviations of the conditional correlation between i and j relative to the averaged conditional correlations related to gene j. as far as we know, a z-score of conditional correlations has not yet been used in the context of network inference, however, the ranking weights introduced above proved to be optimal in the benchmarks delivering an edge sorting of high quality. below we show that the new pg generation approach in combination with the proposed ranking scheme may already deliver a valuable approximation of the network itself but can often be further improved by tr techniques.

regarding the weights to be used for tr , benchmark tests showed us that it is beneficial to use only the z-score of the conditional correlation coefficients.

transitive reduction
identifying and pruning edges representing the indirect interactions in
gp finally yielding
gt is the central goal of transitive reduction. we here present some novel and generalized variants of tr inspired from the original versions of dr-ffl and transwesd.

we observed that the tr used by transwesd  of transwesd described above) can be generalized in multiple ways: 

• one may consider unweighted transwesd by setting α = ∞ in the weight rule .

• one may consider unsigned transwesd by setting all edge signs in
gp to “+”. in this case, the algorithm becomes simpler  as the calculation of shortest paths does not need to distinguish between positive and negative paths. it is then, however, still important to keep the weights to avoid non-unique results in cyclic networks.

• when searching for a suitable path pij that can explain a certain edge i → j, one may restrict the search on paths involving not more edges than a predefined number l. in this way one would manifest the expectation that observed indirect effects can be traced back to short paths.

with these generalizations we introduce the notation transwesds,w,l to specify the chosen tr variant: s ∈ {u,s} indicates whether the signed  or unsigned  tr version is used; w ∈ {u,w} specifies either the unweighted  or weighted  version; and l specifies the maximal path length allowed. accordingly, the original transwesd version corresponds to transwesds,w,∞. we also observe that transwesdu,u,∞ mimics tr used by dr-ffl when removal of edges within one and the same component would be blocked.

however, we soon realized that the unweighted variant of transwesd does not perform very well, in particular when combined with the full_check= <dig> option . we therefore do not analyze the unweighted version in detail but keep the notation for consistency with respect to the following variant.

in addition to the modified version of transwesd, we introduce a related but different strategy which we call local transitive reduction . there are two key differences: only paths of length  <dig> are considered as possible explanations for indirect effects and an alternative condition on the edge weight is introduced replacing rule . the ltr algorithm considers an edge i → j potentially removable if three criteria are fulfilled:  existence of a feed-forward loop, i.e.
{i→j,i→k,k→j}∈gp;  sign consistency, i.e. sij = sik · skj; and  the weight condition:

  α·zijc≤zikc·zkjc,. 

recall that we introduced zc as the z-score of the correlation coefficients and that the relation to the edge weight wt which we use for modified transwesd is thus simply zc = 1 − wt. therefore, the smaller
zijc the higher the confidence that the path i → k → j can explain the edge i → j .

analogously as described for transwesd, to deal with non-uniqueness, the potentially removable edges are iteratively deleted according to the edge weights  and for each edge to be removed it is checked, whether all edges originally contained in
gp are still explainable by a 2-path in the remaining graph .

although ltr is also a weighted and signed tr variant, it is considerably simpler than transwesd as it uses a simple triangle rule which is much easier to check than searching for suitable paths. for this reason, in contrast to transwesd, we can easily use the exact variant with path_exact=full_check= <dig> in large-scale networks. as will be shown in the section, despite its simplicity, ltr yielded excellent performance in the benchmarks. for ltr we also tested different variants, including the unweighted  is dropped by setting α = 0), the unsigned and the unsigned/unweighted version . we introduce a similar notation as for transwesd: ltrs,w indicates whether edge signs  and weights  are considered or not; the length parameter l becomes obsolete as it is fixed to  <dig> 

edge sorting
we use a simple edge ranking procedure which is similar to the strategy used by dr-ffl and  transwesd. note that all n potential edges  are included into this list, also those that were not contained in the pg
gp or that were removed during tr. the position of each edge is determined by the ranking weights stored in wr : edges with highest ranking weights are put first. to ensure that edges contained in the final graph
gt are really ranked higher than all other edges, an offset is added to the weight of all edges in
gt.

RESULTS
in the following we present performance results of the new pg generation algorithm in combination with the modified transwesd and the new ltr technique for subsequent transitive reduction. we used two different case studies for benchmarking:  the datasets of the dream <dig> insilico_size <dig> network inference challenge, and  a novel large-scale synthetic compendium consisting of  <dig> 5000-gene networks simulated by sysgensim
 <cit>  with different connectivities and noise levels. the dream <dig> benchmark also enables a comparison of the performances of the new approaches with its inspiring original techniques dr-ffl and  transwesd. generally, in the case of in silico datasets , the goodness of the predictions is evaluated based on the established area under the curve  measures of roc  and pr  curves. the aupr is the most informative  performance measure for the case studies in this paper due to the sparsity of gene networks implying large auroc values differing only insignificantly for the different methods.

in addition to the two in silico studies where the reconstruction results can be evaluated by a perfect gold standard, we used our framework in a realistic application scenario to infer gene interactions in yeast saccharomyces cerevisiae based on a library of gene expression data measured in mutants with single knockouts of transcription factors.

performance on dream <dig> networks
in the dream <dig> insilico_size <dig> network reconstruction challenge
 <cit> , simulated steady-state measurements of the expression of each gene in the wild-type as well as in the single-gene knockout and single-gene knockdown mutant were provided for  <dig> different in silico networks  from which the networks had to be reconstructed. we only make use of wildtype and knockout data as they directly support the generation of the pg . for assessing the quality of reconstructed networks, an evaluation script is available at the dream website
 <cit>  which computes an overall score obtained from the geometric mean of p-values calculated for the aupr and the auroc measures from all  <dig> reconstructed networks.

we considered predictions by several combinations of the original as well as of the new pg generation and tr methods. the methods’ parameters were chosen according to previously used values  or according to preliminary tests. importantly, one and the same parameter set was used for all five networks, i.e., no optimization was conducted for every single network. the dream <dig> evaluation script was used to compute the respective overall scores which are summarized in table
 <dig> 

pg
1
 + transwesd
u,w,∞
pg
1
 + ltr
u,u
pg
2
 + transwesd
s,w,2
pg
2
 + ltr
s,w
pg
new
pg
new
 + transwesd
s,w,2
pg
new
 + ltr
s,w
the table summarizes the performance , false positives  and false negatives ) of the different pg generation and tr algorithms when applied to the dream <dig> networks together with the displayed  parameters. the last column tp <dig> shows the average number of tps within the first  <dig> top-ranked  edges. as a comparison, the scores of the  <dig> best-performing algorithms within the challenge are shown. pg2∗ denotes pg <dig> computed with a minor bug in the original implementation.

we recall that the combined use of the unsigned and z-score-based pg <dig> with dr-ffl
 <cit>  originally obtained the best score  for the dream <dig> challenge, while the coupling of pg <dig> and  transwesd was ranked third with a score of  <dig>  . although we used here only the knockout data  the results presented in table
 <dig> are slightly better  by fixing a small bug in the computation of pg <dig> 

the dream <dig> best overall score of  <dig>  is already exceeded by just applying unsigned transwesdu,w,∞ or unsigned and unweighted ltru,u to the unsigned perturbation graph pg <dig>  this supports the statement in
 <cit>  about the weakness of the original dr-ffl algorithm, where transitive reduction is applied only to edges between but not within strongly connected components of the pg. in fact, transwesdu,w,∞ and especially transwesdu,w, <dig> and ltru,u/w improve the score of pg <dig> significantly up to  <dig> .

regarding the results for pg <dig> originally used by the transwesd method in
 <cit>  we observe that the quality  of the pg is lower than for the simple z-score pg <dig>  although all tested tr techniques  can improve the score, it remains below the performance results obtained for the z-score approach pg <dig> 

next we tested the performance results of the tr techniques in pgnew where we also applied the new edge sorting scheme and sorting weights. as a first observation, a notable quality improvement is obtained by the novel pgnew alone achieving a score of  <dig>  which is markedly higher than the scores obtained by pg <dig> and pg <dig>  even after tr. a somewhat unexpected result was that the γ threshold for the conditional correlation coefficients was virtually not required as its optimal value turned out to be  <dig>  however, in other tests described below, using a non-zero value for this threshold in combination with β  turns out to be beneficial. we also analyzed the robustness of the quality of pgnew and its edge ordering with respect to the chosen threshold parameters β and γ: figure
 <dig> displays the overall score of pgnew when varying the threshold parameters showing that it is  higher than the previous winning score ,  higher than pg <dig>  and  higher than pg <dig> – even for the complete space of meaningful parameter values scanned. hence, a reasonable robustness of the quality of pgnew with respect to the two threshold parameters can be concluded.

we then applied the tr techniques to pgnew which increase the scores up to  <dig> , thus well above the best score recorded at the dream <dig> challenge. regarding the different transwesd variants, we see that the signed version  is only slightly better than the unsigned variant  whereas “local” transwesd, which takes only paths of length  <dig> into account, results in a further significant improvement of the score . in line with these observations, unsigned and signed ltr differ only marginally whereas signed and weighted ltrs,w produces the best overall results, not far from the unweighted variant. recall that transwesds,w, <dig> and ltrs,w differ essentially only by condition  vs. . although the results of both local variants are comparable, it seems that the rule used by ltr can better predict true indirect effects. generally, table
 <dig> shows that all tr techniques work well by strongly decreasing the number of false positive edges  with only a slight decrease in number of true positives . apparently, the best ratio is obtained by local tr variants . we also noticed that the  enrichment of tps under the first  <dig> reconstructed edges in the sorted edge list  is especially large confirming the potential of our methods: it reaches  <dig>  for pgnew,  <dig>  for transwesds,w, <dig> and even  <dig>  for ltrs,w. hence, there is a high probability that top-ranked edges correspond to true interactions – a desirable property when validating the edges experimentally.

figure
 <dig> demonstrates that transwesd  and ltr  are also fairly robust with respect to the confidence factor, as the score of the perturbation graph pgnew is highly improved by both methods for a broad range of meaningful values of α. in this context it is also of interest that unweighted ltr yielded very good predictions even without the need to specify any further parameter .

we summarize that the best-ranked algorithms of the dream <dig> competition are significantly outperformed by our new methods for pg generation, tr, and edge sorting. we noticed that also other recently published network inference techniques applied to the dream <dig> networks
 <cit>  reported lower predictions. for example, the highest overall score in
 <cit>  is  <dig>  obtained by using both knockout and knockdown datasets whereas a score of  <dig>  was achieved in
 <cit>  by cutter-w, an approach similar to unsigned  transwesd. moreover, if we also include knockdown data in our analysis , the scores in table
 <dig> grow up by approximately 3– <dig> points each, reaching a top of  <dig>  with pgnew + ltrs,w. as expected, this confirms that an increase of the number of measurements corresponds to an improvement of the prediction. however, most of the information is already provided by the knockout experiments.

performance on sysgensim datasets
in order to provide an even more exhausting and more realistic test scenario for the developed inference algorithms, the software sysgensim
 <cit>  was used to create a new collection of synthetic gene networks and to simulate knockout experiments under different connectivities and noise conditions. sysgensim is able to generate large networks with a topology similar to those observed in real organisms, i.e., with a modular structure featuring exponential and power-law behavior for the in- and out-degree distributions of nodes
 <cit> . the generated  <dig> in silico networks have a considerable  size of  <dig> nodes each. one third of them has a low average degree ,  <dig> networks have an intermediate average degree , while the last third of the networks exhibits the largest average degree . finally, using equations of biochemical kinetics where the degradation rate of gene expression is represented by a first-order process and where the transcription rate exhibits essential features of cooperativity and saturation
 <cit> , single knockout experiments have been simulated for all the genes of each network with sysgensim’s default kinetic parameters under  <dig> different combinations of noise conditions . in fact, sysgensim allows for the selection of the standard deviation σθ of the gaussian distribution from which the biological synthesis and degradation variances are sampled  in
 <cit> ) as well as the standard deviation σν of the gaussian distribution from which the experimental noise ν is sampled. as possible values for both standard deviations we considered { <dig> , <dig> , <dig> }, yielding a total of  <dig> combinations summarized in table
 <dig>  therefore a grand total of  <dig> different networks  with simulations of single-knockout experiments have been produced, the goal being the testing of the inference methodologies under different conditions of edge density, biological variance, and multiplicative measurement noise.

σ


θ

σ


ν

columns σθ and σν show the values of the standard deviations of the gaussian distributions with μ =  <dig> from which the biological variances θsyn and θdeg and the measurement error ν were sampled in sysgensim. each configuration is also represented by a 2-character string, indicating the intensity levels , medium , high ) of the biological variance  and of the measurement error , respectively.

due to the superior performance of pgnew we present results only for this pg. figure
 <dig> displays the performance of pgnew for the  <dig> different noise configurations of network  <dig>  in dependency of a wide range of  parameters . the novel pg generation algorithm exhibits reasonable robustness with respect to both noise and threshold parameters. in fact it works decently with the same β and γ as used for the dream <dig> networks , while the procedures for pg <dig> and pg <dig> would need a more extensive re-tuning of the parameters to obtain reasonable results .

the effect of the tr algorithms applied to pgnew  becomes more heterogeneous and differentiated compared to the dream <dig> networks. first of all, we observe that the unweighted versions of ltr decrease in all cases the quality of the perturbation graph pgnew whereas weighted ltr and  transwesd improve it – partially significantly – in all scenarios . this demonstrates that weighted tr can be highly beneficial. however, local transwesds,w, <dig>  which was comparable with ltr in the dream <dig> networks, achieves similar unfavorable results for these large and noisy networks as unweighted ltr. this confirms again that rule  seems to be better suited for local tr than rule . furthermore, the quality of the pg as well as the relative improvement by the  tr techniques depends substantially on the magnitude of the noise level both with respect to aupr and in the number of tps and fps. an interesting observation can be made regarding the effect of biological variance on the reconstruction quality: it appears that moderately increased  biological noise is advantageous in case of high measurement noise for all k’s . thus, higher biological noise may help to uncover true perturbation effects under high uncertainty of measurements.

each score is the mean of the aupr computed for the  <dig> networks with k ≃  <dig>  simulated according to the same noise configuration. thresholds used by the inference algorithms are β =  <dig>  and γ =  <dig>  for generating pgnew, α =  <dig>  for transwesd·,w,∞, α =  <dig>  for transwesd·,w, <dig> and α =  <dig>  for ltr·,w. analogous performances for k ≃  <dig> and k ≃  <dig>  are shown in tables t <dig> and t <dig> in additional file
 <dig> 

the number of edges in the perturbation graph and the number of fps and tps are shown in the table. the relative reduction of these measures  in the graphs obtained after applying the different tr techniques compared to the pg is also displayed. these averaged statistics are computed from the analysis of the graphs obtained after inferring the  <dig> sysgensim networks simulated according to noise configuration  <dig> . thresholds used are β =  <dig>  and γ =  <dig>  for generating pgnew, α =  <dig>  for transwesd·,w,∞, α =  <dig>  for transwesd·,w, <dig> and α =  <dig>  for ltr·,w. analogous tables for the other  <dig> noise configurations  are shown in tables t3–t <dig> in additional file
 <dig> 

it can also be noticed that, in general, transwesds,w, ∞ and ltrs,w achieve similar superior aupr performance, but by different means as manifested in table
4: the ltr technique prunes the edges of the pg more generously than transwesds,w,∞, resulting in a better reduction of false positive edges, but at the same time in an undesired higher decrease of true positives. we can also confirm a result from the dream <dig> benchmark: signed  ltr and transwesd achieved always better aupr scores than their unsigned versions , but only to a very small extent. this important observation is discussed in more detail in the conclusion section.

finally, figure f <dig> in additional file
 <dig> shows how the precision of pgnew and the effectiveness of tr decrease when the network connectivity  increases. moreover, the superiority of weighted vs. unweighted tr can again clearly be seen.

application to a realistic yeast knockout dataset
the ultimate test for our reverse-engineering algorithm would be the application to a genome-scale real-world dataset of single-gene perturbation experiments . only few such datasets are available. the most suitable for our purpose is the s. cerevisiae transcription factor knockout expression compendium of hu et al.
 <cit>  where the expression of n =  <dig> genes was measured after single knockouts  of m =  <dig> transcription factors  being the most important regulators in yeast. herein we refer to the revised dataset provided by reimand et al.
 <cit>  where the original raw data of hu et al. were reanalyzed with more sophisticated statistical techniques of the bioconductor package
 <cit>  leading to an increased informative content of the microarray measurements.

the processed data of reimand et al.  consists of three matrices of size m × n: 

• l contains the log-fold change values for all genes across all knockout experiments.

• p includes the p-values for differential expression.

• a is the signed adjacency matrix of the graph reconstructed by reimand et al. the entries a correspond to  edges with a p-value of p <  <dig> .

our goal was to re-process the log-fold change values in order to apply our network inference algorithm and to produce a ranked list of edges. for comparing our reconstructed network with the predicted network of reimand et al. we need a gold standard. however, as a reliable gold standard for gene regulation in s. cerevisiae is still not available , we made use of four published “silver standard” networks containing experimentally validated interactions : 

 <dig>  ss1: is a collection of found chip-chip results and motifs from  <dig> tfs
 <cit>  .

 <dig>  ss2: is a subset of the binding sites from ss <dig> which are also in nucleosome-depleted regions
 <cit>  .

 <dig>  ss3: this silver standard network contains known regulatory interactions between  <dig> tfs and  <dig> targets compiled from the results of genetic, biochemical and chip -chip experiments
 <cit>  .

 <dig>  ss4: contains interactions between  <dig> tfs and  <dig> targets. this network was used as a reference network for a sub-challenge of the dream <dig> competition
 <cit>  .

in order to obtain a gene expression matrix g exploitable by our inference algorithm, we “inverted” the log-fold change values to obtain g = 2l for all the possible edges. in this way, expression values larger than  <dig> represent an increase of the gene expression of j after the knockout of i , and vice versa a positive regulation for values smaller than  <dig> 

as for the synthetic datasets, the gene expression matrix g served then as input to produce the perturbation graph pgnew and the weight matrices wr and wt. the transitive reduction techniques transwesd and ltr were then applied to pgnew and the resulting edges for each method were sorted according to our ranking scheme. this sorted edge list was delivered as output  of our procedure. we performed the whole inference process by employing the same parameters used for the simulated networks, i.e. β =  <dig> , γ =  <dig> , α =  <dig>  for transwesd, α =  <dig>  for local transwesd, and α =  <dig>  for ltr. note that m =  <dig> tfs were perturbed, hence, we can only infer edges that will start in a tf node and point to tf or non-tf genes.

a  confidence-sorted edge list was also obtained for the original dataset of reimand et al. by re-sorting the absolute values of the log-fold changes in l according to the adjacency matrix a, which is then used as a reference to assess the performance of reimand’s reconstructed network.

afterwards we evaluated all predictions against the  <dig> silver standards. to allow for a fair scoring, only common nodes from silver standard networks and prediction lists were taken into consideration, i.e. if edge  is in the prediction list but node i or j is not contained in the silver standard, then the edge is not scored. on the other hand, if node k belongs to the silver standard but was not included in the microarray dataset, then all ingoing and outgoing edges of k were removed from the silver standard. accordingly, the size of the silver standard ss <dig> reduced from 142 ×  <dig> to 122 ×  <dig> and of ss <dig> from 114 ×  <dig> to 108 ×  <dig> 

for each of the four silver standards, figure
 <dig> shows the aupr and the number of true positive edges  computed for an increasing number of edges selected from top of the ordered edge lists as given by  reimand’s predictions,  the perturbation graph pgnew,  transwesds,w,∞,  ltru,u, and  ltrs,w. generally, the results of our methods - with respect to the four different silver standard networks appear to be satisfactory, though with different measure for the four silver standard networks. it is apparent that our methods work especially well within the 100 –  <dig> top-ranked edges where all of the inferred networks - show better agreement with the silver standards than the interactions found by reimand. the pg itself performs again reasonably well and better than reimand’s network in this region. all variants of tr show positive effects but not among the top-ranked edges because these are immune against pruning . we observe that unweighted and unsigned ltru,u performed best for this dataset. however, one should keep in mind that no tuning or adaptation of the parameters has been performed which could have prevented a better result for the weighted versions.

when increasing the number of considered edges to  <dig>  it appears that reimand’s network becomes better and better eventually, in some cases, getting higher overall agreement with the silver standards than our methods. however, we argue that for practical applications  the first ≈  <dig> edges are the most important ones. in this region, given the silver standards, our approach seems to work most efficient yielding high statistical significance: for the four silver standard networks we obtained  <cit>  tps in the network reconstructed with ltru,u yielding corresponding p-values of , based on the hypergeometric distribution. these values are very similar for the other four pg/tr-based methods. it is most likely that the number of tps is even larger given the high probability that not all interactions might be contained in the silver standards. our prediction list might thus provide useful targets for validations. a sorted list of the  <dig>  edges with highest confidence and a comparison with the four silver standards can be found in table t <dig> in the additional file
 <dig> 

CONCLUSIONS
we presented novel algorithms for the inference of gene regulatory networks from systematic perturbation experiments. these algorithms support the reconstruction of regulatory networks via three steps:  pg generation,  tr to remove edges representing indirect effects in the pg, and  sorting of edge candidates. we presented new variants for all of these three steps whose combined use yielded superior results over previous methods when tested with standardized benchmark scenarios.

regarding the pg, it proved advantageous to identify, weight and sort candidate edges by a mixture of two measures, one being the standard z-score of deviations, the other one the z-score of conditional correlation coefficients. in particular, the latter was highly informative for edge pruning by tr whereas a combined weight of both z-scores proved beneficial for edge sorting. with the new candidate edge selection and edge sorting schemes, we observed that the pg alone  achieved a reconstruction quality that is far above the results of previous methods after tr. importantly, the quality of the pg appeared to be robust against larger variations in the two required threshold parameters. in this regard, one aspect for future work is to develop algorithms for automatic thresholding, that is to estimate the threshold parameters from the data.

we proposed new variants of tr and, based on unbiased in silico benchmarks, compared them with the original versions of the algorithms. several key observations could be made: 

 <dig>  the dr-ffl method
 <cit>  was inferior to all other tr methods tested which led us to the conclusion that tr should be employed not only between but also within cyclic structures. the winning performance of the original dr-ffl in the dream challenge can mainly be attributed to its pg which is in parts similar to the one used by pgnew.

 <dig>  we found that explicitly accounting for edge signs almost always improves the results in terms of aupr but only to a very minor extent. while this is in agreement with the observations made in
 <cit> , we give here an extended explanation for this unexpected result. generally, neglecting the edge sign can only be “harmful” during tr, if the true network contains a negative feed-forward loop . as an example, figure
 <dig>  shows a hypothetical interaction graph containing one such negative ffl between node a and e . if we now assume that all nodes are perturbed in single perturbation experiments we would get, in the ideal case, a pg as shown in figure
 <dig> . this pg corresponds to the transitive closure of the original graph, in which each node i induces a significant effect on another node j if there is an edge or path from i to j in the true graph. what we can now see is that each edge contained in the pg but not in the true graph  is part of a positive ffl consisting of this edge and a path of the same sign. this happens because all these edges will have the same sign as the path they were induced from. hence, if we compute the tr within the unsigned version of this pg  all edges that stem from indirect effects and span one branch of the induced ffls would still correctly be removed.

regarding the original negative ffl included in the true graph , we cannot be sure which sign it will get in the pg as there is a positive path as well as a negative edge from a to e and, hence, the direction of change in e when perturbing a cannot be predicted uniquely. only if the overall effect of a on e measured during perturbation of a is negative , it may happen that it will be falsely removed during tr if edge signs are neglected. however, when using edge weights for  tr, it is rather unlikely that the path from a to e fulfills the rule  or, for a 2-path used by ltr, rule  since the measured overall effect from a to e turned out to be negative, hence, the path seems to have a low potential to transduce an effect from a to e. thus, it is unlikely that the true edge a ⊣ e would be falsely removed.

to summarize this aspect, there is a low probability that  tr removes a true edge within a negative feed-forward loop and neglecting edge signs in tr will therefore have only minor impact on the reconstruction quality. this has important consequences since then the computationally expensive search for the shortest sign-consistent paths  can be safely turned into a simple search for a shortest  path connecting a given pair of nodes . thus, when applying transwesd to the 5000-nodes networks, we may then use an exact  instead of an approximate  sub-algorithm for computing shortest signed path. in contrast, full_check= <dig> is still required for transwesd in large networks.

 <dig>  with ltr and transwesds,w, <dig> we considered local variants of tr removing an edge only if there is an explaining path of length  <dig>  whereas transwesds,w, <dig> performed well for the dream challenge but unfavorable for the sysgensim data, weighted ltr yielded superior performance in almost all benchmark tests and only  transwesd applied to all paths could deliver comparable results. we can thus first conclude that using the multiplicative rule  is better suited than the max rule  when focusing on short paths. however, it remains still paradoxical why tr restricted to paths of length  <dig> should be sufficient. this can once more be illustrated by figure
 <dig>  if we again assume that the true graph induces a complete pg  then we can indeed recognize that there is always a 2-path that can, in principle, explain an edge from an indirect effect . hence, in principle, all false positive edges could be identified and removed explaining why ltr exhibits good behavior. however, one has to keep in mind that 2-paths may contain edges that are themselves indirect effects , hence, the order of edge removal might then become crucial. here, the strategy to cut lowest-confidence-edges first worked apparently well in the benchmarks.

again, showing that local tr based on 2-paths does not lead to lower performance has important consequences, as we can then restrict the search on simple triangles whose detection is computationally easier than detecting paths of arbitrary length. in fact, unsigned  ltr required in the average only  <dig>  seconds in networks with  <dig> nodes whereas transwesd  needed  <dig>  seconds.

 <dig>  the sysgensim benchmark showed that edge weights really matter to obtain good results with ltr. since  local ltr and unsigned transwesd are computationally feasible in 5000-nodes networks and as they achieved superior results in all benchmarks  these techniques appear to be well-suited for the reconstruction of large-scale regulatory networks based on systematic perturbation experiments.

 <dig>  applied to a realistic application scenario with gene expression data from yeast mutants with single knockouts of transcription factors we could demonstrate that our approach delivers a high enrichment of known interactions especially within the top-ranked edge candidates. with this property, our method holds great potential to identify true unknown gene interactions that can subsequently be validated in experiments.

a potential weakness of our pg- and tr-based methods is the requirement to perturb each node in the network at least once. at a genome-scale level, such datasets are currently only available for a small number of organisms. on the other hand, one might focus on smaller sub-networks where all nodes can be perturbed. furthermore, if m nodes out of n nodes can be perturbed in a network, we can use the information of the corresponding m perturbation experiments to  infer the complete sub-network containing only the m perturbed nodes and  to infer edges leading from the m perturbed nodes to the n − m unperturbed nodes. in the second of these sub-networks, tr cannot work effectively  meaning that some of the  edges in the pg reflecting indirect edges cannot be identified as such. however, the provided output might still have its own value and indicate direct or indirect functional relationships. in fact, we employed this approach for the yeast knockout dataset where “only” the tfs were knocked-out.

we also emphasize that perturbation graphs  could also be constructed by other approaches than systematic knockouts of all genes. one example are genetical genomics data containing gene expressions measurements from naturally occurring multifactorial perturbations . as an example for using pg- and tr-based methods based on genetical genomics data see
 <cit> .

we noticed that ltr shares some similarities with aracne presented in
 <cit> . aracne also eliminates an edge in a feed-forward loop consisting of three edges  if a certain weight condition is fulfilled. however, there are several key differences since aracne only operates on undirected and unsigned graphs and uses different weights based on mutual information.

as an important additional results of our study, we have generated new and unprecedented large-scale benchmark datasets that, in contrast to comparable simulations, account for different noise levels. we think that these datasets, which can be downloaded from
http://sysgensim.sourceforge.net/datasets.html, are generally useful for unbiased testing of network inference methodologies complementing other available in silico benchmarks.

availability of supporting data
the presented inference algorithms and the 5000-gene benchmark  can be downloaded from
http://sysgensim.sourceforge.net/datasets.html.

abbreviations
pg: perturbation graph; tr: transitive reduction; ltr: local transitive reduction; dr-ffl: down-ranking of feed-forward loop; ffl: feed-forward loop; transwesd: transitive reduction in weighted signed digraphs; tp: true positive; fp: false positive; fn: false negative.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
sk and alf designed the study. ap generated the new datasets. ap and sk implemented the new algorithms. ap, rjf, sh and sk analyzed the data. all authors were involved in the analysis of the benchmark results and in drafting and proofreading the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
supplementary tables and figures. a collection of additional tables and figures is available in additional_file_ <dig> pdf.

click here for file

 additional file 2
list of the  <dig> most confident edges in the reconstructed yeast transcription factor network. the list of the  <dig> most confident edges identified with ltru,u from the yeast knockout dataset is available in additional_file_ <dig> pdf.

click here for file

 acknowledgements
sk and sh acknowledge funding by the german federal ministry of education and research  and by the ministry of education and research of saxony-anhalt . ap and alf have been partially supported by the sardinian regional authority .
