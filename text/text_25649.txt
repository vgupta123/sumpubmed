BACKGROUND
in this section, we relate the content of the paper to the state-of-the-art. both passage retrieval and automatic text categorization are introduced, however as the rest of the paper, which reflects the second biocreative task, the presentation focuses on the categorization task.

passage retrieval
passage retrieval is an important step in question-answering . it bridges the gap between document retrieval and very short textual answers needed for qa. however, the purpose of the passage retrieval task proposed in biocreative is to find a short fragments which would appropriately support 1) the already known go annotation in task  <dig> , and 2) the automatic go term assignement in task  <dig> . in both cases the targeted text is already known. thus, the task is similar to the known-item search task  <cit> . in trec, this task aimed at retrieving s single know document in corrupted collections. corruptions were caused by misspellings  <cit>  or by running optical character recognition  <cit> ) tools.

text categorization
text categorization  aims at attributing a set of concepts to an input text. typical applications use a set of keywords to be selected into a glossary. tc is performed daily by professional indexers working in digital or classical libraries. however, keyword assignment is only a particular instance of text categorization. tc can also be seen as an information extraction task, when conducted for named-entity  recognition purposes as investigated in task 1b. computer-based concept mapping technologies include:

• retrieval based on string matching, which attributes concepts to texts based on shared features ;

• empirical learning of text-concept associations from a training set of texts and their associated concepts.

in the former approach, the targeted concepts are indexed. each indexing unit is attributed with a specific weight. while in the latter, a more complex model of the data is built in order to provide text-concept associations beyond strict features sharing. retrieval based on string-matching is often presented as the weaker method  <cit>  of the two, but in many real situations, like those defined in the biocreative challenge, learning approaches cannot be applied. for instance, empirical learning methods require large training sets of data that are usually not available and whose development costs would exceed the budget of most research groups. additionally, the size of category sets can be some orders of magnitude above the capacities of current learning algorithms running on a standard computing framework. designing tc as a retrieval task means indexing of a collection of terms, in our case terms from the go, as if they were documents, and then processing each document as if it was a query. then, the retrieval tool uses the score attributed to each term to rank them. because the document collection is made of entities  that are clearly shorter than usual documents. our study aims at exploring the behavior of classical statistical models. for tc, the use of a vector space engine, using both stems and linguistically-motivated indexing features, and its combination with a search tool based on pattern matching constitutes the main modules of our system. we also investigated some refinements of this core combination.

scalability issues
automatic text categorization has been extensively studied and has led to an impressive number of papers. a partial list  of machines learning approaches applied to text categorization includes naive bayes  <cit> , support vector machines  <cit> , boosting  <cit> , and rule-learning algorithms  <cit> . however, most of these studies apply text classification to a small set of classe, usually a few hundreds, as in the reuters' collection  <cit> . in comparison, our retrieval methods are designed to handle large class sets since they relies on an inverted file to allow fast categorization. the inverted file relates each indexing unit  to the terms where it occurs in the go. the size of the inverted file, which additionally stores the weight of each word , is an important parameter but 105– <dig> is still a modest range so that even large controlled vocabularies can be indexed.

in text categorization based on learning methods, the scalability issue is twofold. it concerns both the ability of these data-driven systems to work with large concept sets and their ability to learn and generalize regularities for rare events. theoretically, if large multi class problems can be recast as binary classifiers in order to be solved by learning approaches, in practice it is often difficult. larkey and croft  <cit>  show how the frequency of concepts in the collection is a major parameter. our approach is data-poor because it only demands a small collection of annotated texts for fine tuning as opposed to data-intensive machine learning approaches, which require large annotated sets.

to our knowledge the largest set of categories ever used by text classification systems is above  <dig>  these systems were applied to the domain of life sciences. yang and chute  <cit>  worked with the international classification of diseases . similarly, the ohsumed collection contains  <dig> medical subject headings . in contrast, our system is tailored to be applied to much larger class sets. the unified medical language system  contains  <dig>  different concepts and  <dig>  million terms , while trembl contains about  <dig>  protein names, often including synonyms. for the biocreative competition, the categorization space of our system was restricted to the go partition of the unified medical language system .

indexing units
in addition, to usual word-based features more elaborated indexing units have been proposed in information retrieval . the general idea in indexing entities, which are different than words , is to handle information as conveyed in word collocations. thus, expressions such as cystic fibrosis can be seen as one semantic entry in an inverted file. various phrase indexing methods have been proposed in the past and generally, retrieval or categorization performance conclusions on the use of phrases as indexing units were inconsistent  <cit> . for ir, hull et al.  <cit>  and strzalkowski et al.  <cit>  used phrases and were able to report some improvement. for text categorization, tan et al.  <cit>  and mongovi et al.  <cit>  have reported that statistical bigrams increased performance, while toole and chen  <cit>  relied on linguistically-motivated phrases. mitra et al.  <cit>  re-examined the use of statistical and syntactic phrases for retrieval and came to the conclusion that "once a good basic ranking scheme is used, the use of phrases do not have a major effect on precision at high ranks". for linguistically-motivated phrases, arampatzis et al.  <cit>  question the use of syntactic structures as substitute for semantic content. as for our present concerns, statistical phrase indexing is problematic. usually inspired by mutual information measures  <cit> , it requires important volumes of training data, while we aim at designing a data independent system. therefore, in our systems phrases are based on syntactic parsing  <cit>  rather than statistical analysis. however, let us remark thaz data needed to identify statistical phrases are not of the same kind as those needed for training a classifier: the former approach requires only large corpora, while the latter needs supervision, i.e. annotated data, so both tasks are data-intensive but discovering statistical phrase extraction is much cheaper than text categorization.

methods
most data sets and metrics are common to each of the subtasks, therefore we introduce these aspects first, then the methods used for conducting each task are reported.

resources
the data resources used in the experiments can be separated into three subsets, the document collection, the swiss-prot  <cit>  records and the go terms  <cit> . the gene ontology merges three structured vocabularies, organized as ontologies, that describe gene products in terms of their associated biological process, cellular component  and molecular function in a species-independent manner. the molecular function terms describe activities at the molecular level. a biological process is accomplished by one or more ordered assemblies of molecular functions. the cellular component is a component of the cell, which is part of some larger object. for example either an anatomical structure or a gene product group.

collections and metrics
an initial set of  <dig> articles  from the journal of biological chemistry, was provided by the organizers,  <dig> were used for tuning our tools  and the other half was used for non-official evaluations . the data set used for the official evaluation of task  <dig>  comprised  <dig> proteins-gene ontology category relations . the number of relations depends on each participants, because some participants decided not to submit results for every relations. for  <dig> ,  <dig> proteins-gene ontology category relations were evaluated. however, for tuning our system prior to submitting our official run, as well as for conducting post results investigations, we used retrieval-inspired metrics. retrieval techniques yield a ranked list of terms for each document, therefore the main evaluation measure is usually based on the mean average precision . in addition, for go annotation, the number of token assigned per protein ranges from  <dig> to  <dig> , but  <dig> % of proteins in the dsi sample of swiss-prot have less than  <dig> go terms, so that precision for top ranks , is probably more important; therefore, this metric is mostly used in our non-official evaluations. when map is used, the top  <dig> terms returned by the system are used.

for task  <dig>  the expert has to decide whether the evidence text corresponds to the given go concept and protein, or if it is not appropriate. additionally, in task  <dig> , the judge assesses whether the go concept has been correctly predicted for each text. there are three different marks  to evaluate the quality of the results. these marks evaluate go concept and protein separately. for task  <dig> , high, generally and low evaluate the relevance of the sentence, which supports the annotation of the protein with go concepts. for the task  <dig> , high means that the protein or the go concept has been correctly predicted. generally, as an evaluation for the go term, means that it is not totally wrong but too general to be useful for annotation. generally, as an evaluation for the protein means that the specific protein has not been found but instead a homologue from another organism or a reference to the protein family. low means that the answer was wrong.

passage retrieval
the purpose of the passage retrieval task is to facilitate and improve annotation by offering a short segment of text that can indicate the correct go term. our approach is based on the idea that the relevant passage and the go terms share some kind of lexical, and hopefully semantic, similarity. therefore, the basic method consists of searching for the concept directly in the text. for the passage retrieval task, only the go term is used to rank passages from the input text. although, using the protein name and synonyms of the go term could have been useful to expand the matching power of our approach, we decided to focus on an high precision matching rather than relying on additionnal materials. a possible improvement would be to boost go concepts, which occur more than once in the candidate list. identifying parts of go terms in text is an simple strategy, which does not require any training data set and which can be manually tuned. the main difficulty encountered with this approach is defining a distance that measures the similarity between a go concept and a given sentence. different types of distances were tested, but the basic idea is to rank the candidate sentences and to select a single top-ranked passage. two independendt modules were developped: a sentence splitter, which defines the basic retrieval units, and the sentence ranker. although specialization of the parameters used for each of the three go axis could have been beneficial, we used the same settings for each of the three go axis.

sentence splitting
as preliminary observations we noted that applying our tools on full text articles rather than on abstracts did require improving our pre-processing tools, especially to detect sentence boundaries, therefore the official competition experiments were done using abstracts. for experiments conducted afterwards, the impact of using full-text articles was investigated.

for passage retrieval, the length of the appropriate segment to be considered was crucial. following what was learned from the information extraction task of the trec genomic track, we assumed that sentences were likely to be relevant segments  <cit> . the trec task aimed at returning a gene reference into function , i.e. a short passage, which provides information on the function of a protein in the locuslink repository.

lacking clean training data, we decided not to investigate the use of machine learning approaches to solve the sentence pre-processing problem , and instead we decided to use simple manually crafted regular expressions. the tool relies on a set of finite-state automata, which are applied sequentially. although the system is simple, it offers a certain level of maintainability and a good accuracy , which is similar to more advanced sentence boundary detection methods.

sentence weighting
two different similarity measures have been used to compute a score between sentences and go terms. the two similarity measures are: 1) a high precision but low discriminative power exact match method and 2) a low precision but good recall fuzzy string-edit distance. these two measures are then linearly combined to obtain a unique score for each sentence in the input document as in the following equation:



with the following parameters and parameter values:

• s0: perfect score;

• s1: fuzzy score;

• w0: weight of s0;

• w1: weight of s <dig> 

the direct match method computes a dice-like distance as in the following equation:



each time a word of the go concept is found in the candidate passage the go term and passage intersection set is increased by one. this score is divided by the total number of words, which composes the concept. the normalization factor is important to smooth length variations in the go controlled vocabulary. it is also interesting to notice that full and exact match is unusual, but when it occurs  then very high precision is achieved, thus precision becomes a trivial issue. in a quite unusual manner for categorization and information retrieval purposes, recall is more difficult to achieve. indeed, unlike in large text collections , where the natural redundancy of information help to find a relevant document whatever words are used to query the system, searching for a relevant passage in an abstract is more challenging regarding recall.

the string edit distance module computes a distance between two strings. the score counts the minimal number of modifications  needed to transform the first string into the second one . string-edit distances operations are very sensitive to small cost variations making this step very time-consuming.

as shown in table  <dig>  different distances were tested. the levenstein distance is the basic edit distance. all basic operations, i.e. insertion, deletion and substitution, cost  <dig>  the levenstein distance computes the score between two strings by selecting at each stage the cheapest operation to transform one string into another. the final score expresses the distance between the two strings. in the smith-waterman, a particular cost is associated to each operation. in our experiments, costs were chosen by manual tuning. the jaro metric measures distances between tokens. it is well adapted to assess distances between two terms, which may share similar tokens in a different order. in the resulting combined distance, transposition between two words are under-weighted as compared to operations made on single characters. the jaccard distance computes the distance between two sets by the ratio of the size of their intersection to the size of their union.

the choice of the best distances was made empirically. some characters, such as "-" or digits, have a very low replacement costs. as exemplified in table  <dig> given the three following sentences and the term "protein serine/threonine kinase activity", the smith-waterman distance performed generally well:

s <dig>  cdc42-induced activation of the mixed-lineage kinase sprk in vivo.

s <dig>  src homology  <dig> domain -containing proline-rich protein kinase /mixed-lineage kinase - <dig> is a serine/threonine kinase that upon overexpression in mammalian cells activates the c-jun nh-terminal kinase pathway.

s <dig>  this is, to the best of our knowledge, the first demonstrated example of a cdc42-mediated change in the in vivo phosphorylation of a protein kinase.

in this example, we assume that s <dig> is the best candidate sentence. two direct matches are observed in s <dig> and s <dig>  and so these two segments are better candidates than s <dig>  but to rank segments s <dig> and s <dig>  we relied on the string-edit distance module. in table  <dig>  we see that both smith-waterman and jaccard measures are discriminant, while neither jaro, nor levenshtein are effective. the final score is a linear combination which favors smith-waterman and jaccard over jaro and levenshtein distances. this score will be used in our evaluations to estimate the reliability of the passage assignement.

go categorization
in this section, we present the architecture of the go categorization tool. the weighting schema of the tool will be the same for each of the three classifiers we have developed. each classifier corresponds to the mutually exclusive axes of the go: cellular components, molecular functions and biological processes. two main modules constitute the skeleton of our system: the regular expression  component, and the vector space  component. the former component uses both tokens as indexing units, while the latter uses both stems  and noun phrases. each of these basic classifiers uses known approaches to document retrieval. the first tool is based on a regular expression pattern matcher. it is expected to perform well when applied on very short documents such as keywords. as shown in table  <dig>  90% of go terms do not contains more than  <dig> tokens. the second type of classifier is based on a vector space engine. this second tool is expected to provide high recall in contrast with the regular expression-based tool which should privilege precision. to draw a parallel between the categorization and the passage retrieval task, the pattern-matcher and the exact match measure plays the same role, while the vector-space behaves like a fuzzy and long-distance similarity measure.

regular expressions
our system does not use any specific string normalization module. the system extracts every contiguous sequence of  <dig> tokens by moving a window through the abstract. these pentagrams are then matched against the collection of go terms. basically, the manually crafted finite-state automata allow two insertions or one deletion within a go term. ranking of the proposed candidate terms is based on these two basic edit operations: insertion costs  <dig>  while deletion costs  <dig>  the resulting pattern matcher acts as a term proximity scoring system  <cit> , but with a  <dig> token matching window. krallinger and padron  <cit>  use a similar strategy but they generalize the idea and vary the window size too.

vector space classifier
the vector space module is based on a general ir engine with tf.idf  weighting. we used the smart  <cit>  representation for expressing statistical weighting factors. given a collection profile , it is possible to calculate an optimal weighting scheme by varying a set of parameters. the main parameters are provided in table  <dig>  a retrieval experiment can be characterized by a pair of triples -ddd.qqq- where the first triple corresponds to term weighting used for the document collection , and the second triple corresponds to the query term weight . each triple refers to a term frequency, an inverse document frequency and a normalization function as provided in table  <dig>  more elaborated weighting, such as the deviation from randomness  <cit>  and the pivoted normalization  <cit>  were tested but did not result in any improvement as compared to the cosine normalization given in table  <dig> 

the engine uses stems  as indexing units and a stop word list . we observed that cosine normalization was especially effective for our task. this is not surprising, considering the fact that cosine normalization performs well when all documents have the same length  <cit> .

go thesaurus
an updated version of the go was released some days before the competition, but all experiments were done with a slightly older version than the one used for establishing the benchmark. it contained  <dig> synonyms:  <dig> for components,  <dig> for processes, and  <dig> for the function axis. together with the  <dig> terms, chosen as best representative of go concepts, the index contains  <dig> entries. although working with an updated version could have brought some improvement, it is important to notice that the proposed learning-free approach allows to be largely independent on concept drifting issues  <cit> , which necessary occur when controlled vocabularies evolve to reflect changes in the field. an example of synonyms for each axis is provided in table  <dig>  when the thesaurus is used, terms variants are indexed like other terms , but for each set of synonyms, only the best ranked term is kept in the candidate list to avoid duplicating go concepts.

phrase indexing
go terms contain between  <dig> and  <dig> words and almost verb-free noun phrases  if we omit some rare participle forms such as in "cell-cell signaling involved in cell fate commitment", which occur in less than  <dig> % of go terms. noun phrase indexing was expected to be beneficial because of the profile of these terms. in our approach, only the content of go terms is stored in the indexes, and phrase recognition is only applied on the input document in order to identify possible go terms. formally, this manipulation of the abstract can be viewed as a reformulation process. the abstract is translated into a set of noun phrases before to be matched to the list of go terms. our working hypothesis is a weak variant of the phrase retrieval hypothesis  <cit> . we assumed that np recognition can help reducing noisy mapping for subterms.

our shallow parser uses both statistical and manually written patterns, applied at the syntactic level  of each sentence  <cit> , to identify noun phrase boundaries. the parser concentrates on adjective  and noun  sequences, such as:  , i.e. n, an, nn, ann, nnn, aann, annn, nnnn, aannn, nnnnn... adjectives as well as prepositions such as of, with are optional. unlike in other technical glossaries  <cit> , we observed that templates with conjunctions are rare in go terms. we counted  <dig> occurences of conjunction tokens the go terminology terminology , therefore we decided to ignore it.

we call noisy subterm mapping an erroneous behavior of the mapping process, when it selects some erroneous go terms that are part of a relevant term. thus, considering an input text dealing with the term cystic fibrosis, both cystic and fibrosis are irrelevant subterms likely to be proposed as indexing units, so being able to recognize that cystic fibrosis constitutes a noun phrases will help discard these two noisy candidates. however, discarding all subterms from the candidate list may result in negative effects, so that subterm removal must be based on contextual evidences. if a subterm occur in the input text as an autonomous noun phrase, then it is kept in the candidate list. therefore two different indexes  are constructed. the merger of this index with the index of stems is described in the next paragraph.

fusion of classifiers
the hybrid system combines the regular expression classifier with the vector-space classifier. unlike larkey and croft  <cit>  we do not merge our classifiers by linear combination because the regex module does not return a scoring consistent with the vector space system. the combination of classifiers uses the list returned by the vector space module as a reference list  and the list returned by the regular expression module is used as boosting list . this method serves to improve the ranking of terms listed in rl. a third factor takes into account the length of terms. both the number of characters  and the number of tokens  are computed, so that long and compound terms, which appear in both lists, are favored over single single and short terms. we assume that the reference list has good recall, and we do not set any threshold on it. for each concept t listed in the rl, the combined retrieval status value  is:



the value of the k parameter is set empirically.

the index of phrases is used to reorder the set of terms returned by the engine. the strategy is the following: when a given term is found in the list of terms  returned by the hybrid system , and this term is not found alone in the phrase list  stored for this abstract, then the rsv of this concept is downscored. the shorter the subterm, the more its rsv is affected, as expressed in the following equation, which gives the final rsv. frsv ; m =  <dig> in equation  <dig>  since go terms contain no more than  <dig> words:



in principle, to transform a retrieval engine, which returns a ranked list of concepts, into a categorization system, which make binary decisions on each concept, it is necessary to set a threshold on the retrieval status value. however, the number of concepts to be returned for each protein-go axis pair is known, so this threshold may be a priori ignored in the current design of the categorizer.

go definition, prior probability and full article
as shown in table  <dig>  most go terms  are provided with a definition. this definition can be used to expand the matching features between an abstract and the go terms in the feature space. however, because features in go terms are more important than features appearing in definitions, an underweighting factor is applied on features of the definition.

another refinement that we tested concerns the application of a prior probability. in table  <dig>  we give the distribution of go term in the dsi data set. the prior probability factor is applied after logistic smoothing on the rsv returned for each go term. go categories occurring less than three times are not taken into account.

RESULTS
in this section, we present and discuss the official results as well as results gathered after the competition. all official results were provided by the biocreative judges.

passage retrieval
official evaluations, distributed over each go axis, are reported in table  <dig>  from these data, we can observe that biological processes  are more abundant than molecular functions  and cellular components . this table also confirms that the evaluated set  is a balanced sample of the original data . in general, we also observe that predictions are more relevant regarding the protein  than the go category . the total is 55% vs. 15% respectively for the high results. in general, the quality is equally distributed among the three axis regarding the protein, but regarding go annotation, passage retrieval seems more difficult for biological processes  than for cellular components  or molecular functions  categories. for the passage retrieval task, our system achieved a competitive precision regarding both the go annotation and the protein annotation  if we consider that the only system  <cit>  which achieves a better protein annotation score  perform less effectively regarding the go annotation .

gene ontology annotation
for task  <dig> , official results for all three axis are reported in figure  <dig> both for protein  and go annotation. in figure  <dig>  evaluations made by go curators are provided for different confidence estimations. a confidence threshold of  <dig> means that all predictions were evaluated. this threshold dictated the official results. two other thresholds are proposed,  <dig>  and  <dig> . as expected the passage retrieval score returned by the sentence ranker is an excellent confidence estimator. the trend is true for both go and prot. strikingly a precision close to 90% is obtained for passages related to the go annotation, when the normalized similarity is above  <dig> . although precision is impressive, this setting brutally affects recall. only  <dig> out of the  <dig> evaluated passages are selected as correct with such a confidence threshold. we observed that trading recall for precision does not affect the comparative effectiveness of our system. the best high-precision system reports only 80% precision, together with a lower recall. additionally this result is obtained by submitting only  <dig> results.

from a more detailed perspective, results in figures  <dig> and  <dig> gives the precision of the tool for different confidence threshold. the higher the confidence is, the less results are submitted so that increasing the value of the threshold results in decreasing the recall of the classifier. the former figure presents the quality of the protein-passage association, the latter presents the quality of the go term-passage association. the normalized retrieval status value of each term is used to estimate the confidence of the prediction. official results were given for all predictions, i.e. we do not set any threshold on the confidence estimator . when all results are examined, our system achieved the best recall-precision ratio  but more interesting is the fact that the retrieval status value can serve opportunely as confidence estimator. thus, the number of high marks directly follows the threshold and symmetrically the number of low marks tends to decrease. finally, the number of generally tend to be equally distributed especially on figure  <dig>  results of experiments generated after the competition are reported in table  <dig>  the official run is also located in this table for comparison. at first sight, we see that experiments carried out after the competition were able to improve the performance of the system when measured by mean average precision and mean reciprocal rank. compared to other evaluations campaigns, the biocreative initiative is probably the first large-scale effort to establish user-centered results and tasks based on sound utility measures. however, we regret that the biocreative task  <dig> did not deliver an evaluator-independent benchmark, that could be reused for other experiments. in this aspect, the passage retrieval task of the biocreative task  <dig> clearly relates to question-answering evaluations, where results rely exclusively on human evaluations made a posteriori.

for r <dig>  we see that the optimal weighting schema for the vector space engine  is not the best schema for combination with the regular expression pattern matcher. the best combination is achieved with ltc.lnn . as expected the impact of the pattern matcher is especially effective at high ranks , while the improvement of the map is less significant . in r <dig>  we observe that the thesaurus has a positive but marginal impact, from  <dig>  to  <dig>  for mrp. the submitted run  confirms that linguistically-motivated phrase indexing is beneficial, from  <dig>  to  <dig>  for mrp and from  <dig>  to  <dig>  for map. in r <dig>  we used ltc.lnn, but experiments performed after the competition time show  that a better tf.idf combination is anc.ltn. for the augmented term frequency factor, noted a, the value of the parameters is α = β =  <dig> . finally, the use of the go definition to expand the document/term matching features is also beneficial . run r <dig> uses the same settings as the official run but applied to the full articles. although using full articles rather than abstracts results in a degradation of the classification in regards to both map and mrp, we cannot conclude that abstracts should be preferred to full articles. infact, we cannot expect that the best combination for processing short abstracts would remain optimal for long articles, and therefore additional experiments with different parameters are needed to study this issue.

related experiments
consistent with conclusions drawn from task 1b, is the fact that data-poor retrieval string matching methods  <cit>  are competitive with more complex data-intensive approaches  <cit> . the impact of features appearing in go definitions and related resources, which were used by some of the competitors, appear to be promising extentions  <cit> . such expansion strategies could improve both the categorization and the passage retrieval task, and we believe that further experiments are necessary to fully exploit these resources. another important evaluation parameter is the size of the retrieved passage. guidelines were not explicit and therefore some participants  <cit>  decided to return document sections rather than sentences. the precision  was not improved, but they retrieved a large number of results in the generally category. furthermore, it is very interesting to analyse the way these other participants envisage the relationship between tasks  <dig>  and  <dig> . passage retrieval  is seen as a feature reduction step, which is preparatory for the go annotation task . working with full text articles, other systems must first reduce the categorization space to a shorter passage, then, categorization is applied. this design is opposite to ours. categorization is performed first, then passage retrieval is accomplished driven by the go category. such strictly inverted strategies suggest that a wide span of approaches can be equally effective. however, considering a related task proposed last year in the context of the trec genomics track , it seems that passages longer than a sentence are generally not appropriate for protein annotation. thus, for the trec genomics track  <cit> , ruch et al.  <cit>  report that sentence shortening was an effective strategy to model generif extraction as performed by humans. finally, recent advances in text mining applied to biomedical litterature suggest that argumentative content  <cit> , i.e. paragraphs or sentences specific to categories such as purpose, methods, results and conclusion might be of interest for information retrieval  <cit>  and extraction of gene and protein functions  <cit> .

CONCLUSIONS
we have reported on the development and evaluation of a passage retrieval tool used to support an automatic text categorization tool for protein annotation. for passage retrieval, the tool combines an exact match strategy and a string-to-string edit distance to select the best ranked sentence. for text categorization, the systems combines: 1) a pattern matcher, based on regular expressions; 2) a vector space retrieval engines that uses stems and phrases as indexing units, a traditional tf.idf weighting schema, and cosine as normalization factor. the use of noun phrases seems to improve the categorization's average precision by at least 3%. the combined system can be applied on any controlled vocabulary, even when manually annotated data are not available. the system achieved very competitive results in the context of the biocreative challenge.

