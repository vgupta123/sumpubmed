BACKGROUND
organelles with different functions are the specialized subunits in a cell.  most organelles are closed compartments separated by lipid membranes, such as mitochondria, chloroplasts, peroxisomes, lysosomes, endoplasmic reticulum, cell nucleus and golgi apparatus. these compartments play different roles, for instance, mitochondria supply chemical energy atp for cell survive; chloroplasts transform light energy to chemical energy using photosynthesis; peroxisomes participate metabolism process; lysosomes degrade engulfed viruses or bacteria, and destroyed organelles; cell nucleus contains almost genetic information, carried by dna together with variable proteins to form chromosomes; golgi apparatus is responsible to package proteins and lipids and modify chemicals to make them functional  <cit> .

protein subcellular localization is crucial for genome annotation, protein function prediction, and drug discovery  <cit> . proteins perform their appropriate functions as, and only when, they localize in the correct subcellular compartments. take prokaryotic and eukaryotic proteins as examples, for prokaryotes, many proteins that are synthesized in the cytoplasm are ultimately found noncytoplasmic locations  <cit> , such as to a cell membrane or the extracellular environment, while most eukaryotic proteins are encoded in the nuclear and transported to the cytosol for further synthesis.

the annotations of protein subcellular localization can be detected by various wet-lab experiments. cell fractionation, electron microscopy and fluorescence microscopy are three major experimental methods for the study of protein subcellular localization. however, the experimental approaches are time-consuming and expensive, so that there is a wide gap between the number of known protein subcellular localizations and the number of uncovered ones. for instance, according to the swiss-prot database version  <dig>  related on 30-may- <dig> the number of protein sequences with localization annotations is just about 14% of total eukaryotic protein entries  <cit> . this means that there are about 86% of eukaryotic protein entries without localization labels, which motivates us to find computational methods to predict the protein subcellular localization automatically and accurately.

many methods have been developed and applied in an attempt to predict protein subcellular localization. methods in  <cit>  are based on amino acid composition to predict localization. furthermore, scientists took account of sequence order together with amino acid composition to overcome information missing problem  <cit> . in addition, supervised learning algorithms such neural networks  <cit> , k-nn algorithm  <cit> , svm  <cit>  are widely applied to solve this problem. among these learning-based approaches, svm is popularly adopted in bioinformatics and is shown to perform relatively better compared to many others. there are also a large number of specialized databases are exploited such as dbsubloc  <cit> , eslpred  <cit> , hslpred  <cit> , locsvmpsi  <cit> , loc3d  <cit> , psortb  <cit> , psort  <cit> , loctree  <cit> , bacello  <cit> , targetp  <cit> , secretomep  <cit> , predictnls  <cit> , wolf psort  <cit> , proteome analyst  <cit> , and cello  <cit> .

in this paper, we present a novel approach to exploit the use of unlabeled data to aid the overall accuracy of protein subcellular localization and reduce the labeling effort. the existence of the relative large amount of unlabeled data provides us with a chance to mine useful information about the statistical distributions. we resort to two classical machine learning approaches, namely semi-supervised learning and ensemble learning. experimental results on real biological data sets demonstrate that our efforts can effectively improve the accuracy of the state-of-the-art svm classifiers with fewer labeled instances.

RESULTS
materials
this protein dataset includes  <dig>  eukaryotic proteins with determined subcellular localizations, which were extracted from swiss-prot release  <dig>  by park and kanehisa  <cit>  and  <dig>  eukaryotic proteins without subcellular localization information also extracted from swiss-prot. within  <dig>  proteins, there are  <dig> localizations: chloroplast, cytoplasmic, cytoskeleton, endoplasmic reticulum, extracellular, golgi apparatus, lysosomal, mitochondrial, nuclear, peroxisomal, plasma membrane, vacuolar. detailed statistics of this protein dataset is shown in the following table  <dig> 

we adopt the 2-gram protein encoding method to generate feature of amino acid compositions, which is widely used in many existing protein subcellular localization protein systems  <cit> .

empirical evaluations
we conducted extensive experiments to compare the coforest approach with other state-of-the art prediction algorithms based on evaluation measurement 'accuracy'. in this paper, accuracy is defined as the proportion of true results, namely,

  accuracy=tp+tntp+fp+fn+tn 

tp means: the number of true positives

tn means: the number of true negatives

fp means: the number of false positives

fn means: the number of false negatives

can we achieve same or better prediction with fewer labeled data?
we first demonstrate that our semi-supervised learning approach is indeed useful. in the next method section, we will demonstrate that two parameters will affect the overall performance of coforest. we have chosen different values of f and n and also different numbers of labeled instances. the labeled instances are drawn randomly from the  <dig> localization classes in the labeled dataset. we sample the number of labeled instances from  <dig>  to  <dig>  and also change the number of classifiers from  <dig> to  <dig>  as a result, the corresponding prediction accuracy on the whole set of  <dig>  labeled instances are computed. the results in terms of prediction accuracy are described in table  <dig>  table  <dig> and table  <dig> 

from the results, we can see that by using only about 20% of the labeled instances, we can achieve a prediction accuracy of more than 75%. as a rule of thumb, we can see that the prediction accuracy increases as f and n increase. this follows from our intuition of the algorithm description in the last section.

comparison with baseline algorithms
we also compared coforest with a number of machine learning algorithms, such as decision tree, adaboost and svm. the reason for us to choose these classifiers as baseline algorithms are as follows: since the weak learners we use in coforest algorithm are in fact decision trees, we want to demonstrate the effectiveness of ensemble learning in our approach. furthermore, since adaboost is also one of the most effective ensemble learning algorithms, we want to show that by using adaboost one could not achieve the same performance as our classifier does, where adaboost did not use unlabeled data to help refine the accuracy. a third choice of our baseline classifiers is the support vector machine , which is the state-of-the-art algorithm in protein subcellular localization. we use this algorithm to show that our algorithm can perform better by using even fewer labeled instances.

for all the three baseline algorithms, we did not use any unlabeled instance since they are supervised machine learning algorithms and did not use the information from unlabeled data. we also ranged the number of training instances from  <dig>  to  <dig>  to show different levels of prediction accuracy as a function of labeled training data.

for decision tree, we used the c <dig>  package implemented in weka  <cit>  and tested the algorithm accuracy in two settings. one setting is the ten-fold cross validation, where we randomly split the labeled data into ten folds, where one is used for testing and the other nine for training. this process is iterated ten times and the resulting ten classification accuracy values are averaged to get the final result of ten-fold cross validation. another test setting is to simply use the whole set of  <dig>  labeled instances for testing. for adaboost, we applied the adaboost package in weka, and used decision stump as weak learners. again we use 10-fold cross validation and external testing for the two test settings. experimental results for these two baseline algorithms are shown in table  <dig>  we could see that by using only the tree-based approach on adaboost, the overall performance is relatively lower than the coforest approach.

comparisons between our proposed and the baseline algorithms can be visualized directly in the following figures, figure  <dig>  figure  <dig> and figure  <dig>  these three figures indicate performances of different algorithms based on the same number of labeled training data.

we next compared the prediction accuracy with support vector machine, which is the state-of-the-art algorithm for protein subcellular localization. due to time constraint, we did not consider different values of labeled instances when training the svm classifier, we used the  <dig>  labeled instances and did a ten-fold cross validation. we tuned the γ parameter in rbf kernel, which is a typical setting in protein subcellular localization, and the different values of γ will undoubtedly affect the overall prediction accuracy. the experimental results are shown in table  <dig> 

from the results, we can see that svm could almost achieve a 80% accuracy when γ is set to  <dig> , and typically the prediction accuracy is between 75% and 80%. however, as shown in our coforest approach, the prediction accuracy can be increased to 85% when we are using only  <dig> labeled instances for training, thus, by using about 40% of labeled instances, one can achieve a 10% performance increase than the state-of-the-art algorithms. this result is very promising.

CONCLUSIONS
in this paper, we present a semi-supervised learning approach to solve protein subcellular localization problem. one particular feature of protein subcellular localization is that a large amount of unlabeled protein sequences are available but no literature tries to make use of these unlabeled instances. we used the coforest algorithm and the large number of unlabeled protein sequences for predicting protein subcellular localization. experimental results show that we can achieve more than 10% accuracy increase than svm and moreover, we used only about 30% labeled instances to achieve this accuracy.

there are several possible directions for future research into this coforest framework. the performance of coforest may be better enhanced when we incorporate the active learning framework into coforest, i.e. we could extract more useful information by selecting some representative unlabeled instances, instead of randomly choosing the unlabeled instances. another possible solution is to further incorporate the transfer learning framework into this approach, where the distribution of unlabeled data may not follow the overall distribution of labeled data. using a semi-supervised transfer learning approach may further improve the prediction accuracy.

