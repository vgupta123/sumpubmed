BACKGROUND
with the advancement of whole-genome technologies and unbiased discovery approaches such as microarrays and mass spectrometry, molecular biomarker panel development has attracted much attention and investment in the past decade. given that biomarker panels may be valuable for prognosis, diagnosis or prediction of a medical condition, or for efficacy and safety of a treatment option  <cit> , many teams have embarked on biomarker panel development projects and programs with the aim of clinical utility and health care benefits.

the mission of the nce cecr centre of excellence for prevention of organ failure  is to develop biomarker panels for heart, lung and kidney conditions along the life cycle from risk to presence, progression and variable responses to clinical interventions including pharmacotherapies. its flagship program is the biomarker in transplantation initiative, which began in  <dig>  one branch of the work focuses on renal allograft rejection, which is harnessed in this paper as an illustrative case study. samples from this study are of one of two types: acute rejection  or non-rejection , representing binary classification tasks. acute renal allograft rejection in transplant patients in canada occurs in approximately 10-20% of transplant patients within the first  <dig> weeks post-transplant. acute rejection is a serious problem that leads to kidney failure and graft loss if untreated and recurrent. early detection of acute rejection with a highly sensitive test followed by appropriate treatment is thus of paramount importance; similarly, the exclusion of acute rejection with a highly specific test followed by tailoring of immunosuppressive therapy will benefit many patients by reducing toxic side-effects. acute rejection is currently diagnosed by tissue biopsy, an invasive procedure that requires subjective grading by pathologists to determine if and to what degree acute rejection is present in the tissue sample  <cit> . a promising alternative to tissue biopsy, one which we have pursued since  <dig>  is the use of blood-based biomarkers for diagnosing acute rejection. we reported the first such genomic biomarker panel in transplantation  <cit>  and a proteomic panel in molecular&cellular proteomics  <cit> . with successful replication of our early results, we participated in a voluntary exploratory data submission to the usa fda. a multi-national observational trial on refined biomarker panels is now in its late stages, with the goal of obtaining regulatory approval from the usa fda and health canada.

this paper will first present an established computational biomarker development pipeline for genomic and proteomic data. the pipeline begins with data acquisition , quality control, statistical analysis and mining of the data, and finally various forms of validation. several groups, including ours, have explored blood-based genomic and proteomic classifiers of acute rejection in kidney and heart transplant recipients with promising results  <cit> . however, the potential of combining genomic- and proteomic-based classifiers in an effective manner remains largely unknown. second, we describe an ensemble approach for building proteo-genomic biomarker panels. an intuitive strategy for building such panels is to merge genomic and proteomic data and apply a single-platform analysis strategy to the merged data set  <cit> . unfortunately, with this approach, one encounters challenges related to scaling and normalization, especially with the large differences in the distribution of the data values between the two platforms. in addition, due to differing signal strengths between genomic and proteomic data, it is likely for data from one platform to dominate the final classifier panel, masking what might be a potentially valuable contribution from the second data type. although these issues have been addressed by potential solutions, such as the promising approach taken by mixomics tools that incorporate partial least squares and canonical correlation analysis  <cit> , a different path is described in this paper. fully developed individual classifiers are combined in an ensemble  <cit> , thus avoiding the aforementioned issues while allowing for an intuitive interpretation and straight-forward implementation.

methods
biomarker development pipeline
the biomarker development process represents a series of sequential steps that can be described as a computational pipeline. figure  <dig> shows the genomic biomarker development pipeline, with initial data quality assessment, sample selection, and pre-processing steps on the left, and main analysis components such as pre-filtering, uni- and multivariate ranking and filtering steps in the center. the numbers on the right represent the number of features  that correspond to each analysis step. the purpose of pre-filtering, uni- and multivariate ranking, and filtering steps is to reduce the number of features to be used in the classification model, while selecting relevant features for the classification task. this final list of features represents the biomarker panel which typically ranges in size from 1– <dig> features.

the analysis of proteomic data requires some proteomic-specific analytical steps that are beyond the scope of this article, including data assembled from untargeted lists of identified protein groups, imputation of missing values, and quality assessment of protein identification parameters  <cit> . regardless, the main aims of the analyses undertaken at the different steps of the proteomics and the genomics pipeline are essentially the same. briefly, at the discovery stage, the proteomics computational pipeline utilizes a combination of appropriate univariate and multivariate statistical methodologies to identify a panel of candidate biomarker proteins. the quality of the identified list of markers is evaluated looking at protein identification parameters and examining the existence of potential confounding factors. in previous studies based on itraq-maldi-tof/tof technology, the total number of identified protein groups was about  <dig>  however, due to undersampling commonly seen in shotgun proteomics studies, only about 10% of these protein groups were consistently detected in all the samples involved in a particular analysis. thus, the proteomic analysis data sets from this technology were smaller than the genomic one described in figure  <dig> 

quality assessment
it is important to detect quality issues to prevent them from entering the biomarker development pipeline and negatively affecting analysis results. the quality of samples is therefore assessed as the first step. only samples that did not raise quality concerns are included in the analysis, otherwise samples are reanalyzed using a different aliquot of the same sample. for affymetrix human genome u <dig> plus  <dig> genechip microarray experiments, quality assessment is through visual inspection of rle, nuse and weight plots produced with the affyplm-package. other options include the mdqc-package  and the arrayqualitymetrics-package in r  <cit> . quality control of the plasma depletion step and the acquired itraq data have been previously described  <cit> , which examines the reproducibility of sample handling procedures, the confidence on the identified protein identities to be analyzed as well as their levels.

sample selection
analysis samples are selected by a domain expert working with a statistician to ensure that a statistically sound analysis can be performed on samples that are relevant to the study question. group sizes are reviewed to ensure a reasonable design in regards to balance, possible confounders , and power of the study. the domain expert is responsible for choosing samples that represent the conditions of interest. for the two-group acute kidney rejection case study that is used as an example throughout this paper, a nephrologist confirmed the rejection status of individuals with acute rejection  based on biopsy information, and selected control cases with clinical and demographic characteristics similar to those of rejection cases. the time of blood collection relative to start of rejection treatment in ar patients is an important factor  <cit> , and was taken into account during sample selection. the presented case study is based on a prospective longitudinal design, which required a sample selection step as described in figure  <dig>  depending on the specific experimental design, a sample selection step might not be needed in general.

pre-processing
depending on the type of data, specific pre-processing steps are applied to prepare the raw data for subsequent statistical analysis. in the case of affymetrix microarray experiments, raw data represents expression values for probes on the array. these values are provided in cel-files together with other information about the experiment. pre-processing in this case includes background adjustment, normalization and summarization of probe information into probe sets that can be mapped to genes. this process transforms raw cel-files into a data matrix of probe set values for all analysis samples. we have used the robust multi-array average -pr1ocedure in bioconductor as implemented in the rma- and refplus-packages to perform these steps but other methods can be substituted, for example gcrma or factor analysis for robust microarray summarization   <cit> . the normalization can use an expanded sample set to provide increased performance and stability of the pre-processing procedures, e.g., by including all available microarray samples at different time points for the selected patients in the rma-normalization procedure.

prefiltering
not all features in a data set carry useful information. probe sets with little variation and low expression for example are dominated by noise that can negatively affect the statistical analysis, depending on the methods used. the main goal of the pre-filtering step is therefore to remove features with little variation across analysis samples, independent of sample class, before applying univariate ranking and filtering methods on the remaining features. for that purpose a quantile-based filter was applied to the kidney rejection case study which ranked all samples according to an empirical central mass range  as given in eq. where f <dig> is the fraction of the smallest class, e.g. f1=minnarnar+nnr,nnrnar+nnr in the 2-class classification problem of acute renal allograft rejection, and then removed all features with values below the median ecmr.

  ecmrx=quantilex,1−f12−quantilex,f <dig> 

for the genomic data from the affymetrix human genome u <dig> plus  <dig> genechip, this approach removes half of the  <dig>  probe sets. if a more stringent pre-filter is desired, one could for example remove 75% of features with the lowest ecmr. the inter-quartile range  is a special case of the ecmr with f1= <dig> , i.e., iqr and ecmr are the same for balanced class sizes. for unbalanced class sizes the ecmr-based filter allows variation in the smaller class to enter the calculation of the quantile range. other pre-filtering options include application of an absolute count cut-off that requires at least k samples to have an expression above a fixed threshold, which would address concerns regarding the impact of dependencies between pre- and univariate filters and the ability to control type-i error rates  <cit> . the choice of threshold in any of these methods represents a trade-off between allowing more potential biomarkers to pass the filter and at the same time adding more noisy features, which increase the chance of identifying false biomarkers down-stream.

univariate ranking and filtering
having a large number of features in a biomarker panel is typically not practical, as diagnostic or predictive tests in clinical applications are commonly based on a small number of relevant markers. in fact, many currently applied laboratory tests are based on single markers. in addition, some classification models pose statistical constraints on the number of features that they can incorporate, e.g., a linear discriminant analysis  classification model has to be based on fewer features than the number of training samples. for that reason a univariate ranking and filtering step is applied to reduce the number of candidate features to be included in the classification model.

the univariate ranking step calculates a measure of class differentiation ability for each individual feature that passed the pre-filtering stage. moderated t-tests are commonly used for determining differentially expressed features when sample sizes are small. examples are the limma-package in bioconductor or the signficance anaysis of microarrays  tool  <cit> . these tests return adjusted p-values or false discovery rates  that account for multiple hypothesis testing by applying permutation tests , bonferroni, benjamini and hochberg, or other methods, which is generally recommended for –omics data  <cit> . the limma package includes an empirical bayes method that moderates the standard errors of the estimated log-fold changes. this approach results in more stable inference and improved power, especially for experiments with small numbers of arrays  <cit> .

various combinations of fdr cut-offs and fold-change thresholds are applied to produce reduced lists of candidate features that serve as input for the subsequent multivariate ranking, filtering and supervised learning steps. in addition, lower and upper counts for the number of features are sometimes imposed to ensure a minimum and/or maximum number of features in the returned list.

multivariate ranking and filtering
it might be desirable in some instances to filter a list of features that are relevant as a group without requiring all of them to be relevant individually. multivariate ranking is achieved by applying a multivariate scoring method that orders features by method-specific weights. examples are support vector machines  where squared weights from the svm model are used, or random forest  which provides a feature-importance measure. the multivariate filtering step simply applies a cut-off regarding the number of ranked features to include.

the steps described above are put together in the order shown in figure  <dig> to develop a biomarker panel. the final product in terms of class prediction, e.g. acute rejection versus non-rejection, is a classification model based on a biomarker panel in combination with a supervised learner. the requirements for a supervised learner are that it has to be able to  train its classification model based on a training set representing pairs of features  and response , and  return a class probability or score for the different response types given a test case, i.e., a set of input features. not all steps in the center portion of figure  <dig> are performed every time. for example, the multivariate ranking and filtering step may be skipped, and the output from the univariate steps is then used to directly define the biomarker panel. it is possible that a classification model applies an additional feature selection step, e.g., elastic net  <cit> .

for the binary classification task of separating acute rejection from non-rejection samples, four supervised learning methods were applied: support vector machine  with linear kernel, linear discriminant analysis , elastic net , and random forest   <cit> . where applicable, algorithm parameters were tuned for model selection. additional methods such as pam   <cit>  or spls-da   <cit>  have been explored for other data sets at the proof centre.

model assessment and selection
performance of classification models needs to be estimated for model assessment and selection. for this purpose, it is common practice to split a data set into  <dig> parts:  training,  validation and  testing, with suggested splits being 50%, 25% and 25%, respectively  <cit> . a set of candidate models is first trained on the training set. one of the candidate models is then selected by comparing performances on the validation data, and the performance of the selected model is finally assessed on the test data. in many cases however, particularly in the high-throughput genomic and proteomic arena, data sets suffer from low sample size and cross-validation or boot-strap methods are typically applied to avoid excluding too many samples from the training set.

for the present case study, nested leave-one-out cross-validation  was used in combination with minimum misclassification error for model selection and assessment. the outer loop was used for model selection while the nested loops were used for model assessment by averaging performance over k models that were tuned in the inner loops of the nested cross-validation procedure. model parameters were tuned for elastic net  and lda , while the default cost parameter in svm and default settings for mtry and node-size parameters were used in random forest, since these parameters had little impact on the classification performance in the given data sets. in general, it is advisable to tune these parameters and study their effects on classification performance to decide whether tuning is necessary. estimators based on loo-cv are known to have low bias but large variance. an alternative to nested loo-cv, especially for larger sample sizes, is based on averaging performances over multiple k-fold cv partitions.

in general, models with multiple parameters require multi-parameter optimization. this is not straightforward especially when sample sizes are small and different areas of the multi-parameter plane show the same or similar performances. in these cases it is not clear which parameter combination should be chosen. one solution is to fix all but one parameter and select a model based on tuning that parameter. for example, elastic net has two parameters, alpha and lambda, where alpha is typically fixed to select a trade-off between lasso penalization and ridge regression, while lambda is varied to tune the model.

in addition to misclassification error, sensitivity, specificity and area under the roc curve  were determined. misclassification error, sensitivity and specificity depend on the probability cut-off used. for example, if a sample has a predicted probability of  <dig>  of being an ar, it would be misclassified using a cut-off of  <dig>  but correctly classified using a cut-off of  <dig> . misclassification error is the fraction of misclassified ar and nr samples. all reported misclassification errors, sensitivities and specificities are based on a  <dig>  cut-off. the auc is a quantitative measurement that averages classification performance over all probability cut-offs, and as such does not depend on any particular cut-off value.

ensemble classifiers
in an effort to integrate multiple classification models, separately developed genomic and proteomic classifiers were combined in an ensemble of classifiers as shown in figure  <dig>  ensemble classification methods have been applied in a variety of fields with promising results  <cit> . ensembles often combine predictions from a large number of different individual classifiers to produce a final classification that is based on specific aggregation methods, e.g., average vote. the motivating idea behind ensembles is that inclusion of a diverse set of classifiers ensures representation of various aspects of the underlying system, while a single classifier typically has limited focus. for example, a genomic classifier might focus mainly on an immunological signature in whole blood, while a proteomic classifier might focus on an inflammation signature in plasma.

proteo-genomic ensembles combine classifiers from genomics and proteomics in an effort to improve performance and robustness of predictions. each ensemble consists of a set of genomic and proteomic classifiers that are characterized by a biomarker panel, i.e., a list of probe sets or protein groups. all classifiers produce a probability of acute rejection  when given an unknown sample. predicted class probabilities from individual classifiers were aggregated using one of two methods: average probability  or vote threshold . the ap aggregation method averaged class probability for a specific sample from all individual classifiers in the respective ensemble. ensemble auc and other performance measures were then derived from these average probabilities. the vt aggregation method represents a modified majority vote approach that can be applied to binary classification tasks with only two classes g <dig> and g <dig>  the predicted class from each classifier is interpreted as a vote for that class; if the number of votes for g <dig> exceeds a fixed threshold, then the predicted class is g <dig>  otherwise it is declared g <dig> 

ensembling of classifiers is well-studied in the literature  <cit> . in  <cit> , the analysis of ensembling is extended to imbalanced and high-dimensional data . the analysis indicates that the more "independent" the individual classifiers are, the larger the expected performance gain of the ensemble. this is particularly relevant to integrating molecular signals from whole blood rna and plasma proteins.

prior to the case study described in this paper, blood samples were collected from renal allograft recipients in the biomarkers in transplantation initiative-  <cit> . whole-blood rna samples were analyzed with affymetrix human genome u <dig> plus  <dig>  arrays  and plasma samples were analyzed with itraq maldi-tof/tof mass spectrometry . the two data sources are derived from different compartments of peripheral blood and focus on two separate types of biological material, i.e., leukocyte cellular rna and plasma proteins. perhaps not surprisingly, signals detected by genomic analysis are different from those detected by proteomic analysis, although both types of signals are consistent with the current understanding of the pathogenesis of acute rejection injury. in particular, differentially expressed genes represent three major biological processes related to immune signal transduction, cytoskeletal reorganization, and apoptosis  <cit> , and differentially expressed proteins represent biological processes related to inflammation, complement activation, blood coagulation, and wound repair  <cit> . this diversity in biological signals is maintained in individual genomic- and proteomic-based acute rejection classifiers, and is a desired property in ensemble classifiers. in general, ensemble classifiers demonstrate improved classification performance when individual classifiers in the ensemble represent independent experts  <cit> .

although the current case study focuses on combining genomic with proteomic data, the ensemble framework is more general in nature and does not need to be restricted to these types of data. a second analysis was performed to show how gene expression could be combined with mirna classifiers. this analysis was based on publicly available mrna- and mirna- data sets from a cancer study  <cit> . using the computational pipeline, classifiers for the diagnosis of tumour- versus normal- samples were developed separately for the mrna- and mirna- data sets. a number of ensembles were defined and performances for the ap and vt aggregation methods were estimated.

RESULTS
genomic and proteomic classifiers were developed independently with the biomarker development pipeline using  <dig> samples from the same  <dig> patients  collected at the same time point. all samples were used for classifier training, and thus no samples remained for classifier testing. as such, validation and calculation of probability-of-ar was done with 32-fold  cross-validation wherein 32-models were created for each of the genomic and proteomic classifiers separately with one of the samples left out. the classifer then tested the left-out sample and a probability-of-ar was returned. when classifier development included a model tuning step, nested cross-validation was applied to ensure an unbiased estimate of the probability-of-ar.

the  <dig> samples were used in previous publications that describe the development of the genomics  <dig> and proteomics  <dig> classifiers with a simplified pipeline  <cit> a. genomic data represent rna-based gene expression profiles as measured by affymetrix hg-u <dig> plus  <dig> genechips and were pre-processed with rma using an enlarged pool of  <dig> genomic samples that were available at different time-points for the  <dig> patients, plus an additional  <dig> samples from healthy volunteers, taken from the same biomarker project as described in  <cit> . an ecmr-based pre-filter shown in eq.  was applied to the subset of  <dig> analysis samples and returned  <dig>  probe sets for the analysis. expression values were analyzed on the log-base  <dig> scale.

proteomic data represent ratios between depleted plasma samples from transplant patients and healthy pooled controls as measured by itraq-maldi-tof/tof methodology and several post-processing steps, including proteinpilot™ software v <dig>  with the integrated paragon™ search and pro group™algorithms, and searching against the international protein index  database. a protein group code algorithm  was used to link protein groups across different itraq experiments by defining global protein group codes  from multiple runs  <cit> . there were a total of  <dig> pgcs, each of which was detected in at least one sample. of those,  <dig> pgcs passed a 75% minimum detection rule filter across the  <dig> analysis samplesb.

the number of features and performance characteristics of five genomic and five proteomic classifiers is summarized in table 1c. performance of individual classifiers as measured by auc was typically high, and specificity was higher than sensitivity for all classifiers. in addition to the published genomic classifier  <cit> , four additional genomic classifiers based on svm, rf and en classification methods were developed  <cit> . genomics  <dig>  and  <dig>  classifiers were based on the top  <dig> fdr-ranked probe sets while genomics  <dig> and  <dig> classifiers were based on probe sets selected by elastic net from the probe sets with an fdr< <dig>  .

shown is a list of  <dig> genomic and  <dig> proteomic classifiers, their individual classification performance and their inclusion into  <dig> ensembles that are explored in this paper. lda stands for linear discriminant analysis; en for elastic net ; svm for support vector machine, and rf for random forest. sensitivity, specificity and area under the roc  curve  for the individual classifiers were estimated using cross-validation.

the development of the proteomics  <dig> classifier was described previously  <cit> . four additional proteomic classifiers were developed in a process similar to that used for the genomics analysis described above. classifiers proteomics 2– <dig> in table  <dig> are based on en and svm classification methods, either robust limma  or no univariate filter , and a fold-change cutoff of fc≥ <dig>  in all cases. in addition, a 75%-rule regarding missing values was implemented, i.e., a protein group was only included if it was detected in at least 75% of all samples. the missing values were imputed using k-nearest neighbours  with k= <dig> across all training samples, independent of class label. imputation of test samples was performed in each fold of the cross-validation by combining the imputed training data with the test data, then applying knn imputation.

also shown in table  <dig> is the definition of five ensembles representing different combinations of the  <dig> individual classifiers. ensemble  <dig> represents a two-classifier ensemble based on the published genomic and proteomic biomarker panels, ensemble  <dig> and  <dig> expand on ensemble  <dig> by adding  <dig> genomic and  <dig> proteomic classifier , and one genomic and  <dig> proteomic classifiers . ensemble  <dig> combines the largest genomic  and proteomic  classifiers and genomics  <dig>  ensemble  <dig> combines all  <dig> genomic and  <dig> proteomic classifiers.

the performance of ensemble classifiers was characterized by sensitivity, specificity and auc. these measures were all derived from a probability-of-ar for the ensemble, which was calculated from probability-of-ar values returned by individual classifiers in the ensemble in combination with either the average probability  or vote-threshold  aggregation methods. for vt a threshold of one was used, i.e., a single ar call by any of the classifiers in the ensemble was enough to call the sample as ard. a probability-threshold of  <dig>  was used in the calculation of sensitivity and specificity. results are summarized in tables  <dig> and  <dig> 

shown is classification performance as measured by sensitivity, specificity and auc – for the  <dig> ensembles defined in table  <dig> when using the average probability aggregation method. the minimum, maximum and average performances of individual classifiers in the respective ensemble are included in the table for comparison.

shown is classification performance for the  <dig> ensembles defined in table  <dig> when using the vote threshold aggregation method. similarly to table  <dig>  individual classifier performances are included for comparison.

ensemble  <dig> in combination with aggregation method ap achieves a sensitivity and specificity equaling that of the genomics  <dig> classifier, while the auc is improved slightly relative to the proteomics  <dig> classifier. figure  <dig> shows the estimated probabilities of acute rejection from the different classifiers for each of the 11ar and  <dig> nr samples. for the  <dig> ar samples all red and orange pairs fall on the same side of the  <dig> -probability threshold line used to determine rejection status. this means that the genomics  <dig> and ensemble  <dig> classifiers not only display the same sensitivity, but they also misclassify the same ar samples. also, for the  <dig> nr samples all black and grey pairs fall on the same side of the  <dig> -probability threshold line, which explains the same specificity of genomics  <dig> and ensemble  <dig>  again due to the same nr samples being misclassified. the figure also provides an explanation for the improved auc of the ensemble as compared to that of genomics  <dig> alone. it is due to the probability of the misclassified nr samples being reduced from  <dig>   to a smaller value , in one case close to the  <dig> -probability line. in other words, although the same two nr samples remain misclassified, the auc of the ensemble is improved because auc is calculated based on the order of probability-of-ar for all samples. overall, ensemble  <dig> in combination with aggregation method ap does not seem to improve classification performance much beyond that of the genomics  <dig> classifier alone.

for all  <dig> analyses , we find that sensitivity always meets or exceeds the maximum sensitivity of all individual classifiers in the corresponding ensemble, but exceeds the maximum value for all ensembles wherein the vote-threshold aggregation method is used. a similar observation holds for ensemble  <dig> when the ap aggregation method is used and an increased sensitivity of 82% is observed. specificity, on the other hand, is never better than the best specificity of all individual classifiers in an ensemble, but is always within the min/max range for the  <dig> ensembles when the ap aggregation method is used, or is usually below the min/max range when the vt aggregation method is used. ensemble  <dig> is again the exception here, achieving specificity equaling the minimum value of 81%.

when measuring classifier performance, it can be informative to look at performance in a threshold-independent manner. the area under the curve  in the roc assesses performance in this way, summarizing a classifier’s ability to separate two classes across the complete range of possible probability-thresholds. using this measure of performance, we find that the auc of ensembles based on the ap aggregation method is always higher than the best  auc of the individual classifiers in the corresponding ensemble, although the improvement is generally small as can be seen in table  <dig>  the auc when using the vt aggregation method is typically within the range for individual classifiers, but for ensemble  <dig> with an auc of  <dig>  slightly exceeds the best individual auc of  <dig> .

comparing ensemble performance with mean performance of individual classifiers in tables  <dig> and  <dig> shows that the sensitivity and auc is always higher in the ensemble classifiers, while ensemble specificity is below mean specificity for all  <dig> ensembles with vt aggregation, and  <dig> out of  <dig> ensembles with ap aggregation.

in figure  <dig>  one of the two genomic classifiers  in ensemble  <dig> is compared with the proteomic classifier from the same ensemble, using posterior probabilities of acute rejection . the plot demonstrates that for the majority of samples the two classifiers agree and assign the same class label , although they do not produce the same probabilities ; in some cases, the classifiers disagree on the class of a particular sample . for example, the proteomic classifier misclassifies the  <dig> ar samples in the right bottom quadrant, while the genomic classifier misclassifies the two ar samples in the top left quadrant. one ar sample in the bottom left  square is misclassified by both classifiers. it is possible to compare all pairs of classifiers in an ensemble using the scatter plot approach from figure  <dig>  an example of this is shown in figure  <dig>  which displays a matrix of scatter plots for all  <dig> possible pairs of individual classifiers from ensemble  <dig> 

in addition to the presented case study, the ensemble framework was also applied to a set of publicly available mrna- and mirna- data that contain samples from a variety of human cancers as well as samples for comparable normal tissue. we focused on six tissue types  and used all tumour and normal samples for which both mrna and mirna data were available. this resulted in  <dig> samples . the computational pipeline was applied, using 10x 19-fold cross-validation and a maximum auc  model selection criteria to develop a set of  <dig> classifiers for each of the mrna- and mirna- data sets separately. classifier characteristics and estimated performances are shown in table  <dig>  together with the definition of six ensembles that represent different combinations of mrna- and mirna- classifiers. similar to our results, previous work by ramaswamy et al. on a super-set of the mrna-data was able to differentiate tumour- from normal samples with an accuracy of 92% using svm and cross-validation  <cit> .

shown is a list of  <dig> mrna- and  <dig> mirna classifiers, their individual classification performance and their inclusion into  <dig> ensembles that are explored for classification of tumour vs normal samples. abbreviations are the same as in table  <dig> 

performance of ensemble classifiers was then determined for the ap and vt aggregation methods. the vote threshold was set to one as before, i.e. a sample was classified to class tumour if at least one of the classifiers in the ensemble classified it as such. classification performance is summarized in table  <dig>  and table  <dig> . for both ap and vt aggregation methods, all ensembles achieve a higher auc than the best individual classifier in the respective ensemble. ensembles d and f with the ap aggregation method show the best performances, both having sensitivity of 100%, specificity of 95% and auc of  <dig> , although ensemble f is based on twice as many individual classifiers as ensemble d. for both ensembles, only one normal sample is misclassified as can be seen in figure  <dig>  which shows the probability of tumour for ensemble d and for the six individual classifiers that are equally split between mrna- and mirna-classifiers .

shown is performance for tumour vs normal classification for the  <dig> ensembles defined in table  <dig> using the average probability aggregation method. the minimum, maximum and average performances of individual classifiers in the respective ensemble are included in the table for comparison.

shown is performance for tumour vs normal classification for the  <dig> ensembles defined in table  <dig> using the vote threshold aggregation method. similarly to table  <dig>  individual classifier performances are included for comparison.

from figure  <dig>  it can be seen across the  <dig> samples that the three classifiers based on mrna-data show similar probabilities of tumour most of the time, as do the three classifiers based on mirna-data. however, because mirna-classifiers perform better when mrna-classifiers misclassify , and mrna-classifiers perform better when some of the mirna classifiers misclassify , the ensemble can overall benefit from the averaging of probabilities. this is evident by the fact that all ensemble probabilities for the cancer samples  fall above the probability= <dig>  dashed line, thus achieving the aforementioned sensitivity of 100%. a similar effect of probability-grouping by platform is observed for the normal samples. for example, the mrna-classifiers show a probability of tumour> <dig>  for the single misclassified normal sample, while all mirna-classifiers have a probability of less than  <dig>  for the same sample.

discussion
a biomarker development pipeline with applications in genomic-, proteomic-, and other –omic data was presented and applied to the clinical challenge of classifying acute renal allograft rejection in blood samples. genomic- and proteomic-based classification models were developed and showed adequate classification performance for clinical use. individual genomic- and proteomic-based classifiers were then combined into ensemble classifiers. given the cited improvement in classification performance of ensemble classifiers in other fields  <cit> , an important question underlying our analysis was the extent that ensembles can improve classification performance regarding acute renal allograft rejection beyond that of individual genomic and proteomic classifiers alone. our application area is characterized by small sample sizes and adequate classification performance of individual classifiers. in general, we found that classification performance improved by using ensembles, although improvements in some performance measures might be countered by a decrease in other performance measures. in general, the number of classifiers in an ensemble did not seem to affect performance improvements.

when diagnosing acute kidney rejection, it is arguably more important to avoid false negatives  than false positives , because delays in the treatment of acute rejection cause both short- and long-term harm to the patient  <cit> . this was the motivation behind the vote-threshold aggregation method, which ensures that a single individual classifier vote for acute-rejection would result in an acute-rejection classification by the ensemble. the results in table  <dig> demonstrate that the vt aggregation method achieved an increase in sensitivity across all ensembles though at the intuitively expected cost of decreased specificity in  <dig> out of  <dig> ensembles. the impact of this approach is similar to lowering the probability-of-ar-threshold for an individual classifier, but it benefits from the increased diversity that comes with an ensemble, which in our case includes genomic- and proteomic-based biological signals. the vt method is especially valuable in cases where one platform is able to detect a rejection signal in some patients while another platform is not, as is demonstrated, for example, in figure  <dig> 

one of the ensembles  represents a two-classifier ensemble combining our previously published genomic and proteomic classifiers  <cit> . even though auc improves slightly when using the ap aggregation method, the same samples are misclassified as in the genomic classifier of ensemble  <dig>  sensitivity is improved beyond that of the genomic or proteomic classifier alone when the vt aggregation method is used, but specificity dropped below the values for the individual classifiers. ensemble  <dig> therefore does not seem to improve classification performance much beyond that of the genomics  <dig> classifier alone. ensembles  <dig>   <dig> and  <dig> represent an extension of ensemble  <dig>  where further genomic and/or proteomic classifiers were added. for the ap aggregation method these three ensembles show a similar performance range as ensemble  <dig>  while for the vt aggregation method ensembles  <dig> and  <dig> can improve sensitivity to 100% but drop below the range of individual classifiers for specificity, while staying within range regarding auc. ensemble  <dig> has a specificity of 62% which is the lowest specificity across all  <dig> ensembles and  <dig> individual classifiers. this is not surprising since ensemble  <dig> combines all  <dig> individual classifiers and a single ar-classification of one of the  <dig> classifiers is enough to call the sample ar, therefore maximally increasing sensitivity and lowering specificity. in this case and for ensembles with a larger number of individual classifiers, the vt method might perform better with a higher threshold, which could be, for example, ar-classification from at least two classifiers.

the best-performing ensemble  excludes the published genomic and proteomic classifiers but instead combines the largest genomic, the largest proteomic and a 50-feature genomic classifier based on random forest. the results in table  <dig> and table  <dig> favour ensemble  <dig>  which is the only one that improves sensitivity and auc beyond that of individual classifiers in the ensemble while staying within the range for specificity. the two genomic classifiers in ensemble  <dig> are based on elastic net  and random forest . the proteomic classifier is based on svm using  <dig> features that were selected by fold-change criteria. a contributing factor for the good performance of ensemble  <dig> could therefore be the use of comparatively large classifier panels and a fold-change filter on the proteomic side.

several parts of the biomarker development pipeline for individual classifiers were designed to reduce the selection of false positive biomarkers, including pre-filtering, multiple hypothesis testing correction, cross-validation to maximize use of the small number of available samples, and nested cross-validation to avoid bias when models are tuned  <cit> . ensembles provide an additional layer of robustness for classification when aggregation methods that average over several classifiers, e.g. average probability or majority vote, are used. this robustness is achieved by reducing the impact of inaccurate classifiers based on false positive genes or proteins by allowing more accurate classifiers in the ensemble to “out-vote” a small number of inaccurate classifiers. related to the previous point is the fact that the kidney rejection data is “wide” data, which is defined as having more features than samples. in “wide” data problems it is not feasible to find the best classifier. instead, one commonly finds many and possibly quite different classifiers that seem equally valid while displaying a range of classification performances. ensembling therefore provides a robust approach to “wide” data classification problems.

an important question surrounding ensembling concerns the choice of individual classifiers that should be part of the ensemble. theoretical analysis points to including classifiers that are as independent as possible  <cit> . one source of “independence” in the acute kidney rejection case study comes from the two data types, i.e. genomic versus proteomic. within genomic and proteomic data, classifiers are developed using different combinations of filtering- and classification methods as shown in figure  <dig>  thus focusing on different aspects of genomic and proteomic data respectively. an additional source of “independence” that has not been explored in this study could be provided on a biological level. bioinformatics tools, such as pathway analysis tools and ontology-based tools, can provide insights as to how much individual biomarker panels differ biologically. individual classifiers in an ensemble could then be selected to cover a wide range of biological pathways, thus providing a diverse biological cross-section. pathway analysis is an area of active research in its own right that is currently going through a dynamic flux  <cit> . hence, we have concentrated in our approach and discussion on computational aspects of ensemble classifiers.

in addition to selecting individual classifiers to be combined in an ensemble, a weighting needs to be provided. we have used equal weights of individual classifiers in our analyses, as suggested by the term average probability. in general, each classifier can be weighted differently in classifier aggregation such that more trustworthy classifiers receive a higher weight. it is important to note that any composition of an ensemble introduces a form of weighting. for example, an ensemble of  <dig> genomic and  <dig> proteomic classifiers, in which all classifiers have equal weights, would put a higher weight on proteomic-based classifiers as a group when compared to genomic-based classifiers. if one prefers to give equal weight to genomic- and proteomic-based classifier-groups, the two genomic-based classifiers should have a weight of  <dig>  each , while the five proteomic-based classifiers should have a weight of  <dig>  each . the five ensembles in table  <dig> followed an underlying balanced design in this regard, i.e., the difference in the number of genomic and proteomic classifiers in an ensemble, is at most  <dig> 

because the proteo-genomic ensemble approach assumes fully developed individual classifiers, test samples need to be classified by genomic and proteomic classifiers before they can be aggregated. this requires the samples to be run on both platforms. in cases where a sample is only run on one platform, the ensemble classifier cannot be used. an alternative in this case is to fall back on a platform-specific classifier, which by itself could be an ensemble , although one would lose the advantage of using information from diverse sources for classification. the inclusion of data from other platforms within the presented ensemble framework, for example mirna, metabolomic or clinical data sources, is easily possible as long as patient-matched measurements from the corresponding platforms are provided. the generality of the ensemble framework has been demonstrated by applying it off the shelf to an additional cancer data set based on two different types of genomic data . the findings there show that ensemble classifiers can improve upon already well-performing individual mrna and mirna classifiers, thus supporting the notion that ensemble classifiers based on a diverse set of individual classifiers across different platforms have the ability to outperform any single classifier in the ensemble.

CONCLUSIONS
proteo-genomic biomarker ensemble classifiers show promise in the diagnosis of acute renal allograft rejection and can improve classification performance beyond that of individual genomic or proteomic classifiers alone. the vote threshold application method allows fine-tuning of sensitivity and specificity while incorporating diverse classification signals from individual classifiers. this is an important feature in application areas where sensitivity is more important than specificity. validation of our renal allograft rejection results in an international multicenter study is currently underway.

endnotes
athe genomics  <dig> classifier was developed based on 33-samples which included one additional non-rejection sample that was available only on the genomic platform. this sample was not included in the development of the other genomic and proteomic classifiers.

bclassifier proteomics  <dig> in table  <dig> is from a previous publication  <cit>  which used a 67% minimum detection rule.

cperformance estimates for classifier genomics  <dig> in table  <dig> were based on values for  <dig> samples derived from 11-fold cross-validation of the  <dig> sample set as described in a previous publication  <cit> .

dperformance estimates for ensembles that included the genomics  <dig> classifier used posterior probabilities for the  <dig> samples in common.

abbreviations
ar: acute rejection; nr: non-rejection; lda: linear discriminant analysis; svm: support vector machine; en: elastic net ; rf: random forest; roc: receiver operating characteristics; auc: area under the  curve; pgca: protein group code algorithm; ap: average probability; vt: vote threshold; mrna: messenger rna; mirna: microrna.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
og carried out computational genomic- and ensemble analyses, participated in the design, execution and analytical discussions of the work, and prepared the manuscript. vc carried out the computational proteomic analysis and contributed to the design, execution and analytical discussions of the work presented in this manuscript. gcf contributed to the design, development and description of the proteomics pipeline, analytical discussion of the work and reviewing the manuscript. rb contributed to conception, design and statistical discussion of the computational pipeline and ensembles discussed in the manuscript. st contributed to the design and participated in analytical and biologically discussions of the work. zh contributed to design and analytical discussion of the computational pipeline, and data management support. mt participated in analytical discussion of the work and preparation of itraq proteomics data. rm participated in the conception and design of the work discussed in this manuscript. bm contributed to the conception, design, execution and analytical discussions of the work discussed in this manuscript. pk participated in the conception, design and execution of the work discussed in this manuscript. rn contributed to the conception, design, execution and analytical discussions of the work, and participated in preparing the manuscript. all authors read and approved the final manuscript.

