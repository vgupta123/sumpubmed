BACKGROUND
with recent advances in high-throughput biological data collection, reverse engineering of regulatory networks from large-scale genomics data has become a problem of broad interest to biologists. the construction of regulatory networks is essential for defining the interactions between genes and gene products, and predictive models may be used to develop novel therapies  <cit> . both microarrays and more recently next generation sequencing provide the ability to quantify the expression levels of all genes in a given genome. often, in such experiments, gene expression is measured in response to drug treatment, environmental perturbations, or gene knockouts, either at steady state or over a series of time points. this type of data captures information about the effect of one gene’s expression level on the expression level of another gene. hence, such data can, in principle, be reverse engineered to provide a regulatory network that models these effects.

a regulatory network can be represented as a directed graph, in which each node represents a gene  and each directed edge  represents the relationship between regulator r and gene g. we aim to infer the directed edges that describe the relationships among the nodes. in this case, the causal relationship is statistically inferred, in contrast to the classic definition of causality used in biology to imply direct physical interaction leading to a phenotypic change. this is a challenging problem, especially on a genome-wide scale, since the goal is to unravel a small number of regulators  out of thousands of candidate nodes in the graph. even with high-dimensional gene expression data, network inference is difficult, in part because of the small number of observations for each gene. in order to improve network inference, one would like a coherent approach to integrate external knowledge and data to both fill in gaps in the gene expression data and to constrain or guide the network search.

in this article, we present a network inference method that addresses the dimensionality challenge with a bayesian variable selection method. our method uses a supervised learning framework to incorporate external data sources. we applied our method to a set of time-series mrna expression profiles for  <dig> yeast segregants and their parental strains, over six time points in response to a drug perturbation. this extends our previous work  <cit>  by incorporating prior probabilities of transcriptional regulation inferred using external data sources. our method also accommodates feedback loops, a feature allowed only in some current network construction methods.

previous work
bayesian networks  <cit>  are one of the most popular modeling approaches for network construction using gene expression data  <cit> . a bayesian network is a probabilistic graphical model for which the joint distribution of all the nodes is factorized into independent conditional distributions of each node given its parents. the goal of bayesian network inference is to arrive at a directed graph such that the joint probability distribution is optimized globally. while different bayesian network structures may give rise to the same probability distribution, so that such networks in general do not imply causal relationships, prior information can be used to break this nonidentifiability so that causal inferences can be made. for example, systematic sources of perturbation such as naturally occurring genetic variation in a population or specific drug perturbations in which response is observed over time can lead to reliable causal inference  <cit> . a bayesian network is a directed acyclic graph . therefore, cyclic components or feedback loops cannot be accommodated. this dag constraint is an obstacle to using the bayesian network approach for modeling gene regulatory networks because feedback loops are typical in many biological systems  <cit> . the dag constraint is removed when dynamic bayesian networks are used to model time-series expression data  <cit> . dynamic bayesian networks represent genes at successive time points as separate nodes, thus allowing for the existence of cycles. bayesian network construction is an np-hard problem  <cit> , with computational complexity increasing exponentially with the number of nodes considered in the network construction process. in spite of some attempts to reduce the computational cost  <cit> , the bayesian network approach in general is computationally intensive to implement, especially for network inference on a genome-wide scale.

in regression-based methods, network construction is recast as a series of variable selection problems to infer regulators for each gene. the greatest challenge is the fact that there are usually far more candidate regulators than observations for each gene. some authors have used singular value decompositions to regularize the regression models  <cit> . others have built a regression tree for each target gene, using a compact set of regulators at each node  <cit> . huang et al.  <cit>  used regression with forward selection after pre-filtering of candidates deemed irrelevant to the target gene, and imoto et al.  <cit>  used nonparametric regression embedded within a bayesian network. l1-norm regularization, including the elastic net  <cit>  and weighted lasso  <cit> , has also been widely used  <cit> .

ordinary differential equations  provide another class of network construction strategies  <cit> . using first-order odes, the rate of change in transcription for a target gene is described as a function of the expression of its regulators and the effects caused by applied perturbations. ode-based methods can be broadly classified into two categories, depending on whether the gene expressions are measured at steady state  <cit>  or over time  <cit> . as an example, the tsni  algorithm used odes to model time series expression data subject to an external perturbation  <cit> . to handle the dimensionality challenge , bansal et al. employed a cubic smoothing spline to interpolate additional data points, and applied principal component analysis to reduce dimensionality.

to help mitigate problems with using gene expression data in network inference, external data sources can be integrated into the inference process. public data repositories provide a rich resource of biological knowledge relevant to transcriptional regulation. integrating such external data sources into network inference has become an important problem in systems biology. james et al.  <cit>  incorporated documented experimental evidence about the presence of a binding site for each known transcription factor  in the promoter region of its target gene in escherichia coli. djebbari and quackenbush  <cit>  used preliminary networks derived from literature indexed in pubmed and protein-protein interaction  databases as seeds for their bayesian network analysis. zhu et al.  <cit>  showed that combining information from tf binding sites and ppi data increased overall predictive power. geier et al.  <cit>  examined the impact of external knowledge with different levels of accuracy on network inference, albeit on a simulated setting. imoto et al.  <cit>  described different ways to specify knowledge about ppi, documented regulatory relationships and well-studied pathways as prior information. lee et al.  <cit>  presented a systematic way to include various types of biological knowledge, including the gene ontology  database, chip-chip binding experiments and a compressive collection of information about sequence polymorphisms.

our contributions
this article is an extension of yeung et al.  <cit>  which adopted a regression-based framework in which candidate regulators are inferred for each gene using expression data at the previous time point. iterative bayesian model averaging   <cit>  was used to account for model uncertainty in the regression models. a supervised framework was used to estimate the relative contribution of each type of external knowledge and from this a shortlist of promising regulators for each gene was predicted. this shortlist was used to infer regulators for each gene in the regression framework.

our contributions are four-fold. first, we develop a new method called ibma-prior that explicitly incorporates external biological knowledge into ibma in the form of a prior distribution. intuitively, we consider models consisting of candidate regulators supported by considerable external evidence to be frontrunners. a model that contains many candidate regulators with little support from external knowledge is penalized. second, we demonstrate the merits of specifying the expected number of regulators per gene as priors through ibma-size, which is a simplified version of ibma-prior without using gene-specific external knowledge. third, we refine the supervised framework to adjust for sampling bias towards positive cases in the training data, thereby calibrating the prior distribution. fourth, we expand our benchmark to include simulated data, and compare our ibma methods to l1-regularized regression-based methods. specifically, we applied ibma-prior to real and simulated time-series gene expression data, and found that it out-performed our previous work  <cit>  and other leading methods in the literature on these data, producing more compact and accurate networks. figure  <dig> summarizes ibma-prior and our main contributions.

RESULTS
we applied our method, ibma-prior, to a time-series data set of gene expression levels for  <dig> genotyped haploid yeast segregants perturbed with the macrolide drug rapamycin over  <dig> time points  <cit> . these data are described in detail in the methods section. to evaluate the performance of ibma-prior, other published regression-based network construction methods were applied to the same time-series gene expression data set and the resulting networks were assessed for the recovery of documented regulatory relationships that were not used in the network construction process. we also checked whether each method recovered target genes enriched in upstream regions containing the binding sites of known tfs. we further carried out a simulation study to assess our method.

comparison of different methods
first, we assessed the improvement of ibma-prior over that of our previous work ibma-shortlist from yeung et al.  <cit>   when applied to the same yeast time-series gene expression data. then, we compared our bma-based methods to several l1-regularized methods, including the least absolute shrinkage and selection operator   <cit>  and least angle regression   <cit> . regularized regression methods combine shrinkage and variable selection. l1-regularized methods aim to minimize the sum of squared errors with a bound on the sum of the absolute values of the coefficients  <cit> . efficient implementations are available for some of these methods, including lasso and lar, and these methods have been applied to high-dimensional data in which there are more variables than observations  <cit> .

we also compared the performance of our method with and without using external biological knowledge. we assessed hybrid methods by combining lasso and lar with the same supervised learning stage that was used in ibma-prior and ibma-shortlist. table  <dig> lists all the methods compared in this analysis.

assessment: recovery of documented relationships
to evaluate the accuracy of the network constructed by each method, we assessed its concordance with the yeastract database, a curated repository of regulatory relationships between known tfs and target genes in the saccharomyces cerevisiae literature  <cit> . if a regulatory relationship documented in yeastract was also inferred in the network, we concluded that this relationship was recovered by direct evidence. some of the positive examples used in the supervised learning stage are also documented in yeastract. to avoid bias, we did not consider those regulatory relationships in the assessment. for each method compared, we applied pearson’s chi-square test to a  <dig> ×  <dig> contingency table that quantified the concordance of the inferred network with the yeastract database. we also computed the true positive rate , defined as the proportion of the inferred positive relationships that are documented in yeastract. it should be noted that yeastract cannot document all “true” relationships as the entire set of regulatory relationships in yeast has yet to be defined. we further considered the ratio of the observed number of recovered relationships to its expected count as a result of random assortment . more detailed definitions of the assessment criteria can be found in additional file 1: figure s <dig> 

a the p-value of pearson’s chi-square test measures the strength of association between an inferred network and the yeastract database.

b true positive rate  is defined as the proportion of inferred regulatory relationships that are documented in yeastract.

c the number of misclassified cases is the sum of false positives and false negatives.

d the o/e ratio is the number of folds the observed number of recovered relationships  in excess of the expected count of recovery by chance.

next, we compared our ibma-based methods to l1-regularized methods. all the approaches that used lasso and lar generated networks that had far more mis-classifications than the ibma-based methods. specifically, applications of lasso or lar without the supervised framework  had tprs of  <dig> % and  <dig> % respectively, the lowest among all the methods considered. incorporating external knowledge did improve both lasso and lar, increasing the tprs to about 11% in both lasso-shortlist and lar-shortlist. however, these tprs were still lower than the tprs for our ibma-based methods. our ibma-based methods therefore outperformed methods based on lasso and lar for these data.

finally, we investigated the impact of priors in ibma-size, in which we applied a model size prior to calibrate the sparsity of the inferred networks without using any external data sources. ibma-size can be considered as a simplified version of ibma-prior that sets the regulatory potential  to a constant parameter that controls the expected number of regulators per gene. from table  <dig>  ibma-size produced a tpr of  <dig> %, which was higher than all the other methods considered except ibma-prior. although the number of recovered positive relationships was lower than that of ibma-prior , ibma-size also produced a network that was more compact . we would recommend ibma-size when gene-specific external information is not available.

in table  <dig> and additional file 2: table s <dig>  all the ibma networks were thresholded at a posterior probability of 50% . we found that ibma-prior also out-performed other methods for these data over different posterior probability thresholds .

assessment: transcription factor binding site analysis
in another assessment, we checked whether the set of target genes containing known binding sites for a certain tf were enriched among the child nodes of that tf in each inferred network. we first extracted the known binding sites for  <dig> tfs documented in the jaspar database  <cit> . using tfmscan  <cit> , we retrieved a set of genes containing the known binding sites in their upstream regions for each tf. we then checked for enrichment of these genes among the inferred child nodes of the corresponding tfs in each network with fisher’s exact test. table  <dig> reports the number of tfs whose inferred child nodes exhibited such enrichment, at a false discovery rate  of 10%. all of the methods that made use of external information outperformed all of those that did not, illustrating the benefit of incorporating external knowledge. lasso-shortlist and lar-shortlist appeared to produce slightly better results than ibma-prior in this binding site analysis, but it is likely the consequence of their larger network sizes .

a fdr was controlled at 10%.

comparison with lirnet
lee et al.  <cit>  proposed a regression-based network construction method called lirnet, which performed well on a publicly available gene expression data set from brem et al.  <cit> . the brem data set recorded the steady-state expression levels for  <dig> yeast segregants,  <dig> of which were profiled in our time-series experiments under different growth conditions. lee et al.  <cit>  showed that lirnet out-performed bayesian networks on the same data, and so we compared our top performer, ibma-prior, with lirnet. because lirnet was formulated to analyze steady-state expression data with no time components, we adapted our method to static data by removing the subscript referring to the time point from equation :

  e=βg,0+∑r∈rgβg,rxr,s, 

we applied ibma-prior to the same 3152-gene subset of the brem et al. data that lee et al.  <cit>  used. lirnet constrained the search of regulators for each target gene to  <dig> known tfs. for fair comparison, we also confined the set of candidate regulators to the same tfs. networks constructed from steady-state gene expression data cannot have feedback loops  <cit> . to detect and remove such loops from our inferred network, we identified all strongly connected components using the igraph r package, and deleted the tf-gene link associated with the lowest posterior probability for each cycle.

same as before, we evaluated different methods by assessing the concordance of the inferred networks with the yeastract database using pearson’s chi-square test. the assessment results in table  <dig> show that ibma-prior outperformed lirnet, almost doubling the tpr and the o/e ratio while producing a comparable number of misclassified regulatory relationships.

a the p-value of pearson’s chi-square test measures the strength of association between an inferred network and the yeastract database.

b true positive rate  is defined as the proportion of inferred regulatory relationships that are documented in yeastract.

c the number of misclassified cases is the sum of false positives and false negatives.

d the o/e ratio is the number of folds the observed number of recovered relationships  in excess of the expected count of recovery by chance.

simulation study
we designed and conducted a series of simulations to further assess our proposed method. we used the fitted model obtained from applying ibma-prior to the yeast time-series microarray data set as the true underlying network, and generated simulated expression data from the estimated linear regression model. twenty data sets, each with the same dimensions as the real time-series expression data, were independently generated as follows:

 <dig>  set the prior probability of a regulatory relationship for each gene pair to the same value as the regulatory potential obtained at the supervised learning stage using the real external data.

 <dig>  set the expression levels of the  <dig> genes for the  <dig> yeast segregants and the two parental strains at time t =  <dig> as the observed measurements in the real yeast time-series gene expression data.

 <dig>  for each target gene g, define the set rg of true regulators as those with a posterior probability of ≥50% in our inferred network using ibma-prior and the real time-series data.

 <dig>  for time t =  <dig> to  <dig> 

for gene g =  <dig> to  <dig>  generate the simulated true expression level for each segregant s using the following equation:

  xg,t,strue=βg,0+∑r∈rgβg,rxr,t− <dig> strue, 

where the β’s are given by the posterior expectation of the regression coefficients corresponding to the set of true regulators determined in step  <dig> 

 <dig>  generate the simulated observed gene expression levels by adding noise to the true expression levels without measurement errors, i.e.,

  xg,t,s=xg,t,strue+ϵg,t,s, 

where ϵg,t,s ~ n with σg <dig> being given by the sample variance of the regression residuals in the real data analysis. others, e.g.  <cit> , have shown that the error in log ratios of expression data is reasonably approximately by a normal distribution.

to assess the accuracy of networks inferred with the simulated data sets, we compared each of these networks to the true network created in step  <dig> of the data generation algorithm. we used the same assessment criteria as in the real data analysis with the true network replacing yeastract as the reference. as shown in table  <dig>  ibma-prior out-performed the other ibma-based methods, yielding a tpr of  <dig> % averaged over  <dig> replications .

a the p-value of pearson’s chi-square test measures the strength of association between an inferred network and the true network for the simulation study.

b true positive rate  is defined as the proportion of correctly inferred regulatory relationships.

c the number of misclassified cases is the sum of false positives and false negatives.

remark: the values reported in the table were averaged across the  <dig> replications. the true network for the simulation study contained a total of  <dig> edges.

CONCLUSIONS
in this article, we have proposed a methodology that systematically integrates external biological knowledge into bma for network construction. a key feature of our approach is a formal mechanism to account for model uncertainty. for each target gene, we arrive at a compact set of promising models from which to draw inference, the weights of which are calibrated by the external biological knowledge. our method infers sparse, compact and accurate networks upon the input of a reasonable estimate of network density from both real and simulated data. it does not put a hard limit on the number of regulators per target gene, unlike some other methods, such as bayesian network approaches that impose this constraint to reduce the computational burden. while known tfs are in general favored a priori with the available external biological knowledge, we do not confine the search for regulators to them. this allows for the discovery of new regulatory relationships.

we showed that our method, ibma-prior, consistently outperformed our previous method  <cit>  using both real and simulated time-series gene expression data. we showed that this improvement is mostly due to the incorporation of external data sources via prior probabilities . we also improved upon our previous supervised method by adjusting for the sampling bias of positive and negative training samples . we further showed that our ibma-based methods  recovered a higher percentage of known regulatory relationships  than other popular variable selection methods .

a key contribution of this work is the derivation of more compact networks with higher tprs. unfortunately, due to incomplete knowledge, the evaluation of false positives and false negatives is difficult using real data. therefore, we supplemented our study with a simulation study designed to mimic the real data, and showed that ibma-prior produced fewer misclassified cases  than other ibma-based methods.

there are many directions for future work. a time-lag regression model, i.e., one that accounts for the current expression level of a target gene with the past expression levels of its regulators, is used in our methodology. this model formulation is in line with many other regression-based methods targeting time-series gene expression data  <cit> . the expression levels were taken at regular time intervals in our yeast time-series gene expression data set. if the levels were measured at non-uniform time intervals, we could create interpolated time-series data with interpolation strategies employed in the literature  <cit> . it would be useful to apply our methodology to network construction in prokaryotic systems as we would expect better performance in these less complex systems that tend to be more dominated by transcriptional control  <cit> .

