BACKGROUND
the non-recombining portion of haploid chromosome y is passed intact from father to son with a mutation rate several times greater than autosomes  <cit> . as such, patterns of variation in y are widely used to uncover historical patterns of human migration; are important in genealogical reconstruction and have application in forensic analyses.

the y chromosome consortium  published a revised y-chromosome dna haplogroup tree in  <dig>  consisting of approximately  <dig> markers which can be used to characterize  <dig> major global haplogroups, labeled a-t, as well as sub-classification into a total of  <dig> haplogroups at the finest level of resolution. different major haplogroups have been found at high frequencies in different geographical regions, for example the e clade in africa, and the o clade in eastern asia. particular fine-level haplogroups are found in multiple locations, such as r1a in eastern europe, south asia and central asia, indicating migration of r1a from eurasian steppes to the new world. the c <dig> haplogroup, found at high frequency throughout asia is commonly interpreted as genealogical remnants of the empire of genghis khan  <cit> .

y haplogroup assignment has traditionally been carried out by targeted genotyping using a combination of short tandem repeat typing, multiplex pcr and mini-sequencing  <cit> , often using a hierarchical strategy in order to first refine the major haplogroup, and subsequently genotype markers within that haplogroup which illuminate finer levels of resolution. such a procedure requires substantial amount of wet-lab analysis, requires stringent replication and quality control to eliminate errors which can arise due to the limited amount of information collected at each step. more recently, personal genetic companies have included specific y chromosome markers on custom genotyping arrays  <cit> . nevertheless, the resolution available from genotyping arrays is limited by markers included on the chip.

high coverage high throughput sequencing has the potential to capture all single nucleotide and insertion/deletion variation, and as such provide near-perfect assignment of individuals to y haplogroups. one recently published method  demonstrated the effectiveness of assigning y haplogroups with high coverage sequence data  <cit> . as high coverage sequencing of large population samples remains expensive, low coverage population sequencing, in which each individual is sequenced at less than 2x haploid coverage is an attractive alternative, but this will not capture all individual-level variation. amy-tree, for example, found insufficient information in low coverage genomes from  <dig> genomes project for confident haplogroup assignment  <cit> .

we hypothesize that, given the sharing of haplogroups within an ethnically homogenous population, it should be possible to borrow information across individuals within a population in order to improve haplogroup assignment. in this manuscript, we present the yhap tool, which has been designed for assigning haplogroups to low-coverage population re-sequencing data. yhap borrows information across all samples to assign samples to haplogroups probabilistically, thus providing an accurate representation of the inference which can be made from the data collected. yhap is a complete solution and can also be applied to high-coverage sequence data, as well as data from genotyping arrays.

methods
we use the set of haplogroups and mutations defined in  <cit> . we map the forward and reverse primers described in this manuscript to identify the reported strand of the variation in the grch <dig> reference. after strand correction, we identify whether the mutant allele is the equal to the alternative or reference allele, so that we can subsequently work in reference/alternative allele space on the forward strand, consistent with conventional genotype calling schema. next, we map each mutation to its position on the pre-defined y phylogenetic tree t. finally we create a haplogroup matrix h of size nref*l where l is the total number of nodes in t  and nref is the number of pre-defined y markers. each entry hil = {hilg} is a probability distribution vector expressing the probability that a sampled individual from the clade below node j carries allele g . at leaf nodes, this probability vector is either { <dig> } or { <dig> }, and at internal nodes, it is the proportion of descendant leaf nodes with reference or alternate alleles, respectively.

to assign a sequenced individual to a specific haplogroup, we obtained genotype likelihoods at each putative variant site  from chromosome y vcf files of the  <dig> genome project. this results in a matrix g of size n*m where m is the number of sequenced samples, n is the number of putative variants, and gij = {gijg} is a vector of genotype likelihoods. we then generated an augmented h* matrix by adding in extra sites in g but not h with probability vector h*il = { <dig> , <dig> }. the pipeline is similar for genotype data, except that the genotype likelihoods are taken to be either  <dig>  if gi,j=g or  <dig> otherwise. to illustrate the entries of this matrix, we have included a heatmap of both the standard y chromosome consortium positions which are polymorphic in the ceu, as well as the full h* matrix trained on ceu data .

we can calculate the assignment of each individual using

  pg.j|h.l*=∏i= <dig> .n∑g= <dig> pgi,j|g*pg|hil* 

where pg|hil*=hilg* and pgij|g=gijg

we can then calculate the posterior probability of each haplogroup amongst a set of haplogroups, where prior haplogroup probability distribution p is set to the uniform distribution,

  ph.l*|g.j=pg.j|h.l*ph.l*∑k= <dig> .lpg.j|h.k*ph.k* 

by restricting the set of haplogroups considered in equation , yhap can be customized to either only assign to within the major haplogroups , or all possible haplogroups at the finest level of classification.

while this model is sufficient for assigning y haplogroups individually, it does not capture shared information between sequenced samples adequately, particularly for low coverage sequencing. given that a population sample will share individuals from the same haplogroup, and while none of these individuals may have enough depth at informative y haplogroup markers, there is enough information across the pooled reads from all samples from the same haplogroup. however, we do not know a-priori which samples can be pooled as coming from the same haplogroup.

in order to pool information between samples, we treat the allele probability distribution {h*ilg} at markers present in the sequence data but not present as haplogroup markers, as parameters in our model. we update these parameters using expectation maximization, in which we first calculate the posterior probability assigning each sample j to each haplogroup l using equation  <dig>  and then update the {h*ilg} to reflect the average of genotypes assigned to haplogroup l at position i, weighted by this posterior probability of assignment. in this way, the model learns which alleles are characteristic of the pre-defined haplogroups, and is thus able to more accurately assign individuals which may not have good coverage at those sites, but which show similarity to other individuals across the y chromosome. the probabilities p are also updated at each step to reflect the proportion of haplogroups assigned in the population.

RESULTS
we applied yhap to low-coverage sequencing data generated in the pilot phase of the  <dig> genome consortium which were also part of the hapmap project, including  <dig> yri,  <dig> jpt,  <dig> ceu and  <dig> chb samples  <cit> . major y haplogroups have been previously assigned to these samples as part of the hapmap project. the average sequencing depth of these samples is  <dig> x as described in  <dig> genome y chromosome analysis report. compared to haplogroups previously obtained from the hapmap project  <cit> , yhap showed perfect assignment accuracy . we also used yhap on the hapmap combined phase  <dig> , <dig> y genotype data and obtained the same assignments previously reported with this data.

1
2
3
4
1
2
3
4
1
2
3
4
*e1b1a was formerly known as e3a.

1hapmap indicates results from hapmap consortium.

2ikg indicates results form  <dig> genomes consortium.

3chip indicates results from yhap applied to hapmap genotype data.

4ngs indicates results from yhap applied to  <dig> genomes consortium sequence data.

the resolution reported for yhap is the level at which a single assignment achieved greater than 90% posterior probability.

in order to investigate the ability of yhap to assign finer-level haplogroups we compared yhap results obtained at complete resolution  on both hapmap genotype data and also  <dig> genomes low coverage sequence data . we see that there is complete concordance at the major haplogroup level, and there is increasing uncertainty in assignment as the resolution of assignment increases, particularly using dense genotype data. we also observe that accuracy remains high amongst those assignments which yhap assigns high confidence.

we compared yhap’s performance with amy-tree on the  <dig> genome dataset. firstly we consider those  <dig> genomes samples which were also assigned with amy-tree based on high coverage complete genomics data . yhap achieved greater resolution than amy-tree relative to this benchmark on  <dig> of  <dig> samples . in  <dig> of  <dig> samples yhap identified e1b1a <dig> haplogroup, whereas amy-hap assigned e1b1a <dig> using both  <dig> genomes and complete genomics data, although in both cases yhap assigned the same haplogroup on the basis of hapmap genotype data.

next, we use hapmap genotype data as a validation, using results on  <dig> samples for which we have hapmap and  <dig> genomes sequence data. yhap achieved greater resolution than amy-tree in  <dig> of  <dig> samples, whereas amy-tree never had greater resolution than yhap. as an example, this included yhap correctly identifying na <dig> as belonging to r1b1b <dig> haplogroup vs root for amy-tree  amy-tree identified a haplogroup inconsistent with hapmap data in  <dig> of  <dig> samples , and yhap identified an inconsistent haplogroup in  <dig> of  <dig> samples .

finally, in order to investigate the relationships between sequencing depth and assignment accuracy, we randomly downsampled the original bam files from  <dig> genome to  <dig> x. for simplicity, we chose jpt to run the test. we see that downsampling increases the uncertainty of assignment , but yhap accuracy remains high amongst those assignments which are made with high posterior probability. this demonstrates that as the underlying amount of information decreases, yhap is still able to extract inference and accurately represent the uncertainty of this inference.

the total complexity for the whole procedure is o, conventionally, when using default settings, it will take almost 10 min to locate 10 ~  <dig> individuals and approximately 200 mb memory.

discussion and 
CONCLUSIONS
we have demonstrated the utility of using low-coverage population sequence data to accurately resolve y haplogroups at high resolution. this can be achieved via efficiently borrowing information between individuals in the population which have a common y haplogroup using a probabilistic assignment model. moreover, we have demonstrated that it is possible to accurately quantify the uncertainty in the haplogroup assignment, such that even for very low coverage sequence data  it is possible to make inference of y haplogroups, but only achieve high certainty for a top-level haplogroup assignment.

moreover, yhap can inform discovery of new haplogroup markers. essentially the conditional haplogroup allele probabilities h*ij , the chinese  <dig> program , the national natural science foundation of china . ljmc is supported by an arc future fellowship no. ft <dig> 

authors’ contributions
we developed this software with a joint effort of two research groups, lachlan coin’s lab and yingrui li’s team, with equal contribution. lc is the senior author for the project design. yl and cy are the senior authors for the data analysis team. lc and fz wrote the manuscript. lc, fz and dl participated in software development. rc, yj, and xy are responsible for data analysis and gl is in charge of information organizing. the authors are grateful to people in  <dig> genome consortium and hapmap consortium for their help in providing validation information. the manuscript has been seen an approved by all authors.

supplementary material
additional file 1: table s1
concordance of hapmap array data and  <dig> genomes sequence data. table s <dig>  haplogroup assignments comparison using amy complete genomics data based result as golden standard. table s <dig>  haplogroup assignments comparison using yhap hapmap array data based result as golden standard. table s <dig>  accuracy and certainty of half-coverage. table s <dig>  accuracy and certainty of downsampling on high-depth sample from  <dig> genome project. figure s <dig>  heatmap representing probability that haplogroup carries non-reference allele on only y chromosom consortium snps. figure s <dig>  heatmap representing probability that haplogroup carries non-reference allele at all snps modelled.

click here for file
