BACKGROUND
affymetrix genechips® are routinely used to measure relative amounts of mrna transcripts on a genome wide basis. the large number of probe sets  available on these arrays gives the researcher a wealth of information, but the multiple testing raises the potential for a large number of false positives. false positives and false negatives can both pose problems for the researcher, each with its own cost, so the balance between the two should be evaluated based upon the goals of the experiment. increasing the stringency for accepting differences as significant  reduces false positives, which is important if verification and follow-up are costly, but simultaneously reduces true positives and may lead investigators to miss important trends in the data. measurements of false positive risk, such as false discovery rate   <cit> , are now commonly used to help guide decisions. although fdr gives the investigator an estimate of how many false positives to expect, it does nothing to identify which results are false positives.

methods that differentially eliminate data that are likely to be unreliable can be of great help to the investigator. not all genes are expected to be expressed at levels that are either biologically significant or detectable by the affymetrix technology  in any particular tissue; in fact, the subset of genes expressed is what determines the characteristics of each tissue. for example, jongeneel, et al.  <cit>  estimated that  <dig> – <dig>  transcripts are expressed in human cell lines at one copy per cell or above. data for genes not actually expressed represent experimental noise and cannot increase true positives, but can  generate false positives. discarding data for genes that are not expressed at detectable levels is, therefore, justified by biology and should result in an improvement in the balance between true and false positives.

each affymetrix genechip® probe set contains  <dig> to  <dig> paired perfect match  and mismatch  25-mer probes, which are used to determine whether a given gene is expressed and to measure the expression level   <cit> . the affymetrix microarray suite version  <dig>  algorithm uses the probe-pair data in different ways to calculate the detection call and the signal. mas <dig> uses a non-parametric statistical test  of whether significantly more perfect matches show more hybridization signal than their corresponding mismatches to produce the detection call , present  or marginal ) for each probe set  <cit> . we will use the convention of capitalized present, absent, and marginal to indicate the formal detection calls. the signal is the anti-log of an average  of the log for all of the probe pairs, where mmadj is equal to mm or an adjusted quantity which will produce a positive value  <cit> . genes that are not detectably expressed nevertheless generate signal values, usually low; random fluctuations in these low values can often produce large apparent fold-changes.

different methods have been used to pre-filter data to remove data for probe sets that are believed to be less reliable, but the effects of such pre-filtering are rarely analyzed quantitatively. filtering by signal   <cit>  removes probe sets with signal close to background; the choice of how close to background is arbitrary. removal of probe sets that are called absent on all arrays has been reported  <cit> . some use post-hoc methods by eliminating significant probe sets with low fold changes  <cit> ; again, the choice of fold-change is arbitrary and there is no theoretical null distribution. others use combinations of these strategies: trimming upper and lower signals plus fold change filter  <cit> ; confidence score based on fold change, p-value, signal and percent present  <cit> ; signal, fold change and percent present filters  <cit> ; minimum signal and fold change  <cit> . most of these studies did not provide a reference for their selection of filtering criteria or provide evidence that these strategies were helpful. aston et al.  <cit>  chose their fold-change threshold based on fold changes seen in previous microarray studies of post-mortem brain tissue, but technical variations between experiments can affect the distribution of signals. stossi et al.  <cit>  provided two references for their confidence score but neither of these gave a rationale for the calculation. seo, et al. demonstrated that using the mas <dig> detection p-value as a weighting factor in the distance measures for hierarchical clustering increased the ability to separate samples from biologically different groups  <cit> .

we have filtered out probe sets that were not called present by the mas <dig> detection call in at least 50% of the samples in one treatment group  <cit> . requiring the probe set to meet the criterion in any one treatment group retains genes that are turned on or off; these are usually very interesting to biologists. our method, which we call filtering by fraction present, improves fdr. here, we evaluate the effects of setting different thresholds and compare this approach to the use of thresholds for signal values. these analyses were performed using expression level data generated by two widely used algorithms, mas <dig> and rma . rma is an alternative log scale measurement of expression derived from only the perfect match probes by fitting them to a linear model normalized across all arrays in the experiment. rma does not provide a measure comparable to the mas <dig> detection call. we examined the effects of the fraction present filtering on the ability to detect changes in expression using a parametric t-test and also using a permutation-based test, significance analysis of microarrays   <cit> . we also explore how experiment size can affect the ability to detect differences in gene expression, and how the sample size interacts with the choice of filtering thresholds, using permutations of the full data set to create virtual experiments of smaller sample sizes. these analyses provide useful guidelines for improving the design and interpretation of microarray experiments.

RESULTS
distribution of signal and rma values
the a priori expectation is that not all genes are expressed in any given tissue at levels detectable by affymetrix genechip® arrays   <cit> . it therefore makes both biological and statistical sense to avoid analyzing differences in the apparent expression of genes that are not truly expressed. to compare two methods of filtering out such probe sets, we examined a dataset that compares  <dig> arrays from cells without interferon to  <dig> arrays from cells treated with interferon alpha . of the  <dig>  individual probe sets  in the ifn data set, 54% were called absent by the mas <dig> algorithm. there is a strong suggestion of bimodality in the distribution of log <dig> for all probe sets , with a large number of absent probe sets forming a shoulder at low signal values. removing probe sets in which fewer than half of the arrays in at least one of the experimental groups was called present eliminates the large shoulder of absent probe sets, leaving a distribution that is more nearly normal . it is important to note that the signals for all samples in a particular probe set are treated as a group; all are retained or all removed based on whether at least one experimental group  meets the filtering criterion. in fig.  <dig>  signal values for probe sets for individual samples are shown, hence the retention of some absent samples after filtering. an alternative method of removing probe sets thought to represent genes with little or no expression is to set a minimum average signal level for at least one of the two experimental groups. fig. 1c shows the distribution of signal values when a minimum average signal of  <dig> is required;  <dig> was chosen to retain a similar number of probe sets as the 50% present filter shown in fig. 1b. filtering based on the signal values more severely truncated the low expression values .

the distribution of rma values  has a greater abundance of probe sets with low values than does the mas <dig> signal, and more of the probe sets called present have low values . filtering by a threshold of 50% present leaves many of the low-level present probe sets . in contrast, filtering by the average rma value ≤ <dig> , which removes a comparable number of probe sets, removes the low probe sets and truncates the left-most portion of the graph .

effects of different filtering thresholds
we explored the effect of setting different thresholds for both types of filtering on the percentage of probe sets retained that have each detection call . when adjusted to remove comparable numbers of probe sets, filtering by fraction present does better at retaining probe sets called present. about 37% of the probe sets are absent on all  <dig> arrays, and are therefore removed by the fraction present filter set to any fraction greater than  <dig> . no present probe sets were removed until the threshold was at least 20%, by which point 81% of the absent probe sets were removed. setting the fraction present to 50% removes  <dig> % of the present probe sets along with 92% of the absent probe sets . filtering by either signal value  or rma value , when adjusted to remove a comparable number of probe sets, leaves a less favorable balance between absent and present probe sets. unlike filtering by fraction present, signal-based filtering removes present probe sets even when using a very low minimum mas <dig> signal: a minimum mas <dig> signal of  <dig> leaves the same number of probe sets as the present filter set at >0%; at that signal threshold,  <dig> % of the present probe sets are removed along with 66% of the absent probe sets. for rma the balance between removing absent and present probe sets is even worse: the equivalent threshold of  <dig>  removes  <dig> % of present probe sets and 57% of absent. as the signal value is increased beyond that, a greater fraction of present probe sets is removed. average signal or rma value thresholds that leave a number of probe sets equal to the results of using 50% present remove  <dig> % and  <dig> % of present probe sets while only removing 86% and 77% of the absent probe sets .

there was substantial agreement among the filtering methods in which probe sets were retained when the thresholds were chosen to retain comparable numbers of probe sets . between  <dig> and 89% of the probe sets retained with the fraction present filter were also retained when filtering by minimum mas <dig> signal. the agreement was less when filtering by rma values, with only 77% of the probe sets in common. similar findings are seen for the vitamin a data . very few probe sets with p ≤  <dig>  are lost by filtering and the overlap between signal and fraction present filtering is better with mas <dig> data than rma data .  increasing the stringency of filtering decreases the number of probe sets with nominally significant p-values, as expected, but the more significant probe sets  are the least affected .

sig254
sig375
sig475
sig593
sig795
sig200
sig265
sig323
sig400
sig475
afor comparison of different filters, thresholds were selected for each filter that removed similar number of probe sets. types of filter: fraction present, 'fp' followed by threshold value; average mas <dig> signal, 'sig' followed by signal threshold; average rma value, 'rma' followed by threshold value. bthe percent of probe sets in common retained by both fraction present and average mas <dig> signal filter. cthe percent of probe sets in common retained by both fraction present and average rma value filter.

sig254
sig375
sig475
sig593
sig795
sig200
sig265
sig323
sig400
sig475
afor comparison of different filters, thresholds were selected for each filter that removed similar number of probe sets. types of filter: fraction present, 'fp' followed by threshold value; average mas <dig> signal, 'sig' followed by signal threshold; average rma value, 'rma' followed by threshold value. total number of probe sets with p ≤  <dig> , followed by the number removed at each threshold .

the fdr for any particular p-value is an estimate of the percentage of probe sets expected to be false positives for the group of probe sets that have a p-value less than or equal to the selected p-value. fdr is based on the number of probe sets used in the analysis . filtering by fraction present or by signal or rma value have similar effects on the fdr calculated according to benjamini and hochberg  <cit>  . the largest stepwise improvement in fdr occurs with the initial filtering, present fraction > 0% or removal of an equivalent number of probe sets by an average mas <dig> signal ≥  <dig> or rma value ≥  <dig> . increasing the stringency of the filter continues to improve the fdr. however, in the ifn experiment , increasing stringency beyond 25% present, mas <dig> signal ≥  <dig>  or rma value ≥  <dig>  leads to little improvement in fdr for the more significant probe sets , while increasing the number of those very significant probe sets lost . results for the smaller vitamin a data seta are similar . the smoking dataset  has higher variability within each group. in those data, the fraction present filter shows a larger advantage over the average signal filter, which increases with increasing stringency .

the benjamini and hochberg  <cit>  fdr is conservative. an alternative fdr algorithm described by storey and tibshirani  <cit>  produced fdr estimates that were about 50% better  than those shown in fig. 5a. like the benjamini and hochberg fdr, the storey fdr was improved by more than 50% when the data were filtered using a threshold of 25% present.

permutation analyses
we used permutations of the ifn data in which  <dig> samples from each treatment group were combined to produce two new groups expected to show no difference. welch's t-tests on the mas <dig> log transformed data produced fewer nominally significant probe sets than expected by chance :  <dig>  at a nominal p =  <dig>  and  <dig>  at a nominal p =  <dig> . in these balanced permutations, 37% of probe sets are absent on all arrays but 43% of the probe sets with p ≤  <dig>  are found in this "all-absent" group, demonstrating that the absent probe sets make a disproportionate contribution to false positives. similar analyses of the smoking data  also produced fewer nominally significant probe sets than expected by chance.

permutation of the mas <dig> data such that no true positives would be expected were carried out  <dig> times. results shown are the average fraction called significant by the welch's t-test for selected p-values . results are for unfiltered data, probe sets called absent for all samples , and data filtered using fraction present > <dig> 

to determine if filtering would also improve other types of analyses, we analyzed the ifn mas <dig> data either unfiltered or after filtering by fraction present with thresholds of >0%, 25% and 50% using significance analysis of microarrays   <cit> ; sam uses permutations to calculate an fdr . filtering by fraction present increased the number of probe sets deemed significant at each fdr, demonstrating that filtering is beneficial for this alternate method of determining significant changes. comparing fraction present >0% to unfiltered data, there was a 35% improvement in the number of probe sets significant at 1% fdr. in this 10-sample experiment, more restrictive filtering  did not result in appreciable improvement over >0% present.

effects on genes turned on or off
the most pronounced difference between filtering by fraction present and by average signal is the effect on probe sets that are turned "on" or "off". genes that are turned on or off are of particular biological interest. in the ifn data there are  <dig> probe sets that met our criteria for being turned on or off ; there are  <dig> in the vitamin a data. filtering by fraction present, none of these probe sets were removed when the threshold was ≤ 50% for either data set. filtering by signal value, on the other hand, removed "on/off" probe sets at each of the selected thresholds . demanding that all probe sets be present in one of the two conditions leads to a 70% decrease in the detection of probe sets turned on or off in ifn data and an approximately 50% decrease for the vitamin a data.

filtering by fraction present  and average mas <dig> signal  followed by threshold. on/off: probe sets with p <  <dig>  for t-test and in which the sum of present calls differed by more than  <dig> for ifn data and more than  <dig> for vitamin a data between the two treatment groups were called turned "on" or "off".

effects of using fraction present in entire experiment rather than by treatment group
our approach of requiring at least one group to meet the threshold insures that the gene is expressed at a detectable level in at least one biologically defined group; that seems a priori preferable to requiring a  fraction present across the entire experiment, because the latter could include genes that are not reliably detected in any biological condition. to examine whether our choice led to a significant bias, we compared these two approaches. using a fraction present > <dig>  is, of course, identical for both methods. comparing thresholds of 25% or 50% present in at least one group  with thresholds across the entire experiment that led to retention of similar numbers of probe sets, the number significant at any particular p-value was within 2%. filtering based on fraction present in at least one group was much better at preserving probe sets turned on or off than using a global threshold.

effects of sample size on power
most of the experiments completed by our core facility have fewer than  <dig> samples per treatment group, typically 4– <dig>  and some in the literature use fewer than  <dig>  to understand the effects of sample size on filtering we created smaller virtual experiments  from the ifn data by using permutations of the original data. we randomly selected arrays without replacement within each treatment group; this created virtual experiments in which a difference in expression is expected. there is a large increase in power as the sample size increases  especially for the most significant probe sets : a 15-fold increase from 3-sample experiments to 8-sample experiments. the effects of filtering in the smaller experiments were similar to the effects seen in the full experiment . the more significant probe sets  were mostly retained when filtering was at ≤ 50% present . the fdr is similarly improved by filtering . similar permutations were performed using the smoking data for samples sizes of  <dig>   <dig> and  <dig>  the number of probe sets with p ≤  <dig>  increased nearly 3-fold going from  <dig> to  <dig> samples; increasing to  <dig> sample added another 70% and the full  <dig> samples had a further 60% improvement over  <dig> 

number of probe sets at p ≤  <dig>  found in the unfiltered ifn data, and the number of those lost by filtering at each of several fraction present thresholds, for experiments with  <dig> to  <dig> samples per treatment group.

we carried out a second set of permutations this time randomly selecting equal numbers of samples from each treatment group to create two new groups expected to produce no true positives. for these tests of  <dig>   <dig> and  <dig> samples in each treatment group, a disproportionate number of the false positives were found in the probe sets that are absent for all arrays . the number found significant was less than expected for a normal distribution, results that are similar to the results of permutation tests on the full data set.

permutations generating smaller experiments with  <dig>   <dig>  or  <dig> samples per treatment group of the ifn mas <dig> data such that no true positives would be expected were carried out  <dig> times. results shown are the average fraction called significant by the welch's t-test for selected p-values . results are given for unfiltered data, probe sets called absent for all samples, and data filtered using fraction present > <dig> 

effect of sample size and filtering on consistently significant probe sets
while there is no gold standard for the ifn data, the full 10-sample dataset provides a reasonable standard to which the smaller virtual experiments can be compared. the benjamini and hochberg  <cit>  fdr for the full experiment  at p =  <dig>  is 25%, the storey  <cit>  fdr is 17%, and the estimate by permutation is 20%. therefore, a crude estimate of false discovery can be made by comparing the results from the small experiments to the results using all samples, assuming that any probe set that was called significant in the smaller experiments but had a p-value >  <dig>  in the full experiment  was a false positive. the number of false positives identified in this manner is slightly smaller than was found by permutations, and remains about constant for experiments of size  <dig> to  <dig> samples per treatment group . the number identified as "true positives"  at p ≤  <dig>  increases with the size of the experiment. filtering at 50% present removes about 50% of the false positive probe sets across the full range of sizes, and removes from  <dig> %  to  <dig> %  of the true positive probe sets . this suggests that larger experiments do not need as stringent a fraction present filter.

another way of analyzing the likely true positives in smaller experiments is by examining the reproducibility of results. we assumed that probe sets deemed significant at least 50% of the time  represents consistent, reproducible data. the number of consistently significant probe sets increases as the experiment size increases and approaches the number identified as true positive probe sets . in the smaller virtual experiments  only 2–4% of the probe sets consistently significant at p ≤  <dig>  are lost when filtering by 50% present. in larger experiments  6–9% of these consistently significant probe sets were lost when filtering by 25% present . for those probe sets consistent at p ≤  <dig> , the number lost by filtering is even smaller, almost none for 3– <dig> samples at 50% present and 1–2% for 5– <dig> samples per group at 25% present. only  <dig> probe sets in the 3-sample permutations were found to be significant at p ≤  <dig>  at least 50% of time, whereas  <dig> such probe sets were found in the 4-sample permutations. all of these were retained by fraction present filtering at all thresholds.

in contrast to removing probe sets that represent genes not expressed, setting a fold change limit by itself does not appear to increase the likelihood that a change is in fact real. absent probe sets with low signals have an increased probability of generating spurious large fold changes, especially in smaller experiments . for these small experiments, the probe sets remaining after 50% present filter generate a modest number of fold changes ≥ <dig> of which 71–84% are called significant in the full 10-sample experiment at p ≤  <dig> . on the other hand those probe sets removed by the 50% filter generate about  <dig> times as many fold changes ≥ <dig>  of which only  <dig> to 10% are called significant in the 10-sample experiment at p ≤  <dig> .

discussion
microarray experiments allow one to examine global patterns of gene expression, but by their nature involve multiple comparisons that can generate false positives. while the idea of removing probe sets that are unlikely to produce positive results is not new, we present a systematic analysis of the effects of several strategies. not all genes are expressed in any one tissue  <cit> . probe sets that have very low signals or are called absent primarily reflect noise in the data, and give a large number of false positives without adding many true positives. permutations expected to produce no significant changes confirmed that absent probe sets have an increased risk of producing false positives . requiring that only one treatment group meet the threshold, particularly with our recommended filtering by fraction present, preserves data for genes that are turned on or off, genes that may be of great interest to biologists.

filtering by fraction present does a better job of removing most of the absent probe sets while retaining most of the present probe sets than filtering by either average mas <dig> signal or rma value , and results in much better fdr . our main evaluation criteria, improvement of fdr, was chosen because this experiment-wide measure of confidence is widely applied. because there is no "gold standard" for real experiments, we used measures that increased the likelihood of a result being a true positive, such as p-value <  <dig>  for a welch's t-test and consistency of detecting the difference in multiple permutations. fraction present filtering removes very few probe sets with p ≤  <dig>  ; it does not remove probe sets that are turned on or off unless the threshold is set above 50% present . unlike using signal or rma values, thresholds chosen for fraction present are not affected by chip type, percent called present, method of scaling or normalization, nor by the method used to produce the expression value .

permutation of the ifn data to simulate smaller experiments also showed that the absent probe sets generated a disproportionate number of false positives  many of which had fold changes larger than  <dig>  showing that fold-change alone as a filter cannot fix this problem.

filtering increased the average number of probe sets that met an fdr of  <dig>  in the ifn data for experiments of all sizes , and was particularly helpful for the smaller experiments: over 3-fold improvement for the  <dig> sample experiments  and nearly double for the  <dig> sample experiments . small experiments  have limited power to detect changes, and very few probe sets can be consistently identified . filtering by fraction present greatly improves fdr even for small experiments, and retains nearly all of these reproducible probe sets . while we think that experiments should use more than  <dig> or  <dig> samples, this filtering method should improve results from small experiments such as pilot projects.

pavlidis, et al.  <cit>  demonstrated that  <dig> to  <dig> samples  produced reproducible results, as determined by their stability measures of order and recovery. our study demonstrates that even large experiments benefited from filtering by fraction present; the ifn data with  <dig> samples and the smoking data with  <dig>  both had improvements in fdr after filtering , with approximately a 50% improvement in fdr when using a fraction present of  <dig>  for filtering.

removing only those probe sets called absent in all samples provides the single largest improvement in fdr and appears to be sufficient for large experiments. although the fdr is somewhat better with more stringent filtering , the loss of probe sets at p ≤  <dig>  indicates there may be an accelerated loss of true positives in the larger data sets . as the experiment size decreases, the criterion for filtering should be increased . for data sets with 3– <dig> samples 50% present spares most of the probe sets significant at p ≤  <dig>  and those probes sets found most consistently . for more samples, relaxing the threshold to 25% fraction present is reasonable . requiring 100% present in one of the two treatment groups is not recommended, because it removes too many highly significant probe sets  and removes a large portion of the probe sets turned on or off  in experiments of any size.

the results are similar for datasets that differ greatly. the ifn data, presented in the most detail, was from an experiment that examined the effects of interferon treatment on human pbmc in vitro  <cit> , and used the hgu133a genechip®. the vitamin a data compared rna extracted from liver tissue from sprague-dawley rats fed vitamin a deficient or sufficient diets  <cit> , and used the relatively old rgu34a genechip®, designed with much less sequence data and informatics. the smoking data are from a large study examining differences in bronchial epithelia extracted from human subjects  <cit> , and also used hgu133a genechip®; the variability within each group in the smoking dataset is much greater than in the others. the pearson correlation between samples from subjects within each of the two groups in the smoking data were  <dig>  and  <dig> , compared to an average pearson correlation > <dig>  for samples within each group for the ifn data. in all three cases, representing different generations of genechip®, different species, different laboratories and different amounts of intra-group variability, our approach achieved the primary goal of improving fdr while minimizing the removal of very significant probe sets  and retaining those probe sets turned on or off.

filtering based on the fraction of present calls is superior to methods based on signal or rma value because it is more likely to preserve probe sets turned on or off and it removes probe sets that show cross-hybridization. filtering by fraction present is also much easier to implement, because general guidelines can be set based upon the experiment size instead of having to examine the distribution of signal values; the variability of the signal distributions for different datasets is such that no average signal value gives comparable results across all datasets . although the detection call is generated by mas <dig>  this method can be used as a pre-filter to improve results using non-mas <dig> generated data, such as rma.

CONCLUSIONS
filtering out data that are not reliably detected by setting a threshold for fraction of arrays  in which the probe set is called present by the mas <dig> algorithm is a simple, easy to implement approach that works well to reduce false positives with little cost in loss of true positives. it is superior to using the average signal or rma value because it is more likely to preserve probe sets turned on or off and it removes probe sets that show cross-hybridization. another advantage is that filtering by fraction present is much easier to implement, because general guidelines can be set based upon the experiment size instead of having to examine the distribution of expression values.

filtering by fraction present improves both parametric  and non-parametric analyses . for t-tests, this type of filtering rarely removes very significant probe sets . although similar results in fdr improvement can be achieved filtering by average signal or rma value, approaches based on expression level are more likely to remove genes that are being turned on or off. permutations of data expected to produce no true positives resulted in fewer false positives than predicted by the benjamini and hochberg method  <cit> , and demonstrated that probe sets called absent produce a disproportionate fraction of false positives.

using fold change by itself for filtering is problematic. probe sets that are all or mostly absent  can generate large fold changes  that are not reproducible, and represent false positives.

smaller experiments benefit from filtering with a threshold of  <dig>  or higher ; criteria can be relaxed for larger experiments although filtering is still of substantial value. setting the threshold to 100% present  is too stringent for experiments of any size, because it removes many of the genes being turned on or off and removes a large proportion of very significant genes with little improvement in fdr.

