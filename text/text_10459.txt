BACKGROUND
the biochemistry we observe in life on earth is an island in the chemical space of possible biochemistry. not all possible small organic molecules are made by life, and the chemicals making up the metabolic pathways common to life are limited to a small number of classes of chemicals – aldehydes, polyols, amines, alpha amino acids etc.. understanding why biochemistry uses the molecules that it does is central both to engineering biochemistry to produce useful products and to understanding how terrestrial biochemistry originated. is the restriction on the observed chemistry of life simply because life has not evolved the catalysts needed to make other molecules, because life has not found a need for them, or because there is selection against chemistry outside ‘biochemical space’?

it is plausible to suggest that life simply has not invented the means to make some classes of chemicals. we know that life makes carbon-carbon bonds using aldol condensation and not  metathesis  <cit> , although metathesis enzymes can be designed in principle  <cit> . there may simply not be any functional reason for making some molecules driving the evolution of the relevant enzymatic mechanisms.

there may also be limits on what biochemistry can achieve outside those imposed by catalytic mechanisms and the function of metabolites. for example, it has previously been shown that a simple measure of the degree of saturation of a molecule may be used to indicate that molecule’s toxicity, in the absence of any other structural information about the molecule, a finding that is related to the distribution of biochemicals in chemical space  <cit> . it would be surprising if this were the only such constraint on the molecules of life.

in this paper i present evidence that there is selection against the incorporation of chemicals that contain structural features not found in central metabolism – chemicals that i term ‘unbiological’ – into metabolism, separate from the constraints provided by selection for specific function and the ability of life to catalyse specific types of reaction. specifically, the sections below argue that:i) the chemical space of the biochemicals that are common to life on earth is a small subset of the chemical space possible to the chemistry of life .

ii) that chemicals outside biochemical space have a higher chance of being toxic at millimolar concentrations than chemicals that fall inside biochemical space .

iii) that a wide range of experimental data suggests that many small molecules bind to many proteins with low millimolar affinity, which provides a mechanism for the toxicity of chemicals at millimolar concentrations 

iv) that the reason for correlation of the toxicity of chemicals and their distance from biochemistry is that life has systematically evolved proteins to avoid unwanted millimolar interactions with metabolites in order to avoid poisoning itself .



the results in the paper are in two parts to reflect this reasoning. the results and discussion sections  describes the chemical space of life and the low level toxicity of chemicals falling outside this space. the sections on mechanism of ub correlation with toxicity and proposed mechanism of correlation of ub with millimolar toxicity  provides an explanation for this effect.

these results suggest that biochemistry is more of an integrated whole than the conventional metabolic map would suggest. this has theoretical and practical implications, which i discuss briefly at the end of the paper.

RESULTS
biochemistry occupies a limited chemical space
i first establish that biochemical space is a relatively small subset of the possible chemical space from which metabolism could be selected. it is a commonplace that many of the components of primary metabolism “look similar to each other” . this section establishes that this apparent limitation of metabolism to a few chemical types is a real restriction in chemical space.

the chemical space from which metabolism is selected is the space of chemicals made from c, n, o, and h, with s as s and p, bonded in ways that are found in biological molecules. for example, 2-amino-4-hydroxyhexanoate looks like a plausible amino acids, but it happens not be made by life, <dig> whereas acca  does not fit an intuitive feeling of what a biochemical looks like, as few biological compounds contain a cyclobutane ring. of the myriad compounds that can be formed from the elements c, n, o, p and s , life rarely forms hydrazines, peroxides, rings of less than five atoms, or phosphorus compounds other than phosphates.fig.  <dig> examples of non-metabolites



these rules, and some others relating to molecular stability, were implemented in the program combimol as previously described  <cit> . the chemical space of possible biochemicals includes structures usually excluded from drug design due to their sensitivity to metabolism  <cit> . from the chemical space of all such molecules, all fragments were generated as described in  <cit> . this provides a library of substructures with which to probe the space of actual molecules that make up metabolism.

life’s metabolic diversity is enormous  <cit> . for the purposes of this paper, i use a small subset of metabolites that are components of the central metabolic processes of all life on earth, and pragmatically those processes that are shown on the roche/expasy metabolic map  <cit> . all the small molecules listed in part  <dig>  were used as a set of metabolites here called “core metabolism”, a collection of  <dig> molecules widely used by all life on earth .

there are more fragments of  <dig>   <dig> and  <dig> atoms than there are metabolites in core metabolism, so we would expect that some of them would not be represented in that metabolism. the chances that a 5-atom fragment will be a substructure of a molecule depends on the size of the molecule. figure 2a shows the expected fraction of those fragments that would not be found in a set of  <dig> molecules if the molecules were constructed randomly from the atoms and bonds found in core metabolism.  fig. 2a shows that the expected number of fragments that are not found is substantially smaller than the actual number: core metabolism must represent a small subset of the chemical space of possible water-stable chemicals that can be made from c, n, o s and p . figure 2b extends this analysis to the ~ <dig>  natural product chemicals in the dictionary of natural products . dnp records the detection and structural analysis of organic chemicals from any natural source, and so samples the full diversity of chemistry of terrestrial life. if terrestrial biochemistry sampled all the chemical space of chon, s and p chemistry, then essentially all of the fragments searched here should be represented in the database. however over 50 % of 6-atom fragments are not found in the database.fig.  <dig> extent of biochemical space. fraction  of fragments derived from the space of all possible chemicals that are not found in actual metabolites, compared to the fraction that would be expected not to be found in the same number of chemicals sampled at random from the chemical space of possible metabolites, plotted as a function of fragment size . blue squares – fraction of fragments not found in actual metabolites. red circles – fraction not found in an equivalent size collection of random molecules. panel a: fragments not found in the ‘core metabolism’ of  <dig> molecules represented in the expasy metabolic map. panel b: fragments not found in the ~ <dig>  unique molecules listed in the dictionary of natural products  <cit> 



why is biochemistry apparently limited to a subset of the possible chemistry that life could perform? the next three sections demonstrates that chemicals that fall outside the chemical space occupied by biochemistry are not merely unlikely to be part of a metabolism, but interfere with that metabolism in a way as to produce a toxic effect, and the further outside ‘biochemical space’ they are, the greater that antagonism.

mild toxicity is correlated with ‘unbiological’ chemical characteristics
in this section i introduce a measure of how different a chemical is from the chemical space of life. i show that a greater difference is correlated with low levels of non-specific toxicity. toxicity is related to the existence of structures in the test chemical that are different from chemical structures usually found in biology.

chemicals can be toxic for one of three broad reasons.

toxic chemicals can be chemically reactive, such as formaldehyde or mercury compounds, and so chemically modify the components of life. reactive toxicity depends on specific chemical functionality. the combimol chemical generation software automatically excludes reactive moieties, and so this is not a class of toxicity probed by these studies.

toxic chemicals can interact with a specific molecular mechanism in the organism, and so disrupt a particular biochemical function . drugs and plant secondary metabolite toxins achieve their effect in this way. this is caused by very specific chemical structures, which confer specific toxicity on molecules that contain them. such ‘structural alerts’ were originally identified to predict mutagenicity  <cit> , but have been extended to more general toxicity prediction in programs such as derek  <cit> , topkat, multicase  <cit>  and others  <cit> . in my terms, a ‘structural alert’ is a fragment that has a high affinity for a specific molecular target whose blockade produces a toxic effect. in agreement with this, ‘structural alert’ approaches to toxicity prediction or other structure-activity relationship methods that try to relate large structural features to biological endpoints work well for specific toxicity mechanisms, such as herg blockade giving rise to cardiac toxicity  <cit>  or electrophilic attack on dna giving rise to carcinogenicity  <cit> .

structural alert approaches do not work well for predicting broad toxicity endpoints, such as death  <cit> . a wide range of industrial chemicals have, or are claimed to have, toxicity that is not severe or life-threatening at low concentrations, and which is not obviously linked to structural alerts, but which nevertheless cause morbidity and mortality in model organisms at higher concentrations. interactions of some of these chemicals with various receptors or enzymes is claimed, but most are simply observed to disable or kill model species without a mechanism for their toxicity being known or postulated. it is this third class of low potency, non-specific toxicity that i have probed further below.

i use a fragment-based approach to identify the largest part of a molecule which is different from anything found in biology. fragment-based methods of describing molecules are well known, computationally simple approaches to describing a molecule in terms of how its structure would be drawn by a chemist  <cit> . several groups have described using a fragment-based approach for molecular description and design , claiming that building drug-like molecules from chemical fragments derived from biochemicals lead to more ‘drug-like’ results.

i define a measure of the fraction of a molecule that is not similar to a biological molecule, which i call “unbiological” . ub is defined as the largest region of a test molecule that does not overlap with at least one molecule in the core metabolite set. ub has to be defined in terms of the size of the fragments used to determine overlaps. because the difference between the expected and observed occupancy of chemical space shown in fig.  <dig> is greatest for 5-atom and 6-atom fragments, 5-atom and 6-atom overlaps were both used for this study, designated as ub <dig> and ub <dig> respectively. the algorithm used to generate the ub measures is summarised in the methods section, with more detail on the actual computational steps used in appendix  <dig>  and a graphic summary of the process in fig.  <dig> fig.  <dig> cartoon of calculating unbiological . this takes a ‘toy domain’ of four metabolites and three target molecules to explain the process. only fragments of  <dig> or  <dig> atoms are considered in this example. in reality there are  <dig> metabolites, ~ <dig> targets molecules  and  <dig> fragments of size  <dig> to  <dig> atoms. metabolites and target molecules are used to generate fragments that are present in at least two of the overall set of molecules . fragments are classified as to whether they occur in the set of metabolites  or do not occur in metabolites . the target set of molecules is then matched to the set of fragments that do not occur in metabolites – the size of the largest such fragment is the ub measure. note that in this simplified model it is clear that the presence of a chlorine atom confers ‘unbiological-ness’ on a molecule. the size of the ub fragment can be the same as the size of the whole molecule . as illustrated here, this approach takes no account of the potential reactivity of a molecule, only its topological structure



in table  <dig> i show the result of correlating the values of ub calculated for each chemical species with the toxicity endpoints measured for that chemical species, for a variety of measures of general, non-specific toxicity. as is standard in toxicology, the measure of toxicity is the logarithm of the concentration that gives a half-maximal toxic effect in the system under consideration. log  scales are commonly used in biochemistry because of the linear relationship between the binding energy of a small molecule binding to a large one and the logarithm of the equilibrium constant of that binding. pragmatically, a log scale also enables visualization of data spanning many orders of magnitude. the half-maximal affect  is the commonly reported value for many toxicological and pharmacological measures. in the case where the effect is causes by simple binding to a single target, a half-maximal effect represents the concentration at which the target is 50 % occupied, i.e. the kd.table  <dig> correlations of ub with toxicity endpoints

rank correlation coefficient between toxicity endpoints and unbiological  measures. two ub measures are shown – ub
 <dig> and ub
 <dig>  calculated from an overlap of  <dig> and  <dig> atoms between target molecule and the pool of metabolites. see appendix  <dig> for more detailed descriptions of calculation of ub. column 1: toxicity endpoint. column 2: number of data points. column  <dig> and 4: correlation of ub
 <dig> and ub
 <dig> respectively with appropriate toxicity endpoint. significance of the correlation of flagged by asterisks.* = p <  <dig> .** = p <  <dig> *** = p <  <dig> . note that*** is a value selected to be  <dig> /, to correct for multiple testing of  <dig> toxicity endpoints and  <dig> correlates. if ub
 <dig> and ub
 <dig> were randomly distributed with respect to toxicity, then we would expect to have to do this study  <dig> times to come up with one correlation of p <  <dig> 



here the ub measure  is negatively correlated with the logarithm of the concentration at which a chemical has a half-maximal effect. this might be ld <dig> for a lethal toxicity measure or ec <dig> for a non-lethal measure. a negative value of the correlation means that a larger ub is associated with a lower concentration, i.e. with a more potent toxin.

in almost all cases, for ub <dig> and ub <dig>  there is a significant negative correlation between ub and toxic concentration. for a wide range of living systems, from isolated mammalian cells through unicellular plants and protests to multicellular plants and diverse animal species, ub is correlated with toxicity. this correlation is highly statistically significant. the “***” level of significance in table  <dig> is an indication of p <  <dig>  that the indicated correlation will be produced by chance. there were around  <dig> correlations performed for this initial analysis of the data . if ub was uncorrelated with toxicity, there is only a p =  <dig>  chance that we would observe one “***” level correlation in this data set.

the one exception to the pattern of correlation of ub with toxicity is saccharomyces cereviseae, which shows only weak correlation between the toxicity endpoints reported here and ub <dig> or ub <dig>  a possible reason for this will be discussed below in the section on thresholds for correlations.

i emphasize what this does and does not show. the correlations show robustly that molecules with segments that are not represented in the chemicals of core metabolism have a higher chance of being toxic at any given concentration level than molecules made up of structures found in core metabolism. the larger that “unbiological” segment is, the more toxic the molecule is. none of the molecules tested for toxicity here are normal components of central metabolism .

however this is not a method for detecting or predicting pharmacology mediated by a single, known target, or for detecting or predicting toxicity based on a single mechanism. the effects being detected here are relatively non-specific: while many of the toxins are known to interact with proteins, they typically interact with many proteins, and toxic effects often cannot be attributed to a specific molecular interaction. this is illustrated by the exploratory analysis in table  <dig>  table  <dig> shows the result of correlating unbiological with three conventional toxicity endpoints and two pharmacological ones. herg toxicity is a significant risk factor for cardiac toxicity in pre-clinical drug candidates, and is detected by screening for blockade of the herg ion channel in cells  <cit> . oestrogenic potential is a common ecotoxicological toxicity measure, and is measured here by binding to the oestrogen receptor  <cit> . tadpole narcosis is a whole organism measure of both central nervous system penetration and effect on a select set of neurotransmitter receptors  <cit> . all three are therefore mechanism-based measures of toxicity, and all three show weaker correlations with ub <dig> and no correlation with ub <dig>  an initial statistical analysis of the distribution of ub <dig> and ub <dig> in the molecules used for the analyses in tables  <dig> and  <dig>  suggests that the molecules analysed for tadpole narcosis may be atypical of the other sets in the study, and so the lack of correlation found between ub <dig> and tadpole narcosis may be a result of an unrepresentative set of chemicals. the other sets of chemicals whose analysis is summarized in table  <dig> appear similar in overall ub <dig> and ub <dig> properties to those whose analysis is summarized in table  <dig> table  <dig> correlation of ub with other biological endpoints

rank correlation coefficient of three target-related toxicity measures and two pharmacological endpoints with unbiological measures ub
 <dig> and ub
 <dig>  column 1: pharmacological endpoint. column 2: number of data points. columns  <dig> and 4: correlations with ub
 <dig> and ub
 <dig> respectively. significance flags are the same as in table 1


data sets used in this paper



drugs can also be toxic in the wrong place or dose. in table  <dig> i also show that ub is uncorrelated with the potency of compounds for just two drug targets , antihistamines and nsaids that inhibit cycloxygenase- <dig>  neither show any significant correlation with ub.

i do not claim that other toxicity or pharmacology endpoints will not be found to correlate with unbiological. the examples in table  <dig> are included to make the point that ub is correlated with broad, whole-organism toxicity, not necessarily with target-specific mechanisms.

reasons for variability of correlation
table  <dig> provides robust statistical evidence for believing that unbiological is correlated with whole organism toxicity. however the degree of correlation varies substantially between species, as does the statistical significance of that correlation. this could be due to genuine biological differences, or differences in the chemical space being sampled. the issue of chemical space coverage is significant. for example, an initial study suggested a strong correlation of ub with the potency of phosphodiesterase-4b inhibitors . however this was based on analysis of the data in two qsar studies on pde4b inhibition. the chemicals in the two studies were very similar to each other . in effect, ub was being used to classify compounds into the two studies, one of which was developing a much more potent drug series than the other. therefore ub could identify more potent pde4b inhibitors, but for the trivial reason that it was identifying two studies looking at two classes of chemicals. when a wider set of pde <dig> inhibitors was analysed, the correlation was reduced. <dig> it seems likely that, as with other qsar methods, unbiological will work best on a chemical set spread uniformly across the chemical space that is to be analysed. bias in the molecules that happen to have been investigated to generate the data analysed here may be a cause of the differences in correlation of ub and toxicity. this can only be addressed by collecting a more systematic set of multi-species toxicity data on defined chemicals. data filed for the reach legislation  <cit>  may provide such a data set in the future.

statistical significance is a function of sample size. it is not practical to collect hundreds of toxicity endpoints from all the species involved, and not desirable to discard endpoints from species that have been extensively tested. therefore this aspect of variability has been retained in the study.

threshold for correlations is millimolar concentration
many of the correlations summarised in table  <dig> are statistically robust but relatively small. direct plots of ub vs. toxicity are usually uninformative. a good and strong statistical correlation can be shown for data that does not appear ‘correlated’ to the eye – this is the reason for performing correlation calculations. however, for some of the more strongly correlated data sets containing relatively few data points, such as those plotted in fig.  <dig>  the correlation between ub and toxicity appears stronger for weakly potent toxins than for highly potent ones . this has also been observed for the correlation of structural redox with toxicity  <cit> .fig.  <dig> unbiological vs. toxicity for selected organisms. plots of unbiological vs. toxicity endpoints for three of the data sets analysed here. each dot represents the ld <dig>  vs ub value  for one compound. ub is calculated as described in the methods section and appendix  <dig>  in summary, ub represents the largest region on a molecule that is not present in a metabolite, as defined by a 5-atom  or 6-atom  overlap. a: ub
 <dig> vs. ld <dig> for chlorella, b: ub <dig> vs. ld <dig> for rainbow trout, c: ub
 <dig> vs. ld <dig> for lemna, intoxicated with compounds other than herbicides



for some of the data sets there are a sufficiently large number of data points to split the data into potency bands and correlate these independently with unbiological. the results from this analysis are shown in fig.  <dig>  for consistency, toxicity data was binned into bands of round number log units of ld <dig> or ec <dig>  which results in different numbers of data points in each bin, and hence different levels of significance for the resulting correlations.fig.  <dig> correlation of unbiological with toxicity by potency band. correlation of ub
 <dig> and ub
 <dig> with different toxicity endpoints. for each data set, the data on a compound was binned for compounds having different ec <dig> or ld <dig> values, and the correlation of the toxicity endpoint with ub was correlated with the toxicity values within that concentration range. thus for rat oral ld <dig> , toxicity was binned into log < − <dig>  log between − <dig> and − <dig>  log between − <dig> and − <dig>  and log > − <dig>  all values in molar. correlations were calculated for each of these four data sets. error bars are 95 % confidence limits for the correlation, based on the number of data points in each bin. for all panels: x axis = concentration bins, in log . y axis: correlation of ub and toxicity within that data sub-set. panels a: to f: − rat oral toxicity, mouse oral toxicity, rat carcinogenic potential , nci cell line cytotoxicity, fathead minnow toxicity and tetrahymena toxicity



figure  <dig> shows trends in most of the larger data sets that lower potency toxins have better correlation with ub than higher potency toxins. for the nci cytotoxicity and fathead minnow data  there is little trend for ub <dig>  although for ub <dig> only the highest concentration data  shows a statistically significant correlation . for all other data sets, both ub <dig> and ub <dig> show negative correlation of ub with concentration  only for the highest concentration band. figure  <dig> confirms, for these data sets, that the correlation of unbiological with toxicity is an effect seen primarily in compounds that have low intrinsic toxicity.

this observation may explain the failure to observe a correlation of ub with toxicity in saccharomyces. in the data set analysed here, saccharomyces was tested for the effects of chemicals at six concentrations from  <dig>  um to  <dig> um. thus no chemical with an ic <dig> of > <dig> um could be detected in this screen, and so the ic <dig> values analysed here are all below the threshold at which a statistically robust correlation of ub and toxicity would be expected.

mechanism of ub correlation with toxicity
the observation that a simple and non-specific measure of chemical structure like ub might be correlated with toxicity is unexpected. the observation that the correlation is more pronounced for weak toxins is, on the face of it, baffling. qsar measures of biological potency are usually more effective for the most potent agents – whether toxins, drugs, hormones or other effectors. the findings in figs.  <dig> and  <dig> therefore require a mechanistic explanation for the correlation of ub with toxicity that operates at millimolar but not micromolar concentrations. this second part of the paper, and the results shown in it, address the plausibility of a potential mechanism.

the mechanism i propose here is that many, probably most chemicals will interact with some, maybe many, components of the cell at millimolar affinity.

the distinction of small molecules into ‘ligands’ and ‘non-ligands’ is a convenient classification for small molecules with respect to their effects on a specific protein, but it is a fiction not reflected in chemical reality. it suggests an absolute distinction between ‘binding sites’ and ‘non-binding’ sites. in reality, a small molecule can interact with atoms across the surface of a protein, and can often bind to proteins in more than one conformation and at more than one site . only those sites which are unique and bind molecules with much higher affinity than any other site are called ‘binding sites’. the reality of the other sites that can, and do, interact weakly with small molecules is however illustrated by experimental evolution studies, where new protein functions are typically created by selecting new modes of interaction between protein and ligand from weak interactions already present in the original protein  <cit> .

there is a substantial body of literature that suggests that many, maybe most small molecules can interact with many, possibly most proteins at millimolar concentration. i summarise three lines of such evidence below. this data will be very familiar to those involved in pharmaceutical screening programmes.

high-throughput screen data
high-throughput screening  is a common route to discovering novel biological function in large libraries of chemicals. in an hts campaign, a very large library of chemicals  is tested at one or a few concentrations in an entirely automated assay designed to give a simple, semi-quantitative measure of whether a chemical interacts with a specific molecular target. compounds that reach a threshold of activity  are then taken on for further study. such large screening programmes are a common approach to drug discovery  <cit> .

typical reports of such screens report a ‘hit rate’ of between  <dig>  and 1 %, and report finding ‘hits’ that bind to the target protein with micromolar affinities  <cit> . most freely available databases of the biological effects of molecules also assume that compounds either bind to a target with micromolar affinity or better, or that they do not  <cit> . such databases imply that ‘not binding’ at the tested concentration means not binding at all. however this literature is misleading. more detailed reports of hts campaigns routinely report widespread “non-specific” interaction of small molecules with protein or cellular targets . assay conditions, screening concentrations, detection thresholds and other factors are tuned to achieve a hit rate of < <dig>  % in what in reality is a continuum of binding.

usually the raw data behind an hts screening programme is not available – only summary statistics and the data on the ‘hits’ is published. however the reality of hts binding can be illustrated with hts data available from the national cancer institute, which has published detailed screening data on a library of ~ <dig>  compounds for anti-hiv effect and ~ <dig>  compounds for anti-cancer effect  <cit> . figure  <dig> summarises this data in terms of the chance that a compound will be found to have a positive effect on a screen at a particular concentration. not all compounds are tested at higher concentrations, so fig.  <dig> plots the fraction of compounds that have an effect at a concentration as a fraction of the compounds tested at that concentration. the result is clear. there is a continuum of affinity in this essentially random set of chemicals for their molecular targets, and while the chance that a compound has an effect at micromolar concentration is low, the chance that it has a biological effect on mammalian cells approaches  <dig> as the concentration approaches 10 mm.fig.  <dig> nci screening data analysis. x axis: concentration. y axis: fraction of compounds in nci public datasets on cell-based screens that show inhibitory effect in that assay as a fraction of number of compounds tested at that concentration. results are binned into concentration bins on a log scale, each bin representing log  =  <dig> . blue diamonds: hiv screening data  <cit> . red squares: cell line screening for anti-cancer effect  <cit> 



fragment-based screening
fragment-based screening  seeks to identify small molecules that bind with relatively low affinity to proteins, and then combine these into larger molecules that bind with greater affinity . fbs actively looks for high micromolar or low millimolar affinity of small molecules to proteins. it is a commonplace for researchers in this field that many small molecules  bind to most proteins at low millimolar concentrations. for example,  <cit>  comment that “novice users  are often surprised to see how often small molecules bind indiscriminately to proteins when compounds are assayed at high concentrations”. the data they give suggests ~75 % of a  <dig> compound subset of the maybridge ro <dig> library bound equally well to two different targets at high micromolar to low millimolar concentrations. congreve et al.  <cit>  find that 90 % of compounds in their library have some binding at mm affinities. hubbard  <cit>  found a ‘hit’ rate of between  <dig>  and  <dig>  % when measuring small molecule binding to proteins at  <dig>  mm by nmr. giannetti  <cit>  reviewed  <dig> different fragment-based screens, and report that all show ‘non-specific’ binding at affinities of  <dig> – 4 mm, although the highest affinities found ranged over three orders of magnitude in the different experiments. spurlino  <cit>  found that between  <dig> and 50 % of a library bound to target protein crystals at 5 mm .

other non-specific binding observations
non-specific interactions are a fact of life for pharmaceutical researchers, even among molecules that are selected for their specificity of action. even in launched pharmaceuticals, supposedly selected for their singular, specific interaction with one target or target class, multi-target interactions are being recognised as the rule rather than the exception  <cit> . labella commented “the non-specificity of drugs is a generally acknowledged truism” over 20 years ago  <cit> , with genome-scale testing of molecules confirming that nearly all small molecules bind to multiple proteins  <cit> . such ‘non-specific effects’ now being accepted as a critical part of drugs’ actions  <cit> . houk et al. review a range of studies of binding of small molecules to proteins and cyclodextrin mimics of protein binding sites, and find an average binding affinity of ~ <dig>  mm  <cit> .

molecular mechanism of low affinity binding effects
it is worthwhile touching briefly on potential mechanisms of millimolar binding of compounds to proteins, and the likelihood that this will materially affect the protein’s function. again, we must challenge the conventional model of a ligand binding to a ‘binding site’ on a protein. structural studies have shown that many proteins can bind a diversity of chemical structures through adaptation of their structure . many proteins exist in dynamic equilibrium with partially or completely unfolded structures, some being dominantly disordered . post translational modification  <cit>  or ligand binding  <cit>  can switch proteins from a disordered to a more ordered state, switches which can be related to their regulation and function  <cit> . proteins can also have multiple ordered, metastable structures , and different folding states can be selected by ligand binding and have significantly different biological function . there can also multiple folding paths leading to each of those states .

a molecule that binds even weakly to one folding state of a protein and not to another will bias the population of protein folding states by stabilising the bound state over the others . if one of the structures in the spectrum of structures has a function absent from other structures, then binding of the small molecule will change that function by changing the amount of the functional conformer. the binding need not be ‘tight’, and may not even be detectable on the canonical crystal structure for the protein, but will nevertheless affect function in the cell.

in conclusion, it is found in many types of experimental systems that all, or nearly all, small molecules interact with many proteins with low millimolar affinity, and these low affinity bindings can have significant biological affect through modulation of the population of structures adopted by a protein. this observation leads both to an explanation of the mechanism of millimolar toxicity, and to its correlation with unbiological.

proposed mechanism of correlation of ub with millimolar toxicity
selection against protein binding of metabolites
the observations above that many molecules interact with many cellular targets at millimolar concentration, and that these are likely to have significant biological effects, raises an obvious question. if many molecules can interact with many proteins at low millimolar levels, and such interaction has adverse effects on the cell, and many metabolites are present in the cell at low millimolar concentration, then why does the cell not poison itself with its own metabolites?

a plausible explanation is that the proteins  have evolved to avoid interference from the cell’s normal constituents. a protein that needs to interact with  an α-amino acid will evolve a binding site for that α-amino acid. a protein that does not require interaction with an α-amino acid for its function may nevertheless have a low affinity binding site for an α-amino acid in one of its conformers by chance. if this low affinity binding site has an adverse effect on the cell, then it will be selected against. in short, any non-specific interaction of the cell’s normal constituents will be selected against just as there will be positive selection for beneficial interactions.

thus we would expect any binding site or pocket on a protein that could bind an amino acid to be selected against unless that interaction provided a beneficial effect on the function of the protein. any compound that ‘looked like’ an amino acid  would therefore also not find binding sites on that protein. similarly there would be selection against random or fortuitous binding sites for the chemical features present in sugars, lipids, phosphate esters and other common structures in metabolism. however there would be no selection against low affinity, random binding to flurocarbons, organosilicon compounds or other chemicals quite different from anything normally in a cell. these, therefore, would be free to bind to any cellular protein if, by chance, a binding site happened to exist for them. the larger the segment of the xenobiotic that was unlike the chemistry of life, the greater the potential affinity for such a non-canonical binding site. the association of unbiological with toxicity shown in table  <dig> is therefore a consequence of the failure of biochemistry to be selected to avoid random binding of chemicals that the cell does not usually encounter.

testing the hypothesis with molecular docking
such a hypothesis has not been tested experimentally as far as i know, except in so far as low affinity binding of small molecules to proteins is commonly observed as noted above, although it has been observed that d-amino acids are mildly toxic to a wide range of microorganisms compared to their l-enantiomers  <cit> . in principle the low millimolar binding of small ligands to proteins could be tested computationally using molecular docking software, by trying to dock molecules known to not be ligands for a protein to that protein. large-scale protein docking exercises do show that the majority of small molecules dock to target proteins with low millimolar or high micromolar affinity . unfortunately, the low-affinity predictions of these exercises are unreliable . as we do not know where the ‘binding site’ for a non-ligand might be, the test non-ligand must be docked to the whole protein, this provides such a large number of potential interactions that the software cannot reliably discriminate actual likely binding sites from implausible ones. figure 7a illustrates this, docking  <dig> drugs with the abl receptor. there is a strong trend for larger molecules to be predicted to have a higher affinity for abl , but the largest molecules are predicted to bind as tightly as some bona fide inhibitors, despite having no known inhibitory effect on the enzyme.fig.  <dig> docking small molecules with entire protein structures. a. binding of  <dig> known abl inhibitors, compared to the binding of  <dig> drugs or natural products not reported to have any effect on abl kinase activity. y axis: vina output binding energy. x axis: molecular weight. b. comparison of the predicted binding energy of  <dig> alpha amino acid and their alpha-n methyl alpha-carboxymethyl derivatives with the binding energy of equivalent beta amino acids and amino acid derivatives to abl, aldolase, hiv protease, pde2b4b and ppar gamma structures.. excluded amino acids were: glycine, which has no beta amino acid, beta alanine which is a metabolite in its own right and so was excluded, beta aspartate and asparagine which are the same as alpha aspartate and asparagines, and beta threonine which is likely to be unstable and so not a realistic chemical structure. error bars are 95 % confidence limits 



if we confine ourselves to comparing molecules of the same size and atomic constitution, then some of the artefactual results shown in fig. 7a might be avoided. figure 7b shows the comparison of the predicted energies of binding of α-amino acids compared to β-amino acids to five mammalian proteins, selected to represent a mix of functional classes of proteins for which multiple structures and many authentic ligands were known. α-amino acids are core metabolites in mammals, β-amino acids are not part of normal mammalian metabolism with a couple of exceptions. for some but not all proteins tested, α-amino acids are predicted to bind with lower affinity than β-amino acids, as predicted by the hypothesis. the exceptions found here are hiv protease  and ppar-γ . repeating this exercise with more sophisticated models that took the dynamics of proteins as well as ligands into account  might produce more useful results.

conflict with pharmaceutical experience
the suggestion that molecules that are not like biological molecules are more likely to be toxic appears paradoxical to the pharmaceutical chemist, as many drugs have potent  effects precisely because they are close molecular mimics of known metabolites. thus, steroid drugs are potent precisely because they mimic natural steroids, dideoxyribonucleotides block viral dna synthesis because of their mimicry of normal nucleosides  <cit> , penicillins mimic peptidoglycan components  <cit> , and so on. however these molecules have been selected by evolution or by chemists to both mimic a specific biological effector and not to have any other effects than their target pharmacology. it is a truism of drug discovery that achieving this combination is extremely hard, and that unexpected or ‘off-target’ effects are a common cause of failure in drug discovery and development programmes . some of these effects are due to the close structural similarity between members of families of proteins, so that a drug selected to bind with high affinity to one target will be likely to bind to another, structurally similar target. however other ‘off-target’ effects are not obviously related to the known structural similarity of the ‘off-target’ proteins  <cit> . yamanishi et al.  <cit>  suggest that this is because small regions  confer protein binding. a substantial fraction of the effort in drug discovery programmes is tailoring the specificity of the candidate drug to bind to a small number of targets, and many launched drugs actually bind to more than one protein family . drugs are therefore a special case, the result of extensive selection by man to fit with biology. the same explanation is true for the observation that chemicals that are not metabolites but fall within ‘biochemical space’ have a higher chance of being toxic even in the absence of selected pharmacology  <cit> .

detoxification and resistance
a second apparent conflict with pharmaceutical experience is that organisms can and do tolerate a wide range of compounds that are toxic through tolerance, detoxification, and resistance mechanisms. the first two of these are less important to my general thesis than they might appear, and the third actually supports it.

tolerance to a toxin or drug is almost invariably caused by changes in the organism’s physiology to compensate for the action of the drug or toxin. this is classically true of pharmacological agents such as alcohol, nicotine or heroin, but also to classic toxins such as arsenic. mechanisms that oppose the effect of the drug or toxin are induced to restore a more normal physiological state. this is unrelated to the mechanism of intoxication in the first place.

detoxification is a broad approach to removing toxins from an organism. it usually relies on enzymes  or transporters  with very broad substrate specificities. it can also involve physical separation of the toxin into a defensive cell compartment. compartmentalization is a common strategy for cells to sequester damaging metabolic chemistry from cell components that that chemistry might damage . sequestering misfolded proteins, damaged cell components or toxins can be seen as a form of ‘internal exile’, analogous to the export of these materials.

acquisition of resistance be through one of two broad mechanisms. detoxification mechanisms can be increased, often by mutation that increases expression of the relevant protein – this is a common mechanism of acquisition of drug resistance in cancer cells and in bacteria  many, possibly most proteins would have to be mutated to evade toxicity. the mechanism of organisms’ resistance to chemicals other than drugs has not been reviewed systematically, so we do not know if this prediction is true.

CONCLUSIONS
i have shown above that molecules that contain segments that are not similar to common components of metabolism are more likely to show toxicity at millimolar levels than compounds that have chemistry similar to life. i relate this to the widespread observation that many chemicals bind to many proteins at low millimolar levels, and that this can materially affect the function of those proteins.

this observation is an explanation for the observation that the chemistry of life occupies a small corner of the chemical space. in order to function, the components of the cell must interact with each other appropriately, both with functional interactions between the macro-molecules and metabolites of the cell and with the absence of unwanted interactions. each new chemical added to metabolism requires adaptation of the whole proteome to accommodate the new chemical. once a complex, self-perpetuating metabolism has evolved, adding to it will be an increasingly demanding evolutionary task, not an impossible one but one that the pragmatic mechanisms of evolution will tend to avoid.

this finding has two implications. firstly, unbiological could be used as a measure of the chance that a new molecule is toxic. such broad toxicity predictions are less useful than predictions of specific mechanisms of toxicity, and unbiological specifically does not provide a mechanistic explanation. it is also only as statistical estimate. from the data analysed here, ub <dig> or ub <dig> could be used to give an order-of-magnitude estimate of the potency of a low-potency toxin, but would say nothing about high potency toxicity. it is possible that coupling ub with other measures  <cit>  might give more accurate estimates. as an initial screen for ‘drug-like’ properties , however, such a statistical indicator could find a use.

in this application of predicting toxicity, a strong limitation of the analysis presented here is that it takes no account of the concentration of metabolites in the cell. metabolic intermediates present at nanomolar concentration are given the same weight in the ub calculations above as common components such as glucose or glycine. one would however expect the selective pressure on proteins to avoid binding glucose to be much stronger than the pressure to avoid binding metabolites present at nanomolar concentrations.

an extension of this work would therefore include a concentration term in the calculation of unbiological. this would include two components – consideration of the differing metabolomes of different cells or organisms, and quantitative consideration of the concentration of metabolites in an organism. in this study, a single collection of metabolites  was used to define unbiological. i expect that predictions of toxicity based on the actual intracellular metabolome of a specific species would be more accurate for that species  than this generic approach. this is however a substantial undertaking, involving re-calculation of most of the comparisons presented here for each species, and so has not been attempted in this paper: my goal here is to show that this approach is theoretically and practically interesting. it might also be valuable to weight the contributions of metabolies to the ub calculation according to their intracellular concentration, although this is fraught with difficulty as intracellular concentrations of metabolites are very hard to measure, and in any case are modulated by the protein binding that this study postulates occurs promiscuously and universally. future work could also explore the size of the overlap necessary to define ub: again, this would be doable, but time-consuming, and so has been left for future work.

the second implication of this work is in the field of metabolic engineering and synthetic biology. engineering an organism to produce a new chemical or execute a new metabolic pathway has been thought to require the expression of suitable enzymes to make the chemical and any intermediate or precursor molecules at sufficient concentration, efficiency, and from suitable feedstock. the rest of the cellular machinery is generally viewed as a ‘chassis’ on which to attach these changes . for chemicals or gene products produced at low concentrations this is likely to be true  <cit> . however if the goal of the engineering is to produce a chemical at substantial levels  <cit> , then the analysis in this paper suggests that many aspects of the cell must be engineered, especially if the chemical to be produced is very different from one usually present in the cell.

