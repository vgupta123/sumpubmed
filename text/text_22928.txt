BACKGROUND
the discipline of bioinformatics makes use of varied data resources that provide access to both experimental data and the results of analyses over such data. there are many hundred resources in the public domain  <cit> ; individual laboratories maintain their own collections by either building on local data or collecting relevant results of specific studies.

duplication of facilities occurs amongst interfaces to many such repositories. typical functionalities include the ability to:

• browse top-level collections in a repository, such as listing experiments recorded in a microarray database;

• evaluate simple parameterised searches over the contents of repositories, such as using thresholds when running identification algorithms over mass spectrometric data;

• use predicates applied to selected fields to construct searches over repository collections, such as using resolution values to retrieve only certain structures from a protein database;

• and evaluate queries over repositories using query languages specific to those repositories.

repositories do not often provide all capabilities, and some repositories provide specialised interfaces, such as data-specific graphical viewers. however, where capabilities are similar amongst interfaces, these interfaces are routinely constructed in a bespoke manner.

the central role of data repositories in bioinformatics seems secure, given the ever-growing numbers of high-throughput experimental techniques. also, there will be a need for laboratories to manage large and increasing quantities of locally produced experimental data before any associated analyses can be submitted for publication. furthermore, the bioinformatics community increasingly encourages its members to produce data sets that may be more easily exchanged within the community than has previously been the case. to further this aim, various organisations are developing standards using models that describe the storage, structure and content of laboratory data. the need to supply data that conform to such standards will increase the dependence of experimental laboratories on data repositories. such repositories may be accessed within the laboratory as well as by collaborators or the wider research community.

developing effective interfaces to bioinformatics resources requires consideration of the limitations imposed by the working environments in which these interfaces are created. laboratories may second personnel to maintain data repositories. these repositories often begin as prototype services  <cit> . laboratory personnel are trained in their domain science but are rarely trained software engineers. moreover, repositories may be designed for specific, short-term goals, but then may come to be depended upon by a larger community that has different goals, necessitating software evolution. such development activities are often of an ad hoc nature and yield interfaces that are not robust, and are difficult to evolve or maintain once the associated personnel have left.

the focus of this paper is the development of a systematic, model-driven approach to the construction of user interfaces to bioinformatics repositories. with this approach, many aspects of software infrastructure are specified using declarative models, and executable programs are generated from such models. this approach adapts a design paradigm called the model driven architecture   <cit> , which has had less exposure in bioinformatics than in other domains.

the remainder of this paper describes the model-driven approach to software development. we indicate how this has been adopted in the development of a system called pierre, which uses models to construct and generate user interfaces to bioinformatics resources.

model driven software development
spectrum of approaches
software development methods can be characterised by the relationship between a model and an application's code base  <cit> . these methods are ordered, below, by the increasing role of models in descriptions of software behaviour.

• code-only: no models describing the system are developed. in this approach, the code is the only artefact that results from a development cycle. any design abstractions used are expressed solely in the structure of code components.

• code-visualisation: uses software tools that associate graphical modeling notations with views of code bases. such tools allow programmers to manipulate notations rather than code. for example, button elements could be altered in size graphically, which has the effect of setting dimension properties in the code.

• round-trip engineering : uses an abstract model of the system to help guide development of the code base. the model is manually implemented during the design phase prior to the implementation. designs that are captured in models can be enhanced by refinements in implementation, and models should reflect such refinements. in this approach, models must be synchronised with their associated code bases, and the model serves as part of the system-level documentation.

• model-centric: the models are developed in sufficient detail to allow them to be used to derive the code base. developers refine the models through a series of transformation steps that ultimately yield program code.

• model-only: models are developed in sufficient detail to allow code bases to be derived from them. models are refined through a series of transformation steps, resulting in program code. this approach is employed when a project's goal is to develop models for later use in creating implementations.

user interfaces to bioinformatics resources are developed in environments that typically do not easily facilitate these approaches. prototyping can identify short-term requirements for development, and the code written for these is often not well-structured. experimental environments that evolve rapidly emphasise the exploration of new techniques and not the support of software products. within such environments, prototyping is an activity that works well. however, prototypes are often used as the end product, rather than as a stage towards an end product. in this event, requests for capability enhancement can result in code bases that are difficult to maintain.

code visualisation is a technique that provides a graphical framework within which a code base is developed. however, this technique may be too limited to capture important features of the design. for example, some visualisation tools focus on allowing developers to build user interfaces using predefined classes for features such as buttons, scroll bars, and text fields. developers provide the detailed functionality of the applications by filling in stubbed call-back methods associated with these features. in such an approach, however, rather little of the functionality of the application may be represented in the visualisation.

rte assumes developers have enough skill, time, and discipline both to create models and to synchronise them with code bases. this approach may also require developers to create an analysis model, a design model, and a code base. rte is unlikely to be sufficiently responsive for use in rapidly changing contexts, such as bioinformatics laboratory environments.

the model-only approach is used by standards bodies in bioinformatics for the purpose of producing models that describe data sets for a particular biological domain. their aim is to produce models that describe the data sets for some particular biological domain  <cit> . with this approach, developers are delegated to creating and maintaining data repositories and interfaces, both of which are expected to be compliant with a model. however, this approach leads to software applications that evolve independently of community models.

the model-centric approach has a number of characteristics that are well suited to environments in which bioinformatics tools are produced. model-centric applications are designed to accommodate change: model changes, which are reflected in code changes. this process also tends to be done automatically, which helps to reduce the number of errors in code bases. distinctions can be made between modeling and developing, but with this approach, modelers may find themselves engaging in development activities. this allows laboratory personnel to focus on making contributions based on domain knowledge rather than attempting to perform software engineering. when additional programming is required, it can focus on customised features rather than on generic ones. the model-centric form of development supports rapid prototyping activities that allow end-users to validate models. this validation is done by means of feedback on automatically generated applications. the result of using this approach is that time spent prototyping is reduced and time spent adapting applications for production environments in increased.

model driven architectures
the model-centric approach is embodied by the object management group's model-driven architecture   <cit> . the main aim of mdas is to support software development through the application of transformations to various kinds of models. these models are listed below in order of their decreasing level of abstraction.

• computation-independent model : represents concepts from domain experts' perspectives. for example, concepts such as protein, modification, or gel may be used by the cim to describe proteomics schemata.

• platform-independent model : describes system aspects that are independent of deployment activities. pims describe tasks supported by software applications but do not include implementation details. examples of pim concepts include editing, searching and browsing

• platform-specific model : describes implementation-specific details of given deployment environments. an example psm could include details of how specific features are supported in web applications.

the term platform can have various meanings, and can include one or more system aspects such as operating system, network configuration or programming language. more important than the definition of platform is the notion that the pim addresses application logic and separates this from the psm, which addresses implementation details. a central idea of mda is that transformations can be applied to convert a cim to a pim and finally to a psm. the psm is supposed to contain sufficient information about domain concepts, software features and platform details to facilitate the automatic generation of software code  <cit> .

model-based user interface development environments   <cit>  have been developed for user interface development using techniques that are closely related to omg's mda but that either do not follow omg explicitly or predate omg. for example, the midas project  <cit>  proposed a model-driven methodology for the development of web information systems , and teallach  <cit>  supported model-based user interface development for databases. however, mbuides have not been widely adopted in practice, probably for a combination of reasons. these reasons may include the following factors:  the collection of models used to develop comprehensive interfaces is complex;  the emphasis of many proposals is task-model centred, suiting only certain styles of interface; and  models for describing user interface functionality have often been poorly integrated with other models used as part of the software development process. these issues are addressed in this paper by adopting model-driven techniques in a narrowly defined domain. in this way, models are straightforward, tasks are drawn from a fixed set, and data repositories are accessed through consistent interfaces.

a few projects have applied this paradigm specifically to bioinformatics. for example, memops  <cit>  presents a framework for scientific data modeling and automated software development. this framework was originally developed to suit applications for nmr spectroscopy, although its authors claim it is general enough to apply to other domains. the focus of memops appears to be the application of model-centric approaches to automatically generating software that can read and write data expressed in various formats. the framework promotes the idea of client programs interacting with an application program interface  rather than directly with a particular data format.

this paper's focus is the use of the model-driven approach, as supported by pierre, for automatically generating interfaces for accessing data repositories. this follows on from earlier work by the authors on the pedro system  <cit> . pedro generates data capture forms directly from an xml schema, which describes the structure of data to be captured, and from additional configuration information provided by data modelers. examples of configuration information are context-specific help and controlled vocabularies, both of which can be used to guide data capture. however, pierre adopts a model-centric approach more comprehensively than does pedro. pierre supports an interactive design phase through which pims are developed. these pims may, in turn, be associated with psms for both creating different styles of interface and accessing different kinds of repository.

methods
this section describes the scope, design, implementation and use of pierre. success in applying mdas has so far depended on the following:

• use of declarative models for the identification of use-case patterns that lend themselves to description;

• development of models that directly capture common behaviours;

• design of effective interfaces between models and existing components;

• and provision of effective tools for model construction and application generation.

in pierre, we address these aspects by:

• identifying four common access patterns to data repositories: browsing; simple searching using canned queries; advanced searching using user-defined filtering based on predicates; and expert searching based on direct use of query languages. individual interfaces can support any combination of these categories of data access.

• developing models specific to each data access category, whereby application-specific interfaces are described using a manageable number of modeling decisions.

• designing an open architecture that allows pierre applications to interface to existing data management systems, security models and ontology services.

• providing a service configuration tool that supports both immediate review of interfaces and generation of applications implementing different interfaces. the interfaces are supported by the underlying model.

an example of a pierre deployment is the user interface to the e-fungi database, which contains sequence and functional data from multiple fungal species. from the web version of the e-fungi deployment, figure  <dig> illustrates the browse interface, which lists properties of the genomes in the database, and allows users to navigate to obtain further details. figures  <dig> and  <dig> illustrate the simple search interface. figure  <dig> shows how a list of canned queries is made available, each of which is associated with a form that collects the parameters for a search, as illustrated in figure  <dig>  figure  <dig> illustrates the advanced search interface, in which a search is configured. this is done by identifying a collection over which the search is to take place and the predicates that are to be used to filter the objects in the collection. figure  <dig> also shows the advanced search interface, but this time for the stand-alone application.

RESULTS
pierre as a model-driven architecture
the use of the pierre system involves two phases: a rapid prototyping phase and a deployment phase. figure  <dig> shows how a service designer builds a service using the service configuration tool; the numbers in brackets are explained below. the tool is driven by concepts provided by a computation-independent model  which is expressed as an xml schema  <cit>  and a platform independent model  which is expressed in xml. the cim contains domain concepts such as "protein", "gene", "sample" and "experiment" that are relevant to the application. the cim typically describes the schema of the database to which an interface is being provided. these concepts can be associated with various form generation properties described in the pim. for example, the pim could describe whether a form field supported free-text entries as well as selection based on existing values. it could also describe properties of features such as canned queries, queries that could be dynamically constructed by users and a facility for submitting free-text queries.

these two models provide concepts that drive the operation of the tool . a service designer uses the service configuration tool to iteratively build a description of how the dissemination service should behave . that is, the pim is created using the service configuration tool. the designer can then auto-generate a representative service to show service users . this service communicates with a fake data repository that returns random data. the service is intended to provide enough information for service users to evaluate the prototype  without requiring that a finished data repository has already been developed. the users convey their feedback back to the service designer , who then modifies the definition of the service. when the service users accept the prototype, the service designer can use the configuration tool to generate a definition of the service.

the deployment phase is shown in figure  <dig>  during or after the service is prototyped, the repository designer creates a live data repository . pierre has been used with xml databases containing cell image metadata and proteome experimental results, a relational database containing medical data, and the e-fungi object database. the service designer can use the service configuration tool to auto-generate a human readable description of what the service can do. this functional specification can aid the repository designers in their task of creating a repository that responds to the needs of the service users. when the back-end of the service is completed, the service designers can configure the service to substitute the fake repository for the live one. they can then use the service configuration tool to automatically generate multiple deployment forms  based on the same service definition .

in mda terminology, each deployment is regarded as a platform-specific model . the approach advocates expressing a psm as a configurable model that can be used to auto-generate code. however, in pierre, properties of the psms are fixed and reflected in code rather than in formal models. this is done to make the service configuration tool simpler to use by the service designers.

the service configuration tool supports the tasks described above. its top-level interface is illustrated in figure  <dig>  which indicates the different capabilities that the service developer can configure. the use of the service configuration tool to design a simple search is illustrated in figure  <dig>  and the design of an advanced search is illustrated in figure  <dig> 

users will eventually endorse a prototype service, which will become the initial production version, allowing the service designer the option to enter the deployment phase of development. the service configuration tool uses a description of the service to automatically generate an ant  <cit>  script. this script is then run and multiple deployment forms are automatically generated: web-based, stand-alone, text menu and command line. each deployment interacts with the live data repository through an api. this api can also be used by other software clients that wish to use data provided by the service. to support the integration of deployments in complex sequences of tasks, the stand-alone application can also be invoked as a component by other software clients. the web deployment that is generated is a folder that is meant to be placed in the web applications directory of a tomcat instance.

pierre as an open architecture
in the mda approach, generic program features are supported through model-driven activities and specialised program features are supported by a collection of services known as a service oriented architecture . developers customise an application by implementing one or more service interfaces as software plugins. the types of services that are supported represent aspects of the domain use case that warrant customisation. these areas were identified for data dissemination applications used in bioinformatics:

• reports: display results of querying and browsing; default representations are provided. service developers can augment standard representations for such things as new layouts or specialist visualisations for specific kinds of data, such as multiple sequence alignments.

• 'links: cross-references from pierre reports to other sources of information. a link may lead to an external information source or may implicitly cause more refined queries to be applied to the repository. service developers can augment standard types of links with navigation implementations. for example, the ability to navigate to a web page may be adapted so that links evaluate follow-on queries over the data repository.

• ontology services: ontologies or controlled vocabularies associated with specific search fields in simple and advanced search. ontologies may be maintained using different technologies, and service developers can augment the ontology services provided by pierre to obtain terms from custom ontology servers or formats. pierre's ontology services are managed using the pedro ontology services framework  <cit> .

• security: mechanisms used by applications to control the release of information. service developers can include custom mechanisms for authenticating users and for authorising specific tasks, such as the evaluating specific queries.

• validation: supplied by most pierre capabilities as simple form field type-checking, as in simple search and advanced search. service developers can augment the validation provided to support custom checks, such as verifying that keys comply with regular expressions or do not appear in external databases.

• data repository: the most important point of extensibility. all repositories are accessed by implementations of an abstract repository interface illustrated in figure  <dig>  repository designers have developed deployments that access relational databases , xml repositories  and object databases  through extensions to the data repository interface. furthermore, a single data repository service could access multiple data repositories, for example through some form of distributed querying infrastructure, although pierre itself does not directly support data integration.

these aspects of extensibility are supported as service classes within pierre. figure  <dig> shows how these services augment the behaviour of a deployment during the course of a query submission activity. initially, a query form is auto-generated by the pierre deployment. it may consult a security service to determine what form features are appropriate to display for a given service user . before specifying a query, the users may want to access context help information  which could describe the meaning of form concepts. as they fill in the form, they may want to mark up some fields with terms provided by one or more ontology services . when they submit the query, validation services  are invoked to check for any errors.

when the query is correctly specified, the deployment bundles the form values into an abstract query object  . the aqo holds a canned query and contains data structures that correspond to concepts defined in the pim. the aqo is received by a pierre service, which uses a published api to interact with auto-generated deployments as well as other custom deployments. the pierre service forwards the aqo onto the data repository , which executes the query and retrieves results from a database management system. the data repository may consult the security service  to determine what kinds of results are appropriate to show a given service user. the repository assembles results into a report  that is returned and displayed to the user.

the service user may access a link displayed in the report to request further information. figure  <dig> shows how an implementation of a report service renders the results of a search in tabular form. the link mechanism is represented by a link object, which may have different representations for different deployments. for example, it may present a hyperlink in the standalone or web deployment but may present a menu number in the text menu application. the pierre deployment will ask the report if it knows about a link object. if the link is not known to the report, it is assumed to be a link to an external information source . for example, in the web deployment, a hyperlink could refer to another web site. if the link is known to the report, the pierre deployment assumes the object represents a request to obtain more information from the data repository . the link object is forwarded to the data repository via the pierre service. the data repository uses parameters defined in the link to construct a follow-on query, and then produces a report in the same manner as before.

the aqo and pierre service are used to foster communication between the pierre deployments and the data repository. the remaining objects are all services that can be customised by software developers. pierre comes with default implementations for all services, although the implementation of the data repository typically requires some coding effort to tailor it for a specific application. in particular, the construction of a suitable top-level representation of the contents of a repository for the browse interface normally requires some manual coding, and the queries made available through the simple search interface have to be implemented by the developer. by contrast, the default implementations of advanced search and expert search can be expected to work with little configuration. for example pierre deployments supply data repository components for the advanced query interface that support translation from interactive representations to query languages of the underlying database. implementations of such translations have been developed for sql, jdoql  <cit>  and xpath  <cit> .

deployments
pierre has been used to create interfaces for three kinds of data repositories. pierre documentation for the service designer uses a tutorial model based on cancer patient medical records, the data for which are stored in a mysql database. documentation for pierre addresses several roles identified for the creation of a repository interface, and this documentation is available online or with the pierre download. the second use case was to rework the interface to pedrodb  <cit> , which is a database of experimental proteomics data captured using the model from  <cit> . this model is represented in an xml schema, and has been implemented using the exist  <cit>  native xml database system. the third use case was to develop the web interface to the e-fungi data warehouse. this data warehouse is used to support comparative analyses of fungal species and is an evolution of the gims  <cit>  database. the e-fungi use case has been implemented with an object database using the jdo application programming interface to fastobjects.

the results of applying the tool are encouraging. the successful deployment of the tutorial database shows that a system using an xml representation of the database can be applied to work with relational databases. the auto-generated web application used for pedrodb supports greater functionality than that described in  <cit> , and shows that pierre can be applied effectively over existing databases. here, also, pierre is used directly with native xml databases, which may become widely used for storing standardised data. the e-fungi interface confirms the utility of this approach for a diversity of both domains and data management technologies.

discussion
the objective of the pierre project is to use model-driven development techniques to achieve several defined goals. we want to support functionality requirements from multiple domains. we also want to reduce the amount of time spent on common interface programming tasks in the hope that the time saved allows resources to be better deployed to the specifics of projects. moreover, this project facilitates the development of applications that are robust enough to support the demands of a production environment. this section reviews pierre in the context of these criteria and discusses related work.

functionality
pierre produces data access interfaces that have functionalities comparable to those interfaces supported by many public bioinformatics databases . this is not surprising, as the features supported for model-driven generation in pierre are those identified by the authors as representing important recurring themes. pierre supports the inclusion of interface functionalities that are necessary, but not always sufficient, in many contexts. in principle, pierre could be used outside bioinformatics, but the requirements supported have been gleaned from studying user interfaces in bioinformatics, and we anticipate that there will be significant functionality gaps if pierre is deployed in unrelated application areas.

generic interfaces that support common behaviours cannot compete with interfaces produced by well-resourced specialised development activities, such as those associated with genome sequencing activities  <cit> . however, we contend that there are serious limitations to the development resources that many bioinformatics researchers are able to commit to the construction of interfaces to potentially important data resources; thus that pierre addresses a common need. in addition, if a site develops multiple interfaces using pierre, this will increase consistency between the interfaces, thereby reducing complexity and learning times for users.

developer resources
the system design methodology supported by pierre can save time in at least five ways. first, it reduces the time programmers spend manually coding prototypes. second, parallel development of the front and back ends of a query service is facilitated by the decoupling of front-end concerns from back-end concerns. third, the requirement to develop interfaces for common cases is removed. in practice, creating a data access application involves straightforward, but time-consuming, interface programming, often in environments with steep learning curves. fourth, the fact that pierre can generate deployments that use different delivery platforms removes the need to develop and maintain code bases for multiple platforms. fifth, as less code is developed for a specific deployment, the times both testing and fixing such code is reduced.

it is difficult to make general statements about how long it takes to develop a deployment using pierre. most of our current deployments were produced at the same time as the associated repository services, significant components from which can be reused in future deployments. however, we note that pierre supports incremental development, and that the time taken to develop a preliminary deployment can be modest. for example, to create a deployment over a relational database, the following steps are required:

 <dig>  create a cim that represents some or all or part of the schema of the database; a tool is provided for this purpose.

 <dig>  load the resulting cim into the service configuration tool, and generate a default deployment.

the default deployment will include only advanced search and expert search, but should be able to be created in a small number of hours. this assumes that the database already exists, the relevant software is installed, and the developer is familiar with pierre. thereafter, the creation of a browse interface involves a small amount of design with the service configuration tool, and the implementation in java of an interface provided with the repository service. depending on the complexity of the browsing to be supported, this task should take from a few hours to a few days. the development of a query for simple search involves a small amount of design with the service configuration tool, and the implementation in java of the associated search in the context of the repository service. depending on the complexity of the search to be supported, this task should take from a few hours to a few days. as such, having learned how to use the pierre system , a deployment over an existing relational database, including a top-level browse interface,  <dig> queries in the simple search, advanced search and expert search should be able to be developed in a small number of weeks. of course, a typical development activity involves significant effort on requirements capture, including iterative design steps. however, the work required on the implementation of a service comparable to the e-fungi interface illustrated in figures  <dig> to  <dig> should involve weeks rather than months of effort.

robustness
pierre generates most of a deployment's executable code. this allows for systematic testing of the code base to be conducted, and revisions, which are suggested by multiple deployment communities, to be incorporated in a structured way. furthermore, developer effort associated with a specific deployment is focused on certain tasks. this enables developers to take a systematic approach to testing of both custom analysis features and repository capabilities.

related work
the application of techniques from model-driven architectures has allowed pierre to improve the efficiency of interface development for bioinformatics resources. this section focuses on comparing and contrasting pierre with other generic infrastructures used for developing bioinformatics interfaces. generic infrastructures are defined here as those infrastructures that are not associated principally with a single data repository or a single domain within bioinformatics; we focus in particular on biomart  <cit>  and srs  <cit> .

like pierre, biomart supports development of customised interfaces to bioinformatics databases, including the construction of advanced search interfaces. the principal difference in ethos between pierre and biomart is that the latter is designed for use over relational databases implementing a variation of star schema models from data warehouses. as such, biomart encourages and exploits a specific way of representing the data over which interfaces are to be built, and thus may be less suitable than pierre for use with existing databases. given a suitable schema, biomart provides many configuration options, which cover aspects of security, report linking and output file formats. pierre provides fewer configuration options than biomart, but retains considerable flexibility through an open architecture with many extensibility points. while biomart provides a flexible infrastructure for development, it integrates the design of the repository and the repository interface more closely than does pierre. as such, we assess pierre as allowing repository designers greater flexibility in their choices by separating interface design and development from data management.

srs is a well established infrastructure, principally designed to support the development of navigational interfaces to flat-file repositories, although other data repositories can also be accessed using this infrastructure. however, srs continues to have a principal focus on linked collections of file-based resources, which are indexed to support efficient access and navigation. as a result, srs provides both management and integration capabilities, and thus focuses more on enterprise-level information management than does pierre. in contrast, pierre's principal use is to construct interfaces to individual data resources, often where these resources exist already and where the effort in creating or maintaining bespoke interfaces is felt to be problematic.

CONCLUSIONS
this paper has described an architecture that increases the efficiency of development of interfaces to bioinformatics data resources. this is done by identifying recurring requirements that such interfaces must support, and by adopting a model-driven architecture to support these requirements. developers use a service configuration tool as a means of manipulating the underlying model in order to specify interface characteristics for specific kinds of data. development efficiency is also increased by supporting an open architecture, whereby components may be replaced or extended to augment default behaviours.

the overall approach has been implemented in a system known as pierre. this, in turn, has been used to construct user interfaces to several bioinformatics data repositories implemented using different kinds of database management systems. the pierre system, with its model-driven approach, greatly reduces the amount of time spent on re-addressing the routine aspects of interface development. this enables domain experts to make meaningful contributions to the development process based on their true expertise.

availability and requirements
the pierre project is described at: . the pierre code base is maintained on source forge and is distributed under the academic free license. the software has been tested on windows-based environments and currently depends on jdk <dig>  and ant  <dig> . the tutorial repository requires that mysql is installed. automatically generated web applications work with an environment that uses tomcat  <dig>  and apache  <dig> . the three example databases referred to in this paper may be linked to from .

authors' contributions
kg is the main software architect for the pierre project and initially drafted the paper. cg has been responsible for creating the repository data model for the tutorial and adapting the pedrodb query service to suit pierre. he is also responsible for end-user training, and development of test plans for the project. he, together with sgo, proof-read the draft developed by kg and np. ch used pierre to develop the e-fungi deployment. tg provided feedback on an early version of pierre. ns developed the generic data repository service for relational databases. sgo oversees the life science aspects of the projects that motivated the development of pierre and thus provided a user's perspective. np managed the project, helped to steer development of the architecture, and ensured the paper targeted bioinformaticians. all authors have read and approved the final manuscript.

