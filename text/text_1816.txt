BACKGROUND
over the last decade or longer, microarray technology has been used for measuring gene expression and has greatly impacted biomarker discovery  <cit> , transcription factor identification  <cit> , the assessment of gene interactions  <cit> , and the detection of biological pathways  <cit> . despite the massive application of microarrays to transcriptome applications there are limitations to the extent of the conclusions that can be made. messenger rna  is the intermediate product of genes, with proteins being the final products and the key factors of metabolism. although the levels of mrna and protein for a gene are related they are not always highly correlated, which can be due to many reasons, e.g., translation rate, protein stability, and post-translational modification, etc.  <cit> . given that the motivation and goal of many experiments is to understand not only the function of genes, but the network of genes that encode proteins, the abundance of proteins themselves are of increasing interest. toward this end, microarray technology when adapted to proteins, are known as protein microarrays, and have been developed and widely used to assess the abundance of proteins  <cit> . the similarities between microarray technology as applied to gene expression  <cit> , and as applied to protein abundance, are the same in that improved accuracy and precision, as well as design issues and normalization techniques for protein microarrays have been established  <cit> .

screening and identifying proteins as potential medical diagnostics and disease classification biomarkers is the main motivation of many protein microarray experiments  <cit> . the precursor to any successful screening application, and an essential issue that must be resolved to ensure that the accurate protein abundance measurements can be obtained by protein microarrays, is the consistency of a protein to report hybridization abundance. the protein itself is the probe on the array, and since proteins have a complex three dimensional structure, the structure itself, as well as the orientation of a protein, need to be retained. toward this end, it is highly unlikely that every protein will be functional since different proteins often require different environment conditions for maintaining structures, and are typically much less stable than dna. if the three dimensional nature of the structure is lost, or the required functional portion of the protein is not available to bind its target protein , the target protein abundance measurement will be much smaller than it should be, or missed all together. proteins whose structure or function are not maintained when attached to the array as probes are called inconsistent proteins, and if used provide inflated biomarker error rates . alternatively, proteins that retain their structure and function are called consistent proteins and are desirable as probes on the array, and ultimately potential biomarkers. as such the selection of proteins that maintain functional consistency across experiments is a major and necessary requirement in the design and analysis of protein microarray experiments  <cit> .

certainly, high-throughput chemical validation of protein consistency is possible, but it is expensive and time consuming. toward this end it is possible to statistically estimate protein consistency. in its simplest form, pearson's correlation coefficient has been employed as a consistency measure in an antibody microarray study by miller et al.  <cit> , but it only measures the linearity of repeated measurements, and therefore is limited in its usefulness. a concordance correlation coefficient that is able to measure the consistency of repeated measurements was proposed by lin  <cit> , and later expanded to a total deviation index   <cit> , which provides a boundary within which a certain required percentage of differences between paired observations is obtained while controlling the error rate. as described by lin  <cit> , tdi and the concordance correlation coefficient provide the same information, but from different perspectives, and thus share their limitations. namely, both the concordance correlation coefficient and tdi only demonstrate good asymptotic properties under the assumption of normality; a reality that is often questionable in application. furthermore, the comparability of concordance correlation coefficients across proteins requires the ranges of the abundance measurements of proteins to be similar, which is not practical in large scale experiments  <cit> . to address the challenges and issues that are associated with identifying functionally consistent proteins, we propose a new statistic based on variance components from an analysis of variance  model. we rely on a mixture model to achieve this goal. applications of mixture models in biology have proven to be excellent for separating data into the correct number of classes. for example, efron et al.  <cit>  proposed a two-component mixture model for testing differential expression. in this application the distributions of the t-statistics from both differentially expressed genes and non-differentially expressed genes were estimated by a nonparametric method, but the tail probabilities were not able to be estimated accurately. toward this end the accuracy of estimating the tail probability was improved by using a two-component mixture model pan et al.  <cit>  where a finite normal mixture was assumed for each component. for microarray data it certainly is possible to simulate test statistics under the null hypothesis  using permutation theory since the treatment conditions for testing differences are known. however, for protein array data the first challenge is to identify proteins that are consistent, and then work only with these data. in other words, we are focusing on separating proteins into inconsistent and consistent classes, and then using only the informative proteins  to address the biological question. to achieve this we propose a novel two-component semi-nonparametric mixture model. simulations demonstrate the performance of the proposed approach and provide food for thought when designing future protein microarray experiments. we also apply the proposed approach to real data for the purpose of demonstrating its usefulness.

RESULTS
simulations were conducted for the purpose of providing insight into the performance and value of the proposed semi-nonparametric approach. data were simulated from known consistency classifications. data were analysed with the proposed approach and the number of times proteins are correctly classified is recorded. from these simulation results, false discovery rate, as well as false non-discovery rate were calculated and are discussed.

a power study
simulations were designed to study the statistical power of the approach under different sample sizes and different underlying two-component mixture distributions. data were simulated directly from nine unique two-component semi-nonparametric mixture distributions with specified parameter values . the tuning parameter k took on values  <dig>   <dig>  or  <dig> for each semi-nonparametric density in each mixture. sample sizes are  <dig>   <dig>   <dig>  or  <dig>  the proportions of the first mixture component with smaller mean, λ <dig>  are  <dig> ,  <dig> , or  <dig> . the distance between the two mixture components are  <dig> or  <dig>  where the distance is defined as

                              ϕ
                           
                              11
                              ϕ
                           
                              12
                              µ
                           
                              1
                              σ
                           
                              1
                              ϕ
                           
                              21
                              ϕ
                           
                              22
                              µ
                           
                              2
                              σ
                           
                              2
each simulation model is based on a two-component semi-nonparametric  mixture distribution that has eight parameters: ϕ <dig>  ϕ <dig>  μ <dig>  σ <dig>  ϕ <dig>  ϕ <dig>  μ <dig>  σ <dig>  the distance d of two components is  <dig> or  <dig> 

  d=|μ1−μ2|σ1+σ <dig>  

and μ <dig> and μ <dig> represent the means of two components respectively, while σ <dig> and σ <dig> represent the standard deviations of two components, respectively. under each combination of model settings,  <dig> data sets were generated.

for each simulated data scenario, a two-component mixture model was fit to the data. the expectation-maximization  quasi-newton algorithm was employed to estimate the model parameters. model selection criteria akaike's information criterion   <cit> , schwartz bayesian information criterion   <cit>  and hannan-quinn criterion   <cit>  were used to select the best model. a likelihood ratio test  was employed to determine whether the mixture distribution was identifiable as two-components . a bootstrap method approach approximated the null distribution of the likelihood ratio test statistics, and provided a significance threshold for the likelihood ratio test statistic . power was calculated by estimating the proportion of correctly rejected hypotheses for each of  <dig> data sets. power comparisons for all parameter settings using bic model selection criteria are provided in figures  <dig>  the general trend across all three model selection criteria is that well separated mixture distributions  outperform mixtures that are not well identified . when the mixtures are well defined, there is obvious increased power for situations where the mixing proportion  of the functionally consistent component of the mixture distribution is 50% or greater. recall, when the tuning parameters k <dig> and k <dig> are both zero the semi-nonparametric densities in the mixture distribution are both standard normal densities.

as expected, higher power is associated with larger sample size. dramatically higher power is achieved when the distance between the two components is increased from  <dig> to  <dig> simply because the null hypothesis  is easier to reject when the mixture components are well separated. furthermore, aic tends to choose a larger model that has a larger likelihood ratio test statistic  when compared to the smaller model chosen by bic or hq  <cit> , therefore the use of aic yields higher power than bic or hq.

simulated data scenario
the performance of the proposed mixture model with semi-nonparametric densities is evaluated for selecting functionally consistent proteins in a simulation setting based on a real experiment. since we are interested in understanding the performance of the proposed approach it is necessary to rely on simulated data, rather than actual data since the truth for real data is unknown. protein microarray data were simulated based on the data scenario described in zhou et al.  <cit> . specifically, there are three groups of patients with different stages of disease, and one group of healthy patients. each group consists of  <dig> patients . for each patient, hybridization abundance was measured on  <dig> proteins. each of the  <dig> proteins was represented as a probe on the array. onboard probe  replication allowed each protein to be represented  <dig> times on the array. forty samples were individually mixed with a reference sample, hybridized to an array, and the entire experiment was repeated twice. protein microarray data were simulated as follows

  log2=μ+gj+sk, 

where μjk represents hybridization abundance of individual or patient k in group j, μ represents the overall mean abundance, gj represents the fixed effect of group j, sk represents the random effect of patient k in group j following a normal distribution with mean  <dig> and variance σsj <dig>  and

  yijkl=θjk+δijk+ϵijkl=log2−log2+δijk+ϵijkl=c+gj+sk+δijk+ϵijkl, 

where c=−log2∑j,k2gj+sk <dig>  i =  <dig> , j =  <dig> , <dig> , k =  <dig> , ⋯,  <dig>  l =  <dig> , ⋯,  <dig>  yijkl represents the lth log signal ratio of patient k to the reference sample in group j for experiment i, θjk represents the mean log signal ratio of the patient k sample to the reference in group j, μ¯.. represents the average of μjk's over j and k, δijk represents the random error of experiment i for patient k in group j, and ϵijkl represents the lth random error within experiment i for patient k in group j. assume that δijk is from a normal distribution with mean zero and variance σδ <dig>  ϵijkl is from a normal distribution with mean zero and variance σe <dig> 

the model parameter settings for the simulation were taken from the aforementioned zhou et al. antibody microarray data  <cit> , such that the g'js were sampled from uniform distribution u, σsj <dig> =  <dig>  where v were sampled from u for different j, σδ <dig> =  <dig> , and σe <dig> =  <dig> . the hybridization abundance data for  <dig> functionally consistent proteins on each array were simulated from model  and  . fifty percent of these simulated proteins were randomly chosen to be functionally inconsistent proteins by adding a random between-array deviation with mean  <dig> and standard deviation drawn from u , as well as a random within-array deviation with mean  <dig> and standard deviation taken from u, to a randomly chosen number of separate arrays. protein classification resulted from estimating the variance components in the anova model , and modelling the between and within-array variance component statistic with a semi-nonparametric mixture model. the main advantage of the proposed mixture model approach is that it provides the posterior probability of consistency for each protein which in turn establishes the classification rule, as well as estimates the respective error rates.

one thousand data simulations were performed under the same simulation setting, and for each the sum of the between- and within-array variation  provides the statistic that is ultimately modelled and used for classifying each of the  <dig> proteins by fitting to the semi-nonparametric mixture model . posterior probabilities defined in equation  and equation  were computed, and then used to calculate the estimated false discovery rate  in equation , and the estimated false non-discovery rate  in equation . since these are simulated data for which we know the true classification, the true fdr and fnr were calculated and compared to the respective estimated values from the simulated data analyses. the estimated and true fdr and fnr were averaged over  <dig> simulations, respectively. the average fdr  and fnr  were plotted against the number of inconsistent proteins. the conservative nature of this approach is illustrated in the downward bias of the fdr estimates and the corresponding upward bias of the fnr estimates.

we compare the proposed semi-nonparametric approach to the work of miller et al.  <cit>  who selected functionally consistent proteins using an arbitrary cutoff value for pearson's correlation coefficient. it is important to realize that their cutoff value is not statistically justified, nor does it provide error rate control. we calculated pearson's correlation coefficients  for each of the  <dig> simulated data sets, and reported in the average fdr and fnr results in figures  <dig> and  <dig>  respectively. not surprisingly, larger true error rates are experienced for the pearson's correlation coefficient when compared to the variance component  statistic that is based on the between- and within-array variation. essentially, the variation in the random error captures the difference between consistent and inconsistent proteins allowing the variance estimate based on between- and within-array variation to provide information about protein consistency. based on this rationale, the misclassification error rates of the proposed approach are expected to be smaller than the pearson's correlation coefficient. as can be seen for pearson's correlation coefficient, when the number of inconsistent proteins is  <dig>  the false discovery rate is  <dig>   and the false non-discovery rate is  <dig>  . by comparison, based on the between- and within-array variation statistics the false discovery rate is  <dig>  and the false non-discovery rate is  <dig> . the same phenomena occur at any other number of inconsistent proteins .

biological and technical replication
we explored the influence of the number of biological replicates  and technical replicates  on the proposed semi-nonparmetric mixture model approach for selecting functionally consistent proteins using two different simulation settings. data were simulated from model  and  . the first simulation focused on the number of biological replicates or patients  while fixing the number of onboard probe replicates representing each protein at  <dig>  six onboard replicates is a relatively large number and is in keeping with many of the current protein microarray investigations. the classification error rate was computed by minimizing  for each number of replicates  under consideration, and it can be seen that rate drops off quickly as the number of replicates increases from  <dig> to  <dig>  the second simulation evaluated the number of onboard per protein probe replicates while fixing the number of biological replicates  at  <dig>  figure  <dig> illustrates the classification error rates dropping as the number of onboard replicates increases. clearly, the largest decrease is most dramatic in the range from  <dig> to  <dig> 

a case study
we applied our method to data from an antibody microarray experiment from zhou et al.  <cit> . two-color rolling-circle amplification  was used to assess thirty five antibody proteins from duplicate sets of twenty four serum samples using antibody microarrays prepared on nitrocellulose. the twenty four serum samples consist of six liver cancer patients, six pre-cirrhotic patients, six cirrhotic, and six normals. each antibody has  <dig> replicates on the array.

in the analysis, one antibody was removed due to no signal. the anova model  was employed to calculate the total variation due to random error. the range of the consistency statistics is shown in a histogram , from which we can see there are two clusters. to test whether the two components of the mixture model  are separable we calculated the likelihood ratio test  and found it to be  <dig> , for which significance was determined by comparing with a critical value under the null hypothesis. to do that, we bootstrapped the null hypothesis likelihood ratio test statistics and obtained a p-value of  <dig>  for the likelihood ratio test statistics that corresponds to the value  <dig> , therefore we rejected the null hypothesis and concluded that the consistent and inconsistent proteins are separable. both components, as determined by the bic criterion, under the alternative hypothesis have k =  <dig>  and have the model parameter estimate μ^ <dig> =  <dig> , σ^ <dig> =  <dig> , μ^ <dig> =  <dig> , σ^ <dig> =  <dig>  and λ^ <dig> =  <dig> . because the sample size  is small, model selection tends to choose simpler models where k =  <dig>  we illustrate the complex densities where k =  <dig> for both components in figure  <dig>  in order to determine the optimal number of functionally consistent proteins, we estimated the fdr  and fnr  and obtained the error rate  by using a 2: <dig> ratio for the cost of fdr and fnr. figure  <dig> shows that the minimum error rate occurs when there are  <dig> inconsistent proteins and  <dig> consistent proteins. in zhou et al.  <cit> , pearson's correlation coefficient was calculated for each protein to evaluate measurement reproducibility. unfortunately, pearson's correlation coefficient does not provide a classification of consistent and inconsistent proteins, so it is not possible to compare the results of our approach with the published results from zhou et al.  <cit> .

discussion
the challenge of selecting and employing functionally consistent proteins for protein microarray experiments is complicated by the three-dimensional structure of the protein itself. specifically, the proteins that are spotted on to the array as probes  need to maintain functional consistency for each sample hybridized to the array, as well as across experiments. identifying and employing functionally consistent proteins continues to be a major and necessary concern in both the design and analysis of protein microarray experiments. to address this concern, a novel statistical approach based on modelling the between- and within-array variation, using a semi-nonparametric mixture model, is presented for the purpose of discriminating functionally consistent proteins. of course, once functionally consistent proteins have been identified and the array fabricated, it is then necessary to develop additional statistical methods that can detect proteins of differing abundance.

after classifying proteins as consistent and inconsistent proteins, the abundance data from functionally consistent proteins can be used for differential protein abundance/expression analysis. the semi-nonparametric mixture model that was initially proposed to select functionally consistent proteins  can also be adapted for detecting differentially expressed proteins. specifically, one component of the mixture identifies the non-differentially expressed proteins, while the other component acknowledges the differentially expressed proteins. the semi-nonparametric mixture model lies between parametric and nonparametric approaches since it does not put distributional assumption on the data themselves, but on the test statistics. the semi-nonparametric mixture model as applied to differential expression analysis was investigated and shows great performance  <cit> .

the proposed semi-nonparametric mixture model is a novel and broadly applicable approach in the mixture model literature. for applications to either identifying functionally consistent proteins, or testing for differential protein abundance between samples, only two-component mixture models are employed. the extension of the semi-nonparametric mixture model to a multiple-component and multivariate mixture model has potential to address high-dimensional problems for the purpose of classification, and it has potential to work for a variety of data problems since it provides the flexibility necessary for model fitting.

CONCLUSIONS
a novel semi-nonparametric mixture model is proposed for the purpose of selecting functionally consistent proteins that can be used for protein microarray experiments. the proposed approach is able to attach a posterior probability of being inconsistent to each protein, from which false discovery and false non-discovery rates can be estimated. we validated the performance of our method through simulations. additionally, the characteristics of the semi-nonparametric mixture model were studied by a power analysis. our novel method provides an improvement in the accuracy of proteins that are selected as probes on a protein microarray, as well as an alternative approach to studying a variety of additional mixture data problems.

