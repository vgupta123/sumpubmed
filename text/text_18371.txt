BACKGROUND
with the advent of whole-genome shotgun  sequencing in the mid-1990s, the genomics community had an urgent need for software that could process tens of thousands of individual sequence "reads" and assemble those into the genome from which they had come. the first generation of assemblers, including tigr assembler  <cit> , phrap  <cit> , and cap <dig>  <cit> , were able to assemble small- to medium-sized bacterial genomes, often requiring several weeks of computer time on the fastest computers then available. as sequencing technology improved, ever larger projects were attempted with the wgs method, and it became clear that new methods were needed. for the  <dig> million base pair  genome of the fruit fly drosophila melanogaster, an entirely new assembler was developed  <cit> , which incorporated many new ideas about efficient memory usage and sophisticated repeat processing. the celera assembler  was also the first algorithm to use mate pair information to any serious degree: taking advantage of the fact that most reads in a wgs project are generated in pairs, that system used the expected distance between reads in a pair to impose many useful constraints on the overall assembly. other large-scale wgs assemblers followed, including arachne  <cit> , which was used to assemble the  <dig>  billion base pair  mouse genome  <cit> , phusion  <cit> , atlas  <cit> , and jazz  <cit> .

as these systems have scaled up to meet the needs of very large wgs projects, they have grown in size and complexity, so that today, only a few very sophisticated bioinformatics groups have the expertise needed to install and run them. like many large systems, these assemblers are relatively brittle, meaning that they often crash if the data does not conform to fairly rigid specifications. however, because they produce far superior results to the first generation of assemblers, the leading genome centers have focused their efforts on these large assemblers to the exclusion of other approaches.

meanwhile, a host of new genome sequencing applications has arisen that place different demands on assembly algorithms. although large-scale sequencing has pushed assembly technology in productive directions, small-scale sequencing efforts have proliferated as well. our group recognized the growing need for an assembler that could assemble a handful of sequencing reads with a minimum of overhead , and as a result we have developed minimus, a fast, "lightweight" assembler that addresses these needs. before describing the algorithm and our results, we will describe several of these motivating applications.

gap closure
since the very first bacterial genome, haemophilus influenza  <cit> , was sequenced, we and our colleagues at the institute for genomic research  have been developing methods for closing the gaps in a draft genome. the initial assembly of a wgs project normally produces a large collection of contiguous pieces of dna  that are separated by gaps. improvements in sequencing and assembly technology have yielded fewer gaps per megabase in recent years, but nonetheless, the increased scale of sequencing has meant that large centers have many more gaps to fill. one unintended by-product of this trend is that many genomes today are left in "draft" form: the initial assembly is the only assembly, and the published genome consists of hundreds or thousands of unordered contigs.

fortunately, many genomes, especially those of the greatest scientific interest, are still being finished, which means that all gaps need to be closed. gap closure consists of running additional sequencing reactions that fill in the gap between two adjacent contigs. if the gap is filled with repetitive sequence , then "closure" teams may go to great lengths to clone and sequence small dna fragments that correctly span the gap. once these sequences are generated, the final step is to assemble the gap. this requires that the newly generated sequences, often spanning just a few kilobases or even less, be assembled together with the two surrounding contigs.

large-scale assemblers such as celasm and arachne can be used for this task, but this presents several problems. first, the scale of these programs means that simply loading them into memory can take longer than the execution time of the assembly itself. second, the laboratory teams filling gaps typically use graphical tools to manage gaps, and configuring these tools to call a very large external program is impractical if not impossible. third, and perhaps most telling, the cleverness of these wgs assemblers is a hindrance for gap closure, because the data do not conform to the characteristics of a typical shotgun process. the depth of coverage of finishing reads often differs from that in the surrounding areas thereby confusing the statistical repeat detection mechanisms present in large-scale assemblers, and preventing a correct assembly of the gap. therefore an assembler for gaps will do better by using a simple, straight-forward algorithm, focused on a specific region of the genome. finally, these assemblers cannot be easily modified to address the specific issues raised by specialized finishing procedures, especially as new finishing techniques are continuously being developed. for example, high-throughput finishing experiments often use transposons to sample a problematic region, resulting in paired reads that are facing away from each other . such constraints cannot be easily incorporated in existing assemblers which are hard-coded to assume paired reads are facing inwards, towards the middle of the corresponding shotgun fragment. flexible tools like minimus and amos provide the potential for incorporating such information through add-on modules.

gene assembly
another important use of small-scale assembly takes advantage of the rapidly growing trace archive at ncbi  <cit> , a public repository of all the raw data from many large sequencing projects. because it takes months and sometimes years before the final, assembled sequence from a genome project is released, scientists use the blast search function at the trace archive to find reads matching a gene of interest. if the gene is contained in the trace archive data, then a search will return anywhere from a handful to a few hundred sequences. these need to be assembled together to produce a better picture of the genomic region containing the gene. once again, the scientist needs a small, less finicky assembler for this purpose.

small genomes
although most sequencing capacity is taken up by the largest genome projects, the number of small genomes being sequenced easily outstrips – in number of species and strains – the number of large genomes. ironically, some of the very clever and complicated ideas that make celasm, arachne, and other assemblers work for large genomes make them less than ideal for these small genomes. viruses are a good example: they typically have genomes ranging from 5– <dig> kilobases, and they contain relatively little repetitive dna. thus there is no need to characterize the repeat content, and a simple assembler that ignores the issues of large-scale wgs projects will produce a perfectly correct assembly more quickly. for example, the influenza genome sequencing project, which uses an rt-pcr strategy rather than wgs, has assembled over  <dig> influenza genomes using minimus  <cit> , with savings coming from not having to address special formatting requirements to prepare the data and from not having to maintain a large assembly software package.

implementation
implementation details of minimus
the minimus assembler was built in a modular fashion from software modules available within the amos assembly package  <cit>  and is released as one of the components of this package. amos is an open-source software package that provides researchers with a collection of modules and software libraries that are useful in the development of genome assembly and analysis software. a full description of the amos package is beyond the scope of this paper and will be published elsewhere .

minimus consists of the combination of three amos modules, following the traditional overlap-layout-consensus paradigm  <cit> . these modules interact with each other through a central amos data-structure  as shown in figure  <dig>  the three modules are:

 <dig>  hash-overlap – a sequence overlapper that uses minimizers  <cit>  to increase speed and decrease memory usage.

 <dig>  tigger – a unitigger, i.e. tool that identifies clusters of reads which can be uniquely assembled based on algorithms developed by myers  <cit> ; in graph theoretic terms a unitigger identifies maximal interval subgraphs of the overlap graph.

 <dig>  make-consensus – a progressive multiple alignment program that refines the read layout generated by the unitigger to build a precise multiple alignment of these reads.

note that sequence quality values are only used during the generation of the multiple alignment consensus . other assemblers, such as phrap, use the quality values as an integral component of the assembly algorithm. we found that, due to the high quality of data produced by modern sequencing instruments, the explicit consideration of quality values during the overlap and unitigging steps is unnecessary. instead we only use the quality data to trim the poor quality flanks of each read , and to compute the consensus  for the multiple alignment of co-assembled reads.

an execution of minimus consists of the following stages, described in detail below.

input stage
the shotgun reads are loaded into the amos bank. the inputs are presented as an amos message file, whose format is modeled on the format used by celera assembler  <cit> . virtually any existing format for representing shotgun data can be easily converted to this message format with the help of conversion tools distributed with the amos package.

overlap stage
the hash-overlap program is used to compute all pair-wise alignments between the reads provided in the input.

unitigger stage
the tigger module constructs a graph representation of the set of overlaps determined in the overlap stage. the overlap graph contains a node for each shotgun read, and an edge connects two nodes if the corresponding reads overlap. the unitigger then uses several reduction steps to simplify this graph, and generate a set of unitigs, based on algorithms originally developed by myers  <cit> . briefly, these reduction steps are:

 <dig>  removal of containment edges. reads completely contained within other reads in the input are removed from the graph.

 <dig>  transitive reduction. for any set of three reads , if the overlap between a and c can be inferred from the overlaps between reads a and b, and b and c, this overlap  is removed from the graph.

 <dig>  unique-join collapsing. every simple path in the graph  are collapsed into a single vertex. each such vertex represents an individual unitig.

consensus stage
the final stage of minimus constructs the full multiple alignment of the reads aligned within each unitig, using as a guide the approximate placement of the reads inferred from the overlap information.

sequence trimming
the criteria used for trimming the vector sequence and the poor quality flanks of shotgun reads vary significantly depending on the source of the data and on the protocols employed during sequencing. in designing minimus we, thus, opted to perform the trimming of the data with external software tools that can be customized to the specific characteristics of the data. for the examples described in this paper we followed two different approaches for sequence trimming:

 <dig>  for data where we had confidence that the trace archive clipping coordinates were correct  we simply used the coordinates provided to us.

 <dig>  for the other data-sets  we followed the protocol described at  <cit> , specifically we used the program lucy  <cit>  for quality trimming, followed by a k-mer based vector trimming protocol.

note that while phrap performs some trimming based on quality values, in order to ensure consistent trimming of the data, we provided phrap with sequences already trimmed according to the protocol described above.

extraction of gpc <dig> homologues from zebrafish shotgun data
to extract the set of zebrafish shotgun reads that map to the human gpc <dig> gene, we built an ncbi blast database containing the high-quality region of the zebrafish reads . we then aligned the protein sequence of the human gpc <dig> gene using tblastn with an e-value cutoff of  <dig> . all reads matching gpc <dig> under these extremely relaxed criteria were then provided to minimus for assembly.

RESULTS
to demonstrate the capabilities of minimus we present its application to the assembly of several small data-sets: influenza a virus isolates, individual genes, and bac clones. we compare the performance of minimus to that of phrap  <cit> , the "small assembler" most commonly used for such small assembly tasks. we also used minimus to assemble two bacterial genomes, brucella suis, and staphylococcus aureus, to illustrate its potential use as one of the components of a complex assembly pipeline. genome assemblers such as atlas  <cit> , developed at the human genome sequencing center at the baylor college of medicine, and phusion  <cit> , developed at the sanger center, represent such assembly pipelines. both assemblers use a hierarchical approach to partition the reads into small sets during an initial clustering step, then assemble each of the clusters with the phrap assembler.

before describing our results we would like to emphasize the fact that the comparisons to phrap provided below are inherently skewed due to the fact that phrap and minimus were designed to solve different problems. these comparisons are relevant, however, because phrap has been widely applied to assembly tasks that fall outside the scope of the original intended use for this program. we will demonstrate that minimus provides scientists with a better tool for small assembly tasks, be it the assembly of viral genomes or individual genes, or as a component in a larger assembly pipeline such as atlas or phusion. the high stringency of the algorithms employed by minimus obviates the need for the complex modules commonly used  in such assembly pipelines to correct the errors introduced by phrap. in addition, the flexibility provided by minimus' well defined interfaces and open-source license, allow scientists to adapt and extend our software as needed by their specific projects. such enhancements are virtually impossible with phrap due to the restrictive license and code release model.

assembly of influenza a virus isolates
assembling the influenza a virus is an ideal application for minimus due to the small size of the virus. the influenza a sequencing project, currently underway at tigr  <cit> , has been using minimus to assemble the genomes of more than  <dig> individual isolates of the influenza virus. the sequencing pipeline at tigr generates approximately  <dig> sequencing reads for each viral isolate, providing approximately 4-fold coverage of the  <dig> segments composing the flu genome. the assembly of the influenza genome is performed in a hierarchical manner, building a collection of contigs using minimus with high stringency settings, then improving this assembly during two additional passes that combine minimus with quality trimming software. in approximately 95% of the cases , this hierarchical process results in complete reconstructions of each of the segments, these data forming the substrate for genome annotation and for other subsequent analyses. the whole assembly process, including the time needed to access the database used to store the reads and the resulting assemblies, takes approximately  <dig> minutes. the actual time used by minimus for assembling the data is approximately  <dig> seconds/segment during each of the three passes. the shotgun reads, and the assemblies produced by minimus are made freely available to the scientific community by submission to the ncbi trace and assembly archives  <cit> .

assembly of individual genes
one of the applications that initially drove the development of minimus is the assembly of an individual gene from reads "fished" out of a shotgun dataset by alignment to a homologous gene from a related organism. this application is particularly relevant to the study of large eukaryotic genomes that are being sequenced but for which no assembly has yet been made available to the scientific community. while sequencing is a highly automated process, the assembly of large genomes is a time-consuming activity that requires extensive manual intervention, particularly in the case of large, highly repetitive genomes, or genomes with highly divergent homologous chromosomes. thus, it is not uncommon for the raw shotgun data to be deposited in the trace archive months, and sometimes years, before an assembly of a genome is made available, even in a draft form. this situation makes it difficult for scientists to ask questions such as "does this organism being sequenced have a homologue of gene x?", or "how many copies of gene y are present in this genome?" such questions are often difficult to answer even if a draft assembly is available, as evidenced, for example, by the absence of chromosome y-linked genes in an early draft of drosophila pseudoobscura; in that case, investigators found the genes of interest by directly examining the underlying shotgun data  <cit> .

to highlight the application of minimus to assembling individual genes directly extracted from the shotgun data, we attempted to assemble the zebrafish  homologues to the human glypican- <dig>  gene. the gpc <dig> gene is highly expressed during development and has been implicated in a variety of cancers as well as in the simpson-golabi-behmel overgrowth syndrome . we chose this combination of organisms due to the large evolutionary distance between human and zebrafish, as well as the fluid nature of the draft assembly of the zebrafish genome .

we extracted  <dig> danio rerio shotgun reads  that could be mapped to the sequence of the human gpc <dig> protein . we then assembled these reads using minimus, resulting in  <dig> contigs, representing individual exons of the zebrafish gpc <dig> homologue. to ascertain the quality of the reconstruction, we mapped the individual contigs to the human gene. the overview of the alignments is shown in figure  <dig> , indicating that approximately half of the human gpc <dig> gene is covered by high quality matches to four contigs generated by minimus. interestingly, these four contigs do not share any significant similarity at the nucleotide level, indicating the presence in zebrafish of at least four homologues to the human gpc <dig> gene, not unexpected given that in human gpc <dig> is part of a larger gene family. this result could, however, not be immediately inferred from the zebrafish information network  – the central database for the zebrafish community. a search for "glypican" in zfin returns a single entry – that for the zebrafish homologue to gpc <dig> 

to ascertain whether the incomplete coverage of the human gpc <dig> is due to limitations in our methodology, or to actual differences between the human and zebrafish homologues, we aligned the annotated zebrafish gpc <dig> homologue to the human protein . the alignment reveals the zebrafish gpc <dig> gene to be shorter than its human counterpart, consistent with our reconstruction. in fact, the minimus contigs cover most of the zebrafish gene, with the exception of approximately  <dig> amino acids at the c terminus. this comparison also reveals a limitation of our approach. short exons and/or splicing differences between the human and zebrafish homologues of the gene may prevent a simple translated search from identifying the shotgun reads necessary to reconstruct the full length gene. despite such limitations, we believe our results show that minimus can be successfully used as a first step in characterizing the homologues of a gene of interest in a newly sequenced organism. furthermore, the approach we chose can be easily augmented to hierarchically recruit additional shotgun reads that extend the initial set of contigs, eventually reconstructing assemblies of entire genes. we implemented a simple version of such a procedure by also recruiting the mates for all reads identified during the translated searches. unfortunately, the inclusion of these reads into the assembly process only resulted in marginal improvements. better results will undoubtedly be obtained by extending this process to also incorporate reads that overlap the reconstructed contigs, however an implementation of such a procedure is beyond the scope of the current paper.

bac clone assembly
the sequencing of complex genomes sometimes follows a hierarchical process, whereby the dna is first sheared into segments of between 50- <dig> kbp which are then amplified in e. coli. these segments, called bacterial artificial chromosomes , are then sequenced through the shotgun method. this hierarchical approach can overcome the complexity of highly repetitive genomes , and has also been applied to the exploration of environmental samples . the shotgun sequencing of individual bac clones generates approximately 2000– <dig> sequencing reads, which can be easily assembled with minimus. we extracted, at random, from the ncbi trace archive a collection of  <dig> shotgun libraries generated from mouse bac clones, and assembled these data with both minimus and phrap. all the selected bac clones have been finished, providing us with a "gold standard" for evaluating the correctness of the assemblies. the results of this comparison are summarized in table  <dig>  on these datasets, minimus ran faster than phrap  and produced contigs that mapped with few errors to the finished sequences; in contrast, the phrap contigs contained up to five times as many errors as minimus  when compared to each of the finished bacs. these results are unsurprising as phrap's aggressive attempts to generate longer contigs  often result in mis-assemblies  <cit> . we argue that the conservative approach taken by minimus is preferable in the case of bac assembly, as mis-assemblies are often difficult to identify and correct, whereas the fragmented assemblies produced by minimus can be easily improved by utilizing mate-pair information and by using alignment information between the individual contigs.

minimus ran considerably faster than phrap and produced no errors, at the expense of a larger number of contigs. note that the table contains two quantities denoted "coverage": the sequencing coverage  represents the total amount of dna in the sequenced reads, divided by the size of the chromosome, i.e. the redundancy in the sequenced data; the column headed "coverage" represents the fraction of the reference sequence covered by assembled contig. the latter measure does not take into account assembly errors, i.e. partial contig matches contribute to the overall coverage.

assembly of bacterial genomes
in addition to the assembly of small datasets such as those described above, minimus can also be used in conjunction with other assembly modules  to build an assembly pipeline for larger genomes. to assess the suitability of minimus as a replacement for the phrap assembler in pipelines such as atlas or phusion, we compared the two assemblers on their ability to assemble two bacterial genomes: brucella suis, and staphylococcus aureus. both genomes were sequenced and fully finished at tigr, and all the sequencing reads generated for these projects are publicly available at both the ncbi trace archive, and from our website  <cit> . the availability of a finished molecule allowed us to compare the correctness of the assemblies generated by minimus and phrap respectively, as shown in figure  <dig>  the results of our comparison are shown in table  <dig>  similar to the case of bac assembly, minimus ran faster than phrap  and produced no errors. the phrap assembly contained multiple errors , though it produced larger contigs, 4– <dig> times larger than those produced by minimus. again, the conservative approach taken by minimus, as well as its efficiency, make it a better choice as the core component of a genome assembly pipeline such as atlas or phusion. in this context, mis-assemblies may present more challenges than the relatively smaller contigs generated by minimus.

minimus ran faster than phrap and produced no errors. however, it generated a considerably larger number of contigs. note that the table contains two quantities denoted "coverage": the sequencing coverage  represents the total amount of dna in the sequenced reads, divided by the size of the chromosome, i.e. the redundancy in the sequenced data; the column headed "coverage" represents the fraction of the reference sequence covered by assembled contig. the latter measure does not take into account assembly errors, i.e. partial contig matches contribute to the overall coverage.

discussion
one, perhaps surprising, result of our experiments is the higher fragmentation of the bac assemblies in comparison to the bacterial assemblies , even though the bacs were sequenced to a deeper level of coverage. the reason for this fragmentation is the higher density of repeats in the mouse genome. eukaryotic genomes often contain high-copy repeats that disrupt the assembly process, even within the range of a bac insert. such complex repeats are less frequently encountered in bacteria.

CONCLUSIONS
we have described minimus, a shotgun sequence assembly program designed for the assembly of small data-sets, and shown that minimus can be successfully used to extract individual genes from shotgun data-sets, thereby providing scientists with the means to analyze newly sequenced organisms long before complete genome assemblies are made available. due to its small size and modular design minimus is perfectly suited to be a component of complex assembly pipelines, as shown by its use at tigr as the main workhorse in the influenza virus sequencing pipeline. traditionally, phrap has been used as a main component of such pipelines. we compared minimus to phrap on two median-sized assembly tasks, bac clones and bacterial genomes, and found that minimus is able to perform such assemblies more efficiently and more accurately than phrap, at the cost of producing smaller contigs. we would like to emphasize the fact that it important to obtain a correct assembly, even if this assembly is fragmented. assembly errors are often difficult to detect and correct, and are usually resolved through an expensive and time-consuming process of manual curation , while fragmented assemblies can easily be improved in a high-throughput fashion by, for example, hierarchically combining the fragmented contigs based on lower-stringency overlap information. these results highlight the potential for minimus to be used as a replacement for phrap in assembly pipelines such as atlas or phusion, especially as these pipelines already implement mechanisms for combining contigs. also note that the errors in the phrap assemblies are an artifact of the greedy assembly algorithm used by phrap and cannot be resolved by simply adjusting the stringency of the assembly process.

finally, the modular design of minimus  allows scientists to easily fine-tune, or replace, individual components of the assembly pipeline, tailoring the execution of minimus to the specific characteristics of the data. such fine-tuning is impossible in phrap, partly due to its restrictive license, and also due to its monolithic design. minimus is therefore more than a simple assembler: it can be thought of as a potential testbed for evaluating specific assembly approaches, whether for educational purposes as part of a bioinformatics curriculum, or during the conduct of research in genome assembly.

availability and requirements
minimus is distributed under an open source license  as a component of the amos package  <cit> . the details for this package are provided below.

project name: amos

project homepage: 

operating systems: unix 

programming languages: c++, perl

other requirements: none for minimus, some components of amos require the qt library

license: osi artistic license

any restrictions to use by non-academics: none

test data for running minimus can be downloaded from the minimus website: .

authors' contributions
dds implemented the unitigger and the overall execution pipeline and ran the assemblies presented in the results section. ald implemented the overlapper and multi-aligner programs. sls provided the initial impetus for the design of minimus and encouraged and oversaw the integration with the flu sequencing pipeline. mp led the design of the package, provided conversion utilities for various assembly formats, and performed the analysis of the zebrafish gpc <dig> homologues. all authors contributed to writing the manuscript.

