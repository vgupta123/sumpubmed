BACKGROUND
the medical evaluation of sensorineural hearing loss  involves a combination of non-genetic laboratory and radiographic tests. the former provide little diagnostic or prognostic information  <cit> . radiographic evaluations are helpful in diagnosing temporal bone anomalies, but are expensive and require sedation or general anaesthesia in children  <cit> . additionally, these tests are time-consuming and stressful for the child and family. most recently, genetic testing of the gjb <dig> gene has been added to the diagnostic evaluation. mutations in this gene account for about 20% of children with nonsyndromic snhl  <cit> . recent data has demonstrated the utility of gjb <dig> analysis in determining prognosis, the best intervention, and recurrence risks to future children and other family members  <cit> . genetic testing can also predict the absence or onset of a syndrome for which the other clinical problems may not be present at birth or early childhood . when the genetic etiology can be determined in a large cohort of patients, it will provide a better understanding of the genotype-phenotype correlations that exist for each of the genes examined, which could direct specific therapeutic interventions.

beyond gjb <dig>  it is uncertain what genetic mutations are the next most prevalent in patients with hearing loss. other genes thought to play a significant role in childhood hearing loss include slc26a <dig>  <cit> , usher type  <dig> genes   <cit>  and otof  <cit> , though no studies have looked at many genes to appreciate their relative contributions. the identification of over  <dig> genes causative for snhl now makes it imperative to develop a high-throughput resequencing assay. such a technology would allow for a more comprehensive and therefore higher yield diagnostic evaluation of the etiology of hearing loss in patients. current technology allows for widespread screening of only the most common genes related to snhl .

recent advances in molecular microarray technology have made it feasible to rapidly screen dna samples for thousands of possible genetic mutations  <cit> . the advantages of microarray-based screening include its accuracy, simplicity, efficiency and cost-effectiveness when employed on a large scale. however, call rates among different microarray designs may vary considerably  <cit> . while computational methods for reduction in false positives due to systematic effects have previously been proposed  <cit> , inadequate call coverage is also a considerable limitation of the resequencing array-based approach  <cit> .

the efficiency of sequence-specific hybridization is dependent on the properties of the probe and target sequences  <cit> . high gc-content, presence of a nearby snp and cross-hybridizing sequences are known to affect base-calling, thus limiting the capacity of resequencing microarrays. it has been shown that c-rich probes perform better than the complementary g-rich probes  <cit> . additionally, it has been reported that nearly 80% of no-calls can be resolved by visual inspection of the intensities as one of the strands provides a clear signature for these positions  <cit> . however, there are no existing computational approaches that leverage such sequence-specific characteristics in an attempt to resolve gseq no-calls that have a distinct signature on one strand but are still ruled no-call due to improper hybridization on the complementary strand.

gseq is known to produce very few false negatives, thus providing a highly sensitive test. however, follow-up dideoxy sequencing for resolution of no-calls leads to an additional variable cost, a factor which needs to be carefully considered for clinical application of the technology. to this effect, we propose a novel algorithm for resolution of no-calls from gseq. it should be noted that the algorithm is not designed to be an alternative to gseq. instead, it provides an optional step for salvaging unresolved bases from gseq before initiating confirmatory dideoxy sequencing.

our work focuses on evaluating the effectiveness of resequencing arrays as a tool for variant detection and discusses the impact on base-calling of adopting additional computational algorithms and laboratory protocols. this study presents the results from hearing loss arrays developed in two different research facilities and highlights some of the approaches we adopted to enhance the applicability of the arrays in a clinical setting.

RESULTS
overall array performance
the harvard array contained  <dig> genes . performance characteristics were determined from data analyzed for a set of  <dig> arrays run after protocol optimization . the average base call rate across the  <dig> arrays  was  <dig> % using affymetrix gdas  <dig> . we confirmed every variant call with dideoxy sequencing to determine the false positive rate. on average, about  <dig> variants were called per array but only 28% were true variants and the rest were false positives. dideoxy sequencing of  <dig>  bases across  <dig> arrays was performed and the data compared to array calls. factoring in false negatives and false positives, we obtained an average base call accuracy of  <dig> % across the  <dig> arrays.

percentages are obtained by averaging individual percent values over all arrays.

a: bases called/total bases on array

b: correct calls/total calls

c: wild-type bases incorrectly identified as variants/total calls * 100% 

d: true variants incorrectly called wild-type/total calls * 100% 

e: wild-type bases incorrectly identified as variants/total variant calls * 100%

f: true variants incorrectly called wild-type/total true variants * 100%

g: average number of bases not called per array

h: number of exons that need follow-up sequencing to interrogate no-calls or variant calls

*:  <dig> harvard arrays with full dideoxy sequencing results were used for determination of false negatives and overall accuracy. however, no-calls and variant calls across all  <dig> harvard arrays were used for call rates and false positive rates.

the cincinnati array also contained  <dig> genes,  <dig> of which were common to the harvard array . we ran  <dig> arrays in the pilot batch and characterized array performance. base call rates for these  <dig> arrays  ranged from  <dig> % to  <dig> % with an average call rate of  <dig> % using gseq  <dig>  . dideoxy sequencing was performed for  <dig>  of the bases and comparison of this data with array calls gave a call accuracy of  <dig> % with nearly  <dig> false positives per array.

improved array performance with protocol optimization
when we compared data from cincinnati and harvard arrays, the number of no-calls and false positives from the former were found to be higher. early data from the harvard arrays had shown that call rate worsened when the fragmentation was incomplete and that the bases most affected were those within the long range pcr fragments. in addition, the reproducibility of the quantity of product from long range pcr was less. based upon these two factors, the target amplification process for cincinnati arrays was modified. instead of using a combination of long and short range pcr , as was employed in the pilot batch, all long range pcrs were converted to short range resulting in  <dig> fragments ranging from  <dig> to  <dig> bases in length. the impact of using shorter pcr products was evaluated by comparing array data across the two protocols . a total of  <dig> arrays  were run with the optimized "short range pcr only" protocol and an average call rate of  <dig> %  was obtained with gseq . dideoxy sequencing was performed for  <dig>  of the bases and comparison of this data with array calls gave an array call accuracy of  <dig> %. the average number of false positives dropped from  <dig> to  <dig> per array. the modified protocol with shorter pcr products was then adopted for subsequent arrays.

detection of insertions and deletions
through dideoxy sequencing, we identified four cases with at least one insertion or deletion  in tmprss3), of which  <dig> had been previously reported and therefore had probes tiled on the array for their detection  . we analyzed array data to look for no-calls or variant calls in the vicinity of the indel sites but did not observe any such patterns for the 35delg and 167delt alleles. it should be noted that the local high gc-content surrounding the 35delg  and the 167delt  would be expected to make detection extremely difficult. on the other hand, there was a continuous stretch of  <dig> no-calls and a variant call spanning the deleted bases of the tmprss <dig> gene that led to the detection of the mutation. we also analyzed raw feature intensities within fragments to see if indels cause degradation in intensities surrounding the variant site. we observed lower peak intensities surrounding the tmprss <dig> mutation but did not find such evidence for either of the single base gjb <dig> deletions . gdas/gseq are currently not designed for identifying indels so their low detection rate was an expected observation.

differential impact of high c-content and g-content on probe performance
in agreement with previously reported findings  <cit> , we observed that an increase in probe g- and c-contents have differential impact on performance. we used complementary feature quartets to determine intensities associated with the c- or g-content of a probe. intensity characteristics varied differently with respect to an increase in c- or g-content and average peak intensity was affected more severely by a high g-content than by an equally high c-content . in order to assess if our data demonstrated previously reported debilitating effect of stretches of gs  on probe performance  <cit> , we compared hybridization intensities among probes with the same g-content grouped based on the presence or absence of g-stretches . for the same g-content, probes with g-stretches produced lower peak intensities than probes with c-stretches or without any stretches of gs or cs .

overall array performance with sprofiler
sprofiler was only used on no-calls from gdas/gseq. examined bases were called wild-type based on single-strand evidence or were left as no-calls depending upon the feature intensity profile. base calls were subsequently compared against gseq and dideoxy sequencing calls. table  <dig> and figures  <dig> & <dig> provide detailed comparison of call rates, number of false positives and false negatives before and after analyzing gseq calls with sprofiler. for cincinnati arrays run with short and long range pcr fragments, the average call rate increased to  <dig> % . the average number of no-calls dropped from  <dig> to  <dig> per array and the number of false positives dropped from  <dig> to  <dig> bases per array. improvement was obtained at the cost of incorrectly assigning an additional  <dig>  true variants per array as wild-type. for the optmized cincinnati arrays, average call rate increased to  <dig> %  with  <dig> % call accuracy and number of no-calls dropped from  <dig> to  <dig> . the number of false positives dropped from  <dig> to  <dig> per array with the application of filters to screen variant calls based on low quality scores and the number of no-calls and variant calls in the vicinity. improvement was achieved at the cost of an additional  <dig>  false negative per array. we also calculated the number of exons per array that would need to be interrogated with dideoxy sequencing in order to resolve no-calls and confirm positive calls. after processing gseq calls with sprofiler, the average number of exons to be sequenced in order to clarify no-calls and confirm variants dropped from  <dig>  to  <dig>  per array.

when using sprofiler on the harvard arrays, the average call rate increased from  <dig> % to  <dig> % and number of no-calls dropped from  <dig> to  <dig> per array . false positive calls could be reduced from  <dig> to  <dig> per array with the filters for false positive calls. an additional  <dig>  variants were falsely called wild-type using the algorithm. because all no-calls are followed up by dideoxy sequencing, the implementation of the sprofiler resulted in substantially fewer exons  needing follow-up.

clinical sensitivity of arrays
a detailed list of all variants and associated frequencies in the patient cohorts and control populations is included in additional file  <dig>  a total of  <dig> true variants were detected across  <dig> harvard arrays, out of which,  <dig> were called wildtype by gdas . interestingly, the  <dig> missed variants represent a single common snp  seen in  <dig> different arrays. as such, it appears that this single substitution may be problematic. the basis of the poor sensitivity for this variant did not appear to be overall high gc-content, which was 52%, nor a local g/c stretch . of the  <dig> variants,  <dig> represent rare variants, many of potential clinical significance. none of these were missed by the array, although  <dig> were assigned no-calls. of the  <dig> true variants identified across the  <dig> optimized cincinnati arrays,  <dig> synonymous variants  were called wild-type by gseq . the cdh <dig> and myo7a variants were found to lie within a g/c stretch with probe gc-contents of 68% and 52% respectively but the kcnq <dig> variant was not associated with high gc-content or a g/c stretch.

a: all  <dig> wild-type calls  were due to a single repeatedly miscalled common benign variant in myo7a .

b: false negatives were from cdh <dig> , myo7a  and kcnq <dig> 

after excluding synonymous and/or common variants, 18/ <dig> patients examined by the cincinnati array and 9/ <dig> patients examined on the harvard array had at least one variant of potential or likely clinical significance . see additional file  <dig> for a full list of all variants found on a per patient basis. to further assess the likelihood that each variant may be disease-causing, efforts are currently underway to examine these variants in further control studies and using in silico algorithms to predict protein impact. after these studies are completed, variants with potential clinical significance will be confirmed in a clia environment with results returned to patients under an irb approved protocol.

discussion
serial molecular techniques  have been employed for detection of mutations associated with disorders showing high genetic and allelic heterogeneity but they can be laborious requiring high turnaround times and show little difference in their direct costs per base, which are high  <cit> . conventional serial methods can be especially ineffective for screening large genes without definite hot spots for disease-associated mutations  <cit> . although new advancements in next generation sequencing will soon replace all large scale sequencing platforms, these technologies are still too costly for medium size applications of targeted disease sequencing. high-density oligonucleotide microarrays provide an efficient and economically competitive method for genetic screening of heterogeneous disorders by allowing parallel resequencing of multiple genes in a single experiment. since the first study reporting detection of known genomic variants using oligonucleotide arrays  <cit> , several others have been published describing the principles of resequencing array technology  <cit>  and its application for genotyping in prokaryotes and eukaryotes  <cit> .

we developed two resequencing microarrays containing  <dig> unique genes implicated in nonsyndromic snhl. array base calls were compared to dideoxy sequencing to determine accuracy. through optimization of protocols and data analysis methods, similar high-quality performance measures could be achieved for microarrays developed at two independent research facilities and containing different sets of genes.

the critical performance characteristics we attempted to understand and optimize are call rate, sensitivity and specificity. affymetrix gseq is an upgraded version of the gdas base-calling software and offers some additional features as described in the gseq technical datasheet http://www.affymetrix.com/support/technical/datasheets/gseq_datasheet.pdf. however, they both employ a base-calling algorithm built upon the adaptive background genotyping-calling scheme  developed by cutler and colleagues  <cit> . gdas and gseq produce few false negatives because these algorithms are conservative in making wild-type calls. false positives or no-calls do not represent a lack of test sensitivity when they are followed up by dideoxy sequencing; however, they compromise the cost-effectiveness of the technology if a large amount of sequencing is required. in our hands, the cost reduction is roughly a 25%-50% reduction compared to traditional capillary sequencing when thorough follow-up is employed to resolve all variant calls and rare no-calls. the exact reduction depends on the degree of multiplexing employed in the up-front pcr step and the amount of follow-up sequencing that is needed. the latter factor is unique to each test depending on the sequences included, pcr robustness, the amount of dna variation in the regions tested and degree of bioinformatics and test optimization that has been achieved.

it has previously been suggested that large pcr amplicons do not hybridize efficiently to immobilized probes possibly due to steric constraints on the approach of the target dna  <cit>  and this finding has been taken into consideration during design of nucleic acid amplification strategies  <cit> . optimizing the target amplification process to include only short range pcr improved the overall array performance in the cincinnati arrays, thus providing further evidence for the relationship between pcr amplicon length and hybridization efficiency. it should be noted that the data generated by the harvard arrays was based upon a combination of short range and long range pcr. however, the harvard group has also discontinued use of long range pcr in subsequently developed array-based sequencing tests. this is because the efforts needed to continually optimize the fragmentation of long range pcr fragments and the additional limitations caused by diminished dna quantity and variable amplification efficiency in long range pcr do not outweigh the benefits. for most nuclear genes with dispersed exons, only one to a handful of exons can be combined into a long range pcr reaction limiting the efficiency gained by this approach. in contrast, amplification of long stretches of contiguous interrogated dna, such as that present in the mitochondrial genome, enables the highest efficiency savings for long-range pcr approaches.

average call rates of  <dig> % and  <dig> % for all of harvard arrays and the optimized cincinnati arrays respectively were achieved using gdas/gseq. previous resequencing array-based studies  <cit>  have reported call rates ranging from  <dig> % to 98% with gdas/gseq. while our call rates are within the high end of reported ranges, a large percentage  of the tiled exons required sequencing to follow-up on ambiguous calls, representing a limitation to clinical application of the technology under the current methodologies.

while it is well known that the gc-content of a probe can impact hybridization http://www.affymetrix.com/support/technical/technotes/customseq_arraybase_technote.pdf,  <cit>  c-rich probes perform better than g-rich probes for the identical site when complementary strand quartets are compared  <cit>  and fluorescence intensity declines with g-richness of a probe  <cit> . additionally, bases within the g-stretch of a probe produce lower peak intensities, especially for stretches with ≥  <dig> continuous gs. it has previously been suggested that probes with multiple gs in a row  tend to have higher cross-hybridization signals possibly caused by formation of g-quartets due to multiplex binding  <cit> .

taken together, the above findings imply that sites interrogated with g-rich probes may show stronger signal on the complementary strand employing c-rich probes. by applying additional computer algorithms  to reduce gdas/gseq no-calls by utilizing a distinct signal on either strand, 86% and 82% of the no-calls could be resolved for harvard and cincinnati arrays respectively while maintaining overall accuracy at ≥ <dig> %.

mutations in gc-rich regions have previously been reported to be missed  <cit> . we also observed that variants that could be correctly identified were associated with lower gc-content probes as compared to those that were missed . adjusting probe length and positioning a known variable base at either end of the probe have been suggested to improve variant detection in gc-rich regions  <cit> .

small indels constitute nearly 24% of disease-causing mutations in the human gene mutation database as of november  <dig> and have been shown to cause severe phenotypic variability  <cit> . the inability of resequencing arrays to have high sensitivity for detecting novel indels, especially those involving only a few base pairs, presents a significant limitation  <cit> . regions showing aberrant hybridization patterns can be selected for confirmatory dideoxy sequencing to potentially detect variations  that are missed with resequencing arrays. however, as is evident from our data, small indels present challenges as they sometimes do not lead to easily discernible variability in hybridization patterns. after interrogating three different deletions on our arrays, we could detect only the largest deletion through a series of no-calls and a variant call in the region. further algorithmic and technical improvements could entail development of a scheme for detection of indels by virtue of identifying a regional drop in signal intensity. although we only observed a single intensity drop for one of the indels included in our validation, modification of the technical protocol to limit the secondary amplification of signal, originally employed to increase detection of low level transcripts in expression arrays, may not be necessary for resequencing arrays interrogating germline nuclear dna variations present with at least 50% signal compared to wildtype. this protocol modification could lead to better discrimination of signal intensity drops across regions with an indel. in the interim, we have employed clinical oligo hybridization based sequencing technology only for diseases in which most mutations are substitutions  or the disease is recessive  in which detection is aimed at finding at least one of the pathogenic variants followed by capillary sequencing of the relevant gene to detect a second mutation that may have been missed.

although a minor loss in analytical sensitivity is incurred through the use of hybridization based sequencing, this can be balanced with the increased efficiency and diminished cost of this technology compared to traditional approaches. resequencing array-based mutation detection has been reported to produce a throughput of nearly  <dig> patients per technician per month and can thus be used as a method for initial genetic screening while being supplemented with conventional dideoxy sequencing for samples in which the array cannot identify a causative mutation  <cit> . in our hands, this technology has allowed us to cut the cost of testing roughly in half compared to dideoxy capillary sequencing approaches also employed in our clinical laboratories. as such, we have now implemented this technology in four different clinical tests including the hcm cardiochip, dcm cardiochip, noonan spectrum chip, and otochip as described on http://pcpgm.partners.org/lmm.

CONCLUSIONS
in conclusion, the described hearing loss gene chips represent the first resequencing arrays for molecular testing of nonsyndromic pediatric snhl. using the experimental protocols and additional computation algorithms described here, this technology provides a rapid, cost-effective and reasonably accurate method for identifying known and novel sequence variants in targeted dna regions. however, follow-up sequencing required to resolve no-calls and false positives does limit the cost-effectiveness of the technology.

