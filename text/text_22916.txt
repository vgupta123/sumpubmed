BACKGROUND
the rapid advancements in the field of genome sequencing is aiding our understanding of genome organisation in many biological systems
 <cit> . these tools are intended to analyse high throughput next-generation sequence  data and present biologically relevant interpretations. given the high throughput nature of present day genomics, heuristic algorithms are implicated to identify or predict genome variations as small as single base nucleotide substitutions  to insertion-deletion events  and copy number variations . hence, it is imperative for developers of ngs data analysis pipelines to establish the limits of their predictions based on simulated data as in current practice. in the last five years, computational biologists and bioinformatics specialists have developed new algorithms for different types of variant calling, have implemented existing algorithms for short-read mapping to reference genomes and/or optimized pipelines to perform a specific type of primary and secondary analysis
 <cit> . snvs, indels and cnvs are the most common types of biological variations in the genome. the tools to detect these variants have the common objective of finding novel variations with low frequency of false positives, rediscovering known variations in the genome of interest and facilitate subsequent genome visualization and interpretation. hence, availability of reliable and realistic simulated dataset bearing the three major types of genomic variations  is critical to test the operational limitations of newly developed or existing tools. this approach allows computational biologists to generate simulated datasets with biological meaning and sensitive to systematic error inherent to different sequencing technology platforms.

although, next-generation sequencing  instruments generate reads of various lengths and with varying error profiles, the most popular source of data remains sequencing instruments from illumina, which employs a sequencing-by-synthesis
 <cit>  chemistry to generate short-reads. keeping this in mind, we have developed an efficient, fast simulator and a read generator that mimics sequencing quality generated by illumina platform. hence, sinc uses a realistic error model based on base quality values of reads generated by the most prevalent sequencing platform, hence catering to the larger interest group. although we have used the illumina-derived base quality values, it can easily be adopted for any other sequencing platform by supplying an instrument-specific error profile.

currently available tools can either generate platform-specific, error-profile based reads or simulate reads across platforms
 <cit> . it is also in our interest of disambiguation to classify the existing simulators into two major classes based on their functionality. first, the stand-alone read generators  like metasim
 <cit> , flowsim
 <cit> , 454sim
 <cit> , pbsim
 <cit> , genfrag
 <cit>  and art
 <cit>  among others with functionality limited to read generation. the second class of simulators  include pirs
 <cit> , gemsim
 <cit> , dwgsim
 <cit>  , which have the option of simulating genomic variations coupled with read generation functionality. each of the above mentioned tools, although has its own set of advantages, suffers from either having a simplistic error model , errors that does not model real data , does not assign quality values to reads , does not simulate illumina reads  or does not simulate multiple types of variations . interestingly, none of the existing srg simulators present the option to simulate cnvs. hence, we have developed and implemented a c-program, sinc, to enable simulation of all the three major types of genomic variations, snvs, indels and cnvs, coupled with a multi-threaded, error-profile based read generator. sinc has obvious advantages over the popular srg simulators as dwgsim simulates reads with identical dummy base quality values relieving the data of any base-quality related effects, pirs cannot simulate cnvs and gemsim simulates only snvs. sinc models errors based on real data from illumina instruments as in pirs and additionally presents fine tuned options to replicate biologically meaningful variant simulations including cnvs. the multi-threaded algorithm in sinc for read generation provides substantial advantage in run time and allows for seamless simulation of high coverage data in a desktop environment.

here we present an evaluation of sinc using commonly used snv, indel and cnv detection tools. the speed, accuracy and efficiency was compared against other popular simulators and read generators.

implementation
sinc performs two jobs; first it simulates variants  and then it generates reads . sinc simulator consists of three independent modules  that can either be executed independently in a mutually exclusive manner or in any combination.

snv simulation
the exact frequency of snps in the human genome has not yet been determined accurately. based on inferences from  <dig> complete genomes representing several human populations in the  <dig> genome data, the current range of frequency of snv lies between one per  <dig> to  <dig> bases
 <cit> . for this purpose, we have assumed that the substitution events in human genome are independent and random. sinc simulator accepts a user defined percentage value to simulate snvs. the algorithm identifies this percentage value as the fraction of genome to estimate the number of snvs and simulates snvs across the genome. to maintain positional identities of these snvs with respect to their frequency, that are normally distributed over the sequenced genome, the mean distance of separation  between snvs is calculated .

this ensures that the simulated snvs are well distributed over the genome. a positional filter is applied to remove the outlier snvs, which are less than  <dig> bases apart. sinc simulator neglects snvs simulated in the n-regions of the genome . then the algorithm applies a user-defined transition to transversion  metric to maintain the biological significance of the snvs across the genome. a ti/tv ratio of  <dig>  was maintained across the population of simulated snvs with 20% inherent heterozygosity to simulate human genome data as previously reported
 <cit> . the flow chart illustrated in figure 
1a depicts the algorithm for simulating snvs.

indel simulation
insertion and deletion  events have a wide range of size-based variability. sinc simulator simulates short, medium and large indels in the range of 1-10 bp 11-20 bp and 21-100 bp respectively in concordance with earlier studies
 <cit> . the ratio of incidence of insertions to deletions and heterozygous to homozygous indels in human genome is set to 1: <dig> based on previous observations
 <cit> . the flow chart in figure 
1b depicts the algorithm for simulating indels.

the algorithm first randomly generates the position for indels and then uses a filter to replace any indel within the region of the n-region of the genome  with one in the sequenced region. to remove duplicates, the simulated indels are coordinate sorted and only the unique locations are retained. usually, a redundancy of 2-5% is filtered out post coordinate sorting . hence, an additional 5% of indels are generated at the initial stage of the algorithm to account for the loss of indels at the duplicate removal step. in the next stage of the algorithm, the frequency of short, medium and large indels was factored in based on previous literature evidence for their distribution in human
 <cit> . the indel simulation produces two output files assuming the bi-allelic nature of human genes, each containing allele-specific coordinate information of simulated indels. among the total number of simulated indels, the algorithm simulates 30% single base indels, 20% repeat expansions, 49% 2-20 bp indels, and 1% long indels including repeat expansions .

cnv simulation
the cnv simulation constitutes the final step of the simulation algorithm, as it can ply in a sequential manner post indel simulation. since the input files from indel simulation may contain heterozygous indels, which may be of unequal size, hence the cnv module takes it into consideration and prevents the possibility of boundary overlaps with indels. the flow chart in figure 
1c depicts the algorithm for simulating cnvs.

unlike the indel module, here the size and location of the variants are both generated dynamically with the flow of the program after obtaining the feed from the user to determine the number of cnvs and their range of size distribution . such simulated data is particularly useful to test the accuracy and sensitivity of a new or existing cnv caller across a wide range of cnv sizes. the algorithm then filters the simulated cnvs based on its coordinates. first the span of each of the cnvs are evaluated to ensure correspondence with chromosomal boundary in either allele and subsequently the cnv boundaries are checked for overlap with neighboring cnvs. the cnv is logged and the next iteration of location and size are generated upon meeting the aforementioned conditions. unlike the snv and indel simulation modules, the annotation data for both alleles in the cnv module is stored in the same file in the form of a tabular data. the tool also outputs a simplified results file , which can be read easily by any program for visualizing cnvs.

read generation
sinc has a read generator part that generates short reads using a multi-threaded approach utilizing the parallel processing power of commonly used quad-core desktop/laptop architecture. the process of read generation uses a quality profile distribution-based error-model. we have used publicly available 100 bp read pair data derived by using illumina instrument from the sra database to generate the quality profile distribution and assessed the quality distribution for both forward and reverse reads of the training set and data post read generation . for customization purpose, the tool is provided as a standalone tool in the sourceforge package so that the user can generate independent error profiles for reads with certain read lengths to be used during the read generation stage. the read generation algorithm follows a “divide and conquer” approach where each thread spans the input sequence once and the number of reads required to obtain the user defined coverage are pooled from the estimated number of threads. user-specified cores utilization is implemented in the sinc read generator to prevent over-utilization of available cpu resources. the other major user defined parameters, include read length, error profile, insert size  and standard deviation of insert size . the algorithm initially creates one thread, which generates reads for the input fasta file. depending on the read pairs generated in the first run, the numbers of threads required to obtain the desired coverage are calculated and then executed in an iterative manner based on the number of cores specified by the user . sinc is optimized to run with  <dig> threads suiting a quad-core processor.

evaluation of sinc
variant re-discovery
we used human chromosome  <dig> sequence from the ucsc build hg <dig> for generating snvs and indels using all the four different srg simulators. the snv rate, indel percentage and coverage was maintained across all the tools and the resulting reads were aligned using novoalign
 <cit> . these mapped files were subject to snv and indel detection by gatk
 <cit>  and pindel
 <cit>  respectively . the predicted snvs and indels from the different simulators were compared to the actual number of incorporated variants to estimate the percentage rediscovery. rediscovery percentage using pindel has a limitation that it merges short indels within a span of  <dig> nucleotides of each other leading to a slight loss  of rediscovered indels across all the simulators .
 <dig>  the rediscovery percentages of c) heterozygous and d) homozygous snvs are compared.

time profiling
given the high-throughput nature of ngs data, generating the bulk of simulated data still remains a time consuming process. hence, we have implemented a “divide and conquer” approach to the read generation module to reduce the time footprint in generating high coverage data. this property allows user to simulate data at a high coverage  without inordinate expense of time. sinc can utilize  <dig> to  <dig> threads for optimal function. our comparison was set up based on default use of  <dig> core ranging upto a maximum utilization of  <dig> cores in sinc versus the other tools . details are provided in the additional file
 <dig> 

transition/transversion  ratio
a transition mutation involves a change from purine to purine or pyrimidine to pyrimidine and a tranversion mutation involves a change from pyrimidine to purine or vice versa. this makes a transversion event twice as favourable as a transition event for any random mutation event. hence, the ti/tv ratio for a random variation resulting from systematic errors in the sequencing technology, alignment artifacts and data processing failures should be close to  <dig> . as published earlier, ti/tv ratio for whole genome falls between  <dig>  -  <dig>  for both known and unknown snps. sinc incorporates a user-defined ti/tv ratio for simulation of snvs.

all the scripts to simulate variants and generate reads used default parameters and details of the scripts used are given in the additional file
 <dig> 

RESULTS
we have developed a simulator for all commonly occurring biological variants in the genome along with a read generator. we compared the latest pick of simulators with sinc simulator and read generator. in our model for snv simulation, we have limited the range of simulation of snvs using a distribution of distance between two consecutive snvs. based on snv frequency studies in human genome
 <cit> , under default simulation parameters the mean distance between two consecutive snvs, davg, is set dynamically between  <dig> to  <dig> bases depending upon user defined input for snv rate. in indel simulations, the complexity of simulation depends on the frequency of indels in the simulated data. in the default mode for indel simulation, the algorithm is sensitive to the natural frequencies and size ranges as evidenced from existing literature
 <cit> . the model for cnv simulation is an extension of the indel simulation, wherein the cnvs are dynamically generated while maintaining the allele specificity and genomic positions of indels simulated in the prior step. the simulated variants are captured in log files, combined with input allele fasta files and processed by a multi-threaded process to enable fast-paced read generation.

in order to assess the number of variants post simulation and read-generation in comparison to the number of variants that a sensitive variant caller like gatk
 <cit>  identifies, we used variant re-discovery rate as one of the parameters of evaluation. variant re-discovery, although not linked with the efficiency of the simulator, can be used as one of the parameters to judge the combined efficiency of the simulator + read-generator + variant calling process. the process of re-discovery can be impacted by the read-generation step, which incorporates different error models and/or base quality values. given the fact that we used the same tool  across all the simulators + read-generator pairs, discrepancies in the number of variants rediscovered provided us with indirect evidence on the individual tools’ efficiency. the most likely explanation for varying re-discovery rate could be due to different methodology adopted during the process of read generation where different error models  are taken into consideration. additionally, variant re-discovery rate is a widely used parameter to assess the quality of variant calling and analysis, including in the  <dig> genome project. in order to delineate coverage from that of combined simulation + read-generation + variant calling and re-discovery, we simulated reads at 10x, 20x or 30x coverage and found that the coverage does not affect the re-discovery rate of snps using sinc . the snv rediscovery percentage suggested that sinc was at par with pirs in the efficiency of simulating snvs and comprehensively outperformed both gemsim and dwgsim , suggesting the role of similar error-profile based model during the read generation process. although other tools like dwgsim and gemsim are close to sinc in homozygous rediscovery rate , sinc outperforms both these tools for heterozygous rediscovery rate  suggesting the importance in simulating both homozygous and heterozygous real variants. in the rediscovery of indels, sinc emerges as the only simulator with the highest percentage of total rediscovered indels, ahead at least by 15% from the closest contender pirs . we further tested the accuracy of the rediscovered indels by adding a size-based constraint and estimated the percentage rediscovered in the size ranges containing  <dig> to  <dig>   <dig> to  <dig>   <dig> to  <dig> and  <dig> to  <dig> nucleotide long indels. these size ranges were simulated due to their overall high  natural prevalence in human genomes
 <cit> . this exercise corroborated the superiority of sinc in detecting indels while retaining the size-based constraints implicated in the simulation algorithm in comparison to the other tools tested . the numbers of snvs and indels rediscovered by sinc are especially important because the total number of snvs simulated by sinc is about 10-20% more than the other tools tested and 20-40% higher for indels. another significant advantage of sinc is apparent from the rediscovered heterozygous snvs. as depicted in figure 
2c, the difference in homozygous snv rediscovery is rather conserved across the simulators compared to figure 
2d, which gives sinc an edge in conservation of zygosity of the calls post read generation. notably, pirs although uses a similar error-profile as sinc, it does not catalog the simulated snvs to facilitate rediscovery of heterozygous and homozygous snvs separately. the cnv module of sinc simulator was used in a previous study to test a cnv prediction tool, cops
 <cit> , and was used to compare its accuracy and sensitivity to other popular cnv prediction tools. we were unable to perform a comparative analysis of the cnv module in sinc due to the unavailability of any published tools that can simulate cnvs. however, as previously shown
 <cit> , the percentage rediscovery using multiple cnv discovery tools like cnaseg cnv-seq, cnvnator and svdetect yielded >90% cnvs.

next, we wanted to test the speed of sinc read generator. figure 
 <dig> depicts the advantages that sinc provides during read generation due to implementation of a “divide and conquer” approach by efficient utilization of c thread functions. the tool was tested for its processing capability under a range of multi-threaded options ranging from default utilization of  <dig> core to a maximum utilization of  <dig> cores. sinc accomplished read generation at least one and a half times faster than pirs and three times faster than art; the two most recent illumina read simulators . the time profile demonstrated substantial reduction in time footprint using sinc in comparison to the other tools sampled in our study. this difference in generation time of simulated data is reflected clearly in generating high coverage datasets from large genomes, human genome in our case as shown in figures 
3b and c.

although there are a multitude of popular tools capable of predicting genomic variations using high-throughput sequence data, the generality of such tools are questionable. in many ways, a simulated dataset is crucial towards determining the success of predictive algorithms in the context of real dataset. simulators that can simulate variants and generate reads are valuable tools used for developing and testing tools for sequence data analysis. an ideal tool that can both simulate multiple variant types  and generate sequencing reads taking into account a realistic platform-specific quality-profile of an sequencing instrument is currently lacking. we tried filling this void by designing a versatile and fast tool that can generate multiple types of biological variants  and can run on a minimalistic quad core desktop computer using multi-threaded option. the time advantage obtained in sinc could be attributed to the optimized algorithms and efficient use of c thread functions to manage the i/o streams. this advantage is also obvious in a single core, which delegates the bulk of the data generation to multiple threads to ensure efficient use of memory in line with “divide and conquer” approach. the optimization of multiple core usage is available upto  <dig> cores in quad-core architecture.

another major functional advantage of this tool is its ability to simulate cnvs. cnvs have been shown to contribute more towards genetic diversity than snvs and are conspicuous by their pervasiveness in human genome
 <cit> . the advent of ngs platforms has geared multiple efforts to build frameworks towards identifying cnvs and assess their penetrance in disease etiology. however, most of these efforts are only partially effective in capturing population-based generalizations. in order to build a robust and generic framework, it is imperative to build exhaustive datasets with the known signatures and explore the range of false discovery rates inherent to the tools and subsequently improve them. the ability to create such datasets will definitely improve the approach and accuracy of predictions made by existing tools. hence, a flexible, user-input based simulator has substantial application in building useful datasets allowing for improvement of current approaches towards variant discovery as a whole. although there have been efforts in the past to discovering cnvs using ngs data, currently there are no available simulators to fine-tune cnv detection algorithms. sinc simulator not only fulfills the simulation of cnvs but an additional functionality of sinc simulator is to generate allele-specific cnvs. this is particularly useful if one has to understand the copy number changes at an allelic level important for many diseases
 <cit> .

production of large amount of heterogeneous data in high-throughput biology requires sophisticated computational tools for efficient analysis, storage, sharing and archiving. this requires resources, both software and hardware, and interoperability of computational resources. a common practice among computational biologist is to use simulated data to test the efficacy of the tools before applying them to real dataset. although there are many simulators available currently, there is none that suits the need of every computational biologist wanting to make tools for short-read sequence data. keeping this in mind, we have developed a tool to help computational biologists create simulated datasets using only one simulator that can span across sequencing platforms and variant types . although, sinc simulator was tested with human genome, it is versatile to address the complexity of any genome, its substitution rate, variant frequency and transition to transversion ratio. large genomes, like that from many plants, need time to generate simulated reads at high coverage and this is where the multi-threaded capability of sinc scores high in comparison to other tools. by using a standalone quality-score distribution model of real dataset, sinc provides an opportunity to individual user to generate reads at different read lengths but with realistic quality.

CONCLUSIONS
we report a tool called sinc that can simulate and generate short sequence reads with different types of biological variants. the ability of sinc to generate realistic fastq reads based on illumina read quality profiles along with its capacity to simulate multiple biological variants and generate reads concurrently makes it a powerful option in a variety of simulation studies and a part of computational biologists’ essential toolkit.

availability and requirements
project name: sincsimulator

project home page:http://sourceforge.net/projects/sincsimulator

operating system: linux

programming language: c

other requirements: gnu scientific library, pthreads library

license: creative commons attribution non-commercial license v <dig> 

any restrictions to use by non-academics: license needed

abbreviations
snp: single nucleotide polymorphism; indel: insertions and deletions; cnv: copy number variations.

competing interests
both sp and bp are paid by strand life sciences. the authors declare that they have no other competing interests.

authors’ contributions
bp conceived the project and come up with the tool’s parameters. sp designed the analytical workflow and fixed bugs in the code. aar coded the first version of the tool. sg helped in filling parts of the code, fixed bugs and tested the tool. sp and bp wrote the manuscript. all authors read and approved the manuscript.

supplementary material
additional file 1
sinc snp distribution. a) a gaussian distribution was implemented to dynamically allocate distance between two snvs. under default conditions, which follows a snv rate of  <dig> , the mean distance, davg, between two snvs was set to  <dig> as evidenced by studies from  <dig> genome project. also, a lower limit of davg was set to  <dig> based on these studies allowing us to dynamically simulate snvs of biological relevance. b) normalized frequency distribution of simulated snvs per chromosome in hg <dig> assembly.

click here for file

 additional file 2
time profiles of sinc, and variant re-discovery numbers. time elapsed to perform one complete simulation with default options using 1– <dig> cores a) for chromosome  <dig> at 15x b) for human whole genome  at 5x. snps were re-discovered using gatk and indels with pindel.

click here for file

 additional file 3
sinc indel distribution. a) the size based frequency distribution of indels used in sinc based on literature evidence from millis et al. b) normalized frequency distribution of simulated indels per chromosome in hg <dig> assembly.

click here for file

 additional file 4
illumina-derived base quality score distribution used to generate reads by sinc. quality score distribution of reads from training sets vs reads simulated using sinc; a) for forward read b) for reverse reads. top panel: training set, bottom panel: reads simulated using sinc.

click here for file

 additional file 5
scripts used to run various tools.

click here for file

 additional file 6
coverage verses snp re-discovery rate. effect of coverage on combined process of simulation + read-generation + variant calling and re-discovery.

click here for file

 acknowledgements
we thank professor n.yathindra for encouragement. research is funded by department of electronics and information technology, government of india /2010-e-infra., 31-03-2010) and department of it, bt and st, government of karnataka, india  under the “bio-it project”.
