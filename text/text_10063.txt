BACKGROUND
recent advances in sequencing technologies have drastically reduced the cost of nucleotide sequencing  <cit>  and are rapidly establishing themselves as very powerful tools for quantifying a growing list of cellular properties that include sequence variation, rna expression levels, protein-dna/rna interaction sites, and chromatin methylation  <cit> . an expensive step in the sequencing process is sample preparation where time consuming procedures such as library preparation must be applied to each individual sample. this greatly reduces the utility of a sequencer for sequencing a small genomic region in many individuals because the cost of preparing each sample counteracts the efficiency of the sequencer. in fact the sequencing capacity in terms of the number of reads generated by the sequencer is often much higher than is necessary for the application. this raises the need for the development of multiplexing strategies that allow the processing of multiple samples per single sample preparation step at the cost of requiring additional sequencing capacity. however, in several practical scenarios, the overall cost can be reduced. one such multiplexing scheme is the use of overlapping pools  <cit> . in this scheme subsets of samples are mixed together into pools followed by a single sample preparation for each pool. typically in such a sample preparation, a barcoding technique is applied so each read generated from the pool will be able to be identified as originating from the pool. by combining the results of the sequencing with the information on which samples appeared in which pool, the mixed information from each pool can be “decoded” to obtain information on the sequence of each sample.

multiplexing pools are practical for sequencing a short genomic region in many individuals. as sequence capacity increases, it is likely that this technique will become even more practical in the future. sequencing capacity is constantly increasing and therefore it is plausible that multiplexing pools will benefit whole-genome sequencing in the future. we note that in erlich et al  <cit>  the use of multiplexing has been proven in the lab, showing that this methodology is not merely a theoretical exercise. the current techniques for overlapping pool sequencing  <cit>  are based on group testing or compressed sensing schemes. their main limitation is that they are only applicable to detect rare variants. if a variant is common in the population, it will be present in almost every pool, causing the above pooling schemes to fail in identifying which subset of the samples contain the common variant.

in this paper, we present an alternate scheme for sequencing using overlapping pools which, unlike all previous approaches, is able to quantify both rare and common variation. the key idea underlying our scheme is that we formulate the pooling problem within a likelihood framework that provides several advantages over previous methods. our scheme is flexible and can be applied to a wide variety of applications. we demonstrate this by applying the scheme to two very different applications, each of which takes advantage of the likelihood framework within our approach and is difficult to solve using previously proposed combinatorial methods.

the first application we consider is obtaining highly accurate genotype information for a set of individuals. currently, genotype microarrays are the most accurate method for measuring individual genetic variation at a base-pair level at variable locations across the genome . a typical array will collect up to  <dig>  or more genotype calls at common snps across the genome. using imputation techniques and a reference dataset such as the hapmap  <cit>  or the  <dig>  genomes project, we can make predictions for the remaining common variants in the genome. while error rates of genotyping are usually less than .5% errors at imputed variants range from around 5% in europeans, and it could be as high as 10-15% for non-european populations  <cit> . imputation accuracy is particularly poor for rare snps and for snps in regions of low linkage disequilibrium. we introduce here a scheme for obtaining highly accurate genotype information on both common and rare snps by combining genotyping microarrays, imputation and sequencing in pools of samples. this application is possible because our likelihood framework allows us to integrate the information from the imputation into the procedure to help us “decode” the information obtained from each pool. furthermore, our scheme allows us to utilize the variant frequency information obtained in each pool. our results show that our algorithm is capable of calling rare snps with high accuracy, but in contrast to previous multiplexing methods, it can also call common snps with high accuracy, by combining the imputation data with the pooling scheme. in fact, the same experiment which can obtain genotype information for rare variants combined with imputation can obtain genotype information at the common variants. importantly, the outcome of our approach results in genotype information on the common variation which is more accurate than what is collected using microarrays. this application is particularly practical because much of the follow up sequencing of populations will be done in the same cohorts in which genome-wide association studies were performed. for these individuals, genotyping at common snps using microarrays has already been performed and for many of these studies only the regions of interest are targeted for sequencing, or exome sequencing is being performed, which makes multiplexing pools a practical approach at present.

the second application we consider in this work is to rapidly screen for fusion genes in cancer samples. fusion genes play an important role in cancers and are caused by genomic rearrangements in a tumor that create new genes consisting of several exons from one gene followed by several exons from a second gene. our application considers the sequencing of rna obtained from cancer tumors with paired-end reads. the read pairs of interest are ones that span exon boundaries with each read of the pair coming from a different exon. the majority of such read pairs will map to the same gene when aligned to the reference genome and. however, read pairs from fusion genes will map to two exons from different genes. one potential approach in identifying fusion genes is to search for read pairs that contain reads mapping to different genes. the main drawback of this approach is that it leads to a very high level of false positives making it difficult to distinguish actual fusions from experimental artifacts. our application will mix rna from a large number of cancer tumors into overlapping pools and utilize the likelihood framework to decode which fusion genes come from which samples. in order to accomplish that, we extended the basic overlapping pool model to consider different levels of expression for each gene. this can be estimated from the data. our decoding scheme is based on a likelihood formulation which presents novel computational challenges compared to previous approaches. each possible configuration  is assigned a likelihood and the goal of the algorithm is to identify the most likely decoding. we identify good solutions for the problem by formulating a related problem as a linear program which we can efficiently solve. we note that these results are just the first steps in applying this framework to multiplexing sequencing pools and it is likely that better optimization algorithms and better designs of pooling schemes can lead to more substantial savings.

RESULTS
genotyping using overlapping pools and imputation
we first report the results of applying our approach to genotyping individuals to obtain both common and rare variation using combining overlapping sequencing pools with genotyping and imputation. in this set of experiments, we utilize the  <dig> birth cohort from the wellcome trust case control consortium  <cit>  data which contains approximately  <dig>  individuals. these individuals were genotyped at approximately  <dig>  snps. for every 10th snp, we set the values of the genotypes to missing and applied mach  <cit>  using the hapmap data  <cit> , an imputation algorithm, on these snps to make predictions. since the snps were genotyped in the dataset, we can evaluate the accuracy of the imputation. we filter out any snp with minor allele frequency lower than 5% since rare variants are easily genotyped using overlapping sequencing pools and the goal of these experiments is to evaluate the methods ability to genotype common variants. we simulate applying our method by generating sequencing reads by generating reads consistent with the true values of the genotypes at the missing snps for each pool and then apply our method to make predictions of the genotypes incorporating the imputation information. we then measure the increase in accuracy of our prediction relative to the imputation information.

for our experiments we consider a total of  <dig> individuals mixed into  <dig> pools which is a reduction of the total number of sample preparations necessary by 1/ <dig>  we use a very high coverage of  <dig> per individual within a pool for our experiments under the assumption that the bottleneck is not the coverage, but the number of pools, each which requires a single sample preparation step. we assume a sequencing error of  <dig> . we measure the accuracy of the predictions by comparing the predicted genotypes to the true genotypes and only call a prediction correct if the genotypes are correct for all  <dig> individuals. we note that this is a very high standard and only  <dig> of our  <dig> snps have a correct imputation prediction. our method has very high accuracy significantly improving over imputation. table  <dig> summarizes the results.

genotyping using overlapping pools without imputation
we also apply our scheme to predict the genotypes without the imputation for rare variants such as those not found in the reference. the only difference in our methodology is that in the optimization problem, for the imputation vector we use a zero vector since we expect most individuals will not have the variant. this problem is actually much easier than the case of common alleles and we get perfect accuracy for the parameters above.

cancer fusion gene detection
we evaluate our approaches ability to detect cancer fusion genes using a similar simulation framework. in this application, rna from different tumors is is mixed into overlapping pools and sequenced. in each pool we search for reads which cross exon boundaries from different genes and are evidence of fusion genes. counts of these fusion genes in each pool are then decoded to identify the samples which contain the fusion genes.

we simulate this process by generating reads in a similar fashion to the genotyping without imputation simulations. we assume that we have  <dig> cancer samples where either  <dig>   <dig> or  <dig> of the samples contain a specific fusion gene. we assume a sequence error rate of 1% and vary the coverage and number of pools in our experiments. a difficulty in this application is that each individual has a different level of expression for each gene. we simulate this by randomly selecting an expression level in the range such that the concentration of the fusion gene in the rna will differ by up to a factor of  <dig>  table  <dig> shows the results of our cancer fusion gene detection simulation experiment. for each experiment, we report the fraction of the time that the algorithm identified correctly which samples contain the fusion gene.

each entry in the table is the fraction that the algorithm correctly identified the samples harboring the fusion gene.

CONCLUSIONS
in this paper we have described a flexible framework for overlapping pool sequencing and two applications of this framework. we presented some results showing the bounds on the performance of decoding rare and common variants . we argue that due to information theoretic bounds, common variants are impossible to decode without the addition of external information; we propose to use imputation results as possible external information. in practice, it is often the case that such information is given, as many of the samples have already been genotyped through the massive effort of genome-wide association studies; in addition, current cost of genotyping has reduced considerably and is negligible compared to sequencing costs .

our decoding framework is likelihood based framework and is general enough to account for different types of data and error models. particularly, we demonstrate how our method can be extended to the case where there are different unknown concentrations of each variant in each sample as motivated by the cancer fusion gene detection example. we note that our approach to detect fusion genes using rna sequences can only detect fusion genes that are expressed in the tumor since we are sequencing rna, but this is the case for a significant subset of the total fusion genes  <cit> .

we expect that with improved optimization algorithms and better designs of pooling schemes, we can achieve even more substantial savings.

