BACKGROUND
probabilistic methods for phylogenetic inference are based on mathematical models of sequence evolution  <cit> . in the last  <dig> years, several approaches have been proposed for developing more sophisticated models, accounting for various properties of substitution processes  <cit> . one of the most well-characterized example of such an improvement is provided by the rate across sites  model  <cit> , which relaxes the assumption that all sites of a protein or a nucleotide sequence evolve at the same rate. more specifically, the ras model includes site-specific substitution rates, modeled as random variables following a gamma distribution. it generally has a better fit to the data, and it allows to circumvent certain artefacts in phylogenetic inference  <cit> . it has been implemented in most maximum-likelihood and bayesian phylogenetic software, and is now widely used for routine phylogenetic inference. more sophisticated distributions of substitution rates, such as mixtures of gamma distributions  <cit> , further increase the fit of the model to alignments, suggesting that improvements of the ras model are still possible.

functional and structural restrictions operating at a given residue may be subject to change over time  <cit> , which should be reflected by substitution rates varying not only across sites, but also across time. in this line of thought, fitch and markowitz  <cit>  proposed the covarion hypothesis: due to functional restrictions, some codons  can accept substitutions at a given time, while others  cannot. importantly a site can shift from being variable to being invariable  over time. more generally, philippe and lopez  <cit>  proposed, instead of covarion-like expression, the term heterotachy  to describe the fact that sites evolve at different rates across time.

heterotachy was shown to be frequent in both nucleotide and amino acid sequences  <cit> . for instance, up to 95% of the variable sites of cytochrome b have a heterotachous behavior within vertebrates  <cit> . importantly, both simulation  <cit>  and empirical  <cit>  studies demonstrate that heterotachy may impede phylogenetic inference. this is expected because probabilistic methods are inconsistent when the underlying assumptions of their models are seriously violated. models that handle heterotachy are thus of prime interest, particularly as larger and larger datasets are used  <cit> .

the initial covarion hypothesis, as formulated by  <cit> , makes an explicit link between site interdependencies and rate shifts, and for that reason, is not easy to implement. as a more tractable alternative, tuffley and steel  <cit>  proposed a site-independent mathematical version of the covarion idea, which was later implemented in a bayesian framework  <cit> . in tuffley and steel's covarion model, the substitution history at each site unfolds according to a doubly stochastic process: a classical first-order markov process of substitution among the  <dig> nucleotide bases, or the  <dig> amino-acids, whose substitution rate is itself time-modulated in an on-off fashion. in huelsenbeck's model, evolutionary rates of sites, when in the on state, are modeled by a gamma distribution. galtier  <cit>  proposed a variant of this model, by merging the covarion-like random effects with the site-specific random-effects introduced by the ras model: sites can take more than two rates , i.e. the off category plus, e.g., the four rates of a discretized gamma distribution. more recently, wang et al.  <cit>  propose a more general model in which evolutionary rates can switch among different rate classes when they are in a variable state.

one merit of tuffley and steel's version of the covarion model is that it aims at capturing the dynamic heterotachous scenario by using only two additional global stationary parameters: s <dig>  the switching rate from the off to the on state, and s <dig>  the rate from on to off.  note that these two parameters are both assumed to be stationary over time. on the other hand, this model assumes that rate-shifts occur in a strictly site-independent fashion, whereas, in principle, it is possible to imagine more general scenarios, in which groups of sites undergo collective rate shifts at very specific time-points, due to a sudden change of the selection pressure .

recently, kolaczkowski and thornton  <cit>  proposed a 'mixture of branch lengths'  model that could handle this kind of collective rate shifting. in this finite mixture model, which was later mathematically corrected  <cit> , each observation is assumed to arise from one of several components , each specifying a distinct and independent set of branch lengths, onto the same topology. loosely speaking, each site can "choose" among the available components that which best describes its pattern of changes along the tree. in practice, as there is no a priori knowledge of which site belongs to which component, the likelihood at each site is a weighted sum over all components  <cit> . the kind of heterotachy assumed in the mbl model  <cit>  can appear artificial at first sight, but is theoretically able to capture collective rate shifts, rather than the purely site independent on-off processes of the covarion model. in principle, the mbl model could thus provide a useful device for detecting singular and collective rate shift events.

however, the potential gain of the mbl over the covarion model is statistically expensive, because of the serious increase of the number of parameters implied *, and the weights of the components, nc-1): *, where nc is the number of components in the mixture, and s is the number of taxa. the mbl model poses practical challenges as well. for instance, in the bayesian markov chain monte carlo framework, the complicated structure of a single tree with several valuations  makes it difficult to propose update mechanisms that would be efficient for mixing in tree space, or, in a reversible-jump perspective, for averaging over the number of components. as a result, jointly estimating the phylogeny and the number of components will be a computational challenge.

a common statistical practice when facing computational difficulties is to make simplifying assumptions , and to contrast the merit of different model configurations based on their statistical fit. note that model comparisons based on likelihood ratio tests are not directly applicable here, as the set of models of interest do not all form a nested hierarchy. . an alternative is to use likelihood penalty methods, such as the bayesian information criterion , or akaike information criterion . when the number of observations  is sufficiently large, bic is asymptotically equivalent to the bayes factor, and aic to the expected relative kullback-leibler information  <cit>  although easy to compute, these two measures rely on many assumptions to estimate the penalty for the increased number of parameters. moreover, as for aic, it further assumes that the models being tested are 'not too far' from the true model  <cit> . in addition, aic seems to overestimate the number of parameters when there are many parameters compared to the sample size  <cit> . contrary to aic, bic has a tendency to under-estimation, given sparse data and results  <cit> . furthermore, in the context of mixture models, the regular assumptions for the aic and bic are no longer valid  <cit> . in any case, djuric  <cit>  argued that the penalty for over-parameterization should strongly depend on the model structure, i.e., the types of unknown model parameters. although bic works reasonably well at the practical level  <cit> , djuric  <cit>  suggested a careful examination before applying aic/bic.

another evaluation of model fitness is the cross-validation  method  <cit> : it measures the predictive power of a model fitted to a first, randomly drawn, part of the dataset, when applied to the remaining  part of the data. here, the portion of data set aside plays the role of 'future' observations. accordingly, the best model is naturally the one that best predicts these future data. compared to aic and bic, cv is computationally much more demanding, but also more reliable in principle:  this is an operational test, in which one measures the predictive power on data that have not been seen during the learning step, which guarantees the 'honesty' of the measure. in particular, it implies that there is no need to account for a dimensional penalty.  the expectation of cross-validated likelihood is an unbiased estimate of the kullback-leibler  distance between the "true" distribution of column patterns, and the distribution implied by the model  <cit> , and  in fairly general settings , cross validation is asymptotically consistent, i.e. is able to choose the true model among identifiable alternatives  <cit> . in addition to these theoretical guarantees, there is no specific requirement on the compared models .

in this work, we explore the use of aic, bic and cv for the comparison of covarion and mbl models. we first validate and examine properties of the mbl model using simulations. second, we contrast the conclusions of aic, bic and cv to the problem of determining the number of components of the mbl model, and to general comparisons with the covarion model. third, we extend our model comparisons to three real data sets from nuclear, plastid and mitochondrial compartments, and show that the covarion model is always favored over the optimal mbl model.

RESULTS
simulated data
we first implemented the mixture branch length model in the phylobayes package  <cit> . simulations allowed us to explore the performance of the mbl model when the true number of components as well as other parameters are known. various levels of heterotachy can be easily obtained by tuning a single parameter, τ, without affecting the average branch length  of the tree topology displayed on figure  <dig>  in addition, the degree of rate variation across sites was modulated by using several values of α, the shape parameter of the gamma distribution. a total of  <dig> data sets of  <dig>  sites each were synthesized under the two-component mbl model and analyzed using the mbl model with number of components varying from one to four.

when the simulated data are analyzed with the exact number of components , the inferred values of the parameters are generally close to their true values . for instance, the value of α is always inferred with an error smaller than 5%. the branch lengths and the weights are also well recovered, although only when the level of heterotachy is pronounced . interestingly, when weakly heterotachous datasets  are analyzed under the two-component model, the weight for one of the two components shrinks to almost zero, and the corresponding branch lengths become meaningless, taking on extremely large or small values.

note that the correlation between the true branch lengths of the two components are  <dig> ,  <dig> ,  <dig>  and - <dig>  with τ =  <dig> ,  <dig> ,  <dig>  and  <dig> , respectively. two components were used for the inference. when τ =  <dig> , the partition identity cannot be recovered, so the branch lengths cannot be compared with the true ones.

inferring the number of components followed a similar, but more complex, pattern . when the dataset contains a strong heterotachous signal , aic, bic and cv recover the expected number of components . in contrast, as the level of heterotachy gets weaker , all criteria almost always choose the one-component model. the amount of heterotachous signal is simply insufficient in these  <dig>  positions. interestingly, under these conditions, when the mbl model with two components is used, the weight of one of them tends to be extremely small , which is consistent with the higher fit of the one-component model. for intermediate level of heterotachy , aic supports  <dig> and  <dig> components and bic  <dig> or  <dig>  suggesting that aic might tend to overestimate, and bic might underestimate, the number of components, . in contrast, in both cases, cv recovers the correct value.

we next extended the comparisons by including the covarion model . as expected because sequences were simulated using an mbl model, the covarion model is never favored. however, under a low level of heterotachy , the covarion model performs slightly better than the two-component model, in spite of the fact that the dataset is indeed a mixture of two components. this could be due to the fact that the covarion model requires less parameters than the 2-components mbl model.

the mean  of the difference between the cv log likelihood of the current model and the model with the highest cv log likelihood is given. five random runs were performed for this two-fold cv.

real data
when applied to three real datasets from nuclear, mitochondrial and plastid compartments, cv and bic always supports the covarion model , while aic favors parameter-rich mbl model. in the selection of the optimal number of components of the mbl model, cv always favors the two-component model . in contrast, bic favors one component, except for mitochondrial alignment in which four or six components are virtually indistinguishable , and aic three or four components.

for cv, standard deviation can be easily computed and is thus indicated.

we also studied the branch lengths of the two partitions detected by the mbl model . interestingly, in the case of mitochondrial alignment, the branch lengths of the two partitions mainly differ for catarrhinian primates, i.e. they evolved much faster in component i. to know whether particular genes are involved in this heterotachous behavior, we computed the posterior probability of each site belonging to either component , and then averaged these posterior probabilities over the sites, separately for each gene. the sites belonging to the cytochrome oxidase  and cytochrome b  genes show a significantly different posterior probability of belonging to component i than the sites from other genes . a chi-square test was also performed, showing that the two partitioning of the sites, into the cox/cytb or the non-cox/cytb gene groups, and into the  <dig> components of the model, are not independent . similarly, for plastid alignment, the two components are biologically relevant. the branch lengths of one component are relatively clock-like whereas for the other one all green plants except mesostigma showed a highly accelerated rate. interestingly, rna polymerases show a significantly higher posterior probability of belonging to component ii than the sites from ribosomal proteins  in agreement with recent studies  <cit> .

observed/expected numbers of positions are indicated.

discussion
model comparisons: cv is more reliable than aic and bic
the maximum likelihood value is always improved when more parameters are added to the model. the widely used likelihood penalty information criteria, aic and bic, evaluate the fitness of models by heuristically adjusting the likelihood score. based on asymptotic arguments  <cit> , they compensate for the automatic increase of the likelihood merely due to the increase in number of parameters, using simple  formulae for the dimensional penalty. by construction, aic gives a milder dimensional penalty than bic. in many practical cases, the difference may be overwhelmed by the difference in log-likelihood between the two models. however, in the present case, and on both real and simulated data sets, aic and bic do not always reach the same conclusions .

cross-validation methods are much more expensive in terms of cpu time than these information criteria. however, they are conceptually more trustworthy, since they consist in a true blind test, i.e. instead of relying on a heuristic dimensional penalty, they measure the predictive power of the model on data that have not been seen during the parameter optimization step. in addition, they are valid even far from the asymptotic regime, i.e. when the number of sites is small. from comparisons among aic, bic and cv, we observe that bic and cv generally agree, while aic overestimates the fit of parameter-rich models. these observations are consistent with the reports that aic seems to have an inherent bias in favor of overly parameterized models  <cit> ,.

properties of the mixture branch length  model
the mbl model is able to detect heterotachous signals and recover the true number of components, sets of branch lengths, weights for the components, as well as the alpha parameter for the ras gamma distribution, when datasets are simulated with a strong level of heterotachy . in contrast, when the level of heterotachy is weak  and the alignment size is in the order of magnitude of the currently used ones , the homotachous  model is preferred. this is consistent with the observations that the performance of the homotachous model is weakly affected under weakly heterotachous datasets , and that it starts to get devastating only when the level of heterotachy gets higher   <cit> . it seems therefore that, at least on these simulated cases, when heterotachy does not impair phylogenetic inference, the classical non-mixture model is indeed found to be the optimal by standard model selection methods.

estimating the adequate number of components can be viewed as a limitation of mbl models. on the one hand, we have shown that only the computationally demanding cv is able to provide an accurate estimate of the optimal number. on the other hand, it appears that, when the number of components is too high, the weights of these useless components are small . in other words, the over-parameterized model naturally reduces, but does not abolish, the effect of useless parameters, but is logically penalized in model comparison.

interestingly, in the case of mitochondrial and plastid alignments, heterotachy detected by the mbl model is meaningful . for instance, the most important heterotachous signal detected by the mbl model on the mitochondrial data set consists in a collective rate-shift, preferentially concerning the positions of cox and cytb gene. this acceleration of the multisubunit respiratory complex cytochrome c oxidase in primates is well documented and co-evolution implies genes encoded in the nucleus and in the mitochondrion  <cit> . thus, the mbl model seems to be indeed able to detect collective behavior, corresponding to real biological events.

how to model heterotachy?
however, and in spite of the considerable interest received by the mbl model recently  <cit> , both bic and cross-validation indicate that the covarion model performs significantly better than the mbl model on all real data sets we have analyzed so far. this considerably reduces the relevance of kolaczkowski and thornton  observations, concerning the failure of current models and methods, including covarion, to correctly infer phylogenetic trees under heterotachous conditions, as it further confirms how artificial the simulation conditions were.

an obvious explanation for mbl's failure is that it is too parameter-rich  *, s is the number of species and nc the number of components). indeed, a completely new set of branch lengths has to be inferred for each component, which may be too expensive, as heterotachy may manifest itself only on a subset of the branches. accordingly, branch lengths of the two components are relatively well correlated , illustrating a parametric redundancy. the difference in the behavior of the covarion model and the mbl model on the real datasets and the simulation datasets implies that the real dataset might not have such global rate shifts  as designed in the simulation datasets.

when multiple genes are analyzed, a separate model  <cit>  is aimed at capturing heterotachous signal among genes. the only difference with the mbl model is that the number of components and their structures are defined a priori. the separate model may therefore probably suffer from the same weaknesses as the mbl model, an inherent over-parameterization due to the fact that branch lengths are well correlated among genes, with few exceptions  <cit> . on the other hand, it may lead to more accurate phylogenetic inference, in case where the covarion model failed  <cit> . this indicates that both the separate model and mbl-like approaches still deserve further studies.

mixture models generally imply numerous additional parameters. improved fitness is obtained only if most of these additional parameters are natural, i.e. have a great explanatory power. this is for example the case for the cat model  <cit>  in which components reflect the amino acid spectrum allowed by structural and functional constraints. unfortunately, the combinatorial effect is too important for mbl modeling to be efficient for instance, assuming only  <dig> independent collective rate shifts on two distinct branches, involving two intersecting groups of sites, will create  <dig> distinct site patterns, describing all possible ways a given site may have 'responded' to the first and/or to the second rate shift. in this situation, the mbl model will need  <dig> components to explain every site correctly. more generally, with s independent collective rate shifts, 2s components will be needed to describe all possible combinations that will all be likely to occur across the alignment. this combinatorial argument may explain the failure of the mbl model in practice, in spite of its ability to detect collective behaviors.

CONCLUSIONS
the covarion model, in spite of its better fit, is a purely site-independent model. as such, it may not be optimally efficient at capturing collective rate shifts, such as those that we can detect using mbl, and may instead be meant for the background of "stationary" heterotachy present at every site. this suggests that an explicit model accounting for collective events, in the spirit of mbl, albeit more parsimonious in terms of parameterization, would be an interesting direction to take. a natural approach to do this would be a divergence point model  <cit> , where, due to the functional and/or structural shift, some sites evolve differently from other sites in the different areas of the phylogeny defined by the divergence points.

in another direction, the covarion model, in the version that we test here  <cit> , can also be improved. wang et al.  <cit>  introduced a more general model, in which rate can not only switch from on to off but also from a given rate to another and demonstrated a slight, but generally significant, improvement. yet, this model remains homogeneous over positions, a constraint that could be released by considering a mixture model in which the parameters of the covarion process are component specific.

