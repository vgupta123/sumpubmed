BACKGROUND
cancer is a complex disease, characterized by multiple molecular alterations triggered by genetic, environmental and lifestyle effects. cancer cells typically accumulate alterations disrupting the cell's life cycle of growth, proliferation, and death  <cit> . genomic changes that can eventually lead to cancer include mutations , single nucleotide polymorphisms , insertion and deletion polymorphisms and structural changes in chromosomes. snps are the most common type of inherited genomic variation and recent advances in high-throughput technologies have led to whole-genome snp arrays; datasets of such profiles over many subjects provide a valuable way to discover the relationship between snps and diseases such as cancer  <cit> .

a genome wide association study  compares the snp profiles, over a wide range of snps, of two groups of participants: e.g., people with the disease  versus people without the disease . each individual snp whose values are significantly different between these groups  is said to be associated with the disease  <cit> . of course, the resulting associated snps even those with high statistical significance using genome-wide corrections for multiple hypothesis testing are at best proxies for truly causal information, which can only be obtained through further deep sequencing of the associated loci and well-designed appropriate wet-lab studies. the database of genotypes and phenotypes  archives and distributes the results of studies that have investigated the interaction of a genotype and phenotype in gwass  <cit> . however, while gwass can help the researchers better understand diseases, genes and pathways, they are not designed to predict whether a currently undiagnosed subject is likely to develop the disease.

this paper introduces genome wide predictive studies , which take the same input as a gwas  but outputs a classification model that can be used later to predict the class label of a previously undiagnosed person, based on his/her snp profile. the field of machine learning provides a variety of statistical, probabilistic and optimization techniques that allow computers to learn such classifiers from these datasets of labelled patients. machine learning has been applied successfully in many areas of biology and medicine, often to produce effective predictors. baldi and brunak  <cit> , larranga et al.  <cit> , tarca et al.  <cit> , cruz and wishart  <cit>  each surveyed various applications of machine learning in biology, including gene finding  <cit> , eukaryote promoter recognition  <cit> , protein structure prediction  <cit> , pattern recognition in microarrays  <cit> , gene regulatory response prediction  <cit> , protein/gene identification in text  <cit> , and gene expression microarray based cancer diagnosis and prognosis  <cit> . we consider a way to learn a predictor , for a dataset that specifies all available snps about each subject.

our "genome wide" approach differs from research that attempts to learn predictors from only a pre-defined set of candidate snps. as an example of such a candidate snp study, listgarten et al.  <cit>  applied a machine learning tool  to a pre-defined set of  <dig> snps, distributed over  <dig> genes of potential relevance to breast cancer, to develop a predictive model with 63% accuracy for predicting breast cancer. ban et al.  <cit>  applied a svm to analyze  <dig> snps in  <dig> genes involved in type  <dig> diabetes  related pathways, and achieved 65% accuracy in t2d disease prediction. wei et al.  <cit>  studied type  <dig> diabetes  and reported 84% area under curve  using an svm.

our approach also differs from the conventional risk modeling/prediction studies. those studies also begin with a small set of pre-defined features: they first sort the training subjects into a small set of bins, based on the values of these features e.g., the gail model uses  <dig> features and record the percentage in each bin with the phenotype   <cit> . afterwards, to estimate the risk a new subject will face, this tool uses the subject's values for those relevant features to sort that subject into the proper bin, and returns the associated probability . hence this approach bases its assessment on only a small number of pre-specified features. note this might not be sufficient to usefully characterize the subjects, especially if the hand-picked features are not adequate. on the other hand, our machine learning  approach lets the data dictate on the possible combination of features that are relevant. , which is basically risk). our general goal is to develop a tool to help screen women, by predicting which of the apparently healthy subjects sampled in a population will eventually develop breast cancer. this cannot be done by gene expression-based microarray analyses, as those results require biopsies of tissues from organs or tumours, which means they are only relevant to individuals with suspect tissues; hence they are not effective at identifying individuals at risk in a general population, before the onset of the disease, and so cannot be used for our early detection. the standard breast cancer risk assessment model  is designed to help with early detection; however, it has only limited clinical value. note that researchers recently extended this gail model by including  <dig> or  <dig> snps associated with breast cancer susceptibility ; however, this led to only marginally improved accuracy  <cit> .

this paper presents a method to learn, from a dataset containing genome-wide snps of a cohort of subjects , a classifier that can predict whether a new subject is predisposed to the phenotype of breast cancer.  we describe the challenges of addressing this high-dimensional data and show that a learner is capable of producing a classifier that can identify, with  <dig> % accuracy, whether the subject has breast cancer, based only on her snp profile. while this might not be clinically relevant, this performance is statistically significantly better than the baseline , which demonstrates that  there is information relevant to breast cancer in a patient's snp values  and  that today's machine learning tools are capable of finding this important information.

methods
in general, a genome wide predictive study  takes as input the snp profiles of a set of n individuals  and outputs a classifier, which can later be used to predict the class label of a new individual, based on his/her snp profile; see figure  <dig>  here, we used a dataset of n =  <dig> subjects including  <dig> breast cancer cases  and  <dig> controls , accessed from a previous study on sporadic breast cancer wherein breast cancer predisposition in women is not related to mutations in the known high penetrance breast cancer genes  nor other genes of moderate penetrance, described in earlier studies  <cit> . germline dna was isolated from peripheral blood lymphocytes. genotyping profiles were generated using affymetrix human snp  <dig>  array platform . the study subjects provided informed consent and the study was approved by the alberta cancer research ethics committee of the alberta health services. following probe labelling, hybridization and scanning, population stratification correction using eigenstrat removed  <dig> subjects  that did not co-cluster with hapmap ii caucasian subjects, which left  <dig> caucasian subjects   <cit> . after that, the dataset was filtered by removing any snp  that had any missing calls,  whose genotype frequency deviated from hardy-weinberg equilibrium  or  whose minor allele frequency were less than 5% ; this left a total number of  <dig>  snps for analysis. for each snp, we represented wild type homozygous, heterozygous and variant homozygous by  <dig>   <dig>  and  <dig> respectively.

a trivial classifier, which just predicts the majority class , will be 321/ <dig> =  <dig> % accurate. the challenge is producing a classifier that uses subject snp data to produce predictions that are significantly more accurate. in particular, we explored tools that use the given labelled dataset to find the patterns that identify breast cancer . fortunately, the field of machine learning  provides many such learning algorithms, each of which takes as input a labelled dataset, and returns a classifier. these systems typically work best when there are a relatively small number of features typically dozens to hundreds but they tend to work poorly in our situation, with over half-a-million features; here, they will often over-fit  <cit> : that is, do very well on the training data as they find ways to fit the details of this sample, but in a way that does not work well on the subjects that were not part of the training dataset. note that our goal is to correctly classify such novel  subjects. we therefore apply a pre-processing step to first reduce the dimensionality of the data, by autonomously identifying a subset of the most relevant snps . we then give this reduced dataset to a learning algorithm, which produces a classifier  <cit> . we later discuss how to evaluate the classifier produced by this "feature selection + learning" system.

feature selection
in our analysis, as we expect only a subset of the snps to be relevant to our prediction task, we focused on ways to select such a small subset of the features. in general, this involves identifying the features that have the highest score based on some criteria . in this study, we used the meandiff feature selection method, which first sorts the snps based on their respective meandiff values, which is the absolute value of the difference between mean values of this snp over the cases and the controls:

  meandiffsnpi,d=|μi,c-μi,h| 

over the dataset d = c ∪ h where c is the set of subjects known to have cancer  and h is the remaining healthy subjects , and using expr as the value of the i'th snp of subject j, μ=1|h|∑j∈hexpr is the mean value of the i'th snp over the subset h  and μ=1|c|∑j∈cexpr is the mean value of the i'th snp over the subset c . note this meandiff score will be  <dig> when snpi is irrelevant and presumably larger for snps that are more relevant to our prediction task. here, we decided to use the m =  <dig> snps with the largest meandiff values; see the summary information of these top  <dig> meandiff selected snps in additional file 1: appendix <dig> 

learning
to build a classifier, we use the very simple learning algorithm, k-nearest neighbors , which simply stores the  profiles for all of the training data  <cit> . to classify a new subject p, this classifier determines p's k nearest neighbors, and then assigns p the majority vote. . of course, we need to define distances to determine the nearest neighbors. as we are representing each patient as a m-tuple of the snp values, we define the distance between two individuals p =  and q =  as the square of the euclidean distance  as shown below.

  d= ∑i=1m <dig> 

learning parameter selection
notice the knn learning algorithm requires us to specify how many neighbors to consider the k mentioned above. which value should we use i.e., should we use k =  <dig> , or k =  <dig> or k =  <dig> or...? it is tempting to set k by: running 1-nn on the data, then determining the apparent error , then computing the error associated with 3-nn, then 5-nn, and so forth; and finally selecting the value k ∈ { <dig>   <dig>   <dig>  7} that produces the smallest error. unfortunately, this would mean finding a relevant parameter based on its score on the full set of training data, which corresponds to testing on the training data. that is, the k-value that optimizes that score might not be the one that produces the best performance on novel subjects, as the value determined in this fashion can lead to serious over-fitting.

we therefore need a more elaborate method, bestknn, to determine the appropriate values for this parameter. here, bestknn first divides the training data into r =  <dig> disjoint subsets, d = d <dig> ∪... ∪dr, then for each i =  <dig> .r, defines d-i=d - di as the complement of di, and lets ci <dig> be the 1-nn classifier that is trained on d-i. for each i, the ci <dig> classifier uses the m snps that have the best meandiff scores, based on the d-i dataset. as d-i is different from d-j when i≠j, the m snps used by ci <dig> will typically be different from the m snps used for cj <dig>  bestknn then computes the accuracy, acc, of this ci <dig> classifier over di ie, over data that it was not trained on. it then computes the average accuracy over all r different folds, score=1r ∑i=1racc which is an estimate of how well 1-nn would work over the complete dataset d. bestknn similarly computes score  based on 3-nn, and score, etc., for k∈{ <dig>   <dig>   <dig>  7}, then uses the high-watermark as the appropriate value of k. here, using r =  <dig> folds, it found k* = <dig> worked best for our dataset . bestknn then defines the final classifier based on the top m snps over the entire dataset, using this specific k* = <dig> value.

evaluation
the next challenge is estimating the quality of the classifier, c <dig> = bestknn the classifier produced by running bestknn , on our  <dig> subject cohort d <dig>  here we use two strategies to evaluate our classification algorithm:  by using leave-one-out cross validation  strategy and  by using an external hold-out  dataset.

first, we use the loocv strategy, which first runs the bestknn algorithm to produce a classifier based on n- <dig> =  <dig> training subjects , which is then tested on the  <dig> remaining subject. we ran these processes n times, so that every subject is used one time as the test dataset. we estimate the true accuracy of c <dig> as the percentage of correctly classified subjects, over these  <dig> folds. producing this estimate means running all of bestknn  <dig> more times which, recall, each involves computing the top m snps for 40+ <dig> different configurations. some earlier researchers mistakenly ran their feature-selection process over the entire dataset d, and then committed to these features for all folds of the cross-validation process. unfortunately, this gives inaccurate  estimates  <cit> . on our task, we found that this incorrect process suggests that the resulting classifier has an apparent accuracy of over 90% -- which is considerably above its true accuracy of around 60% .

second, we used an external validation dataset of  <dig> subjects  from the cancer genetic markers of susceptibility  breast cancer project  <cit> . genotyping profiles for these subjects were generated using illumina humanhap <dig>  array platform .to date, this is the only publicly available dataset related to a genome wide association study of breast cancer, which is on caucasian population set.

RESULTS
accuracy = /= <dig> %; precision = tp/= <dig> %;

recall/sensitivity = tp/= <dig> %; specificity = tn/= <dig> %.

to test the effectiveness of our approach, we next explored ways to apply it to other datasets. the standard approach involves running the resulting classifiers on another dataset, whose subjects include values for the same set of features and are labeled with the same phenotypes. unfortunately, there are no other public datasets for this phenotype that use the same affymetrix human snp  <dig>  array platform. we did, however, consider applying our c <dig> = bestknn classifier on the cgems breast cancer dataset that includes  <dig> breast cancer cases and  <dig> controls genotyped on the illumina i <dig> array platform. unfortunately, due to this difference between the platforms, this dataset includes only  <dig> snps in common with the m =  <dig> snps used by c <dig>  as this meant the cgems data was missing ~80% of the snp values used by c <dig>  we obviously could not apply c <dig> directly on this dataset. as this cgems breast cancer dataset is the only available genome-wide dataset on caucasian population, we therefore had to design another experiment to evaluate our approach, based on the meandiff500+bestknn learning method. here, we used the same meandiff500+bestknn algorithm, but here trained this method over d <dig>  the  <dig> subjects of cgems breast cancer dataset. we again evaluated the performance of this learned model using the loocv method. table  <dig> shows the estimated accuracy of this learning algorithm on this external validation dataset, bestknn, is  <dig> % , with precision  <dig> %, recall/sensitivity  <dig> %, and specificity  <dig> %. this confirms that our approach and algorithm, is reproducible, as this exact system works effectively on a second, very different breast cancer dataset. notice others have used the same validation approach; see  <cit> .

accuracy = /= <dig> %; precision = tp/=  <dig> %;

recall/sensitivity = tp/= <dig> %; specificity = tn/= <dig> %.

hoping to further improve these results, we explored several techniques both biologically naïve and informed for both selecting features and for building the classifier itself. to select features, we considered biologically naïve methods such as information gain  <cit> , minimum redundancy maximum relevance   <cit>  and principal component analysis   <cit> . we also applied other biologically naïve learning algorithms, including decision trees  <cit> , and support vector machines   <cit> . in all, we tried dozens of different combinations of the learning and feature selection algorithms  each of which proved to be computationally intensive . table  <dig> shows the accuracy of each of these combinations. here, we see that none of these combinations are more accurate than our suggested combination of meandiff <dig> feature selection and bestknn learning ; indeed, several do not even beat the baseline of  <dig> %.

10-fold cross validation accuracies of combination of  <dig> feature selection methods and  <dig> learning methods shows that none of these combinations are more accurate than our suggested combination of meandiff <dig> feature selection and bestknn learning ; indeed, several do not even beat the baseline of  <dig> %.

we also used biological information related to cancer to inform feature selection i.e., use snps known to be relevant to breast cancer, rather than our biologically-naïve meandiff method: first, we considered the  <dig> snps identified by recent gwass as being highly associated with breast cancer . we trained knn over the  <dig> subjects, but using only these  <dig> snps. unfortunately the loocv of this classifier was just baseline, indicating that the snps that appear to be the most associated content with breast cancer are not sufficient to produce an effective classifier. indeed, none of those  <dig> snps appear in the top  <dig> that meandiff selected. while different studies often identify different snps as significant, biological pathways seem much more stable, in that certain pathways are identified across multiple studies. this motivated us to try using only the  <dig>  snps associated with genes of the kegg's cancer pathways  <cit>  recognized as hallmarks of cancer  <cit> ; unfortunately, the classifier based on these features also did not perform better than baseline. finally, we built a classifier using only the  <dig>  snps associated with breast cancer in the f-snp database  <cit> ; this too had just baseline accuracy. these negative results show that the obvious approach of first using prior biological information to identify snps, and then learning a classifier using only those snps, does not seem to work here.

 <dig> snps identified by the  <dig> recent genome wide association studies on breast cancer. the accuracy of the classifier learned over these  <dig> genotyped snps was not better than the baseline of  <dig> %.

discussion
our study confirms that snps do carry information related to breast cancer genetic susceptibility, and that gwpss are a promising tool for decoding and exploiting this information. while this approach is theoretically applicable for studying other cancer types and diseases, we list below some of the potential limitations that may make it difficult to produce more accurate prediction models, for breast cancer or other diseases:

small sample size vs. large feature size: as noted earlier, as the number of subjects in this study is significantly less than the number of snps , we face high-dimensionality problem, which can cause the learning systems to over-fit i.e., produce models that perform well on the training subjects but relatively poorly on new subjects distinct from those used for training. two categories of techniques that attempt to tackle high-dimensionality are feature selection and sample integration. this report shows feature selection produces a classifier whose accuracy is significantly above baseline. sample integration involves increasing the number of subjects in the study by either collecting more instances or by combining the dataset with other existing datasets, perhaps from different laboratories. however, there are still many significant challenges here, including dealing with batch effects  <cit> .

breast cancer heterogeneity: breast cancer is biologically heterogeneous: current molecular classifications based on transcriptome-wide analysis, clinical determinations of steroid hormone receptor  status, human epidermal growth factor receptor  <dig>  status, or proliferation rate status , all suggest a minimum of four distinct biological subtypes  <cit> . our current dataset ignores the differences by merging these different sub-classes into the single label: case. we might be able to produce a more accurate predictor if we employed more detailed labelling of sub-cases, to produce a classifier that could map each subject to a molecular subtype. however, as our dataset is relatively small, further stratification of cases into subtypes of breast cancer might add to the high-dimensionality problem.

snps are only one form of genomic alterations: while this study considered only snps, there are also many other heritable genetic factors including mutations, copy number variations , and other chromosomal changes. we believe that augmenting the snp data with additional genetic information, such as insertion/deletion polymorphisms and cnvs, could lead to more accurate breast cancer predictive models. of course, as this means using yet more features, this could also increase the risk of over-fitting.

breast cancer is also influenced by non-genetic factors: heritable factors are only part of the issue: while they play a major role in monogenic diseases such as haemophilia, diseases such as tuberculosis and lung cancer have a very high environmental and life style component, meaning genetic component contributes only a small amount to overall risk. indeed, for many of diseases, the genetic component accounts for only 30-60% of the risk, with the remaining risk due to environmental and life style risk factors. there are many factors that contribute to developing breast cancer, in addition to heritable  changes. the major environmental and lifestyle risk factors include age, estrogen exposure , smoking, radiation exposure, obesity, and lifestyle in general  <cit> . as the breast cancer predictive model presented here used only germline dna, it did not incorporate any of these non-genetic variables. we anticipate better results from a comprehensive model that includes both genetic and non-genetic factors.

CONCLUSIONS
we present a genome wide predictive study as a way to understand, and effectively use, data from multiple single nucleotide polymorphisms. we first contrast this approach with the more standard associative studies, connecting this predictive approach directly with screening and personalized health care. we also show that it differs from the risk model  as our model can involve a large number of characteristics for each patient .

our studies confirmed the feasibility of predicting breast cancer susceptibility from genome wide analysis of snps, by presenting a learning model that first uses the meandiff feature selection technique to identify the best subset of  snps from the over-500k snps of the original dataset, then used k-nearest neighbour  as the classifier over these snps. leave- one-out cross validation estimates the prediction accuracy of this proposed method to be  <dig> %. a random permutation test indicated that this result is significantly better than the baseline predictor . sensitivity analysis on performance of our classifier showed that our model is robust to the number of meandiff-selected snps. we externally validated our learning algorithm using  <dig> subjects from the cgems breast cancer dataset; this again produced a classifier whose loocv accuracy was significantly better than the baseline, which shows the reproducibility of our combination of meandiff and bestknn in breast cancer prediction.

to better understand the challenge of this dataset, we systematically explored a large variety of other feature selection and learning algorithms. we found that none of the biologically naïve approaches to feature selection worked as well as our meandiff. we also considered many biologically-informed methods to select snps using snps reported in the literature to be associated with breast cancer, snps associated with genes of kegg's cancer pathways, and snps associated with breast cancer in the f-snp database. however, those snps produced classifiers that were not even better than baseline. these negative findings suggest the challenge of our task, and of the importance of findings of our study.

we also identified several limitations that may hinder a more accurate predictive model for breast cancer susceptibility. sporadic breast cancer is a heterogeneous phenotype, which is also heavily influenced by environmental factors. moreover, while our study does involve  <dig> samples, this is small relative to the number of features  from a whole genome scan; we expect to achieve yet better results given a larger sample sizes. furthermore, we anticipate developing better predictive models by incorporating other information both other genetic information  as well as environmental and lifestyle factors. the fact that our study produced statistically significant results, despite these limitations, demonstrates the potential of this machine learning approach in this context of screening, and of personalized patient care.

competing interests
the authors declare that they have no competing interests.

authors' contributions
mh designed and implemented the experiments and drafted the manuscript; bd, mhs, and fs helped running preliminary experiments; jrm provided insights from clinical oncology; cec and sd as investigators on the canadian breast cancer foundation  tumor bank in alberta provided access to clinical data; rg participated in the design of experiments and manuscript edits; sd as the principal investigator of the whole genome breast cancer studies, offered data, provided suggestions during the course of experiments and edited the manuscript. all authors read and approved the final manuscript.

supplementary material
additional file 1
appendix <dig>  summary information of the top  <dig> meandiff selected snps.

click here for file

 acknowledgements
we thank mr. bret hoehn, ms. nasimeh asgarian, dr. badan sehrawat, and dr. yadav sapkota for discussions and help with the data preparation. we sincerely thank dr. paula robson from the tomorrow project of the alberta health services, alberta for discussions and for providing data for our gwas studies. this study is funded by the faculty of medicine & dentistry/faculty of science interdisciplinary graduate studentship award, university of alberta ; natural sciences and engineering research council and alberta innovates centre for machine learning ; alberta cancer foundation, canadian breast cancer foundation- prairies/nwt region, alberta innovates-health solutions funding support for the alberta cancer research biorepository/cbcf-tumor bank ; canadian breast cancer foundation- prairies/nwt region for financial support through operating grants . we acknowledge dbgap of ncbi for providing us access to the cancer genetic markers of susceptibility  breast cancer dataset.

declarations
rg provided the cost for the publication of this article.

this article has been published as part of bmc bioinformatics volume  <dig> supplement  <dig>  2013: selected articles from the 9th annual biotechnology and bioinformatics symposium . the full contents of the supplement are available online at http://www.biomedcentral.com/bmcbioinformatics/supplements/14/s13
