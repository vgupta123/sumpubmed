BACKGROUND
systems biology states that, in order to quantitatively understand and predict the cell behaviour, its constitutive components and their interactions must be studied as a whole system  <cit> . metabolic networks are a paradigmatic example of this aim because, even incomplete as they may be, they are the best characterized cellular networks  <cit> . in recent times, the information embedded in metabolic networks is being used to assemble constraint-based models under the pseudo steady-state assumption, thus not requiring the knowledge of kinetic parameters, which are still rarely known  <cit> . constraint-based models allow the calculation of the possible metabolic states or "behaviours" that can be exhibited by the cell; however, they do not predict which of these are likely under given circumstances. one approach to perform these predictions is flux balance analysis , which is based on the assumption that cell behaviour has evolved to be optimal in a certain sense  <cit> . it has been shown that fba is able to predict the actual fluxes  <cit> , but this requires to identify which are the relevant objectives for different conditions  <cit> . as an alternative, one could perform a metabolic flux analysis  which, generally speaking, is the exercise of estimating the fluxes shown by cells by combination of a constraint-based model and the set of available experimental measurements.

in order to estimate the intracellular fluxes, traditional metabolic flux analysis  employs only measurements of uptake and production rates  that are stoichiometrically balanced  <cit> . this purely stoichiometric approach has some limitations, but most of them can be overcome with simple extensions, as it will be shown below.

one typical difficulty to be tackled by mfa is that the available measurements may be insufficient to estimate the intracellular fluxes, particularly in large-scale networks, because there may be different flux distributions compatible with the available measurements. to face this situation, intracellular information obtained from stable isotope tracer experiments has been incorporated in many studies   <cit> . yet, data from isotope tracer experiments will not be considered in this work. instead, we follow a constraint-based modeling approach, in the sense that we do not attempt necessarily to predict the actual fluxes with precision, but rather to distinguish "most possible" from "impossible" flux states, based on a suitable definition of "possibility", a constraint-based model and the available measurements, which in most cases do not include isotopic data.

another option to face a lack of measurements is the use of some rational hypotheses to chose one flux distribution among those that are compatible with the measurements. for instance, nookaew et al. have proposed to estimate the intracellular fluxes based on the assumption that cells are likely to use as many pathways as possible to maintain robustness and redundancy  <cit> . related hypotheses have been formulated using the concept of elementary modes  <cit> . the assumption of optimal cell behavior typically used in fba could be also used . it will be shown that the methodology we propose is able to detect these flux distribution that are equally possible , but for the sake of simple exposition we will not use any hypothesis herein. however, the possibilistic framework might be extended to incorporate hypotheses, as discussed in the conclusions section.

in this context, the paper discusses the use of a possibilistic framework for metabolic flux analysis.

uncertainty, lack of measurements and model imprecision will be handled introducing the notion of "degree of possibility". then, an efficient optimization-based approach will be employed to query the most possible fluxes and their possibility distributions. the methodology is based on a re-interpretation of the consistent causal reasoning paradigm  <cit>  as an equivalent problem of feasibility subject to equality and inequality constraints; preferences under uncertain knowledge are incorporated by transforming the feasibility problem into a linear optimisation one, which may be interpreted in possibilistic terms. the optimisation approach to logic reasoning has been previously explored by the research group to which the authors belong in  <cit> , and this paper applies it to mfa.

the main features of the possibilistic framework introduced in the paper are the following:  it is based on a constraint-based model and not only on stoichiometric balances,  it considers measurements uncertainty in a flexible way  and  even model imprecision,  it provides possibility distributions  which are more informative than point-wise estimations when multiple flux values might be reasonably possible,  it is reliable even if only a few fluxes are measurable,  it has the ability to detect, and handle, inconsistencies between measurements and model, and furthermore  with high computational efficiency.

the structure of the paper is as follows: preliminaries on possibility, optimization and metabolic flux analysis are first addressed. then, the basics of possibilistic mfa and some refinements are discussed; the framework is illustrated with simple examples and a well-know model of c. glutamicum. the paper is closed with a summary and a discussion on future work.

preliminaries: possibility and optimization
in an abstract ideal situation, many estimation problems in science and engineering can be cast as estimating some decision variables δ given the known values of a set of other ones m  and a model expressed as a set of equality and inequality constraints . then, the valid estimations will be the feasible solutions of a constraint satisfaction problem  <cit> .

however, in many practical cases, the measurements are imprecise and the model parameters and constraints are also not accurate, so real data violates them. this is the reason why most real-life models should include uncertainty. the most basic representation of uncertainty would be giving interval values to measurements and model parameters. refinements of the uncertainty representation give rise to probabilistic  <cit>  and possibilistic  <cit>  frameworks.

probabilistic frameworks have an underlying interpretation in terms of the frequency in which some flux conditions appear; on the other hand, possibilistic frameworks measure the degree of compliance  of some decision variables with some  modeling constraints. in this sense, the basic assumptions of both paradigms of inference under uncertainty are different.

in the following subsections the possibilistic framework will be described. afterwards, this section of preliminaries will be closed discussing the relationship between probability and possibility and justifying the use the possibilistic framework.

soft constraint satisfaction problems: a possibilistic approach
as explained above, the possibilistic framework is the chosen representation for the problem under study, following the ideas in  <cit> , where possibilistic constraint satisfaction problems  are presented. there, the authors introduce constraints which are satisfied to a degree, transforming the feasibility/infeasibility of a potential solution into a gradual notion: given a csp with multiple solutions δ ∈ Δ , a function π : Δ →  <cit>  was suggested in order to represent preference or priority as a "consistency degree". the meaning of π =  <dig> would indicate that δ is in full agreement with the model and measurement constraints; the meaning of π =  <dig> indicates that δ is in "absolute, total contradiction" with the problem constraints, and never should be considered a feasible value. intermediate values would denote values of decision variables which "somehow mildly" violate the problem constraints but could be considered "partially possible" from the "practical" knowledge of the "expert" modeller who defined π. the higher the value of π, the higher the accordance with the problem constraints should be . given the here outlined subjective meaning of π, it is denoted in literature as possibility distribution. the possibilistic calculus  <cit>  refers then, to computations with possibility distributions from a series of axioms. basic ideas on it will be outlined below in this section. a simple example now illustrates the basic idea.

example
consider a flux balance {f <dig> = f2}, stating equality between two flows, f <dig> and f <dig>  supposedly measured in a biological or chemical reaction. the measurements ma =  and mb =  are infeasible, whereas mc =  is feasible. however, it seems clear that the subjective "possibility" of mb is higher than that of ma; mb can be thought to be quite reasonable in practice due to measurement errors.

the idea can be easily formalised for further computations by defining a possibility distribution, for instance, . in this way, potential solutions can be ranked: π =  <dig> , π  =  <dig>  and π =  <dig>  the search space in which to define the possibility, Δ, could be defined as, say, Δ = {| <dig> ≤ δi ≤ 10}.

usually, the function π is built by "conjunction" of possibility functions of individual relations πi . such conjunction will be latter discussed in this section. the best csp solutions are defined to be those which satisfy the global problem to the maximal degree.

in this way, once the user has defined such function expressing how a particular combination of system variables is "consistent" with its model, the basic idea on possibilistic calculus is, given a subset of the system variables , estimate the "most possible" values of all the remaining variables via an optimization problem. the close relationship between possibilistic calculus and optimisation is discussed in the subsection below.

possibility theory
the basic building block of possibility theory is a user-defined possibility distribution π : Δ →  <cit> . this defines the possibility of each "point" δ in Δ. a consistent problem formulation is defined to be the one in which there exists at least one point with possibility equal to one.

the second building block are events, formally defined as subsets of Δ, in order to address problems such as, in the above example, determining the possibility of event a = { ∈ Δ |  <dig> ≤ f <dig> ≤  <dig>   <dig> ≤ f <dig> ≤ 10}.

possibility calculus as optimization
by definition, the possibility of an event a  is computed via:

   

and, obviously, given two events a and b, a ⊂ b entails π ≤ π.

hence, possibility computations are optimisation problems .

for a multidimensional Δ = Δ <dig> × Δ <dig>  δ =  ∈ Δ, the marginal possibility distribution of δ <dig> is defined as:

   

i.e., the possibility of the event {δ <dig> = }.

optimization as possibility calculus
conversely, consider a cost function j : Δ → r+  ≤  <dig> for all δ ∈ Δ), so that there exists δ <dig> ∈ Δ such that j =  <dig>  then, a consistent possibility distribution may be defined on Δ via:

   

and the possibility of an event a is given by replacing the possibility definition  in , resulting in:

   

in the next sections, abusing the notation, an event a will be usually described by a set of constraints on the decision variables δ.

in this way, numeric constrained optimisation problems may be subjectively interpreted in possibilistic terms: the cost j will be interpreted as the log-possibility of δ and, by definition, unfeasible values of decision variables will be assigned zero possibility.

let us now review some other relevant definitions and issues in possibilistic calculus.

necessity
in order to assert that an event a is necessarily true , saying that a is "possible" may be not enough: it must also be true that the complementary event "not a" is not possible. this motivates the introduction of a necessity measure:

   

in a binary setting, all solutions belong to a subset a if and only if π = n = 1; there exist solutions in a  if π =  <dig> but n =  <dig>  and there are no solutions in a if π =  <dig> 

extending the measures π, n to  <cit>  provides a natural gradation of such concepts: π =  <dig> , n =  <dig>  would indicate that there are very possible solutions in a, but not all of them are in there .

interactivity and possibilistic conjunction
the possibilistic analog to statistical independence is the non-interactivity.

if the joint possibility of two variables Δ = Δ <dig> × Δ <dig>  δ =  ∈ Δ can be expressed as the product of two univariate ones:

   

then variables δ <dig> and δ <dig> are said to be non-interactive. in that way, given an event a <dig> ⊂ Δ <dig> and an event a <dig> ⊂ Δ <dig>  it is straightforward to prove that:

   

which can be read as "the possibility of event a <dig> and event a <dig> is the product of the individual possibilities when the events relate non-interactive variables", interpreting, as usual in literature, set intersection as a linguistic conjunction.

under non-interactivity assumption, if the possibility is defined as the logarithm of a cost index , the product  gets transformed into a sum:

   

on the following, given individual cost indices j <dig>  j <dig>  etc. relating to different constraints, the above expression  will be the one used in most cases to define a possibility distribution in the product space. in this way, we are interpreting the possibilistic conjunction operator in  <cit>  as an algebraic product of possibilities, i.e., stating an underlying non-interactivity assumption between different constraints. note, however, that the interactivity assumption is not always intuitively needed. in the other extreme , we would have: π ≤ max, π), which would suggest the maximum possibility as the conjunction operator when two events affect exactly the same decision variables. in between those two extremes, other choices may be also possible .

conditional possibility
the possibilistic analog to conditional probability is conditional possibility.

consider an event b with nonzero possibility. a quotient definition for conditional possibility of an event a given event b will be used in this paper:

   

in this way, given a  possibility distribution π, the conditional possibility can be computed as:

   

so, if the possibility distribution is actually the exponential of a cost index, we get:

   

that is, computing the possibility by subtracting the cost associated to event b from the cost of any of its subsets.

in order to get a conditional possibility distribution of a variable δ, we assume event a being an individual point δ*, getting:

   

that is, the conditional distribution can be obtained by dividing the possibility distribution function for all points in a set by the maximum possibility of them, i.e., normalising the possibility distribution on a restricted conditioning domain b to a maximum equal to one.

the conditional definitions allow for an analogy to bayesian inference: if we assume that b is actually certain  was), then conditional possibility may be understood as an a posteriori possibility.

possibility versus probability
both possibility theory and probability theory are frameworks for handling uncertainty in constraint satisfaction problems. basically, a subjective interpretation would assign high possibility to events with high probability. hence, in a first approximation, user-defined probabilities and possibilities should be related by an implicit monotonically increasing function. possibility-necessity measures have also been linked to imprecise probabilities  <cit> . however, once aggregation takes place , although the subjective interpretation might be considered similar, there is no longer an implicit function relating probability and possibility. for further discussion on possibility, probability, and other uncertain reasoning frameworks, and their interrelations, the reader is referred to  <cit> .

ideally, probabilistic results would be preferable . however, there are some drawbacks:  exact probabilistic inference under equality and inequality modeling constraints is computationally hard   some of the a priori bayesian probabilities are in practice rough user-given estimates,  some of the assumptions  may not hold in practice, and  there may be some uncertainty in the model parameters or in the model probabilities. thus, as practical use of probability does not fully adhere to the theoretical assumptions, its results should be interpreted with some flexibility. as this work will discuss, the proposed possibilistic framework is much less demanding computationally  and gives similar results to the probabilistic approach in realistic cases.

the objective of the next sections is to set up a possibilistic framework for efficient computations in metabolic flux analysis.

preliminaries for metabolic flux analysis
in biology, the metabolism of living cells is usually represented by a metabolic network encoding the elementary biochemical reactions taking place within the cell  <cit> . these metabolic networks can be translated to a matrix n, where rows are the m internal metabolites and columns the n reactions. assuming that these metabolites are at steady state, mass balances can be formulated as follows  <cit> :

   

where v = t is the n-dimensional vector of metabolic fluxes.

hence, a  flux vector v represents the metabolic state of the cells at a given time, without any information on the kinetics of the reactions; it shows the contribution of each reaction to the overall metabolic processes of substrate utilization and product formation. notice that as typically n is larger than m, the system  is underdetermined, i.e. there is a wide range of stoichiometrically-feasible flux vectors. assuming now that some fluxes in v have been measured , while the rest remain unknown , equation  can be rearranged as follows:

   

as measurements are imprecise in practice, such measurement imprecision can be incorporated as constraints:

   

where em represents measurements errors and  represents the actually measured flux value. in our approach, the measurement uncertainty is translated into an a-priori possibility distribution for em from sensor characteristics. other approaches consider different choices, as discussed below.

at this point, traditional metabolic flux analysis  can be defined as the estimation of the flux vector satisfying  and compatible with the measurements . in particular, tmfa can be formulated as a two step procedure  <cit> :  analyze measurements consistency  using chi-square tests, and  solve a least squares problem to estimate the actual flux vector v:

   

where it is assumed that em are distributed normally with a mean value of zero and a variance-covariance matrix f.

since all the constraints are linear equalities, the analytic solution of this minimization problem can be obtained, resulting in the expressions to estimate vu and vm that are typically seen in literature . however, with this formulation tmfa has some important limitations:  irreversibility constraints, or any other inequality constraints, cannot be considered,  measurement errors are assumed to be normally distributed,  it only provides unique-valued flux estimation, and  it needs a high number of measurable fluxes to be of use – system  has to be determined and redundant  <cit> .

several alternatives have been suggested to face those limitations . quadratic programming solves the least squares problem  allowing to include irreversibility constraints , but inherits the rest of drawbacks . the flux spectrum approach  follows an interval approach to overcome the limitations mentioned before, but its estimations tend to be conservative because only lower and upper bounds are used to represent measurements uncertainty  <cit> . monte carlo has been also used in the context of 13c-mfa , but rarely in absence of isotopic data. moreover, sometimes it has been used incorrectly: monte carlo cannot be performed just solving a quadratic programming problem for each simulated set of measurements, because this introduce a bias on the results. anyway, the major drawback of monte carlo is its high computational cost, which restricts its use for large metabolic networks as an impractical number of samples is required to assess probabilities within a reasonable accuracy.

possibilistic mfa  is compared with four approaches for metabolic flux analysis, traditional mfa , mfa as a constraint least-squares problem  and the flux spectrum approach . legend:  provided feature,  partially provided feature and  potentially provided feature.

in the following sections we introduce a possibilistic framework for mfa that brings several interesting features:  it overcomes all the mentioned limitations of tmfa,  has the ability to detect, and handle, inconsistencies between measurements and model, and furthermore  with high computational efficiency.

RESULTS
possibilistic mfa: problem statement
in this section the possibilistic framework for mfa flux estimations is discussed. first, we define a set of time-invariant constraints derived from the metabolism being modelled. then we incorporate the constraints imposed by the measured fluxes, representing its uncertainty, by means of auxiliar slack decision variables and a cost index. in this way, the notion of "degree of possibility" is incorporated. finally, it will be shown how  optimisation problems will be able to settle queries about the most possible fluxes, the possibility distributions, etc.

model-based constraints
first, let us define a set of invariant constraints that every steady-state flux vector must satisfy; they do not depend on environmental conditions, do not change through evolution, etc.  <cit> . in this work this model-based constraints, denoted as , will be the stoichiometric relationships  and irreversibility constraints, described by means of inequalities:

   

where d is a diagonal nxn-matrix with di, i =  <dig> if the flux i is irreversible .

other model-based constraints can be defined in an analogous way. for instance, elementary balances or degree of reduction balances might be incorporated into  as additional constraints  <cit> . it may be also possible to add constraints based on standard gibbs free energy changes  <cit>  or extracellular metabolites concentrations  <cit> .

incorporating the measurements
estimating the non-measured fluxes would amount for solving the above equations , where some of the elements in vector v are measured . however, this simple approach will be impractical in two very common situations:

• the measurements are very few, so the system has many -possibly infinite- solutions.

• real measurements do not exactly satisfy the constraints due to measurements  errors. therefore, no solution will be found. 

hence, the approach needs refinements to deal with a lack of measurements and to introduce the "possibility" of sensor errors and imperfect models. as shown below, such difficulties can be overcame by the introduction of slack variables and a cost index, enabling a grading of the different candidate flux vectors as more or less "possible".

possibilistic description of measurements
each experimental measurement  can be described by a constraint as follows:

   

where em is a decision variable that represents the intrinsic uncertainty of the experimental measurements, i.e. the discrepancy between the actual flux vm, and the measured value . for convenience , em is substituted by two non-negative decision variables, ε <dig> and μ1:

   

these decision variables δ = {ε <dig>  μ1} relax the basic assertion  = vm, conforming a possibility distribution in  associated to some cost index jm. among different possible choices, a simple -yet sensible- one is the linear cost index:

   

with α ≥  <dig> and β =  <dig> .

recalling the concepts introduced t vm he preliminaries section, the interpretation of  and  may be: "vm =  is fully possible; the more vm differs from , the less possible such situation is". indeed, the event a = {vm = } ≡ {ε <dig> - μ <dig> = 0} will be fully possible – as , achieved at ε <dig> = μ <dig> =  <dig>  and then π = e- <dig> =  <dig>  on the other hand, the possibility of the event a corresponding to vm being different from  – say, for instance, a = {vm =  + ρ} ≡ {ε <dig> - μ <dig> = ρ} – will be given by . for instance, with a cost index j = 5ε <dig> + 5μ <dig>  and a measurement  =  <dig> , the possibility of the actual flux vm being vm =  <dig>  is e-5* <dig>  =  <dig>  , and the possibility of vm =  <dig>  is e-5* <dig> =  <dig>  .

remark
as explained in a subsequent section, the weights α and β should be defined related to each measurement's "a priori accuracy".

a global cost index
consider now a set of measurements  with its associated slack variables δ <dig> = ,... δm = , and individual cost indices j <dig> ... jm. the corresponding constraints will be called measurement-based constraints, :

   

in order to have a possibility distribution, under the non-interactivity assumption , the cost index is defined as:

   

where α and β are row vectors of sensor accuracy coefficients and ε <dig>  ·μ <dig> correspond to stacking in vectors the artificial variables from individual constraints.

the possibilistic mfa problem
at this point, we can define the possibilistic mfa  problem by means of the cost index j  and the set of constraints :

   

where the decision variables δ are the actual fluxes v = , and the slack variables ε <dig> and μ <dig> 

the cost index j reflects the log-possibility of a particular combination of the decision variables, that is, the log-possibility of a particular flux vector v.

remark
the pmfa will be cast as a linear programming problem; this is the reason why the non-negative decision variables ε <dig> and μ <dig> were introduced in substitution of em. however, it can be formulated using any other optimization framework. for instance, pmfa can be easily cast under a quadratic programming framework. throughout the paper linear programming will be assumed due to its great computational performance . this supposes a great advantage when dealing with large-scale metabolic networks. nevertheless, an example using quadratic programming will be described in a subsequent section to point out the flexibility of the pmfa.

example  <dig> – problem statement
consider the toy metabolic network depicted at the top of figure  <dig>  and the corresponding constraints,  and . let us consider that the measurement of v <dig> is "very accurate", that of v <dig> is moderately accurate and those of v <dig> and v <dig> are quite unreliable. the weights α and β associated to the slack variables ε <dig>  and μ <dig>  can be defined in accordance with this information: if we take α <dig> = β <dig> =  <dig>  α <dig> = β <dig> =  <dig> , and α <dig> = β <dig> = α <dig> = β <dig> =  <dig> , the measurements are depicted on the bottom in figure  <dig>  for supposed measurements  =  <dig>   =  <dig>   =  <dig>   =  <dig> 

point-wise flux estimations
the simplest outcome of a pmfa problem is a point-wise flux estimation: the minimum-cost  flux vector. this problem can be conveniently cast as the optimisation of a linear functional subject to linear constraints.

according to , the maximum possibility  flux vector vmp corresponding to a given set of measurements is obtained as the solution to the linear programming  optimization problem:

   

being its degree of possibility π = exp.

the obtained flux vector vmp contains the most possible flux values compatible  with the model and the measurements. a possibility equal to one must be interpreted as the flux vector being in complete agreement with the model and the original measurements. lower values of possibility imply that vmp corresponds to fluxes vm deviated from the measurements .

notice that as π = π(), it can be interpreted as the "a priori" possibility of encountering the measurements ; so if it is low, this implies that either  there is a gross error in the measurements,  there is an error in the model, or both. therefore, the maximum possibility can be used to evaluate consistency and detect errors . we will come back to this point in a subsequent section.

example  <dig>  continued
consider again the model and the measurements given in figure  <dig>  the maximum possibility flux vector resulting from  is vmp = , with a possibility of e- <dig>  =  <dig> . the most possible flux vector being not fully possible  indicates that the measurements and the model are not in complete agreement. indeed, as a matter of fact, the model says that v <dig> - v <dig> = v <dig> - v <dig>  but  = - <dig> and  =  <dig>  should the measurements had been fully compatible with the constraints imposed by the metabolic network – i.e.  =  <dig>   =  <dig>   =  <dig> and  =  <dig> – the maximum possibility flux vector would have been vmp = , with a possibility of π =  <dig> 

notice also that the possibility depends on the reliability associated to each measurement. for instance, if all the measurements were supposed to be more reliable – say α' = 10·α and β' = 10·β – the possibility distribution functions would be narrower. the interpretation of the new coefficients would, therefore, be that the same deviation from the fluxes of maximum possibility will be now be considered as a less possible fact.

possibility distributions as flux estimations
clearly, a point-wise flux estimation is limited in a situation where multiple flux values might be reasonably possible. to face these situation, marginal and conditional possibility distributions  can be obtained, again, by solving linear optimisation problems. these provide a much more informative flux estimation than a point-wise one, such as the maximum possibility flux vector, or the interval of minimum-maximum possible values in  <cit> .

these flux estimations, which are illustrated in figure  <dig>  wil be presented along this subsection.

marginal possibility distributions
marginal possibility distributions  can be easily plotted and give a valuable information for the end user: they show, and rank, the possible values for each flux in the network.

the possibility of vi being equal to a given value f, π, is computed by simply adding a constraint to :

   

hence, plotting the marginal possibility for a range of fixed given values f  will provide the marginal possibility distributions that be interpreted as the "distribution of the possible values for each flux in the network, given the measurements" .

notice that "cuts"  of a possibility distribution, containing those values of vi with a marginal possibility higher than γ can be obtained solving two lp problems:

   

this provides a highly efficient procedure to compute a possibility distribution: compute "cuts" of possibilities between  <dig> and  <dig>  say,  <dig> ,  <dig> , etc. . this approach is better than defining a range of values f and computing its possibility with  because it avoids the problem of determining the most convenient step size and bounds of the flux .

conditional possibility distributions
using the definition given in the preliminaries , the conditional possibility distribution of a flux vi can be computed as follows:

   

remember that conditional distribution can be obtained normalising the marginal possibility distribution to a maximum equal to one .

conditional possibility may be understood as an a posteriori possibility: π is the possibility of vi having the value f, if we assume that  is actually certain, i.e. that the model and the measurements are correct.

 possibilistic intervals
in analogy to , the interval of flux values  with a degree of conditional  possibility higher than can be obtained solving two lp problems:

   

the upper bound would be obtained by replacing minimum by maximum.

these possibilistic intervals have a similar interpretation to "confidence intervals"  in bayesian statistics, providing a concise flux estimation that can be represented by means of a box-plot chart .

example  <dig>  continued
with the measurements in figure  <dig>  the resulting marginal possibility distributions for each flux are plotted in figure 3a. they show that, for instance, the most possible value of v <dig> is  <dig>  , that v <dig> being  <dig>  is quite possible, but that v <dig> bigger than  <dig> is almost impossible . the possibility distributions also reflect the reliability of the estimation of each flux: the estimation of v <dig> is less reliable than the one of v <dig> or v <dig>  since it has a wide range of highly possible values.

notice too that the uncertainty on the measurements is often strikingly reduced through the flux estimation. for instance, the estimation of v <dig> – whose measurement was quite unreliable a priori – has been significantly improved, once model constraints and other measurements have been incorporated. this reflects the already noticed fact that the metabolic network structure greatly constrains the possible values of fluxes for a given, typically small, set of measured flux values. the plots of marginal possibility can also detect multiple flux vectors with maximum possibility . figure 3b depicts the maximum possibility flux estimation and three possibilistic intervals by means of a box-plot chart. the intervals point out that, for instance, the highly possible a posteriori values of v <dig> are those in   and that those in  are also quite possible , while those outside  are almost impossible as their a posteriori possibility is lower than  <dig> .

possibilistic mfa: refinements
now that the basics of the pmfa framework have been introduced, some refinements will be discussed.

a better description of measurement's uncertainty
the formulation used above to describe the uncertainty of the experimental measurements might be considered somehow limited in some applications.

fortunately, it is very easy to add new slack variables, and modify the   and the cost index , allowing to work with possibility distribution functions of different characteristics.

as an example, the constraints  and cost  below describe an interval measurement plus some possibility of outlier measurements:

   

and

   

the possibility of  is one and the possibility of the actual flux being vm being out of the referred interval depends on the cost index weights .

for instance, a band with possibility equal to one can be used to account for systemic errors in measuring a particular flux, and a couple of additional slack variables may be defined to account for the decreasing possibility of random errors. these kind of representation of measurement uncertainty will be illustrated in subsequent examples.

remark
notice that more slack variables can be added to achieve a more complex representation of the measured flux uncertainty. in fact, any convex representation of the log-possibility uncertainty can be approximated if a sufficient number of slack variables are incorporated . details are omitted for brevity.

considering uncertainty in the model structure
until now, the model-based constraints  – the stoichiometric relationships, reaction's irreversibility, or any other – have been considered as hard constraints; only those flux vectors v that exactly satisfy them could be feasible solutions. however, these constraints can be "softened" via suitable slack variables to consider uncertain knowledge. then, these additional slack variables may be used in a cost index to generate a possibility distribution.

consider, as an example, an equality restriction a = b. a relaxed  version of such restriction may be written as:

   

with ϵ and ν being slack variables penalised in an optimisation index j = f, typically with linear cost index terms, γϵ + τυ, in an analogous way to the discussion on uncertain measurements.

notice also that a "softened" inequality restriction is nothing but an equality one with no penalisation on one of the slack variables above. for instance a ≤ b + ε can be expressed as a = b + ε - μ with free μ.

such softened model constraints may be used to roughly incorporate imprecision in the model arising, for instance, from non-compliance with the pseudo-steady-state assumption, partial unbalance of some metabolites or uncertain yields. although these issues require further research, let us outline some preliminary ideas below.

relaxing the pseudo-steady state assumption
equation  derives from the dynamic mass balance around the internal metabolites c, where it is assumed that  ≈  <dig> and that the term μ·c is negligible . adding slack decision variables to , as it has been explained, makes it possible to relax this assumption.

partial unbalance of metabolites
sometimes, a metabolite cannot be assumed to be balanced because there are reactions producing or consuming this metabolite that have not been taken into account in the network; for instance, this is often the case for the cofactors, atp, nadp, etc. this unknown consumption/production can be represented by means of slack variables  if some interval limits  are provided.

uncertainty in stoichiometric yields
in some cases, the value of a yield coefficient is not exactly known. this is usually the case of the yield coefficients of lump reactions used to represent biomass synthesis. let vr be the flux through a reaction with an uncertain yield yi, r for the metabolite i. the row corresponding to this metabolite in  can be rewritten as:

   

if it is known that  and vr is irreversible, equation  can be substituted by two constraints:

   

   

however, if the flux vr is reversible, inequalities in  cannot be set up, and the approach is no longer applicable. integrating modal interval arithmetic  <cit>  in the proposed framework might be a possible option, under research at this moment.

illustrative examples of other features of pmfa
other features of possibilistic mfa  will be briefly illustrated using the simple metabolic network in figure  <dig> 

example 2: errors detection in measurements and model
as earlier mentioned, the value of the peak possibility in the resulting flux distribution provides an indication of the agreement between the model () and the measurements (). a low degree of possibility means that the model and the measurements are inconsistent. that is, that there is not any flux vector "near" the measured values satisfying the model-based constraints. therefore, if the the maximum possibility flux vector has a low value, one must assume that either  there is an important error in one or more measurements,  there is a relevant error in the model , or both.

if a high inconsistency  is detected, it is possible to investigate what is causing it, and thus correct the measurements or improve the model. following a straight approach, we can remove one measured flux at a time and perform the flux estimation to determine if the removed measurement was causing the low possibility. if this is the case, we may consider the following alternatives:  consider that  is a totally unreliable measurement and, thus, accept the flux estimation inferred from the others measurements,  obtaining either  again, or a different measurable flux which could provide additional information,  consider  a reliable piece of data and, hence, conclude that there is an error in the model or its assumptions. in case , a similar approach can be used to investigate which particular model-based constraint is causing the low possibility – by "softening" the suspicious constraints one at a time.

a simple example of the procedure just described is shown in figure  <dig>  initially, a pmfa estimation using all the measured fluxes was performed, obtaining a maximum possibility flux vector with low possibility, π = π() =  <dig> . if the estimation is repeated removing the flux , the maximum possibility does not increase; however, when the estimation is performed removing , the maximum possibility is significantly higher . this suggests that there was a large error in the value , or an error in the model related to the balance around metabolite c which involved fluxes v <dig>  v <dig> and v <dig> 

example 3: scenario lack of data
one of the features of pmfa is that it can be used even if there is a lack of measurements; i.e. even if  is underdetermined or not redundant  <cit> .

to point this out, let us continue with our example assuming now that only two fluxes are measured . pmfa flux estimations, the marginal possibility distributions and the a posteriori intervals, are shown in figure  <dig>  notice that crisp flux estimations will only be obtained if the irreversibility constraints – or other inequalities – are able to "bound" the underdeterminacy of . interestingly, our experience show that this is often the case for medium size networks. moreover, if this is not the case, the possibilistic flux estimation will be less precise – large intervals and "wide" distributions – but still reliable, i.e. the estimation will always be as precise as allowed by the available measurements and knowledge.

example 4: using quadratic programming
to show how pmfa can be cast within other optimisation frameworks, an example using quadratic programming will be discussed. we define  as  = vm + em and j = ·w·em, where w is a diagonal matrix of weights. hence, we have  for each measurement, i.e. measurements uncertainty is represented as a quadratic possibility distribution.

let us continue with our example using the measurements of figure  <dig>  but representing them with the quadratic formulation just introduced. the original possibility distribution of single measurements  and the possibility distributions computed with pmfa  are depicted in the figure  <dig>  notice that results are similar to those obtained in the previous example , where the standard linear programming framework was used . however, the qualitative similarity between the results makes the author think that, in most cases, the linear programming setup is expressive enough and much more efficient than quadratic or other more complex optimization cases.

example 5: comparison with other methods
this example compares pmfa with traditional mfa and some of its extensions. we continue using the network depicted in figure  <dig>  and perform the estimations with pmfa, traditional mfa , mfa as a constraint, least-squares problem  and the flux spectrum .

to show that pmfa is able to represent the measurements in a flexible way, we assume that errors in v <dig> and v <dig> are non-symmetric, and we add a band of uncertainty to account for systemic errors .

inconveniently, errors have to be approximated with a normal distribution so that tmfa and ls-mfa can be used . for the estimations with fs-mfa we represent the measurements with the interval of 95%, or 2σ . all the results are depicted in figure  <dig>  notice that tmfa assigns a negative value to an irreversible flux, v <dig>  since it is not taking these constraints into account – this was predictable, but it must be highlighted because tmfa is still being widely used in the literature. the results also point out that the possibilistic distribution  are much more informative than the point-wise estimations of tmfa and ls-mfa, or the intervals of fs-mfa. basically, point-wise estimations fail when several flux values reasonably possible, whereas the flux spectrum interval tend to be conservative. furthermore, remember that tmfa and ls-mfa cannot be used in scenarios lacking data, such as example  <dig>  where pmfa was shown to be valuable.

to complete this perspective, the next section will discuss a comparison between pmfa and monte carlo approaches.

example 6: comparison with monte carlo
continuing with our example, now measurements are represented  in possibilistic terms  and  with a "similar" probabilistic formulation assuming that errors are normally distributed. both representations are depicted in figure  <dig> . then, we performed two flux estimations using  pmfa and  monte carlo simulations . the conditional possibility distributions and the histograms resulting from pmfa and monte carlo, respectively, are depicted in figure  <dig>  even if probability and possibility are not truly equivalent, a reasonable similarity between the results from both approaches exists.

notice also that this is a simple case where monte carlo can be applied. nonetheless, its worst performance is clear: the cost of computing the possibility distributions is polynomial in the number of fluxes , whereas the cost of a monte carlo approach grows exponentially with the number of independent decision variables.

larger-scale example: c. glutamicum
in this section we apply possibilistic mfa  to a medium-size example. for illustrative purposes, we have chosen a very well-know metabolic model of corynebacterium glutamicum.

metabolic network model
the metabolic network of c. glutamicum has been taken from  <cit>  and is a slight variation of the one originally constructed in  <cit> . the reactions considered in describing the biochemistry of the primary metabolism of c. glutamicum necessary to support lysine and biomass synthesis from glucose are given in the additional file  <dig>  a reaction of atp dissipation is included in the network, so that the atp balance could be maintained, without actually constraining the flux space. on the contrary, the co-factors nadp, nad and fad are supposed to be balanced. the reaction for biomass formation is an approximation using as reactants those amino acids that explicitly appear in the network and the precursors of the other amino acids synthesized by c. glutamicum.

pmfa setting
the stoichiometric relationships, embedded in a  <dig> ×  <dig> stoichiometric matrix, and the irreversibility of certain reactions, embedded in a  <dig> ×  <dig> diagonal matrix, define our model-based constraints () according to . both matrices are given in the additional file  <dig> 

experimental measurements
experimental data of a batch fermentation of c. glutamicum cultured on minimal glucose medium has been taken from  <cit> . there, the growth rate and the fluxes  of the external metabolites – lactate, acetate, glucose, o <dig>  co <dig>  nh <dig>  lysine and trehalose – were experimentally measured. since the accumulation of lactate and acetate was negligible, their flux is always zero in this case study. the measured fluxes vglc , vo <dig> , vnh <dig> , vly , vthre  and vco <dig>  and the growth rate vbio , and also their standard deviations, are given in figure  <dig> 

pmfa setting
using the data in figure  <dig>  we have built a possibilistic representation of single measurements defining convenient auxiliar variables and weights. the criterion to choose the weights was: full possibility for vm ∈  ± σ/ <dig> and possibility  <dig>  for those in ± σ. the values in ± 2·σ have possibility  <dig>  . the resultant decision variables and weights define our measurement-based constraints () according to . these possibilistic representations are depicted in figure  <dig> 

possibilistic flux estimation of c. glutamicum
we used all the available measurements – vglc , vo <dig> , vnh <dig> , vly , vthre , vco <dig>  and vbio  – to obtain the maximum possibility flux vector . the flux vector had a degree of possibility  <dig> , which could be considered "low" if one considers that a significant degree of uncertainty was already being taken into account . we then obtained the marginal possibility distributions for each flux, which inspection indicated that the low possibility was almost completely caused by only one measured flux, vnh <dig> . this suggests that this measurement was inaccurate, or that its standard deviation was underestimated. interestingly, this flux was indeed the most uncertain one in the original dataset .

as a results of this analysis – which is a rough example of the procedure mentioned in a previous section – we decided to remove the measurement and repeat our calculations. as expected, this time we obtained a maximum possibility flux vector with a similar shape, but higher possibility . the marginal possibility distributions are depicted in figure 9a, and the maximum possibility flux estimation and the flux intervals are depicted in figure 9b. numerical data are given in the additional file  <dig>  where they can be compared with those obtained if the measurement of vnh <dig> is used.

possibilistic flux estimation lacking measurements
we performed a flux estimation using only data of three extracellular fluxes that can be measured with standard equipment: vglc , vco <dig>  and biomass vbio . in this case, the obtained maximum possibility flux vector is fully possible. this flux vector and the flux intervals are depicted in figure  <dig>  remarkably, even if only three fluxes were measured, there was a small range of flux vectors with an a posteriori possibility higher than  <dig> . numerical results are given in the additional file  <dig> 

possibilistic flux estimation with uncertain model
as explained above, we can "soften" the model-based constraints to relax the pseudo-steady state assumption. as example, we assumed a degree of uncertainty around all the mass balances introducing decision variables ϵ <dig> and υ <dig> and weights γ <dig> = τ <dig> =  <dig> . hence, flux vectors which imply small accumulations of some metabolites will be accepted, yet considered less possible.

it could be also stated that the metabolic network used herein, the one introduced by vallino et al., relies on an unrealistic assumption: that co-factors nadp, nad and fad are balanced  <cit> . to avoid this, we can remove these metabolites from our stoichiometric matrix or, as an alternative, use the expressivity of the possibilistic framework to allow a certain degree of unbalance for these metabolites. just as example, herein we assumed that cofactors may be unbalanced with some limits . this "knowledge" can be easily incorporated into our model defining the convenient auxiliar variables and weights .

at this point, pmfa was performed in three scenarios:  the model-based constraints are not relaxed   the pseudo-steady state assumption is relaxed and nadp/nadph is allowed to be unbalanced, and  the pseudo-steady state assumption is relaxed and the three cofactors – nadp/nadph, fad/fadh and nad/nadh – are allowed to be unbalanced. the marginal possibility distributions obtained in each case are compared in figure  <dig>  where it can be observe how the model uncertainty is translated into the flux estimations; consider this uncertainty results in less precise flux estimations, given the less reliable model equations.

CONCLUSIONS
in this paper we have discussed a possibilistic framework for the estimation of the metabolic fluxes shown by cells at given conditions given.

considering ordinary constraint-satisfaction problems, metabolic fluxes fulfilling a set of model-based constraints and compatible some experimental measurements are "possible", otherwise "impossible". in this paper, this idea is refined to cope with uncertain knowledge – in the form of measurements errors or imperfect models – by introducing the notion of "degree of possibility", which enables grading the candidate flux values as more or less possible. then, possibilistic mfa is able to query the flux vector of maximum possibility. moreover, when multiple flux vectors might be reasonably possible, the marginal and conditional possibility distributions for each flux can be computed.

possibilistic mfa overcomes several limitations of traditional mfa and some of its extensions. it considers measurements uncertainty in a flexible way  and also model imprecision, and it is reliable even if only a few fluxes are measurable . possibilistic mfa also computes possibility distributions  which are more informative than point-wise estimations when multiple flux values might be reasonably possible. these distributions are also better than the intervals provided by the flux spectrum, or other methods giving upper and lower bounds for the fluxes. in addition, possibilistic mfa has the ability to detect, and handle, inconsistencies between measurements and model. finally, it must be remarked that possibilistic mfa estimations have been cast as linear optimisation problems, for which widely-known and efficient tools exist . this great computational performance makes the methodology capable of dealing with large-scale or even genome-scale metabolic networks.

it must be noticed that there is a challenge when estimating the fluxes in large-scale networks because there may be diffierent flux vectors compatible with the few available measurements  <cit> . interestingly, the proposed methodology is still of use in this situation: possibilistic mfa will detect all these flux vectors that are equally possible  and depict them by means of possibilistic distributions or intervals . unfortunately, if there is a wide range of candidates, the estimation may be sometimes little informative . one strategy to face this difficulty consists of using a rational hypothesis to promote certain flux vector among those that are equally possible. for instance, it can be assumed that cell behaviour has evolved to be optimal in some sense, so that the fluxes are optimally regulated depending on the given environmental conditions, and then invoke this principle to choose particular flux vectors  <cit> . there might be still alternate optima, but the approach will reduce the range of possible flux vectors. notice that this optimality principle, or any other hypothesis, might be incorporated into the possibilistic framework as far as they are encoded in in the form of a cost index . this point requires further work.

further extension may also address the adaptation of the ideas introduced herein to metabolic flux analysis with data from labelling experiments   <cit> . extracellular dynamics could be also taken into account incorporating measurements in different time instants  <cit> . finally, we are currently developing a software that implements the possibilistic mfa methods and its future extensions, which will be freely available for academia.

in summary, this papers introduces a unifying framework for flux estimation and  evaluation of consistency that is flexible, usable in scenarios lacking data, highly informative, and computationally efficient. in our opinion, the combination of computational efficiency and flexibility of the assumptions is a distinctive advantage with respect to other approaches which either may rely on stronger assumptions , or be only data-based , or provide only point-wise estimates , or be computationally intensive .

authors' contributions
fll, as and jp designed the study, analyze the results and conceptualized the manuscript. fll performed the estimations of the case studies. all authors read and approved the final manuscript.

supplementary material
additional file 1
realistic example. additional material related with the experimental case study with c. glutamicum. this includes a list of reactions and metabolites, the stoichiometric matrix and measurements data. numerical results of the four examples described in the article are also included.

click here for file

 additional file 2
code for solving a simple example. simple matlab script solving example 1; it computes the maximum possibility flux vector and the marginal possibility distribution for v <dig>  format: matlab script . further details are given in 

click here for file

 acknowledgements
this research has been partially supported by the spanish government . fll is recipient of a fellowship from the spanish ministry of science and innovation .
