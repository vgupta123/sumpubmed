BACKGROUND
dna microarrays are a very useful tool that has become ubiquitous in biological and medical research. their ability to simultaneously measure expression levels of thousands of genes depends essentially on the availability of dna oligonucleotides, or probes, that bind specifically to their targets. a dna oligonucleotide, henceforth oligo, is a single-stranded piece of dna that uniquely binds to a given region, called target . an oligo can be short  or long ; we focus in this work on long oligos as they provide increased performance  <cit> .

the problem of designing high quality oligos has received considerable attention by the research community and quite a few software programs have been developed for designing oligos  <cit> . the reader is referred to the survey of  <cit>  for a detailed description of the best existing such programs.

the oligos designed by these programs have to meet several conditions. the first is sensitivity: oligos have to bind strongly to their targets at similar temperature. sensitivity is achieved by ensuring that their melting temperatures  <cit>  are not far from each other, with implications on the gc content, and by avoiding secondary structures that would make the oligos bind onto themselves instead of targets.

the second, and much more difficult to fulfill, condition is specificity, that is, the oligos must not bind to non-targets. avoiding cross-hybridization is the most important, and the most difficult, issue for oligo selection. precise criteria have been established, and widely adopted by the community, to ensure non-cross-hybridization  <cit> ; they are often referred to in the literature as kane’s conditions: 

 the overall complementarity with non-targets should be less than 75% and

 there should be no contiguous complementary region with non-targets of length  <dig> or more.

technically, condition c <dig> means that the hamming distance between the oligo and any non-target should be less than 75% of their length. oligos satisfying these conditions will be called simply “good”, whereas those that do not will be called “bad.” the search for specific oligos implies detection and elimination of regions that are similar. therefore, many programs employ blast  <cit> , the most widely used tool for similarity search. we show that the specificity that can be achieved this way is quite low. while condition  can be easily fulfilled using text indexes, as done by picky  <cit> , condition  is much more difficult. the only program that achieves good specificity is yoda  <cit> . however, it employs an exhaustive search that is too slow to be used for most datasets.

other conditions the oligo design programs have to meet are coverage, that is, designing oligos for as many genes as possible  and speed; they should not only run in reasonable time but also be able to deal with datasets of any size. it turns out that none of the existing programs meet all these criteria.

we introduce a new approach with our software program bond , that enables us to compute highly specific dna oligos, for all the genes that admit unique probes, while running orders of magnitude faster than the competing programs. bond is implemented in c/c++ and openmp, does not use any external software, is easy to use, and it allows the user to adjust a variety of parameters.

the same approach enables us to introduce as well an evaluation procedure that correctly measures the quality of the oligos. extensive comparison is performed to prove our claims.

methods
oligo design, similarity search, and blast
an oligo binds to a non-target when they share considerable complementarity, as described by the conditions  and . that means, the reverse complement of the oligo and the non-target have substantial similarity and hence the search for specific oligos implies detection and elimination of regions that are similar. therefore, many programs employ blast  <cit> , the most widely used tool for similarity search.

the blast program has been enormously successful for similarity search  however, it is ill suited for oligo design since in this case exhaustive search is needed and blast misses many similarities. doubts about using blast for this purpose have been expressed before  <cit>  but the impact on the quality of the oligos produced has never been properly quantified. we provide such an evaluation in this section.

blast works by the “hit-and-extend” principle where a hit consisting of  <dig> consecutive matches is extended attempting to identify a local similarity. the  <dig> consecutive matches form what is called a seed. we plot in figure  <dig> the probability  of blast’s seed to identify the similarity of oligos with non-targets as a function of their sequence identity. according to condition , we are concerned with the shaded part of the graph, where sequence identity is 75% or larger. the red part represents missed similarities and the green part those that are found by blast. approximately 17% will be missed, which explains clearly why blast is not suitable for oligo design. in addition, in order to improve the speed, not all hits are investigated, thus bringing the probability of detection even lower and failing to fulfill condition  as well.

the above reasoning applies in principle to any hit-and-extend method that uses consecutive matches as hits, assuming the hits are at least as long as the blast seed;  <dig> out of  <dig> programs listed in  <cit>  use some form of consecutive matching.

spaced seeds
it has been noticed already in  <cit>  that spaced matches provide better sensitivity but it was in  <cit>  that research on finding the best spaced seeds with such properties was started. the first similarity search software program to use spaced seeds was patternhunter  <cit> ; it used the seed 111⋆1⋆⋆1⋆1⋆⋆11⋆ <dig>  for comparison, the contiguous seed of blast is  <dig> 

a spaced seed s is a sequence of 1’s  and ⋆’s . the number of 1’s is the weight of a seed and the total number of symbols is its length. assuming a bernoulli model  <cit> , an alignment can be modelled as a sequence r of 1’s, for matches, and 0’s, for mismatches. a hit of s is a region of r of the same length as s such that 1’s in s correspond to 1’s in r. given the length n of the alignment and the sequence identity p , the sensitivity of s is the probability that s hits r.

a multiple spaced seed  <cit>  consists of several spaced seeds. its sensitivity is computed similarly. we say that a multiple spaced seed consisting of k seeds of weight g is a wgsk seed. for instance, patternhunter has a w11s <dig> seed  whereas patternhunterii has a w11s <dig> seed . multiple spaced seeds can increase dramatically the sensitivity. as an example, the sensitivity of the blast’s, w11s <dig>  and w11s <dig> seeds mentioned above, for n =  <dig> and p =  <dig> %, is 30%, 47%, and 92%, respectively.

increasing the weight decreases the sensitivity but increases the specificity. to have both sensitivity and specificity high, we need to increase the number of seeds. the crucial observation  <cit>  is that doubling the number of seeds has an effect on sensitivity that is similar to reducing the weight by one. since the running time is proportional with the number of seeds and the number of random hits decreases four times when increasing the weight by one, both sensitivity and speed can be increased simultaneously.

bond’s seeds
for the design of bond, we have employed multiple spaced seeds, as anticipated in the study of  <cit> . properly designed, multiple spaced seeds can achieve near 100% sensitivity and for this reason we used them in bond. however, the distribution of the matches in seeds is by no means random and finding the optimal arrangement is a hard problem  <cit> . a number of software programs for designing spaced seeds exist  but speed  <cit>  is the only polynomial-time algorithm that computes good  seeds and we have adapted it for our needs. we have computed a w9s <dig> seed whose sensitivity is plotted in figure  <dig> ; its sensitivity is called “seed sensitivity” to avoid confusion with the sensitivity of the oligos). its sensitivity at 75% identity is  <dig> % and the probability of detecting bad oligos of length  <dig> so that they respect condition  is  <dig> %.  and the total area of sequence identity 75% or higher; red and green together.) this is nearly perfect. we could have computed better seeds but this one did not make any error in all our tests and decreasing weight or increasing the number of seeds would slow down the program.

there are two reasons why this w9s <dig> seed is so effective. first, the sensitivity as given by the model is slightly underestimating the actual probability of the seed to find bad oligos since sequence identity below 75% is allowed in the model but not in our application. second, we screen first the input data using a different w10s <dig> seed, also computed by speed, in order to quickly eliminate long repetitions.

bond’s algorithm
there are several features that make bond fast. first, in order to achieve the sensitivities of the seeds as computed above, we need to investigate every possible hit in the input data, for each seed. in this context, a hit of a seed is a pair of substrings of the same length as the seed which match on all positions corresponding to 1’s in the seed. this would be time consuming for the w9s <dig> seed. therefore, in phase i, we filter the input data for long repeats, using the w10s <dig> seed. moreover, only pairs of consecutive hitting substrings are considered.

assume l is the required oligo length. a region of length l will be called unique if it does not have 75% sequence identity or more with any other region of the same length. we keep a binary array, initialized with 0’s, where starting positions of non-unique regions are eliminated by marking them with 1’s. phase i usually eliminates a substantial portion of the input. phase ii uses the more sensitive w9s <dig> seed. we still do not consider all remaining 0’s as it would still be too time consuming. instead, we use an effective heuristic. the middle position of the longest contiguous stretch of 0’s is considered first to be tested by the w9s <dig> seed. all possible hits concerning the potential oligo ending at this position are considered, thus using the entire power of the seed. if this oligo is found to be bad, then the position is marked with a  <dig> and the algorithm continues trying to find a good oligo until either one is found or the gene is shown not to have one. it is important to notice that the order in which the genes are considered is irrelevant; this helps parallelizing the process.

using tm to denote the melting temperature, assume that the requested oligo length is l and the size of the melting temperature interval is Δtm. for example, in our tests l =  <dig> and Δtm =  <dig>  by l-mer we shall mean a substring of length l. the high-level structure of the algorithm of bond is as follows: 

 <dig>  encode dna sequences

 <dig>  eliminate l-mers not satisfying  

 <dig>  eliminate l-mers not satisfying gc content 

 <dig>  eliminate l-mers not satisfying  – phase i 

 <dig>  compute melting temperature interval t 

 <dig>  eliminate l-mers with tm not in t 

 <dig>  check selected oligos for  – phase ii 

 <dig>  output oligos found, with genes and positions

l-mers are eliminated when found not to fulfill one of the required conditions. at any moment in the algorithm, the l-mers that were not eliminated so far are called valid. in step  <dig>  the input data is processed so additional information is eliminated and only dna sequences are kept. at the same time, all l-mers containing ambiguous or unknown nucleotides are eliminated. step  <dig> eliminates l-mers containing 15-mers that occur elsewhere ). step  <dig> eliminates l-mers with gc content outside the required range. step  <dig> performs phase i of , using the w10s <dig> seed as explained above. for step  <dig>  the melting temperatures  are computed for all currently valid l-mers. the interval t, of size Δtm, containing the highest number of genes having valid l-mers with tm within t is computed by evaluating, in linear time, all intervals of the given size starting at any hundredth of degree between minimum and maximum tm. all l-mers having their melting temperature outside t are eliminated in step  <dig>  phase ii of  follows at step  <dig>  using the full power of the w9s <dig> seed as explained above. finally, at step  <dig>  good oligos are reported.

evaluation algorithm
evaluating the quality of oligos involves solving problems similar with those faced during oligo design and the lack of tools for the latter implied the nonexistence of adequate procedures for the former. for instance, the evaluation of  <cit>  uses blast with default weight  <dig>  thus having the problems we have mentioned above. we have designed a similar approach for our evaluation procedure, however, in order to accurately measure the performance of oligo design programs, including bond, we need a much more powerful tool. we have used again speed to design the evaluation seed with the estimated probability of error  <dig> %.  the sensitivity of the three seeds are compared in figure  <dig>  this seed is estimated to make one error for each million oligos but, again, it is even more accurate in practice. it is thus safe to assume that it provides perfect evaluation.

all hits of this seed in each oligo are checked against the entire input. due to very low weight of the seed, the evaluation is time consuming, but the results are quite reliable. it is interesting to notice that our evaluation is still considerably faster than the exhaustive search of yoda. this is due to the performance of the multiple spaced seed and efficient implementation.

the evaluation seed accurately classifies the oligos into “good” or “bad”, depending on whether they satisfy conditions  and  or not, respectively. the ratio between bad oligos and the total number of oligos gives the specificity. in order to evaluate coverage, that is, how many of the maximum possible number of genes can be associated with good oligos, we give an algorithm that approximates very well this maximum number of genes. due to, again, lack of tools, coverage has not been measured before.

the approximation of the maximum number of genes that can have oligos, needed to evaluate coverage, is done as follows. what we need to find is the melting temperature interval that can produce the highest number of oligos. steps 1- <dig> of bond are performed first. then, for each interval m of size Δtm, the number of genes that contain a valid l-mer with melting temperature in m is computed. those intervals for which this number is less than the number of oligos computed by bond are eliminated, since they have no chance to perform better than bond. an interval larger than Δtm is left and step  <dig> of bond is performed with this interval. from the remaining oligos, an extended phase ii is performed, in which all valid l-mers are checked using the w9s <dig> seed. finally, the highest number of genes in an interval of size Δtm is reported.

implementation
both bond and the evaluation algorithms are given a fast parallel implementation. there are two level of parallelization, one involving bit operations and the other multiple processors.

dna sequences are stored using two bits per nucleotide. all l-mers including unknown and ambiguous positions are eliminated from the beginning. seeds are stored as 64-bit integers and hash tables are used to store the positions of all possible spaced w-mers corresponding to each seed; given a seed of weight w, a spaced w-mer is any sequence of w letters in positions that corresponds to the matches in the seed. each spaced w-mer is computed by and-ing the mask of the seed with each position in the dna sequences and stored as a 64-bit integers. a similar strategy is used for 15-substrings ). since only elimination is performed, there is no need to use a text index, such as the suffix array to sort the 15-mers.

the most time consuming tasks are then performed in parallel. the hash tables for all seeds are computed in parallel for all seeds in each set. the uniqueness checking for all candidate oligos is done in parallel as well.

RESULTS
datasets and parameters
the web site of picky  <cit>  contains a wide variety of datasets and we considered them all for our comparison. we have added the dataset used in the survey of  <cit> , consisting of  <dig> genes involved in the development of the mouse nervous system, as well as the complete set of mouse genes from which those have been extracted. the datasets are shown in table  <dig>  descriptions of the datasets, including download links are provided in the additional file 1: table s <dig> 

the size given represents only the actual dna sequences.

we have used the most common parameters for evaluating the programs: oligo length  <dig>  gc content between  <dig> .70%, size of melting temperature interval   <dig>  maximum identity with non-target below 75%, and maximum consecutive matches allowed  <dig> 

comparison
we have compared bond with six programs that performed the best in the survey of  <cit> : arrayoligoselector  <cit> , oligoarray  <cit> , oligopicker  <cit> , oligowiz  <cit> , picky  <cit> , and yoda  <cit> . since the length of the oligos is fixed and the interval of melting temperatures has the same size, similar sensitivity is expected. therefore, we have measured the specificity, coverage, and speed. table  <dig> shows the total results for all seven programs. detailed results, for each of the considered organisms, are given in the additional file 2: table s <dig>  visual comparison is presented in figure  <dig>  where  gives good vs bad oligos,  specificity and coverage, and  speed.

the specificity represents the percentage of good oligos out of the total number. the maximum number of genes that have good oligos was estimated by our evaluation program at  <dig>  oligos. the coverage represents the percentage the number of good oligos represents out of this estimated maximum.

all programs were tested on the same machine, dell vostro, with intel core i7- <dig> cpu ,  <dig> gb of ram, and 8mb of cache running gnu linux version  <dig> . <dig> -desktop-69mib; the compiler used was gcc  <dig> . <dig>  the more time consuming evaluation was performed on the sharcnet high performance computers .

out of the six existing programs, arrayoligoselector, oligoarray, and oligowiz showed low performance in all respects. oligopicker has fair coverage but the specificity and speed are both low. picky is the fastest and the specificity is good, however the coverage is low. picky uses the suffix array  <cit>  to correctly fulfill condition  and achieves good speed. yoda has the highest specificity and coverage, which is expected due to the exhaustive search involved. however, its speed is the lowest among all programs. for instance, it took more than five days to complete the rice dataset.

bond performs significantly better than all the other programs; under the testing conditions, it achieves 100% sensitivity and 100% coverage. all  <dig>  oligos produced are good and the estimated maximum possible is  <dig> , that is, bond may have missed  <dig> oligos. likely, this is not due to lack of sensitivity but to the slightly suboptimal decision on the melting temperature interval . as far as speed is concerned, bond is six times faster than picky, two orders of magnitude faster than oligopicker, and over three orders of magnitude faster than yoda. bond completed most tests under one minute.

bond is freely available for non-commercial use from http://www.csd.uwo.ca/\~ilie/bond/. it requires no additional software and is easy to use. a wide range of input parameters allow the user to customize the oligos been produced in many ways: oligo length, gc content, size of melting temperature interval, oligos at 3’- or 5’-end, maximum number of consecutive matches allowed, maximum sequence identity allowed, secondary structure parameters. details are given in the user manual provided in the same website.

CONCLUSIONS
we provide an improved solution to the important problem of oligonucleotide design. our bond software provides highly specific oligos, that cover the highest possible number of genes, while running orders of magnitude faster than existing software. we have provided also a thorough evaluation of oligo design programs.

we have focused here on the basic problem of finding gene-specific oligos. we plan to extend bond in the near future to compute genome-wide tiling arrays; see  <cit>  for references to such programs.

we hope bond will become a useful tool for researchers in biological and medical sciences by making the microarray procedures faster and more accurate. we shall gladly receive their suggestions for further development.

competing interests
the authors declare that they have no competing interests.

authors’ contributions
li designed the new approach, the algorithm of bond, the bit-parallel implementation, the evaluation algorithm, optimized the code, modified speed to compute the multiple spaced seeds used, and wrote the manuscript. hm wrote the parallel code of bond and the evaluation program, helped improving its running speed, and performed the tests and comparisons with the other programs. gbg was the advisor on biological matters and wfs provided algorithmic suggestions. all authors met regularly to discuss decisions concerning the development of the software. the final version of the manuscripts was read and approved by all authors.

supplementary material
additional file 1: table s1
 descriptions of the datasets used in the paper, including download links.

click here for file

 additional file 2: table s2
 detailed results for comparison between bond and the currently leading software programs for oligo design.

click here for file

 acknowledgements
performance evaluation has been performed using the facilities of the shared hierarchical academic research computing network  and compute/calcul canada. l.i., h.m., g.b.g., and w.f.s. have been partially supported by grants from the the natural sciences and engineering research council of canada .
