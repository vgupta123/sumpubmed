BACKGROUND
since its introduction by mullis et al.  <cit> , the polymerase chain reaction  has been widely used to amplify and quantify small amounts of dna. briefly it constitutes a few dozen cycles in each of which there are three stages: denaturation, annealing and extension.

at each cycle each dna strand either doubles  or fails to double. defining amplification efficiency, e, as e=1+p the expected number nc of strands after c cycles, given constant p, is  nc=n0c=n0ec,  where n <dig> is the initial number. we use this definition of e to be consistent with ruitjer et al.  <cit>  and in that we deviate from miqe guidelines  <cit> .

the amount of dna can be estimated fluorimetrically using, for instance, sybr green  <dig> dye which binds to the minor groove in double-stranded dna  <cit> . commonly the relevant question biologically is one of relative quantification: the ratio of initial dna in two samples. if samples a and b, initially containing na and nb strands, exhibit the same fluorescence after ca and cb cycles respectively, then assuming constant p,  naca=nbcb,  from which we have   na/nb==eΔc, 

where Δc=cb−ca. accordingly, the cycle difference, Δc, and e , are the key to estimation of the ratio na/nb.

in common use there are two fundamentally different approaches to the estimation of e. one involves the generation of curves from a series of dilutions: an eight-fold dilution, for instance, would delay the fluorescence by three cycles if e= <dig> because 23= <dig>  if e= <dig> , however, it would delay the fluorescence curve by  <dig>  cycles, because  <dig> .53= <dig>  alternatively , e can be estimated from the real-time fluorescence data. at each cycle early in the sequence, fluorescence above background will increase by a factor e, which can therefore be estimated from the data in this ‘log-linear’ phase. the early phase of exponential increase is short-lived. as resources become limiting, the fluorescence curve flattens out, and liu and saint  <cit>  have used the sigmoid or logistic function,   f=fb+fmax1+eβ, 

where fb is background, and fmax is maximum contribution of the reaction to fluorescence, , to describe the data. rutledge and stewart  <cit>  introduced an analysis which takes into account the linear decrease in amplification under this model, simplifying the estimation of the initial amplification efficiency from the curve itself. miqe guidelines  <cit>  recommend the former approach: ‘pcr amplification efficiency must be established by means of calibration curves...’ but we acknowledge ongoing debate on this issue.

strictly speaking the data from a tube are discontinuous; fluorescence is measured at the end of each cycle, and there is no such thing as a fluorescence after a fractional number of cycles as implied by the continuous functions above. we use the term reference curve to imply an abstraction; a smooth continuous curve of fluorescence as a function of x, which we observe at cycles c which are integer values of x. the observed fluorescence is the fluorescence at these integer values, but with the addition of error or noise.

a key to analyzing pcr, therefore, is, given two fluorescence curves, to measure Δc, the extent to which one curve is shifted laterally relative to the other. there are two very different circumstances under which one may need to do this. if e is to be estimated from the cycle-to-cycle increase in fluorescence of a single assay tube, then quantifying some aspect of the fluorescence is important. conversely, if one is using dilution to estimate amplification then the shape of the curve is of less import so long as the data and the reference curve have in common that they are s-shaped : interest lies only in the extent to which dilution has shifted the curve, of whatever shape, to the right. whatever the method of estimating e, that estimate is commonly used subsequently to derive, in concert with a measured cycle difference between two tubes, Δc, the initial concentration ratio implied by eq.  <dig> 

it is the estimation of cycle shift in these scenarios which we address; to what extent is one fluorescence curve shifted relative to another? there is, of course, a significant literature detailing several algorithms to do just that, and we should justify any attempt to add another. ruitjer et al.  <cit>  have examined the performance of nine estimators of e and have proposed several measures of their relative merits. in using the publicly available data sets comprising dilution series for establishing amplification efficiency, two measures are of central importance. one is the within-replicate variance; most data sets have three or more replicates at each dilution, and for a good estimator we expect values of cq from these replicates to be close. the second measure is the standard deviation of the estimate of the slope when cq is regressed against the logarithm of dilution; the smaller the standard deviation of the slope, the smaller will be that of the estimated efficiency. following ruitjer et al., we use both of these, and compare approaches using friedman’s non-parametric rank sum.

the three algorithms which we examine in detail, and which performed very well in the review by ruitjer et al. are cy <dig>  standard- cq, and pcr-miner. the latter algorithm includes both an estimate of cq, and an estimate of efficiency derived from each curve, and we should emphasize that we are implementing only the cq-estimating component of pcr-miner. to avoid confusion with the full pcr-miner algorithm we will refer to it as the sdm-l <dig> method .

notwithstanding their established utility we have concerns about each of these approaches. for cy <dig>  the derived cq depends on the baseline. we regard baseline fluorescence as a ‘nuisance’ parameter, as do several algorithms that attempt to eliminate it. our bias  is to use an estimator independent of baseline. standard- cq finds the fluorescence  at the second derivative maximum  for the  undiluted sample, and for subsequent samples cq is defined as the  cycle at which fluorescence achieves fq. again this is influenced by sample-to-sample variation in baseline, and for the subsequent diluted samples it takes information from only two readings out of the entire curve. the sdm-l <dig> approach overcomes the above reservations by fitting a four-parameter sigmoid curve and calculating the cycle of sdm as implemented, for instance in some commercially available software  <cit> . this approach is independent both of baseline and of scale, but it raises a more subtle problem. each reference curve is of a different shape. the distance between the curves in a dilution series is not well defined if each curve is of a different shape; they are not the same curve translated laterally along the dilution axis. the distance between the second derivative maxima, for instance, is different from the distance between the first derivative maxima.

methods
biological methods
ethics approval for the use of peripheral blood leucocytes was obtained from the human researach ethics committee of the queen elizabeth hospital , and the use of samples followed the protocol approved by that committee, as documented in bianco-miotto et al.  <cit> .

rna extraction and reverse transcription
rna was extracted from cells grown in tissue culture using trizol  according to the manufacturer’s protocol. the concentration of rna was determined using a biophotometer . dnase treatment of total rna was performed prior to reverse transcription in order to minimize pcr signal arising from carry-over genomic dna . rna was reverse transcribed using superscript iii rt . cdna was diluted  <dig> fold in ultra pure water  prior to real time pcr.

preparation of genomic dna
mononuclear cells were isolated from the peripheral blood of healthy donors using lymphoprep  according to the manufacturer’s instructions. genomic dna  was purified from the mononuclear cells using trizol  according to the manufacturer’s instructions.

preparation of dilution series
 <dig> μl of ultra pure water was aliquoted into a series of  <dig>  ml pcr tubes, and either  <dig> μl of gdna or  <dig> μl of cdna was added to the first tube and mixed by pipetting up and down  <dig> times.  <dig> μl of this mixture was then pipetted to the next tube and mixed, and the process repeated across the tubes, to produce a two-fold serial dilution.

real-time polymerase chain reaction
pcr amplification was performed in  <dig> μl final volumes containing  <dig> μl of cdna or gdna template,  <dig> μl of each forward and reverse primer , and  <dig> μl of  <dig> × quantitect sybr green master mix . thermocycling was performed in a rotorgene  <dig> thermocycler  with an initial activation/denaturation  at 95°c for  <dig> min; followed by  <dig> cycles of  <dig> sec at 95°c,  <dig> sec at the annealing temperature, and  <dig> sec extension at 72°c. after the cycling there was a final extension at 72°c for  <dig> min. triple replicates of twelve  2-fold dilutions reactions were performed on all samples. products were then melted in the rotorgene  <dig> thermocycler from 60°c to 99°c at  <dig> °c for  <dig> sec per step to determine if the pcr products melted at the same temperature as pcr products that had been fractionated through 1% agarose gel to confirm that the product was of the predicted size.

details of amplicons and primers appear under additional file 1: table s <dig> 

numerical methods
data analysis was carried out under gnu/linux ubuntu  <dig>  lts using the r programming language  <cit>  and the associated packages qpcr  <cit>  and ggplot <dig>  <cit> . the fixed-point estimator is as documented below. the methods standard- cq, sdm-l <dig> nd cy <dig> were implemented as follows.

standard- cq
the essence of standard- cq is to locate the fractional cycle corresponding to the sdm of the  undiluted sample, and to define fq as the  fluorescence at that fractional cycle. the cq of each cycle, diluted or undiluted, is the fractional cycle at which fq is achieved.

if fi denotes the fluorescence at the ith cycle of the averaged undiluted samples we find i for which the second derivative,  is maximal, and then assuming that the second derivative of fluorescence, if continuous, would be adequately approximated by a quadratic around the ith cycle we now have as fractional cycle maximizing that quadratic as the location of sdm. the  fluorescence of the undiluted sample is then found by interpolating the cubic through the adjacent four fluorescence values. this defines fq. for each sample we then find k such that fk−1<fq<fk implying that cq for that sample lies between  and k. again the fractional cycle at which fq occurs is found by cubic interpolation of the observed fluorescence at fk−2⋯fk+ <dig> 

sdm-l4
the function pcrfit() from the qpcr statistical package finds for each dilution curve, the parameters of best fit for the four-parameter model defined   y0+a1+b,  from which the location of the sdm is given by  x03b2−2b2+3b+2k. 

cy0
the function pcrfit() as above finds the parameters of best fit for a five-parameter sigmoidal curve. as introduced by guiscini  <cit> , the function used was   fx=fb+fmax)f, 

although the example in the qpcr package uses the closely related   fx=fb+fmaxβ)f, 

and we have implemented both for comparison. we denote the former cy0-b <dig>  the latter cy0-l <dig>  referring to the five-parameter functions b <dig> and l <dig> of the qpcr package.

the function cy <dig> from the qpcr package takes the five parameter function and returns cy <dig> as the point of intersection with the abscissa of the tangent through the maximum first derivative.

theoretical development of fixed-point approach
in estimating Δc we are quantifying the extent to which one curve needs to be shifted horizontally  in order that it might overlie the other. that aim requires three qualifications: first, that there may need to be some vertical shift to accommodate different baselines; second, that the same applies to scale; third that we have equally-spaced points rather than a continuous curve.

if, as in some standard analyses, the ‘position’ of a fluorescence curve is taken to be the fractional cycle at which fluorescence attains some arbitrary threshold, then the tube-to-tube variation in the baseline and scale of fluorescence becomes a problem; scale is particularly so where fluorescence has not reached a terminal plateau. the appeal of using position of maximum first or second derivative  is that these are not influenced by changes in baseline or scale.

we can ask how much one fluorescence curve needs to be shifted such that it overlies another, but because we have points, rather than continuous curves we will usually find that, at best, one set of points lies close to, but between, the points of the other.

a reference curve
the strategy commonly adopted, and which we adopt here, is to fit our observed fluorescence data to some continuous function. the functions discussed below have in common that they are s-shaped . the common definition of a good fit is one which minimizes the sum of squares of differences between the observed data and the continuous function being fitted, and again we follow that practice. the qpcr package  <cit>  uses the marquardt-levenberg algorithm to accomplish this. commonly used are the five-parameter functions adopted in the variants of the cy <dig> estimator introduced earlier simplified version of which are obtained with the constraint f= <dig>  giving the four-parameter curve used in sdm-l <dig> or the four-parameter curve of eq.  <dig> as in liu and saint  <cit> . in explaining the fixed-point approach is convenient to note that we can recast eq.  <dig> as   fx=fb+fmax1+a, 

where a=eβ. we still have four parameters, but instead of varying β to obtain best fit we are varying a=eβ. this makes no difference to the fit; it just makes the physical significance of the parameters more obvious to the reader.

looking at the four parameters in turn we have this is the background fluorescence of an assay which we are assuming to be a nuisance variable. we want our estimate, cq to be independent of fb.

this is the difference in fluorescence between fb and the asymptote which fluorescence is approaching. we take tube-to-tube variation in fmax to result from differences in such factors as the opacity of the assay tubes; it is a nuisance variable, and cq should be invariant with fmax.

this determines shift along the abscissa . in the four-parameter models mentioned, it is the fractional cycle at which the fluorescence representing reaction product is 50% of fmax.

this determines the shape of the curve and we note that the increase in fluorescence due to polymerase reaction during the first cycle is  fmax1+a·1+ax0fmax=1+ax01+a,  which, for large ax <dig> tends to a. that is, the parameter, a is the amplification efficiency during the early, exponential, part of the chain reaction.



if we now want to fit the fluorescence in each tube of a dilution series to the ‘same’ continuous function, it seems preferable to use the function which models the appropriate amplification efficiency. by the ‘same’ continuous function we mean functions for which a is the same. we accept that fb, fmax and x <dig> will vary from tube to tube, because baseline, scale and cq will vary from tube to tube. but the idea of running a dilution series to determine amplification efficiency is predicated on the assumption that amplification efficiency, and hence a, is the same for every tube. we might seek, therefore, to find for each tube the values for fb, fmax and x <dig> that best fit the observed fluorescence in that tube, keeping a fixed at the amplification efficiency as derived in the usual way from a regression of cq against logarithm of dilution.

the impasse is now obvious; the point of dilution assay is to determine the amplification efficiency. until we know the amplification efficiency we do not know the appropriate value of a to use in eq.  <dig> to determine the cq for each tube. the bauer fixed-point theorem resolves that impasse. using fixed-point convergence , we begin with an initial guess, a <dig>  this leads to estimates cq for each tube on the basis of which the slope of regression against logarithm of dilution gives a first estimate e <dig> of amplification efficiency. we now replace our initial guesstimate a <dig> with a1=e <dig> and repeat the process giving a second estimate e <dig> and so on, until subsequent estimates are unchanged and convergence has been achieved.

for the process to converge, the requirement of the fixed-point theorem is that a plot of e <dig> against a <dig> , should have an absolute slope less than one. providing this condition is satisfied , the theorem asserts that the process will converge

the smaller the slope, the faster it will converge

the value to which it converges is independent of the starting estimate a0



we note that, in fitting eq.  <dig> to an observed fluorescence curve, if a is fixed, there are only three parameters, fb, fmax and x <dig> of which both fb and fmax enter the equation linearly. since we are really only interested in the parameter x <dig> we can, under these circumstances, avoid using the marquardt-levenberg algorithm and find the value of x <dig> which maximizes the pearson correlation coefficient between observed fluorescence and the fitted curve. that correlation will be independent of fb and fmax, and will give the same ‘best fit’ x <dig> as a marquardt-levenberg approach minimizing the sum of squares of differences. if we denote by xi the value of x <dig> maximizing correlation in the ith tube, each tube now has a reference curve of the form  11+a. 

the reference curves for all tubes are now the same shape, apart from their shift along the abscissa determined by xi. because shift along the abscissa is the only difference between any two curves the concept of Δcq as that difference is now unambiguous; we could define it as the difference between first derivative maximum, second derivative maximum, or difference between cycles at which some fraction of the increase has been achieved and all these definitions would result in the same Δcq. the simplest definition is to use xi as the cq for the corresponding tube .

in summary the steps in the fixed-point algorithm are as follows. we will use the publicly available dataset batsch <dig> from the qpcr package as an illustration, including the numerical values which we obtain. using an initial guesstimate of amplification efficiency  define  f=f=11+ <dig> . 

use algorithm of choice to find, for each tube, the value of x <dig> which maximizes the correlation between f and the fluorescence data from that tube. for that tube let cq=x <dig>  the first fluorescence data from batsch <dig> is shown in figure  <dig>  by inspection we can see that half the generated fluorescence occurs by about cycle  <dig>  so the reference curve showing greatest correlation will have a value of x <dig> of about  <dig>  figure  <dig> shows a plot of correlation against x <dig> for values of x <dig> from  <dig> to  <dig> and we can see the correlation maximizing at cycle  <dig>  a good first-estimate of the fractional cycle at which correlation maximizes is obtained by quadratic interpolation using the three correlations at this and the adjacent cycles. given the correlations are  <dig> ,  <dig> , and  <dig>  at cycles  <dig>   <dig> and  <dig> respectively we imply a maximum at cycle  x0= <dig> − <dig> = <dig> . figure  <dig> 
a fluorescence curve. the first fluorescence curve from the batsch <dig> data set is approximately half-way between baseline and its maximum at cycle  <dig>  we expect, therefore, that correlation with the sigmoid reference curve will maximize at a value of x
0≈ <dig> 
correlation between reference curve and data. the correlation between the reference curve and the data of figure  <dig> maximizes at a value x
0≈ <dig>  the value of the fractional cycle maximizing correlation can be found either by fitting a quadratic through  <dig> and the adjacent points, or by a one-dimensional non-linear search. for the illustrated data, the maximum is at  <dig>  cycles.



of course, any iterative approach can be used, and as we are only looking for a maximum in one dimension the r procedure optimize() is appropriate. in practice, for these data there is no improvement; a maximum correlation is found at cycle fractional cycle  <dig> . set cq for this tube as  <dig> . repeat for each tube.

regressing cq against logarithm of dilution determine estimated amplification efficiency, and return to step  <dig> replacing a with this estimate. we prefer to use logarithms to base  <dig> as in figure  <dig> because the implication of the regression slope is clear from inspection; a doubling at each cycle  would imply that a two-fold dilution shifts the fluorescence curve by exactly one cycle. the regression slope in figure  <dig> is  <dig> , implying that it takes  <dig>  cycles to compensate for a two-fold dilution. if there is an e-fold increase each cycle then  e <dig> = <dig>  from which it is immediate that  e1= <dig> = <dig> . figure  <dig> 
the regression of
c
q
 against logarithm of dilution . if each pcr cycle were to double the dna, then a two-fold dilution would delay the curve by one cycle. the slope of the straight line regressing c
q against log of dilution  tells us how many cycles are required to double the dna. using a reference curve with a= <dig>  slope is  <dig>  cycles per doubling, or equivalently increasing the dna  <dig>  - fold per cycle. the next fixed-point iteration will use a= <dig>  in the reference curve.



return to step  <dig>  replacing the initial a= <dig>  with a= <dig> . iterate until estimated efficiency is unchanged. this is the fixed-point iteration, and is illustrated in figure  <dig>  in the above we started with guesstimate a0= <dig>   and the first cycle returns an estimated efficiency  <dig> . this corresponds to the vertical blue line on figure  <dig> in which the red curve shows for this process the output e for a range on input a from 1· <dig> to 2· <dig>  bauer’s fixed point theorem guarantees convergence if the slope of this line is absolutely less than one in the region of interest . we then replace our initial a0= <dig>  with the revised a1= <dig>  , varies according to the assumed amplification efficiency  used to construct the sigmoid reference curve. the red line is a plot of  as a function of . applied iteratively, however, the process converges to the point of intersection of the red curve and the line of identity . this point of convergence, the fixed-point, is independent of the starting value. with a starting value of a= <dig>  the first iteration is shown in blue, the second in green.





RESULTS
fixed point convergence
for all data sets with an initial estimate a0= <dig>  used in the logistic function, deliberately far from the expected e, the fixed-point iteration had converged to within. <dig> of its asymptote in four iterations; a convergence well beyond any biological relevance. the rapid convergence results from the relative insensitivity of estimated e to the a used in the logistic reference curve. figure  <dig> shows estimated e <dig> as a function of input a <dig> for all ten data sets from our laboratory. the slope of all curves in the interval of interest is well within the  required for convergence by the banach fixed-point theorem. for nine of the ten data sets, however, the parameter of the logistic function does influence the corresponding e estimate and it is important that the parameter be determined objectively. additional files  <dig> and  <dig> show the corresponding figures for the publicly available data sets.figure  <dig> 
convergence of fixed-point iteration. the convergence of the iterative process illustrated in figure  <dig> depends on the slope of the curve relating e - out to a - in. the process will converge provided the slope is not too great . we illustrate the ten data sets from this laboratory: the slope is less than that of the line of identity, and fixed-point convergence is guaranteed. numbers  <dig> to  <dig> correspond to the data sets flind <dig> - flind <dig> respectively.



there are  <dig> data sets, giving  <dig> standard deviations for estimates of slope by each of the five analysis methods. the rank sums appear in the first line of table  <dig>  using friedman’s rank sum to compare the standard deviation of the estimate of slope the null hypothesis of equal distributions is rejected . the best two estimators are sdm-l <dig> and fixed-point. proceeding to a direct comparison of the two, the fixed-point estimator performs better, having a smaller standard deviation in  <dig> of  <dig> comparison. the difference, however, is not of statistical significance.table  <dig> 
sum of ranks 



variable
sdm-l4
std
c
q
cy0-l5
cy0-b5
fixed point
for each of the five estimators of c
q we have ranked their performance as judged by the standard deviation of replicates  and by the standard deviation of the estimated slope when c
q is regressed against log. dilution . for both approaches the null hypothesis of equal distributions of ranks is rejected. on direct comparison of the best two , fixed-point has a smaller standard deviation of replicates in  <dig> of  <dig> comparisons, and a smaller standard deviation of slopes in  <dig> of  <dig> comparisons.



within the  <dig> data sets are  <dig> sets of replicate cq. the rank sums of replicate standard deviations appear as the second line of table  <dig>  again using friedman’s rank sum test on the null hypothesis of equal distributions of replicate standard deviations the null hypothesis is rejected . on direct comparison of the better two estimators, sdm-l <dig> and fixed-point, the fixed-point is the better estimator in  <dig> of  <dig> comparisons but again this is not statistically significant.

caveats
we would caution, however, against too literal an interpretation of the standard deviation of the slope estimate. the linear regression of position against log on which it is based assumes normally-distributed homoscedastic data. data from qpcr dilution series are almost never homoscedastic because higher dilutions lead to more variable fluorescence sequences than do lower dilutions. even if errors at low dilutions are gaussian, those at higher dilutions result from poisson effects and will not be gaussian. figure  <dig> is characteristic of the regression line and associated data, and demonstrates the increased variance at higher dilutions. in addition, the linear regression assumes that the dilution itself is error-free, and we doubt that this is true of our own data. although these concerns lead us to doubt the absolute values of the standard deviations, the concerns apply equally to the five estimators, and are unlikely to draw into question the ordering of these for any one data set.figure  <dig> 
regression of
c
q
 against logarithm of dilution. amplification efficiency is estimated from the slope of the line relating c
q to the dilution, the latter on a logarithmic scale. the confidence limits for the slope, when calculated from unweighted least-squares  is strictly appropriate only for normally-distributed homoscedastic data. we caution that our data are not homoscedastic, and are unlikely to be normally distributed.



when cq is regressed against log dilution the standard deviation of the slope depends in part on whether cq increases linearly with log dilution, and this in turn depends on amplification efficiency being constant at all dilutions. in using the variance of slope as a measure of the merit of a method, we assume that amplification efficiency is invariant with dilution. in practice the data sets we have analyzed show a remarkable linearity; the reason for assaying at intermediate dilutions is to confirm that linearity, without which a dilution series would be difficult to interpret.

the fixed-point method assumes that the fluorescence data approach the plateau. if, in a dilution series, the higher dilutions result in only the very early part of the fluorescence curve emerging, then the estimated cq at these dilutions will be unreliable.

finally we have presented a comparison of the five methods discussed, and use friedman’s non-parametric rank sum as a test of the null hypothesis that the methods are equivalent. our data, however, are not randomly selected from the population of dilution series in general, and the friedman’s test should be interpreted with caution in this context. we have examined two ‘merits’ of the methods: replicate standard deviation and slope standard deviation. these are not independent: the standard deviation of the slope estimate takes into account that of the replicates.

CONCLUSIONS
the use of a reference curve,  relative to which the position of fluorescence data can be measured, avoids subjective decisions as to baseline and scale and threshold. using data from the whole curve, rather than just a few points, it offers an approach to the estimation of amplification efficiency from a dilution series. the logistic function represents a family of curves, however, and the specific curve appropriate to a given dilution series can be defined by fixed-point iteration. convergence is rapid and for the illustrative data used here the method is often, but not always, an improvement on existing estimators.

additional files
additional file  <dig> 
table s <dig>  details of incubates flind <dig> to flind <dig> 



additional file  <dig> 
convergence of fixed-point iteration. this figure corresponds to figure  <dig> of the main text, but looks at the publicly-available data sets batsch <dig> to batsch <dig>  and reps , reps <dig> , reps <dig> .



additional file  <dig> 
convergence of fixed-point iteration. as for additional file  <dig>  but with the publicly-available data sets boggy , guiscini , lievens <dig> , rutledge  and sisti .



competing interests

the authors declare that they have no competing interests.

authors’ contributions

dw and dh conceived and oversaw the research. dh, tw and gm constructed the primers and carried out the experimental work. mj and gm devised, carried out, and documented the data analysis. all authors read and approved the final manuscript.

this work was funded by grant app <dig> from the national health and medical research council of australia. we gratefullly acknowledge the recommendations of two anonymous reviewers contributed substantially to the final form of this manuscript.
