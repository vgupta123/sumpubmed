BACKGROUND
owing to recent advances in microscopic technology, biological labeling and digitization technology, large-scale live imaging with high spatiotemporal resolution is now possible. the live imaging technique accompanied by advanced computational methods has realized the automated analysis of biological dynamics. the usual automated technique, cell tracking during embryonic development, has been successfully performed in the nematode caenorhabditis elegans , zebrafish  <cit> , and drosophila melanogaster  <cit> .

the embryonic development of c. elegans proceeds through a stereotypical pattern of cell divisions, known as an invariant cell lineage. automated cell tracking exploits the invariant cell lineage, enabling large-scale systematic analysis of cellular dynamics in wild type and mutant embryos. comparing the cell tracking results of different individuals, researchers have revealed small differences in cell division timings, cell cycle lengths and cell positions during embryonic development  <cit> . cell tracking has been combined with the reporter gene expression of multiple genes and merged onto a reference lineage for gene expression profiling  <cit> . noting that the generated profile distinguishes nearly all pairs of embryonic cells  <cit> , du et al.  <cit>  constructed a strategy that detects homeotic transformations on genetic perturbations by comparing the mutant and wild-type profiles, and infers the system-level mechanistic model of differentiation  <cit> .

on the other hand, cells form stereotypical shapes during essential cell movements  <cit> , cell–cell interactions  <cit>  and morphological changes  <cit> . such shape changes have mainly been analyzed by visual inspection, which limits the analysis to only part of the embryonic development  <cit> . given that automated cell tracking enables a wide variety of systematic analyses, its application to cell shape dynamics would provide us with unprecedented knowledge.

in cell tracking analysis, fluorescently labeled cell nuclei are segmented by image processing and are temporally associated  <cit> . the cell shape dynamics can be captured by a nearly identical procedure, which labels the cell membranes rather than the nuclei. however, membrane segmentation is more difficult than nuclear segmentation, not only because the segmentation itself is more complex, but also because a high segmentation quality is required.

whereas cell nuclei are thick, well-separated spherical structures, cell membranes are thin planar shapes that contact each other, forming complicated networks. the segmentation is especially difficult for membranes that are parallel to the focal planes. in conventional confocal microscopy, the effective sampling resolution depends on the point spread function, which is worse in the axial  direction than in the planer  direction. therefore, membranes parallel to the focal planes are sometimes imaged discontinuously. additionally, unlike nuclei , spherical cells can become squashed or expand lamellipodia and filopodia. these dynamics are difficult to segment using a shape model.

the primary objective of nuclear segmentation is to quantify the cell positions, so the segmentation quality is less important for nuclear shapes than for cell shapes. in membrane segmentation, the analysis must quantify the cell shape features, so the segmentation quality is critical.

high segmentation quality is not easily maintained, because the image quality  is degraded at deeper focal planes by light scattering, absorption, and aberration  <cit> , and at later time points by photo-bleaching  <cit> . as the fluorescence distribution in cell nuclei approximates a gaussian distribution  <cit> , a nucleus can be localized by detecting the locally bright centric region. however, when extracting cell shape features, the dimmer regions must be detected as well, which is very challenging.

seeding the membrane segmentation with nuclei has successfully supported membrane segmentation , but is insufficient for accurate segmentation. therefore, researchers have adopted additional sophisticated image processing techniques.

in the first step of sophisticated image processing, the membrane signals are enhanced by combining multiple filters. the filter sets include gaussian or median filters and hessian-based membrane enhancement filters  <cit> , rank filters and difference of gaussian filters  <cit> , anisotropic filters and histogram equalization, and geodesic curvature filters and edge detectors  <cit> . once the membrane signals are enhanced, the discontinuous or gap regions are filled by iterative morphological closing  <cit>  or tensor voting  <cit> . alternatively, a segmentation that is robust to gaps, such as active mesh framework  <cit>  or viscous watershed  <cit> , is applied.

in all approaches, the parameters must be adequately set to achieve sufficient performance. the parameters include the window size and sigma in filtering, the size of the morphological operations, the noise and watershed levels, the weights of the energy terms, the iteration number, and objective sizes such as cell diameter. because each parameter must be optimally valued within a certain range, the number of parameter sets that must be tested increases in a combinatorial manner.

in the parameter adjustment process, the segmentation results must be evaluated in comparisons with the original membrane images. this evaluation is especially difficult for images in deeper focal planes, where the membrane signals are ambiguous. because we must assume the cell shapes from upper focal planes, the evaluation in these deep planes is confounding and, of course, subjective. additionally, a parameter set that properly segments the upper focal planes often fails in deeper planes, and vice versa. the same is true for images between early and late time points. thus, we must seek a parameter set that performs accurate segmentation through all focal planes and time points, which is complicated and requires visual inspection.

when developing a new segmentation method or applying an existing method to a new problem, the parameter adjustments and segmentation assessments are iterated until the accuracy of the segmentation reaches the required level. as the number of parameter sets is enormous, and evaluating the segmentation results is complicated and reliant on human imagination, this iterative evaluation process is subjective, laborious and time-consuming.

in this study, we developed a new framework for cell shape extraction in c. elegans embryos, which automates both the segmentation and evaluation processes. because it optimizes an objective function under biological knowledge-based constraints, our framework is named bcoms . the performance of bcoms is demonstrated in comparisons with cell shapes in a c. elegans embryo.

RESULTS
design
when segmenting cell membranes by a newly developed or existing method, we must adjust all parameters in the method for an accurate segmentation. typical approaches iterate the following three steps: perform segmentation with a parameter set, evaluate the segmentation result, and adjust the parameter set. the iterations terminate when an accurate segmentation is computed . the main concept of the bcoms framework is automation of this process . the segmentations in bcoms are exhaustively performed over the whole parameter space and the optimal segmentation is selected by an automated evaluation method. the evaluation method is formulated as a constrained optimization problem:  <dig> maximizefx,x=x1x2⋯xl 
  <dig> subjecttogx=ce 
  <dig> hx=>cu 
fig.  <dig> comparison of typical and bcoms approaches. schematic comparison of membrane segmentation processes in typical  and bcoms  approaches. a typical approaches iterate segmentation of an input image with a parameter set, evaluation of the segmentation result, and adjustment of the parameter set until the segmentation is sufficiently accurate. b in bcoms approach, segmentations are computed with all parameter sets and the optimal segmentation is selected by an evaluation function. the icons indicate the processed images and segmentation results, which are 3d time-lapse data




where f is the objective function to be maximized in the optimization problem. the vector x is the set of all parameter values included in the segmentation method, and l is the number of parameters in the method. g and h are given functions that satisfy the equality and inequality constraints  and 3), respectively). these functions ensure that the optimization problem is solved under biologically acceptable conditions. therefore, the goal of this optimization problem is to find a set of parameter values x
o that maximize the objective function f under the equality and inequality constraints. the final segmentation result is the segmentation result calculated with the parameter set x
o. the functions f, g and h are differently determined in each segmentation problem.

the bcoms realized the concept by a two-step segmentation framework; embryonic region segmentation using a level set method  <cit> , and cell membrane segmentation using a segmented nuclei-seeded watershed . by segmenting the cell membrane, cellular regions are also simultaneously segmented. the nuclei-seeds can be prepared by two-color imaging, the cell membrane and cell nucleus are recorded in separate channels sequentially, and then segmenting the cell nuclear regions. the cell nucleus images are only used for giving the seeds.fig.  <dig> schematic of the bcoms framework. schematic representation of embryonic region segmentation  and cell membrane segmentation  processes. in the two-step segmentation process of the cell membrane, the optimal segmentations are selected by solving optimization problems under defined constraints. the icons indicate the processed images and segmentation results, which are 3d time-lapse data. names and variables of the icons  and s
memb
) are defined in the main text




in the embryonic region segmentation process , the segmentation results computed over the whole parameter space are evaluated by the following evaluation function:  <dig> maximize∑pip∗spedgey∑pspedgey,y=y <dig> y2⋯,ym 
  <dig> subjectto∑pspnuc∗spemb∼y= <dig> 



  <dig> vminyvmaxy=> <dig>  


eq.  maximizes the objective functions, and eqs.  and  define the equality and inequality constraints, respectively. the vector y is a set of all parameter values included in the embryonic region segmentation method, and m is the number of parameters in the method . s
emb is the segmented embryonic region calculated with the parameter set y. s
edge is created by extracting an edge on each focal plane of the segmented embryonic region s
emb. s
p
edge. is the binary value of pixel p in s
edge. i
p is the intensity value of pixel p in membrane image i. the * operator denotes multiplication, namely, each pixel intensity value in the membrane image i is multiplied by the corresponding pixel’s binary value in s
edge. Σp denotes summation over the pixel indices p. note that all images and segmentation results are 4d  data. therefore, the objective function measures the average intensity value of the pixels that are segmented as the embryonic edge in the membrane image. s
p
emb and s
p
nuc denote the binary values of pixel p in the segmented embryonic region s
emb and in the seed nuclei image, respectively. the seed nuclei image contains the segmented nuclear regions created by a previously developed image processing method . the ~ operator represents inversion of a binary image. therefore, the equality constraint  ensures that all nuclei are enclosed in the segmented embryonic region. v
min and v
max are the minimum and maximum volumes of the segmented embryos calculated with the parameter set y, respectively. the volume is calculated by counting the pixels contained in each segmented embryonic region at each time point. the inequality constraint  ensures that the embryo maintains a near-stable volume throughout its development, as observed in our experiments. the inequality constraint excludes segmentations in which the later-stage embryonic regions are shrunken. shrinking in later-stage embryos occurs by photo-bleaching, which degrades the image quality. to cancel this effect, our method adjusts the contraction bias by changing the weight parameters in the level set method according to the image brightness . the inequality constraint ensures the correct performance of this adjustment.

the value of the objective function is maximized when the edge of the segmented embryonic regions locates on the outermost membranes , and decreases when the edge locates inside these membranes . when the edge locates along the inner membranes , the objective value may again increase but these segmentations are rejected by the equality constraint  that forces the embryonic regions to enclose all seed nuclei.fig.  <dig> the objective function is maximized when the segmented membranes are just on the membranes. embryonic region segmentations of a membrane image computed with different parameter sets. red lines indicate the edges of the segmentation results. the value of the objective function is maximized when the edge locates just on the outermost membrane , and reduces when the edge locates inside this membrane . the value may again increase when the edge locates on the inner membranes . however this result is rejected because it violates the equality constraint  that forces the embryonic regions to enclose all seed nuclei




in the cell membrane segmentation process , the segmentation results computed over the whole parameter space are evaluated by the following evaluation function:  <dig> maximize∑pip∗spmembz∑pspmembz,z=z <dig> z2⋯,zn 


where the vector z is the set of all parameter values included in the cell membrane segmentation method and n is the number of parameters in the method . s
p
emb is the binary value of pixel p in the segmented cell membranes calculated with the parameter set z. no explicit constraints are given for the evaluation function . however, the watershed segmentation in the cell segmentation method is seeded with nuclei , and each seed nucleus is enclosed by its self-formed region. by ensuring that each nuclear region is enclosed in its own cellular region, this method imposes an implicit biological constraint corresponding to eq.  in the evaluation of embryonic region segmentation. an inequality constraint corresponding to eq.  is not imposed, because the cell size may change.

comparison with ground truth
to extract the cell shape dynamics, we recorded the embryonic development of c. elegans in the two- to 54-cell stages by 3d time-lapse imaging. for membrane segmentation by the bcoms framework, we labeled the cell nucleus and cell membrane of the embryo as mcherry and gfp, respectively. applying bcoms to the image data, we acquired the segmentation results . the cell shapes were accurately segmented across all focal planes throughout the developmental period, including the deep focal planes  where the image quality was reduced, and at later developmental stages. the segmentation results revealed a variety of cell shapes, from spherical to squashed.fig.  <dig> accurate segmentations across focal planes and time points

shown are the membrane images and segmentation results computed by bcoms at representative developmental stages and focal  planes. the bottom and top focal planes are denoted as z =  <dig> and z =  <dig>  respectively. the top panels are the 3d volume renderings of the membrane images and segmentation results. cellular regions are rendered in different colors and the segmented membranes and background are rendered in black




as bcoms was developed for automated extraction of the cell shape dynamics from the segmentation results, we must evaluate the accuracy of the extracted cell shapes. for this purpose, we created a ground truth of the 24-cell stage embryo by manual segmentation. this stage was selected because the cells contact each other in all three dimensions, and are sufficiently large to evaluate their shape features. gastrulation in c. elegans is initiated around the 26-cell stage, so accurate segmentation of the embryo at this stage is essential for analyzing the cell shape dynamics during morphogenesis.

to quantitatively measure the cell shapes, we selected  <dig> cell shape features that are widely used in the image processing field. these features include volume, perimeter length, centroid location, cell length, surface area, convexity and sphericity. we computed the shape features of every cell in both the bcoms result and the ground truth, then calculated their deviations by subtracting the feature values of the segmentation result from those of the ground truth, and dividing the absolute values of the results by the ground truth values. the average deviation among all features was  <dig> % ±  <dig> % .table  <dig> deviations between bcoms and ground truth for  <dig> representative cell shape features




currently, no method can automate the extraction of cell shapes in c. elegans embryos. therefore, we compared our result with the cell shapes of drosophila and mouse embryos extracted by race software  <cit> . stegmaier et al.  <cit>  calculated the deviations of  <dig> cell shape features and averaged them over both organisms, obtaining  <dig> % ±  <dig> %. as the  <dig> features used in our comparison include all  <dig> of their features, we recalculated the average deviation of  <dig> shape features previously calculated by bcoms, and obtained  <dig> % ±  <dig> %. although the evaluated organisms are different, this comparison confirms that our segmentation result is sufficiently accurate to analyze cell shape features.

analysis of deviation
the deviations are expected to be larger in the z direction  than in the x–y direction. to confirm this expectation, we compared the deviations of the cell lengths in the x, y and z directions. indeed, the deviation was larger along the z axis  than along the planar directions . likewise, the perimeter lengths deviated more on the yz and zx planes  than on the xy planes . these results support the larger deviation in the z direction than in the x–y direction.

to further analyze the cause of the deviation, we measured the distance of each pixel in each cell of the automated segmentation result from the nearest pixel in the corresponding cell of the ground truth . in most of the cells, the edges differed by approximately one pixel from the ground truth. as the drawn line cannot pass through the exact center of the membrane, some deviation is inevitable. moreover, the computationally segmented membranes are one pixel thick and are three-dimensionally connected . on the other hand, manual segmentation cannot be drawn to pixel-level accuracy. considering these difficulties, deviations of a few pixels are acceptable.fig.  <dig> differences between automated segmentations and ground truth caused by membranes parallel to the focal planes.  original image, bcoms, ground truth, and pixel-level difference in the 24-cell stage embryo. 3d view images  and 2d view images . the cellular regions in the bcoms segmentations and the ground truth are represented by different colors. for each pixel in each cell of the automated segmentation result, the pixel level difference was measured as the distance from the nearest pixel in the corresponding cell of the ground truth, and is displayed in pseudo color. the differences increase at the contacting surfaces of adjacent cells , and at bare surfaces that do not contact with other cells 




the differences were larger in some locations. representative focal planes with deviations exceeding two pixels are shown in fig.  <dig>  b and c. regions of large difference include the contacting surfaces of adjacent cells  or bare surfaces that do not contact with other cells . in both scenarios, the surfaces were parallel to the focal planes. in the contacting surfaces of adjacent cells , membrane signals were difficult to distinguish from noise even by manual inspection. these membranes are diagonal in the focal planes. therefore, to accurately connect them between adjacent focal planes, we must imagine their three-dimensional shapes. manual segmentation of these membranes is inherently less accurate than segmentation of membranes perpendicular to the focal planes. in addition, during watershed segmentation, a region of a cell might extend beyond the separating membrane with insufficient fluorescence signals. on the other hand, in bare surfaces that do not contact with other cells , the automated segmentation extracted the outer  bare surfaces instead of the correct bare surfaces. parameter sets that do not extract the dimmer bare surfaces cannot avoid the incursion of extracted bare surfaces inside the true embryonic region during the level set segmentation. segmentations using these parameter sets were generated in the segmentation process but rejected by the constraints, which force the embryonic region to enclose all of the segmented nuclei. however, extraction of the dimmer bare surfaces is not necessarily inaccurate because these surfaces are brighter than the background. we conclude that the deviations between the bcoms segmentations and the ground truth arise from extremely ambiguous membranes.

comparison between adjacent time points
as only a limited number of ground truths can be created by manual effort, we compared the segmentation results between two adjacent time points. although the cell shapes may change throughout the cell cycle, they should be almost stable between two adjacent time points, because the time interval of our imaging is 15 s . we computed the shape features throughout the development of each cell, then calculated their deviations between two adjacent time points. the deviation was calculated by subtracting the feature values at the previous time-point from those at the later time point, and dividing the absolute values of the results by the feature values at the previous time point. across all cell cycles and all cells, the average deviation among all features was  <dig> % ±  <dig> % . the average deviation was smaller than that between the automated segmentation result and the ground truth. this result suggests that bcoms successfully segments the membrane throughout the early embryonic development of c. elegans.table  <dig> deviations between two adjacent time points for  <dig> representative cell shape features




discussion
bcoms framework
our new framework bcoms was developed for automated cell shape extraction in c. elegans embryos. bcoms automates not only the segmentation process but also the evaluation process. the evaluation was automated by solving an optimization problem under biological constraints. to apply bcoms, we must adjust the parameters to fit the biological constraints, rather than adjust the image processing parameters. this replacement of the parameter fitting provides obvious benefits to both users and developers, and can be regarded as the major contribution of bcoms.

benefit to users
when solving new problems by existing segmentation methods, we must adjust the image processing parameters . such adjustment requires understanding of what is controlled by each parameter. therefore, users need at least a basic knowledge of the underlying algorithm. to users unfamiliar with image processing, such as experimental biologists, gaining this understanding is non-trivial. bcoms replaces the image processing parameters with biological constraints. in the present study, the constraints enclose the nuclei within the embryonic or cellular regions, and limit the volume change of the embryo or each cell to a certain range. the former constraint is parameter-free, and the parameter of the latter is easily understood by biologists. therefore, this replacement converts the complicated image processing method to a more user-friendly framework.

benefit to developers
although bcoms was developed for cell membrane segmentation in c. elegans, this framework is applicable to membrane segmentation in other organisms. to this end, both the segmentation and evaluation processes can be customized. to customize the segmentation process, we can simply replace the segmentation method. for instance, our novel segmentation method can be replaced by an existing method. in the evaluation process, the objective function measures the consistency between the membrane image and segmentation results, and is applicable to membrane segmentation in other organisms. however, the biological constraints may need to be tailored to different organisms. for example, the constraint of embryonic size stability is not suitable for mouse embryos, because mouse embryos grow as their development proceeds. in such cases, the constraints must be newly constructed. if the constraints are too strict, no segmentations are generated. conversely, if the constraints are too loose, biologically unacceptable segmentations are selected. as the number of constraints is unlimited, the segmentation should incorporate as many constraints as possible. these constraints can be constructed by users with no knowledge of image processing, but must be based on biological knowledge of the target organism. this will present no problem to researchers familiar with the target organism. to fully exploit the advantages of bcoms, experimentalists should collaborate with software developers.

performance of bcoms
the performance of bcoms was validated by comparisons with the ground truth and by comparing the results at two adjacent time points. after analyzing the pixel-level deviation of the automated segmentation result from the ground truth in each cellular region, we found that the deviations increased on membranes parallel to the focal planes. in fact, these membranes were difficult to segregate even by manual methods. therefore, even the ground truth is not necessarily accurate. comparing the two segmentations, many of these difficult-to-separate membranes were more accurately segmented by bcoms than by the manual method. therefore, the accuracy of the automated segmentation is equivalent to that of manual analysis.

additionally, the automated segmentation faithfully follows the segmentation “rule” that every cell is necessarily separated by membranes, and that the membranes are three-dimensionally connected into a 26-connected neighborhood. in contrast, adjacent cells in manual segmentation may be directly contacted with no intervening membranes. the faithful segmentation by the automated method is especially important in systematic large-scale analyses, where stereotypical data are desired.

future work
here, the optimization problem was solved by exhaustive searching. although the search was completed in reasonable computational time, the computational efficiency would be improved by applying a more sophisticated optimization method. in future work, we will explore various optimization methods, and identify the most suitable methods for our problem. to this end, we will clarify how each parameter relates to the objective function and the biological constraints. a more sophisticated computation will reduce the human labor and time consumption of bcoms applications, achieving an efficient developmental environment and a user-friendly analysis framework.

CONCLUSIONS
we developed a new framework bcoms which automated extraction of cell shapes in developing c. elegans embryos. the accuracy of bcoms was validated by comparisons with the ground truth and by comparing the results at two adjacent time points. by replacing image processing parameters with easily adjustable biological constraints, bcoms provides a user-friendly framework. the framework is also applicable to other model organisms by customizing the biological constraints. this customization is a critical step requiring collaboration between an experimentalist and a software developer.

