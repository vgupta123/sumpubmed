BACKGROUND
during the past ten years there has been significant progress in the development of computational tools for the detection of co-evolution between pairs of positions in a protein family by analysis of its msa . if the msa of a protein family contains a sufficiently large number of sequences, information about the proximities between residues derived from the covariation map can be used to predict the protein fold. however, in many cases the structure of one or more members of a protein family is already known, and interest in identifying covarying positions lies instead in the information that this knowledge can provide about the protein mechanism and dynamic properties, or in its use as a starting point for mutagenesis studies.

unfortunately, the reliability of covariation data can be diminished by the existence of correlations originating not just from the direct interactions  between two residues, but also from their shared interaction with one or more other residues, and by the shared phylogenetic history of several homologous proteins in the msa. attempts to disentangle direct from indirect and phylogenetic correlations were made with the mip/apc  <cit> , zres  <cit>  and zpx  <cit>  corrections of mi statistics, with the application of bayesian modeling in the logr method  <cit> , with direct coupling analysis   <cit> , a maximum entropy method, with the use of sparse inverse covariance estimation in the psicov method  <cit> , and most recently using a pseudolikelyhood framework  <cit> , or combining principal component analysis  with dca  <cit> . while the performance of these methods has been tested primarily with high quality msas containing a very large number of sequences , very often investigators are interested in studying the covarying positions of proteins for which the available msa contains less than l sequences, and whose alignment quality is not optimal due to the presence of many  gaps, or significant sequence heterogeneity in the protein family. in these cases, it is difficult to argue that a single best method exists, since different algorithms may be more  effective in capturing the covariation signal from msas with widely different statistical properties, and a better strategy may rely on merging the information derived from a few methods based on different principles. in order to expand the choice of algorithms available for covariation analysis, here we present a new class of methods, based on multidimensional mutual information , specifically designed to remove indirect coupling up to ternary/quaternary interdependencies. these new methods were tested on a set of  <dig> protein families each represented by a msa containing between ~ <dig>  and ~ <dig> l sequences.

RESULTS
derivation of 3d and 4d mi covariation matrices
in most traditional applications mutual information is used to study the interaction between two variables. if we consider a channel with a single discrete input x <dig> and a single discrete output x <dig>  the amount of transmission between x <dig> and x <dig> is defined as their ‘mutual information’ i:

  ix1;x2=hx1+hx2−hx <dig> x <dig> 

where the h’s represent the individual  and joint  entropies. for our application, x <dig> and x <dig> represent columns in the msa. we can consider a more complicated case including a third channel . in this case, i between the three variables represents the ‘interaction information’ for a channel with two discrete inputs x <dig> and x <dig> and a single discrete output x <dig> . it is defined  <cit>  as:

  ix1;x2;x3=hx1+hx2+hx3−hx <dig> x2−hx <dig> x3−hx <dig> x3+hx <dig> x <dig> x <dig> 

the mutual information i is provided by the terms in bold font in . the following considerations help understand the nature of the remaining terms. if we are interested in ‘explaining out’ the effect of x <dig> on the transmission between x <dig> and x <dig>  we can take a sum of the mutual information i for each possible value x <dig> of x <dig>  weighted by the probability of occurrence  of each of those values:

 ix3x1;x2=∑px3ix1;x2|x3=x3=ix1;x2|x3=ix <dig> x3;x2−ix3;x <dig> 

where i is the mi between the joint variable  and x <dig>  developing further we have:

  ==hx <dig> x3−hx <dig> x <dig> x2−hx3+hx <dig> x <dig> 

the right-hand side of  can be recognized as the negative of the terms in regular  font in . from this observation and rearranging, we obtain that the mutual information ix <dig> between x <dig> and x <dig>  when the effect of x <dig> on the transmission between them has been eliminated, can be obtained by subtracting the interaction information i from the mutual information i:

  ix3x1;x2=ix1;x2−ix1;x2;x <dig> 

averaging over all values of x <dig>  in an msa we obtain for the 3-dimensional mi between any two columns :

  <ix3x1;x2>x3≠x <dig> x2=ix1;x2−<ix1;x2;x3>x3≠x <dig> x2=<hx <dig> x3−hx <dig> x <dig> x2−hx3+hx <dig> x2>x3≠x <dig> x <dig> 

we notice here that  is calculated independently for every possible pair x <dig> x <dig> with respect to each column x3 ≠ x <dig> x <dig> in the alignment. then the values of  obtained for each pair x <dig> x <dig> with all columns x3 ≠ x <dig> x <dig> are averaged. since the effects of all 3rd residues are averaged, 3-dimensional mi provides a global removal of all indirect couplings exerted on a pair by any other individual residue in the sequence .

likewise, the mutual information ix <dig> x <dig> between x <dig> and x <dig>  when the effect of two additional variables x <dig> and x <dig> on the transmission between them is removed, is obtained  <cit>  as:

  ix <dig> x4x1;x2=∑px <dig> x4ix1;x2|x3=x <dig> x4=x4=ix1;x2|x <dig> x <dig> 

by the ‘chain property’ of multivariate mi  <cit>  we derive:

  ix1;x2|x <dig> x4=ix1;x2|x4−ix1;x2;x3|x4=ix <dig> x2−ix1;x2;x4−ix1;x2;x3+ix1;x2;x3;x <dig> 

where the ‘interaction information’ between the four variables is:

  ix1;x3;x2;x4=−+−hx <dig> x <dig> x <dig> x <dig> 

averaging over all values of x <dig> and x <dig> , and recalling that all the values taken by x <dig> and x <dig> are the same with respect to x <dig> and x <dig> in a msa , we finally obtain:

  <ix <dig> x4x1;x2>x <dig> x4≠x <dig> x2=ix1;x2−2<ix1;x2;x3>x3≠x <dig> x2+<ix1;x2;x3;x4>x <dig> x4≠x <dig> x <dig> 

expanding  leads to a direct expression of ix <dig> x <dig> in terms of the entropies of the individual variables and simplifies to :

  ix <dig> x4x1;x2=−hx <dig> x4+hx <dig> x <dig> x4+hx <dig> x <dig> x4−hx <dig> x <dig> x <dig> x <dig> 

averaging over x <dig> and x4:

  <ix <dig> x4x1;x2>x <dig> x4≠x <dig> x2=<−hx <dig> x4+hx <dig> x <dig> x4+hx <dig> x <dig> x4−hx <dig> x <dig> x <dig> x4>x <dig> x4≠x <dig> x <dig> 

we notice here that  is calculated independently for every possible pair x <dig> x <dig> with respect to each column x3 ≠ x <dig> x <dig> and for each value of x <dig> with respect to each column x4 ≠ x <dig> in the alignment. first the values of  obtained for a given pair x <dig> x <dig> with a given column x3 ≠ x <dig> x <dig> for all possible columns x4 ≠ x <dig> are averaged. then, the values of  obtained for the same pair x <dig> x <dig> with all possible x3 ≠ x <dig> x <dig> are averaged. since the effect of any 3rd and 4th residues are averaged, 4-dimensional mi provides a global removal of all indirect couplings exerted on a pair by any two other residues in the sequence .

both  and  can be computed from the marginal frequencies of the aa symbols in any  <dig> or  <dig> columns of a msa.

we have implemented equations  as a matlab function  included in the new release of our toolbox  for the covariation analysis of msas. upon derivation of the < ix3 > and < ix <dig> x4 > values, the covariation matrices are further processed as described in our earlier work  <cit>  to derive the corresponding zpx <dig> matrices  <cit> . the final matrices are named ’3d_mi’ and ‘4d_mi’ . the same function provides also a standard mi map, which for consistency is called here ‘2d_mi’.

in its current parallel version 3d_mi runs on a single cpu in ~3 min with a msa of  <dig> positions and  <dig> sequences, and its speed increases almost linearly with the recruitment of more cpu’s. as expected 4d_zpx <dig> is significantly slower and with large memory requirements. despite this limitation, 4d_mi can be very useful to analyze in great detail small parts of a large msa. however, in the following section we show that the simpler and faster 3d_mi is already very effective in calculating the direct coupling between the positions of a msa.

prediction of close contacts in x-ray crystal structures
we have evaluated the performance of standard mi , 3d_mi, 4d_mi, psicov  <cit> , plmdca  <cit> , gremlin  <cit> , and hopfield-potts_dca with principal component analysis  <cit>  with the msas of  <dig> protein families, which we have used as test sets in our recent survey of covariation detection methods  <cit> . these msas contain less than  <dig> sequences with ratios of sequence number to sequence length  between  <dig>  and  <dig> , and thus represent a particularly sensitive test for the performance of the different methods with less than optimal size msas. it is worth noting that psicov, plmdca, gremlin, and hppca apply by default the ‘average product correction’  that was originally introduced by gloor  <cit>  as a correction for the entropic and phylogenetic bias of mi statistics. later on, independently, little  <cit>  and gloor  <cit>  introduced a second correction called respectively zres or zpx, to be applied after the apc correction, and dickson  <cit>  showed that this second correction further improves the accuracy of covariation detection particularly in msas containing some degree of misalignment. for this reason, an apc correction  and a zpx correction were applied to all covariation maps derived in this study with different methods. we found that the maps so corrected, performed uniformly better than the uncorrected maps in the detection of close contacts. although each msa contained less than  <dig> sequences, all the methods tested produced covariation maps that closely resembled the contact maps derived from the representative x-ray structures of each family: and example of these maps is shown in figure  <dig> for the mdh family, which contains  <dig> sequences with an l ratio slightly larger than  <dig> 

to quantify the detection of close contacts, we measured what percentage of all residue pairs separated by less than 8 Å in the x-ray structure was represented in the top covarying pairs identified by each method. a number of pairs equal to the number of residues l in each sequence was considered. this result was further filtered to include either all the pairs or only pairs whose component residues are separated by at least  <dig>   <dig>   <dig> positions in sequence space. results obtained with all  <dig> msas for all pairs and for pairs separated by at least  <dig> positions in sequence are shown in figure  <dig> . when all possible pairs are considered , plmdca identifies a higher percentage of pairs separated by < 8 Å in almost all the msas. however, a significant variability in performance between the different methods becomes apparent when only pairs separated by at least  <dig> positions in sequence  are considered. for example, in the arsa family plmdca clearly includes the highest percentage  of proximal pairs  in the top  <dig> covariation scores : however only  <dig> out of these  <dig> pairs are in the subset of pairs that are distant in sequence, and these  <dig> represent only < <dig> % of all pairs close in space . conversely, gremlin includes a smaller number  of proximal pairs in the top  <dig> covariation scores, but  <dig> of them are in the subset of pairs that are distant in sequence, and they represent almost 1% of all pairs close in space. these results indicate that the better overall performance of plmdca with arsa  is due to the fact that a very large number of pairs close in sequence is represented in the top  <dig> covariation scores. extending this type of analysis to all  <dig> protein families, it becomes clear that if we were primarily interested in the pairs that are distant in sequence but close in space, we would perhaps achieve the highest accuracy using gremlin with arsa, arsc, and mdh, but 4d_mi would be the method of choice with atp11p, phbh, and ccra, while either gremlin, plmdca, and hppca would work best for atp12p.

however, even for cases in which several methods give comparable results in the type of analysis shown in figure  <dig>  we may wonder whether the pairs identified by any two of these methods are the same or not. in table  <dig> the average percentage  of pairs shared by all methods in the top l covariation scores is shown as a matrix, with values above the diagonal referring to all possible pairs, and values below the diagonal referring to pairs separated by at least  <dig> positions in sequence. this matrix shows that a significant number of pairs are shared among methods that are conceptually similar . however, the percentage of pairs shared by methods that are conceptually different is much smaller: for example 3d_mi and plmdca share less than 40% of all pairs, and even plmdca and gremlin, which operate within a similar pseudolikelyhood framework, share at most 64% of all pairs.
l 
covariation scores: average of  <dig> protein families

values above the diagonal. all protein pairs. values below the diagonal. only pairs whose residues are separated by at least  <dig> intervening positions in sequence space.

thus, even from just this set of only  <dig> protein families, it appears that a single method that would give the best result with all protein families is hard to find, as each algorithm performs quite differently with different msas, and even algorithms whose overall performance is similar on a statistical basis, share no more than 2/ <dig> of all the pairs among the top l covariation scores, if they are based on different principles.

dependence of the covariation signal on secondary structure
if there are significant differences in the performance of each method with different msas, it is important to understand the origin of such differences, and how they affect the structural information derived from covariation maps. for example, since each protein family is characterized by a variable mixture of secondary structures , we have analyzed the dependence of the covariation signal detected by each method on the type of secondary structure  in which covarying pairs are located . non-independent selection of neighboring residues is a phenomenon known to occur in helices and strands, and thus the features of these secondary structures provide a rich framework to study residue coupling. with the set of  <dig> protein families, all methods produce noticeable peaks or shoulders at periods corresponding to up to  <dig> helix turns, and at periods of  <dig>   <dig>  and  <dig> residues in strands, corresponding to side-by-side residues pointing in the same direction . however each method has its own pattern with stronger covariation scores assigned on average on one or another of these periods. thus, the wide performance range of each method with different msas results in contact predictions that may reflect more or less well the secondary structure features of each protein family.

network connectivity
an important aspect of recent improvements in the accuracy of covariation detection methods is the separation of the direct coupling between two residues from the indirect coupling. given residues a,b,c, when pair ab and pair bc are among the top pairs and represent true structural contacts based on protein geometry, we may find pair ac as highly covarying  as an induced coupling produced by pairs ab and bc. this kind of induced coupling can extend along chains of contacts: for example if a contacts b, b contacts c, c contacts d, …n- <dig> contacts n, covariation maps may show some level of covariation between a and n. this type of covariation is not necessarily a statistical artifact. in fact since proteins are very tightly packed a mutation that produces a change in volume in some part of the structure, can be compensated by small changes of volume along chains of residues contacting each other. a similar effect can be observed for a mutation that produces a change of charge, polarity, or hydrogen bond patterns. the very existence of this type of chaining effects as a real physical phenomenon occurring inside proteins is proven by the dependence of the covariation signal on secondary structure, which was analyzed in the previous section. true chain-dependent coupling between residues should be distinguished from the statistical correlation that may occurr between residue a and residue b because of their physical correlation to a third residue c despite the lack of any physical correlation between a and b.

we have used tools from graph theory as applied to the analysis of networks to explore further the influence of chaining effects on the covariation scores of pairs that are not in direct physical contact. we recall here that a covariation map is a weigthed adjacency matrix of the graph representing the network of interactions between residues in a protein. for each pair a,b in the covariation map, within a given threshold of top covariation scores, we ask the question: is there a physical path that connects a to b through residues that belong to high scoring pairs? if there is such a path  we want to know what is the total length of the shortest path  and what is the mean length of the steps that lead from a to b. in practice this question is answered by selecting a group of pairs based on a score threshold from the covariation map of a protein family, and solving the ‘traveling salesman’ problem for the corresponding pairs in the distance map of a reference x-ray structure. for example, if the shortest non-direct path 20-91-123-203- <dig> is found in the x-ray structure between the components of the high scoring pair 20– <dig>  it means that pairs 20– <dig>  91– <dig>  123– <dig>  and 203– <dig> are present among the pairs selected within a given number of top covariation scores. an example of this type of analysis is presented in figure 4a for the mdh protein family using covariation maps derived with different methods. the top right panel shows the mean length of the path connecting the pairs within scoring threshold: the threshold is progressively lowered to include a larger number of pairs up to 3 l. as more pairs are included in the analysis the probability of finding a shorter path increases and all traces converge to a smaller path length. the top left panel shows the mean length of the steps in each path. clearly, smaller steps favor the transfer of physical perturbations  along a chain of contacts. it is significant that the ranking of different methods in this panel, based on the length of the steps , corresponds quite well to their capacity to recognize close contacts in the reference x-ray structure of the mdh family as shown in figure  <dig>  this correlation was found to hold true also for the other msas analyzed, and suggests that chaining effects actually favor, rather than confound, the recognition of close contacts by covariation methods. further support for this conclusion is provided in the lower left panel of figure 4a, which shows the correlation between the covariation score of pairs and the mean step length of the path that connect the two members of each pairs through residues that belong to other pairs. with the exception of a few points representing the very top scoring pairs , most points of the best performing methods  sit in a range of negative correlation, indicating that the covariation score is higher when the mean step length  is smaller.

an average of the results obtained with the path length connectivity analysis for all  <dig> protein families is shown in . also in this case, the ranking of different methods based on the mean step length of the connectivity paths  corresponds reasonably well to the average performance of the methods in predicting close contacts .

in a different type of analysis, we used the concept of graph transitivity to investigate how the covariation scores produced by different methods are affected by the statistical correlation that may occur between residue a and residue b because of their physical correlation to a third residue c despite the lack of any physical correlation between a and b. at each given threshold of covariation scores, transitivity, tr, measures the number of “completed triads” relative to the number of “potential triads”, and ranges from  <dig> to  <dig> . protein covariation graphs were manipulated for the set of  <dig> proteins either by changing the covariation stringency  or by changing the minimum sequence distance of residue pairs at constant graph size . transitivity was then calculated for each covariation graph.

an example of this analysis for the mdh protein family is shown in figure 4b. as the graph size is increased by lowering the score threshold at a constant sequence distance of  <dig>  transitivity values decrease for plmdca, hppca, gremlin and psicov, while they increase for the three mi/mdmi based methods  . for all methods transitivity values reach a plateau when the network reaches size ≈ l . as the minimum sequence distance is increased at constant network size = l , all methods show a trend of decreasing transitivity, with the decrement rate being maximal within the first few positions for most methods. in both types of analysis there is a clear separation of the different methods in two groups with psicov, plmdca, gremlin and hppca showing significantly lower values of transitivity than the mi/mdmi based methods. the transitivity trends shown in figure 4b are consistent with the path connectivity analysis shown in figure 4a: top scoring pairs identified by mi/mdmi methods are connected on average by shorter indirect paths involving other residues, but the steps of these paths are longer  leading to a higher number of completed triads . at the same time if, for example, a is connected to b and b is connected to c, the increased step length decreases the probability of a real physical perturbation propagating from a to c through b. in this case increased transitivity can be rationalyzed as evidence of a statistical correlation between a and c without physical interaction. however, high transitivity appears to have little effect on the identification of close contacts among residues separated by >  <dig> positions in sequence, as the performance of 3d_mi and 4d_mi in this respect approaches that of plmdca or gremlin .

CONCLUSIONS
in this study we have introduced a new class of methods to detect covariation from experimental msas, based on multidimensional mutual information . simple algebraic relationships  for the removal of 3rd and 4th order indirect coupling between the columns of a msa were derived and implemented as matlab functions. due to the long execution times and large memory requirements  of 4d_mi only the removal of 3rd order indirect coupling  is practical with desktop computers for msas of sequences longer than  <dig> residues. the performance of 3d_mi and 4d_mi vis-a-vis that of standard mi , psicov, plmdca, gremlin and hppca was tested with the msas of  <dig> protein families; although each msa contained less than  <dig> sequences, all the methods produced covariation maps that closely resembled the contact maps derived from the representative x-ray structures of each family . while we observed significant variability in the performance of the methods with each msa , on average removal of only 3rd order indirect coupling by 3d_mi was sufficient to replicate the performance of plmdca and gremlin . one merit of 3d_mi is its algebraic simplicity , grounded in the traditional relationships of multivariate information theory  <cit> .

while all the methods used in this study performed quite well in terms of percentage of close contacts recognized among the top covarying pairs, they did not necessarily recognize the same close contacts, as no more than 50% of all the pairs were shared between the mi/mdmi based methods and the other methods . the percentage of pairs shared among the residues separated by at least  <dig> intervening positions in sequence space was even lower . furthermore, while on average all methods produced noticeable peaks or shoulders at periods corresponding to up to  <dig> helix turns, and at periods of  <dig>   <dig>  and  <dig> residues in strands, there were significant differences in the methods capacity to identify distance dependent covariation among residues located in the same secondary structures . these results suggest that if the goal of a covariation analysis is not that of structure prediction, and if one or more representative x-ray structures are available for a given protein family, analyzing both the accuracy of residue-residue contact prediction, and the patterns of distance dependent covariation in secondary structures, may point to the method that offer the best performance with a specific msa. finally, since there is < 65% overlap among the sets of covarying residues identified by algorithms based on different principles, further improvement in accuracy is likely to be obtained by selecting only the shared pairs or by averaging the results from different methods.

in this study we have also attempted to identify whether the difference in performance among covariation detection methods is due to phenomena of network connectivity among the covarying pairs. several reports have stressed the importance of removing covariation due to “chaining” as a means to reduce false positive rates in the prediction of structural contacts  <cit> . this concept has been invoked again most recently in the introduction to the hppca method  <cit> . however, it is not clear that it is really the removal of chaining that produces better covariation maps. for example, in our testing of  <dig> protein families mi/mdmi based methods achieve close contacts recognition comparable to that of plmdca and gremlin  despite showing on average higher values of network transitivity.

some clarity may be offered by considering what is the meaning of the partial correlation between variables  in the context of the information that covariation detection methods are trying to extract from sequence data. in covariation studies, we typically start with some type of covariance matrix, and we try to guess its inverse, from which we can derive the partial correlations. this inverse can be thought as related to the partial derivatives of a hidden optimization process that evolution carries out on a ‘fit function’ , by changing one or more amino acids at a time. from this point of view, the idea that transitivity depends on the existence of ‘chains’ of residues in which correlation is transferred from one residues to the next, so that distant residues appear correlated but in reality are not, loses appeal. the important question becomes instead: is a change in residue a by itself producing a change in the ‘fit function f’  that goes in the same  direction as a change in residue b by itself ? for two positions to appear correlated, it is not necessary to be part of a chain of contacts, as all that matters is their individual effect on the fit function. what is important in these cases of covariation is not the presence of a direct physical interaction, but the fact that residues exposed to like forces , will respond ‘individually’  in a correlated  way to the changes that affect the fit function.

on this basis, it appears that the reason why methods that derive partial correlation between the columns of a msa  provide a better recognition of close contacts is not because they remove chaining effects, but because they filter out the correlation between distant residues that originates from general fitness constraints  <cit>  without the need for physical contacts. in contrast true chaining effects are expression of real physical perturbations that propagate inside proteins, and therefore are not removed by the derivation of partial correlation between variables.

