BACKGROUND
identifying differentially expressed gene transcripts is the most common task in analyzing microarray data. the current state-of-the-art in microarray design and analysis involves identifying differentially expressed genes by assessing the statistical significance of observed ratios in replicated microarray hybridizations with independent samples  <cit> . after performing the initial data processing designed to remove several important sources of variation, the traditional and most commonly used approach is to treat each probe  as an independent experiment. after performing usual statistical analysis such as the t-test or analysis of variance, individual p-values are adjusted for the number of hypotheses performed  <cit> .

considering data for each probe/gene transcript separately when testing for differential expression is statistically inefficient. the estimates of variance are often poor due to small sample sizes. however, additional information may be gained by combining variance estimates across all genes, and methods that exploit this information improve results  <cit> . several of these methods use hierarchical bayesian models or other methods for calculating "moderated" variances for individual genes, weighted averages of the gene-specific sample variances and the pooled estimate of variance calculated from all genes  <cit> . empirical comparisons of such procedures have demonstrated that the gain in statistical power can be substantial  <cit> . others use more heuristic types of arguments to modify artificially small variance estimates that are likely a consequence of random fluctuations in the data  <cit> .

an additional source of information not commonly utilized in the statistical analysis of microarray data is the well documented dependence of gene variances on overall expression level of corresponding genes  <cit> . one notable exception is cyber-t  <cit> , a hierarchical bayesian method in which gene-specific "prior" variances are calculated within a window of genes with similar expression levels. interestingly, cyber-t performed best in the analysis of a "spike-in" affymetrix experiment  <cit> . however, the applicability of cyber-t is somewhat limited in that two important parameters, the window size and the prior degrees of freedom, need to be specified by users, and it supports only t-tests, paired t-tests, and one-way analysis of variance . in contrast to cyber-t, the moderated-t procedure proposed by smyth  <cit>  , and implemented in the ebayes function in the limma package of bioconductor, uses an empirical bayes framework to estimate all parameters from data and it can be used to test any hypothesis within the traditional linear models framework. however, it does not utilize the relationship between variances of expression level measurements and their magnitude.

recently, fox and dimmic proposed an extension of cyber-t, , for two-sample comparisons. like cyber-t, this method assumes a hierarchical bayesian model and uses a moving window average to calculate the prior variances. although they remove some of the ad hoc nature of cyber-t, the window size is still specified by the user, and the prior degrees of freedom are calculated based on the moving window size, by assuming genes with similar expression levels have identical variance. this is an important contrast with smyth's and our method  <cit> . furthermore, fox's method is limited to simple two-sample comparisons and cannot account for the dye-effect in dual-channel microarrays. here we describe and evaluate a new bayes moderated-t statistic which we refer to as ibmt . ibmt is an extension of smt  <cit>  and accounts for the dependence of variance on gene signal intensity. like smt, ibmt can be used with any experimental design, including but not limited to experiments with multiple treatments and/or both technical and biological replicates, experiments with a continuous covariate, and dual-channel experiments with dye-effects. it can also be used with any array platform, for example affymetrix, dual-channel, tiling arrays, etc. similar to smyth, we use empirical bayes  theory to estimate all parameters of the hierarchical bayesian model. we use non-parametric local regression to functionally relate variance and absolute gene expression measurements. this possibility has been previously proposed but has not been further explored  <cit> .

in this paper, we describe the hierarchical model for gene expression data, detail the procedure for estimating all parameters in the model, and describe the testing procedure for identifying differentially expressed genes. in simulations carefully designed to mimic real microarray data  <cit> , we determine that overall our method outperforms all other tested methods, including the simple t-statistic, fold change cut-off, smt, and fox. we demonstrate that ibmt performs as well as, or better than any other tested method in when using simulated data and "spike-in" affymetrix experiments  <cit> . we also apply our method to two experimental microarray datasets  <cit>  that due to their experimental designs, cannot be correctly analysed with previously proposed methods that account for the variance-intensity relationship . we find that our method generally resulted in higher significance of gene ontology   <cit>  groups when testing for an enrichment of differentially expressed genes. we also provide examples of how our method results in biological conclusions that may not have been attained using an alternative method.

RESULTS
intensity-based bayesian model
s0g <dig> = f + εg     

where the average log-expression level of gene g is denoted by αg, f is some function of αg defined on the range of αg, and s0g <dig> is the estimated prior variance. as explained below, we chose to model the function s0g <dig>  using local regression. the use of local regression differs from the window method of cyber-t in that the window method pools the standard deviation estimates of all genes in the window, whereas local regression uses a weighted average of the log-variances, where the weight for each gene j depends on the difference between the intensity of gene j and the intensity of the gene g, of interest. this relationship on its own can significantly reduce the uncertainty in the true variance of gene expression variances. for example, the relationship shown in figure  <dig> explains approximately 34% of variability in individual gene expression variances.

for our intensity-based method, we follow a hierarchical bayesian set-up similar to smt  <cit> . individual gene variances for genes with similar overall expression levels are assumed to have been generated by a single probability distribution. the parameters for the distribution of the variances, d <dig> and s0g <dig>  are termed the hyperparameters, and are estimated from the data using eb theory. in terms of the precision of the gene expression levels, which is defined as the reciprocal of the variance, 1/s0g <dig> is the mean, andthe hyperparameter d <dig> is the prior degrees of freedom and determines the spread of the distribution for a given s0g <dig>  larger d <dig> values result in smaller spread of the distribution for the precision and variance of gene expression levels. similar to previous methods  <cit> , by assuming a single hyperparameter for the prior degrees of freedom, we make the assumption that the spread of variance estimates about the background variance level is similar across the entire range of fluorescence levels.

suppose that β^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiigacuwfyogygaqcaaaa@2e64@g is the estimate of the contrast of interest obtained after fitting the appropriate linear model for gene expression data for gene g. in the simplest case when comparing expression levels between two samples, β^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiigacuwfyogygaqcaaaa@2e64@g is just the difference in average log-expression levels for gene g under the two experimental conditions. we assume the β^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiigacuwfyogygaqcaaaa@2e64@g measurements of log-fold change for each gene follow a normal distribution centered at βg, the actual log-fold change:

β^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiigacuwfyogygaqcaaaa@2e64@g ~ n 

where σg <dig> is the residual variance in the linear model for gene g and vg is the coefficient of the variance required to calculate the standard error. for a two-sample t-test, vg is 1/n <dig> + 1/n <dig> where n <dig> and n <dig> are the number of observations for each sample. given the variance σg <dig>  the sample variance for each gene is assumed to follow a scaled chi-square distribution with dg degrees of freedom:

sg2|σg2~σg2dgχdg <dig> 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgzbwcdaqhaawcbagaem4zacgabagaegomaidaaogaeiifawhccigae83wdm3aa0baasqaaiabdeganbqaaiabikdayaaakiabc6ha+naalaaabagae83wdm3aa0baasqaaiabdeganbqaaiabikdayaaaaoqaaiabdsgaknaabaaaleaacqwgnbwzaeqaaaaakiab=d8ajnaadaaaleaacqwgkbazdawgaaadbagaem4zacgabeaaasqaaiabikdayaaakiabc6cauaaa@45b4@

we adopt the conjugate prior distribution for σg2

1σg2~1d0s0g2χd02
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaadawcaaqaaiabigdaxaqaaggaciab=n8aznaadaaaleaacqwgnbwzaeaacqaiyagmaaaaaogaeiofa43aasaaaeaacqaixaqmaeaacqwgkbazdawgaawcbagaegimaadabeaakiabdohaznaadaaaleaacqaiwaamcqwgnbwzaeaacqaiyagmaaaaaogae83xdm2aa0baasqaaiabdsgaknaabaaameaacqaiwaamaeqaaawcbagaegomaidaaaaa@4114@

where d <dig> and s0g <dig> are the hyperparameters for the degrees of freedom and variance, respectively. with this model, the closed-form solutions for the posterior mean of the variance and degrees of freedom given the hyperparameters are:

df=d0+dgs˜g2=d0s0g2+dgsg2d0+dg
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakqaabeqaaiabdsgakjabdagamjabg2da9iabdsgaknaabaaaleaacqaiwaamaeqaaogaey4kasiaemizaq2aasbaasqaaiabdeganbqabaaakeaacuwgzbwcgaacamaadaaaleaacqwgnbwzaeaacqaiyagmaagccqgh9aqpdawcaaqaaiabdsgaknaabaaaleaacqaiwaamaeqaaogaem4cam3aa0baasqaaiabicdawiabdeganbqaaiabikdayaaakiabgucariabdsgaknaabaaaleaacqwgnbwzaeqaaogaem4cam3aa0baasqaaiabdeganbqaaiabikdayaaaaoqaaiabdsgaknaabaaaleaacqaiwaamaeqaaogaey4kasiaemizaq2aasbaasqaaiabdeganbqabaaaaaaaaa@50d4@

where df is the posterior degrees of freedom, dg is likelihood degrees of freedom, and s˜g2
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacuwgzbwcgaacamaadaaaleaacqwgnbwzaeaacqaiyagmaaaaaa@30a0@ is the posterior mean of the variance. our goal is to calculate point estimates of hyperparameters so that we can calculate expected values for the posterior parameters, σg <dig> and df.

we can now use the moderated t-statistic:

tgi=β^gis˜gvgi
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwg0baddawgaawcbagaem4zacmaemyaakgabeaakiabg2da9maalaaabaaccigaf8nsdimbakaadawgaawcbagaem4zacmaemyaakgabeaaaoqaaiqbdohazzaaiawaasbaasqaaiabdeganbqabagcdagcaaqaaiabdaha2naabaaaleaacqwgnbwzcqwgpbqaaeqaaaqabaaaaaaa@3e29@

to test the hypothesis h0: βg =  <dig> vs. ha: βg ≠  <dig> with df degrees of freedom, where β^
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaaiigacuwfyogygaqcaaaa@2e64@gi is the estimate of log-fold change for gene g and contrast i, and s˜
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacuwgzbwcgaacaaaa@2e2a@g is the posterior standard deviation.

as demonstrated by smyth  <cit> , under the null-hypothesis, the resulting moderated t-statistic in ibmt is distributed as student's-t with df degrees of freedom. thus, differentially expressed genes can be identified by calculating p-values and making appropriate multiple comparisons adjustments. however, if the data grossly deviate from the distributional assumptions, the moderated t-statistics can be used as a heuristic score for ranking genes based on the likelihood that they are differentially expressed, or an alternative empirical-based multiple comparison adjustment can be made, as in  <cit> .

estimation of hyperparameters
the formulas for posterior mean of the variance and degrees of freedom assume known hyperparameters d <dig> and s0g. we follow the empirical bayes approach and estimate hyperparameters from the data. gene-specific prior variances are estimated from f as given in , where f is a fitted local regression model of adjusted individual genes' log-variances  on the average log-expression levels. in this way, we avoid having to pre-specify a functional form for this dependency, and obtain predicted variances for each gene given their spot intensities.

to estimate the prior variance and prior degrees of freedom, we use the common empirical bayesian method of equating the empirical to expected values for the first and second moments of log-variance. according to the hierarchical model, the sampling variance for each gene, marginally, has the following scaled-f distribution  <cit> :

sg2
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgzbwcdaqhaawcbagaem4zacgabagaegomaidaaaaa@3091@ ~ s0g2
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgzbwcdaqhaawcbagaegimaajaem4zacgabagaegomaidaaaaa@317f@fdg,d0

consequently, the log-sample variance is distributed as the sum of a constant and fisher's z distribution and has the following expected value and variance:

e  = log s0g2
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgzbwcdaqhaawcbagaegimaajaem4zacgabagaegomaidaaaaa@317f@ + ψ - ψ + log     

var = ψ' + ψ'     

where ψ() is the digamma function and ψ'() is the trigamma function  <cit> . we denote with eg the non-constant part of  for each gene after solving for log

eg = log sg2
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgzbwcdaqhaawcbagaem4zacgabagaegomaidaaaaa@3091@ - ψ + log,     

with

e = log s0g2
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgzbwcdaqhaawcbagaegimaajaem4zacgabagaegomaidaaaaa@317f@ - ψ + log.     

next, we determine the predicted values for eg, pred, as a function of average log-intensities by local regression. we define the prior variance for each gene, s0g <dig>  to be the exponential of pred + ψ - log, by substituting pred for e in  and solving for log. to calculate the prior degrees of freedom we equate the empirical variance of the log-sample variances with the marginal variance in  and solve for d <dig>  as indicated before, we assume a priori that σg <dig> varies with g, but its variance is constant for all g. thus, if dg's were all the same and ψ' = c, say, then the marginal variance as given in  would be a constant, with a consistent estimator given by

mean2=1n∑ <dig> 
 mathtype@mtef@5@5@+=feaafiart1ev1aaatcvaufkttlearuwrp9mdh5mbpbiqv92aaexatlxbi9gbaebbnrfifhhdyfgasaach8aky=wiffydh8gipec8eeeu0xxdbba9frfj0=oqffea0dxdd9vqai=hguq8kuc9pgc9s8qqaq=dirpe0xb9q8qilsfr0=vr0=vr0dc8meaabaqaciaacagaaeqabaqabegadaaakeaacqwgtbqbcqwglbqzcqwghbqycqwgubgbcqggbbwwcqwglbqzdawgaawcbagaem4zacgabeaakiabgkhitiabdchawjabdkhayjabdwgaljabdsgakjabcicaoiabdwgalnaabaaaleaacqwgnbwzaeqaaogaeiykakiaeiyxa01aawbaasqabeaacqaiyagmaagccqgh9aqpdawcaaqaaiabigdaxaqaaiabd6gaubaadaaeabqaaiabcufabjabdwgalnaabaaaleaacqwgnbwzaeqaaaqabeqaniabgghildgccqghsislcqwgwbaccqwgybgccqwglbqzcqwgkbazcqggoaakcqwglbqzdawgaawcbagaem4zacgabeaakiabcmcapiabc2fadnaacaaaleqabagaegomaidaaogaeiola4caaa@5b6e@

this would yield an estimator for ψ', given by

mean <dig> - c.     

when dg's are different, the marginal variances in  differ for different g, but by known values ψ'. thus if we assume that dg does not vary drastically, in the sense that mean = ∑ψ' approaches a constant c as n gets large, then  is a consistent estimate of ψ'. typically, dg does not vary substantially with good quality data, and with affymetrix data dg is usually constant. thus d <dig> can be estimated consistently by solving

ψ' = mean <dig> - mean

for d <dig>  note that if dg is constant for all genes, then using log sg <dig> in placement of eg results in the same solution for d <dig> 

simulation study
simulations were designed to imitate a six slide, single-channel microarray experiment with three treatments and three controls. the simulations were performed to compare the performance of five methods  with respect to: a) the strength of relationship between variance and signal intensity, b) estimation of the correct prior degrees of freedom, and c) unbiased estimation of the true false positive rate. average expression intensities were generated assuming a log-normal distribution with a scale parameter of  <dig> , shape parameter equal to  <dig> , and threshold parameter  <dig> . the parameters for this distribution were chosen to closely fit the actual distribution of average expression intensities seen from real experiments . simulations were run assuming prior degrees of freedom d <dig> ∈  <cit> . for each prior degrees of freedom, actual and sample standard deviations were simulated for three different strengths of dependency on average log-intensities , referred to as low, medium, and high. the specific functional form used for this was

g = p1e- <dig>  + p2

with the following values used for p <dig> and p2: low: p <dig> = p <dig> =  <dig> , medium: p <dig> =  <dig>  and p <dig> =  <dig> , and high: p <dig> =  <dig> , p <dig> =  <dig> . to determine differences among the methods due to sample size, additional simulations were run for a 4-slide experiment  and a 10-slide experiment , with the high strength dependency, and an additional simulation was also run for the 6-slide experiment with no dependency of variance on average intensities. in the case of no dependence, ibmt performed nearly identical to smt. all simulations were performed with  <dig> "genes",  <dig>  of which were designed to be "differentially expressed". log-ratios for all genes were simulated as described in  <cit> . actual mean log-ratios for the  <dig> differentially expressed genes were simulated from the normal distribution n, and simulated measured mean log-ratios for all genes were assumed to follow the normal distribution n, where μ =  <dig> if the gene is not differentially expressed, and the simulated log-ratio for the  <dig>  differentially expressed genes.

the simulation process is summarized here:

for all  <dig> genes:

 <dig>  simulate αg as random draws from a log-normal distribution,

 <dig>  define function, f, for dependence of variance on αg,

 <dig>  simulate σg <dig> as random draws from d0*f/,

 <dig>  simulate sg <dig> as random draws from σg2/dg*chi-square with dg =  <dig> degrees of freedom,

 <dig>  w.l.o.g., assume the first  <dig> genes are differentially expressed,

simulate their mean log-ratios μg as random draws from n,

 <dig>  for the remaining  <dig> non-differentially expressed genes

set μg =  <dig> 

 <dig>  simulate estimated log-ratios as random draws from n.

results from the simulations indicate that the added complexity of the model is outweighed by the additional gain in information. four methods were compared in their ability to correctly estimate the false positive rate, using estimated false discovery rates   <cit> : the simple t-statistic , smyth's moderated t-statistic , our intensity-based moderated-t  method, and fox's method . all methods except fox accurately estimate the percent of false positives, as demonstrated by figure  <dig>  when the prior degrees of freedom is low, fox's method underestimates the percent of false positives , suggesting the possibility of a real risk of fox's method to give overly-optimistic results with real data. control of the true false positive rate under additional parameter sets gave the same results, and may be viewed as supplemental figure s <dig> .

we compared the ability of the methods to identify differentially expressed genes by creating false positive rate curves for each parameter set. these were created by ranking the genes by significance level, and then calculating the number of accumulated false positives with rank less than or equal to x. example false positive rate curves for the five methods are shown in figure  <dig>  figure  <dig> summarizes the results for all parameter sets by presenting normalized areas under the false positive curves described above. all results shown are the average of  <dig> simulation runs. all methods performed poorly when the data was simulated with only one prior degree of freedom. as the number of prior degrees of freedom increased, the performance of all methods except the simple t-test improved with ibmt overall outperforming the other methods. fox's method closely followed the performance of the fold change method, with a substantial advantage over fold with high dependence of variance on signal intensity. however, it had poor performance when gene's variances were approximately independent . both these results are probably due to this method's assumption that genes with similar intensities have identical variances. for the simulation with no dependence of variance on expression level, the areas under the false positive curves were the same for both smt and ibmt. the poor performance of the simple t-statistic in these simulations is most likely related to the low number of experimental replicates. we used four sample degrees of freedom, which was insufficient to accurately measure the variance of each gene separately. in additional simulations performed with higher sample degrees of freedom , the simple t-test showed marked improvement over results based on fewer degrees of freedom, while the other methods did not show as much improvement as the degrees of freedom increased .

finally we compared the ability of ibmt to smt to accurately estimate the prior degrees of freedom . since fox's prior degrees of freedom is dependent only on the free parameter and sample size rather than estimated from the data , fox was not included in this comparison. as expected, the empirical bayes method that does not account for the relationship between the variance and the magnitude of expression measurements tends to underestimate the prior degrees of freedom, especially for larger d <dig> values. as the dependency of variance on average intensities increases, this bias grows stronger. for the simulation with no dependence of variance on intensity level, using d <dig> =  <dig>  both methods accurately estimated the prior degrees of freedom, with estimates of d0/ equal to  <dig>  and  <dig>  for smt and ibmt respectively.

values listed are for the function d0/ and are the mean of  <dig> simulations. perfect values for each prior degrees of freedom are: d <dig> = 1:  <dig> , d <dig> = 4:  <dig> , d <dig> = 16:  <dig> , and d <dig> = 100:  <dig> 

results from the controlled spike-in dataset
two publicly-available, and completely controlled, "spike-in" affymetrix datasets were used to compare the performance of the same methods, plus cyber-t, on real-world microarray data. the analysis of these experiments is a natural extension of the simulation studies as the "correct" results are known. the first experiment consisted of three technical replicates each of control rna samples and samples with known amounts of spiked-in rna, and consisting of  <dig>  individual crnas. we used the average of the top  <dig> expression datasets, as reported by choe et al.  <cit>  and available for download at  <cit> . the description of all pre-processing steps used for these expression datasets, as well as further detail of the experimental methods are given in the original publication  <cit> . in the original publication, cyber-t was determined to be the preferred method for identifying differentially expressed genes, with sam  <cit>  and the simple t-test being the other methods tested. for all six methods , we ranked the genes by significance level, and then the number of false positives was calculated as a function of the number of genes deemed to be significant. the order of performance in accumulating the least number of false positives, from best to worst, is ibmt, fox, cyber-t, smt, the simple t-test, and finally fold change .

the ability of the different methods to correctly establish the statistical significance of differential expression was assessed by comparing estimated and empirically established false discovery rates   <cit> . the simple t-test performed best in correctly estimating the fdr . of the four other methods, ibmt and smt resulted in estimated false discovery rates closest to their true proportion of false positive rates . all five methods underestimate the number of false positives, which under normal circumstances may result in an unacceptable amount of over-confidence in the significance of results. however, we stress that in this experiment even the simple t-test underestimated the true number of false positives, as has been previously noted  <cit> . the prior degrees of freedom estimated for this study ranged from  <dig>  –  <dig>  for ibmt and  <dig>  –  <dig>  for smt, and using the defaults for the other methods, cyber-t used  <dig> and fox used  <dig> 

the second spike-in dataset used was the affymetrix hg-u <dig> latin-square data set available at  <cit> , and consisting of  <dig>  probe sets. this dataset consists of  <dig> sets of  <dig> chips, each having  <dig> probe sets  spiked-in. after preprocessing with rma, each consecutive pair of triplicates was analyzed separately, to identify the 2-fold changes in expression. in addition, ibmt was used to analyze each set of three consecutive triplicates. figure 7a and 7b compare the average accumulation of false positives by gene rank and estimation of the true proportion of false positives respectively. note the slight improvement in using three sets at a time compared to pairs. possibly due to the low number of spiked-in genes for this experiment, the ability of ibmt, cyber-t, and fox to rank the differentially expressed genes on top could not be differentiated, as the curves for these three experiments cross. however, these methods did outperform smt, fold change, and the t-test, again indicating the importance of accounting for the dependence of variance on gene signal intensity. similar to the previous spike-in experiment, figure 7b shows that the t-test performed best in estimating the true proportion of false positives, and cyber-t and fox resulted in the greatest underestimation of false positives. prior degrees of freedom for this data set ranged from  <dig>  –  <dig>  for ibmt and  <dig>  –  <dig>  for smt, while cyber-t and fox used the same defaults as the previous data set. the relationship between variance and intensity for this study can be seen in supplemental figure s <dig> 

case studies: analysis and interpretation of two microarray datasets
results from the mef ahr-/- dataset
although simulations and spike-in datasets point to the potential advantage of ibmt and allow a determination of its general behavior, only with the analysis of experimental data can the practical advantages or disadvantages of the method be observed. we compared the t-test based on the simple linear model, fold change cut-off, smt, and ibmt on two experimental datasets. cyber-t and fox's method were not included because they could not be properly used with the experimental designs of these datasets. the first is a comparison of relative rna levels of wildtype mouse embryo fibroblast  cells to aryl-hydrocarbon receptor gene  knockout mef cells, involving both technical and biological replicate arrays. the aryl-hydrocarbon receptor protein  is a critical mediator of the molecular defense of exposures to environmental toxicants by serving as the receptor in a toxicant-activated signaling pathway  <cit> . the top  <dig>  ranked genes from each of the four methods were used to test for gene ontology categories significantly enriched with differentially expressed genes to compare the ability of each method to reveal pathways or cellular processes involved in ahr function. we used a fixed number of genes to test gene ontology to keep the comparison of methods unbiased. testing was performed using expression analysis systematic explorer , and linking to the three branches of the gene ontology database. fisher's exact probability was calculated for each gene category, and a bonferroni-adjusted p-value <  <dig>  was used as the significance cut-off level  <cit> . assuming the treatment affects a certain number of known biological pathways and molecular functions in the cell, the method that detects the highest number of these is the most desirable.

top ten categories for each of the four compared methods: magnitude of fold change, simple t-test, smt, and ibmt. the ibmt method resulted in both the highest number of significant categories using a  <dig>  bonferroni-adjusted p-value cut-off, as well as the highest number of genes in a significant category.

results from nickel exposure dataset
the second experimental dataset that we analysed using ibmt is a time series response to nickel inhalation in female 129s1/svimj strain mouse lung  <cit> . five times were used , each being compared to control samples in triplicate. for each time, samples for one array were labelled with opposite dyes. data was normalized and analysed for differentially expressed genes as described in the methods. as in the previous section, the analysis of this experiment, which must account for both dye-effect and multiple treatment conditions, is an example not able to be analysed correctly by either cyber-t or fox's method.

we tested for significant go categories as described above for the top ranked  <dig>  genes in each comparison, and three different p-value cut-off values were used for significance rather than the stricter bonferroni adjustment due to overall lower p-values from fisher's exact test in this dataset. two hundred rather than  <dig> genes were used in this experiment because only approximately  <dig> genes were significantly differentially expressed at the earliest time-point based on previous analysis. table  <dig> displays a summary of the results from testing for significant gene ontology categories. ibmt found the highest number of unique genes  involved in the significantly found categories across time. the fold method results in the highest number of significant categories overall, and ibmt found the most significant categories using the two smaller p-values of  <dig>  and  <dig> .

the number of significant categories, as well as the number of genes assigned to the significant categories, are shown for the five time points for each of three p-value cut-offs.

given the nature of this experiment, one would expect that some functional categories would be affected at two or more time points. therefore, an additional measure of performance is the level of overlap across time points in which categories were found to be significant. to accomplish this aim, we calculated the average number of time points each significant category was determined to be significant using the three same p-value cut-offs as above. the results are, for p-values of  <dig> ,  <dig> , and  <dig>  respectively, fold:  <dig> ,  <dig> , and  <dig> ; t:  <dig> ,  <dig> , and  <dig> ; smt:  <dig> ,  <dig> , and  <dig> ; and ibmt:  <dig> ,  <dig> , and  <dig> . thus, according to the results, the ibmt method gave the most consistent results through time. the list of significant go categories is available as supplemental information .

acute lung injury is a severe clinical syndrome that results from multiple causes including pneumonia, sepsis, trauma, and inhaled irritants  <cit> . pathological conditions associated with the development of acute lung injury include alveolar damage, inflammatory cell influx and activation, pulmonary edema and hemorrhage, alteration of surfactant production, and insufficient gas exchange  <cit> . prior studies have assessed aspects of the molecular mechanisms involved in the pathogenesis of acute lung injury in mice using inhaled nickel  <cit> .

ibmt identified several transcripts that could play significant roles in the development of nickel-induced acute lung injury that were not recognized using the smt method. for example, following  <dig> h of nickel exposure, transcripts for three heat shock proteins  were found to be induced using the ibmt method as compared to the smt method, including heat shock  <dig> kd protein  <dig> , heat shock protein 1b , and heat shock protein 9a . hsps are a group of genes that are transcriptionally regulated in response to cellular stress. in the lung, induction of hsps protects against acute lung injury in in vivo  <cit>  and in vitro models  <cit> . thus, hsp induction in response to nickel may be involved in an early cytoprotective mechanism in the development of acute lung injury.

another transcript that was determined to be significantly changed using the ibmt method as compared to the smt method was from a group of genes known as aquaporins, which facilitate water movement through the air space-capillary barrier in the lung  <cit> . expression of aquaporin  <dig> , the major water channel gene expressed in alveolar, and bronchial epithelium, decreased an estimated  <dig> -fold after  <dig> h of nickel exposure. in previous studies, decreased expression of aqp <dig> has been associated with acute lung injury caused by adenoviral infection  <cit>  and bleomycin treatment  <cit>  in mice. these data are consistent with the modulation of aqp <dig> expression in regulating fluid homeostasis and abnormal fluid fluxes in the development of pulmonary inflammation and edema associated with acute lung injury.

finally, another significantly altered transcript that was identified by ibmt and not smt was fibroblast growth factor  <dig> . mouse lung fgf <dig> transcript levels were estimated to be induced  <dig> -fold after  <dig> h of nickel exposure. in the lung, fgf <dig> is expressed in alveolar type ii cells  <cit> , and may have multiple biological activities in vitro and in vivo, including angiogenesis, mitogenesis, and cellular differentiation  <cit> . additionally, induction of fgf <dig> expression can influence cell proliferation and biosynthetic events that are important to the proper resolution of tissue injury in the lung  <cit> . thus, increased fgf <dig> expression may be an important molecular event in the pathogenesis of nickel-induced acute lung injury.

taken together, the ibmt method successfully identified several transcripts that were significantly changed at various times throughout the development of nickel-induced acute lung injury in mice that were not identified by the smt method. these transcripts have been previously investigated in the development of lung injury, and may have biological relevance in our mouse model. the lists of top-ranked genes by ibmt but not smt, and vice versa, are available as supplemental information.

CONCLUSIONS
ibmt has the strength of balancing two important factors in the analysis of microarray data: the degree of independence of variances relative to the degree of identity , and the relationship between variance and signal intensity. we demonstrated that incorporating information about the dependence of the variance of genes on expression intensity level can improve the efficiency of the empirical bayes moderated t-statistics, and that properly estimating the prior degrees of freedom is important in estimating the true proportion of false positives. if a non-intensity-based moderated-t is used, and the variance of low expressed genes is higher than average, then an over-representation of low expressed genes will occur in the top ranked differentially expressed transcripts because their variance estimates will be "shrunk" towards the lower overall variability. this in turn results in a higher rate of falsely implicated genes and makes the interpretation of the results more difficult. indeed, this trend could be seen in the comparison of genes found to be significant in smt but not ibmt, or vice versa, in the nickel exposure experiment. smt identified a large number of relatively low expressed genes , often with unknown function, as being significantly changed compared to ibmt . to our knowledge, ibmt is the first to account for the dependence of gene variance on intensity levels in a completely data-dependent manner, without a need for specification of free parameters by the user, within the empirical bayes analysis framework. furthermore, as opposed to cyber-t  <cit>  and fox  <cit> , ibmt can properly analyze data from any experimental design setup and array platform, including multiple treatments or time series, affymetrix chips or two-dye arrays, and experiments with both technical and biological replicates. the prior variance levels are estimated using local regression and the prior degrees of freedom are estimated using a consistent estimator based on the empirical bayes approach.

the ibmt method outperformed or performed as well as the simple t-statistic, fold change, smt, and fox in simulation studies intended to mimic real microarray data and on real microarray data itself. the improved performance of ibmt on spike-in experiments suggests that the pooling of information across genes, as well as accounting for the relationship between the variances and overall intensities of gene expression measurements, is warranted. the "spike-in" affymetrix datasets also revealed the need to correctly estimate the prior degrees of freedom for correctly estimating the proportion of false positives. by simply accepting user input for this parameter , one is at risk of either greatly overestimating or underestimating the true accumulation of false positives. for the "spike-in" experiments, this may explain the poorest estimation of the true false positive rate by cyber-t and fox. as our results show, all methods underestimated the proportion of false positives in these affymetrix spike-in datasets. this may partially be due to the design of these experiments, creating correlations that would not be seen in experimental data, or even unintended real changes. however, correlations among genes and microarrays have been observed in experimental data also, and in this case, the significance statistics may be more accurately calculated using a local fdr procedure with an empirical null distribution, as proposed by efron  <cit> , rather than the benjamini fdr  <cit>  as applied in this paper. even if no correlations are expected, efron's local fdr procedure with the theoretical normal null may improve accuracy in estimating signficance levels for any chosen analysis method.

our method was also applied to two experimental dual-channel datasets, a simple knockout versus wildtype comparison and a time-series experiment. analysis of these data indicated that ibmt generated the greatest number of genes involved in go categories significantly enriched with genes determined to be differentially expressed. although the biological pathways affected in each experiment can be ascribed with limited certainty, in the time series experiment we examined self-consistency among sampling times. although affected pathways may change across time, it is reasonable to expect that some should be consistent for at least two or more times. our analysis showed that ibmt had the highest self-consistency. in addition to the comparison of methods using gene ontology, interpretation of the results hinted that biological categories found in the mef ahr-/- experiment using ibmt were more consistent with functions previously ascribed to this receptor. ibmt also provided a greater percent of genes directly relevant to what is currently known of the response to nickel exposure in mice.

