BACKGROUND
two central problems in computational biology are the determination of the alignment and phylogeny of a set of biological sequences. current methods first align the sequences, and then infer the phylogeny given this fixed alignment. several software packages are available that deal with one or both of these sub-problems. for example, clustalw  <cit>  and t-coffee  <cit>  are popular sequence alignment packages, while mrbayes  <cit> , paup*  <cit>  and phylip  <cit>  all provide phylogenetic reconstruction and inference. despite working very well in practice, these methods share some problems. first, the separation into a multiple-alignment step and a phylogenetic inference step, is fundamentally flawed. the two inference problems are mutually dependent, and alignments and phylogeny should ideally be co-estimated, a point first made by sankoff, morel and cedergren  <cit> . indeed, a proper weighting of mutation events in multiple sequences requires a tree, which in turn can only be determined if a multiple alignment is available. for instance, clustalw and t-coffee compute their alignments based on a neighbour-joining guide tree, biasing subsequent phylogenetic estimates based on the resulting alignment. moreover, fixing the alignment after the first step ignores the residual uncertainty in the alignment, resulting in an overconfident phylogenetic estimate.

this leads on to the second issue, which is that heuristic methods are used to deal with insertions and deletions , and sometimes also substitutions. this lack of a proper statistical framework makes it very difficult to accurately assess the reliability of the alignment estimate, and the phylogeny depending on it.

the relevance of statistical approaches to evolutionary inference has long been recognised. time-continuous markov models for substitution processes were introduced more than three decades ago  <cit> . inference methods based on these have been considerably improved since then  <cit> , and now have all but replaced older parsimony methods for phylogeny reconstruction. with alignments, progress towards statistically grounded methods has been slower. the idea to investigate insertions and deletions in a statistical framework was first considered by bishop and thompson  <cit> . the first evolutionary model, termed the tkf <dig> model, and corresponding statistical tools for pairwise sequence alignment were published by thorne, kishino and felsenstein  <cit> . its extension to multiple sequences related by a tree has been intensively investigated in the last few years  <cit> , and has recently also been extended to rna gene evolution  <cit> . current methods for statistical multiple alignment often computationally demanding, and full maximum likelihood approaches are limited to small trees. markov chain monte carlo techniques can extend these methods to practical problem sizes.

statistical modelling and mcmc approaches have a long history in population genetic analysis. in particular, coalescent approaches to genealogical inference have been very successful, both in maximum likelihood  <cit>  and bayesian mcmc frameworks  <cit> . the mcmc approach is especially promising, as it allows the analysis of large data sets, as well as nontrivial model extensions, see e.g.  <cit> . since divergence times in population genetics are small, alignment is generally straightforward, and genealogical inference from a fixed alignment is well-understood  <cit> . however, these approaches have difficulty dealing with indels when sequences are hard to align. indel events are generally treated as missing data  <cit> , which renders them phylogenetically uninformative. this is unfortunate as indel events can be highly informative of the phylogeny, because of their relative rarity compared to substitution events. statistical models of alignment and phylogeny often refer to missing data. not all of these can be integrated out analytically , and these are dealt with using monte carlo methods. the efficiency of such approaches depend to a great extent on the choice of missing data. in previous approaches to statistical alignment, the sampled missing data were either unobserved sequences at internal nodes  <cit> , or both internal sequences and alignments between nodes  <cit> , or dealt exclusively with pairwise alignments  <cit> . in all cases the underlying tree was fixed. in  <cit>  we published an efficient algorithm for computing the likelihood of a multiple sequence alignment under the tkf <dig> model, given a fixed underlying tree. the method analytically sums out all missing data , eliminating the need for any data augmentation of the tree. this methodology is referred to in the mcmc literature as rao-blackwellization  <cit> . as a result, we can treat indels in a statistically consistent manner with no more than a constant multiplicative cost over existing methods that ignore indels.

the only missing ingredient for a full co-estimation procedure is an alignment sampler. unfortunately, there exists no gibbs alignment sampler that corresponds to the analytic algorithm referred to above. in this paper we introduce a partial importance sampler to resample alignments, based on a proposal mechanism built on a partial score-based alignment procedure. this type of sampler supports the data format we need for efficient likelihood calculations, while still achieving good mixing in reasonable running time .

we implemented the likelihood calculator and the alignment sampler in java, and interfaced them with an existing mcmc kernel for phylogenetics and population genetics  <cit> . we demonstrate the practicality of our approach on an analysis of  <dig> globin sequences.

RESULTS
definition of the tkf model
the tkf <dig> model is a continuous-time reversible markov model describing the evolution of nucleotide  sequences. it models three of the main processes in sequence evolution, namely substitutions, insertions and deletions of characters, approximating these as single-character processes. a sequence is represented as a string alternatingly consisting of links and characters connected by these links. this string both starts and terminates with a link. insertions and deletions are modeled through a time-continuous birth-death process of links. when a new link is born, its associated character  is chosen from the equilibrium distribution of the substitution process.  when a link dies, its associated character dies too. the leftmost link of the sequence has no corresponding character to its left, and is never deleted. for this reason it is called the immortal link.

since subsequences evolve independently, it is sufficient to describe the evolution of a single character-link pair. in a given finite time span, this pair evolves into a finite subsequence of characters and links. since insertions originate from links, only the first character of this descendant subsequence may be homologous to the original character, while subsequent ones will have been inserted and therefore not be homologous to ancestral characters. the model as applied to pairwise alignments was solved analytically in  <cit> , see also  <cit> . conceptually, the model can be trivially extended to trees, but the corresponding algorithms for likelihood calculations have been developed only recently  <cit> .

because the tkf <dig> model is time reversible, the root placement does not influence the likelihood, an observation known as felsenstein's "pulley principle"  <cit> ). although the algorithms we developed are not manifestly invariant under changes in root placement, in fact they are. we have used time reversibility to check correctness of our implementations.

computing the likelihood of a homology structure
the concept of homology structure  <cit> , also known as effective alignment  <cit> , refers to an alignment of sequences at leaves without reference to the internal tree structure, and without specifying the ordering of exchangable columns . we derived a linear-time algorithm that computes the likelihood of observing a set of sequences and their homology structure, given a phylogeny and evolutionary parameters, under the tkf <dig> model  <cit> . by definition, this likelihood is the sum of the probabilities of all evolutionary scenarios resulting in the observed data. it was previously shown that such evolutionary scenarios can be described as a path in a multiple-hmm , and the likelihood can thus be calculated as the sum of path probabilities over all such paths, in time polynomial in the number of states. however, this straightforward calculation is infeasible for practical-sized biological problems, since the number of states in the hmm grows exponentially with the number of sequences  <cit> . since our algorithm does not feature this exponential blow-up of markov states, we termed it the one-state recursion. in contrast to previous approaches  <cit> , the one-state recursion relieves us from the need to store missing data at internal tree nodes, allowing us to change the tree topology without having to resample this missing data. this enables us to consider the tree as a parameter, and efficiently sample from tree space. the concept of homology structure referred to above is key to our algorithm, and we will presently define this concept more precisely. let a <dig>  a <dig>  ...am be sequences, related by a tree t with vertex set v. let  denote the jth character of sequence ai, and let  denote its k long prefix. a homology structure  on a <dig>  ..., am is an equivalence relation ~ on the set of all the characters of the sequences, c = {}, specifying which characters are homologous to which. the evolutionary indel process generating the homology structure on the sequences imposes constraints on the equivalence relations that may occur. more precisely, the equivalence relation ~ has the property that a total ordering, <h, exists on c such that



 in particular, these conditions imply that the characters constituting a single sequence are mutually nonhomologous. the ordering <h corresponds to the ordering of columns of homologous characters in an alignment. note that for a given homology structure, this ordering may not be unique . this many-to-one relationship of alignment to homology structure is the reason for introducing the concept of homology structure, instead of using the more common concept of alignment.

the one-state recursion, which calculates the likelihood of a homology structure, is a convolution of two dynamic programming algorithms. the top-level algorithm traverses the prefix set of the multiple alignments representing the homology structure . this repeatedly calls on a reverse traversal algorithm on the phylogenetic tree, which sums out the likelihood contributions of substitutions and indels under the tkf <dig> model. see  <cit>  for full details.

a partial metropolized independence sampler
because our algorithm does not require the phylogenetic tree to be augmented with missing data, proposing changes to the evolutionary tree is easy, and mixing in tree space is very good. the drawback however is that without data augmentation, it is unclear how to perform gibbs sampling of alignments, and we have to resort to other sampling schemes. one straightforward choice would be a standard metropolis-hastings procedure with random changes to the alignment, but we expect slow mixing from such an approach. another general approach is metropolized independence sampling. its performance depends on the difference between the proposal distribution and the target distribution, and this will inevitably become appreciable with growing dimension of the problem, as measured by the number and length of the sequences to be aligned. we therefore opted for a partial metropolized independence sampler  <cit> , where we partly defy the "curse of dimensionality" by resampling only a segment of the current alignment. above increasing the acceptance ratio, this method has the added advantage of being a more efficient proposal scheme, since the time complexity of the algorithm is proportional to the square of the window size, and so leads to an effective increase in mixing per processor cycle. metzler et al.  <cit>  followed a parallel approach, using a partial gibbs sampler, and showed that this resulted in faster mixing compared to a full gibbs sampling step. since the realignment step may change the window length , to have a reversible markov chain we need all window sizes to have positive proposal probability. we chose a geometric length distribution, but other distributions can be considered equally well.

the proposal algorithm
the proposal algorithm is as follows. a window size and location is proposed, the alignment of subsequences within this window is removed, and a new alignment is proposed by a stochastic version of the standard score-based progressive pairwise alignment method. first, dynamic programming  tables are filled as for a deterministic score-based multiple alignment, starting at the tree tips and working towards the root, aligning sequences and profiles. we used linear gap penalties, and a similarity scoring matrix that was obtained by taking the log-odds of a probabilistic substitution matrix. the underlying phylogeny was used to define divergence times, and served as alignment guide tree. after filling the dp tables, we applied stochastic traceback. the probabilities for the three possible directions at each position was taken to be proportional to exp, where s is the deterministic score and α is a scale parameter . the set of paths that emerged in this way then determined the multiple alignment. all possible alignments can be proposed in this manner, and the proposal as well as the back-proposal probabilities can be calculated straightforwardly.

correctness of the sampler
there are two problems with the proposal sampler introduced above. first, we propose alignments instead of homology structures. we need the latter, since the algorithm derived in this paper calculates the likelihood of the homology structure, not the particular alignment. although it would be conceptually and  computationally simpler to use alignments, we are not aware of any efficient algorithm that can calculate such alignment likelihoods. the second problem is that calculating the proposal probability of a particular alignment is not straightforward. any choice of window size and location may result in the same proposal alignment. to calculate the true proposal probability of particular alignments, we need to sum over all possible windows, which is prohibitively expensive.

fortunately, we can solve both problems efficiently. we can sample alignments uniformly inside a homology structure, and at the same time sample homology structures according to their posterior probabilities. as biologically meaningful questions refer to homologies and not particular alignments, it seems reasonable to impose a simple uniform distribution over alignments within homology structures. the second problem is solved by not calculating an alignment proposal probability, but the proposal probability of the combination of an alignment and a resampling window. for a proposal of alignment x <dig> and window w from a current alignment x <dig>  we use the following metropolis-hastings ratio:



where h <dig> and h <dig> are homology structures corresponding to the alignments x <dig> and x <dig> respectively, |h1| and |h2| are their cardinalities , and t is the proposal probability. using this ratio, the markov chain will converge to the desired distribution π = π/|h|, since the detailed balance condition is satisfied. indeed,



where the final equality holds because of the symmetry of the left-hand side. the cardinality of a homology structure, |h1|, is the number of possible directed paths in the graph spanned by the one-state recursion; in other words, the number of permutations of alignment columns that result in alignments compatible with the given homology structure . this number can be calculated straightforwardly using a dynamic programming algorithm that traverses the one-state recursion graph  <cit> .

discussion
the one-state recursion provides a method for calculating the likelihood l = pr{a, |t, q, λ, μ} of observing the sequences with their homology structure  given the tree and model parameters. here a are the amino acid sequences,  is their homology structure, t is the tree including branch lengths, q is the substitution rate matrix, and λ, μ are the amino acid insertion and deletion rates. to demonstrate the practicality of the new algorithm for likelihood calculation we undertook a bayesian mcmc analysis of ten globin protein sequences . we chose to use the standard dayhoff rate matrix to describe the substitution of amino acids. as initial homology structure we used the alignment computed by t-coffee. we co-estimated homology structures, the parameters of the tkf <dig> model, and the tree topology and branch lengths. to do this we sampled from the posterior,



where z is the unknown normalising constant. we chose the prior distribution on our parameters, f , so that t was constrained to a molecular clock, and λ = μl/ to make the expected sequence length under the tkf <dig> model agree with the observed lengths; here l is the geometric average sequence length. all other parameters were sampled under uniform priors. we assume a molecular clock to gain insight into the relative divergence times of the alpha-, beta- and myoglobin families. in doing so we incorporate insertion-deletion events as informative events in the evolutionary analysis of the globin family. the posterior density h is a complicated function defined on a space of high dimension. we summarise the information it contains by computing the expectations, over h, of various statistics of interest. we estimate these expectations by using mcmc to sample from h. marginalizations for continuous variables can be done in a straightforward manner; see for example figure  <dig>  which depicts the marginal posterior density of the μ parameter for two independent mcmc runs, showing excellent convergence.

for alignments, the maximum a-posteriori alignment is very hard to estimate from an mcmc sample run, as there are typically far too many plausible alignments contributing to the likelihood. indeed, we found that almost all alignments in a moderately long mcmc run  were unique. however, it is possible to reconstruct a reliable maximum posterior decoding  <cit>  alignment from such a moderate long sampling run. this alignment uses the posterior single-column probabilities, which can be estimated much more reliably since many alignments share particular columns, to obtain an alignment that maximizes the product of individual column posteriors. this alignment can be obtained by a simple dynamic programming algorithm  <cit> , see fig.  <dig>  it is hard to visualise alternative suboptimal alignments, but the individual posterior column probabilities clearly reveal the more and less reliable regions of the alignment. we found that the reliable alignment regions broadly correspond to the alpha helical structure of the globin sequences.

the estimated time of the most recent common ancestor of each of the alpha, beta and myoglobin families are all mutually compatible , suggesting that the molecular clock hypothesis is at least approximately valid. analysis of a four sequence dataset demonstrate consistency in μ estimates between mcmc and previous ml analyses  <cit>  . interestingly, the current larger dataset supports a lower value of μ. this is probably due to the fact that no indels are apparent within any of the subfamilies despite a considerable sequence divergence. the indel rate estimated by the current cosampling procedure is greater than the estimate on a fixed multiple alignment  <cit>  , but this discrepancy is not significant for the current dataset. it should be stressed that the two mcmc analyses of the globin data set presented here are purely illustrative of the practicality of the algorithm described, and no novel biological results were obtained. the two mcmc runs of  <dig> million states each required less than  <dig> hours of cpu time each on a  <dig>  ghz g <dig> apple macintosh running os x, using an unoptimised implementation of the algorithm. from these runs we sampled  <dig> states each. the estimated number of independent samples  for the posterior probabilities was  <dig> and  <dig>  respectively , while for the indel rate μ the esss were calculated at  <dig> and  <dig>  we expect analyses of data sets of around  <dig> sequences to be readily attainable with only a few days computation.

CONCLUSIONS
in this paper we present a new cosampling procedure for phylogenetic trees and sequence alignments. the underlying likelihood engine uses recently introduced and highly efficient algorithms based on an evolutionary model  that combines both the substitution and insertion-deletion processes in a principled way  <cit> . we show that the proposed method is applicable to medium-sized practical multiple alignment and phylogenetic inference problems.

one motivation for using a fully probabilistic model, and for using a co-estimation procedure for alignments and phylogeny, is that this makes it possible to assess the uncertainties in the inferences. fixing either the alignment or the phylogeny leads to an underestimate of the uncertainty in the other, and score-based methods give no assessment of uncertainty whatsoever.

we show that the confidence estimates so obtained can contain biologically meaningful information. in the case of the multiple alignment of globin sequences, peaks in the posterior column reliabilities correspond broadly to the various conserved alpha helices that constitute the sequences . in the case of the tree estimate, the non-traditional phylogeny supported by the myoglobin subtree coincided with a significant polyphyly, as indicated by the posterior tree topology probabilities, and graphically represented by significantly overlapping 95% node height confidence boxes . it is clear that such confidence information significantly contributes to the usefulness of the inference.

at the heart of the method lies a recently introduced algorithm, termed the "indel peeling algorithm", that extends felsenstein's peeling algorithm to incorporate insertion and deletion events under the tkf <dig> model  <cit> . this renders indel events informative for phylogenetic inference. although incurring considerable algorithmic complications, the resulting algorithm is still linear-time for biological alignments . moreover, our approach allows efficient sampling of tree topologies, as no data is presented at internal nodes.

we also developed a method for sampling multiple alignments, which is applicable for the data augmentation scheme we used for the efficient likelihood calculations. by combining the two samplers, we can co-sample alignments, evolutionary trees and other evolutionary parameters such as indel and substitution rates. the resulting samples from the posterior distribution can be summarized in traditional ways. we obtained maximum a-posteriori estimates of alignment, tree and parameters, and augmented these with estimates of reliability.

as was already mentioned in  <cit> , it would be desirable to have a statistical sequence evolution model that deals with 'long' insertions and deletions, instead of single nucleotides at a time. for score-based algorithms, this is analogous to the contrast between linear and affine gap penalties. it is clear that the extension of the model to include long indels would result in considerable improvements, but the algorithmic complexities are considerable. we have made progress on a full likelihood method for statistical sequence alignment under such an evolutionary model  <cit> , but the generalization of this method seems nontrivial. we believe that here too, markov chain monte carlo approaches, combined with data augmentation, will be essential for practical algorithms. however, we also believe that in certain restricted but biologically meaningful situations, such as highly conserved proteins, the tkf <dig> model is reasonably realistic for the co-estimation procedure presented here to be of practical interest.

availability and requirements
the beast package , which includes the algorithm described in this paper, is available from , with full installation and requirement details. the data set used in this paper is avaliable 

authors' contributions
im conjectured and gl proved the one-state recursion. gl and im independently implemented the algorithms, and wrote the paper. jlj simplified the proof of the recursion, gl suggested to use it within an mcmc phylogeny cosampler, and im suggested to use a metropolised importance sampler and proved its correctness. gl and ad interfaced the java algorithms to the beast phylogeny sampling package  <cit> , and ad carried out the mcmc analysis. jh provided project management. all authors read and approved the final manuscript.

supplementary material
additional file 1
this xml file specifies the mcmc run for the example phylogeny and alignment co-estimation given in this paper . to run, download the beast package 

click here for file

 acknowledgements
the authors thank yun song, dirk metzler, anton wakolbinger and ian holmes for several useful suggestions and discussions. this research is supported by epsrc  and mrc . i.m. was further supported by a békésy györgy postdoctoral fellowship.

figures and tables
