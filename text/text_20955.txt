BACKGROUND
the immense potential of quantitative molecular biology in life sciences is challenged by inconsistent approaches for control of errors in the final results. due to its performance characteristics and general applicability, quantitative pcr  has become the golden standard method for the quantification of nucleic acids. although with the help of laboratory automation, qpcr data generation has become easy and fast, quantitative data analysis and interpretation is still not trivial due to several factors that can influence the final result. to ensure high quality of results and allow for potential reproduction of experiment, the minimum information for publication of quantitative real-time pcr experiments  guidelines have been proposed  <cit> .

qpcr is used to measure the quantity of target dnas in a given sample through repeated cycles of dna amplification. the cycle at which the observed amplification-derived fluorescence first exceeds a certain threshold is called the quantification cycle . the analysis starts with the examination of the amplification curves and initial assessment of their quality, followed by the determination of the cq values, which are further used for the quantification of the nucleic acids. it can be performed by either a standard curve or a comparative approach . both approaches are relative, but each is based on its own assumptions  <cit> . in the standard curve approach, the number of target dna molecules in the sample is calculated using a calibration curve of serially diluted dna standards of known concentrations. the calibration curve presents a linear relationship between the cq and the logarithm of the initial amount of template dna. test sample copy numbers are calculated from the linear regression of the standard curve, assuming equal amplification efficiencies for the standard and test samples  <cit> . when reference materials with known contents are available, the outcomes are absolute copy numbers  <cit>  whereas when the copy numbers of the targets in the standards are not known, relative standard curves can be used to determine copy numbers ratios between different samples  <cit> . the second approach, comparative quantification, is based on determining the fold-differences in the expression of the target in relation to the reference gene. the most popular, comparative threshold cycle method  relies on a direct comparison of the cq values and assumes equal and 100% efficiencies of the target and the reference gene. however, the amplification efficiencies between different genes analysed can differ which makes the ΔΔcq method unsuitable in many cases  <cit> . consequently, modifications that allow for amplification efficiency correction have been developed  <cit> . although they do not perform as accurate as the standard curve approach  <cit> , they can be applicable in research applications where high accuracy is not needed.

the efficiency of pcr amplification is considered as one of the most important parameters in qpcr analysis, as it strongly influences the final result  <cit> . the efficiency is defined as the fraction of target molecules that are copied in one pcr cycle. deviations from an optimal 100% efficiency are observed as inhibition, caused by the presence of inhibitory components, or over-amplification, caused by compound or structural conformation changes during the pcr  <cit> . most common and broadly accepted way of efficiency determination is from the slope of a standard curve using linear least squares regression  <cit>  where the preciseness of the efficiency estimate is affected by qpcr platform, the number of replicate reactions and serial dilution volume  <cit> . recently, robust regression methods were shown to present a reliable alternative because they are less affected by outliers  <cit> . alternatively, the efficiency can be calculated from the fluorescent increment in single amplification curves which were shown to be less accurate  and they also require an additional step in the analysis that is sometimes cumbersome and impractical. the efficiency of the amplification is highly dependent on primer sequence and therefore the assumption of most quantification algorithms is that pcr efficiency is assay-dependent and sample-independent  <cit> . yet, it is not uncommon that individual samples originating from different or even same matrix have different amplification efficiencies  <cit>  which can result in quantification inaccuracies  <cit> . a simple control of efficiency in individual samples can be performed by analysing two dilutions of the same sample  <cit> .

normalization controls for variations in extraction yield, reverse-transcription yield and efficiencies of amplification, thus enabling comparisons of nucleic acid concentrations across different samples. various normalization strategies and reference genes selection algorithms have been proposed with the common guideline that several validated reference genes should be used for normalization .

although numerous commercial and open-access software tools for the analysis of qpcr data exist , they lack quality control  of the final result that would aid the researcher in interpreting it. we have developed the web application quantgenius , the only qpcr data analysis solution that integrates a qc-based decision support system . among other features, it includes a control of inhibition in individual samples which is extremely useful when working with difficult samples, such as environmental or plant samples. in this way, it helps the scientist to obtain reliable results in a fast and high-throughput manner and thus provides the basis for biologically meaningful data interpretation.

implementation
front-end of the web application is built in html, css and javascript. back end is written in php with extensive use of laravel framework. the data is stored and managed using mysql relational database management system . the application is fully functional in most popular web browsers  with enabled javascript.

the most recent quantgenius release is available at http://quantgenius.nib.si. the source code for quantgenius is freely available under the gnu general public license version  <dig> . all the application functionalities are freely available without login or registration. nevertheless, registration and login option have been implemented for users that wish to keep their datasets for later analysis.

in the application, data are organised as experiments, containing data for all the assays that were analysed in a sample set .

the quantgenius workflow features three main steps: 1) data import, 2) interactive calculation of target and reference genes copy numbers and normalization to reference genes with implemented qc-dss and 3) export of final results in a gene-sample matrix format . quantgenius enables a transparent overview of all calculations, including intermediate values and mathematical formulas used as well as qc-based decisions. all the formulas used for calculations are available in the additional file  <dig>  and a detailed user manual is available on the application website.fig.  <dig> quantgenius workflow. the data for the target and reference genes is imported and quality controlled. relative copy numbers are calculated using standard curve parameters and normalized. the final results are exported as a gene-sample matrix. the calculation steps are marked with bold, while the calculated parameters are listed below with regular letters. all the formulas used for calculations  are available in the additional file  <dig>  abbreviations: cq – quantification cycle, rel. - relative no.- number, std. – standard, qc – quality control, cv - coefficient of variation, cqextc – cq value of the extraction control, cqloq – cq value of the limit of quantification




RESULTS
platform-independent and consistency-checked data input
the application’s input is qpcr machine- and chemistry- independent. for each tested assay, sample names, cq values and relative copy numbers  are imported by pasting pre-formatted tab-delimited data into the input form. in this way, sample data analysed with one or two sample dilutions and any number of technical replicates can be processed. data for the standard curve, which can be either actual or relative copy numbers, are imported separately .

standard output files of the microfluidic qpcr platform biomark  can be converted to a format suitable for the import using the “fluidigm data prep tool”, available on the quantgenius website.

all imported data are automatically checked for consistency  to prevent wrong calculations due to incorrect imports .

copy number calculation and normalization to reference genes
in quantgenius, a standard curve quantification approach is implemented, which allows for the calculation of comparable copy numbers on multi-plate experiments, when the same standard curve is used on all plates. for optimal transparency of the process, the calculations are performed in several steps , differing slightly whether simple  or two-dilution analysis is selected. based on the standard curve parameters , sample target and reference gene copy numbers are calculated . in the next steps, replicate copy numbers are averaged and sample dilution is taken into account .

target gene copy numbers are normalized to reference gene copy numbers, or in the case of several reference genes, to their average . to avoid unequal contribution of the individual reference genes and to allow for quantification in the cases where data for one of the reference genes is missing due to qc issues, all the reference gene copy numbers are scaled to the average of the reference gene that was imported first .fig.  <dig> screenshot of the calculation of the reference copy numbers. an example of two reference genes  is shown. the second imported reference gene  is scaled to the average of the first reference gene imported and the average of both values is calculated. the calculations are performed for each dilution separately




user-guided quality control-based decision support system
the unique and novel feature of the presented application, quantgenius, is the implementation of an easy-to-use qc-based dss that enables robust analyses of quantitative biology data. it includes all critical parameters of qpcr qc, such as technical pipetting errors, nucleic acid extraction and reverse transcription yields, estimations of the detection and quantification ranges of the assays as well identification presence of inhibitors in the individual samples  <cit> . several qc parameters are calculated at different steps of the workflow . the qc stringency is user-controlled, based on the level of accuracy required for particular application . by changing the qc parameters all the data are instantly recalculated. moreover, the “clone experiment” option allows for analysis of the same experiment with different qc parameters and thus direct comparison of the effects that the parameter settings changes have on the final results.fig.  <dig> screenshot of the individual gene calculations. the calculations are done in three steps. 1) qc parameters cqloq, cqextc, slope range, and slope difference and calculation mode are defined by the user. 2) standard curve is reviewed for possible outlier reactions. 3) sample reactions are reviewed. the pipetting error  causes deviations from the predefined qc parameters . all formulas used for the calculations can be viewed 




quantgenius enables a transparent overview of all qc-related issues and decisions. highlighting of the values that fall out of the pre-defined qc thresholds enables the identification of the pipetting errors in the standard curve or target sample reactions as well as standard curve dilutions that are out of the quantification range which should all be manually removed by the user .

based on the implemented dss, the final result will be, in the case that the data is out of the quantification range, imputed or, if the calculated numbers are considered unreliable, not given. in both cases, warnings are issued, notifying the user about the qc issues. the decision tree slightly differs depending on whether simple  or two-dilution calculation approach is chosen  and hierarchically takes into account the following factors:fig.  <dig> quantgenius quality control-based decision support system . decision tree case of  simple  calculation and  two-dilution calculation. the following qc control steps are implemented hierarchically: 1) extraction control, 2) limit of detection 3) limit of quantification, and 4) individual sample efficiency of amplification control. based on the dss, the final result is calculated , modified  or not given  and warnings are issued. abbreviations: cq – quantification cycle, cqextc – cq value of the extraction control, no. – number, cqloq – cq value of the limit of quantification, dil. – dilution, qc – quality control, cv - coefficient of variation





extraction control. for each reference gene assay, cqextc, a cq value indicating a valid nucleic acid  extraction procedure is defined by the user ensuring that only good quality data is used for calculations. by default, the cqextc is set to  <dig>  therefore rarely affecting the quantification. based on the assumption that the reference genes are highly expressed, the users can, however, lower this threshold to identify outlier samples. if all the reference genes fail this criterion, the target gene final result is not calculated .


limit of quantification . for each target gene assay, the cq at the loq , specifying the lower limit of the quantification of the assay is defined by the user, either based on previous in-house validation data  or estimated from the experiment’s standard curve. on the other hand, the loq can be recognized by quantgenius as high variability  between the replicates’ copy numbers, arising from pipetting stochasticity, assuming that the true pipetting errors have previously been manually removed. in the simple calculation, the final result for samples below loq is imputed based on the cqloq and all sample reference gene data . in the two-dilution calculation, the loq qc step is performed in two steps: a) if the first dilution  is under loq, the final result is calculated as in the simple calculation , b) if only the second dilution  is under loq, the first dilution is used for the calculation of the final result .


limit of detection . if all reactions of the sample for a target gene are missing cq values, indicating that the target dna levels in the sample are under the lod of the assay, then the final result is imputed based on the cqloq copy numbers of all sample reference gene data . the final result is, therefore, a very small number  which makes further data analyses possible without additional data imputation. lod imputation is performed only for target genes, as the reference genes must be present well above the loq.


individual sample amplification efficiency control. this qc step is implemented only in the case of two-dilution calculation and is used to identify outlier samples with apparently inappropriate amplification efficiencies as compared to the one of the standard curve  <cit> . if the individual sample slope  falls out of the pre-defined slope range or its difference from the standard curve’s slope  is bigger than the pre-defined maximum slope difference, the reference or target gene copy numbers are not calculated for this sample .

export enabling further data analysis
all the data, imported sample names, quantities and cq values, intermediate calculations and qc parameters as well final results are available for the export from quantgenius to allow for further analysis and visualization in third-party software tools. all the data per individual gene can be exported in excel  format . on the other hand, final results for all the target genes in the experiment can be also exported in a form of a sample-gene matrix in tab-delimited.txt or.xls formats. in the latter, the results are complemented with the qc warnings, so the user can distinguish between values, calculated directly from the sample data or the imputed values.

comparison of features with advance qpcr analysis software tools
the quantification approach and crucial qc features of quantgenius were compared with similarly advanced software tools for qpcr data analysis: rest  <cit> , one of the first software tools for qpcr analysis, two popular commercial packages qbase+  and genex  as well as an open source tool dag expression  <cit> , one of the rare tools that uses standard curve based quantification . it is important to note that the compared software tools have additional features that are not included in quantgenius, such as qualitative qc parameters  or further steps in the data analysis pipeline such as statistical analysis, graph plotting etc. these features were not included in quantgenius as it is focused on the quantification aspect of the qpcr data analysis pipeline.table  <dig> comparison of selected features of quantgenius and other software tools

quantification method, use of multiple reference genes for normalization and implementation of qc factors in quantification are compared. std.curve – standard curve, ΔΔcq-e – efficiency corrected ΔΔcq method, replicates – replicate variability, extraction control – extraction efficiency, loq/lod imputation – identification and imputation of copy numbers that are under loq or lod, respectively, sample efficiency – individual sample efficiency estimate, gdna – gdna contamination correction




performance validation
the current version of the application was tested in-house for a year to detect and remove coding bugs. further, we have analysed  <dig> experiments from different projects, where  <dig> were set on 384-well plates and  <dig> on the fluidigm  <dig>  dynamic arrays. quantification and qc were performed in parallel in quantgenius and microsoft excel using preformatted formulas. a subset of the comparison is shown in the additional files  <dig> and  <dig>  respectively. using both approaches, all the intermediate and final copy numbers, as well as those of the calculated qc parameters, were identical.

use cases showing the importance of the quantgenius decision support system
to show the importance of proper qc in quantitative analyses we have reanalysed two datasets from different qpcr applications using quantgenius, a gene expression study and a genetically modified organism  quantification analysis.

for the gene expression use case, a subset of qpcr data from our previously published experiment  <cit> , analysing two target genes in the response of potato to virus inoculation. the raw data  and basic experimental details are available in additional file  <dig>  while the experimental details are available in the original publication  <cit> . three quantification approaches were compared:quantgenius two-dilution quantification with the default qc settings

standard curve quantification approach without any qc-dss

commonly used ΔΔcq approach  <cit> , using only one dilution of the samples




the relative copy numbers obtained in the three approaches are presented in fig.  <dig> and additional file  <dig>  the overall results of the methods correlate highly  for both target genes. nevertheless, the power of quantgenius is shown in the case of individual samples with low gene expression values and sub-optimal amplification efficiencies.fig.  <dig> importance of implemented qc-dss as shown in the gene expression use case. expression of two target genes  was analysed in mock- and virus-inoculated potato plants at one, three and six days post infection . ef- <dig> and cox were used for normalization  <cit> , . relative expression values obtained by quantgenius  are compared to the ones obtained using standard curve quantification without qc performed  and the ΔΔcq quantification approach . to get comparable values in the three approaches, the results of each approach were normalized to one of the samples  and then scaled to the average expression of the first experimental group . a arrows - examples of samples with cq values near loq showing high variability among the quantification approaches used. b arrows - examples of outlier samples with an efficiency problem detected in either the target or the reference gene where results are not calculated in quantgenius




the expression of the pr-1b gene was near the loq in the mock-inoculated samples , which resulted in high copy number variation  between different quantification approaches . with quantgenius, the copy number values below loq are imputed with a small value number that is in the range of values calculated for other samples near loq. the user is alerted with a warning and will take this into account when interpreting the results. on the other hand, in the samples where only more diluted reactions were under the loq, only the less diluted reactions were used for the quantification.

in both target genes, there were cases of inhibition of amplification in individual samples, resulting in outlier results, which are especially evident in the glu-ii gene results . in these cases, quantgenius does not calculate the final result and thus again increases the reliability of the outputs of the quantification.

the second dataset is from the gmo diagnostics, where the quantity the gmo  in the samples is quantified as a ratio of the transgene and reference gene  copy numbers, both calculated from the standard curve of the reference material with known gmo content  <cit> . in the presented example, strong inhibition for the both, the reference gene and the transgene assays in both of the analysed dna extractions from the same sample was observed which resulted in more diluted dna reactions having lower cq values than less diluted ones . without the qc, the calculated % of the gmo would have been ranging from  <dig> to 1090%, depending on the dna isolation and dilution used. on the other hand, in the quantgenius workflow, the results for this sample are not given, primarily because of unacceptable efficiency of the reference gene . for this sample, the dna isolation and qpcr analysis were repeated and it then passed qc and the gmo content was determined to be 33% .

discussion
the paper presents a web application for quantification of nucleic acids, integrating unique qc-based dss , built based on the acknowledged qpcr standards  <cit>  which ensure that only high-quality data is used for biological interpretation. most qpcr data analysis tools  have been designed with a simple experimental design. individual qc steps that are implemented in quantgenius are also included in other software tools . none, however, to our knowledge, uses individual sample efficiency estimates as a qc step. moreover, the application was built to be simple and intuitive and offers full flexibility for different experimental setups. although the same calculations, including qc, can be done in spreadsheet software such as microsoft excel, the use of quantgenius does not require manual interventions for either qc or data preparation for other analysis tools. combined with the import data consistency check-up, the use of quantgenius greatly reduces the risk of human errors when handling the data. the qc steps implemented in the dss are the ones critical for quantification, whereas the users need to perform initial  qc steps, such as checking fluorescence curves, qdna contamination, the efficiency of reverse transcription, non-template or other controls, prior to importing the data to quantgenius.

quantgenius is based on quantification using a standard curve  <cit> . although this approach is more robust and gives the user the biggest flexibility in the cases of suboptimal samples and/or assays  <cit>  and also eliminates the need for additional interplate calibration if the same standard curve is used on all plates  <cit> , it is implemented only in some qpcr data analysis tools . it was previously shown that with ideal samples and assays, the results of more commonly used ΔΔct and the standard curve approach are identical  <cit> , as was also confirmed by the presented case study, where the correlation of the quantgenius and ΔΔcq results was really high .

in quantgenius, normalization to several validated reference genes is enabled, as it is considered the gold standard for most of the experimental setups and is also recommended by the miqe guidelines  <cit> . still, the selection and validation of the reference genes should be performed beforehand by specialized tools .

lower copy numbers of the reference gene can indicate problems with dna/rna isolation or reverse transcription yields  <cit> , leading to unreliable quantification of target genes. the extraction control implemented in quantgenius eliminates such samples from further analyses .

depending on the biological system studied, the targets in individual samples may not be detected . moreover, low amounts of dna in the qpcr reaction can increase the measurement uncertainty due to the high variability of quantity estimations caused by the occurrence of stochastic effects, therefore only the reactions above the loq can be accurately quantified  <cit> . the reactions where cq values are not determined are treated differently in different analysis approaches: they are either excluded from downstream analysis, which makes further calculation impossible and can lead to unnecessary information loss or even false interpretation. alternatively, these reactions are assigned a maximum obtained cq value which leads to biased inference or they are imputed using different statistical models  <cit> . in the quantgenius data analysis scheme , the values below lod and loq are imputed taking into account the target gene copy numbers at the loq and average reference gene copy numbers, resembling the background correction implemented in high-throughput gene expression analysis methods  <cit> . therefore, the imputed values are comparable but appropriately lower than the ones within quantification range of the assay where the lod imputed values are lower than the loq imputed ones. in this way, the user can easily spot the imputed values when inspecting the resulting output matrix and take appropriate caution when interpreting such results as was shown in our gene expression use case . nevertheless, in cases, where the target dna is truly absent , the lod imputation may result in false “positive” result and in these cases the exported data matrix without the imputed values should be used for interpretation of the results.

low reproducibility of the cq values from technical replicates can be an indication of an unstable assay, a pipetting error or stochastic effects due to the low amount of dna in the reaction  <cit> . the latter is implemented in quantgenius, as an indication of below loq target dna amounts  <cit>  which allows for robust analysis.

there is currently no consensus on how sample specific pcr efficiencies should be calculated and used for robust quantification. although the individual sample amplification efficiencies determined from the amplification curves increase the random error of qpcr quantifications  <cit> , the individual sample efficiency determination has a great value for outlier detection  <cit> . however, as the reaction efficiency is both sample and assay dependent  <cit> , use of rna spike-ins is not the best option for individual sample efficiency. therefore, quantgenius workflow includes a simple control of pcr efficiency in individual samples by comparing the cq values of two dilutions of the same sample to identify outlier samples with suboptimal efficiencies. as quantification is in those cases not accurate, no result is given for those samples. the presented approach is associated with slightly higher cost of wet-lab analysis , but on the other hand it greatly increases the quality and reliability of the data, especially in samples where the presence of inhibitors is expected, such as plant samples, food and feed samples, environmental samples, microorganisms grown in complex media etc.  <cit> . this kind of outlier samples were also observed in our gene expression dataset  and in the gmo quantification use case . the default limits of acceptable individual sample efficiencies are quite loose, allowing for reliable detection of two-fold copy number differences. the stringency of this qc parameter can be modified depending on the application which will result in change of the quantification measurement uncertainty  <cit> . however, in matrices free of inhibitors , a simple  approach, which is also available in quantgenius, can be used safely.

to promote quantgenius use within the scientific community, the application was is registered in the elixir tools and data services registry   <cit> . future improvements are envisaged to automate data import, which is especially beneficial for the analysis of data generated by high-throughput platforms. moreover, the connection of the application database to other databases  will contribute to data management following the fair data principles  <cit> .

CONCLUSIONS
as opposed to black box solutions, quantgenius was designed by biologists with ease of use, flexibility and transparency in mind. it is an intuitive and easy to use tool for qpcr data organization, analysis and decision support in various qpcr applications. the integration of qc-based dss makes it unique and enables researchers to spend more time for interpreting the biology behind the results than analysing the data.

additional files

additional file 1: schema  of the database and data organization in quantgenius. 

 
additional file 2: equations used in quantgenius workflow. 

 
additional file 3: qpcr data import screenshot. 

 
additional file 4: example of the export of results and intermediate values for an individual gene. 

 
additional file 5: quantgenius performance validation: calculations in excel. 

 
additional file  <dig> experimental data of the gene expression use case. 

 
additional file 7: comparison of gene expression values calculated by quantgenius and other standard methods. 

 
additional file 8: gmo quantification use case. 

 


abbreviations
cqquantification cycle

cqextccq value of the extraction control

cqloqcq value of the limit of quantification

cvcoefficient of variation

dssdecision support system

gmogenetically modified organism

lodlimit of quantification

loqlimit of detection

qcquality control

qpcrquantitative pcr

rrsround-up-ready soybean

electronic supplementary material

the online version of this article  contains supplementary material, which is available to authorized users.

