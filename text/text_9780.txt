BACKGROUND
metagenomics involves collecting samples from an environment  and then extracting and studying the genetic material from the microorganisms present in these samples  <cit> . this approach is transforming microbiology, ecology, medicine, and other research areas investigating various microbiomes, allowing us to analyze for the first time microbial species, including those not culturable, at a level of detail not previously possible  <cit> . metagenomics sequence reads can be taxonomically classified to identify the microbes, or functionally classified  to identify the functional potential of the community. there exist two general approaches for characterizing the taxonomic content of environmental samples:  sequencing of pcr amplicons corresponding to phylogenetic marker genes ;  shotgun sequencing whereby all genomic dna in the community is sequenced. a drawback of the shotgun sequencing approach is increased cost, but advantages include the ability to gain insights into metabolism and gene function through functional classification, and the avoidance of potentially biased amplification steps  <cit> . furthermore, a notable subset of taxa cannot be captured by traditional 16s sequencing owing to divergent 16s rrna gene sequences  <cit> . this, combined with the continuing decrease in cost of sequencing, may result in shotgun metagenomics becoming increasingly used for the taxonomic classification of microbial communities.

taxonomic classification methods generally fall into four categories, reflecting their different strategies:  sequence similarity based methods, which use the results of a sequence similarity search against a database of a reference set of sequences,  sequence composition based methods, which are based on characteristics of their nucleotide composition   <cit> ,  hybrid methods which incorporate components of the first two, and  marker-based methods which identify species based on the occurrence of certain specific marker sequences. composition methods generate models from the reference organisms’ genomes, and will classify the input sequence reads based on which model fit the read best. they have had trouble with classifying reads of short length , with phymm being the first method published demonstrating reasonable accuracy at short read lengths  <cit> . sequence similarity based methods, on the other hand, perform very well at identifying reads from genomes within the reference database that they search against, even at read lengths as short as  <dig> base pairs  <cit> . however, many reads from metagenomics samples come from genomes that are not in any reference database  <cit> . similarity based methods have traditionally used blast  <cit> , and have been generally slower to run compared to composition based methods. hybrid methods combine the similarity approach and the composition approach, with the goal of improving classification or speed. for improving classification, scores may be combined from both the similarity portion and the composition portion of the method for each prediction  <cit> . another hybrid strategy, aimed at increasing speed, is to use the composition approach to narrow down the set of candidate organisms, and thus have the similarity search occur against a fraction of the original database  <cit> .

a related group of methods try to determine community composition from metagenomes by utilizing marker genes. these methods differ from methods that perform taxonomic classification, as they do not to try to classify all of the reads. instead, they focus on classifying only marker genes to try to determine the microbial community composition of the sample. most marker based approaches utilize universal genes. however, another approach, utilized by metaphlan, involves use of clade-specific marker genes  <cit> .

the first step in a marker based approach is to identify reads that hit to one of the markers. as the size of the reference database of markers these methods use is relatively small, these methods are comparatively quick to run. in addition to focusing on a limited set of markers, which greatly reduce the computational cost of analysis, these methods are not affected by differences in genome size. if the goal of the analysis is to identify the community composition of the sample, taxonomic classification methods are biased by genome sizes, as organisms with larger genomes will generate more reads. amplicon sequencing using the 16s rrna gene also suffers bias due to variability in 16s rrna copy number  <cit> . thus, marker based approaches using shotgun metagenomics sequencing data may provide the least biased relative abundance information for organisms in the community.

tools vary in several additional characteristics which may influence researcher’s choice
in addition to the class of method, there are many other characteristics which may affect the consideration of which method to use. for example, whether a method is available via a gui, command line, or web server can be an important consideration, as is whether the method can also perform functional  classification, or how much memory and compute time the method requires. in addition, some methods are limited to certain groups of microbes. some methods, such as amphora <dig>  <cit> , are limited to analysis of bacteria and archaea. others, such as phylosift  <cit> , can additionally predict viruses and eukaryotes. furthermore, some methods continue to be supported while others are not, and some eventually become unavailable or difficult to access.

another distinction that can be made is between methods which are rank-flexible, versus rank-specific. rank-flexible methods vary the rank at which reads are predicted by classifying each read to the lowest taxonomic level at which the given method is confident. an example of a simple rank-flexible method is the lowest common ancestor  approach, first used by megan  <cit> . this approach takes the set of taxa that the read hit in the similarity search , and assigns the read to the lca of this set. in contrast, rank-specific methods give the same rank predictions for all reads.

clade exclusion is an important technique to evaluate how well methods will perform on environmental samples
sequence similarity based methods perform very well when identifying query reads identical to genomes/sequences within the reference database that they search against. however, because the majority of microorganisms have not had their genome sequenced, in most environments many of the sequence reads that would be generated in a metagenomics experiment would be quite unrelated to any sequences that are in a reference database, or at minimum not identical  <cit> . thus, one of the approaches used in the evaluation of taxonomic classifiers is clade-level exclusion. this involves removing all sequences from a database at a certain taxonomic level and then evaluating the ability to make predictions at higher taxonomic levels. for example, if performing species level exclusion for pseudomonas aeruginosa, all pseudomonas aeruginosa genome sequences would be removed from the reference database and/or models of the methods being evaluated. then, the method’s ability to classify reads from pseudomonas aeruginosa at higher taxonomic levels  would be evaluated. such clade exclusion methodology is one way to avoid obtaining artificially high accuracy levels caused by the problem of testing and training with identical data.

the present work builds upon a previous evaluation performed without clade exclusion
there has been one previous evaluation of metagenomics bioinformatics methods reported that is not limited to examining a small set of tools with its own tool  <cit> . this study was an important first step in comparing many metagenomics classification tools; however, the microbial genomes used in the analysis were found in the reference databases and training sets of the methods evaluated. this means that the accuracy of the methods shown from the study will be considerably higher than when they are used to classify reads from organisms not in the reference databases or training sets. samples from most environments, such as soil, ocean, and freshwater samples, are very diverse and the majority of organisms existing in these environments have not been characterized. the human gut is an environment in which intense research interest has resulted in substantial effort to sequence relevant microbes  <cit> ; however, even in the human gut, it appears that the majority of species are not present in reference databases  <cit> . in addition, the previous comparison relied solely on in silico simulated reads. as sequence simulators cannot capture all of the factors that may affect read sampling in metagenomics, in vitro communities  are an important complementary set of data to evaluate methods on. an unpublished study was recently made publicly available, which includes an evaluation using in silico evolved genomes  <cit> . this approach, with its artificially evolved sequences, complements the clade exclusion approach taken here where we use both computationally simulated and real sequences. one additional notable difference is that their evaluation looked only at the phylum level classifications, whereas this study looks at classifications at all taxonomic levels. furthermore, they constructed their communities to contain only 5 % taxonomically novel . therefore, the results are not comparable to our evaluations using clade exclusion where all of the sequences are from genomes not in the reference databases of the methods, and where performance is based on classification at all taxonomic levels rather than just at the phylum level.

in the present study, a variety of metagenomic taxonomic classification methods are evaluated on mock communities simulated both in silico and in vitro . the performance of the methods in terms of their sensitivity, precision, and number of incorrectly predicted species are analyzed. in addition, the performance of the methods is compared as simulated read length is increased, and level of clade exclusion is varied. methods evaluated more fully were chosen to encompass the range of types of methods available, as well as based on their popularity, and amenability to clade exclusion. we demonstrate how the accuracy of shotgun metagenomics classification methods varies widely. no one program clearly outperformed others in all evaluation scenarios, rather the results illustrate the strengths and weaknesses of different methods for different purposes—information critical for researchers to be aware of when performing their particular analysis.

methods
simulation of metasimhc and freshwater in silico and in vitro datasets
two different microbial communities were used for this evaluation, both made up of diverse taxa for which completed genome sequences were available. the first was previously proposed as a “high complexity” dataset in  <cit> , and will be referred to as metasimhc. this was chosen since it has been proposed to be a reference dataset for analysis of methods, and consists of diverse microbial species covering several phyla of both bacteria and archaea. the second was chosen with the aim of having a set of species commonly found in freshwater, suitable as a control for a watershed metagenomics project we participated in  <cit> . this was done by identifying species that were common among several publicly available freshwater datasets , and will be referred to as fw . the organisms used in each of these datasets can be found in table  <dig>  both of these datasets were simulated using metasim  at sequence lengths of  <dig>   <dig>   <dig>  and 1000 bp, with each organism at 1x coverage. although the sets of sequences of differing read length were generated independently, they are generated at 1x coverage so the effects of sampling only portions of genomes that are predicted particularly well or poorly should be mitigated. no error model was used, because there was not an error model for illumina reads at the longer read lengths , and we wanted to be consistent as read length was varied. also, the in vitro dataset gives us data off of an actual sequencer which allows us to see how methods perform on data with real sequencing errors. clade exclusion was performed at the level of species, genus, family, order, and class. the fw dataset was simulated both with metasim  and an in vitro mock community . to construct the fw in vitro, the bacteria were grown up in pure culture, and then their dna were extracted and spiked in equal concentrations into sterile, distilled water for sequencing. all complete bacterial and archaeal genomes were downloaded from ncbi on june  <dig>   <dig>  for the creation of databases and supervised models used in the different methods. the numbers of genomes left in the databases and training sets of the methods in the evaluation scenarios are shown in additional file 1: table s <dig>  the datasets used in these evaluation scenarios have been deposited to the mg-rast database and accession numbers can be found in additional file 1: table s <dig>  and the number of reads simulated from each organism for the in silico datasets can be found in additional file 1: table s <dig>  note that while certainly test datasets could be constructed using a larger number of species, it is non-trivial to construct a similar in vitro, mock community dataset using a high number of species. we purposefully constructed our dataset to contain taxa with a variety of levels of divergence from one another, including closely related species . the latter helps evaluate the ability of methods to handle taxa prediction when closely related taxa are present.table  <dig> microbes used in the  <dig> simulated mock communities

metasimhca

agrobacterium
tumefaciens
bacillus
amyloliquefaciens

anabaena
variabilis
bacillus
cereus

archaeoglobus
fulgidus
burkholderia
cenocepacia

bdellovibrio
bacteriovorus
escherichia
coli

campylobacter
jejuni
frankia
sp.

clostridium
acetobutylicum
micrococcus
luteus

lactococcus
lactis
pseudomonas
aeruginosa

nitrosomonas
europaea
pseudomonas
aeruginosa

pseudomonas
aeruginosa
pseudomonas
fluorescens

streptomyces
coelicolor
pseudomonas
putida

sulfolobus
tokodaii
rhodobacter
capsulatus
streptomyces
coelicolor

ametasimhc is a test dataset of  <dig> diverse microbial genomes covering several phyla of bacteria and archaea proposed in  <cit> 


bfreshwater  is a set of bacterial genomes found in previous freshwater metagenomics studies 



because there is such a large difference in microbial communities  in terms of number of organisms, which organisms are present, their taxonomic novelty, and diversity in terms of abundance distribution, it is not possible to simulate communities that will be appropriate for all environmental communities. this is why we suggest researchers test their own mock communities that approximate their expected community.

laboratory preparation and sequencing of the mock freshwater in vitro community
bacillus amyloliquefaciens fzb <dig> , bacillus cereus , escherichia coli k <dig> , micrococcus luteus nctc  <dig> , pseudomonas fluorescens pf- <dig> , and pseudomonas putida kt <dig>  were obtained as freeze-dried stocks and used per recommended protocol to start cultures in prescribed media. burkholderia cenocepacia j <dig> was cultured in luria broth at 37 °c. frankia sp. cci <dig> was grown in liquid frankia defined minimal medium  in stationary culture at 30 °c for  <dig> week. pseudomonas aeruginosa ucbpp-pa <dig> was cultured in luria-bertani broth at 37 °c. rhodobacter capsulatus sb  <dig> was cultured on  <dig>  % yeast extract,  <dig>  % bactopeptone, cacl <dig>  and mgso <dig>  at 30 °c. streptomyces coelicolor a <dig> was cultured in  <dig>  % tryptone,  <dig>  % yeast extract, ph  <dig>  at 28 °c for  <dig> week. for each of the strains of bacteria, after they were plated on the appropriate media, single colonies were picked. these were cultured overnight in 3 ml of appropriate media at the appropriate temperature . frankia sp. cci <dig> and pseudomonas aeruginosa ucbpp-pa <dig> were cultured for several days until they reached stationary phase. the other bacteria strains were fast growing, so the starter cultures were diluted 1: <dig>  and grown with vigorous shaking  to saturation overnight. genomic dna was extracted from these cultures with the nucleospin tissue kit from macherey-nagel according to manufacturer’s instructions. for gram-positive bacteria, cells were pre-incubated with buffer containing 20 mg/ml lysozyme for an hour at 37 °c, followed by proteinase k at 56 °c until complete lysis was obtained. the library was prepared using a nextera xt dna sample preparation kit following the manufacturer’s instructions. this library was sequenced with a miseq platform using a v <dig> 500 cycles kit.

quality control of sequenced reads
trimmomatic- <dig>   <cit>  was used to  trim reads using a sliding window of  <dig> and phred quality score of q < = <dig>  followed by  checking if any of the last  <dig> bases had a q < = <dig>  and if so removing up to that base, and finally  filtering out any reads with length < <dig> bases. after quality control, there were  <dig>  reads with an average length of  <dig> nucleotides.

evaluation of methods and metrics
performance metrics used to evaluate different software are sensitivity, precision, taxonomic distance, and running time. sensitivity and precision are calculated based on the numbers of true-positives , false-positives , and false-negatives . true-positives are the number of reads assigned correctly, false-positives are the number of reads assigned incorrectly, and false-negatives are the number of reads unassigned. sensitivity was calculated as tp/, and precision as tp/. taxonomic distance was calculated from correctly assigned reads as the average number of ranks above the best possible rank the assignment could be made at, and running time as the number of minutes taken for the program to complete classification. for sensitivity, precision, and taxonomic distance, the values were averaged over all the species in the test dataset. this gave equal weighting to all of the species in the datasets; otherwise, the species with larger genomes  would have a larger influence on the scores. for the in silico datasets, reads were categorized as correctly assigned  if they classified to a node  that was anywhere in the path from the correct species to the superkingdom level  of the ncbi taxonomic tree, and as incorrect if the read was assigned to a node that was not in this path. in the case where overpredictions were considered correct, the taxonomic level that was used to determine if a read was classified correctly was the best possible correct level that could be predicted. for example, under species clade exclusion, reads would still be classified as correct if they were in the correct genus but classified to an incorrect species. although most of the methods evaluated were rank-flexible in their predictions, rita and phymmbl are rank-specific, and thus were only shown for the evaluation where overpredictions were considered correct. although rita does have a rank-flexible mode, it requires having 16s rdna profiles of a community. phymmbl provides a confidence score which in theory could provide a cut-off for which rank to assign the reads; however, we would have had to choose the cut-offs ourselves, and previous researchers have found confidence scores to be high for a false positive dataset  <cit> . mg-rast was evaluated due to the popularity of the method, but because it does not allow the user to create custom clade exclusion reference databases, it is an example of a method where we were only able to evaluate it without clade exclusion.

additional file 1: table s <dig> lists the version numbers of all of the methods evaluated. all methods were run with default parameters except for filtered kraken  <cit>  which was run using the kraken-filter script with a threshold of  <dig> , which moves assignments up to successfully higher levels of the taxonomic tree until the threshold is reached. this separate analysis was done because we noticed that kraken was tending to overclassify reads and there was an option that would help assign reads with greater confidence. note that some methods have variations in the way they can be run. for example, some methods can take a variety of similarity search programs as input, or have the option to utilize paired-end sequence read information. in some cases these variations had relatively small differences in sensitivity, precision, and taxonomic distance of methods, and in these cases only one of the variants was presented in the figures to be concise. briefly, megan <dig>  <cit>  has the option to allow the use of paired-end information from sequence reads, and the paired-end version is presented; metaphyler  <cit>  can use blastx, blastn, or a combination of the results, and the results for the blastx/blastn combination are presented; megan <dig> and discribinate  <cit>  have the option of taking results as input from either rapsearch <dig>  <cit>  or blastx, and the rapsearch <dig> versions are presented. rapsearch <dig> is an alternative to blast, which we found to run over  <dig> times faster than blastx, with comparable accuracy .

RESULTS
table  <dig> provides an overview of methods and their features, grouped by their class. note that it does not include all methods available, and there are more methods being continually published. included is the number of citations each method has received, to give an indication of how much of an influence or use each method has. however, it should be noted that several of the methods have capabilities beyond just classification, such as comparisons between samples and visualization, and thus may be cited when used for purposes other than classification. also, it is worth noting that methods that were published earlier may be highly cited, yet newer methods often improve upon their strategies. as discussed below, even with accuracy assessment aside, the different method properties can have different advantages under certain analysis scenarios and so are summarized here. notably, many methods cannot undergo full, robust evaluation with clade exclusion, since their reference databases cannot be manipulated, and so methods chosen for full evaluation of the accuracy were limited to ones that allowed it.table  <dig> list of metagenomics sequence classification methods and their characteristics sorted by class of method

discribinate d

n/a not applicable, imm interpolated markov model, nb naive bayes, svm support vector machine, k-nn k-nearest neighbour, rai relative abundance index, dbc signature de bruijn chain signature, cv composition vector


astandalone refers to whether the program can be run locally


bsome methods have had several publications, with later publications regarding improvements on functionality. in these cases the most recent publication was listed, with the first time the method was published in brackets


cnumber of citations is based on web of science as of april  <dig>  2015


ddiscribinate is the successor for sort-items so they were included in the same row



several methods vastly overestimate the number of species present
to assess accuracy, first the quality of the assignments made by different methods was examined with no clade exclusion, so that as many representative methods could be comparatively examined as possible. the sensitivity, precision, and taxonomic distance  were computed on the metasimhc dataset with no clade exclusion. results were as expected, with all methods generally showing a relatively high sensitivity and precision. the exceptions are tacoa  <cit> , which is known to perform poorly on short reads, and metaphyler, which is a marker based method and thus only classifies a small proportion of the reads, resulting in low sensitivity . next, the numbers of incorrectly predicted species, based on different thresholds of percentage abundance in the predicted community were tabulated . it is notable that several methods greatly overpredict the numbers of species present, considering that the sequences the methods are trying to classify exist in the reference databases or training sets. under genus clade exclusion conditions , the number of incorrectly predicted species increases further for any method that makes incorrect predictions at the examined taxonomic level.

sensitivity and precision vary widely between methods, with sensitivity generally decreasing at higher levels of clade exclusion and increasing with read length
the quality of the assignments made by the different methods was further examined under clade exclusion scenarios at different taxonomic levels. sensitivity and precision were computed on the metasimhc dataset  and found to vary notably. to examine in greater detail what led to the differences in sensitivity and precision of these methods, the taxonomic distance for each method was evaluated . furthermore, the proportion of reads assigned at each taxonomic rank was determined. an example of the results under the genus clade exclusion scenario is shown in fig.  <dig>  with the data for the rest in additional file  <dig>  additionally, the numbers of reads miss-assigned and correctly assigned or overpredicted for each rank were compiled . many of the methods assign a considerable proportion of reads to the species level, when species level assignment is impossible since they are excluded from the database. also notable is that tacoa assigns the majority of reads to the superkingdom level, so the method will be of limited use for those interested in more specific taxonomic ranks, at least at these shorter read lengths.fig.  <dig> performance as clade exclusion level is varied. sensitivity  and precision  on the metasimhc dataset of simulated 250 bp reads. there is a wide range of variability in the sensitivity and precision of the methods with sensitivity tending to decrease as the level of clade exclusion moves from species to class. performance is calculated based on proportion of reads appropriately assigned and averaged per genome 

fig.  <dig> distributions of assignments to taxonomic ranks. proportion of reads assigned at each taxonomic rank on the metasimhc dataset of simulated 250 bp reads under genus clade exclusion . although the lowest possible correct rank is family, many methods still classify the majority of reads at the species level. carma <dig> and discribinate are slightly more conservative, classifying a large number of reads at the family or order levels, whereas tacoa is extremely conservative, classifying the majority of the reads at the superkingdom level



in some cases, overpredictions  are less problematic than incorrect predictions . thus, sensitivity and precision were recalculated after reclassifying overpredictions as correct classifications . there was notable increase in sensitivity and precision for methods such as megan <dig> and metabin which are less conservative in their predictions. for more conservative methods such as carma <dig> and discribinate, there was little change.fig.  <dig> performance as clade exclusion level is varied with overpredictions  classified as correct. sensitivity  and precision  on the metasimhc dataset of simulated 250 bp reads. methods such as megan <dig> which classify many reads at lower taxonomic levels see a considerable increase in performance, whereas more conservative methods such as carma <dig> see only a slight improvement. performance is calculated based on proportion of reads appropriately assigned and averaged per genome 



the changes in sensitivity, precision, and taxonomic distance as read length increased was then examined. this was done on the metasimhc dataset . sensitivity followed the expected trend of increasing along with read lengths; however, precision and taxonomic distance showed no clear trend and remained relatively unchanged.

analysis of the fw dataset reveals similar performance between in vitro data and in silico data, and between the fw and metasimhc datasets
a comparison between the fw in silico versus in vitro datasets is illustrated in fig.  <dig> under species clade exclusion, and in additional file 2: figure s <dig> without clade exclusion. for the in vitro dataset, as it is not possible to determine which read absolutely should be associated with which organism in the mock microbial community, a hit to any of the taxa in the fw dataset was considered correct. in addition, this meant the sensitivity, precision, and taxonomic distance was based on all of the reads classified rather than averaged over all taxa. the results are similar between the in vitro and in silico communities, suggesting that for this simple community the methods evaluated are relatively robust to illumina sequencing errors with the sequencing technology used. a comparison of results between metasimhc and fw in silico revealed that the relative performance of methods remained similar when analyzing these two different datasets . additionally, the numbers of incorrectly predicted species, based on different thresholds of percentage abundance in the predicted community, were again tabulated for the in vitro data . many of the methods incorrectly predict hundreds of species, with metacv incorrectly predicting  <dig> species, although after filtering out low abundance predictions the numbers of incorrect predictions were drastically reduced. under genus clade exclusion conditions , the number of incorrectly predicted species increases further, and even after filtering out low abundance predictions there were sometimes considerable numbers of false species predictions. the number of incorrectly predicted species is higher for the in vitro data relative to the in silico data . the greater number of incorrectly predicted species is particularly notable in some methods that perform very well on the in silico data such as megan <dig> blastn, which goes from  <dig> incorrectly predicted species to  <dig>  the performance for each of the component genomes on all in silico datasets is provided in additional file  <dig> fig.  <dig> performance of fw in silico versus fw in vitro. sensitivity  and precision  of methods on the fw dataset comparing the performance on the in silico community versus the in vitro community under species clade exclusion. the results are similar between the in vitro and in silico communities, demonstrating that methods appear to be relatively robust to real illumina sequencing errors for this simple community. performance is calculated based on proportion of reads appropriately assigned and averaged per genome 

fig.  <dig> performance of metasimhc compared to fw in silico. sensitivity  and precision  of methods on the metasimhc dataset compared to the fw in silico of simulated 250 bp reads. values are averaged over all levels of clade exclusion from species to class. although the microbes in the dataset changed, the relative performance of the methods remains very similar. performance is calculated based on proportion of reads appropriately assigned and averaged per genome 

discribinate rapsearch2c
phymmblc
tacoac

ausing the fw in vitro dataset of sequenced reads from  <dig> species


ba cutoff of > × %, for example  <dig>  %, would indicate that only species with a predicted abundance of at least x % of the total set of predictions were considered. correctly predicted species are any of the  <dig> species that were used to simulate the reads in the dataset, whereas any other predicted species was incorrect


cthese methods do not predict to the species level at this read length . see additional analyses at other levels of clade exclusion

discribinate rapsearch2c
phymmblc
tacoac

ausing the fw in silico dataset of sequenced reads from  <dig> species


ba cutoff of > × %, for example  <dig>  %, would indicate that only species with a predicted abundance of at least × % of the total set of predictions were considered


cthese methods do not predict to the species level at this read length . see additional analyses at other levels of clade exclusion



there is substantial variation in the computational cost of different methods
to evaluate how long the various methods took to run,  <dig>  reads of  <dig>   <dig>   <dig> and 1000 bp, and an additional  <dig>  reads of 250 bp were simulated using the metasimhc dataset. the time taken by the methods to complete an analysis of these sequences varied widely, and nearly all methods scaled roughly linearly with both read length and number of reads on our datasets . sequence similarity based methods that rely on blastx take considerably longer than all other methods except tacoa, taking over 24 h for just  <dig>  reads of 250 bp under the cpu conditions in the test . at the other extreme, kraken and clark took less than  <dig> min to classify all of the reads.

discussion
all of the methods analyzed performed very well in terms of sensitivity and precision when the query sequences were in the reference databases . of course, this type of analysis would be expected to give potentially artificially high accuracy values since one is essentially evaluating using test data identical to the reference/training data. under this type of analysis scenario, the more informative metrics to examine are taxonomic distance and the number of incorrectly predicted species. notably, several methods substantially overpredicted the number of species present in the simulated communities. this included popular methods such as mg-rast and megan <dig>  however, most of these incorrectly predicted species are predicted at a very low abundance. by setting a threshold to filter out low abundance predictions, the number of incorrect predictions can be considerably reduced. the thresholds presented here are not intended as suggestions, but rather to demonstrate the principle of using thresholds to filter out incorrect predictions. microbial communities in certain environments are very complex, such as those found in soil  <cit> . these environments, which are very diverse and contain a large number of organisms, would have a large proportion of the microbes found at less than 1 % of the total abundance of the community, and thus a 1 % filtering threshold would filter out many of the microbes actually in the metagenome. if thresholds are used, they should ideally be chosen based on a mock community control that reflects the anticipated level of diversity and complexity expected in the metagenomics analysis being performed. if the goal is to choose thresholds based on relative abundance, genome size of the organisms would also be useful to take into account. otherwise, if two organisms are present in the community at low levels but one organism’s genome is much bigger, the organism with the smaller genome may get filtered out while the organism with the larger genome does not, due to greater number of reads from the larger genome. it is important for researchers doing metagenomics projects to know the level of precision of the method that they are using to have an idea of how well they can trust the taxa predicted at lower abundance. there is a trade-off between finding all of the taxa that exist in the sample, and confidence in the prediction of the taxa. two ways to adjust this trade-off are to choose a more precise  method, or to alter the minimum abundance threshold, with only the taxa over this abundance threshold being reported. some methods already have a way of choosing this threshold. for example, megan <dig> by default requires at least  <dig> reads to hit a taxon before the taxon is reported. the reads that are initially assigned to a taxon with less than the chosen threshold number of reads are then pushed up the taxonomy until they reach a taxon with a number of reads assigned to it that is over the threshold. however, when many reads are analyzed, overprediction will still occur and we have found for our analyses that it is necessary to use an additional threshold for removal of low abundance reads that are likely false predictions for such methods. ideally this threshold may be chosen in part from an analysis of an in vitro mock community sample—an important experimental control in any metagenomics analysis. such evaluation of methods using real sequence data also acts as an additional important control regarding other aspects of metagenomics sequencing pipelines.

as demonstrated in fig.  <dig>  the sensitivity and precision of methods vary dramatically. methods show a general trend of decreasing sensitivity as the rank of clade exclusion increases. this is expected as the sequences left in the database will become increasingly divergent, and the scores of the matches, if any, will decrease. there is a notable decrease in performance for methods relying on sequence composition or nucleotide-based blastn similarity searches, versus the protein/amino acid sequence-based blastx and rapsearch <dig> similarity based methods. this confirms what has been reported previously, that sequence composition based methods have lower performance than sequence similarity based methods at shorter read lengths  <cit> . blastn is likely outperformed by amino acid-based similarity approaches under clade exclusion because nucleotide sequence search is well known to be less sensitive for more divergent sequences due to its lower number of different characters .

the differences in performance between methods can be partially explained by the distribution of taxonomic ranks that they assign reads to. as seen in fig.  <dig>  carma <dig> and discribinate are assigning reads more conservatively; that is, they are assigning much fewer reads to the lower taxonomic ranks. many of these lower level predictions of other methods are in fact overpredictions, as demonstrated by their large increases in sensitivity and precision between figs.  <dig> and  <dig>  due to the way we evaluated methods, the most conservative methods will show the highest sensitivity and precision, but may not be making classifications at specific enough taxonomic ranks to be useful. tacoa, for example, shows high sensitivity and precision, yet makes classifications at very high taxonomic ranks that would not be useful for most researchers.

not surprisingly, the sensitivity increases for methods as read length increases. the most dramatic increase appears to be between read lengths of  <dig> and 250 bp. thus, when choosing a sequencing technology, it may be important to try and obtain a sequence read length of at least around 250 bp. the precision and the taxonomic distance of methods remained relatively unchanged. this was likely due to any increased performance in precision and taxonomic distance offset by additionally classified reads  with greater dissimilarity to sequences in the databases of methods, which would have poorer performance in terms of precision and taxonomic distance.

our comparison of the in silico to the in vitro freshwater community showed similar results in terms of relative performance of the methods. this gives us some confidence in our results of the other in silico simulations, as well as demonstrating the robustness of the evaluated methods to real sequence errors for this simple community. however, this would not necessarily generalize to more diverse communities, or other sequencing technologies. the sensitivity and precision of the methods followed the trends seen in the metasimhc in silico evaluation, although filtered kraken showed somewhat lower relative precision. upon further analysis, this appeared to be due to the nature of the way precision was calculated in this comparison. for the comparison to be done fairly between the in silico and in vitro community, the metrics were based on all reads rather than the average for all organisms. filtered kraken seemed to stand out in that for most organisms it classified few of the reads, and the ones it classified were mostly correct. however, for two organisms , the majority of the reads were classified incorrectly. this means that because more of the reads of e. coli and b. cereus were classified than the other organisms, their  classifications had a relatively large influence on the precision. the numbers of genomes/taxa in the mock communities was small, relative to the anticipated number of species in most real metagenomic analyses, so abnormal results from individual genomes could have a large impact on the results, as seen here with filtered kraken. it is also notable that e. coli and b. cereus, mainly due to historical reasons, come from regions of the taxonomic tree that are not reflective of the typical case for many environments; genomes with high sequence similarity and composition in this part of the tree are classified as the same species, whereas if they were found in other parts of the tree they would be classified as different species or genera  <cit> . thus, species that are not yet discovered will not be classified in a similar manner to the genomes in escherichia or bacillus, and so the performance of methods on these genomes likely does not reflect performance on as yet undiscovered microbes in metagenomics samples. however, it must be emphasized that there is no one mock community dataset that can best evaluate all metagenomics software. key is for researchers to design mock communities for evaluation that are suitable for their experiment, and use this published analysis to appreciate the types of issues they should watch out for.

the differences we saw in computational cost of the methods were substantial. although we only ran a few small test datasets of thousands of reads, we were able to clearly show very large differences in computational cost of the methods. current metagenomics datasets often include millions of reads; without access to large amounts of compute power, many researchers will not find it practical to utilize blastx based methods for illumina sequence sized data sets as are currently produced. the need for a more rapid alternative is already being addressed by such methods as rapsearch <dig>  <cit> , last  <cit> , pauda  <cit> , and diamond  <cit> . notably, rapsearch <dig> shows similar, or in some cases even increased, performance relative to the same methods using blastx, while requiring much less time to run . many methods provide the option of running multiple threads, so access to additional processors will allow the methods to run substantially quicker. furthermore, for most methods reads are classified independently from one another, so files of reads can be broken up into multiple smaller files and each file run on a separate processor, and the results of the classifications combined. in addition to computational cost, the amount of ram used by different methods varies considerably. both kraken and clark require large amounts of ram, but do provide reduced standard databases for users with low-memory computing environments . certain methods also allow users to adjust settings to allow trade-offs between speed, accuracy and ram usage, such as the sampling factor value in clark. a final consideration of computational resources when choosing a method is the amount of disk space that a method requires. the databases used by some methods require relatively large amounts of disk space, such as the standard database of kraken which requires at least 160 gb of disk space. another aspect that may affect method choice is the relative ease of generating new databases for the methods. certain methods rely on the results of a similarity search, and expanding the database is a relatively simple process of generating a new database for that similarity search, such as blast. however, other methods may require substantial computational resources that researchers may not have access to. for example, the authors of gottcha state that the creation of a database from the  <dig> prokaryotic genome projects available in  <dig> required 2 tb of ram. other methods, such as many online only methods, do not even allow the modification/expansion of the database.

protein sequence similarity-based methods  perform very well in clade exclusion scenarios but do not perform as well as nucleotide based methods when there is no clade exclusion. this is likely because a proportion of microbial genome sequence  are non-coding. protein similarity-based methods still have a relatively high sensitivity, generally > <dig>  and, as noted in  <cit> , this is due to many reads overlapping at least partially with a coding region. this explanation makes sense with our finding that as read length is increased, sensitivity of the aforementioned methods increases , as it would be less likely that a longer read would cover only non-coding regions. a quick examination of these incorrectly classified reads confirmed that they were the non-coding regions of the genomes, in many cases rrna genes.

the results presented should guide researchers to the choice of method that best fits their research question and computational resources. clearly, certain methods perform well in certain situations. kraken, filtered kraken, and megan <dig> blastn perform exceedingly well when there is no clade exclusion, yet their sensitivity is low when there is clade exclusion. however, filtered kraken classifies only a small percentage of reads when the species present in the dataset is not in the database. for example, filtered kraken classifies less than 8 % of the reads under genera exclusion . a strategy researchers may therefore use is to take their dataset and first run it on filtered kraken, followed by running the reads not classified by filtered kraken on a more conservative method such as discribinate rapsearch <dig>  filtered kraken would classify the reads from genomes in the reference database, while leaving the majority of reads from genomes not in the reference database unclassified. then, discribinate rapsearch <dig>  which will assign a much greater proportion of reads from genomes not in reference databases, could be run on the unclassified reads. if a conservative method such as discribinate rapsearch <dig> is run alone, it may miss many of the assignments of known genomes to the species rank, due to its tendency to make assignments at higher ranks. however, in some cases, such as when analyzing less well characterized microbiomes  the use of such conservative methods could be entirely appropriate. the pipeline idea of combining methods is integrated into some methods like rita, which first identifies a highest-confidence set of predictions, then subjects the sequences not yet classified to a series of downstream classification steps. carma <dig> performs well in both the no-clade exclusion scenario  as well as the clade exclusion scenario. however, carma <dig> takes a considerable time to run, and may not be computationally feasible for those with large datasets and without access to notable compute power. another technique involving combining methods would be to use multiple methods and look for consistent assignments among methods  <cit> . depending on the type of analysis, this could increase precision and confidence in the assignments, although at the cost of sensitivity in most cases and run time .

the test datasets used in this evaluation are limited in their complexity and diversity, as well as the number of reads simulated. for example, millions of reads are often sequenced for metagenomics samples, while our datasets were smaller, containing tens to hundreds of thousands of reads. furthermore, many environments sampled are far more complex and diverse, containing a much larger number of microbes with varying relative abundance, such as soil or the human gut. our analyses were also either on in silico simulated communities or communities sequenced with a single sequencing technology. the aim of this research was not to recommend any specific method, but to raise awareness of the advantages and disadvantages of different methods and issues in metagenome analyses. this evaluation highlights that there are large differences in methods on even the relatively simple communities used for our datasets, such as number of organisms predicted, sensitivity and precision, how specific the classifications tend to be , and computational resources required to run. however, other factors such as the diversity and microbes present in a community, and the sequencing technology used, will also affect the performance of the methods. additionally, certain tools may have advantages and be particularly useful for specific environments. for example, some tools contain genomes in their databases that are not present in refseq, while most methods use refseq exclusively for their databases. an example of this is metaphlan, which includes many draft genomes from the larger human microbiome project   <cit> , and thus may be particularly useful for human microbiome samples. metagenomics as a field is expanding rapidly. new tools are needed to classify the sequences obtained from these studies. there is a large need, and lots of interest in this, as evidenced by the large number of methods released over the past few years. however, it is non-trivial to perform an evaluation of methods. this is due to the sheer number of metagenomic methods available, the difficulty in setting up some of these methods, and the challenge in performing robust evaluation techniques such as clade exclusion or leave-one-out evaluation. furthermore, methods only available on the web are generally unable to be thoroughly evaluated as in many cases they do not allow the use of custom reference databases or training sets, and sometimes limit the number of reads that can be uploaded. to address these difficulties, an initiative called the critical assessment of metagenomic interpretation  has been initiated  <cit> . this community-led initiative will have researchers run their own methods on data sets made up of unpublished microbial genomes. this will be a valuable contribution to methodology assessment, but researchers are still encouraged to use mock microbial communities as controls for their own particular analyses, especially mock communities that reflect the types of microbes, diversity, and complexity they expect to see in their study. while cami will provide a useful additional comparative evaluation of methods, one should always perform a metagenomics analysis using appropriate controls to best refine methodology and any threshold cutoffs suitable for the specific analysis needs.

another issue is that there does not seem to be a consensus on the way to evaluate performance. some researchers consider classification of a read to a taxonomic level more specific than what is correct  as assigned correctly . other researchers, however, classify these overprediction assignments as false positives or mispredictions . depending on the research goal, one may prefer a more liberal or conservative method. for example, if a researcher is interested in comparing the genera in one metagenomics sample to another sample, overpredictions that are incorrect at the species level will not matter if they are correct at the genera level. the more conservative method may assign the same reads to the family level, and will thus completely miss the relevant taxa. on the other hand, if a researcher is interested in taking all of the predictions at all taxonomic ranks, they may make erroneous conclusions that a specific species is increased in one sample over another if it is just an overprediction. it should also be stressed that many methods allow flexibility in the parameters used, so it may be possible to tune a method to be more or less conservative. however, some parameters cannot be changed, and there are fundamental differences in the ways reads are classified by different methods. for example, megan <dig> and mg-rast make assignments based on bit-score as the sole parameter for judging significance. other methods, such as discribinate, carma <dig>  and metaphyler, employ additional measures such as alignment parameter thresholds and/or a reciprocal blast search step, which have been shown to improve the accuracy of taxonomic assignments in certain scenarios  <cit> . for example, using these methods a read from a novel pseudomonas species with a single hit over the bit-score threshold to pseudomonas aeruginosa may not align well enough to be assigned to the species level based on the additional alignment parameters, and thus could be assigned correctly to pseudomonas. however, in megan <dig> or mg-rast the read would pass the bit-score threshold and because there were no other hits, it would be assigned directly to pseudomonas aeruginosa.

again, careful examination of controls  may provide insight into the best method to use and suitable threshold cutoffs for low abundance reads, especially if that mock community includes a suitable level of diversity and/or includes species expected in the metagenomics analysis. developers of new methods are encouraged to enable their method to be evaluated using customized reference datasets, including clade exclusion-based analysis, to enable robust analysis of their method.

CONCLUSIONS
there has been a real need for a comprehensive evaluation of metagenomics classification methods, due to the notable number of new methods being released. in this case we have focused on taxonomic classification, for which an expanded comparative analysis was needed, to build on previous assessments and include more clade exclusion-based analysis. for the methods we analyzed, there is no single method that stands out as superior to all others, as there are a wide variety of characteristics in which the methods differ—characteristics that may make them more suitable for certain research group infrastructure, and research projects, than others. few researchers will have the time to evaluate methods robustly themselves, so may just use the method which is most popular or easiest to use, which would not necessarily be well suited for their particular computational resources and/or goals. this evaluation explains some of the issues researchers should consider when choosing an analysis approach for their metagenomics project, and reveals that very misleading results can occur, in particular notable overprediction of the number of taxa and/or missed taxa, if an inaccurate or unsuitable analysis approach is used. the results from this evaluation will hopefully help guide researchers’ decisions in selecting appropriate analysis methods suitable for their metagenomics studies. as new methods are developed, further evaluations will need to be performed, including with a reference dataset like metasimhc, and/or the cami approach. this study provides a model for such analyses to compare method accuracies and benefits, and highlights criteria that should be evaluated. it would be very helpful for evaluation purposes if method developers would allow their method’s reference databases to be manipulated, to permit analyses like clade exclusion, to avoid biases that can occur when no clade exclusion is performed . regardless, researchers are strongly encouraged to include appropriate negative and positive controls for their metagenomic experiments, including appropriate in vitro mock communities reflecting their expected type of data  to help fine tune their methodology as appropriate for their specific experiment. robust metagenomic data analysis is absolutely critical at this stage of the development of microbiome research as a key research area. microbiome research promises to be widely applicable to many, studying human health, the environment, agrifood, mining and other natural resource management, but it will only be valuable if high-quality, careful analysis is performed.

availability of supporting data
the data sets supporting the results of this article are available in the mg-rast repository  and accession numbers can be found in additional file 1: table s <dig> 

additional files
additional file 1: supplementary tables. 
table s <dig>  number of genomes left in the reference databases and training sets of the methods used in the evaluation scenarios. table s <dig>  datasets used in the evaluation scenarios and their accession numbers. table s <dig>  number of reads simulated for each organism in the in silico datasets. table s <dig>  methods that were the focus of this evaluation and their version numbers. methods were run with default parameters except for what we called filtered kraken which used the kraken-filter script with a threshold score of  <dig> . table s <dig>  number of correctly and incorrectly predicted speciesa for different thresholdsb without clade exclusion, illustrating how some methods vastly overpredict the number species, even when the true number of species is low . table s <dig>  number of incorrectly predicted speciesa for different abundance thresholdsb with genus clade exclusion. table s <dig>  number of incorrectly predicted speciesa for different abundance thresholdsb with genus clade exclusion. even more incorrectly predicted species are predicted under these conditions versus without clade exclusion. 

additional file 2: supplementary figures. 
figure s <dig>  sensitivity and precision with no clade exclusion. performance of methods on the metasimhc dataset of simulated 250 bp reads. figure s <dig>  taxonomic distance of methods on the metasimhc dataset of simulated 250 bp reads with no clade exclusion. figure s <dig>  taxonomic distance of methods on the metasimhc dataset of simulated 250 bp reads with various level of clade exclusion. figure s <dig>  distributions of misassigned  and correct/overpredicted assignments  to each taxonomic rank on the metasimhc dataset of simulated 250 bp reads under genus clade exclusion. figure s <dig>  performance as read length is varied. sensitivity , precision , and taxonomic distance  of methods on the metasimhc dataset simulated at lengths of  <dig>   <dig>   <dig>  and  <dig> bases with genera clade exclusion. figure s <dig>  performance of fw in silico versus fw in vitro without clade exclusion. sensitivity  and precision  of methods on the fw dataset comparing the performance on the in silico community versus the in vitro community. figure s <dig>  comparison of running time. running time for the various methods was calculated on a metasimhc dataset of  <dig>  simulated reads of various read lengths , or  <dig>  and  <dig>  reads of 250 bp . 

additional file 3: 
the proportion of reads assigned at each taxonomic rank on all
in silico
datasets. 

additional file 4: 
the numbers of reads misassigned and correctly assigned  for each rank on all
in silico
datasets. 

additional file 5: 
the performance for each of the component genomes on all
in silico
datasets. 



competing interests

the authors declare that they have no competing interests.

authors’ contributions

map and fslb conceived the work. map created the in silico mock communities and performed the analysis. map and tvr wrote scripts to create the clade exclusion scenarios. rl created the in vitro mock communities. map wrote the manuscript, with revisions and contributions by tvr, rl, and fslb. all authors read and approved the final manuscript.

