BACKGROUND
gene network estimation from time series gene expression data is a key task for elucidating cellular systems. thus far, wide variety of approaches have been proposed based on the vector autoregressive  model  <cit> , the state space model  <cit> , and the dynamic bayesian network  <cit> . recently, time series gene expression data on multiple conditions aiming at analyzing effects of cell treatment such as drug dosing and heat shock are available. we here assume that some gene regulations are disrupted but many of the gene regulations do not change due to some treatment of interest, and try to find a small number of changes on regulations as keys for elucidating effects by the treatment.

a possible way for finding changes on regulations is to estimate networks from two data sets separately and then compare their structures. however, due to the limited length of time series data  and unignorable measurement noise, networks are estimated with high error rates and the estimation errors cause the serious failure on identifying changes on regulations. thus, approaches using two time series data in an efficient manner are strongly demanded. also, widely used statistical methods such as the var model and dynamic bayesian network assume equally spaced time points in time series data. however, observed time points on usually available time series data are not equally spaced  <cit> , and approaches that can handle unequally spaced time series data in a theoretically correct way should be considered.

we propose a new statistical model that estimates gene networks on two different conditions in order to identify changes on regulations between the conditions. as the basis of the proposed model, we employ the state space representation for var model , in which observation noise is considered between the measured or observed gene expressions and the true gene expressions in observation model and gene regulations between true gene expressions are considered in the system model  <cit> . the var-ssm can handle unequally spaced time series data by ignoring observation model on the non-observed time points. for considering the changes on regulations, we introduce hidden variables to the var-ssm in order to indicate the presence of regulations in each condition. if hidden binary variables on two conditions indicating the presence of a regulation are both estimated as one, the regulation is considered as a commonly existing regulation. on the other hand, if only one of the hidden binary variables for the regulation is estimated as one, the regulation is considered as a condition specific regulation. we also introduce a potential function between the hidden binary variables that is designed to take high probability if the hidden binary variables on two conditions take the same value. from the design of the potential function, the similarity of networks on two conditions is automatically considered. since the time series data on both conditions are used for estimating commonly existing regulation due to the use of the hidden binary variables, an efficient data assignment is achieved. in addition, from the more accurate estimation of commonly existing regulations by the efficient data assignment, accurate identification of changes on regulations is induced.

the hidden binary variables are estimated by searching the configuration of binary variables that maximizes the marginal likelihood of the model. however, searching the optimal configuration is computationally intractable. thus, as an alternative approach, we derive a new variational annealing method based on  <cit>  in order to estimate the hidden binary variables. we also give a proof for the effectiveness of the variational annealing compared to other candidate alternatives, the variational annealing and the em algorithm, in order to show the validity of using the variational annealing.

for the performance evaluation, we generate two regulatory networks in such a way that most of the regulations commonly exist and some exist only on one of the networks. we then apply our proposed approach and existing var model based and dynamic bayesian network based approaches to two equally spaced time series data drawn separately from the generated networks. from the comparisons of true positive rates and false positive rates of these approaches, we confirm the effectiveness of our approach. we also generate unequally spaced time series data from these networks, and show that our approach works correctly on unequally spaced time series data while the performance of the existing approaches assuming equally spaced time points is drastically worsened.

our proposed approach is used to analyze changes on regulations in gene networks between normal human lung cells and human lung cells treated by stimulating egf-receptors and dosing an anticancer drug termed gefitinib. a lung cancer condition is simulated by the stimulation of egf-receptors in the treated cells. since gefitinib is known as a selective inhibitor of egf-receptors, the stimulation of egf-receptors would be counteracted by gefitinib, and hence the treated cells are expected to be the same condition as normal cells. however, gene expression profiles from normal and treated cells are actually different, and off-targets of gefitinib causing unexpected positive or negative effects are implied. we focus on genes with changes on regulations between the networks estimated by our approach and find possible off-target genes of gefitinib. according to the published clinical information, one of the possible off-target genes is suggested as one of factors of interstitial pneumonia, which is known as a side effect of gefitinib.

methods
vector autoregressive model and its state space representation
vector autoregressive model
given gene expression profile vectors of p genes during t time points {y <dig>  ..., yt}, the first order vector autoregressive ) model at time point t is given by

 yt=ayt-1+ε <dig>  

where a is a p × p autoregressive coefficient matrix, and εt is observation noise at time t and follows n, a normal distribution with mean  <dig> and variance diag. the th element of a, aij, indicates a temporal regulation from the jth gene to the ith gene, and if aij ≠  <dig>  regulation from the jth gene to the ith gene is considered. by examining whether aij is zero or not for all i and j, a gene network is constructed. since equally space time points are assumed in the var model, it has difficulty on handling unequally spaced time series data.

state space representation of var model 
let t be the set of equally spaced entire t time points and tobs the set of time points where gene expressions are observed. note that tobs⊆t holds. var-ssm is comprised of two models: system model and observation model. let xt be hidden variable vector representing true gene expression at time t. the system model is given as the var model of xt:

 xt=axt-1+ηt,t∈t, 

where ηt is the system noise normally distributed with mean  <dig> and variance h = diag. the observation model represents measurement error of observed gene expression yt and true gene expression xt at observed time point t∈tobs:

 yt=xt+ρt,t∈tobs, 

where ρt is the observation noise normally distributed with mean  <dig> and variance r = diag. unequally spaced time series data are handled by ignoring observation model at non-observed time points.

joint model of var-ssm for two time series data
let {yt}t∈tobs be time series gene expression data on cell condition c, where tobs is the set of observed time points on cell condition c. we also let t be the set of time points from  <dig> to t, where t= max{t∈tobs}. given time series data on two types of cell conditions c =  <dig> and  <dig>  we propose a new var-ssm model to estimate gene networks in the two conditions as well as identify changes on regulations between them. the model is comprised of the following two equations:

 xt=a∘ext-1+ηt,t∈t,yt=xt+ρt,t∈tobs, 

where ∘ denotes the hadamard product, e is a p × p binary matrix, and ηt and ρt are respectively system and observation noises from n and n. in this model, the th element eij takes one if regulation from gene j to gene i exists on condition c and zero otherwise, i.e., the presence of regulations is controlled by e and the ar coefficient matrix a is commonly used in conditions  <dig> and  <dig>  changes on regulations are identified when regulations exist only in a condition.

the complete likelihood of our model, p, where y, x, Θ, and e are respectively the sets of yt,xt, parameters, and e, is given by the following equation:

 p= ∏c=12∏t∈t|h|-1∕22πp exp-12-a∘ext-1)′h-1-a∘ext-1)×∏t∈tobs|r|-1∕22πp exp-12-xt)′r-1-xt)p,  

where the prior distribution p is assumed to be factorized as

 p= ∏ipp∏jpp,eij,zij). 

here, zij is a parameter for a potential function of eij and eij defined later. the prior distributions of aij is given by

 p,eij)=nfijn1-fij, 

where α <dig> and α <dig> are parameters controlling the shrinkage of coefficients a and fij is a binary variable that takes  <dig> if eij or eij takes  <dig> and  <dig> otherwise, i.e., fij is given by 1-∏c= <dig>  α <dig> is set to a large value, while α <dig> is set to smaller than α <dig>  from the design of the prior for aij, if eij or eij takes one, i.e., there exists regulation from gene j to i in condition  <dig> or  <dig>  weaker prior n is selected and the shrinkage of the coefficients are avoided. otherwise stronger prior n is selected and the sparsity of the network structures is promoted. the prior distributions of hi , and ri are given by

 p=ig,p=ig, 

where ig represents the density function of inverse gamma distribution, u <dig> and v <dig> are the shape parameters, and k <dig> and l <dig> are the inverse scaling parameters. under the assumption that a small number of regulations change between two conditions, we design the prior distribution for eij and eij,p,eij,zij) by using the following potential function between eij for c =  <dig> or 2:

 12ϕ,eij;zij)=zijifeij≠eij1-zijotherwise. 

in this setting, if zij is small, eij and eij tend to take the same value and thus most of the regulations exist in both two conditions. we also introduce a prior distribution for zij by beta distribution with parameters ζi <dig> and ζi1:

 b=1bzijζi0-1ζi1- <dig>  

where b is the beta function. thus, the prior distribution of eij is given by

 p,eij,zij)=ϕ,eij)b. 

for the parameter estimation, we search the configuration of e maximizing the following marginal likelihood:

  Ê= argmaxe ∫ dx∫ dΘp. 

finding the optimal configuration of e is computationally intractable, and heuristics approaches such as the em algorithm and the variational method are used in practice. here, we use the variational annealing, an extension of the deterministic annealing for discrete variables  <cit> . in the next section, we give a small explanation of the variational annealing and show its effectiveness compared to the em algorithm and the variational method.

parameter estimation by variational annealing
in the deterministic annealing, optimization problem is solved while gradually changing temperature in a some schedule, and maximum likelihood estimator is obtained like the em algorithm  <cit> . yoshida and west proposed to use the deterministic annealing to find the configuration of the binary variables that maximizes the likelihood of factor models with sparseness priors  <cit> . we derive a new variational annealing method by extending yoshida and west's approach to find the configuration of the binary variables on marginal likelihood function, which can be applied for searching e that maximizes equation .

let e, x, and Θ be p dimensional binary variables, unobserved variables, and parameters, respectively, and consider to search e maximizing the following marginal likelihood:

  maxe∈{ <dig> }p log∫ dx∫ dΘp. 

the maximum of the marginal likelihood on e is bounded by the following formula:

  maxe∈{ <dig> }p log∫ dx∫ dΘp≥τlog∫ pde∫ dx∫ dΘp1∕τ, 

where τ is called temperature and the equality holds for τ → + <dig>  hereafter, the integral range of e is omitted if no confusion occurs. let q be a normalized non-negative function, i.e., q ≥  <dig> and ∫ qde =  <dig> 

from the gibbs inequality, the right side of equation  is also bounded:

 τlog∫ de∫ dx∫ dΘp1∕τ≥∫ deqlog∫ dx∫
dΘpqτ. 

here, q is considered as an approximation function of p1∕τ∫ p1∕τde′. under the assumption that p ∝ qq, where q and q are normalized non-negative functions, we have the following inequality

  ∫ deqlog∫ dx∫
dΘpqτ≥∫ de∫ dx∫ dΘqqqlogpqqqτ. 

thus, as an approximation of e maximizing equation , we try to find Ê= argmaxeq, where q is the function maximizing the lower bound in equation . since higher values on p are weighed more in the approximation by q for τ <  <dig>  the better approximation is expected for the higher values. this property on the limited case is shown in proposition  <dig>  as is in the variational method and the em algorithm, the maximum of the lower bound in equation  is searched by a hill climbing from high temperature τ >  <dig> 

in the hill climbing, q, q, and q are alternately updated from the following equations:

 q∝ exp1τ∫ dx∫ dΘqqlogp,q∝ exp∫ de∫ dΘqqlogp,q∝ exp∫ de∫ dxqqlogp. 

gradually converging τ to  <dig>  local optimum of the lower bound and corresponding q, q, and q are obtained.

effectiveness of variational annealing
as alternatives of the variational annealing, we may consider the variational method and the em algorithm where x is the set of hidden variables and e is handled as the set of parameters to be maximized. we show the effectiveness of variational annealing compared to the variational method and the em algorithm under the following conditions: p is factorized into pp, and p is given as a binomial distribution, where ei is the ith element of e. if factorization of p = qqq is assumed in the calculation of the variational method, arg maxe q is not the optimal solution of equation  in general. in the em algorithm, by allowing e to move around a p-dimensional continuous space p,Êem= argmaxe∈mp can be calculated. let Êem,i be the ith element of Êem. usually, Êem,i is mapped to  <dig> if Êem,i> <dig>  and  <dig> otherwise for discretizing Êem to the p-dimensional binary space { <dig> }p, but such a mapping is not guaranteed to provide argmaxe∈{ <dig> }mp. although other mappings can be considered, to the best of our knowledge, no mapping is guaranteed to provide the optimal solution in polynomial time of p.

in the following, we prove a proposition in order to show that the variational annealing possibly give the optimal solution of equation  even if the factorization of q= ∏i=1pq is additionally considered.

proposition  <dig>  p is factorized into pp, and p is given as a binomial distribution. let q^be q maximizing the lower bound of the variational annealing for τ → + <dig> given by

  ∫ de <dig> ..∫ dep ∫ dx∫ dΘqq∏iqlogpqq∏iqτ. 

then, the set of ei ∈ { <dig> } maximizing Êemis argmaxe∈{ <dig> }pp.

for the proof of the proposition, see section  <dig> in additional file  <dig>  from proposition  <dig>  if the factorization p = pp is satisfied and optimal q functions are found, the variational annealing is guaranteed to provide the optimal solution of equation  while the variational method and the em algorithm are not. although the factorization is not a generally satisfied property, the factorization is often assumed in approaches based on the variational method, and the assumption usually works as good approximations. thus, the variational annealing is expected to provide the better performance than the variational method and the em algorithm even if the factorization is not satisfied exactly.

procedures of variational annealing on proposed model
in the variational annealing on the proposed model, we calculate q functions for hidden variables x, parameters Θ, and binary variables e iteratively while cooling temperature τ to zero gradually at each iteration cycle. in the following, we show the calculation procedures of q, q, and q on the proposed model as variational e-step, variational m-step, and variational a-step, respectively. more details of the procedures are given in additional file  <dig>  for the notational brevity, we denote the expectation of a value x with a probability distribution q as 〈x〉q.

variational e-step
parameters of q are mean of xt, variance of xt, and cross time variance of xt- <dig> and xt. these parameters can be calculated via variational kalman filter by using following terms expected with qq: 〈e〉qq, 〈a〉qq, 〈h- <dig> a ○ e〉qq, and 〈)'h-1a ○ e〉qq. for the details of variational kalman filter, see  <cit> . from the parameters of q, expectations of the following terms with q required in other steps are calculated: xtq,〈xtxt′〉q, and 〈xt+1xt′〉q.

variational m-step
q is factorized into ∏iq qq ∏jq, where ai is a vector given by '. from the design of the proposed model, q, q, q, and q are given in the following form:

 q=n,q=ig,q=ig,q=b. 

parameters for the above functions are calculated by using 〈xt〉q,〈xtxt′〉q,〈xt+1xt′〉q,, and 〈eij〉q.

variational a-step
for the calculation of q, we assume the factorization of q to ∏c∏ijq) in order to make the computation tractable. q) follows a binomial distribution that takes one with probability eij and zero with probability 1-eij, and thus the expectation of eij with q is given by eij. for the preparation, we calculate 〈a〉q,〈h-1a〉q,〈a′h-1a〉q,〈xt〉q,〈xtxt′〉q, and 〈xt+1xt′〉q. q) is then iteratively calculated by using these expected terms as well as 〈eik〉q for k ≠ j. a few iterations are enough for the convergence.

update and selection of hyperparameters
the proposed model contains u <dig>  k <dig>  v <dig>  l <dig>  ζi <dig>  ζi  <dig>  α <dig>  and α <dig> as hyperparameters. α <dig> and α <dig> should be α <dig> <α <dig> as in the model setting, but this condition can be violated in the update step of the variational method. thus, we select α <dig> and α <dig> by cross validation, and update other hyperparameters as in the variational method.

we first consider update of hyperparameters u <dig>  k <dig>  v <dig>  l <dig>  ζi <dig>  and ζi <dig> to increase the lower bound of marginal probability. u <dig> and k <dig> are updated by maximizing the following equation:

 = argmax ∑i∫ qlogigdhi= argmax∑i〈loghi〉qp+u <dig> logk0-k0∑i〈1∕hi〉qp- logΓ. 

û <dig> and k^ <dig> are obtained by numerical optimization methods such as the newton-raphson method. v <dig> and l <dig> are also updated in a similar manner to u <dig> and k <dig>  ζi <dig> and ζi <dig> are updated by solving the following equation:

 = argmaxζi <dig> ζi <dig> ∑j∫ qlogbdzij= argmaxζi <dig> ζi1∑j〈log〉qp+∑j〈logzij〉qp- logb. 

ζ^i <dig> and ζ^i <dig> can also be obtained by the newton-raphson method.

for the selection of α <dig> and α <dig>  we set α <dig> to some large value and select α <dig> by a leave one out cross validation procedure. for condition c ∈ { <dig>  2} and time point t∈tobs, we remove yt from data set y and use the data set to train the model. we calculate square sum of residues rt,c <dig> between yt and the prediction of xt estimated from the variational kalman filter on the trained model given by rt,c2=-xt)′-xt). by grid search on parameter space of α <dig>  we select α <dig> that minimizes ∑c=12∑t∈tobsrt,c <dig> 

summary of procedures
the procedures for estimating parameters in the proposed model are summarized as follows:

 <dig>  set τ to some large value. also set α <dig> to a small value and α <dig> to a large value satisfying that α <dig> <α <dig> 

 <dig>  initialize other hyperparameters and hidden variables.

 <dig>  perform the following procedures:

 calculate variational m-step.

 update hyperparameters.

 calculate variational e-step.

 calculate variational a-step.

 go back to step  until some convergence criterion is satisfied.

 <dig>  divide τ by some value >  <dig> such as  <dig> .

 <dig>  go back to step  <dig> if τ is larger than some very small value >  <dig> 

in our setting, α <dig> is set to  <dig> . for the initialization of τ and other hyperparameters, we use the following settings: τ= <dig> ,eij= <dig> ,ui= <dig> ki= <dig> vi= <dig> li= <dig> ζi0= <dig>  and ζi1= <dig>  if yt is observed, we initialize xt with yt. otherwise, we use the linearly interpolated one.

RESULTS
performance evaluation by monte carlo experiments
for the evaluation of the proposed approach, we generate two linear regulatory network models with similar topological structures g <dig> and g <dig> based on a linear regulatory network model g <dig>  g <dig> is prepared in the following manner:  a scale free network of  <dig> nodes and  <dig> edges is generated;  edge directions are assigned randomly;  autoloop edges are added to root nodes of the directed network; and  ar coefficients for the directed edges are chosen randomly from {- <dig> , - <dig> , - <dig> , - <dig> , - <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig> ,  <dig> }. we then generate g <dig> and g <dig> from g <dig> as follows:  autoloop edges and 70% of non-autoloop edges in g <dig> are used for commonly existing edges in g <dig> and g2; and  the other 30% of non-autoloop edges are randomly assigned as either g <dig> or g <dig> specific edges. note that ar coefficients on edges of g <dig> and g <dig> are preserved, i.e., if a regulation from gene j to gene i exists in g <dig> or g <dig>  then its coefficient is the same as that of the regulation from gene j to gene i in g <dig> 

from each of g <dig> and g <dig>  we obtain two equally spaced time series data of  <dig> time points and  <dig> time points. for system noise and observation noise, normally distributed values with mean  <dig> and standard deviation  <dig> and mean  <dig> and standard deviation  <dig>  and  <dig> are used, respectively. the signal-noise ratio for system noise with standard deviation  <dig> and observation noise with standard deviation  <dig>  is  <dig> db, and the signal is bit stronger than the noise. on the other hand, for observation noise with standard deviation  <dig>  the signal-noise ratio is - <dig> db. in the condition, the noise is stronger than the signal, and the noise level is quite high.

comparison between variational annealing and em algorithm
we first compare the performances of the proposed approach and the approach that is based on the proposed approach but uses the em algorithm instead of the variation annealing using the equally spaced time series data of  <dig> and  <dig> time points on the system noise with standard deviation  <dig> and observation noise with standard deviation  <dig> . from the comparison, we verify the effectiveness of the variational annealing, compared to the em algorithm. table  <dig> summarizes the results of the proposed approach and the em algorithm based approach. for the em algorithm, the regulation from j to i on condition c is considered to exist if the estimated eij is more than  <dig> .

 the number of true positives  and false positives  of estimated regulations in two network models by the proposed approach and em for equally spaced time series data. pre denotes the precision of the results. regulations in two networks are  <dig> in total.  the number of true positives  and false positives  of changes on regulations between two network models estimated by the proposed approach and em for equally spaced time series data. the regulations changed in two networks are in total  <dig> 

from the comparison, the results of the proposed approach contain more true positives than those of the em algorithm based approach except for identifying changes on regulations for time points  <dig>  for identifying changes on regulations, the em algorithm based approach estimates bit more true positives than the proposed approach, but the difference is so small that it can be ignored. on the other hand, the results of the em algorithm based approach contain more false positives than those of the proposed approach, and hence the precision of the results by the em algorithm is worse than that of the proposed approach. therefore, the effectiveness of the variational annealing is confirmed in the computational experiment as well.

comparison between proposed approach and existing approaches
we employ the elastic net based var model approach  <cit>  and the dynamic bayesian network based approach termed g1dbn  <cit>  as existing approaches for estimating networks from time series data. for the experiments, two versions of these approaches are considered: enet <dig> and enet <dig> from the elastic net based var model approach, and g1dbn <dig> and g1dbn <dig> from g1dbn. these approaches are different in the following point: enet <dig> and g1dbn <dig> estimate g <dig> and g <dig> independently, i.e., for the estimation of g <dig>  only time series data from g <dig> is used, while enet <dig> and g1dbn <dig> assume that g <dig> and g <dig> have the same network structure and estimate a network by using two time series data. thus, enet <dig> and g1dbn <dig> are considered to more use data sample than enet <dig> and g1dbn <dig> for network estimation, but changes on regulations between g <dig> and g <dig> are not considered. for selection of hyperparameters in enet <dig> and enet <dig>  aicc is used  <cit> , and for hyperparameters α <dig> and α <dig> of g1dbn <dig> and g1dbn <dig>  a setting of α <dig> =  <dig>  and α <dig> =  <dig>  considered in  <cit>  is used.

for the comparison of these approaches, we focus on the following two points: the number of correctly estimated regulations and the number of correctly estimated changes on regulations. the former is usually considered for evaluating the performance of gene network estimation methods. the numbers of true positives and false negatives of the estimated regulations are summarized in table  <dig>  the precisions of the results given by

 the number of true positives  and false positives  of estimated regulations in two network model by the proposed approach, enet <dig>  enet <dig>  g1dbn <dig>  and g1dbn <dig> for equally and unequally spaced time series data. pre denotes the precision of the results. regulations in two networks are  <dig> in total.  the number of true positives  and false positives  of changes on regulations between two network models estimated by the proposed approach, enet <dig>  enet <dig>  g1dbn <dig>  and g1dbn <dig> for equally and unequally spaced time series data. since no changes are estimated by enet <dig> and g1dbn <dig>  their results are indicated by '-'. the regulations changed in two networks are in total  <dig> 

 thenumberoftruepositivesthenumberoftruepositives + thenumberoffalsepositives 

are also provided. the results are averaged on ten data sets. the number of regulations in the true network models of g <dig> and g <dig> are in total  <dig>  for the latter point, we consider the estimated regulations existing only in one of two estimated networks as changed regulations, and check if they correctly exist only in the corresponding true network. the numbers of true positives and false negatives of the estimated changes on regulations and the precisions are summarized in table  <dig>  the results are also averaged on ten data sets. the number of true changes on regulations between in g <dig> and g <dig> are  <dig>  i.e., the number of true positives on this case is at most  <dig> 

for the estimation of the regulations in table  <dig>  the proposed approach outperforms other approaches in terms of true positives. the proposed approach contains more false positives than enet <dig>  g1dbn <dig>  and g1dbn <dig> on the data of  <dig> time points. we further consider these cases in terms of the precision. the precisions of the proposed approach, enet <dig>  g1dbn <dig>  and g1dbn <dig> are given by  <dig> ,  <dig> ,  <dig> , and  <dig> , respectively. from this analysis, the proposed approach shows better performance than enet <dig>  g1dbn <dig>  and g1dbn <dig> on the whole. more true positives are estimated by enet <dig> than enet <dig>  and the precisions of enet <dig> tend to be better than those of enet <dig>  this type of relationship is also observed between g1dbn <dig> and g1dbn <dig>  also, the elastic net based var model approaches estimate more true positives than the approaches from g1dbn. however, in the precision, the approaches from g1dbn are better than the elastic net based var model approaches. from the results in table  <dig>  we see that the proposed approach estimates more true changes on regulations than enet <dig> and g1dbn <dig> on both data of  <dig> and  <dig> time points. in addition, the results of the proposed approach contain less false positives than those of enet <dig> and g1dbn <dig>  no changes on regulations are detected in enet <dig> and g1dbn <dig> as topological differences are ignored in these approaches. since the proposed approach considers differences on network structures as well as uses two time series data efficiently, it can provide better results than other approaches on both estimating regulations and identifying changes on regulations.

one may think it is strange that false positives in enet <dig> and g1dbn <dig> in table  <dig> is more than those in table  <dig>  but this case can occur from the following reason. if a regulation exists in both of the true network models of g <dig> and g <dig>  but is estimated only for g <dig>  then the case is not counted as a false positive in table  <dig> while it is counted as a false positive in table  <dig>  thus, the number of false positives in table  <dig> can be greater than those in table  <dig> 

in order to show the performance in unequally spaced time series data, we generate unequally spaced time series data of  <dig> and  <dig> observed time points. for time series data of  <dig> observed time points, we first generate equally spaced time series data of  <dig> time points and divide it into three blocks:  <dig> time points,  <dig> time points, and  <dig> time points. we then remove time points in the following manner: no time point is removed in the first block; one of every two time points are removed in the second block; and two of every three time points are removed in the third block. figure  <dig> shows the time point schedule of time series data obtained in this process. for time series data of  <dig> observed time points, we first generate equally space time series data of  <dig> time points, divide it into three blocks:  <dig> time points,  <dig> time points, and  <dig> time points. then, some time points are removed in a similar manner. we apply the proposed approach, enet <dig>  enet <dig>  g1dbn <dig>  and g1dbn <dig> to the unequally spaced time series data. results for the dataset are also summarized in tables  <dig> and  <dig>  from the comparison of results on equally and spaced time series data, the results of the proposed approach from unequally spaced time series data are worse than those from equally spaced one even with the same number of observed time points. however, results of enet <dig>  enet <dig>  g1dbn <dig>  and g1dbn <dig> are worsened more than those of the proposed approach. this is probably because unequally spaced time points break their assumption, and their estimation process is misled.

we also consider the time series data with the high level noise: system noise with standard deviation  <dig> and observation noise with standard deviation  <dig>  the results for the case are summarized in tables  <dig> and  <dig>  the proposed approach shows the better performance on the number of true positives and precisions than other approaches except for the identification of the changes on regulations from the equally spaced time series data of  <dig> time points. for equally spaced time series data of  <dig> time points, the number of true positives on the changes on regulations estimated by the proposed approach is more than that of g1dbn <dig>  but less than that of enet <dig>  however, the precisions on the estimated changes by both enet <dig> and g1dbn are much worse than the proposed approach. thus, overall, the proposed approach is more effective than other methods. although the proposed approach provides the better performance than other methods, the results of all the approaches are worsened due to the high level noise, and the differences on the performance among the approaches get smaller, compared to the case of observation noise with standard deviation  <dig> .

 the number of true positives  and false positives  of estimated regulations in two network model by the proposed approach, enet <dig>  enet <dig>  g1dbn <dig>  and g1dbn <dig> for equally and unequally spaced time series data. pre denotes the precision of the results. regulations in two networks are  <dig> in total.  the number of true positives  and false positives  of changes on regulations between two network models estimated by the proposed approach, enet <dig>  enet <dig>  g1dbn <dig>  and g1dbn <dig> for equally and unequally spaced time series data. since no changes are estimated by enet <dig> and g1dbn <dig>  their results are indicated by '-'. the regulations changed in two networks are in total  <dig> 

analysis of time series microarray data from human small airway epithelial cells
we apply the proposed approach to two time series microarray gene expression data from normal human small airway epithelial cells  and saecs treated by stimulating egf-receptors and dosing an anticancer drug termed gefitinib. egf-receptors are often overexpressed in lung cancer cells such as tumoral saecs, and a lung cancer condition is simulated in the treated saecs by stimulating egf-receptors. since gefitinib is known as a selective inhibiter of egf-receptors, the stimulation of egf-receptors would be counteracted by gefitinib, and the condition of treated saces should be the same as that of normal saecs in theory. however, since some gene expression patterns are different between the two conditions in practice, some unknown effects by gefitinib may be involved in the phenomenon. thus, we focus on changed regulations between the gene networks estimated from gene expression data in these two conditions in order to find some insights on the unknown effects of gefitinib.

for gene set selection, we first screen  <dig> genes from the ranking of the gene list sorted by coefficient variation  <cit> . we then select  <dig> genes with highly varied expression profiles between normal saecs and treated saecs. the time series gene expression data from both types of cells are comprised of spaced  <dig> time points in  <dig> hours. the time schedule of  <dig> time points are { <dig> h,  <dig> h,  <dig> h,  <dig> h,  <dig> h,  <dig> h,  <dig> h,  <dig> h,  <dig> h,  <dig> h,  <dig> h,  <dig> h,  <dig> h,  <dig> h}. for the analysis on the proposed approach, we set interval on system model to three hours.

the estimated networks from time series gene expression data in normal saecs and treated saecs are summarized and given in figure  <dig>  black arrows, red arrows, and green arrows indicate regulations in both conditions, only in normal saecs, and only in treated saecs, respectively. table  <dig> gives a list of the estimated regulations only in normal saecs or in treated saec.

estimated regulations only in normal or treated saecs are listed in the left side or right side, respectively.

from table  <dig>  we see that prss <dig> is involved in most of the regulations only in treated saecs. prss <dig> is a tryptase, one of serine proteases, and its relationship with the airways is suggested by a report about its expression in the airways in a developmentally regulated manner. tryptase is a potent mitogen of fibroblast  <cit> , and it is reported that the increase and activation of fibroblast are promoted in lung cells under the condition of interstitial pneumonia. interstitial pneumonia is known as a side effect of gefitinib, and these findings suggest that prss <dig> is an off-target of gefitinib and is possibly related to the side effect of gefitinib. also, filip1l, a gene estimated as one of targets of prss <dig> in treated saecs, is reported as an inhibitor of cell proliferation of fibroblast  <cit> . this observation supports the relation between prss <dig> and fibroblast as well.

we also focus on other several genes related to changes on regulations in normal and treated saecs. lif, leukemia inhibitory factor, is known to affect cell growth and development. gefitinib is also known to be effective for acute myelogenous leukemia via sky, which is an off-target gene of gefitinib  <cit> . in addition, wang et al. reported that lif prolongs the cell cycle of stem cells on acute myelogenous leukemia lines  <cit> . although, to the best of our knowledge, no direct influence from gefitinib to lif is reported, the above facts suggest some relation between gefitinib and lif, and support changes on regulations of lif between normal and treated saecs.

heikema et al. reported that human siglecs, siglecs- <dig>  - <dig>  and - <dig> interact with transmembrain adaptor proteins containing the immunoreceptor tyrosine-based activation motif such as dap <dig>  <cit> , and therefore they potentially mediate the activation of intracellular signaling. gefitinib is a selective inhibitor of tyrosine kinase, and the inhibition of tyrosine kinase is considered to affect the regulations around siglec- <dig> 

although the stimulation of egf-receptors in the treated saecs is considered to be counteracted by gefitinib, the expressions of some genes may be affected by the stimulation in practical conditions. has <dig> is related to synthesis of the unbranched glycosaminoglycan hyaluronic acid and is reported to be up-regulated by egf  <cit> . the stimulation of egf-receptors affects the amount of egf taken into cells, and hence the stimulation is expected to cause the changes on the regulations around has <dig>  foxn <dig> is a member of family of fox proteins. fox proteins are known to play important roles on controlling the expressions of genes related to cell growth, proliferation, and differentiation. some members of fox family are related to efg-receptors, e.g., the expression of foxn <dig> is suppressed by egf-receptor signaling  <cit>  although no direct relation between egf-receptors and foxn <dig> is found. foxa <dig> is also a member of family of fox proteins. egf-receptor signaling is known to decrease the expression of foxa, which prevents the mucus production  <cit> .  <cit>  reported the relation between egf-receptors and foxa <dig> in the airways of asthmatic patients. thus, it appears that the change on the regulation related to foxa <dig> is caused by the stimulation of egf-receptors.

CONCLUSIONS
we proposed the new computational model that is based on var-ssm and estimates gene networks from time series data on normal and treated conditions as well as identifies changes regulations by the treatment. unlike many of existing gene network estimation approaches assuming equally spaced time points, our approach can handle unequally spaced time series data. the efficient use of time series data is achieved by representing the presence of regulations on each condition with hidden binary variables. since finding the optimal configuration of the hidden binary variables on the proposed model is computationally in tractable, we derive the extended variational annealing method in order to address the problem as the alternative method.

in the monte carlo experiments, we use equally and spaced time series data from synthetically generated two regulatory networks whose structures are different in several regulations, and verified the effectiveness of the proposed model in both estimation of regulations and changes on regulations between the two conditions, compared to existing methods.

as the real data application, we use the proposed approach to analyze two time series data from normal saecs and saecs treated by stimulating egf-receptors and dosing gefitinib. from genes related to changes on regulations by the treatment, we find possible off-target genes of gefitinib, and one of these genes is suggested to be related to a factor of interstitial pneumonia, which is known as a side effect of gefitinib. in this study, we consider changes on regulations in two conditions, but the proposed approach can be extended to identifying changes among more than two conditions.

competing interests
the authors declare that they have no competing interests.

authors' contributions
kk, si, ry, and sm designed the approach to identify the changes on regulations by the cell treatment to saecs. kk, si, and af contributed to the statistical modeling for the approach, and devised the details of methodologies for estimating the proposed model. my and ng carried out the microarray experiment for measuring time series the gene expression data on normal and treated saecs.

supplementary material
additional file 1
proof of proposition  <dig> and more details on the procedures of variational annealing. a proof of proposition  <dig> and more details on the procedures of variational annealing on the proposed model are described.

click here for file

 acknowledgements
we thank the anonymous reviewers for their constructive comments and suggestions, which improved the quality of this publication.

this article has been published as part of bmc genomics volume  <dig> supplement  <dig>  2012: selected articles from the tenth asia pacific bioinformatics conference . the full contents of the supplement are available online at http://www.biomedcentral.com/1471-2164/13?issue=s <dig> 
