BACKGROUND
whole-exome sequencing  is becoming a rapid and cost-effective molecular diagnostic tool in individuals with genetic diseases . recent reports demonstrate wes’ utility in both clinical  as well as basic genetics research . with growing demand for wes and drop in costs of next-generation sequencing , wes as a technique requires greater understanding of how experimental design can improve data interpretation and thereby biological outcomes.

inherent within wes and ngs, however, is much heterogeneity and bias in mean number of times a targeted nucleotide base is sequenced  <cit> . this heterogeneity in sequencing depth arises due to numerous factors, such as target-enrichment kit used  <cit> , target sequence gc bias  <cit> , pcr amplification bias  <cit> , repeats and pseudo-genes  <cit> , and other experimental design variables. these factors directly and systematically influence sensitivity of wes  <cit> . while evolving versions of exome-enrichment kits continue to address these biases, effects of technical replicate experimental design in pedigree-based wes are poorly understood.

pedigree-based wes approaches facilitate the discovery of not only de novo variants , but also multiple-inherited variants  <cit> . overall, clinical exome sequencing studies report significantly higher molecular diagnostic yield for pedigree-based approaches compared to single-proband sequencing  <cit>  stressing the importance of understanding wes’s performance in multiple-generation families.

here, we present an investigation on estimating the proportion of wes target sequence coverage biases that can be eliminated by repetition of the procedure in all individuals in a multiple-generation family. specifically, we directly compare independent exome-capture libraries generating  <dig> technical replicates in  <dig> members of a multiple-generation family . in this study, we evaluated variability and interpreted targeted sequencing within targeted exome regions. overall, our work reveals the advantages of technical replicate pedigree-based wes in multiple generations, specifically in relation to interpretation of wes derived genotypes  <cit> .

RESULTS
direct comparisons of exome-capture samples in triplicate
we compared the results of independent exome-capture in triplicate for six individuals from three generations , evaluating them for high-quality bases  aligned to a reference human genome . we compared the alignment results either between technical replicate samples of a single individual or between individuals within the pedigree by utilizing pooled data of all technical replicates for each individual. in total,  <dig> exome data sets from six individuals were evaluated. illumina hiseq <dig> sequencing generated 53– <dig> million paired-end  100-bp reads per technical replicate library to produce >48x mean alignment target depth of high-quality mapped bases  for each technical replicate library . this generated 5– <dig> gb of high-quality target-aligned data per technical replicate and cumulatively 20– <dig> gb  to give  <dig> - 208x average target coverage for each individual in the pedigree .fig.  <dig> independent technical replicate target exome capture and aggregate data alignment results for a six member multiple generation family. a probability density function plots of three independent library targeted exome capture experiments as a function of depth of sequencing per targeted base  categorized by each member of the six member  <dig> generation family. b mean depth of coverage as a function of total bases aligned in targeted exome region  for all  <dig> technical replicates, and aggregate data for  <dig> individuals derived by merging  <dig> technical replicate captures per individual. c percent targeted bases sequenced at ≥1x, ≥10x, and ≥20x thresholds as a function of total number of bases aligned in targeted exome region  for technical replicate and aggregate data for each individual. black lines show the predicted local polynomial regression  fit to data with default span value of  <dig> , and red dashed lines represent predicted 95 % confidence interval along the predicted line



technical replicate data were compared directly for each individual . the mean target-depth of sequencing varied linearly with the input of total sequence data and was evident for all technical replicates derived from the six individuals . the most variable technical replicate depth of sequencing results was from individual id <dig>  and the least variable was from individual id <dig> . upon aggregation of data from all technical replicates for each individual, the depths of coverage were  <dig> - 208x for targeted regions .

to determine sequencability of targeted bases, we determined the percentage coverage with ≥1x to ≥100x  in each technical replicate and in each aggregate data set . this analysis identified minimal variability at ≥1x coverage but appreciable variability at ≥20x coverage  among the technical replicates of each individual . greater variability was observed at higher  depth of sequencing thresholds . subsequently we restricted our analysis to ≥1x, ≥10x and ≥20x thresholds. we observed that this variability was a function of the total number of bases aligned to target regions. therefore, we used a local polynomial regression  package in the r statistical software to estimate variation in percent target region coverage as a function of sequenced bases aligned to target regions. we used this tool to fit data for technical replicate and cumulative percent target region sequenced . using this approach, we predicted a polynomial fit to percent target bases sequenced as a function of total bases aligned in targeted regions, and determined the predicted 95 % confidence interval along the fitted line. results showed higher standard error at ≥20x relative to ≥1x . in addition, at ≥1x we noticed that the fitted line approached saturation as a function of total bases aligned to target. taken together, this suggested that lower thresholds  had lower variability, and ≥20x threshold was highly sensitive to changes in total bases aligned to target . given these observations, we investigated whether higher depth of sequencing would stabilize this effect at ≥20x threshold and repeated this analysis using the aggregate data for each individual. in addition to sequencing  <dig>  -  <dig>  % of targeted bases at ≥20x, we observed less influence of input sequence data on the variability of percent target bases sequenced . overall, our results supported the conclusion that current exome sequencing results  have high variability at the ≥20x coverage threshold.fig.  <dig> estimation of stochastic variability between technical replicate targeted sequencing experiments within the same individual. a schematic representation of intersection–union test  on technical replicate data generated independently in triplicate . the probability density function was generated from technical replicate data of a single individual  with least variable input sequence data. the iut is performed at preset thresholds to test for low stochastic variability  or the alternative hypothesis of high stochastic variability   area-proportional euler venn diagram  of targeted bases sequenced in three technical replicates r <dig>  r <dig> and r <dig> at ≥20x. the square represents the total targeted bases, and area in white as the total number of targeted bases not sequenced at a given threshold . c area-proportional euler venn diagram  of targeted bases sequenced in three technical replicates r <dig>  r <dig> and r <dig> at ≥1x. the square represents the total targeted bases , and area in white as the total number of targeted bases not sequenced at a given threshold 



stochastics in capture and sequencing can be estimated by replicate libraries
data from exome sequencing are typically reported as percent targeted bases sequenced at a given sequencing depth threshold. although informative for the performance of targeted sequencing as a whole, this masks the ‘true’ stochastic nature of per-target-base coverage. in other words, it does not clarify whether a given targeted base achieves the required minimum depth of sequencing if the capture experiment were to be repeated independently. to address this, we analyzed the technical replicate data regarding what fraction of total targeted nucleotides were subject to stochastic genotypeability and sequencing given comparable, equal input sequence data . to investigate the relative stochastic variation in coverage at a per-target-base level, we grouped the technical replicate samples by individual. technical replicate data for all individuals are shown in additional file 1: table s <dig>  as proof of principle, we picked the set with the least variable sequence input data . the null expectation  was that there would be no appreciable difference between the intersection and the union of technical replicate sets . we observed that  <dig> , <dig> bases  of  <dig> , <dig> targeted bases were sequenced at ≥20x coverage in all three technical replicates , whereas  <dig> , <dig>  targeted bases were sequenced at ≥20x coverage in at least one but not all three technical replicates  . similar variation was observed for the three technical replicates of each of the five other individuals .fig.  <dig> impact of deep sequencing as estimated by aggregate exome sequence data from replicates in least variable individual. a area-proportional euler venn diagram  of targeted bases sequenced by standard exome sequencing  and aggregate exome sequencing. sequenced data are represented within circles of venn diagram , whereas targeted and missed by exome sequencing is represented by the square . left panel represents targeted bases in megabases , and right panel represents the results as percentage of total targeted bases. b distribution analysis of number of consecutive targeted bases recovered by deep sequencing to ≥20x. left panel is a log-log plot of frequency of consecutive targeted bases recovered. right panel plots the distribution of total number of bases sequenced as a function of consecutive targeted bases recovered by deep sequencing to ≥20x. red dashed lines represent 95 % confidence interval of loess predicted to the data . c ucsc genome browser screen shot example of lmna exon that illustrates the variability of ≥20x sequencing along the length of the exon. the black arrow and red box highlight a known disease causing mutation  that is consistently missed at the ≥20x threshold by all three technical replicates, but addressed by aggregate sequencing. aggregate data covers the entire exon to ≥20x



because the above results for coverage at ≥20x were theoretically dependent on sequencing input quantity, we repeated the analysis at near ‘predicted’ saturation of capture and sequencability . only  <dig>  % of targeted bases were variable among the technical replicates. specifically,  <dig> , <dig> bases  were sequenced at ≥1x coverage, whereas  <dig> , <dig> bases  were sequenced in at least one but not all three technical replicates  . this suggested that stochastic variability among these technical replicates contributes little to overall sequencability  although it had an appreciable affect on usable  sequence data.

cumulative technical replicate sequencing improves targeted sequence interpretation
of the variability within wes target capture regions, 2-3 % arose within protein-coding regions at ≥20x depth of sequencing threshold  <cit> . to understand whether or not deep sequencing addresses stochastic variability and benefits achieve theoretical maximum coverage , we merged the three technical replicate bam files from each subject to generate a single bam file . for each aggregate data set, 20– <dig> gb high quality reads covered targeted wes regions; each targeted base had an average of  <dig> - 208x coverage. compared to  <dig>  -  <dig>  %  coverage of targeted bases at ≥20x in the individual technical replicates, the merged data covered  <dig>  -  <dig>  % of targeted bases  at ≥20x, suggesting a  <dig>  –  <dig>  % improvement in coverage . each individual’s aggregate dataset recovered  <dig>  –  <dig>  million bases of variable targeted region.

the distribution of consecutive targeted bases recovered to ≥20x sequencing depth followed a power-law distribution . aggregate data recovered  <dig> - <dig>  singleton target-base positions ; the average-size of consecutive bases recovered was ~50 bp . in each individual, we identified  <dig>  -  <dig>  segments greater than 50 bp. we then intersected regions greater than 50 bp with ucsc known-gene protein-coding exons. intersecting ucsc known-gene coding bases with recovered regions revealed that  <dig>  -  <dig>  regions  overlapped protein-coding regions, including 12– <dig> of the  <dig> genes that the american college of medical genetics  recommended for return of incidental findings in clinical sequencing  <cit> . figure 3c illustrates that current depths of sequencing consistently fail to meet 20x coverage at clinically important sites. for example c.16c > t variant  in lmna, a cause of autosomal dominant emery-dreifuss muscular dystrophy   <cit> . this illustrates how aggregate deep sequencing may help recover variable regions to 20x or greater depth of coverage. taken together, this analysis not only revealed the advantage of technical replicate sequencing to determine exact targeted regions affected by stochastics under current exome sequencing standards but also demonstrated the utility of merging the technical replicate data to permit interpretation of regions with coverage that is otherwise too shallow.

genotyping sensitivity and accuracy to detect de novo variants improves with cumulative replicate sequencing
we investigated the effect of stochastic variation on genotyping of variants among technical replicate data sets of the same individual. we included all  <dig> technical replicates for this analysis. since depth of sequencing and the relative proportion of representation of the alternate allele play a key role in genotype calling  <cit> , we delineated genotype discordances among technical replicates at varying depths of sequencing. to address this question systematically, we binned each targeted position into 10-19x, 20-29x, and ≥30x bins. we evaluated sites within each of these bins where genotype calls disagreed between technical replicates of the same individual. in total we evaluated  <dig> , <dig>   <dig> , <dig>  and  <dig> , <dig> positions in the 10-19x, 20-29x, and ≥30x bins, respectively, and found  <dig> differences.  <dig> of these differences were in the 10-19x bin ,  <dig> in the 20-29x bin  and none in the ≥30x bin.

to evaluate the accuracy of wes genotyping at the  <dig> genotype-discordant sites, we performed sanger dideoxy chain-termination sequencing. of the  <dig> differences for which we could design functional primers , sanger sequencing showed that  <dig>  were heterozygous;  <dig>  were homozygous reference, and  <dig>  were homozygous non-reference. this demonstrated that  <dig> heterozygotes were not called in at least one technical replicate in an individual , while  <dig> variant sites were falsely called as heterozygotes in at least one technical replicate. the sequence surrounding  <dig> of the  <dig> sites mapped to multiple regions of the human reference sequence suggesting that the differences arose from mis-mapping .

next, we called de novo variants that arose in second and third generations of the family. in technical replicate data, for each trio, we found 3– <dig>  and 1– <dig>  de novos at 10x and 20x thresholds, respectively. in aggregated data, we found 4– <dig>  and 3– <dig>  de novos at 10x and 20x thresholds, respectively. of the  <dig> sites for which we could design effective primers, sanger sequencing showed that  <dig> were true de novo variants in technical replicates . two of the  <dig> de novo variants identified in the aggregate data were missed in technical replicate data. the technical replicate and aggregate variants that did not validate by sanger sequencing were in regions with problematic gc-content or mappability   <cit> . taken together, technical replicate data along with aggregate data for a given individual improved the interpretation of ngs genotype calls compared to current wes standards.

discussion
in this study, we investigated the utility of independent generation of exome capture libraries for the purpose of interlibrary comparison, the effects of stochastics on targeted genomic region capture, the advantages of aggregate data on targeted resequencing, and finally the effect of the overall process on genotyping and de novo detection.

we showed that current accepted exome-sequencing threshold of ≥ 20x is unsaturated at average 50x-100x wes target coverage, since interpretation of the targeted bases varied significantly among technical replicates at a ≥ 20x threshold and not significantly at ≥ 1x threshold. our results are consistent with current understanding that capture sequencing data interpretation is heavily dependent on amount of exome data generated  <cit> . certain targeted regions had variable coverage only as a consequence of input data since aggregate data met the genotyping threshold of ≥ 20x coverage. controlled analysis done by limiting the effect of input sequence data on overall measurement of stochastics showed variability between technical replicates at the genotypeability threshold of ≥ 20x and this is addressed by aggregating data to higher depths. a recent report by redin and colleagues  <cit>  support our conclusion that aggregate data is beneficial to the overall interpretation of exome data. they showed that un-interpretable regions within targeted portions can be as low as  <dig>  kb  given deep-sequencing  compared to our observation that it  can be as high as  <dig> -2 mb. therefore deeper exome sequencing may have potential to improve diagnostic yield for unselected patients, which for rare disorders is currently 25 %  in clinical laboratories  <cit> .

our approach is unique and novel because it addresses the potential library generation-specific sequencing biases that may propagate through the sequencing process and when evaluated, appear as true single nucleotide variants. our study design comparing technical replicate library data from the same individual provides an added advantage to detect genotyping anomalies that would otherwise be undetectable. this approach however raises the question of whether funding would be better spent on two additional technical replicates rather than on single library preparation and generating additional sequence data. at the time when this study was designed and performed, it cost $ <dig> per replicate library preparation . however, due to the rapid drop in prices and technological advancements, cost estimates for replicate library preparations currently are around $ <dig> per replicate library . using the triplicate library approach would therefore equate to an extra cost of $ <dig> per individual sequenced, when compared to single library preparation coupled with deep sequencing approach . estimating current sequencing costs at $ <dig>  per million bases sequenced , we assess that $ <dig> would theoretically allow for purchase of  <dig>  gb of additional sequence data per sample. given 70-85 % of  <dig>  gb would pass post-alignment and quality-filter analysis,  <dig> - <dig>  gb mappable data would be available for interpretation. given our observations of target-base coverage saturation at ≥ 20x threshold for 20– <dig> gb aggregate user-quality data, we conclude that an extra  <dig> - <dig>  gb per sample would minimally alter the overall interpretation of targeted regions under evaluation .

finally, we argue that our approach and findings are consistent with other studies that note benefits of replicate exome comparisons for variant detection and replicated exome merging for variant calling accuracy  <cit> . benefits of this approach may also minimize the stochastic branching process of allele-distribution in exome datasets derived from a single library generation process and may additionally help mitigate library specific amplification biases  <cit> .

CONCLUSIONS
we describe a method to evaluate the reproducibility and stochastics in exome library preparation, and delineate the advantages of aggregating the data derived from technical replicates. the implications of this study are directly applicable and provide an opportunity to rapidly, efficiently, and accurately diagnose patients.

