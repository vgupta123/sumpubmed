BACKGROUND
one of the most challenging goals of current biomedical research is to link the genotypic and phenotypic information generated by high-throughput experimental technologies  <cit> . the shift from hypothesis based to hypothesis-free research that has been made possible by these technological advances opens unprecedented new opportunities for studying biological systems on a large scale, at a low cost, and with a holistic perspective that promises to expand our understanding of biological processes and of their connections with clinically relevant outcomes. the price to pay for this paradigmatic shift is that researchers will increasingly need to handle very large volumes of heterogeneous data, both generated by their own experiments and retrieved from publicly available repositories of genomic knowledge. integration, exploration, manipulation and interpretation of such data therefore need to become as automated as possible. the "traditional" data inspection and analysis methods are quickly becoming inadequate in a scenario in which an investigator can sample hundreds of thousands of variables in parallel: not only ad-hoc analysis methods need to be developed in order to address problems related with the statistical significance of the analysis results, but all phases of the scientific discovery process  will have to be adapted to this new reality. in an era in which an entire new genome can be sequenced and annotated in a matter of days, it will become essential to be able to automatically link new observations and findings to pre-existing knowledge. finally, new data storage and retrieval systems will need to be adopted in order to handle the unprecedented volumes of data and information being generated in an efficient and productive way. these tools, however, should be easily accessible to the broad research community, facilitating the discovery process by providing high usability and effective automation. information technology will therefore play an increasingly crucial role in modern biomedical and translational research  <cit> , by developing the methods and tools that will allow researchers to bridge the gap between biomedical research and clinical applications. the ability to effectively address the challenges outlined above will have a direct, dramatic impact on the speed, accuracy and effectiveness of the scientific progress in all areas of the life sciences.

we therefore propose the application of data warehouse concepts to facilitate the investigation of biomedical data by researchers lacking technical expertise and database skills  <cit> . our system, called phenotype miner, provides a simple and effective way to organize, represent and navigate phenotypic data along multiple dimensions, and to select subsets of subjects based on one or more phenotypes of interest. our current aim is to turn the system into a general tool for hypothesis generation, experiment design, automated annotation and biomedical data management, by relating phenotypic data to genomic knowledge. in this paper we describe the overall architecture of the system, which exploits a distributed architecture based on web services to integrate the phenotype miner with two additional modules that support automated hypothesis generation process as an integral part of modern translational research. the first one is the data uploader, a tool to parse user-provided data sets of phenotypic data and to store them in the phenotype miner's database. the data uploader modular architecture makes it possible to easily customize both the parsing method  and the way in which data are stored in the database . the second module allows the system to access external resources providing background genomic information and knowledge through a standard web services protocol. this tool can be used, for example, to automatically link the phenotypes under study with available genotype data on the basis of pre-existing knowledge about the relationship between the phenotypes and genomic markers.

in the following we present a detailed description of the system's architecture and usage, we illustrate the most important technological and methodological solutions we adopted for its implementation, and we present an application example. using two sample datasets, the first one containing a dozen heterogeneous clinical measurements on about one hundred individuals and the second one containing their genotypes obtained with a snp microarray, we demonstrate the system's usability and we highlight the ways in which it can be used to answer complex questions about genotype-phenotype correlations.

system description
the phenotype miner, the core module of the system, was developed as an application of data warehousing to the domain of genetic studies. these studies rely on the integration and manipulation of large amounts of heterogeneous data, including genotypic, phenotypic and genealogical information, and therefore pose significant challenges related with structuring the data and querying them effectively. in particular, we showed how the definition and interpretation of phenotypic data can be improved through a multidimensional analysis approach  <cit> .

data warehouse techniques: the olap engine for data exploration
while a normalized structure  may be preferred for a correct management of the database in terms of data integrity and reliability, the adoption of query-oriented models that reflect the logical structure of the data elements greatly facilitates the task of filtering the data on the basis of the desired combination of phenotypes and patient features. thus, we used a logical database design technique to support end-user queries in a data warehouse called "dimensional modelling", and we adopted a data structure called "star-join schema", that has become a standard for data warehouse applications. unlike the entity-relation model, a dimensional model is very asymmetric. there is one large dominant table in the center of the schema, called fact table. it is the only table in the schema which is connected to the other tables with multiple joins. such other tables, called dimensional tables, only require a single join to be referenced by the fact table  <cit> .

typically a clinical database can be modeled by a star schema in which each record in the fact table represents a combination of a clinical measure and its values on a specific date for a specific patient. therefore, the dimensions are individuals, measurement time and measurement values: all of them can be further specified using a snowflake model, that is, a model in which a given dimension has relationships to other attributes of the same dimension   <cit> .

multidimensional analysis is implemented by software tools called olap  engines. unlike online transaction processing , where typical operations read and modify individual and small numbers of records, olap engines deal with large quantities of data in real time, and operations are generally read-only. the term "online" implies that even though huge quantities of data are involved – typically many millions of records, occupying several gigabytes – the system must respond to queries fast enough to allow an interactive exploration of the data.

moreover, formalization of the phenotype definition is needed to implement automated query generation. the definition and use of a formal phenotype definition allowed us to implement an automatic query generation tool, suitable for users who may not possess the necessary technical skills in query languages and database manipulation.

as a results, we developed the phenotype miner system, which included three main components: i) the phenotype editor, for the automated definition of phenotype queries, ii) a customized version of the mondrian  <cit>  olap engine for dynamic data inspection, iii) the pedlauncher  <cit>  plug-in, used to map phenotype information onto the population pedigree when needed  <cit> . a detailed schema of the data structure and components interaction is shown and described in figure  <dig>  while the web interface is presented in figure  <dig> 

the data uploader
phenotypic datasets are, in general, highly complex and deeply structured: the definition of the value types and ranges of the individual data elements, of the relationships that exist among them, and of the role they play is a function of the study being performed, and the structure of the database that will hold them should reflect the specific purpose for which they are going to be used. moreover, phenotypic data comes in a very wide variety of formats, encodings and representations. it is therefore impossible to develop a single, universal method to import phenotypic data into a general-purpose tool such as the phenotype miner. instead, we developed a modular component, the data uploader, which acts as the interface between the user-provided data source and the database. as described below, the data uploader can easily be reconfigured to adapt to changes in the database structure or to accept different input data formats. in this way, the phenotype miner can be used as an off-the shelf data mining tool, which is independent of the original data source used.

the soap interface
the final component of the system is a module to communicate with external resources through a suitable web services interface. according to the w3c, a web service is defined as "a software system designed to support interoperable machine to machine interaction over a network"  <cit> . web services are web-based communication protocols that allow a program to access one or more services available on a remote system over the network. the protocols specify how to define, locate, implement, and invoke services. in the case of soap  <cit> , the most widely used protocol in the web services context, messages are encoded as xml documents and are transmitted between client and server using the http/https protocols.

we developed a soap client interface by which the phenotype miner can access external repositories of genomic knowledge that support the web services protocols. in particular, we implemented methods to interact with genephony, an online tool for genomic dataset annotation  <cit> . in the current prototype, we exploit the functionalities provided by genephony to automatically find snps related to a mendelian phenotype by searching the omim database  <cit> .

thanks to the addition of the two above-described modules, the phenotype miner becomes a complete, general and flexible tool to integrate phenotypic and genomic information. in the most common usage scenario, the user imports patient phenotypic data into the database using a suitable data uploader and uses the phenotype miner components  to perform the desired selection and filtering operations on the dataset. the user may then use the available external knowledge bases to integrate the phenotypic data with genomic information in order to help in their interpretation or correlate them with available data at the genomic level. finally, the resulting dataset can be browsed or exported for subsequent analysis.

methods
the system was entirely developed using the java programming language and related technologies and products. it is implemented as a servlet-based application, hosted by an apache tomcat web server, and relies on a mysql local relational database as the data warehouse. user interaction with the system takes place through a web-based interface, and communication with external tools and resources also takes place over the web. an overview of the system's architecture and of its components is given in figure  <dig> 

the phenotype editor and the olap engine
final users can create phenotype definitions using a graphical wizard developed in java programming language. the tool runs as a java web start application in order to exploit both the development facilities provided by stand-alone gui apis and to keep it available as a web tool . it interacts with two sections of the non-normalized database, i.e. the star schema of the clinical data and the phenotypes definition tables. the conditions  may be defined by combo boxes, which provide lists of attributes according to the measures table of the star schema, suggesting the admissible ranges of values for each attribute. once the rules are defined, the corresponding sql string is created by merging conditions by and operators, in order to: i) store the rules in the phenotype section tables, and ii) select the subgroup of individuals satisfying the conditions and storing the individuals-phenotype relationship. in the same way, it is possible to use another graphical panel to select previously defined phenotypes to be merged together by or operators to create a new phenotype, which is then saved in the phenotypes section of the database.

when the olap engine starts, it reads an xml file containing the data definition. the first page of the system shows a set of check boxes containing the fields of the underlying tables, so that the user may choose the variable to be investigated . once the features have been chosen, the engine loads information related to the individuals having that phenotype. then a visual inspection of the measurement values can be performed expanding or collapsing cells of the resulting table, so that the analysis can be executed at different levels of detail.

the data uploader
the data uploader module allows the user to upload study data from text files directly into the system's database. it is composed of different modules , each of which is designed to parse a different type of file. the uploader engine parses the supplied file using the appropriate datasheet parser, and inserts the resulting data into the database according to the star-schema structure. user intervention is only needed to describe the logical connections between the fields in the source files and the data elements represented in the database. we assume that the data have already been pre-processed to ensure their quality, as data cleaning and filtering are beyond the scope of this paper.

the final result is that the data are automatically stored in the data warehouse according to the star-join structure exploited by the phenotype miner.

it is important to note that data import is not necessarily limited to parsing local files. as the use of web services becomes more widespread, it is conceivable that a growing number of repositories of phenotypic data  will make their data available to authorized software agents using standard interoperability protocols such as soap. in this case, it will be sufficient to implement a soap-based data uploader to give our system the ability to automatically acquire data from remote primary sources.

the soap interface
the soap interface is a module that provides the phenotype miner with the ability to access genomic knowledge stored within a remote resource. while there are several different types of messaging patterns available in soap, the most common is the remote procedure call  pattern, in which one network node  sends a request message to another node  invoking the execution of a specified function on a specified set of arguments. the server executes the function, and automatically sends a response message back to the client with the results of the computation.

the current prototype of our system includes a soap interface to communicate with genephony, an online tool for the creation and annotation of large genomic datasets. using the services provided by genephony, the phenotype miner can perform complex data annotation tasks in an efficient and straightforward way. as an example, we used the soap interface to retrieve the set of snps that are potentially related with a mendelian phenotype of interest. this is accomplished through the following sequence of steps:

 <dig>  the client requests the creation of a session, in which all subsequent processing will take place;

 <dig>  the client queries genephony for all omim entries containing the term  identifying the phenotype of interest; genephony stores the resulting set in the current session;

 <dig>  the client asks for all genomic regions referenced in the omim entries , and then for all snps belonging to these regions;

 <dig>  finally, the client retrieves the resulting list of snp identifiers.

the actual processing takes place on the genephony server, with several advantages: there is no need for a local annotation database or for methods to access multiple external resources, the communication between the client and the server can be optimized , and the computational load on the client application is minimized. it should be noted that although omim only provides information about mendelian diseases, the process just described could be applied equally well to other sources of knowledge about genotype-phenotype correlations .

RESULTS
as an example scenario of the system usage, here we consider a case-control genome-wide association study. association studies aim to find statistically significant differences in the distribution of a set of markers between a group of individuals showing a trait of interest  and a group of unrelated individuals who do not exhibit the trait   <cit> . among the several different kinds of association studies, genome-wide association studies  rely on a set of genetic markers covering the whole genome  <cit> . this strategy is motivated when there is little or no a priori information about the location of the genetic cause of the phenotype being studied. although the power of a genome-wide association study is usually low, such studies are useful to pinpoint areas of the genome that may contain candidate genes, and to guide a subsequent, more targeted analysis step. as the costs of genotyping decreases and the number of known, well characterized genetic markers in the human genome increases, the genome-wide approach represents an increasingly cost-effective way of generating testable research hypotheses.

genome-wide association studies typically rely on two kinds of datasets, one collecting clinical  measurements, and the other one storing the individuals' genotypic markers values. in our case we assume the genotype dataset to be the result of large-scale snp genotyping, while the clinical dataset may include any kind of measurement or observation. starting from these two sources of information, the user's objective is to identify a set of individuals sharing a phenotype of interest, to identify a set of snps known to be related to the phenotype, and finally to extract from the genotype database the allelic values of the snps for the previously identified individuals. these steps will be reflected in the following sequence of operations in the system:

• upload the subjects' phenotype information ;

• define the phenotypes of interest;

• find individuals showing the defined phenotype;

• find the set of genomic markers known to be related to the phenotype;

• finally, retrieve and download genotypes for those individuals and markers only.

the starting point is the file containing clinical measurements . the user can upload the data into the database through the data uploader web interface . the tool shows the contents of the datasheet in several re-organized menus, through which the user may specify additional information, such as which columns to parse, and the appropriate data type for each clinical measurement and variable. the data are then automatically inserted into the data mart on which the phenotype miner relies.

once the data are in the system database, the user may start defining the phenotype to investigate using the phenotype editor. let us suppose that the user is interested in studying individuals affected by diabetes-induced hyperglycemia. this condition can be defined as a set of logical statements on clinical measurements and other variables: for example, the diabetes phenotype may be defined as: "glycemia >  <dig> mg/dl and gender = both" . once a phenotype has been defined in this way, the system automatically generates and executes a query to identify individuals that meet the specified definition .

internally, phenotypes are represented as filters, one of the functionalities provided by the olap engine . when the user selects one of them, the dynamic navigation table in the web interface main page is automatically loaded with all the data regarding the individuals showing the selected phenotype. the user can then stratify the data at different levels of detail, simply by expanding or collapsing the table rows and columns .

the next step is to retrieve a set of markers that are known to be related to the phenotypes. through the automatic soap request to genephony described above, the user can retrieve all the snps  related to the omim entry associated with the phenotype under study. in this example, the dataset produced by genephony in response to the query contains about  <dig>  snps. of course not all snps will be actually needed for the purposes of the study, since many snps will be redundant with each other because of their proximity, and, more importantly, not all of them will be represented on the genotyping microarray used in the analysis.

therefore, a further processing step consists in filtering the resulting set of snps according to the specific genotyping platform used in the study, and to other desired properties . this step too can be performed through a soap request to a genomic annotation service such as genephony.

finally, the system needs to retrieve the allelic values of the selected individuals only for snps that are known to be related to the phenotype and present in the user's database. since the genotyping results may in general be stored in a remote database, we have used the soap protocol again to allow the phenotype miner to retrieve them. the remote database provides a soap service that takes as input a list of subject identifiers and a list of snp identifiers, and returns the encoded genotypes for the specified subset of individuals and snps. the resulting data table is proposed to the user in a common tabular format, in which the selected individuals are listed in the rows, and the snps genotype values are in the columns. the table may be downloaded as a text file for further analysis through external genetic analysis software tools .

so far, we have shown how to retrieve specific genotypic information that is related to a phenotype of interest. using the same sequence of operations it is possible to investigate whether genetic differences arise when including other covariates in the phenotype definition. for example, we could investigate if the snp patterns related to the previous definition of diabetes would be different in individuals who also have an obesity problem, by including conditions on bmi or cholesterol values in the new phenotype definition .

since the phenotype definition is different, the system will not only retrieve a different set of patients, but also a  different set of genetic markers. after performing association analysis in the two cases, it would therefore be possible to compare the resulting sets of associated markers directly, for example to determine if some of them are associated with both phenotypes, or to identify markers that are associated with only one of the two conditions.

thanks to the ability to access external resources for genomic annotation, the system could then provide the user with detailed information about the genomic context of the markers thus identified . the system here described can therefore be used to generate hypothesis about candidate genetic factors potentially involved in disease development, through dynamic and powerful data exploration and annotation features.

CONCLUSIONS
in this paper we presented a web-based software system aimed at addressing the problem of managing and exploring heterogeneous phenotypic and genotypic information in an automated, integrated and easy to use application. after describing the main system, called phenotype miner, which allows a dynamical inspection of clinical data, we described in more detail a set of desirable system's functionalities that we developed in order to: i) allow the user to upload experimental data, and ii) retrieve genomic information from existing biological knowledge bases and integrate it with user-supplied data. the typical application scenario of our system is in the context of studies aimed at investigating genetic factors potentially underlying phenotypes of interest.

we integrated different methodologies to develop the various software components of our system. we used a logical formalization for phenotype definition, a powerful graphical tool to define phenotypes, a data warehouse approach for dynamic, multi-dimensional data investigation, and a "web services" architecture to access external sources of genomic data and knowledge. the modular nature of the system makes it suitable for the development of new applications that integrate clinical data with already available external services and information resources. future developments will concern the inclusion of new sources of information, such as investigation results from the literature, and a post-processing phase to provide specific output data formats for genetic analysis software, as well as including some preliminary statistical analysis.

a prototype version of the system is freely available at the url . a pre-populated example database is provided for demonstration purposes.

competing interests
the authors declare that they have no competing interests.

authors' contributions
a.n. designed and implemented the phenotype miner system described in this paper. a.r. provided assistance with the development of the soap interface. r.b. contributed to the overall design of this project and supervised the phenotype miner project. all three authors participated in writing the present paper and approved it.

