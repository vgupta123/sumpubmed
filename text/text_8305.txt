BACKGROUND
genome resequencing has emerged as the principal means for identifying both the genotypes of single individuals and genetic variation within populations or species. methods such as whole genome and whole exome sequencing can generate data on large numbers of common and rare variants and discover previously uncharacterized variants. further, population genomics via sequencing shows reduced ascertainment bias relative to microarrays and other a posteriori methods . improvements in sequencing chemistry, methodologies, hardware, and software have increased sequencing read quantity and length, improved multiplexing scalability, and added further robustness to genotyping calls  <cit> . associated bioinformatics have seen similar advancement in the filtering of false positives, imputation of missing data, and utilization of datasets for genomics . in the course of these advances, two major avenues for genome resequencing have emerged: whole genome sequencing  and a variety of methods collectively referred to as reduced representation sequencing .

wgs methodologies attempt to query the entire genome in an as unbiased a manner as technically possible by constructing and sequencing libraries of randomly sheared genomic dna. millions of short reads are aligned to a reference genome to identify variants. while per-base error rate in most ngs methodologies is low, technical limitations, insufficient sequencing depth, and sequence and structural inaccuracies in the reference genomes can result in numerous errors  <cit> . deep sequence coverage of overlapping reads can significantly reduce errors in variant calling. hence, each position in the genome is represented by many overlapping reads on both strands of dna that result in highly robust genotype calls and reduced errors from pcr, sequencing artifacts, and alignment errors. the amount of sequencing required to achieve high coverage, especially in large eukaryotic genomes such as many plants, can be prohibitively expensive. this restricts the application of high-coverage wgs-based genotyping. therefore, wgs methods that rely on 20× to 30× coverage are preferred when attempting to identify sample specific variation or very limited numbers of samples in a population are available.

low-coverage  wgs is typically kept around 5× and, in some cases, less than 1× mean coverage per base for a given sample. lc-wgs reduces the cost and improves the ability to multiplex samples in a single sequencing run. its limitation is the accuracy of variant calling due to incomplete genome coverage and the inability to distinguish variants and inherent errors. for instance, polymorphisms may be lost in a sample due to low coverage or subsequent filtering during computational steps. errors introduced by pcr and sequencing may be misidentified as variants when coverage is low. nevertheless, when a reference genome and sufficient samples are available to infer haplotype structure, statistical methods such as imputation may result in variant calling that rivals that produced by hc-wgs both in terms of quantity and accuracy for a fraction of the cost . yet, without some form of cross-sample validation of variation, lc-wgs is at a disadvantage to high coverage sequencing.

a second category of genome resequencing can be collectively called reduced representation sequencing  methodologies. quite simply, rrs methodologies reduce a genome’s complexity by enriching, separating, or eliminating a portion of the genome prior to sequencing. some methods attempt to increase the informative fraction of the sequenced genome, such as exome sequencing  <cit> , while others ensure a consistent portion of the genome is retargeted for sequencing among samples . exome sequencing, the most common rrs methodology, is based on oligonucleotide capture technologies, where short dna fragments bind complementary targets of interest. captured fragments are then isolated from the rest of the genome and sequenced. large oligo capture arrays allow high specificity even when interrogating large genomic regions, such as the human exome. while this technology can be applied to almost any set of targets, initial implementation can be very costly and requires the genome of interest be well characterized.

alternative rrs technologies are restriction-site associated dna  sequencing  <cit> , spin-off methods called double-digest rad or ddrad  <cit> , 2b-rad  <cit> , and a related method called genotyping-by-sequencing or gbs  <cit> . these methods rely on an initial digest of sample dna by restriction enzyme to reduce genome representation. the 2b-rad method uses a type iib restriction enzyme, which cuts at two points to produce a fixed-size dsdna fragment. in ddrad, a second digest of gdna by a different enzyme follows the first. in both rad and ddrad, a biotinylated adaptor specific to the initial enzyme captures dna fragments of interest  <cit> . 2b-rad uses size selection to capture fragments of interest. rad technologies and gbs can be adapted to poorly characterized genomes, but lack the specificity to regions of interest of exome sequencing. in addition, much of the sequence will originate from non-informative, repetitive regions.

gbs is similar to rad sequencing whereby a restriction enzyme digest of gdna produces a size spectrum of dna fragments. as restriction enzyme sites are reasonably fixed  within a species’ genome, homologous regions will produce size spectrums that are consistent between members of a population. reduced representation is achieved by sequencing a small range of fragment sizes, rather than by capture of biotinylated adaptor. gbs can target as little as  <dig> % of a genome for sequencing  <cit> . more importantly, this small portion remains sufficiently consistent across samples to produce comparative results even in highly diverse species  <cit> , especially when other resources, such as nam lines or a high quality reference genome, are available to guide calls. in maize, which has undergone extensive gbs-based research, there is approximately tenfold more inter-accession diversity than exists across the spectrum of human populations  <cit> . this methodology is easily implemented, low cost, adaptable to poorly characterized genomes, and suitable for large-scale multiplexing of both library preparation and sequencing  <cit> . interest in the gbs protocol has resulted in expansions to the original protocol and improved computational data filtering and imputation .

in spite of its popularity, several issues limit the adoption of gbs methodology. one key issue is the requirement of customized barcoded adaptors specific to a single restriction overhang sequence. this greatly reduces flexibility and increases the cost of implementation. based on the gbs methodology, we have developed a novel approach to genotyping via restriction enzyme-based reduced representation library. this approach, which is compatible with all blunt-end restriction enzymes, is high-throughput, scalable to large sample sizes, and has a significantly lower cost to implement than other methods. the key, novel element in this standardized protocol is the incorporation of universal adaptors that are compatible with any blunt-end restriction enzyme. supporting this change is the use of a low-cycle pcr-based dual indexing system that allows exceptional multiplexing of individual samples, and a simple bead based library preparation protocol that allows in solution reaction cleanup and size selection in microtiter plates. our results demonstrate how enzymes can be selected to meet the needs of a given experiment and how informative sequences can be enriched by selecting enzymes that minimize repetitive and ambiguous reads. high levels of multiplexing and consistent genome representation can be achieved by utilizing enzymes with complex recognition motifs, while enzymes with simple motifs may better serve experiments requiring extensive variant identification. finally, we show that genome size, repetitiveness, methylation status, and quality of the associated reference are all factors that may ultimately affect enzyme selection.

RESULTS
modifications to existing gbs methods
to improve the flexibility and scalability of gbs several modifications were incorporated into the protocol. the key modification was that by choosing restriction enzymes that generated blunt ends fragments rather than ones with staggered ends, the custom enzyme-specific adaptors used in the original protocol  <cit>  could be replaced with standard illumina y-adaptors. this change removes the need for a costly end-repair step in the library preparation and enables the protocol to be compatible with a variety of enzymes. supporting the switch to blunt-end enzymes and universal illumina y-adaptors, barcodes that were previously incorporated into custom adaptors were replaced with a primer-based method that adds dual indices, one to each end of an adaptor ligated dna fragment, during a low-cycle pcr step  <cit> . finally, a solid phase reversible immobilization   <cit>  based library preparation allows for the entire protocol, including size-selection, to be done in microtiter plates, without the need for gels or columns  <cit> . the results of these modifications were significant reduction in cost, compatibility with a variety of blunt-end restriction enzymes, and a streamlined protocol that was adaptable to high throughput population genomic applications. the ability to choose restriction enzymes has several advantages as discussed later.

to test the robustness of these changes to the gbs methods, eight blunt end restriction enzymes were surveyed on two different plant reference genomes zea mays b <dig>  <cit>  and oryza sativa japonica nipponbare  <cit> . these genomes differ significantly in size, repetitive content, and methylated fraction. these eight multiplexed samples from each library were pooled and sequenced. enzymes, motifs, and summary sequencing information are summarized in table  <dig> table  <dig> 
enzyme summary statistics




validation of restriction motif in reads
a detailed assessment of the quality of data produced was performed. the first parameter tested was the quality of the sequenced fragments by confirming the appropriate restriction motif at the end of reads. all restriction enzymes, other than mlyi, tested in maize and rice had >80% and in most cases >90% of reads with the proper cutsite . mlyi is a special case, as its non-palindromic recognition site is offset from its cleavage site, which results in the restriction motif being absent from 50% of the reads. only  <dig> % and  <dig> % of the reads in maize and rice were observed with the proper mlyi motif, however.

paired versus unpaired sequencing tags
the modified gbs method produces minimal chimeric reads due to the da-tailing step. thus, it is highly suited to paired-end sequencing and associated data analysis. paired-end reads are generally held to be more likely to align correctly to a genome than single end reads, both due to the increased amount of sequence and the distance between sequences. to evaluate the effect of paired versus single end reads on alignment, the mapping quality of reads was assessed. mapping quality  is a measure of confidence in a given read alignment, given the information available in the reference genome. mq is a phred scaled value; a mq of  <dig> indicates a  <dig> in  <dig> chance of misalignment, and a mq of  <dig> indicates a  <dig> in  <dig> chance. reads that map equally well at multiple locations or fail to map at all are given mapping qualities of  <dig>  for many experiments, alignments below a certain mapping quality, usually values of  <dig>   <dig> or  <dig>  are filtered out.

sequences were retained as pairs or as “single tags” as in the original gbs protocol  <cit> . paired reads are generally held to be more likely to map correctly than unpaired reads  <cit> . sequences from each enzyme dataset were aligned as both paired and unpaired reads to the maize and rice reference genomes. the fraction of reads aligning at mapping quality mq ≥ <dig> and mq ≥ <dig> was then determined. in maize , a significantly higher fraction of reads in the paired dataset aligned at mq ≥ <dig>  and mq ≥ <dig> . in rice , there was no significant difference at mq ≥ <dig>  but a small significant decrease in the fraction of paired reads aligning at mq ≥ <dig>  compared to unpaired reads.figure  <dig> 
mapping quality differences between paired and unpaired reads. the mean fraction and standard error of reads across all enzymes aligning at mq ≥ <dig> and mq ≥ <dig> was determined for a) maize and b) rice.



mapping quality
a major source of data loss in gbs and many other next generation sequencing methodologies is the inability to align reads with sufficient confidence. to assess read alignment quality in the dataset, overall mapping quality of one million paired end reads was assessed at mq ≥ <dig> and mq ≥ <dig> for each enzyme in both maize and rice and compared to the mq distribution of whole genome samples consisting of one million paired-end reads truncated to  <dig> bp. in maize  hincii, stui, and drai all had mq scores higher than the whole genome control , while rsai and ecorv were lower. in rice , the majority of enzymes had higher mq scores than the whole genome dataset , except for haeiii, which was similar in value, and mlyi, which was considerably lower. these studies indicated that enzyme choice influences the proportion of reads that could be confidently aligned to the genome and utilized in downstream experiments.figure  <dig> 
effect of enzyme choice on mapping quality. grey lines represent the fraction of reads with mq ≥ <dig> and mq ≥ <dig> of rice and maize whole genome samples consisting of one million paired-end reads truncated to  <dig> bp. the fraction of reads aligning at mq ≥ <dig> and mq ≥ <dig> in a) maize and b) rice were compared to wg samples.



in silico site prediction
a key goal of this project was to both be able to predict which sites would be covered by sequencing reads and to understand the factors affecting sequencing coverage. simply quantifying each individual restriction site as having reads aligning to it or not would fail to distinguish between restriction sites that would reliably generate sequencing reads and restriction sites that generated spurious reads from singular events. an example of a singular event would be a restriction site that would not normally be covered due to the distance between it and proximal restriction sites occurring sufficiently close to the random end of a dna strand to produce a suitable fragment for sequencing. instead, sites were classified into four categories based on restriction sites identified in silico and the alignments of both ends of paired-end reads .figure  <dig> 
read alignments compared to digest sites predicted
in silico
. an in silico digest of the maize and rice reference genomes identified predicted restriction sites for each enzyme. following alignment to the genome, sequencing reads from each gbs dataset were categorized as “predicted”  when the ends aligned to proximal restriction sites, “mispaired”  when the ends aligned to non-proximal restriction sites, “singlet”  when only one end of a read aligned to a restriction site, and “null”  when neither end of a read aligned to an in silico predicted restriction site. the number of each type of site with coverage  ≥20) was determined for both a) maize and b) rice. the mean coverage per site type  was also calculated in c) maize and d) rice for all enzymes.



“predicted” sites were defined as reads originating from proximal restriction sites. reads aligning to non-proximal restriction sites were designated as “mispaired”. paired reads with one end aligning to a restriction site and the other end aligning to no predicted restriction site were designated “singlets”. reads that did not align to any predicted restriction site were identified as “null”. only reads with a mapping quality  score ≥ <dig>  or a 99% chance of correct alignment, were included for further analysis.

we predicted that the vast majority of reads for all enzymes would originate from proximal restriction sites, which we designated as predicted sites. to test this, the alignments of actual reads  were compared to in silico digest predictions of the maize and rice reference genomes. in maize, between  <dig> % and  <dig> % of all actual reads with mq ≥ <dig> aligned to predicted sites, while in rice  <dig> % to  <dig> % of reads aligned to predicted sites . in raw count of unique sites with sequencing coverage, predicted sites were the most common for all enzymes except ecorv in maize  and hincii in rice . in terms of depth of coverage, predicted sites were the highest across all enzymes in both maize  and rice . the ultimate outcome of this analysis was the conclusion that proximal restriction sites are the origin of most sequenced reads. this provided us with a framework for the prediction of sequenced sites. this framework not only allowed us to predict what sites might be covered, but to compare the total set of predicted sites to the subset of sites with sequencing coverage to discover factors that influence site coverage.table  <dig> 
predicted site counts and coverage


maize
rice
*a read alignment with mq ≥ <dig> is required for a site to be considered “covered”.



effect of fragment size on coverage
dna fragment size is a major factor affecting coverage in both maize and rice. the largest proportion of covered predicted sites in maize  and rice  occurs between  <dig> and  <dig> bp in all enzymes. for some enzymes, coverage of predicted sites extends outwards to  <dig> bp or further, but all enzymes show a reduction in the fraction of predicted sites with sequencing coverage after  <dig> bp. therefore, the anchoring of reads to restriction sites and the bias in sequenced fragment sizes were two sources for reduced representation in genome coverage in gbs datasets. further, depth of sequencing coverage per site tends to be higher for smaller sites in both maize  and rice , with the highest coverage occurring in sites between  <dig> and  <dig> bp. covered, predicted sites > <dig> bp had the lowest coverage for all enzymes. sites between  <dig> bp and  <dig> bp occupied an intermediate position. this observation suggests that while a complete coverage saturation of all possible sites may require an excessive number of reads, it is possible to achieve near saturation of sites within a limited size-spectrum at much lower depth of coverage.figure  <dig> 
size distribution and sequencing coverage of predicted sites. sites were predicted based on in silico digests of each enzyme against a) maize and b) rice reference genomes then plotted by log <dig> site count in  <dig> bp bins. predicted site count is displayed in grey. sites with aligned reads  are displayed in heatmap colors as a non-log scale fraction of predicted sites. the heatmap for covered sites represents the total fraction of aligned reads within a given bin.



gc content of reads
a source of coverage bias may be base composition of fragments due to poor amplification in the pcr step of library preparation. the protocol tried to minimize this bias by keeping the pcr cycles, necessary for indexing, to a minimum. in silico predicted sites, based on proximal restriction sites, were used to estimate bias in actual coverage due to the effect of base composition ratios. the gc ratios of all predicted sites between  <dig> and  <dig> bp were compared to the gc ratios of actual sequenced reads aligning to predicted sites between  <dig> and  <dig> bp in size for all tested enzymes in maize  and rice . sites/reads were placed in  <dig> % gc-content bins from  <dig> to 100% and predicted versus sequenced read distributions were compared via two-tailed paired t-test. no bin showed a significant difference  after correction for false discovery rate  <cit> . this suggests that the low number of cycles employed in barcoding and amplification  and the kapa hifi pcr reagents likely minimized any pcr bias in at or gc rich regions.

site density
a factor important for the design of gbs experiments is the density of restriction site motifs found in a given genome. site density will affect the ability to resolve recombination breakpoints and overall number of variants discovered. the distribution of distances between covered predicted sites with sequencing coverage was determined for all enzymes in maize  and rice . for all enzymes the shortest distance between predicted sites was  <dig> bp, indicating both upstream and downstream sequencing from a restriction site. in maize, alui had the shortest mean distance between covered sites ) followed shortly after by haeiii ). the longest mean distances between covered sites occurred in ecorv ) followed by stui ). in rice, alui had the shortest mean distance between covered sites , followed by haeiii ). stui had the longest mean distance ) followed by ecorv ). the longest interval without a covered site observed in any organism was  <dig>  mbp .figure  <dig> 
distribution of distances in bp between predicted digest sites with sequencing coverage. density of sequenced sites is displayed via normalized violin plot for all enzymes based on the distribution of distances between predicted sites with aligned reads for a) maize and b) rice.



coverage in genic regions
another important parameter in experimental design was the fraction of predicted sites with sequencing coverage in genic regions. markers in genic regions are generally held to be more informative than non-genic markers as they are less repetitive and, for many studies, more likely to be in proximity of a trait-associated polymorphism. the genic fractions of all predicted sites and sites with sequencing coverage in genic regions were determined . predicted genic site fraction varied from enzyme to enzyme, but in maize   the covered genic fraction for hincii , alui,  and rsai  were considerably higher than predicted. in rice  , covered genic fractions tended to be closer to predicted genic fractions for all enzymes tested. to better understand the ratio of the total predicted and covered predicted genic fractions, termed genic enrichment, the maize and rice genomes were divided into  <dig> mbp bins. the predicted versus covered genic ratio was plotted for each of these bins and graphed. while both the predicted and covered genic fractions did vary from bin to bin based, likely based on genic fraction within the bin itself, the relationship between the two was consistent for most enzymes .table  <dig> 
genic fractions of total and covered predicted sites


maize
rice
*a read alignment with mq ≥ <dig> is required for a site to be considered “covered”.
fraction of predicted versus covered sites in genic regions. the fraction of total predicted sites in genic regions was compared to the genic fraction of predicted sites with actual sequencing coverage for a) maize and b) rice.



enzyme methylation sensitivity
one possible factor responsible for the enrichment of covered sites in genic regions relative to the predicted values for some enzymes is cytosine methylation sensitivity of the restriction enzyme. repetitive dna in plants tends to be methylated at cpg and cpnpg motifs. digestion of repetitive gdna by methylation sensitive enzymes may result in dna fragments too large to sequence being generated, whereas non-methylated regions would produce a normal dna size spectrum.

to assess the contribution of cytosine methylation to genic enrichment, the nucleotide ratios flanking the motifs of restriction sites were compared in predicted sites with aligned reads for a given enzyme versus the total set of predicted sites. sites were further broken up into ones overlapping introns and exons and sites in non-genic regions, as repetitive, intergenic regions are often methylated. this analysis indicated that in maize several enzymes, namely hincii, rsai, and alui show considerable reductions in guanine one to two bp upstream and cytosine one to two bp downstream of restriction motifs. further, this difference is more pronounced in non-genic than in genic regions .

in maize, hincii was sensitive to both cpnpg and cpg methylation. hincii had the largest genome-wide decrease between predicted and covered upstream cytosine  and downstream guanine  ratios. further, it had greatest increase in covered versus predicted sites in genic regions of all tested enzymes . rsai, showed clear sensitivity to cpg methylation but was much less sensitive to cpnpg methylation. rsai showed a  <dig> -fold enrichment in predicted sites with sequencing coverage in genic regions versus all predicted sites . interestingly, the enzyme with the third highest increase covered genic fraction relative to predicted  was alui, which, due to its recognition motif of agct, was only sensitive to cpnpg methylation.

in the less repetitive rice genome, predicted versus covered nucleotide ratios were similar for most enzymes, and differences between covered and predicted sites for a given enzyme in rice were smaller than in maize . in rice, hincii was the enzyme with the largest difference in g/c ratios between predicted and covered sites. the cytosine ratio  <dig> bp upstream of the hincii motif decreased from  <dig>  to  <dig>  and the guanine ratio downstream decreased from  <dig>  to  <dig>  between total and covered predicted sites. that g/c ratios would be closer between covered and predicted sites in rice than maize was expected, as no enzyme in rice had a covered sites genic fraction >25% that of predicted sites. these results indicated that benefits conferred from methylation sensitive enzymes are genome dependent.

it is worth noting that, while different enzymes showed different degrees of methylation sensitivity in this study, this may be a product of the genomes tested more than an intrinsic property of the enzymes themselves. if an enzyme’s recognition motif predisposes it to cut more often in a repetitive region, it may appear more methylation sensitive than one whose recognition site biases it away from these regions.

gbs-based population genomics
the low cost and high multiplexing capacity of the modified gbs protocols indicated that the method would be suitable for population genomics. to test the suitability for trait mapping and population structure analysis, rsai and hincii restriction digestions were used to create multiplexed gbs libraries from an f <dig> population  derived from a cross between b <dig> and country gentleman  maize inbreds. eighty-nine rsai samples and ninety hincii samples were analyzed, with eighty-eight in common to both libraries along with both parental inbreds . reads were demultiplexed and aligned to all predicted and covered sites in the b <dig> reference datasets for rsai  and hincii . no evidence was found of bias due to barcodes, as regression analysis found little correlation between samples sequenced with the same barcodes between hincii and rsai , excluding the fourteen hincii samples that were resequenced. there remains the possibility that certain, specific barcodes will underperform, but these are likely to be only identified through repeated experiments.figure  <dig> 
fraction of predicted sites covered in samples from a f
2
admixture population. reads from each f <dig> sample were aligned to predicted sites, then predicted sites were placed in  <dig> bp bins, with the fraction covered in each bin indicated by the heatmap. a) the rsai dataset, aligned against total predicted sites. b) rsai dataset, aligned against the subset of predicted sites with sequencing coverage in the original rsai b <dig> gbs experiment. c) hincii dataset, aligned against total predicted sites. d) hincii dataset, aligned against predicted sites with at least one read coverage in the original hincii experiment. sample order is given, left to right, in additional file 5: table s <dig> 



as with previous experiments, the results indicated that the highest fraction of covered sites was between  <dig> and  <dig> bp. in this range, f <dig> sites were more concordant with predicted sites covered in the reference b <dig> datasets as expected. above  <dig> bp, the performance of the set of predicted sites covered by the b <dig> hincii and rsai datasets was no better than the total set of predicted sites for most f <dig> samples .

variant calling and imputation
variant filtering is a critical step in identifying informative markers, and special methods are required for gbs datasets. variants were filtered using a combination of standard and population genomics based criteria. filtered variants were required to be homozygous, opposite calls in parentals, covered at 2× or greater in at least twenty f <dig> individuals, mq and phred score > <dig>  and r <dig> correlation ≥ <dig>  with five proximal variants upstream or downstream. a total of  <dig>  post-filtration variants were identified in the hincii dataset and  <dig>  post-filtration variants were identified in the rsai dataset . for the rsai there was a mean per-sample post-filter variant count of  <dig> .1 ±  <dig> . <dig>  , while hincii had a mean per-sample post-filter variant count of  <dig> .7 ±  <dig>   .figure  <dig> 
number of samples with a call passing quality control filters for each marker in final b73xcg f
2
datasets.




next, parental contribution and recombination breakpoints were determined by imputation of variants by first phasing the final set of variants by parental genotype  then applying a least squares algorithm with a sliding window for final genotype calls . f <dig> samples typed in both the hincii and rsai datasets had a concordance of  <dig> % ± <dig> %  on a genomewide, nucleotide level. while large regions with a single genotype were consistent with some minor variation in imputed breakpoint position, the genotype of smaller regions varied between some replicates of samples covered in both the hincii and rsai datasets . these differences may be due to reduced per-variant sequencing coverage in the rsai dataset resulting in false homozygous calls in heterozygous regions, or reduced marker density in the hincii dataset resulting in events being missed.figure  <dig> 
imputed rsai gbs datasets from an f
2
admixture population. a) phased, filtered variants displayed by “mean” genotype as indicated by heatmap in  <dig> mbp bins. b) post imputation genotypes. sample order is given, outermost to innermost, in additional file 5: table s <dig> 



trait mapping
the f <dig> population segregated for two recessive traits previously mapped in maize: sugary <dig>  and yellowy <dig> . the su <dig> gene maps between chr4:  <dig> ,510- <dig> , <dig>  and y <dig> maps between chr6:  <dig> ,148-82- <dig> . to further validate our variant calling and imputation efficacy of our gbs methodology, these traits were mapped using gbs in the f <dig> population. a one way anova test on both pre and post imputation datasets of post-filter markers  were able to localize causative alleles in the correct regions with p <1e- <dig> figure  <dig> 
trait mapping for
yellowy
 and
sugary
 in an f
2
admixture population. a green line in the plots annotates the locations of both genes. pre-imputation markers are shown in black and grey. markers, post-imputation and error correction are shown in color. a) rsai gbs dataset, su <dig> map. b) rsai gbs dataset, y <dig> map. c) hincii gbs dataset, su <dig> map. d) rsai gbs dataset, y <dig> map.



coverage simulations
an important consideration in multiplexing for population studies is the per sample depth of coverage. to determine how depth of sequencing coverage affected imputation and marker calling, multiple subsets of randomly selected reads were taken from one rsai f <dig> sample  and one hincii f <dig> sample . these samples were selected due to their high read-count, which resulted in a near saturation of potential markers . subsets were then realigned against the reference genome, variants were called, and genotypes were imputed. the original rsai sample contained  <dig> , <dig> reads and  <dig>  variant calls. to obtain 90% of the original sample’s variant calls,  <dig> , <dig> reads were required . the original hincii sample contained  <dig> , <dig> reads and  <dig> variant calls. results indicated that as few as  <dig>  reads were required to obtain 90% of the imputed variant calls found in the primary sample. . the post-imputation genome similarity with the original sample remained above 90% in all read subsets. in both the post-imputation rsai  and hincii  datasets, as the number of reads decreased, small recombination events disappeared and possible artifacts began to appear. for rsai, imputed genome similarity, as measured against the original, high-coverage sample fell beneath  <dig> % at  <dig>  reads while genome similarity at  <dig>  reads fell to only  <dig> %. discordant recombination breakpoints, defined as a pattern of recombination different from that of the primary sample, began to appear at  <dig>  million reads. these incongruities were seen as minor segments of miscalled genotypes and discordant localization of recombination breakpoints. for hincii, genome similarity remained at 98% at  <dig>  reads and the lowest percent genome similarity was  <dig> % at  <dig>  reads. discordant recombination breakpoints began to appear at  <dig>  reads.figure  <dig> 
effect of read count on marker dataset size and imputation. fraction of shared post-filter, pre-imputation genetic markers and fraction of post-imputation shared genome with original sample for subsamplings of a) rsai f2- <dig> and b) hincii f2- <dig>  c) imputed genomes for each subsample in rsai f2- <dig> displayed in concentric rings. sample read count declines from the outermost ring to the innermost. d) imputed genomes for each subsample in hincii f2- <dig> displayed in concentric circles. sample read count declines from the outermost ring to the innermost.



discussion
genotyping-by-sequencing is a high-throughput, low-cost technology that meets the need for robust variant identification in diverse populations from a variety of species . the extant gbs technology has several limitations that were addressed in this study. the use of enzyme-specific barcoded adaptors means that for each utilized enzyme a number of doubled-stranded adaptors equal to multiplexing targets must be developed. this results in a high cost to initially implement gbs and to switch enzymes, discouraging changes in experimental design even when an alternative enzyme may better meet experimental needs.

modifications to gbs
to improve both flexibility and scalability of gbs we modified the original protocol in a number of ways. the most important and novel change was to remove the requirement for custom enzyme-specific barcoded adaptors. to make this change, restriction enzymes were chosen that created blunt-end fragments that required a single adenylation step for compatibility with standard illumina y-adaptors. next, dna barcodes required for multiplexing samples were added to the universal adaptors during a low-cycle pcr step. this dual indexing system allows a great number of samples to be multiplexed during sequencing to minimize cost. for instance, with just twenty indexed forward and twenty indexed reverse primers as many as four hundred samples can be multiplexed on a single hiseq  <dig> lane. finally, a bead-based in-solution library preparation protocol facilitates automation and allows for gel-free size selection.

over forty blunt-end enzymes compatible with this gbs protocol are commercially available. we selected eight enzymes that represented a variety of recognition motif lengths, sequence contents, and methylation sensitivities to test the robustness of these new methods. this panel of enzymes was used to create gbs datasets from two reference genomes z. mays b <dig>  <cit>  and oryza sativa japonica nipponbare  <cit> . haploid genome length , repeat content, methylation, and genic fraction differ considerably between the two genomes. in addition, a maize f <dig> population consisting of ninety-one individuals was created from two maize inbreds b <dig> x country gentleman and genotyped by gbs using two enzymes, rsai and hincii.

prediction of coverage
the vast majority of reads for all enzymes align to proximal restriction sites. further, these sites tend to be between  <dig> bp and  <dig> bp in size . this is likely a result of the size selection step during the library preparation and the bias of the illumina sequencer towards smaller fragments.

mispair sites tended to have lower coverage than predicted sites across all enzymes, but their >1× coverage values indicated that some mispair events were reproducibly covered. these may have been generated as a result of polymorphism or methylation disrupting a restriction site or the digest of a given site inactivating proximal ones.

singlet sites, events where one end of a read aligned to a restriction site and the other end aligned to random dna could also be generated from two potential sources. the first possibility is a polymorphism creating a restriction site that was not found in the reference. the other possibility is that the restriction site occurs near the random end of a dna fragment. the later is the most common case, as in most samples singlet sites were at or barely above 1× mean coverage, which suggests singular events.

null sites occurred when neither end of a read aligned to a restriction site. for mlyi, drai, hincii, ecorv, and stui in maize and all enzymes in rice save mlyi, these sites had a mean coverage near 1×, suggesting they were the result of random dna fragments being sequenced. in alui, haeiii, and rsai in maize, coverage was considerably above 1×, though the number of unique sites was small compared to the others. the likely reason for this is that some reads were misaligned to the same location in the genome multiple times. several observations support this. first, as random fragments are generated from degradation, a consistent amount of these would be expected to be generated for each library as the amount of input dna was equal between them. for enzymes that cut rarely and produce relatively few reads, such as drai, hincii, ecorv, and stui, these would make up a larger overall proportion or the reads than for enzymes that cut frequently and generate large numbers of potential reads, such as alui and haeii. second, misaligned reads represent a fraction of the total amount of reads generated and aligned. thus, high coverage null sites are observed for enzymes that cut frequently and generate large datasets, such as alui and haeiii. finally, null sites with high coverage generated by misalignments would be expected to be more common in maize, due to the highly repetitive and difficult nature of the genome, than in rice, which is much simpler to align reads to. this is also concordant with observations.

finally, it is worth noting that all reads that are accurately aligned and whose alignments are observed across multiple samples in a population contribute to the value of a dataset, not just reads aligning to predicted sites. mispair sites are the most common example of this, though singlet sites contribute as well. given the likelihood that many null sites represent misalignments or broken dna fragments, however, it may be advisable to filter these reads.

to further examine how well we could predict gbs sequencing coverage, we realigned reads from two datasets, one produced by rsai and the other by hincii, generated from a b <dig> × cg f <dig> population to the total set of predicted sites and to the set of predicted sites with sequencing coverage . as was expected from our original datasets, the majority of coverage occurred between  <dig> and  <dig> bp. predictability of coverage, as measured by the fraction of sites covered, improved when an f <dig> sample’s reads were aligned against sites covered in the pilot b <dig> experiment rather than the total set of predicted sites. in rsai, this improvement was modest, with many samples only improving 5-10%. in hincii, however, the improvement was considerable. while only 30-40% of the total predicted sites were covered in each f <dig> sample, up to 80-90% of the pilot-experiment sites were covered in the same f <dig> samples. the reasons for this are likely twofold. first, our identification of total predicted sites did not take into account the ability to unambiguously align reads to these sites. the use of a dataset based on predicted sites with sequencing coverage intrinsically did, as there was a mq ≥ <dig> cutoff for sites. second, the use of predicted sites with sequencing coverage by nature accounted for sites that were made inaccessible by methylation. the improvement in hincii data quality between the total and covered sites was likely due to this, as hincii is highly sensitive to methylation. finally, though not as applicable in this case, pilot experiments account for differences between the target genome and the reference genome that cannot be identified in silico.

enzyme parameters and data quality
our results clearly show that the ability to use a panel of enzymes for gbs has several clear benefits. a major source of data loss in sequencing is the inability to uniquely align reads with sufficient confidence  <cit> . as assessed by mapping quality, certain enzymes, such as drai, stui, and hincii produced datasets that were aligned with greater accuracy than others, such as mlyi, haeiii, and ecorv in maize . this may reflect a bias against repetitive elements due to motif, or it could be methylation sensitivity limiting digest in repetitive regions.

enrichment of genic regions was another parameter looked at closely. hincii, rsai, and alui in maize produced datasets that contained a considerably greater portion of covered sites in genic regions . on the other hand, for mlyi, drai, ecorv, and haeiii in maize as well as all enzymes in rice , the proportion of covered sites overlapping genic regions was similar to the genic fraction of total predicted sites. the difference between the two categories appears to be due to methylation sensitivity, which biases enzymes away from cutting the genome in repetitive, heterochromatic regions. the ability to enrich for genic coverage is beneficial in any dataset but is especially beneficial for association studies in populations that have undergone large amounts of recombination. in these studies, a trait may only have associations to markers in the immediate vicinity of the functional variant.

restriction motif presence and nucleotide complexity
one initial concern was that the lack of enzyme-specific adaptors might produce more random reads derived from broken dna fragments. by omitting the end-repair step, we attempted to enrich for digest fragments, as end-repair both fixes broken ends and adds a phosphate group necessary for adaptor ligation to the 5′ ends of the fragment. the phosphate group is naturally retained on the 5′ with a restriction digest  <cit> . all enzymes save mlyi reliably produced dna fragments with more than 80% of ends containing the proper restriction motif . mlyi, due to its offset cut site, had a restriction motif present in less than half of its reads. counterintuitive to expectations, this may be beneficial. this is due to how the illumina software must calibrate both to identify the cluster boundaries on the flow cell and to assess the quality of nucleotide calls. proper calibration requires that both the red laser, recognizing g/t and the green laser, recognizing a/c, be sufficiently excited, which requires nucleotide complexity at every cycle in the sequencing run. this is especially important in the early cycles  <cit> . as the restriction site for enzymes recognizing palindromic motifs occur at the beginning of a read, this has the potential to severely disrupt a sequencing run.

for most enzymes, namely ones that cut in the center of a palindromic sequence, this means that approximately 20-30% of a run must consist of a “calibration” sample with a random sequence. when whole genome sequence is desired or the sequencing center can arrange to conduct multiple experiments on a single lane, waste is not an issue due to this. when a full lane is desired, custom sequencing protocols may be used that defer cluster coordinate mapping past the motif-containing sequencing cycles  <cit>  or utilize custom sequencing primers that “mask” the restriction site may be used to avoid low-complexity issues. further, mlyi and other blunt-end restriction enzymes without a cutsite in the center of a palindromic sequence  do not have this calibration requirement as half or more of the reads will not contain a restriction motif at all.

sequencing efficiency
overall sequencing efficiency is a point of interest. gbs libraries prepared using this method lack complexity during the initial few cycles of a sequencing reaction, which much be compensated for as discussed above. they also have a considerably wider size range than a randomly sheared library. regarding the amount of sequencing that can be expected per lane of the hiseq  <dig>  we have obtained similar results to standard whole genome sequencing on some libraries. the rice enzyme panel produced just over two hundred million  <dig> ×  <dig> bp paired-end reads when run on an illumina hiseq  <dig>  lane, which was approximately 33% above what would be expected from a lane of wgs sequencing per illumina literature. the maize enzyme panel produced just over one hundred and fifty million reads, or approximately what was expected. the b <dig> x cg f <dig> populations, both hincii and rsai, were not run on a single lane however. both were initially run on 80% of a hiseq  <dig> lane then small amounts of additional resequencing were performed. in the case of rsai, this was targeted across all samples, whereas for hincii, fourteen specific samples were resequenced. this is likely part of the reason why the coefficient of variation in readcount was much smaller for hincii  than rsai . variations in sample read count were most likely due to the use of manual pipetting as well as variation in dna input quantity, as we found no evidence of a correlation between readcounts for samples that shared the same barcodes between datasets . we have found based on later gbs experiments that improvements in normalizing dna input as well as a switch to automatic pipette systems have reduced sample variation considerably.

effect of genome on enzyme selection
enzyme panels were tested on both b <dig> maize and nipponbare rice. while both are critical crop species, their genomes are very dissimilar. the maize genome is large at  <dig> mbp and highly enriched for methylated transposon content. estimates place the total transposable element content of the b <dig> genome at above 80%  <cit> . the rice genome is much smaller at approximately  <dig> mbp and is much less repetitive at approximately 40%  <cit> . these parameters resulted in very different experimental outcomes.

the first, and most obvious difference was in the fraction of reads that could be aligned to a genome with high confidence, represented by mapping quality. on average, twenty percent more reads could be aligned with a mq ≥ <dig> in rice than in maize . this is not an unexpected result. what was unexpected was that while paired-end reads conferred a statistically significant improvement in alignment quality over single end reads in maize, they did not do so in rice. in fact, the opposite was observed. again, this is likely due to the differences in repetitive content between the two genomes. additional sequence was able to improve the rate of alignment in maize, but in rice, where shorter sequences were more likely to be suitable for a unique alignment, additional sequence just increased the likelihood of sequencing errors reducing the alignment quality.

the second experimental outcome that differed greatly between the two genomes was methylation sensitivity. in maize, hincii, rsai, and alui showed significant reductions in g/c content surrounding the restriction motif at sequenced sites versus the predicted g/c content of all possible sites . further, the fraction of covered reads in genic regions was also greater than predicted by as much as twofold . in rice, the proportion of covered sites in genic regions was higher than in maize, the differences between the total predicted and covered datasets tended to be much smaller . further, there was little or no evidence of bias against restriction sites with a potentially methylated motif for any enzyme . this follows the observation that the maize genome contains a much larger proportion of methylated, repetitive content than rice.

the conclusion of the genome comparison, that enzyme choice should take into account the genome of the target organism is not surprising. utilization of methylation sensitive enzymes avoids repeat content in methylated, repeat rich genomes. paired-end sequencing in difficult, highly repetitive genomes may produce a considerable increase in useable markers, whereas in much simpler genomes the use of single-end sequencing this may not be an issue. one area that was not directly examined in this study but would likely improve data quality is the use of restriction enzymes that are biased away from repetitive regions by the sequence of their recognition motif. identifying transposon families or repetitive elements likely to be present in a given genome and selecting an enzyme that does not recognize their sequence may further reduce coverage of unformative regions.

variant calling and filtering
gbs datasets present unique challenges to variant calling and filtering. while traditional metrics like mapping quality and phred score can be applied, the fixed ends of gbs fragments confound the allelic balance metric and the removal of pcr duplicates by collapsing non-unique reads. incorporating a low cycle pcr step minimized the latter issue but gbs variant filtering required additional metrics, such as linkage disequilibrium, heterozygosity, and hardy-weinberg equilibrium . each of these metrics has circumstantial utility. for instance, linkage disequilibrium analysis requires a reference genome with contigs or scaffolds of sufficient size to compare markers. in wild populations, linkage disequilibrium is highly dependent on population history  <cit> . hwe is a useful metric for wild populations, but artificial crosses may have issues with segregation distortion or non-random mating. heterozygosity is applicable to many experiments, but measurements should be corrected for coverage and take into account population history. a final note for any error correction is that variants called from paired-end reads aligning to the same position should be collapsed to a single datapoint when attempting admixture analysis or trait mapping and should be weighted accordingly. when treating paired-reads as single-end tags, this may cause allelic bias if each tag is treated independently. many of the error correction tools and concepts have been built into tassel, a software package developed for gbs analysis  <cit> .

trait mapping in an f <dig> population
to test our modified gbs protocol, we mapped two traits, yellowy  and sugary  in a maize f <dig> population of ninety-one individuals. correct locations for each causative allele were identified with both tested enzymes, rsai and hincii. while data imputation did confer additional significance to association measurements, filtered, unimputed markers were still able to correctly identify the regions containing the causative alleles .

rsai, as was suggested by its marker density profile and overall less complex motif, was able to identify over ninety thousand post-filter markers, compared to just over twelve thousand post-filter markers in the hincii dataset . in addition, each rsai sample had, on average, three times as many covered markers as per hincii sample. the rsai and hincii samples both underwent approximately the same amount of sequencing. at first glance, this indicates rsai was the better enzyme. higher marker density leads to better resolution of recombination breakpoints. however, what is also noteworthy is the number of samples covered per marker . with hincii, markers were covered across almost every sample, while in rsai each marker was covered in only ~30% of samples. further, many rsai markers even within a few cm to the mapped locations of y <dig> and su <dig> did not necessarily show significant association with their respective phenotypes pre-imputation. in hincii, virtually every marker surrounding the previously identified locations for the two mapped traits showed a significant association with phenotypes pre and post imputation. thus, in scenarios where imputation is not possible, enzymes with a long, complex motif resulting in a more limited set of covered sites may be desirable.

CONCLUSIONS
next generation sequencing has clearly demonstrated its utility for generating large, robust datasets for population genomics in humans. migrating these methods and utilities to other reference organisms has been met with difficulty, however. the major obstacle has traditionally been poor or non-existent reference genomes combined with the high cost of developing oligo capture arrays required for exome sequencing, the most popular method for genotyping in humans. nonetheless, low-cost, highly scalable sequencing is a critical requirement for large-scale population genomics in any species. since the introduction of rad sequencing seven years ago, methods have steadily progressed that answer this need. our modified gbs protocol represents another step that significantly improves on pre-existing capacity while adding several new ones.

most critical amongst these refinements is the low starting cost adaptors, primers and reagents required for implementation. compatibility with numerous blunt-end restriction enzymes allows for enzyme parameters to be matched to the needs of a given experiment. further, the switch to illumina y-adaptors results in reduced concatamer formation due to the da tailing step, which in turn improves the quality of paired-end sequencing data.

the resulting protocol has several advantages and disadvantages compared to the original protocol described by elshire et al. the key advantage is the ability to switch between restriction enzymes with no change in utilized primers or adaptors. further, compatibility with illumina y-adaptors, paired with the da tailing step, prevents concatamer formation, increases the sequenceable fraction of the library, and allows for paired-end sequencing. finally, the use of illumina y-adaptors allows the pcr incorporation of dual-indexed barcodes during library amplification, which facilitates large-scale, inexpensive multiplexing.

there are several disadvantages, however, compared to the elshire et al. protocol. first, the use of custom adaptors allows for modulation of the barcode length, whereas this protocol requires the “spike-in” of approximately 20% random dna to a sequencing lane to prevent sequencer calibration problems from arising due to reduced nucleotide complexity. this can be avoided by the use of custom sequencing primers that mask the restriction motif or the use of “dark cycling”, which is the continuation of the non-imaging portion of the sequencing pcr reaction through invariant bases. in addition, the use of custom adaptors specific to an enzyme overhang reduces the number of sequencing reads originating from random, broken dna fragments. these random, broken ends occur on less than 1% of the sequencing reads for enzymes such as alui, but may occur in up to or over 10% of the reads in hincii, stui, and ecorv.

the key factors that must be balanced in any gbs experiment are multiplexing, resolution, and coverage. optimal marker density for qtl mapping and other population genomics increases with the expected number of recombination events per sample and sample size. this can be empirically calculated to a degree  <cit> . all three are directly affected by enzyme choice. a four base pair cutting enzyme will produce a dense site profile across the genome but large amount of sequencing is required to obtain coverage on predicted sites. a six base pair cutting enzyme will produce a sparse site profile, but less sequencing will accomplish coverage saturation. as demonstrated by our b <dig> × cg f <dig> population, even a simple imputation method resolved these issues by removing ambiguous data. however, imputation remains a critical area for improvement in gbs.

many popular imputation algorithms are designed specifically for human data  <cit> . these methods often assume high per-marker accuracy, complex haplotype, and the availability of a reference genome. gbs datasets, on the other hand, may have significant amounts of missing or inaccurate data. haplotypes may be complex in some cases, but in many experiments parental data will be available and genotypes can be phased in a straightforward manner. reference genomes are often not available or are incomplete. while popular methods such as fastphase can be applied to gbs data , pre-processing is advisable. pre-processing should test for false homozygotes resulting from low coverage and collapse non-independent markers into single values. non-independent markers are polymorphisms called from a set of reads aligned to the same location, which is typical with gbs experiments. errors, including misalignment, false homozygosity, and paralogous sequence will be common to all markers originating from this set of reads. improperly accounted for, they may offer multiple, seemingly independent confirmations of a false genotype that may produce an incorrect result from imputation. thus, it is recommended that all markers from the same set of reads be treated as a single event rather than independently.

in the case of datasets from organisms with non-existent or incomplete reference genomes, namely ones that exist as unscaffolded contigs, algorithms designed for humans fail entirely. imputation methods do exist that are suitable for these datasets that can provide high levels of accuracy  <cit> . while differing in implementation, these methods consistently rely on identifying proximal markers through linkage disequilibrium. as such, an initial dataset with only a modest number of missing markers is advisable when employing these methods. in addition, data with a high error rate may be unsuitable for these algorithms.

imputation methods designed for gbs are implemented to incorporate parental data into phasing and, when necessary, impute missing parental genotypes from population data. further, they do not assume hardy-weinberg equilibrium or random mating, as may be the case with many populations. many, however, are designed to work with nams or other populations without heterozygosity  <cit> . of the gbs capable imputation methods that do exist, most are designed for inbred lines where heterozygosity is largely absent. for populations with large remaining amounts of heterozygosity, these methods are unsuitable. thus, the next critical field for improvement in gbs is likely to be an imputation algorithm or package of algorithms that can answer its unique requirements.

the choice of enzyme is therefore highly dependent on available data resources. in a population with a well-established reference genome and little heterozygosity, imputation may reconcile a dataset with large amounts of missing markers into a robust genetic map. in an organism with a contig-level or non-existent reference genome, selecting an enzyme with a sparse profile so each marker is covered in a large number of samples may be desirable. that being said, most error correction methods will require that a given marker have sequencing coverage across a sufficient number of samples.

gbs has already demonstrated viability in trait mapping, admixture analysis, genome wide association, population genomics, and characterization of diversity in reference and non-reference organisms  <cit> . the modifications described here increase the portability of gbs to individual labs interested in adopting it by reducing the initial cost of oligos, allowing for simple, low-cost, pilot experiments, and integrating library preparation more directly into the standard illumina pipeline.

